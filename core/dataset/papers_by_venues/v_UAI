#index 385444
#* Uncertainty in Artificial Intelligence: Proceedings of the Thirteenth Conference
#@ Dan Geiger;Prakash Pundalik Shenoy
#t 1998
#c 12
#! From the Publisher:Proceedings of the annual Conference on Uncertainty in Artificial Intelligence, available for 1991-present.

#index 455905
#* Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence
#@ Craig Boutilier;Moisés Goldszmidt
#t 2000
#c 12

#index 455906
#* Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence
#@ Jack S. Breese;Daphne Koller
#t 2001
#c 12

#index 527853
#* Experiments with Random Projection
#@ Sanjoy Dasgupta
#t 2000
#c 12

#index 527854
#* A Two-Round Variant of EM for Gaussian Mixtures
#@ Sanjoy Dasgupta;Leonard J. Schulman
#t 2000
#c 12

#index 527855
#* Likelihood Computations Using Value Abstraction
#@ Nir Friedman;Dan Geiger;Noam Lotner
#t 2000
#c 12

#index 527856
#* Computational Investigation of Low-Discrepancy Sequences in Simulation Algorithms for Bayesian Networks
#@ Jian Cheng;Marek J. Druzdzel
#t 2000
#c 12

#index 527857
#* Feature Selection and Dualities in Maximum Entropy Discrimination
#@ Tony Jebara;Tommi Jaakkola
#t 2000
#c 12

#index 527858
#* Conversation as Action Under Uncertainty
#@ Tim Paek;Eric Horvitz
#t 2000
#c 12

#index 527859
#* PEGASUS: A policy search method for large MDPs and POMDPs
#@ Andrew Y. Ng;Michael I. Jordan
#t 2000
#c 12

#index 527860
#* User Interface Tools for Navigation in Conditional Probability Tables and Elicitation of Probabilities in Bayesian Networks
#@ Haiqin Wang;Marek J. Druzdzel
#t 2000
#c 12

#index 527984
#* Bayesian Classification and Feature Selection from Finite Data Sets
#@ Frans Coetzee;Steve Lawrence;C. Lee Giles
#t 2000
#c 12

#index 527985
#* Model Criticism of Bayesian Networks with Latent Variables
#@ David M. Williamson;Russell Almond;Robert Mislevy
#t 2000
#c 12

#index 527986
#* Inference for Belief Networks Using Coupling From the Past
#@ Michael Harvey;Radford M. Neal
#t 2000
#c 12

#index 527987
#* Learning to Cooperate via Policy Search
#@ Leonid Peshkin;Kee-Eung Kim;Nicolas Meuleau;Leslie Pack Kaelbling
#t 2000
#c 12

#index 527988
#* Any-Space Probabilistic Inference
#@ Adnan Darwiche
#t 2000
#c 12

#index 527989
#* Causal Mechanism-based Model Constructions
#@ Tsai-Ching Lu;Marek J. Druzdzel;Tze-Yun Leong
#t 2000
#c 12

#index 527990
#* Conditional Plausibility Measures and Bayesian Networks
#@ Joseph Y. Halpern
#t 2000
#c 12

#index 527991
#* Compact Securities Markets for Pareto Optimal Reallocation of Risk
#@ David M. Pennock;Michael P. Wellman
#t 2000
#c 12

#index 527992
#* Reversible Jump MCMC Simulated Annealing for Neural Networks
#@ Christophe Andrieu;Nando de Freitas;Arnaud Doucet
#t 2000
#c 12

#index 527993
#* Game Networks
#@ Pierfrancesco La Mura
#t 2000
#c 12

#index 527994
#* Policy Iteration for Factored MDPs
#@ Daphne Koller;Ronald Parr
#t 2000
#c 12

#index 527995
#* Approximately Optimal Monitoring of Plan Preconditions
#@ Craig Boutilier
#t 2000
#c 12

#index 527996
#* A Bayesian Method for Causal Modeling and Discovery Under Selection
#@ Gregory F. Cooper
#t 2000
#c 12

#index 527997
#* Conditional Independence and Markov Properties in Possibility Theory
#@ Jirina Vejnarová
#t 2000
#c 12

#index 527998
#* YGGDRASIL-A statistical package for learning Split Models
#@ Søren Højsgaard
#t 2000
#c 12

#index 527999
#* Probabilistic Models for Agent's Beliefs and Decisions
#@ Brian Milch;Daphne Koller
#t 2000
#c 12

#index 528000
#* Combining Feature and Example Pruning by Uncertainty Minimization
#@ Marc Sebban;Richard Nock
#t 2000
#c 12

#index 528001
#* Representing and Solving Asymmetric Bayesian Decision Problems
#@ Thomas D. Nielsen;Finn Verner Jensen
#t 2000
#c 12

#index 528002
#* Mix-nets: Factored Mixtures of Gaussians in Bayesian Networks with Mixed Continuous And Discrete Variables
#@ Scott Davies;Andrew W. Moore
#t 2000
#c 12

#index 528003
#* Value-Directed Belief State Approximation for POMDPs
#@ Pascal Poupart;Craig Boutilier
#t 2000
#c 12

#index 528004
#* Being Bayesian about Network Structure
#@ Nir Friedman;Daphne Koller
#t 2000
#c 12

#index 528005
#* Gaussian Process Networks
#@ Nir Friedman;Iftach Nachman
#t 2000
#c 12

#index 528006
#* The Complexity of Decentralized Control of Markov Decision Processes
#@ Daniel S. Bernstein;Shlomo Zilberstein;Neil Immerman
#t 2000
#c 12

#index 528007
#* Building a Stochastic Dynamic Model of Application Use
#@ Peter Gorniak;David Poole
#t 2000
#c 12

#index 528008
#* Model-Based Hierarchical Clustering
#@ Shivakumar Vaithyanathan;Byron Dom
#t 2000
#c 12

#index 528009
#* Risk Agoras: Dialectical Argumentation for Scientific Reasoning
#@ Peter McBurney;Simon Parsons
#t 2000
#c 12

#index 528010
#* Separation Properties of Sets of Probability Measures
#@ Fabio Gagliardi Cozman
#t 2000
#c 12

#index 528011
#* Pivotal Pruning of Trade-offs in QPNs
#@ Silja Renooij;Linda C. van der Gaag;Simon Parsons;Shaw Green
#t 2000
#c 12

#index 528012
#* A principled analysis of merging operations in possibilistic logic
#@ Souhila Kaci;Salem Benferhat;Didier Dubois;Henri Prade
#t 2000
#c 12

#index 528013
#* Dynamic Trees: A Structured Variational Method Giving Efficient Propagation Rules
#@ Amos J. Storkey
#t 2000
#c 12

#index 528014
#* Stochastic Logic Programs: Sampling, Inference and Applications
#@ James Cussens
#t 2000
#c 12

#index 528015
#* Using ROBDDs for Inference in Bayesian Networks with Troubleshooting as an Example
#@ Thomas D. Nielsen;Pierre-Henri Wuillemin;Finn Verner Jensen;Uffe Kjæruff
#t 2000
#c 12

#index 528016
#* Probabilistic Arc Consistency: A Connection between Constraint Reasoning and Probabilistic Reasoning
#@ Michael C. Horsch;William S. Havens
#t 2000
#c 12

#index 528017
#* A Knowledge Acquisition Tool for Bayesian-Network Troubleshooters
#@ Claus Skaanning
#t 2000
#c 12

#index 528018
#* Nash Convergence of Gradient Dynamics in General-Sum Games
#@ Satinder P. Singh;Michael J. Kearns;Yishay Mansour
#t 2000
#c 12

#index 528019
#* Variational Approximations between Mean Field Theory and the Junction Tree Algorithm
#@ Wim Wiegerinck
#t 2000
#c 12

#index 528020
#* Variational Relevance Vector Machines
#@ Christopher M. Bishop;Michael E. Tipping
#t 2000
#c 12

#index 528021
#* Evaluating Influence Diagrams using LIMIDs
#@ Dennis Nilsson;Steffen L. Lauritzen
#t 2000
#c 12

#index 528022
#* Perfect Tree-like Markovian Distributions
#@ Ann Becker;Dan Geiger;Christopher Meek
#t 2000
#c 12

#index 528023
#* Probabilistic Models for Query Approximation with Large Sparse Binary Data Sets
#@ Dmitry Pavlov;Heikki Mannila;Padhraic Smyth
#t 2000
#c 12

#index 528024
#* A Qualitative Linear Utility Theory for Spohn's Theory of Epistemic Beliefs
#@ Phan H. Giang;Prakash P. Shenoy
#t 2000
#c 12

#index 528025
#* A Differential Approach to Inference in Bayesian Networks
#@ Adnan Darwiche
#t 2000
#c 12

#index 528026
#* Utilities as Random Variables: Density Estimation and Structure Discovery
#@ Urszula Chajewska;Daphne Koller
#t 2000
#c 12

#index 528027
#* Making Sensitivity Analysis Computationally Efficient
#@ Uffe Kjærulff;Linda C. van der Gaag
#t 2000
#c 12

#index 528150
#* Marginalization in Composed Probabilistic Models
#@ Radim Jirousek
#t 2000
#c 12

#index 528151
#* Tractable Bayesian Learning of Tree Belief Networks
#@ Marina Meila;Tommi Jaakkola
#t 2000
#c 12

#index 528152
#* Dependency Networks for Collaborative Filtering and Data Visualization
#@ David Heckerman;David Maxwell Chickering;Christopher Meek;Robert Rounthwaite;Carl Myers Kadie
#t 2000
#c 12

#index 528153
#* Fast Planning in Stochastic Games
#@ Michael J. Kearns;Yishay Mansour;Satinder P. Singh
#t 2000
#c 12

#index 528154
#* Dynamic Bayesian Multinets
#@ Jeff Bilmes
#t 2000
#c 12

#index 528155
#* A Complete Calcultis for Possibilistic Logic Programming with Fuzzy Propositional Variables
#@ Teresa Alsinet;Lluis Godo
#t 2000
#c 12

#index 528156
#* Collaborative Filtering by Personality Diagnosis: A Hybrid Memory and Model-Based Approach
#@ David M. Pennock;Eric Horvitz;Steve Lawrence;C. Lee Giles
#t 2000
#c 12

#index 528157
#* Maximum Entropy and the Glasses You are Looking Through
#@ Peter Grünwald
#t 2000
#c 12

#index 528158
#* An Uncertainty Framework for Classification
#@ Loo-Nin Teow;Kia-Fock Loe
#t 2000
#c 12

#index 528159
#* Probabilities of Causation: Bounds and Identification
#@ Jin Tian;Judea Pearl
#t 2000
#c 12

#index 528160
#* On the Use of Skeletons when Learning in Bayesian Networks
#@ Harald Steck
#t 2000
#c 12

#index 528161
#* Exploiting Qualitative Knowledge in the Learning of Conditional Probabilities of Bayesian Networks
#@ Frank Wittig;Anthony Jameson
#t 2000
#c 12

#index 528162
#* Monte Carlo inference via greedy importance sampling
#@ Dale Schuurmans;Finnegan Southey
#t 2000
#c 12

#index 528163
#* Combinatonal Optimization by Learning and Simulation of Bayesian Networks
#@ Pedro Larrañaga;Ramon Etxeberria;Jose Antonio Lozano;Jose Manuel Peña
#t 2000
#c 12

#index 528164
#* The Anchors Hierarchy: Using the Triangle Inequality to Survive High Dimensional Data
#@ Andrew W. Moore
#t 2000
#c 12

#index 528165
#* Learning Graphical Models of Images, Videos and Their Spatial Transformations
#@ Brendan J. Frey;Nebojsa Jojic
#t 2000
#c 12

#index 528166
#* Minimum Message Length Clustering Using Gibbs Sampling
#@ Ian Davidson
#t 2000
#c 12

#index 528167
#* Adaptive Importance Sampling for Estimation in Structured Domains
#@ Luis E. Ortiz;Leslie Pack Kaelbling
#t 2000
#c 12

#index 528168
#* A Decision Theoretic Approach to Targeted Advertising
#@ David Maxwell Chickering;David Heckerman
#t 2000
#c 12

#index 528169
#* Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks
#@ Arnaud Doucet;Nando de Freitas;Kevin P. Murphy;Stuart J. Russell
#t 2000
#c 12

#index 528170
#* A Bayesian Multiresolution Independence Test for Continuous Variables
#@ Dimitris Margaritis;Sebastian Thrun
#t 2001
#c 12

#index 528171
#* Efficient Approximation for Triangulation of Minimum Treewidth
#@ Eyal Amir
#t 2001
#c 12

#index 528172
#* A Logic for Reasoning about Upper Probabilities
#@ Joseph Y. Halpern;Riccardo Pucella
#t 2001
#c 12

#index 528173
#* Confidence Inference in Bayesian Networks
#@ Jian Cheng;Marek J. Druzdzel
#t 2001
#c 12

#index 528174
#* Multivariate Information Bottleneck
#@ Nir Friedman;Ori Mosenzon;Noam Slonim;Naftali Tishby
#t 2001
#c 12

#index 528175
#* Approximating MAP using Local Search
#@ James D. Park;Adnan Darwiche
#t 2001
#c 12

#index 528176
#* UCP-Networks: A Directed Graphical Representation of Conditional Utilities
#@ Craig Boutilier;Fahiem Bacchus;Ronen I. Brafman
#t 2001
#c 12

#index 528177
#* Aggregating Learned Probabilistic Beliefs
#@ Pedrito Maynard-Reid, II;Urszula Chajewska
#t 2001
#c 12

#index 528178
#* Direct and Indirect Effects
#@ Judea Pearl
#t 2001
#c 12

#index 528179
#* Maximum Likelihood Bounded Tree-Width Markov Networks
#@ Nathan Srebro
#t 2001
#c 12

#index 528180
#* Efficient Stepwise Selection in Decomposable Models
#@ Amol Deshpande;Minos N. Garofalakis;Michael I. Jordan
#t 2001
#c 12

#index 528181
#* Recognition Networks for Approximate Inference in BN20 Networks
#@ Quaid Morris
#t 2001
#c 12

#index 528182
#* Probabilistic Models for Unified Collaborative and Content-Based Recommendation in Sparse-Data Environments
#@ Alexandrin Popescul;Lyle H. Ungar;David M. Pennock;Steve Lawrence
#t 2001
#c 12

#index 528183
#* A Case Study in Knowledge Discovery and Elicitation in an Intelligent Tutoring Application
#@ Ann E. Nicholson;Tal Boneh;Tim A. Wilkin;Kaye Stacey;Liz Sonenberg;Vicki Steinle
#t 2001
#c 12

#index 528184
#* A Calculus for Causal Relevance
#@ Blai Bonet
#t 2001
#c 12

#index 528185
#* Vector-space Analysis of Belief-state Approximation for POMDPs
#@ Pascal Poupart;Craig Boutilier
#t 2001
#c 12

#index 528186
#* When do Numbers Really Matter?
#@ Hei Chan;Adnan Darwiche
#t 2001
#c 12

#index 528187
#* Conditions Under Which Conditional Independence and Scoring Methods Lead to Identical Selection of Bayesian Network Models
#@ Robert G. Cowell
#t 2001
#c 12

#index 528188
#* Semi-Instrumental Variables: A Test for Instrument Admissibility
#@ Tianjiao Chu;Richard Scheines;Peter Spirtes
#t 2001
#c 12

#index 528189
#* Discovering Multiple Constraints that are Frequently Approximately Satisfied
#@ Geoffrey E. Hinton;Yee Whye Teh
#t 2001
#c 12

#index 528190
#* Incorporating Expressive Graphical Models in VariationalApproximations: Chain-graphs and Hidden Variables
#@ Tal El-Hay;Nir Friedman
#t 2001
#c 12

#index 528191
#* A Clustering Approach to Solving Large Stochastic Matching Problems
#@ Milos Hauskrecht;Eli Upfal
#t 2001
#c 12

#index 528192
#* Probabilistic Logic Programming under Inheritance with Overriding
#@ Thomas Lukasiewicz
#t 2001
#c 12

#index 528298
#* Using Bayesian Networks to Identify the Causal Effect of Speeding in Individual Vehicle/Pedestrian Collisions
#@ Gary A. Davis
#t 2001
#c 12

#index 528299
#* Robust Combination of Local Controllers
#@ Carlos Guestrin;Dirk Ormoneit
#t 2001
#c 12

#index 528300
#* Belief Optimization for Binary Networks: A Stable Alternative to Loopy Belief Propagation
#@ Max Welling;Yee Whye Teh
#t 2001
#c 12

#index 528301
#* Hypothesis Management in Situation-Specific Network Construction
#@ Kathryn B. Laskey;Suzanne M. Mahoney;Ed Wright
#t 2001
#c 12

#index 528302
#* Decision-Theoretic Planning with Concurrent Temporally Extended Actions
#@ Khashayar Rohanimanesh;Sridhar Mahadevan
#t 2001
#c 12

#index 528303
#* Estimating Well-Performing Bayesian Networks using Bernoulli Mixtures
#@ Geoff A. Jarrad
#t 2001
#c 12

#index 528304
#* Enumerating Markov Equivalence Classes of Acyclic Digraph Models
#@ Steven B. Gillispie;Christiane Lemieux
#t 2001
#c 12

#index 528305
#* A Mixed Graphical Model for Rhythmic Parsing
#@ Christopher Raphael
#t 2001
#c 12

#index 528306
#* Learning the Dimensionality of Hidden Variables
#@ Gal Elidan;Nir Friedman
#t 2001
#c 12

#index 528307
#* A Bayesian Approach to Tackling Hard Computational Problems
#@ Eric Horvitz;Yongshao Ruan;Carla P. Gomes;Henry A. Kautz;Bart Selman;David Maxwell Chickering
#t 2001
#c 12

#index 528308
#* Planning and Acting under Uncertainty: A New Model for Spoken Dialogue System
#@ Bo Zhang;Qingsheng Cai;Jianfeng Mao;Baining Guo
#t 2001
#c 12

#index 528309
#* Exact Inference in Networks with Discrete Children of Continuous Parents
#@ Uri Lerner;Eran Segal;Daphne Koller
#t 2001
#c 12

#index 528310
#* Toward General Analysis of Recursive Probability Models
#@ Daniel Pless;George F. Luger
#t 2001
#c 12

#index 528311
#* Plausible reasoning from spatial observations
#@ Jérôme Lang;Philippe Muller
#t 2001
#c 12

#index 528312
#* Iterative Markov Chain Monte Carlo Computation of Reference Priors and Minimax Risk
#@ John D. Lafferty;Larry A. Wasserman
#t 2001
#c 12

#index 528313
#* A Comparison of Axiomatic Approaches to Qualitative Decision Making Using Possibility Theory
#@ Phan H. Giang;Prakash P. Shenoy
#t 2001
#c 12

#index 528314
#* Instrumentality Tests Revisited
#@ Blai Bonet
#t 2001
#c 12

#index 528315
#* Variational MCMC
#@ Nando de Freitas;Pedro A. d. F. R. Højen-Sørensen;Stuart J. Russell
#t 2001
#c 12

#index 528316
#* Statistical Modeling in Continuous Speech Recognition (CSR)
#@ Steve Young
#t 2001
#c 12

#index 528317
#* A Tractable POMDP for Dynamic Sequencing with Applications to Personalized Internet Content Provision
#@ Paat Rusmevichientong;Benjamin Van Roy
#t 2001
#c 12

#index 528318
#* A Factorized Variational Technique for Phase Unwrapping in Markov Random Field
#@ Kannan Achan;Brendan J. Frey;Ralf Koetter
#t 2001
#c 12

#index 528319
#* Bayesian Error-Bars for Belief Net Inference
#@ Tim Van Allen;Russell Greiner;Peter Hooper
#t 2001
#c 12

#index 528320
#* Lattice Particle Filters
#@ Dirk Ormoneit;Christiane Lemieux;David J. Fleet
#t 2001
#c 12

#index 528321
#* Classifier Learning with Supervised Marginal Likelihood
#@ Petri Kontkanen;Petri Myllymäki;Henry Tirri
#t 2001
#c 12

#index 528322
#* Policy Improvement for POMDPs Using Normalized Importance Sampling
#@ Christian R. Shelton
#t 2001
#c 12

#index 528323
#* Sufficiency, Separability and Temporal Probabilistic Models
#@ Avi Pfeffer
#t 2001
#c 12

#index 528324
#* A Dynamic Programming Model for Determining Bidding Strategies in Sequential Auctions: Quasi-linear Utility and Budget Constraints
#@ Hiromitsu Hattori;Makoto Yokoo;Yuko Sakurai;Toramatsu Shintani
#t 2001
#c 12

#index 528325
#* The Optimal Reward Baseline for Gradient-Based Reinforcement Learning
#@ Lex Weaver;Nigel Tao
#t 2001
#c 12

#index 528326
#* Markov Chain Monte Carlo using Tree-Based Priors on Model Structure
#@ Nicos Angelopoulos;James Cussens
#t 2001
#c 12

#index 528327
#* Inference in Hybrid Networks: Theoretical Limits and Practical Algorithms
#@ Uri Lerner;Ronald Parr
#t 2001
#c 12

#index 528328
#* Hybrid Processing of Beliefs and Constraints
#@ Rina Dechter;David Larkin
#t 2001
#c 12

#index 528329
#* Linearity Properties of Bayes Nets with Binary Variables
#@ David Danks;Clark Glymour
#t 2001
#c 12

#index 528330
#* Expectation Propagation for approximate Bayesian inference
#@ Thomas P. Minka
#t 2001
#c 12

#index 528331
#* Analysing Sensitivity Data from Probabilistic Networks
#@ Linda C. van der Gaag;Silja Renooij
#t 2001
#c 12

#index 528332
#* Causal Discovery from Changes
#@ Jin Tian;Judea Pearl
#t 2001
#c 12

#index 528333
#* Improved learning of Bayesian networks
#@ Tomas Kocka;Robert Castelo
#t 2001
#c 12

#index 528334
#* Causes and Explanations: A Structural-Model Approach: Part 1: Causes
#@ Joseph Y. Halpern;Riccardo Pucella
#t 2001
#c 12

#index 528335
#* On characterizing Inclusion of Bayesian Networks
#@ Tomas Kocka;Remco R. Bouckaert;Milan Studený
#t 2001
#c 12

#index 528336
#* Solving Influence Diagrams using HUGIN, Shafer-Shenoy and Lazy Propagation
#@ Anders L. Madsen;Dennis Nilsson
#t 2001
#c 12

#index 528337
#* Using Temporal Data for Making Recommendations
#@ Andrew Zimdars;David Maxwell Chickering;Christopher Meek
#t 2001
#c 12

#index 528338
#* Pre-processing for Triangulation of Probabilistic Networks
#@ Hans L. Bodlaender;Arie M. C. A. Koster;Frank van den Eijkhof;Linda C. van der Gaag
#t 2001
#c 12

#index 528339
#* Value-Directed Sampling Methods for POMDPs
#@ Pascal Poupart;Luis E. Ortiz;Craig Boutilier
#t 2001
#c 12

#index 528340
#* The Factored Frontier Algorithm for Approximate Inference in DBNs
#@ Kevin P. Murphy;Yair Weiss
#t 2001
#c 12

#index 564809
#* Credal Networks under Maximum Entropy
#@ Thomas Lukasiewicz
#t 2000
#c 12

#index 564810
#* Symmetric Collaborative Filtering Using the Noisy Sensor Model
#@ Rita Sharma;David Poole
#t 2001
#c 12

#index 564813
#* Graphical readings of possibilistic logic bases
#@ Salem Benferhat;Didier Dubois;Souhila Kaci;Henri Prade
#t 2001
#c 12

#index 567879
#* A Branch-and-Bound Algorithm for MDL Learning Bayesian Networks
#@ Jin Tian
#t 2000
#c 12

#index 567880
#* Probabilistic State-Dependent Grammars for Plan Recognition
#@ David V. Pynadath;Michael P. Wellman
#t 2000
#c 12

#index 567881
#* Similarity Measures on Preference Structures, Part II: Utility Functions
#@ Vu A. Ha;Peter Haddawy;John Miyamoto
#t 2001
#c 12

#index 567882
#* Cross-covariance modelling via DAGs with hidden variables
#@ Jacob A. Wegelin;Thomas Richardson
#t 2001
#c 12

#index 567883
#* Graphical Models for Game Theory
#@ Michael J. Kearns;Michael L. Littman;Satinder P. Singh
#t 2001
#c 12

#index 788035
#* Proceedings of the 20th conference on Uncertainty in artificial intelligence
#@ Christopher Meek;Max Chickering;Joseph Halpern
#t 2004
#c 12
#! This year marks the 20th anniversary of the Conference of Uncertainty in Artificial Intelligence (UAI). From its beginnings as a small workshop, UAI has grown to become the leading conference in the field. It is now the primary international forum for presenting new results on the use of principled methods for reasoning under uncertainty within intelligent systems. The scope of UAI is wide, including, but not limited to, representation, automated reasoning, learning, decision making, and knowledge acquisition under uncertainty. This year's conference (UAI 2004) continues the tradition, including contributions that report on advances in these core areas, as well as insights derived from the construction and use of applications involving uncertain reasoning. This volume comprises the papers accepted for presentation at UAI 2004, held at the Banff Park Inn in Banff, Canada, from July 7 through 11, 2004. Papers appearing in this volume were subjected to rigorous review; three Program Committee members (or in some cases, auxiliary reviewers) reviewed each paper under the supervision of an Area Chair, who made recommendations to the Program Chairs. The assignment of Program Committee members to papers was based on their expertise and expressed interests in the papers, with an eye toward coverage of the relevant aspects of each paper. This year a record 253 papers were submitted to UAI, and 76 papers were accepted for plenary or poster presentation at the conference. All accepted papers appear in this volume. We are confident that the proceedings, like past UAI Conference Proceedings, will become an important archival reference for the field. Based on the recommendation of the program committee, we selected one paper for the recipient of the Best Paper Award and one as the recipient of the Best Student Paper Award. These awards were given for outstanding technical contributions. We are pleased to present the UAI 2004 Best Paper Award to David McAllester, Michael Collins, and Fernando Pereira for their paper The Case-Factor Complexity of Markov Random Fields and the 2004 Best Student Paper Award to Mathias Drton and Thomas Richardson for their paper Iterative Conditional Fitting for Gaussian Ancestral Graph Models. The runners-up for the Best Student Paper Award were Gal Elidan, Iftach Nachman, and Nir Friedman for their paper "Ideal Parent" Structure Learning for Continuous Variable Networks. In addition to the presentation of technical papers, we were very pleased to have five distinguished invited speakers: Ed George (University of Pennsylvania), Jon Kleinberg (Cornell University), Lillian Lee (Cornell University), Alon Orlitsky (University of California at San Diego), and Moshe Y. Vardi (Rice University). UAI 2004 also continued the tradition of offering a full-day course on Advanced Topics in Uncertainty in Artificial Intelligence consisting of tutorials by Ronen Brafman (Ben-Gurion University), Rina Dechter (University of California at Irvine), Nir Friedman (Hebrew University), and Martin Wainwright (University of California at Berkeley). The set of papers, invited talks, and full-day course topics illustrate both the depth and breadth of UAI techniques and applications. We are proud of the quality of this year's conference, and are looking forward to continued contributions and growth in the future.

#index 788036
#* Exponential families for conditional random fields
#@ Yasemin Altun;Alex J. Smola;Thomas Hofmann
#t 2004
#c 12
#% 33917
#% 268069
#% 277516
#% 464434
#% 466597
#% 466892
#% 722815
#% 786576
#% 816181
#% 938738
#! In this paper we define conditional random fields in reproducing kernel Hilbert spaces and show connections to Gaussian Process classification. More specifically, we prove decomposition results for undirected graphical models and we give constructions for kernels. Finally we present efficient means of solving the optimization problem using reduced rank decompositions and we show how stationarity can be exploited efficiently in the optimization process.

#index 788037
#* Using arguments for making decisions: a possibilistic logic approach
#@ Leila Amgoud;Henri Prade
#t 2004
#c 12
#% 77841
#% 116292
#% 179919
#% 198464
#% 277105
#% 306015
#% 315415
#% 330290
#% 417812
#% 431089
#% 442844
#% 1279256
#% 1290145
#% 1650765
#! Humans currently use arguments for explaining choices which are already made, or for evaluating potential choices. Each potential choice has usually pros and cons of various strengths. In spite of the usefulness of arguments in a decision making process, there have been few formal proposals handling this idea if we except works by Fox and Parsons and by Bonet and Geffner. In this paper we propose a possibilistic logic framework where arguments are built from an uncertain knowledge base and a set of prioritized goals. The proposed approach can compute two kinds of decisions by distinguishing between pessimistic and optimistic attitudes. When the available, maybe uncertain, knowledge is consistent, as well as the set of prioritized goals (which have to be fulfilled as far as possible), the method for evaluating decisions on the basis of arguments agrees with the possibility theory-based approach to decision-making under uncertainty. Taking advantage of its relation with formal approaches to defeasible argumentation, the proposed framework can be generalized in case of partially inconsistent knowledge, or goal bases.

#index 788038
#* Recovering articulated object models from 3D range data
#@ Dragomir Anguelov;Daphne Koller;Hoi-Cheung Pang;Praveen Srinivasan;Sebastian Thrun
#t 2004
#c 12
#% 117665
#% 213577
#% 317002
#% 398443
#% 565233
#% 580307
#% 592413
#% 593940
#% 625130
#% 641982
#% 662898
#% 670826
#% 761536
#% 1279343
#% 1562511
#! We address the problem of unsupervised learning of complex articulated object models from 3D range data. We describe an algorithm whose input is a set of meshes corresponding to different configurations of an articulated object. The algorithm automatically recovers a decomposition of the object into approximately rigid parts, the location of the parts in the different object instances, and the articulated object skeleton linking the parts. Our algorithm first registers all the meshes using an unsupervised non-rigid technique described in a companion paper. It then segments the meshes using a graphical model that captures the spatial contiguity of parts. The segmentation is done using the EM algorithm, iterating between finding a decomposition of the object into rigid parts, and finding the location of the parts in the object instances. Although the graphical model is densely connected, the object decomposition step can be performed optimally and efficiently, allowing us to identify a large number of object parts while avoiding local maxima. We demonstrate the algorithm on real world datasets, recovering a 15-part articulated model of a human puppet from just 7 different puppet configurations, as well as a 4 part model of a flexing arm where significant non-rigid deformation was present.

#index 788039
#* Learning diagnostic policies from examples by systematic search
#@ Valentina Bayer-Zubek
#t 2004
#c 12
#% 25470
#% 136350
#% 183497
#% 384911
#% 443640
#% 447606
#% 464639
#% 466568
#% 1272369
#% 1650588
#% 1650712
#! A diagnostic policy specifies what test to perform next, based on the results of previous tests, and when to stop and make a diagnosis. Cost-sensitive diagnostic policies perform tradeoffs between (a) the costs of tests and (b) the costs of misdiagnoses. An optimal diagnostic policy minimizes the expected total cost. We formalize this diagnosis process as a Markov Decision Process (MDP). We investigate two types of algorithms for solving this MDP: systematic search based on the AO* algorithm and greedy search (particularly the Value of Information method). We investigate the issue of learning the MDP probabilities from examples, but only as they are relevant to the search for good policies. We do not learn nor assume a Bayesian network for the diagnosis process. Regularizers are developed that control overfitting and speed up the search. This research is the first that integrates overfitting prevention into systematic search. The paper has two contributions: it discusses the factors that make systematic search feasible for diagnosis, and it shows experimentally, on benchmark data sets, that systematic search methods produce better diagnostic policies than greedy methods.

#index 788040
#* Computing Nash equilibria of action-graph games
#@ Navin A. R. Bhat;Kevin Leyton-Brown
#t 2004
#c 12
#% 338466
#% 527993
#% 567883
#% 578708
#% 1279321
#% 1279323
#% 1289289
#% 1650376
#! Action-graph games (AGGs) are a fully expressive game representation which can compactly express both strict and context-specific independence between players' utility functions. Actions are represented as nodes in a graph G, and the payoff to an agent who chose the action s depends only on the numbers of other agents who chose actions connected to s. We present algorithms for computing both symmetric and arbitrary equilibria of AGGs using a continuation method. We analyze the worst-case cost of computing the Jacobian of the payoff function, the exponential-time bottleneck step, and in all cases achieve exponential speedup. When the in-degree of G is bounded by a constant and the game is symmetric, the Jacobian can be computed in polynomial time.

#index 788041
#* On finding minimal w-cutset
#@ Bozhena Bidyuk;Rina Dechter
#t 2004
#c 12
#% 1675
#% 36814
#% 68183
#% 150128
#% 269916
#% 275929
#% 289947
#% 338423
#% 341672
#% 370075
#% 420720
#% 451125
#% 644201
#% 1389692
#% 1650271
#% 1650763
#% 1672982
#! The complexity of a reasoning task over a graphical model is tied to the induced width of the underlying graph. It is well-known that the conditioning (assigning values) on a subset of variables yields a subproblem of the reduced complexity where instantiated variables are removed. If the assigned variables constitute a cycle-cutset, the rest of the network is singly-connected and therefore can be solved by linear propagation algorithms. A w-cutset is a generalization of a cycle-cutset defined as a subset of nodes such that the subgraph with cutset nodes removed has induced-width of w or less. In this paper we address the problem of finding a minimal w-cutset in a graph. We relate the problem to that of finding the minimal w-cutset of a tree-decomposition. The latter can be mapped to the well-known set multi-cover problem. This relationship yields a proof of NP-completeness on one hand and a greedy algorithm for finding a w-cutset of a tree decomposition on the other. Empirical evaluation of the algorithms is presented.

#index 788042
#* Compact value-function representations for qualitative preferences
#@ Ronen I. Brafman;Carmel Domshlak;Tanya Kogan
#t 2004
#c 12
#% 419996
#% 528176
#% 529348
#% 578692
#% 578698
#% 578734
#% 731407
#% 1272026
#% 1279242
#% 1650274
#% 1650354
#% 1650628
#% 1650721
#! We consider the challenge of preference elicitation in systems that help users discover the most desirable item(s) within a given database. Past work on preference elicitation focused on structured models that provide a factored representation of users' preferences. Such models require less information to construct and support efficient reasoning algorithms. This paper makes two substantial contributions to this area: (1) Strong representation theorems for factored value functions. (2) A methodology that utilizes our representation results to address the problem of optimal item selection.

#index 788043
#* Applying discrete PCA in data analysis
#@ Wray Buntine;Aleks Jakulin
#t 2004
#c 12
#% 269217
#% 280819
#% 443948
#% 458673
#% 719598
#% 722904
#% 1650387
#! Methods for analysis of principal components in discrete data have existed for some time under various names such as grade of membership modelling, probabilistic latent semantic analysis, and genotype inference with admixture. In this paper we explore a number of extensions to the common theory, and present some application of these methods to some common statistical tasks. We show that these methods can be interpreted as a discrete version of ICA. We develop a hierarchical version yielding components at different levels of detail, and additional techniques for Gibbs sampling. We compare the algorithms on a text prediction task using support vector machines, and to information retrieval.

#index 788044
#* Sensitivity analysis in Bayesian networks: from single to multiple parameters
#@ Hei Chan;Adnan Darwiche
#t 2004
#c 12
#% 44876
#% 351595
#% 527860
#% 528027
#% 571102
#% 578736
#% 1272350
#% 1673013
#% 1784188
#! Previous work on sensitivity analysis in Bayesian networks has focused on single parameters, where the goal is to understand the sensitivity of queries to single parameter changes, and to identify single parameter changes that would enforce a certain query constraint. In this paper, we expand the work to multiple parameters which may be in the CPT of a single variable, or the CPTs of multiple variables. Not only do we identify the solution space of multiple parameter changes that would be needed to enforce a query constraint, but we also show how to find the optimal solution, that is, the one which disturbs the current probability distribution the least (with respect to a specific measure of disturbance). We characterize the computational complexity of our new techniques and discuss their applications to developing and debugging Bayesian networks, and to the problem of reasoning about the value (reliability) of new information.

#index 788045
#* A logic programming framework for possibilistic argumentation with vague knowledge
#@ Carlos I. Chesñevar;Guillermo R. Simari;Teresa Alsinet;Lluís Godo
#t 2004
#c 12
#% 95229
#% 116292
#% 167544
#% 330290
#% 417788
#% 431089
#% 449611
#% 528155
#% 743396
#% 743452
#% 752766
#% 1650266
#% 1675014
#! Defeasible argumentation frameworks have evolved to become a sound setting to formalize commonsense, qualitative reasoning from incomplete and potentially inconsistent knowledge. Defeasible Logic Programming (DeLP) is a defeasible argumentation formalism based on an extension of logic programming. Although DeLP has been successfully integrated in a number of different real-world applications, DeLP cannot deal with explicit uncertainty, nor with vague knowledge, as defeasibility is directly encoded in the object language. This paper introduces P-DeLP, a new logic programming language that extends original DeLP capabilities for qualitative reasoning by incorporating the treatment of possibilistic uncertainty and fuzzy knowledge. Such features will be formalized on the basis of PGL, a possibilistic logic based on Gödel fuzzy logic.

#index 788046
#* Hybrid influence diagrams using mixtures of truncated exponentials
#@ Barry R. Cobb;Prakash P. Shenoy
#t 2004
#c 12
#% 34262
#% 61079
#% 119308
#% 528336
#% 739074
#% 1650309
#! Mixtures of truncated exponentials (MTE) potentials are an alternative to discretization for representing continuous chance variables in influence diagrams. Also, MTE potentials can be used to approximate utility functions. This paper introduces MTE influence diagrams, which can represent decision problems without restrictions on the relationships between continuous and discrete chance variables, without limitations on the distributions of continuous chance variables, and without limitations on the nature of the utility functions. In MTE influence diagrams, all probability distributions and the joint utility function (or its multiplicative factors) are represented by MTE potentials and decision nodes are assumed to have discrete state spaces. MTE influence diagrams are solved by variable elimination using a fusion algorithm.

#index 788047
#* Bayesian biosurveillance of disease outbreaks
#@ Gregory F. Cooper;Denver H. Dash;John D. Levander;Weng-Keen Wong;William R. Hogan;Michael M. Wagner
#t 2004
#c 12
#% 280413
#% 777338
#% 1650342
#% 1650731
#! Early, reliable detection of disease outbreaks is a critical problem today. This paper reports an investigation of the use of causal Bayesian networks to model spatio-temporal patterns of a non-contagious disease (respiratory anthrax infection) in a population of people. The number of parameters in such a network can become enormous, if not carefully managed. Also, inference needs to be performed in real time as population data stream in. We describe techniques we have applied to address both the modeling and inference challenges. A key contribution of this paper is the explication of assumptions and techniques that are sufficient to allow the scaling of Bayesian network modeling and inference to millions of nodes for real-time surveillance applications. The results reported here provide a proof-of-concept that Bayesian networks can serve as the foundation of a system that effectively performs Bayesian biosurveillance of disease outbreaks.

#index 788048
#* Propositional and relational Bayesian networks associated with imprecise and qualitative probabilistic assessments
#@ Fabio Gagliardi Cozman;Cassio Polpo de Campos;Jaime Shinsuke Ide;José Carlos Ferreira da Rocha
#t 2004
#c 12
#% 3034
#% 73571
#% 90371
#% 144840
#% 147677
#% 170207
#% 181038
#% 228812
#% 267725
#% 319172
#% 370075
#% 417753
#% 443359
#% 443639
#% 449617
#% 464304
#% 477924
#% 503673
#% 528010
#% 564813
#% 1650318
#% 1650391
#% 1650395
#% 1650396
#% 1650727
#% 1673003
#! This paper investigates a representation language with flexibility inspired by probabilistic logic and compactness inspired by relational Bayesian networks. The goal is to handle propositional and first-order constructs together with precise, imprecise, indeterminate and qualitative probabilistic assessments. The paper shows how this can be achieved through the theory of credal networks. New exact and approximate inference algorithms based on multilinear programming and iterated/loopy propagation of interval probabilities are presented; their superior performance, compared to existing ones, is shown empirically.

#index 788049
#* Stable independence and complexity of representation
#@ Peter de Waal;Linda C. van der Gaag
#t 2004
#c 12
#% 3460
#% 370075
#% 417569
#! The representation of independence relations generally builds upon the well-known semigraphoid axioms of independence. Recently, a representation has been proposed that captures a set of dominant statements of an independence relation from which any other statement can be generated by means of the axioms; the cardinality of this set is taken to indicate the complexity of the relation. Building upon the idea of dominance, we introduce the concept of stability to provide for a more compact representation of independence. We give an associated algorithm for establishing such a representation. We show that, with our concept of stability, many independence relations are found to be of lower complexity than with existing representations.

#index 788050
#* Mixtures of deterministic-probabilistic networks and their AND/OR search space
#@ Rina Dechter;Robert Mateescu
#t 2004
#c 12
#% 147677
#% 228812
#% 370075
#% 528328
#% 644201
#% 1499510
#% 1672978
#! The paper introduces mixed networks, a new framework for expressing and reasoning with probabilistic and deterministic information. The framework combines belief networks with constraint networks, defining the semantics and graphical representation. We also introduce the AND/OR search space for graphical models, and develop a new linear space search algorithm. This provides the basis for understanding the benefits of processing the constraint information separately, resulting in the pruning of the search space. When the constraint part is tractable or has a small number of solutions, using the mixed representation can be exponentially more effective than using pure belief networks which model constraints as conditional probability tables.

#index 788051
#* Iterative conditional fitting for Gaussian ancestral graph models
#@ Mathias Drton;Thomas S. Richardson
#t 2004
#c 12
#% 262665
#% 265483
#% 370075
#% 1672999
#! Ancestral graph models, introduced by Richardson and Spirtes (2002), generalize both Markov random fields and Bayesian networks to a class of graphs with a global Markov property that is closed under conditioning and marginalization. By design, ancestral graphs encode precisely the conditional independence structures that can arise from Bayesian networks with selection and unobserved (hidden/latent) variables. Thus, ancestral graph models provide a potentially very useful framework for exploratory model selection when unobserved variables might be involved in the data-generating process but no particular hidden structure can be specified. In this paper, we present the Iterative Conditional Fitting (ICF) algorithm for maximum likelihood estimation in Gaussian ancestral graph models. The name reflects that in each step of the procedure a conditional distribution is estimated, subject to constraints, while a marginal distribution is held fixed. This approach is in duality to the well-known Iterative Proportional Fitting algorithm, in which marginal distributions are fitted while conditional distributions are held fixed.

#index 788052
#* A unified framework for order-of-magnitude confidence relations
#@ Didier Dubois;Hélène Fargier
#t 2004
#c 12
#% 12938
#% 77841
#% 107155
#% 111942
#% 115327
#% 289953
#% 480204
#% 723624
#% 781197
#% 1272041
#% 1272312
#% 1279256
#% 1476313
#% 1650292
#% 1650690
#% 1650798
#! The aim of this work is to provide a unified framework for ordinal representations of uncertainty lying at the crossroads between possibility and probability theories. Such confidence relations between events are commonly found in nonmonotonic reasoning, inconsistency management, or qualitative decision theory. They start either from probability theory, making it more qualitative, or from possibility theory, making it more expressive. We show these two trends converge to a class of genuine probability relations, numerically representable, that cumulate features of probability and possibility theories. We provide characterization results for these useful tools that preserve the qualitative nature of possibility rankings, while enjoying the power of expressivity of additive representations.

#index 788053
#* Region-based incremental pruning for POMDPs
#@ Zhengzhu Feng;Shlomo Zilberstein
#t 2004
#c 12
#% 101869
#% 646457
#% 646971
#% 706380
#% 1650702
#! We present a major improvement to the incremental pruning algorithm for solving partially observable Markov decision processes. Our technique targets the cross-sum step of the dynamic programming (DP) update, a key source of complexity in POMDP algorithms. Instead of reasoning about the whole belief space when pruning the cross-sums, our algorithm divides the belief space into smaller regions and performs independent pruning in each region. We evaluate the benefits of the new technique both analytically and experimentally, and show that it produces very significant performance gains. The results contribute to the scalability of POMDP algorithms to domains that cannot be handled by the best existing techniques.

#index 788054
#* Dynamic programming for structured continuous Markov decision problems
#@ Zhengzhu Feng;Richard Dearden;Nicolas Meuleau;Richard Washington
#t 2004
#c 12
#% 86259
#% 236730
#% 266288
#% 314843
#% 317313
#% 425080
#% 578724
#% 1478746
#% 1650297
#% 1650355
#% 1650702
#! We describe an approach for exploiting structure in Markov Decision Processes with continuous state variables. At each step of the dynamic programming, the state space is dynamically partitioned into regions where the value function is the same throughout the region. We first describe the algorithm for piecewise constant representations. We then extend it to piecewise linear representations, using techniques from POMDPs to represent and reason about linear surfaces efficiently. We show that for complex, structured problems, our approach exploits the natural structure so that optimal solutions can be computed efficiently.

#index 788055
#* Metrics for finite Markov decision processes
#@ Norm Ferns;Prakash Panangaden;Doina Precup
#t 2004
#c 12
#% 54215
#% 104387
#% 135428
#% 363744
#% 374130
#% 449600
#% 464615
#% 473120
#% 528124
#% 655325
#% 1650710
#! We present metrics for measuring the similarity of states in a finite Markov decision process (MDP). The formulation of our metrics is based on the notion of bisimulation for MDPs, with an aim towards solving discounted infinite horizon reinforcement learning tasks. Such metrics can be used to aggregate states, as well as to better structure other value function approximators (e.g., memory-based or nearest-neighbor approximators). We provide bounds that relate our metric distances to the optimal values of states in the given MDP.

#index 788056
#* On-line prediction with kernels and the complexity approximation principle
#@ Alex Gammerman;Yuri Kalnishkan;Vladimir Vovk
#t 2004
#c 12
#% 81507
#% 165663
#% 232319
#% 234979
#% 251997
#% 272412
#% 341541
#% 466081
#! The paper describes an application of Aggregating Algorithm to the problem of regression. It generalizes earlier results concerned with plain linear regression to kernel techniques and presents an on-line algorithm which performs nearly as well as any oblivious kernel predictor. The paper contains the derivation of an estimate on the performance of this algorithm. The estimate is then used to derive an application of the Complexity Approximation Principle to kernel methods.

#index 788057
#* Algebraic statistics in model selection
#@ Luis David Garcia
#t 2004
#c 12
#% 1373888
#% 1650377
#% 1650397
#% 1650582
#% 1650619
#% 1673038
#! We develop the necessary theory in computational algebraic geometry to place Bayesian networks into the realm of algebraic statistics. We present an algebra-statistics dictionary focused on statistical modeling. In particular, we link the notion of effective dimension of a Bayesian network with the notion of algebraic dimension of a variety. We also obtain the independence and non-independence constraints on the distributions over the observable variables implied by a Bayesian network with hidden variables, via a generating set of an ideal of polynomials associated to the network. These results extend previous work on the subject. Finally, the relevance of these results for model selection is discussed.

#index 788058
#* Decision making for symbolic probability
#@ Phan H. Giang;Sathyakama Sandilya
#t 2004
#c 12
#% 146906
#% 301796
#% 370075
#% 528313
#% 729449
#% 746849
#% 1673010
#! This paper proposes a decision theory for a symbolic generalization of probability theory (SP). Darwiche and Ginsberg [2, 3] proposed SP to relax the requirement of using numbers for uncertainty while preserving desirable patterns of Bayesian reasoning. SP represents uncertainty by symbolic supports that are ordered partially rather than completely as in the case of standard probability. We show that a preference relation on acts that satisfies a number of intuitive postulates is represented by a utility function whose domain is a set of pairs of supports. We argue that a subjective interpretation is as useful and appropriate for SP as it is for numerical probability. It is useful because the subjective interpretation provides a basis for uncertainty elicitation. It is appropriate because we can provide a decision theory that explains how preference on acts is based on support comparison.

#index 788059
#* The minimum information principle for discriminative learning
#@ Amir Globerson;Naftali Tishby
#t 2004
#c 12
#% 115608
#% 226495
#% 464434
#% 528175
#% 528312
#% 722936
#% 1815045
#! Exponential models of distributions are widely used in machine learning for classification and modelling. It is well known that they can be interpreted as maximum entropy models under empirical expectation constraints. In this work, we argue that for classification tasks, mutual information is a more suitable information theoretic measure to be optimized. We show how the principle of minimum mutual information generalizes that of maximum entropy, and provides a comprehensive framework for building discriminative classifiers. A game theoretic interpretation of our approach is then given, and several generalization bounds provided. We present iterative algorithms for solving the minimum information problem and its convex dual, and demonstrate their performance on various classification tasks. The results show that minimum information classifiers outperform the corresponding maximum entropy models.

#index 788060
#* A complete anytime algorithm for treewidth
#@ Vibhav Gogate;Rina Dechter
#t 2004
#c 12
#% 2028
#% 31482
#% 289947
#% 322910
#% 528171
#% 528338
#% 576387
#% 1478758
#! In this paper, we present a Branch and Bound algorithm called QuickBB for computing the treewidth of an undirected graph. This algorithm performs a search in the space of perfect elimination ordering of vertices of the graph. The algorithm uses novel pruning and propagation techniques which are derived from the theory of graph minors and graph isomorphism. We present a new algorithm called minor-min-width for computing a lower bound on treewidth that is used within the branch and bound algorithm and which improves over earlier available lower bounds. Empirical evaluation of QuickBB on randomly generated graphs and benchmarks in Graph Coloring and Bayesian Networks shows that it is consistently better than complete algorithms like Quick-Tree [Shoikhet and Geiger, 1997] in terms of cpu time. QuickBB also has good anytime performance, being able to generate a better upper bound on treewidth of some graphs whose optimal treewidth could not be computed up to now.

#index 788061
#* Bidding under uncertainty: theory and experiments
#@ Amy Greenwald;Justin Boyan
#t 2004
#c 12
#% 341923
#% 341936
#% 416726
#% 496251
#% 578793
#% 644560
#% 754150
#% 1271997
#% 1272022
#% 1279450
#! This paper describes a study of agent bidding strategies, assuming combinatorial valuations for complementary and substitutable goods, in three auction environments: sequential auctions, simultaneous auctions, and the Trading Agent Competition (TAC) Classic hotel auction design, a hybrid of sequential and simultaneous auctions. The problem of bidding in sequential auctions is formulated as an MDP, and it is argued that expected marginal utility bidding is the optimal bidding policy. The problem of bidding in simultaneous auctions is formulated as a stochastic program, and it is shown by example that marginal utility bidding is not an optimal bidding policy, even in deterministic settings. Two alternative methods of approximating a solution to this stochastic program are presented: the first method, which relies on expected values, is optimal in deterministic environments; the second method, which samples the nondeterministic environment, is asymptotically optimal as the number of samples tends to infinity. Finally, experiments with these various bidding policies are described in the TAC Classic setting.

#index 788062
#* Exploiting first-order regression in inductive policy selection
#@ Charles Gretton;Sylvie Thiébaux
#t 2004
#c 12
#% 289949
#% 314843
#% 322913
#% 333786
#% 337981
#% 342119
#% 544926
#% 578724
#% 643852
#% 743353
#% 1279355
#% 1289241
#% 1650297
#% 1650413
#% 1673012
#! We consider the problem of computing optimal generalised policies for relational Markov decision processes. We describe an approach combining some of the benefits of purely inductive techniques with those of symbolic dynamic programming methods. The latter reason about the optimal value function using first-order decision-theoretic regression and formula rewriting, while the former, when provided with a suitable hypotheses language, are capable of generalising value functions or policies for small instances. Our idea is to use reasoning and in particular classical first-order regression to automatically generate a hypotheses language dedicated to the domain at hand, which is then used as input by an inductive solver. This approach avoids the more complex reasoning of symbolic dynamic programming while focusing the inductive solver's attention on concepts that are specifically relevant to the optimal value function for the domain considered.

#index 788063
#* When ignorance is bliss
#@ Peter D. Grünwald;Joseph Y. Halpern
#t 2004
#c 12
#% 115608
#% 137786
#% 424807
#% 528157
#% 1650720
#% 1809531
#! It is commonly-accepted wisdom that more information is better, and that information should never be ignored. Here we argue, using both a Bayesian and a non-Bayesian analysis, that in some situations you are better off ignoring information if your uncertainty is represented by a set of probability measures. These include situations in which the information is relevant for the prediction task at hand. In the non-Bayesian analysis, we show how ignoring information avoids dilation, the phenomenon that additional pieces of information sometimes lead to an increase in uncertainty. In the Bayesian analysis, we show that for small sample sizes and certain prediction tasks, the Bayesian posterior based on a non-informative prior yields worse predictions than simply ignoring the given information.

#index 788064
#* Solving factored MDPs with continuous and discrete variables
#@ Carlos Guestrin;Milos Hauskrecht;Branislav Kveton
#t 2004
#c 12
#% 75936
#% 393786
#% 496267
#% 644560
#% 707761
#% 739715
#% 778078
#% 1272002
#% 1289239
#% 1290041
#! Although many real-world stochastic planning problems are more naturally formulated by hybrid models with both discrete and continuous variables, current state-of-the-art methods cannot adequately address these problems. We present the first framework that can exploit problem structure for modeling and solving hybrid problems efficiently. We formulate these problems as hybrid Markov decision processes (MDPs with continuous and discrete state and action variables), which we assume can be represented in a factored way using a hybrid dynamic Bayesian network (hybrid DBN). This formulation also allows us to apply our methods to collaborative multiagent settings. We present a new linear program approximation method that exploits the structure of the hybrid MDP and lets us compute approximate value functions more efficiently. In particular, we describe a new factored discretization of continuous variables that avoids the exponential blow-up of traditional approaches. We provide theoretical bounds on the quality of such an approximation and on its scale-up potential. We support our theoretical arguments with experiments on a set of control problems with up to 28-dimensional continuous state space and 22-dimensional action space.

#index 788065
#* From fields to trees
#@ Firas Hamze;Nando de Freitas
#t 2004
#c 12
#% 21142
#% 338741
#% 424897
#% 528169
#% 798509
#% 1227446
#% 1672982
#! We present new MCMC algorithms for computing the posterior distributions and expectations of the unknown variables in undirected graphical models with regular structure. For demonstration purposes, we focus on Markov Random Fields (MRFs). By partitioning the MRFs into non-overlapping trees, it is possible to compute the posterior distribution of a particular tree exactly by conditioning on the remaining tree. These exact solutions allow us to construct efficient blocked and Rao-Blackwellised MCMC algorithms. We show empirically that tree sampling is considerably more efficient than other partitioned sampling schemes and the naive Gibbs sampler, even in cases where loopy belief propagation fails to converge. We prove that tree sampling exhibits lower variance than the naive Gibbs sampler and other naive partitioning schemes using the theoretical measure of maximal correlation. We also construct new information theory tools for comparing different MCMC schemes and show that, under these, tree sampling is more efficient.

#index 788066
#* Dependent Dirichlet priors and optimal linear estimators for belief net parameters
#@ Peter M. Hooper
#t 2004
#c 12
#% 277480
#% 528319
#! A Bayesian belief network is a model of a joint distribution over a finite set of variables, with a DAG structure representing immediate dependencies among the variables. For each node, a table of parameters (CP-table) represents local conditional probabilities, with rows indexed by conditioning events (assignments to parents). CP-table rows are usually modeled as independent random vectors, each assigned a Dirichlet prior distribution. The assumption that rows are independent permits a relatively simple analysis but may not reflect actual prior opinion about the parameters. Rows representing similar conditioning events often have similar conditional probabilities. This paper introduces a more flexible family of "dependent Dirichlet" prior distributions, where rows are not necessarily independent. Simple methods are developed to approximate the Bayes estimators of CP-table parameters with optimal linear estimators; i.e., linear combinations of sample proportions and prior means. This approach yields more efficient estimators by sharing information among rows. Improvements in efficiency can be substantial when a CP-table has many rows and samples sizes are small.

#index 788067
#* Dynamical systems trees
#@ Andrew Howard;Tony Jebara
#t 2004
#c 12
#% 246836
#% 277483
#% 315282
#% 335489
#% 857094
#% 1650381
#! We propose dynamical systems trees (DSTs) as a flexible class of models for describing multiple process that interact via a hierarchy of aggregating parent chains. DSTs extend Kalman filters, hidden Markov models and nonlinear dynamical systems to an interactive group scenario. Various individual processes interact as communities and sub-communities in a tree structure that is unrolled in time. To accommodate nonlinear temporal activity, each individual leaf process is modeled as a dynamical system containing discrete and/or continuous hidden states with discrete and/or Gaussian emissions. Subsequent higher level parent processes act like hidden Markov models and mediate the interaction between leaf processes or between other parent processes in the hierarchy. Aggregator chains are parents of child processes that they combine and mediate, yielding a compact overall parameterization. We provide tractable inference and learning algorithms for arbitrary DST topologies via an efficient structured mean-field algorithm. The diverse applicability of DSTs is demonstrated by experiments on gene expression data and by modeling group behavior in the setting of an American football game.

#index 788068
#* Regret minimizing equilibria and mechanisms for games with strict type uncertainty
#@ Nathanael Hyafil;Craig Boutilier
#t 2004
#c 12
#% 257694
#% 261358
#% 301588
#% 378910
#% 460806
#% 528176
#% 578711
#% 819415
#% 1250151
#% 1279257
#% 1650358
#% 1672988
#% 1784525
#! Mechanism design has found considerable application to the construction of agent-interaction protocols. In the standard setting, the type (e.g., utility function) of an agent is not known by other agents, nor is it known by the mechanism designer. When this uncertainty is quantified probabilistically, a mechanism induces a game of incomplete information among the agents. However, in many settings, uncertainty over utility functions cannot easily be quantified. We consider the problem of incomplete information games in which type uncertainty is strict or unquantified. We propose the use of minimax regret as a decision criterion in such games, a robust approach for dealing with type uncertainty. We define minimax-regret equilibria and prove that these exist in mixed strategies for finite games. We also consider the problem of mechanism design in this framework by adopting minimax regret as an optimization criterion for the designer itself, and study automated optimization of such mechanisms.

#index 788069
#* A Bayesian approach toward active learning for collaborative filtering
#@ Rong Jin;Luo Si
#t 2004
#c 12
#% 116165
#% 132678
#% 236729
#% 464268
#% 466095
#% 466576
#% 495929
#% 528156
#% 730049
#% 1650569
#% 1672989
#% 1673052
#! Collaborative filtering is a useful technique for exploiting the preference patterns of a group of users to predict the utility of items for the active user. In general, the performance of collaborative filtering depends on the number of rated examples given by the active user. The more the number of rated examples given by the active user, the more accurate the predicted ratings will be. Active learning provides an effective way to acquire the most informative rated examples from active users. Previous work on active learning for collaborative filtering only considers the expected loss function based on the estimated model, which can be misleading when the estimated model is inaccurate. This paper takes one step further by taking into account of the posterior distribution of the estimated model, which results in more robust active learning algorithm. Empirical studies with datasets of movie ratings show that when the number of ratings from the active user is restricted to be small, active learning methods only based on the estimated model don't perform well while the active learning method using the model distribution achieves substantially better performance.

#index 788070
#* Joint discovery of haplotype blocks and complex trait associations from SNP sequences
#@ Nebojsa Jojic;Vladimir Jojic;David Heckerman
#t 2004
#c 12
#% 137711
#% 277483
#! Haplotypes, the global patterns of DNA sequence variation, have important implications for identifying complex traits. Recently, blocks of limited haplotype diversity have been discovered in human chromosomes, intensifying the research on modelling the block structure as well as the transitions or co-occurrence of the alleles in these blocks as a way to compress the variability and infer the associations more robustly. The haplotype block structure analysis is typically complicated by the fact that the phase information for each SNP is missing, i.e., the observed allele pairs are not given in a consistent order across the sequence. The techniques for circumventing this require additional information, such as family data, or a more complex sequencing procedure. In this paper we present a hierarchical statistical model and the associated learning and inference algorithms that simultaneously deal with the allele ambiguity per locus, missing data, block estimation, and the complex trait association. While the block structure may differ from the structures inferred by other methods, which use the pedigree information or previously known alleles, the parameters we estimate, including the learned block structure and the estimated block transitions per locus, define a good model of variability in the set. The method is completely data-driven and can detect Chron's disease from the SNP data taken from the human chromosome 5q31 with the detection rate of 80% and a small error variance.

#index 788071
#* Probabilistic index maps for modeling natural signals
#@ Nebojsa Jojic;Yaron Caspi;Manuel Reyes-Gomez
#t 2004
#c 12
#% 269188
#% 444047
#% 726462
#! One of the major problems in modeling natural signals is that signals with very similar structure may locally have completely different measurements, e.g., images taken under different illumination conditions, or the speech signal captured in different environments. While there have been many successful attempts to address these problems in application-specific settings, we believe that underlying a large set of problems in signal representation is a representational deficiency of intensity-derived local measurements that are the basis of most efficient models. We argue that interesting structure in signals is better captured when the signal is defined as a matrix whose entries are discrete indices to a separate palette of possible measurements. In order to model the variability in signal structure, we define a signal class not by a single index map, but by a probability distribution over the index maps, which can be estimated from the data, and which we call probabilistic index maps. The existing algorithms can be adapted to work with this representation. Furthermore, the probabilistic index map representation leads to algorithms with computational costs proportional to either the size of the palette or the log of the size of the palette, making the cost of significantly increased invariance to non-structural changes quite bearable. We illustrate the benefits of the probabilistic index map representation in several applications in computer vision and speech processing.

#index 788072
#* A generative Bayesian model for aggregating experts' probabilities
#@ Joseph M. Kahn
#t 2004
#c 12
#% 722760
#% 788411
#! In order to improve forecasts, a decision-maker often combines probabilities given by various sources, such as human experts and machine learning classifiers. When few training data are available, aggregation can be improved by incorporating prior knowledge about the event being forecasted and about salient properties of the experts. To this end, we develop a generative Bayesian aggregation model for probabilistic classification. The model includes an event-specific prior, measures of individual experts' bias, calibration, accuracy, and a measure of dependence between experts. Rather than require absolute measures, we show that aggregation may be expressed in terms of relative accuracy between experts. The model results in a weighted logarithmic opinion pool (LogOps) that satisfies consistency criteria such as the external Bayesian property. We derive analytic solutions for independent and for exchangeable experts. Empirical tests demonstrate the model's use, comparing its accuracy with other aggregation methods.

#index 788073
#* Modeling waveform shapes with random effects segmental hidden Markov models
#@ Seyoung Kim;Padhraic Smyth;Stefan Luther
#t 2004
#c 12
#% 13215
#% 137711
#% 310502
#% 480146
#% 1291532
#! In this paper we describe a general probabilistic framework for modeling waveforms such as heartbeats from ECG data. The model is based on segmental hidden Markov models (as used in speech recognition) with the addition of random effects to the generative model. The random effects component of the model handles shape variability across different waveforms within a general class of waveforms of similar shape. We show that this probabilistic model provides a unified framework for learning these models from sets of waveform data as well as parsing, classification, and prediction of new waveforms. We derive a computationally efficient EM algorithm to fit the model on multiple waveforms, and introduce a scoring method that evaluates a test waveform based on its shape. Results on two real-world data sets demonstrate that the random effects methodology leads to improved accuracy (compared to alternative approaches) on classification and segmentation of real-world waveforms.

#index 788074
#* Conditional Chow-Liu tree structures for modeling discrete-valued vector time series
#@ Sergey Kirshner;Padhraic Smyth;Andrew W. Robertson
#t 2004
#c 12
#% 70370
#% 466257
#% 722753
#! We consider the problem of modeling discrete-valued vector time series data using extensions of Chow-Liu tree models to capture both dependencies across time and dependencies across variables. Conditional Chow-Liu tree models are introduced, as an extension to standard Chow-Liu trees, for modeling conditional rather than joint densities. We describe learning algorithms for such models and show how they can be used to learn parsimonious representations for the output distributions in hidden Markov models. These models are applied to the important problem of simulating and forecasting daily precipitation occurrence for networks of rain stations. To demonstrate the effectiveness of the models, we compare their performance versus a number of alternatives using historical precipitation data from Southwestern Australia and the Western United States. We illustrate how the structure and parameters of the models can be used to provide an improved meteorological interpretation of such data.

#index 788075
#* Pre-selection of independent binary features: an application to diagnosing Scrapie in sheep
#@ L. I. Kuncheva;C. J. Whitaker;P. D. Cockcroft;Z. S. J. Hoare
#t 2004
#c 12
#% 177826
#% 227486
#% 243727
#% 246831
#% 729437
#! Suppose that the only available information in a multi-class problem are expert estimates of the conditional probabilities of occurrence for a set of binary features. The aim is to select a subset of features to be measured in subsequent data collection experiments. In the lack of any information about the dependencies between the features, we assume that all features are conditionally independent and hence choose the Naive Bayes classifier as the optimal classifier for the problem. Even in this (seemingly trivial) case of complete knowledge of the distributions, choosing an optimal feature subset is not straightforward. We discuss the properties and implementation details of Sequential Forward Selection (SFS) as a feature selection procedure for the current problem. A sensitivity analysis was carried out to investigate whether the same features are selected when the probabilities vary around the estimated values. The procedure is illustrated with a set of probability estimates for Scrapie in sheep.

#index 788076
#* Selection of identifiability criteria for total effects by using path diagrams
#@ Manabu Kuroki;Zhihong Cai
#t 2004
#c 12
#% 297171
#% 1650356
#! Pearl has provided the back door criterion, the front door criterion and the conditional instrumental variable (IV) method as identifiability criteria for total effects. In some situations, these three criteria can be applied to identifying total effects simultaneously. For the purpose of increasing estimating accuracy, this paper compares the three ways of identifying total effects in terms of the asymptotic variance, and concludes that in some situations the superior of them can be recognized directly from the graph structure.

#index 788077
#* An extended &Ccaron;encov-Campbell characterization of conditional information geometry
#@ Guy Lebanon
#t 2004
#c 12
#! We formulate and prove an axiomatic characterization of conditional information geometry, for both the normalized and the non-normalized cases. This characterization extends the axiomatic derivation of the Fisher geometry by &Ccaron;encov and Campbell to the cone of positive conditional models, and as a special case to the manifold of conditional distributions. Due to the close connection between the conditional I-divergence and the product Fisher information metric the characterization provides a new axiomatic interpretation of the primal problems underlying logistic regression and AdaBoost.

#index 788078
#* Linear contour learning: a method for supervised dimension reduction
#@ Bing Li;Hongyuan Zha;Francesca Chiaromonte
#t 2004
#c 12
#! We propose a novel approach to sufficient dimension reduction in regression, based on estimating contour directions of negligible variation for the response surface. These directions span the orthogonal complement of the minimal space relevant for the regression, and can be extracted according to a measure of the variation in the response, leading to General Contour Regression (GCR). In comparison to existing sufficient dimension reduction techniques, this contour-based methodology guarantees exhaustive estimation of the central space under ellipticity of the predictor distribution and very mild additional assumptions, while maintaining √n-consistency and computational ease. Moreover, it proves to be robust to departures from ellipticity. We also establish some useful population properties for GCR. Simulations to compare performance with that of standard techniques such as ordinary least squares, sliced inverse regression, principal hessian directions, and sliced average variance estimation confirm the advantages anticipated by theoretical analyses. We also demonstrate the use of contour-based methods on a data set concerning grades of students from Massachusetts colleges.

#index 788079
#* Active model selection
#@ Omid Madani;Daniel J. Lizotte;Russell Greiner
#t 2004
#c 12
#% 2837
#% 135414
#% 203337
#% 416988
#% 447606
#% 464268
#% 563266
#% 715337
#% 735357
#% 1673023
#! Classical learning assumes the learner is given a labeled data sample, from which it learns a model. The field of Active Learning deals with the situation where the learner begins not with a training sample, but instead with resources that it can use to obtain information to help identify the optimal model. To better understand this task, this paper presents and analyses the simplified "(budgeted) active model selection" version, which captures the pure exploration aspect of many active learning problems in a clean and simple problem formulation. Here the learner can use a fixed budget of "model probes" (where each probe evaluates the specified model on a random indistinguishable instance) to identify which of a given set of possible models has the highest expected accuracy. Our goal is a policy that sequentially determines which model to probe next, based on the information observed so far. We present a formal description of this task, and show that it is NP-hard in general. We then investigate a number of algorithms for this task, including several existing ones (eg, "Round-Robin", "Interval Estimation", "Gittins") as well as some novel ones (e.g., "Biased-Robin"), describing first their approximation properties and then their empirical performance on various problem instances. We observe empirically that the simple biased-robin algorithm significantly outperforms the other algorithms in the case of identical costs and priors.

#index 788080
#* An empirical evaluation of possible variations of lazy propagation
#@ Anders L. Madsen
#t 2004
#c 12
#% 34262
#% 61079
#% 289951
#% 351595
#% 370075
#% 388024
#% 424851
#% 567872
#% 919561
#% 1650778
#! As real-world Bayesian networks continue to grow larger and more complex, it is important to investigate the possibilities for improving the performance of existing algorithms of probabilistic inference. Motivated by examples, we investigate the dependency of the performance of Lazy propagation on the message computation algorithm. We show how Symbolic Probabilistic Inference (SPI) and Arc-Reversal (AR) can be used for computation of clique to clique messages in the addition to the traditional use of Variable Elimination (VE). In addition, the paper presents the results of an empirical evaluation of the performance of Lazy propagation using VE, SPI, and AR as the message computation algorithm. The results of the empirical evaluation show that for most networks, the performance of inference did not depend on the choice of message computation algorithm, but for some randomly generated networks the choice had an impact on both space and time performance. In the cases where the choice had an impact, AR produced the best results.

#index 788081
#* Convolutional factor graphs as probabilistic models
#@ Yongyi Mao;Frank R. Kschischang;Brendan J. Frey
#t 2004
#c 12
#% 281743
#% 370075
#% 1672999
#% 1673008
#% 1810385
#% 1815540
#! Based on a recent development in the area of error control coding, we introduce the notion of convolutional factor graphs (CFGs) as a new class of probabilistic graphical models. In this context, the conventional factor graphs are referred to as multiplicative factor graphs (MFGs). This paper shows that CFGs are natural models for probability functions when summation of independent latent random variables is involved. In particular, CFGs capture a large class of linear models, where the linearity is in the sense that the observed variables are obtained as a linear transformation of the latent variables taking arbitrary distributions. We use Gaussian models and independent factor models as examples to demonstrate the use of CFGs. The requirement of a linear transformation between latent variables (with certain independence restriction) and the observed variables, to an extent, limits the modelling flexibility of CFGs. This structural restriction however provides a powerful analytic tool to the framework of CFGs; that is, upon taking the Fourier transform of the function represented by the CFG, the resulting function is represented by a MFG with identical structure. This Fourier transform duality allows inference problems on a CFG to be solved on the corresponding dual MFG.

#index 788082
#* Case-factor diagrams for structured probabilistic modeling
#@ David McAllester;Michael Collins;Fernando Pereira
#t 2004
#c 12
#% 3873
#% 147677
#% 147928
#% 226495
#% 329486
#% 398849
#% 464434
#% 543491
#% 571102
#% 872235
#% 1650666
#% 1650767
#% 1672978
#! We introduce a probabilistic formalism subsuming Markov random fields of bounded tree width and probabilistic context free grammars. Our models are based on a representation of Boolean formulas that we call case-factor diagrams (CFDs). CFDs are similar to binary decision diagrams (BDDs) but are concise for circuits of bounded tree width (unlike BDDs) and can concisely represent the set of parse trees over a given string under a given context free grammar (also unlike BDDs). A probabilistic model consists of a CFD defining a feasible set of Boolean assignments and a weight (or cost) for each individual Boolean variable. We give an inside-outside algorithm for simultaneously computing the marginal of each Boolean variable, and a Viterbi algorithm for finding the mininum cost variable assignment. Both algorithms run in time proportional to the size of the CFD.

#index 788083
#* Bayesian learning in undirected graphical models: approximate MCMC algorithms
#@ Iain Murray;Zoubin Ghahramani
#t 2004
#c 12
#% 226495
#% 450888
#% 528019
#% 574568
#! Bayesian learning in undirected graphical models---computing posterior distributions over parameters and predictive quantities---is exceptionally difficult. We conjecture that for general undirected models, there are no tractable MCMC (Markov Chain Monte Carlo) schemes giving the correct equilibrium distribution over parameters. While this intractability, due to the partition function, is familiar to those performing parameter optimisation, Bayesian learning of posterior distributions over undirected model parameters has been unexplored and poses novel challenges. We propose several approximate MCMC schemes and test on fully observed binary models (Boltzmann machines) for a small coronary heart disease data set and larger artificial systems. While approximations must perform well on the model, their interaction with the sampling scheme is also important. Samplers based on variational mean-field approximations generally performed poorly, more advanced methods using loopy propagation, brief sampling and stochastic dynamics lead to acceptable parameter posteriors. Finally, we demonstrate these techniques on a Markov random field with hidden variables.

#index 788084
#* "Ideal Parent" structure learning for continuous variable networks
#@ Iftach Nachman;Gal Elidan;Nir Friedman
#t 2004
#c 12
#% 51749
#% 277467
#% 297490
#% 465762
#% 529185
#% 729437
#% 771837
#% 833046
#% 1650289
#% 1650318
#% 1673001
#! In recent years, there is a growing interest in learning Bayesian networks with continuous variables. Learning the structure of such networks is a computationally expensive procedure, which limits most applications to parameter learning. This problem is even more acute when learning networks with hidden variables. We present a general method for significantly speeding the structure search algorithm for continuous variable networks with common parametric distributions. Importantly, our method facilitates the addition of new hidden variables into the network structure efficiently. We demonstrate the method on several data sets, both for learning structure on fully observable data, and for introducing new hidden variables during structure search.

#index 788085
#* PAC-learning bounded tree-width graphical models
#@ Mukund Narasimhan;Jeff Bilmes
#t 2004
#c 12
#% 31482
#% 62392
#% 136358
#% 272734
#% 325348
#% 1272387
#% 1650281
#! We show that the class of strongly connected graphical models with tree-width at most k can be properly efficiently PAC-learnt with respect to the Kullback-Leibler Divergence. Previous approaches to this problem, such as those of Chow ([1]), and Hoffgen ([7]) have shown that this class is PAC-learnable by reducing it to a combinatorial optimization problem. However, for k 1, this problem is NP-complete ([15]), and so unless P=NP, these approaches will take exponential amounts of time. Our approach differs significantly from these, in that it first attempts to find approximate conditional independencies by solving (polynomially many) submodular optimization problems, and then using a dynamic programming formulation to combine the approximate conditional independence information to derive a graphical model with underlying graph of the tree-width specified. This gives us an efficient (polynomial time in the number of random variables) PAC-learning algorithm which requires only polynomial number of samples of the true distribution, and only polynomial running time.

#index 788086
#* MOB-ESP and other improvements in probability estimation
#@ Rodney D. Nielsen
#t 2004
#c 12
#% 136350
#% 209021
#% 236656
#% 280442
#% 400847
#% 424997
#% 458229
#% 464280
#% 466568
#% 564273
#% 580510
#% 1499572
#! A key prerequisite to optimal reasoning under uncertainty in intelligent systems is to start with good class probability estimates. This paper improves on the current best probability estimation trees (Bagged-PETs) and also presents a new ensemble-based algorithm (MOB-ESP). Comparisons are made using several benchmark datasets and multiple metrics. These experiments show that MOB-ESP outputs significantly more accurate class probabilities than either the baseline B-PETs algorithm or the enhanced version presented here (EB-PETs). These results are based on metrics closely associated with the average accuracy of the predictions. MOB-ESP also provides much better probability rankings than B-PETs. The paper further suggests how these estimation techniques can be applied in concert with a broader category of classifiers.

#index 788087
#* On modeling profiles instead of values
#@ Alon Orlitsky;Narayana P. Santhanam;Krishnamurthy Viswanathan;Junan Zhang
#t 2004
#c 12
#% 115608
#% 217824
#% 280864
#% 748738
#% 1815170
#% 1818269
#! We consider the problem of estimating the distribution underlying an observed sample of data. Instead of maximum likelihood, which maximizes the probability of the observed values, we propose a different estimate, the high-profile distribution, which maximizes the probability of the observed profile---the number of symbols appearing any given number of times. We determine the high-profile distribution of several data samples, establish some of its general properties, and show that when the number of distinct symbols observed is small compared to the data size, the high-profile and maximum-likelihood distributions are roughly the same, but when the number of symbols is large, the distributions differ, and high-profile better explains the data.

#index 788088
#* Robust probabilistic inference in distributed systems
#@ Mark A. Paskin;Carlos E. Guestrin
#t 2004
#c 12
#% 336865
#% 388024
#% 751027
#% 1394381
#% 1672996
#! Probabilistic inference problems arise naturally in distributed systems such as sensor networks and teams of mobile robots. Inference algorithms that use message passing are a natural fit for distributed systems, but they must be robust to the failure situations that arise in real-world settings, such as unreliable communication and node failures. Unfortunately, the popular sum--product algorithm can yield very poor estimates in these settings because the nodes' beliefs before convergence can be arbitrarily different from the correct posteriors. In this paper, we present a new message passing algorithm for probabilistic inference which provides several crucial guarantees that the standard sum--product algorithm does not. Not only does it converge to the correct posteriors, but it is also guaranteed to yield a principled approximation at any point before convergence. In addition, the computational complexity of the message passing updates depends only upon the model, and is independent of the network topology of the distributed system. We demonstrate the approach with detailed experimental results on a distributed sensor calibration task using data from an actual sensor network deployment.

#index 788089
#* Robustness of causal claims
#@ Judea Pearl
#t 2004
#c 12
#% 297171
#% 578735
#% 1650356
#! A causal claim is any assertion that invokes causal relationships between variables, for example, that a drug has a certain effect on preventing a disease. Causal claims are established through a combination of data and a set of causal assumptions called a "causal model." A claim is robust when it is insensitive to violations of some of the causal assumptions embodied in the model. This paper gives a formal definition of this notion of robustness, and establishes a graphical condition for quantifying the degree of robustness of a given causal claim. Algorithms for computing the degree of robustness are also presented.

#index 788090
#* A hierarchical graphical model for record linkage
#@ Pradeep Ravikumar;William W. Cohen
#t 2004
#c 12
#% 201889
#% 251405
#% 311027
#% 350103
#% 480499
#% 577263
#% 632079
#% 1650579
#! The task of matching co-referent records is known among other names as record linkage. For large record-linkage problems, often there is little or no labeled data available, but unlabeled data shows a reasonably clear structure. For such problems, unsupervised or semi-supervised methods are preferable to supervised methods. In this paper, we describe a hierarchical graphical model framework for the record-linkage problem in an unsupervised setting. In addition to proposing new methods, we also cast existing unsupervised probabilistic record-linkage methods in this framework. Some of the techniques we propose to minimize overfitting in the above model are of interest in the general graphical model setting. We describe a method for incorporating monotonicity constraints in a graphical model. We also outline a bootstrapping approach of using "single-field" classifiers to noisily label latent variables in a hierarchical model. Experimental results show that our proposed unsupervised methods perform quite competitively even with fully supervised record-linkage methods.

#index 788091
#* Variational Chernoff bounds for graphical models
#@ Pradeep Ravikumar;John Lafferty
#t 2004
#c 12
#% 190611
#% 757953
#! Recent research has made significant progress on the problem of bounding log partition functions for exponential family graphical models. Such bounds have associated dual parameters that are often used as heuristic estimates of the marginal probabilities required in inference and learning. However these variational estimates do not give rigorous bounds on marginal probabilities, nor do they give estimates for probabilities of more general events than simple marginals. In this paper we build on this recent work by deriving rigorous upper and lower bounds on event probabilities for graphical models. Our approach is based on the use of generalized Chernoff bounds to express bounds on event probabilities in terms of convex optimization problems; these optimization problems, in turn, require estimates of generalized log partition functions. Simulations indicate that this technique can result in useful, rigorous bounds to complement the heuristic variational estimates, with comparable computational cost.

#index 788092
#* Computing best-response strategies in infinite games of incomplete information
#@ Daniel M. Reeves;Michael P. Wellman
#t 2004
#c 12
#% 188086
#% 233137
#% 314946
#% 430214
#% 527993
#% 557552
#% 567883
#% 754142
#% 1279321
#! We describe an algorithm for computing best-response strategies in a class of two-player infinite games of incomplete information, defined by payoffs piecewise linear in agents' types and actions, conditional on linear comparisons of agents' actions. We show that this class includes many well-known games including a variety of auctions and a novel allocation game. In some cases, the best-response algorithm can be iterated to compute Bayes-Nash equilibria. We demonstrate the efficacy of our approach on existing and new games.

#index 788093
#* Evidence-invariant sensitivity bounds
#@ Silja Renooij;Linda C. van der Gaag
#t 2004
#c 12
#% 417831
#% 528027
#% 528331
#% 578736
#% 1272350
#% 1784188
#! The sensitivities revealed by a sensitivity analysis of a probabilistic network typically depend on the entered evidence. For a real-life network therefore, the analysis is performed a number of times, with different evidence. Although efficient algorithms for sensitivity analysis exist, a complete analysis is often infeasible because of the large range of possible combinations of observations. In this paper we present a method for studying sensitivities that are invariant to the evidence entered. Our method builds upon the idea of establishing bounds between which a parameter can be varied without ever inducing a change in the most likely value of a variable of interest.

#index 788094
#* The author-topic model for authors and documents
#@ Michal Rosen-Zvi;Thomas Griffiths;Mark Steyvers;Padhraic Smyth
#t 2004
#c 12
#% 280819
#% 438103
#% 722904
#% 1650387
#! We introduce the author-topic model, a generative model for documents that extends Latent Dirichlet Allocation (LDA; Blei, Ng, & Jordan, 2003) to include authorship information. Each author is associated with a multinomial distribution over topics and each topic is associated with a multinomial distribution over words. A document with multiple authors is modeled as a distribution over topics that is a mixture of the distributions associated with the authors. We apply the model to a collection of 1,700 NIPS conference papers and 160,000 CiteSeer abstracts. Exact inference is intractable for these datasets and we use Gibbs sampling to estimate the topic and author distributions. We compare the performance with two other generative models for documents, which are special cases of the author-topic model: LDA (a topic model) and a simple author model in which each author is associated with a distribution over words rather than a distribution over topics. We show topics recovered by the author-topic model, and demonstrate applications to computing similarity between authors and entropy of author output.

#index 788095
#* A new characterization of probabilities in Bayesian networks
#@ Lenhart K. Schubert
#t 2004
#c 12
#% 44876
#% 68244
#% 90681
#% 136358
#% 147677
#% 233132
#% 266726
#% 327779
#% 342378
#% 484593
#% 527848
#% 571102
#% 711139
#% 729449
#% 1279353
#% 1289247
#% 1290046
#% 1476308
#% 1650727
#% 1784188
#! We characterize probabilities in Bayesian networks in terms of algebraic expressions called quasi-probabilities. These are arrived at by casting Bayesian networks as noisy AND-OR-NOT networks, and viewing the subnetworks that lead to a node as arguments for or against a node. Quasi-probabilities are in a sense the "natural" algebra of Bayesian networks: we can easily compute the marginal quasi-probability of any node recursively, in a compact form; and we can obtain the joint quasi-probability of any set of nodes by multiplying their marginals (using an idempotent product operator). Quasi-probabilities are easily manipulated to improve the efficiency of probabilistic inference. They also turn out to be representable as square-wave pulse trains, and joint and marginal distributions can be computed by multiplication and complementation of pulse trains.

#index 788096
#* Blind construction of optimal nonlinear recursive predictors for discrete sequences
#@ Cosma Rohilla Shalizi;Kristina Lisa Shalizi
#t 2004
#c 12
#% 115608
#% 222437
#% 259119
#% 297171
#% 349551
#% 383546
#% 713461
#% 788097
#% 857087
#% 1818269
#! We present a new method for nonlinear prediction of discrete random sequences under minimal structural assumptions. We give a mathematical construction for optimal predictors of such processes, in the form of hidden Markov models. We then describe an algorithm, CSSR (Causal-State Splitting Reconstruction), which approximates the ideal predictor from data. We discuss the reliability of CSSR, its data requirements, and its performance in simulations. Finally, we compare our approach to existing methods using variable-length Markov models and cross-validated hidden Markov models, and show theoretically and experimentally that our method delivers results superior to the former and at least comparable to the latter.

#index 788097
#* Predictive state representations: a new theory for modeling dynamical systems
#@ Satinder Singh;Michael R. James;Matthew R. Rudary
#t 2004
#c 12
#% 651665
#% 770781
#% 788097
#% 1271848
#! Modeling dynamical systems, both for control purposes and to make predictions about their behavior, is ubiquitous in science and engineering. Predictive state representations (PSRs) are a recently introduced class of models for discrete-time dynamical systems. The key idea behind PSRs and the closely related OOMs (Jaeger's observable operator models) is to represent the state of the system as a set of predictions of observable outcomes of experiments one can do in the system. This makes PSRs rather different from history-based models such as nth-order Markov models and hidden-state-based models such as HMMs and POMDPs. We introduce an interesting construct, the system-dynamics matrix, and show how PSRs can be derived simply from it. We also use this construct to show formally that PSRs are more general than both nth-order Markov models and HMMs/POMDPs. Finally, we discuss the main difference between PSRs and OOMs and conclude with directions for future work.

#index 788098
#* Heuristic search value iteration for POMDPs
#@ Trey Smith;Reid Simmons
#t 2004
#c 12
#% 135414
#% 181627
#% 337981
#% 544786
#% 1271823
#% 1271954
#% 1279358
#% 1478842
#% 1478843
#% 1650297
#% 1650567
#% 1650702
#! We present a novel POMDP planning algorithm called heuristic search value iteration (HSVI). HSVI is an anytime algorithm that returns a policy and a provable bound on its regret with respect to the optimal policy. HSVI gets its power by combining two well-known techniques: attention-focusing search heuristics and piecewise linear convex representations of the value function. HSVI's soundness and convergence have been proven. On some bench-mark problems from the literature, HSVI displays speedups of greater than 100 with respect to other state-of-the-art POMDP value iteration algorithms. We also apply HSVI to a new rover exploration problem 10 times larger than most POMDP problems in the literature.

#index 788099
#* Sequential information elicitation in multi-agent systems
#@ Rann Smorodinsky;Moshe Tennenholtz
#t 2004
#c 12
#% 188086
#% 631039
#% 765317
#! We introduce the study of sequential information elicitation in strategic multi-agent systems. In an information elicitation setup a center attempts to compute the value of a function based on private information (a-k-a secrets) accessible to a set of agents. We consider the classical multi-party computation setup where each agent is interested in knowing the result of the function. However, in our setting each agent is strategic, and since acquiring information is costly, an agent may be tempted not spending the efforts of obtaining the information, free-riding on other agents' computations. A mechanism which elicits agents' secrets and performs the desired computation defines a game. A mechanism is 'appropriate' if there exists an equilibrium in which it is able to elicit (sufficiently many) agents' secrets and perform the computation, for all possible secret vectors. We characterize a general efficient procedure for determining an appropriate mechanism, if such mechanism exists. Moreover, we also address the existence problem, providing a polynomial algorithm for verifying the existence of an appropriate mechanism.

#index 788100
#* Factored latent analysis for far-field tracking data
#@ Chris Stauffer
#t 2004
#c 12
#% 218947
#% 722904
#% 1650298
#! This paper uses Factored Latent Analysis (FLA) to learn a factorized, segmental representation for observations of tracked objects over time. Factored Latent Analysis is latent class analysis in which the observation space is subdivided and each aspect of the original space is represented by a separate latent class model. One could simply treat these factors as completely independent and ignore their interdependencies or one could concatenate them together and attempt to learn latent class structure for the complete observation space. Alternatively, FLA allows the interdependencies to be exploited in estimating an effective model, which is also capable of representing a factored latent state. In this paper, FLA is used to learn a set of factored latent classes to represent different modalities of observations of tracked objects. Different characteristics of the state of tracked objects are each represented by separate latent class models, including normalized size, normalized speed, normalized direction, and position. This model also enables effective temporal segmentation of these sequences. This method is data-driven, unsupervised using only pairwise observation statistics. This data-driven and unsupervised activity classification technique exhibits good performance in multiple challenging environments.

#index 788101
#* Reputation systems: an axiomatic approach
#@ Moshe Tennenholtz
#t 2004
#c 12
#% 100137
#% 101263
#% 233131
#% 316798
#% 480348
#% 580514
#% 782310
#% 1279507
#% 1650358
#! Reasoning about agent preferences on a set of alternatives, and the aggregation of such preferences into some social ranking is a fundamental issue in reasoning about uncertainty and multi-agent systems. When the set of agents and the set of alternatives coincide, we get the so-called reputation systems setting. Famous types of reputation systems include page ranking in the context of search engines and traders ranking in the context of e-commerce. In this paper we present the first axiomatic study of reputation systems. We present three basic postulates that the desired/aggregated social ranking should satisfy and prove an impossibility theorem showing that no appropriate social ranking, satisfying all requirements, exists. Then we show that by relaxing any of these requirements an appropriate social ranking can be found. We first study reputation systems with (only) positive feedbacks. This setting refers to systems where agents' votes are interpreted as indications for the importance of other agents, as is the case in page ranking. Following this, we discuss the case of negative feedbacks, a most common situation in e-commerce settings, where traders may complain about the behavior of others. Finally, we discuss the case where both positive and negative feedbacks are available.

#index 788102
#* ARMA time-series modeling with graphical models
#@ Bo Thiesson;David Maxwell Chickering;David Heckerman;Christopher Meek
#t 2004
#c 12
#% 424851
#% 541077
#% 1759697
#! We express the classic ARMA time-series model as a directed graphical model. In doing so, we find that the deterministic relationships in the model make it effectively impossible to use the EM algorithm for learning model parameters. To remedy this problem, we replace the deterministic relationships with Gaussian distributions having a small variance, yielding the stochastic ARMA (σARMA) model. This modification allows us to use the EM algorithm to learn parameters and to forecast, even in situations where some data is missing. This modification, in conjunction with the graphical-model approach, also allows us to include cross predictors in situations where there are multiple time series and/or additional non-temporal covariates. More surprising, experiments suggest that the move to stochastic ARMA yields improved accuracy through better smoothing. We demonstrate improvements afforded by cross prediction and better smoothing on real data.

#index 788103
#* Identifying conditional causal effects
#@ Jin Tian
#t 2004
#c 12
#% 297171
#% 370075
#% 578740
#% 1272178
#% 1650649
#% 1650678
#! This paper concerns the assessment of the effects of actions from a combination of nonexperimental data and causal assumptions encoded in the form of a directed acyclic graph in which some variables are presumed to be unobserved. We provide a procedure that systematically identifies cause effects between two sets of variables conditioned on some other variables, in time polynomial in the number of variables in the graph. The identifiable conditional causal effects are expressed in terms of the observed joint distribution.

#index 788104
#* Monotonicity in Bayesian networks
#@ Linda C. van der Gaag;Hans L. Bodlaender;Ad Feelders
#t 2004
#c 12
#% 89748
#% 351595
#% 399790
#% 417627
#% 1650391
#% 1650603
#% 1786724
#! For many real-life Bayesian networks, common knowledge dictates that the output established for the main variable of interest increases with higher values for the observable variables. We define two concepts of monotonicity to capture this type of knowledge. We say that a network is isotone in distribution if the probability distribution computed for the output variable given specific observations is stochastically dominated by any such distribution given higher-ordered observations; a network is isotone in mode if a probability distribution given higher observations has a higher mode. We show that establishing whether a network exhibits any of these properties of monotonicity is coNPPP-complete in general, and remains coNP-complete for poly-trees. We present an approximate algorithm for deciding whether a network is monotone in distribution and illustrate its application to a real-life network in oncology.

#index 788105
#* Convergence and asymptotic normality of variational Bayesian approximations for exponential family models with missing values
#@ Bo Wang;D. M. Titterington
#t 2004
#c 12
#% 1650268
#! We study the properties of variational Bayes approximations for exponential family models with missing values. It is shown that the iterative algorithm for obtaining the variational Bayesian estimator converges locally to the true value with probability 1 as the sample size becomes indefinitely large. Moreover, the variational posterior distribution is proved to be asymptotically normal.

#index 788106
#* On the choice of regions for generalized belief propagation
#@ Max Welling
#t 2004
#c 12
#% 450290
#% 475714
#% 528300
#% 528330
#% 1650409
#! Generalized belief propagation (GBP) has proven to be a promising technique for approximate inference tasks in AI and machine learning. However, the choice of a good set of clusters to be used in GBP has remained more of an art then a science until this day. This paper proposes a sequential approach to adding new clusters of nodes and their interactions (i.e. "regions") to the approximation. We first review and analyze the recently introduced region graphs and find that three kinds of operations ("split", "merge" and "death") leave the free energy and (under some conditions) the fixed points of GBP invariant. This leads to the notion of "weakly irreducible" regions as the natural candidates to be added to the approximation. Computational complexity of the GBP algorithm is controlled by restricting attention to regions with small "region-width". Combining the above with an efficient (i.e. local in the graph) measure to predict the improved accuracy of GBP leads to the sequential "region pursuit" algorithm for adding new regions bottom-up to the region graph. Experiments show that this algorithm can indeed perform close to optimally.

#index 788107
#* An integrated, conditional model of information extraction and coreference with application to citation matching
#@ Ben Wellner;Andrew McCallum;Fuchun Peng;Michael Hay
#t 2004
#c 12
#% 438103
#% 460812
#% 464434
#% 528019
#% 529678
#% 643004
#% 770844
#% 816181
#% 854799
#% 855119
#% 1650403
#% 1673026
#! Although information extraction and coreference resolution appear together in many applications, most current systems perform them as independent steps. This paper describes an approach to integrated inference for extraction and coreference based on conditionally-trained undirected graphical models. We discuss the advantages of conditional probability training, and of a coreference model structure based on graph partitioning. On a data set of research paper citations, we show significant reduction in error by using extraction uncertainty to improve coreference citation matching accuracy, and using coreference to improve the accuracy of the extracted fields.

#index 788108
#* Graph partition strategies for generalized mean field inference
#@ Eric P. Xing;Michael I. Jordan;Stuart Russell
#t 2004
#c 12
#% 205305
#% 209961
#% 246836
#% 277467
#% 468074
#% 528019
#% 1673048
#! An autonomous variational inference algorithm for arbitrary graphical models requires the ability to optimize variational approximations over the space of model parameters as well as over the choice of tractable families used for the variational approximation. In this paper, we present a novel combination of graph partitioning algorithms with a generalized mean field (GMF) inference algorithm. This combination optimizes over disjoint clustering of variables and performs inference using those clusters. We provide a formal analysis of the relationship between the graph cut and the GMF approximation, and explore several graph partition strategies empirically. Our empirical results provide rather clear support for a weighted version of MinCut as a useful clustering algorithm for GMF inference, which is consistent with the implications from the formal analysis.

#index 788109
#* Similarity-driven cluster merging method for unsupervised fuzzy clustering
#@ Xuejian Xiong;Kap Luk Chan;Kian Lee Tan
#t 2004
#c 12
#% 104472
#% 142413
#% 279256
#% 318800
#% 387914
#% 469425
#% 1788284
#! In this paper, a similarity-driven cluster merging method is proposed for unsupervised fuzzy clustering. The cluster merging method is used to resolve the problem of cluster validation. Starting with an overspecified number of clusters in the data, pairs of similar clusters are merged based on the proposed similarity-driven cluster merging criterion. The similarity between clusters is calculated by a fuzzy cluster similarity matrix, while an adaptive threshold is used for merging. In addition, a modified generalized objective function is used for prototype-based fuzzy clustering. The function includes the p-norm distance measure as well as principal components of the clusters. The number of the principal components is determined automatically from the data being clustered. The properties of this unsupervised fuzzy clustering algorithm are illustrated by several experiments.

#index 788110
#* Discretized approximations for POMDP with average cost
#@ Huizhen Yu;Dimitri P. Bertsekas
#t 2004
#c 12
#% 92301
#% 102126
#% 137576
#% 351418
#% 363744
#% 1272319
#% 1289243
#! In this paper, we propose a new lower approximation scheme for POMDP with discounted and average cost criterion. The approximating functions are determined by their values at a finite number of belief points, and can be computed efficiently using value iteration algorithms for finite-state MDP. While for discounted problems several lower approximation schemes have been proposed earlier, ours seems the first of its kind for average cost problems. We focus primarily on the average cost case, and we show that the corresponding approximation can be computed efficiently using multi-chain algorithms for finite-state MDP. We give a preliminary analysis showing that regardless of the existence of the optimal average cost J* in the POMDP, the approximation obtained is a lower bound of the liminf optimal average cost function, and can also be used to calculate an upper bound on the limsup optimal average cost function, as well as bounds on the cost of executing the stationary policy associated with the approximation. We show the convergence of the cost approximation, when the optimal average cost is constant and the optimal differential cost is continuous.

#index 788111
#* Annealed MAP
#@ Changhe Yuan;Tsai-Ching Lu;Marek J. Druzdzel
#t 2004
#c 12
#% 172544
#% 183497
#% 302413
#% 448887
#% 501239
#% 515030
#% 528175
#% 1650318
#% 1650391
#% 1673033
#! Maximum a Posteriori assignment (MAP) is the problem of finding the most probable instantiation of a set of variables given the partial evidence on the other variables in a Bayesian network. MAP has been shown to be a NP-hard problem [22], even for constrained networks, such as polytrees [18]. Hence, previous approaches often fail to yield any results for MAP problems in large complex Bayesian networks. To address this problem, we propose ANNEALEDMAP algorithm, a simulated annealing-based MAP algorithm. The ANNEALEDMAP algorithm simulates a non-homogeneous Markov chain whose invariant function is a probability density that concentrates itself on the modes of the target density. We tested this algorithm on several real Bayesian networks. The results show that, while maintaining good quality of the MAP solutions, the ANNEALEDMAP algorithm is also able to solve many problems that are beyond the reach of previous approaches.

#index 788112
#* Maximum entropy for collaborative filtering
#@ C. Lawrence Zitnick;Takeo Kanade
#t 2004
#c 12
#% 124010
#% 173879
#% 465928
#% 722754
#% 840577
#% 1650399
#% 1650569
#% 1673017
#! Within the task of collaborative filtering two challenges for computing conditional probabilities exist. First, the amount of training data available is typically sparse with respect to the size of the domain. Thus, support for higher-order interactions is generally not present. Second, the variables that we are conditioning upon vary for each query. That is, users label different variables during each query. For this reason, there is no consistent input to output mapping. To address these problems we purpose a maximum entropy approach using a non-standard measure of entropy. This approach can be simplified to solving a set of linear equations that can be efficiently solved.

#index 1417051
#* Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence
#@ David McAllester
#t 2009
#c 12

#index 1417052
#* On maximum a posteriori estimation of hidden Markov processes
#@ Armen Allahverdyan;Aram Galstyan
#t 2009
#c 12
#% 1051604
#% 1810819
#! We present a theoretical analysis of Maximum a Posteriori (MAP) sequence estimation for binary symmetric hidden Markov processes. We reduce the MAP estimation to the energy minimization of an appropriately defined Ising spin model, and focus on the performance of MAP as characterized by its accuracy and the number of solutions corresponding to a typical observed sequence. It is shown that for a finite range of sufficiently low noise levels, the solution is uniquely related to the observed sequence, while the accuracy degrades linearly with increasing the noise strength. For intermediate noise values, the accuracy is nearly noise-independent, but now there are exponentially many solutions to the estimation problem, which is reflected in non--zero ground--state entropy for the Ising model. Finally, for even larger noise intensities, the number of solutions reduces again, but the accuracy is poor. It is shown that these regimes are different thermodynamic phases of the Ising model that are related to each other via first-order phase transitions.

#index 1417053
#* Lower bound Bayesian networks: an efficient inference of lower bounds on probability distributions in Bayesian networks
#@ Daniel Andrade;Bernhard Sick
#t 2009
#c 12
#% 44876
#% 231738
#% 528027
#% 788048
#% 913188
#% 1042075
#% 1289559
#% 1673003
#% 1786966
#! We present a new method to propagate lower bounds on conditional probability distributions in conventional Bayesian networks. Our method guarantees to provide outer approximations of the exact lower bounds. A key advantage is that we can use any available algorithms and tools for Bayesian networks in order to represent and infer lower bounds. This new method yields results that are provable exact for trees with binary variables, and results which are competitive to existing approximations in credal networks for all other network structures. Our method is not limited to a specific kind of network structure. Basically, it is also not restricted to a specific kind of inference, but we restrict our analysis to prognostic inference in this article. The computational complexity is superior to that of other existing approaches.

#index 1417054
#* A Bayesian sampling approach to exploration in reinforcement learning
#@ John Asmuth;Lihong Li;Michael L. Littman;Ali Nouri;David Wingate
#t 2009
#c 12
#% 174161
#% 425075
#% 466731
#% 722895
#% 840955
#% 876032
#% 983931
#% 1269760
#! We present a modular approach to reinforcement learning that uses a Bayesian representation of the uncertainty over models. The approach, BOSS (Best of Sampled Set), drives exploration by sampling multiple models from the posterior and selecting actions optimistically. It extends previous work by providing a rule for deciding when to re-sample and how to combine the models. We show that our algorithm achieves near-optimal reward with high probability with a sample complexity that is low relative to the speed at which the posterior distribution converges during learning. We demonstrate that BOSS performs quite favorably compared to state-of-the-art reinforcement-learning approaches and illustrate its flexibility by pairing it with a non-parametric model that generalizes across states.

#index 1417055
#* On smoothing and inference for topic models
#@ Arthur Asuncion;Max Welling;Padhraic Smyth;Yee Whye Teh
#t 2009
#c 12
#% 277483
#% 329569
#% 449654
#% 643056
#% 681851
#% 722904
#% 788105
#% 961199
#% 1108903
#% 1742154
#% 1767909
#! Latent Dirichlet analysis, or topic modeling, is a flexible latent variable framework for modeling high-dimensional sparse count data. Various learning algorithms have been developed in recent years, including collapsed Gibbs sampling, variational inference, and maximum a posteriori estimation, and this variety motivates the need for careful empirical comparisons. In this paper, we highlight the close connections between these approaches. We find that the main differences are attributable to the amount of smoothing applied to the counts. When the hyperparameters are optimized, the differences in performance among the algorithms diminish significantly. The ability of these algorithms to achieve solutions of comparable accuracy gives us the freedom to select computationally efficient approaches. Using the insights gained from this comparative study, we show how accurate topic models can be learned in several seconds on text corpora with thousands of documents.

#index 1417056
#* REGAL: a regularization based algorithm for reinforcement learning in weakly communicating MDPs
#@ Peter L. Bartlett;Ambuj Tewari
#t 2009
#c 12
#% 239000
#% 363744
#% 425075
#% 722895
#% 840942
#% 871302
#% 876055
#! We provide an algorithm that achieves the optimal regret rate in an unknown weakly communicating Markov Decision Process (MDP). The algorithm proceeds in episodes where, in each episode, it picks a policy using regularization based on the span of the optimal bias vector. For an MDP with S states and A actions whose optimal bias vector has span bounded by H, we show a regret bound of Õ(HS√AT). We also relate the span to various diameter-like quantities associated with the MDP, demonstrating how our results improve on previous regret bounds.

#index 1417057
#* Alternating projections for learning with expectation constraints
#@ Kedar Bellare;Gregory Druck;Andrew McCallum
#t 2009
#c 12
#% 211044
#% 464434
#% 939527
#% 1045261
#% 1074125
#% 1211770
#% 1328345
#% 1674771
#! We present an objective function for learning with unlabeled data that utilizes auxiliary expectation constraints. We optimize this objective function using a procedure that alternates between information and moment projections. Our method provides an alternate interpretation of the posterior regularization framework (Graca et al., 2008), maintains uncertainty during optimization unlike constraint-driven learning (Chang et al., 2007), and is more efficient than generalized expectation criteria (Mann & McCallum, 2008). Applications of this framework include minimally supervised learning, semi-supervised learning, and learning with constraints that are more expressive than the underlying model. In experiments, we demonstrate comparable accuracy to generalized expectation criteria for minimally supervised learning, and use expressive structural constraints to guide semi-supervised learning, providing a 3%-6% improvement over state-of-the-art constraint-driven learning.

#index 1417058
#* Conditional probability tree estimation analysis and algorithms
#@ Alina Beygelzimer;John Langford;Yuri Lifshits;Gregory Sorkin;Alex Strehl
#t 2009
#c 12
#% 136350
#% 276526
#% 376266
#% 763708
#% 1705511
#! We consider the problem of estimating the conditional probability of a label in time O(log n), where n is the number of possible labels. We analyze a natural reduction of this problem to a set of binary regression problems organized in a tree structure, proving a regret bound that scales with the depth of the tree. Motivated by this analysis, we propose the first online algorithm which provably constructs a logarithmic depth tree on the set of labels to solve this problem. We test the algorithm empirically, showing that it works succesfully on a dataset with roughly 106 labels.

#index 1417059
#* Deterministic POMDPs revisited
#@ Blai Bonet
#t 2009
#c 12
#% 25470
#% 174161
#% 297171
#% 310835
#% 337981
#% 361729
#% 703709
#% 788098
#% 1068450
#% 1250642
#% 1269573
#% 1272075
#% 1272129
#% 1272248
#% 1272331
#% 1290265
#% 1291454
#% 1291498
#! We study a subclass of POMDPs, called Deterministic POMDPs, that is characterized by deterministic actions and observations. These models do not provide the same generality of POMDPs yet they capture a number of interesting and challenging problems, and permit more efficient algorithms. Indeed, some of the recent work in planning is built around such assumptions mainly by the quest of amenable models more expressive than the classical deterministic models. We provide results about the fundamental properties of Deterministic POMDPs, their relation with AND/OR search problems and algorithms, and their computational complexity.

#index 1417060
#* Optimization of structured mean field objectives
#@ Alexandre Bouchard-Côté;Michael I. Jordan
#t 2009
#c 12
#% 304811
#% 416663
#% 528019
#% 528315
#% 1166535
#% 1272120
#% 1295075
#% 1762457
#! In intractable, undirected graphical models, an intuitive way of creating structured mean field approximations is to select an acyclic tractable subgraph. We show that the hardness of computing the objective function and gradient of the mean field objective qualitatively depends on a simple graph property. If the tractable subgraph has this property---we call such subgraphs v-acyclic---a very fast block coordinate ascent algorithm is possible. If not, optimization is harder, but we show a new algorithm based on the construction of an auxiliary exponential family that can be used to make inference possible in this case as well. We discuss the advantages and disadvantages of each regime and compare the algorithms empirically.

#index 1417061
#* Multilingual topic models for unaligned text
#@ Jordan Boyd-Graber;David M. Blei
#t 2009
#c 12
#% 722904
#% 747947
#% 748574
#% 757787
#% 786585
#% 812535
#% 854571
#% 876067
#% 879587
#% 983644
#% 1190212
#! We develop the multilingual topic model for unaligned text (MuTo), a probabilistic model of text that is designed to analyze corpora composed of documents in two languages. From these documents, MuTo uses stochastic EM to simultaneously discover both a matching between the languages and multilingual latent topics. We demonstrate that MuTo is able to find shared topics on real-world multilingual corpora, successfully pairing related documents across languages. MuTo provides a new framework for creating multilingual topic models without needing carefully curated parallel corpora and allows applications built using the topic model formalism to be applied to a much wider class of corpora.

#index 1417062
#* Convex coding
#@ David M. Bradley;J. Andrew Bagnell
#t 2009
#c 12
#% 757953
#% 855261
#% 871302
#% 873583
#% 873584
#% 883858
#% 961261
#% 983899
#% 1073960
#% 1108903
#% 1164188
#! Inspired by recent work on convex formulations of clustering (Lashkari & Golland, 2008; Nowozin & Bakir, 2008) we investigate a new formulation of the Sparse Coding Problem (Olshausen & Field, 1997). In sparse coding we attempt to simultaneously represent a sequence of data-vectors sparsely (i.e. sparse approximation (Tropp et al., 2006)) in terms of a "code" defined by a set of basis elements, while also finding a code that enables such an approximation. As existing alternating optimization procedures for sparse coding are theoretically prone to severe local minima problems, we propose a convex relaxation of the sparse coding problem and derive a boosting-style algorithm, that (Nowozin & Bakir, 2008) serves as a convex "master problem" which calls a (potentially non-convex) sub-problem to identify the next code element to add. Finally, we demonstrate the properties of our boosted coding algorithm on an image denoising task.

#index 1417063
#* Mean field variational approximation for continuous-time Bayesian networks
#@ Ido Cohn;Tal El-Hay;Nir Friedman;Raz Kupferman
#t 2009
#c 12
#% 277467
#% 1166535
#% 1650390
#% 1650568
#! Continuous-time Bayesian networks is a natural structured representation language for multi-component stochastic processes that evolve continuously over time. Despite the compact representation, inference in such models is intractable even in relatively simple structured networks. Here we introduce a mean field variational approximation in which we use a product of inhomogeneous Markov processes to approximate a distribution over trajectories. This variational approach leads to a globally consistent distribution, which can be efficiently queried. Additionally, it provides a lower bound on the probability of observations, thus making it attractive for learning tasks. We provide the theoretical foundations for the approximation, an efficient implementation that exploits the wide range of highly optimized ordinary differential equations (ODE) solvers, experimentally explore characterizations of processes for which this approximation is suitable, and show applications to a large-scale real-world inference problem.

#index 1417064
#* Prediction markets, mechanism design, and cooperative game theory
#@ Vincent Conitzer
#t 2009
#c 12
#% 431455
#% 754152
#% 770091
#% 873565
#% 963364
#% 963365
#% 1071508
#% 1071510
#% 1339861
#! Prediction markets are designed to elicit information from multiple agents in order to predict (obtain probabilities for) future events. A good prediction market incentivizes agents to reveal their information truthfully; such incentive compatibility considerations are commonly studied in mechanism design. While this relation between prediction markets and mechanism design is well understood at a high level, the models used in prediction markets tend to be somewhat different from those used in mechanism design. This paper considers a model for prediction markets that fits more straightforwardly into the mechanism design framework. We consider a number of mechanisms within this model, all based on proper scoring rules. We discuss basic properties of these mechanisms, such as incentive compatibility. We also draw connections between some of these mechanisms and cooperative game theory. Finally, we speculate how one might build a practical prediction market based on some of these ideas.

#index 1417065
#* L2 regularization for learning kernels
#@ Corinna Cortes;Mehryar Mohri;Afshin Rostamizadeh
#t 2009
#c 12
#% 116149
#% 197394
#% 466081
#% 722805
#% 743284
#% 763697
#% 770848
#% 829029
#% 829031
#% 875950
#% 876014
#% 983953
#% 1674773
#% 1705523
#! The choice of the kernel is critical to the success of many learning algorithms but it is typically left to the user. Instead, the training data can be used to learn the kernel by selecting it out of a given family, such as that of non-negative linear combinations of p base kernels, constrained by a trace or L1 regularization. This paper studies the problem of learning kernels with the same family of kernels but with an L2 regularization instead, and for regression problems. We analyze the problem of learning kernels with ridge regression. We derive the form of the solution of the optimization problem and give an efficient iterative algorithm for computing that solution. We present a novel theoretical analysis of the problem based on stability and give learning bounds for orthogonal kernels that contain only an additive term O(√p/m) when compared to the standard kernel ridge regression stability bound. We also report the results of experiments indicating that L1 regularization can lead to modest improvements for a small number of kernels, but to performance degradations in larger-scale cases. In contrast, L2 regularization never degrades performance and in fact achieves significant improvements with a large number of kernels.

#index 1417066
#* Complexity analysis and variational inference for interpretation-based probabilistic description logics
#@ Fabio Gagliardi Cozman;Rodrigo Bellizia Polastro
#t 2009
#c 12
#% 90371
#% 254087
#% 267725
#% 296869
#% 420743
#% 591180
#% 729449
#% 923861
#% 944140
#% 1000502
#% 1036395
#% 1036397
#% 1042075
#% 1111118
#% 1111120
#% 1136065
#% 1222411
#% 1270261
#% 1271815
#% 1279259
#% 1289559
#% 1289560
#% 1478789
#% 1650727
#% 1815596
#! This paper presents complexity analysis and variational methods for inference in probabilistic description logics featuring Boolean operators, quantification, qualified number restrictions, nominals, inverse roles and role hierarchies. Inference is shown to be PEXP-complete, and variational methods are designed so as to exploit logical inference whenever possible.

#index 1417067
#* Seeing the forest despite the trees: large scale spatial-temporal decision making
#@ Mark Crowley;John Nelson;David Poole
#t 2009
#c 12
#% 384911
#% 565550
#% 1073929
#% 1090422
#! We introduce a challenging real-world planning problem where actions must be taken at each location in a spatial area at each point in time. We use forestry planning as the motivating application. In Large Scale Spatial-Temporal (LSST) planning problems, the state and action spaces are defined as the cross-products of many local state and action spaces spread over a large spatial area such as a city or forest. These problems possess state uncertainty, have complex utility functions involving spatial constraints and we generally must rely on simulations rather than an explicit transition model. We define LSST problems as reinforcement learning problems and present a solution using policy gradients. We compare two different policy formulations: an explicit policy that identifies each location in space and the action to take there; and an abstract policy that defines the proportion of actions to take across all locations in space. We show that the abstract policy is more robust and achieves higher rewards with far fewer parameters than the elementary policy. This abstract policy is also a better fit to the properties that practitioners in LSST problem domains require for such methods to be widely useful.

#index 1417068
#* Bayesian multitask learning with latent hierarchies
#@ Hal Daumé, III
#t 2009
#c 12
#% 236497
#% 840962
#% 876034
#% 961246
#% 983814
#% 1261539
#% 1264789
#! We learn multiple hypotheses for related tasks under a latent hierarchical relationship between tasks. We exploit the intuition that for domain adaptation, we wish to share classifier structure, but for multitask learning, we wish to share covariance structure. Our hierarchical model is seen to subsume several previously proposed multitask learning models and performs well on three distinct real-world data sets.

#index 1417069
#* Correlated non-parametric latent feature models
#@ Finale Doshi-Velez;Zoubin Ghahramani
#t 2009
#c 12
#% 44876
#% 420515
#% 891060
#% 1342841
#! We are often interested in explaining data through a set of hidden factors or features. When the number of hidden features is unknown, the Indian Buffet Process (IBP) is a nonparametric latent feature model that does not bound the number of active features in dataset. However, the IBP assumes that all latent features are uncorrelated, making it inadequate for many realworld problems. We introduce a framework for correlated non-parametric feature models, generalising the IBP. We use this framework to generate several specific models and demonstrate applications on realworld datasets.

#index 1417070
#* A sampling-based approach to computing equilibria in succinct extensive-form games
#@ Miroslav Dudík;Geoffrey J. Gordon
#t 2009
#c 12
#% 235377
#% 527859
#% 578708
#% 805727
#% 868462
#% 1014647
#% 1073917
#% 1272105
#% 1279322
#% 1289289
#! A central task of artificial intelligence is the design of artificial agents that act towards specified goals in partially observed environments. Since such environments frequently include interaction over time with other agents with their own goals, reasoning about such interaction relies on sequential game-theoretic models such as extensive-form games or some of their succinct representations such as multi-agent influence diagrams. The current algorithms for calculating equilibria either work with inefficient representations, possibly doubly exponential in the number of time steps, or place strong assumptions on the game structure. In this paper, we propose a sampling-based approach, which calculates extensive-form correlated equilibria with small representations without placing such strong assumptions. Thus, it is practical in situations where the previous approaches would fail. In addition, our algorithm allows control over characteristics of the target equilibrium, e.g., we can ask for an equilibrium with high social welfare. Our approach is based on a multiplicative-weight update algorithm analogous to AdaBoost, and Markov chain Monte Carlo sampling. We prove convergence guarantees and explore the utility of our approach on several moderately sized multi-player games.

#index 1417071
#* Learning continuous-time social network dynamics
#@ Yu Fan;Christian R. Shelton
#t 2009
#c 12
#% 1650390
#% 1673032
#! We demonstrate that a number of sociology models for social network dynamics can be viewed as continuous time Bayesian networks (CTBNs). A sampling-based approximate inference method for CTBNs can be used as the basis of an expectation-maximization procedure that achieves better accuracy in estimating the parameters of the model than the standard method of moments algorithm from the sociology literature. We extend the existing social network models to allow for indirect and asynchronous observations of the links. A Markov chain Monte Carlo sampling algorithm for this new model permits estimation and inference. We provide results on both a synthetic network (for verification) and real social network data.

#index 1417072
#* Robust graphical modeling with t-distributions
#@ Michael A. Finegold;Mathias Drton
#t 2009
#c 12
#% 465762
#% 895804
#% 1074353
#% 1074367
#! Graphical Gaussian models have proven to be useful tools for exploring network structures based on multivariate data. Applications to studies of gene expression have generated substantial interest in these models, and resulting recent progress includes the development of fitting methodology involving penalization of the likelihood function. In this paper we advocate the use of the multivariate t and related distributions for more robust inference of graphs. In particular, we demonstrate that penalized likelihood inference combined with an application of the EM algorithm provides a simple and computationally efficient approach to model selection in the t-distribution case.

#index 1417073
#* Generating optimal plans in highly-dynamic domains
#@ Christian Fritz;Sheila A. McIlraith
#t 2009
#c 12
#% 194656
#% 342119
#% 1272131
#% 1272367
#% 1275138
#% 1289241
#% 1527494
#! Generating optimal plans in highly dynamic environments is challenging. Plans are predicated on an assumed initial state, but this state can change unexpectedly during plan generation, potentially invalidating the planning effort. In this paper we make three contributions: (1) We propose a novel algorithm for generating optimal plans in settings where frequent, unexpected events interfere with planning. It is able to quickly distinguish relevant from irrelevant state changes, and to update the existing planning search tree if necessary. (2) We argue for a new criterion for evaluating plan adaptation techniques: the relative running time compared to the "size" of changes. This is significant since during recovery more changes may occur that need to be recovered from subsequently, and in order for this process of repeated recovery to terminate, recovery time has to converge. (3) We show empirically that our approach can converge and find optimal plans in environments that would ordinarily defy planning due to their high dynamics.

#index 1417074
#* Censored exploration and the Dark Pool Problem
#@ Kuzman Ganchev;Michael Kearns;Yuriy Nevmyvaka;Jennifer Wortman Vaughan
#t 2009
#c 12
#% 425075
#% 722895
#% 871302
#! We introduce and analyze a natural algorithm for multi-venue exploration from censored data, which is motivated by the Dark Pool Problem of modern quantitative finance. We prove that our algorithm converges in polynomial time to a near-optimal allocation policy; prior results for similar problems in stochastic inventory control guaranteed only asymptotic convergence and examined variants in which each venue could be treated independently. Our analysis bears a strong resemblance to that of efficient exploration/exploitation schemes in the reinforcement learning literature. We describe an extensive experimental evaluation of our algorithm on the Dark Pool Problem using real trading data.

#index 1417075
#* Approximate inference on planar graphs using loop calculus and belief propagation
#@ Vicenç Gómez;Hilbert J. Kappen;Michael Chertkov
#t 2009
#c 12
#% 44876
#% 252620
#% 272514
#% 1014671
#% 1650318
#% 1673015
#% 1810386
#% 1815596
#% 1815597
#! We introduce novel results for approximate inference on planar graphical models using the loop calculus framework. The loop calculus (Chertkov and Chernyak, 2006b) allows to express the exact partition function Z of a graphical model as a finite sum of terms that can be evaluated once the belief propagation (BP) solution is known. In general, full summation over all correction terms is intractable. We develop an algorithm for the approach presented in Chertkov et al. (2008) which represents an efficient truncation scheme on planar graphs and a new representation of the series in terms of Pfaffians of matrices. We analyze in detail both the loop series and the Pfaffian series for models with binary variables and pairwise interactions, and show that the first term of the Pfaffian series can provide very accurate approximations. The algorithm outperforms previous truncation schemes of the loop series and is competitive with other state-of-the-art methods for approximate inference.

#index 1417076
#* Distributed parallel inference on large factor graphs
#@ Joseph E. Gonzalez;Yucheng Low;Carlos Guestrin;David O'Hallaron
#t 2009
#c 12
#% 44876
#% 258598
#% 276701
#% 580307
#% 879222
#! As computer clusters become more common and the size of the problems encountered in the field of AI grows, there is an increasing demand for efficient parallel inference algorithms. We consider the problem of parallel inference on large factor graphs in the distributed memory setting of computer clusters. We develop a new efficient parallel inference algorithm, DBRSplash, which incorporates over-segmented graph partitioning, belief residual scheduling, and uniform work Splash operations. We empirically evaluate the DBRSplash algorithm on a 120 processor cluster and demonstrate linear to super-linear performance gains on large factor graph models.

#index 1417077
#* First-order mixed integer linear programming
#@ Geoffrey J. Gordon;Sue Ann Hong;Miroslav Dudík
#t 2009
#c 12
#% 299169
#% 420771
#% 495768
#% 576214
#% 840927
#% 850430
#% 1269437
#% 1270261
#% 1289246
#% 1289560
#% 1289565
#% 1416205
#! Mixed integer linear programming (MILP) is a powerful representation often used to formulate decision-making problems under uncertainty. However, it lacks a natural mechanism to reason about objects, classes of objects, and relations. First-order logic (FOL), on the other hand, excels at reasoning about classes of objects, but lacks a rich representation of uncertainty. While representing propositional logic in MILP has been extensively explored, no theory exists yet for fully combining FOL with MILP. We propose a new representation, called first-order programming or FOP, which subsumes both FOL and MILP. We establish formal methods for reasoning about first order programs, including a sound and complete lifted inference procedure for integer first order programs. Since FOP can offer exponential savings in representation and proof size compared to FOL, and since representations and proofs are never significantly longer in FOP than in FOL, we anticipate that inference in FOP will be more tractable than inference in FOL for corresponding problems.

#index 1417078
#* New inference strategies for solving Markov decision processes using reversible jump MCMC
#@ Matt Hoffman;Hendrik Kueck;Nando de Freitas;Arnaud Doucet
#t 2009
#c 12
#% 225838
#% 424878
#% 443894
#% 527859
#% 576218
#% 876063
#% 1194369
#! In this paper we build on previous work which uses inferences techniques, in particular Markov Chain Monte Carlo (MCMC) methods, to solve parameterized control problems. We propose a number of modifications in order to make this approach more practical in general, higher-dimensional spaces. We first introduce a new target distribution which is able to incorporate more reward information from sampled trajectories. We also show how to break strong correlations between the policy parameters and sampled trajectories in order to sample more freely. Finally, we show how to incorporate these techniques in a principled manner to obtain estimates of the optimal policy.

#index 1417079
#* Improved mean and variance approximations for belief net responses via network doubling
#@ Peter Hooper;Yasin Abbasi-Yadkori;Russ Greiner;Bret Hoehn
#t 2009
#c 12
#% 528319
#% 876011
#% 1027304
#% 1269480
#! A Bayesian belief network models a joint distribution with an directed acyclic graph representing dependencies among variables and network parameters characterizing conditional distributions. The parameters are viewed as random variables to quantify uncertainty about their values. Belief nets are used to compute responses to queries; i.e., conditional probabilities of interest. A query is a function of the parameters, hence a random variable. Van Allen et al. (2001, 2008) showed how to quantify uncertainty about a query via a delta method approximation of its variance. We develop more accurate approximations for both query mean and variance. The key idea is to extend the query mean approximation to a "doubled network" involving two independent replicates. Our method assumes complete data and can be applied to discrete, continuous, and hybrid networks (provided discrete variables have only discrete parents). We analyze several improvements, and provide empirical studies to demonstrate their effectiveness.

#index 1417080
#* Bayesian discovery of linear acyclic causal models
#@ Patrik O. Hoyer;Antti Hyttinen
#t 2009
#c 12
#% 197387
#% 297171
#% 763715
#% 961205
#! Methods for automated discovery of causal relationships from non-interventional data have received much attention recently. A widely used and well understood model family is given by linear acyclic causal models (recursive structural equation models). For Gaussian data both constraint-based methods (Spirtes et al., 1993; Pearl, 2000) (which output a single equivalence class) and Bayesian score-based methods (Geiger and Heckerman, 1994) (which assign relative scores to the equivalence classes) are available. On the contrary, all current methods able to utilize non-Gaussianity in the data (Shimizu et al., 2006; Hoyer et al., 2008) always return only a single graph or a single equivalence class, and so are fundamentally unable to express the degree of certainty attached to that output. In this paper we develop a Bayesian score-based approach able to take advantage of non-Gaussianity when estimating linear acyclic causal models, and we empirically demonstrate that, at least on very modest size networks, its accuracy is as good as or better than existing methods. We provide a complete code package (in R) which implements all algorithms and performs all of the analysis provided in the paper, and hope that this will further the application of these methods to solving causal inference problems.

#index 1417081
#* Identifying confounders using additive noise models
#@ Dominik Janzing;Jonas Peters;Joris Mooij;Bernhard Schölkopf
#t 2009
#c 12
#% 297171
#% 891549
#% 961141
#% 1093476
#% 1673681
#! We propose a method for inferring the existence of a latent common cause ("confounder") of two observed random variables. The method assumes that the two effects of the confounder are (possibly nonlinear) functions of the confounder plus independent, additive noise. We discuss under which conditions the model is identifiable (up to an arbitrary reparameterization of the confounder) from the joint distribution of the effects. We state and prove a theoretical result that provides evidence for the conjecture that the model is generically identifiable under suitable technical conditions. In addition, we propose a practical method to estimate the confounder from a finite i.i.d. sample of the effects and illustrate that the method works well on both simulated and real-world data.

#index 1417082
#* MAP estimation, message passing, and perfect graphs
#@ Tony Jebara
#t 2009
#c 12
#% 44876
#% 101250
#% 749535
#% 806952
#% 857454
#% 876037
#% 1164839
#% 1166535
#% 1810398
#% 1815753

#index 1417083
#* Temporal action-graph games: a new representation for dynamic games
#@ Albert Xin Jiang;Kevin Leyton-Brown;Avi Pfeffer
#t 2009
#c 12
#% 527993
#% 528021
#% 567883
#% 711139
#% 788040
#% 1222623
#% 1250614
#% 1271984
#% 1279321
#% 1279323
#% 1650767
#% 1784146
#! In this paper we introduce temporal action graph games (TAGGs), a novel graphical representation of imperfect-information extensive form games. We show that when a game involves anonymity or context-specific utility independencies, its encoding as a TAGG can be much more compact than its direct encoding as a multiagent influence diagram (MAID). We also show that TAGGs can be understood as indirect MAID encodings in which many deterministic chance nodes are introduced. We provide an algorithm for computing with TAGGs, and show both theoretically and empirically that our approach improves significantly on the previous state of the art.

#index 1417084
#* Counting belief propagation
#@ Kristian Kersting;Babak Ahmadi;Sriraam Natarajan
#t 2009
#c 12
#% 44876
#% 528340
#% 850430
#% 1000502
#% 1250334
#% 1270256
#% 1270261
#% 1279353
#% 1289560
#% 1411174
#% 1416197
#% 1650318
#% 1650568
#! A major benefit of graphical models is that most knowledge is captured in the model structure. Many models, however, produce inference problems with a lot of symmetries not reflected in the graphical structure and hence not exploitable by efficient inference techniques such as belief propagation (BP). In this paper, we present a new and simple BP algorithm, called counting BP, that exploits such additional symmetries. Starting from a given factor graph, counting BP first constructs a compressed factor graph of clusternodes and clusterfactors, corresponding to sets of nodes and factors that are indistinguishable given the evidence. Then it runs a modified BP algorithm on the compressed graph that is equivalent to running BP on the original factor graph. Our experiments show that counting BP is applicable to a variety of important AI tasks such as (dynamic) relational models and boolean model counting, and that significant efficiency gains are obtainable, often by orders of magnitude.

#index 1417085
#* Monolingual probabilistic programming using generalized coroutines
#@ Oleg Kiselyov;Chung-chieh Shan
#t 2009
#c 12
#% 277465
#% 576214
#% 737186
#% 1000502
#% 1001192
#% 1002378
#% 1090404
#% 1478844
#! Probabilistic programming languages and modeling toolkits are two modular ways to build and reuse stochastic models and inference procedures. Combining strengths of both, we express models and inference as generalized coroutines in the same general-purpose language. We use existing facilities of the language, such as rich libraries, optimizing compilers, and types, to develop concise, declarative, and realistic models with competitive performance on exact and approximate inference. In particular, a wide range of models can be expressed using memoization. Because deterministic parts of models run at full speed, custom inference procedures are trivial to incorporate, and inference procedures can reason about themselves without interpretive overhead. Within this framework, we introduce a new, general algorithm for importance sampling with look-ahead.

#index 1417086
#* Constraint processing in lifted probabilistic inference
#@ Jacek Kisyński;David Poole
#t 2009
#c 12
#% 644201
#% 1000502
#% 1270256
#% 1270261
#% 1279353
#% 1416197
#! First-order probabilistic models combine representational power of first-order logic with graphical models. There is an ongoing effort to design lifted inference algorithms for first-order probabilistic models. We analyze lifted inference from the perspective of constraint processing and, through this viewpoint, we analyze and compare existing approaches and expose their advantages and limitations. Our theoretical results show that the wrong choice of constraint processing method can lead to exponential increase in computational complexity. Our empirical tests confirm the importance of constraint processing in lifted inference. This is the first theoretical and empirical study of constraint processing in lifted inference.

#index 1417087
#* The temporal logic of causal structures
#@ Samantha Kleinberg;Bud Mishra
#t 2009
#c 12
#% 297171
#% 297770
#% 463903
#% 494192
#% 832892
#% 1650580
#! Computational analysis of time-course data with an underlying causal structure is needed in a variety of domains, including neural spike trains, stock price movements, and gene expression levels. However, it can be challenging to determine from just the numerical time course data alone what is coordinating the visible processes, to separate the underlying prima facie causes into genuine and spurious causes and to do so with a feasible computational complexity. For this purpose, we have been developing a novel algorithm based on a framework that combines notions of causality in philosophy with algorithmic approaches built on model checking and statistical techniques for multiple hypotheses testing. The causal relationships are described in terms of temporal logic formulæ, reframing the inference problem in terms of model checking. The logic used, PCTL, allows description of both the time between cause and effect and the probability of this relationship being observed. We show that equipped with these causal formulæ with their associated probabilities we may compute the average impact a cause makes to its effect and then discover statistically significant causes through the concepts of multiple hypothesis testing (treating each causal relationship as a hypothesis), and false discovery control. By exploring a well-chosen family of potentially all significant hypotheses with reasonably minimal description length, it is possible to tame the algorithm's computational complexity while exploring the nearly complete search-space of all prima facie causes. We have tested these ideas in a number of domains and illustrate them here with two examples.

#index 1417088
#* MAP estimation of semi-metric MRFs via hierarchical graph cuts
#@ M. Pawan Kumar;Daphne Koller
#t 2009
#c 12
#% 44876
#% 249183
#% 575676
#% 580714
#% 592345
#% 593840
#% 635689
#% 770763
#% 772862
#% 803614
#% 889176
#% 1073932
#% 1081627
#% 1148252
#% 1667612
#% 1815753
#% 1845478
#! We consider the task of obtaining the maximum a posteriori estimate of discrete pairwise random fields with arbitrary unary potentials and semi-metric pairwise potentials. For this problem, we propose an accurate hierarchical move making strategy where each move is computed efficiently by solving an st-MINCUT problem. Unlike previous move making approaches, e.g. the widely used α-expansion algorithm, our method obtains the guarantees of the standard linear programming (LP) relaxation for the important special case of metric labeling. Unlike the existing LP relaxation solvers, e.g. interior-point algorithms or tree-reweighted message passing, our method is significantly faster as it uses only the efficient st-MINCUT algorithm in its design. Using both synthetic and real data experiments, we show that our technique outperforms several commonly used algorithms.

#index 1417089
#* Quantum annealing for clustering
#@ Kenichi Kurihara;Shu Tanaka;Seiji Miyashita
#t 2009
#c 12
#% 722904
#% 983872
#! This paper studies quantum annealing (QA) for clustering, which can be seen as an extension of simulated annealing (SA). We derive a QA algorithm for clustering and propose an annealing schedule, which is crucial in practice. Experiments show the proposed QA algorithm finds better clustering assignments than SA. Furthermore, QA is as easy as SA to implement.

#index 1417090
#* Improving compressed counting
#@ Ping Li
#t 2009
#c 12
#% 347223
#% 378388
#% 460787
#% 466510
#% 578389
#% 593957
#% 749451
#% 769927
#% 805744
#% 821929
#% 821933
#% 873255
#% 879397
#% 894646
#% 903187
#% 995020
#% 1002033
#% 1014686
#% 1035574
#% 1039579
#% 1132191
#% 1141469
#% 1164863
#% 1176937
#! Compressed Counting (CC) [22] was recently proposed for estimating the αth frequency moments of data streams, where 0 This paper presents a new algorithm for improving CC. The improvement is most substantial when α → 1--. For example, when α = 0.99, the new algorithm reduces the estimation variance roughly by 100-fold. This new algorithm would make CC considerably more practical for estimating Shannon entropy. Furthermore, the new algorithm is statistically optimal when α = 0.5.

#index 1417091
#* Multi-task feature learning via efficient l2, 1-norm minimization
#@ Jun Liu;Shuiwang Ji;Jieping Ye
#t 2009
#c 12
#% 757953
#% 769886
#% 891559
#% 1073978
#% 1074364
#% 1077165
#% 1128929
#% 1128931
#% 1211772
#% 1214676
#! The problem of joint feature selection across a group of related tasks has applications in many areas including biomedical informatics and computer vision. We consider the l2, 1-norm regularized regression model for joint feature selection from multiple tasks, which can be derived in the probabilistic framework by assuming a suitable prior from the exponential family. One appealing feature of the l2, 1-norm regularization is that it encourages multiple predictors to share similar sparsity patterns. However, the resulting optimization problem is challenging to solve due to the non-smoothness of the l2, 1-norm regularization. In this paper, we propose to accelerate the computation by reformulating it as two equivalent smooth convex optimization problems which are then solved via the Nesterov's method---an optimal first-order black-box method for smooth convex optimization. A key building block in solving the reformulations is the Euclidean projection. We show that the Euclidean projection for the first reformulation can be analytically computed, while the Euclidean projection for the second one can be computed in linear time. Empirical evaluations on several data sets verify the efficiency of the proposed algorithms.

#index 1417092
#* Quantifying the strategyproofness of mechanisms via metrics on payoff distributions
#@ Benjamin Lubin;David C. Parkes
#t 2009
#c 12
#% 314944
#% 345429
#% 453488
#% 788092
#% 818584
#% 868478
#% 890339
#% 1083993
#% 1289307
#% 1339858
#% 1650358
#! Strategyproof mechanisms provide robust equilibrium with minimal assumptions about knowledge and rationality but can be unachievable in combination with other desirable properties such as budget-balance, stability against deviations by coalitions, and computational tractability. In the search for maximally-strategyproof mechanisms that simultaneously satisfy other desirable properties, we introduce a new metric to quantify the strategyproofness of a mechanism, based on comparing the payoff distribution, given truthful reports, against that of a strategyproof "reference" mechanism that solves a problem relaxation. Focusing on combinatorial exchanges, we demonstrate that the metric is informative about the eventual equilibrium, where simple regret-based metrics are not, and can be used for online selection of an effective mechanism.

#index 1417093
#* Interpretation and generalization of score matching
#@ Siwei Lyu
#t 2009
#c 12
#% 318790
#% 363808
#% 450888
#% 829017
#% 878207
#% 927528
#% 940582
#% 1131589
#% 1862006
#! Score matching is a recently developed parameter learning method that is particularly effective to complicated high dimensional density models with intractable partition functions. In this paper, we study two issues that have not been completely resolved for score matching. First, we provide a formal link between maximum likelihood and score matching. Our analysis shows that score matching finds model parameters that are more robust with noisy training data. Second, we develop a generalization of score matching. Based on this generalization, we further demonstrate an extension of score matching to models of discrete data.

#index 1417094
#* Multiple source adaptation and the Rényi divergence
#@ Yishay Mansour;Mehryar Mohri;Afshin Rostamizadeh
#t 2009
#c 12
#% 252472
#% 399588
#% 816180
#% 1117687
#% 1272110
#! This paper presents a novel theoretical study of the general problem of multiple source adaptation using the notion of Rényi divergence. Our results build on our previous work [12], but significantly broaden the scope of that work in several directions. We extend previous multiple source loss guarantees based on distribution weighted combinations to arbitrary target distributions P, not necessarily mixtures of the source distributions, analyze both known and unknown target distribution cases, and prove a lower bound. We further extend our bounds to deal with the case where the learner receives an approximate distribution for each source instead of the exact one, and show that similar loss guarantees can be achieved depending on the divergence between the approximate and true distributions. We also analyze the case where the labeling functions of the source domains are somewhat different. Finally, we report the results of experiments with both an artificial data set and a sentiment analysis task, showing the performance benefits of the distribution weighted combinations and the quality of our bounds based on the Rényi divergence.

#index 1417095
#* Domain knowledge uncertainty and probabilistic parameter constraints
#@ Yi Mao;Guy Lebanon
#t 2009
#c 12
#% 757953
#% 961183
#% 1073905
#! Incorporating domain knowledge into the modeling process is an effective way to improve learning accuracy. However, as it is provided by humans, domain knowledge can only be specified with some degree of uncertainty. We propose to explicitly model such uncertainty through probabilistic constraints over the parameter space. In contrast to hard parameter constraints, our approach is effective also when the domain knowledge is inaccurate and generally results in superior modeling accuracy. We focus on generative and conditional modeling where the parameters are assigned a Dirichlet or Gaussian prior and demonstrate the framework with experiments on both synthetic and real-world data.

#index 1417096
#* Group sparse priors for covariance estimation
#@ Benjamin M. Marlin;Mark Schmidt;Kevin P. Murphy
#t 2009
#c 12
#% 1074353
#% 1211778
#! Recently it has become popular to learn sparse Gaussian graphical models (GGMs) by imposing l1 or group l1, 2 penalties on the elements of the precision matrix. This penalized likelihood approach results in a tractable convex optimization problem. In this paper, we reinterpret these results as performing MAP estimation under a novel prior which we call the group l1 and l1, 2 positive-definite matrix distributions. This enables us to build a hierarchical model in which the l1 regularization terms vary depending on which group the entries are assigned to, which in turn allows us to learn block structured sparse GGMs with unknown group assignments. Exact inference in this hierarchical model is intractable, due to the need to compute the normalization constant of these matrix distributions. However, we derive upper bounds on the partition functions, which lets us use fast variational inference (optimizing a lower bound on the joint posterior). We show that on two real world data sets (motion capture and financial data), our method which infers the block structure outperforms a method that uses a fixed block structure, which in turn outperforms baseline methods that ignore block structure.

#index 1417097
#* Convergent message passing algorithms: a unifying view
#@ Talya Meltzer;Amir Globerson;Yair Weiss
#t 2009
#c 12
#% 450290
#% 776581
#% 889176
#% 975169
#% 1272112
#% 1650318
#% 1815596
#% 1815597
#% 1815753
#! Message-passing algorithms have emerged as powerful techniques for approximate inference in graphical models. When these algorithms converge, they can be shown to find local (or sometimes even global) optima of variational formulations to the inference problem. But many of the most popular algorithms are not guaranteed to converge. This has lead to recent interest in convergent message-passing algorithms. In this paper, we present a unified view of convergent message-passing algorithms. We present a simple derivation of an abstract algorithm, tree-consistency bound optimization (TCBO) that is provably convergent in both its sum and max product forms. We then show that many of the existing convergent algorithms are instances of our TCBO algorithm, and obtain novel convergent algorithms "for free" by exchanging maximizations and summations in existing algorithms. In particular, we show that Wainwright's non-convergent sum-product algorithm for tree based variational bounds, is actually convergent with the right update order for the case where trees are monotonic chains.

#index 1417098
#* Convexifying the Bethe free energy
#@ Ofer Meshi;Ariel Jaimovich;Amir Globerson;Nir Friedman
#t 2009
#c 12
#% 230651
#% 277467
#% 450290
#% 528300
#% 788106
#% 854049
#% 961199
#% 1166535
#% 1272112
#% 1650318
#% 1673015
#% 1815596
#% 1815597
#! The introduction of loopy belief propagation (LBP) revitalized the application of graphical models in many domains. Many recent works present improvements on the basic LBP algorithm in an attempt to overcome convergence and local optima problems. Notable among these are convexified free energy approximations that lead to inference procedures with provable convergence and quality properties. However, empirically LBP still outperforms most of its convex variants in a variety of settings, as we also demonstrate here. Motivated by this fact we seek convexified free energies that directly approximate the Bethe free energy. We show that the proposed approximations compare favorably with state-of-the art convex free energy approximations.

#index 1417099
#* Virtual vector machine for Bayesian online classification
#@ Thomas P. Minka;Rongjing Xiang;Yuan (Alan) Qi
#t 2009
#c 12
#% 274216
#% 450245
#% 528330
#% 768635
#% 801566
#% 961152
#% 1773349
#! In a typical online learning scenario, a learner is required to process a large data stream using a small memory buffer. Such a requirement is usually in conflict with a learner's primary pursuit of prediction accuracy. To address this dilemma, we introduce a novel Bayesian online classification algorithm, called the Virtual Vector Machine. The virtual vector machine allows you to smoothly trade-off prediction accuracy with memory size. The virtual vector machine summarizes the information contained in the preceding data stream by a Gaussian distribution over the classification weights plus a constant number of virtual data points. The virtual data points are designed to add extra non-Gaussian information about the classification weights. To maintain the constant number of virtual points, the virtual vector machine adds the current real data point into the virtual point set, merges two most similar virtual points into a new virtual point or deletes a virtual point that is far from the decision boundary. The information lost in this process is absorbed into the Gaussian distribution. The extra information provided by the virtual points leads to improved predictive accuracy over previous online classification algorithms.

#index 1417100
#* Using the Gene Ontology hierarchy when predicting gene function
#@ Sara Mostafavi;Quaid Morris
#t 2009
#c 12
#% 832903
#% 889273
#% 905823
#% 906025
#! The problem of multilabel classification when the labels are related through a hierarchical categorization scheme occurs in many application domains such as computational biology. For example, this problem arises naturally when trying to automatically assign gene function using a controlled vocabularies like Gene Ontology. However, most existing approaches for predicting gene functions solve independent classification problems to predict genes that are involved in a given function category, independently of the rest. Here, we propose two simple methods for incorporating information about the hierarchical nature of the categorization scheme. In the first method, we use information about a gene's previous annotation to set an initial prior on its label. In a second approach, we extend a graph-based semi-supervised learning algorithm for predicting gene function in a hierarchy. We show that we can efficiently solve this problem by solving a linear system of equations. We compare these approaches with a previous label reconciliation-based approach. Results show that using the hierarchy information directly, compared to using reconciliation methods, improves gene function prediction.

#index 1417101
#* Logical inference algorithms and matrix representations for probabilistic conditional independence
#@ Mathias Niepert
#t 2009
#c 12
#% 44876
#% 644201
#% 788049
#% 793338
#% 809266
#% 977238
#% 1041134
#% 1650644
#! Logical inference algorithms for conditional independence (CI) statements have important applications from testing consistency during knowledge elicitation to constraint-based structure learning of graphical models. We prove that the implication problem for CI statements is decidable, given that the size of the domains of the random variables is known and fixed. We will present an approximate logical inference algorithm which combines a falsification and a novel validation algorithm. The validation algorithm represents each set of CI statements as a sparse 0--1 matrix A and validates instances of the implication problem by solving specific linear programs with constraint matrix A. We will show experimentally that the algorithm is both effective and efficient in validating and falsifying instances of the probabilistic CI implication problem.

#index 1417102
#* Exact structure discovery in Bayesian networks with less space
#@ Pekka Parviainen;Mikko Koivisto
#t 2009
#c 12
#% 197387
#% 763715
#% 985940
#% 1089371
#! The fastest known exact algorithms for score-based structure discovery in Bayesian networks on n nodes run in time and space 2nnO(1). The usage of these algorithms is limited to networks on at most around 25 nodes mainly due to the space requirement. Here, we study space--time tradeoffs for finding an optimal network structure. When little space is available, we apply the Gurevich--Shelah recurrence---originally proposed for the Hamiltonian path problem---and obtain time 22n-snO(1) in space 2snO(1) for any s = n/2, n/4, n/8, ...; we assume the indegree of each node is bounded by a constant. For the more practical setting with moderate amounts of space, we present a novel scheme. It yields running time 2n(3/2)pnO(1) in space 2n(3/4)pnO(1) for any p = 0, 1, ..., n/2; these bounds hold as long as the indegrees are at most 0.238n. Furthermore, the latter scheme allows easy and efficient parallelization beyond previous algorithms. We also explore empirically the potential of the presented techniques.

#index 1417103
#* Regret-based reward elicitation for Markov decision processes
#@ Kevin Regan;Craig Boutilier
#t 2009
#c 12
#% 22388
#% 384911
#% 466418
#% 529348
#% 578692
#% 810882
#% 983832
#% 1250151
#% 1270052
#% 1272002
#% 1291488
#% 1650580
#% 1672988
#! The specification of a Markov decision process (MDP) can be difficult. Reward function specification is especially problematic; in practice, it is often cognitively complex and time-consuming for users to precisely specify rewards. This work casts the problem of specifying rewards as one of preference elicitation and aims to minimize the degree of precision with which a reward function must be specified while still allowing optimal or near-optimal policies to be produced. We first discuss how robust policies can be computed for MDPs given only partial reward information using the minimax regret criterion. We then demonstrate how regret can be reduced by efficiently eliciting reward information using bound queries, using regret-reduction as a means for choosing suitable queries. Empirical results demonstrate that regret-based reward elicitation offers an effective way to produce near-optimal policies without resorting to the precise specification of the entire reward function.

#index 1417104
#* BPR: Bayesian personalized ranking from implicit feedback
#@ Steffen Rendle;Christoph Freudenthaler;Zeno Gantner;Lars Schmidt-Thieme
#t 2009
#c 12
#% 734592
#% 734594
#% 770788
#% 840846
#% 840924
#% 844329
#% 1077627
#% 1083671
#% 1127481
#% 1176909
#% 1176959
#! Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive k-nearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion.

#index 1417105
#* A factorization criterion for acyclic directed mixed graphs
#@ Thomas S. Richardson
#t 2009
#c 12
#% 44876
#% 417568
#% 1134183
#% 1385988
#! Acyclic directed mixed graphs, also known as semi-Markov models represent the conditional independence structure induced on an observed margin by a DAG model with latent variables. In this paper we present a factorization criterion for these models that is equivalent to the global Markov property given by (the natural extension of) dseparation.

#index 1417106
#* Characterizing predictable classes of processes
#@ Daniil Ryabko
#t 2009
#c 12
#% 787659
#% 871302
#% 1091634
#% 1110375
#! The problem is sequence prediction in the following setting. A sequence x1, ..., xn, ... of discrete-valued observations is generated according to some unknown probabilistic law (measure) μ. After observing each outcome, it is required to give the conditional probabilities of the next observation. The measure μ belongs to an arbitrary class C of stochastic processes. We are interested in predictors ρ whose conditional probabilities converge to the "true" μ-conditional probabilities if any μ ε C is chosen to generate the data. We show that if such a predictor exists, then a predictor can also be obtained as a convex combination of a countably many elements of C. In other words, it can be obtained as a Bayesian predictor whose prior is concentrated on a countable set. This result is established for two very different measures of performance of prediction, one of which is very strong, namely, total variation, and the other is very weak, namely, prediction in expected average Kullback-Leibler divergence.

#index 1417107
#* Quantum annealing for variational Bayes inference
#@ Issei Sato;Kenichi Kurihara;Shu Tanaka;Hiroshi Nakagawa;Seiji Miyashita
#t 2009
#c 12
#% 722904
#% 1650268
#! This paper presents studies on a deterministic annealing algorithm based on quantum annealing for variational Bayes (QAVB) inference, which can be seen as an extension of the simulated annealing for variational Bayes (SAVB) inference. QAVB is as easy as SAVB to implement. Experiments revealed QAVB finds a better local optimum than SAVB in terms of the variational free energy in latent Dirichlet allocation (LDA).

#index 1417108
#* Modeling discrete interventional data using directed cyclic graphical models
#@ Mark Schmidt;Kevin Murphy
#t 2009
#c 12
#% 272520
#% 297171
#% 722754
#% 757953
#% 1417383
#% 1650683
#% 1650803
#% 1650807
#% 1650808
#% 1673008
#! We outline a representation for discrete multivariate distributions in terms of interventional potential functions that are globally normalized. This representation can be used to model the effects of interventions, and the independence properties encoded in this model can be represented as a directed graph that allows cycles. In addition to discussing inference and sampling with this representation, we give an exponential family parametrization that allows parameter estimation to be stated as a convex optimization problem; we also give a convex relaxation of the task of simultaneous parameter and structure learning using group l1-regularization. The model is evaluated on simulated data and intracellular flow cytometry data.

#index 1417109
#* Bisimulation-based approximate lifted inference
#@ Prithviraj Sen;Amol Deshpande;Lise Getoor
#t 2009
#c 12
#% 249143
#% 256685
#% 341672
#% 408396
#% 420495
#% 448887
#% 602816
#% 1000502
#% 1127415
#% 1250334
#% 1270256
#% 1270261
#% 1279353
#% 1289560
#% 1650326
#! There has been a great deal of recent interest in methods for performing lifted inference; however, most of this work assumes that the first-order model is given as input to the system. Here, we describe lifted inference algorithms that determine symmetries and automatically lift the probabilistic model to speedup inference. In particular, we describe approximate lifted inference techniques that allow the user to trade off inference accuracy for computational efficiency by using a handful of tunable parameters, while keeping the error bounded. Our algorithms are closely related to the graph-theoretic concept of bisimulation. We report experiments on both synthetic and real data to show that in the presence of symmetries, run-times for inference can be improved significantly, with approximate lifted inference providing orders of magnitude speedup over ground inference.

#index 1417110
#* A direct method for estimating a causal ordering in a linear non-Gaussian acyclic model
#@ Shohei Shimizu;Aapo Hyvärinen;Yoshinobu Kawahara;Takashi Washio
#t 2009
#c 12
#% 258937
#% 297171
#% 430893
#% 722887
#% 961205
#% 1073925
#% 1673681
#% 1860500
#! Structural equation models and Bayesian networks have been widely used to analyze causal relations between continuous variables. In such frameworks, linear acyclic models are typically used to model the data-generating process of variables. Recently, it was shown that use of non-Gaussianity identifies a causal ordering of variables in a linear acyclic model without using any prior knowledge on the network structure, which is not the case with conventional methods. However, existing estimation methods are based on iterative search algorithms and may not converge to a correct solution in a finite number of steps. In this paper, we propose a new direct method to estimate a causal ordering based on non-Gaussianity. In contrast to the previous methods, our algorithm requires no algorithmic parameters and is guaranteed to converge to the right solution within a small fixed number of steps if the data strictly follows the model.

#index 1417111
#* Effects of treatment on the treated: identification and generalization
#@ Ilya Shpitser;Judea Pearl
#t 2009
#c 12
#% 44876
#% 297171
#% 578740
#% 716378
#% 1250349
#! Many applications of causal analysis call for assessing, retrospectively, the effect of with-holding an action that has in fact been implemented. This counterfactual quantity, sometimes called "effect of treatment on the treated," (ETT) have been used to to evaluate educational programs, critic public policies, and justify individual decision making. In this paper we explore the conditions under which ETT can be estimated from (i.e., identified in) experimental and/or observational studies. We show that, when the action invokes a singleton variable, the conditions for ETT identification have simple characterizations in terms of causal diagrams. We further give a graphical characterization of the conditions under which the effects of multiple treatments on the treated can be identified, as well as ways in which the ETT estimand can be constructed from both interventional and observational distributions.

#index 1417112
#* Products of Hidden Markov Models: it takes N1 to tango
#@ Graham W. Taylor;Geoffrey E. Hinton
#t 2009
#c 12
#% 246836
#% 424845
#% 450888
#% 828270
#% 1073981
#% 1074005
#! Products of Hidden Markov Models (PoHMMs) are an interesting class of generative models which have received little attention since their introduction. This may be in part due to their more computationally expensive gradient-based learning algorithm, and the intractability of computing the log likelihood of sequences under the model. In this paper, we demonstrate how the partition function can be estimated reliably via Annealed Importance Sampling. We perform experiments using contrastive divergence learning on rainfall data and data captured from pairs of people dancing. Our results suggest that advances in learning and evaluation for undirected graphical models and recent increases in available computing power make PoHMMs worth considering for complex time-series modeling tasks.

#index 1417113
#* Measuring inconsistency in probabilistic knowledge bases
#@ Matthias Thimm
#t 2009
#c 12
#% 44876
#% 209373
#% 417766
#% 757953
#% 878207
#% 992249
#% 1099877
#% 1111181
#% 1289428
#% 1400952
#% 1650809
#% 1705012
#! This paper develops an inconsistency measure on conditional probabilistic knowledge bases. The measure is based on fundamental principles for inconsistency measures and thus provides a solid theoretical framework for the treatment of inconsistencies in probabilistic expert systems. We illustrate its usefulness and immediate application on several examples and present some formal results. Building on this measure we use the Shapley value---a well-known solution for coalition games---to define a sophisticated indicator that is not only able to measure inconsistencies but to reveal the causes of inconsistencies in the knowledge base. Altogether these tools guide the knowledge engineer in his aim to restore consistency and therefore enable him to build a consistent and usable knowledge base that can be employed in probabilistic expert systems.

#index 1417114
#* Computing posterior probabilities of structural features in Bayesian networks
#@ Jin Tian;Ru He
#t 2009
#c 12
#% 197387
#% 297171
#% 763715
#! We study the problem of learning Bayesian network structures from data. Koivisto and Sood (2004) and Koivisto (2006) presented algorithms that can compute the exact marginal posterior probability of a subnetwork, e.g., a single edge, in O(n2n) time and the posterior probabilities for all n(n-1) potential edges in O(n2n) total time, assuming that the number of parents per node or the indegree is bounded by a constant. One main drawback of their algorithms is the requirement of a special structure prior that is non uniform and does not respect Markov equivalence. In this paper, we develop an algorithm that can compute the exact posterior probability of a subnetwork in O(3n) time and the posterior probabilities for all n(n - 1) potential edges in O(n3n) total time. Our algorithm also assumes a bounded indegree but allows general structure priors. We demonstrate the applicability of the algorithm on several data sets with up to 20 variables.

#index 1417115
#* Ordinal Boltzmann Machines for collaborative filtering
#@ Tran The Truyen;Dinh Q. Phung;Svetha Venkatesh
#t 2009
#c 12
#% 266281
#% 330687
#% 450888
#% 465928
#% 722754
#% 734592
#% 770816
#% 983903
#% 1083671
#% 1650569
#! Collaborative filtering is an effective recommendation technique wherein the preference of an individual can potentially be predicted based on preferences of other members. Early algorithms often relied on the strong locality in the preference data, that is, it is enough to predict preference of a user on a particular item based on a small subset of other users with similar tastes or of other items with similar properties. More recently, dimensionality reduction techniques have proved to be equally competitive, and these are based on the co-occurrence patterns rather than locality. This paper explores and extends a probabilistic model known as Boltzmann Machine for collaborative filtering tasks. It seamlessly integrates both the similarity and co-occurrence in a principled manner. In particular, we study parameterisation options to deal with the ordinal nature of the preferences, and propose a joint modelling of both the user-based and item-based processes. Experiments on moderate and large-scale movie recommendation show that our framework rivals existing well-known methods.

#index 1417116
#* Probabilistic structured predictors
#@ Shankar Vembu;Thomas Gärtner;Mario Boley
#t 2009
#c 12
#% 212147
#% 217824
#% 249167
#% 723928
#% 765548
#% 840862
#% 959392
#% 961135
#% 961192
#% 983847
#% 983905
#% 1000325
#% 1029093
#% 1211722
#! We consider MAP estimators for structured prediction with exponential family models. In particular, we concentrate on the case that efficient algorithms for uniform sampling from the output space exist. We show that under this assumption (i) exact computation of the partition function remains a hard problem, and (ii) the partition function and the gradient of the log partition function can be approximated efficiently. Our main result is an approximation scheme for the partition function based on Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling assumption holds in several application settings that are of importance in machine learning.

#index 1417117
#* Which spatial partition trees are adaptive to intrinsic dimension?
#@ Nakul Verma;Samory Kpotufe;Sanjoy Dasgupta
#t 2009
#c 12
#% 249334
#% 788670
#% 983695
#% 1041764
#% 1061636
#% 1168985
#% 1815968
#! Recent theory work has found that a special type of spatial partition tree -- called a random projection tree -- is adaptive to the intrinsic dimension of the data from which it is built. Here we examine this same question, with a combination of theory and experiments, for a broader class of trees that includes k-d trees, dyadic trees, and PCA trees. Our motivation is to get a feel for (i) the kind of intrinsic low dimensional structure that can be empirically verified, (ii) the extent to which a spatial partition can exploit such structure, and (iii) the implications for standard statistical tasks such as regression, vector quantization, and nearest neighbor search.

#index 1417118
#* Temporal-difference networks for dynamical systems with continuous observations and actions
#@ Christopher M. Vigorito
#t 2009
#c 12
#% 384911
#% 788097
#% 840946
#% 983896
#% 1073951
#% 1084055
#% 1093835
#% 1149535
#% 1289484
#! Temporal-difference (TD) networks are a class of predictive state representations that use well-established TD methods to learn models of partially observable dynamical systems. Previous research with TD networks has dealt only with dynamical systems with finite sets of observations and actions. We present an algorithm for learning TD network representations of dynamical systems with continuous observations and actions. Our results show that the algorithm is capable of learning accurate and robust models of several noisy continuous dynamical systems. The algorithm presented here is the first fully incremental method for learning a predictive representation of a continuous dynamical system.

#index 1417119
#* Simulation-based game theoretic analysis of keyword auctions with low-dimensional bidding strategies
#@ Yevgeniy Vorobeychik
#t 2009
#c 12
#% 576218
#% 868468
#% 963333
#% 1083993
#! We perform a simulation-based analysis of keyword auctions modeled as one-shot games of incomplete information to study a series of mechanism design questions. Our first question addresses the degree to which incentive compatibility fails in generalized second-price (GSP) auctions. Our results suggest that sincere bidding in GSP auctions is a strikingly poor strategy and a poor predictor of equilibrium outcomes. We next show that the rank-by-revenue mechanism is welfare optimal, corroborating past results. Finally, we analyze profit as a function of auction mechanism under a series of alternative settings. Our conclusions coincide with those of Lahaie and Pennock [2007] when values and quality scores are strongly positively correlated: in such a case, rank-by-bid rules are clearly superior. We diverge, however, in showing that auctions that put little weight on quality scores almost universally dominate the pure rank-by-revenue scheme.

#index 1417120
#* Exploring compact reinforcement-learning representations with linear regression
#@ Thomas J. Walsh;István Szita;Carlos Diuk;Michael L. Littman
#t 2009
#c 12
#% 240774
#% 384911
#% 425076
#% 495933
#% 562935
#% 722895
#% 1073902
#% 1073943
#% 1074003
#% 1211721
#% 1269521
#% 1269772
#% 1272089
#% 1272161
#% 1272468
#% 1450170
#! This paper presents a new algorithm for online linear regression whose efficiency guarantees satisfy the requirements of the KWIK (Knows What It Knows) framework. The algorithm improves on the complexity bounds of the current state-of-the-art procedure in this setting. We explore several applications of this algorithm for learning compact reinforcement-learning representations. We show that KWIK linear regression can be used to learn the reward function of a factored MDP and the probabilities of action outcomes in Stochastic STRIPS and Object Oriented MDPs, none of which have been proven to be efficiently learnable in the RL setting before. We also combine KWIK linear regression with other KWIK learners to learn larger portions of these models, including experiments on learning factored MDP transition and reward functions together.

#index 1417121
#* Herding dynamic weights for partially observed random field models
#@ Max Welling
#t 2009
#c 12
#% 281756
#% 443994
#% 450888
#% 788083
#% 829017
#% 1074005
#% 1211819
#% 1211830
#! Learning the parameters of a (potentially partially observable) random field model is intractable in general. Instead of focussing on a single optimal parameter value we propose to treat parameters as dynamical quantities. We introduce an algorithm to generate complex dynamics for parameters and (both visible and hidden) state vectors. We show that under certain conditions averages computed over trajectories of the proposed dynamical system converge to averages computed over the data. Our "herding dynamics" does not require expensive operations such as exponentiation and is fully deterministic.

#index 1417122
#* The Infinite Latent Events Model
#@ David Wingate;Noah D. Goodman;Daniel M. Roy;Joshua B. Tenenbaum
#t 2009
#c 12
#% 246836
#% 541077
#% 627805
#% 739673
#% 1058707
#% 1272002
#% 1650580
#! We present the Infinite Latent Events Model, a nonparametric hierarchical Bayesian distribution over infinite dimensional Dynamic Bayesian Networks with binary state representations and noisy-OR-like transitions. The distribution can be used to learn structure in discrete timeseries data by simultaneously inferring a set of latent events, which events fired at each timestep, and how those events are causally linked. We illustrate the model on a sound factorization task, a network topology identification task, and a video game task.

#index 1417123
#* A Bayesian framework for community detection integrating content and link
#@ Tianbao Yang;Rong Jin;Yun Chi;Shenghuo Zhu
#t 2009
#c 12
#% 280819
#% 313959
#% 420495
#% 466574
#% 987253
#% 1083684
#! This paper addresses the problem of community detection in networked data that combines link and content analysis. Most existing work combines link and content information by a generative model. There are two major shortcomings with the existing approaches. First, they assume that the probability of creating a link between two nodes is determined only by the community memberships of the nodes; however other factors(e.g. popularity) could also affect the link pattern. Second, they use generative models to model the content of individual nodes, whereas these generative models are vulnerable to the content attributes that are irrelevant to communities. We propose a Bayesian framework for combining link and content information for community detection that explicitly addresses these shortcomings. A new link model is presented that introduces a random variable to capture the node popularity when deciding the link between two nodes; a discriminative model is used to determine the community membership of a node by its content. An approximate inference algorithm is presented for efficient Bayesian inference. Our empirical study shows that the proposed framework outperforms several state-of-the-art approaches in combining link and content information for community detection.

#index 1417124
#* The entire quantile path of a risk-agnostic SVM classifier
#@ Jin Yu;S. V. N. Vishwanathan;Jian Zhang
#t 2009
#c 12
#% 190265
#% 420142
#% 425036
#% 466229
#% 729437
#% 793245
#% 881477
#% 961178
#% 1073923
#! A quantile binary classifier uses the rule: Classify x as + 1 if P(Y = 1|X = x) ≥ τ, and as -1 otherwise, for a fixed quantile parameter τ ∈ [0, 1]. It has been shown that Support Vector Machines (SVMs) in the limit are quantile classifiers with τ = 1/2. In this paper, we show that by using asymmetric cost of misclassification SVMs can be appropriately extended to recover, in the limit, the quantile binary classifier for any τ. We then present a principled algorithm to solve the extended SVM classifier for all values of τ simultaneously. This has two implications: First, one can recover the entire conditional distribution P(Y = 1|X = x) = τ for τ ∈ [

#index 1417125
#* Most Relevant Explanation: properties, algorithms, and evaluations
#@ Changhe Yuan;Xiaolu Liu;Tsai-Ching Lu;Heejin Lim
#t 2009
#c 12
#% 527524
#% 1270265
#% 1273478
#% 1650703
#% 1705556
#! Most Relevant Explanation (MRE) is a method for finding multivariate explanations for given evidence in Bayesian networks [12]. This paper studies the theoretical properties of MRE and develops an algorithm for finding multiple top MRE solutions. Our study shows that MRE relies on an implicit soft relevance measure in automatically identifying the most relevant target variables and pruning less relevant variables from an explanation. The soft measure also enables MRE to capture the intuitive phenomenon of explaining away encoded in Bayesian networks. Furthermore, our study shows that the solution space of MRE has a special lattice structure which yields interesting dominance relations among the solutions. A K-MRE algorithm based on these dominance relations is developed for generating a set of top solutions that are more representative. Our empirical results show that MRE methods are promising approaches for explanation in Bayesian networks.

#index 1417126
#* A uniqueness theorem for clustering
#@ Reza Bosagh Zadeh;Shai Ben-David
#t 2009
#c 12
#% 338343
#% 995140
#! Despite the widespread use of Clustering, there is distressingly little general theory of clustering available. Questions like "What distinguishes a clustering of data from other data partitioning?", "Are there any principles governing all clustering paradigms?", "How should a user choose an appropriate clustering algorithm for a particular task?", etc. are almost completely unanswered by the existing body of clustering literature. We consider an axiomatic approach to the theory of Clustering. We adopt the framework of Kleinberg, [Kle03]. By relaxing one of Kleinberg's clustering axioms, we sidestep his impossibility result and arrive at a consistent set of axioms. We suggest to extend these axioms, aiming to provide an axiomatic taxonomy of clustering paradigms. Such a taxonomy should provide users some guidance concerning the choice of the appropriate clustering paradigm for a given task. The main result of this paper is a set of abstract properties that characterize the Single-Linkage clustering function. This characterization result provides new insight into the properties of desired data groupings that make Single-Linkage the appropriate choice. We conclude by considering a taxonomy of clustering functions based on abstract properties that each satisfies.

#index 1417127
#* On the identifiability of the post-nonlinear causal model
#@ Kun Zhang;Aapo Hyvärinen
#t 2009
#c 12
#% 272526
#% 297171
#% 527830
#% 528005
#% 961205
#% 1044130
#! By taking into account the nonlinear effect of the cause, the inner noise effect, and the measurement distortion effect in the observed variables, the post-nonlinear (PNL) causal model has demonstrated its excellent performance in distinguishing the cause from effect. However, its identifiability has not been properly addressed, and how to apply it in the case of more than two variables is also a problem. In this paper, we conduct a systematic investigation on its identifiability in the two-variable case. We show that this model is identifiable in most cases; by enumerating all possible situations in which the model is not identifiable, we provide sufficient conditions for its identifiability. Simulations are given to support the theoretical results. Moreover, in the case of more than two variables, we show that the whole causal structure can be found by applying the PNL causal model to each structure in the Markov equivalent class and testing if the disturbance is independent of the direct causes for each variable. In this way the exhaustive search over all possible causal structures is avoided.

#index 1650265
#* Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence
#@ Kathryn B. Laskey;Henri Prade
#t 1999
#c 12

#index 1650266
#* On the semantics and automated deduction for PLFC, a logic of possibilistic uncertainty and fuzziness
#@ Teresa Alsinet;Lluís Godo;Sandra Sandri
#t 1999
#c 12
#% 61899
#% 167544
#% 318264
#! inconsistent Recently, a syntactical extension of first order Possibilistic logic (called PLFC) dealing with fuzzy constants and fuzzily restricted quantifiers has been proposed. In this paper we present steps towards both the formalization of PLFC itself and an automated deduction system for it by (i) providing a formal semantics; (ii) defining a sound resolution-style calculus by refutation; and (iii) describing a first-order proof procedure for PLFC clauses based on (ii) and on a novel notion of most general substitution of two literals in a resolution step.

#index 1650267
#* A temporal Bayesian network for diagnosis and prediction
#@ Gustavo Arroyo-Figueroa;Luis Enrique Suear
#t 1999
#c 12
#% 44876
#% 319244
#% 1477302
#% 1650655
#% 1650725
#% 1650757
#! Diagnosis and prediction in some domains, like medical and industrial diagnosis, require a representation that combines uncertainty management and temporal reasoning. Based on the fact that in many cases there are few state changes in the temporal range of interest, we propose a novel representation called Temporal Nodes Bayesian Network (TNBN). In a TNBN each node represents an event or state change of a variable, and an arc corresponds to a causal-temporal relation. The temporal intervals can differ in number and size for each temporal node, so this allows multiple granularity. Our approach is contrasted with a dynamic Bayesian network for a simple medical example. An empirical evaluation is presented for a more complex problem, a subsystem of a fossil power plant, in which this approach is used for fault diagnosis and event prediction with good results.

#index 1650268
#* Inferring parameters and structure of latent variable models by variational bayes
#@ Hagai Attias
#t 1999
#c 12
#% 106318
#% 129987
#% 132676
#% 132678
#% 190861
#% 197387
#% 232117
#% 246834
#% 246836
#% 266876
#% 269195
#% 271760
#% 272525
#% 281743
#% 1272279
#% 1650579
#% 1762022
#! Current methods for learning graphical models with latent variables and a fixed structure estimate optimal values for the model parameters. Whereas this approach usually produces overfitting and suboptimal generalization performance, carrying out the Bayesian program of computing the full posterior distributions over the parameters remains a difficult problem. Moreover, learning the structure of models with latent variables, for which the Bayesian approach is crucial, is yet a harder problem. In this paper I present the Variational Bayes framework, which provides a solution to these problems. This approach approximates full posterior distributions over model parameters and structures, as well as latent variables, in an analytical manner without resorting to sampling methods. Unlike in the Laplace approximation, these posteriors are generally non-Gaussian and no Hessian needs to be computed. The resulting algorithm generalizes the standard Expectation Maximization algorithm, and its convergence is guaranteed. I demonstrate that this algorithm can be applied to a large class of models in several domains, including unsupervised clustering and blind source separation.

#index 1650269
#* Relative loss bounds for on-line density estimation with the exponential family of distributions
#@ Katy S. Azoury;M. K. Warmuth
#t 1999
#c 12
#% 81507
#% 165663
#% 197370
#% 214313
#% 227736
#% 232319
#% 240785
#% 251999
#% 272386
#% 451055
#% 1808887
#% 1809407
#% 1809458
#% 1860015
#! We consider on-line density estimation with a parameterized density from the exponential family. The on-line algorithm receives one example at a time and maintains a parameter that is essentially an average of the past examples. After receiving an example the algorithm incurs a loss which is the negative log-likelihood of the example w.r.t. the past parameter of the algorithm. An off-line algorithm can choose the best parameter based on all the examples. We prove bounds on the additional total loss of the on-line algorithm over the total loss of the off-line algorithm. These relative loss bounds hold for an arbitrary sequence of examples. The goal is to design algorithms with the best possible relative loss bounds. We use a certain divergence to derive and analyze the algorithms. This divergence is a relative entropy between two exponential distributions.

#index 1650270
#* An application of uncertain reasoning to requirements engineering
#@ Philip S. Barry;Kathryn Blackrnond Laskey
#t 1999
#c 12
#% 91003
#% 100745
#% 169469
#% 202220
#% 325050
#% 380725
#% 382946
#% 743877
#% 1650734
#! This paper examines the use of Bayesian Networks to tackle one of the tougher problems in requirements engineering, translating user requirements into system requirements. The approach taken is to model domain knowledge as Bayesian Network fragments that are glued together to form a complete view of the domain specific system requirements. User requirements are introduced as evidence and the propagation of belief is used to determine what are the appropriate system requirements as indicated by user requirements. This concept has been demonstrated in the development of a system specification and the results are presented here.

#index 1650271
#* Random algorithms for the loop cutset problem
#@ Ann Becker;Reuven Bar-Yehuda;Dan Geiger
#t 1999
#c 12
#% 6199
#% 34262
#% 44876
#% 68183
#% 80008
#% 212221
#% 212442
#% 282420
#% 408396
#% 497071
#% 527514
#% 527523
#% 527850
#% 1272945
#! We show how to find a minimum loop cutset in a Bayesian network with high probability. Finding such a loop cutset is the first step in Pearl's method of conditioning for inference. Our random algorithm for finding a loop cutset, called REPEATEDWGUESSI, out - puts a minimum loop cutset, after O(c.6kkn) steps, with probability at least 1 - (1 - 1/6k)c6k, where c 1 is a constant specified by the user, k is the size of a minimum weight loop cutset, and n is the number of vertices. We also show empirically that a variant of this algorithm, called WRA, often finds a loop cutset that is closer to the minimum loop cutset than the ones found by the best deterministic algorithms known.

#index 1650272
#* Possibilistic logic bases and possibilistic graphs
#@ Salem Benferhat;Didier Dubois;Laurent Garcia;Henri Prade
#t 1999
#c 12
#% 44876
#% 167544
#% 380725
#% 503818
#% 503845
#! Possibilistic logic bases and possibilistic graphs are two different frameworks of interest for representing knowledge. The former stratifies the pieces of knowledge (expressed by logical formulas) according to their level of certainty, while the latter exhibits relationships between variables. The two types of representations are semantically equivalent when they lead to the same possibility distribution (which rankorders the possible interpretations). A possibility distribution can be decomposed using a chain rule which may be based on two different kinds of conditioning which exist in possibility theory (one based on product in a numerical setting, one based on minimum operation in a qualitative setting). These two types of conditioning induce two kinds of possibilistic graphs. In both cases, a translation of these graphs into possibilistic bases is provided. The converse translation from a possibilistic knowledge base into a min-based graph is also described

#index 1650273
#* Artificial decision making under uncertainty in intelligent buildings
#@ Magnus Boman;Paul Davidsson;Håkan L. Younes
#t 1999
#c 12
#% 130135
#% 181578
#% 230414
#% 368152
#% 518935
#! Our hypothesis is that by equipping certain in a multi-agent system controlling an intelligent building with automated decision support, two important factors will be increased. The first is energy saving in the building. The second is customer value-how the people in the building experience the effects of the actions of the agents. We give evidence for the truth of this hypothesis through experimental findings related to tools for artificial decision making. A number of assumptions related to agent control, through monitoring and delegation of tasks to other kinds of agents, of rooms at a test site are relaxed. Each assumption controls at least one uncertainty that complicates considerably the procedures for selecting actions part of each such agent. We show that in realistic decision situations, room-controlling agents can make bounded rational decisions even under dynamic real-time constraints. This result can be, and has been, generalized to other domains with even harsher time constraints.

#index 1650274
#* Reasoning with conditional ceteris paribus preference statements
#@ Craig Boutilier;Ronen I. Brafman;Holger H. Hoos;David Poole
#t 1999
#c 12
#% 70370
#% 166352
#% 1477356
#% 1650573
#% 1650586
#% 1650628
#! In many domains it is desirable to assess the preferences of users in a qualitative rather than quantitative way. Such representations of qualitative preference orderings form an important component of automated decision tools. We propose a graphical representation of preferences that reflects conditional dependence and independence of preference statements under a ceteris paribus (ali else being equal) interpretation. such a representation is often compact and arguably natural. We describe several search algorithms for dominance testing based on this representation; these algorithms are quite effective, especially in specific network topologies, such as chain- and treestructured networks, as well as polytrees.

#index 1650275
#* Continuous value function approximation for sequential bidding policies
#@ Craig Boutilier;Moisés Goldszmidt;Bikash Sabata
#t 1999
#c 12
#% 16363
#% 92301
#% 203554
#% 267752
#% 363744
#% 1273805
#% 1478842
#! Market-based mechanisms such as auctions are being studied as an appropriate means for resource allocation in distributed and multiagent decision problems. When agents value resources in combination rather than in isolation. they must often deliberate about appropriate bidding strategies for a sequence of auctions offering resources of interest. We briefly describe a discrete dynamic programming model for constructing appropriate bidding policies for resources exhibiting both complementarities substitutability. We then introduce a continuous approximation of this model, assuming that money (or the numeraire good) is infinitely divisible. Though this has the potential to reduce the computational cost of computing policies, value functions in the transformed problem do not have a convenient closed form representation. We develop grid-based approximations for such value functions, representing value functions using piecewise linear approximations. We show that these methods can offer significant computational savings with relatively small cost in solution quality.

#index 1650276
#* Discovering the hidden structure of complex dynamic systems
#@ Xavier Boyen;Nir Friedman;Daphne Koller
#t 1999
#c 12
#% 101213
#% 185079
#% 197387
#% 277480
#% 283131
#% 304882
#% 465762
#% 567872
#% 669191
#% 1290139
#% 1650289
#% 1650568
#% 1650579
#% 1650580
#! Dynamic Bayesian networks provide a compact and natural representation for complex dynamic systems. However, in many cases, there is no expert available from whom a model can be elicited. Learning provides an alternative approach for constructing models of dynamic systems. In this paper, we address some of the crucial computational aspects of learning the structure of dynamic systems, particularly those where some relevant variables are partially observed or even entirely unknown. Our approach is based on the Structural Expectation Maximization (SEM) algorithm. The main computational cost of the SEM algorithm is the gathering of expected sufficient statistics. We propose a novel approximation scheme that allows these sufficient statistics to be computed efficiently. We also investigate the fundamental problem of discovering the existence of hidden variables without exhaustive and expensive search. Our approach is based on the observation that, in dynamic systems, ignoring a hidden variable typically results in a violation of the Markov property. Thus, our algorithm searches for such violations in the data, and introduces hidden variables to explain them. We provide empirical results showing that the algorithm is able to learn the dynamics of complex systems in a computationally tractable way.

#index 1650277
#* Comparing Bayesian network classifiers
#@ Jie Cheng;Russell Greiner
#t 1999
#c 12
#% 44876
#% 129987
#% 240222
#% 243728
#% 246832
#% 458168
#% 1477185
#% 1478493
#% 1650719
#! In this paper, we empirically evaluate algorithms for learning four types of Bayesian network (BN) classifiers - Naïve-Bayes, tree augmented Naïve-Bayes, BN augmented Naïve-Bayes and general BNs, where the latter two are learned using two variants of a conditional-independence (CI) based BN-learning algorithm. Experimental results show the obtained classifiers, learned using the CI based algorithms, are competitive with (or superior to) the best known classifiers, based on both Bayesian networks and other formalisms: and that the computational time for learning and using these classifiers is relatively small. Moreover, these results also suggest a way to learn yet more effective classifiers we demonstrate empirically that this new algorithm does work as expected. Collectively, these results argue that BN classifiers deserve more attention in machine learning and data mining communities.

#index 1650278
#* Fast learning from sparse data
#@ David Maxwell Chickering;David Heckerman
#t 1999
#c 12
#% 101213
#% 101217
#% 197387
#% 232117
#% 246834
#% 1272326
#% 1650705
#! We describe two techniques that significantly improve the running time of several standard machine-learning algorithms when data is sparse. The first technique is an algorithm that efficiently extracts one-way and two-way counts-either real or expected-from discrete data. Extracting such counts is a fundamental step in learning algorithms for constructing a variety of models including decision trees, decision graphs, Bayesian networks, and naive-Bayes clustering models. The second technique is an algorithm that efficiently performs the E-step of the EM algorithm (i.e., inference) when applied to a naive-Bayes clustering model. Using real-world data sets, we demonstrate a dramatic decrease in running time for algorithms that incorporate these techniques.

#index 1650279
#* Causal discovery from a mixture of experimental and observational data
#@ Gregory F. Cooper;Changwon Yoo
#t 1999
#c 12
#% 44876
#% 129987
#% 197387
#% 1650650
#% 1650659
#! This paper describes a Bayesian method for combining an arbitrary mixture of observational and experimental data in order to learn causal Bayesian networks. Observational data are passively observed. Experimental data, such as that produced by randomized controlled trials, result from the exoerimenter manioulatine one or more variables (tipically randomiy) and observing the states of other variables. The paper presents a Bayesian method for learning the causal structure and parameters of the underlying causal process that is generating the data, given that (1) the data contains a mixture of observational and experimental case records, and (2) the causal process is modeled as a causal Bayesian network. This learning method was applied using as input various mixtures of experimental and observational data that were generated from the ALARM causal Bayesian network. In these experiments, the absolute and relative quantities of experimental and observational data were varied systematically. For each of these training datasets, the learning method was applied to predict the causal structure and to estimate the causal parameters that exist among randomly selected pairs of nodes in ALARM that are not confounded. The paper reports how these structure predictions and parameter estimates compare with the true causal structures and parameters as given by the ALARM network.

#index 1650280
#* Loglinear models for first-order probabilistic reasoning
#@ James Cussens
#t 1999
#c 12
#% 33376
#% 144840
#% 226495
#% 228812
#% 271391
#% 568785
#% 741139
#% 1271905
#% 1273025
#% 1478844
#% 1650691
#% 1650727
#% 1650767
#! Recent work on loglinear models in probabilistic constraint logic programming is applied to first-order probabilistic reasoning. Probabilities are defined directly on the proofs of atomic formulae, and by marginalisation on the atomic formulae themselves. We use Stochastic Logic Programs (SLPs) composed of labelled and unlabelled definite clauses to define the proof probabilities. We have a conservative extension of first-order reasoning, so that, for example, there is a one-one mapping between logical and random variables. We show how, in this framework, Inductive Logic Programming (ILP) can be used to induce the features of a loglinear model from data. We also compare the presented framework with other approaches to first-order probabilistic reasoning.

#index 1650281
#* Learning polytrees
#@ Sanjoy Dasgupta
#t 1999
#c 12
#% 44876
#% 115608
#% 151222
#% 217822
#% 246832
#% 246833
#% 503343
#% 1477186
#! We consider the task of learning the maximum-likelihood polytree from data. Our first result is a performance guarantee establishing that the optimal branching (or Chow-Liu tree), which can be computed very easily, constitutes a good approximation to the best polytree. We then show that it is not possible to do very much better, since the learning problem is NP-hard even to approximately solve within some constant factor.

#index 1650282
#* A hybrid anytime algorithm for the construction of causal models from sparse data
#@ Denver Dash;Marek J. Druzdzel
#t 1999
#c 12
#% 129987
#% 197387
#% 420055
#% 527830
#% 1650638
#% 1650771
#! We present a hybrid constraint-based/ Bayesian algorithm for learning causal networks in the presence of sparse data. The algorithm searches the space of equivalence classes of models (essential graphs) using a heuristic based on conventional constraint-based techniques. Each essential graph is then converted into a directed acyclic graph and scored using a Bayesian scoring metric. Two variants of the algorithm are developed and tested using data from randomly generated networks of sizes from 15 to 45 nodes with data sizes ranging from 250 to 2000 records. Both variations are compared to, and found to consistently outperform two variations of greedy search with restarts.

#index 1650283
#* Model based Bayesian exploration
#@ Richard Dearden;Nir Friedman;David Andre
#t 1999
#c 12
#% 8202
#% 90041
#% 98073
#% 160859
#% 266287
#% 272648
#% 277480
#% 304894
#% 361100
#% 465918
#% 466075
#% 1272286
#% 1650666
#! Reinforcement learning systems are often concerned with balancing exploration of untested actions against exploitation of actions that are known to be good. The benefit of exploration can be estimated using the classical notion of Value of Information - the expected improvement in future decision quality arising from the information acquired by exploration. Estimating this quantity requires an assessment of the agent's uncertainty about its current value estimates for states. In this paper we investigate ways to represent and reason about this uncertainty in algorithms where the system attempts to learn a model of its environment. We explicitly represent uncertainty about the parameters of the model and build probability distributions over Q-values based on these. These distributions are used to compute a myopic approximation to the value of information for each action and hence to select the action that best balances exploration and exploitation

#index 1650284
#* Hybrid probabilistic programs: algorithms and complexity
#@ Michael I. Dekhtyar;Alex Dekhtyar;V. S. Subrahmanian
#t 1999
#c 12
#% 3034
#% 33376
#% 124785
#% 130843
#% 144840
#% 165651
#% 181038
#% 235023
#% 458522
#% 464363
#% 561913
#% 1273452
#% 1650605
#! Hybrid Probabilistic Programs (HPPs) are logic programs that allow the programmer to explicitly encode his knowledge of the dependencies between events being described in the program. In this paper, we classify HPPs into three classes called HPP1, HPP2 and HPPr, r 3. For these classes, we provide three types of results for HPPs. First, we develop algorithms to compute the set of all ground consequences of an HPP. Then we provide algorithms and complexity results for the problems of entailment ("Given an HPP P and a query Q as input, is Q a logical consequence of P?) and consistency ("Given an HPP P as input, is P consistent?"). Our results provide a fine characterization of when polynomial algorithms exist for the above problems, and when these problems become intractable.

#index 1650285
#* Assessing the value of a candidate: comparing belief function and possibility theories
#@ Didier Dubois;Michel Grabisch;Henri Prade;Philippe Smets
#t 1999
#c 12
#% 48720
#% 119166
#% 161238
#% 393800
#% 1290145
#% 1650578
#% 1784126
#! The problem of assessing the value of a candidate is viewed here as a multiple combination problem. On the one hand a candidate can be evaluated according to different criteria, and on the other hand several experts are supposed to assess the value of candidates according to each criterion. Criteria are not equally important, experts are not equally competent or reliable. Moreover levels of satisfaction of criteria, or levels of confidence are only assumed to take their values in linearly ordered scales, whose nature is often qualitative. The problem is discussed within two frameworks, the transferable belief model and the qualitative possibility theory. They respectively offer a quantitative and a qualitative setting for handling the problem, providing thus a way to compare the nature of the underlying assumptions.

#index 1650286
#* Evaluation of distributed intelligence on the smart card
#@ Kazuo J. Ezawa;Greg Napiorkowski;Mariusz Kossarski
#t 1999
#c 12
#% 446081
#% 536305
#% 536329
#% 536477
#% 1650646
#! We describe challenges in the risk management of smart card based electronic cash industry and describe a method to evaluate the effectiveness of distributed intelligence on the smart card. More specifically, we discuss the evaluation of distributed intelligence function called "on-chip risk management" of the smart card for the global electronic cash payment application using micro dynamic simulation. Handling of uncertainty related to future economic environment, various potential counterfeit attack scenarios, requires simulation of such environment to evaluate on-chip performance. Creation of realistic simulation of electronic cash economy, transaction environment, consumers, merchants, banks are challenge themselves. In addition, we shows examples of detection capability of off-chip, host based counterfeit detection systems based on the micro dynamic simulation model generated data set.

#index 1650287
#* Qualitative models for decision under uncertainty without the commensurability assumption
#@ Hélène Fargier;Patrice Perny
#t 1999
#c 12
#% 130021
#% 179919
#% 195539
#% 1290145
#% 1476312
#% 1478741
#% 1650578
#% 1650714
#% 1650798
#! This paper investigates a purely qualitative version of Savage's theory for decision making under uncertainty. Until now, most representation theorems for preference over acts rely on a numerical representation of utility and uncertainty where utility and uncertainty are commensurate. Disrupting the tradition, we relax this assumption and introduce a purely ordinal axiom requiring that the Decision Maker (DM) preference between two acts only depends on the relative position of their consequences for each state. Within this qualitative framework, we determine the only possible form of the decision rule and investigate some instances compatible with the transitivity of the strict preference.

#index 1650288
#* Data analysis with bayesian networks: a bootstrap approach
#@ Nir Friedman;Moises Goldszmidt;Abraham Wyner
#t 1999
#c 12
#% 44876
#% 197387
#% 277480
#% 443025
#% 443632
#% 465895
#% 1650638
#% 1650673
#! In recent years there has been significant progress in algorithms and methods for inducing Bayesian networks from data. However, in complex data analysis problems, we need to go beyond being satisfied with inducing networks with high scores. We need to provide confidence measures on features of these networks: Is the existence of an edge between two nodes warranted? Is the Markov blanket of a given node robust? Can we say something about the ordering of the variables? We should be able to address these questions, even when the amount of data is not enough to induce a high scoring network. In this paper we propose Efron's Bootstrap as a computationally efficient approach for answering these questions. In addition, we propose to use these confidence measures to induce better structures from the data, and to detect the presence of latent variables.

#index 1650289
#* Learning bayesian network structure from massive datasets: the «sparse candidate« algorithm
#@ Nir Friedman;Iftach Nachman;Dana Peér
#t 1999
#c 12
#% 70370
#% 115608
#% 129987
#% 197387
#% 219474
#% 277480
#% 380725
#% 465895
#% 1272326
#% 1273915
#% 1650276
#% 1650638
#% 1650646
#% 1650771
#! Learning Bayesian networks is often cast as an optimization problem, where the computational task is to find a structure that maximizes a statistically motivated score. By and large, existing learning tools address this optimization problem using standard heuristic search techniques. Since the search space is extremely large, such search procedures can spend most of the time examining candidates that are extremely unreasonable. This problem becomes critical when we deal with data sets that are large either in the number of instances, or the number of attributes. In this paper. we introduce an algorithm that achieves faster learning by restricting the search space. This iterative algorithm restricts the parents of each variable to belong to a small subset of candidates. We then search for a network that satisfies these constraints. The learned network is then used for selecting better candidates for the next iteration. We evaluate this algorithm both on synthetic and real-life data. Our results show that it is significantly faster than alternative search procedures without loss of quality in the learned structures

#index 1650290
#* Parameter priors for directed acyclic graphical models and the characterization of several probability distributions
#@ Dan Geiger;David Heckerman
#t 1999
#c 12
#% 44876
#% 61079
#% 129987
#% 183490
#% 197387
#% 527830
#% 1272363
#% 1650638
#% 1650658
#% 1650715
#! We show that the only parameter prior for complete Gaussian DAG models that satisfies global parameter independence, complete model equivalence, and some weak regularity assumptions, is the normal-Wishart distribution. Our analysis is based on the following new characterization of the Wishart distribution: let W be an n × n, n 3, positive-definite symmetric matrix of random variables and f(W) be a pdf of W. Then, f(W) is a Wishart distribution if and only if W11 - W12W22-1, is independent of {W12, W22) for every block partitioning W11, W12, W12, W22 of W. Similar characterizations of the normal and normal-Wishart distributions are provided as well. We also show how to construct a prior for every DAG model over X from the prior of a single regression model.

#index 1650291
#* Quantifier elimination for statistical problems
#@ Dan Geiger;Christopher Meek
#t 1999
#c 12
#% 44876
#% 46020
#% 73571
#% 93770
#% 112098
#% 144248
#% 195408
#% 505561
#% 527830
#% 1650582
#% 1650674
#! Recent improvements on Tarski's procedure for quantifier elimination in the first order theory of real numbers makes it feasible to solve small instances of the following problems completely automatically: 1. listing all equality and inequality constraints implied by a graphical model with hidden variables. 2. Comparing graphical models with hidden variables (i.e., model equivalence, inclusion, and overlap). 3. Answering questions about the identification of a model or portion of a model, and about bounds on quantities derived from a model. 4. Determining whether an independence assertion is implied from a given set of independence assertions. We discuss the foundations of quantifier elimination and demonstrate its application to these problems.

#index 1650292
#* On transformations between probability and spohnian disbelief functions
#@ Phan H. Giang;Prakash P. Shenoy
#t 1999
#c 12
#% 26518
#% 100251
#% 111942
#% 119147
#% 128627
#% 136554
#% 160255
#% 527506
#% 527528
#% 567872
#! In this paper, we analyze the relationship between probability and Spohn's theory for representation of uncertain beliefs. Using the intuitive idea that the more probable a proposition is, the more believable it is, we study transformations from probability to Spohnian disbelief and vice-versa. The transformations described in this paper are different from those described in the literature. In particular, the former satisfies the principles of ordinal congruence while the latter does not. Such transformations between probability and Spohn's calculi can contribute to (1) a clarification of the semantics of nonprobabilistic degree of uncertain belief, and (2) to a construction of a decision theory for such calculi. In practice, the transformations will allow a meaningful combination of more than one calculus in different stages of using an expert system such as knowledge acquisition, inference, and interpretation of results.

#index 1650293
#* A new model of plan recognition
#@ Robert P. Goldman;Christopher W. Geib;Christopher A. Miller
#t 1999
#c 12
#% 25471
#% 147677
#% 147680
#% 171477
#% 247892
#% 1477099
#! We present a new abductive, probabilistic theory of plan recognition. This model differs from previous theories in being centered around a model of plan execution: most previous methods have been based on plans as formal objects or on rules describing the recognition process. We show that our new model accounts for phenomena omitted from most previous plan recognition theories: notably the cumulative effect of a sequence of observations of partially-ordered, interleaved plans and the effect of context on plan adoption. The model also supports inferences about the evolution of plan execution in situations where another agent intervenes in plan execution. This facility provides support for using plan recognition to build systems that will intelligently assist a user.

#index 1650294
#* Multi-objects association in perception of dynamical situation
#@ Dominique Gruyer;Véronique Berge-Cherfaoui
#t 1999
#c 12
#% 503829
#% 1784071
#! In current perception systems applied to the rebuilding of the environment for intelligent vehicles, the part reserved to object association for the tracking is increasingly significant. This allows firstly to follow the objects temporal evolution and secondly to increase the reliability of environment perception. We propose in this communication the development of a multiobjects association algorithm with ambiguity removal entering into the design of such a dynamic perception system for intelligent vehicles. This algorithm uses the belief theory and data modelling with fuzzy mathematics in order to be able to handle inaccurate as well as uncertain information due to imperfect sensors. These theories also allow the fusion of numerical as well as symbolic data. We develop in this article the problem of matching between known and perceived objects. This makes it possible to update a dynamic environment map for a vehicle. The belief theory will enable us to quantify the belief in the association of each perceived object with each known object. Conflicts can appear in the case of object appearance or disappearance, or in the case of a confused situation or bad perception. These conflicts are removed or solved using an assignment algorithm, giving a solution called the «best» and so ensuring the tracking of some objects present in our environment.

#index 1650295
#* A hybrid approach to reasoning with partially elicited preference models
#@ Vu Ha;Peter Haddawy
#t 1999
#c 12
#% 8039
#% 179919
#% 195542
#% 234537
#% 257460
#% 499542
#% 1650573
#% 1650586
#% 1650721
#! Classical Decision Theory provides a normative framework for representing and reasoning about complex preferences. Straight forward application of this theory to automate decision making is difficult due to high elicitation cost. In response to this problem, researchers have recently developed a number of qualitative, logic-oriented approaches for representing and reasoning about preferences. While effectively addressing some expressiveness issues, these logics have not proven powerful enough for building practical automated decision making systems. In this paper we present a hybrid approach to preference elicitation and decision making that is grounded in classical multi-attribute utility theory, but can make effective use of the expressive power of qualitative approaches. Specifically, assuming a partially specified multilinear utility function, we show how comparative statements about classes of decision alternatives can be used to further constrain the utility function and thus identify supoptimal alternatives. This work demonstrates that quantitative and qualitative approaches can be synergistically integrated to provide effective and flexible decision support.

#index 1650296
#* Faithful approximations of belief functions
#@ David Harmanec
#t 1999
#c 12
#% 59547
#% 83937
#% 136365
#% 168315
#% 168542
#% 168564
#% 168565
#% 168568
#% 527686
#% 1650762
#! A conceptual foundation for approximation of belief functions is proposed and investigated. It is based on the requirements of consistency and closeness. An optimal approximation is studied. Unfortunately, the computation of the optimal approximation turns out to be intractable. Hence, various heuristic methods are proposed and experimantally evaluated both in terms of their accuracy and in terms of the speed of computation. These methods are compared to the earlier proposed approximations of belief functions.

#index 1650297
#* SPUDD: stochastic planning using decision diagrams
#@ Jesse Hoey;Robert St-Aubin;Alan Hu;Craig Boutilier
#t 1999
#c 12
#% 3873
#% 44876
#% 75936
#% 159243
#% 224762
#% 233849
#% 266384
#% 363744
#% 1290041
#% 1478746
#% 1650679
#% 1650699
#% 1650767
#% 1650779
#! Recently, structured methods for solving factored Markov decisions processes (MDPs) with large state spaces have been proposed recently to allow dynamic programming to be applied without the need for complete state enumeration. We propose and examine a new value iteration algorithm for MDPs that uses algebraic decision diagrams (ADDs) to represent value functions and policies, assuming an ADD input representation of the MDP. Dynamic programming is implemented via ADD manipulation. We demonstrate our method on a class of large MDPs (up to 63 million states) and show that significant gains can be had when compared to tree-structured representations (with up to a thirty-fold reduction in the number of nodes required to represent optimal value functions).

#index 1650298
#* Probabilistic latent semantic analysis
#@ Thomas Hofmann
#t 1999
#c 12
#% 78792
#% 124009
#% 277483
#% 280819
#% 304908
#% 406493
#% 748465
#! Probabilistic Latent Semantic Analysis is a novel statistical technique for the analysis of two-mode and co-occurrence data, which has applications in information retrieval and filtering, natural language processing, machine learning from text, and in related areas. Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed method is based on a mixture decomposition derived from a latent class model. This results in a more principled approach which has a solid foundation in statistics. In order to avoid overfitting, we propose a widely applicable generalization of maximum likelihood model fitting by tempered EM. Our approach yields substantial and consistent improvements over Latent Semantic Analysis in a number of experiments.

#index 1650299
#* Estimating the value of computation in flexible information refinement
#@ Michael C. Horsch;David Poole
#t 1999
#c 12
#% 34262
#% 98073
#% 300843
#% 1272302
#% 1477091
#% 1650592
#! We outline a method to estimate the value of computation for a flexible algorithm using empirical data. To determine a reasonable trade-off between cost and value, we build an empirical model of the value obtained through computation, and apply this model to estimate the value of computation for quite different problems. In particular, we investigate this trade-off for the problem of constructing policies for decision problems represented as influence diagrams. We show how two features of our anytime algorithm provide reasonable estimates of the value of computation in this domain.

#index 1650300
#* Attention-sensitive alerting
#@ Eric Horvitz;Andy Jacobs;David Hovel
#t 1999
#c 12
#% 101225
#% 165111
#% 190581
#% 260001
#% 269207
#% 269218
#% 272793
#% 272917
#% 458379
#% 1275346
#% 1650569
#% 1650593
#% 1650660
#% 1650725
#! We introduce utility-directed procedures for mediating the flow of potentially distracting alerts and communications to computer users. We present models and inference procedures that balance the context-sensitive costs of deferring alerts with the cost of interruption. We describe the challenge of reasoning about such costs under uncertainty via an analysis of user activity and the content of notifications. After introducing principles of attention-sensitive alerting, we focus on the problem of guiding alerts about email messages. We dwell on the problem of inferring the expected criticality of email and discuss work on the PRIORITIES system, centering on prioritizing email by criticality and modulating the communication of notifications to users about the presence and nature of incoming email.

#index 1650301
#* Mini-bucket heuristics for improved search
#@ Kalev Kask;Rina Dechter
#t 1999
#c 12
#% 241
#% 1722
#% 44876
#% 101250
#% 408680
#% 527842
#% 1273791
#% 1650617
#% 1650711
#% 1650778
#! The paper is a second in a series of two papers evaluating the power of a new scheme that generates search heuristics mechanically. The heuristics are extracted from an approximation scheme called mini-bucket elimination that was recently introduced. The first paper introduced the idea and evaluated it within Branch-and-Bound search. In the current paper the idea is further extended and evaluated within Best-First search. The resulting algorithms are compared on coding and medical diagnosis problems, using varying strength of the mini-bucket heuristics. Our results demonstrate an effective search scheme that permits controlled tradeoff between preprocessing (for heuristic generation) and search. Best-first search is shown to outperform Branch-and-Bound, when sup plied with good heuristics, and sufficient memory space.

#index 1650302
#* A general algorithm for approximate inference and its application to hybrid bayes nets
#@ Daphne Koller;Uri Lerner;Dragomir Angelov
#t 1999
#c 12
#% 61079
#% 115608
#% 179925
#% 361100
#% 457558
#% 465918
#% 527664
#% 565673
#% 567872
#% 1290139
#% 1650666
#% 1650669
#% 1650732
#% 1650793
#! The clique tree algorithm is the standard method for doing inference in Bayesian networks. It works by manipulating clique potentials - distributions over the variables in a clique. While this approach works well for many networks, it is limited by the need to maintain an exact representation of the clique potentials. This paper presents a new unified approach that combines approximate inference and the clique tree algorithm, thereby circumventing this limitation. Many known approximate inference algorithms can be viewed as instances of this approach. The algorithm essentially does clique tree propagation, using approximate inference to estimate the densities in each clique. In many settings, the computation of the approximate clique potential can be done easily using statistical importance sampling. Iterations are used to gradually improve the quality of the estimation.

#index 1650303
#* On supervised selection of Bayesian networks
#@ Petri Kontkanen;Petri Myllymäki;Tomi Silander;Henry Tirri
#t 1999
#c 12
#% 44876
#% 129987
#% 197387
#% 212698
#% 232117
#% 246832
#% 369349
#% 424807
#% 1650585
#% 1650722
#% 1808676
#% 1809511
#% 1809531
#! Given a set of possible models (e.g., Bayesian network structures) and a data sample, in the unsupervised model selection problem the task is to choose the most accurate model with respect to the domain joint probability distribution. In contrast to this, in supervised model selection it is a priori known that the chosen model will be used in the future for prediction tasks involving more "focused" predictive distributions. Although focused predictive distributions can be produced from the joint probability distribution by marginalization, in practice the best model in the unsupervised sense does not necessarily perform well in supervised domains. In particular, the standard marginal likelihood score is a criterion for the unsupervised task, and, although frequently used for supervised model selection also, does not perform well in such tasks. In this paper we study the performance of the marginal likelihood score empirically in supervised Bayesian network selection tasks by using a large number of publicly available classification data sets, and compare the results to those obtained by alternative model selection criteria, including empirical crossvalidation methods, an approximation of a supervised marginal likelihood measure, and a supervised version of Dawid's prequential (predictive sequential) principle. The results demonstrate that the marginal likelihood score does not perform well for supervised model selection, while the best results are obtained by using Dawid's prequential approach.

#index 1650304
#* Bayesian poker
#@ Kevin B. Korb;Ann E. Nicholson;Nathalie Jitnah
#t 1999
#c 12
#% 44876
#% 233137
#% 266213
#% 323701
#! Poker is ideal for testing automated reasoning under uncertainty. It introduces uncertainty both by physical randomization and by incomplete information about opponents' hands. Another source of uncertainty is the limited information available to construct psychological models of opponents, their tendencies to bluff, play conservatively, reveal weakness, etc. and the relation between their hand strengths and betting behaviour. All of these uncertainties must be assessed accurately and combined effectively for any reasonable level of skill in the game to be achieved, since good decision making is highly sensitive to those tasks. We describe our Bayesian Poker Program (BPP), which uses a Bayesian network to model the program's poker hand, the opponent's hand and the opponent's playing behaviour conditioned upon the hand, and betting curves which govern play given a probability of winning. The history of play with opponents is used to improve BPP's understanding of their behaviour. We compare BPP experimentally with: a simple rule-based system; a program which depends exclusively on hand probabilities (i.e., without opponent modeling); and with human players. BPP has shown itself to be an effective player against all these opponents, barring the better humans. We also sketch out some likely ways of improving play.

#index 1650305
#* On quantified linguistic approximation
#@ Ryszard Kowalczyk
#t 1999
#c 12
#% 516761
#% 1787856
#! Most fuzzy systems including fuzzy decision support and fuzzy control systems provide outputs in the form of fuzzy sets that represent the inferred conclusions. Linguistic interpretation of such outputs often involves the use of linguistic approximation that assigns a linguistic label to a fuzzy set based on the predefined primary terms, linguistic modifiers and linguistic connectives. More generally, linguistic approximation can be formalized in the terms of the re-translation rules that correspond to the translation rules in explicitation (e.g. simple, modifier, composite, quantification and qualification rules) in computing with words [Zadeh 1996]. However most existing methods of linguistic approximation use the simple, modifier and composite retranslation rules only. Although these methods can provide a sufficient approximation of simple fuzzy sets the approximation of more complex ones that are typical in many practical applications of fuzzy systems may be less satisfactory. Therefore the question arises why not use in linguistic approximation also other retranslation rules corresponding to the translation rules in explicitation to advantage. In particular linguistic quantification may be desirable in situations where the conclusions interpreted as quantified linguistic propositions can be more informative and natural. This paper presents some aspects of linguistic approximation in the context of the retranslation rules and proposes an approach to linguistic approximation with the use of quantification rules, i.e. quantified linguistic approximation. Two methods of the quantified linguistic approximation are considered with the use of linguistic quantifiers based on the concepts of the non-fuzzy and fuzzy cardinalities of fuzzy sets. A number of examples are provided to illustrate the proposed approach

#index 1650306
#* Choosing among interpretations of probability
#@ Henry E. Kyburg;Choh Man Teng
#t 1999
#c 12
#! There is available an ever-increasing variety of procedures for managing uncertainty. These methods are discussed in the literature of artificial intelligence, as well as in the literature of philosophy of science. Heretofore these methods have been evaluated by intuition, discussion, and the general philosophical method of argument and counterexample. Almost any method of uncertainty management will have the property that in the long run it will deliver numbers approaching the relative frequency of the kinds of events at issue. To find a measure that will provide a meaningful evaluation of these treatments of uncertainty, we must look, not at the long run, but at the short or intermediate run. Our project attempts to develop such a measure in terms of short or intermediate length performance. We represent the effects of practical choices by the outcomes of bets offered to agents characterized by two uncertainty management approaches: the subjective Bayesian approach and the Classical confidence interval approach. Experimental evaluation suggests that the confidence interval approach can outperform the subjective approach in the relatively short run.

#index 1650307
#* Expected utility networks
#@ Piero La Mura;Yoav Shoham
#t 1999
#c 12
#% 44876
#% 480348
#% 1650628
#! We introduce a new class of graphical representations, expected utility networks (EUNs), and discuss some of its properties and potential applications to artificial intelligence and economic theory. In EUNs not only probabilities, but also utilities enjoy a modular representation. EUNs are undirected graphs with two types of arc, representing probability and utility dependencies respectively. The representation of utilities is based on a novel notion of conditional utility independence, which we introduce and discuss in the context of other existing proposals. Just as probabilistic inference involves the computation of conditional probabilities, strategic inference involves the computation of conditional expected utilities for alternative plans of action. We define a new notion of conditional expected utility (EU) independence, and show that in EUNs node separation with respect to the probability and utility subgraphs implies conditional EU independence.

#index 1650308
#* My brain is full: when more memory helps
#@ Christopher Lusena;Tong Li;Shelia Sittinger;Chris Wells;Judy Goldsmith
#t 1999
#c 12
#% 30037
#% 102136
#% 171032
#% 252330
#% 707796
#% 1022821
#% 1650588
#% 1650702
#% 1650750
#! We consider the problem of finding good finite-horizon policies for POMDPs under the expected reward metric. The policies considered are free finite-memory policies with limited memory; a policy is a mapping from the space of observation-memory pairs to the space of action-memory pairs (the policy updates the memory as it goes), and the number of possible memory states is a parameter of the input to the policy-finding algorithms. The algorithms considered here are preliminary implementations of three search heuristics: local search. simulated annealing, and genetic algorithms. We compare their outcomes to each other and to the optimal policies for each instance. We compare run times of each policy and of a dynamic programming algorithm for POMDPs developed by Hansen that iteratively improves a finite-state controller - the previous state of the art for finite memory policies. The value of the best policy can only improve as the amount of memory increases, up to the amount needed for an optimal finite-memory policy. Our most surprising finding is that more memory helps in another way: given more memory than is needed for an optimal policy, the algorithms are more likely to converge to optimal-valued policies.

#index 1650309
#* Lazy evaluation of symmetric Bayesian decision problems
#@ Anders L. Madsen;Finn V. Jensen
#t 1999
#c 12
#% 34262
#% 119308
#% 130135
#% 527687
#% 1650606
#% 1650624
#% 1650712
#% 1650778
#! Solving symmetric Bayesian decision problems is a computationally intensive task to perform regardless of the algorithm used. In this paper we propose a method for improving the efficiency of algorithms for solving Bayesian decision problems. The method is based on the principle of lazy evaluation - a principle recently shown to improve the efficiency of inference in Bayesian networks. The basic idea is to maintain decompositions of potentials and to postpone computations for as long as possible. The efficiency improvements obtained with the lazy evaluation based method is emphasized through examples. Finally, the lazy evaluation based method is compared with the HUGIN and valuation-based systems architectures for solving symmetric Bayesian decision problems.

#index 1650310
#* Representing and combining partially specified CPTs
#@ Suzanne M. Mahoney;Kathryn Blackmond Laskey
#t 1999
#c 12
#% 44876
#% 89748
#% 101221
#% 130878
#% 708358
#% 1650607
#% 1650616
#% 1650644
#% 1650734
#% 1650767
#% 1650783
#% 1650793
#% 1650799
#! This paper extends previous work with network fragments and situation-specific network construction. We formally define the asymmetry network, an alternative representation for a conditional probability table. We also present an object-oriented representation for partially specified asymmetry networks. We show that the representation is parsimonious. We define an algebra for the elements of the representation that allows us to 'factor' any CPT and to soundly combine the partially specified asymmetry networks.

#index 1650311
#* On the complexity of policy iteration
#@ Yishay Mansour;Satinder Singh
#t 1999
#c 12
#% 22348
#% 174161
#% 361730
#% 384911
#% 703709
#! Decision-making problems in uncertain or stochastic domains are often formulated as Markov decision processes (MDPs). Policy iteration (PI) is a popular algorithm for searching over policy-space, the size of which is exponential in the number of states. We are interested in bounds on the complexity of PI that do not depend on the value of the discount factor. In this paper we prove the first such non-trivial, worst-case, upper bounds on the number of iterations required by PI to converge to the optimal policy. Our analysis also sheds new light on the manner in which PI progresses through the space of policies.

#index 1650312
#* Approximate planning for factored POMDPs using belief state simplification
#@ David A. McAllester;Satinder Singh
#t 1999
#c 12
#% 30037
#% 51999
#% 115608
#% 384911
#% 703709
#% 1650568
#! We are interested in the problem of planning for factored POMDPs. Building on the recent results of Kearns, Mansour and Ng, we provide a planning algorithm for factored POMDPs that exploits the accuracy efficiency tradeoff in the belief state simplification introduced by Boyen and Koller.

#index 1650313
#* Solving POMDPs by searching the space of finite policies
#@ Nicolas Meuleau;Kee-Eung Kim;Leslie Pack Kaelbling;Anthony R. Cassandra
#t 1999
#c 12
#% 171032
#% 179940
#% 252330
#% 272652
#% 272662
#% 305081
#% 363744
#% 384911
#% 466259
#% 702594
#% 706380
#% 707273
#% 707796
#% 1290265
#% 1650314
#% 1650588
#! Solving partially observable Markov decision processes (POMDPS) is highly intractable in general, at least in part because the optimal policy may be infinitely large. In this paper, we explore the problem of finding the optimal policy from a restricted set of policies, represented as finite state automata of a given size. This problem is also intractable, but we show that the complexity can be greatly reduced when the POMDP andlor policy are further constrained. We demonstrate good empirical results with a branch-and-bound method for finding globally optimal deterministic policies, and a gradient-ascent method for finding locally optimal stochastic policies.

#index 1650314
#* Learning finite-state controllers for partially observable environments
#@ Nicolas Meuleau;Leonid Peshkin;Kee-Eung Kim;Leslie Pack Kaelbling
#t 1999
#c 12
#% 171032
#% 179940
#% 252330
#% 272652
#% 305081
#% 363744
#% 384911
#% 393786
#% 449561
#% 466259
#% 702594
#% 706380
#% 707273
#% 707796
#% 1272286
#% 1290265
#% 1650313
#% 1650588
#! Reactive (memoryless) policies are sufficient in completely observable Markov decision processes (MDPS), but some kind of memory is usually necessary for optimal control of a partially observable MDP. Policies with finite memory can be represented as finite-state automata. In this paper, we extend Baird and Moore's VAPS algorithm to the problem of learning general finite-state automata. Because it performs stochastic gradient descent, this algorithm can be shown to converge to a locally optimal finitestate controller. We provide the details of the algorithm and then consider the question of under what conditions stochastic gradient descent will outperform exact gradient descent. We conclude with empirical results comparing the performance of stochastic and exact gradient descent, and showing the ability of our algorithm to extract the useful information contained in the sequence of past observations to compensate for the lack of observability at each time-step.

#index 1650315
#* Bayes nets in educational assessment: Where the numbers come from
#@ Robert J. Mislevy;Russell G. Almond;Duanli Yan;Linda S. Steinberg
#t 1999
#c 12
#! As observations and student models become complex, educational assessments that exploit advances in technology and cognitive psychology can outstrip familiar testing models and analytic methods. Within the Portal conceptual framework for assessment design, Bayesian inference networks (BINS) record beliefs about students' knowledge and skills, in light of what they say and do. Joining evidence model BIN fragments--which contain observable variables and pointers to student model variables--to the student model allows one to update belief about knowledge and skills as observations arrive. Markov Chain Monte Carlo (MCMC) techniques can estimate the required conditional probabilities from empirical data, supplemented by expert judgment or substantive theory. Details for the special cases of item response theory (IRT) and multivariate latent class modeling are given, with a numerical example of the latter.

#index 1650316
#* A Bayesian network classifier that combines a finite mixture model and a naïve bayes model
#@ Stefano Monti;Gregory F. Cooper
#t 1999
#c 12
#% 44876
#% 115608
#% 131258
#% 190581
#% 232117
#% 235377
#% 246831
#% 246832
#% 246834
#% 420054
#% 420065
#% 465904
#% 466086
#% 1650646
#! In this paper we present a new Bayesian network model for classification that combines the naive Bayes (NB) classifier and the finite mixture (FM) classifier. The resulting classifier aims at relaxing the strong assumptions on which the two component models are based, in an attempt to improve on their classification performance, both in terms of accuracy and in terms of calibration of the estimated probabilities. The proposed classifier is obtained by superimposing a finite mixture model on the set of feature variables of a naive Bayes model.. We present experimental results that compare the predictive performance on real datasets of the new classifier with the predictive performance of the NB classifier and the FM classifier.

#index 1650317
#* A variational approximation for Bayesian networks with discrete and continuous latent variables
#@ Kevin P. Murphy
#t 1999
#c 12
#% 61079
#% 101216
#% 169358
#% 246835
#% 277465
#% 277467
#% 277483
#% 304944
#% 443637
#% 527664
#% 705252
#% 1272398
#% 1650643
#% 1650732
#% 1650756
#% 1650763
#% 1809993
#! We show how to use a variational approximation to the logistic function to perform approximate inference in Bayesian networks containing discrete nodes with continuous parents. Essentially, we convert the logistic function to a Gaussian, which facilitates exact inference, and then iteratively adjust the variational parameters to improve the quality of the approximation. We demonstrate experimentally that this approximation is much faster than sampling, but comparable in accuracy. We also introduce a simple new technique for handling evidence, which allows us to handle arbitrary distributionson observed nodes, as well as achieving a significant speedup in networks with discrete variables of large cardinality.

#index 1650318
#* Loopy belief propagation for approximate inference: an empirical study
#@ Kevin P. Murphy;Yair Weiss;Michael I. Jordan
#t 1999
#c 12
#% 44876
#% 68244
#% 101510
#% 136358
#% 144664
#% 527655
#% 527664
#% 527688
#% 669227
#% 857454
#% 1272279
#% 1272398
#% 1809964
#% 1848680
#% 1848687
#! Recently, researchers have demonstrated that "loopy belief propagation" -- the use of Pearl's polytree algorithm in a Bayesian network with loops -- can perform well in the context of error-correcting codes. The most dramatic instance of this is the near Shannon-limit performance of "Turbo Codes" -- codes whose decoding algorithm is equivalent to loopy belief propagation in a chain-structured Bayesian network. In this paper we ask: is there something special about the error-correcting code context, or does loopy propagation work as an approximate inference scheme in a more general setting? We compare the marginals computed using loopy propagation to the exact ones in four Bayesian network architectures, including two real-world networks: ALARM and QMR. We find that the loopy beliefs often converge and when they do, they give a good approximation to the correct marginals. However, on the QMR network, the loopy beliefs oscillated and had no obvious relationship to the correct posteriors. We present some initial investigations into the cause of these oscillations, and show that some simple methods of preventing them lead to the wrong results.

#index 1650319
#* Learning Bayesian networks from incomplete data with stochastic search algorithms
#@ James W. Myers;Kathryn Blackmond Laskey;Tod Levitt
#t 1999
#c 12
#% 17144
#% 129987
#% 185079
#% 197387
#% 465882
#% 478645
#% 1650579
#! This paper describes stochastic search approaches, including a new stochastic algorithm and an adaptive mutation operator, for learning Bayesian networks from incomplete data. This problem is characterized by a huge solution space with a highly multimodal landscape. State-of-the-art approaches all involve using deterministic approaches such as the elrpectation-maximization algorithm. These approaches are guaranteed to find local maxima, but do not explore the landscape for other modes. Our approach evolves structure and the missing data. We compare our stochastic algorithms and show they all produce accurate results.

#index 1650320
#* Learning Bayesian networks with restricted causal interactions
#@ Julian R. Neil;Chris S. Wallace;Kevin B. Korb
#t 1999
#c 12
#% 33209
#% 44876
#% 68244
#% 101213
#% 129987
#% 130878
#% 277467
#% 1650616
#% 1650705
#% 1650722
#% 1650738
#% 1650767
#% 1650783
#% 1650797
#! A major problem for the learning of Bayesian networks (BNs) is the exponential number of parameters needed for conditional probability tables. Recent research reduces this complexity by modeling local structure in the probability tables. We examine the use of log-linear local models. While log-linear models in this context are not new (Whittaker, 1990; Buntine, 1991; Neal, 1992; Heckerman and Meek, 1997), it is generally subsumed under a naive Bayes model. We describe an alternative using a Minimum Message Length (MML) (Wallace and Freeman, 1987) metric for the selection of local models with causal independence, which we term a first-order model (FOM). We also combine FOMs and full conditional models on a node-by-node basis.

#index 1650321
#* The decision-theoretic interactive video advisor
#@ Hien Nguyen;Peter Haddawy
#t 1999
#c 12
#% 91361
#% 173879
#% 202009
#% 202011
#% 266281
#% 282625
#% 1650586
#! The need to help people choose among large numbers of items and to filter through large amounts of information has led to a flood of research in construction of personal recommendation agents. One of the central issues in constructing such agents is the representation and elicitation of user preferences or interests. This topic has long been studied in Decision Theory, but surprisingly little work in the area of recommender systems has made use of formal decision-theoretic techniques. This paper describes DIVA, a decision-theoretic agent for recommending movies that contains a number of novel features. DIVA represents user preferences using pairwise comparisons among items, rather than numeric ratings. It uses a novel similarity measure based on the concept of the probability of conflict between two orderings of items. The system has a rich representation of preference, distinguishing between a user's general taste in movies and his immediate interests. It takes an incremental approach to preference elicitation in which the user can provide feedback if not satisfied with the recommendation list. We empirically evaluate the performance of the system using the EachMovie collaborative filtering database.

#index 1650322
#* Welldefined decision scenarios
#@ Thomas D. Nielsen;Finn V. Jensen
#t 1999
#c 12
#% 34262
#% 119308
#% 527687
#% 1650620
#% 1650624
#! Influence diagrams serve as a powerful tool for modelling symmetric decision problems. When solving an influence diagram we determine a set of strategies for the decisions involved. A strategy for a decision variable is in principle a function over its past. However, some of the past may be irrelevant for the decision, and for computational reasons it is important not to deal with redundant variables in the strategies. We show that current methods (e.g. the Decision Bayes-ball algorithm [Shachter, 1998]) do not determine the relevant past, and we present a complete algorithm. Actually, this paper takes a more general outset: When formulating a decision scenario as an influence diagram, a linear temporal ordering of the decisions variables is required. This constraint ensures that the decision scenario is welldefined. However, the structure of a decision scenario often yields certain decisions conditionally independent, and it is therefore unnecessary to impose a linear temporal ordering on the decisions. In this paper we deal with partial influence diagrams i.e. influence diagrams with only a partial temporal ordering specified. We present a set of conditions which are necessary and sufficient to ensure that a partial influence diagram is welldefined. These conditions are used as a basis for the construction of an algorithm for determining whether or not a partial influence diagram is welldefined.

#index 1650323
#* Accelerating EM: an empirical study
#@ Luis E. Ortiz;Leslie Pack Kaelbling
#t 1999
#c 12
#% 188076
#% 211820
#% 232117
#% 246835
#% 252139
#% 646790
#% 669163
#% 1051482
#% 1650609
#% 1650696
#! Many applications require that we learn the parameters of a model from data. EM (Expectation-Maximization) is a method for learning the parameters of probabilistic models with missing or hidden data. There are instances in which this method is slow to converge. Therefore, several accelerations have been proposed to improve the method. None of the proposed acceleration methods are theoretically dominant and experimental comparisons are lacking. In this paper, we present the different proposed accelerations and compare them experimentally. From the results of the experiments, we argue that some acceleration of EM is always possible, but that which acceleration is superior depends on properties of the problem.

#index 1650324
#* Variational learning in mixed-state dynamic graphical models
#@ Vladimir Pavlovic;Brendan J. Frey;Thomas S. Huang
#t 1999
#c 12
#% 32357
#% 44876
#% 115608
#% 130878
#% 137711
#% 191855
#% 235061
#% 246836
#% 261205
#% 277467
#% 465918
#% 541077
#% 708626
#% 1650568
#! Many real-valued stochastic time-series are locally linear (Gaussian), but globally nonlinear. For example, the trajectory of a human hand gesture can be viewed as a linear dynamic system driven by a nonlinear dynamic system that represents muscle actions. We present a mixed-state dynamic graphical model in which a hidden Markov model drives a linear dynamic system. This combination allows us to model both the discrete and continuous causes of trajectories such as human gestures. The number of computations needed for exact inference is exponential in the sequence length, so we derive an approximate variational inference technique that can also be used to learn the parameters of the discrete and continuous models. We show how the mixed-state model and the variational technique can be used to classify human hand gestures made with a computer mouse.

#index 1650325
#* Graphical representations of consensus belief
#@ David M. Pennock;Michael P. Wellman
#t 1999
#c 12
#% 44876
#% 46437
#% 67866
#% 68244
#% 130104
#% 191854
#% 216975
#% 380725
#% 567876
#! Graphical models based on conditional independence support concise encodings of the subjective belief of a single agent. A natural question is whether the consensus belief of a group of agents can be represented with equal parsimony. We prove, under relatively mild assumptions, that even if everyone agrees on a common graph topology, no method of combining beliefs can maintain that structure. Even weaker conditions rule out local aggregation within conditional probability tables. On a more positive note, we show that if probabilities are combined with the logarithmic opinion pool (LogOP), then commonly held Markov independencies are maintained. This suggests a straightforward procedure for constructing a consensus Markov network. We describe an algorithm for computing the LogOP with time complexity comparable to that of exact Bayesian inference.

#index 1650326
#* SPOOK: a system for probabilistic object-oriented knowledge representation
#@ Avi Pfeffer;Daphne Koller;Brian Milch;Ken T. Takusagawa
#t 1999
#c 12
#% 266230
#% 266237
#% 1478758
#% 1650731
#% 1650734
#% 1650767
#% 1650799
#! In previous work, we pointed out the limitations of standard Bayesian networks as a modeling framework for large, complex domains. We proposed a new, richly structured modeling language, Object-oriented Bayesian Networks, that we argued would be able to deal with such domains. However, it turns out that OOBNs are not expressive enough to model many interesting aspects of complex domains: the existence of specific named objects, arbitrary relations between objects, and uncertainty over domain structure. These aspects are crucial in real-world domains such as battlefield awareness. In this paper, we present SPOOK, an implemented system that addresses these limitations. SPOOK implements a more expressive language that allows it to represent the battlespace domain naturally and compactly. We present a new inference algorithm that utilizes the model structure in a fundamental way, and show empirically that it achieves orders of magnitude speedup over existing approaches.

#index 1650327
#* Bayesian networks for dependability analysis: an application to digital control reliability
#@ Luigi Portinale;Andrea Bobbio
#t 1999
#c 12
#% 44876
#% 101221
#% 103309
#% 132173
#% 147677
#% 182943
#% 482909
#% 558697
#% 1272178
#% 1273478
#% 1784146
#! Bayesian Networks (BN) provide robust probabilistic methods of reasoning under uncertainty, but despite their formal grounds are strictly based on the notion of conditional dependence, not much attention has been paid so far to their use in dependability analysis. The aim of this paper is to propose BN as a suitable tool for dependability analysis, by challenging the formalisnl with basic issues arising in dependability tasks. We will discuss how both modeling and analysis issues can be naturally dealt with by BN. Moreover, we will show how some limitations intrinsic to combinatorial dependability methods such as Fault Trees can be overcome using BN. This will be pursued through the study of a real-world example concerning the reliability analysis of a redundant digital Programmable Logic Controller (PLC) with majority voting 2:3

#index 1650328
#* Enhancing QPNs for trade-off resolution
#@ Silja Renooij;Linda C. van der Gaag
#t 1999
#c 12
#% 89748
#% 564806
#% 1478675
#% 1650603
#% 1650676
#! Qualitative probabilistic networks have been introduced as qualitative abstractions of Bayesian belief networks. One of the major drawbacks of these qualitative networks is their coarse level of detail, which may lead to unresolved trade-offs during inference. We present an enhanced formalism for qualitative networks with a finer level of detail. An enhanced qualitative probabilistic network differs from a regular qualitative network in that it distinguishes between strong and weak influences. Enhanced qualitative probabilistic networks are purely qualitative in nature, as regular qualitative networks are, yet allow for efficiently resolving trade-offs during inference.

#index 1650329
#* A possibilistic model for qualitative sequential decision problems under uncertainty in partially observable environments
#@ Régis Sabbadin
#t 1999
#c 12
#% 22348
#% 51999
#% 71810
#% 102136
#% 179940
#% 363744
#% 1290039
#% 1290145
#% 1478842
#% 1478843
#% 1650578
#! In this article we propose a qualitative (ordinal) counterpart for the Partially Observable Markov Decision Processes model (POMDP) in which the uncertainty, as well as the preferences of the agent, are modeled by possibility distributions. This qualitative counterpart of the POMDP model relies on a possibilistic theory of decision under uncertainty, recently developed. One advantage of such a qualitative framework is its ability to escape from the classical obstacle of stochastic POMDPs, in which even with a finite state space, the obtained belief state space of the POMDP is infinite. Instead, in the possibilistic framework even if exponentially larger than the state space, the belief state space remains finite.

#index 1650330
#* Inference networks and the evaluation of evidence: alternative analyses
#@ David A. Schum
#t 1999
#c 12
#% 44876
#% 61633
#% 689633
#! Inference networks have a variety of important uses and are constructed by persons having quite different standpoints. Discussed in this paper are three different but complementary methods for generating and analyzing probabilistic inference networks. The first method, though over eighty years old, is very useful for knowledge representation in the task of constructing probabilistic arguments. It is also useful as a heuristic device in generating new forms of evidence. The other two methods are formally equivalent ways for combining probabilities in the analysis of inference networks. The use of these three methods is illustrated in an analysis of a mass of evidence in a celebrated American law case.

#index 1650331
#* Approximate learning in complex dynamic Bayesian networks
#@ R. Settimi;J. Q. Smith;A. S. Gargoum
#t 1999
#c 12
#% 128629
#% 235061
#% 267572
#% 361888
#% 380725
#% 1650568
#! In this paper we extend the work of Smith and Papamichail (1999) and present fast approximate Bayesian algorithms for learning in complex scenarios where at any time frame, the relationships between explahatory state space variables can be described by a Bayesian network that evolve dynamically over time and the observations taken are not necessarily Gaussian. It uses recent developments in approximate Bayesian forecasting methods in combination with more familiar Gaussian propagation algorithms on junction trees. The procedure for learning state parameters from data is given explicitly for common sampling distributions and the methodology is illustrated through a real application. The efficiency of the dynamic approximation is explored by using the Hellinger divergence measure and theoretical bounds for the efficacy of such a procedure are discussed.

#index 1650332
#* Efficient value of information computation
#@ Ross D. Shachter
#t 1999
#c 12
#% 34262
#% 119308
#% 130135
#% 1650620
#% 1650712
#! One of the most useful sensitivity analysis techniques of decision analysis is the computation of value of information (or clairvoyance), the difference in value obtained by changing the decisions by which some of the uncertainties are observed. In this paper, some simple but powerful extensions to previous algorithms are introduced which allow an efficient value of information calculation on the rooted cluster tree (or strong junction tree) used to solve the original decision problem.

#index 1650333
#* Learning hidden Markov models with geometrical constraints
#@ Hagit Shatkay
#t 1999
#c 12
#% 267315
#% 466072
#% 646794
#% 1271848
#% 1290038
#% 1650658
#! Hidden Markov models (HMMS) and partially observable Markov decision processes (POMDPS)form a useful tool for modeling dynamical systems. They are particularly useful for representing environments such as road networks and office buildings, which are typical for robot navigation and planning. The work presented here is concerned with acquiring such models. We demonstrate how domain-specific information and consaaints can be incorporated into the statistical estimation process, greatly improving the learned models in terms of the model quality, the number of iterations required for convergence and robustness to reduction in the amount of available data. We present new initialization heuristics which can be used even when the data suffers from cumulative rotational error, new update rules for the model parameters, as an instance of generalized EM, and a strategy for enforcing complete geometrical consistency in the model. Experimental results demonstrate the effectiveness of our approach for both simulated and real robot data, in traditionally hard-to-learn environments.

#index 1650334
#* Practical uses of belief functions
#@ Philippe Smets
#t 1999
#c 12
#% 20853
#% 44876
#% 65346
#% 71134
#% 83936
#% 128630
#% 133504
#% 161238
#% 168315
#% 168316
#% 262078
#% 319279
#% 503493
#% 503525
#% 503670
#% 503823
#% 503829
#% 527686
#% 1273620
#% 1280097
#% 1290141
#! We present examples where the use of belief functions provided sound and elegant solutions to real life problems. These are essentially characterized by 'missing' information. The examples deal with 1) discriminant analysis using a learning set where classes are only partially known; 2) an information retrieval systems handling inter-documents relationships; 3) the combination of data from sensors competent on partially overlapping frames; 4) the determination of the number of sources in a multi-sensor environment by studying the intersensors contradiction. The purpose of the paper is to report on such applications where the use of belief functions provides a convenient tool to handle 'messy' data problems

#index 1650335
#* Multiplicative factorization of noisy-max
#@ Masami Takikawa;Bruce D'Ambrosio
#t 1999
#c 12
#% 59918
#% 527688
#% 564806
#% 707483
#% 1272302
#% 1272945
#% 1477089
#% 1650694
#% 1650751
#! The noisy-or and its generalization noisy-max have been utilized to reduce the complexity of knowledge acquisition. In this paper, we present a new representation of noisy-max that allows for efficient inference in general Bayesian networks. Empirical studies show that our method is capable of computing queries in well-known large medical networks, QMR-DT and CPCS, for which no previous exact inference method has been shown to perform well.

#index 1650336
#* An update semantics for defeasible obligations
#@ Leepdert van der Torre;Yao-Hua Tan
#t 1999
#c 12
#% 179919
#% 235089
#% 235474
#% 495773
#! The deontic logic DUS is a Deontic update Semantics for prescriptive obligations based on the update semantics of Veltman. In DUS the definition of logical validity of obligations is not based on static truth values but on dynamic action transitions. In this paper prescriptive defeasible obligations are formalized in update semantics and the diagnostic problem of defeasible deontic logic is discussed. Assume a defeasible obligation 'normally α ought to be (done)' together with the fact '¬α (done).' Is this an exception of the normality claim, or is it a violation of the obligation? In this paper we formalize the heuristic principle that it is a violation, unless there is a more specific overriding obligation. The underlying motivation from legal reasoning is that criminals should have as little opportunities as possible to excuse themselves by claiming that their behavior was exceptional rather than criminal.

#index 1650337
#* Mixture approximations to Bayesian networks
#@ Volker Tresp;Michael Haft;Reimar Hofmann
#t 1999
#c 12
#% 256667
#% 272505
#% 1272279
#% 1650601
#! Structure and parameters in a Bayesian network uniquely specify the probability distribution of the modeled domain. The locality of both structure and probabilistic information are the great benefits of Bayesian networks and require the modeler to only specify local information. On the other hand this locality of information might prevent the modeler -and even more any other personfrom obtaining a general overview of the important relationships within the domain. The goal of the work presented in this paper is to provide an "alternativen view on the knowledge encoded in a Bayesian network which might sometimes be very helpful for providing insights into the underlying domain. The basic idea is to calculate a mixture approximation to the probability distribution represented by the Bayesian network. The mixture component densities can be thought of as representing typical scenarios implied by the Bayesian model, providing intuition about the basic relationships. As an additional benefit, performing inference in the approximate model is very simple and intuitive and can provide additional insights. The computational complexity for the calculation of the mixture approximations critically depends on the measure which defines the distance between the probability distribution represented by the Bayesian network and the approximate distribution. Both the KL-divergence and the backward KL-divergence lead to inefficient algorithms. Incidentally, the latter is used in recent work on mixtures of mean field solutions to which the work presented here is closely related. We show, however, that using a mean squared error cost function leads to update equations which can be solved using the junction tree algorithm. We conclude that the mean squared error cost function can be used for Bayesian networks in which inference based on the junction tree is tractable. For large networks, however, one may have to rely on mean field approximations.

#index 1650338
#* How to elicit many probabilities
#@ L. C. van der Gaag;S. Renooij;C. L. M. Witteman;B. M. P. Aleman;B. G. Taal
#t 1999
#c 12
#% 138290
#% 1650644
#! In building Bayesian belief networks, the elicitation of all probabilities required can be a major obstacle. We learned the extent of this often-cited observation in the construction of the probabilistic part of a complex influence diagram in the field of cancer treatment. Based upon our negative experiences with existing methods, we designed a new method for probability elicitation from domain experts. The method combines various ideas, among which are the ideas of transcribing probabilities and of using a scale with both numerical and verbal anchors for marking assessments. In the construction of the probabilistic part of our influence diagram, the method proved to allow for the elicitation of many probabilities in little time.

#index 1650339
#* Probabilistic belief change: expansion, conditioning and constraining
#@ Frans Voorbraak
#t 1999
#c 12
#% 45265
#% 116624
#% 168317
#% 503981
#% 1650584
#! The AGM theory of belief revision has become an important paradigm for investigating rational belief changes. Unfortunately, researchers working in this paradigm have restricted much of their attention to rather simple representations of belief states, namely logically closed sets of propositional sentences. In our opinion, this has resulted in a too abstract categorisation of belief change operations: expansion, revision, or contraction. Occasionally, in the AGM paradigm, also probabilistic belief changes have been considered, and it is widely accepted that the probabilistic version of expansion is conditioning. However, we argue that it may be more correct to view conditioning and expansion as two essentially different kinds of belief change, and that what we call constraining is a better candidate for being considered probabilistic expansion.

#index 1650340
#* Bayesian control for concentrating mixed nuclear waste
#@ Robert L. Welch;Clayton Smith
#t 1999
#c 12
#% 34262
#% 68244
#% 172069
#% 1650592
#% 1650594
#! A control algorithm for batch processing of mixed waste is proposed based on conditional Gaussian Bayesian networks. The network is compiled during batch staging for real-time response to sensor input.

#index 1650341
#* Contextual weak independence in Bayesian networks
#@ S. K. M. Wong;C. J. Butz
#t 1999
#c 12
#% 44876
#% 101221
#% 243717
#% 1650731
#% 1650767
#! It is well-known that the notion of (strong) conditional independence (CI) is too restrictive to capture independencies that only hold in certain contexts. This kind of contextual independency, called context-strong independence (CSI), can be used to facilitate the acquisition, representation, and inference of probabilistic knowledge. In this paper, we suggest the use of contextual weak independence (CWI) in Bayesian networks. It should be emphasized that the notion of CWI is a more general form of contextual independence than CSI. Furthermore, if the contextual strong independence holds for all contexts, then the notion of CSI becomes strong CI. On the other hand, if the weak contextual independence holds for all contexts, then the notion of CWI becomes weak independence (WI) which is a more general noncontextual independency than strong CI. More importantly, complete axiomatizations are studied for both the class of WI and the class of CI and WI together. Finally, the interesting property of WI being a necessary and sufficient condition for ensuring consistency in granular probabilistic networks is shown.

#index 1650342
#* Inference in multiply sectioned Bayesian networks with extended Shafer-Shenoy and lazy propagation
#@ Y. Xiang;F. V. Jensen
#t 1999
#c 12
#% 44876
#% 216975
#% 360087
#% 1477089
#% 1650606
#% 1650731
#! As Bayesian networks are applied to larger and more complex problem domains, search for flexible modeling and more efficient inference methods is an ongoing effort. Multiply sectioned Bayesian networks (MSBNs) extend the HUGIN inference for Bayesian networks into a coherent framework for flexible modeling and distributed inference. Lazy propagation extends the Shafer-Shenoy and HUGIN inference methods with reduced space complexity. We apply the Shafer-Shenoy and lazy propagation to inference in MSBNs. The combination of the MSBN framework and lazy propagation provides a better framework for modeling and inference in very large domains. It retains the modeling flexibility of MSBNs and reduces the runtime space complexity, allowing exact inference in much larger domains given the same computational resources.

#index 1650343
#* Time-critical dynamic decision making
#@ Yanping Xiang;Kim-Leng Poh
#t 1999
#c 12
#% 34262
#% 98073
#% 110379
#% 701040
#! Recent interests in dynamic decision modeling have led to the development of several representation and inference methods. These methods however, have limited application under time critical conditions where a trade-off between model quality and computational tractability is essential. This paper presents an approach to time-critical dynamic decision modeling. A knowledge representation and modeling method called the time-critical dynamic influence diagram is proposed. The formalism has two forms. The condensed form is used for modeling and model abstraction, while the deployed form which can be converted from the condensed form is used for inference purposes. The proposed approach has the ability to represent space-temporal abstraction within the model. A knowledge-based meta-reasoning approach is proposed for the purpose of selecting the best abstracted model that provide the optimal trade-off between model quality and model tractability. An outline of the knowledge-based model construction algorithm is also provided.

#index 1650344
#* A method for speeding up value iteration in partially observable Markov decision processes
#@ Nevin L. Zhang;Stephen S. Lee;Weihong Zhang
#t 1999
#c 12
#% 101869
#% 706380
#% 707796
#% 1272319
#% 1650702
#! We present a technique for speeding up the convergence of value iteration for partially observable Markov decisions processes (POMDPs). The underlying idea is similar to that behind modified policy iteration for fully observable Markov decision processes (MDPs). The technique can be easily incorporated into any existing POMDP value iteration algorithms. Experiments have been conducted on several test problems with one POMDP value iteration algorithm called incremental pruning. We find that the technique can make incremental pruning run several orders of magnitude faster.

#index 1650345
#* Proceedings of the Eighteenth conference on Uncertainty in artificial intelligence
#@ Adnan Darwiche;Nir Friedman
#t 2002
#c 12

#index 1650346
#* Markov equivalence classes for maximal ancestral graphs
#@ R. Ayesha Ali;Thomas S. Richardson
#t 2002
#c 12
#% 297171
#% 1650638
#% 1650673
#! Ancestral graphs provide a class of graphs that can encode conditional independence relations that arise in directed acyclic graph (DAG) models with latent and selection variables, corresponding to marginalization and conditioning. However, for any ancestral graph, there may be several other graphs to which it is Markov equivalent. We introduce a simple representation of a Markov equivalence class of ancestral graphs, thereby facilitating the model search process for some given data. More specifically, we define a join operation on ancestral graphs which will associate a unique graph with an equivalence class. We also extend the separation criterion for ancestral graphs (which is an extension of d-separation) and provide a proof of the pairwise Markov property for joined ancestral graphs. Proving the pairwise Markov property is the first step towards developing a global Markov property for these graphs. The ultimate goal of this work is to obtain a full characterization of the structure of Markov equivalence classes for maximal ancestral graphs, thereby extending analogous results for DAGs given by Frydenberg (1990), Verma and Pearl (1991), Chickering (1995) and Andersson et al. (1997).

#index 1650347
#* Learning hierarchical object maps of non-stationary environments with mobile robots
#@ Dragomir Anguelov;Rahul Biswas;Daphne Koller;Benson Limketkai;Sebastian Thrun
#t 2002
#c 12
#% 39654
#% 418645
#% 466078
#% 1273895
#! Building models, or maps, of robot environments is a highly active research area; however, most existing techniques construct unstructured maps and assume static environments. In this paper, we present an algorithm for learning object models of non-stationary objects found in office-type environments. Our algorithm exploits the fact that many objects found in office environments look alike (e.g., chairs, recycling bins). It does so through a two-level hierarchical representation, which links individual objects with generic shape templates of object classes. We derive an approximate EM algorithm for learning shape pararneters at both levels of the hierarchy, using local occupancy grid maps for representing shape. Additionally, we develop a Bayesian model selection algorithm that enables the robot to estimate the total number of objects and object templates in the environment. Experimental results using a real robot equipped with a laser range finder indicate that our approach performs well at learning object-based maps of simple office environments. The approach outperforms a previously developed non-hierarchical algorithm that models objects jects but lacks class templates.

#index 1650348
#* A constraint satisfaction approach to the robust spanning tree problem with interval data
#@ Ionut Aron;Pascal Van Hentenryck
#t 2002
#c 12
#% 9240
#% 494175
#% 1846113
#! Robust optimization is one of the fundamental approaches to deal with uncertainty in combinatorial optimization. This paper considers the robust spanning tree problem with interval data, which arises in a variety of telecommunication applications. It proposes a constraint satisfaction approach using a combinatorial lower bound, a pruning component that removes infeasible and suboptimal edges, as well as a search strategy exploring the most uncertain edges first. The resulting algorithm is shown to produce very dramatic improvements over the mathematical programming approach of Yaman et al. and to enlarge considerably the class of problems amenable to effective solutions.

#index 1650349
#* On the construction of the inclusion boundary neighbourhood for markov equivalence classes of bayesian network structures
#@ Vincent Auvray;Louis Wehenkel
#t 2002
#c 12
#% 44876
#% 388024
#% 528333
#% 722804
#% 1650771
#! The problem of learning Markov equivalence classes of Bayesian network structures may be solved by searching for the maximum of a scoring metric in a space of these classes. This paper deals with the definition and analysis of one such search space. We use a theoretically motivated neighbourhood, the inclusion boundary, and represent equivalence classes by essential graphs. We show that this search space is connected and that the score of the neighbours can be evaluated incrementally. We devise a practical way of building this neighbourhood for an essential graph that is purely graphical and does not explicitely refer to the underlying independences. We find that its size can be intractable, depending on the complexity of the essential graph of the equivalence class. The emphasis is put on the potential use of this space with greedy hillclimbing search.

#index 1650350
#* Tree-dependent component analysis
#@ Francis R. Bach;Michael I. Jordan
#t 2002
#c 12
#% 70370
#% 276877
#% 281743
#% 528174
#% 674153
#% 1042787
#! We present a generalization of independent component analysis (ICA), where instead of looking for a linear transform that makes the data components independent, we look for a transform that makes the data components well fit by a tree-structured graphical model. Treating the problem as a semiparametric statistical problem, we show that the optimal transform is found by minimizing a contrast function based on mutual information, a function that directly extends the contrast function used for classical ICA. We provide two approximations of this contrast function, one using kernel density estimation, and another using kernel generalized variance. This tree-dependent component analysis framework leads naturally to an efficient general multivariate density estimation technique where only bivariate density estimation needs to be performed.

#index 1650351
#* Bipolar possibilistic representations
#@ Salem Benferhat;Didier Dubois;Souhila Kaci;Henri Prade
#t 2002
#c 12
#% 78634
#% 167544
#% 319292
#% 418170
#% 422003
#% 483946
#% 504126
#! Recently, it has been emphasized that the possibility theory framework allows us to distinguish between i) what is possible because it is not ruled out by the available knowledge, and ii) what is possible for sure. This distinction may be useful when representing knowledge, for modelling values which are not impossible because they are consistent with the available knowledge on the one hand, and values guaranteed to be possible because reported from observations on the other hand. It is also of interest when expressing preferences, to point out values which are positively desired among those which are not rejected. This distinction can be encoded by two types of constraints expressed in terms of necessity measures and in terms of guaranteed possibility functions, which induce a pair of possibility distributions at the semantic level. A consistency condition should ensure that what is claimed to be guaranteed as possible is indeed not impossible. The present paper investigates the representation of this bipolar view, including the case when it is stated by means of conditional measures, or by means of comparative context-dependent constraints. The interest of this bipolar framework, which has been recently stressed for expressing preferences, is also pointed out in the representation of diagnostic knowledge.

#index 1650352
#* Learning with scope, with application to information extraction and classification
#@ David M. Blei;J. Andrew Bagnell;Andrew K. McCallum
#t 2002
#c 12
#% 190581
#% 252011
#% 303620
#% 466896
#% 715096
#% 1289267
#! In probabilistic approaches to classification and information extraction, one typically builds a statistical model of words under the assumption that future data will exhibit the same regularities as the training data. In many data sets, however, there are scopelimited features whose predictive power is only applicable to a certain subset of the data. For example, in information extraction from web pages, word formatting may be indicative of extraction category in different ways on different web pages. The difficulty with using such features is capturing and exploiting the new regularities encountered in previously unseen data. In this paper, we propose a hierarchical probabilistic model that uses both local/scope-limited features, such as word formatting, and global features, such as word content. The local regularities are modeled as an unobserved random parameter which is drawn once for each local data set. This random parameter is estimated during the inference process and then used to perform classification with both the local and global features- a procedure which is akin to automatically retuning the classifier to the local regularities on each newly encountered web page. Exact inference is intractable and we present approximations via point estimates and variational methods. Empirical results on large collections of web data demonstrate that this method significantly improves performance from traditional models of global features alone.

#index 1650353
#* Qualitative MDPs and POMDPs: an order-of-magnitude approximation
#@ Blai Bonet;Judea Pearl
#t 2002
#c 12
#% 179940
#% 187566
#% 361729
#% 366370
#% 384911
#% 527528
#% 528024
#% 1271823
#% 1271828
#% 1289211
#% 1290145
#% 1290265
#% 1476298
#% 1477308
#% 1478679
#% 1650329
#% 1650690
#! We develop a qualitative theory of Markov Decision Processes (MDPS) and Partially Observable MDPS that can be used to model sequential decision making tasks when only qualitative information is available. Our approach is based upon an order-of-magnitude approximation of both probabilities and utilities, similar to ε-semantics. The result is a qualitative theory that has close ties with the standard maximum-expected-utility theory and is amenable to general planning techniques.

#index 1650354
#* Introducing variable importance tradeoffs into CP-nets
#@ Ronen I. Brafman;Carmel Domshlak
#t 2002
#c 12
#% 1650274
#! The ability to make decisions and to assess potential courses of action is a comer-stone of many AI applications, and usually this requires explicit information about the decision-maker's preferences. In many applications, preference elicitation is a serious bottleneck. The user either does not have the time, the knowledge, or the expert support required to specify complex multi-attribute utility functions. In such cases, a method that is based on intuitive, yet expressive, preference statements is required. In this paper we suggest the use of TCP-nets, an enhancement of CP-nets, as a tool for representing, and reasoning about qualitative preference statements. We present and motivate this framework, define its semantics, and show how it can be used to perform constrained optimization.

#index 1650355
#* Planning under continuous time and resource uncertainty: a challenge for AI
#@ John Bresina;Richard Dearden;Nicolas Meuleau;Sailesh Ramakrishnan;David Smith;Rich washington
#t 2002
#c 12
#% 124601
#% 179961
#% 194652
#% 265807
#% 266386
#% 266387
#% 272665
#% 283215
#% 283219
#% 314789
#% 363744
#% 393786
#% 466575
#% 529665
#% 544926
#% 707175
#% 743461
#% 1271828
#% 1272287
#% 1272331
#% 1272399
#% 1273921
#% 1289211
#% 1289212
#! We outline a class of problems, typical of Mars rover operations, that are problematic for current methods of planning under uncertainty. The existing methods fail because they suffer from one or more of the following limitations: 1) they rely on very simple models of actions and time, 2) they assume that uncertainty is manifested in discrete action outcomes, 3) they are only practical for very small problems. For many real world oroblems, these assumptions fail to hold. In particular, when planning the activities for a Mars rover, none of the above assumptions is valid: 1) actions can be concurrent and have differing durations, 2) there is uncertainty concerning action durations and consumption of continuous resources like power, and 3) typical daily plans involve on the order of a hundred actions. This class of problems may be of particular interest to the UAI community because both classical and decision-theoretic planning techniques may be useful in solving it. We describe the rover problem, discuss previous work on planning under uncertainty, and present a detailed, but very small, example illustrating some of the difficulties of finding good plans.

#index 1650356
#* Generalized instrumental variables
#@ Carlos Brito;Judea Pearl
#t 2002
#c 12
#% 297171
#% 578735
#! This paper concerns the assessment of direct causal effects from a combination of: (i) nonexperimental data, and (ii) qualitative domain knowledge. Domain knowledge is encoded in the form of a directed acyclic graph (DAG), in which all interactions are assumed linear, and some variables are presumed to be unobserved. We provide a generalization of the well-known method of Instrumental Variables, which allows its application to models with few conditional independeces.

#index 1650357
#* Finding optimal bayesian networks
#@ David Maxwell Chickering;Christopher Meek
#t 2002
#c 12
#% 44876
#% 197387
#% 1272387
#% 1650281
#% 1650638
#! In this paper, we derive optimality results for greedy Bayesian-network search algorithms that perform single-edge modifications at each step and use asymptotically consistent scoring criteria. Our results extend those of Meek (1997) and Chickering (2002), who demonstrate that in the limit of large datasets, if the generative distribution is perfect with respect to a DAG defined over the observable variables, such search algorithms will identify this optimal (i.e. generative) DAG model. We relax their assumption about the generative distribution, and assume only that this distribution satisfies the composition property over the observable variables, which is a more realistic assumption for real domains. Under this assumption, we guarantee that the search algorithms identify an inclusion-optimal model; that is, a model that (1) contains the generative distribution and (2) has no sub-model that contains this distribution. In addition, we show that the composition property is guaranteed to hold whenever the dependence relationships in the generative distribution can be characterized by paths between singleton elements in some generative graphical model (e.g. a DAG, a chain graph, or a Markov network) even when the generative model includes unobserved variables, and even when the observed data is subject to selection bias.

#index 1650358
#* Complexity of mechanism design
#@ Vincent Conitzer;Tuomas Sandholm
#t 2002
#c 12
#% 271160
#% 344879
#% 345429
#% 567883
#% 578703
#% 781210
#% 1289289
#! The aggregation of conflicting preferences is a central problem in multiagent systems. The key difficulty is that the agents may report their preferences insincerely. Mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully and a (socially) desirable outcome is chosen. We propose an approach where a mechanism is automatically created for the preference aggregation setting at hand. This has several advantages, but the downside is that the mechanism design optimization problem needs to be solved anew each time. Focusing-on settings where side payments are not possible, we show that the mechanism design problem is NP-complete for deterministic mechanisms. This holds both for dominantstrategy implementation and for Bayes-Nash implementation. We then show that if we allow randomized mechanisms, the mechanism design problem becomes tractable. In other words, the coordinator can tackle the computational complexity introduced by its uncertainty the agents face additional uncertainty. This comes at no loss, and in some cases at a gain, in the (social) objective.

#index 1650359
#* Continuation methods for mixing heterogeneous sources
#@ Adrian Corduneanu;Tommi Jaakkola
#t 2002
#c 12
#% 193341
#% 311027
#% 416666
#! A number of modern learning tasks involve estimation from heterogeneous information sources. This includes classification with labeled and unlabeled data as well as other problems with analogous structure such as competitive (game theoretic) problems. The associated estimation problems can be typically reduced to solving a set of fixed point equations (consistency conditions). We introduce a general method for combining a preferred information source with another in this setting by evolving continuous paths of fixed points at intermediate allocations. We explicitly identify critical points along the unique paths to either increase the stability of estimation or to ensure a significant departure from the initial source. The homotopy continuation approach is guaranteed to terminate at the second source, and involves no combinatorial effort. We illustrate the power of these ideas both in classification tasks with labeled and unlabeled data, as well as in the context of a competitive (min-max) formulation of DNA sequence motif discovery.

#index 1650360
#* Interpolating conditional density trees
#@ Scott Davies;Andrew Moore
#t 2002
#c 12
#% 232117
#% 277503
#% 449588
#% 528002
#% 528005
#% 714917
#% 1650289
#% 1650611
#% 1650643
#% 1650658
#% 1650732
#! Joint distributions over many variables are frequently modeled by decomposing them into products of simpler, lower-dimensional conditional distributions, such as in sparsely connected Bayesian networks. However, automatically learning such models can be very computationally expensive when there are many datapoints and many continuous variables with complex nonlinear relationships, particularly when no good ways of decomposing the joint distribution are known a priori. In such situations, previous research has generally focused on the use of discretization techniques in which each continuous variable has a single discretization that is used throughout the entire network. In this paper, we present and compare a wide variety of tree-based algorithms for learning and evaluating conditional density estimates over continuous variables. These trees can be thought of as discretizations that vary according to the particular interactions being modeled; however, the density within a given leaf of the tree need not be assumed constant, and we show that such nonuniform leaf densities lead to more accurate density estimation. We have developed Bayesian network structure-learning algorithms that employ these tree-based conditional density representations. and we show that they can be used to practically learn complex joint prob ability models over dozens of continuous variables from thousands of datapoints. We focus on finding models that are simultaneously accurate, fast to learn, and fast to evaluate once they are learned.

#index 1650361
#* Iterative join-graph propagation
#@ Rina Dechter;Kalev Kask;Robert Mateescu
#t 2002
#c 12
#% 1675
#% 44876
#% 68244
#% 205391
#% 528300
#% 578738
#% 836134
#% 1273786
#% 1650711
#% 1650778
#! The paper presents an iterative version of join-tree clustering that applies the message passing of join-tree clustering algorithm to join-graphs rather than to join-trees, iteratively. It is inspired by the success of Pearl's belief propagation algorithm (BP) as an iterative approximation scheme on one hand, and by a recently introduced mini-clustering (MC(i)) success as an anytime approximation method, on the other. The proposed Iterative Join-graph Propagation (IJGP) belongs to the class of generalized belief propagation methods, recently proposed using analogy with algorithms in statistical physics. Empirical evaluation of this approach on a number of problem classes demonstrates that even the most time-efficient variant is almost always superior to IBP and MC(i), and is sometimes more accurate by as much as several orders of magnitude.

#index 1650362
#* An information-theoretic external cluster-validity measure
#@ Byron E. Dom
#t 2002
#c 12
#% 36672
#% 115608
#% 626387
#! In this paper we propose a measure of similarity/ association between two partitions of a set of objects. Our motivation is the desire to use the measure to characterize the quality or accuracy of clustering algorithms by somehow comparing the clusters they produce with "ground truth" consisting of classes assigned by manual means or some other means in whose veracity there is confidence. Such measures are referred to as "external". Our measure also allows clusterings with different numbers of clusters to be compared in a quantitative and principled way. Our evaluation scheme quantitatively measures how useful the cluster labels are as predictors of their class labels. It computes the reduction in the number of bits that would be required to encode (comress) the class labels if both the encoder and decoder have free access to the cluster labels. To achieve this encoding the estimated conditional probabilities of the class labels given the cluster labels must also be encoded. In addition to defining the measure we compare it to other commonly used external measures and demonstrate its superiority as judged by certain criteria.

#index 1650363
#* Causes and explanations in the structural-model approach
#@ Thomas Eiter;Thomas Lukasiewicz
#t 2002
#c 12
#% 44876
#% 160190
#% 243712
#% 243717
#% 289948
#% 297171
#% 366370
#% 496256
#% 528334
#% 564806
#% 578737
#% 1271819
#% 1289151
#% 1289152
#% 1477149
#% 1477321
#% 1478800
#% 1650703
#! In this paper, we continue our research on the algorithmic aspects of Halpern and Pearl's causes and explanations in the structural-model approach. To this end, we present new characterizations of weak causes for certain classes of causal models, which show that under suitable restrictions deciding causes and explanations is tractable. To our knowledge, these are the first explicit tractability results for the structural model approach.

#index 1650364
#* The thing that we tried didn't work very well: deictic representation in reinforcement learning
#@ Sarah Finney;Natalia H. Gardiol;Leslie Pack Kaelbling;Tim Oates
#t 2002
#c 12
#% 111440
#% 124687
#% 131357
#% 333786
#% 393786
#% 578686
#% 702594
#% 1469385
#% 1650314
#! Most reinforcement learning methods operate on propositional representations of the world state. Such representations are often intractably large and generalize poorly. Using a deictic representation is believed to be a viable alternative: they promise generalization while allowing the use of existing reinforcement-learning methods. Yet, there are few experiments on learning with deictic representations reported in the literature. In this paper we explore the effectiveness of two forms of deictic representation and a naïve propositional representation in a simple blocks-world domain. We find, empirically, that the deictic representations actually worsen learning performance. We conclude with a discussion of possible causes of these results and strategies for more effective learning in domains with objects.

#index 1650365
#* Factorization of discrete probability distributions
#@ Dan Geiger;Christopher Meek;Bernd Sturmfels
#t 2002
#c 12
#% 44876
#! We formulate necessary and sufficient conditions for an arbitrary discrete probability distribution to factor according to an undirected graphical model, or a log-linear model, or other more general exponential models. This result generalizes the well known Hammersley-Clifford Theorem.

#index 1650366
#* Statistical decisions using likelihood information without prior probabilities
#@ Phan H. Giang;Prakash P. Shenoy
#t 2002
#c 12
#% 116624
#% 130021
#% 528024
#% 528313
#! This paper presents a decision-theoretic approach to statistical inference that satisfies the Likelihood Principle (LP) without using prior information. Unlike the Bayesian approach, which also satisfies LP, we do not assume knowledge of the prior distribution of the unknown parameter. With respect to information that can be obtained from an experiment, our solution is more efficient than Wald's minimax solution. However, with respect to information assumed to be known before the experiment, our solution demands less input than the Bayesian solution.

#index 1650367
#* Reduction of maximum entropy models to hidden markov models
#@ Joshua Goodman
#t 2002
#c 12
#% 226495
#% 466892
#% 647092
#% 742399
#% 747788
#% 815129
#% 1478844
#! We show that maximum entropy (maxent) models can be modeled with certain kinds of HMMs, allowing us to construct maxent models with hidden variables, hidden state sequences, or other characteristics. The models can be trained using the forward-backward algorithm. While the results are primarily of theoretical interest, unifying apparently unrelated concepts, we also give experimental results for a maxent model with a hidden variable on a word disambiguation task; the model outperforms standard techniques.

#index 1650368
#* Updating probabilities
#@ Peter D. Grünwald;Joseph Y. Halpern
#t 2002
#c 12
#% 74868
#% 115608
#% 137786
#% 243704
#% 563117
#% 1272393
#% 1650720
#! As examples such as the Monty Hall puzzle show, applying conditioning to update a probability distribution on a "naive space", which does not take into account the protocol used, can often lead to counterintuitive results. Here we examine why. A criterion known as CAR ("coarsening at random") in the statistical literature characterizes when "naive" conditioning in a naive space works. We show that the CAR condition holds rather infrequently. We then consider more generalized notions of update such as Jeffrey conditioning and minimizing relative entropy (MRE). We give a generalization of the CAR condition that characterizes when Jeffrey conditioning leads to appropriate answers, but show that there are no such conditions for MRE. This generalizes and interconnects previous results obtained in the literature on CAR and MRE.

#index 1650369
#* Distributed planning in hierarchical factored MDPs
#@ Carlos Guestrin;Geoffrey Gordon
#t 2002
#c 12
#% 75936
#% 265807
#% 272662
#% 272665
#% 286423
#% 363744
#% 565532
#% 1271827
#% 1273919
#% 1290043
#% 1650589
#% 1650731
#! We present a principled and efficient planning algorithm for collaborative multiagent dynamical systems. All computation, during both the planning and the execution phases, is distributed among the agents; each agent only needs to model and plan for a small part of the system. Each of these local subsystems is small, but once they are combined they can represent an exponentially larger problem. The subsystems are connected through a subsystem hierarchy. Coordination and communication between the agents is not imposed, but derived directly from the structure of this hierarchy. A globally consistent plan is achieved by a message passing algorithm, where messages correspond to natural local reward functions and are computed by local linear programs; another message passing algorithm allows us to execute the resulting policy. When two portions of the hierarchy share the same structure, our algorithm can reuse plans and messages to speed up computation.

#index 1650370
#* Reasoning about expectation
#@ Joseph Y. Halpern;Riccardo Pucella
#t 2002
#c 12
#% 31237
#% 73571
#% 74868
#% 528172
#% 729449
#! Expectation is a central notion in probability theory. The notion of expectation also makes sense for other notions of uncertainty. We introduce a propositional logic for reasoning about expectation, where the semantics depends on the underlying representation of uncertainty. We give sound and complete axiomatizations for the logic in the case that the underlying representation is (a) probability, (b) sets of probability measures, (c) belief functions, and (d) possibility measures. We show that this logic is more expressive than the corresponding logic for reasoning about likelihood in the case of sets of probability measures, but equi-expressive in the case of probability, belief, and possibility. Finally, we show that satisfiability for these logics is NP-complete, no harder than satisfiability for propositional logic.

#index 1650371
#* Expectation propagation for approximate inference in dynamic bayesian networks
#@ Tom Heskes;Onno Zoeter
#t 2002
#c 12
#% 44876
#% 246836
#% 272401
#% 424851
#% 450290
#% 528327
#% 528330
#% 528340
#% 857094
#% 1650318
#% 1650568
#% 1810385
#! We describe expectation propagation for approximate inference in dynamic Bayesian networks as a natural extension of Pearl's exact belief propagation. Expectation propagation is a greedy algorithm, converges in many practical cases, but not always. We derive a double-loop algorithm, guaranteed to converge to a local minimum of a Bethe free energy. Furthermore, we show that stable fixed points of (damped) expectation propagation correspond to local minima of this free energy, but that the converse need not be the case. We illustrate the algorithms by applying t,hem to switching linear dynamical systems and discuss implications for approximate inference in general Bayesian networks.

#index 1650372
#* Coordinate: probabilistic forecasting of presence and availability
#@ Eric Horvitz;Paul Koch;Carl M. Kadie;Andy Jacobs
#t 2002
#c 12
#% 87520
#% 159108
#% 272745
#% 272793
#% 320854
#% 1650300
#% 1650593
#% 1650705
#! We present methods employed in COORDINATE, a prototype service that supports collaboration and communication by learning predictive models that provide forecasts of users' presence and availability. We describe how data is collected about user activity and proximity from multiple devices, in addition to analysis of the content of users' calendars, the time of day, and day of week. We review applications of presence forecasting embedded in the PRIORITIES application and then present details of the COORDINATE service that was informed by the earlier efforts.

#index 1650373
#* Unconstrained influence diagrams
#@ Finn V. Jensen;Marta Vomlelová
#t 2002
#c 12
#% 34262
#% 119308
#% 204851
#% 528001
#% 739074
#% 1650309
#% 1650322
#% 1650620
#! We extend the language of influence diagrams to cope with decision scenarios where the order of decisions and observations is not determined. As the ordering of decisions is dependent on the evidence, a step-strategy of such a scenario is a sequence of dependent choices of the next action. A strategy is a step-strategy together with selection functions for decision actions. The structure of a step-strategy can be represented as a DAG with nodes labeled with action variables. We introduce the concept of GS-DAG: a DAG incurporating an optimal step-strategy for any instantiation. We give a method for constructing GS-DAGs, and we show how to use a GS-DAG for determining an optimal strategy. Finally we discuss how analysis of relevant past can be used to reduce the size of the GS-DAG.

#index 1650374
#* CFW: a collaborative filtering system using posteriors over weights of evidence
#@ Carl M. Kadie;Christopher Meek;David Heckerman
#t 2002
#c 12
#% 173879
#% 330687
#% 722754
#% 1650569
#! We describe CFW, a computationally efficient algorithm for collaborative filtering that uses posteriors over weights of evidence. In experiments on real data, we show that this method predicts as well or better than other methods in situations where the size of the user query is small. The new approach works particularly well when the user's query contains low frequency (unpopular) items. The approach complements that of dependency networks which perform well when the size of the query is large. Also in this paper, we argue that the use of posteriors over weights of evidence is a natural way to recommend similar items--a task that is somewhat different from the usual collaborative-filtering task.

#index 1650375
#* A bayesian network scoring metric that is based on globally uniform parameter priors
#@ Mehmet Kayaalp;Gregory F. Cooper
#t 2002
#c 12
#% 101213
#% 101217
#% 129987
#% 197387
#! We introduce a new Bayesian network (BN) scoring metric called the Global Uniform (GU) metric. This metric is based on a particular type of default parameter prior. Such priors may be useful when a BN developer is not willing or able to specify domain-specific parameter priors. The GU parameter prior specifies that every prior joint probability distribution P consistent with a BN structure S is considered to be equally likely. Distribution P is consistent with S if P includes just the set of independence relations defined by S. We show that the GU metric addresses some undesirable behavior of the BDeu and K2 Bayesian network scoring metrics, which also use particular forms of default parameter priors. A closed form formula for computing GU for special classes of BNs is derived. Efficiently computing GU for an arbitrary BN remains an open problem.

#index 1650376
#* Efficient nash computation in large population games with bounded influence
#@ Michael Kearns;Yishay Mansour
#t 2002
#c 12
#% 567883
#% 578708
#! We introduce a general representation of large-population games in which each player's influence on the others is centralized and limited, but may otherwise be arbitrary. This representation significantly generalizes the class known as congestion games in a natural way. Our main results are provably correct and efficient algorithms for computing and learning approximate Nash equilibria in this general framework.

#index 1650377
#* Dimension correction for hierarchical latent class models
#@ Tomáš Kočka;Nevin L. Zhang
#t 2002
#c 12
#% 129987
#% 232117
#% 246834
#% 578691
#% 1650619
#% 1650786
#! Model complexity is an important factor to consider when selecting among graphical models. When all variables are observed, the complexity of a model can be measured by its standard dimension, i.e. the number of independent parameters. When hidden variables are present, however, standard dimension might no longer be appropriate. One should instead use effective dimension (Geiger et al. 1996). This paper is concerned with the computation of effective dimension. First we present an upper bound on the effective dimension of a latent class (LC) model. This bound is tight and its computation is easy. We then consider a generalization of LC models called hierarchical latent class (HLC) models (Zhang 2002). We show that the effective dimension of an HLC model can be obtained from the effective dimensions of some related LC models. We also demonstrate empirically that using effective dimension in place of standard dimension improves the quality of models learned from data.

#index 1650378
#* Almost-everywhere algorithmic stability and generalization error
#@ Samuel Kutin;Partha Niyogi
#t 2002
#c 12
#% 235377
#% 296521
#% 722805
#! We explore in some detail the notion of algorithmic stability as a viable framework for analyzing the generalization error of learning algorithms. We introduce the new notion of training stability of a learning algorithm and show that, in a general setting, it is sufficient for good bounds on generalization error. In the PAC setting, training stability is both necessary and sufficient for learnability. The approach based on training stability makes no reference to VC dimension or VC entropy. There is no need to prove uniform convergence, and generalization error is bounded directly via an extended McDiarmid inequality. As a result it potentially allows us to deal with a broader class of learning algorithms than Empirical Risk Minimization. We also explore the relationships among VC dimension, generalization error, and various notions of stability. Several examples of learning algorithms are considered.

#index 1650379
#* Value function approximation in zero-sum markov games
#@ Michail G. Lagoudakis;Ronald Parr
#t 2002
#c 12
#% 203596
#% 304312
#% 393786
#% 400877
#% 449561
#% 527994
#% 707761
#% 1289288
#! This paper investigates value function approximation in the context of zero-sum Markov games, which can be viewed as a generalization of the Markov decision process (MDP) framework to the two-agent case. We generalize error bounds from MDPs to Markov games and describe generalizations of reinforcement learning algorithms to Markov games. We present a generalization of the optimal stopping problem to a two-player simultaneous move Markov game. For this special problem, we provide stronger bounds and can guarantee convergence for LSTD and temporal difference learning with linear value function approximation. We demonstrate the viability of value function approximation for Markov games by using the Least squares policy iteration (LSPI) algorithm to learn good policies for a soccer domain and a flow control problem.

#index 1650380
#* Computer generated higher order expansions
#@ Martijn A. R. Leisink;Hilbert J. Kappen
#t 2002
#c 12
#% 855575
#% 1650793
#! In this article we show the rough outline of a computer algorithm to generate lower bounds on the exponential function of (in principle) arbitrary precision. We implemented this to generate all necessary analytic terms for the Boltzmann machine partition function thus leading to lower bounds of any order. It turns out that the extra variational parameters can be optimized analytically. We show that bounds upto nineth order are still reasonably calculable in practical situations. The generated terms can also be used as extra correction terms (beyond TAP)in mean field expansions.

#index 1650381
#* Monitoring a complex physical system using a hybrid dynamic bayes net
#@ Uri Lerner;Brooks Moses;Maricia Scott;Sheila McIlraith;Daphne Koller
#t 2002
#c 12
#% 75936
#% 394009
#% 424819
#% 528327
#% 529185
#% 757953
#% 1650731
#! The Reverse Water Gas Shift system (RWGS) is a complex physical system designed to produce oxygen from the carbon dioxide atmosphere on Mars. If sent to Mars, it would operate without human supervision, thus requiring a reliable automated system for monitoring and control. The RWGS presents many challenges typical of real-world systems, including: noisy and biased sensors, nonlinear behavior, effects that are manifested over different time granularities, and unobservability of many important quantities. In this paper we model the RWGS using a hybrid (discrete/continuous) Dynamic Bayesian Network (DBN), where the state at each time slice contains 33 discrete and 184 continuous variables. We show how the system state can be tracked using probabilistic inference over the model. We discuss how to deal with the various challenges presented by the RWGS, providing a suite of techniques that are likely to be useful in a wide range of applications. In particular, we describe a general framework for dealing with nonlinear behavior using numerical integration techniques, extending the successful Unscented Filter. We also show how to use a fixed-point computation to deal with effects that develop at different time scales, specifically rapid changes occurring during slowly changing processes. We test our model using real data collected from the RWGS, demonstrating the feasibility of hybrid DBNs for monitoring complex real-world physical systems.

#index 1650382
#* Polynomial value iteration algorithms for deterministic MDPs
#@ Omid Madani
#t 2002
#c 12
#% 122671
#% 174161
#% 205422
#% 578697
#% 703709
#% 707796
#% 1289239
#% 1837909
#! Value iteration is a commonly used and empirically competitive method in solving many Markov decision process problems. However, it is known that value iteration has only pseudopolynomial complexity in general. We establish a somewhat surprising polynomial bound for value iteration on deterministic Markov decision (DMDP) problems. We show that the basic value iteration procedure converges to the highest average reward cycle on a DMDP problem in θ(n2) iterations, or θ(mn2) total time, where n denotes the number of states, and m the number of edges. We give two extensions of value iteration that solve the DMDP in θ(mn) time. We explore the analysis of policy iteration algorithms and report on an empirical study of value iteration showing that its convergence is much faster on random sparse graphs.

#index 1650383
#* Decayed MCMC iltering
#@ Bhaskara Marthi;Hanna Pasula;Stuart Russell;Yuval Peres
#t 2002
#c 12
#% 44876
#% 217824
#% 246836
#% 528330
#% 593790
#% 1650568
#% 1757273
#! Filtering--estimating the state of a partially observable Markov process from a sequence of observations-is one of the most widely studied problems in control theory, AI, and computational statistics. Exact computation of the posterior distribution is generally intractable for large discrete systems and for nonlinear continuous systems, so a good deal of effort has gone into developing robust approximation algorithms. This paper describes a simple stochastic approximation algorithm for filtering called decayed MCMC. The algorithm applies Markov chain Monte Carlo sampling to the space of state trajectories using a proposal distribution that favours flips of more recent state variables. The formal analysis of the algorithm involves a generalization of standard coupling arguments for MCMC convergence. We prove that for any ergodic underlying Markov process, the convergence time of decayed MCMC with inversepolynomial decay remains bounded as the length of the observation sequence grows. We show experimentally that decayed MCMC is at least competitive with other approximation algorithms such as particle filtering.

#index 1650384
#* Formalizing scenario analysis
#@ Peter McBurney;Simon Parsons
#t 2002
#c 12
#% 155817
#% 216970
#% 277915
#% 417752
#% 528009
#% 564806
#% 743452
#! We propose a formal treatment of scenarios in the context of a dialectical argumentation formalism for qualitative reasoning about uncertain propositions. Our formalism extends prior work in which arguments for and against uncertain propositions were presented and compared in interaction spaces called Agoras. We now define the notion of a scenario in this framework and use it to define a set of qualitative uncertainty labels for propositions across a collection of scenarios. This work is intended to lead to a formal theory of scenarios and scenario analysis.

#index 1650385
#* Staged mixture modelling and boosting
#@ Christopher Meek;Bo Thiesson;David Heckerman
#t 2002
#c 12
#% 235377
#% 465762
#% 466662
#% 722753
#% 1650705
#% 1860128
#! In this paper, we introduce and evaluate a data-driven staged mixture modeling tcchnique for building density, regression, and classification models. Our basic approach is to sequentially add components to a finite mixture model using the structural expectation maximization (SEM) algorithm. We show that our technique is qualitatively similar to boosting. This correspondence is a natural byproduct of the fact that we use the SEM algorithm to sequentially fit the mixture model. Finally, in our experimental evaluation, we demonstrate the effectiveness of our approach on a variety of prediction and density estimation tasks using real-world data.

#index 1650386
#* Optimal time bounds for approximate clustering
#@ Ramgopal R. Mettu;C. Greg Plaxton
#t 2002
#c 12
#% 190611
#% 271130
#% 271236
#% 279755
#% 325357
#% 338392
#% 347263
#% 492449
#% 593913
#% 593926
#% 594010
#% 594012
#% 746518
#! Clustering is a fundamental problem in unsupervised learning, and has been studied widely both as a problem of learning mixture models and as an optimization problem. In this paper, we study clustering with respect the k-median objective function, a natural formulation of clustering in which we attempt to minimize the average distance to cluster centers. One of the main contributions of this paper is a simple but powerful sampling technique that we call successive sampling that could be of independent interest. We show that our sampling procedure can rapidly identify a small set of points (of size just O(klogn/k)) that summarize the input points for the purpose of clustering. Using successive sampling, we develop an algorithm for the k-median problem that runs in O(nk) time for a wide range of values of k and is guaranteed, with high probability, to return a solution with cost at most a constant factor times optimal. We also establish a lower bound of Ω(nk) on any randomized constant-factor approximation algorithm for the k-median problem that succeeds with even a negligible (say 1/100) probability. The best previous upper bound for the problem was Õ(nk), where the Õ-notation hides polylogarithmic factors in n and k. The best previous lower bound of Ω(nk) applied only to deterministic k-median algorithms. While we focus our presentation on the k-median objective, all our upper bounds are valid for the k-means objective as well. In this context our algorithm compares favorably to the widely used k-means heuristic, which requires O(nk) time for just one iteration and provides no useful approximation guarantees.

#index 1650387
#* Expectation-propagation for the generative aspect model
#@ Thomas Minka;John Lafferty
#t 2002
#c 12
#% 715096
#% 1650298
#! The generative aspect model is an extension of the multinomial model for text that allows word probabilities to vary stochastically across documents. Previous results with aspect models have been promising, but hindered by the computational difficulty of carrying out inference and learning. This paper demonstrates that the simple variational methods of Blei et al. (2001) can lead to inaccurate inferences and biased learning for the generative aspect model. We develop an alternative approach that leads to higher accuracy at comparable cost. An extension of Expectation-Propagation is used for inference and then embedded in an EM algorithm for learning. Experimental results are presented for both synthetic and real data sets.

#index 1650388
#* Real-valued all-dimensions search: low-overhead rapid searching over subsets of attributes
#@ Andrew Moore;Jeff Schneider
#t 2002
#c 12
#% 210160
#% 210182
#% 232136
#% 310505
#% 342640
#% 395162
#% 420112
#% 449559
#% 449566
#% 578689
#% 1272179
#% 1272326
#! This paper is about searching the combinatorial space of contingency tables during the inner loop of a nonlinear statistical optimization. Examples of this operation in various data analytic communities include searching for nonlinear combinations of attributes that contribute significantly to a regression (Statistics), searching for items to include in a decision list (machine learning) and association rule hunting (Data Mining). This paper investigates a new, efficient approach to this class of problems, called RADSEARCH (Real-valued All-Dimensions-tree Search). RADSEARCH finds the global optimum, and this gives us the opportunity to empirically evaluate the question: apart from algorithmic elegance what does this attention to optimality buy us? We compare RADSEARCH with other recent successful search algorithms such as CN2, PRIM, APriori, OPUS and DenseMiner. Finally, we introduce RADREG, a new regression algorithm for learning real-valued outputs based on RADSEARCHing for highorder interactions.

#index 1650389
#* Factored particles for scalable monitoring
#@ Brenda Ng;Leonid Peshkin;Avi Pfeffer
#t 2002
#c 12
#% 75936
#% 132583
#% 283131
#% 528169
#% 1650568
#! Exact monitoring in dynamic Bayesian networks is intractable, so approximate algorithms are necessary. This paper presents a new family of approximate monitoring algorithms that combine the best qualities of the particle filtering and Boyen-Koller methods. Our algorithms maintain an approximate representation the belief state in the form of sets of factored particles, that correspond to samples of clusters of state variables. Empirical results show that our algorithms outperform both ordinary particle filtering and the Boyen-Koller algorithm on large systems.

#index 1650390
#* Continuous time bayesian networks
#@ Uri Nodelman;Christian R. Shelton;Daphne Koller
#t 2002
#c 12
#% 44876
#% 75936
#% 1650568
#% 1650655
#! In this paper we present a language for finite state continuous time Bayesian networks (CTBNs), which describe structured stochastic processes that evolve over continuous time. The state of the system is decomposed into a set of local variables whose values change over time. The dynamics of the system are described by specifying the behavior of each local variable as a function of its parents in a directed (possibly cyclic) graph. The model specifies, at any given point in time, the distribution over two aspects: when a local variable changes its value and the next value it takes. These distributions are determined by the variable's current value and the current values of its parents in the graph. More formally, each variable is modelled as a finite state continuous time Markov process whose transition intensities are functions of its parents. We present a probabilistic semantics for the language in terms of the generative model a CTBN defines over sequences of events. We list types of queries one might ask of a CTBN, discuss the conceptual and computational difficulties associated with exact inference, and provide an algorithm for approximate inference which takes advantage of the structure within the process.

#index 1650391
#* MAP complexity results and approximation methods
#@ James D. Park
#t 2002
#c 12
#% 30037
#% 44876
#% 112014
#% 172544
#% 205391
#% 283232
#% 302413
#% 329486
#% 420743
#% 528175
#% 1272331
#% 1650318
#% 1650778
#! MAP is the problem of nding a most probable instantiation of a set of variables in a Bayesian network, given some evidence. MAP appears to be a signi cantly harder problem than the related problems of computing the probability of evidence (Pr), or MPE (a special case of MAP). Because of the complexity of MAP, and the lack of viable algorithms to approximate it, MAP computations are generally avoided by practitioners. This paper investigates the complexity of MAP. We show that MAP is complete for NPPP. We also provide negative complexity results for elimination based algorithms. It turns out that MAP remains hard even when MPE, and Pr are easy. We show that MAP is NP-complete when the networks are restricted to polytrees, and even then can not be e ectively approximated. Because there is no approximation algorithm with guaranteed results, we investigate best effort approximations. We introduce a generic MAP approximation framework. As one instantiation of it, we implement local search coupled with belief propagation (BP) to approximate MAP. We show how to extract approximate evidence retraction information from belief propagation which allows us to perform e cient local search. This allows MAP approximation even on networks that are too complex to even exactly solve the easier problems of computing Pr or MPE. Experimental results indicate that using BP and local search provides accurate MAP estimates in many cases.

#index 1650392
#* Bayesian network classifiers in a high dimensional framework
#@ Tatjana Pavlenko;Dietrich von Rosen
#t 2002
#c 12
#% 44876
#% 197387
#% 246832
#% 388024
#% 528321
#% 528331
#! We present a growing dimension asymptotic formalism. The perspective in this paper is classification theory and we show that it can accommodate probabilistic networks classifiers, including naive Bayes model and its augmented version. When represented as a Bayesian network these classifiers have an important advantage: The corresponding discriminant function turns out to be a specialized case of a generalized additive model, which makes it possible to get closed form expressions for the asymptotic misclassification probabilities used here as a measure of classification accuracy. Moreover, in this paper we propose a new quantity for assessing t,he discriminative power of a set, of features which is then used to elaborate the augmented naive Bayes classifier. The result is a weighted form of the augmented naive Bayes that distributes weights among the sets of features according to their discriminative power. We derive the asymptotic distribution of the sample based discriminative power and show that it is seriously overestimated in a high dimensional case. We then apply this result, to find the optimal, in a sense of minimum misclassification probability, type of weighting.

#index 1650393
#* Modeling information incorporation in markets, with application to detecting and explaining events
#@ David M. Pennock;Sandip Debnath;Eric J. Glover;C. Lee Giles
#t 2002
#c 12
#% 342608
#% 615723
#! We develop a model of how information flows into a market, and derive algorithms for automatically detecting and explaining relevant events. We analyze data from twenty-two "political stock markets" (i.e., betting markets on political outcomes) on the Iowa Electronic Market (IEM). We prove that, under certain efficiency assumptions, prices in such betting markets will on average approach the correct outcomes over time, and show that IEM data conforms closely to the theory. We present a simple model of a betting market where information is revealed over time, and show a qualitative correspondence between the model and real market data. We also present an algorithm for automatically detecting significant events and generating semantic explanations of their origin. The algorithm operates by discovering significant changes in vocabulary on online news sources (using expected entropy loss) that align with major price spikes in related betting markets.

#index 1650394
#* Mechanism design with execution uncertainty
#@ Ryan Porter;Amir Ronen;Yoav Shoham;Moshe Tennenholtz
#t 2002
#c 12
#% 233131
#% 529651
#% 1289296
#! We introduce the notion of fault tolerant mechanism design, which extends the standard game theoretic framework of mechanism design to allow for uncertainty about execution. Specifically, we define the problem of task allocation in which the private information of the agents is not only their costs to attempt the tasks, but also their probabilities of failure. For several different instances of this setting we present technical results, including positive ones in the form of mechanisms that are incentive compatible, individually rational and efficient, and negative ones in the form of impossibility theorems.

#index 1650395
#* From qualitative to quantitative probabilistic networks
#@ Silja Renooij;Linda C. van der Gaag
#t 2002
#c 12
#% 44876
#% 89748
#% 443356
#% 564806
#% 1478675
#% 1650338
#% 1650603
#! Quantification is well known to be a major obstacle in the construction of a probabilistic network, especially when relying on human experts for this purpose. The construction of a qualitative probabilistic network has been proposed as an initial step in a network's quantification, since the qualitative network can be used to gain preliminary insight in the projected network's reasoning behaviour. We extend on this idea and present a new type of network in which both signs and numbers are specified; we further present an associated algorithm for probabilistic inference. Building upon these semi-qualitative networks, a probabilistic network can be quantified and studied in a stepwise manner. As a result, modelling inadequacies can be detected and amended at an early stage in the quantification process.

#index 1650396
#* Inference with separately specified sets of probabilities in credal networks
#@ José Carlos Ferreira da Rocha;Fabio Gagliardi Cozman
#t 2002
#c 12
#% 44876
#% 170207
#% 267725
#% 319172
#% 417800
#% 528010
#% 528327
#% 1650640
#! We present new algorithms for inference in credal networks -- directed acyclic graphs associated with sets of probabilities. Credal networks are here interpreted as encoding strong independence relations among variables. We first present a theory of credal networks based on separately specified sets of probabilities. We also show that inference with polytrees is NP-hard in this setting. We then introduce new techniques that reduce the computational effort demanded by inference, particularly in polytrees, by exploring separability of credal sets.

#index 1650397
#* Asymptotic model selection for naive Bayesian networks
#@ Dmitry Rusakov;Dan Geiger
#t 2002
#c 12
#% 44876
#% 129987
#% 197387
#% 856208
#% 1650619
#% 1650786
#! We develop a closed form asymptotic formula to compute the marginal likelihood of data given a naive Bayesian network model with two hidden states and binary features. This formula deviates from the standard BIC score. Our work provides a concrete example that the BIC score is generally not valid for statistical models that belong to a stratified exponential family. This stands in contrast to linear and curved exponential families, where the BIC score has been proven to provide a correct approximation for the marginal likelihood.

#index 1650398
#* Advances in boosting
#@ Robert E. Schapire
#t 2002
#c 12
#% 697
#% 73372
#% 157162
#% 170649
#% 198701
#% 226495
#% 235377
#% 236729
#% 276509
#% 276511
#% 299255
#% 302391
#% 311034
#% 425065
#% 464454
#% 464465
#% 558918
#% 722756
#! Boosting is a general method of generating many simple classification rules and combining them into a single, highly accurate rule. This paper reviews the AdaBoost boosting algorithm and some of its underlying theory, and then looks at some of the challenges of applying AdaBoost to bidding in complicated auctions and to human-computer spoken-dialogues systems.

#index 1650399
#* An MDP-based recommender system
#@ Guy Shani;Ronen I. Brafman;David Heckerman
#t 2002
#c 12
#% 301590
#% 314933
#% 316139
#% 528337
#% 702594
#% 722754
#% 1650569
#! Typical Recommender systems adopt a static view of the recommendation process and treat it as a prediction problem. We argue that it is more appropriate to view the problem of generating recommendations as a sequential decision problem and, consequently, that Markov decision processes (MDP) provide a more appropriate model for Recommender systems. MDPs introduce two benefits: they take into account the long-term effects of each recommendation, and they take into account the expected value of each recommendation. To succeed in practice, an MDP-based Recommender system must employ a strong initial model; and the bulk of this paper is concerned with the generation of such a model. In particular, we suggest the use of an n-gram predictive model for generating the initial MDP. Our n-gram model induces a Markovchain model of user behavior whose predictive accuracy is greater than that of existing predictive models. We describe our predictive model in detail and evaluate its performance on real data. In addition, we show how the model can be used in an MDP-based Recommender system.

#index 1650400
#* Reinforcement learning with partially known world dynamics
#@ Christian R. Shelton
#t 2002
#c 12
#% 124687
#% 203611
#% 374580
#% 464438
#% 464609
#% 466230
#% 466739
#% 466751
#% 466923
#% 528322
#% 563107
#% 703709
#% 706874
#% 711673
#% 1271827
#% 1289239
#! Reinforcement learning would enjoy better success on real-world problems if domain knowledge could be imparted to the algorithm by the modelers. Most problems have both hidden state and unknown dynamics. Partially observable Markov decision processes (POMDPs) allow for the modeling of both. Unfortunately, they do not provide a natural framework in which to specify knowledge about the domain dynamics. The designer must either admit to knowing nothing about the dynamics or completely specify the dynamics (thereby turning it into a planning problem). We propose a new framework called a partially known Markov decision process (PKMDP) which allows the designer to specify known dynamics while still leaving portions of the environment's dynamics unknown. The model represents not only the environment dynamics but also the agent's knowledge of the dynamics. We present a reinforcement learning algorithm for this model based on importance sampling. The algorithm incorporates planning based on the known dynamics and learning about the unknown dynamics. Our results clearly demonstrate the ability to add domain knowledge and the resulting benefits for learning.

#index 1650401
#* Unsupervised active learning in large domains
#@ Harald Steck;Tommi S. Jaakkola
#t 2002
#c 12
#% 236729
#% 269194
#% 1650279
#% 1650288
#! Active learning is a powerful approach to analyzing data effectively. We show that the feasibility of active learning depends crucially on the choice of measure with respect to which the query is being optimized. The standard information gain, for example, does not permit an accurate evaluation with a small committee, a representative subset of the model space. We propose a surrogate measure requiring only a small committec and discuss the properties of this new measure. We devise, in addition, a bootstrap approach for committee selection. The advantages of this approach are illustrated in the context of recovering (regulatory) network models.

#index 1650402
#* Real-time inference with large-scale temporal bayes nets
#@ Masami Takikawa;Bruce D'Ambrosio;Ed Wright
#t 2002
#c 12
#% 44876
#% 174161
#% 265806
#% 1272302
#% 1272308
#% 1477089
#% 1650335
#! An increasing number of applications require real-time reasoning under uncertainty with streaming input. The temporal (dynamic) Bayes net formalism provides a powerful representational framework for such applications. However, existing exact inference algorithms for dynamic Bayes nets do not scale to the size of models required for real world applications which often contain hundreds or even thousands of variables for each time slice. In addition, existing algorithms were not developed with real-time processing in mind. We have developed a new computational approach to support real-time exact inference in large temporal Bayes nets. Our approach tackles scalability by recognizing that the complexity of the inference depends on the number of interface nodes between time slices and by exploiting the distinction between static and dynamic nodes in order to reduce the number of interface nodes and to factorize their joint probability distribution. We approach the real-time issue by organizing temporal Bayes nets into static representations, and then using the symbolic probabilistic inference algorithm to derive analytic expressions for the static representations. The parts of these expressions that do not change at each time step are pre-computed. The remaining parts are compiled into efficient procedural code so that the memory and CPU resources required by the inference are small and fixed.

#index 1650403
#* Discriminative probabilistic models for relational data
#@ Ben Taskar;Pieter Abbeel;Daphne Koller
#t 2002
#c 12
#% 44876
#% 190581
#% 226495
#% 248810
#% 266215
#% 266230
#% 290830
#% 430761
#% 464434
#% 466263
#% 466896
#% 496116
#% 1289267
#% 1650318
#! In many supervised learning tasks, the entities to be labeled are related to each other in complex ways and their labels are not independent. For example, in hypertext classification, the labels of linked pages are highly correlated. A standard approach is to classify each entity independently, ignoring the correlations between them. Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach. First, undirected models do not impose the acyclicity constraint that hinders representation of many important relational dependencies in directed models. Second, undirected models are well suited for discriminative training, where we optimize the conditional likelihood of the labels given the features, which generally improves classification accuracy. We show how to train these models effectively, and how to use approximate probabilistic inference over the learned model for collective classification of multiple related entities. We provide experimental results on a webpage classification task, showing that accuracy can be significantly improved by modeling relational dependencies.

#index 1650404
#* Loopy belief propagation and Gibbs measures
#@ Sekhar C. Tatikonda;Michael I. Jordan
#t 2002
#c 12
#% 380725
#% 857454
#! We address the question of convergence in the loopy belief propagation (LBP) algorithm. Specifically, we relate convergence of LBP to the existence of a weak limit for a sequence of Gibbs measures defined on the LBP's associated computation tree. Using tools from the theory of Gibbs measures we develop easily testable sufficient conditions for convergence. The failure of convergence of LBP implies the existence of multiple phases for the associated Gibbs specification. These results give new insight into the mechanics of the algorithm.

#index 1650405
#* Anytime state-based solution methods for decision processes with non-Markovian rewards
#@ Sylvie Thiébaux;Froduald Kabanza;John Slaney
#t 2002
#c 12
#% 68238
#% 100138
#% 189636
#% 194647
#% 194652
#% 296170
#% 314843
#% 337981
#% 417597
#% 578723
#% 1289213
#% 1291498
#% 1476293
#% 1478747
#% 1650297
#! A popular approach to solving a decision process with non-Markovian rewards (NMRDP) is to exploit a compact representation of the reward function to automatically translate the NMRDP into an equivalent Markov decision process (MDP) amenable to our favorite MDP solution method. The contribution of this paper is a representation of non-Markovian reward functions and a translation into MDP aimed at making the best possible use of state-based anytime algorithms as the solution method. By explicitly constructing and exploring only parts of the state space, these algorithms are able to trade computation time for policy quality, and have proven quite effective in dealing with large MDPs. Our representation extends future linear temporal logic (FLTL) to express rewards. Our translation has the effect of embedding modelchecking in the solution method. It results in an MDP of the minimal size achievable without stepping outside the anytime framework, and consequently in better policies by the deadline.

#index 1650406
#* Particle filters in robotics
#@ Sebastian Thrun
#t 2002
#c 12
#% 44876
#% 82083
#% 126193
#% 211908
#% 266616
#% 290714
#% 337494
#% 380686
#% 389693
#% 418730
#% 469837
#% 470933
#% 528169
#% 578742
#% 578744
#% 1042865
#% 1290265
#% 1650568
#% 1650666
#! In recent years, particle filters have solved several hard perceptual problems in robotics. Early successes of particle filters were limited to low-dimensional estimation problems, such as the problem of robot localization in environments with known maps. More recently, researchers have begun exploiting structural properties of robotic domains that have led to successful particle filter applications in spaces with as many as 100,000 dimensions. The fact that every model--no mater how detailed--fails to capture the full complexity of even the most simple robotic environments has lead to specific tricks and techniques essential for the success of particle filters in robotic domains. This article surveys some of these recent innovations, and provides pointers to in-depth articles on the use of particle filters in robotics.

#index 1650407
#* On the testable implications of causal models with hidden variables
#@ Jin Tian;Judea Pearl
#t 2002
#c 12
#% 44876
#% 527830
#% 578740
#% 710011
#% 1650291
#% 1650582
#% 1650677
#% 1650743
#! The validity of a causal model can be tested only if the model imposes constraints on the probability distribution that governs the generated data. In the presence of unmeasured variables, causal models may impose two types of constraints: conditional independencies, as read through the d-separation criterion, and functional constraints, for which no general criterion is available. This paper offers a systematic way of identifying functional constraints and, thus, facilitates the task of testing causal models as well as inferring such models from data.

#index 1650408
#* Exploiting functional dependence in bayesian network inference
#@ Jifi Vomlel
#t 2002
#c 12
#% 59918
#% 238182
#% 335982
#% 527688
#% 1272302
#% 1650335
#% 1650606
#! In this paper we propose an efficient method for Bayesian network inference in models with functional dependence. We generalize the multiplicative factorization method originally designed by Takikawa and D'Ambrosio (1999) for models with independence of causal influence. Using a hidden variable, we transform a probability potential into a product of two-dimensional potentials. The multiplicative factorization yields more efficient inference. For example, in junction tree propagation it helps to avoid large cliques. In order to keep potentials small, the number of states of the hidden variable should be minimized. We transform this problem into a combinatorial problem of minimal base in a particular space. We present an example of a computerized adaptive test, in which the factorization method is significantly more efficient than previous inference methods.

#index 1650409
#* A new class of upper bounds on the log partition function
#@ Martin J. Wainwright;Tommi S. Jaakkola;Alan S. Willsky
#t 2002
#c 12
#% 143314
#% 715096
#% 715615
#% 1650793
#! Bounds on the log partition function are important in a variety of contexts, including approximate inference, model fitting, decision theory, and large deviations analysis [11, 5, 4]. We introduce a new class of upper bounds on the log partition function, based on convex combinations of distributions in the exponential domain, that is applicable to an arbitrary undirected graphical model. In the special case of convex combinations of tree-structured distributions, we obtain a family of variational problems, similar to the Bethe free energy, but distinguished by the following desirable properties: (i) they are convex, and have a unique global minimum; and (ii) the global minimum gives an upper bound on the log partition function. The global minimum is defined by stationary conditions very similar to those defining fixed points of belief propagation (BP) or tree-based reparameterization [see 13, 14]. As with BP fixed points, the elements of the minimizing argument can be used as approximations to the marginals of the original model. The analysis described here can be extended to structures of higher treewidth (e.g., hypertrees), thereby making connections with more advanced approximations (e.g., Kikuchi and variants [15, 10]).

#index 1650410
#* Decision-principles to justify carnap's updating method and to suggest corrections of probability judgments
#@ Peter P. Wakker
#t 2002
#c 12
#% 44876
#% 116624
#% 215750
#% 739270
#% 739273
#! This paper uses decision-theoretic principles to obtain new insights into the assessment and updating of probabilities. First, a new foundation of Bayesianism is given. It does not require infinite atomless uncertainties as did Savage's classical result, and can therefore be applied to any finite Bayesian network. It neither requires linear utility as did de Finetti's classical result, and therefore allows for the empirically and normatively desirable risk aversion. Finally, by identifying and fixing utility in an elementary manner, our result can readily be applied to identify methods of probability updating. Thus, a decision-theoretic foundation is given to the computationally efficient method of inductive reasoning developed by Rudolf Carnap. Finally, recent empirical findings on probability assessments are discussed. It leads to suggestions for correcting biases in probability assessments, and for an alternative to the Dempster-Shafer belief functions that avoids the reduction to degeneracy after multiple updatings.

#index 1650411
#* Adaptive foreground and shadow detection in image sequences
#@ Yang Wang;Tele Tan
#t 2002
#c 12
#% 73572
#% 186480
#% 191603
#% 235356
#% 313937
#% 313954
#% 329472
#% 351595
#% 593665
#% 658379
#% 658970
#% 1650716
#% 1775055
#! This paper presents a novel method of foreground segmentation that distinguishes moving objects from their moving cast shadows in monocular image sequences. The models of background, edge information, and shadow are set up and adaptively updated. A Bayesian belief network is proposed to describe the relationships among the segmentation label, background, intensity, and edge information. The notion of Markov random field is used to encourage the spatial connectivity of the segmented regions. The solution is obtained by maximizing the posterior possibility density of the segmentation field.

#index 1650412
#* IPF for discrete chain factor graphs
#@ Wim Wiegerinck;Tom Heskes
#t 2002
#c 12
#% 44876
#% 130878
#% 226495
#% 266401
#% 304919
#% 380725
#% 1650633
#% 1650644
#% 1810385
#! Iterative Proportional Fitting (IPF), combined with EM, is commonly used as an algorithm for likelihood maximization in undirected graphical models. In this paper, we present two iterative algorithms that generalize upon IPF. The first one is for likelihood maximization in discrete chain factor graphs, which we define as a wide class of discrete variable models including undirected graphical models and Bayesian networks, but also chain graphs and sigmoid belief networks. The second one is for conditional likelihood maximization in standard undirected models and Bayesian networks. In both algorithms, the iteration steps are expressed in closed form. Numerical simulations show that the algorithms are competitive with state of the art methods.

#index 1650413
#* Inductive policy selection for first-order MDPs
#@ SungWook Yoon;Alan Fern;Robert Givan
#t 2002
#c 12
#% 135539
#% 194647
#% 209021
#% 289949
#% 314843
#% 333786
#% 363744
#% 449508
#% 449559
#% 544926
#% 835098
#% 1289239
#% 1289241
#% 1477388
#% 1478746
#! We select policies for large Markov Decision Processes (MDPs) with compact first-order representations. We find policies that generalize well as the number of objects in the domain grows, potentially without bound. Existing dynamic-programming approaches based on flat, propositional, or first-order representations either are impractical here or do not naturally scale as the number of objects grows without bound. We implement and evaluate an alternative approach that induces first-order policies using training data constructed by solving small problem instances using PGraphplan (Blurn & Langford, 1999). Our policies are represented as ensembles of decision lists, using a taxonomic concept language. This approach extends the work of Martin and Geffner (2000) to stochastic domains, ensemble learning, and a wider variety of problems. Empirically, we find "good" policies for several stochastic first-order MDPs that are beyond the scope of previous approaches. We also discuss the application of this work to the relational reinforcement-learning problem.

#index 1650414
#* Robust feature selection by mutual information distributions
#@ Marco Zaffalon;Marcus Hutter
#t 2002
#c 12
#% 17144
#% 44876
#% 115608
#% 136350
#% 243727
#% 246831
#% 277480
#% 290482
#% 345862
#% 385564
#% 443025
#% 652482
#% 729437
#% 817843
#! Mutual information is widely used in artificial intelligence, in a descriptive way, to measure the stochastic dependence of discrete random variables. In order to address questions such as the reliability of the empirical value, one must consider sample-to-population inferential approaches. This paper deals with the distribution of mutual information, as obtained in a Bayesian framework by a second-order Dirichlet prior distribution. The exact analytical expression for the mean and an analytical approximation of the variance are reported. Asymptotic approximations of the distribution are proposed. The results are applied to the problem of selecting features for incremental learning and classification of the naive Bayes classifier. A fast, newly defined method is shown to outperform the traditional approach based on empirical mutual information on a number of real data sets. Finally, a theoretical development is reported that allows one to efficiently extend the above methods to incomplete samples in an easy and effective way.

#index 1650415
#* Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence
#@ Craig Boutilier;Moisés Goldszmidt
#t 2000
#c 12

#index 1650416
#* A complete calculus for possibilistic logic programming with fuzzy propositional variables
#@ Teresa Alsinet;Lluís Godo
#t 2000
#c 12
#% 28052
#% 61899
#% 90725
#% 95229
#% 167544
#% 306484
#% 379636
#% 442844
#% 470500
#% 496429
#% 1273140
#% 1290144
#% 1650266
#% 1650890
#! In this paper we present a propositional logic programming language for reasoning under possibilistic uncertainty and representing vague knowledge. Formulas are represented by pairs (ϕ, α), where ϕ is a many valued proposition and α ∈ [0, 1] is a lower bound on the belief on ϕ in terms of necessity measures. Belief states are modeled by possibility distributions on the set of all manyvalued interpretations. In this framework, (i) we define a syntax and a semantics of the general underlying uncertainty logic; (ii) we provide a modus ponens-style calculus for a sublanguage of Horn-rules and we prove that it is complete for determining the maximum degree of possibilistic belief with which a fuzzy propositional variable can be entailed from a set of formulas; and finally, (iii) we show how the computation of a partial matching between fuzzy propositional variables, in terms of necessity measures for fuzzy sets, can be included in our logic programming system.

#index 1650417
#* Reversible jump MCMC simulated annealing for neural networks
#@ Christophe Andrieu;Nando de Freitas;Arnaud Doucet
#t 2000
#c 12
#% 51676
#% 132678
#% 185955
#% 266411
#% 330125
#% 360691
#% 1759150
#! We propose a novel reversible jump Markov chain Monte Carlo (MCMC) simulated annealing algorithm to optimize radial basis function (RBF) networks. This algorithm enables us to maximize the joint posterior distribution of the network parameters and the number of basis functions. It performs a global search in the joint space of the parameters and number of parameters, thereby surmounting the problem of local minima. We also show that by calibrating a Bayesian model, we can obtain the classical AIC, BIC and MDL model selection criteria within a penalized likelihood framework. Finally, we show theoretically and empirically that the algorithm converges to the modes of the full posterior distribution in an efficient way.

#index 1650418
#* Perfect tree-like Markovian distributions
#@ Ann Becker;Dan Geiger;Christopher Meek
#t 2000
#c 12
#% 44876
#! We show that if a strictly positive joint probability distribution for a set of binary random variables factors according to a tree, then vertex separation represents all and only the independence relations encoded in the distribution. The same result is shown to hold also for multivariate strictly positive normal distributions. Our proof uses a new property of conditional independence that holds for these two classes of probability distributions.

#index 1650419
#* A principled analysis of merging operations in possibilistic logic
#@ Salem Benferhat;Didier Dubois;Souhila Kaci;Henri Prade
#t 2000
#c 12
#% 167544
#% 207782
#% 459823
#% 567035
#% 1273626
#! Possibilistic logic offers a qualitative framework for representing pieces of information associated with levels of uncertainty or priority. The fusion of multiple sources information is discussed in this setting. Different classes of merging operators are considered including conjunctive, disjunctive, reinforcement, adaptive and averaging operators. Then we propose to analyse these classes in terms of postulates. This is done by first extending the postulates for merging classical bases to the case where priorities are available.

#index 1650420
#* The complexity of decentralized control of Markov decision processes
#@ Daniel S. Bernstein;Shlomo Zilberstein;Neil Immerman
#t 2000
#c 12
#% 30037
#% 215532
#% 274915
#% 280042
#% 283210
#% 283224
#% 431493
#% 527987
#% 1068423
#% 1290265
#% 1650588
#% 1650702
#! Planning for distributed agents with partial state information is considered from a decisiontheoretic perspective. We describe generalizations of both the MDP and POMDP models that allow for decentralized control. For even a small number of agents, the finite-horizon problems corresponding to both of our models are complete for nondeterministic exponential time. These complexity results illustrate a fundamental difference between centralized and decentralized control of Markov processes. In contrast to the MDP and POMDP problems, the problems we consider provably do not admit polynomialtime algorithms and most likely require doubly exponential time to solve in the worst case. We have thus provided mathematical evidence corresponding to the intuition that decentralized planning problems cannot easily be reduced to centralized problems and solved exactly using established techniques.

#index 1650421
#* Dynamic Bayesian multinets
#@ Jeff A. Bilmes
#t 2000
#c 12
#% 18378
#% 107414
#% 115608
#% 205380
#% 246832
#% 443025
#% 707089
#% 709350
#% 969466
#% 1650276
#% 1650289
#% 1650579
#% 1650580
#! In this work, dynamic Bayesian multinets are introduced where a Markov chain state at time t determines conditional independence patterns between random variables lying within a local time window surrounding t. It is shown how information-theoretic criterion functions can be used to induce sparse, discriminative, and classconditional network structures that yield an optimal approximation to the class posterior probability, and therefore are useful for the classification task. Using a new structure learning heuristic, the resulting models are tested on a medium-vocabulary isolated-word speech recognition task. It is demonstrated that these discriminatively structured dynamic Bayesian multinets, when trained in a maximum likelihood setting using EM, can outperform both HMMs and other dynamic Bayesian networks with a similar number of parameters.

#index 1650422
#* Variational relevance vector machines
#@ Christopher M. Bishop;Michael E. Tipping
#t 2000
#c 12
#% 277467
#% 277483
#% 304879
#% 424806
#% 1042718
#! The Support Vector Machine (SVM) of Vapnik [9] has become widely established as one of the leading approaches to pattern recognition and machine learning. It expresses predictions in terms of a linear combination of kernel functions centred on a subset of the training data, known as support vectors. Despite its widespread success, the SVM suffers from some important limitations, one of the most significant being that it makes point predictions rather than generating predictive distributions. Recently Tipping [8] has formulated the Relevance Vector Machine (RVM), a probabilistic model whose functional form is equivalent to the SVM. It achieves comparable recognition accuracy to the SVM, yet provides a full predictive distribution, and also requires substantially fewer kernel functions. The original treatment of the RVM relied on the use of type II maximum likelihood (the 'evidence framework') to provide point estimates of the hyperparameters which govern model sparsity. In this paper we show how the RVM can be formulated and solved within a completely Bayesian paradigm through the use of variational inference, thereby giving a posterior distribution over both parameters and hyperparameters. We demonstrate the practicality and performance of the variational RVM using both synthetic and real world examples.

#index 1650423
#* Approximately optimal monitoring of plan preconditions
#@ Craig Boutilier
#t 2000
#c 12
#% 75936
#% 102136
#% 159243
#% 179940
#% 179955
#% 695783
#% 695957
#% 1272287
#% 1275454
#% 1290041
#% 1478818
#! Monitoring plan preconditions can allow for replanning when a precondition fails, generally far in advance of the point in the plan where the precondition is relevant. However, monitoring is generally costly, and some precondition failures have a very small impact on plan quality. We formulate a model for optimal precondition monitoring, using partially-observable Markov decisions processes, and describe methods for solving this model effectively, though approximately. Specifically, we show that the single-precondition monitoring problem is generally tractable, and the multiple-precondition monitoring policies can be effectively approximated using single-precondition solutions.

#index 1650424
#* Utilities as random variables: density estimation and structure discovery
#@ Urszula Chajewska;Daphne Koller
#t 2000
#c 12
#% 232117
#% 361100
#% 529348
#% 1650628
#% 1650767
#! Decision theory does not traditionally include uncertainty over utility functions. We argue that the a person's utility value for a given outcome can be treated as we treat other domain attributes: as a random variable with a density function over its possible values. We show that we can apply statistical density estimation techniques to learn such a density function from a database of partially elicited utility functions. In particular, we define a Bayesian learning framework for this problem, assuming the distribution over utilities is a mixture of Gaussians, where the mixture components represent statistically coherent subpopulations. We can also extend our techniques to the problem of discovering generalized additivity structure in the utility functions in the population. We define a Bayesian model selection criterion for utility function structure and a search procedure over structures. The factorization of the utilities in the learned model, and the generalization obtained from density estimation, allows us to provide robust estimates of utilities using a significantly smaller number of utility elicitation questions. We experiment with our technique on synthetic utility data and on a real database of utility functions in the domain of prenatal diagnosis.

#index 1650425
#* Computational investigation of low-discrepancy sequences in simulation algorithms for Bayesian networks
#@ Jian Cheng;Marek J. Druzdzel
#t 2000
#c 12
#% 68244
#% 116388
#% 131064
#% 176697
#% 193367
#% 197850
#% 237553
#% 255915
#% 527664
#% 527691
#% 1841273
#! Monte Carlo sampling has become a major vehicle for approximate inference in Bayesian networks. In this paper, we investigate a family of related simulation approaches, known collectively as quasi-Monte Carlo methods based on deterministic low-discrepancy sequences. We first outline several theoretical aspects of deterministic low-discrepancy sequences, show three examples of such sequences, and then discuss practical issues related to applying them to belief updating in Bayesian networks. We propose an algorithm for selecting direction numbers for Sobol sequence. Our experimental results show that low-discrepancy sequences (especially Sobol sequence) significantly improve the performance of simulation algorithms in Bayesian networks compared to Monte Carlo sampling.

#index 1650426
#* A decision theoretic approach to targeted advertising
#@ David Maxwell Chickering;David Heckerman
#t 2000
#c 12
#% 1650705
#% 1650783
#! A simple advertising strategy that can be used to help increase sales of a product is to mail out special offers to selected potential customers. Because there is a cost associated with sending each offer, the optimal mailing strategy depends on both the benefit obtained from a purchase and how the offer affects the buying behavior of the customers. In this paper, we describe two methods for partitioning the potential customers into groups, and show how to perform a simple cost-benefit analysis to decide which, if any, of the groups should be targeted. In particular, we consider two decision-tree learning algorithms. The first is an "off the shelf" algorithm used to model the probability that groups of customers will buy the product. The second is a new algorithm that is similar to the first, except that for each group, it explicitly models the probability of purchase under the two mailing scenarios: (1) the mail is sent to members of that group and (2) the mail is not sent to members of that group. Using data from a real-world advertising experiment, we compare the algorithms to each other and to a naive mail-to-all strategy.

#index 1650427
#* Bayesian classification and feature selection from finite data sets
#@ Frans M. Coetzee;Steve Lawrence;C. Lee Giles
#t 2000
#c 12
#% 243727
#% 1477332
#! Feature selection aims to select the smallest subset of features for a specified level of performance. The optimal achievable classification performance on a feature subset is summarized by its Receiver Operating Curve (ROC). When infinite data is available, the Neyman-Pearson (NP) design procedure provides the most efficient way of obtaining this curve. In practice the design procedure is applied to density estimates from finite data sets. We perform a detailed statistical analysis of the resulting error propagation on finite alphabets. We show that the estimated performance curve (EPC) produced by the design procedure is arbitrarily accurate given sufficient data, independent of the size of the feature set. However, the underlying likelihood ranking procedure is highly sensitive to errors that reduces the probability that the EPC is in fact the ROC. In the worst case, guaranteeing that the EPC is equal to the ROC may require data sizes exponential in the size of the feature set. These results imply that in theory the NP design approach may only be valid for characterizing relatively small feature subsets, even when the performance of any given classifier can be estimated very accurately. We discuss the practical limitations for on-line methods that ensures that the NP procedure operates in a statistically valid region.

#index 1650428
#* A Bayesian method for causal modeling and discovery under selection
#@ Gregory F. Cooper
#t 2000
#c 12
#% 44876
#% 68244
#% 129987
#% 197387
#% 297171
#% 527667
#% 1650279
#% 1650684
#% 1650786
#! This paper describes a Bayesian method for learning causal networks using samples that were selected in a non-random manner from a population of interest. Examples of data obtained by non-random sampling include convenience samples and case-control data in which a fixed number of samples with and without some condition is collected; such data are not uncommon. The paper describes a method for combining data under selection with prior beliefs in order to derive a posterior probability for a model of the causal processes that are generating the data in the population of interest. The priors include beliefs about the nature of the nonrandom sampling procedure. Although exact application of the method would be computationally intractable for most realistic datasets. efficient suecial-case and approximation methods are discussed. Finally, the paper describes how to combine learning under selection with previous methods for learning from observational and experimental data that are obtained on random samples of the population of interest. The net result is a Bayesian methodology that supports causal modeling and discovery from a rich mixture of different types of data.

#index 1650429
#* Separation properties of sets of probability measures
#@ Fabio G. Cozman
#t 2000
#c 12
#% 3034
#% 20853
#% 44876
#% 170207
#% 267725
#% 564649
#% 1650574
#% 1650640
#% 1650708
#% 1650773
#% 1784100
#! This paper analyzes independence concepts for sets of probability measures associated with directed acyclic graphs. The paper shows that epistemic independence and the standard Markov condition violate desirable separation properties. The adoption of a contraction condition leads to d-separation but still fails to guarantee a belief separation property. To overcome this unsatisfactory situation, a strong Markov condition is proposed, based on epistemic independence. The main result is that the strong Markov condition leads to strong independence and does enforce separation properties; this result implies that (1) separation properties of Bayesian networks do extend to epistemic independence and sets of probability measures, and (2) strong independence has a clear justification based on epistemic independence and the strong Markov condition.

#index 1650430
#* Stochastic logic programs: sampling, inference and applications
#@ James Cussens
#t 2000
#c 12
#% 379345
#% 1650280
#! Algorithms for exact and approximate inference in stochastic logic programs (SLPs) are presented, based respectively, on variable elimination and importance sampling. We then show how SLPs can be used to represent prior distributions for machine learning, using (i) logic programs and (ii) Bayes net structures as examples. Drawing on existing work in statistics, we apply the Metropolis-Hasting algorithm to construct a Markov chain which samples from the posterior distribution. A Prolog implementation for this is described. We also discuss the possibility of constructing explicit representations of the posterior.

#index 1650431
#* A differential approach to inference in Bayesian networks
#@ Adnan Darwiche
#t 2000
#c 12
#% 185079
#% 380725
#% 388024
#% 405926
#% 503995
#% 1272302
#% 1272308
#% 1290046
#% 1476308
#% 1650778
#% 1784188
#! We present a new approach for inference in Bayesian networks, which is mainly based on partial differentiation. According to this approach, one compiles a Bayesian network into a multivariate polynomial and then computes the partial derivatives of this polynomial with respect to each variable. We show that once such derivatives are made available, one can compute in constant-time answers to a large class of probabilistic queries, which are central to classical inference, parameter estimation, model validation and sensitivity analysis. We present a number of complexity results relating to the compilation of such polynomials and to the computation of their partial derivatives. We argue that the combined simplicity, comprehensiveness and computational complexity of the presented framework is unique among existing frameworks for inference in Bayesian networks.

#index 1650432
#* Any-space probabilistic inference
#@ Adnan Darwiche
#t 2000
#c 12
#% 44876
#% 101510
#% 329486
#% 388024
#% 1272302
#% 1477089
#% 1650778
#% 1650779
#! We have recently introduced an any-space algorithm for exact inference in Bayesian networks, called Recursive Conditioning, RC, which allows one to trade space with time at increments of X-bytes, where X is the number of bytes needed to cache a floating point number. In this paper, we present three key extensions of RC. First, we modify the algorithm so it applies to more general factorizations of probability distributions, including (but not limited to) Bayesian network factorizations. Second, we present a forgetting mechanism which reduces the space requirements of RC considerably and then compare such requirements with those of variable elimination on a number of realistic networks, showing orders of magnitude improvements in certain cases. Third, we present a version of RC for computing maximum a posteriori hypotheses (MAP), which turns out to be the first MAP algorithm allowing a smooth time-space tradeoff. A key advantage of the presented MAP algorithm is that it does not have to start from scratch each time a new query is presented, but can reuse some of its computations across multiple queries, leading to significant savings in certain cases.

#index 1650433
#* Experiments with random projection
#@ Sanjoy Dasgupta
#t 2000
#c 12
#% 197394
#% 361100
#% 593926
#% 593928
#! Recent theoretical work has identified random projection as a promising dimensionality reduction technique for learning mixtures of Gaussians. Here we summarize these results and illustrate them by a wide variety of experiments on synthetic and real data.

#index 1650434
#* A two-round variant of EM for Gaussian mixtures
#@ Sanjoy Dasgupta;Leonard J. Schulman
#t 2000
#c 12
#% 361100
#% 593926
#% 1051482
#% 1650729
#! We show that, given data from a mixture of k well-separated spherical Gaussians in Rn, a simple two-round variant of EM will, with high probability, learn the centers of the Gaussians to near-optimal precision, if the dimension is high (n ≫ log k). We relate this to previous theoretical and empirical work on the EM algorithm.

#index 1650435
#* Minimum message length clustering using Gibbs sampling
#@ Ian Davidson
#t 2000
#c 12
#% 53981
#! The K-Means and EM algorithms are popular in clustering and mixture modeling due to their simplicity and ease of implementation. However, they have several significant limitations. Both converge to a local optimum of their respective objective functions (ignoring the uncertainty in the model space), require the apriori specification of the number of classes/clusters, and are inconsistent. In this work we overcome these limitations by using the Minimum Message Length (MML) principle and a variation to the K-Means/EM observation assignment and parameter calculation scheme. We maintain the simplicity of these approaches while constructing a Bayesian mixture modeling tool that samples/searches the model space using a Markov Chain Monte Carlo (MCMC) sampler known as a Gibbs sampler. Gibbs sampling allows us to visit each model according to its posterior probability. Therefore, if the model space is multi-modal we will visit all modes and not get stuck in local optima. We call our approach multiple chains at equilibrium (MCE) MML sampling.

#index 1650436
#* Mix-nets: factored mixtures of Gaussians in Bayesian networks with mixed continuous and discrete variables
#@ Scott Davies;Andrew Moore
#t 2000
#c 12
#% 129987
#% 197387
#% 232117
#% 246832
#% 277483
#% 277503
#% 280502
#% 304932
#% 465891
#% 465904
#% 528164
#% 1650289
#% 1650302
#% 1650611
#% 1650643
#% 1650722
#% 1650732
#% 1650756
#% 1650783
#! Recently developed techniques have made it possible to quickly learn accurate probability density functions from data in low-dimensional continuous spaces. In particular, mixtures of Gaussians can be fitted to data very quickly using an accelerated EM algorithm that employs multiresolution kd-trees (Moore, 1999). In this paper, we propose a kind of Bayesian network in which low-dimensional mixtures of Gaussians over different subsets of the domain's variables are combined into a coherent joint probability model over the entire domain. The network is also capable of modeling complex dependencies between discrete variables and continuous variables without requiring discretization of the continuous variables. We present efficient heuristic algorithms for automatically learning these networks from data, and perform comparative experiments illustrating how well these networks model real scientific data and synthetic data. We also briefly discuss some possible improvements to the networks, as well as possible applications.

#index 1650437
#* Rao-blackwellised particle filtering for dynamic Bayesian networks
#@ Arnaud Doucet;Nando de Freitas;Kevin Murphy;Stuart Russell
#t 2000
#c 12
#% 44876
#% 235061
#% 246836
#% 388024
#% 424819
#% 457558
#% 1650568
#% 1650666
#% 1650767
#! Particle filters (PFs) are powerful sampling-based inference/learning algorithms for dynamic Bayesian networks (DBNs). They allow us to treat, in a principled way, any type of probability distribution, nonlinearity and non-stationarity. They have appeared in several fields under such names as "condensation", "sequential Monte Carlo" and "survival of the fittest". In this paper, we show how we can exploit the structure of the DBN to increase the efficiency of particle filtering, using a technique known as Rao-Blackwellisation. Essentially, this samples some of the variables, and marginalizes out the rest exactly, using the Kalman filter, HMM filter, junction tree algorithm, or any other finite dimensional optimal filter. We show that Rao-Blackwellised particle filters (RBPFs) lead to more accurate estimates than standard PFs. We demonstrate RBPFs on two problems, namely non-stationary online regression with radial basis function networks and robot localization and map building. We also discuss other potential application areas and provide references to some finite dimensional optimal filters.

#index 1650438
#* Learning graphical models of images, videos and their spatial transformations
#@ Brendan J. Frey;Nebojsa Jojic
#t 2000
#c 12
#% 257039
#% 443790
#% 476717
#% 635750
#% 1860128
#! Mixtures of Gaussians, factor analyzers (probabilistic PCA) and hidden Markov models are staples of static and dynamic data modeling and image and video modeling in particular. We show how topographic transformations in the input, such as translation and shearing in images, can be accounted for in these models by including a discrete transformation variable. The resulting models perform clustering, dimensionality reduction and time-series analysis in a way that is invariant to transformations in the input. Using the EM algorithm, these transformation invariant models can be fit to static data and time series. We give results on filtering microscopy images, face and facial pose clustering, handwritten digit modeling and recognition, video clustering, object tracking, and removal of distractions from video sequences.

#index 1650439
#* Likelihood computations using value abstraction
#@ Nir Friedman;Dan Geiger;Noam Lotner
#t 2000
#c 12
#% 1272302
#% 1273913
#% 1650767
#% 1650778
#! In this paper, we use evidence-specific value abstraction for speeding Bayesian networks inference. This is done by grouping variable values and treating the combined values as a single entity. As we show, such abstractions can exploit regularities in conditional probability distributions and also the specific values of observed variables. To formally justify value abstraction, we define the notion of safe value abstraction and devise inference algorithms that use it to reduce the cost of inference. Our procedure is particularly useful for learning complex networks with many hidden variables. In such cases, repeated likelihood computations are required for EM or other parameter optimization techniques. Since these computations are repeated with respect to the same evidence set, our methods can provide significant speedup to the learning procedure. We demonstrate the algorithm on genetic linkage problems where the use of value abstraction sometimes differentiates between a feasible and non-feasible solution.

#index 1650440
#* Being Bayesian about network structure
#@ Nir Friedman;Daphne Koller
#t 2000
#c 12
#% 101213
#% 129987
#% 197387
#% 277480
#% 297490
#% 298269
#% 443025
#% 1650288
#% 1650658
#! In many domains, we are interested in analyzing the structure of the underlying distribution, e.g., whether one variable is a direct parent of the other. Bayesian model-selection attempts to find the MAP model and use its structure to answer these questions. However, when the amount of available data is modest, there might be many models that have non-negligible posterior. Thus, we want compute the Bayesian posterior of a feature, i.e., the total posterior probability of all models that contain it. In this paper, we propose a new approach for this task. We first show how to efficiently compute a sum over the exponential number of networks that are consistent with a fixed ordering over network variables. This allows us to compute, for a given ordering, both the marginal probability of the data and the posterior of a feature. We then use this result as the basis for an algorithm that approximates the Bayesian posterior of a feature. Our approach uses an Markov Chain Monte Carlo (MCMC) method, but over orderings rather than over network structures. The space of orderings is much smaller and more regular than the space of structures, and has a smoother posterior "landscape". We present empirical results on synthetic and real-life datasets that compare our approach to full model averaging (when possible), to MCMC over network structures, and to a non-Bayesian bootstrap approach.

#index 1650441
#* Gaussian process networks
#@ Nir Friedman;Iftach Nachman
#t 2000
#c 12
#% 101213
#% 101364
#% 129987
#% 185079
#% 197387
#% 232117
#% 246834
#% 246835
#% 297490
#% 369349
#% 465904
#% 528004
#% 1051482
#% 1650290
#% 1650623
#% 1650658
#% 1650738
#! In this paper we address the problem of learning the structure of a Bayesian network in domains with continuous variables. This task requires a procedure for comparing different candidate structures. In the Bayesian framework, this is done by evaluating the marginal likelihood of the data given a candidate structure. This term can be computed in closed-form for standard parametric families (e.g., Gaussians), and can be approximated, at some computational cost, for some semi-parametric families (e.g., mixtures of Gaussians). We present a new family of continuous variable probabilistic networks that are based on Gaussian Process priors. These priors are semiparametric in nature and can learn almost arbitrary noisy functional relations. Using these priors, we can directly compute marginal likelihoods for structure learning. The resulting method can discover a wide range of functional dependencies in multivariate data. We develop the Bayesian score of Gaussian Process Networks and describe how to learn them from data. We present empirical results on artificial data as well as on real-life domains with non-linear dependencies.

#index 1650442
#* A qualitative linear utility theory for Spohn's theory of epistemic beliefs
#@ Phan H. Giang;Prakash P. Shenoy
#t 2000
#c 12
#% 44876
#% 100251
#% 111942
#% 179919
#% 211580
#% 315415
#% 417568
#% 527528
#% 567872
#% 1290145
#% 1476312
#% 1478741
#% 1650578
#% 1650690
#% 1650765
#! In this paper, we formulate a qualitative "linear" utility theory for lotteries in which uncertainty is expressed qualitatively using a Spohnian disbelief function. We argue that a rational decision maker facing an uncertain decision problem in which the uncertainty is expressed qualitatively should behave so as to maximize "qualitative expected utility." Our axiomatization of the qualitative utility is similar to the axiomatization developed by von Neumann and Morgenstern for probabilistic lotteries. We compare our results with other recent results in qualitative decision making.

#index 1650443
#* Building a stochastic dynamic model of application use
#@ Peter J. Gorniak;David Poole
#t 2000
#c 12
#% 241642
#% 284823
#% 449588
#% 529818
#% 1650593
#! Many intelligent user interfaces employ application and user models to determine the user's preferences, goals and likely future actions. Such models require application analysis, adaptation and expansion. Building and maintaining such models adds a substantial amount of time and labour to the application development cycle. We present a system that observes the interface of an unmodified application and records users' interactions with the application. From a history of such observations we build a coarse state space of observed interface states and actions between them. To refine the space, we hypothesize substates based upon the histories that led users to a given state. We evaluate the information gain of possible state splits, varying the length of the histories considered in such splits. In this way, we automatically produce a stochastic dynamic model of the application and of how it is used. To evaluate our approach, we present models derived from real-world application usage data.

#index 1650444
#* Maximum entropy and the glasses you are looking through
#@ Peter Grünwald
#t 2000
#c 12
#% 115608
#% 246832
#% 1272359
#% 1290136
#% 1809072
#! We give an interpretation of the Maximum Entropy (MaxEnt) Principle in gametheoretic terms. Based on this interpretation, we make a formal distinction between different ways of applying Maximum Entropy distributions. MaxEnt has frequently been criticized on the grounds that it leads to highly representation dependent results. Our distinction allows us to avoid this problem in many cases.

#index 1650445
#* Conditional plausibility measures and Bayesian networks
#@ Joseph Y. Halpern
#t 2000
#c 12
#% 44876
#% 74868
#% 146906
#% 282857
#% 527523
#% 1478554
#% 1650640
#% 1650648
#! A general notion of algebraic conditional plausibility measures is defined. Probability measures, ranking functions, possibility measures, and (under the appropriate definitions) sets of probability measures can all be viewed as defining algebraic conditional plausibility measures. It is shown that the technology of Bayesian networks can be applied to algebraic conditional plausibility measures.

#index 1650446
#* Inference for belief networks using coupling from the past
#@ Michael Harvey;Radford M. Neal
#t 2000
#c 12
#% 21142
#% 44876
#% 195016
#% 212147
#% 249167
#% 388024
#! Inference for belief networks using Gibbs sampling produces a distribution for unobserved variables that differs from the correct distribution by a (usually) unknown error, since convergence to the right distribution occurs only asymptotically. The method of "coupling from the past" samples from exactly the correct distribution by (conceptually) running dependent Gibbs sampling simulations from every possible starting state from a time far enough in the past that all runs reach the same state at time t = 0. Explicitly considering every possible state is intractable for large networks, however. We propose a method for layered noisy-or networks that uses a compact, but often imprecise, summary of a set of states. This method samples from exactly the correct distribution, and requires only about twice the time per step as ordinary Gibbs sampling, but it may require more simulation steps than would be needed if chains were tracked exactly.

#index 1650447
#* Dependency networks for collaborative filtering and data visualization
#@ David Heckerman;David Maxwell Chickering;Christopher Meek;Robert Rounthwaite;Carl Kadie
#t 2000
#c 12
#% 173879
#% 272520
#% 1650569
#% 1650705
#% 1650722
#% 1650783
#! We describe a graphical representation of probabilistic relationships--an alternative to the Bayesian network--called a dependency network. Like a Bayesian network, a dependency network has a graph and a probability component. The graph component is a (cyclic) directed graph such that a node's parents render that node independent of all other nodes in the network. The probability component consists of the probability of a node given its parents for each node (as in a Bayesian network). We identify several basic properties of this representation, and describe its use in collaborative filtering (the task of predicting preferences) and the visualization of predictive relationships.

#index 1650448
#* YGGDRASIL: a statistical package for learning split models
#@ Søren Højsgaard
#t 2000
#c 12
#% 101221
#% 185075
#% 1650767
#! There are two main objectives of this paper. The first is to present a statistical framework for models with context specific independence structures, i.e. conditional independencies holding only for specific values of the conditioning variables. This framework is constituted by the class of split models. Split models are an extension of graphical models for contingency tables and allow for a more sophisticated modelling than graphical models. The treatment of split models include estimation, representation and a Markov property for reading off those independencies holding in a specific context. The second objective is to present a software package named YGGDRASIL which is designed for statistical inference in split models, i.e. for learning such models on the basis of data.

#index 1650449
#* Probabilistic arc consistency: a connection between constraint reasoning and probabilistic reasoning
#@ Michael C. Horsch;William S. Havens
#t 2000
#c 12
#% 36814
#% 44876
#% 125386
#% 272514
#% 319789
#% 419951
#% 486490
#% 1272302
#% 1272945
#% 1478757
#% 1650318
#! We document a connection between constraint reasoning and probabilistic reasoning. We present an algorithm, called probabilistic arc consistency, which is both a generalization of a well known algorithm for arc consistency used in constraint reasoning, and a specialization of the belief updating algorithm for singly-connected networks. Our algorithm is exact for singlyconnected constraint problems, but can work well as an approximation for arbitrary problems. We briefly discuss some empirical results, and related methods.

#index 1650450
#* Feature selection and dualities in maximum entropy discrimination
#@ Tony Jebara;Tommi Jaakkola
#t 2000
#c 12
#% 226495
#% 235377
#% 276511
#% 304917
#% 304919
#% 466263
#% 469390
#% 493884
#! Incorporating feature selection into a classification or regression method often carries a number of advantages. In this paper we formalize feature selection specifically from a discriminative perspective of improving classification/ regression accuracy. The feature selection method is developed as an extension to the recently proposed maximum entropy discrimination (MED) framework. We describe MED as a flexible (Bayesian) regularization approach that subsumes, e.g., support vector classification, regression and exponential family models. For brevity, we restrict ourselves primarily to feature selection in the context of linear classification/regression methods and demonstrate that the proposed approach indeed carries substantial improvements in practice. Moreover, we discuss and develop various extensions of feature selection, including the problem of dealing with example specific but unobserved degrees of freedom - alignments or invariants.

#index 1650451
#* Marginalization in composed probabilistic models
#@ Radim Jiroušek
#t 2000
#c 12
#% 360087
#% 380725
#% 403535
#% 567872
#% 1650728
#! Composition of low-dimensional distributions, whose foundations were laid in the paper published in the Proceedings of UAI'97 (Jiroušek 1997), appeared to be an alternative apparatus to describe multidimensional probabilistic models. In contrast to Graphical Markov Models, which define multidimensional distributions in a declarative way, this approach is rather procedural. Ordering of low-dimensional distributions into a proper sequence fully defines the respective computational procedure; therefore, a study of different types of generating sequences is one of the central problems in this field. Thus, it appears that an important role is played by special sequences that are called perfect. Their main characterization theorems are presented in this paper. However, the main result of this paper is a solution to the problem of marginalization for general sequences. The main theorem describes a way to obtain a generating sequence that defines the model corresponding to the marginal of the distribution defined by an arbitrary generating sequence. From this theorem the reader can see to what extent these computations are local; i.e., the sequence consists of marginal distributions whose computation must be made by summing up over the values of the variable eliminated (the paper deals with a finite model).

#index 1650452
#* Fast planning in stochastic games
#@ Michael Kearns;Yishay Mansour;Satinder Singh
#t 2000
#c 12
#% 465913
#% 1273835
#% 1273918
#% 1650275
#% 1650312
#! Stochastic games generalize Markov decision processes (MDPs) to a multiagent setting by allowing the state transitions to depend jointly on all player actions, and having rewards determined by multiplayer matrix games at each state. We consider the problem of computing Nash equilibria in stochastic games, the analogue of planning in MDPs. We begin by providing a simple generalization of finite-horizon value iteration that computes a Nash strategy for each player in general-sum stochastic games. The algorithm takes an arbitrary Nash selection function as input, which allows the translation of local choices between multiple Nash equilibria into the selection of a single global Nash equilibrium. Our main technical result is an algorithm for computing near-Nash equilibria in large or infinite state spaces. This algorithm builds on our finite-horizon value iteration algorithm, and adapts the sparse sampling methods of Kearns, Mansour-and Ng (1999) to stochastic games. We conclude by describing a counterexample showing that infinite-horizon discounted value iteration, which was shown by Shapley to converge in the zero-sum case (a result we give extend slightly here), does not converge in the general-sum case.

#index 1650453
#* Making sensitivity analysis computationally efficient
#@ Uffe Kjærulff;Linda C. van der Gaag
#t 2000
#c 12
#% 217078
#% 503995
#% 1650789
#% 1784188
#! To investigate the robustness of the output probabilities of a Bayesian network, a sensitivity analysis can be performed. A one-way sensitivity analysis establishes, for each of the probability parameters of a network, a function expressing a posterior marginal probability of interest in terms of the parameter. Current methods for computing the coefficients in such a function rely on a large number of network evaluations. In this paper, we present a method that requires just a single outward propagation in a junction tree for establishing the coefficients in the functions for all possible parameters; in addition, an inward propagation is required for processing evidence. Conversely, the method requires a single outward propagation for computing the coefficients in the functions expressing all possible posterior marginals in terms of a single parameter. We extend these results to an n-way sensitivity analysis in which sets of parameters are studied.

#index 1650454
#* Policy iteration for factored MDPs
#@ Daphne Koller;Ronald Parr
#t 2000
#c 12
#% 75936
#% 203596
#% 289947
#% 393786
#% 536408
#% 707761
#% 1273919
#% 1290041
#% 1478746
#! Many large MDPs can be represented compactly using a dynamic Bayesian network. Although the structure of the value function does not retain the structure of the process, recent work has suggested that value functions in factored MDPs can often be approximated well using a factored value function: a linear combination of restricted basis functions, each of which refers only to a small subset of variables. An approximate factored value function for a particular policy can be computed using approximate dynamic programming, but this approach (and others) can only produce an approximation relative to a distance metric which is weighted by the stationary distribution of the current policy. This type of weighted projection is ill-suited to policy improvement. We present a new approach to value determination, that uses a simple closed-form computation to compute a least-squares decomposed approximation to the value function for any weights directly. We then use this value determination algorithm as a subroutine in a policy iteration process. We show that, under reasonable restrictions, the policies induced by a factored value function can be compactly represented as a decision list, and can be manipulated efficiently in a policy iteration process. We also present a method for computing error bounds for decomposed value functions using a variableelimination algorithm for function optimization. The complexity of all of our algorithms depends on the factorization of the system dynamics and of the approximate value function.

#index 1650455
#* Game networks
#@ Pierfrancesco La Mura
#t 2000
#c 12
#% 44876
#% 480348
#% 710147
#% 1650307
#! We introduce Game networks (G nets), a novel representation for multi-agent decision problems. Compared to other game-theoretic representations, such as strategic or extensive forms, G nets are more structured and more compact; more fundamentally, G nets constitute a computationally advantageous framework for strategic inference, as both probability and utility independencies are captured in the structure of the network and can be exploited in order to simplify the inference process. An important aspect of multiagent reasoning is the identification of some or all of the strategic equilibria in a game; we present original convergence methods for strategic equilibrium which can take advantage of strategic separabilities in the G net structure in order to simplify the computations. Specifically, we describe a method which identifies a unique equilibrium as a function of the game payoffs, and one which identifies all equilibria.

#index 1650456
#* Combinatorial optimization by learning and simulation of Bayesian networks
#@ Pedro Larrañaga;Ramon Etxeberria;José A. Lozano;José M. Peña
#t 2000
#c 12
#% 44876
#% 101213
#% 129987
#% 212700
#% 256661
#% 380725
#% 382160
#% 388024
#% 421241
#% 443025
#% 479151
#% 647162
#% 1022861
#% 1022902
#% 1650319
#% 1784114
#! This paper shows how the Bayesian network paradigm can be used in order to solve combinatorial optimization problems. To do it some methods of structure learning from data and simulation of Bayesian networks are inserted inside Estimation of Distribution Algorithms (EDA). EDA are a new tool for evolutionary computation in which populations of individuals are created by estimation and simulation of the joint probability distribution of the selected individuals. We propose new approaches to EDA for combinatorial optimization based on the theory of probabilistic graphical models. Experimental results are also presented.

#index 1650457
#* Causal mechanism-based model constructions
#@ Tsai-Ching Lu;Marek J. Druzdzel;Tze Yun Leong
#t 2000
#c 12
#% 44876
#% 101217
#% 163717
#% 217078
#% 443356
#% 1650326
#% 1650731
#% 1650734
#% 1650799
#! We propose a framework for building graphical causal model that is based on the concept of causal mechanisms. Causal models are intuitive for human users and, more importantly, support the prediction of the effect of manipulation. We describe an implementation of the proposed framework as an interactive model construction module, Ima-GeNIe, in SMILE (Structural Modeling, Inference, and Learning Engine) and in GeNIe (SMILE'S Windows user interface).

#index 1650458
#* Credal networks under maximum entropy
#@ Thomas Lukasiewicz
#t 2000
#c 12
#% 20853
#% 44876
#% 61179
#% 73239
#% 147677
#% 167626
#% 216970
#% 250115
#% 267725
#% 478109
#% 503976
#% 503986
#% 527849
#% 564649
#% 1272359
#% 1272395
#% 1272947
#% 1499550
#% 1650574
#% 1650708
#% 1650809
#! We apply the principle of maximum entropy to select a unique joint probability distribution from the set of all joint probability distributions specified by a credal network. In detail, we start by showing that the unique joint distribution of a Bayesian tree coincides with the maximum entropy model of its conditional distributions. This result, however, does not hold anymore for general Bayesian networks. We thus present a new kind of maximum entropy models, which are computed sequentially. We then show that for all general Bayesian networks, the sequential maximum entropy model coincides with the unique joint distribution. Moreover, we apply the new principle of sequential maximum entropy to interval Bayesian networks and more generally to credal networks. We especially show that this application is equivalent to a number of small local entropy maximizations.

#index 1650459
#* Risk agoras: dialectical argumentation for scientific reasoning
#@ Peter McBurney;Simon Parsons
#t 2000
#c 12
#% 132001
#% 290539
#% 489182
#% 504002
#% 659863
#! We propose a formal framework for intelligent systems which can reason about scientific domains, in particular about the carcinogenicity of chemicals, and we study its properties. Our framework is grounded in a philosophy of scientific enquiry and discourse, and uses a model of dialectical argumentation. The formalism enables representation of scientific uncertainty and conflict in a manner suitable for qualitative reasoning about the domain.

#index 1650460
#* Tractable Bayesian learning of tree belief networks
#@ Marina Meilă;Tommi Jaakkola
#t 2000
#c 12
#% 197387
#% 709446
#! In this paper we present decomposable priors, a family of priors over structure and parameters of tree belief nets for which Bayesian learning with complete observations is tractable, in the sense that the posterior is also decomposable and can be completely determined analytically in polynomial time. This follows from two main results: First, we show that factored distributions over spanning trees in a graph can be integrated in closed form. Second, we examine priors over tree parameters and show that a set of assumptions similar to (Heckerman and al., 1995) constrain the tree parameter priors to be a compactly parametrized product of Dirichlet distributions. Besides allowing for exact Bayesian learning, these results permit us to formulate a new class of tractable latent variable models in which the likelihood of a data point is computed through an ensemble average over tree structures.

#index 1650461
#* Probabilistic models for agents' beliefs and decisions
#@ Brian Milch;Daphne Koller
#t 2000
#c 12
#% 44876
#% 147680
#% 157172
#% 284811
#% 1650593
#% 1650620
#% 1650681
#! Many applications of intelligent systems require reasoning about the mental states of agents in the domain. We may want to reason about an agent's beliefs, including beliefs about other agents; we may also want to reason about an agent's preferences, and how his beliefs and preferences relate to his behavior. We define a probabilistic epistemic logic (PEL) in which belief statements are given a formal semantics, and provide an algorithm for asserting and querying PEL formulas in Bayesian networks. We then show how to reason about an agent's behavior by modeling his decision process as an influence diagram and assuming that he behaves rationally. PEL can then be used for reasoning from an agent's observed actions to conclusions about other aspects of the domain, including unobserved domain variables and the agent's mental states.

#index 1650462
#* The anchors hierarchy: using the triangle inequality to survive high dimensional data
#@ Andrew W. Moore
#t 2000
#c 12
#% 105666
#% 210182
#% 232136
#% 280463
#% 304932
#% 317313
#% 465891
#% 466425
#% 479462
#% 593959
#% 1272326
#% 1290057
#! This paper is about metric data structures in high-dimensional or non-Euclidean space that permit cached sufficient statistics accelerations of learning algorithms. It has recently been shown that for less than about 10 dimensions, decorating kd-trees with additional "cached sufficient statistics" such as first and second moments and contingency tables can provide satisfying acceleration for a very wide range of statistical learning tasks such as kernel regression, locally weighted regression, k-means clustering, mixture modeling and Bayes Net learning. In this paper, we begin by defining the anchors hierarchy--a fast data structure and algorithm for localizing data based only on a triangle-inequality-obeying distance metric. We show how this, in its own right, gives a fast and effective clustering of data. But more importantly we show how it can produce a well-balanced structure similar to a Ball-Tree (Omohundro, 1991) or a kind of metric tree (Uhlmann, 1991; Ciaccia, Patella, & Zezula, 1997) in a way that is neither "topdown" nor "bottom-up" but instead "middleout". We then show how this structure, decorated with cached sufficient statistics, allows a wide variety of statistical learning algorithms to be accelerated even in thousands of dimensions.

#index 1650463
#* PEGASUS: a policy search method for large MDPs and POMDPs
#@ Andrew Y. Ng;Michael Jordan
#t 2000
#c 12
#% 124687
#% 145224
#% 184047
#% 305081
#% 361817
#% 384911
#% 565532
#% 707761
#% 837668
#% 1650314
#! We propose a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP), given a model. Our approach is based on the following observation: Any (PO)MDP can be transformed into an "equivalent" POMDP in which all state transitions (given the current state and action) are deterministic. This reduces the general problem of policy search to one in which we need only consider POMDPs with deterministic transitions. We give a natural way of estimating the value of all policies in these transformed POMDPs. Policy search is then simply performed by searching for a policy with high estimated value. We also establish conditions under which our value estimates will be good, recovering theoretical results similar to those of Kearns, Mansour and Ng [7], but with "sample complexity" bounds that have only a polynomial rather than exponential dependence on the horizon time. Our method applies to arbitrary POMDPs, including ones with infinite state and action spaces. We also present empirical results for our approach on a small discrete problem, and on a complex continuous state/continuous action problem involving learning to ride a bicycle.

#index 1650464
#* Representing and solving asymmetric Bayesian decision problems
#@ Thomas D. Nielsen;Finn V. Jensen
#t 2000
#c 12
#% 119308
#% 138515
#% 204851
#% 303580
#% 1650309
#% 1650322
#! This paper deals with the representation and solution of asymmetric Bayesian decision problems. We present a formal framework, termed asymmetric influence diagrams, that is based on the influence diagram and allows an efficient representation of asymmetric decision problems. As opposed to existing frameworks, the asymmetric influence diagram primarily encodes asymmetry at the qualitative level and it can therefore be read directly from the model. We give an algorithm for solving asymmetric influence diagrams. The algorithm initially decomposes the asymmetric decision problem into a structure of symmetric subproblems organized as a tree. A solution to the decision problem can then be found by propagating from the leaves towards the root using existing evaluation methods to solve the subproblems.

#index 1650465
#* Using ROBDDs for inference in Bayesian networks with troubleshooting as an example
#@ Thomas D. Nielsen;Pierre-Henri Wuillemin;Finn V. Jensen;Uffe Kjærulff
#t 2000
#c 12
#% 3873
#% 21138
#% 1476265
#% 1650768
#! When using Bayesian networks for modelling the behavior of man-made machinery, it usually happens that a large part of the model is deterministic. For such Bayesian networks the deterministic part of the model can be represented as a Boolean function, and a central part of belief updating reduces to the task of calculating the number of satisfying configurations in a Boolean function. In this paper we explore how advances in the calculation of Boolean functions can be adopted for belief updating, in particular within the context of troubleshooting. We present experimental results indicating a substantial speed-up compared to traditional junction tree propagation.

#index 1650466
#* Evaluating influence diagrams using LIMIDs
#@ Dennis Nilsson;Steffen L. Lauritzen
#t 2000
#c 12
#% 6199
#% 34262
#% 119308
#% 130135
#% 388024
#% 567872
#% 1650322
#% 1650332
#% 1650620
#% 1650624
#! We present a new approach to the solution of decision problems formulated as influence diagrams. The approach converts the influence diagram into a simpler structure, the LImited Memory Influence Diagram (LIMID), where only the requisite information for the computation of optimal policies is depicted. Because the requisite information is explicitly represented in the diagram, the evaluation procedure can take advantage of it. In this paper we show how to convert an influence diagram to a LIMID and describe the procedure for finding an optimal strategy. Our approach can yield significant savings of memory and computational time when compared to traditional methods.

#index 1650467
#* Adaptive importance sampling for estimation in structured domains
#@ Luis E. Ortiz;Leslie Pack Kaelbling
#t 2000
#c 12
#% 68244
#% 144664
#% 527664
#% 527691
#% 564834
#! Sampling is an important tool for estimating large, complex sums and integrals over high-dimensional spaces. For instance, importance sampling has been used as an alternative to exact methods for inference in belief networks. Ideally, we want to have a sampling distribution that provides optimal-variance estimators. In this paper, we present methods that improve the sampling distribution by systematically adapting it as we obtain information from the samples. We present a stochastic-gradient-descent method for sequentially updating the sampling distribution based on the direct minimization of the variance. We also present other stochastic-gradient-descent methods based on the minimization of typical notions of distance between the current sampling distribution and approximations of the target, optimal distribution. We finally validate and compare the different methods empirically by applying them to the problem of action evaluation in influence diagrams.

#index 1650468
#* Conversation as action under uncertainty
#@ Tim Paek;Eric Horvitz
#t 2000
#c 12
#% 233
#% 42214
#% 128612
#% 185842
#% 185854
#% 199215
#% 284808
#% 1273424
#% 1650593
#% 1650666
#! Conversations abound with uncertainties of various kinds. Treating conversation as inference and decision making under uncertainty, we propose a task independent, multimodal architecture for supporting robust continuous spoken dialog called Quartet. We introduce four interdependent levels of analysis, and describe representations, inference procedures, and decision strategies for managing uncertainties within and between the levels. We highlight the approach by reviewing interactions between a user and two spoken dialog systems developed using the Quartet architecture: Presenter, a prototype system for navigating Microsoft PowerPoint presentations, and the Bayesian Receptionist, a prototype system for dealing with tasks typically handled by front desk receptionists at the Microsoft corporate campus.

#index 1650469
#* Probabilistic models for query approximation with large sparse binary data sets
#@ Dmitry Pavlov;Heikki Mannila;Padhraic Smyth
#t 2000
#c 12
#% 44876
#% 105771
#% 185077
#% 211044
#% 226495
#% 252472
#% 280494
#% 481290
#% 1650778
#! Large sparse sets of binary transaction data with millions of records and thousands of attributes occur in various domains: customers purchasing products, users visiting web pages, and documents containing words are just three typical examples. Real-time query selectivity estimation (the problem of estimating the number of rows in the data satisfying a given predicate) is an important practical problem for such databases. We investigate the application of probabilistic models to this problem. In particular, we study a Markov random field (MRF) approach based on frequent sets and maximum entropy, and compare it to the independence model and the Chow-Liu tree model. We find that the MRF model provides substantially more accurate probability estimates than the other methods but is more expensive from a computational and memory viewpoint. To alleviate the computational requirements we show how one can apply bucket elimination and clique tree approaches to take advantage of structure in the models and in the queries. We provide experimental results on two large real-world transaction datasets.

#index 1650470
#* Collaborative filtering by personality diagnosis: a hybrid memory- and model-based approach
#@ David M. Pennock;Eric Horvitz;Steve Lawrence;C. Lee Giles
#t 2000
#c 12
#% 42214
#% 124010
#% 173879
#% 202011
#% 220706
#% 220711
#% 266281
#% 281366
#% 301590
#% 438103
#% 465906
#% 465928
#% 529806
#% 564279
#% 1010743
#% 1272396
#% 1650569
#! The growth of Internet commerce has stimulated the use of collaborative filtering (CF) algorithms as recommender systems. Such systems leverage knowledge about the known preferences of multiple users to recommend items of interest to other users. CF methods have been harnessed to make recommendations about such items as web pages, movies, books, and toys. Researchers have proposed and evaluated many approaches for generating recommendations. We describe and evaluate a new method called personality diagnosis (PD). Given a user's preferences for some items, we compute the probability that he or she is of the same "personality type" as other users, and, in turn, the probability that he or she will like new items. PD retains some of the advantages of traditional similarity-weighting techniques in that all data is brought to bear on each prediction and new data can be added easily and incrementally. Additionally, PD has a meaningful probabilistic interpretation, which may be leveraged to justify, explain, and augment results. We report empirical results on the EachMovie database of movie ratings, and on user profile data collected from the CiteSeer digital library of Computer Science research papers. The probabilistic framework naturally supports a variety of descriptive measurements--in particular, we consider the applicability of a value of information (VOI) computation.

#index 1650471
#* Compact securities markets for pareto optimal reallocation of risk
#@ David M. Pennock;Michael P. Wellman
#t 2000
#c 12
#% 44876
#% 68244
#% 88134
#% 567876
#% 1650325
#! The securities market is the fundamental theoretical framework in economics and finance for resource allocation under uncertainty. Securities serve both to reallocate risk and to disseminate probabilistic information. Complete securities markets-which contain one securitv for every possible state of nature-support Pareto optimal allocations of risk. Complete markets suffer from the same exponential dependence on the number of underlying events as do joint probability distributions. We examine whether markets can be structured and "compacted" in the same manner as Bayesian network representations of joint distributions. We show that, if all agents' risk-neutral independencies agree with the independencies encoded in the market structure, then the market is operationally complete: risk is still Pareto optimally allocated, yet the number of securities can be exponentially smaller. For collections of agents of a certain type, agreement on Markov independencies is sufficient to admit compact and operationally complete markets.

#index 1650472
#* Learning to cooperate via policy search
#@ Leonid Peshkin;Kee-Eung Kim;Nicolas Meuleau;Leslie Pack Kaelbling
#t 2000
#c 12
#% 56461
#% 124687
#% 171032
#% 266286
#% 305081
#% 384911
#% 465913
#% 466259
#% 466262
#% 528006
#% 1272286
#% 1273798
#% 1650314
#! Cooperative games are those in which both agents share the same payoff structure. Value-based reinforcement-learning algorithms, such as variants of Q-learning, have been applied to learning cooperative games, but they only apply when the game state is completely observable to both agents. Policy search methods are a reasonable alternative to value-based methods for partially observable environments. In this paper, we provide a gradient-based distributed policy-search method for cooperative games and compare the notion of local optimum to that of Nash equilibrium. We demonstrate the effectiveness of this method experimentally in a small, partially observable simulated soccer domain.

#index 1650473
#* Value-directed belief state approximation for POMDPs
#@ Pascal Poupart;Craig Boutilier
#t 2000
#c 12
#% 75936
#% 128629
#% 179940
#% 266616
#% 465918
#% 695957
#% 1476294
#% 1650297
#% 1650312
#% 1650568
#% 1650702
#! We consider the problem belief-state monitoring for the purposes of implementing a policy for a partially-observable Markov decision process (POMDP), specifically how one might approximate the belief state. Other schemes for beliefstate approximation (e.g., based on minimizing a measure such as KL-divergence between the true and estimated state) are not necessarily appropriate for POMDPs. Instead we propose a framework for analyzing value-directed approximation schemes, where approximation quality is determined by the expected error in utility rather than by the error in the belief state itself. We propose heuristic methods for finding good projection schemes for belief state estimation--exhibiting anytime characteristics--given a POMDP value function. We also describe several algorithms for constructing bounds on the error in decision quality (expected utility) associated with acting in accordance with a given belief state approximation.

#index 1650474
#* Probabilistic state-dependent grammars for plan recognition
#@ David V. Pynadath;Michael P. Wellman
#t 2000
#c 12
#% 75896
#% 128629
#% 147680
#% 246836
#% 247892
#% 283143
#% 363592
#% 709172
#% 748561
#% 817829
#% 1279706
#% 1478844
#% 1650293
#% 1650568
#% 1650681
#! Techniques for plan recognition under uncertainty require a stochastic model of the plangeneration process. We introduce probabilistic state-dependent grammars (PSDGs) to represent an agent's plan-generation process. The PSDG language model extends probabilistic contextfree grammars (PCFGs) by allowing production probabilities to depend on an explicit model of the planning agent's internal and external state. Given a PSDG description of the plan-generation process, we can then use inference algorithms that exploit the particular independence properties of the PSDG language to efficiently answer plan-recognition queries. The combination of the PSDG language model and inference algorithms extends the range of plan-recognition domains for which practical probabilistic inference is possible, as illustrated by applications in traffic monitoring and air combat.

#index 1650475
#* Pivotal pruning of trade-offs in QPNs
#@ Silja Renooij;Linda C. van der Gaag;Simon Parsons;Shaw Green
#t 2000
#c 12
#% 44876
#% 70370
#% 89748
#% 1478675
#% 1650328
#% 1650603
#% 1650620
#% 1650676
#% 1650735
#! Qualitative probabilistic networks have been designed for probabilistic reasoning in a qualitative way. Due to their coarse level of representation detail, qualitative probabilistic networks do not provide for resolving trade-offs and typically yield ambiguous results upon inference. We present an algorithm for computing more insightful results for unresolved trade-offs. The algorithm builds upon the idea of using pivots to zoom in on the trade-offs and identifying the information that would serve to resolve them.

#index 1650476
#* Monte Carlo inference via greedy importance sampling
#@ Dale Schuurmans;Finnegan Southey
#t 2000
#c 12
#% 44876
#% 68244
#% 115608
#% 136358
#% 231738
#% 261205
#% 277467
#% 277472
#% 360691
#% 374580
#% 457558
#% 527664
#% 1273622
#% 1650666
#! We present a new method for conducting Monte Carlo inference in graphical models which combines explicit search with generalized importance sampling. The idea is to reduce the variance of importance sampling by searching for significant points in the target distribution. We prove that it is possible to introduce search and still maintain unbiasedness. We then demonstrate our procedure on a few simple inference tasks and show that it can improve the inference quality of standard MCMC methods, including Gibbs sampling, Metropolis sampling, and Hybrid Monte Carlo. This paper extends previous work which showed how greedy importance sampling could be correctly realized in the one-dimensional case.

#index 1650477
#* Combining feature and example pruning by uncertainty minimization
#@ Marc Sebban;Richard Nock
#t 2000
#c 12
#% 92533
#% 214236
#% 243727
#% 307100
#% 465760
#% 466562
#% 515372
#% 1499584
#! We focus in this paper on dataset reduction techniques for use in k-nearest neighbor classification. In such a context, feature and prototype selections have always been independently treated by the standard storage reduction algorithms. While this certifying is theoretically justified by the fact that each subproblem is NP-hard, we assume in this paper that a joint storage reduction is in fact more intuitive and can in practice provide better results than two independent processes. Moreover, it avoids a lot of distance calculations by progressively removing useless instances during the feature pruning. While standard selection algorithms often optimize the accuracy to discriminate the set of solutions, we use in this paper a criterion based on an uncertainty measure within a nearestneighbor graph. This choice comes from recent results that have proven that accuracy is not always the suitable criterion to optimize. In our approach, a feature or an instance is removed if its deletion improves information of the graph. Numerous experiments are presented in this paper and a statistical analysis shows the relevance of our approach, and its tolerance in the presence of noise.

#index 1650478
#* Nash convergence of gradient dynamics in general-sum games
#@ Satinder Singh;Michael Kearns;Yishay Mansour
#t 2000
#c 12
#% 176293
#% 593736
#! Multi-agent games are becoming an increasingly prevalent formalism for the study of electronic commerce and auctions. The speed at which transactions can take place and the growing complexity of electronic marketplaces makes the study of computationally simple agents an appealing direction. In this work, we analyze the behavior of agents that incrementally adapt their strategy through gradient ascent on expected payoff, in the simple setting of two-player, two-action, iterated general-sum games, and present a surprising result. We show that either the agents will converge to a Nash equilibrium, or if the strategies themselves do not converge, then their average payoffs will nevertheless converge to the payoffs of a Nash equilibrium.

#index 1650479
#* A knowledge acquisition tool for Bayesian-network troubleshooters
#@ Claus Skaanning
#t 2000
#c 12
#% 107414
#% 183497
#% 314815
#% 1650338
#% 1650686
#! This paper describes a domain-specific knowledge acquisition tool for intelligent automated troubleshooter!; based on Bayesian networks. No Bayesian network knowledge is required to use the tool., and troubleshooting information can be spec.ified as natural and intuitive as possible. Probabilities can be specified in the direction that is most natural to the domain expert. Thus, the knowledge acquisition efficiently removes the traditional knowledge acquisition bottleneck of Bayesian networks.

#index 1650480
#* On the use of skeletons when learning in Bayesian networks
#@ Harald Steck
#t 2000
#c 12
#% 44876
#% 129987
#% 232117
#% 527830
#% 1650623
#% 1650638
#% 1650771
#! In this paper, we present a heuristic operator which aims at simultaneously optimizing the orientations of all the edges in an intermediate Bayesian network structure during the search process. This is done by alternating between the space of directed acyclic graphs (DAGs) and the space of skeletons. The found orientations of the edges are based on a scoring function rather than on induced conditional independences. This operator can be used as an extension to commonly employed search strategies. It is evaluated in experiments with artificial and real-world data.

#index 1650481
#* Dynamic trees: a structured variational method giving efficient propagation rules
#@ Amos J. Storkey
#t 2000
#c 12
#% 44876
#% 277483
#% 304963
#% 658100
#% 857094
#% 857454
#! Dynamic trees are mixtures of tree structured belief networks. They solve some of the problems of fixed tree networks at the cost of making exact inference intractable. For this reason approximate methods such as sampling or mean field approaches have been used. However, mean field approximations assume a factorised distribution over node states. Such a distribution seems unlikely in the posterior, as nodes are highly correlated in the prior. Here a structured variational approach is used, where the posterior distribution over the non-evidential nodes is itself approximated by a dynamic tree. It turns out that this form can be used tractably and efficiently. The result is a set of update rules which can propagate information through the network to obtain both a full variational approximation, and the relevant marginals. The propagation rules are more efficient than the mean field approach and give noticeable quantitative and qualitative improvement in the inference. The marginals calculated give better approximations to the posterior than loopy propagation on a small toy problem.

#index 1650482
#* An uncertainty framework for classification
#@ Loo-Nin Teow;Kia-Fock Loe
#t 2000
#c 12
#% 65443
#% 91872
#% 92148
#% 95220
#% 169358
#% 182919
#% 190581
#% 197394
#% 211707
#% 280817
#% 387914
#% 420077
#% 1478493
#% 1762960
#! We define a generalized likelihood function based on uncertainty measures and show that maximizing such a likelihood function for different measures induces different types of classifiers. In the probabilistic framework, we obtain classifiers that optimize the cross-entropy function. In the possibilistic framework, we obtain classifiers that maximize the interclass margin. Furthermore, we show that the support vector machine is a sub-class of these maximummargin classifiers.

#index 1650483
#* A branch-and-bound algorithm for MDL learning Bayesian networks
#@ Jin Tian
#t 2000
#c 12
#% 44876
#% 129497
#% 129987
#% 197387
#% 408732
#% 437610
#% 443025
#% 681749
#! This paper extends the work in [Suzuki, 1996] and presents an efficient depth-first branch-and-bound algorithm for learning Bayesian network structures, based on the minimum description length (MDL) principle, for a given (consistent) variable ordering. The algorithm exhaustively searches through all network structures and guarantees to find the network with the best MDL score. Preliminary experiments show that the algorithm is efficient, and that the time complexity grows slowly with the sample size. The algorithm is useful for empirically studying both the performance of suboptimal heuristic search algorithms and the adequacy of the MDL principle in learning Bayesian networks.

#index 1650484
#* Probabilities of causation: bounds and identification
#@ Jin Tian;Judea Pearl
#t 2000
#c 12
#% 160190
#% 217477
#% 243717
#% 297171
#% 1650583
#% 1650587
#% 1650629
#% 1650768
#! This paper deals with the problem of estimating the probability that one event was a cause of another in a given scenario. Using structural-semantical definitions of the probabilities of necessary or sufficient causation (or both), we show how to optimally bound these quantities from data obtained in experimental and observational studies, making minimal assumptions concerning the data-generating process. In particular, we strengthen the results of Pearl (1999) by weakening the data-generation assumptions and deriving theoretically sharp bounds on the probabilities of causation. These results delineate precisely how empirical data can be used both in settling questions of attribution and in solving attribution-related problems of decision making.

#index 1650485
#* Model-based hierarchical clustering
#@ Shivakumar Vaithyanathan;Byron Dom
#t 2000
#c 12
#% 118771
#% 274604
#% 466395
#% 672659
#% 1273827
#% 1280027
#! We present an approach to model-based hierarchical clustering by formulating an objective function based on a Bayesian analysis. This model organizes the data into a cluster hierarchy while specifying a complex feature-set partitioning that is a key component of our model. Features can have either a unique distribution in every cluster or a common distribution over some (or even all) of the clusters. The cluster subsets over which these features have such a common distribution correspond to the nodes (clusters) of the tree representing the hierarchy. We apply this general model to the problem of document clustering for which we use a multinomial likelihood function and Dirichlet priors. Our algorithm consists of a two-stage process wherein we first perform a flat clustering followed by a modified hierarchical agglomerative merging process that includes determining the features that will have common distributions over the merged clusters. The regularization induced by using the marginal likelihood automatically determines the optimal model structure including number of clusters, the depth of the tree and the subset of features to be modeled as having a common distribution at each node. We present experimental results on both synthetic data and a real document collection.

#index 1650486
#* Conditional independence and Markov properties in possibility theory
#@ Jiřina Vejnarová
#t 2000
#c 12
#% 277058
#% 282857
#! Conditional independence and Markov properties are powerful tools allowing expression of multidimensional probability distributions by means of low-dimensional ones. As multidimensional possibilistic models have been studied for several years, the demand for analogous tools in possibility theory seems to be quite natural. This paper is intended to be a promotion of de Cooman's measure-theoretic approach to possibility theory, as this approach allows us to find analogies to many important results obtained in probabilistic framework. First we recall semi-graphoid properties of conditional possibilistic independence, parameterized by a continuous t-norm, and find sufficient conditions for a class of Archimedean t-norms to have the graphoid property. Then we introduce Markov properties and factorization of possibility distributions (again parameterized by a continuous t-norm) and find the relationships between them. These results are accompanied by a number of counterexamples, which show that the assumptions of specific theorems are substantial.

#index 1650487
#* User interface tools for navigation in conditional probability tables and elicitation of probabilities in Bayesian networks
#@ Haiqin Wang;Marek J. Druzdzel
#t 2000
#c 12
#% 277058
#% 282857
#! Elicitation of probabilities is one of the most laborious tasks in building decision-theoretic models, and one that has so far received only moderate attention in decision-theoretic systems. We propose a set of user interface tools for graphical probabilistic models, focusing on two aspects of probability elicitation: (1) navigation through conditional probability tables and (2) interactive graphical assessment of discrete probability distributions. We propose two new graphical views that aid navigation in very large conditional probability tables: the CPTREE (Conditional Probability Tree) and the sCPT (shrinkable Conditional Probability Table). Based on what is known about graphical presentation of quantitative data to humans, we offer several useful enhancements to probability wheel and bar graph, including different chart styles and options that can be adapted to user preferences and needs. We present the results of a simple usability study that proves the value of the proposed tools.

#index 1650488
#* Variational approximations between mean field theory and the junction tree algorithm
#@ Wim Wiegerinck
#t 2000
#c 12
#% 44876
#% 68244
#% 91872
#% 130878
#% 246836
#% 269189
#% 269195
#% 277396
#% 303620
#% 304811
#% 307241
#% 380725
#% 382160
#% 705252
#% 1272279
#% 1272398
#% 1650317
#! Recently, variational approximations such as the mean field approximation have received much interest. We extend the standard mean field method by using an approximating distribution that factorises into cluster potentials. This includes undirected graphs, directed acyclic graphs and junction trees. We derive generalised mean field equations to optimise the cluster potentials. We show that the method bridges the gap between the standard mean field approximation and the exact junction tree algorithm. In addition, we address the problem of how to choose the structure and the free parameters of the approximating distribution. F'rom the generalised mean field equations we derive rules to simplify the approximation in advance without affecting the potential accuracy of the model class. We also show how the method fits into some other variational approximations that are currently popular.

#index 1650489
#* Model criticism of Bayesian networks with latent variables
#@ David M. Williamson;Russell G. Almond;Robert J. Mislevy
#t 2000
#c 12
#% 197387
#% 443632
#% 1650786
#! The application of Bayesian networks (BNs) to cognitive assessment and intelligent tutoring systems poses new challenges for model construction. When cognitive task analyses suggest constructing a BN with several latent variables, empirical model criticism of the latent structure becomes both critical and complex. This paper introduces a methodology for criticizing models both globally (a BN in its entirety) and locally (observable nodes), and explores its value in identifying several kinds of misfit: node errors, edge errors, state errors, and prior probability errors in the latent structure. The results suggest the indices have potential for detecting model misfit and assisting in locating problematic components of the model.

#index 1650490
#* Exploiting qualitative knowledge in the learning of conditional probabilities of Bayesian networks
#@ Frank Wittig;Anthony Jameson
#t 2000
#c 12
#% 44876
#% 89748
#% 246835
#% 277480
#% 292185
#% 382160
#% 1290046
#% 1650323
#% 1650644
#% 1650696
#% 1650719
#! Algorithms for learning the conditional probabilities of Bayesian networks with hidden variables typically operate within a high-dimensional search space and yield only locally optimal solutions. One way of limiting the search space and avoiding local optima is to impose qualitative constraints that are based on background knowledge concerning the domain. We present a method for integrating formal statements of qualitative constraints into two learning algorithms, APN and EM. In our experiments with synthetic data, this method yielded networks that satisfied the constraints almost perfectly. The accuracy of the learned networks was consistently superior to that of corresponding networks learned without constraints. The exploitation of qualitative constraints therefore appears to be a promising way to increase both the interpretability and the accuracy of learned Bayesian networks with known structure.

#index 1650491
#* Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence
#@ Jack Breese;Daphne Koller
#t 2001
#c 12

#index 1650492
#* A factorized variational technique for phase unwrapping in Markov random fields
#@ Kannan Achan;Brendan J. Frey;Ralf Koetter
#t 2001
#c 12
#% 269188
#% 380896
#% 1857074
#! Some types of medical and topographic imaging device produce images in which the pixel values are "phase-wrapped", i.e., measured modulus a known scalar. Phase unwrapping can be viewed as the problem of inferring the integer number of relative shifts between each and every pair of neighboring pixels, subject tO an a priori preference for smooth surfaces, and a zero curl constraint, which requires that the shifts must sum to 0 around every loop. We formulate phase unwrapping as a probabilistic inference problem in a Markov random field where the prior favors the zero curl constraint. We derive a relaxed, factorized variational method that infers approximations to the marginal probabilities of the integer shifts between pairs of neighboring pixels. The original, unwrapped image can then be obtained by integrating the integer shifts. We compare our mean field technique with the least squares method on a synthetic 100 × 100 image, and give results on a larger 512 × 512 image measured using synthetic aperature radar from Sandia National Laboratories.

#index 1650493
#* Efficient approximation for triangulation of minimum treewidth
#@ Eyal Amir
#t 2001
#c 12
#% 31482
#% 55926
#% 70370
#% 93660
#% 115509
#% 157302
#% 179784
#% 187074
#% 198055
#% 219474
#% 283101
#% 296756
#% 375029
#% 475714
#% 527826
#% 566573
#% 1478758
#% 1650763
#! We present four novel approximation algorithms for finding triangulation of minimum treewidth. Two of the algorithms improve on the running times of algorithms by Robertson and Seymour, and Becker and Geiger that approximate the optimum by factors of 4 and 32/3, respectively. A third algorithm is faster than those but gives an approximation factor of 41/2. The last algorithm is yet faster, producing factor-O(lgk) approximations in polynomial time. Finding triangulations of minimum treewidth for graphs is central to many problems in computer science. Realworld problems in artificial intelligence, VLSI design and databases are efficiently solvable if we have an efficient approximation algorithm for them. We report on experimental results confirming the effectiveness of our algorithms for large graphs associated with real-world problems.

#index 1650494
#* Markov chain monte carlo using tree-based priors on model structure
#@ Nicos Angelopoulos;James Cussens
#t 2001
#c 12
#% 379345
#% 528004
#% 528014
#% 528304
#! We present a general framework for defining priors on model structure and sampling from the posterior using the Metropolis-Hastings algorithm. The key ideas are that structure priors are defined via a probability tree and that the proposal distribution for the Metropolis-Hastings algorithm is defined using the prior, thereby defining a cheaply computable acceptance probability. We have applied this approach to Bayesian net structure learning using a number of priors and proposal distributions. Our results show that these must be chosen appropriately for this approach to be successful.

#index 1650495
#* Graphical readings of possibilistic logic bases
#@ Salem Benferhat;Didier Dubois;Souhila Kaci;Henri Prade
#t 2001
#c 12
#% 111942
#% 121322
#% 167544
#% 297824
#% 504286
#% 536285
#% 1650272
#! Possibility theory offers either a qualitative, or a numerical framework for representing uncertainty, in terms of dual measures of possibility and necessity. This leads to the existence of two kinds of possibilistic causal graphs where the conditioning is either based on the minimum, or on the product operator. Benferhat et al. [3] have investigated the connections between min-based graphs and possibilistic logic bases (made of classical formulas weighted in terms of certainty). This paper deals with a more difficult issue: the product-based graphical representation of possibilistic bases, which provides an easy structural reading of possibilistic bases.

#index 1650496
#* Pre-processing for triangulation of probabilistic networks
#@ Hans L. Bodlaender;Arie M. C. A. Koster;Frank van den Eijkhof;Linda C. van der Gaag
#t 2001
#c 12
#% 451
#% 10517
#% 31482
#% 152680
#% 212265
#% 263371
#% 1478758
#% 1650763
#! The currently most efficient algorithm for inference with a probabilistic network builds upon a triangulation of a network's graph. In this paper, we show that pre-processing can help in finding good triangulations for probabilistic networks, that is, triangulations with a minimal maximum clique size. We provide a set of rules for stepwise reducing a graph. The reduction allows us to solve the triangulation problem on a smaller graph. From the smaller graph's triangulation, a triangulation of the original graph is obtained by reversing the reduction steps. Our experimental results show that the graphs of some well-known real-life probabilistic networks can be triangulated optimally just by pre-processing; for other networks, huge reductions in size are obtained.

#index 1650497
#* A calculus for causal relevance
#@ Blai Bonet
#t 2001
#c 12
#% 243717
#% 297171
#% 528332
#% 1650587
#! We present a sound and complete calculus for causal relevance that uses Pearl's functional causal models as semantics. The calculus consists of axioms and rules of inference for reasoning about causal relevance relationships. We extend the set of known axioms for causal relevance with new axioms and rules of inference. The axioms are then divided into different sets for reasoning about specific subclasses of models. These subclasses make up a new decomposition of the class of causal models. At the end, we show how the calculus for causal relevance can be used in the task of identifying causal structure from non-observational data.

#index 1650498
#* Instrumentality tests revisited
#@ Blai Bonet
#t 2001
#c 12
#% 160190
#% 297171
#% 405926
#% 1272178
#% 1650582
#% 1650677
#! An instrument is a random variable that is uncorrelated with certain (unobserved) error terms and, thus, allows the identification of structural parameters in linear models. In nonlinear models, instrumental variables are useful for deriving bounds on causal effects. Few years ago, Pearl introduced a necessary test for instruments which permits researchers to identify variables that could not serve as instruments. In this paper, we extend Pearl's result in several directions. In particular, we answer in the affirmative an open conjecture about the non-testability of instruments in models with unrestricted variables, and we devise new tests for models with discrete and continuous variables.

#index 1650499
#* UCP-networks: a directed graphical representation of conditional utilities
#@ Craig Boutilier;Fahiem Bacchus;Ronen I. Brafman
#t 2001
#c 12
#% 529348
#% 1271902
#% 1272302
#% 1289345
#% 1650274
#% 1650307
#% 1650628
#% 1650778
#! We propose a directed graphical representation of utility functions, called UCP-networks, that combines aspects of two existing preference models: generalized additive models and CP-networks. The network decomposes a utility function into a number of additive factors, with the directionality of the arcs reflecting conditional dependence in the underlying (qualitative) preference ordering under a ceteris paribus interpretation. The CP-semantics ensures that computing optimization and dominance queries is very efficient. We also demonstrate the value of this representation in decision making. Finally, we describe an interactive elicitation procedure that takes advantage of the linear nature of the constraints on "tradeoff weights" imposed by a UCP-network.

#index 1650500
#* When do numbers really matter?
#@ Hei Chan;Adrian Darwiche
#t 2001
#c 12
#% 44876
#% 217078
#% 380725
#% 503995
#% 528025
#% 528027
#% 1290046
#% 1650616
#% 1650719
#% 1784188
#! Common wisdom has it that small distinctions in the probabilities quantifying a belief network do not matter much for the results of probabilistic queries. Yet, one can develop realistic scenarios under which small variations in network probabilities can lead to significant changes in computed queries. A pending theoretical question is then to analytically characterize parameter changes that do or do not matter. In this paper, we study the sensitivity of probabilistic queries to changes in network parameters and prove some tight bounds on the impact that such parameters can have on queries. Our analytical results pinpoint some interesting situations under which parameter changes do or do not matter. These results are important for knowledge engineers as they help them identify influential network parameters. They also help explain some of the previous experimental results and observations with regards to network robustness against parameter changes.

#index 1650501
#* Confidence inference in bayesian networks
#@ Jian Cheng;Marek J. Druzdzel
#t 2001
#c 12
#% 44876
#% 172544
#% 231738
#% 314829
#% 527664
#% 527691
#% 1271825
#! We present two sampling algorithms for probabilistic confidence inference in Bayesian networks. These two algorithms (we call them AIS-BN-µ and AIS-BN-σ algorithms) guarantee that estimates of posterior probabilities are with a given probability within a desired precision bound. Our algorithms are based on recent advances in sampling algorithms for (1) estimating the mean of bounded random variables and (2) adaptive importance sampling in Bayesian networks. In addition to a simple stopping rule for sampling that they provide, the AIS-BN-µ and AIS-BN-σ algorithms are capable of guiding the learning process in the AIS-BN algorithm. An empirical evaluation of the proposed algorithms shows excellent performance, even for very unlikely evidence.

#index 1650502
#* Semi-instrumental variables: a test for instrument admissibility
#@ Tianjiao Chu;Richard Scheines;Peter Spirtes
#t 2001
#c 12
#% 1650677
#! In a causal graphical model, an instrument for a variable X and its effect Y is a random variable that is a cause of X and independent of all the causes of Y except X (Pearl 1995). For continuous variables, instrumental variables can be used to estimate how the distribution of an effect will respond to a manipulation of its causes, even in the presence of unmeasured common causes (confounders). In typical instrumental variable estimation, instruments are chosen based on domain knowledge. There is currently no statistical test for validating a continuous variable as an instrument. In this paper, we introduce the concept of semi-instrument, which generalizes the concept of instrument: each instrument is a semi-instrument, but the converse does not hold. We show that in the framework of additive models, under certain conditions, we can test whether a variable is semi-instrumental. Moreover, adding some distribution assumptions, we can test whether two semi-instruments are instrumental. We give algorithms to test whether a variable is semi-instrumental, and whether two semi-instruments are both instrumental. These algorithms can be used to test the experts' choice of instruments, or to identify instruments automatically.

#index 1650503
#* Conditions under which conditional independence and scoring methods lead to identical selection of Bayesian network models
#@ Robert G. Cowell
#t 2001
#c 12
#% 129987
#% 197387
#% 212698
#% 240222
#% 277480
#% 388024
#! It is often stated in papers tackling the task of selecting a Bayesian network structure from data that there are these two distinct approaches: (i) Apply conditional independence tests when testing for the presence or otherwise of edges; (ii) Search the model space using a scoring metric. Here I argue that for complete data and a given node ordering this division is largely a myth, by showing that cross entropy methods for checking conditional independence are mathematically identical to methods based upon discriminating between models by their overall goodness-of-fit logarithmic scores.

#index 1650504
#* Linearity properties of bayes nets with binary variables
#@ David Danks;Clark Glymour
#t 2001
#c 12
#% 44876
#% 297171
#% 422651
#! It is "well known" that in linear models: (1) testable constraints on the marginal distribution of observed variables distinguish certain cases in which an unobserved cause jointly influences several observed variables; (2) the technique of "instrumental variables" sometimes permits an estimation of the influence of one variable on another even when the association between the variables may be confounded by unobserved common causes; (3) the association (or conditional probability distribution of one variable given another) of two variables connected by a path or pair of paths with a single common vertex (a trek) can be computed directly from the parameter values associated with each edge in the trek; (4) the association of two variables produced by multiple treks can be computed from the parameters associated with each trek; and (5) the independence of two variables conditional on a third implies the corresponding independence of the sums of the variables over all units conditional on the sums over all units of each of the original conditioning variables. These properties are exploited in search procedures. We show that (1) and (2) hold for all Bayes nets with binary variables. We further show that for Bayes nets parameterized as noisy-OR and noisy-AND gates, all of these properties save (4) hold.

#index 1650505
#* Using Bayesian networks to identify the causal effect of speeding in individual vehicle/pedestrian collisions
#@ Gary A. Davis
#t 2001
#c 12
#% 160190
#% 297171
#! Estimating individual probabilities of causation generally requires prior knowledge of causal mechanisms. For traffic accidents such knowledge is often available and supports the discipline of accident reconstruction. In this paper structural knowledge is combined with Bayesian network methods to calculate the probability of necessity due to speeding for each of a set of vehicle/pedestrian collisions. Gibbs sampling is used to carry out the computations.

#index 1650506
#* Hybrid processing of beliefs and constraints
#@ Rina Dechter;David Larkin
#t 2001
#c 12
#% 1675
#% 44876
#% 289947
#% 408680
#% 420720
#% 527688
#% 1271900
#% 1650327
#% 1650778
#% 1848680
#! This paper explores algorithms for processing probabilistic and deterministic information when the former is represented as a belief network and the latter as a set of boolean clauses. The motivating tasks are 1. evaluating belief networks having a large number of deterministic relationships and 2. evaluating probabilities of complex boolean queries or complex evidence information over a belief network. We present and analyze a variable elimination algorithm that exploits both types of information, and provide empirical evaluation demonstrating its computational benefits.

#index 1650507
#* Variational MCMC
#@ Nando de Freitas;Pedro Højen-Sørensen;Michael I Jordan;Stuart Russell
#t 2001
#c 12
#% 303620
#% 424806
#% 856769
#% 1272398
#% 1757186
#! We propose a new class of learning algorithms that combines variational approximation and Markov chain Monte Carlo (MCMC) simulation. Naive algorithms that use the variational approximation as proposal distribution can perform poorly because this approximation tends to underestimate the true variance and other features of the data. We solve this problem by introducing more sophisticated MCMC algorithms. One of these algorithms is a mixture of two MCMC kernels: a random walk Metropolis kernel and a block Metropolis-Hastings (MH) kernel with a variational approximation as proposal distribution. The MH kernel allows one to locate regions of high probability efficiently. The Metropolis kernel allows us to explore the vicinity of these regions. This algorithm outperforms variational approximations because it yields slightly better estimates of the mean and considerably better estimates of higher moments, such as covariances. It also outperforms standard MCMC algorithms because it locates the regions of high probability quickly, thus speeding up convergence. We also present an adaptive MCMC algorithm that iterates between improving the variational approximation and improving the MCMC approximation. We demonstrate the algorithms on the problem of Bayesian parameter estimation for logistic (sigmoid) belief networks.

#index 1650508
#* Efficient stepwise selection in decomposable models
#@ Amol Deshpande;Minos Garofalakis;Michael I. Jordan
#t 2001
#c 12
#% 226495
#% 237646
#% 277480
#% 289424
#% 333946
#% 481951
#% 539682
#% 722753
#% 748601
#! In this paper, we present an efficient algorithm for performing stepwise selection in the class of decomposable models. We focus on the forward selection procedure, but we also discuss how backward selection and the combination of the two can be performed efficiently. The main contributions of this paper are (1) a simple characterization for the edges that can be added to a decomposable model while retaining its decomposability and (2) an efficient algorithm for enumerating all such edges for a given decomposable model in O(n2) time, where n is the number of variables in the model. We also analyze the complexity of the overall stepwise selection procedure (which includes the complexity of enumerating eligible edges as well as the complexity of deciding how to "progress"). We use the KL divergence of the model from the saturated model as our metric, but the results we present here extend to many other metrics as well.

#index 1650509
#* Incorporating expressive graphical models in variational approximations: chain-graphs and hidden variables
#@ Tal El-Hay;Nit Friedman
#t 2001
#c 12
#% 44876
#% 115608
#% 246836
#% 277467
#% 277470
#% 304811
#% 388024
#% 528019
#% 1272279
#! Global variational approximation methods in graphical models allow efficient approximate inference of complex posterior distributions by using a simpler model. The choice of the approximating model determines a tradeoff between the complexity of the approximation procedure and the quality of the approximation. In this paper, we consider variational approximations based on two classes of models that are richer than standard Bayesian networks, Markov networks or mixture models. As such, these classes allow to find better tradeoffs in the spectrum of approximations. The first class of models are chain graphs, which capture distributions that are partially directed. The second class of models are directed graphs (Bayesian networks) with additional latent variables. Both classes allow representation of multi-variable dependencies that cannot be easily represented within a Bayesian network.

#index 1650510
#* Learning the dimensionality of hidden variables
#@ Gal Elidan;Nir Friedman
#t 2001
#c 12
#% 185079
#% 197387
#% 246834
#% 277480
#% 466850
#% 476708
#% 527833
#% 1273915
#% 1650579
#! A serious problem in learning probabilistic models is the presence of hidden variables. These variables are not observed, yet interact with several of the observed variables. Detecting hidden variables poses two problems: determining the relations to other variables in the model and determining the number of states of the hidden variable. In this paper, we address the latter problem in the context of Bayesian networks. We describe an approach that utilizes a score-based agglomerative state-clustering. As we show, this approach allows us to efficiently evaluate models with a range of cardinalities for the hidden variable. We show how to extend this procedure to deal with multiple interacting hidden variables. We demonstrate the effectiveness of this approach by evaluating it on synthetic and real-life data. We show that our approach learns models with hidden variables that generalize better and have better structure than previous approaches.

#index 1650511
#* Multivariate information bottleneck
#@ Nir Friedman;Ori Mosenzon;Noam Slonim;Naftali Tishby
#t 2001
#c 12
#% 44876
#% 115608
#% 190861
#% 262059
#% 280819
#% 309128
#% 748465
#! The Information bottleneck method is an unsupervised non-parametric data organization technique. Given a joint distribution P(A, B), this method constructs a new variable T that extracts partitions, or clusters, over the values of A that are informative about B. The information bottleneck has already been applied to document classification, gene expression, neural code, and spectral analysis. In this paper, we introduce a general principled framework for multivariate extensions of the information bottleneck method. This allows us to consider multiple systems of data partitions that are inter-related. Our approach utilizes Bayesian networks for specifying the systems of clusters and what information each captures. We show that this construction provides insight about bottleneck variations and enables us to characterize solutions of these variations. We also present a general framework for iterative algorithms for constructing solutions, and apply it to several examples.

#index 1650512
#* A comparison of axiomatic approaches to qualitative decision making using possibility theory
#@ Phan H. Giang;Prakash P. Shenoy
#t 2001
#c 12
#% 111942
#% 211580
#% 233138
#% 315415
#% 527528
#% 528024
#% 1290145
#! In this paper we analyze two recent axiomatic approaches proposed by Dubois et al., [5] and by Giang and Shenoy [10] for qualitative decision making where uncertainty is described by possibility theory. Both axiomtizations are inspired by yon Neumann and Morgenstern's system of axioms for the case of probability theory. We show that our approach naturally unifies two axiomatic systems that correspond, respectively, to pessimistic and optimistic decision criteria proposed by Dubois et al. The simplifying unification is achieved by (i) replacing axioms that are supposed to reflect two informational attitudes (uncertainty aversion and uncertainty attraction) by an axiom that imposes order on set of standard lotteries, and (ii) using a binary utility scale in which each utility level is represented by a pair of numbers.

#index 1650513
#* Enumerating Markov equivalence classes of acyclic digraph dels
#@ Steven B. Gillispie;Michael D. Perlman
#t 2001
#c 12
#% 44876
#% 61079
#% 67866
#% 70370
#% 129987
#% 130153
#% 303844
#% 380725
#% 527830
#% 1272363
#% 1349492
#% 1650638
#% 1650673
#% 1650771
#! Graphical Markov models determined by acyclic digraphs (ADGs), also called directed acyclic graphs (DAGs), are widely studied in statistics, computer science (as Bayesian networks), operations research (as influence diagrams), and many related fields. Because different ADGs may determine the same Markov equivalence class, it long has been of interest to determine the efficiency gained in model specification and search by working directly with Markov equivalence classes of ADGs rather than with ADGs themselves. A computer program was written to enumerate the equivalence classes of ADG models as specified by Pearl & Verma's equivalence criterion. The program counted equivalence classes for models up to and including 10 vertices. The ratio of numbers of classes to ADGs appears to approach an asymptote of about 0.267. Classes were analyzed according to number of edges and class size. By edges, the distribution of number of classes approaches a Gaussian shape. By class size, classes of size 1 are most common, with the proportions for larger sizes initially decreasing but then following a more irregular pattern. The maximum number of classes generated by any undirected graph was found to increase approximately factorially. The program also includes a new variation of orderly algorithm for generating undirected graphs.

#index 1650514
#* Robust combination of local controllers
#@ Carlos Guestrin;Dirk Ormoneit
#t 2001
#c 12
#% 135966
#% 318485
#% 367254
#% 393786
#% 1068430
#% 1650589
#% 1650613
#! Finding solutions to high dimensional Markov Decision Processes (MDPs) is a difficult problem, especially in the presence of uncertainty or if the actions and time measurements are continuous. Frequently this difficulty can be alleviated by the availability of problem-specific knowledge. For example, it may be relatively easy to design controllers that are good locally, though having no global guarantees. We propose a nonparametric method to combine these local controllers to obtain globally good solutions. We apply this formulation to two types of problems: motion planning (stochastic shortest path problems) and discounted-cost MDPs. For motion planning, we argue that only considering the expected cost of a path may be overly simplistic in the presence of uncertainty. We propose an alternative: finding the minimum cost path, subject to the constraint that the robot must reach the goal with high probability. For this problem, we prove that a polynomial number of samples is sufficient to obtain a high probability path. For discounted MDPs, we consider various problem formulations that explicitly deal with model uncertainty. We provide empirical evidence of the usefulness of these approaches using the control of a robot arm.

#index 1650515
#* Similarity measures on preference structures, part ii: utility functions
#@ Vu Ha;Peter Haddawy;John Miyamoto
#t 2001
#c 12
#% 8951
#% 90740
#% 173879
#% 235439
#% 282625
#% 528026
#% 529348
#% 1650295
#% 1650321
#% 1650586
#! In previous work [8] we presented a casebased approach to eliciting and reasoning with preferences. A key issue in this approach is the definition of similarity between user preferences. We introduced the probabilistic distance as a measure of similarity on user preferences, and provided an algorithm to compute the distance between two partially specified value functions. This is for the case of decision making under certainty. In this paper we address the more challenging issue of computing the probabilistie distance in the ease of decision making under uncertainty. We present algorithms to compute the probabilistic distance between two completely or partially specified utility functions. We demonstrate the use of this algorithm with a medical data set of partially specified patient preferences, where none of the other existing distance measures appear definable. Using this data set, we also demonstrate that the case-based approach to preference elicitation is applicable in domains with uncertainty.

#index 1650516
#* Causes and explanations: a structural-model approach: part i: causes
#@ Joseph Y. Halpern;Judea Pearl
#t 2001
#c 12
#% 243717
#% 297171
#% 417721
#% 1271819
#% 1272178
#% 1289151
#% 1290153
#! We propose a new definition of actual causes, using structural equations to model counterfactuals. We show that the definition yields a plausible and elegant account of causation that handles well examples which have caused problems for other definitions and resolves major difficulties in the traditional account.

#index 1650517
#* A logic for reasoning about upper probabilities
#@ Joseph Y. Halpern;Riccardo Pucella
#t 2001
#c 12
#% 20853
#% 73571
#% 110373
#% 183232
#! We present a propositional logic to reason about the uncertainty of events, where the uncertainty is modeled by a set of probability measures assigning an interval of probability to each event. We give a sound and complete axiomatization for the logic, and show that the satisfiability problem is NP-complete, no harder than satisfiability for propositional logic.

#index 1650518
#* Dynamic programming model for determining bidding strategies in sequential auctions: quasi-linear utility and budget constraints
#@ Hiromitsu Hattori;Makoto Yokoo;Yuko Sakurai;Toramatsu Shintani
#t 2001
#c 12
#% 267752
#% 274891
#% 283057
#% 635935
#% 743843
#% 978234
#% 978268
#% 1273805
#% 1273807
#% 1273808
#% 1291498
#! In this paper, we develop a new method for finding the optimal bidding strategy in sequential auctions, using a dynamic programming technique. The existing method assumes that the utility of a user is represented in an additive form. From this assumption, the remaining endowment of money must be explicitly represented in each state, and the calculation of the optimal bidding strategy becomes time-consuming when the initial endowment of money m becomes large. More specifically, we develop a new problem formalization whereby the utility of a user can be represented in a quasi-linear form. By assuming a quasi-linear utility, the payment can be represented as a state-transition cost. Accordingly, we can avoid explicitly representing the remaining endowment of money. Experimental evaluations show that we can obtain more than an m-fold speed-up in the computation time. Furthermore, we have developed a method for obtaining a semi-optimal bidding strategy under budget constraints, and have experimentally confirmed the efficacy of this method.

#index 1650519
#* A clustering approach to solving large stochastic matching problems
#@ Milos Hauskrecht;Eli Upfal
#t 2001
#c 12
#% 224762
#% 265807
#% 527994
#% 1290041
#% 1290043
#% 1478746
#% 1650589
#! In this work we focus on efficient heuristics for solving a class of stochastic planning problems that arise in a variety of business, investment, and industrial applications. The problem is best described in terms of future buy and sell contracts. By buying less reliable, but less expensive, buy (supply) contracts, a company or a trader can cover a position of more reliable and more expensive sell contracts. The goal is to maximize the expected net gain (profit) by constructing a close to optimum portfolio out of the available buy and sell contracts. This stochastic planning problem can be formulated as a two-stage stochastic linear programming problem with recourse. However, this formalization leads to solutions that are exponential in the number of possible failure combinations. Thus, this approach is not feasible for large scale problems. In this work we investigate heuristic approximation techniques alleviating the efficiency problem. We primarily focus on the clustering approach and devise heuristics for finding clusterings leading to good approximations. We illustrate the quality and feasibility of the approach through experimental data.

#index 1650520
#* Discovering multiple constraints that are frequently approximately satisfied
#@ Geoffrey E. Hinton;Yee-Whye Teh
#t 2001
#c 12
#% 92145
#% 92146
#% 303620
#% 450888
#% 520224
#! Some high-dimensional datasets can be modelled by assuming that there are many different linear constraints, each of which is Frequently Approximately Satisfied (FAS) by the data. The probability of a data vector under the model is then proportional to the product of the probabilities of its constraint violations. We describe three methods of learning products of constraints using a heavy-tailed probability distribution for the violations.

#index 1650521
#* A bayesian approach to tackling hard computational problems
#@ Eric Horvitz;Yongshao Ruan;Carla Gomes;Henry Kautz;Bart Selman;Max Chickering
#t 2001
#c 12
#% 65441
#% 103309
#% 129987
#% 155827
#% 160208
#% 179788
#% 183497
#% 266200
#% 327779
#% 420713
#% 527850
#% 529517
#% 1273727
#% 1273776
#% 1289196
#% 1477331
#% 1478761
#% 1478764
#% 1650661
#% 1650705
#! We describe research and results centering on the construction and use of Bayesian models that can predict the run time of problem solvers. Our efforts are motivated by observations of high variance in the time required to solve instances for several challenging problems. The methods have application to the decision-theoretic control of hard search and reasoning algorithms. We illustrate the approach with a focus on the task of predicting run time for general and domain-specific solvers on a hard class of structured constraint satisfaction problems. We review the use of learned models to predict the ultimate length of a trial, based on observing the behavior of the search algorithm during an early phase of a problem session. Finally, we discuss how we can employ the models to inform dynamic run-time decisions.

#index 1650522
#* Estimating well-performing bayesian networks using Bernoulli mixtures
#@ Geoff Jarrad
#t 2001
#c 12
#% 129987
#% 130878
#% 443025
#% 528004
#% 1650337
#% 1650719
#% 1650783
#! A novel method for estimating Bayesian network (BN) parameters from data is presented which provides improved performance on test data. Previous research has shown the value of representing conditional probability distributions (CPDs) via neural networks (Neal 1992), noisy-OR gates (Neal 1992, Diez 1993) and decision trees (Friedman and Goldszmidt 1996). The Bernoulli mixture network (BMN) explicitly represents the CPDs of discrete BN nodes as mixtures of local distributions, each having a different set of parents. This increases the space of possible structures which can be considered, enabling the CPDs to have finer-grained dependencies. The resulting estimation procedure induces a model that is better able to emulate the underlying interactions occurring in the data than conventional conditional Bernoulli network models. The results for artificially generated data indicate that overfitting is best reduced by restricting the complexity of candidate mixture substructures local to each node. Furthermore, mixtures of very simple substructures can perform almost as well as more complex ones. The BMN is also applied to data collected from an online adventure game with an application to keyhole plan recognition. The results show that the BMN-based model brings a dramatic improvement in performance over a conventional conditional Bernoulli BN model.

#index 1650523
#* Graphical models for game theory
#@ Michael Kearns;Michael L. Littman;Satinder Singh
#t 2001
#c 12
#% 527993
#! We introduce a compact graph-theoretic representation for multi-party game theory. Our main result is a provably correct and efficient algorithm for computing approximate Nash equilibria in one-stage games represented by trees or sparse graphs.

#index 1650524
#* On characterizing inclusion of Bayesian networks
#@ Tomáš Kočka;Remco R. Bouckaert;Milan Studeny
#t 2001
#c 12
#% 44876
#% 417570
#% 527514
#% 527830
#% 1650638
#! The inclusion problem deals with how to characterize (in graphical terms) whether all independence statements in the model induced by a DAG K are in the model induced by a second DAG L. Meek (1997) conjectured that this inclusion holds iff there exists a sequence of DAGs from L to K such that only certain 'legal' arrow reversal and 'legal' arrow adding operations are performed to get the next DAG in the sequence. In this paper we give several characterizations of inclusion of DAG models and verify Meek's conjecture in the case that the DAGs K and L differ in at most one adjacency. As a warming up a rigorous proof of graphical characterizations of equivalence of DAGs is given.

#index 1650525
#* Improved learning of Bayesian networks
#@ Tonáš Kočka;Robert Castelo
#t 2001
#c 12
#% 101213
#% 129497
#% 129987
#% 197387
#% 527830
#% 528304
#% 528335
#% 1650638
#% 1650771
#! The search space of Bayesian Network structures is usually defined as Acyclic Directed Graphs (DAGs) and the search is done by local transformations of DAGs. But the space of Bayesian Networks is ordered with respect to inclusion and it is natural to consider that a good search policy should take this into account. The first attempt to do this (Chickering 1996) was using equivalence classes of DAGs instead of DAGs itself. This approach produces better results but it is significantly slower. We present a compromise between these two approaches. It uses DAGs to search the space in such a way that the ordering by inclusion is taken into account. This is achieved by repetitive usage of local moves within each equivalence class of DAGs. We show that this new approach produces better results than the original DAGs approach without substantial change in time complexity. We present empirical results, within the framework of heuristic search and Markov Chain Monte Carlo, provided through the Alarm dataset.

#index 1650526
#* Classifier learning with supervised marginal likelihood
#@ Petri Kontkanen;Petri Myllymäki;Henry Tirri
#t 2001
#c 12
#% 44876
#% 197387
#% 246832
#% 272995
#% 276523
#% 304919
#% 1650303
#% 1650722
#! It has been argued that in supervised classification tasks it may be more sensible to perform model selection with respect to a more focused model selection score, like the supervised (conditional) marginal likelihood, than with respect to the standard unsupervised marginal likelihood criterion. However, for most Bayesian network models, computing the supervised marginal likelihood score takes exponential time with respect to the amount of observed data. In this paper, we consider diagnostic Bayesian network classifters where the significant model parameters represent conditional distributions for the class variable, given the values of the predictor variables, in which case the supervised marginal likelihood can be computed in linear time with respect to the data. As the number of model parameters grows in this case exponentially with respect to the number of predictors, we focus on simple diagnostic modeis where the number of relevant predictors is small, and suggest two approaches for applying this type of models in classification. The first approach is based on mixtures of simple diagnostic models, while in the second approach we apply the small predictor sets of the simple diagnostic models for augmenting the Naive Bayes classifier.

#index 1650527
#* Plausible reasoning from spatial observations
#@ Jérôme Lang;Philippe Muller
#t 2001
#c 12
#% 161238
#% 168564
#% 404251
#! This article deals with plausible reasoning from incomplete knowledge about large-scale spatial properties. The available information, consisting of a set of pointwise observations, is extrapolated to neighbour points. We use belief functions to represent the influence of the knowledge at a given point to another point; the quantitative strength of this influence decreases when the distance between both points increases. These influences are aggregated using a variant of Dempster's rule of combination taking into account the relative dependence between observations.

#index 1650528
#* Iterative Markov chain Monte Carlo computation of reference priors and minimax risk
#@ John Lafferty;Larry Wasserman
#t 2001
#c 12
#% 115608
#% 1809072
#! We present an iterative Markov chain Monte Carlo algorithm for computing reference priors and minimax risk for general parametric families. Our approach uses MCMC techniques based on the Blahut-Arimoto algorithm for computing channel capacity in information theory. We give a statistical analysis of the algorithm, bounding the number of samples required for the stochastic algorithm to closely approximate the deterministic algorithm in each iteration. Simulations are presented for several examples from exponential families. Although we focus on applications to reference priors and minimax risk, the methods and analysis we develop are applicable to a much broader class of optimization problems and iterative algorithms.

#index 1650529
#* Hypothesis management in situation-specific network construction
#@ Kathryn Blackmond Laskey;Suzanne M. Mahoney;Ed Wright
#t 2001
#c 12
#% 101215
#% 129369
#% 147680
#% 387978
#% 1650310
#% 1650326
#% 1650607
#% 1650731
#% 1650734
#% 1650735
#! This paper considers the problem of knowledgebased model construction in the presence of uncertainty about the association of domain entities to random variables. Multi-entity Bayesian networks (MEBNs) are defined as a representation for knowledge in domains characterized by uncertainty in the number of relevant entities, their interrelationships, and their association with observables. An MEBN implicitly specifies a probability distribution in terms of a hierarchically structured collection of Bayesian network fragments that together encode a joint probability distribution over arbitrarily many interrelated hypotheses. Although a finite query-complete model can always be constructed, association uncertainty typically makes exact model construction and evaluation intractable. The objective of hypothesis management is to balance tractability against accuracy. We describe an approach to hypothesis management, present an application to the problem of military situation awareness, and compare our approach to related work in the tracking and fusion literature.

#index 1650530
#* Inference in hybrid networks: theoretical limits and practical algorithms
#@ Uri Lerner;Ronald Parr
#t 2001
#c 12
#% 32357
#% 36562
#% 252472
#% 424793
#% 424819
#% 529185
#% 857094
#% 1650568
#! An important subclass of hybrid Bayesian networks are those that represent Conditional Linear Gaussian (CLG) distributions -- a distribution with a multivariate Gaussian component for each instantiation of the discrete variables. In this paper we explore the problem of inference in CLGs, and provide complexity resuits for an important class of CLGs, which includes Switching Kalman Filters. In particular, we prove that even if the CLG is restricted to an extremely simple structure of a polytree, the inference task is NP-hard. Furthermore, we show that, unless P=NP, even approximate inference on these simple networks is intractable. Given the often prohibitive computational cost of even approximate inference, we must take advantage of special domain properties which may enable efficient inference. We concentrate on the fault diagnosis domain, and explore several approximate inference algorithms. These algorithms try to find a small subset of Gaussians which are a good approximation to the full mixture distribution. We consider two Monte Carlo approaches and a novel approach that enumerates mixture components in order of prior probability. We compare these methods on a variety of problems and show that our novel algorithm is very promising for large, hybrid diagnosis problems.

#index 1650531
#* Exact inference in networks with discrete children of continuous parents
#@ Uri Lerner;Eran Segal;Daphne Koller
#t 2001
#c 12
#% 32357
#% 527664
#% 528019
#% 528327
#% 529185
#% 1650302
#% 1650317
#% 1650732
#! Many real life domains contain a mixture of discrete and continuous variables and can be modeled as hybrid Bayesian Networks (BNs). An important subclass of hybrid BNs are conditional linear Gaussian (CLG) networks, where the conditional distribution of the continuous variables given an assignment to the discrete variables is a multivariate Gaussian. Lauritzen's extension to the clique tree algorithm can be used for exact inference in CLG networks. However, many domains include discrete variables that depend on continuous ones, and CLG networks do not allow such dependencies to be represented. In this paper, we propose the first "exact" inference algorithm for augmented CLG networks -- CLG networks augmented by allowing discrete children of continuous parents. Our algorithm is based on Lauritzen's algorithm, and is exact in a similar sense: it computes the exact distributions over the discrete nodes, and the exact first and second moments of the continuous ones, up to inaccuracies resulting from numerical integration used within the algorithm. In the special case of softmax CPDs, we show that integration can often be done efficiently, and that using the first two moments leads to a particularly accurate approximation. We show empirically that our algorithm achieves substantially higher accuracy at lower cost than previous algorithms for this task.

#index 1650532
#* Probabilistic logic programming under inheritance with overriding
#@ Thomas Lukasiewicz
#t 2001
#c 12
#% 3034
#% 73571
#% 77841
#% 89958
#% 109950
#% 144840
#% 147677
#% 167626
#% 171477
#% 211580
#% 216970
#% 228812
#% 318484
#% 336009
#% 408396
#% 503986
#% 564809
#% 780340
#% 1650284
#% 1650727
#! We present probabilistic logic programming under inheritance with overriding. This approach is based on new notions of entailment for reasoning with conditional constraints, which are obtained from the classical notion of logical entailment by adding inheritance with overriding. This is done by using recent approaches to probabilistic default reasoning with conditional constraints. We analyze the semantic properties of the new entailment relations. We also present algorithms for probabilistic logic programming under inheritance with overriding, and we analyze its complexity in the propositional case.

#index 1650533
#* Solving influence diagrams using HUGIN, shafer-shenoy and lazy propagation
#@ Anders L. Madsen;Dennis Nilsson
#t 2001
#c 12
#% 34262
#% 119308
#% 289951
#% 528021
#% 567872
#% 1650602
#! In this paper we present three different architectures for the evaluation of influence diagrams: HUGIN, Shafer-Shenoy (S-S), and Lazy Propagation (LP). HUGIN and LP are two new architectures introduced in this paper. The computational complexity using the three architectures are compared on the same structure, the Limited Memory Influence Diagram (LIMID), where only the requisite information for the computation of optimal policies is depicted. Because the requisite information is explicitly represented in the diagram, the evaluation procedure can take advantage of it. Previously, it has been shown that significant savings in computational time can be obtained by performing the calculation on the LIMID rather than on the traditional influence diagram. In this paper we show how the obtained savings is considerably increased when the computations are performed according to the LP scheme.

#index 1650534
#* A Bayesian multiresolution independence test for continuous variables
#@ Diraitris Margaritis;Sebastian Thrun
#t 2001
#c 12
#% 44876
#% 277503
#% 465904
#! In this paper we present a method of computing the posterior probability of conditional independence of two or more continuous variables from data, examined at several resolutions. Our approach is motivated by the observation that the appearance of continuous data varies widely at various resolutions, producing very different independence estimates between the variables involved. Therefore, it is difficult to ascertain independence without examining discretized data at several carefully selected resolutions. In our paper, we accomplish this using the exact computation of the posterior probability of independence, calculated analytically given a resolution. At each examined resolution and boundary placement, we assume a multinomial distribution with Dirichlet priors for the discretized table parameters, and compute the posterior using Bayesian integration. Across resolutions, we use a search procedure to approximate the Bayesian integral of probability over an exponential number of possible boundary placements. Our method generalizes to an arbitrary number variables in a straightforward manner. The test is suitable for Bayesian network learning algorithms that use independence tests to infer the network structure, in domains that contain any mix of continuous, ordinal discrete, and categorical variables.

#index 1650535
#* Aggregating learned probabilistic beliefs
#@ Pedrito Maynard-Reid;Urszula Chajewska
#t 2001
#c 12
#% 44876
#% 101213
#% 130104
#% 466743
#% 1650325
#% 1650715
#! We consider the task of aggregating beliefs of several experts. We assume that these beliefs are represented as probability distributions. We argue that the evaluation of any aggregation technique depends on the semantic context of this task. We propose a framework, in which we assume that nature generates samples from a 'true' distribution and different experts form their beliefs based on the subsets of the data they have a chance to observe. Naturally, the optimal aggregate distribution would be the one learned from the combined sample sets. Such a formulation leads to a natural way to measure the accuracy of the aggregation mechanism. We show that the well-known aggregation operator LinOP is ideally suited for that task. We propose a LinOP-based learning algorithm, inspired by the techniques developed for Bayesian learning, which aggregates the experts' distributions represented as Bayesian networks. We show experimentally that this algorithm performs well in practice.

#index 1650536
#* Expectation propagation for approximate Bayesian inference
#@ Thomas P. Minka
#t 2001
#c 12
#% 272514
#% 274216
#% 527512
#% 715096
#% 857429
#% 1650302
#% 1650318
#% 1650568
#% 1810385
#! This paper presents a new deterministic approximation technique in Bayesian networks. This method, "Expectation Propagation," unifies two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. Loopy belief propagation, because it propagates exact belief states, is useful for a limited class of belief networks, such as those which are purely discrete. Expectation Propagation approximates the belief states by only retaining expectations, such as mean and varitmce, and iterates until these expectations are consistent throughout the network. This makes it applicable to hybrid networks with discrete and continuous nodes. Experiments with Gaussian mixture models show Expectation Propagation to be donvincingly better than methods with similar computational cost: Laplace's method, variational Bayes, and Monte Carlo. Expectation Propagation also provides an efficient algorithm for training Bayes point machine classifiers.

#index 1650537
#* Recognition networks for approximate inference in BN20 networks
#@ Quaid Morris
#t 2001
#c 12
#% 144664
#% 191855
#% 476879
#% 527688
#% 1271825
#% 1272398
#% 1650318
#! A recognition network is a multilayer perception (MLP) trained to predict posterior maxginals given observed evidence in a particulax Bayesian network. The input to the MLP is a vector of the states of the evidential nodes. The activity of an output unit is interpreted as a prediction of the posterior marginal of the corresponding variable. The MLP is trained using samples generated from the corresponding Bayesian network. We evaluate a recognition network that was trained to do inference in a large Bayesian network, similax in structure and complexity to the Quick Medical Reference, Decision Theoretic (QMR-DT) network. Our network is a binary, two-layer, noisy-OR (BN20) network containing over 4000 potentially observable nodes and over 600 unobservable, hidden nodes. In real medical diagnosis, most observables are unavailable, and there is a complex and unknown process that selects which ones axe provided. We incorporate a very basic type of selection bias in our network: a known preference that available observables are positive rather than negative. Even this simple bias has a significant effect on the posterior. We compare the performance of our recognition network to state-of-the-art approximate inference algorithms on a large set of test cases. In order to evaluate the effect of our simplistic model of the selection bias, we evaluate algorithms using a variety of incorrectly modelled selection biases. Recognition networks perform well using both correct and incorrect selection biases.

#index 1650538
#* The factored frontier algorithm for approximate inference in DBNs
#@ Kevin Murphy;Yair Weiss
#t 2001
#c 12
#% 44876
#% 101510
#% 128629
#% 225837
#% 246836
#% 304882
#% 388024
#% 857454
#% 1271902
#% 1650318
#% 1650568
#% 1848680
#! The Factored Frontier (FF) algorithm is a simple approximate inference algorithm for Dynamic Bayesian Networks (DBNs). It is very similar to the fully factorized version of the Boyen-Koller (BK) algorithm, but instead of doing an exact update at every step followed by marginalisation (projection), it always works with factored distributions. Hence it can be applied to models for which the exact update step is intractable. We show that FF is equivalent to (one iteration of) loopy belief propagation (LBP) on the original DBN, and that BK is equivalent (to one iteration of) LBP on a DBN where we cluster some of the nodes. We then show empirically that by iterating more than once, LBP can improve on the accuracy of both FF and BK. We compare these algorithms on two real-world DBNs: the first is a model of a water treatment plant, and the second is a coupled HMM, used to model freeway traffic.

#index 1650539
#* A case study in knowledge discovery and elicitation in an intelligent tutoring application
#@ Ann Nicholson;Tal Boneh;Tim Wilkin;Kaye Stacey;Liz Sonenberg;Vicki Steinle
#t 2001
#c 12
#% 424810
#% 443356
#% 501811
#% 1650658
#! Most successful Bayesian network (BN) applications to date have been built through knowledge elicitation from experts. This is difficult and time consuming, which has lead to recent interest in automated methods for learning BNs from data. We present a case study in the construction of a BN in an intelligent tutoring application, specifically decimal misconceptions. We describe the BN construction using expert elicitation and then investigate how certain existing automated knowledge discovery methods might support the BN knowledge engineering process.

#index 1650540
#* Lattice particle filters
#@ Dirk Ormoneit;Christiane Lemieux;David J. Fleet
#t 2001
#c 12
#% 116388
#% 266616
#% 283140
#% 424075
#% 458100
#% 458107
#% 458130
#% 739254
#! A promising approach to approximate inference in state-space models is particle filtering. However, the performance of particle filters often varies significantly due to their stochastic nature. We present a class of algorithms, called lattice particle filters, that circumvent this difficulty by placing the particles deterministically according to a Quasi-Monte Carlo integration rule. We describe a practical realization of this idea, discuss its theoretical properties, and its efficiency. Ex~ perimental results with a synthetic 2D tracking problem show that the lattice particle filter is equivalent to a conventional particle filter that has between 10 and 60% more particles, depending on their "sparsity" in the state-space. We also present results on inferring 3D human motion from moving light displays.

#index 1650541
#* Approximating MAP using local search
#@ James D. Park;Adnan Darwiche
#t 2001
#c 12
#% 68244
#% 136358
#% 302413
#% 329486
#% 388024
#% 527988
#% 528025
#% 653203
#% 1272302
#% 1650778
#! MAP is the problem of finding a most probable instantiation of a set of variables in a Bayesian network, given (partial) evidence about the complement of that set. Unlike computing priors, posteriors, and MPE (a special case of MAP), the time and space complexity of MAP is not only exponential in the network treewidth, but also in a larger parameter known as the "constrained" treewidth. In practice, this means that computing MAP can be orders of magnitude more expensive than computing priors, posteriors or MPE. For this reason, MAP computations are generally avoided or approximated by practitioners. We have investigated the approximation of MAP using local search. The local search method has a space complexity which is exponential only in the network treewidth, as is the complexity of each step in the search process. Our experimental results show that local search provides a very good approximation of MAP, while requiring a small number of search steps. Practically, this means that the average case complexity of local search is often exponential only in treewidth as opposed to the constrained treewidth, making approximating MAP as efficient as other computations.

#index 1650542
#* Direct and indirect effects
#@ Judea Pearl
#t 2001
#c 12
#% 297171
#! The direct effect of one event on another can be defined and measured by holding constant all intermediate variables between the two. Indirect effects present conceptual and practical difficulties (in nonlinear models), because they cannot be isolated by holding certain variables constant. This paper presents a new way of defining the effect transmitted through a restricted set of paths, without controlling variables on the remaining paths. This permits the assessment of a more natural type of direct and indirect effects, one that is applicable in both linear and nonlinear models and that has broader policy-related interpretations. The paper establishes conditions under which such assessments can be estimated consistently from experimental and nonexperimental data, and thus extends path-analytic techniques to nonlinear and nonparametric models.

#index 1650543
#* Sufficiency, separability and temporal probabilistic models
#@ Avi Pfeffer
#t 2001
#c 12
#% 89748
#% 265806
#% 283131
#% 1271900
#% 1273913
#% 1650568
#% 1650767
#! Suppose we are given the conditional probability of one variable given some other variables. Normally the full joint distribution over the conditioning variables is required to determine the probability of the conditioned variable. Under what circumstances are the marginal distributions over the conditioning variables sufficient to determine the probability of the conditioned variable? Sufficiency in this sense is equivalent to additive separability of the conditional probability distribution. Such separability structure is natural and can be exploited for efficient inference. Separability has a natural generalization to conditional separability. Separability provides a precise notion of hierarchical decomposition in temporal probabilistic models. Given a system that is decomposed into separable subsystems, exact marginal probabilities over subsystems at future points in time can be computed by propagating maxginal subsystem probabilities, rather than complete system joint probabilities. Thus, separability can make exact prediction tractable. However, observations can break separability, so exact monitoring of dynamic systems remains hard.

#index 1650544
#* Toward general analysis of recursive probability models
#@ Daniel Pless;George Luger
#t 2001
#c 12
#% 6304
#% 44876
#% 101031
#% 171477
#% 266230
#% 529159
#% 711139
#% 1478844
#% 1650326
#% 1650731
#% 1650734
#% 1650767
#% 1650778
#! There is increasing interest within the research community in the design and use of recursive probability models. There remains concern about computational complexity costs and the fact that computing exact solutions can be intractable for many nonrecursive models. Although inference is undecidable in the general case for recursive problems, several research groups are actively developing computational techniques for recursive stochastic languages. We have developed an extension to the traditional λ calculus as a framework for families of Turing complete stochastic languages. We have also developed a class of exact inference algorithms based on the traditional reductions of the λ calculus. We further propose that using the deBruijn notation (a λ-calculus notation with nameless dummies) supports effective caching in such systems, as the reuse of partial solutions is an essential component of efficient computation. Finally, our extension to the λ-calculus offers a foundation and general theory for the construction of recursive stochastic modeling languages as well as promise for effective caching and efficient approximation algorithms for inference.

#index 1650545
#* Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments
#@ Alexandrin Popescul;David M. Pennock;Steve Lawrence
#t 2001
#c 12
#% 124010
#% 173879
#% 202011
#% 220706
#% 266281
#% 283169
#% 301259
#% 301590
#% 406493
#% 438103
#% 445370
#% 465906
#% 465928
#% 528152
#% 528156
#% 529806
#% 564279
#% 1272396
#% 1273828
#% 1650298
#% 1650569
#! Recommender systems leverage product and community information to target products to consumers. Researchers have developed collaborative recommenders, content-based recommenders, and a few hybrid systems. We propose a unified probabilistic framework for merging collaborative and content-based recommendations. We extend Hofmarm's (1999) aspect model to incorporate three-way co-occurrence data among users, items, and item content. The relative influence of collaboration data versus content data is not imposed as an exogenous parameter, but rather emerges naturally from the given data sources. However, global probabilistic models coupled with standard EM learning algorithms tend to drastically overfit in the sparsedata situations typical of recommendation applications. We show that secondary content information can often be used to overcome sparsity. Experiments on data from the Researchlndex library of Computer Science publications show that appropriate mixture models incorporating secondary data produce significantly better quality recommenders than k-nearest neighbors (k-NN). Global probabilistic models also allow more general inferences than local methods like k-NN.

#index 1650546
#* Vector-space analysis of belief-state approximation for POMDPs
#@ Pascal Poupart;Craig Boutilier
#t 2001
#c 12
#% 30037
#% 102136
#% 179940
#% 283210
#% 528003
#% 528339
#% 1271823
#% 1476294
#% 1478842
#% 1650568
#% 1650702
#! We propose a new approach to value-directed belief state approximation for POMDPs. The value directed model allows one to choose approximation methods for belief state monitoring that have a small impact on decision quality. Using a vector space analysis of the problem, we devise two new search procedures for selecting an approximation scheme that have much better computational properties than existing methods, Though these provide looser error bounds, we show empirically that they have a similar impact on decision quality in practice, and run up to two orders of magnitude more quickly.

#index 1650547
#* Value-directed sampling methods for monitoring POMDPs
#@ Pascal Poupart;Luis E. Ortiz;Craig Boutilier
#t 2001
#c 12
#% 179940
#% 266616
#% 267315
#% 424819
#% 527691
#% 528003
#% 528169
#% 528185
#% 564834
#% 1476294
#% 1650312
#% 1650568
#% 1650666
#% 1650704
#! We consider the problem of approximate belief-state monitoring using particle filtering for the purposes of implementing a policy for a partially observable Markov decision process (POMDP). While particle illtering has become a widely used tool in AI for monitoring dynamical systems, rather scant attention has been paid to their use in the context of decision making. Assuming the existence of a value function, we derive error bounds on decision quality associated with filtering using importance sampling. We also describe an adaptive procedure that can be used to dynamically determine the number of samples required to meet specific error bounds, Empirical evidence is offered supporting this technique as a profitable means of directing sampiing effort where it is needed to distinguish policies.

#index 1650548
#* A mixed graphical model for rhythmic parsing
#@ Christopher Raphael
#t 2001
#c 12
#% 388024
#% 852280
#! A method is presented for the rhythmic parsing problem: Given a sequence of observed musical note onset times, we simultaneously estimate the corresponding notated rhythm and tempo process. A graphical model is developed that represents the evolution of tempo aud rhythm and relates these hidden quantities to an observable performance. The rhythm variables are discrete and the tempo and observation variables are continuous. We show how to compute the globally most likely configuration of the tempo and rhythm variables given an observation of note onset times. Preliminary experiments are presented on a small data set. A generalization to computing MAP estimates for arbitrary conditional Gaussian distributions is outlined.

#index 1650549
#* Decision-theoretic planning with concurrent temporally extended actions
#@ Khashayar Rohanimanesh;Sridhar Mahadevan
#t 2001
#c 12
#% 272665
#% 286423
#% 314843
#% 1273919
#% 1290041
#% 1478746
#! We investigate a model for planning under uncertainty with temporally extended actions, where multiple actions can be taken concurrently at each decision epoch. Our model is based on the options framework, and combines it with factored state space models, where the set of options can be partitioned into classes that affect disjoint state variables. We show that the set of decision epochs for concurrent options defines a semi-Markov decision process, if the underlying temporally extended actions being parallelized are restricted to Markov options. This property allows us to use SMDP algorithms for computing the value function over concurrent options. The concurrent options model allows overlapping execution of options in order to achieve higher performance or in order to perform a complex task. We describe a simple experiment using a navigation task which illustrates how concurrent options results in a more optimal plan when compared to the case when only one option is taken at a time.

#index 1650550
#* A tractable POMDP for a class of sequencing problems
#@ Paat Rusmevichientong;Benjamin Van Roy
#t 2001
#c 12
#% 30037
#% 44876
#% 92301
#% 361817
#% 527688
#! We consider a partially observable Markov decision problem (POMDP) that models a class of sequencing problems. Although POMDPs are typically intractable, our formulation admits tractable solution. Instead of maintaining a value function over a highdimensional set of belief states, we reduce the state space to one of smaller dimension, in which grid-based dynamic programming techniques are effective. We develop an error bound for the resulting approximation, and discuss an application of the model to a problem in targeted advertising.

#index 1650551
#* Symmetric collaborative filtering using the noisy sensor model
#@ Rita Sharma;David Poole
#t 2001
#c 12
#% 173879
#% 188076
#% 202011
#% 301590
#% 465928
#% 528156
#% 1650569
#! Collaborative filtering is the process of making recommendations regarding the potential preference of a user, for example shopping on the Internet, based on the preference ratings of the user and a number of other users for various items. This paper considers collaborative filtering based on explicit multivalued ratings. To evaluate the algorithms, we consider only pure collaborative filtering, using ratings exclusively, and no other information about the people or items. Our approach is to predict a user's preferences regarding a particular item by using other people who rated that item and other items rated by the user as noisy sensors. The noisy sensor model uses Bayes' theorem to compute the probability distribution for the user's rating of a new item. We give two variant models: in one, we learn a classical normal linear regression model of how users rate items; in another, we assume different users rate items the same, but the accuracy of the sensors needs to be learned. We compare these variant models with state-of-the-art techniques and show how they are significantly better, whether a user has rated only two items or many. We report empirical results using the EachMovie database of movie ratings. We also show that by considering items similarity along with the users similarity, the accuracy of the prediction increases.

#index 1650552
#* Policy improvement for POMDPs using normalized importance sampling
#@ Christian R. Shelton
#t 2001
#c 12
#% 124687
#% 374580
#% 464438
#% 466259
#% 466751
#% 563107
#! We present a new method for estimating the expected return of a POMDP from experience. The estimator does not assume any knowledge of the POMDP, can estimate the returns for finite state controllers, allows experience to be gathered from arbitrary sequences of policies, and estimates the return for any new policy. We motivate the estimator from function-approximation and importance sampling points-of-view and derive its bias and variance. Although the estimator is biased, it has low variance and the bias is often irrelevant when the estimator is used for pair-wise comparisons. We conclude by extending the estimator to policies with memory and compare its performance in a greedy search algorithm to the REINFORCE algorithm showing an order of magnitude reduction in the number of trials required.

#index 1650553
#* Maximum likelihood bounded tree-width Markov networks
#@ Nathan Srebro
#t 2001
#c 12
#% 325348
#% 709446
#% 1650281
#! We study the problem of projecting a distribution onto (or finding a maximum likelihood distribution among) Markov networks of bounded tree-width. By casting it as the combinatorial optimization problem of finding a maximum weight hypertree, we prove that it is NP-hard to solve exactly and provide an approximation algorithm with a provable performance guarantee.

#index 1650554
#* Causal discovery from changes
#@ Jin Tian;Judea Pearl
#t 2001
#c 12
#% 129987
#% 197387
#% 297171
#% 420110
#% 527830
#% 1650279
#% 1650673
#! We propose a new method of discovering causal structures, based on the detection of local, spontaneous changes in the underlying data-generating model. We analyze the classes of structures that axe equivalent relative to a stream of distributions produced by local changes, and devise algorithms that output graphical representations of these equivalence classes. We present experimental results, using simulated data, and examine the errors associated with detection of changes and recovery of structures.

#index 1650555
#* Bayesian error-bars for belief net inference
#@ Tim Van Allen;Russell Greiner;Peter Hooper
#t 2001
#c 12
#% 44876
#% 68244
#% 129987
#% 216984
#% 246835
#% 277465
#% 277480
#% 333677
#% 528025
#% 1650602
#% 1650719
#% 1650767
#! A Bayesian Belief Network (BN) is a model of a joint distribution over a finite set of variables, with a DAG structure to represent the immediate dependencies between the variables, and a set of parameters (aka CPTables) to represent the local conditional probabilities of a node, given each assignment to its parents. In many situations, the parameters are themselves treated as random variables -- reflecting the uncertainty remaining after drawing on knowledge of domain experts and/or observing data generated by the network. A distribution over the CPtable parameters induces a distribution for the response the BN will return to any "What is Pr{H/E}?" query. This paper investigates the distribution of this response, shows that it is asymptotically normal, and derives expressions for its mean and asymptotic variance. We show that this computation has the same complexity as simply computing the (mean value of the) response -- i.e., O(n exp(w)), where n is the number of variables and w is the effective tree width. We also provide empirical evidence showing that the error-bars computed from our estimates are fairly accurate in practice, over a wide range of belief net structures and queries.

#index 1650556
#* Analysing sensitivity data from probabilistic networks
#@ Linda C. van der Gaag;Silja Renooij
#t 2001
#c 12
#% 217078
#% 417831
#% 528027
#% 558867
#% 1650338
#% 1650789
#% 1784188
#! With the advance of efficient algorithms for sensitivity analysis of probabilistic networks, studying the sensitivities revealed by real-life networks is becoming feasible. As the amount of data yielded by an analysis of even a moderatelysized network is already overwhelming, effective methods for extracting relevant information from these data are called for. One such method is to study the derivatives of the sensitivity functions yielded, to identify the parameters that upon variation are expected to have a large effect on a probability of interest. We further propose to build upon the concept of admissible deviation, which captures the extent to which a parameter can be varied without inducing a change in the most likely outcome. We illustrate these concepts by means of a sensitivity analysis of a reallife probabilistic network in the field of oncology.

#index 1650557
#* The optimal reward baseline for gradient-based reinforcement learning
#@ Lex Weaver;Nigel Tao
#t 2001
#c 12
#% 124687
#% 285808
#% 384911
#% 465759
#% 690846
#! There exist a number of reinforcement learning algorithms which learn by climbing the gradient of expected reward. Their long-run convergence has been proved, even in partially observable environments with non-deterministic actions, and without the need for a system model. However, the variance of the gradient estimator has been found to be a significant practical problem. Recent approaches have discounted future rewards, introducing a bias-variance trade-off into the gradient estimate. We incorporate a reward baseline into the learning system, and show that it affects variance without introducing further bias. In particular, as we approach the zerobias, high-variance parametedzation, the optimal (or variance minimizing) constant reward baseline is equal to the long-term average expected reward. Modified policy-gradient algorithms are presented, and a number of experiments demonstrate their improvement over previous work.

#index 1650558
#* Cross-covariance modelling via DAGs with hidden variables
#@ Jacob A. Wegelin;Thomas S. Richardson
#t 2001
#c 12
#% 297171
#% 1650619
#! DAG models with hidden variables present many difficulties that are absent when all nodes are observed. In particular, fully observed DAG models are identified and correspond to well-defined sets of distributions, whereas this is not true if nodes are unobserved. In this paper we characterize exactly the set of distributions given by a class of Gaussian models with one-dimensional latent variables. These models relate two blocks of observed variables, modeling only the crosscovariance matrix. We describe the relation of this model to the singular value decomposition of the cross-covariance matrix. We show that, although the model is underidentified, useful information may be extracted. We further consider an alternative parameterization in which one latent variable is associated with each block. Our analysis leads to some novel covariance equivalence results for Gaussian hidden variable models.

#index 1650559
#* Belief optimization for binary networks: a stable alternative to loopy belief propagation
#@ Max Welling;Yee Whye Teh
#t 2001
#c 12
#% 44876
#% 272514
#% 304828
#% 304995
#% 857454
#% 1650318
#% 1848680
#! We present a novel inference algorithm for arbitrary, binary, undirected graphs. Unlike loopy belief propagation, which iterates fixed point equations, we directly descend on the Bethe free energy. The algorithm consists of two phases, first we update the pairwise probabilities, given the marginal probabilities at each unit, using an analytic expression. Next, we update the marginal probabilities, by following the negative gradient of the Bethe free energy. Both steps are guaranteed to decrease the Bethe free energy, and since it is lower bounded, the algorithm is guaranteed to converge to a local minimum. We also show that the Bethe free energy is equal to the TAP free energy up to second order in the weights. In experiments we confirm that when belief propagation converges it usually finds identical solutions as our belief optimization method. The stable nature of belief optimization makes it ideally suited for learning graphical models from data.

#index 1650560
#* Statistical modelling in continuous speech recognition (CSR)
#@ Steve Young
#t 2001
#c 12
#% 158687
#% 207963
#% 246184
#% 278011
#% 292004
#% 301186
#% 818073
#% 818089
#% 898583
#% 969312
#% 969347
#% 1501920
#! Automatic continuous speech recognition (CSR) is sufficiently mature that a variety of real world applications are now possible including large vocabulary transcription and interactive spoken dialogues. This paper reviews the evolution of the statistical modelling techniques which underlie current-day systems, specifically hidden Markov models (HMMs) and N-grams. Starting from a description of the speech signal and its parameterisation, the various modelling assumptions and their consequences are discussed. It then describes various techniques by which the effects of these assumptions can be mitigated. Despite the progress that has been made, ther limitations of current modelling techniques are still evident. The paper therefore concludes with a brief review of some of the more fundamental modelling work now in progress.

#index 1650561
#* Planning and acting under uncertainty: a new model for spoken dialogue systems
#@ Bo Zhang;Qingsheng Cai;Jianfeng Mao;Baining Guo
#t 2001
#c 12
#% 527858
#% 531457
#% 706380
#% 817553
#% 1271823
#% 1290265
#% 1476294
#% 1650702
#! Uncertainty plays a central role in spoken dialogue systems. Some stochastic models like the Markov decision process (MDP) are used to model the dialogue manager. But the partially observable system state and user intentions hinder the natural representation of the dialogue state. A MDP-based system degrades quickly when uncertainty about a user's intention increases. We propose a novel dialogue model based on the partially observable Markov decision process (POMDP). We use hidden system states and user intentions as the state set, parser results and low-level information as the observation set, and domain actions and dialogue repair actions as the action set. Here, low-level information is extracted from different input modalities, including speech, keyboard, mouse, etc., using Bayesian networks. Because of the limitation of the exact algorithms, we focus on heuristic approximation algorithms and their applicability in POMDP for dialogue management. We also propose two methods for grid point selection in grid-based algorithms

#index 1650562
#* Using temporal data for making recommendations
#@ Andrew Zimdars;David Maxwell Chickering;Christopher Meek
#t 2001
#c 12
#% 173879
#% 220711
#% 232117
#% 387427
#% 722754
#% 748738
#% 1273828
#% 1650278
#% 1650705
#! We treat collaborative filtering as a univariate time series problem: given a user's previous votes, predict the next vote. We describe two families of methods for transforming data to encode time order in ways amenable to off-the-shelf classification and density estimation tools. Using a decision-tree learning tool and two real-world data sets, we compare the results of these approaches to the results of collaborative filtering without ordering information. The improvements in both predictive accuracy and in recommendation quality that we realize advocate the use of predictive algorithms exploiting the temporal order of data.

#index 1650563
#* Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence
#@ Gregory F. Cooper;Serafín Moral
#t 1998
#c 12

#index 1650564
#* On the acceptability of arguments in preference-based argumentation
#@ Leila Amgoud;Claudette Cayrol
#t 1998
#c 12
#% 100152
#% 116292
#% 121990
#% 179921
#% 196352
#% 198464
#% 200290
#% 231742
#% 503526
#% 503676
#% 503678
#% 503821
#% 637526
#% 1273626
#% 1273654
#% 1290084
#% 1290085
#! Argumentation is a promising model for reasoning with uncertain and inconsistent knowledge. The key concept of acceptability enables to differentiate arguments and defeaters: The certainty of a proposition can then be evaluated through the most acceptable arguments for that proposition. In this paper, we investigate different complementary points of view: an acceptability based on the existence of direct defeaters and an acceptability based on the existence of defenders. Pursuing previous work on preference-based argumentation principles, we enforce both points of view by taking into account preference orderings for comparing arguments. Our approach is illustrated in the context of reasoning with stratified knowledge bases.

#index 1650565
#* Merging uncertain knowledge bases in a possibilistic logic framework
#@ Salem Benferhat;Claudio Sossai
#t 1998
#c 12
#% 29844
#% 134290
#% 167544
#% 590977
#% 1290085
#% 1650631
#! This paper addresses the problem of merging uncertain information in the framework of possibilistic logic. It presents several syntactic combination rules to merge possibilistic knowledge bases, provided by different sources, into a new possibilistic knowledge base. These combination rules are first described at the meta-level outside the language of possibilistic logic. Next, an extension of possibilistic logic, where the combination rules are inside the language, is proposed. A proof system in a sequent form, which is sound and complete with respect to the possibilistic logic semantics, is given.

#index 1650566
#* A hybrid algorithm to compute marginal and joint beliefs in Bayesian networks and its complexity
#@ Mark Bloemeke;Marco Valtorta
#t 1998
#c 12
#% 31482
#% 44876
#% 67866
#% 247866
#% 380725
#% 408680
#! There exist two general forms of exact algorithms for updating probabilities in Bayesian Networks. The first approach involves using a structure, usually a clique tree, and performing local message based calculation to extract the belief in each variable. The second general class of algorithm involves the use of non-serial dynamic programming techniques to extract the belief in some desired group of variables. In this paper we present a hybrid algorithm based on the latter approach yet possessing the ability to retrieve the belief in all single variables. The technique is advantageous in that it saves a NP-hard computation step over using one algorithm of each type. Furthermore, this technique re-enforces a conjecture of Jensen and Jensen [JJ94] in that it still requires a single NP-hard step to set up the structure on which inference is performed, as we show by confirming Li and D'Ambrosio's [LD94] conjectured NP-hardness of OFP.

#index 1650567
#* Structured reachability analysis for Markov decision processes
#@ Craig Boutilier;Ronen I. Brafman;Christopher Geib
#t 1998
#c 12
#% 75936
#% 115513
#% 159243
#% 172505
#% 224762
#% 324095
#% 393786
#% 536408
#% 544766
#% 544791
#% 1290041
#% 1290043
#% 1290109
#% 1478679
#% 1478746
#% 1650699
#! Recent research in decision theoretic planning has focussed on making the solution of Markov decision processes (MDPs) more feasible. We develop a family of algorithms for structured reachability analysis of MDPs that are suitable when an initial state (or set of states) is known. Usin compact, structured representations of MDPs (e.g., Bayesian networks), our methods, which vary in the tradeoff between complexity and accurac roduce structured descriptions of (estimated) reacpagle states that can be used to eliminate variables oy variable values from the problem description, reducing the size of the MDP and making it easier to solve. One contribution of our work is the extension of ideas from GRAPHPLAN to deal with the distributed nature of action reoresentations typically embodied within Bayes nets and the problem of correlated action effects. We also demonstrate that our algorithm can be made more complete by using k-ary constraints instead of binary constraints. Another contribution is the illustration of how the compact representation of reachability constraints can be exploited by several existing (exact and approximate) abstraction algorithms for MDPs.

#index 1650568
#* Tractable inference for complex stochastic processes
#@ Xavier Boyen;Daphne Koller
#t 1998
#c 12
#% 75936
#% 115608
#% 128612
#% 128629
#% 225837
#% 465918
#% 1290139
#% 1650666
#% 1650711
#! The monitoring and control of any dynamic system depends crucially on the ability to reason about its current status and its future trajectory. In the case of a stochastic system, these tasks typically involve the use of a belief state--a probability distribution over the state of the process at a given point in time. Unfortunately, the state spaces of complex processes are very large, making an explicit representation of a belief state intractable. Even in dynamic Bayesian networks (DBNs), where the process itself can be represented compactly, the representation of the belief state is intractable. We investigate the idea of maintaining a compact approximation to the true belief state, and analyze the conditions under which the errors due to the approximations taken over the lifetime of the process do not accumulate to make our answers completely irrelevant. We show that the error in a belief state contracts exponentially as the process evolves. Thus, even with multiple approximations, the error in our process remains bounded indefinitely. We show how the additional structure of a DBN can be used to design our approximation scheme, improving its performance significantly. We demonstrate the applicability of our ideas in the context of a monitoring task, showing that orders of magnitude faster inference can be achieved with only a small degradation in accuracy.

#index 1650569
#* Empirical analysis of predictive algorithms for collaborative filtering
#@ John S. Breese;David Heckerman;Carl Kadie
#t 1998
#c 12
#% 173879
#% 220706
#% 220707
#% 220710
#% 232117
#% 246834
#% 406493
#% 979690
#% 1650705
#! Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list. Experiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time.

#index 1650570
#* Query expansion in information retrieval systems using a Bayesian network-based thesaurus
#@ Luis M. de Campos;Juan M. Fernández;Juan F. Huete
#t 1998
#c 12
#% 36399
#% 44876
#% 64896
#% 73046
#% 86535
#% 111456
#% 115473
#% 118030
#% 133886
#% 166643
#% 183496
#% 217255
#% 229348
#% 288166
#% 375017
#% 382160
#% 677232
#% 837642
#! Information Retrieval (IR) is concerned with the identification of documents in a collection that are relevant to a given information need, usually represented as a query containing terms or keywords, which are supposed to be a good description of what the user is looking for. IR systems may improve their effectiveness (i.e., increasing the number of relevant documents retrieved) by using a process of query expansion, which automatically adds new terms to the original query posed by an user. In this paper we develop a method of query expansion based on Bayesian networks. IJsing a learning algorithm, we construct a Bayesian network that represents some of the relationships among the terms appearing in a given document collection; this network is then used as a thesaurus (specific for that collection). We also report the results obtained by our method on three standard test collections.

#index 1650571
#* Dealing with uncertainty in situation assessment: towards a symbolic approach
#@ Charles Castel;Corine Cossart;Catherine Tessier
#t 1998
#c 12
#% 100324
#% 503674
#% 1477272
#% 1650761
#! The situation assessment problem is considered, in terms of object, condition, activity, and plan recognition, based on data coming from the realword via various sensors. It is shown that uncertainty issues are linked both to the models and to the matching algorithm. Three different types of uncertainties are identified, and within each one, the numerical and the symbolic cases are distinguished. The emphasis is then put on purely symbolic uncertainties: it is shown that they can be dealt with within a purely symbolic framework resulting from a transposition of classical numerical estimation tools.

#index 1650572
#* Marginalizing in undirected graph and hypergraph models
#@ Enrique F. Castillo;Juan Ferrándiz;Pilar Sanmartín
#t 1998
#c 12
#% 451
#% 382160
#! Given an undirected graph G or hypergraph H model for a given set of variables V, we introduce two marginalization operators for obtaining the undirected graph GA or hypergraph HA associated with a given subset A ⊂ V such that the marginal distribution of A factorizes according to GA or HA, respectively. Finally, we illustrate the method by its application to some practical examples. With them we show that hypergraph models allow defining a finer factorization or performing a more precise conditional independence analysis than undirected graph models.

#index 1650573
#* Utility elicitation as a classification problem
#@ Urszula Chajewska;Lise Getoor;Joseph Norman;Yuval Shahar
#t 1998
#c 12
#% 44876
#% 46809
#% 1650721
#! We investigate the application of classification techniques to utility elicitation. In a decision problem, two sets of parameters must generally be elicited: the probabilities and the utilities. While the prior and conditional probabilities in the model do not change from user to user, the utility models do. Thus it is necessary to elicit a utility model separately for each new user. Elicitation is long and tedious, particularly if the outcome space is large and not decomposable. There are two common approaches to utility function elicitation. The first is to base the determination of the user's utility function solely on elicitation of qualitative preferences. The second makes assumptions about the form and decomposability of the utility function. Here we take a different approach: we attempt to identify the new user's utility function based on classification relative to a database of previously collected utility functions. We do this by identifying clusters of utility functions that minimize an appropriate distance measure. Having identified the clusters, we develop a classification scheme that requires many fewer and simpler assessments than full utility elicitation and is more robust than utility elicitation based solely on preferences. We have tested our algorithm on a small database of utility functions in a prenatal diagnosis domain and the results are quite promising.

#index 1650574
#* Irrelevance and independence relations in Quasi-Bayesian networks
#@ Fabio Cozman
#t 1998
#c 12
#% 20853
#% 42211
#% 44876
#% 109042
#% 116624
#% 380725
#% 527687
#% 527849
#% 567872
#% 1650640
#% 1650708
#% 1650773
#% 1650774
#! This paper analyzes irrelevance and independence relations in graphical models associated with convex sets of probability distributions (called Quasi-Bayesian networks). The basic question in Quasi-Bayesian networks is, How can irrelevance/independence relations in Quasi-Bayesian networks be detected, enforced and exploited? This paper addresses these questions through Walley's definitions of irrelevance and independence. Novel algorithms and results are presented for inferences with the so-called natural extensions using fractional linear programming, and the properties of the so-called type-1 extensions are clarified through a new generalization of d-separation.

#index 1650575
#* Dynamic jointrees
#@ Adnan Darwiche
#t 1998
#c 12
#% 1650642
#! It is well known that one can ignore parts of a belief network when computing answers to certain probabilistic queries. It is also well known that the ignorable parts (if any) depend on the specific query of interest and, therefore, may change as the query changes. Algorithms based on jointrees, however, do not seem to take computational advantage of these facts given that they typically construct jointrees for worst-case queries; that is, queries for which every part of the belief network is considered relevant. To address this limitation, we propose in this paper a method for reconfiguring jointrees dynamically as the query changes. The reconfiguration process aims at maintaining a jointree which corresponds to the underlying belief network after it has been pruned given the current query. Our reconfiguration method is marked by three characteristics: (a) it is based on a nonclassical definition of jointrees; (b) it is relatively efficient; and (c) it can reuse some of the computations performed before a jointree is reconfigured. We present preliminary experimental results which demonstrate significant savings over using static jointrees when query changes are considerable.

#index 1650576
#* On the semi-Markov equivalence of causal models
#@ Benoit Desjardins
#t 1998
#c 12
#% 18262
#% 34262
#% 44876
#% 129987
#% 197387
#% 527830
#% 710011
#% 1650638
#% 1650673
#! The variability of structure in a finite Markov equivalence class of causally sufficient models represented by directed acyclic graphs has been fully characterized. Without causal sufficiency, an infinite semi-Markov equivalence class of models has only been characterized by the fact that each model in the equivalence class entails the same marginal statistical dependencies. In this paper, we study the variability of structure of causal models within a semi-Markov equivalence class and propose a systematic approach to construct models entailing any specific marginal statistical dependencies.

#index 1650577
#* Comparative uncertainty, belief functions and accepted beliefs
#@ Didier Dubois;Hélène Fargie;Henri Prade
#t 1998
#c 12
#% 12938
#% 77841
#% 160255
#% 218813
#% 1476313
#% 1478740
#% 1650645
#% 1650714
#% 1650788
#% 1650798
#! This paper relates comparative belief structures and a general view of belief management in the setting of deductively closed logical representations of accepted beliefs. We show that the range of compatibility between the classical deductive closure and uncertain reasoning covers precisely the nonmonotonic 'preferential' inference system of Kraus, Lehmann and Magidor and nothing else. In terms of uncertain reasoning any possibility or necessity measure gives birth to a structure of accepted beliefs. The classes of probability functions and of Shafer's belief functions which yield belief sets prove to be very special ones.

#index 1650578
#* Qualitative decision theory with Sugeno integrals
#@ Didier Dubois;Henri Prade;Régis Sabbadin
#t 1998
#c 12
#% 12938
#% 93934
#% 222201
#% 384209
#% 1290145
#% 1478741
#% 1650714
#% 1650798
#! This paper presents an axiomatic framework for qualitative decision under uncertainty in a finite setting. The corresponding utility is expressed by a sup-min expression, called Sugeno (or fuzzy) integral. Technically speaking, Sugeno integral is a median, which is indeed a qualitative counterpart to the averaging operation underlying expected utility. The axiomatic justification of Sugeno integral-based utility is expressed in terms of preference between acts as in Savage decision theory. Pessimistic and optimistic qualitative utilities, based on necessity and possibility measures, previously introduced by two of the authors, can be retrieved in this setting by adding appropriate axioms.

#index 1650579
#* The Bayesian structural EM algorithm
#@ Nir Friedman
#t 1998
#c 12
#% 44876
#% 129987
#% 185079
#% 197387
#% 205380
#% 232117
#% 246834
#% 246835
#% 272529
#% 277480
#% 277494
#% 465762
#% 1272279
#% 1478812
#% 1650705
#% 1650767
#% 1650786
#! In recent years there has been a flurry of works on learning Bayesian networks from data. One of the hard problems in this area is how to effectively learn the structure of a belief network from incomplete data--that is, in the presence of missing values or hidden variables. In a recent paper, I introduced an algorithm called Structural EM that combines the standard Expectation Maximization (EM) algorithm, which optimizes parameters, with structure search for model selection. That algorithm learns networks based on penalized likelihood scores, which include the BIC/MDL score and various approximations to the Bayesian score. In this paper, I extend Structural EM to deal directly with Bayesian model selection. I prove the convergence of the resulting algorithm and show how to apply it for learning a large class of probabilistic models, including Bayesian networks and some variants thereof.

#index 1650580
#* Learning the structure of dynamic probabilistic networks
#@ Nir Friedman;Kevin Murphy;Stuart Russell
#t 1998
#c 12
#% 17145
#% 101213
#% 128629
#% 129987
#% 181342
#% 185079
#% 197387
#% 225837
#% 246835
#% 246836
#% 266086
#% 277494
#% 465762
#% 1290139
#% 1650568
#% 1650579
#% 1650666
#% 1650738
#! Dynamic probabilistic networks are a compact representation of complex stochastic processes. In this paper we examine how to learn the structure of a DPN from data. We extend structure scoring rules for standard probabilistic networks to the dynamic case, and show how to search for structure when some of the variables are hidden. Finally, we examine two applications where such a technology might be useful: predicting and classifying dynamic behaviors, and learning causal orderings in biological processes. We provide empirical results that demonstrate the applicability of our methods in both domains.

#index 1650581
#* Learning by transduction
#@ A. Gammerman;V. Vovk;V. Vapnik
#t 1998
#c 12
#% 96673
#% 190581
#% 197394
#! We describe a method for predicting a classification of an object given classifications of the objects in the training set, assuming that the pairs object/classification are generated by an i.i.d. process from a continuous probability distribution. Our method is a modification of Vapnik's support-vector machine; its main novelty is that it gives not only the prediction itself but also a practicable measure of the evidence found in support of that prediction. We also describe a procedure for assigning degrees of confidence to predictions made by the support vector machine. Some experimental results are presented, and possible extensions of the algorithms are discussed.

#index 1650582
#* Graphical models and exponential families
#@ Dan Geiger;Christopher Meek
#t 1998
#c 12
#% 44876
#% 61079
#% 129987
#% 417566
#% 1650705
#% 1650758
#% 1650783
#% 1650786
#% 1784146
#! We provide a classification of graphical models according to their representation as subfamilies of exponential families. Undirected graphical models with no hidden variables are linear exponential families (LEFs), directed acyclic graphical models and chain graphs with no hidden variables, including Bayesian networks with several families of local distributions, are curved exponential families (CEFs) and graphical models with hidden variables are stratified exponential families (SEFs). An SEF is a finite union of CEFs satisfying a frontier condition. In addition, we illustrate how one can automatically generate independence and non-independence constraints on the distributions over the observable variables implied by a Bayesian network with hidden variables. The relevance of these results for model selection is examined.

#index 1650583
#* Psychological and normative theories of causal power and the probabilities of causes
#@ Clark Glymour
#t 1998
#c 12
#% 44876
#! This paper (1) shows that the best supported current psychological theory (Cheng, 1997) of how human subjects judge the causal power or influence of variations in presence or absence of one feature on another, given data on their covariation, tacitly uses a Bayes network which is either a noisy or gate (for causes that promote the effect) or a noisy and gate (for causes that inhibit the effect); (2) generalizes Cheng's theory to arbitrary acyclic networks of noisy or and noisy and gates; (3) gives various sufficient conditions for the estimation of the parameters in such networks when there are independent, unobserved causes; (4) distinguishes direct causal influence of one feature on another (influence along a path with one edge) from total influence (influence along all paths from one variable to another) and gives sufficient conditions for estimating each when there are unobserved causes of the outcome variable; (5) describes the relation between Cheng models and a simplified version of the "Rubin" framework for representing causal relations.

#index 1650584
#* Updating sets of probabilities
#@ Adam J. Grove;Joseph Y. Halpern
#t 1998
#c 12
#% 116624
#% 210861
#% 470007
#% 527849
#% 567878
#% 1290136
#! There are several well-known justifications for conditioning as the appropriate method for updating a single probability measure, given an observation. However, there is a significant body of work arguing for sets of probability measures, rather than single measures, as a more realistic model of uncertainty. Conditioning still makes sense in this context--we can simply condition each measure in the set individually, then combine the results--and, indeed, it seems to be the prel ferred updating procedure in the literature. But how justified is conditioning in this richer setting? Here we show, by considering an axiomatic account of conditioning given by van Fraassen, that the single-measure and sets-of-measures cases are very different. We show that van Fraassen's axiomatization for the former case is nowhere near sufficient for updating sets of measures. We give a considerably longer (and not as compelling) list of axioms that together force conditioning in this setting, and describe other update methods that are allowed once any of these axioms is dropped.

#index 1650585
#* Minimum encoding approaches for predictive modeling
#@ Peter Grünwald;Petri Kontkanen;Petri Myllymäki;Tomi Silander;Henry Tirri
#t 1998
#c 12
#% 115608
#% 129987
#% 197387
#% 246832
#% 369349
#% 458392
#% 1808676
#! We analyze differences between two information-theoretically motivated approaches to statistical inference and model selection: the Minimum Description Length (MDL) principle, and the Minimum Message Length (MML) principle. Based on this analysis, we present two revised versions of MML: a pointwise estimator which gives the MML-optimal single parameter model, and a volumewise estimator which gives the MML-optimal region in the parameter space. Our empirical results suggest that with small data sets, the MDL approach yields more accurate predictions than the MML estimators. The empirical results also demonstrate that the revised MML estimators introduced here perform better than the original MML estimator suggested by Wallace and Freeman.

#index 1650586
#* Toward case-based preference elicitation: similarity measures on preference structures
#@ Vu Ha;Peter Haddawy
#t 1998
#c 12
#% 95227
#% 125556
#% 173879
#% 217824
#% 220711
#% 282625
#% 1080900
#% 1348786
#% 1650573
#% 1650721

#index 1650587
#* Axiomatizing causal reasoning
#@ Joseph Y. Halpern
#t 1998
#c 12
#% 243717
#% 374945
#% 564806
#% 1272178
#% 1650703
#! Causal models defined in terms of a collection of equations, as defined by Pearl, are axiomatized here. Axiomatizations are provided for three successively more general classes of causal models: (1) the class of recursive theories (those without feedback), (2) the class of theories where the solutions to the equations are unique, (3) arbitrary theories (where the equations may not have solutions and, if they do, they are not necessarily unique). It is shown that to reason about causality in the most general third class, we must extend the language used by Galles and Pearl. In addition, the complexity of the decision procedures is examined for all the languages and classes of models considered.

#index 1650588
#* Solving POMDPs by searching in policy space
#@ Eric A. Hansen
#t 1998
#c 12
#% 64788
#% 179940
#% 272652
#% 544786
#% 637552
#% 646959
#% 646971
#% 707796
#% 1478842
#% 1478843
#% 1650702
#! Most algorithms for solving POMDPs iteratively improve a value function that implicitly represents a policy and are said to search in value function space. This paper presents an approach to solving POMDPs that represents a policy explicitly as a finite-state controller and iteratively improves the controller by search in policy space. Two related algorithms illustrate this approach. The first is a policy iteration algorithm that can outperform value iteration in solving infinitehorizon POMDPs. It provides the foundation for a new heuristic search algorithm that promises further speedup by focusing computational effort on regions of the problem space that are reachable, or likely to be reached, from a start state.

#index 1650589
#* Hierarchical solution of Markov decision processes using macro-actions
#@ Milos Hauskrecht;Nicolas Meuleau;Leslie Pack Kaelbling;Thomas Dean;Craig Boutilier
#t 1998
#c 12
#% 1474
#% 23011
#% 194647
#% 224762
#% 272662
#% 272663
#% 363744
#% 393786
#% 458377
#% 1274731
#% 1290041
#% 1290043
#% 1478746
#! We investigate the use of temporally abstract actions, or macro-actions, in the solution of Markov decision processes. Unlike current models that combine both primitive actions and macro-actions and leave the state space unchanged, we propose a hierarchical model (using an abstract MDP) that works with macro-actions only, and that significantly reduces the size of the state space. This is achieved by treating macroactions as local policies that act in certain regions of state space, and by restricting states in the abstract MDP to those at the boundaries of regions. The abstract MDP approximates the original and can be solved more efficiently. We discuss several ways in which macro-actions can be generated to ensure good solution quality. Finally, we consider ways in which macro-actions can be reused to solve multiple, related MDPs; and we show that this can justify the computational overhead of macro-action generation.

#index 1650590
#* Inferring informational goals from free-text queries: a Bayesian approach
#@ David Heckerman;Eric Horvitz
#t 1998
#c 12
#% 86371
#% 169782
#% 183496
#% 288166
#% 289109
#% 1650593
#! People using consumer software applications typically do not use technical jargon when querying an online database of help topics. Rather, they attempt to communicate their goals with common words and phrases that describe software functionality in terms of structure and objects they understand. We describe a Bayesian approach to modeling the relationship between words in a user's query for assistance and the informational goals of the user. After reviewing the general method, we describe several extensions that center on integrating additional distinctions and structure about language usage and user goals into the Bayesian models.

#index 1650591
#* Evaluating las vegas algorithms: pitfalls and remedies
#@ Holger H. Hoos;Thomas Stützle
#t 1998
#c 12
#% 155827
#% 160270
#% 160272
#% 210195
#% 539441
#% 539605
#% 1268732
#% 1377974
#% 1478526
#% 1478779
#% 1478780
#% 1499519
#% 1650718
#! Stochastic search algorithms are among the most sucessful approaches for solving hard combinatorial problems. A large class of stochastic search approaches can be cast into the framework of Las Vegas Algorithms (LVAs). As the run-time behavior of LVAs is characterized by random variables, the detailed knowledge of run-time distributions provides important information for the analysis of these algorithms. In this paper we propose a novel methodology for evaluating the performance of LVAs, based on the identification of empirical run-time distributions. We exemplify our approach by applying it to Stochastic Local Search (SLS) algorithms for the satisfiability problem (SAT) in propositional logic. We point out pitfalls arising from the use of improper empirical methods and discuss the benefits of the proposed methodology for evaluating and comparing LVAs.

#index 1650592
#* An anytime algorithm for decision making under uncertainty
#@ Michael C. Horsch;David Poole
#t 1998
#c 12
#% 34262
#% 130135
#% 138515
#% 300843
#% 449588
#% 1280031
#% 1650790
#! We present an anytime algorithm which computes policies for decision problems represented as multi-stage influence diagrams. Our algorithm constructs policies incrementally, starting from a policy which makes no use of the available information. The incremental process constructs policies which includes more of the information available to the decision maker at each step. While the process converges to the optimal policy, our approach is designed for situations in which computing the optimal policy is infeasible. We provide examples of the process on several large decision problems, showing that, for these examples, the process constructs valuable (but sub-optimal) policies before the optimal policy would be available by traditional methods.

#index 1650593
#* The lumière project: Bayesian user modeling for inferring the goals and needs of software users
#@ Eric Horvitz;Jack Breese;David Heckerman;David Hovel;Koos Rommelse
#t 1998
#c 12
#% 42214
#% 75936
#% 128612
#% 147680
#% 183497
#% 1650590
#% 1650660
#% 1650681
#! The Lumière Project centers on harnessing probability and utility to provide assistance to computer software users. We review work on Bayesian user models that can be employed to infer a user's needs by considering a user's background, actions, and queries. Several problems were tackled in Lumière research, including (1) the construction of Bayesian models for reasoning about the time-varying goals of computer users from their observed actions and queries, (2) gaining access to a stream of events from software applications, (3) developing a language for transforming system events into observational variables represented in Bayesian user models, (4) developing persistent profiles to capture changes in a user's expertise, and (5) the development of an overall architecture for an intelligent user interface. Lumière prototypes served as the basis for the Ofice Assistant in the Microsoft Office '97 suite of productivity applications.

#index 1650594
#* Any time probabilistic reasoning for sensor validation
#@ P. H. Ibargüengoytia;L. E. Sucar;S. Vadera
#t 1998
#c 12
#% 43695
#% 44876
#% 159239
#% 188076
#% 205385
#% 418039
#% 1650792
#! For many real time applications, it is important to validate the information received from the sensors before entering higher levels of reasoning. This paper presents an any time probabilistic algorithm for validating the information provided by sensors. The system consists of two Bayesian network models. The first one is a model of the dependencies between sensors and it is used to validate each sensor. It provides a list of potentially faulty sensors. To isolate the real faults, a second Bayesian network is used, which relates the potential faults with the real faults. This second model is also used to make the validation algorithm any time, by validating first the sensors that provide more information. To select the next sensor to validate, and measure the quality of the results at each stage, an entropy function is used. This function captures in a single quantity both the certainty and specificity measures of any time algorithms. Together, both models constitute a mechanism for validating sensors in an any time fashion, providing at each step the probability of correct/faulty for each sensor, and the total quality of the results. The algorithm has been tested in the validation of temperature sensors of a power plant.

#index 1650595
#* Measure selection: notions of rationality and representation independence
#@ Manfred Jaeger
#t 1998
#c 12
#% 73239
#% 209373
#% 1290136
#% 1650644
#% 1650720
#! We take another look at the general problem of selecting a preferred probability measure among those that comply with some given constraints. The dominant role that entropy maximization has obtained in this context is questioned by arguing that the minimum information principle on which it is based could be supplanted by an at least as plausible "likelihood of evidence" principle. We then review a method for turning given selection functions into representation independent variants, and discuss the tradeoffs involved in this transformation.

#index 1650596
#* Implementing resolute choice under uncertainty
#@ Jean-Yves Jaffray
#t 1998
#c 12
#% 62880
#! The adaptation to situations of sequential choice under uncertainty of decision criteria which deviate from (subjective) expected utility raises the problem of ensuring the selection of a nondominated strategy. In particular, when following the suggestion of Machina and McClennen of giving up separability (also known as consequentialism), which requires the choice of a substrategy in a subtree to depend only on data relevant to that subtree, one must renounce to the use of dynamic programming, since Bellman's principle is no longer valid. An interpretation of McClennen's resolute choice, based on cooperation between the successive Selves of the decision maker, is proposed. Implementations of resolute choice which prevent Money Pumps, negative prices of information or, more generally, choices of dominated strategies, while remaining computationally tractable, are proposed.

#index 1650597
#* Dealing with uncertainty on the initial state of a petri net
#@ Iman Jarkass;Michèle Rombaut
#t 1998
#c 12
#% 1818829
#! This paper proposes a method to find the actual state of a complex dynamic system from information coming from the sensors on the system himself, or on its environment. The nominal evolution of the system is a priori known and can be modeled (by an expert, for example), by different methods. In this paper, the Petri nets have been chosen. Contrary to the usual use of the Petri nets, the initial state of the system is unknown. So a degree of belief is bound to each places, or set of places. The theory used to model this uncertainty is the Dempster-Shafer's one which is well adapted to this type of problems. From the given Petri net characterizing the nominal evolution of the dynamic system, and from the observation inputs, the proposed method allows to determine according to the reliability of the model and the inputs, the state of the system at any time.

#index 1650598
#* Hierarchical mixtures-of-experts for exponential family regression models with generalized linear mean functions: a survey of approximation and consistency results
#@ Wenxin Jiang;Martin A. Tanner
#t 1998
#c 12
#% 169358
#% 213010
#% 277470
#% 361100
#% 669194
#% 1042787
#% 1051484
#% 1809361
#! We investigate a class of hierarchical mixtures-of-experts (HME) models where exponential family regression models with generalized linear mean functions of the form ψ(α + xT β) are mixed. Here ψ(ċ) is the inverse link function. Suppose the true response y follows an exponential family regression model with mean function belonging to a class of smooth functions of the form ψ(h(x)) where h(ċ) ∈ W∞2 (a Sobolev class over [0, 1]s). It is shown that the HME probability density functions can approximate the true density, at a rate of O(m-2/s) in Lp, norm, and at a rate of O(m-4/s) in Kullback-Leibler divergence. These rates can be achieved within the family of HME structures with no more than s-layers, where s is the dimension of the predictor x. It is also shown that likelihood-based inference based on HME is consistent in recovering the truth, in the sense that as the sample size n and the number of experts m both increase, the mean square error of the predicted mean response goes to zero. Conditions for such results to hold are stated and discussed.

#index 1650599
#* Exact inference of hidden structure from sample data in noisy-OR networks
#@ Michael Kearns;Yishay Mansour
#t 1998
#c 12
#% 44876
#% 176024

#index 1650600
#* Large deviation methods for approximate probabilistic inference
#@ Michael Kearns;Lawrence Saul
#t 1998
#c 12
#% 44876
#% 115608
#% 130878
#% 136358
#% 272345
#% 277467
#% 380725
#% 705252
#% 1272279
#! We study two-layer belief networks of binary random variables in which the conditional probabilities Pr [child|parents] depend monotonically on weighted sums of the parents. In large networks where exact probabilistic inference is intractable, we show how to compute upper and lower bounds on many probabilities of interest. In particular, using methods from large deviation theory, we derive rigorous bounds on marginal probabilities such as Pr[children] and prove rates of convergence for the accuracy of our bounds as a function of network size. Our results apply to networks with generic transfer function parameterizations of the conditional probability tables, such as sigmoid and noisy-OR. They also explicitly illustrate the types of averaging behavior that can simplify the problem of inference in large networks.

#index 1650601
#* Mixture representations for inference and learning in Boltzmann machines
#@ Neil D. Lawrence;Christopher M. Bishop;Michael I. Jordan
#t 1998
#c 12
#% 68819
#% 272505
#% 277467
#% 277483
#! Boltzmann machines are undirected graphical models with two-state stochastic variables, in which the logarithms of the clique potentials are quadratic functions of the node states. They have been widely studied in the neural computing literature, although their practical applicability has been limited by the difficulty of finding an effective learning algorithm. One well-established approach, known as mean field theory, represents the stochastic distribution using a factorized approximation. However, the corresponding learning algorithm often fails to find a good solution. We conjecture that this is due to the implicit uni-modality of the mean field approximation which is therefore unable to capture multi-modality in the true distribution. In this paper we use variational methods to approximate the stochastic distribution using multi-modal mixtures of factorized distributions. We present results for both inference and learning to demonstrate the effectiveness of this approach.

#index 1650602
#* A comparison of Lauritzen-Spiegelhalter, Hugin, and Shenoy-Shafer architectures for computing marginals of probability distributions
#@ Vasilica Lepar;Prakash P. Shenoy
#t 1998
#c 12
#% 6199
#% 119147
#% 257887
#% 360087
#% 361888
#% 567872
#% 1650730
#! In the last decade, several architectures have been proposed for exact computation of marginals using local computation. In this paper, we compare three architectures--Lauritzen-Spiegelhalter, Hugin, and Shenoy-Shafer--from the perspective of graphical structure for message propagation, message-passing scheme, computational efficiency, and storage efficiency.

#index 1650603
#* Incremental tradeoff resolution in qualitative probabilistic networks
#@ Chao-Lin Liu;Michael P. Wellman
#t 1998
#c 12
#% 46437
#% 89748
#% 128627
#% 136358
#% 470333
#% 564806
#% 1272302
#% 1478675
#% 1650604
#% 1650676
#! Qualitative probabilistic reasoning in a Bayesian network often reveals tradeoffs: relationships that are ambiguous due to competing qualitative influences. We present two techniques that combine qualitative and numeric probabilistic reasoning to resolve such tradeoffs, inferring the qualitative relationship between nodes in a Bayesian network. The first approach incrementally marginalizes nodes that contribute to the ambiguous qualitative relationships. The second approach evaluates approximate Bayesian networks for bounds of probability distributions, and uses these bounds to determinate qualitative relationships in question. This approach is also incremental in that the algorithm refines the state spaces of random variables for tighter bounds until the qualitative relationships are resolved. Both approaches provide systematic methods for tradeoff resolution at potentially lower computational cost than application of purely numeric methods.

#index 1650604
#* Using qualitative relationships for bounding probability distributions
#@ Chao-Lin Liu;Michael P. Wellman
#t 1998
#c 12
#% 21142
#% 67866
#% 89748
#% 110379
#% 130150
#% 136358
#% 159239
#% 237038
#% 373938
#% 1271900
#% 1271902
#% 1273621
#% 1478675
#% 1650603
#% 1650688
#% 1650708
#% 1650774
#% 1650793
#! We exploit qualitative probabilistic relationships among variables for computing bounds of conditional probability distributions of interest in Bayesian networks. Using the signs of qualitative relationships, we can implement abstraction operations that are guaranteed to bound the distributions of interest in the desired direction. By evaluating incrementally improved approximate networks, our algorithm obtains monotonically tightening bounds that converge to exact distributions. For supermodular utility functions, the tightening bounds monotonically reduce the set of admissible decision alternatives as well.

#index 1650605
#* Magic inference rules for probabilistic deduction under taxonomic knowledge
#@ Thomas Lukasiewicz
#t 1998
#c 12
#% 3034
#% 42485
#% 44876
#% 73571
#% 101210
#% 128621
#% 130150
#% 167626
#% 170207
#% 240165
#% 287295
#% 289305
#% 503681
#! We present locally complete inference rules for probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. Crucially, in contrast to similar inference rules in the literature, our inference rules are locally complete for conjunctive events and under additional taxonomic knowledge. We discover that our inference rules are extremely complex and that it is at first glance not clear at all where the deduced tightest bounds come from. Moreover, analyzing the global completeness of our inference rules, we find examples of globally very incomplete probabilistic deductions. More generally, we even show that all systems of inference rules for taxonomic and probabilistic knowledge-bases over conjunctive events are globally incomplete. We conclude that probabilistic deduction by the iterative application of inference rules on interval restrictions for conditional probabilities, even though considered very promising in the literature so far, seems very limited in its field of application.

#index 1650606
#* Lazy propagation in junction trees
#@ Anders L. Madsen;Finn V. Jensen
#t 1998
#c 12
#% 34262
#% 1477089
#% 1650663
#% 1650735
#% 1650778
#! The efficiency of algorithms using secondary structures for probabilistic inference in Bayesian networks can be improved by exploiting independence relations induced by evidence and the direction of the links in the original network. In this paper we present an algorithm that on-line exploits independence relations induced by evidence and the direction of the links in the original network to reduce both time and space costs. Instead of multiplying the conditional probability distributions for the various cliques, we determine on-line which potentials to multiply when a message is to be produced. The performance improvement of the algorithm is emphasized through empirical evaluations involving large real world Bayesian networks, and we compare the method with the HUGIN and Shafer-Shenoy inference algorithms.

#index 1650607
#* Constructing situation specific belief networks
#@ Suzanne M. Mahoney;Kathryn Blackmond Laskey
#t 1998
#c 12
#% 31874
#% 34262
#% 128626
#% 443631
#% 503673
#% 527687
#% 527841
#% 1477272
#% 1650675
#% 1650734
#% 1650735
#! This paper describes a process for constructing situation-specific belief networks from a knowledge base of network fragments. A situation-specific network is a minimal querycomplete network constructed from a knowledge base in response to a query for the probability distribution on a set of target variables given evidence and context variables. We present definitions of query completeness and situation-specific networks. We describe conditions on the knowledge base that guarantee query completeness. The relationship of our work to earlier work on KBMC is also discussed.

#index 1650608
#* Treatment choice in heterogeneous populations using experiments without covariate data
#@ Charles F. Manski
#t 1998
#c 12
#! I examine the problem of treatment choice when a planner observes (i) covariates that describe each member of a population of interest and (ii) the outcomes of an experiment in which subjects randomly drawn from this population are randomly assigned to treatment groups within which all subjects receive the same treatment. Covariate data for the subjects of the experiment are not available. The optimal treatment rule is to divide the population into subpopulations whose members share the same covariate value, and then to choose for each subpopulation a treatment that maximizes its mean outcome. However the planner cannot implement this rule. I draw on my work on nonparametric analysis of treatment response to address the planner's problem

#index 1650609
#* An experimental comparison of several clustering and initialization methods
#@ Marina Meilă;David Heckerman
#t 1998
#c 12
#% 131258
#% 232117
#% 246834
#% 274604
#% 1650696
#! We examine methods for clustering in high dimensions. In the first part of the paper, we perform an experimental comparison between three batch clustering algorithms: the Expectation-Maximization (EM) algorithm, a "winner take all" version of the EM algorithm reminiscent of the K-means algorithm, and model-based hierarchical agglomerative clustering. We learn naive-Bayes models with a hidden root node, using high-dimensional discrete-variable data sets (both real and synthetic). We find that the EM algorithm significantly outperforms the other methods, and proceed to investigate the effect of various initialization schemes on the final solution produced by the EM algorithm. The initializations that we consider are (1) parameters sampled from an uninformative prior, (2) random perturbations of the marginal distribution of the data, and (3) the output of hierarchical agglomerative clustering. Although the methods are substantially different, they lead to learned models that are strikingly similar in quality.

#index 1650610
#* From likelihood to plausibility
#@ Paul-André Monney
#t 1998
#c 12
#% 1650739
#! Several authors have explained that the likelihood ratio measures the strength of the evidence represented by observations in statistical problems. This idea works fine when the goal is to evaluate the strength of the available evidence for a simple hypothesis versus another simple hypothesis. However, the applicability of this idea is limited to simple hypotheses because the likelihood function is primarily defined on points - simple hypotheses - of the parameter space. In this paper we define a general weight of evidence that is applicable to both simple and composite hypotheses. It is based on the Dempster-Shafer concept of plausibility and is shown to be a generalization of the likelihood ratio. Functional models are of a fundamental importance for the general weight of evidence proposed in this paper. The relevant concepts and ideas are explained by means of a familiar urn problem and the general analysis of a real-world medical problem is presented.

#index 1650611
#* A multivariate discretization method for learning Bayesian networks from mixed data
#@ Stefano Monti;Gregory F. Cooper
#t 1998
#c 12
#% 44876
#% 129987
#% 197387
#% 277503
#% 1650772
#! In this paper we address the problem of discretization in the context of learning Bayesian networks (BNs) from data containing both continuous and discrete variables. We describe a new technique for multivariate discretization, whereby each continuous variable is discretized while taking into account its interaction with the other variables. The technique is based on the use of a Bayesian scoring metric that scores the discretization policy for a continuous variable given a BN structure and the observed data. Since the metric is relative to the BN structure currently being evaluated, the discretization of a variable needs to be dynamically adjusted as the BN structure changes.

#index 1650612
#* Resolving conflicting arguments under uncertainties
#@ Benson Hin-Kwong Ng;Kam-Fai Wong;Boon-Toh Low
#t 1998
#c 12
#% 100152
#% 129789
#% 198464
#% 224479
#% 560073
#! Distributed knowledge based applications in open domain rely on common sense information which is bound to be uncertain and incomplete. To draw the useful conclusions from ambiguous data, one must address uncertainties and conflicts incurred in a holistic view. No integrated frameworks are viable without an in-depth analysis of conflicts incurred by uncertainties. In this paper, we give such an analysis and based on the result, propose an integrated framework. Our framework extends definite argumentation theory to model uncertainty. It supports three views over conflicting and uncertain knowledge. Thus, knowledge engineers can draw different conclusions depending on the application context (i.e. view). We also give an illustrative example on strategical decision support to show the practical usefulness of our framework.

#index 1650613
#* Flexible decomposition algorithms for weakly coupled Markov decision problems
#@ Ronald Parr
#t 1998
#c 12
#% 51999
#% 102136
#% 124694
#% 160859
#% 179940
#% 241833
#% 272648
#% 272662
#% 272663
#% 706874
#% 1290043
#% 1650589
#! This paper presents two new approaches to decomposing and solving large Markov decision problems (MDPs), a partial decoupling method and a complete decoupling method. In these approaches, a large, stochastic decision problem is divided into smaller pieces. The first approach builds a cache of policies for each part of the problem independently, and then combines the pieces in a separate, light-weight step. A second approach also divides the problem into smaller pieces, but information is communicated between the different problem pieces, allowing intelligent decisions to be made about which piece requires the most attention. Both approaches can be used to find optimal policies or approximately optimal policies with provable bounds. These algorithms also provide a framework for the efficient transfer of knowledge across problems that share similar structure.

#index 1650614
#* Logarithmic time parallel Bayesian inference
#@ David M. Pennock
#t 1998
#c 12
#% 44876
#% 46437
#% 58600
#% 67866
#% 68244
#% 70370
#% 119415
#% 128617
#% 136358
#% 148495
#% 174161
#% 427411
#% 437610
#% 527667
#% 567876
#% 1068655
#% 1272278
#! I present a parallel algorithm for exact probabilistic inference in Bayesian networks. For polytree networks with n variables, the worstcase time complexity is O(logn) on a CREW PRAM (concurrent-read, exclusive-write parallel random-access machine) with n processors, for any constant number of evidence variables. For arbitrary networks, the time complexity is O(r3w log n) for n processors, or O(w log n) for r3w log n processors, where r is the maximum range of any variable, and w is the induced width (the maximum clique size), after moralizing and triangulating the network.

#index 1650615
#* Learning from what you don't observe
#@ Mark A. Peot;Ross D. Shachter
#t 1998
#c 12
#% 34262
#! The process of diagnosis involves learning about the state of a system from various observations of symptoms or findings about the system. Sophisticated Bayesian (and other) algorithms have been developed to revise and maintain beliefs about the system as observations are made. Nonetheless, diagnostic models have tended to ignore some common sense reasoning exploited by human diagnosticians. In particular, one can learn from which observations have not been made, in the spirit of conversational implicature. In order to extract information from the observations not made, we propose the following two concepts. First, some symptoms, if present, are more likely to be reported before others. Second. most human diagnosticians and expert systems are economical in their data-gathering, searching first where they are more likely to find symptoms present. Thus, there is a desirable bias toward reporting symptoms that are present. We develop a simple model for these concepts that can significantly improve diagnostic inference.

#index 1650616
#* Context-specific approximation in probabilistic inference
#@ David Poole
#t 1998
#c 12
#% 44876
#% 83938
#% 101224
#% 136350
#% 147677
#% 216980
#% 217078
#% 224762
#% 231738
#% 673698
#% 1271900
#% 1271902
#% 1272302
#% 1477089
#% 1650767
#% 1650778
#! There is evidence that the numbers in probabilistic inference don't really matter. This paper considers the idea that we can make a probabilistic model simpler by making fewer distinctions. Unfortunately, the level of a Bayesian network seems too coarse; it is unlikely that a parent will make little difference for all values of the other parents. In this paper we consider an approximation scheme where distinctions can be ignored in some contexts, but not in other contexts. We elaborate on a notion of a parent context that allows a structured context-specific decomposition of a probability distribution and the associated probabilistic inference scheme called probabilistic partial evaluation (Poole 1997). This paper shows a way to simplify a probabilistic model by ignoring distinctions which have similar probabilities, a method to exploit the simpler model, a bound on the resulting errors, and some preliminary empirical results on simple networks.

#index 1650617
#* Empirical evaluation of approximation algorithms for probabilistic decoding
#@ Irina Rish;Kalev Kask;Rina Dechter
#t 1998
#c 12
#% 31482
#% 36814
#% 44876
#% 272514
#% 277465
#% 419897
#% 706969
#% 1271902
#% 1272302
#% 1650711
#% 1650778
#% 1848680
#! It was recently shown that the problem of decoding messages transmitted through a noisy channel can be formulated as a belief updating task over a probabilistic network [14]. Moreover, it was observed that iterative application of the (linear time) belief propagation algorithm designed for polytrees [15] outperformed state of the art decoding algorithms, even though the corresponding networks may have many cycles. This paper demonstrates empirically that an approximation algorithm approx-mpe for solving the most probable explanation (MPE) problem, developed within the recently proposed mini-bucket elimination framework [4], outperforms iterative belief propagation on classes of coding networks that have bounded induced width. Our experiments suggest that approximate MPE decoders can be good competitors to the approximate belief updating decoders.

#index 1650618
#* Decision theoretic foundations of graphical model selection
#@ Paola Sebastiani;Marco Ramoni
#t 1998
#c 12
#% 129987
#% 420055
#! This paper describes a decision theoretic formulation of learning the graphical structure of a Bayesian Belief Network from data. This framework subsumes the standard Bayesian approach of choosing the model with the largest posterior probability as the solution of a decision problem with a 0-1 loss function and allows the use of more general loss functions able to trade-off the complexity of the selected model and the error of choosing an over-simplified model. A new class of loss functions, called disintegrable, is introduced, to allow the decision problem to match the decomposability of the graphical model. With this class of loss functions, the optimal solution to the decision problem can be found using an efficient bottom-up search strategy.

#index 1650619
#* On the geometry of Bayesian graphical models with hidden variables
#@ Raffaella Settimi;Jim Q. Smith
#t 1998
#c 12
#% 185079
#% 424787
#% 1650742
#% 1650786
#! In this paper we investigate the geometry of the likelihood of the unknown parameters in a simple class of Bayesian directed graphs with hidden variables. This enables us, before any numerical algorithms are employed, to obtain certain insights in the nature of the unidentifiability inherent in such models, the way posterior densities will be sensitive to prior densities and the typical geometrical form these posterior densities might take. Many of these insights carry over into more complicated Bayesian networks with systematic missing data.

#index 1650620
#* Bayes-ball: Rational pastime (for determining irrelevance and requisite information in belief networks and influence diagrams)
#@ Ross D. Shachter
#t 1998
#c 12
#% 34262
#% 44876
#% 46437
#% 101252
#% 130135
#% 527687
#% 1272178
#% 1650735
#% 1650803
#% 1650804
#! One of the benefits of belief networks and influence diagrams is that so much knowledge is captured in the graphical structure. In particular, statements of conditional irrelevance (or independence) can be verified in time linear in the size of the graph. To resolve a particular inference query or decision problem, only some of the possible states and probability distributions must be specified, the "requisite information." This paper presents a new, simple, and efficient "Bayes-ball" algorithm which is wellsuited to both new students of belief networks and state of the art implementations. The Bayes-ball algorithm determines irrelevant sets and requisite information more efficiently than existing methods, and is linear in the size of the graph for belief networks and influence diagrams.

#index 1650621
#* Switching portfolios
#@ Yoram Singer
#t 1998
#c 12
#% 11773
#% 115608
#% 232728
#% 240809
#% 1808716
#! A constant rebalanced portfolio is an asset allocation algorithm which keeps the same distribution of wealth among a set of assets along a period of time. Recently, there has been work on on-line portfolio selection algorithms which are competitive with the best constant rebalanced portfolio determined in hindsight [6, 11, 81. By their nature, these algorithms employ the assumption that high returns can be achieved using a fixed asset allocation strategy. However, stock markets are far from being stationary and in many cases the wealth achieved by a constant rebalanced portfolio is much smaller than the wealth achieved by an ad-hoc investment strategy that adapts to changes in the market. In this paper we present an efficient Bayesian portfolio selection algorithm that is able to track a changing market. We also describe a simple extension of the algorithm for the case of a general transaction cost, including the transactions cost models recently investigated in [4]. We provide a simple analysis of the competitiveness of the algorithm and check its performance on real stock data from the New York Stock Exchange accumulated during a 22-year period.

#index 1650622
#* Bayesian networks from the point of view of chain graphs
#@ Milan Studený
#t 1998
#c 12
#% 44876
#% 503662
#% 527830
#% 1650814
#! The paper gives a few arguments in favour of use of chain graphs for description of probabilistic conditional independence structures. Every Bayesian network model can be equivalently introduced by means of a factorization formula with respect to chain graph which is Markov equivalent to the Bayesian network. A graphical characterization of such graphs is given. The class of equivalent graphs can be represented by a distinguished graph which is called the largest chain graph. The factorization formula with respect to the largest chain graph is a basis of a proposal how to represent the corresponding (discrete) probability distribution in a computer (i.e. 'parametrize' it). This way does not depend on the choice of a particular Bayesian network from the class of equivalent networks and seems to be the most efficient way from the point of view of memory demands. A separation criterion for reading independences from a chain graph is formulated in a simpler way. It resembles the well-known d-separation criterion for Bayesian networks and can be implemented 'locally'.

#index 1650623
#* Learning mixtures of DAG models
#@ Bo Thiesson;Christopher Meek;David Maxwell Chickering;David Heckerman
#t 1998
#c 12
#% 61079
#% 129987
#% 197387
#% 205380
#% 232117
#% 443790
#% 465762
#% 669222
#% 1272363
#% 1478812
#% 1650579
#% 1860128
#! We describe computationally efficient methods for learning mixtures in which each component is a directed acyclic graphical model (mixtures of DAGs or MDAGs). We argue that simple search-and-score algorithms are infeasible for a variety of problems, and introduce a feasible approach in which parameter and structure search is interleaved and expected data is treated as real data. Our approach can be viewed as a combination of (1) the Cheeseman-Stutz asymptotic approximation for model posterior probability and (2) the Expectation-Maximization algorithm. We evaluate our procedure for selecting among MDAGs on synthetic and real examples.

#index 1650624
#* Probabilistic inference in influence diagrams
#@ Nevin Lianwen Zhang
#t 1998
#c 12
#% 34262
#% 44876
#% 46437
#% 119308
#% 130135
#% 1272302
#! This paper is about reducing influence diagram (ID) evaluation into Bayesian network (BN) inference problems. Such reduction is interesting because it enables one to readily use one's favorite BN inference algorithm to efficiently evaluate IDS. Two such reduction methods have been proposed previously (Cooper 1988, Shachter and Peot 1992). This paper proposes a new method. The BN inference problems induced by the mew method are much easier to solve than those induced by the two previous methods.

#index 1650625
#* Planning with partially observable Markov decision processes: advances in exact solution method
#@ Nevin L. Zhang;Stephen S. Lee
#t 1998
#c 12
#% 101869
#% 646479
#% 646971
#% 695957
#% 1272319
#% 1650702
#! There is much interest in using partially observable Markov decision processes (POMDPs) as a formal model for planning in stochastic domains. This paper is concerned with finding optimal policies for POMDPs. We propose several improvements to incremental pruning, presently the most efficient exact algorithm for solving POMDPs.

#index 1650626
#* Flexible and approximate computation through state-space reduction
#@ Weixiong Zhang
#t 1998
#c 12
#% 241
#% 1722
#% 25998
#% 136358
#% 159239
#% 179914
#% 197425
#% 205385
#% 266199
#% 288165
#% 408396
#% 672552
#% 1279690
#% 1291451
#% 1478529
#% 1478708
#! In the real world, insufficient information, limited computation resources, and complex problem structures often force an autonomous agent to make a decision in time less than that required to solve the problem at hand completely. Flexible and approximate computation are two approaches to decision making under limited computation resources. Flexible computation helps an agent to flexibly allocate limited computation resources so that the overall system utility is maximized. Approximate computation enables an agent to find the best satisfactory solution within a deadline. In this paper, we present two state-space reduction methods for flexible and approximate computation: quantitative reduction to deal with inaccurate heuristic information, and structural reduction to handle complex problem structures. These two methods can be applied successively to continuously improve solution quality if more computation is available. Our results show that these reduction methods are effective and efficient, finding better solutions with less computation than some existing well-known methods.

#index 1650695
#* Proceedings of the Thirteenth conference on Uncertainty in artificial intelligence
#@ Dan Geiger;Prakash Pundalik Shenoy
#t 1997
#c 12

#index 1650696
#* Update rules for parameter estimation in Bayesian networks
#@ Eric Bauer;Daphne Koller;Yoram Singer
#t 1997
#c 12
#% 3084
#% 115608
#% 130114
#% 150152
#% 185079
#% 229809
#% 246835
#% 682442
#% 1272363
#% 1290046
#% 1650715
#! This paper re-examines the problem of parameter estimation in Bayesian networks with missing values and hidden variables from the perspective of recent work in on-line learning [13]. We provide a unified framework for parameter estimation that encompasses both on-line learning, where the model is continuously adapted to new data cases as they arrive, and the more traditional batch learning, where a pre-accumulated set of samples is used in a one-time model selection process. In the batch case, our framework encompasses both the gradient projection algorithm [2, 3] and the EM algorithm [15] for Bayesian networks. The framework also leads to new on-line and batch parameter update schemes, including a parameterized version of EM. We provide both empirical and theoretical results indicating that parameterized EM allows faster convergence to the maximum likelihood parameters than does standard EM.

#index 1650697
#* Bayes networks for sonar sensor fusion
#@ Ami Berler;Solomon Eyal Shimony
#t 1997
#c 12
#% 44876
#% 130108
#% 179925
#% 1290139
#% 1650810
#! Wide-angle sonar mapping of the environment by mobile robot is nontrivial due to several sources of uncertainty: dropouts due to "specular" reflections, obstacle location uncertainty due to the wide beam, and distance measurement error. Earlier papers address the latter problems, but dropouts remain a problem in many environments. We present an approach that lifts the overoptimistic independence assumption used in earlier work, and use Bayes nets to represent the dependencies between objects of the model. Objects of the model consist of readings, and of regions in which "quasi location invariance" of the (possible) obstacles exists, with respect to the readings. Simulation supports the method's feasibility. The model is readily extensible to allow for prior distributions, as well as other types of sensing operations.

#index 1650698
#* Exploiting uncertain and temporal information in correlation
#@ J. Bigham
#t 1997
#c 12
#% 3460
#% 116296
#% 147677
#% 567029
#% 1273560
#! A modelling language is decribed which is suitable for the correlation of information when the underlying functional model of the system is incomplete or uncertain and the temporal dependencies are imprecise. An efficient md incremental implementation is outlined which depends on cost functions satisfying certain criteria. Possibilistic logic and probability theory (as it is used in the applications targetted) satisfy these criteria.

#index 1650699
#* Correlated action effects in decision theoretic regression
#@ Craig Boutilier
#t 1997
#c 12
#% 75936
#% 124691
#% 179939
#% 179955
#% 203598
#% 224762
#% 363744
#% 536408
#% 1280031
#% 1290041
#% 1291498
#% 1478679
#% 1650767
#! Much recent research in decision theoretic planning has adopted Markov decision processes (MDPs) as the model of choice, and has attempted to make their solution more tractable by exploiting problem structure. One particular algorithm, structured policy construction achieves this by means of a decision theoretic analog of goal regression, using action descriptions based on Bayesian networks with tree-structured conditional probability tables. The algorithm as presented is not able to deal with actions with correlated effects. We describe a new decision theoretic regression operator that corrects this weakness. While conceptually straightforward, this extension requires a somewhat more complicated technical approach.

#index 1650700
#* Corporate evidential decision making in performance prediction domains
#@ A. G. Biichner;W. Dubitzky;A. Schuster;P. Lopes;P. G. O'Doneghue;J. G. Hughes;D. A. Bell;K. Adamson;J. A. White;J. M. C. C. Anderson;M. D. Mulvenna
#t 1997
#c 12
#% 75907
#% 403600
#% 403696
#% 404046
#% 420056
#% 1650693
#! Performance prediction or forecasting sporting outcomes involves a great deal of insight into the particular area one is dealing with, and a considerable amount of intuition about the factors that bear on such outcomes and performances. The mathematical Theory of Evidence offers representation formalisms which grant experts a high degree of freedom when expressing their subjective beliefs in the context of decision-making situations like performance prediction. Furthermore, this reasoning framework incorporates a powerful mechanism to systematically pool the decisions made by individual subject matter experts. The idea behind such a combination of knowledge is to improve the competence (quality) of the overall decision-making process. This paper reports on a performance prediction experiment carried out during the European Football Championship in 1996. Relying on the knowledge of four predictors, Evidence Theory was used to forecast the final scores of all 31 matches. The results of this empirical study are very encouraging.

#index 1650701
#* Algorithms for learning decomposable models and chordal graphs
#@ Luis M. de Campos;Juan F. Huete
#t 1997
#c 12
#% 44876
#% 289424
#% 1272301
#! Decomposable dependency models and their graphical counterparts, i.e., chordal graphs, possess a number of interesting and useful properties. On the basis of two characterizations of decomposable models in terms of independence relationships, we develop an exact algorithm for recovering the chordal graphical representation of any given decomposable model. We also propose an algorithm for learning chordal approximations of dependency models isomorphic to general undirected graphs.

#index 1650702
#* Incremental pruning: a simple, fast, exact method for partially observable Markov decision processes
#@ Anthony Cassandra;Michael L. Littman;Nevin L. Zhang
#t 1997
#c 12
#% 101869
#% 174161
#% 179940
#% 179941
#% 194652
#% 637552
#% 646971
#% 695957
#% 1290039
#% 1476294
#% 1478487
#! Most exact algorithms for general partially observable Markov decision processes (POMDPs) use a form of dynamic programming in which a piecewise-linear and convex representation of one value function is transformed into another. We examine variations of the "incremental pruning" method for solving this problem and compare them to earlier algorithms from theoretical and empirical perspectives. We find that incremental pruning is presently the most efficient exact method for solving POMDPS.

#index 1650703
#* Defining explanation in probabilistic systems
#@ Urszula Chajewska;Joseph Y. Halpern
#t 1997
#c 12
#% 44876
#% 75936
#% 89958
#% 128428
#% 193498
#% 216970
#% 503673
#% 564806
#% 1272178
#% 1477321
#! As probabilistic systems gain popularity and are coming into wider use, the need for a mechanism that explains the system's findings and recommendations becomes more critical. The system will also need a mechanism for ordering competing explanations. We examine two representative approaches to explanation in the literature-- one due to Gärdenfors and one due to Pearl--and show that both suffer from significant problems. We propose an approach to defining a notion of "better explanation" that combines some of the features of both together with more recent work by Pearl and others on causality.

#index 1650704
#* Structured arc reversal and simulation of dynamic probabilistic networks
#@ Adrian Y. W. Cheuk;Craig Boutilier
#t 1997
#c 12
#% 3873
#% 34262
#% 44876
#% 75936
#% 101221
#% 128629
#% 130108
#% 147677
#% 503673
#% 527664
#% 527691
#% 536408
#% 1290041
#% 1650666
#% 1650767
#% 1650783
#% 1650804
#! We present an algorithm for arc reversal in Bayesian networks with tree-structured conditional probability tables, and consider some of its advantages, especially for the simulation of dynamic probabilistic networks. In particular, the method allows one to produce CPTs for nodes involved in the reversal that exploit regularities in the conditional distributions. We argue that this approach alleviates some of the overhead associated with arc reversal, plays an important role in evidence integration and can be used to restrict sampling of variables in DPNs. We also provide an algorithm that detects the dynamic irrelevance of state variables in forward simulation. This algorithm exploits the structured CPTs in a reversed network to determine, in a time-independent fashion, the conditions under which a variable does or does not need to be sampled.

#index 1650705
#* A Bayesian approach to learning Bayesian networks with local structure
#@ David Maxwell Chickering;David Heckerman;Christopher Meek
#t 1997
#c 12
#% 101213
#% 129987
#% 1650767
#% 1650783
#! Recently several researchers have investigated techniques for using data to learn Bayesian networks containing compact representations for the conditional probability distributions (CPDs) stored at each node. The majority of this work has concentrated on using decision-tree representations for the CPDs. In addition, researchers typically apply non-Bayesian (or asymptotically Bayesian) scoring functions such as MDL to evaluate the goodness-of-fit of networks to the data. In this paper we investigate a Bayesian approach to learning Bayesian networks that contain the more general decision-graph representations of the CPDs. First, we describe how to evaluate the posterior probability-- that is, the Bayesian score--of such a network, given a database of observed cases. Second, we describe various search spaces that can be used, in conjunction with a scoring function and a search procedure, to identify one or more high-scoring networks. Finally, we present an experimentd evaluation of the search spaces, using a greedy algorithm and a Bayesian scoring function.

#index 1650706
#* Exploring parallelism in learning belief networks
#@ T. Chu;Y. Xiang
#t 1997
#c 12
#% 129987
#% 197387
#% 204528
#% 226678
#% 527851
#% 1650820
#! It has been shown that a class of probabilistic domain models cannot be learned correctly by several existing algorithms which employ a single-link lookahead search. When a multilink lookahead search is used, the computational complexity of the learning algorithm increases. We study how to use parallelism to tackle the increased complexity in learning such models and to speed up learning in large domains. An algorithm is proposed to decompose the learning task for parallel processing. A further task decomposition is used to balance load among processors and to increase the speed-up and efficiency. For learning from very large datasets, we present a regrouping of the available processors such that slow data access through file can be replaced by fast memory access. Our implementation in a parallel computer demonstrates the effectiveness of the algorithm.

#index 1650707
#* Efficient induction of finite state automata
#@ Matthew S. Collins;Jonathan J. Oliver
#t 1997
#c 12
#% 31215
#% 43470
#% 121642
#% 177356
#% 727399
#% 1286584
#! This paper introduces a new algorithm for the induction of complex finite state automata from samples of behaviour. The algorithm is based on information theoretic principles. The algorithm reduces the search space by many orders of magnitude over what was previously thought possible. We compare the algorithm with some existing induction techniques for finite state automata and show that the algorithm is much superior in both run time and quality of inductions.

#index 1650708
#* Robustness analysis of Bayesian networks with local convex sets of distributions
#@ Fabio Cozman
#t 1997
#c 12
#% 20853
#% 44876
#% 116624
#% 130885
#% 183497
#% 380725
#% 502765
#% 527849
#% 1272302
#% 1290046
#% 1477322
#% 1650773
#% 1650774
#% 1650778
#% 1650787
#! Robust Bayesian inference is the calculation of posterior probability bounds given perturbations in a probabilistic model. This paper focuses on perturbations that can be expressed locally in Bayesian networks through convex sets of distributions. Two approaches for combination of local models are considered. The first approach takes the largest set of joint distributions that is compatible with the local sets of distributions; we show how to reduce this type of robust inference to a linear programming problem. The second approach takes the convex hull of joint distributions generated from the local sets of distributions; we demonstrate how to apply interior-point optimization methods to generate posterior bounds and how to generate approximations that are guaranteed to converge to correct posterior bounds. We also discuss calculation of bounds for expected utilities and variances, and global perturbation models.

#index 1650709
#* A standard approach for optimizing belief network inference using query DAGs
#@ Adnan Darwiche;Gregory Provan
#t 1997
#c 12
#% 1272308
#% 1650777
#! This paper proposes a novel, algorithm-independent approach to optimizing belief network inference. Rather than designing optimizations on an algorithm by algorithm basis, we argue that one should use an unoptimized algorithm to generate a Q-DAG, a compiled graphical representation of the belief network, and then optimize the Q-DAG and its evaluator instead. We present a set of Q-DAG optimizations that supplant optimizations designed for traditional inference algorithms, including zero compression, network pruning and caching. We show that our Q-DAG optimizations require time linear in the Q-DAG size, and significantly simplify the process of designing algorithms for optimizing belief network inference.

#index 1650710
#* Model reduction techniques for computing approximately optimal solutions for Markov decision processes
#@ Thomas Dean;Robert Givan;Sonia Leach
#t 1997
#c 12
#% 44876
#% 75936
#% 115513
#% 131877
#% 179939
#% 194647
#% 194652
#% 472196
#% 646933
#% 836038
#% 1290041
#% 1478746
#! We present a method for solving implicit (factored) Markov decision processes (MDPs) with very large state spaces. We introduce a property of state space partitions which we call ε-homogeneity. Intuitively, an ε-homogeneous partition groups together states that behave approximately the same under all or some subset of policies. Borrowing from recent work on model minimization in computer-aided software verification, we present an algorithm that takes a factored representation of an MDP and an 0 ≤ ε ≤ 1 and computes a factored ε-homogeneous partition of the state space. This partition defines a family of related MDPs--those MDP's with state space equal to the blocks of the partition, and transition probabilities "approximately" like those of any (original MDP) state in the source block. To formally study such families of MDPs, we introduce the new notion of a "bounded parameter MDP" (BMDP), which is a family of (traditional) MDPs defined by specifying upper and lower bounds on the transition probabilities and rewards. We describe algorithms that operate on BMDPs to find policies that are approximately optimal with respect to the original MDP. In combination, our method for reducing a large implicit MDP to a possibly much smaller BMDP using an ε-homogeneous partition, and our methods for selecting actions in BMDP's constitute a new approach for analyzing large implicit MDP's. Among its advantages, this new approach provides insight into existing algorithms to solving implicit MDPs, provides useful connections to work in automata theory and model minimization, and suggests methods, which involve varying ε, to trade time and space (specifically in terms of the size of the corresponding state space) for solution quality.

#index 1650711
#* A scheme for approximating probabilistic inference
#@ Rind Dechter;Irina Rish
#t 1997
#c 12
#% 241
#% 1675
#% 36814
#% 44876
#% 224751
#% 1271902
#% 1650778
#! This paper describes a class of probabilistic approximation algorithms based on bucket elimination which offer adjustable levels of accuracy and efficiency. We analyze the approximation for several tasks: finding the most probable explanation, belief updating and finding the maximum a posteriori hypothesis. We identify regions of completeness and provide preliminary empirical evaluation on randomly generated networks.

#index 1650712
#* Myopic value of information in influence diagrams
#@ Søren L. Dittmer;Finn V. Jensen
#t 1997
#c 12
#% 34262
#% 119308
#% 130135
#% 380725
#% 1650804
#! We present a method for calculation of myopic value of information in influence diagrams (Howard & Matheson, 1981) based on the strong junction tree framework (Jensen et al., 1994). An influence diagram specifies a certain order of observations and decisions through its structure. This order is reflected in the corresponding junction trees by the order in which the nodes are marginalized. This order of marginalization can be changed by table expansion and use of control structures, and this facilitates for calculating the expected value of information for different information scenarios within the same junction tree. In effect, a strong junction tree with expanded tables may be used for calculating the value of information between several scenarios with different observation-decision order. We compare our method to other methods for calculating the value of information in influence diagrams.

#index 1650713
#* Limitations of skeptical default reasoning
#@ Jens Doerpmund
#t 1997
#c 12
#% 107155
#% 159242
#% 362038
#! Poole has shown that nonmonotonic logics do not handle the lottery paradox correctly. In this paper we will show that Pollock's theory of defeasible reasoning fails for the same reason: defeasible reasoning is incompatible with the skeptical notion of derivability.

#index 1650714
#* Decision-making under ordinal preferences and comparative uncertainty
#@ Didier Dubois;Hélène Fargier;Henri Prade
#t 1997
#c 12
#% 12938
#% 77841
#% 111942
#% 115327
#% 206249
#% 218813
#% 1290145
#% 1476313
#% 1650645
#% 1650798
#! This paper proposes a method that finds a preference relation on a set of acts from the knowledge of an ordering on events describing the decision-maker's uncertainty and an ordering of consequences of acts, describing the decision maker's preferences. However, contrary to classical approaches to decision theory, this method does not resort to any numerical representation of utility nor uncertainty and is purely ordinal. It is shown that although many axioms of Savage theory can be preserved and despite the intuitive appeal of the ordinal method, the approach is inconsistent with a probabilistic representation of uncertainty. It leads to the kind of uncertainty theory encountered in nonmonotonic reasoning (especially preferential and rational inference). Moreover the method turns out to be either very little decisive or to lead to very risky decisions, although its basic principles look sound. This paper raises the question of the very possibility of purely symbolic approaches to Savage-like decision-making under uncertainty and obtains preliminary negative results.

#index 1650715
#* Sequential update of Bayesian network structure
#@ Nir Friedman;Moises Goldszmidt
#t 1997
#c 12
#% 101213
#% 129987
#% 185079
#% 197387
#% 465762
#% 1290046
#% 1650783
#% 1650786
#% 1650899
#! There is an obvious need for improving the performance and accuracy of a Bayesian network as new data is observed. Because of errors in model construction and changes in the dynamics of the domains, we cannot afford to ignore the information in new data. While sequential update of parameters for a fixed structure can be accomplished using standard techniques, sequential update of network structure is still an open problem. In this paper, we investigate sequential update of Bayesian networks were both parameters and structure are expected to change. We introduce a new approach that allows for the flexible manipulation of the tradeoff between the quality of the learned networks and the amount of information that is maintained about past observations. We formally describe our approach including the necessary modifications to the scoring functions for learning Bayesian networks, evaluate its effectiveness through and empirical study, and extend it to the case of missing data.

#index 1650716
#* Image segmentation in video sequences: a probabilistic approach
#@ Nir Friedman;Stuart Russell
#t 1997
#c 12
#% 110918
#% 179925
#% 212688
#% 592236
#% 1857131
#! "Background subtraction" is an old technique for finding moving objects in a video sequence--for example, cars driving on a freeway. The idea is that subtracting the current image from a time-averaged background image will leave only nonstationary objects. It is, however, a crude approximation to the task of classifying each pixel of the current image; it fails with slow-moving objects and does not distinguish shadows from moving objects. The basic idea of this paper is that we can classify each pixel using a model of how that pixel looks when it is part of different classes. We learn a mixture-of-Gaussians classification model for each pixel using an unsupervised technique--an efficient, incremental version of EM. Unlike the standard image-averaging approach, this automatically updates the mixture component for each class according to likelihood of membership; hence slow-moving objects are handled perfectly. Our approach also identifies and eliminates shadows much more effectively than other techniques such as thresholding. Application of this method as part of the Roadwatch traffic surveillance project is expected to result in significant improvements in vehicle identification and tracking.

#index 1650717
#* The complexity of plan existence and evaluation in robabilistic domains
#@ Judy Goldsmith;Michael L. Littman;Martin Mundhenk
#t 1997
#c 12
#% 21145
#% 30037
#% 66645
#% 110377
#% 112014
#% 145332
#% 167629
#% 194652
#% 205391
#% 224480
#% 224762
#% 646959
#% 1290041
#% 1477346
#% 1478845
#! We examine the computational complexity of testing and finding small plans in probabilistic planning domains with succinct representations. We find that many problems of interest are complete for a variety of complexity classes: NP, co-NP, PP, NPPP, co-NP PP, and PSPACE. Of these, the probabilistic classes PP and NPPP are likely to be of special interest in the field of uncertainty in artificial intelligence and are deserving of additional study. These results suggest a fruitful direction of future algorithmic development.

#index 1650718
#* Algorithm portfolio design: theory vs. practice
#@ Carla P. Gomes;Bart Selman
#t 1997
#c 12
#% 174161
#% 179689
#% 210191
#% 319789
#% 1081250
#% 1273544
#% 1279714
#% 1478529
#% 1478531
#% 1650661
#! Stochastic algorithms are among the best for solving computationally hard search and reasoning problems, The runtime of such procedures is characterized by a random variable. Different algorithms give rise to different probability distributions. One can take advantage of such differences by combining several algorithms into a portfolio, and running them in parallel or interleaving them on a single processor. We provide a de- ~ailed evaluation of the portfolio approach on distributions of hard combinatorial search problems. We show under what conditions the portfolio approach can have a dramatic computational advantage over the best traditional methods.

#index 1650719
#* Learning Bayesian nets that perform well
#@ Russell Greiner;Adam J. Grove;Dale Schuurmans
#t 1997
#c 12
#% 44876
#% 129987
#% 136358
#% 150153
#% 151222
#% 179788
#% 205391
#% 211583
#% 443025
#% 1274007
#% 1290046
#% 1476310
#% 1650785
#! A Bayesian net (BN) is more than a succinct way to encode a probabilistic distribution; it also corresponds to a function used to answer queries. A BN can therefore be evaluated by the accuracy of the answers it returns. Many algorithms for learning BNs, however, attempt to optimize another criterion (usually likelihood, possibly augmented with a regularizing term), which is independent of the distribution of queries that are posed. This paper takes the "performance criteria" seriously, and considers the challenge of computing the BN whose performance -- read "accuracy over the distribution of queries" -- is optimal. We show that many aspects of this learning task are more difficult than the corresponding subtasks in the standard model.

#index 1650720
#* Probability update: conditioning vs. cross-entropy
#@ Adam J. Grove;Joseph Y. Halpern
#t 1997
#c 12
#% 120280
#! Conditioning is the generally agreed-upon method for updating probability distributions when one learns that an event is certainly true. But it has been argued that we need other rules, in particular the rule of cross-entropy minimization, to handle updates that involve uncertain information. In this paper we re-examine such a case: van Fraassen's Judy Benjamin problem [1987], which in essence asks how one might update given the value of a conditional probability. We argue that--contrary to the suggestions in the literature--it is possible to use simple conditionalization in this case, and thereby obtain answers that agree fully with intuition. This contrasts with proposals such as cross-entropy, which are easier to apply but can give unsatisfactory answers. Based on the lessons from this example, we speculate on some general philosophical issues concerning probability update.

#index 1650721
#* Problem-focused incremental elicitation of multi-attribute tility models
#@ Vu Ha;Peter Haddawy
#t 1997
#c 12
#% 110379
#% 167626
#% 179919
#% 194647
#% 1650628
#% 1650644
#! Decision theory has become widely accepted in the AI community as a useful framework for planning and decision making. Applying the framework typically requires elicitation of some form of probability and utility information. While much work in AI has focused on providing representations and tools for elicitation of probabilities, relatively little work has addressed the elicitation of utility models. This imbalance is not particularly justified considering that probability models are relatively stable across problem instances, while utility models may be different for each instance. Spending large amounts of time on elicitation can be undesirable for interactive systems used in low-stakes decision making and in time-critical decision making. In this paper we investigate the issues of reasoning with incomplete utility models. We identify patterns of problem instances where plans can be proved to be suboptimal if the (unknown) utility function satisfies certain conditions. We present an approach to planning and decision making that performs the utility elicitation incrementally and in a way that is informed by the domain model.

#index 1650722
#* Models and selection criteria for regression and classification
#@ David Heckerman;Christopher Meek
#t 1997
#c 12
#% 361100
#% 1476310
#% 1650705
#% 1650738
#% 1650786
#! When performing regression or classification, we are interested in the conditional probability distribution for an outcome or class variable Y given a set of explanatory or input variables X. We consider Bayesian models for this task. In particular, we examine a special class of models, which we call Bayesian regression/classification (BRC) models, that can be factored into independent conditional (y[x) and input (x) models. These models are convenient, because the conditional model (the portion of the full model that we care about) can be analyzed by itself. We examine the practice of transforming arbitrary Bayesian models to BRC models, and argue that this practice is often inappropriate because it ignores prior knowledge that may be important for learning. In addition, we examine Bayesian methods for learning models from data. We discuss two criteria for Bayesian model selection that are appropriate for repression/classification: one described by Spiegelhalter etah (1993), and other by Buntine (1993). We contrast these two criteria using the prequentia] framework of Dawid (1984), and give sufficient conditions under which the criteria agree.

#index 1650723
#* Inference with idempotent valuations
#@ Luis D. Hernández;Seraffn Moral
#t 1997
#c 12
#% 2115
#% 136554
#% 470026
#% 491213
#% 503500
#% 567872
#! Valuation based systems verifying an idempotent property are studied. A partial order is defined between the valuations giving them a lattice structure. Then, two different strategies are introduced to represent valuations: as infimum of the most informative valuations or as supremum of the least informative ones. It is studied how to carry out computations with both representations in an efficient way. The particular cases of finite sets and convex polytopes are considered.

#index 1650724
#* Perception, attention, and resources: a decision-theoretic approach to graphics rendering
#@ Eric Horvitz;Jed Lengyel
#t 1997
#c 12
#% 149133
#% 149137
#% 173204
#% 196923
#% 213519
#% 213525
#% 213582
#% 288942
#% 408396
#! We describe work to control graphics rendering under limited computational resources by taking a decision-theoretic perspective on perceptual costs and computational savings of approximations. The work extends earlier work on the control of rendering by introducing methods and models for computing the expected cost associated with degradations of scene components. The expected cost is computed by considering the perceptual cost of degradations and a probability distribution over the attentional focus of viewers. We review the critical literature describing findings on visual search and attention, discuss the implications of the findings, and introduce models of expected perceptual cost. Finally, we discuss policies that harness information about the expected cost of scene components.

#index 1650725
#* Time-critical action: representations and application
#@ Eric Horvitz;Adam Seiver
#t 1997
#c 12
#% 101225
#% 110379
#% 363744
#% 707175
#% 1273423
#% 1650653
#% 1650660
#% 1650666
#% 1650672
#! We review the problem of time-critical action and discuss a reformulation that shifts knowledge acquisition from the assessment of complex temporal probabilistic dependencies to the direct assessment of time-dependent utilities over key outcomes of interest. We dwell on a class of decision problems characterized by the centrality of diagnosing and reacting in a timely manner to pathological processes. We motivate key ideas in the context of trauma-care triage and transportation decisions.

#index 1650726
#* Learning belief networks in domains with recursively embedded pseudo independent submodels
#@ J. Hu;Y. Xiang
#t 1997
#c 12
#% 44876
#% 129987
#% 226678
#% 527851
#% 1650820
#! A pseudo independent (PI) model is a probabilistic domain model (PDM) where proper subsets of a set of collectively dependent variables display marginal independence. PI models cannot be learned correctly by many algorithms that rely on a single link search. Earlier work on learning PI models has suggested a straightforward multi-link search algorithm. However, when a domain contains recursively embedded PI submodels, it may escape the detection of such an algorithm. In this paper, we propose an improved algorithm that ensures the learning of all embedded PI submodels whose sizes are upper bounded by a predetermined parameter. We show that this improved learning capability only increases the complexity slightly beyond that of the previous algorithm. The performance of the new algorithm is demonstrated through experiment.

#index 1650727
#* Relational bayesian networks
#@ Manfred Jaeger
#t 1997
#c 12
#% 89958
#% 147677
#% 503673
#% 1499550
#% 1650675
#! A new method is developed to represent probabilistic relations on multiple random events. Where previously knowledge bases containing probabilistic rules were used for this purpose, here a probability distribution over the relations is directly represented by a Bayesian network. By using a powerful way of specifying conditional probability distributions in these networks, the resulting formalism is more expressive than the previous ones. Particularly, it provides for constraints on equalities of events, and it allows to define complex, nested combination functions.

#index 1650728
#* Composition of probability measures on finite spaces
#@ Radim Jiroušek
#t 1997
#c 12
#% 34262
#% 44876
#% 46437
#% 380725
#% 403535
#! Decomposable models and Bayesian networks can be defined as sequences of oligo-dimensional probability measures connected with operators of composition. The preliminary results suggest that the probabilistic models allowing for effective computational procedures are represented by sequences possessing a special property; we shall call them perfect sequences. The present paper lays down the elementary foundation necessary for further study of iterative application of operators of composition. We believe to develop a technique describing several graph models in a unifying way. We are convinced that practically all theoretical results and procedures connected with decomposable models and Bayesian networks can be translated into the terminology introduced in this paper. For example, complexity of computational procedures in these models is closely dependent on possibility to change the ordering of oligo-dimensional measures defining the model. Therefore, in this paper, lot of attention is paid to possibility to change ordering of the operators of composition.

#index 1650729
#* An information-theoretic analysis of hard and soft assignment methods for clustering
#@ Michael Kearns;Yishay Mansour;Andrew Y. Ng
#t 1997
#c 12
#% 91872
#% 115608
#% 137711
#% 185079
#! Assignment methods are at the heart of many algorithms for unsupervised learning and clustering -- in particular, the well-known K-means and Expectation-Maximizatian (EM) algorithms. In this work, we study several different methods of assignment, including the "hard" assignments used by K-means and the "soft" assignments used by EM. While it is known that K-means minimizes the distortion on the data and EM maximizes the likelihood, little is known about the systematic differences of behavior between the two algorithms. Here we shed light on these differences via an information-theoretic analysis. The cornerstone of our results is a simple decomposition of the expected distortion, showing that K-means (and its extension for inferring general parametric densities from unlabeled sample data) must implicitly manage a trade-off between how similar the data assigned to each cluster are, and how the data are balanced among the clusters. How well the data are balanced is measured by the entropy of the partition defined by the hard assignments. In addition to letting us predict and verify systematic differences between K-means and EM on specific examples, the decomposition allows us to give a rather general argument showing that K-means will consistently find densities with less "overlap" than EM. We also study a third natural assignment method that we call posterior assignment, that is close in spirit to the soft assignments of EM, but leads to a surprisingly different algorithm.

#index 1650730
#* Nested junction trees
#@ Uffe Kjærulff
#t 1997
#c 12
#% 1273439
#! The efficiency of inference in both the Hugin and, most notably, the Shafer-Shenoy architectures can be improved by exploiting the independence relations induced by the incoming messages of a clique. That is, the message to be sent from a clique can be computed via a factorization of the clique potential in the form of a junction tree. In this paper we show that by exploiting such nested junction trees in the computation of messages both space and time costs of the conventional propagation methods may be reduced. The paper presents a structured way of exploiting the nested junction trees technique to achieve such reductions. The usefulness of the method is emphasized through a thorough empirical evaluation involving ten large real-world Bayesian networks and the Hugin inference algorithm.

#index 1650731
#* Object-oriented Bayesian networks
#@ Daphne Koller;Avi Pfeffer
#t 1997
#c 12
#% 103
#% 18606
#% 44876
#% 147677
#% 1478789
#% 1478844
#% 1650675
#% 1650692
#% 1650734
#% 1650799
#! Bayesian networks provide a modeling language and associated inference algorithm for stochastic domains. They have been successfully applied in a variety of medium-scale applications. However, when faced with a large complex domain, the task of modeling using Bayesian networks begins to resemble the task of programming using logical circuits. In this paper, we describe an object-oriented Bayesian network (OOBN) language, which allows complex domains to be described in terms of inter-related objects. We use a Bayesian network fragment to describe the probabilistic relations between the attributes of an object. These attributes can themselves be objects, providing a natural framework for encoding part-of hierarchies, Classes are used to provide a reusable probabilistic model which can be applied to multiple similar objects. Classes also support inheritance of model fragments from a class to a subclass, allowing the common aspects of related classes to be defined only once. Our language has clear declarative semantics: an OOBN can be interpreted as a stochastic functional program, so that it uniquely specifies a probabilistic model. We provide an inference algorithm for OOBNs, and show that much of the structural information encoded by an OOBN--particularly the encapsulation of variables within an object and the reuse of model fragments in different contexts---can also be used to speed up the inference process.

#index 1650732
#* Nonuniform dynamic discretization in hybrid networks
#@ Alexander V. Kozlov;Daphne Koller
#t 1997
#c 12
#% 38364
#% 44876
#% 115608
#% 443637
#% 1650643
#% 1650756
#% 1650778
#! We consider probabilistic inference in general hybrid networks, which include continuous and discrete variables in an arbitrary topology. We reexamine the question of variable discretization in a hybrid network aiming at minimizing the information loss induced by the discretization. We show that a nonuniform partition across all variables as opposed to uniform partition of each variable separately reduces the size of the data structures needed to represent a continuous function. We also provide a simple but efficient procedure for nonuniform partition. To represent a nonuniform discretization in the computer memory, we introduce a new data structure, which we call a Binary Split Partition (BSP) tree. We show that BSP trees can be an exponential factor smaller than the data structures in the standard uniform discretization in multiple dimensions and show how the BSP trees can be used in the standard join tree algorithm. We show that the accuracy of the inference process can be significantly improved by adjusting discretization with evidence. We construct an erative anytime algorithm that gradually improves the quality of the discretization and the accuracy of the answer on a query. We provide empirical evidence that the algorithm converges.

#index 1650733
#* Probabilistic acceptance
#@ Henry E. Kyburg
#t 1997
#c 12
#% 1146
#% 57927
#% 107155
#% 560086
#% 1650815
#! The idea of fully accepting statements when the evidence has rendered them probable enough faces a number of difficulties. We leave the interpretation of probability largely open, but attempt to suggest a contextual approach to full belief. We show that the difficulties of probabilistic acceptance are not as severe as they are sometimes painted, and that though there are oddities associated with probabilistic acceptance they are in some instances less awkward than the difficulties associated with other nonmonotonic formalisms. We show that the structure at which we arrive provides a natural home for statistical inference.

#index 1650734
#* Network fragments: representing knowledge for constructing probabilistic models
#@ Kathryn Blackmond Laskey;Suzanne M. Mahoney
#t 1997
#c 12
#% 31874
#% 44876
#% 101221
#% 116185
#% 130878
#% 443631
#% 527519
#% 527672
#% 1650675
#% 1650767
#% 1650799
#! In most current applications of belief networks, domain knowledge is represented by a single belief network that applies to all problem instances in the domain. In more complex domains, problem-specific models must be constructed from a knowledge base encoding probabilistic relationships in the domain. Most work in knowledge-based model construction takes the rule as the basic unit of knowledge. We present a knowledge representation framework that permits the knowledge base designer to specify knowledge in larger semantically meaningful units which we call network fragments. Our framework provides for representation of asymmetric independence and canonical intercausal interaction. We discuss the combination of network fragments to form problem-specific models to reason about particular problem instances. The framework is illustrated using examples from the domain of military situation awareness.

#index 1650735
#* Computational advantages of relevance reasoning in Bayesian belief networks
#@ Yan Lin;Marek J. Druzdzel
#t 1997
#c 12
#% 34262
#% 44876
#% 68244
#% 136358
#% 138515
#% 147677
#% 375029
#% 437610
#% 527667
#% 527687
#% 527690
#% 527841
#% 1650763
#% 1650767
#! This paper introduces a computational framework for reasoning in Bayesian belief networks that derives significant advantages from focused inference and relevance reasoning. This framework is based on d-separation and other simple and computationally efficient techniques for pruning irrelevant parts of a network. Our main contribution is a technique that we call relevance-based decomposilion, Relevance-based decomposition approaches belief updating in large networks by focusing on their parts and decomposing them into partially overlapping subnetworks. This makes reasoning in some intractable networks possible and, in addition, often results in significant speedup, as the total time taken to update all subnetworks is in practice often considerably less than the time taken to update the network as a whole. We report results of empirical tests that demonstrate practical significance of our approach.

#index 1650736
#* Incremental map generation by low cost robots based on possibility/necessity grids
#@ Maite López-Sánchez;R. López de Mántaras;C. Sierra
#t 1997
#c 12
#% 160869
#% 168320
#% 184027
#% 470459
#% 1279751
#! In this paper we present some results obtained with a troupe of low-cost robots designed to cooperatively explore and adquire the map of unknown structured orthogonal environments. In order to improve the covering of the explored zone, the robots show different behaviours and cooperate by transferring each other the perceived environment when they meet. The returning robots deliver to a host computer their partial maps and the host incrementally generates the map of the environment by means of a possibility/necessity grid.

#index 1650737
#* A target classification decision aid
#@ Todd Michael Mansell
#t 1997
#c 12
#% 1858
#% 44876
#% 91013
#% 361888
#% 1784126
#! A submarine's sonar team is responsible for detecting, localising and classifying targets using information provided by the platform's sensor suite. The information used to make these assessments is typically uncertain and/or incomplete and is likely to require a measure of confidence in its reliability. Moreover, improvements in sensor and communication technology are resulting in increased amounts of on-platform and off-platform information available for evaluation. This proliferation of imprecise information increases the risk of overwhelming the operator. To assist the task of localisation and classification a concept demonstration decision aid (Horizon), based on evidential reasoning, has been developed. Horizon is an information fusion software package for representing and fusing imprecise information about the state of the world, expressed across suitable frames of reference. The Horizon software is currently at prototype stage.

#index 1650738
#* Structure and parameter learning for causal independence and causal interaction models
#@ Christopher Meek;David Heckerman
#t 1997
#c 12
#% 44876
#% 129987
#% 232117
#% 1272279
#% 1272302
#% 1272363
#% 1272945
#% 1290046
#% 1650783
#% 1650786
#% 1650793
#% 1650820
#% 1784146
#! We begin by discussing causal independence models and generalize these models to causal interaction models. Causal interaction models are models that have independent mechanisms where mechanisms can have several causes. In addition to introducing several particular types of causal interaction models, we show how we can apply the Bayesian approach to learning causal interaction models obtaining approximate posterior distributions for the models and obtain MAP and ML estimates for the parameters. We illustrate the approach with a simulation study of learning model posteriors.

#index 1650739
#* Support and plausibility degrees in generalized functional models
#@ Paul-André Monney
#t 1997
#c 12
#! By discussing several examples, the theory of generalized functional models is shown to be very natural for modeling some situations of reasoning under uncertainty. A generalized functional model is a pair (f, P) where f is a function describing the interactions between a parameter variable, an observation variable and a random source, and P is a probability distribution for the random source. Unlike traditional functional models, generalized functional models do not require that there is only one value of the parameter variable that is compatible with an observation and a realization of the random source. As a consequence, the results of the analysis of a generalized functional model are not expressed in terms of probability distributions but rather by support and plausibility functions. The analysis of a generalized functional model is very logical and is inspired from ideas already put forward by R.A. Fisher in his theory of fiducial probability.

#index 1650740
#* The cognitive processing of causal knowledge
#@ Scott B. Morris;Doug Cork;Richard E. Neapolitan
#t 1997
#c 12
#% 6199
#% 44876
#% 67866
#% 382160
#! There is a brief description of the probabilistic causal graph model for representing, reasoning with, and learning causal structure using Bayesian networks. It is then argued that this model is closely related to how humans reason with and learn causal structure. It is shown that studies in psychology on discounting (reasoning concerning how the presence of one cause of an effect makes another cause less probable) support the hypothesis that humans reach the same judgments as algorithms for doing inference in Bayesian networks. Next, it is shown how studies by Piaget indicate that humans learn causal structure by observing the same independencies and dependencies as those used by certain algorithms for learning the structure of a Bayesian network. Based on this indication, a subjective definition of causality is forwarded. Finally, methods for further testing the accuracy of these claims are discussed.

#index 1650741
#* Representing aggregate belief through the competitive equilibrium of a securities market
#@ David M. Pennock;Michael P. Wellman
#t 1997
#c 12
#% 183859
#% 1650801
#! We consider the problem of belief aggregation: given a group of individual agents with probabilistic beliefs over a set of of uncertain events, formulate a sensible consensus or aggregate probability distribution over these events. Researchers have proposed many aggregation methods, although on the question of which is best the general consensus is that there is no consensus. We develop a market-based approach to this problem, where agents bet on uncertain events by buying or selling securities contingent on their outcomes. Each agent acts in the market so as to maximize expected utility at given securities prices, limited in its activity only by its own risk aversion. The equilibrium prices of goods in this market represent aggregate beliefs. For agents with constant risk aversion, we demonstrate that the aggregate probability exhibits several desirable properties, and is related to independently motivated techniques. We argue that the market-based approach provides a plausible mechanism for belief aggregation in multiagent systems, as it directly addresses self-motivated agent incentives for participation and for truthfulness, and can provide a decision-theoretic foundation for the "expert weights" often employed in centralized pooling techniques.

#index 1650742
#* Learning Bayesian networks from incomplete databases
#@ Marco Ramoni;Paola Sebastiani
#t 1997
#c 12
#% 17144
#% 44876
#% 129987
#% 197387
#% 549253
#% 1272363
#! Bayesian approaches to learn the graphical structure of Bayesian Belief Networks (BBNS) from databases share the assumption that the database is complete, that is, no entry is reported as unknown. Attempts to relax this assumption involve the use of expensive iterative methods to discriminate among different structures. This paper introduces a deterministic method to learn the graphical structure of a BBN from a possibly incomplete database. Experimental evaluations show a significant robustness of this method and a remarkable independence of its execution time from the number of missing data.

#index 1650743
#* Estimation of effects of sequential treatments by reparameterizing directed acyclic graphs
#@ James M. Robins;Larry Wasserman
#t 1997
#c 12
#% 1650678
#! The standard way to parameterize the distributions represented by a directed acyclic graph is to insert a parametric family for the conditional distribution of each random variable given its parents. We show that when one's goal is to test for or estimate an effect of a sequentially applied treatment, this natural parameterization has serious deficiencies. By reparameterizing the graph using structural nested models, these deficiencies can be avoided.

#index 1650744
#* Cost-sharing in Bayesian knowledge bases
#@ Solomon Eyal Shimony;Carmel Domshlak;Eugene Santos
#t 1997
#c 12
#% 44876
#% 83104
#% 161246
#% 232102
#% 1477315
#% 1650757
#% 1650758
#! Bayesian knowledge bases (BKBs) are a generalization of Bayes networks and weighted proof graphs (WAODAGs), that allow cycles in the causal graph. Reasoning in BKBs requires finding the most probable inferences consistent with the evidence. The costsharing heuristic for finding least-cost explanations in WAODAGs was presented and shown to be effective by Charniak and Husain. However, the cycles in BKBs would make the definition of cost-sharing cyclic as well, if applied directly to BKBs. By treating the defining equations of cost-sharing as a system of equations, one can properly define an admissible cost-sharing heuristic for BKBs. Empirical evaluation shows that costsharing improves performance significantly when applied to BKBs.

#index 1650745
#* Conditional utility, utility independence, and utility networks
#@ Yoav Shoham
#t 1997
#c 12
#% 74817
#% 1271906
#% 1650628
#! We introduce a new interpretation of two related notions - conditional utility and utility independence. Unlike the traditional interpretation, the new interpretation render the notions the direct analogues of their probabilistic counterparts. To capture these notions formally, we appeal to the notion of utility distribution, introduced in previous paper. We show that utility distributions, which have a structure that is identical to that of probability distributions, can be viewed as a special case of an additive multiattribute utility functions, and show how this special case permits us to capture the novel senses of conditional utility and utility independence. Finally, we present the notion of utility networks, which do for utilities what Bayesian networks do for probabilities. Specifically, utility networks exploit the new interpretation of conditional utility and utility independence to compactly represent a utility distribution.

#index 1650746
#* Sequential thresholds: context sensitive default extensions
#@ Choh Man Teng
#t 1997
#c 12
#% 1146
#% 42003
#% 100160
#% 100178
#% 111937
#% 175371
#% 527526
#% 1272737
#% 1273615
#% 1274592
#% 1274707
#% 1290093
#% 1477167
#% 1650796
#% 1650815
#! Default logic encounters some conceptual difficulties in representing common sense reasoning tasks. We argue that we should not try to formulate modular default rules that are presumed to work in all or most circumstances. We need to take into account the importance of the context which is continuously evolving during the reasoning process. Sequential thresholding is a quantitative counterpart of default logic which makes explicit the role context plays in the construction of a non-monotonic extension. We present a semantic characterization of generic nonmonotonic reasoning, as well as the instantiations pertaining to default logic and sequential thresholding. This provides a link between the two mechanisms as well as a way to integrate the two that can be beneficial to both.

#index 1650747
#* On stable multi-agent behavior in face of uncertainty
#@ Moshe Tennenholtz
#t 1997
#c 12
#% 4332
#% 86446
#% 181622
#% 188086
#% 408638
#% 1272293
#% 1272361
#% 1275317
#% 1477275
#! A stable joint plan should guarantee the achievement of a designer's goal in a multiagent environment, while ensuring that deviations from the prescribed plan would be detected. We present a computational framework where stable joint plans can be studied, as well as several basic results about the representation, verification and synthesis of stable joint plans.

#index 1650748
#* Score and information for recursive exponential models with incomplete data
#@ Bo Thiesson
#t 1997
#c 12
#% 44876
#% 185079
#% 197387
#% 1290046
#% 1650772
#! Recursive graphical models usually underlie the statistical modelling concerning probabilistic expert systems based on Bayesian networks. This paper defines a version of these models, denoted as recursive exponential models, which have evolved by the desire to impose sophisticated domain knowledge onto local fragments of a model. Besides the structural knowledge, as specified by a given model, the statistical modelling may also include expert opinion about the values of parameters in the model. It is shown how to translate imprecise expert knowledge into approximately conjugate prior distributions. Based on possibly incomplete data, the score and the observed information are derived for these models. This accounts for both the traditional score and observed information, derived as derivatives of the log-likelihood, and the posterior score and observed information, derived as derivatives of the log-posterior distribution. Throughout the paper the specialization into recursive graphical models is accounted for by a simple example.

#index 1650749
#* Lexical access for speech understanding using minimum message length encoding
#@ Ian Thomas;Ingrid Zukerman;Jonathan Oliver;David Albrecht;Bhavani Raskutti
#t 1997
#c 12
#% 48799
#% 137711
#% 567602
#% 1815033
#! The Lexical Access Problem consists of determining the intended sequence of words corresponding to an input sequence of phonemes (basic speech sounds) that come from a low-level phoneme recognizer. In this paper we present an information-theoretic approach based on the Minimum Message Length Criterion for solving the Lexical Access Problem. We model sentences using phoneme realizations seen in training, and word and part-of-speech information obtained from text corpora. We show results on multiple-speaker, continuous, read speech and discuss a heuristic using equivalence classes of similar sounding words which speeds up the recognition process without significant deterioration in recognition accuracy.

#index 1650750
#* Region-based approximations for planning in stochastic domains
#@ Nevin L. Zhang;Wenju Liu
#t 1997
#c 12
#% 92301
#% 101869
#% 102136
#% 103309
#% 179940
#% 646950
#% 646971
#% 695957
#% 1290039
#% 1290041
#! This paper is concerned with planning in stochastic domains by means of partially observable Markov decision processes (POMDPs). POMDPs are difficult to solve. This paper identifies a subclass of POMDPs called region observable POMDPs, which are easier to solve and can be used to approximate general POMDPs to arbitrary accuracy.

#index 1650751
#* Independence of causal influence and clique tree propagation
#@ Nevin Lianwen Zhang;Li Yan
#t 1997
#c 12
#% 21142
#% 44876
#% 59918
#% 101224
#% 1272302
#% 1650680
#% 1650767
#! This paper explores the role of independence of causal influence (ICI) in Bayesian network inference. ICI allows one to factorize a conditional probability table into smaller pieces. We describe a method for exploiting the factorization in clique tree propagation (CTP) -- the state-of-the-art exact inference algorithm for Bayesian networks. We also present empirical results showing that the resulting algorithm is significantly more efficient than the combination of CTP and previous techniques for exploiting ICI.

#index 1650752
#* Fast value iteration for goal-directed Markov decision processes
#@ Nevin L. Zhang;Weihoag Zhang
#t 1997
#c 12
#% 22348
#% 70370
#% 75936
#% 103309
#% 646964
#% 1290041
#% 1478679
#% 1650710
#! Planning problems where effects of actions are non-deterministic can be modeled as Markov decision processes. Planning problems axe usually goal-directed. This paper proposes several techniques for exploiting the goal-directedness to accelerate value iteration, a standard algorithm for solving Markov decision processes. Empirical studies have shown that the techniques can bring about significant speedups.

#index 1650753
#* Proceedings of the Twelfth international conference on Uncertainty in artificial intelligence
#@ Eric Horvitz;Finn Jensen
#t 1996
#c 12

#index 1650754
#* An algorithm for finding minimum d-separating sets in belief networks
#@ Silvia Acid;Luis M. De Campos
#t 1996
#c 12
#% 44876
#% 58167
#% 527514
#! The criterion commonly used in directed acyclic graphs (dags) for testing graphical independence is the well-known d-separation criterion. It allows us to build graphical representations of dependency models (usually probabilistic dependency models) in the form of belief networks, which make easy interpretation and management of independence relationships possible, without reference to numerical parameters (conditional probabilities). In this paper, we study the following combinatorial problem: finding the minimum d-separating set for two nodes in a dug. This set would represent the minimum information (in the sense of minimum number of variables) necessary to prevent these two nodes from influencing each other. The solution to this basic problem and some of its extensions can be useful in several ways, as we shall see later. Our solution is based on a two-step process: first, we reduce the original problem to the simpler one of finding a minimum separating set in an undirected graph, and second, we develop an algorithm for solving it.

#index 1650755
#* Constraining influence diagram structure by generative planning: an application to the optimization of oil spill response
#@ John M. Agosta
#t 1996
#c 12
#% 22348
#% 44836
#% 103309
#% 1275349
#% 1650653
#! This paper works through the optimization of a real world planning problem, with a combination of a generative planning tool and an influence diagram solver. The problem is taken from an existing application in the domain of oil spill emergency response. The planning agent manages constraints that order sets of feasible equipment employment actions. This is mapped at an intermediate level of abstraction onto an influence diagram. In addition, the planner can apply a surveillance operator that determines observability of the state--the unknown trajectory of the oil. The uncertain world state and the objective function properties are part of the influence diagram structure, but not represented in the planning agent domain. By exploiting this structure under the constraints generated by the planning agent, the influence diagram solution complexity simplifies considerably, and an optimum solution to the employment problem based on the objective function is found. Finding this optimum is equivalent to the simultaneous evaluation of a range of plans. This result is an example of bounded optimality, within the limitations of this hybrid generative planner and influence diagram architecture.

#index 1650756
#* Inference using message propagation and topology transformation in vector Gaussian continuous networks
#@ Satnam Alag;Alice M. Agogino
#t 1996
#c 12
#% 44876
#% 61079
#% 103309
#% 174161
#% 703476
#% 1650643
#! We extend continuous Gaussian networks - directed acyclic graphs that encode probabilistic relationships between variables - to its vector form. Vector Gaussian continuous networks consist of composite nodes representing multivariables, that take continuous values. These vector or composite nodes can represent correlations between parents, as opposed to conventional univariate nodes. We derive rules for inference in these networks based on two methods: message propagation and topology transformation. These two approaches lead to the development of algorithms, that can be implemented in either a centralized or a decentralized manner. The domain of application of these networks are monitoring and estimation problems. This new representation along with the rules for inference developed here can be used to derive current Bayesian algorithms such as the Kalman filter, and provide a rich foundation to develop new algorithms. We illustrate this process by deriving the decentralized form of the Kalnaan filter. This work unifies concepts from artificial intelligence and modern control theory.

#index 1650757
#* A structurally and temporally extended Bayesian belief network model: definitions, properties, and modeling techniques
#@ Constantin F. Aliferis;Gregory F. Cooper
#t 1996
#c 12
#% 399
#% 44876
#% 67866
#% 68244
#% 129987
#% 136358
#% 159480
#% 394891
#% 503673
#% 1477302
#% 1650655
#% 1650675
#! We developed the language of Modifiable Temporal Belief Networks (MTBNs) as a structural and temporal extension of Bayesian Belief Networks (BNs) to facilitate normative temporal and causal modeling under uncertainty. In this paper we present definitions of the model, its components, and its fundamental properties. We also discuss how to represent various types of temporal knowledge, with an emphasis on hybrid temporal-explicit time modeling, dynamic structures, avoiding causal temporal inconsistencies, and dealing with models that involve simultaneously actions (decisions) and causal and non-causal associations. We examine the relationships among BNs, Modifiable Belief Networks, and MTBNs with a single temporal granularity, and suggest areas of application suitable to each one of them.

#index 1650758
#* An alternative Markov property for chain graphs
#@ Steen A. Andersson;David Madigan;Michael D. Perlman
#t 1996
#c 12
#% 44876
#% 61079
#% 130153
#% 185075
#% 503662
#% 1650633
#% 1650683
#! Graphical Markov models use graphs, either undirected, directed, or mixed, to represent possible dependences among statistical variables. Applications of undirected graphs (UDGs) include models for spatial dependence and image analysis, while acyctic directed graphs (ADGs), which are especially convenient for statistical analysis, arise in such fields as genetics and psychometrics and as models for expert systems and Bayesian belief networks. Lauritzen, Wermuth, and Frydenberg (LWF) introduced a Markov property for chain graphs, which are mixed graphs that can be used to represent simultaneously both causal and associative dependencies and which include both UDGs and ADGs as special cases. In this paper an alternative Markov property (AMP) for chain graphs is introduced, which in some ways is a more direct extension of the ADG Markov property than is the LWF property for chain graph.

#index 1650759
#* Plan development using local probabilistic models
#@ Ella M. Atkins;Edmund H. Durfee;Kang G. Shin
#t 1996
#c 12
#% 62653
#% 179939
#% 179955
#% 179957
#% 181338
#% 288821
#% 394891
#% 1275454
#% 1476349
#% 1478679
#% 1650660
#% 1650672
#! Approximate models of world state transitions are necessary when building plans for complex systems operating in dynamic environments. External event probabilities can depend on state feature values as well as time spent in that particular state. We assign temporally-dependent probability functions to state transitions. These functions are used to locally compute state probabilities, which are then used to select highly probable goal paths and eliminate improbable states. This probabilistic model has been implemented in the Cooperative Intelligent Real-time Control Architecture (CIRCA), which combines an AI planner with a separate real-time system such that plans are developed, scheduled, and executed with real-time guarantees. We present flight simulation tests that demonstrate how our probabilistic model may improve CIRCA performance.

#index 1650760
#* Entailment in probability of thresholded generalizations
#@ Donald Bamber
#t 1996
#c 12
#% 3034
#% 128627
#% 187566
#% 187571
#% 205808
#% 209373
#% 216970
#% 539198
#% 1272359
#% 1273615
#% 1477308
#% 1478551
#! A nonmonotonic logic of thresholded generalizations is presented. Given propositions a and β from a language L and a positive integer k, the thresholded generalization α →k β means that the conditional probability π(β|α) is at least 1 -ψδk. A two-level probability structure is defined. At the lower level, a model is defined to be a probability function on L. At the upper level, there is a probability distribution over models. A definition is given of what it means for a collection of thresholded generalizations to entail another thresholded generalization. This nonmonotonic entailment relation, called entailment in probability, has the feature that its conclusions are probabilistically trustworthy meaning that, given true premises, it is improbable that an entailed conclusion would be false. A procedure is presented for ascertaining whether any given collection of premises entails any given conclusion. It is shown that entailment in probability is closely related to Goldszmidt and Pearl's System-Z+, thereby demonstrating that System-Z+'s conclusions are probabilistically trustworthy.

#index 1650761
#* Object recognition with imperfect perception and redundant description
#@ Claude Barrouil;Jérôme Lemaire
#t 1996
#c 12
#% 134290
#% 630069
#! This paper deals with a scene recognition system in a robotics context. The general problem is to match images with a priori descriptions. A typical mission would consist in identifying an object in an installation with a vision system situated at the end of a manipulator and with a human operator provided description, formulated in a pseudonatural language, and possibly redundant. The originality of this work comes from the nature of the description, from the special attention given to the management of imprecision and uncertainty in the interpretation process and from the way to assess the description redundancy so as to reinforce the overall matching likelihood.

#index 1650762
#* Approximations for decision making in the Dempster-Shafer theory of evidence
#@ Mathias Bauer
#t 1996
#c 12
#% 1858
#% 45265
#% 59547
#% 77847
#% 83937
#% 101260
#% 136365
#% 168542
#% 1272847
#! The computational complexity of reasoning within the Dempster-Shafer theory of evidence is one of the main points of criticism this formalism has to face. To overcome this difficulty various approximation algorithms have been suggested that aim at reducing the number of focal elements in the belief functions involved, Besides introducing a new algorithm using this method, this paper describes an empirical study that examines the appropriateness of these approximation procedures in decision making situations. It presents the empirical findings and discusses the various tradeoffs that have to be taken into account when actually applying one of these methods.

#index 1650763
#* A sufficiently fast algorithm for finding close to optimal junction trees
#@ Ann Becker;Dan Geiger
#t 1996
#c 12
#% 1675
#% 6199
#% 10517
#% 31482
#% 44876
#% 55926
#% 68244
#% 70370
#% 93660
#% 115509
#% 115511
#% 150115
#% 179784
#% 201002
#% 539266
#% 566573
#! Au algorithm is developed for findiug a close to optimal junction tree of a given graph G. The algorithm has a worst case complexity O(ckna) where a and c are constants, n is the nmnber of vertices, and k is the size of the largest clique in a juuction tree of G in which this size is minimized. The algorithm guarantees that the logarithm of the size of the state space of the heaviest clique in the junction tree produced is less than a constant factor off the optional value. When k = O(log n) our algorithm yields a polynomial inference algorithm for Bayesian networks.

#index 1650764
#* Coping with the limitations of rational inference in the framework of possibility theory
#@ Salem Benferhat;Didier Dubois;Henri Prade
#t 1996
#c 12
#% 36236
#% 77841
#% 115327
#% 160378
#% 218813
#% 470364
#% 780340
#% 1274581
#% 1290089
#! Possibility theory offers a framework where both Lehmann's "preferential inference" and the more productive (but less cautious) "rational closure inference" can be represented. However, there are situations where the second inference does not provide expected results either because it cannot produce them, or even provide counterintuitive conclusions. This state of facts is not due to the principle of selecting a unique ordering of interpretations (which can be encoded by one possibility distribution), but rather to the absence of constraints expressing pieces of knowledge we have implicitly in mind. It is advocated in this paper that constraints induced by independence information can help finding the right ordering of interpretations. In particular, independence constraints can be systematically assumed with respect to formulas composed of literals which do not appear in the conditional knowledge base, or for default rules with respect to situations which are "normal" according to the other default rules in the base. The notion of independence which is used can be easily expressed in the qualitative setting of possibility theory. Moreover, when a counterintuitive plausible conclusion of a set of defaults, is in its rational closure, but not in its preferential closure, it is always possible to repair the set of defaults so as to produce the desired conclusion.

#index 1650765
#* Arguing for decisions: a qualitative model of decision making
#@ Blai Bonet;Hector Geffner
#t 1996
#c 12
#% 153275
#% 459577
#% 527528
#% 1290145
#% 1476295
#% 1650690
#! We develop a qualitative model of decision making with two aims: to describe how people make simple decisions and to enable computer programs to do the same. Current approaches based on Planning or Decision Theory either ignore uncertainty and tradeoffs, or provide languages and algorithms that are too complex for this task. The proposed model provides a language based on rules, a semantics based on high probabilities and lexicographical preferences, and a transparent decision procedure where reasons for and against decisions interact. The model is no substitute for Decision Theory, yet for decisions that people find easy to explain it may provide an appealing alternative.

#index 1650766
#* Learning conventions in multiagent stochastic domains using likelihood estimates
#@ Craig Boutilier
#t 1996
#c 12
#% 154046
#% 363744
#% 782311
#% 1273580
#% 1290041
#% 1478501
#! Fully cooperative multiagent systems--those in which agents share a joint utility model--is of special interest in AI. A key problem is that of ensuring that the actions of individual agents are coordinated, especially in settings where the agents are autonomous decision makers. We investigate approaches to learning coordinated strategies in stochastic domains where an agent's actions are not directly observable by others. Much recent work in game theory has adopted a Bayesian learning perspective to the more general problem of equilibrium selection, but tends to assume that actions can be observed. We discuss the special problems that arise when actions are not observable, including effects on rates of convergence, and the effect of action failure probabilities and asymmetries. We also use likelihood estimates as a means of generalizing fictitious play learning models in our setting. Finally, we propose the use of maximum likelihood as a means of removing strategies from consideration, with the aim of convergence to a conventional equilibrium, at which point learning and deliberation can cease.

#index 1650767
#* Context-specific independence in Bayesian networks
#@ Craig Boutilier;Nir Friedman;Moises Goldszmidt;Daphne Koller
#t 1996
#c 12
#% 3873
#% 44876
#% 99022
#% 101221
#% 136350
#% 138515
#% 147677
#% 503673
#% 696946
#% 1290041
#% 1650639
#% 1650783
#! Bayesian networks provide a language for qualitatively representing the conditional independence properties of a distribution, This allows a natural and compact representation of the distribution, eases knowledge acquisition, and supports effective inference algorithms. It is well-known, however, that there are certain independencies that we cannot capture qualitatively within the Bayesian network structure: independencies that hold only in certain contexts, i.e., given a specific assignment of values to certain variables, In this paper, we propose a formal notion of context-specific independence (CSI), based on regularities in the conditional probability tables (CPTs) at a node. We present a technique, analogous to (and based on) d-separation, for determining when such independence holds in a given network. We then focus on a particular qualitative representation scheme--tree-structured CPTs-- for capturing CSI. We suggest ways in which this representation can be used to support effective inference algorithms, in particular, we present a structural decomposition of the resulting network which can improve the performance of clustering algorithms, and an alternative algorithm based on outset conditioning.

#index 1650768
#* Decision-theoretic troubleshooting: a framework for repair and experiment
#@ John S. Breese;David Heckerman
#t 1996
#c 12
#% 1121
#% 21138
#% 160190
#% 183497
#% 1272178
#% 1784146
#! We develop and extend existing decision-theoretic methods for troubleshooting a nonfunctioning device. Traditionally, diagnosis with Bayesian networks has focused on belief updating--determining the probabilities of various faults given current observations. In this paper, we extend this paradigm to include taking actions. In particular, we consider three classes of actions: (1) we can make observations regarding the behavior of a device and infer likely faults as in traditional diagnosis, (2) we can repair a component and then observe the behavior of the device to infer likely faults, and (3) we can change the configuration of the device, observe its new behavior, and infer the likelihood of faults. Analysis of latter two classes of troubleshooting actions requires incorporating notions of persistence into the belief-network formalism used for probabilistic inference.

#index 1650769
#* Tail sensitivity analysis in Bayesian networks
#@ Enrique F. Castillo;Cristina Solares;Patricia Gómez
#t 1996
#c 12
#% 21142
#% 382160
#% 503690
#% 527664
#! The paper presents an efficient method for simulating the tails of a target variable Z = h(X) which depends on a set of basic variables X = (X1,...,Xn). To this aim, variables Xi;i = 1,...., n are sequentially simulated in such a manner that Z = h(x1,..., xi-1, Xi,..., Xn) is guaranteed to be in the tail of Z. When this method is difficult to apply, an alternative method is proposed, which leads to a low rejection proportion of sample values, when compared with the Monte Carlo method. Both methods are shown to be very useful to perform a sensitivity analysis of Bayesian networks, when very large confidence intervals for the marginal/conditional probabilities are required, as in reliability or risk analysis. The methods are shown to behave best when all scores coincide. The required modifications for this to occur are discussed. The methods are illustrated with several examples and one example of application to a real case is used to illustrate the whole process.

#index 1650770
#* Decision-analytic approaches to operational decision making: application and observation
#@ Tom Chávez
#t 1996
#c 12
#% 42214
#% 191983
#% 197387
#% 1784101
#! Decision analysis (DA) and the rich set of tools developed by researchers in decision making under uncertainty show great potential to penetrate the technological content of the products and services delivered by firms in a variety of industries as well as the business processes used to deliver those products and services to market. In this paper I describe work in progress at Sun Microsystems in the application of decision-analytic methods to Operational Decision Making (ODM) in its World-Wide Operations (WWOPS) Business Management group, Working with members of product engineering, marketing, and sales, operations planners from WWOPS have begun to use a decision-analytic framework called SCRAM (Supply Communication/ Risk Assessment and Management) to structure and solve problems in product planning, tracking, and transition. Concepts such as information value provide a powerful method of managing huge information sets and thereby enable managers to focus attention on factors that matter most for their business. Finally, our process-oriented introduction of decision-analytic methods to Sun managers has led to a focused effort to develop decision support software based on methods from decision-making under uncertainty.

#index 1650771
#* Learning equivalence classes of Bayesian network structures
#@ David Maxwell Chickering
#t 1996
#c 12
#% 101213
#% 101217
#% 197387
#% 503513
#% 527830
#% 1650638
#% 1650673
#! Approaches to learning Bayesian networks from data typically combine a scoring function with a heuristic search procedure. Given a Bayesian network structure, many of the scoring functions derived in the literature return a score for the entire equivalence class to which the structure belongs. When using such a scoring function, it is appropriate for the heuristic search algorithm to search over equivalence classes of Bayesian networks as opposed to individual structures. We present the general formulation of a search space for which the states of the search correspond to equivalence classes of structures. Using this space, any one of a number of heuristic search algorithms can easily be applied. We compare greedy search performance in the proposed search space to greedy search performance in a search space for which the states correspond to individual Bayesian network structures.

#index 1650772
#* Efficient approximations for the marginal likelihood of incomplete data given a Bayesian network
#@ David Maxwell Chickering;David Heckerman
#t 1996
#c 12
#% 129987
#% 197387
#% 232117
#% 443025
#% 1272363
#% 1290046
#% 1650786
#! We examine asymptotic approximations for the marginal likelihood of incomplete data given a Bayesian network. We consider the Laplace approximation and the less accurate but more efficient BIC/MDL approximation. We also consider approximations proposed by Draper (1993) and Cheeseman and Stutz (1995). These approximations are as efficient as BIC/MDL, but their accuracy has not been studied in any depth. We compare the accuracy of these approximations under the assumption that the Laplace approximation is the most accurate. In experiments using synthetic data generated from discrete naive-Bayes models having a hidden root node, we find that (1) the BIC/MDL measure is the least accurate, having a bias in favor of simple models, and (2) the Draper and CS measures are the most accurate, having a bias in favor of simple and complex models, respectively.

#index 1650773
#* Independence with lower and upper probabilities
#@ Lonnie Chrisman
#t 1996
#c 12
#% 3034
#% 42210
#% 116624
#% 124580
#% 161238
#% 443638
#% 503339
#% 1650640
#% 1650774
#% 1650775
#! It is shown that the ability of the interval probability representation to capture epistemological independence is severely limited. Two events are epistemologically independent if knowledge of the first event does not alter belief (i.e., probability bounds) about the second. However, iudependence in this form can only exist in a 2-monotone probability function in degenerate cases -- i.e., if the prior bounds are either point probabilities or entirely vacuous. Additional limitations are characterized for other classes of lower probabilities as well. It is argued that these phenomena are a matter of interpretation. They appear to be limitations when one interprets probability bounds as a measure of epistemological indeterminacy (i.e., uncertainty arising from a lack of knowledge), but are exactly as one would expect when probability intervals are interpreted as representations of ontological indeterminacy (indeterminacy introduced by structural approximations).

#index 1650774
#* Propagation of 2-monotone lower probabilities on an undirected graph
#@ Lonnle Chrisman
#t 1996
#c 12
#% 3034
#% 31482
#% 44876
#% 83934
#% 101210
#% 101211
#% 101262
#% 116624
#% 124580
#% 128629
#% 130150
#% 183490
#% 443638
#% 567872
#% 1650773
#% 1650775
#! Lower and upper probabilities, also known as Choquet capacities, are widely used as a convenient representation for sets of probability distributions. This paper presents a graphical decomposition and exact propagation algorithm for computing marginal posteriors of 2-monotone lower probabilities (equivalently, 2-alternating upper probabilities).

#index 1650775
#* Quasi-Bayesian strategies for efficient plan generation: application to the planning to observe problem
#@ Fabio Cozman;Eric Krotkov
#t 1996
#c 12
#% 20853
#% 98073
#% 116624
#% 470455
#% 527676
#% 527849
#! Quasi-Bayesian theory uses convex sets of probability distributions and expected loss to represent preferences about plans. The theory focuses on decision robustness, i.e., the extent to which plans are affected by deviations in subjective assessments of probability. Generating a plan means enumerating the actions to be taken and providing information about the robustness of the actions. The present work presents plan generation problems that can be solved faster in the Quasi-Bayesian framework than within usual Bayesian theory. We investigate this on the planning to observe problem, i.e., an agent must decide whether to take new observations or not. The fundamental question is: How, and how much, to search for a "best" plan, based on the precision of probability assessments? Plan generation algorithms are derived in the context of material classification with an acoustic robotic probe. A package that constructs Quasi-Bayesian plans is available through anonymous ftp.

#index 1650776
#* Some experiments with real-time decision algorithms
#@ Bruce D'Ambrosio;Scott Burgess
#t 1996
#c 12
#% 527691
#% 1273446
#% 1290039
#% 1650651
#% 1650873
#% 1650923
#% 1650973
#! Real-time Decision algorithms are a class of incremental resource-bounded [Horvitz, 89] or anytime [Dean, 93] algorithms for evaluating influence diagrams. We present a test domain for real-time decision algorithms, and the results of experiments with several Real-time Decision Algorithms in this domain. The results demonstrate high performance for two algorithms, a decision-evaluation variant of Incremental Probabilisitic Inference [D'Ambrosio, 93] and a variant of an algorithm suggested by Goldszmidt, [Goldszmidt, 95], PK-reduced. We discuss the implications of these experimental results and explore the broader applicability of these algorithms.

#index 1650777
#* Query DAGs: a practical paradigm for implementing belief-network inference
#@ Adnan Darwiche;Gregory Provan
#t 1996
#c 12
#% 1477089
#! We describe a new paradigm for implementing inference in belief networks, which consists of two steps: (1) compiling a belief network into an arithmetic expression called a Query DAG (Q-DAG); and (2) answering queries using a simple evaluation algorithm. Each non-leaf node of a Q-DAG represents a numeric operation, a number, or a symbol for evidence. Each leaf node of a Q-DAG represents the answer to a network query, that is, the probability of some event of interest. It appears that Q-DAGs can be generated using any of the standard algorithms for exact inference in belief networks -- we show how they can be generated using the clustering algorithm. The time and space complexity of a Q-DAG generation algorithm is no worse than the time complexity of the inference algorithm on which it is based. The complexity of a Q-DAG evaluation algorithm is linear in the size of the Q-DAG, and such inference amounts to a standard evaluation of the arithmetic expression it represents. The main value of Q-DAGs is in reducing the software and hardware resources required to utilize belief networks in on-line, real-world applications. The proposed framework also facilitates the development of on-line inference on different software and hardware platforms due to the simplicity of the Q-DAG evaluation algorithm.

#index 1650778
#* Bucket elimination: a unifying framework for probabilistic inference
#@ Rina Dechter
#t 1996
#c 12
#% 1675
#% 34262
#% 44876
#% 46437
#% 55926
#% 56706
#% 101250
#% 119308
#% 128629
#% 130135
#% 288165
#% 408680
#% 527842
#% 534182
#% 1477089
#% 1650628
#% 1650779
#! Probabilistic inference algorithms for finding the most probable explanation, the maximum aposteriori hypothesis, and the maximum expected utility and for updating belief are reformulated as an elimination-type algorithm called bucket elimination. This emphasizes the principle common to many of the algorithms appearing in that literature and clarifies their relationship to nonserial dynamic programming algorithms. We also present a general way of combining conditioning and elimination within this framework. Bounds on complexity are given for all the aigorithms as a function of the problem's structure.

#index 1650779
#* Topological parameters for time-space tradeoff
#@ Rina Dechter
#t 1996
#c 12
#% 1145
#% 1675
#% 2028
#% 6199
#% 31482
#% 34262
#% 36814
#% 44876
#% 55926
#% 68183
#% 101510
#% 1650628
#% 1650639
#% 1650778
#% 1650782
#! In this paper we propose a family of algorithms combining tree-clustering with conditioning that trade space for time. Such algorithms are useful for reasoning in probabilistic and deterministic networks as well as for accomplishing optimization tasks. By analyzing the problem structure it will be possible to select from a spectrum the algorithm that best meets a given time-space specification.

#index 1650780
#* Sound abstraction of probabilistic actions in the constraint mass assignment framework
#@ AnHai Doan;Peter Haddawy
#t 1996
#c 12
#% 179939
#% 179955
#% 1477094
#% 1478679
#% 1650653
#% 1650787
#! This paper provides a formal and practical framework for sound abstraction of probabilistic actions. We start by precisely defining the concept of sound abstraction within the context of finite-horizon planning (where each plan is a finite sequence of actions). Next we show that such abstraction cannot be performed within the traditional probabilistic action representation, which models a world with a single probability distribution over the state space. We then present the constraint mass assignment representation, which models the world with a set of probability distributions and is a generalization of mass assignment representations. Within this framework, we present sound abstraction procedures for three types of action abstraction. We end the paper with discussions and related work on sound and approximate abstraction. We give pointers to papers in which we discuss other sound abstraction-related issues, including applications, estimating loss due to abstraction, and automatically generating abstraction hierarchies.

#index 1650781
#* Belief revision with uncertain inputs in the possibilistic setting
#@ Didier Dubois;Henri Prade
#t 1996
#c 12
#% 111942
#% 119167
#% 167544
#% 555519
#% 566739
#% 780340
#% 781173
#% 1273433
#% 1273609
#% 1273623
#% 1273626
#% 1290097
#% 1290145
#% 1478690
#! This paper discusses belief revision under uncertain inputs in the framework of possibility theory. Revision can be based on two possible definitions of the conditioning operation, one based on min operator which requires a purely ordinal scale only, and another based on product, for which a richer structure is needed, and which is a particular case of Dempster's rule of conditioning. Besides, revision under uncertain inputs can be understood in two different ways depending on whether the input is viewed, or not, as a constraint to enforce. Moreover, it is shown that M.A. Williams' transmutations, originally defined in the setting of Spohn's functions, can be captured in this framework, as well as Boutilier's natural revision.

#index 1650782
#* An evaluation of structural parameters for probabilistic reasoning: results on benchmark circuits
#@ Yousri El Fattah;Rina Dechter
#t 1996
#c 12
#% 1145
#% 1675
#% 6199
#% 31482
#% 34262
#% 44876
#% 55926
#% 68183
#% 172500
#% 408680
#% 1275464
#% 1290122
#% 1650779
#! Many algorithms for processing probabilistic networks are dependent on the topological properties of the problem's structure. Such algorithms (e.g., clustering, conditioning) are effective only if the problem has a sparse graph captured by parameters such as tree width and cycle-outset size. In this paper we initiate a study to determine the potential of structure-based algorithms in real-life applications. We analyze empirically the structural properties of problems coming from the circuit diagnosis domain. Specifically, we locate those properties that capture the effectiveness of clustering and conditioning as well as of a family of conditioning+clustering algorithms designed to gradually trade space for time. We perform our analysis on 11 benchmark circuits widely used in the testing community. We also report on the effect of ordering heuristics on tree-clustering and show that, on our benchmarks, the wellknown max-cardinality ordering is substantially inferior to an ordering called raindegree.

#index 1650783
#* Learning Bayesian networks with local structure
#@ Nir Friedman;Moises Goldszmidt
#t 1996
#c 12
#% 44876
#% 61792
#% 101213
#% 115608
#% 129987
#% 130878
#% 136350
#% 156181
#% 197387
#% 201410
#% 369349
#% 1650767
#% 1650785
#! In this paper we examine a novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks. Our approach explicitly represents and learns the local structure in the conditional probability tables (CPTs), that quantify these networks. This increases the space of possible models, enabling the representation of CPTs with a variable number of parameters that depends on the learned local structures. The resulting learning procedure is capable of inducing models that better emulate the real complexity of the interactions present in the data. We describe the theoretical foundations and practical aspects of learning local structures, as well as an empirical evaluation of the proposed method. This evaluation indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure. Our results also show that networks learned with local structure tend to be more complex (in terms of arcs), yet require less parameters.

#index 1650784
#* A qualitative Markov assumption and its implications for belief change
#@ Nir Friedman;Joseph Y. Halpern
#t 1996
#c 12
#% 74868
#% 75936
#% 77841
#% 100178
#% 146906
#% 396114
#% 781175
#% 1290096
#% 1290098
#% 1476313
#% 1477300
#% 1650645
#% 1650648
#! The study of belief change has been an active area in philosophy and AI. In recent years, two special cases of belief change, belief revision and belief update, have been studied in detail. Roughly speaking, revision treats a surprising observation as a sign that previous beliefs were wrong, while update treats a surprising observation as an indication that the world has changed. In general, we would expect that an agent making an observation may both want to revise some earlier beliefs and assume that some change has occurred in the world. We define a novel approach to belief change that allows us to do this, by applying ideas from probability theory in a qualitative settings. The key idea is to use a qualitative Markov assumption, which says that state transitions are independent. We show that a recent approach to modeling qualitative uncertainty using plausibility measures allows us to make such a qualitative Markov assumption in a relatively straightforward way, and show how the Markov assumption can be used to provide an attractive belief-change model.

#index 1650785
#* On the sample complexity of learning Bayesian networks
#@ Nir Friedman;Zohar Yakhini
#t 1996
#c 12
#% 44876
#% 115608
#% 129987
#% 151222
#% 197387
#% 369349
#% 1650783
#! In recent years there has been an increasing interest in learning Bayesian networks from data. One of the most effective methods for learning such networks is based on the minimum description length (MDL) principle. Previous work has shown that this learning procedure is asymptotically successful: with probability one, it will converge to the target distribution, given a sufficient number of samples. However, the rate of this convergence has been hitherto unknown. In this work we examine the sample complexity of MDL based learning procedures for Bayesian networks. We show that the number of samples needed to learn an ε-close approximation (in terms of entropy distance) with confidence δ is O ((1/ε)4/3 log 1/ε log 1/δ log log 1/δ). This means that the sample complexity is a low-order polynomial in the error threshold and sub-linear in the confidence bound. We also discuss how the constants in this term depend on the complexity of the target distribution. Finally, we address questions of asymptotic minimality and propose a method for using the sample complexity results to speed up the learning process.

#index 1650786
#* Asymptotic model selection for directed networks with hidden variables*
#@ Dan Geiger;David Heckerman;Christopher Meek
#t 1996
#c 12
#% 129497
#% 129987
#% 130878
#% 197387
#% 232117
#% 1272279
#% 1272363
#% 1650650
#% 1650659
#% 1650772
#! We extend the Bayesian Information Criterion (BIC), an asymptotic approximation for tile marginal likelihood, to Bayesian networks with hidden variables. This approximation can be used to select models given large sampies of data. Tile standard BIC as well as our extension punishes the complexity of a model according to tile dimension of its parameters. We argue that the dimension of a Bayesian uetwork with hidden variables is tile rank of the Jacobian matrix of the transformation between the parameters of the network and the parameters of the observable variables. We compute the dimensions of several networks including the naive Bayes model with a hidden root node.

#index 1650787
#* Theoretical foundations for abstraction-based probabilistic planning
#@ Vu Ha;Peter Haddawy
#t 1996
#c 12
#% 124580
#% 179939
#% 1477094
#% 1478679
#% 1650653
#% 1650780
#! Modeling worlds and actions under uncertainty is one of the central problems in the framework of decision-theoretic planning. The representation must be general enough to capture real-world problems but at the same time it must provide a basis upon which theoretical results can be derived. The central notion in the framework we propose here is that of the affine-operator, which serves as a tool for constructing (convex) sets of probability distributions, and which can be considered as a generalization of belief functions and interval mass assignments. Uncertainty in the state of the worlds is modeled with sets of probability distributions, represented by affine-trees, while actions are defined as tree-manipulators. A small set of key properties of the affine-operator is presented, forming the basis for most existing operator-based definitions of probabilistie action projection and action abstraction. We derive and prove correct three projection rules, which vividly illustrate the precision-complexity tradeoff in plan projection. Finally, we show how the three types of action abstraction identified by Haddawy and Doan are manifested in the present framework.

#index 1650788
#* Defining relative likelihood in partially-ordered preferential structures
#@ Joseph Y. Halpern
#t 1996
#c 12
#% 21146
#% 74868
#% 77841
#% 163720
#% 499542
#% 503190
#% 1279727
#% 1476313
#! Starting with a likelihood or preference order on worlds, we extend it to a likelihood ordering on sets of worlds in a natural way, and examine the resulting logic. Lewis [1973] earlier considered such a notion of relative likelihood in the context of studying counterfactuals, but he assumed a total preference order on worlds. Complications arise when examining partial orders that are not present for total orders. There are subtleties involving the exact approach to lifting the order on worlds to an order on sets of worlds. In addition, the axiomatization of the logic of relative likelihood in the case of partial orders gives insight into the connection between relative likelihood and default reasoning.

#index 1650789
#* Why is diagnosis using belief networks insensitive to imprecision in probabilities?
#@ Max Henrion;Malcolm Pradhan;Brendan Del Favero;Gregory Provan;Paul O'Rorke
#t 1996
#c 12
#% 128627
#% 217078
#% 455903
#! Recent research has found that diagnostic performance with Bayesian belief networks is often surprisingly insensitive to imprecision in the numerical probabilities. For example, the authors have recently completed an extensive study in which they applied random noise to the numerical probabilities in a set of belief networks for medical diagnosis, subsets of the CPCS network, a subset of the QMR (Quick Medical Reference) focused on liver and bile diseases. The diagnostic performance in terms of the average probabilities assigned to the actual diseases showed small sensitivity even to large amounts of noise. In this paper, we summarize the findings of this study and discuss possible explanations of this low sensitivity. One reason is that the criterion for performance is average probability of the true hypotheses, rather than average error in probability, which is insensitive to symmetric noise distributions. But, we show that even asymmetric, Iogodds-normal noise has modest effects, A second reason is that the gold-standard posterior probabilities are often near zero or one, and are little disturbed by noise.

#index 1650790
#* Flexible policy construction by information refinement
#@ Michael C. Horsch;David Poole
#t 1996
#c 12
#% 34262
#% 44876
#% 68244
#% 98073
#% 130135
#% 138515
#% 449588
#! We report on work towards flexible algorithms for solving decision problems represented as influence diagrams. An algorithm is given to construct a tree structure for each decision node in an influence diagram. Each tree represents a decision function and is constructed incrementally. The improvements to the tree converge to the optimal decision function (neglecting computational costs) and the asymptotic behaviour is only a constant factor worse than dynamic programming techniques, counting the number of Bayesian network queries. Empirical results show how expected utility increases with the size of the tree and the number of Bayesian net calculations.

#index 1650791
#* Efficient search-based inference for noisy-OR belief networks: topepsilon
#@ Kurt Huang;Max Henrion
#t 1996
#c 12
#% 21142
#% 68244
#% 101224
#% 144664
#% 217078
#% 527688
#! Inference algorithms for arbitrary belief networks are impractical for large, complex belief networks. Inference algorithms for specialized classes of belief networks have been shown to be more efficient. In this paper, we present a search-based algorithm for approximate inference on arbitrary, noisy-OR belief networks, generalizing earlier work on search-based inference for two-level, noisy-OR belief networks. Initial experimental results appear promising.

#index 1650792
#* A probabilistic model for sensor validation
#@ P. H. Ibargüengoytla;L. E. Sucar;S. Vadera
#t 1996
#c 12
#% 39859
#% 44876
#% 74813
#! The validation of data from sensors has become an important issue in the operation and control of modern industrial plants. One approach is to use knowledge based techniques to detect inconsistencies in measured data. This article presents a probabilistic model for the detection of such inconsistencies. Based on probability propagation, this method is able to find the existence of a possible fault among the set of sensors. That is, if an error exists, many sensors present an apparent fault due to the propagation from the sensor(s) with a real fault. So the fault detection rueehanism can only tell if a sensor has a potential fault, but it can not tell if the fault is real or apparent. So the central problem is to develop a theory, and then an algorithm, for distinguishing real and apparent faults, given that one or more sensors can fail at the same time. This article then, presents an approach based on two levels: (i) probabilistic reasoning, to detect a potential fault, and (ii) constraint management, to distinguish the real fault from the apparent ones. The proposed approach is exemplified by applying it to a power plant model.

#index 1650793
#* Computing upper and lower bounds on likelihoods in intractable networks
#@ Tommi S. Jaakkola;Michael I. Jordan
#t 1996
#c 12
#% 44876
#% 130878
#% 136358
#% 191855
#% 527688
#% 1272279
#! We present deterministic techniques for computing upper and lower bounds on marginal probabilities in sigmoid and noisy-OR networks. These techniques become useful when the size of the network (or clique size) precludes exact computations. We illustrate the tightness of the bounds by numerical experiments.

#index 1650794
#* MIDAS - an influence diagram for management of mildew in winter wheat
#@ Allan Leck Jensen;Finn Verner Jensen
#t 1996
#c 12
#% 119308
#% 130135
#! We present a prototype of a decision support system for management of the fungal disease powdery mildew in winter wheat. The prototype is based on an influence diagram which is used to determine the optimal time and dose of mildew treatments. This involves multiple decision opportunities over time, stochasticity, inaccurate information and incomplete knowledge. The paper describes the practical and theoretical problems encountered during the construction of the influence diagram, and also the experience with the prototype.

#index 1650795
#* Computational complexity reduction for BN2O networks using similarity of states
#@ Alexander V. Kozlov;Jaswinder Pal Singh
#t 1996
#c 12
#% 44876
#% 68244
#% 101224
#% 136358
#% 527688
#% 1650670
#! Although probabilistic inference in a general Bayesian belief network is an NP-hard problem, computation time for inference can be reduced in most practical cases by exploiting domain knowledge and by making approximations in the knowledge representation. In this paper we introduce the property of similarity of states and a new method for approximate knowledge representation and inference which is based on this property. We define two or more states of a node to be similar when the ratio of their probabilities, the likelihood ratio, does not depend on the instantiations of the other nodes in the network. We show that the similarity of states exposes redundancies in the joint probability distribution which can be exploited to reduce the computation time of probabilistic inference in networks with multiple similar states, and that the computational complexity in the networks with exponentially many similar states might be polynomial. We demonstrate our ideas on the example of a BN20 network--a two layer network often used in diagnostic problems--by reducing it to a very close network with mnltiple similar states. We show that the answers to practical queries converge very fast to the answers obtained with the original network. The maximum error is as low as 5% for models that reqnire only 10% of the computation time needed by the original BN20 model.

#index 1650796
#* Uncertain inferences and uncertain conclusions
#@ Henry E. Kyburg, Jr.
#t 1996
#c 12
#% 20853
#% 161238
#! Uncertainty may be taken to characterize inferences, their conclusions, their premises or all three. Under some treatments of uncertainty, the inference itself is never characterized by uncertainty. We explore both the significance of uncertainty in the premises and in the conclusion of an argument that involves uncertainty. We argue that for uncertainty to characterize the conclusion of an inference is natural, but that there is an interplay between uncertainty in the premises and uncertainty in the procedure of argument itself. We show that it is possible in principle to incorporate all uncertainty in the premises, rendering uncertainty arguments deductively valid. But we then argue (1) that this does not reflect human argument, (2) that it is computationally costly, and (3) that the gain in simplicity obtained by allowing uncertainty in inference can sometimes outweigh the loss of flexibility it entails.

#index 1650797
#* Bayesian learning of loglinear models for neural connectivity
#@ Kathryn Blackmond Laskey;Laura Martignon
#t 1996
#c 12
#% 92142
#% 92146
#% 129987
#! This paper presents a Bayesian approach to learning the connectivity structure of a group of neurons from data on configuration frequencies. A major objective of the research is to provide statistical tools for detecting changes in firing patterns with changing stimuli. Our framework is not restricted to the well-understood case of pair interactions, but generalizes the Boltzmann machine model to allow for higher order interactions. The paper applies a Markov Chain Monte Carlo Model Composition (MC3) algorithm to search over connectivity structures and uses Laplace's method to approximate posterior probabilities of structures. Performance of the methods was tested on synthetic data. The models were also applied to data obtained by Vaadia on multiunit recordings of several neurons in the visual cortex of a rhesus monkey in two different attentional states. Results confirmed the experimenters' conjecture that different attentional states were associated with different interaction structures.

#index 1650798
#* Generalized qualitative probability: savage revisited
#@ Daniel Lehmann
#t 1996
#c 12
#! Preferences among acts are analyzed in the style of L. Savage, but as partially ordered. The rationality postulates considered are weaker than Savage's on three counts. The Sure Thing Principle is derived in this setting. The postulates are shown to lead to a characterization of generalized qualitative probability that includes and blends both traditional qualitative probability and the ranked structures used in logical approaches.

#index 1650799
#* Network engineering for complex belief networks
#@ Suzanne M. Mahoney;Kathryn B. Laskey
#t 1996
#c 12
#% 158
#% 39317
#% 44876
#% 72378
#% 101221
#% 115083
#% 116366
#% 128428
#% 130164
#% 174250
#% 527832
#% 646907
#% 696946
#% 1650680
#! Developing a large belief network, like any large system, requires systems engineering to manage the design and construction process. We propose that network engineering follow a rapid prototyping approach to network construction. We describe criteria for identifying network modules and the use of 'stubs' within a belief network. We propose an object oriented representation for belief networks which captures the semantic as well as representational knowledge embedded in the vaziables, their values and their parameters. Methods for evaluating complex networks are described. Throughout the discussion, tools which support the engineering of large belief networks are identified.

#index 1650800
#* Probabilistic disjunctive logic programming
#@ Liem Ngo
#t 1996
#c 12
#% 3034
#% 114723
#% 144840
#% 146275
#% 147677
#% 442830
#% 556918
#% 1272359
#% 1290138
#! In this paper we propose a framework for combining Disjunctive Logic Programming and Poole's Probabilistic Horn Abduction. We use the concept of hypothesis to specify the probability structure. We consider the case in which probabilistic information is not available. Instead of using probability intervals, we allow for the specification of the probabilities of disjunctions. Because minimal models are used as characteristic models in disjunctive logic programming, we apply the principle of indifference on the set of minimal models to derive default probability values. We define the concepts of explanation and partial explanation of a formula, and use them to determine the default probability distribution(s) induced by a program. An algorithm for calculating the default probability of a goal is presented.

#index 1650801
#* Toward a market model for Bayesian inference
#@ David M. Pennock;Michael P. Wellman
#t 1996
#c 12
#% 67866
#% 191271
#% 1268730
#! We present a methodology for representing probabilistic relationships in a general-equilibrium economic model. Specifically, we define a precise mapping from a Bayesian network with binary nodes to a market price system where consumers and producers trade in uncertain propositions. We demonstrate the correspondence between the equilibrium prices of goods in this economy and the probabilities represented by the Bayesian network. A computational market model such as this may provide a useful framework for investigations of belief aggregation, distributed probabilistic inference, resource allocation under uncertainty, and other problems of decentralized uncertainty.

#index 1650802
#* Geometric implications of the naive Bayes assumption
#@ Mark A. Peot
#t 1996
#c 12
#% 67988
#% 147630
#! A Naive (or Idiot) Bayes network is a network with a single hypothesis node and several observations that are conditionally independent given the hypothesis. We recently surveyed a number of members of the UAI community and discovered a general lack of understanding of the implications of the Naive Bayes assumption on the kinds of problems that can be solved by these networks. It has long been recognized [Minsky 61] that if observations are binary, the decision surfaces in these networks are hyperptanes. We extend this result (hyperplane separability) to Naive Bayes networks with m-ary observations. In addition, we illustrate the effect of observation-observation dependencies on decision surfaces. Finally, we discuss the implications of these results on knowledge acquisition and research in learning.

#index 1650803
#* Identifying independencies in causal graphs with feedback
#@ Judea Pearl;Rina Dechter
#t 1996
#c 12
#% 44876
#% 69087
#% 527514
#% 1650657
#% 1650677
#! We show that the d-separation criterion constitutes a valid test for conditional independence relationships that are induced by feedback systems involving discrete variables.

#index 1650804
#* A graph-theoretic analysis of information value
#@ Kim Leng Poh;Eric Horvitz
#t 1996
#c 12
#% 233
#% 31874
#% 44876
#% 45840
#% 101223
#% 101510
#% 107414
#% 110379
#% 128614
#% 130095
#% 218443
#% 527848
#% 527850
#% 688672
#% 1010743
#% 1272178
#% 1273446
#% 1650633
#% 1650642
#% 1650653
#% 1650659
#! We derive qualitative relationships about the informational relevance of variables in graphical decision models based on a consideration of the topology of the models. Specifically, we identify dominance relations for the expected value of information on chance variables in terms of their position and relationships in influence diagrams. The qualitative relationships can be harnessed to generate nonnumerical procedures for ordering uncertain variables in a decision model by their informational relevance.

#index 1650805
#* A framework for decision-theoretic planning I: combining the situation calculus, conditional plans, probability and utility
#@ David Poole
#t 1996
#c 12
#% 75936
#% 90371
#% 117869
#% 147677
#% 179939
#% 194652
#% 374912
#% 646959
#% 1275246
#% 1275454
#% 1290040
#% 1290041
#% 1290146
#% 1476290
#% 1476294
#% 1478679
#% 1650653
#! This paper shows how we can combine logical representations of actions and decision theory in such a manner that seems natural for both. In partitular we assume an axiomatization of the domain in terms of situation calculus, using what is essentially Reiter's solution to the frame problem, in terms of the completion of the axioms defining the state change. Uncertainty is handled in terms of the independent choice logic, which allows for independent choices and a logic program that gives the consequences of the choices. As part of the consequences are a specification of the utility of (final) states. The robot adopts robot plans, similar to the GOLOG programming language. Within this logic, we can define the expected utility of a conditional plan, based on the axiomadzation of the actions, the uncertainty and the utility. The 'planning' problem is to find the plan with the highest expected utility. This is related to recent structured representations for POMDPs; here we use stochastic situation calculus rules to specify the state transition function and the reward/value function. Finally we show that with stochastic frame axioms, actions representations in probabilistic STRIPS are exponentially larger than using the representation proposed here.

#index 1650806
#* Optimal Monte Carlo estimation of belief network inference
#@ Malcolm Pradhan;Paul Dagum
#t 1996
#c 12
#% 21142
#% 58608
#% 68244
#% 89959
#% 101224
#% 136358
#% 144664
#% 231738
#% 443635
#% 527664
#% 527691
#% 593740
#% 1650662
#! We present two Monte Carlo sampling algorithms for probabilistic inference that guarantee polynomial-time convergence for a larger class of network than current sampling algorithms provide. These new methods are variants of the known likelihood weighting algorithm. We use of recent advances in the theory of optimal stopping rules for Monte Carlo simulation to obtain an inference approximation with relative error ε and a small failure probability δ. We present an empirical evaluation of the algorithms which demonstrates their improved performance.

#index 1650807
#* A discovery algorithm for directed cyclic graphs
#@ Thomas Richardson
#t 1996
#c 12
#% 44876
#% 1650683
#! Directed acyclic graphs have been used fruitfully to represent causal structures (Pearl 1988). However, in the social sciences and elsewhere models are often used which correspond both causally and statistically to directed graphs with directed cycles (Spirtes 1995). Pearl (1993) discussed predicting the effects of intervention in models of this kind, so-called linear nonrecursive structural equation models. This raises the question of whether it is possible to make inferences about causal structure with cycles, from sample data. In particular do there exist general, informative, feasible and reliable procedures for inferring causal structure from conditional independence relations among variables in a sample generated by an unknown causal structure? In this paper I present a discovery algorithm that is correct in the large sample limit, given commonly (but often implicitly) made plausible assumptions, and which provides information about the existence or non-existence of causal pathways from one variable to another. The algorithm is polynomial on sparse graphs.

#index 1650808
#* A polynomial-time algorithm for deciding Markov equivalence of directed cyclic graphical models
#@ Thomas Richardson
#t 1996
#c 12
#% 44876
#% 88134
#% 408638
#% 1650683
#! Although the concept of d-separation was originally defined for directed acyclic graphs (see Pearl 1988), there is a natural extension of the concept to directed cyclic graphs. When exactly the same set of d-separation relations hold in two directed graphs, no matter whether respectively cyclic or acyclic, we say that they are Markov equivalent. In other words, when two directed cyclic graphs are Markov equivalent, the set of distributions that satisfy a natural extension of the Global Directed Markov Condition (Lauritzen et al. 1990) is exactly the same for each graph. There is an obvious exponential (in the number of vertices) time algorithm for deciding Markov equivalence of two directed cyclic graphs; simply check all of the d-separation relations in each graph. In this paper I state a theorem that gives necessary and sufficient conditions for the Markov equivalence of two directed cyclic graphs, where each of the conditions can be checked in polynomial time. Hence, the theorem can be easily adapted into a polynomial time algorithm for deciding the Markov equivalence of two directed cyclic graphs. Although space prohibits inclusion of correctness proofs, they are fully described in Richardson (1994b).

#index 1650809
#* Coherent knowledge processing at maximum entropy by spirit
#@ Wilhelm Rödder;Carl-Heinz Meyer
#t 1996
#c 12
#% 451
#% 3034
#% 44876
#% 67866
#% 73239
#% 403535
#% 1272947
#! SPIRIT is an expert system shell for probabilistic knowledge bases. Knowledge acquisition is performed by processing facts and rules on discrete variables in a rich syntax. The shell generates a probability distribution which respects all acquired facts and rules and which maximizes entropy. The user-friendly devices of SPIRIT to define variables, formulate rules and create the knowledge base are revealed in detail. Inductive learning is possible. Medium sized applications show the power of the system.

#index 1650810
#* Sample-and-accumulate algorithms for belief updating in Bayes networks
#@ Eugene Santos, Jr.;Solomon Eyal Shimony;Edward Williams
#t 1996
#c 12
#% 44876
#% 68244
#% 136358
#% 147677
#% 172544
#% 369236
#% 443635
#% 466054
#! Belief updating in Bayes nets, a well known computationally hard problem, has recently been approximated by several deterministic algorithms, and by various randomized approximation algorithlns. Deterministic algorithms usually provide probability bounds, but have an exponential runtime. Some randomized schemes have, a polynomial runtime, but provide only probability estimates. We present randomized algorithms that enumerate high-probability partial instantiations, resulting in probability bounds. Some of these algorithms are also sampling algorithms. Specifically, we introduce and evalu ate a variant of backward sampling, both as a sampling algorithm and as a randomized enumeration algorithm. We also relax the implicit assumption used by both sampling and accumulation algorithms, that query nodes must be instantiated in all the samples.

#index 1650811
#* A measure of decision flexibility
#@ Ross D. Shachter;Marvin Mandelbaum
#t 1996
#c 12
#% 110379
#% 1650637
#! We propose a decision-analytical approach to comparing the flexibility of decision sitnations from the perspective of a decisionmaker who exhibits constant risk-aversion over a monetary value model. Our approach is simple yet seems to be consistent with a variety of flexibility concepts, including robust and adaptive alternatives. We try to compensate within the model for uncertainty that was not anticipated or not modeled. This approach not only allows one to compare the flexibility of plans, but also guides the search for new, more flexible alternatives.

#index 1650812
#* Binary join trees
#@ Prakash P. Shenoy
#t 1996
#c 12
#% 6199
#% 31482
#% 61895
#% 74853
#% 101262
#% 119147
#% 168323
#% 289424
#% 408680
#% 527844
#% 836134
#% 1650642
#! The main goal of this paper is to describe a data structure called binary join trees that are useful in computing multiple marginals efficiently using the Shenoy-Shafer architecture. We define binary join trees, describe their utility, and sketch a procedure for constructing them.

#index 1650813
#* Efficient enumeration of instantiations in Bayesian networks
#@ Sampath Srinivas;Pandurang Nayak
#t 1996
#c 12
#% 24547
#% 42214
#% 44876
#% 125529
#% 406437
#% 527672
#% 1273478
#% 1477222
#% 1477272
#% 1477378
#% 1478546
#% 1478710
#! Over the past several years Bayesian networks have been applied to a wide variety of problems. A central problem in applying Bayesian networks is that of finding one or more of the most probable instantiations of a network. In this paper we develop an efficient algorithm that incrementally enumerates the instantiations of a Bayesian network in decreasing order of probability. Such enumeration algorithms are applicable in a variety of applications ranging from medical expert systems to model-based diagnosis. Fundamentally, our algorithm is simply performing a lazy enumeration of the sorted list of all instantiations of the network. This insight leads to a very concise algorithm statement which is both easily understood and implemented. We show that for singly connected networks, our algorithm generates the next instantiation in time polynomial in the size of the network. The algorithm extends to arbitrary Bayesian networks using standard conditioning techniques. We empirically evaluate the enumeration algorithm and demonstrate its practicality.

#index 1650814
#* On separation criterion and recovery algorithm for chain graphs
#@ Milan Studeny
#t 1996
#c 12
#% 44876
#% 130153
#% 503662
#% 527514
#% 527523
#% 527830
#% 1650633
#% 1650673
#! Chain graphs (CGs) give a natural unifying point of view on Markov and Bayesian networks and enlarge the potential of graphical models for description of conditional independence structures. In the paper a direct graphical separation criterion for CGs which generalizes the d-separation criterion for Bayesian networks is introduced (recalled). It is equivalent to the classic moralization criterion for CGs and complete in the sense that for every CG there exists a probability distribution satisfying exactly independencies derivable from the CG by the separation criterion. Every class of Markov equivalent CGs can be uniquely described by a natural representative, called the largest CG. A recovery algorithm, which on basis of the (conditional) dependency model given by a CG finds the corresponding largest CG, is presented.

#index 1650815
#* Possible world partition sequences: a unifying framework for uncertain reasoning
#@ Choh Man Teng
#t 1996
#c 12
#% 1146
#% 36236
#% 39263
#% 56081
#% 100178
#% 167544
#! When we work with information from multiple sources, the formalism each employs to handle uncertainty may not be uniform. In order to be able to combine these knowledge bases of different formats, we need to first establish a common basis for characterizing and evaluating the different formalisms, and provide a semantics for the combined mechanism. A common framework can provide an infrastructure for building an integrated system, and is essential if we are to understand its behavior. We present a unifying framework based on an ordered partition of possible worlds called partition sequences, which corresponds to our intuitive notion of biasing towards certain possible scenarios when we are uncertain of the actual situation. We show that some of the existing formalisms, namely, default logic, autoepistemic logic, probabilistic conditioning and thresholding (generalized conditioning), and possibility theory can be incorporated into this general framework.

#index 1650816
#* Supply restoration in power distribution systems: a case study in integrating model-based diagnosis and repair planning
#@ Sylvie Thiébaux;Marie-Odile Cordier;Olivier Jehl;Jean-Paul Krivine
#t 1996
#c 12
#% 179940
#% 179955
#% 179957
#% 1478679
#! Integrating diagnosis and repair is particularly crucial when gaining sufficient information to discriminate between several candidate diagnoses requires carrying out some repair actions. A typical case is supply restoration in a faulty power distribution system. This problem, which is a major concern for electricity distributors, features partial observability, and stochastic repair actions which axe more elaborate than simple replacement of components. This paper analyses the difficulties in applying existing work on integrating model-based diagnosis and repair and on planning in partially observable stochastic domains to this real-world problem, and describes the pragmatic approach we have retained so far.

#index 1650817
#* Real time estimation of Bayesian networks
#@ Robert L. Welch
#t 1996
#c 12
#% 68244
#% 136358
#% 174161
#% 369236
#% 374580
#% 527664
#% 527691
#! For real time evaluation of a Bayesian network when there is not sufficient time to obtain an exact solution, a guaranteed response time, approximate solution is required. It is shown that non traditional methods utilizing estimators based on an archive of trial solutions and genetic search can provide an approximate solution that is considerably superior to the traditional Monte Carlo simulation methods.

#index 1650818
#* Testing implication of probabilistic dependencies
#@ S. K. M. Wong
#t 1996
#c 12
#% 6199
#% 44876
#% 67866
#% 68244
#% 286995
#% 287336
#% 287478
#% 287754
#% 289337
#% 289424
#% 346917
#% 403535
#% 470340
#% 836006
#% 836134
#% 1650691
#! Axiomatization has been widely used for testing logical implications. This paper suggests a non-axiomatic method, the chase, to test if a new dependency follows from a given set of probabilistic dependencies. Although the chase computation may require exponential time in some cases, this technique is a powerful tool for establishing nontrivial theoretical results. More importantly, this approach provides valuable insight into the intriguing connection between relational databases and probabilistic reasoning systems.

#index 1650819
#* Optimal factory scheduling using stochastic dominance A
#@ Peter R. Wurman;Michael P. Wellman
#t 1996
#c 12
#% 102372
#% 168288
#% 319222
#% 388034
#% 1650688
#! We examine a standard factory scheduling problem with stochastic processing and setup times, minimizing the expectation of the weighted number of tardy jobs. Because the costs of operators in the schedule are stochastic and sequence dependent, standard dynamic programming algorithms such as A* may fail to find the optimal schedule. The SDA* (Stochastic Dominance A*) algorithm remedies this difficulty by relaxing the pruning condition. We present an improved state-space search formulation for these problems and discuss the conditions under which stochastic scheduling problems can be solved optimally using SDA*. In empirical testing on randomly generated problems, we found that in 70%, the expected cost of the optimal stochastic solution is lower than that of the solution derived using a deterministic approximation, with comparable search effort.

#index 1650820
#* Critical remarks on single link search in learning belief networks
#@ Y. Xiang;S. K. M. Wong;N. Cercone
#t 1996
#c 12
#% 6199
#% 44876
#% 73374
#% 109042
#% 129987
#% 197387
#% 527851
#% 1280019
#! In learning belief networks, the single link lookahead search is widely adopted to reduce the search space. We show that there exists a class of probabilistic domain models which displays a special pattern of dependency. We analyze the behavior of several learning algorithms using different scoring metrics such as the entropy, conditional independence, minireal description length and Bayesian metrics. We demonstrate that single link lookahead search procedures (employed in these algorithms) cannot learn these models correctly. Thus, when the underlying domain model actually belongs to this class, the use of a single link search procedure will result in learning of an incorrect model. This may lead to inference errors when the model is used. Our analysis suggests that if the prior knowledge about a domain does not rule out the possible existence of these models, a multilink lookahead search or other heuristics should be used for the learning process.

#index 1672977
#* Proceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence
#@ Uffe Kjærulff;Christopher Meek
#t 2002
#c 12

#index 1672978
#* New advances in inference by recursive conditioning
#@ David Allen;Adnan Darwiche
#t 2002
#c 12
#% 44876
#% 70756
#% 98188
#% 329486
#% 336874
#% 451125
#% 528328
#% 644201
#% 1279351
#% 1650602
#% 1650778
#! Recursive Conditioning (RC) was introduced recently as an any-space algorithm for inference in Bayesian networks which can trade time for space by varying the size of its cache at the increment needed to store a floating point number. Under full caching, RC has an asymptotic time and space complexity which is comparable to mainstream algorithms based on variable elimination and clustering (exponential in the network treewidth and linear in its size). We show two main results about RC in this paper. First, we show that its actual space requirements under full caching are much more modest than those needed by mainstream methods and study the implications of this finding. Second, we show that RC can effectively deal with determinism in Bayesian networks by employing standard logical techniques, such as unit resolution, allowing a significant reduction in its time requirements in certain cases. We illustrate our results using a number of benchmark networks, including the very challenging ones that arise in genetic linkage analysis.

#index 1672979
#* Web-based question answering: a decision-making perspective
#@ David Azari;Eric Horvitz;Susan Dumais;Eric Brill
#t 2002
#c 12
#% 272793
#% 330616
#% 340953
#% 397160
#% 815861
#% 854668
#% 1650705
#! We investigate the use of probabilistic models and cost-benefit analyses to guide the operation of a Web-based question-answering system. We first provide an overview of research on questionanswering systems. Then, we present details about AskMSR, a prototype question-answering system that synthesizes answers from the results of queries to a Web search engine. We describe Bayesian analyses of the quality of answers generated by the system and show how we can endow the system with the ability to make decisions about the nature and number of queries that should be issued, by considering the expected value and cost of submitting the queries. Finally, we review the results of a set of experiments.

#index 1672980
#* Value elimination: bayesian inference via backtracking search
#@ Fahiem Bacchus;Shannon Dalmao;Toniann Pitassi
#t 2002
#c 12
#% 34262
#% 68183
#% 98188
#% 216980
#% 288165
#% 289947
#% 327779
#% 329486
#% 336874
#% 420720
#% 529186
#% 534159
#% 593872
#% 723877
#% 1650767
#! We present Value Elimination, a new algorithm for Bayesian Inference. Given the same variable ordering information, Value Elimination can achieve performance that is within a constant factor of variable elimination or recursive conditioning, and on some problems it can perform exponentially better, irrespective of the variable ordering used by these algorithms. Value Elimination's other features include: (1) it can achieve the same space-time tradeoff guarantees as recursive conditioning; (2) it can utilize all of the logical reasoning techniques used in state of the art SAT solvers; these techniques allow it to obtain considerable extra mileage out of zero entries in the CPTs; (3) it can be naturally and easily extended to take advantage of context specific structure; and (4) it supports dynamic variable orderings which might be particularly advantageous in the presence of context specific structure. We have implemented a version of Value Elimination that demonstrates very promising performance, often being one or two orders of magnitude faster than a commercial Bayes inference engine, despite the fact that it does not as yet take advantage of context specific structure.

#index 1672981
#* A possibilistic handling of partially ordered information
#@ Salem Benferhat;Sylvain Lagrue;Odile Papini
#t 2002
#c 12
#% 3461
#% 144547
#% 167544
#% 470198
#% 1272312
#% 1273626
#% 1289348
#! In standard possibilistic logic, prioritized information are encoded by means of weighted knowledge bases. This paper proposes an extension of possibilistic logic to deal with partially ordered information which can be viewed as a family of possibilistic knowledge bases. We show that all basic notions of possibilistic logic have natural counterparts when dealing with partially ordered information. Furthermore, we propose an algorithm which computes plausible conclusions of a partially ordered knowledge base.

#index 1672982
#* An empirical study of w-cutset sampling for bayesian networks
#@ Bozhena Bidyuk;Rina Dechter
#t 2002
#c 12
#% 44876
#% 191986
#% 269190
#% 289947
#% 528169
#% 1389692
#% 1650271
#% 1650302
#% 1650669
#! The paper studies empirically the time-space trade-off between sampling and inference in the cutser sampling algorithm. The algorithm samples over a subset of nodes in a Bayesian network and applies exact inference over the rest. As the size of the sampling space decreases, requiring less samples for convergence, the time for generating each single sample increases. Algorithm w-cutset sampling selects a sampling set such that the induced-width of the network when the sampling set is observed is bounded by w, thus requiring inference whose complexity is exponentially bounded by w. In this paper, we investigate the performance of w-cutset sampling as a function of w. Our experiments over a range of randomly generated and real benchmarks, demonstrate the power of the cutset sampling idea and in particular show that an optimal balance between inference and sampling benefits substantially from restricting the cutset size, even at the cost of more complex inference.

#index 1672983
#* On triangulating dynamic graphical models
#@ Jeff A. Bilmes;Chris Bartels
#t 2002
#c 12
#% 128629
#% 477924
#% 541077
#% 716892
#% 1425503
#! This paper introduces improved methodology to triangulate dynamic graphical models and dynamic Bayesian networks (DBNs). In this approach, a standard DBN template can be modified so the repeating and unrolled graph section may dissect the original DBN time slice and may also span (and partially intersect) many such slices. We introduce the notion of a "boundary" which divides a graph into multi-slice partitions each of which has an interface, and define the "boundary algorithm", a method to find the best boundary (and corresponding interface) between partitions in such models. We prove that, after using this algorithm, the sizes of the best forwardand backward- interface (and also the corresponding fill-ins) are identical. The boundary algorithm allows for constrained elimination orders (and therefore graph triangulations) that are impossible using standard slice-by-slice constrained elimination. We describe the above using the Graphical Model ToolKit (GMTK)'s notion of dynamic graphical model, slightly generalizing standard DBN templates. We report triangulation results on hand-concocted graphs, novel speech recognition DBNs, and random graphs, and find that the boundary algorithm can significantly improve both tree width and graph weight.

#index 1672984
#* Bayesian hierarchical mixtures of experts
#@ Christopher M. Bishop;Markus Svenskn
#t 2002
#c 12
#% 169358
#% 277467
#% 361100
#% 424806
#% 450275
#! The Hierarchical Mixture of Experts (HME) is a well-known tree-structured model for regression and classification, based on soft probabilistic splits of the input space. In its original formulation its parameters are determined by maximum likelihood, which is prone to severe overfitting, including singularities in the likelihood function. Furthermore the maximum likelihood framework offers no natural metric for optimizing the complexity and structure of the tree. Previous attempts to provide a Bayesian treatment of the HME model have relied either on local Gaussian representations based on the Laplace approximation, or have modified the model so that it represents the joint distribution of both input and output variables, which can be wasteful of resources if the goal is prediction. In this paper we describe a fully Bayesian treatment of the original HME model based on variational inference. By combining 'local' and 'global' variational methods we obtain a rigorous lower bound on the marginal probability of the data under the model. This bound is optimized during the training phase, and its resulting value can be used for model order selection. We present results using this approach for data sets describing robot arm kinematics.

#index 1672985
#* Parametric dependability analysis through probabilistic Horn abduction
#@ Andrea Bobbio;Stefania Montani;Luigi Portinale
#t 2002
#c 12
#% 101241
#% 147677
#% 171477
#% 452902
#% 482909
#% 515976
#% 1650327
#! Dependability modeling and evaluation is aimed at investigating that a system performs its function correctly in time. A usual way to achieve a high reliability is to design redundant systems that contain several replicas of the same subsystem. In order to provide compactness in system representation, parametric system modeling has been investigated in the jterature: a set of replicas of a given subsystem is parameterized so that only one representative instance is explicitly included in the model. While modeling aspects can be suitably addressed by these approaches, analytical tools working on parametric characterizations are often more difficult to be defined; the standard approach consists in "unfolding" the parametric model, in order to exploit standard analysis algorithms working at the unfolded "ground" level. In the present paper we consider the formalism of Parametric Fault Tree (PFT) and we show how it can be related to Probabilistic Horn Abduction (PHA). Since PHA is a framework where both modeling and analysis can be performed in a restricted firstorder language, we aim at showing that the conversion of a PFT into a PHA theory allows for an approach to dependability analysis directly exploiting parametric representation. We will show that classical qualitative and quantitative dependability measures can be characterized within PHA; this makes the PHA framework a candidate for PFT analysis, where also posterior probability computation (often neglected in standard Fault Tree analysis) can be naturally performed. A simple example of a multi-processor system with several replicated units is used to illustrate the approach.

#index 1672986
#* Upgrading ambiguous signs in QPNs
#@ Janneke H. Bolt;Silja Renooij;Linda C. van der Gaag
#t 2002
#c 12
#% 89748
#% 1478675
#% 1650328
#% 1650395
#% 1650644
#! A qualitative probabilistic network models the probabilistic relationships between its variables by means of signs. Nonmonotonic influences have associated an ambiguous sign. These ambiguous signs typically give rise to uninformative results upon inference. We argue that a non-monotonic influence can be associated with a more informative sign that indicates its effect in the current state of the network. To capture this effect, we introduce the concept of situational sign. Furthermore, if the network converts to a state in which all variables that provoke the nonmonotonicity have been observed, a nonmonotonic influence reduces to a monotonic one. We study the persistence and propagation of situational signs upon inference and give a method for establishing the sign of a reduced influence.

#index 1672987
#* On revising fuzzy belief bases
#@ Richard Booth;Eva Richter
#t 2002
#c 12
#% 167544
#% 175356
#% 341725
#% 351545
#% 1289348
#% 1650654
#! We look at the problem of revising fuzzy belief bases, i.e., belief base revision in which both formulas in the base as well as revisioninput formulas can come attached with varying truth-degrees. Working within a very general framework for fuzzy logic which is able to capture certain types of uncertainty calculi as well as truth-functional fuzzy logics, we show how the idea of rational change from "crisp" base revision, as embodied by the idea of partial meet (base) revision, can be faithfully extended to revising fuzzy belief bases. We present and axiomatise an operation of partial meet fuzzy base revision and illustrate how the operation works in several important special instances of the framework.

#index 1672988
#* Cooperative negotiation in autonomic systems using incremental utility elicitation
#@ Craig Boutilier;Rajarshi Das;Jeffrey O. Kephart;Gerald Tesauro;William E. Walsh
#t 2002
#c 12
#% 261358
#% 423108
#% 452359
#% 528176
#% 529348
#% 578692
#% 1279257
#% 1650721
#! Decentralized resource allocation is a key problem for large-scale autonomic (or self-managing) computing systems. Motivated by a data center scenario, we explore efficient techniques for resolving resource conflicts via cooperative negotiation. Rather than computing in advance the functional dependence of each element's utility upon the amount of resource it receives, which could be prohibitively expensive, each element's utility is elicited incrementally. Such incremental utility elicitation strategies require the evaluation of only a small set of sampled utility function points, yet they find near-optimal allocations with respect to a minimax regret criterion. We describe preliminary computational experiments that illustrate the benefit of our approach.

#index 1672989
#* Active collaborative filtering
#@ Craig Boutilier;Richard S. Zemel;Benjamin Marlin
#t 2002
#c 12
#% 220711
#% 342767
#% 420515
#% 528156
#% 578692
#% 1272282
#% 1273828
#% 1650569
#! Collaborative filtering (CF) allows the preferences of multiple users to be pooled to make recommendations regarding unseen products. We consider in this paper the problem of online and interactive CF: given the current ratings associated with a user, what queries (new ratings) would most improve the quality of the recommendations made? We cast this in terms of expected value of information (EVOI); but the online computational cost of computing optimal queries is prohibitive. We show how ofline prototyping and computation of bounds on EVOI can be used to dramatically reduce the required online computation. The framework we develop is general, but we focus on derivations and empirical study in the specific case of the multiplecause vector quantization model.

#index 1672990
#* Reasoning about bayesian network classifiers
#@ Hei Chan;Adnan Darwiche
#t 2002
#c 12
#% 3873
#% 44876
#% 246832
#% 351595
#% 458648
#% 578736
#% 1478493
#! Bayesian network classifiers are used in many fields, and one common class of classifiers are naive Bayes classifiers. In this paper, we introduce an approach for reasoning about Bayesian network classifiers in which we explicitly convert them into Ordered Decision Diagrams (ODDS), which are then used to reason about the properties of these classifiers. Specifically, we present an algorithm for converting any naive Bayes classifier into an ODD, and we show theoretically and experimentally that this algorithm can give us an ODD that is tractable in size cvcn given an intractable number of instances. Since ODDS are tractable representations of classifiers, our algorithm allows us to efficiently test the equivalence of two naive Bayes classifiers and characterize discrepancies between them. We also show a number of additional results including a count of distinct classifiers that can be induced by changing some CPT in a naive Bayes classifier, and the range of allowable changes to a CPT which keeps the current classifier unchanged.

#index 1672991
#* Using the structure of d-connecting paths as a qualitative measure of the strength of dependence
#@ Sanjay Chaudhuri;Thomas Richardson
#t 2002
#c 12
#% 400980
#% 527523
#! Pearl's concept of a d-connecting path is one of the foundations of the modern t h e ory of graphical models: the absence of a d-connecting path in a DAG indicates that conditional independence will hold in any distribution factorizing according to that graph. In this paper we show that in singlyconnected Gaussian DAGs it is possible to use the form of a d-connecting path to obtain qualitative information about the strength of conditional dependence. More precisely, the squared partial correlations between two given variables, conditioned on different subsets may be partially ordered by examining the relationship between the d-connecting path and the set of variables conditioned upon.

#index 1672992
#* Large-sample learning of bayesian networks is NP-hard
#@ David Maxwell Chickering;Christopher Meek;David Heckerman
#t 2002
#c 12
#% 44876
#% 408396
#% 722900
#% 1272387
#% 1650281
#% 1650638
#! In this paper, we provide new complexity results for algorithms that learn discretevariable Bayesian networks from data. Our results apply whenever the learning algorithm uses a scoring criterion that favors the simplest model able to represent the generative distribution exactly. Our results therefore hold whenever the learning algorithm uses a consistent scoring criterion and is applied to a sufficiently large dataset. We show that identifying high-scoring structures is NP-hard, even when we are given an independence oracle, an inference oracle, and/or an information oracle. Our negative results also apply when learning discrete-variable Bayesian networks in which each node has at most k parents, for all k ≥ 3.

#index 1672993
#* Probabilistic models for joint clustering and time-warping of multidimensional curves
#@ Darya Chudova;Scott Gaffney;Padhraic Smyth
#t 2002
#c 12
#% 280416
#% 397631
#% 444047
#! In this paper we present a family of models and learning algorithms that can simultaneously align and cluster sets of multidimensional curves measured on a discrete time grid. Our approach is based on a generative mixture model that allows both local nonlinear time warping and global linear shifts of the observed curves in both time and measurement spaces relative to the mean curves within the clusters. The resulting model can be viewed as a form of Bayesian network with a special temporal structure. The Expectation-Maximization (EM) algorithm is used to simultaneously recover both the curve models for each cluster, and the most likely alignments and cluster membership for each curve. We evaluate the methodology on two real-world data sets, and show that the Bayesian network models provide systematic improvements in predictive power over more conventional clustering approaches.

#index 1672994
#* Updating with incomplete observations
#@ Gert de Cooman;Marco Zaffalon
#t 2002
#c 12
#% 17144
#% 44876
#% 137786
#% 212217
#% 319172
#% 1650368
#! Currently, there is renewed interest in the problem, raised by Shafer in 1985, of updating probabilities when observations are incomplete (or setvalued). This is a fundamental problem, and of articular interest for Bayesian networks. Recently, Griinwald and Halpern have shown that commonly used updating strategies fail here, except under very special assumptions. We propose a new rule for updating probabilities with incomplete observations. Our approach is deliberately conservative: we make no or weak assumptions about the so-called incompleteness mechanism that produces incomplete observations. We model our ignorance about this mechanism by a vacuous lower prevision, a tool from the theory of imprecise probabilities, and we derive a new updating rule using coherence arguments. In general, our rule produces lower posterior probabilities, as well as partially determinate decisions. This is a logical consequence of the ignorance about the incompleteness mechanism. We show how the new rule can properly address the apparent paradox in the 'Monty Hall' puzzle. In addition, we apply it to the classification of new evidence in Bayesian networks constructed using expert knowledge. We provide an exact algorithm for this task with linear-time complexity, also for multiply connected nets.

#index 1672995
#* On information regularization
#@ Adrian Corduneanu;Tommi Jaakkola
#t 2002
#c 12
#% 169757
#! We formulate a principle for classification with the knowledge of the marginal distribution over the data points (unlabeled data). The principle is cast in terms of Tikhonov style regularization where the regularization penalty articulates the way in which the marginal density should constrain otherwise unrestricted conditional distributions. Specifically, the regularization penalty penalizes any information introduced between the examples and labels beyond what is provided by the available labeled examples. The work extends (Szummer and Jaakkola, 2003) to multiple dimensions, providing a regularizer independent of the covering of the space used in the derivation. In addition we lay the learning theoretical framework for classification with information regularization and provide a sample complexity bound. We illustrate the regularization principle in practice by restricting the class of conditional distributions to be logistic regression models and constructing the regularization penalty from a finite set of unlabeled examples.

#index 1672996
#* Loopy belief propagation as a basis for communication in sensor networks
#@ Christopher Crick;Avi Pfeffer
#t 2002
#c 12
#% 44876
#% 336865
#% 402611
#% 578738
#% 1272308
#% 1848680
#! Sensor networks are an exciting new kind of computer system. Consisting of a large number of tiny, cheap computational devices physically distributed in an environment, they gather and process data about the environment in real time. One of the central questions in sensor networks is what to do with the data, i.e. how to reason with it and how to communicate it. This paper argues that the lessons of the UAI community, in particular that one should produce and communicate beliefs rather than raw sensor values, are highly relevant to sensor networks. We contend that loopy belief propagation is particularly well suited to communicating beliefs in sensor networks, due to its compact implementation and distributed nature. We investigate the ability of loopy belief propagation to function under the stressful conditions likely to prevail in sensor networks. Our experiments show that it performs well and degrades gracefully. It converges to appropriate beliefs even in highly asynchronous settings where some nodes communicate far less frequently than others; it continues to function if some nodes fail to participate in the propagation process; and it can track changes in the environment that occur while beliefs are propagating. As a result, we believe that sensor networks present an important application opportunity for UAI.

#index 1672997
#* Robust independence testing for constraint-based learning of causal structure
#@ Denver Dash;Marek J. Druzdzel
#t 2002
#c 12
#% 129987
#% 197387
#% 277480
#% 283314
#% 420059
#% 528333
#% 1650282
#% 1650771
#! This paper considers a method that combines ideas from Bayesian learning, Bayesian network inference, and classical hypothesis testing to produce a more reliable and robust test of independence for constraintbased (CB) learning of causal structure. Our method produces a smoothed contingency table Nxyz that can be used with any test of independence that relies on contingency table statistics. Nxyz can be calculated in the same asymptotic time and space required to calculate a standard contingency table, allows the specification of a prior distribution over parameters, and can be calculated when the database is incomplete. We provide theoretical justification for the procedure, and with synthetic data we demonstrate its benefits empirically over both a CB algorithm using the standard contingency table, and over a greedy Bayesian algorithm. We show that, even when used with noninformative priors, it results in better recovery of structural features and it produces networks with smaller KL-Divergence, especially as the number of nodes increases or the number of records decreases. Another benefit is the dramatic reduction in the probability that a CB algorithm will stall during the search, providing a remedy for an annoying problem plaguing CB learning when the database is small.

#index 1672998
#* A simple insight into iterative belief propagation's success
#@ Rina Dechter;Robert Mateescu
#t 2002
#c 12
#% 44876
#% 147684
#% 197431
#% 528300
#% 1280094
#% 1650361
#% 1848680
#! In non-ergodic belief networks the posterior belief of many queries given evidence may become zero. The paper shows that when belief propagation is applied iteratively over arbitrary networks (the so called, iterative or loopy belief propagation (IBP)) it is identical to an arc-consistency algorithm relative to zero-belief queries (namely assessing zero posterior probabilities). This implies that zero-belief conclusions derived by belief propagation converge and are sound. More importantly, it suggests that the inference power of IBP is as strong and as weak as that of arcconsistency. This allows the synthesis of belief networks for which belief propagation is useless on one hand, and focuses the investigation on classes of belief networks for which belief propagation may be zero-complete. Finally, we show empirically that IBP's accuracy is correlated with extreme probabilities, therefore explaining its success over coding applications.

#index 1672999
#* A new algorithm for maximum likelihood estimation in gaussian graphical models for marginal independence
#@ Mathias Drton;Thomas S. Richardson
#t 2002
#c 12
#% 44876
#! Graphical models with bi-directed edges (↔) represent marginal independence: the absence of an edge between two vertices indicates that the corresponding variables are marginally independent. In this paper, we consider maximum likelihood estimation in the case of continuous variables with a Gaussian joint distribution, sometimes termed a covariance graph model. We present a new fitting algorithm which exploits standard regression techniques and establish its convergence properties. Moreover, we contrast our procedure to existing estimation algorithms.

#index 1673000
#* Probabilistic reasoning about actions in nonmonotonic causal theories
#@ Thomas Eiter;Thomas Lukasiewicz
#t 2002
#c 12
#% 137786
#% 233132
#% 266241
#% 284644
#% 297171
#% 342119
#% 572371
#% 578731
#% 763743
#% 1289151
#% 1289329
#% 1290265
#% 1478800
#! We present the language PC+ for probabilistic reasoning about actions, which is a generalization of the action language C+ that allows to deal with probabilistic as well as nondeterministic effects of actions. We define a formal semantics of PC+ in terms of probabilistic transitions between sets of states. Using a concept of a history and its belief state, we then show how several important problems in reasoning about actions can be concisely formulated in our formalism.

#index 1673001
#* The Information bottleneck EM algorithm
#@ Gal Elidan;Nir Friedman
#t 2002
#c 12
#% 44876
#% 115608
#% 149628
#% 185079
#% 261550
#% 277467
#% 277480
#% 277483
#% 528174
#% 578676
#% 1650276
#! Learning with hidden variables is a central challenge in probabilistic graphical models that has important implications for many real-life problems. The classical approach is using the Expectation Maximization (EM) algorithm. This algorithm, however, can get trapped in local maxima. In this paper we explore a new approach that is based on the Information Bottleneck principle. In this approach, we view the learning problem as a tradeoff between two information theoretic objectives. The first is to make the hidden variables uninformative about the identity of specific instances. The second is to make the hidden variables informative about the observed attributes. By exploring different tradeoffs between these two objectives, we can gradually converge on a high-scoring solution. As we show, the resulting, Information Bottleneck Expectation Maximization (IB-EM) algorithm, manages to find solutions that are superior to standard EM methods.

#index 1673002
#* Symbolic generalization for on-line planning
#@ Zhengzhu Feng;Eric A. Hansen;Shlomo Zilberstein
#t 2002
#c 12
#% 3873
#% 104387
#% 160859
#% 224762
#% 233849
#% 272648
#% 277494
#% 292004
#% 337981
#% 393786
#% 464435
#% 543325
#% 578724
#% 677039
#% 1291498
#% 1478746
#% 1650297
#! Symbolic representations have been used successfully in off-line planning algorithms for Markov decision processes. We show that they can also improve the performance of on-line planners. In addition to reducing computation time, symbolic generalization can reduce the amount of costly real-world interactions required for convergence. We introduce Symbolic Real-Time Dynamic Programming (or sRTDP), an extension of RTDP. After each step of on-line interaction with an environment, sRTDP uses symbolic model-checking techniques to generalizes its experience by updating a group of states rather than a single state. We examine two heuristic approaches to dynamic grouping of states and show that they accelerate the planning process significantly in terms of both CPU time and the number of steps of interaction with the environment.

#index 1673003
#* Inference in polytrees with sets of probabilities
#@ Jose Carlos Ferreira da Rocha;Fabio Gagliardi Cozmanl;Cassio Polpo de Campos
#t 2002
#c 12
#% 22348
#% 25998
#% 170207
#% 174161
#% 267725
#% 319172
#% 417624
#% 477924
#% 528010
#% 1650396
#% 1650640
#% 1650708
#! Inferences in directed acyclic graphs associated with probability intervals and sets of probabilities are NP-hard, even for polytrees. We propose: 1) an improvement on Tessem's A/R algorithm for inferences on polytrees associated with probability intervals; 2) a new algorithm for approximate inferences based on local search; 3) branch-and-bound algorithms that combine the previous techniques. The first two algorithms produce complementary approximate solutions, while branch-and-bound procedures can generate either exact or approximate solutions. We report improvements on existing techniques for inference with probability sets and intervals, in some cases reducing computational effort by several orders of magnitude.

#index 1673004
#* Structure-based causes and explanations in the independent choice logic
#@ Alberto Finzi;Thomas Lukasiewicz
#t 2002
#c 12
#% 44876
#% 160190
#% 233132
#% 243712
#% 243717
#% 284644
#% 289948
#% 297171
#% 342119
#% 366370
#% 449788
#% 496256
#% 528334
#% 529345
#% 536285
#% 564806
#% 578731
#% 578737
#% 1271819
#% 1289151
#% 1289241
#% 1289329
#% 1477149
#% 1477321
#% 1478800
#% 1650363
#% 1650703
#! This paper is directed towards combining Pearl's structural-model approach to causal reasoning with high-level formalisms for reasoning about actions. More precisely, we present a combination of Pearl's structural-model approach with Poole's independent choice logic. We show how probabilistic theories in the independent choice logic can be mapped to probabilistic causal models. This mapping provides the independent choice logic with appealing concepts of causality and explanation from the structural-model approach. We illustrate this along Halpern and Pearl's sophisticated notions of actual cause, explanation, and partial explanation. This mapping also adds first-order modeling capabilities and explicit actions to the structural-model approach.

#index 1673005
#* Incremental compilation of bayesian networks
#@ M. Julia Flores;José A. Gámez;Kristian G. Olesen
#t 2002
#c 12
#% 351595
#% 1650575
#% 1650642
#% 1781111

#index 1673006
#* A distance-based branch and bound feature selection algorithm
#@ Ari Frank;Dan Geiger;Zohar Yakhini
#t 2002
#c 12
#% 80995
#% 243728
#% 246831
#% 297684
#% 1012295
#! There is no known efficient method for selecting k Gaussian features from n which achieve the lowest Bayesian classification error. We show an example of how greedy algorithms faced with this task are led to give results that are not optimal. This motivates us to propose a more robust approach. We present a Branch and Bound algorithm for finding a subset of k independent Gaussian features which minimizes the naive Bayesian classification error. Our algorithm uses additive monotonic distance measures to produce bounds for the Bayesian classification error in order to exclude many feature subsets from evaluation, while still returning an optimal solution. We test our method on synthetic data as well as data obtained from gene expression profiling.

#index 1673007
#* Locally weighted naive bayes
#@ Eibe Frank;Mark Hall;Bernhard Pfahringer
#t 2002
#c 12
#% 229931
#% 246831
#% 246832
#% 321059
#% 449566
#% 458168
#% 458259
#! Despite its simplicity, the naive Bayes classifier has surprised machine learning researchers by exhibiting good performance on a variety of learning problems. Encouraged by these results, researchers have looked to overcome naive Bayes' primary weakness-attribute independence-and improve the performance of the algorithm. This paper presents a locally weighted version of naive Bayes that relaxes the independence assumption by learning local models at prediction time. Experimental results show that locally weighted naive Bayes rarely degrades accuracy compared to standard naive Bayes and, in many cases, improves accuracy dramatically. The main advantage of this method compared to other techniques for enhancing naive Bayes is its conceptual and computational simplicity.

#index 1673008
#* Extending factor graphs so as to unify directed and undirected graphical models
#@ Brendan J. Frey
#t 2002
#c 12
#% 44876
#% 1042787
#% 1650778
#% 1810385
#! The two most popular types of graphical model are Bayesian networks (BNs) and Markov random fields (MRFs). These types of model offer complementary properties in model construction, expressing conditional independencies, expressing arbitrary factorizations of joint distributions, and formulating messagepassing inference algorithms. We show how the notation and semantics of factor graphs (a relatively new type of graphical model) can be extended so as to combine the strengths of BNs and MRFs. Every BN or MRF can be easily converted to a factor graph that expresses the same conditional independencies, expresses the same factorization of the joint distribution, and can be used for probabilistic inference through application of a single, simple message-passing algorithm. We describe a modified "Bayes-ball" algorithm for establishing conditional independence in factor graphs, and we show that factor graphs form a strict superset of BNs and MRFs. In particular, we give an example of a commonly-used model fragment, whose independencies cannot be represented in a BN or an MRF, but can be represented in a factor graph. For readers who use chain graphs, we describe a further extension of factor graphs that enables them to represent properties of chain graphs.

#index 1673009
#* Phase transition of tractability in constraint satisfaction and bayesian network inference
#@ Yong Gao
#t 2002
#c 12
#% 44876
#% 55926
#% 68244
#% 289332
#% 303620
#% 322912
#% 325348
#% 331899
#% 341488
#% 347206
#% 414854
#% 419990
#% 475714
#% 528175
#% 529517
#% 535150
#% 1650763
#! Identifying tractable subclasses and designing efficient algorithms for these tractable classes are important topics in the study of constraint satisfaction and Bayesian network inference problems. In this paper we investigate the asymptotic average behavior of a typical tractable subclass characterized by the treewidth of the problems. We show that the property of having a bounded treewidth in the constraint satisfaction problem and Bayesian network inference problem has a phase transition that occurs while the underlying structures of problems are still sparse. This implies that algorithms making use of treewidth based structural knowledge only work efficiently in a limited range of random instances.

#index 1673010
#* Decision making with partially consonant belief functions
#@ Phan H. Giang;Prakash P. Shenoy
#t 2002
#c 12
#% 746849
#% 1650366
#! This paper studies decision making for Walley's partially consonant belief functions (pcb). In a pcb, the set of foci are partitioned. Within each partition, foci are nested. The pcb class includes probability and possibility functions as extreme cases. We adopt an axiomatic system, similar in spirit to von Neumann and Morgenstern's axioms for preferences leading to the linear utility theory, for a preference relation on pcb lotteries. We Drove a representation theorem for this preference relation. Utility for a pcb lottery is a combination of linear utility for probabilistic lottery and binary utility for possibilistic lottery.

#index 1673011
#* Sufficient dimensionality reduction with irrelevance statistics
#@ Amir Globerson;Gal Chechik;Naftali Tishby
#t 2002
#c 12
#% 115608
#% 211942
#% 226495
#% 457926
#% 722936
#% 854813
#% 857076
#! The problem of unsupervised dimensionality reduction of stochastic variables while preserving their most relevant characteristics is fundamental for the analysis of complex data. Unfortunately, this problem is ill defined since natural datasets inherently contain alternative underlying structures. In this paper we address this problem by extending the recently introduced "Sufficient Dimensionality Reduction" feature extraction method [7], to use "side information" about irrelevant structures in the data. The use of such irrelevance information was recently successfully demonstrated in the context of clustering via the Information Bottleneck method [1]. Here we use this side-information framework to identify continuous features whose measurements are maximally informative for the main data set, but carry as little information as possible on the irrelevance data set. In statistical terms this can be understood as extracting statistics which are maximally sufficient for the main dataset, while simultaneously maximally ancillary for the irrelevance dataset. We formulate this problem as a tradeoff optimization problem and describe its analytic and algorithmic solutions. Our method is demonstrated on a synthetic example and on a real world application of face images, showing its superiority over other methods such as Oriented Principal Component Analysis.

#index 1673012
#* Implementation and comparison of solution methods for decision processes with non-markovian rewards
#@ Charles Gretton;David Price;Sylvie Thiébaux
#t 2002
#c 12
#% 296170
#% 337981
#% 578724
#% 1290041
#% 1476293
#% 1478747
#! This paper examines a number of solution methods for decision processes with non-Markovian rewards(NMRDPs). They all exploit a temporal logic specification of the reward function to automatically translate the NMRDP into an equivalent Markov decision process (MDP) amenable to well-known MDP solution methods. They differ however in the representation of the target MDP and the class of MDP solution methods to which they are suited. As a result, they adopt different temporal logics and different translations. Unfortunately, no implementation of these methods nor experimental let alone comparative results have ever been reported. This paper is the first step towards filling this gap. We describe an integrated system for solving NMRDPs which implements these methods and several variants under a common interface; we use it to compare the various approaches and identify certain problem features favouring one over the other.

#index 1673013
#* A logic for reasoning about evidence
#@ Joseph Y. Halpern;Riccardo Pucella
#t 2002
#c 12
#% 46020
#% 54190
#% 54223
#% 73571
#% 104387
#% 116624
#% 126329
#% 137786
#% 157172
#% 287455
#% 631045
#% 707145
#% 1068640
#! We introduce a logic for reasoning about evidence, that essentially views evidence as a function from prior beliefs (before making an observation) to posterior beliefs (after making the observation). We provide a sound and complete axiomatization for the logic, and consider the complexity of the decision problem. Although the reasoning in the logic is mainly propositional, we allow variables representing numbers and quantification over them. This expressive power seems necessary to capture important properties of evidence.

#index 1673014
#* Monte-Carlo optimizations for resource allocation problems in stochastic network systems
#@ Milos Hauskrecht;Tomas Singliar
#t 2002
#c 12
#% 70370
#% 265807
#% 416580
#% 431302
#% 528191
#% 1273918
#% 1289239
#% 1478746
#% 1650568
#! Real-world distributed systems and networks are often unreliable and subject to random failures of its components. Such a stochastic behavior affects adversely the complexity of optimization tasks performed routinely upon such systems. In this work we investigate Monte Carlo solutions for a class of two-stage optimization problems in stochastic networks in which the expected value of resources allocated before and after the occurence of stochastic failures needs to be optimized. The limitation of these problems is that their exact solutions are exponential in the number of unreliable network components: thus, exact methods do not scale-up well to large networks often seen in practice. We first show that Monte Carlo optimization methods can overcome the exponential bottleneck of exact methods. Next we support our theoretical findings on resource allocation experiments and show a very good scale-up potential of the methods on problems with large stochastic networks.

#index 1673015
#* Approximate inference and constrained optimization
#@ Tom Heskes;Kees Albers;Bert Kappen
#t 2002
#c 12
#% 185077
#% 277483
#% 450290
#% 1650404
#! Loopy and generalized belief propagation are popular algorithms for approximate inference in Markov random fields and Bayesian networks. Fixed points of these algorithms correspond to extrema of the Bethe and Kikuchi free energy (Yedidia et al., 2001). However, belief propagation does not always converge, which motivates approaches that explicitly minimize the Kikuchi/Bethe free energy, such as CCCP (Yuille, 2002) and UPS (Teh and Welling, 2002). Here we describe a class of algorithms that solves this typically non-convex constrained minimization problem through a sequence of convex constrained minimizations of upper bounds on the Kikuchi free energy. Intuitively one would expect tighter bounds to lead to faster algorithms, which is indeed convincingly demonstrated in our simulations. Several ideas are applied to obtain tight convex bounds that yield dramatic speed-ups over CCCP.

#index 1673016
#* LAYERWIDTH: analysis of a new metric for directed acyclic graphs
#@ Mark Hopkins
#t 2002
#c 12
#% 408396
#% 528334
#% 1650363
#! We analyze a new property of directed acyclic graphs (DAGs), called layerwidth, arising from a useful class of DAGs proposed by Eiter and Lukasiewicz for tractable causal reasoning. First, we establish that the complexity of deciding whether a given graph has a bounded layerwidth is NP-complete. Then we proceed to prove key properties of layerwidth that are helpful in efficiently computing the optimal layerwidth. Finally, we compare this new DAG property to two other important DAG properties: treewidth and bandwidth.

#index 1673017
#* Preference-based graphic models for collaborative filtering
#@ Rong Jin;Luo Si;ChengXiang Zhai
#t 2002
#c 12
#% 173879
#% 261550
#% 272510
#% 528156
#% 528182
#% 564279
#% 668807
#% 1273828
#% 1650569
#! Collaborative filtering is a very useful general technique for exploiting the preference patterns of a group of users to predict the utility of items to a particular user. Previous research has studied several probabilistic graphic models for collaborative filtering with promising results. However, while these models have succeeded in capturing the similarity among users and items, none of them has considered the fact that users with similar interests in items can have very different rating patterns; some users tend to assign a higher rating to all items than other users. In this paper, we propose and study two new graphic models that address the distinction between user preferences and ratings. In one model, called the decoupled model, we introduce two different variables to decouple a user's preferences from hislher ratings. In the other, called the preference model, we model the orderings of items preferred by a user, rather than the user's numerical ratings of items. Empirical study over two datasets of movie ratings shows that, due to its appropriate modeling of the distinction between user preferences and ratings, the proposed decoupled model significantly outperforms all the five existing approaches that we compared with. The preference model, however, performs much worse than the decoupled model, suggesting that while explicit modeling of the underlying user preferences is very important for collaborative filtering, we can not afford ignoring the rating information completely.

#index 1673018
#* 1 Billion Pages = 1 Million Dollars? mining the web to play "who wants to be a millionaire?"
#@ Shyong K. Lam;David M. Pennock;Dan Cosley;Steve Lawrence
#t 2002
#c 12
#% 46437
#% 67565
#% 68274
#% 116297
#% 198055
#% 202611
#% 283238
#% 283328
#% 316521
#% 330619
#% 340953
#% 341865
#% 345265
#% 348163
#% 380725
#% 397160
#% 433674
#% 464296
#% 589174
#% 742102
#! We exploit the redundancy and volume of information on the web to build a computerized player for the ABC TV game show "Who Wants To Be A Millionaire?". The player consists of a question-answering module and a decision-making module. The question-answering module utilizes question transformation techniques, natural language parsing, multiple information retrieval algorithms, and multiple search engines; results are combined in the spirit of ensemble learning using an adaptive weighting scheme. Empirically, the system correctly answers about 75% of questions from the Millionaire CD-ROM, 3rd edition--general-interest trivia questions often about popular culture and common knowledge. The decision-making module chooses from allowable actions in the game in order to maximize expected risk-adjusted winnings, where the estimated probability of answering correctly is a function of past performance and confidence in correctly answering the current question. When given a six question head start (i.e., when starting from the $2,000 level), we find that the system performs about as well on average as humans starting at the beginning. Our system demonstrates the potential of simple but well-chosen techniques for mining answers from unstructured information such as the web.

#index 1673019
#* Approximate Decomposition: a method for bounding and estimating probabilistic and deterministic queries
#@ David Larkin
#t 2002
#c 12
#% 44876
#% 289947
#% 303620
#% 337983
#% 1650711
#! In this paper, we introduce a method for approximating the solution to inference and optimization tasks in uncertain and deterministic reasoning. Such tasks are in general intractable for exact algorithms because of the large number of dependency relationships in their structure. Our method effectively maps such a dense problem to a sparser one which is in some sense "closest". Exact methods can be run on the sparser problem to derive bounds on the original answer, which can be quite sharp. On one large CPCS network, for example, we were able to calculate upper and lower bounds on the conditional probability of a variable, given evidence, that were almost identical in the average case.

#index 1673020
#* Efficient gradient estimation for motor control learning
#@ Gregory Lawrence;Noah Cowan;Stuart Russell
#t 2002
#c 12
#% 124687
#% 379975
#% 527859
#% 528322
#% 528325
#% 1272286
#% 1272385
#! The task of estimating the gradient of a function in the presence of noise is central to several forms of reinforcement learning, including policy search methods. We present two techniques for reducing gradient estimation errors in the presence of observable input noise applied to the control signal. The first method extends the idea of a reinforcement baseline by fitting a local model to the response function whose gradient is being estimated; we show how to find the response surface model that minimizes the variance of the gradient estimate, and how to estimate the model from data. The second method improves this further by discounting components of the gradient vector that have high variance. These methods are applied to the problem of motor control learning, where actuator noise has a significant influence on behavior. In particular, we apply the techniques to learn locally optimal controllers for a dart-throwing task using a simulated three-link arm; we demonstrate that the proposed methods significantly improve the response function gradient estimate and, consequently, the learning curve, over existing methods.

#index 1673021
#* Learning riemannian metrics
#@ Guy Lebanon
#t 2002
#c 12
#% 266215
#% 406493
#% 466900
#% 565549
#! We consider the problem of learning a Riemannian metric associated with a given differentiable manifold and a set of points. Our approach to the problem involves choosing a metric from a parametric family that is based on maximizing the inverse volume of a given dataset of points. From a statistical perspective, it is related to maximum likelihood under a model that assigns probabilities inversely proportional to the Riemannian volume element. We discuss in detail learninga metric on the multinomial simplex where the metric candidates are pull-back metrics of the Fisher information under a continuous group of transformations. When applied to documents, the resulting geodesics resemble, but outperform, the TFIDF cosine similarity measure in classification.

#index 1673022
#* A linear belief function approach to portfolio evaluation
#@ Liping Liu;Catherine Shenoy;Prakash P. Shenoy
#t 2002
#c 12
#% 360087
#% 567872
#! We show how to use linear belief functions to represent market information and financial knowledge, including complete ignorance, statistical observations, subjective speculations, distributional assumptions, linear relations, and empirical asset pricing models. We then appeal to Dempster's rule of combination to integrate the knowledge for assessing an overall belief on portfolio performance, and to update this belief by incorporating additional information.

#index 1673023
#* Budgeted learning of nailve-bayes classifiers
#@ Daniel J. Lizotte;Omid Madani;Russell Greiner
#t 2002
#c 12
#% 697
#% 115521
#% 156186
#% 203337
#% 363744
#% 447606
#% 464268
#% 715337
#% 729437
#% 735357
#% 1289266
#! There is almost always a cost associated with acquiring training data. We consider the situation where the learner, with a fixed budget, may 'purchase' data during training. In particular, we examine the case where observing the value of a feature of a training example has an associated cost, and the total cost of all feature values acquired during training must remain less than this fixed budget. This paper compares methods for sequentially choosing which feature value to purchase next, given the budget and user's current knowledge of Naïve Bayes model parameters. Whereas active learning has traditionally focused on myopic (greedy) approaches and uniform/round-robin policies for query selection, this paper shows that such methods are often suboptimal and presents a tractable method for incorporating knowledge of the budget in the information acquisition process.

#index 1673024
#* Monte Carlo matrix inversion policy evaluation
#@ Fletcher Lu;Dale Schuurmans
#t 2002
#c 12
#% 14738
#% 124695
#% 203596
#% 384911
#% 449561
#% 464462
#% 466235
#! In 1950, Forsythe and Leibler (1950) introduced a statistical technique for finding the inverse of a matrix by characterizing the elements of the matrix inverse as expected values of a sequence of random walks. Barto and Duff (1994) subsequently showed relations between this technique and standard dynamic programming and temporal differencing methods. The advantage of the Monte Carlo matrix inversion (MCMI) approach is that it scales better with respect to state-space size than alternative techniques. In this paper, we introduce an algorithm for performing reinforcement learning policy evaluation using MCMI. We demonstrate that MCMI possesses accuracy similar to a maximum likelihood model-based policy evaluation approach but avoids ML's slow execution time. In fact, we show that MCMI executes at a similar runtime to temporal differencing (TD). We then illustrate a least-squares generalization technique for scaling up MCMI to large state spaces. We compare this leastsquares Monte Carlo matrix inversion (LS-MCMI) technique to the least-squares temporal differencing (LSTD) approach introduced by Bradtke and Barto (1996) demonstrating that both LS-MCMI and LSTD have similar runtime.

#index 1673025
#* Systematic vs. non-systematic algorithms for solving the MPE task
#@ Radu Marinescu;Kalev Kask;Rina Dechter
#t 2002
#c 12
#% 44876
#% 289947
#% 337983
#% 420718
#% 448887
#% 534816
#% 578738
#% 578757
#% 1273786
#% 1650711
#! The paper explores the power of two systematic Branch and Bound search algorithms that exploit partition-based heuristics, BBBT (a new algorithm for which the heuristic information is constructed during search and allows dynamic variable/value ordering) and its predecessor BBMB (for which the heuristic information is pre-compiled) and compares them against a number of popular local search algorithms for the MPE problem as well as against the recently popular iterative belief propagation algorithms. We show empirically that the new Branch and Bound algorithm, BBBT demonstrates tremendous pruning of the search space far beyond its predecessor, BBMB which translates to impressive time saving for some classes of problems. Second, when viewed as approximation schemes, BBBT/BBMB together are highly competitive with the best known SLS algorithms and are superior, especially when the domain sizes increase beyond 2. The results also show that the class of belief propagation algorithms can outperform SLS, but they are quite inferior to BBMB/BBBT. As far as we know, BBBT/BBMB are currently among the best performing algorithms for solving the MPE task.

#index 1673026
#* Efficiently inducing features of conditional random fields
#@ Andrew McCallum
#t 2002
#c 12
#% 95730
#% 162505
#% 226495
#% 235377
#% 278106
#% 464434
#% 464644
#% 466892
#% 722822
#% 816181
#% 854813
#% 1650403
#! Conditional Random Fields (CRFs) are undirected graphical models, a special case of which correspond to conditionally-trained finite state machines. A key advantage of CRFs is their great flexibility to include a wide variety of arbitrary, non-independent features of the input. Faced with this freedom, however, an important question remains: what features should be used? This paper presents an efficient feature induction method for CRFs. The method is founded on the principle of iteratively constructing feature conjunctions that would significantly increase conditional log-likelihood if added to the model. Automated feature induction enables not only improved accuracy and dramatic reduction in parameter count, but also the use of larger cliques, and more freedom to liberally hypothesize atomic input variables that may be relevant to a task. The method applies to linear-chain CRFs, as well as to more arbitrary CRF structures, such as Relational Markov Networks, where it corresponds to learning clique templates, and can also be understood as supervised structure learning. Experimental results on named entity extraction and noun phrase segmentation tasks are presented.

#index 1673027
#* Practically perfect
#@ Christopher Meek;David Maxwell Chickering
#t 2002
#c 12
#% 44876
#% 190611
#% 1650357
#% 1650674
#! We prove that perfect distributions exist when using a finite number of bits to represent the parameters of a Bayesian network. In addition, we provide an upper bound on the probability of sampling a non-perfect distribution when using a fixed number of bits for the parameters and that the upper bound approaches zero exponentially fast as one increases the number of bits. We also provide an upper bound on the number of bits needed to guarantee that a distribution sampled from a uniform Dirichlet distribution is perfect with probability greater than 1/2.

#index 1673028
#* Optimal limited contingency planning
#@ Nicolas Meuleau;David E. Smith
#t 2002
#c 12
#% 283215
#% 283219
#% 363744
#% 544926
#% 707175
#% 1272331
#% 1289211
#% 1289212
#% 1290265
#% 1650355
#% 1650702
#! For a given problem, the optimal Markov policy over a finite horizon is a conditional plan containing a potentially large number of branches. However, there are applications where it is desirable to strictly limit the number of decision points and branches in a plan. This raises the question of how one goes about finding optimal plans containing only a limited number of branches. In this paper, we present an any-time algorithm for optimal k-contingency planning. It is the first optimal algorithm for limited contingency planning that is not an explicit enumeration of possible contingent plans. By modelling the problem as a partially observable Markov decision process, it implements the Bellman optimality principle and prunes the solution space. We present experimental results of applying this algorithm to some simple test cases.

#index 1673029
#* Dealing with uncertainty in fuzzy inductive reasoning methodology
#@ Francisco Mugica;Angela Nebot;Pilar Gómez
#t 2002
#c 12
#! The aim of this research is to develop a strategy of reasoning under uncertainty in the context of the Fuzzy Inductive Reasoning methodology. This methodology allows the prediction of systems behavior by means of two different schemes. The first one corresponds to a pattern prediction scheme, based exclusively on pattern rules. The second one corresponds to a purely Sugeno inference system, i.e. Sugeno prediction scheme. The Sugeno fuzzy rules are automatically extracted from the pattern rules producing a compact representation of the system modelled. In this paper a mixed pattern/fuzzy rules scheme is studied to deal with uncertainty in such a way that the best of both perspectives is used. The proposed scheme is applied to a real biomedical system, i.e. the central nervous system control of the cardiovascular system.

#index 1673030
#* On local optima in learning bayesian networks
#@ Jens D. Nielsen;Tomáš Kočka;Jose M. Peña
#t 2002
#c 12
#% 129497
#% 129987
#% 328317
#% 388024
#% 499072
#% 722900
#% 723247
#% 1650357
#% 1650638
#! This paper proposes and evaluates the k-greedy equivalence search algorithm (KES) for learning Bayesian networks (BNs) from complete data. The main characteristic of KES is that it allows a trade-off between greediness and randomness, thus exploring different good local optima when run repeatedly. When greediness is set at maximum, KES corresponds to the greedy equivalence search algorithm (GES). When greediness is kept at minimum, we prove that under mild conditions KES asymptotically returns any inclusion optimal BN with nonzero probability. Experimental results for both synthetic and real data are reported showing that KES finds a better local optimum than GES considerably often. Additionally, these results illustrate that the number of different local optima is usually huge.

#index 1673031
#* Marginalizing out future passengers in group elevator control
#@ Daniel Nikovski;Matthew Brand
#t 2002
#c 12
#% 275472
#% 352664
#! Group elevator scheduling is an NP-hard sequential decision-making problem with unbounded state spaces and substantial uncertainty. Decision-theoretic reasoning plays a surprisingly limited role in fielded systems. A new opportunity for probabilistic methods has opened with the recent discovery of a tractable solution for the expected waiting times of all passengers in the building, marginalized over all possible passenger itineraries [Nikovski and Brand, 2003]. Though commercially competitive, this solution does not contemplate future passengers. Yet in up-peak traffic, the effects of future passengers arriving at the lobby and entering elevator cars can dominate all waiting times. We develop a probabilistic model of how these arrivals affect the behavior of elevator cars at the lobby, and demonstrate how this model can be used to very significantly reduce the average waiting time of all passengers.

#index 1673032
#* Learning continuous time bayesian networks
#@ Uri Nodelman;Christian R. Shelton;Daphne Koller
#t 2002
#c 12
#% 75936
#% 197387
#% 1650390
#! Continuous time Bayesian networks (CTBN) describe structured stochastic processes with finitely many states that evolve nver continuous time. A CTBN is a directed (possibly cyclic) dependency graph over a set of variables, each of which represents a finite state continuous time Markov process whose transition model is a function of its parents. We address the problem of leaning parameters and structure of a CTBN from fully observed data. We define a conjugate prior for CTBNs and show how it can be used both for Bayesian parameter estimation and as the basis of a Bayesian score for structure learning. Because acyclicity is not a constraint in CTBNs, we can show that the structure leaning problem is significantly easier, both in theory and in practice, than structure leaning for dynamic Bayesian networks (DBNs). Furthermore, as CTBNs can tailor the parameters and dependency structure to the different time granularities of the evolution of different variables, they can provide a better fit to continuous-time processes than DBNs with a fixed time granularity.

#index 1673033
#* Solving MAP exactly using systematic search
#@ James D. Park;Adnan Darwiche
#t 2002
#c 12
#% 302413
#% 329486
#% 448887
#% 528175
#% 1650391
#% 1650778
#! MAP is the problem of finding a most probable instantiation of a set of variables in a Bayesian network, given some partial evidence about the complement of that set. Unlike posterior probabilities, or MPE (a special case of MAP), the time and space complexity of structure-based algorithms for MAP are not only exponential in the network treewidth, but in a larger parameter known as the constrained treewidth. In practice, this means that computing MAP can be orders of magnitude more expensive than computing posterior probabilities or MPE. We introduce in this paper a new, simple upper bound on the probability of a MAP solution, which is shown to be generally much tighter than existing bounds. We then use the proposed upper bound to develop a branch-andbound search algorithm for solving MAP exactly. Experimental results demonstrate that the search algorithm is able to solve many problems that are far beyond the reach of any structurebased method for MAP. For example, we show that the proposed algorithm can compute MAP exactly and efficiently for some networks whose constrained treewidth is more than 40.

#index 1673034
#* An axiomatic approach to robustness in search problems with multiple scenarios
#@ Patrice Perny;Olivier Spanjaard
#t 2002
#c 12
#% 241
#% 40313
#% 102372
#% 205165
#% 205388
#% 266202
#% 578768
#% 1650348
#% 1650688
#% 1650819
#! This paper is devoted to the the search of robust solutions in state space graphs when costs depend on scenarios. We first present axiomatic requirements for preference compatibility with the intuitive idea of robustness. This leads us to propose the Lorenz dominance rule as a basis for robustness analysis. Then, after presenting complexity results about the determination of robust solutions, we propose a new sophistication of A* specially designed to determine the set of robust paths in a state space graph. The behavior of the algorithm is illustrated on a small example. Finally, an axiomatic justification of the refinement of robustness by an OWA criterion is provided.

#index 1673035
#* Policy-contingent abstraction for robust robot control
#@ Joelle Pineau;Geoff Gordon;Sebastian Thrun
#t 2002
#c 12
#% 357083
#% 464303
#% 464470
#% 464607
#% 578674
#% 578743
#% 1271827
#% 1272286
#% 1290265
#% 1478746
#% 1650710
#! This paper presents a scalable control algorithm that enables a deployed mobile robot to make high-level control decisions under full consideration of its probabilistic belief. We draw on insights from the rich literature of structured robot controllers and hierarchical MDPs to propose PolCA, a hierarchical probabilistic control algorithm which learns both subtask-specific state abstractions and policies. The resulting controller has been successfully implemented onboard a mobile robotic assistant deployed in a nursing facility. To the best of our knowledge, this work is a unique instance of applying POMDPs to highlevel robotic control problems.

#index 1673036
#* Learning generative models of similarity matrices
#@ Rómer Rosales;Brendan Frey
#t 2002
#c 12
#% 268079
#% 282905
#% 313959
#% 457710
#% 635713
#! Recently, spectral clustering (a.k.a. normalized graph cut) techniques have become popular for their potential ability at finding irregularly-shaped clusters in data. The input to these methods is a similarity measure between every pair of data points. If the clusters are well-separated, the eigenvectors of the similarity matrix can be used to identify the clusters, essentially by identifying groups of points that are related by transitive similarity relationships. However, these techniques fail when the clusters are noisy and not well-separated, or when the scale parameter that is used to map distances between points to similarities is not set correctly. Our approach to solving these problems is to introduce a generative probability model that explicitly models noise and can be trained in a maximum-likelihood fashion to estimate the scale parameter. Exact inference is computationally intractable, but we describe tractable, approximate techniques for inference and learning. Interestingly, it turns out that greedy inference and learning in one of our models with a fixed scale parameter is equivalent to spectral clustering. We examine several data sets, and demonstrate that our method finds better clusters compared with spectral clustering.

#index 1673037
#* Decentralized sensor fusion with distributed particle filters
#@ Matt Rosencrantz;Geoffrey Gordon;Sebastian Thrun
#t 2002
#c 12
#% 82085
#% 141162
#% 266616
#% 418730
#% 529194
#% 643108
#% 1273895
#% 1279352
#% 1650381
#% 1650406
#! This paper presents a scalable Bayesian technique for decentralized state estimation from multiple platforms in dynamic environments. As has long been recognized, centralized architectures impose severe scaling limitations for distributed systems due to the enormous communication overheads. We propose a strictly decentralized approach in which only nearby platforms exchange information. They do so through an interactive communication protocol aimed at maximizing information flow. Our approach is evaluated in the context of a distributed surveillance scenario that arises in a robotic system for playing the game of laser tag. Our results, both from simulation and using physical robots, illustrate an unprecedented scaling capability to large teams of vehicles.

#index 1673038
#* Automated analytic asymptotic evaluation of the marginal likelihood for latent models
#@ Dmitry Rusakov;Dan Geiger
#t 2002
#c 12
#% 129987
#% 197387
#% 232117
#% 246834
#% 322164
#% 856208
#% 1650397
#% 1650619
#% 1650786
#! We present two algorithms for analytic asymptotic evaluation of the marginal likelihood of data given a Bayesian network with hidden nodes. As shown by previous work, this evaluation is particularly hard because for these models asymptotic approximation of the marginal likelihood deviates from the standard BIC score. Our algorithms compute regular dimensionality drop for latent models and compute the non-standard approximation formulas for singular statistics for these models. The presented algorithms are implemented in Matlab and Maple and their usage is demonstrated on several examples.

#index 1673039
#* On the convergence of bound optimization algorithms
#@ Ruslan Salakhutdinov;Sam Roweis;Zoubin Ghahramani
#t 2002
#c 12
#% 226495
#% 1051482
#! Many practitioners who use EM and related algorithms complain that they are sometimes slow. When does this happen, and what can be done about it? In this paper, we study the general class of bound optimization algorithms - including EM, Iterative Scaling, Non-negative Matrix Factorization, CCCP - and their relationship to direct optimization algorithms such as gradientbased methods for parameter learning. We derive a general relationship between the updates performed by bound optimization methods and those of gradient and second-order methods and identify analytic conditions under which bound optimization algorithms exhibit quasi-Newton behavior, and under which they possess poor, first-order convergence. Based on this analysis, we consider several specific algorithms, interpret and analyze their convergence properties and provide some recipes for preprocessing input to these algorithms to yield faster convergence behavior. We report empirical results supporting our analysis and showing that simple data preprocessing can result in dramatically improved performance of bound optimizers in practice.

#index 1673040
#* CLP(BN): constraint logic programming for probabilistic knowledge
#@ Vítor Santos Costa;David Page;Maleeha Qazi;James Cussens
#t 2002
#c 12
#% 147677
#% 174207
#% 345862
#% 550743
#% 550745
#% 1271905
#% 1272388
#! In Datalog, missing values are represented by Skolem constants. More generally, in logic programming missing values, or existentially-quantified variables, are represented by terms built from Skolem functors. In an analogy to probabilistic relational models (PRMs), we wish to represent the joint probability distribution over missing values in a database or logic program using a Bayesian network. This paper presents an extension of logic programs that makes it possible to specify a joint probability distribution over terms built from Skolem functors in the program. Our extension is based on constraint logic programming (CLP), so we call the extended language CLP(BN). We show that CLP(BN) subsumes PRMs; this greater expressivity carries both advantages and disadvantages for CLP(BN). We also show that algorithms from inductive logic programming (ILP) can be used with only minor modification to learn CLP(BN) programs. An implementation of CLP(BN) is publicly available as part of YAP Prolog at http://www.cos.ufrj.br/~vitor/Yap/clpbn

#index 1673041
#* Learning module networks
#@ Eran Segal;Dana Pe'er;Aviv Regev;Daphne Koller
#t 2002
#c 12
#% 75936
#% 129987
#% 197387
#% 266230
#% 277480
#% 277494
#% 528306
#% 723254
#% 1273915
#! Methods for learning Bayesian networks can discover dependency structure between observed variables. Although these methods are useful in many applications, they run into computational and statistical problems in domains that involve a large number of variables. In this paper, we consider a solution that is applicable when many variables have similar behavior. We introduce a new class of models, module networks, that explicitly partition the variables into modules that share the same parents in the network and the same conditional probability distribution. We define the semantics of module networks, and describe an algorithm that learns the modules' composition and their dependency structure from data. Evaluation on real data in the domains of gene expression and the stock market shows that module networks generalize better than Bayesian networks, and that the learned module network structure reveals regularities that are obscured in learned Bayesian networks.

#index 1673042
#* Efficient inference in large discrete domains
#@ Rita Sharma;David Poole
#t 2002
#c 12
#% 44876
#% 205380
#% 230435
#% 304894
#% 340683
#% 449588
#% 818089
#% 1272302
#% 1650767
#! In this paper we examine the problem of inference in Bayesian Networks with discrete random variables that have very large or even unbounded domains. For example, in a domain where we are trying to identify a person, we may have variables that have as domains, the set of all names, the set of all postal codes, or the set of all credit card numbers. We cannot just have big tables of the conditional probabilities, but need compact representations. We provide an inference algorithm, based on variable elimination, for belief networks containing both large domain and normal discrete random variables. We use intensional (i.e., in terms of procedures) and extensional (in terms of listing the elements) representations of conditional probabilities and of the intermediate factors.

#index 1673043
#* Learning measurement models for unobserved variables
#@ Ricardo Silva;Richard Scheines;Clark Glymour;Peter Spirtes
#t 2002
#c 12
#% 722804
#% 1650397
#! Observed associations in a database may be due in whole or part to variations in unrecorded ("latent") variables. Identifying such variables and their causal relationships with one another is a principal goal in many scientific and practical domains. Previous work shows that, given a partition of observed variables such that members of a class share only a single latent common cause, standard search algorithms for causal Bayes nets can infer structural relations between latent variables. We introduce an algorithm for discovering such partitions when they exist. Uniquely among available procedures, the algorithm is (asymptotically) correct under standard assumptions in causal Bayes net search algorithms, requires no prior knowledge of the number of latent variables, and does not depend on the mathematical form of the relationships among the latent variables. We evaluate the algorithm on a variety of simulated data sets.

#index 1673044
#* The revisiting problem in mobile robot map building: a hierarchical bayesian approach
#@ Benjamin Stewart;Jonathan Ko;Dieter Fox;Kurt konolige
#t 2002
#c 12
#% 528169
#% 1279374
#! We present an application of hierarchical Bayesian estimation to robot map building. The revisiting problem occurs when a robot has to decide whether it is seeing a previously-built portion of a map, or is exploring new territory. This is a difficult decision problem, requiring the probability of being outside of the current known map. To estimate this probability, we model the structure of a "typical" environment as a hidden Markov model that generates sequences of views observed by a robot navigating through the environment. A Dirichlet prior over structural models is learned from previously explored environments. Whenever a robot explores a new environment, the posterior over the model is estimated by Dirichlet hyperparameters. Our approach is implemented and tested in the context of multi-robot map merging, a particularly difficult instance of the revisiting problem. Experiments with robot data show that the technique yields strong improvements over altemative methods.

#index 1673045
#* Renewal strings for cleaning astronomical databases
#@ Amos J. Storkey;Nigel C. Hambly;Christopher K. I. Williams;Robert G. Mannt
#t 2002
#c 12
#% 117680
#! Large astronomical databases obtained from sky surveys such as the SuperCOSMOS Sky Surveys (SSS) invariably suffer from spurious records coming from artefactual effects of the telescope, satellites and junk objects in orbit around earth and physical defects on the photographic plate or CCD. Though relatively small in number these spurious records present a significant problem in many situations where they can become a large proportion of the records potentially of interest to a given astronomer. We have developed renewal strings, a probabilistic technique combining the Hough transform, renewal processes and hidden Markov models which has proven highly effective in this context. The methods are applied to the SSS data to develop a dataset of spurious object detections, along with confidence measures, which can allow this unwanted data to be removed from consideration. These methods are general and can be adapted to any other astronomical survey data.

#index 1673046
#* Boltzmann machine learning with the latent maximum entropy principle
#@ Shaojun Wang;Dale Schuurmans;Fuchun Peng;Yunxin Zhao
#t 2002
#c 12
#% 19775
#% 53981
#% 185079
#% 226495
#% 261550
#% 266401
#% 425065
#% 450453
#% 450888
#% 1814768
#! We present a new statistical learning paradigm for Boltzmann machines based on a new inference principle we have proposed: the latent maximum entropy principle (LME). LME is different both from Jaynes' maximum entropy principle and from standard maximum likelihood estimation. We demonstrate the LME principle by deriving new algorithms for Boltzmann machine parameter estimation, and show how a robust and rapidly convergent new variant of the EM algorithm can be developed. Our experiments show that estimation based on LME generally yields better results than maximum likelihood estimation when inferring models from small amounts of data.

#index 1673047
#* Efficient parametric projection pursuit density estimation
#@ Max Welling;Richard S. Zemel;Geoffrey E. Hinton
#t 2002
#c 12
#% 226495
#% 313975
#% 380342
#% 479708
#% 528189
#% 959472
#% 1860500
#! Product models of low dimensional experts are a powerful way to avoid the curse of dimensionality. We present the "undercomplete product of experts" (UPoE), where each expert models a one dimensional projection of the data. The UPoE may be interpreted as a parametric probabilistic model for projection pursuit. Its ML learning rules are identical to the approximate learning rules proposed before for under-complete ICA. We also derive an efficient sequential learning algorithm and discuss its relationship to projection pursuit density estimation and feature induction algorithms for additive random field models.

#index 1673048
#* A generalized mean field algorithm for variational inference in exponential families
#@ Eric P. Xing;Michael I. Jordan;Stuart Russell
#t 2002
#c 12
#% 246836
#% 277467
#% 424806
#% 528019
#% 528190
#% 528330
#% 855575
#! We present a ciass of generalized mean field (GMF) algorithms for approximate inference in exponential family graphical models which is analogous to the generalized belief propagation (GBP) or cluster variational methods. While those methods are based on overlapping clusters, our approach is based on nonoverlapping clusters. Unlike the cluster variational methods, the approach is proved to converge to a globally consistent set of marginals and a lower bound on the likelihood, while providing much of the flexibility associated with cluster variational methods. We present experiments that analyze the effect of different choices of clustering on inference quality, and compare GMF with belief propagation on several canonical models.

#index 1673049
#* Stochastic complexity of bayesian networks
#@ Keisuke Yamazaki;Sumio Watanabe
#t 2002
#c 12
#% 132676
#% 430829
#% 450896
#% 543599
#% 735504
#% 856208
#% 1650397
#! Bayesian networks arc now used in enormous fields, for example. system diagnosis. data mining, clusterings etc. In spite of wide range of their applications, the statistical properties have not yet bcen clarified because the models are nonidentifiable and non-regular. In a Bayesian network. the set of parameters for a smaller model is an analytic set with singularities in the parameter space of a large model. Because of these singularities, the Fisher information matrices are not positive definite. In other words, the mathematical foundation for learning has not been constructed. In recent years, however, we have developed a method to analyze nonregular models by using algebraic geometry. This method revealed the relation between model's singularities and its statistical properties. In this paper, applying this method to Bayesian networks with latent variables, we clarify the orders of the stochastic complexities. Our result shows that their upper bound is smaller than thc dimension of the parameter space. This means that the Bayesian generalization error is also far smaller than that of a regular model, and that Schwarz's model selection criterion BIC needs to be improved for Bayesian networks.

#index 1673050
#* Markov random walk representations with continuous distributions
#@ Chen-Hsiang Yeang;Martin Szummer
#t 2002
#c 12
#% 464615
#! Representations based on random walks can exploit discrete data distributions for clustering and classification. We extend such representations from discrete to continuous distributions. Transition probabilities are now calculated using a diffusion equation with a diffusion coefficient that inversely depends on the data density. We relate this diffusion equation to a path integral and derive the corresponding path probability measure. The framework is useful for incorporating continuous data densities and prior knowledge.

#index 1673051
#* Exploiting locality in searching the web
#@ Joel Young;Thomas Dean
#t 2002
#c 12
#% 269217
#% 281251
#% 299941
#% 330609
#% 337239
#% 397204
#% 451536
#% 466250
#% 480309
#% 510723
#% 842375
#! Published experiments on spidering the Web suggest that, given training data in the form of a (relatively small) subgraph of the Web containing a subset of a selected class of target pages, it is possible to conduct a directed search and find additional target pages significantly faster (with fewer page retrievals) than by performing a blind or uninformed random or systematic search, e.g., breadthfirst search. If true, this claim motivates a number of practical applications. Unfortunately, these experiments were carried out in specialized domains or under conditions that are difficult to replicate. We present and apply an experimental framework designed to reexamine and resolve the basic claims of the earlier work, so that the supporting experiments can be replicated and built upon. We provide high-performance tools for building experimental spiders, make use of the ground truth and static nature of the WT10g TREC Web corpus, and rely on simple well understand machine learning techniques to conduct our experiments. In this paper, we describe the basic framework, motivate the experimental design, and report on our findings supporting and qualifying the conclusions of the earlier research.

#index 1673052
#* Collaborative ensemble learning: combining collaborative and content-based information filtering via hierarchical bayes
#@ Kai Yu;Anton Schwaighofer;Volker Tresp
#t 2002
#c 12
#% 173879
#% 190581
#% 202011
#% 220709
#% 236497
#% 266281
#% 301259
#% 304425
#% 341269
#% 458379
#% 464284
#% 465928
#% 466750
#% 466913
#% 476537
#% 528182
#% 722754
#% 722799
#% 1271814
#% 1273828
#% 1499473
#% 1650569
#% 1857498
#! Collaborative filtering (CF) and content-based filtering (CBF) have widely been used information filtering applications, both approaches having their individual strengths and weaknesses. This paper proposes a novel probabilistic framework to unify CF and CBF, named collaborative ensemble learning. Based on content based probabilistic models for each user's preferences (the CBF idea), it combines a society of users' preferences to predict an active user's preferences (the CF idea). While retaining an intuitive explanation, the combination scheme can be interpreted as a hierarchical Bayesian approach in which a common prior distribution is learned from related experiments. It does not require a global training stage and thus can incrementally incorporate new data. We report results based on two data sets, the neuters-21578 text data set and a data base of user opionions on art images. For both data sets, collaborative ensemble achieved excellent performance in terms of recommendation accuracy. In addition to recommendation engines, collaborative ensemble learning is applicable to problems typically solved via classical hierarchical Bayes, like multisensor fusion and multitask learning.

#index 1673053
#* An importance sampling algorithm based on evidence pre-propagation
#@ Changhe Yuan;Marek J. Druzdzel
#t 2002
#c 12
#% 44876
#% 68244
#% 136358
#% 322028
#% 374580
#% 527664
#% 527691
#% 857454
#% 1271825
#% 1650318
#% 1848680
#! Precision achieved by stochastic sampling algorithms for Bayesian networks typically deteriorates in face of extremely unlikely evidence. To address this problem, we propose the Evidence Pre-propagation Importance Sampling algorithm (EPIS-BN), an importance sampling algorithm that computes an approximate importance function using two techniques: loopy belief propagation [19, 25] and ε-cutoff heuristic [2]. We tested the performance of EPIS-BN on three large real Bayesian networks: ANDES [3], CPCS [21], and PATHFINDER[11]. We observed that on each of these networks the EPIS-BN algorithm outperforms AISBN [2], the current state of the art algorithm, while avoiding its costly learning stage.

#index 1673054
#* Strong faithfulness and uniform consistency in causal inference
#@ Jiji Zhang;Peter Spirtes
#t 2002
#c 12
#% 44876
#% 297171
#% 1650674
#% 1650807
#! A fundamental question in causal inference is whether it is possible to reliably infer manipulation effects from observational data. There are a variety of senses of asymptotic reliability in the statistical literature, among which the most commonly discussed frequentist notions are pointwise consistency and uniform consistency (see, e.g. Bickel, Doksum [2001]). Uniform consistency is in general preferred to pointwise consistency because the former allows us to control the worst case error bounds with a finite sample size. In the sense of pointwise consistency, several reliable causal inference algorithms have been constructed under the Markov and Faithfulness assumptions [Pearl 2000, Spirtes et al. 2001]. In the sense of uniform consistency, however, reliable causal inference is impossible under the two assumptions when time order is unknown and/or latent confounders are present [Robins et al. 20001. In this paper we present two natural generalizations of the Faithfulness assumption in the context of structural equation models, under which we show that the typical algorithms in the literature (in some cases with modifications) are uniformly consistent even when the time order is unknown. We also discuss the situation where latent confounders may be present and the sense in which the Faithfulness assumption is a limiting case of the stronger assumptions.

