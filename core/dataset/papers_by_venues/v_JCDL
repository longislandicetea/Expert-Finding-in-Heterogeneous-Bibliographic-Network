#index 337223
#* Proceedings of the 1st ACM/IEEE-CS joint conference on Digital libraries
#@ Edward A. Fox;Christine L. Borgman
#t 2001
#c 14

#index 337225
#* Integrating automatic genre analysis into digital libraries
#@ Andreas Rauber;Alexander Müller-Kögler
#t 2001
#c 14
#% 67565
#% 234978
#% 281461
#% 528046
#% 633555
#% 746867
#% 756232
#% 1860651
#! With the number and types of documents in digital library systems incr easing, tools for automatically organizing and presenting the content have to be found. While many approaches focus on topic-based organization and structuring, hardly any system incorporates automatic structural analysis and representation. Yet, genre information (unconsciously) forms one of the most distinguishing features in conventional libraries and in information searches. In this paper we present an approach to automatically analyze the structure of documents and to integrate this information into an automatically created content-based organization. In the resulting visualization, documents on similar topics, yet representing different genres, are depicted as books in differing colors. This representation supports users intuitively in locating relevant information presented in a relevant form.

#index 337226
#* Text categorization for multi-page documents: a hybrid naive Bayes HMM approach
#@ Paolo Frasconi;Giovanni Soda;Alessandro Vullo
#t 2001
#c 14
#% 44876
#% 165111
#% 169717
#% 190074
#% 225837
#% 232653
#% 311027
#% 363592
#% 376266
#% 380725
#% 420055
#% 420495
#% 458379
#% 465747
#% 465754
#% 466263
#% 476708
#% 493639
#% 531459
#% 647276
#% 677431
#! Text categorization is typically formulated as a concept learning prob lem where each instance is a single isolated document. In this paper we are interested in a more general formulation where documents are organized as page sequences, as naturally occurring in digital libraries of scanned books and magazines. We describe a method for classifying pages of sequential OCR text documents into one of several assigned categories and suggest that taking into account contextual information provided by the whole page sequence can significantly improve classification accuracy. The proposed architecture relies on hidden Markov models whose emissions are bag-of-words according to a multinomial word event model, as in the generative portion of the Naive Bayes classifier. Our results on a collection of scanned journals from the Making of America project confirm the importance of using whole page sequences. Empirical evaluation indicates that the error rate (as obtained by running a plain Naive Bayes classifier on isolated page) can be roughly reduced by half if contextual information is incorporated.

#index 337227
#* Automated name authority control
#@ James W. Warnner;Elizabeth W. Brown
#t 2001
#c 14
#% 748550
#! This paper describes a system for the automated assignment of authoriz ed names. A collaboration between a computer scientist and a librarian, the system provides for enhanced end-user searching of digital libraries without increasing drastically the cost and effort of creating a digital library. It is a part of the workflow management system of the Levy Sheet Music Project.

#index 337228
#* Automatic event generation from multi-lingual news stories
#@ Kin Hui;Wai Lam;Helen M. Meng
#t 2001
#c 14
#% 196896
#! We propose a novel approach for automatic generation of topically-rela ted events from multi-lingual news sources. Named entity terms are extracted automatically from the news content. Together with the content terms, they constitute the basis of representing the story. We employ transformation-based linguistic tagging approach for named entity extraction. Two methods of gross translation on Chinese story representation into English have been implemented. The first approach uses only a bilingual dictionary. The second method makes use of a parallel corpus as an additional resource. Unsupervised learning is employed to discover the events.

#index 337229
#* Linked active content: a service for digital libraries for education
#@ David Yaron;D. Jeff Milton;Rebecca Freeland
#t 2001
#c 14
#! A service is described to help enable digital libraries for education, such as the NSDL, to serve as collaboration spaces for the creation, modification and use of active learning experiences. The goal is to redefine the line between those activities that fall within the domain of computer programming and those that fall within the domain of content authoring. The current location of this line, as defined by web technologies, is such that far too much of the design and development process is in the domain of software creation. This paper explores the definition and use of “linked active content”, which builds on the hypertext paradigm by extending it to support active content. This concept has community development advantages, since it provides an authoring paradigm that supports contributions from a more diverse audience, including especially those who have substantial classroom and pedagogical expertise but lack programming expertise. It also promotes the extraction of content from software so that collections may be better organized and more easily repurposed to meet the needs of a diverse audience of educators and students.

#index 337230
#* A component repository for learning objects: a progress report
#@ Jean R. Laleuf;Anne Morgan Spalter
#t 2001
#c 14
#% 187900
#% 211742
#% 234527
#% 279934
#% 307039
#% 603587
#% 966671
#! We believe that an important category of SMET digital library content will be highly interactive, explorable microworlds for teaching science, mathematics, and engineering concepts. Such environments have proved extraordinarily time-consuming and difficult to produce, however, threatening the goals of widespread creation and use. One proposed solution for accelerating production has been the creation of repositories of reusable software components or learning objects. Programmers would use such components to rapidly assemble larger-scale environments. Although many agree on the value of this approach, few repositories of such components have been successfully created. We suggest some reasons for the lack of expected results and propose two strategies for developing such repositories. We report on a case study that provides a proof of concept of these strategies. repositories. We report on a case study that provides a proof of concept of these strategies. contributions from a more diverse audience, including especially those who have substantial classroom and pedagogical expertise but lack programming expertise. It also promotes the extraction of content from software so that collections may be better organized and more easily repurposed to meet the needs of a diverse audience of educators and students.

#index 337231
#* Designing e-books for legal research
#@ Catherine C. Marshall;Morgan N. Price;Gene Golovchinsky;Bill N. Schilit
#t 2001
#c 14
#% 127574
#% 127861
#% 167561
#% 173771
#% 201746
#% 240744
#% 247296
#% 247297
#% 249090
#% 280809
#% 281359
#% 301217
#% 301243
#% 438039
#% 1134773
#! In this paper we report the findings from a field study of legal resea rch in a first-tier law school and on the resulting redesign of XLibris, a next-generation e-book. We first characterize a work setting in which we expected an e-book to be a useful interface for reading and otherwise using a mix of physical and digital library materials, and explore what kinds of reading-related functionality would bring value to this setting. We do this by describing important aspects of legal research in a heterogeneous information environment, including mobility, reading, annotation, link following and writing practices, and their general implications for design. We then discuss how our work with a user community and an evolving e-book prototype allowed us to examine tandem issues of usability and utility, and to redesign an existing e-book user interface to suit the needs of law students. The study caused us to move away from the notion of a stand-alone reading device and toward the concept of a document laptop, a platform that would provide wireless access to information resources, as well as support a fuller spectrum of reading-related activities.

#index 337232
#* The open archives initiative (panel session): perspectives on metadata harvesting
#@ James B. Lloyd;Tim Cole;Donald Waters;Caroline Arms;Simeon Warner;Jeffrey Young
#t 2001
#c 14
#! The Open Archives Initiative [www.openarchives.org] has developed a me tadata harvesting protocol to further its aim of efficient dissemination of content through interoperability standards. In early 2001, at meetings in the U.S. and Europe, the version of the protocol to be used for beta testing was announced. The HTTP-based protocol uses URLs for queries and XML for responses. The default metadata record structure is unqualified Dublin Core using a specified XML Schema. This simple metadata record form is intended to support cross-domain discovery; other record structures for which XML Schemas are defined can also be made available. Developments during the beta test should include the creation of OAI-compliant repositories (data providers) and harvesters (service providers). This panel will explore the purpose and evolution of the Open Archives Initiative from the point of view of various stakeholders, with emphasis on developments during 2001.

#index 337233
#* Mapping the interoperability landscape for networked information retrieval
#@ William E. Moen
#t 2001
#c 14
#% 245815
#! Interoperability is a fundamental challenge for networked information discovery and retrieval. Often treated monolithically in the literature, interoperability is multifaceted and can be analyzed into different types and levels. This paper discusses an approach to map the interoperability landscape for networked information retrieval as part of an interoperability assessment research project.

#index 337234
#* Distributed resource discovery: using z39.50 to build cross-domain information servers
#@ Ray R. Larson
#t 2001
#c 14
#% 109209
#% 194246
#% 230433
#% 262063
#% 262065
#% 287216
#% 329094
#! This short paper describes the construction and application of Cross-D omain Information Servers using features of the standard Z39.50 information retrieval protocol[11]. We use the Z39.50 Explain Database to determine the databases and indexes of a given server, then use the SCAN facility to extract the contents of the indexes. This information is used to build “collection documents” that can be retrieved using probabilistic retrieval algorithms.

#index 337235
#* The open archives initiative: building a low-barrier interoperability framework
#@ Carl Lagoze;Herbert Van de Sompel
#t 2001
#c 14
#% 185259
#% 245815
#% 273914
#% 281337
#% 647304
#% 648866
#% 649139
#! The Open Archives Initiative (OAI) develops and promotes interoperabil ity solutions that aim to facilitate the efficient dissemination of content. The roots of the OAI lie in the E-Print community. Over the last year its focus has been extended to include all content providers. This paper describes the recent history of the OAI - its origins in promoting E-Prints, the broadening of its focus, the details of its technical standard for metadata harvesting, the applications of this standard, and future plans.

#index 337236
#* Enforcing interoperability with the open archives initiative repository explorer
#@ Hussein Suleman
#t 2001
#c 14
#! The Open Archives Initiative (OAI) is an organization dedicated to sol ving problems of digital library interoperability by defining simple protocols, most recently for the exchange of metadata. The success of such an activity requires vigilance in specification of the protocol as well as standardization of implementation. The lack of standardized implementation is a substantial barrier to interoperability in many existing client/server protocols. To avoid this pitfall we developed the Repository Explorer, a tool that supports manual and automated protocol testing. This tool has a significant impact on simplifying development of interoperability interfaces and increasing the level of confidence of early adopters of the technology, thus exemplifying the positive impact of exhaustive testing and quality assurance on interoperability ventures.

#index 337237
#* Arc: an OAI service provider for cross-archive searching
#@ Xiaoming Liu;Kurt Maly;Mohammad Zubair;Michael L. Nelson
#t 2001
#c 14
#! The usefulness of the many on-line journals and scientific digital lib raries that exist today is limited by the lack of a service that can federate them through a unified interface. The Open Archive Initiative (OAI) is one major effort to address technical interoperability among distributed archives. The objective of OAI is to develop a framework to facilitate the discovery of content in distributed archives. In this paper, we describe our experience and lessons learned in building Arc, the first federated searching service based on the OAI protocol. Arc harvests metadata from several OAI compliant archives, normalizes them, and stores them in a search service based on a relational database (MySQL or Oracle). At present we have over 165K metadata records from 16 data providers from various domains.

#index 337238
#* Measuring the reputation of web sites: a preliminary exploration
#@ Greg Keast;Elaine G. Toms;Joan Cherry
#t 2001
#c 14
#% 281251
#% 290830
#% 309868
#! We describe the preliminary results from a pilot study, which assessed the perceived reputation - authority and trustworthiness - of the output from five WWW indexing/ranking tools. The tools are based on three techniques: external link structures, internal content, or human selection/indexing. Twenty-two participants reviewed the output from each tool and assessed the reputation of the retrieved sites.

#index 337239
#* Personalized spiders for web search and analysis
#@ Michael Chau;Daniel Zeng;Hinchun Chen
#t 2001
#c 14
#% 3621
#% 109213
#% 115478
#% 159108
#% 161754
#% 162452
#% 201992
#% 218992
#% 218994
#% 234978
#% 268087
#% 281186
#% 281251
#% 282939
#% 295520
#% 301234
#% 917574
#! Searching for useful information on the World Wide Web has become incr easingly difficult. While Internet search engines have been helping people to search on the web, low recall rate and outdated indexes have become more and more problematic as the web grows. In addition, search tools usually present to the user only a list of search results, failing to provide further personalized analysis which could help users identify useful information and comprehend these results. To alleviate these problems, we propose a client-based architecture that incorporates noun phrasing and self-organizing map techniques. Two systems, namely CI Spider and Meta Spider, have been built based on this architecture. User evaluation studies have been conducted and the findings suggest that the proposed architecture can effectively facilitate web search and analysis.

#index 337240
#* Salticus: guided crawling for personal digital libraries
#@ Robin Burke
#t 2001
#c 14
#% 268081
#% 281251
#% 424292
#! In this paper, we describe Salticus, a web crawler that learns from us ers web browsing activity. Salticus enables users to build a personal digital library by collecting documents and generalizing over the user's choices.

#index 337241
#* Different cultures meet (panel session): lessons learned in global digital library development
#@ Ching Chen;Wen Gao;Hsueh-hua Chen;Li-Zhu Zhou;Von-Wun Soo
#t 2001
#c 14
#! This panel is organized to share the experience gained and lessons lea rned in developing cutting-edge technology applications and digital libraries when different cultures meet together. “Culture”ù is interpreted in different ways and different context. This include the interdisciplinary collaboration among professionals from different fields with their own cultures -- such as library/information science, computer science, humanities, social sciences, science and technology, etc; to more globally as experienced in major international collaborative projects involving R&D professionals from two or more different cultures -- the East and the West, or the North and the South.The moderator will share her own personal perspective on the true meaning of global and interdisciplinary collaboration, drawing upon experiences gained in conducting numerous technology related R&D activities throughout the years, starting from her award winning multimedia project on the First Emperor of China1 and his 7000 magnificent terracotta warriors and horses, supported by the National Endowment for the Humanities in the mid-1980s to her recent (since May 2000) and challenging NSFs International Digital Library Project (IDLP) called Chinese Memory Net (CMNet): US-Sino Collaborative Research Toward Global Digital Library, culminating the community building experiences at NIT conferences with many participants of JCDL from over 15 countries at the NIT 2001 in Beijing, China during May 29-31, 2001. CMNets US affiliates include academic researchers from several universities, including Drexel University, Kent State University, Syracuse University, University of Kentucky, and University of Wisconsin-Milwaukee. Its collaborators in Beijing include Peking University and Tsinghua University, in Shanghai include the Shanghai Jiaotong University, and in Taipei including National Taiwan University, National Tsinghua University, and the Academia Sinica. Several collaborato

#index 337242
#* Power to the people: end-user building of digital library collections
#@ Ian H. Witten;David Bainbridge;Stefan J. Boddie
#t 2001
#c 14
#% 236033
#% 290703
#% 301247
#% 301263
#% 303395
#% 495937
#% 588087
#! Naturally, digital library systems focus principally on the reader: th e consumer of the material that constitutes the library. In contrast, this paper describes an interface that makes it easy for people to build their own library collections. Collections may be built and served locally from the user's own web server, or (given appropriate permissions) remotely on a shared digital library host. End users can easily build new collections styled after existing ones from material on the Web or from their local files-or both, and collections can be updated and new ones brought on-line at any time. The interface, which is intended for non-professional end users, is modeled after widely used commercial software installation packages. Lest one quail at the prospect of end users building their own collections on a shared system, we also describe an interface for the administrative user who is responsible for maintaining a digital library installation.

#index 337243
#* Web-based scholarship: annotating the digital library
#@ Bruce Rosenstock;Michael Gertz
#t 2001
#c 14
#% 479337
#% 535998
#% 673710
#! The DL offers the possibility of collaborative scholarship, but the ap propriate tools must be integrated within the DL to serve this purpose. We propose a Web-based tool to guide controlled data annotations that link items in the DL to a domain-specific ontology and which provide an effective means to query a data collection in an abstract and uniform fashion.

#index 337244
#* A multi-view intelligent editor for digital video libraries
#@ Brad A. Myers;Juan P. Casares;Scott Stevens;Laura Dabbish;Dan Yocum;Albert Corbett
#t 2001
#c 14
#% 57043
#% 96346
#% 126467
#% 127587
#% 151347
#% 152010
#% 173625
#% 173678
#% 175248
#% 190648
#% 194009
#% 219843
#% 220097
#% 236047
#% 237288
#% 262223
#% 297559
#% 316160
#% 435932
#% 438054
#% 582007
#! Silver is an authoring tool that aims to allow novice users to edit di gital video. The goal is to make editing of digital video as easy as text editing. Silver provides multiple coordinated views, including project, source, outline, subject, storyboard, textual transcript and timeline views. Selections and edits in any view are synchronized with all other views. A variety of recognition algorithms are applied to the video and audio content and then are used to aid in the editing tasks. The Informedia Digital Library supplies the recognition algorithms and metadata used to support intelligent editing, and Informedia also provides search and a repository. The metadata includes shot boundaries and a time-synchronized transcript, which are used to support intelligent selection and intelligent cut/copy/paste.

#index 337245
#* VideoGraph: a new tool for video mining and classification
#@ Jia-Yu Pan;Christos Faloutsos
#t 2001
#c 14
#% 201893
#% 239699
#% 438054
#% 637522
#! This paper introduces Videograph, a new tool for video mining and visu alizing the structure of the plot of a video sequence. The main idea is to &lquo;stitch&rquo; together similar scenes which are apart in time. We give a fast algorithm to do stitching and we show case studies, where our approach (a) gives good features for classification (91\% accuracy), and (b) results in Videographs which reveal the logical structure of the plot of the video clips.

#index 337246
#* The Alexandria digital earth prototype
#@ Terence R. Smith;Greg Janee;James Frew;Anita Coleman
#t 2001
#c 14
#! This note summarizes the system development activities of the Alexandr ia Digital Earth Prototype (ADEPT) Project.5 ADEPT and the Alexandria Digital Library (ADL) are, respectively, the research and operational components of the Alexandria Digital Library Project. The goal of ADEPT is to build a distributed digital library (DL) of personalized collections of geospatially referenced information. This DL is characterized by: (1) services for building, searching, and using personalized collections; (2) collections of georeferenced multimedia information, including dynamic simulation models of spatially distributed processes; and (3) user interfaces employing the concept of a “Digital Earth”. Important near-term objectives for ADEPT are to build prototype collections that support undergraduate learning in physical, human, and cultural geography and related disciplines, and then to evaluate whether using such resources helps students learn to reason scientifically. Collections and services developed by ADEPT researchers will migrate to ADL as they mature.

#index 337247
#* Iscapes: digital libraries environments for the promotion of scientific thinking by undergraduates in geography
#@ Anne J. Gilliland-Swetland;Gregory L. Leazer
#t 2001
#c 14
#! This paper reviews considerations associated with implementing the Ale xandria Digital Earth Prototype (ADEPT) in undergraduate geography education by means of Iscapes (or Information landscapes). In particular, we are interested in how Iscapes might be used to promote scientific thinking by undergraduate students. Based upon an ongoing educational needs assessment, we present a set of conceptual principles that might selectively be implemented in the design of educational digital library environments.

#index 337248
#* Project ANGEL: an open virtual learning envoronment with sophisticated access management
#@ John MacColl
#t 2001
#c 14
#! This paper describes a new project funded in the UK by the Joint Infor mation Systems Committee, to develop a virtual learning environment which combines a new awareness of internet sources such as bibliographic databases and full-text electronic journals with a sophisticated access management component which permits single sign-on authentication.

#index 337249
#* NBDL: a CIS framework for NSDL
#@ Joe Futrelle;Su-Shing Chen;Kevin C. Chang
#t 2001
#c 14
#% 480476
#! In this paper, we describe the NBDL (National Biology Digital Library) project, one of the six CIS (Core Integration System) projects of the NSF NSDL (National SMETE Digital Library) Program.

#index 337250
#* Automatic identification and organization of index terms for interactive browsing
#@ Nina Wacholder;Dvid K. Evans;Judith L. Klavans
#t 2001
#c 14
#% 27049
#% 177571
#% 210985
#% 211043
#% 232717
#% 237338
#% 295520
#% 303395
#% 313718
#% 326247
#% 364260
#% 742103
#% 742439
#% 742502
#% 748700
#% 817955
#! The potential of automatically generated indexes for information acces s has been recognized for several decades (e.g., Bush 1945 [2], Edmundson and Wyllys 1961 [4]), but the quantity of text and the ambiguity of natural language processing have made progress at this task more difficult than was originally foreseen. Recently, a body of work on development of interactive systems to support phrase browsing has begun to emerge (e.g., Anick and Vaithyanathan 1997 [1], Gutwin et al. [10], Nevill-Manning et al. 1997 [17], Godby and Reighart 1998 [9]). In this paper, we consider two issues related to the use of automatically identified phrases as index terms in a dynamic text browser (DTB), a user-centered system for navigating and browsing index terms: 1) What criteria are useful for assessing the usefulness of automatically identified index terms? and 2) Is the quality of the terms identified by automatic indexing such that they provide useful access to document content? The terms that we focus on have been identified by LinkIT, a software tool for identifying significant topics in text [7]. Over 90% of the terms identified by LinkIT are coherent and therefore merit inclusion in the dynamic text browser. Terms identified by LinkIT are input to Intell-Index, a prototype DTB that supports interactive navigation of index terms. The distinction between phrasal heads (the most important words in a coherent term) and modifiers serves as the basis for a hierarchical organization of terms. This linguistically motivated structure helps users to efficiently browsing and disambiguate terms. We conclude that the approach to information access discussed in this paper is very promising, and also that there is much room for further research. In the meantime, this research is a contribution to the establishment of a solid foundation for assessing the usability of terms in phrase browsing applications.

#index 337251
#* Digital library collaborations in a world community
#@ David Fulker;Sharon Dawes;Leonid Kalinichenko;Tamara Sumner;Constantino Thanos;Alex Ushakov
#t 2001
#c 14
#! Digital libraries and their user communities are increasingly internat ional in nature. However - though technological progress and global education have brought American and European communities closer - cross-cultural and other crosscutting issues impede the formation of &lquo;world community&rquo; on larger scales. The pertinent issues include: collaboration in the presence of language and cultural barriers, international copyrights, international revenue streams, and universal access. This panel will examine notions of “community” from a variety of theoretical and practical perspectives, and discuss lessons that can be gleaned from applications of the community concept. Topics are expected to include scalability, sustainability, regenerative cycles in healthy communities, and examples of digital-library efforts that have international potential or implications.

#index 337252
#* Public use of digital community information sstems: findings from a recent study with implications for system design
#@ Karen E. Pettigrew;Joan C. Durrance
#t 2001
#c 14
#% 137469
#% 157693
#% 204603
#% 230448
#% 291919
#% 298151
#% 307586
#% 353397
#% 355398
#! The Internet has considerably empowered libraries and changed common p erception of what they entail. Public libraries, in particular, are using technological advancements to expand their range of services and enhance their civic roles. Providing community information (CI) in innovative, digital forms via community networks is one way in which public libraries are facilitating everyday information needs. These networks have been lauded for their potential to strengthen physical communities through increasing information flow about local services and events, and through facilitating civic interaction. However, little is known about how the public uses such digital services and what barriers they encounter. This paper presents findings about how digital CI systems benefit physical communities based on extensive case studies in three states. At each site, rich data were collected using online surveys, field observation, in-depth interviews and focus groups with Internet users, human service providers and library staff. Both the online survey and the follow-up interviews with respondents were based on sense-making theory. In our paper we discuss our findings regarding: (1) how the public is using digital CI systems for daily problem solving, and (2) the types of barriers they encounter. Suggestions for improving digital CI systems are provided.

#index 337253
#* Evaluating the distributed national electronic resource
#@ Peter Brophy;Shelagh Fisher
#t 2001
#c 14
#! The UKs development of a Distributed National Electronic Resource (DNE R) is being subjected to intensive formative evaluation by a multi-disciplinary team. In this paper the Project Director reports on initial actions designed to characterise the DNER from multi-stakeholder perspectives.

#index 337254
#* Collaborative design with use case scenarios
#@ Lynne Davis;Melissa Dawe
#t 2001
#c 14
#! Digital libraries, particularly those with a community-based governanc e structure, are best designed in a collaborative setting. In this paper, we compare our experience using two design methods: a Task-centered method that draws upon a group's strength for eliciting and formulating tasks, and a Use Case method that tends to require a focus on defining an explicit process for tasks. We discuss how these methods did and did not work well in a collaborative setting.

#index 337255
#* Human evaluation of Kea, an automatic keyphrasing system
#@ Steve Jones;Gordon W. Paynter
#t 2001
#c 14
#% 109190
#% 232717
#% 246831
#% 260001
#% 276155
#% 280841
#% 281186
#% 281375
#% 281396
#% 281480
#% 295520
#% 301263
#% 303395
#% 420487
#% 438055
#% 445166
#% 495937
#% 1783134
#! This paper describes an evaluation of the Kea automatic keyphrase extr action algorithm. Tools that automatically identify keyphrases are desirable because document keyphrases have numerous applications in digital library systems, but are costly and time consuming to manually assign. Keyphrase extraction algorithms are usually evaluated by comparison to author-specified keywords, but this methodology has several well-known shortcomings. The results presented in this paper are based on subjective evaluations of the quality and appropriateness of keyphrases by human assessors, and make a number of contributions. First, they validate previous evaluations of Kea that rely on author keywords. Second, they show Kea's performance is comparable to that of similar systems that have been evaluated by human assessors. Finally, they justify the use of author keyphrases as a performance metric by showing that authors generally choose good keywords.

#index 337256
#* Community design of DLESE's collections review policy: a technological frames analysis
#@ Michael Khoo
#t 2001
#c 14
#% 177474
#% 185274
#% 237329
#% 237336
#% 301245
#% 301271
#% 448979
#! In this paper, I describe the design of a collection review policy for the Digital Library for Earth System Education (DLESE). A distinctive feature of DLESE as a digital library is the &lquo;DLESE community&rquo;, composed of voluntary members who contribute metadata and resource reviews to DLESE. As the DLESE community is open, the question of how to evaluate community contributions is a crucial part of the review policy design process. In this paper, technological frames theory is used to analyse this design process by looking at how the designers work with two differing definitions of the &lquo;peer reviewer&rquo;, (a) peer reviewer as arbiter or editor, and (b) peer reviewer as colleague. Content analysis of DLESE documents shows that these frames can in turn be related to two definitions that DLESE offers of itself: DLESE as a library, and DLESE as a digital artifact. The implications of the presence of divergent technological frames for the design process are summarised, and some suggestions for future research are outlined.

#index 337257
#* Legal deposit of digital publications: a review of research and development activity
#@ Adrienne Muir
#t 2001
#c 14
#% 356167
#% 504882
#! There is a global trend towards extending legal deposit to include dig ital publications in order to maintain comprehensive national archives. However, including digital publications in legal deposit regulation is not enough to ensure the long-term preservation of these publications. Concepts, principles and practices accepted and understood in the print environment, may have new meanings or no longer be appropriate in a networked environment. Mechanisms for identifying, selecting and depositing digital material either do not exist, or are inappropriate, for some kinds of digital publication. Work on developing digital preservation strategies is at an early stage. National and other deposit libraries are at the forefront of research and develop in this area, often working in partnership with other libraries, publishers and technology vendors. Most work is of a technical nature. There is some work on developing policies and strategies for managing digital resources. However, not all management issues or users needs are being addressed.

#index 337258
#* Comprehensive access to printed materials (CAPM)
#@ G. Sayeed Choudhury;Mark Lorie;Erin Fitzpatrick;Ben Hobbs;Greg Chirikjian;Allison Okamura;Nicholas E. Flores
#t 2001
#c 14
#! The CAPM Project features the development and evaluation of an automat ed, robotic on-demand scanning system for materials at remote locations. To date, we have developed a book retrieval robot and a valuation analysis framework for evaluating CAPM. We intend to augment CAPM by exploring approaches for automated page turning and improved valuation. These extensions will results in a more fully automated CAPM system and a valuation framework that will not only be useful for assessing CAPM specifically, but also for library services and functions generally.

#index 337259
#* Technology and values: lessons from central and eastern Europe
#@ Nadia Caidi
#t 2001
#c 14
#% 301982
#! Technology does not develop independently of its social context. Rathe r, there is a range of social, cultural and economic factors (in addition to technical factors) that define the parameters for the development and use of technologies. This paper presents a case study of the social shaping of one aspect of digital libraries, the development of national union catalogs (NUC), in four countries of Central and Eastern Europe (CEE). It examines the specific choices and values that are embedded in the design of a NUC, and how these might be transferred to other cultural contexts.

#index 337260
#* A digital strategy for the Library of Congress
#@ Alan Inouye;Margaret Hedstrom;Dale Flecker;David Levy
#t 2001
#c 14
#! Digital libraries challenge the core practices of libraries and archiv es in many respects, not only in terms of accommodating digital information and technology, but also through the need to develop new economic and organizational models. As the world's largest library, the Library of Congress (LC) perhaps faces the most profound questions of how to collect, catalog, preserve, and provide access to digital resources. LC asked the Computer Science and Telecommunications Board of the National Academies for advice in this area by commissioning the study that culminated with the publication of LC21: A Digital Strategy for the Library of Congress. The panelists at this session will provide a brief summary of the LC21 report, review developments subsequent to the publication of LC21, and offer their thoughts on how the library community and information industry could engage LC to the benefit of the nation.

#index 337261
#* Use of multiple digital libraries: a case study
#@ Ann Blandford;Hanna Stelmaszewska;Nick Bryan-Kinns
#t 2001
#c 14
#% 142350
#% 152251
#% 190221
#% 247295
#% 247296
#% 249137
#% 249142
#% 281359
#% 281363
#% 281398
#% 303395
#! The aim of the work reported here was to better understand the usabili ty issues raised when digital libraries are used in a natural setting. The method used was a protocol analysis of users working on a task of their own choosing to retrieve documents from publicly available digital libraries. Various classes of usability difficulties were found. Here, we focus on use in context - that is, usability concerns that arise from the fact that libraries are accessed in particular ways, under technically and organisationally imposed constraints, and that use of any particular resource is discretionary. The concepts from an Interaction Framework, which provides support for reasoning about patterns of interaction between users and systems, are applied to understand interaction issues.

#index 337262
#* An ethnographic study of technical support workers: why we didn't build a tech support digital library
#@ Sally Jo Cunningham;Chris Knowles;Nina Reeves
#t 2001
#c 14
#% 60635
#% 185274
#% 199528
#% 201993
#% 202036
#% 237318
#% 237336
#% 245240
#% 294880
#% 328525
#% 635053
#! In this paper we describe the results of an ethnographic study of the information behaviourss of university technical support workers and their information needs. The study looked at how the group identified, located and used information from a variety of sources to solve problems arising in the course of their work. The results of the investigation are discussed in the context of the feasibility of developing a potential information base that could be used by all members of the group. Whilst a number of their requirements would easily be fulfilled by the use of a digital library, other requirements would not. The paper illustrates the limitations of a digital library with respect to the information behaviourss of this group of subjects and focuses on why a digital library would not appear to be the ideal support tool for their work.

#index 337265
#* Developing recommendation services for a digital library with uncertain and changing data
#@ Gary Geisler;David McArthur;Sarah Giersch
#t 2001
#c 14
#% 220706
#% 301259
#! In developing recommendation services for a new digital library called iLumina (www.ilumina-project.org), we are faced with several challenges related to the nature of the data we have available. The availability and consistency of data associated with iLumina is likely to be highly variable. Any recommendation strategy we develop must be able to cope with this fact, while also being robust enough to adapt to additional types of data available over time as the digital library develops. In this paper we describe the challenges we are faced with in developing a system that can provide our users with good, consistent recommendations under changing and uncertain conditions.

#index 337269
#* Evaluation of DEFINDER: a system to mine definitions from consumer-oriented medical text
#@ Judith L. Klavans;Smaranda Muresan
#t 2001
#c 14
#% 337479
#% 786497
#! In this paper we present DEFINDER, a rule-based system that mines cons umer-oriented full text articles in order to extract definitions and the terms they define. This research is part of Digital Library Project at Columbia University, entitled PERSIVAL (PErsonalized Retrieval and Summarization of Image, Video and Language resources) [5]. One goal of the project is to present information to patients in language they can understand. A key component of this stage is to provide accurate and readable lay definitions for technical terms, which may be present in articles of intermediate complexity. The focus of this short paper is on quantitative and qualitative evaluation of the DEFINDER system [3]. Our basis for comparison was definitions from Unified Medical Language System (UMLS), On-line Medical Dictionary (OMD) and Glossary of Popular and Technical Medical Terms (GPTMT). Quantitative evaluations show that DEFINDER obtained 87% precision and 75% recall and reveal the incompleteness of existing resources and the ability of DEFINDER to address gaps. Qualitative evaluation shows that the definitions extracted by our system are ranked higher in terms of user-based criteria of usability and readability than definitions from on-line specialized dictionaries. Thus the output of DEFINDER can be used to enhance existing specialized dictionaries, and also as a key feature in summarizing technical articles for non-specialist users.

#index 337272
#* Overview of the virtual data center project and software
#@ Micah Altman;L. Andreev;M. Diggory;G. King;E. Kolster;A. Sone;S. Verba;Daniel Kiskis;M. Krot
#t 2001
#c 14
#% 294891
#% 367597
#% 388487
#% 647316
#% 647567
#! In this paper, we present an overview of the Virtual Data Center (VDC) software, an open-source digital library system for the management and dissemination of distributed collections of quantitative data. (see ). The VDC functionality provides everything necessary to maintain and disseminate an individual collection of research studies, including facilities for the storage, archiving, cataloging, translation, and on-line analysis of a particular collection. Moreover, the system provides extensive support for distributed and federated collections including: location-independent naming of objects, distributed authentication and access control, federated metadata harvesting, remote repository caching, and distributed virtual collections of remote objects.

#index 337275
#* Digital libraries and data scholarship
#@ Bruce R. Barkstrom
#t 2001
#c 14
#% 978844
#! In addition to preserving and retrieving digital information, digital libraries need to allow data scholars to create post-publication references to objects within files and across collections of files. Such references can serve as new metadata in their own right and should also provide methods for efficiently extracting the subset of the original data that belongs to the object. This paper discusses some ideas about the requirements for such references within the context of long-term, active archival, where neither the data format nor the institutional basis can be guaranteed to remain constant.

#index 337277
#* SDLIP + STARTS = SDARTS a protocol and toolkit for metasearching
#@ Noah Green;Panagiotis G. Ipeirotis;Luis Gravano
#t 2001
#c 14
#% 194246
#% 227891
#% 262063
#% 267454
#% 273914
#% 273926
#% 287463
#% 300153
#% 301225
#% 309783
#% 333932
#% 461915
#% 479642
#% 480476
#! In this paper we describe how we combined SDLIP and STARTS, two comple mentary protocols for searching over distributed document collections. The resulting protocol, which we call SDARTS, is simple yet expressible enough to enable building sophisticated metasearch engines. SDARTS can be viewed as an instantiation of SDLIP with metasearch-specific elements from STARTS. We also report on our experience building three SDARTS-compliant wrappers: for locally available plain-text document collections, for locally available XML document collections, and for external web-accessible collections. These wrappers were developed to be easily customizable for new collections. Our work was developed as part of Columbia University's Digital Libraries Initiative--Phase 2 (DLI2) project, which involves the departments of Computer Science, Medical Informatics, and Electrical Engineering, the Columbia University libraries, and a large number of industrial partners. The main goal of the project is to provide personalized access to a distributed patient-care digital library.

#index 337285
#* Database selection for processing k nearest neighbors queries in distributed environments
#@ Clement Yu;Prasoon Sharma;Weiyi Meng;Yan Qin
#t 2001
#c 14
#% 185258
#% 213981
#% 227894
#% 443556
#% 443561
#% 479623
#% 479642
#% 479816
#% 479967
#% 479984
#% 480125
#% 481748
#! We consider the processing of digital library queries, consisting of a text component and a structured component in distributed environments. The text component can be processed using techniques given in previous papers such as [7, 8, 11]. In this paper, we concentrate on the processing of the structured component of a distributed query. Histograms are constructed and algorithms are given to provide estimates of the desirabilities of the databases with respect to the given query. Databases are selected in descending order of desirability. An algorithm is also given to select tuples from the selected databases. Experimental results are given to show that the techniques provided here are effective and efficient.

#index 337290
#* The president's information technology advisory committee's february 2001 digital library report and its impact
#@ Sally E. Howe;David C. Nagel;Ching-chih Chen;Stephen M. Griffin;James Lightbourne;Walter L. Warnick
#t 2001
#c 14
#! In February 2001 the Panel on Digital Libraries of the Presidents Info rmation Technology Advisory Committee issued a report entitled “Digital Libraries: Universal Access to Human Knowledge”. This JCDL panel, which consists of two members of the PITAC Panel on Digital Libraries and representatives of key Federal science and digital library agencies who had briefed the Panel, will discuss the report's findings and recommendations and how the report is and can be helpful in improving the development and use of digital libraries.

#index 337415
#* Building searchable collections of enterprise speech data
#@ James W. Cooper;Mahesh Viswanathan;Donna Byron;Margaret Chan
#t 2001
#c 14
#% 198294
#% 204668
#% 218978
#% 237340
#% 309207
#% 595987
#% 607942
#% 625410
#% 723473
#! We have applied speech recognition and text-mining technologies to a set of recorded outbound marketing calls and analyzed the results. Since speaker-independent speech recognition technology results in a significantly lower recognition rate than that found when the recognizer is trained for a particular speaker, we applied a number of post-processing algorithms to the output of the recognizer to render it suitable for the Textract text mining system. We indexed the call transcripts using a search engine and used Textract and associated Java technologies to place the relevant terms for each document in a relational database. Following a search query, we generated a thumbnail display of the results of each call with the salient terms highlighted. We illustrate these results and discuss their utility. We took the results of these experiments and continued this analysis on a set of talks and presentations.We describe a distinct document genre based on the note-taking concept of document content, and propose a significant new method for measuring speech recognition accuracy. This procedure is generally relevant to the problem of capturing meetings and talks and providing a searchable index of these presentations on the web.

#index 337418
#* Transcript-free search of audio archives for the national gallery of the spoken word
#@ John H. L. Hansen;J. R. Deller, Jr.;Michael S. Seadle
#t 2001
#c 14
#% 220382
#% 337420
#% 395959
#% 970370
#! The National Gallery of the Spoken Word (NGSW) project is creating a carefully organized on-line repository of spoken-word collections spanning the 20th century. Unprecedented technical challenges are inherent in the development of an archive of such extensive scale and diversity. This paper describes research on the development of text-free search-engine technology used to locate requested content in the audio records. A companion paper in these proceedings addresses watermarking technologies for copyright protection.

#index 337420
#* Audio watermarking techniques for the National Gallery of the Spoken Word
#@ J. R. Deller, Jr.;Aparna Gurijala;Michael S. Seadle
#t 2001
#c 14
#% 337418
#% 971267
#! This is one of two companion papers describing technical challenges faced in the development of the National Gallery of the Spoken Word (NGSW). The present paper describes watermarking technologies for intellectual property protection. Following an introduction to data watermarking, the paper focuses on a new algorithm called \textit{transform encryption coding} (TEC) and its application to watermarking the NGSW archives. TEC has a number of flexible features that make it amenable to the NGSW development.

#index 337422
#* Music-notation searching and digital libraries
#@ Donald Byrd
#t 2001
#c 14
#% 449284
#% 647454
#% 691479
#! Almost all work on music information retrieval to date has concentrate d on music in the audio and event (normally MIDI) domains. However, music in the form of notation, especially Conventional Music Notation (CMN), is of much interest to musically-trained persons, both amateurs and professionals, and searching CMN has great value for digital music libraries. One obvious reason little has been done on music retrieval in CMN form is the overwhelming complexity of CMN, which requires a very substantial investment in programming before one can even begin studying music IR. This paper reports on work adding music-retrieval capabilities to Nightingale©, an existing professional-level music-notation editor.

#index 337423
#* Feature selection for automatic classification of musical instrument sounds
#@ Mingchun Liu;Chunru Wan
#t 2001
#c 14
#% 970452
#! In this paper, we carry out a study on classification of musical instr uments using a small set of features selected from a broad range of extracted ones by sequential forward feature selection method. Firstly, we extract 58 features for each record in the music database of 351 sound files. Then, the sequential forward selection method is adopted to choose the best feature set to achieve high classification accuracy. Three different classification techniques have been tested out and an accuracy of up to 93% can be achieved by using 19 features.

#index 337426
#* Adding content-based searching to a traditional music library catalogue server
#@ Matthew J. Dovey
#t 2001
#c 14
#! Most online music library catalogues can only be searched by textual m etadata. Whilst highly effective - since the rules for maintaining consistency have been refined over many years - this does not allow searching by musical content. Many music librarians are familiar with users humming their enquiries. Most systems providing a “query by humming&r dquo; interface tend to run independently of music library catalogue systems and not offer similar textual metadata searching. This paper discusses the ongoing investigative work on integrating these two types of system conducted as part of the NSF/JISC funded OMRAS project (http://www.omras.org).

#index 337428
#* Locating question difficulty through explorations in question space
#@ Terry Sullivan
#t 2001
#c 14
#! Three different search effectiveness measures were used to classify 50 question narratives as easy or hard. Each measure was then encoded onto a spatial representation of interquestion similarity. Discriminant analysis based on the resulting map was able to predict question difficulty with approximately 80% accuracy, robust across multiple measures. Implications for the design of digital document collections are discussed.

#index 337429
#* Browsing by phrases: terminological information in interactive multilingual text retrieval
#@ Anselmo Peñas;Julio Gonzalo;Felisa Verdejo
#t 2001
#c 14
#% 218992
#% 262047
#% 280840
#% 280841
#% 280849
#! This paper present an interactive search engine (Website Term Browser) which makes use of phrasal information to process queries and suggest relevant topics in a fully multilingual setting.

#index 337432
#* Approximate ad-hoc query engine for simulation data
#@ Ghaleb Abdulla;Chuck Baldwin;Terence Critchlow;Roy Kamimura;Ida Lozares;Ron Musick;Nu Ai Tang;Byung S. Lee;Robert Snapp
#t 2001
#c 14
#% 274152
#% 308500
#% 480306
#! In this paper, we describe AQSim, an ongoing effort to design and impl ement a system to manage terabytes of scientific simulation data. The goal of this project is to reduce data storage requirements and access times while permitting ad-hoc queries using statistical and mathematical models of the data. In order to facilitate data exchange between models based on different representations, we are evaluating using the ASCI common data model that is comprised of several layers of increasing semantic complexity. To support queries over the spatial-temporal mesh structured data we are in the process of defining and implementing a grammar for MeshSQL

#index 337433
#* Extracting taxonomic relationships from on-line definitional sources using LEXING
#@ Judith Klavans;Brian Whitman
#t 2001
#c 14
#% 438368
#% 748501
#! We present a system which extracts the genus word and phrase from free -form definition text, entitled LEXING, for Lexical Information from Glossaries. The extractions will be used to build automatically a lexical knowledge base from on-line domain specific glossary sources. We combine statistical and semantic processes to extract these terms, and demonstrate that this combination allows us to predict the genus even in difficult situations such as empty head definitions or verb definitions. We also discuss the use of “linking prepositions” for use in skipping past empty head genus phrases. This system is part of a project to extract ontological information for energy glossary information.

#index 337435
#* Hierarchical indexing and document matching in BoW
#@ Maayan Geffet;Dror G. Feitelson
#t 2001
#c 14
#% 46803
#% 68536
#% 89358
#% 115462
#% 157894
#% 234793
#% 247486
#% 301261
#% 301263
#% 336784
#% 406493
#% 448781
#% 465747
#% 466078
#% 511922
#% 840583
#% 963890
#! BoW is an on-line bibliographical repository based on a hierarchical c oncept index to which entries are linked. Searching in the repository should therefore return matching topics from the hierarchy, rather than just a list of entries. Likewise, when new entries are inserted, a search for relevant topics to which they should be linked is required. We develop a vector-based algorithm that creates keyword vectors for the set of competing topics at each node in the hierarchy, and show how its performance improves when domain-specific features are added (such as special handling of topic titles and author names). The results of a 7-fold cross validation on a corpus of some 3,500 entries with a 5-level index are hit ratios in the range of 89-95%, and most of the misclassifications are indeed ambiguous to begin with.

#index 337437
#* Scalable integrated region-based image retrieval using IRM and statistical clustering
#@ James Z. Wang;Yanping Du
#t 2001
#c 14
#% 86950
#% 88056
#% 116390
#% 169940
#% 175248
#% 227856
#% 227939
#% 228351
#% 273919
#% 294852
#% 316196
#% 317950
#% 325549
#% 345848
#% 352313
#% 406493
#% 411694
#% 424287
#% 427199
#% 435141
#% 479462
#% 479649
#% 480093
#% 481956
#% 592143
#% 626558
#% 632311
#% 647573
#! Statistical clustering is critical in designing scalable image retriev al systems. In this paper, we present a scalable algorithm for indexing and retrieving images based on region segmentation. The method uses statistical clustering on region features and IRM (Integrated Region Matching), a measure developed to evaluate overall similarity between images that incorporates properties of all the regions in the images by a region-matching scheme. Compared with retrieval based on individual regions, our overall similarity approach (a) reduces the influence of inaccurate segmentation, (b) helps to clarify the semantics of a particular region, and (c) enables a simple querying interface for region-based image retrieval systems. The algorithm has been implemented as a part of our experimental SIMPLIcity image retrieval system and tested on large-scale image databases of both general-purpose images and pathology slides. Experiments have demonstrated that this technique maintains the accuracy and robustness of the original system while reducing the matching time significantly.

#index 337438
#* The national SMETE digital library program (panel session)
#@ Brandon Muramatsu;Cathryn A. Manduca;Marcia Mardis;James H. Lightbourne;Flora P. McMartin
#t 2001
#c 14
#! “To catalyze and support continual improvements in the quality of scien ce, mathematics, engineering, and technology (SMET) education, the National Science Foundation (NSF) has established the National Science, Mathematics, Engineering, and Technology Education Digital Library (NSDL) program. The resulting digital library, a network of learning environments and resources for SMET education, will ultimately meet the needs of students and teachers at all levels-K-12, undergraduate, graduate, and lifelong learning-in both individual and collaborative settings, as well as formal and informal modes.” -National Science Foundation, 2001The national in the NSDL program is quickly becoming a reality with the broad reach of the currently funded projects. This panel session will provide bring together the leaders developing the National SMETE Digital Library to provide a brief background and broad overview of the NSDL program. Panelists will discuss the overall vision and broad steps underway to develop the National SMETE Digital Library. Building the National SMETE Digital Library presents many challenges:Developing a shared vision for the form and function of the NSDL;Meeting the needs of diverse learners and of the many disciplines encompassed by the NSDL;Acquiring input from the community of users to ensure that the NSDL is both used and useable;Evaluating progress and impacts;Integrating technologies that already exist, and the development of new technologies; andProviding mechanisms for sharing and cooperation of knowledge and resources among NSDL collaborators.

#index 337441
#* Cumulating and sharing end users knowledge to improve video indexing in a video digital library
#@ Marc Nanard;Jocelyne Nanard
#t 2001
#c 14
#% 186292
#% 197986
#% 230396
#% 239697
#% 309811
#% 314733
#% 330770
#% 445330
#% 466147
#% 520122
#% 592089
#! In this paper, we focus on a user driven approach to improve video ind exing. It consists in cumulating the large amount of small, individual efforts done by the users who access information, and to provide a community management mechanism to let users share the elicited knowledge. This technique is currently being developed in the “OPALES” environment and tuned up at the “Institut National de l'Audiovisuel&r dquo;(INA), a National Video Library in Paris, to increase the value of its patrimonial video archive collections. It relies on a portal providing private workspaces to end users, so that a large part of their work can be shared between them. The effort for interpreting documents is directly done by the expert users who work for their own job on the archives. OPALES provides an original notion of “point of view” to enable the elicitation and the sharing of knowledge between communities of users, without leading to messy structures. The overall result consists in linking exportable private metadata to archive documents and managing the sharing of the elicited knowledge between users communities. provide bring together the leaders developing the National SMETE Digital Library to provide a brief background and broad overview of the NSDL program. Panelists will discuss the overall vision and broad steps underway to develop the National SMETE Digital Library. Building the National SMETE Digital Library presents many challenges:Developing a shared vision for the form and function of the NSDL;Meeting the needs of diverse learners and of the many disciplines encompassed by the NSDL;Acquiring input from the community of users to ensure that the NSDL is both used and useable;Evaluating progress and impacts;Integrating technologies that already exist, and the development of new technologies; andProviding mechanisms for sharing and cooperation of knowledge and resources among NSDL collaborators.

#index 337444
#* XSLT for tailored access to a digtal video library
#@ Michael G. Christel;Bryan Maher;Andrew Begun
#t 2001
#c 14
#% 137473
#% 247287
#% 286900
#% 434937
#% 434978
#% 438054
#% 568060
#% 584921
#! Surrogates, summaries, and visualizations have been developed and eval uated for accessing a digital video library containing thousands of documents and terabytes of data. These interfaces, formerly implemented within a monolithic stand-alone application, are being migrated to XML and XSLT for delivery through web browsers. The merits of these interfaces are presented, along with a discussion of the benefits in using W3C recommendations such as XML and XSLT for delivering tailored access to video over the web.

#index 337450
#* Design of a digital library for human movement
#@ Jezekiel Ben-Arie;Purvin Pandit;ShyamSundar Rajaram
#t 2001
#c 14
#% 23998
#% 360042
#% 394915
#% 442962
#% 442974
#% 549080
#% 592070
#% 592228
#% 592413
#% 593484
#% 625129
#% 625176
#% 627118
#! This paper is focused on a central aspect in the design of our planned digital library for human movement, i.e. on the aspect of representation and recognition of human activity from video data. The method of representation is important since it has a major impact on the design of all the other building blocks of our system such as the user interface/query block or the activity recognition/storage block. In this paper we evaluate a representation method for human movement that is based on sequences of angular poses and angular velocities of the human skeletal joints, for storage and retrieval of human actions in video databases. The choice of a representation method plays an important role in the database structure, search methods, storage efficiency etc.. For this representation, we develop a novel approach for complex human activity recognition by employing multidimensional indexing combined with temporal or sequential correlation. This scheme is then evaluated with respect to its efficiency in storage and retrieval.For the indexing we use postures of humans in videos that are decomposed into a set of multidimensional tuples which represent the poses/velocities of human body parts such as arms, legs and torso. Three novel methods for human activity recognition are theoretically and experimentally compared. The methods require only a few sparsely sampled human postures. We also achieve speed invariant recognition of activities by eliminating the time factor and replacing it with sequence information. The indexing approach also provides robust recognition and an efficient storage/retrieval of all the activities in a small set of hash tables.

#index 337452
#* A bucket architecture for the open video project
#@ Michael L. Nelson;Gary Marchionini;Gary Geisler;Meng Yang
#t 2001
#c 14
#% 712422
#! The Open Video project is a collection of public domain digital video available for research and other purposes. The Open Video collection currently consists of approximately 350 video segments, ranging in duration from 10 seconds to 1 hour. Rapid growth for the collection is planned through agreements with other video repository projects and provision for user contribution of video. To handle the increased accession, we are experimenting with “buckets”, aggregative intelligent publishing constructs for use in digital libraries.

#index 337454
#* The físchlár digital video system: a digital library of broadcast TV programmes
#@ A. F. Smeaton;N. Murphy;N. E. O'Connor;S. Marlow;H. Lee;K. McDonald;P. Browne;J. Ye
#t 2001
#c 14
#% 308762
#% 971218
#! Físchl& acute;r is a system for recording, indexing, browsing and playback of broadcast TV programmes which has been operational on our University campus for almost 18 months. In this paper we give a brief overview of how the system operates, how TV programmes are organised for browse/playback and a short report on the system usage by over 900 users in our University.

#index 337457
#* Design principles for the information architecture of a SMET education digital library
#@ Andy Dong;Alice M. Agogino
#t 2001
#c 14
#% 262299
#% 275773
#% 405662
#! This implementation paper introduces principles for the informationarchitecture of an educational digital library, principles that address the distinction between designing digital libraries for education and designing digital libraries for information retrieval in general. Design is a key element of any successful product. Good designers and their designs, put technology into the hands of the user, making the products focus comprehensible and tangible through design. As straightforward as this may appear, the design of learning technologies is often masked by the enabling technology. In fact, they often lack an explicitly stated instructional design methodology. While the technologies are important hurdles to overcome, we advocate learning systems that empower education-driven \ experiences rather than technology-driven experiences. This work describes a concept for a digital library for science, mathematics, engineering and technology education (SMETE), a library with an information architecture designed to meet learners and educators needs. Utilizing a constructivist model of learning, the authors present practical approaches to implementing the information architecture and its technology underpinnings. The authors propose the specifications for the information architecture and a visual design of a digital library for communicating learning to the audience. The design methodology indicates that a scenario-driven design technique sensitive to the contextual nature of learning offers a useful framework for tailoring technologies that help empower, not hinder, the educational sector.

#index 337461
#* Toward a model of self-administering data
#@ ByungHoon Kang;Robert Wilensky0
#t 2001
#c 14
#% 230397
#% 240016
#% 256158
#% 337046
#! We describe a model of self-administering data. In this model, adeclarative description of how a data object should behave is attached to the object, either by a user or by a data input device. A widespread infrastructure of self-administering data handlers is presumed to exist; these handlers are responsible for carrying out the specifications attached to the data. Typically, the specifications express how and to whom the data should be transferred, how it should be incorporated when it is received, what rights recipients of the data will have with respect to it, and the kind of relation that should exist between distributed copies of the object. Functions such as distributed version control can be implemented on top of the basic handler functions. We suggest that this model can provide superior support for common cooperative functions. Because the model is declarative, users need only express their intentions once in creating a self-administering description, and need not be concerned with manually performing subsequent repetitious operations. Because the model is peer-to-peer, users are less dependent on additional, perhaps costly resources, at least when these are not critical.An initial implementation of the model has been created. We are experimenting with the model both as a tool to aid in digital library functions, and as a possible replacement for some server oriented functions.

#index 337479
#* PERSIVAL, a system for personalized search and summarization over multimedia healthcare information
#@ Kathleen R. McKeown;Shih-Fu Chang;James Cimino;Steven Feiner;Carol Friedman;Luis Gravano;Vasileios Hatzivassiloglou;Steven Johnson;Desmond A. Jordan;Judith L. Klavans;André Kushniruk;Vimla Patel;Simone Teufel
#t 2001
#c 14
#% 78171
#% 149109
#% 214546
#% 227891
#% 333932
#% 337277
#% 433620
#% 465747
#% 755818
#% 1499571
#! In healthcare settings, patients need access to online information tha t can help them understand their medical situation. Physicians need information that is clinically relevant to an individual patient. In this paper, we present our progress on developing a system, PERSIVAL, that is designed to provide personalized access to a distributed patient care digital library. Using the secure, online patient records at New York Presbyterian Hospital as a user model, PERSIVAL's components tailor search, presentation and summarization of online multimedia information to both patients and healthcare providers.

#index 337480
#* An approach to search for the digital library
#@ Elaine G. Toms;Joan C. Bartlett
#t 2001
#c 14
#% 85443
#% 186518
#% 245840
#! The chief form of accessing the content of a digital library (DL) is i ts search interface. While a DL needs an interface that integrates a range of options from search to browse to serendipity, in this work we focus on analytical search. We propose using Bates' search tactics as a basis for the re-design of search interfaces. We believe this approach will help to identify the types of tools that need to be supported by a DL interface.

#index 337481
#* TilePic: a file format for tiled hierarchical data
#@ Jeff Anderson-Lee;Robert Wilensky
#t 2001
#c 14
#% 674085
#% 706293
#! TilePic is a method for storing tiled data of arbitrary t ype in a hierarchical, indexed format for fast retrieval. It is useful for storing moderately large, static, spatial datasets in a manner that is suitable for panning and zooming over the data, especially in distributed applications. Because different data types may be stored in the same object, TilePic can support semantic zooming as well. It has proven suitable for a wide variety of applications involving the networked access and presentation of images, geographic data, and text. The TilePic format and its supporting tools are unencumbered, and available to all.

#index 337482
#* High tech or high touch (panel session): automation and human mediation in libraries
#@ David Levy;William Arms;Oren Etzioni;Diane Nester;Barbara Tillett
#t 2001
#c 14
#! There are those who now think that traditional library services, such as cataloging and reference, will no longer be needed in the future, or at least will be fully automated. Others are equally adamant that human intervention is not only important but essential. Underlying such positions are a host of assumptions - about the continued existence and place of paper, the role of human intelligence and interpretation, the nature of research, and the significance of the human element. This panel brings together experts in libraries and digital technology to uncover such issues and assumptions and to discuss and debate the place of people and machines in cataloging and reference work.

#index 337483
#* Long term preservation of digital information
#@ Raymond A. Lorie
#t 2001
#c 14
#% 3888
#% 13044
#% 356167
#% 356606
#! The preservation of digital data for the long term presents a variety of challenges from technical to social and organizational. The technical challenge is to ensure that the information, generated today, can survive long term changes in storage media, devices and data formats. This paper presents a novel approach to the problem. It distinguishes between archiving of data files and archiving of programs (so that their behavior may be reenacted in the future).For the archiving of a data file, the proposal consists of specifying the processing that needs to be performed on the data (as physically stored) in order to return the information to a future client (according to a logical view of the data). The process specification and the logical view definition are archived with the data.For the archiving of a program behavior, the proposal consists of saving the original executable object code together with the specification of the processing that needs to be performed for each machine instruction of the original computer (emulation).In both cases, the processing specification is based on a Universal Virtual Computer that is general, yet basic enough as to remain relevant in the future.

#index 337484
#* Creating trading networks of digital archives
#@ Brian Cooper;Hector Garcia
#t 2001
#c 14
#% 3230
#% 43172
#% 86465
#% 107720
#% 118655
#% 131554
#% 210179
#% 213470
#% 225006
#% 337046
#% 462024
#% 462779
#% 464189
#% 584893
#% 595982
#% 978844
#! Digital archives can best survive failures if they have made several c opies of their collections at remote sites. In this paper, we discuss how autonomous sites can cooperate to provide preservation by trading data. We examine the decisions that an archive must make when forming trading networks, such as the amount of storage space to provide and the best number of partner sites. We also deal with the fact that some sites may be more reliable than others. Experimental results from a data trading simulator illustrate which policies are most reliable. Our techniques focus on preserving the ``bits'' of digital collections; other services that focus on other archiving concerns (such as preserving meaningful metadata) can be built on top of the system we describe here.

#index 337486
#* Cost-driven design for archival repositories
#@ Arturo Crespo;Hector Garcia-Molina
#t 2001
#c 14
#% 45840
#% 281337
#% 281346
#% 584893
#! Designing an archival repository is a complex task because there aremany alternative configurations, each with different reliability levels and costs. In this paper we study the costs involved in an Archival Repository and we introduce a design framework for evaluating alternatives and choosing the best configuration in terms of reliability and cost. We also present a new version of our simulation tool, ArchSim/C that aids in the decision process. The design framework and the usage of ArchSim/C are illustrated with a case study of a hypothetical (yet realistic) archival repository shared between two universities.

#index 337487
#* Hermes: a notification service for digital libraries
#@ D. Faensen;L. Faultstich;H. Schweppe;A. Hinze;A. Steidinger
#t 2001
#c 14
#% 237194
#% 244103
#% 248799
#% 272005
#% 300179
#% 454244
#% 464720
#% 466290
#% 466302
#% 978507
#! The high publication rate of scholarly material makes searching and br owsing an inconvenient way to keep oneself up-to-date. Instead of being the active part in information access, researchers want to be notified whenever a new paper in one's research area is published.While more and more publishing houses or portal sites offer notification services this approach has several disadvantages. We introduce the Hermes alerting service, a service that integrates a variety of different information providers making their heterogeneity transparent for the users. Hermes offers sophisticated filtering capabilities preventing the user from drowning in a flood of irrelevant information. From the user's point of view it integrates the providers into a single source. Its simple provider interface makes it easy for publishers to join the service and thus reaching the potential readers directly.This paper presents the architecture of the Hermes service and discusses the issues of heterogeneity of information sources. Furthermore, we discuss the benefits and disadvantages of message-oriented middleware for implementing such a service for digital libraries.

#index 337488
#* An algorithm for automated rating of reviewers
#@ Tracy Riggs;Robert Wilensky
#t 2001
#c 14
#% 124010
#% 220707
#% 220709
#% 220710
#% 280852
#% 282905
#% 301089
#% 301590
#% 657509
#! The current system for scholarly information dissemination may be amen able to significant improvement. In particular, going from the current system of journal publication to one of self-distributed documents offers significant cost and timeliness advantages. A major concern with such alternatives is how to provide the value currently afforded by the peer review system.Here we propose a mechanism that could plausibly supply such value. In the peer review system, papers are judged meritorious if good reviewers give them good reviews. In its place, we propose a collaborative filtering algorithm which automatically rates reviewers, and incorporates the quality of the reviewer into the metric of merit for the paper. Such a system seems to provide all the benefits of the current peer review system, while at the same time being much more flexible.We have implemented a number of parameterized variations of this algorithm, and tested them on data available from a quite different application. Our initial experiments suggest that the algorithm is in fact ranking reviewers reasonably.

#index 337489
#* Digital libraries supporting digital government
#@ Gary Marchionini;Anne Craig;Larry Brandt;Judith Klavans;Hsinchun Chen
#t 2001
#c 14
#! The needs of society have long been addressed through government resea rch support for new technologies-the Internet representing one example. Today, under the rubric of digital government, federal agencies as well as state and local units of governments at all levels have begun to leverage the fruits of these research investments to better serve the needs of their constituencies. Government agencies apply these technologies in a variety of settings including emergency response, health and safety regulation, financial management, data gathering, and hosts of information dissemination needs. In addition, governments are investigating ways to use technology to encourage citizen participation. There is a growing digital government community of practice that strongly parallels the evolving digital library community. These parallel developments are not surprising because libraries and governments share service missions for their overlapping constituencies.Governments at all levels create enormous volumes of information for use by citizens and have long depended on libraries to organize, disseminate, and preserve this public information. There is an inextricable link between democratic government and libraries stemming from the 19th century creation of public libraries as democracys offer to citizens to learn, to grow, and to participate. The idea of sharing knowledge to enable good citizenship engenders many cross-currents inherent in social-political policy, and today this idea is given new incarnation in the global Internet environment. Digital library projects in national and local libraries were in many ways the precursors of digital government initiatives and it is particularly instructive to examine a selection of digital government projects through the lens of digital libraries. This panel presents overviews of several digital government projects and initiatives that combine the technical and conceptual threads composing these mutuall

#index 337490
#* Designing a digital library for young children
#@ Allison Druin;Benjamin B. Bederson;Juan Pablo Hourcade;Lisa Sherman;Glenda Revelle;Michele Platner;Stacy Weng
#t 2001
#c 14
#% 65949
#% 111563
#% 127860
#% 202038
#% 232971
#% 249142
#% 257634
#% 259945
#% 272925
#% 273164
#% 273165
#% 297627
#% 310998
#% 316460
#% 396139
#! As more information resources become accessible using computers,our digital interfaces to those resources need to be appropriate for all people. However when it comes to digital libraries, the interfaces have typically been designed for older children or adults. Therefore, we have begun to develop a digital library interface developmentally appropriate for young children (ages 5-10 years old). Our prototype system we now call SearchKids offers a graphical interface for querying, browsing and reviewing search results. This paper describes our motivation for the research, the design partnership we established between children and adults, our design process, the technology outcomes of our current work, and the lessons we have learned.

#index 337493
#* Dynamic digital libraries for children
#@ Yin Leng Theng;Norliza Mohd-Nasir;George Buchanan;Bob Fields;Harold Thimbleby;Noel Cassidy
#t 2001
#c 14
#% 32599
#% 111543
#% 174038
#% 185253
#% 237336
#% 273165
#% 273167
#% 273168
#% 281413
#% 301247
#% 301266
#% 301294
#% 313916
#! The majority of current digital libraries (DLs) are not designed forchildren. For DLs to be popular with children, they need to be fun, easy-to-use and empower them, whether as readers or authors. This paper describes a new childrens DL emphasizing its design and evaluation, working with the children (11-14 year olds) as design partners and testers. A truly participatory process was used, and observational study was used as a means of refinement to the initial design of the DL prototype. In contrast with current DLs, the childrens DL provides both a static as well as a dynamic environment to encourage active engagement of children in using it. Design, implementation and security issues are also raised.

#index 337496
#* Looking at digital library usability from a reuse perspective
#@ Tamara Sumner;Melissa Dawe
#t 2001
#c 14
#% 56825
#% 185273
#% 204676
#% 211245
#% 223450
#% 231034
#% 280899
#% 292848
#% 294890
#% 296947
#% 305867
#% 316745
#% 328524
#% 332756
#% 438148
#% 595591
#% 647449
#% 647478
#% 956037
#% 1133902
#! The need for information systems to support the dissemination and reus e of educational resources has sparked a number of large-scale digital library efforts. This article describes usability findings from one such project - the Digital Library for Earth System Education (DLESE) - focusing on its role in the process of educational resource reuse. Drawing upon a reuse model developed in the domain of software engineering, the reuse cycle is broken down into five stages: formulation of a reuse intention, location, comprehension, modification, and sharing. Using this model to analyze user studies in the DLESE project, several implications for library system design and library outreach activities are highlighted. One finding is that resource reuse occurs at different stages in the educational design process, and each stage imposes different and possibly conflicting requirements on digital library design. Another finding is that reuse is a distributed process across several artifacts, both within and outside of the library itself. In order for reuse to be successful, a usability line cannot be drawn at the library boundary, but instead must encompass both the library system and the educational resources themselves.

#index 337507
#* Building a hypertextual digital library in the humanities: a case study on London
#@ Gregory Crane;David A. Smith;Clifford E. Wulfman
#t 2001
#c 14
#% 157704
#% 211513
#% 237305
#% 237316
#% 237329
#% 239266
#% 247317
#% 249147
#% 265171
#% 268075
#% 300974
#% 309724
#% 362524
#% 402784
#% 438103
#% 647283
#% 647632
#% 709630
#! This paper describes the creation of a new humanities digital library collection: 11,000,000 words and 10,000 images representing books, images and maps on pre-twentieth century London and its environs. The London collection contained far more dense and precise information than the materials from the Greco-Roman world on which we had previously concentrated. The London collection thus allowed us to explore new problems of data structure, manipulation, and visualization. This paper contrasts our model for how humanities digital libraries are best used with the assumptions that underlie many academic digital libraries on the one hand and more literary hypertexts on the other. Since encoding guidelines such as those from the TEI provide collection designers with far more options than any one project can realize, this paper describes what structures we used to organize the collection and why. We particularly emphasize the importance of mining historical authority lists (encyclopedias, gazetteers, etc.) and then generating automatic span-to-span links within the collection.

#index 337508
#* Document quality indicators and corpus editions
#@ Jeffrey A. Rydberg-Cox;Anne Mahoney;Gregory R. Crane
#t 2001
#c 14
#% 230538
#% 249149
#% 301283
#% 647268
#% 647435
#! Corpus editions can only be useful to scholars when users know what to expect of the texts. We argue for text quality indicators, both general and domain-specific.

#index 337510
#* The digital atheneum: new approaches for preserving, restoring and analyzing damaged manuscripts
#@ Michael S. Brown;W. Brent
#t 2001
#c 14
#% 31707
#% 206034
#% 245819
#% 252785
#% 268086
#% 301220
#% 1496712
#! This paper presents research focused on developing new techniques and algorithms for the digital acquisition, restoration, and study of damaged manuscripts. We present results from an acquisition effort in partnership with the British Library, funded through the NSF DLI-2 program, designed to capture 3-D models of old and damaged manuscripts. We show how these 3-D facsimiles can be analyzed and manipulated in ways that are tedious or even impossible if confined to the physical manuscript. In particular, we present results from a restoration framework we have developed for "flattening" the 3-D representation of badly warped manuscripts. We expect these research directions to give scholars more sophisticated methods to preserve, restore, and better understand the physical objects they study.

#index 337514
#* Towards an electronic variorum dition of Don Quixote
#@ Richard Furuta;Shueh-Cheng Hu;Siddarth Kalasapur;Rajiv Kochumman;Eduardo Urbina;Ricardo Vivancos
#t 2001
#c 14
#! The Cervantes Project is creating an Electronic Variorum Edition of Ce rvantes well-known Don Quixote. This paper gives an overview of the computer-based tools that we are using in this endeavor, and summarizes the current status of the project. The Electronic Variorum Edition will join the other content elements maintained by the project, which focuses on electronic resources in support of the study of Cervantes, his works, and his times.

#index 337516
#* Digital music libraries - research and development
#@ David Bainbridge;Gerry Bernbom;Mary Wallace;Andrew P. Dillon;Matthew Dovey;Jon W. Dunn;Michael Fingerhut;Ichiro Fujinaga;Eric J. Isaacson
#t 2001
#c 14
#! Digital music libraries provide enhanced access and functionality that facilitates scholarly research and education. This panel will present a report on the progress of several major research and development projects in digital music libraries.

#index 337519
#* Content management for digital museum exhibitions
#@ Jen-Shin Hong;Bai-Hsuen Chen;Jieh Hsiang;Tien-Yu Hsu
#t 2001
#c 14
#! An online exhibition of a digital museum often consists of a varietyof multimedia objects such as webpages, animation, and video clips. Ideally, there should be different exhibitions on the same topic for users with different needs. The difficulty is that it is time-consuming to produce illustrative and intriguing online exhibitions. In this paper, we present a content management system for producing exhibitions. This framework is a novel approach for organizing digital collections and for quickly selecting, integrating, and composing objects from the collection to produce exhibitions of different presentation styles, one for each user group. A prototype based on our framework has been implemented and successfully used in the production of a Lanyu digital museum. Using our method, the Lanyu Digital Museum online exhibition has several features: (1) It provides an easy way to compose artifacts extracted from the digital collection into exhibitions. (2) It provides an easy way to create different presentations of the same exhibition content that are catered to users with different needs. (3) It provides easy-to-use film-editing capability to re-arrange an exhibition and to produce new exhibitions from existing ones.

#index 337521
#* Demonstration of hierarchical document clustering of digital library retrieval results
#@ C. R. Palmer;J. Pesenti;R. E. Valdes-Perez;M. G. Christel;A. G. Hauptmann;D. Ng;H. D. Wactlar
#t 2001
#c 14
#% 438054
#! As digital libraries grow in size, querying their contents will become as frustrating as querying the web is now. One remedy is to hierarchically cluster the results that are returned by searching a digital library. We demonstrate the clustering of search results from Carnegie Mellons Informedia database, a large video library that supports indexing and retrieval with automatically generated descriptors.

#index 337525
#* Indiana university digital music library project
#@ Jon W. Dunn;Eric J. Isaacson
#t 2001
#c 14
#% 281339
#! The Indiana University Digital Music Library project plans to create a digital library testbed system containing music in a variety of formats, designed to support research and education in the field of music and to serve as a platform for digital library research. Prototypes of user interfaces to the system will be demonstrated.

#index 337528
#* Interactive visualization of video metadata
#@ Mark Derthick
#t 2001
#c 14
#% 237081
#% 437509
#! Much current research on digital libraries focuses on named entityextraction and transformation into structured information. Examples include entities like events, people, and places, and attributes like birth date or latitude. This video demonstration illustrates the potential for finding relationships among entities extracted from 50,000 news segments from CMUs Informedia Digital Video Library. A visual query language is used to specify relationships among entities. Data populate the query structure, which becomes an interface for exploration that gives continuous feedback in the form of visualizations of summary statistics. The target user is a data analyst familiar with the domain from which the entities come, but not a computer scientist.

#index 337533
#* PERSIVAL demo: categorizing hidden-web resources
#@ Panagiotis G. Ipeirotis;Luis Gravano;Mehran Sahami
#t 2001
#c 14
#% 333932
#% 465747
#% 1499571

#index 337535
#* PERSIVAL: personalized summarization over multimedia health-care information
#@ Noemie Elhadad;Min-Yen Kan;Simon Lok;Smaranda Muresan
#t 2001
#c 14
#% 337479
#! In this demonstration, we present several integrated components of PER SIVAL PErsonalized Retrieval and Summarization of Image, Video And anguage)[1], a system designed to provide personalized access to a distributed digital library of medical literature and consumer health information. The global system architecture of PERSIVAL is best described as a two-stage processing pipeline. The first stage is a retrieval system that matches user queries with relevant multimedia data in the library. The second stage is a visualization system that processes the multimedia data matched by the first stage for display.Our demonstration focuses on the second stage of PERSIVAL's processing pipeline. Given a set of relevant documents for certain predefined queries, our integrated demonstration seeks to give a tailored response for either physicians or patients, featuring textual summaries, as well as relevant medical definitions. To visualize the summaries and definitions, we employ automated constraint-based layout of the user interface that allows for rich interaction between summaries and definitions.PERSIVAL's natural language processing and user interface modules make up the visualization portion of the system and illustrate state-of-the-art digital library technology. Following are the modules presented in our demonstration.

#index 337538
#* View segmentation and static/dynamic summary generation for echocardiogram videos
#@ Shahram Ebadollahi;Shih-Fu Chang
#t 2001
#c 14
#% 337479

#index 337539
#* Stanford encyclopedia of philosophy: a dynamic reference work
#@ Edward N. Zalta;Colin Allen;Uri Nodelman
#t 2001
#c 14
#! The primary goal of the Stanford Encyclopedia of Philosophy project $$ is to produce an authoritative and comprehensive reference work devoted to the academic discipline of philosophy that will be kept up to date ally so as to remain useful to those in academia and the general public. To accomplish this goal we have designed and implemented web-based software by which academic philosophers can collaboratively write and maintain such a `dynamic reference work'. Our implementation has features that are not found in any other online reference work in any discipline, and that enable the profession of philosophy to maintain such a reference work without the cost or level of staff support required for traditional reference work publishing.

#index 337541
#* A system for adding content-based searching to a traditional music library catalogue server
#@ Matthew J. Dovey
#t 2001
#c 14
#! Most online music library catalogues can only be searched by textual m etadata. Whilst highly effective - since the rules for maintaining consistency have been refined over many years - this does not allow searching by musical content. Many music librarians are familiar with users humming their enquiries. Most systems providing a query by humming interface tend to run independently of music library catalogue systems and not offer similar textual metadata searching. This demonstration shows how we can integrate these two types of system based on work conducted as part of the NSF/JISC funded OMRAS project (http://www.omras.org).

#index 337542
#* Using the repository explorer to achieve OAI protocol compliance
#@ Hussein Suleman
#t 2001
#c 14

#index 337543
#* An atmospheric visualization collection for the NSDL
#@ Christopher Klaus;Keith Andrew
#t 2001
#c 14
#! In this poster, we describe visualization and educational efforts unde rway to build an Atmospheric Visualization Collection for the NSDL.

#index 337545
#* Breaking the metadata generation bottleneck: preliminary findings
#@ Elizabeth D. Liddy;Stuart Sutton;Woojin Paik;Eileen Allen;Sarah Harwell;Michelle Monsour;Anne Turner;Jennifer Liddy
#t 2001
#c 14

#index 337547
#* Building the physical sciences information infrastructure, a phased approach
#@ Judy C. Gilmore;Valerie S. Allen
#t 2001
#c 14
#! In 2000, a vision of a Physical Sciences Information Infrastructure - an integrated network for the physical sciences - was captured and endorsed. Work continues in 2001 as partnerships are formed and strategies are formulated to move the vision forward.

#index 337549
#* Development of an earth environmental digital library system for soil and land-atmospheric data
#@ Eiji Ikoma;Taikan Oki;Masaru Kitsuregawa
#t 2001
#c 14
#! We propose and examine new methods for automatic data loading system and flexible user interface system with many features such as 3D visualization. We implement the earth environmental digital library and operate it on the Web. Though our system is focusing the limited users like earth environmental researchers, more than 8000 hits per month describe the practical usefulness of it.

#index 337551
#* Digital facsimile editions and on-line editing
#@ Harry Plantinga
#t 2001
#c 14
#! Digitizing a large collection of books is an expensive and time-consum ing task-but there may be volunteers all over the world who are willing to do a small portion of the task. This poster describes a system for making digital facsimile editions-e-books consisting of page images and OCRed but uncorrected text. The user can choose to view low or high resolution page images or text for each page or search the text. Authenticated users with little or no training can correct the text on-line, and the corrections are incorporated in the document. Source code is available for the described implementation, which is a part of the Christian Classics Ethereal Library (http://www.ccel.org).

#index 337552
#* DSpace at MIT: meeting the challenges
#@ Michael J. Bass;Margret Branschofsky
#t 2001
#c 14
#! DSpace is a joint development effort by HP and MIT to establish an ele ctronic system that will enable MIT faculty and researchers to capture, preserve, manage, and disseminate their intellectual output, and that will enable the Institute to maintain its intellectual heritage. The effort further aims to facilitate sharing of intellectual content and metadata among institutions by minimizing barriers to adoption and federation. This brief paper describes the motivation behind the project, its goals, objectives, progress, and references to detailed definition & design materials.

#index 337553
#* Exploiting image semantics for picture libraries
#@ Kobus Barnard;David Forsyth
#t 2001
#c 14
#% 218992
#! We consider the application of a system for learning the semantics of image collections to digital libraries. We discuss our approach to browsing and search, and investigate the integration both in more detail.

#index 337554
#* Feature extraction for content-based image retrieval in DARWIN
#@ K. R. Debure;A. S. Russell
#t 2001
#c 14
#% 117651

#index 337555
#* Guided linking: efficiently making image-to-transcript correspondence
#@ Cheng Jiun Yuan;W. Brent Seales
#t 2001
#c 14
#! The problem of annotating unstructured images is labor intensive and d ifficult to automate. Linking is a type of annotation where an image region is tagged by representing a correspondence between the region and other information. Any serious effort at creating a digital edition of a manuscript from nothing but images and their associated information, such as transcripts and editorial remarks, must include the task of creating a large number of links between image regions and the related information. We present an approach to the problem of image linking, which concentrates on the fundamental and labor-intensive task of associating image regions with their textual counterparts. We assume the input to the system is a set of images representing a manuscript, and that associated data, such as a transcript, is available to provide guidance to the automated portion of the system. Our approach targets collections that are damaged and difficult-to-read, such as manuscripts that require intensive editorial annotation. It is essentially impossible to perform fully automated techniques, such as optical character recognition (OCR) or accurate handwriting analysis [2], on these kinds of manuscripts.We approach the problem with a semi-automatic solution that involves a document analysis (DA) module and a graphical user interface. The role of the DA module is to assist the user in formulating an algorithm that will automatically detect and rank regions of interest in the image. We provide the user with the capability to configure the parameters and steps of the analysis algorithm and thereby tune it to the task of identifying and ranking candidate regions for linking. With a graphical user interface, the user can interactively establish correspondences between image regions and other data, refine the correspondences detected by the DA module, and supply simple yet critical cues to the DA module to improve the result of subsequent automated processing. One

#index 337556
#* Integrating digital libraries by CORBA, XML and Servlet
#@ Wing Hang Cheung;Michael R. Lyu;Kam Wing Ng
#t 2001
#c 14
#! In this paper, we describe how we use a mediator-based architecturefor integrating digital libraries. We discuss how we tackle the obstacles of firewalls in the expansion of our system by using XML and Java Servlet, which are used to achieve CORBA general communications and callback features across the firewalls.

#index 337557
#* A national digital library for undergraduate mathematics and science teacher preparation and professional development
#@ Kimberly S. Roempler
#t 2001
#c 14
#! The primary goal of the National Digital Library for Undergraduate Mat hematics and Science Teacher Preparation and Professional Development, funded through the NSF Division of Undergraduate Education National Science Digital Libraries Initiative, is to increase the use of best teaching practices by faculty by providing the resources - tools, training, and data - needed to build inquiry and discovery into all undergraduate science and mathematics courses. Improving the math and science education of future and in-service K-12 teachers is one of the most important challenges facing college and university faculties.The preparation of future teachers is a fundamental element in the improvement of the learning experience of all students, from grades K-16. As teachers know, it is natural to teach as we have been taught ourselves. The standards in mathematics and science call for greater integration of inquiry-based techniques and more rigorous mathematical and science content. Teachers at all levels will be better equipped to meet these standards if they are taught using these approaches during their own education.The resources of this collection target two-year and four-year Colleges of Arts and Sciences faculty members and College of Education faculty that teach mathematics and science content courses. The collection focuses primarily on those resources that can be accessed electronically, whether they be web-based text or data resources, software or video that can be downloaded via the web or other electronic means, or emerging technology applications. Resources are reviewed and selected by mathematics and science content experts before they are made available to online users. This review ensures that the resources are accurate, pedagogically effective, and that this digital library is an efficient source of quality materials. This digital library enables faculty at any undergraduate institution-regardless of financial resources-to

#index 337558
#* Print to electronic: measuring the operational and economic implications of an electronic journal collection
#@ Carol Hansen;Linda S. Marion
#t 2001
#c 14
#! In this poster, we report methodology and initial results from a study of an academic library's migration to an all-electronic journal collection.

#index 337559
#* Turbo recognition: decoding page layout
#@ Taku A. Tokuyasu
#t 2001
#c 14
#% 301089

#index 337560
#* Using Markov models and innovation-diffusion as a tool for predicting digital library access and distribution
#@ Bruce R. Barkstrom
#t 2001
#c 14
#! This paper, discusses a general approach to predicting data access rates and user access patterns for planning distribution capacities and for monitoring data usage. The approach uses a steady-state Markov model to describe user activities and innovation-diffusion to describe the rate at which a na聥ve population adopts accessing data from a digital library.

#index 337561
#* A versatile facsimile and transcription service for manuscripts and rare old books at the Miguel de Cervantes digital library
#@ Alejandro Bia
#t 2001
#c 14
#! The purpose of this poster is to describe our approach to provide facsimiles of manuscripts and old books as one of our DL services publicly available by Internet.

#index 337562
#* The virtual naval hospital: the digital library as knowledge management tool for nomadic patrons
#@ Michael P. D'Alessandro;Richard S. Bakalar;Donna M. D'Alessandro;Denis E. Ashley;Mary J. C. Hendrix
#t 2001
#c 14
#% 157318
#! To meet the information needs of isolated primary care providers and t heir patients in the United States (U.S.) Navy, a digital health sciences library - Virtual Naval Hospital (http://www.vnh.org) - was created through a unique partnership between academia and government. The creation of the digital library was heavily influenced by the principles of user-centered design, and made allowances for the nomadic nature of the digital librarys patrons and the heterogeneous access they have to Internet bandwidth. The result is a digital library that has been in operation since 1997, that continues to expand in size, that is heavily used, and that is highly regarded by its patrons. Over time, the digital library has evolved into a knowledge-management system for the U.S. Navy Bureau of Medicine and Surgery. A number of valuable technical, personal, and political lessons have been learned about delivering digital library and knowledge management services to nomadic patrons. They can be summarized by stating that to succeed in the design and implementation of a digital library that serves as a knowledge management tool, regardless of the field of endeavor, one must focus initially and then consistently on the population served and what their mission is, and tailor the digital library to their needs. If this is done, the result will be a tool that is heavily used and sincerely appreciated. These lessons learned will become increasingly valuable as society moves towards a ubiquitous computing environment.

#index 337564
#* Workshop 1: visual interfaces to digital libraries - its past, present, and future
#@ Katy Börner;Chaomei Chen
#t 2001
#c 14
#! The design of easy-to-use and informative visual interfaces to digital libraries is an integral part to the advances of digital libraries. A wide range of approaches have been developed from a diverse spectrum of perspectives that focus on users and tasks to be supported, data to be modeled, and the efficiency of algorithms. Information visualization aims to exploit the human visual information processing system, especially with non-spatial data (such as documents and images typically found in digital libraries). Generally, information visualization examines semantic relationships intrinsic to an abstract information space and how they can be spatially navigated and memorized using similar cognitive processes to those that would apply during interactions with the real world. This workshop promotes the convergence of information visualization and digital libraries. It brings together researchers and practitioners in the areas of information visualization, digital libraries, human-computer interaction, library and information science, and computer science to identify the most important issues in the past and the present, and what should be done in the future.

#index 337565
#* Workshop 2: the technology of browsing applications
#@ Nina Wacholder;Craig Nevill Manning
#t 2001
#c 14

#index 337567
#* Workshop 3: classification crosswalks
#@ Paul Thompson;Traugott Koch;John Carter;Heike Neuroth;Ed O'Neill;Dagobert Soergel
#t 2001
#c 14
#! Mapping between/among classification schemes is beneficial within an organization that has a number of implicit schemes, between organizations seeking to exchange information, and in a digital library context where collections are organized by different classifications. This cross scheme mapping could be done manually, but if many schemes are to be mapped, it may be desirable to provide automated tools and techniques to support the process. This workshop will present research and projects that identify the state-of-the-practice and outline the research agenda. In addition to the educational part of the program, the afternoon will be devoted to ongoing NKOS activities related to a vocabulary mark-up language, mechanisms for search and retrieval of online knowledge organization sources, and a typology for describing knowledge organization sources that supports the development of knowledge organization services on the Web.The program is available from the NKOS Web site at http://nkos.slis.kent.edu.

#index 337568
#* Workshop 4: digital libraries in asian languages
#@ Su-Shing Chen;Ching-chih Chen
#t 2001
#c 14

#index 337569
#* Workshop 5: information visualization for digital libraries: defining a research agenda for heterogeneous multimedia collections
#@ Lucy Nowell;Elizabeth Hetzler
#t 2001
#c 14
#! This workshop will emphasize small group discussion and brainstorming to explore issues of visualization for heterogeneous digital libraries. The power of visualization lies in its ability to convey information at the high bandwidth of the human perceptual system, facilitating recognition of patterns in the information space, and supporting navigation in large collections. How do we extend these benefits to collections that span the range of digital media? Participants will explore this issue, with the aim of identifying a research agenda.

#index 337581
#* HeinOnline
#@ Richard J. Marisa
#t 2001
#c 14
#% 648868
#! HeinOnline is a new online archive of law journals. Development of He inOnline began in late 1997 through the cooperation of Cornell Information Technologies, William S. Hein & Co., Inc. of Buffalo, NY, and the Cornell Law Library.Built upon the familar Dienst and new Open Archive Initiative protocols, HeinOnline extends the reliable and well-established management practices of open access archives like NCSTRL and CoRR to a subscription-based collection. The decisions made in creating HeinOnline, Dienst architectural extensions, and issues which have arisen during operation of HeinOnline are described.

#index 337690
#* Managing change on the web
#@ Luis Francisco-Revilla;Frank Shipman;Richard Furuta;Unmil Karadkar;Avital Arora
#t 2001
#c 14
#% 173739
#% 231522
#% 232708
#% 234992
#% 240237
#% 240748
#% 249114
#% 249143
#% 290703
#% 309746
#% 424263
#% 1275346
#% 1499473
#! Increasingly, digital libraries are being defined that collect pointers to World-Wide Web based resources rather than hold the resources themselves. Maintaining these collections is challenging due to distributed document ownership and high fluidity. Typically a collections maintainer has to assess the relevance of changes with little system aid. In this paper, we describe the Waldens Paths Path Manager, which assists a maintainer in discovering when relevant changes occur to linked resources. The approach and system design was informed by a study of how humans perceive changes of Web pages. The study indicated that structural changes are key in determining the overall change and that presentation changes are considered irrelevant.

#index 378477
#* Proceedings of the 2nd ACM/IEEE-CS joint conference on Digital libraries
#@ William Hersh;Gary Marchionini
#t 2002
#c 14
#! Welcome to JCDL 2002! This is the second in a series of ACM/IEEE-CS joint conferences on research and development in digital libraries. JCDL 2002 is a major international forum for research reports and discussion on digital libraries and associated technical, practical, and social issues. The conference takes a broad view of digital libraries as both extensions and augmentations of physical libraries, archives, museums, and other cultural institutions. The program captured in these proceedings represents a snapshot of the current state of digital library research and development and provides glimmers into the future of what digital libraries may become.This year's conference attracted 240 submissions from researchers in 18 countries. All full and short papers were reviewed by at least three members of the program committee and those accepted were revised for inclusion in these proceedings. Thirty-three of 99 full papers and 36 of 73 short papers were accepted this year. In addition to the papers, demonstrations, posters, and panels add to the mix of theory and practice and two keynote addresses will stimulate thought and discussion on intellectual property issues and trends in digital library practice. Eight tutorials and seven workshops bookend the conference to provide in-depth treatments of specific topics and issues. As in past years, the Vannevar Bush Award for best paper will be awarded in honor of Dr. Bush, the founder of the National Science Foundation and proposer of the Memex. This award was initiated by Robert Akscyn, President of Knowledge Systems, Inc. A subcommittee of the program committee (Lois Delcambre, Sue Dumais, Linda Hill, Gary Marchionini, Michael Nelson, and Rebecca Wesley) reviewed the seven highest rated papers to select a winner. This year's award goes to Donna Bergmark for her paper "Collection Synthesis.

#index 378478
#* Primarily history: historians and the search for primary source materials
#@ Helen R. Tibbo
#t 2002
#c 14
#% 110066
#% 177579
#! This paper describes the first phase of an international project that is exploring how historians locate primary resource materials in the digital age, what they are teaching their Ph.D. students about finding research materials, and what archivists are doing to facilitate access to these materials. Preliminary findings are presented from a survey of 300 historians studying American History from leading institutions of higher education in the U.S. Tentative conclusions indicate the need to provide multiple pathways of access to historical research materials including paper-based approaches and newer digital ones. The need for user education, especially in regard to electronic search methodologies is indicated.

#index 378479
#* Using the Gamera framework for the recognition of cultural heritage materials
#@ Michael Droettboom;Ichiro Fujinaga;Karl MacMillan;G. Sayeed Chouhury;Tim DiLauro;Mark Patton;Teal Anderson
#t 2002
#c 14
#% 114994
#% 183555
#% 204672
#% 208705
#% 337510
#% 337514
#% 352573
#% 357787
#% 588980
#% 625392
#% 651336
#% 837641
#! This paper presents a new toolkit for the creation of customized structured document recognition applications by domain experts. This open-source system, called Gamera, allows a user, with particular knowledge of the documents to be recognized, to combine image processing and recognition tools in an easy-to-use, interactive, graphical scripting environment. Gamera is one of the key technology components in a proposed international project for the digitization of diverse types of humanities documents.

#index 378480
#* Supporting access to large digital oral history archives
#@ Samuel Gustman;Dagobert Soergel;Douglas Oard;William Byrne;Michael Picheny;Bhuvana Ramabhadran;Douglas Greenberg
#t 2002
#c 14
#% 157392
#% 252472
#% 561333
#% 575576
#! This paper describes our experience with the creation, indexing, and provision of access to a very large archive of videotaped oral histories - 116,000 hours of digitized interviews in 32 languages from 52,000 survivors, liberators, rescuers, and witnesses of the Nazi Holocaust. It goes on to identify a set of critical research issues that must be addressed if we are to provide full and detailed access to collections of this size: issues in user requirement studies, automatic speech recognition, automatic classification, segmentation, summarization, retrieval, and user interfaces. The paper ends by inviting others to discuss use of these materials in their own research.

#index 378481
#* Using sentence-selection heuristics to rank text segments in TXTRACTOR
#@ Daniel McDonald;Hsinchun Chen
#t 2002
#c 14
#% 194251
#% 259990
#% 262112
#% 280835
#% 340882
#% 340885
#% 340916
#% 387791
#% 389155
#% 741058
#% 853647
#! TXTRACTOR is a tool that uses established sentence-selection heuristics to rank text segments, producing summaries that contain a user-defined number of sentences. The purpose of identifying text segments is to maximize topic diversity, which is an adaptation of the Maximal Marginal Relevance criterion used by Carbonell and Goldstein [5]. Sentence selection heuristics are then used to rank the segments. We hypothesize that ranking text segments via traditional sentence-selection heuristics produces a balanced summary with more useful information than one produced by using segmentation alone. The proposed summary is created in a three-step process, which includes 1) sentence evaluation 2) segment identification and 3) segment ranking. As the required length of the summary changes, low-ranking segments can then be dropped from (or higher ranking segments added to) the summary. We compare the output of TXTRACTOR to the output of a segmentation tool based on the TextTiling algorithm to validate the approach.

#index 378482
#* Using librarian techniques in automatic text summarization for information retrieval
#@ Min-Yen Kan;Judith L. Klavans
#t 2002
#c 14
#% 71752
#% 100002
#% 118770
#% 118772
#% 201992
#% 214709
#% 318409
#% 337479
#% 342786
#% 345779
#% 480467
#! A current application of automatic text summarization is to provide an overview of relevant documents coming from an information retrieval (IR) system. This paper examines how Centrifuser, one such summarization system, was designed with respect to methods used in the library community. We have reviewed these librarian expert techniques to assist information seekers and codified them into eight distinct strategies. We detail how we have operationalized six of these strategies in Centrifuser by computing an informative extract, indicative differences between documents, as well as navigational links to narrow or broaden a user's query. We conclude the paper with results from a preliminary evaluation.

#index 378483
#* QuASM: a system for question answering using semi-structured data
#@ David Pinto;Michael Branstein;Ryan Coleman;W. Bruce Croft;Matthew King;Wei Li;Xing Wei
#t 2002
#c 14
#% 237328
#% 262096
#% 280864
#% 309211
#% 742424
#% 815098
#! This paper describes a system for question answering using semi-structured metadata, QuASM (pronounced "chasm"). Question answering systems aim to improve search performance by providing users with specific answers, rather than having users scan retrieved documents for these answers. Our goal is to answer factual questions by exploiting the structure inherent in documents found on the World Wide Web (WWW). Based on this structure, documents are indexed into smaller units and associated with metadata. Transforming table cells into smaller units associated with metadata is an important part of this task. In addition, we report on work to improve question classification using language models. The domain used to develop this system is documents retrieved from a crawl of www.fedstats.gov.

#index 378484
#* Reading-in-the-small: a study of reading on small form factor devices
#@ Catherine C. Marshall;Christine Ruotolo
#t 2002
#c 14
#% 185274
#% 202000
#% 237336
#% 247295
#% 247296
#% 247297
#% 249137
#% 281359
#% 301217
#% 301243
#% 337231
#% 341074
#! The growing ubiquity of small form factor devices such as Palm Pilots and Pocket PCs, coupled with widespread availability of digital library materials and users' increasing willingness to read on the screen, raises the question of whether people can and will read digital library materials on handhelds. We investigated this question by performing a field study based on a university library's technology deployment: two classes were conducted using materials that were available in e-book format on Pocket PCs in addition to other electronic and paper formats. The handheld devices, the course materials, and technical support were all provided to students in the courses to use as they saw fit. We found that the handhelds were a good platform for reading secondary materials, excerpts, and shorter readings; they were used in a variety of circumstances where portability is important, including collaborative situations such as the classroom. We also discuss the effectiveness of annotation, search, and navigation functionality on the small form factor devices. We conclude by defining a set of focal areas and issues for digital library efforts designed for access by handheld computers.

#index 378485
#* A graph-based recommender system for digital library
#@ Zan Huang;Wingyan Chung;Thian-Huat Ong;Hsinchun Chen
#t 2002
#c 14
#% 67565
#% 81584
#% 143306
#% 187767
#% 202009
#% 202011
#% 212287
#% 220706
#% 220709
#% 232647
#% 260778
#% 262178
#% 266281
#% 301259
#% 304425
#% 324569
#% 337265
#% 420121
#% 742162
#% 1271961
#! Research shows that recommendations comprise a valuable service for users of a digital library [11]. While most existing recommender systems rely either on a content-based approach or a collaborative approach to make recommendations, there is potential to improve recommendation quality by using a combination of both approaches (a hybrid approach). In this paper, we report how we tested the idea of using a graph-based recommender system that naturally combines the content-based and collaborative approaches. Due to the similarity between our problem and a concept retrieval task, a Hopfield net algorithm was used to exploit high-degree book-book, user-user and book-user associations. Sample hold-out testing and preliminary subject testing were conducted to evaluate the system, by which it was found that the system gained improvement with respect to both precision and recall by combining content-based and collaborative approaches. However, no significant improvement was observed by exploiting high-degree associations.

#index 378486
#* The effects of topic familiarity on information search behavior
#@ Diane Kelly;Colleen Cool
#t 2002
#c 14
#% 29585
#% 169803
#% 218978
#% 220711
#! We describe results from a preliminary investigation of the relationship between topic familiarity and information search behavior. Two types of information search behaviors are considered: reading time and efficacy. Our results indicate that as one's familiarity with a topic increases, one's searching efficacy increases and one's reading time decreases. These results suggest that it may be possible to infer topic familiarity from information search behavior.

#index 378487
#* A language modelling approach to relevance profiling for document browsing
#@ David J. Harper;Sara Coulthard;Sun Yixing
#t 2002
#c 14
#% 37743
#% 152251
#% 169984
#% 186518
#% 201992
#% 232677
#% 247297
#% 262036
#% 262096
#% 280811
#% 280834
#% 280864
#% 281379
#% 292684
#! This paper describes a novel tool, SmartSkim, for content-based browsing or skimming of documents. The tool integrates concepts from passage retrieval and from interfaces, such as TileBars, which provide a compact overview of query term hits within a document. We base our tool on the concept of relevance profiling, in which a plot of retrieval status values at each word position of a document is generated. A major contribution of this paper is applying language modelling to the task of relevance profiling. We describe in detail the design of the SmartSkim tool, and provide a critique of the design. Possible applications of the tool are described, and we consider how an operational version of SmartSkim might be designed.

#index 378488
#* Compound descriptors in context: a matching function for classifications and thesauri
#@ Douglas Tudhope;Ceri Binding;Dorothee Blocks;Daniel Cunliffe
#t 2002
#c 14
#% 73257
#% 204668
#% 219036
#% 229068
#% 230535
#% 301539
#% 309491
#% 337250
#% 575943
#! There are many advantages for Digital Libraries in indexing with classifications or thesauri, but some current disincentive in the lack of flexible retrieval tools that deal with compound descriptors. This paper discusses a matching function for compound descriptors, or multi-concept subject headings, that does not rely on exact matching but incorporates term expansion via thesaurus semantic relationships to produce ranked results that take account of missing and partially matching terms. The matching function is based on a measure of semantic closeness between terms, which has the potential to help with recall problems. The work reported is part of the ongoing FACET project in collaboration with the National Museum of Science and Industry and its collections database. The architecture of the prototype system and its interface are outlined. The matching problem for compound descriptors is reviewed and the FACET implementation described. Results are discussed from scenarios using the faceted Getty Art and Architecture Thesaurus. We argue that automatic traversal of thesaurus relationships can augment the user's browsing possibilities. The techniques can be applied both to unstructured multi-concept subject headings and potentially to more syntactically structured strings. The notion of a focus term is used by the matching function to model AAT modified descriptors (noun phrases). The relevance of the approach to precoordinated indexing and matching faceted strings is discussed.

#index 378489
#* Structuring keyword-based queries for web databases
#@ Rodrigo C. Vieira;Pavel Calado;Altigran S. da Silva;Alberto H. F. Laender;Berthier A. Ribeiro-Neto
#t 2002
#c 14
#% 219047
#% 309726
#% 348955
#! This paper describes a framework, based on Bayesian belief networks, for querying Web databases using keywords only. According to this framework, the user inputs a query through a simple search-box. From the input query, one or more plausible structured queries are derived and submitted to Web databases. The results are then retrieved and presented to the user as ranked answers. To evaluate our framework, an experiment using 38 example queries was carried out. We found out that 97% of the time, one of the top three resulting structured queries is the proper one. Further, when the user selects one of these three top queries for processing, the ranked answers present average precision figures of 92%.

#index 378490
#* An approach to automatic classification of text for information retrieval
#@ Hong Cui;P. Bryan Heidorn;Hong Zhang
#t 2002
#c 14
#% 278109
#% 420077
#% 458379
#! In this paper, we explore an approach to make better use of semi-structured documents in information retrieval in the domain of biology. Using machine learning techniques, we make those inherent structures explicit by XML markups. This marking up has great potentials in improving task performance in specimen identification and the usability of online flora and fauna.

#index 378491
#* Middle school children's use of the ARTEMIS digital library
#@ June Abbas;Cathleen Norris;Elliott Soloway
#t 2002
#c 14
#% 247290
#% 273451
#% 712911
#! A case study of middle school student's interaction within a digital library, the differential use of interface features by students, and the issues of representation and retrieval obstacles are examined. A mechanism for evaluating user's search terms and questions is explained. Findings of a current case study indicate that student's interaction with the system varied between individual classes and between different achievement levels. Terms used by the system to represent the resources do not adequately represent the user groups' information needs.

#index 378492
#* Partnership reviewing: a cooperative approach for peer review of complex educational resources
#@ John Weatherley;Tamara Sumner;Michael Khoo;Michael Wright;Marcel Hoffmann
#t 2002
#c 14
#% 177474
#% 247276
#% 270951
#% 297605
#% 315450
#% 332756
#% 337256
#% 337488
#% 352901
#! Review of digital educational resources, such as course modules, simulations, and data analysis tools, can differ from review of scholarly articles, in the heterogeneity and complexity of the resources themselves. The Partnership Review Model, as demonstrated in two cases, appears to promote cooperative interactions between distributed resource reviewers, enabling reviewers to effectively divide up the task of reviewing complex resources with little explicit coordination. The shared structural outline of the resource made visible in the review environment enables participants to monitor other reviewers' actions and to thus target their efforts accordingly. This reviewing approach may be effective in educational digital libraries that depend on community volunteers for most of their reviewing.

#index 378493
#* A digital library for geography examination resources
#@ Lian-Heong Chua;Dion Hoe-Lian Goh;Ee-Peng Lim;Zehua Liu;Rebecca Pei-Hui Ang
#t 2002
#c 14
#% 378546
#! We describe a Web-based application developed above a digital library of geographical resources for Singapore students preparing to take a national examination in geography. The application provides an interactive, non-sequential approach to learning that supplements textbooks.

#index 378494
#* Digital library services for authors of learning materials
#@ Flora McMartin;Youki Terada
#t 2002
#c 14
#% 337254
#! Digital libraries, particularly those designed to meet the needs of educators and students, focus their primary services on the needs of their end users [1]. In this paper, we introduce and discuss the types of services authors of the materials cataloged within this type of digital library expect, or may find useful. Results from a study of authors cataloged in NEEDS - a national engineering education digital library guide this discussion.

#index 378495
#* Integration of simultaneous searching and reference linking across bibliographic resources on the web
#@ William H. Mischo;Thomas G. Habing;Timothy W. Cole
#t 2002
#c 14
#% 311077
#% 647421
#! Libraries and information providers are actively developing customized portals and gateway software designed to integrate secondary information resources such as A & I services, online catalogs, and publishers full-text repositories. This paper reports on a project carried out at the Grainger Engineering Library at the University of Illinois at Urbana-Champaign to provide web-based asynchronous simultaneous searching of multiple secondary information resources and integrated reference linking between bibliographic resources.The project has tested two different approaches to simultaneous broadcast searching. One approach utilizes custom distributed searchbots and shared blackboard databases. The other approach uses event-driven asynchronous HTTP queries within a single web script.The reference linking implementation is built around the application of OpenURL and Digital Object Identifier (DOI) technologies and the CrossRef metadata database within a proxy server environment.

#index 378496
#* Exploring discussion lists: steps and directions
#@ Paula S. Newman
#t 2002
#c 14
#% 111245
#% 172812
#% 194251
#% 237338
#% 249111
#% 283171
#% 292216
#% 292681
#% 301263
#% 308845
#% 308906
#% 309128
#% 324960
#% 337433
#% 352869
#% 441087
#% 466892
#% 726086
#! This paper describes some new facilities for exploring archived email-based discussion lists. The facilities exploit some specific properties of email messages to obtain improved archive overviews, and then use new tree visualizations, developed for the purpose, to obtain thread overviews and mechanisms to aid in the coherent reading of threads. We consider these approaches to be limited, but useful, approximations to more ideal facilities; a final section suggests directions for further work in this area.

#index 378497
#* Comparison of two approaches to building a vertical search tool: a case study in the nanotechnology domain
#@ Michael Chau;Hsinchun Chen;Jialun Qin;Yilu Zhou;Yi Qin;Wai-Ki Sung;Daniel McDonald
#t 2002
#c 14
#% 27049
#% 109213
#% 161754
#% 162452
#% 168969
#% 176502
#% 218992
#% 218994
#% 234978
#% 268078
#% 268079
#% 281251
#% 295520
#% 301234
#% 337239
#% 345119
#% 378557
#% 387791
#% 741058
#% 917574
#! As the Web has been growing exponentially, it has become increasingly difficult to search for desired information. In recent years, many domain-specific (vertical) search tools have been developed to serve the information needs of specific fields. This paper describes two approaches to building a domain-specific search tool. We report our experience in building two different tools in the nanotechnology domain -- (1) a server-side search engine, and (2) a client-side search agent. The designs of the two search systems are presented and discussed, and their strengths and weaknesses are compared. Some future research directions are also discussed.

#index 378498
#* A multilingual, multimodal digital video library system
#@ Michael R. Lyu;Edward Yau;Sam Sze
#t 2002
#c 14
#% 219732
#% 235342
#% 235355
#% 289942
#% 295899
#% 301578
#% 337444
#% 337556
#% 434937
#% 437509
#% 445330
#% 584921
#% 589934
#% 625486
#% 970540
#% 1854659
#% 1854923
#! This paper presents the iVIEW system, a multi-lingual, multi-modal digital video content management system for intelligent searching and access of English and Chinese video contents. iVIEW allows full content indexing, searching and retrieval of multi-lingual text, audio and video material. It consists image processing techniques for scenes and scene changes analyses, speech processing techniques for audio signal transcriptions, and multi-lingual natural language processing techniques for word relevance determination. iVIEW can host multi-lingual contents and allow multi-modal search. It facilitate content developers to perform multi-modal information processing of rich video media and to construct XML-based multimedia representation in enhancing multi-modal indexing and searching capabilities, so that the end users can enjoy viewing flexible and seamless delivery of multimedia contents in various browsing tools and devices.

#index 378499
#* A digital library data model for music
#@ Natalia Minibayeva;Jon W. Dunn
#t 2002
#c 14
#% 281339
#! In this paper, we introduce a data and metadata model being developed for use in a music digital library system to support search and navigation of music content in multiple formats.

#index 378500
#* Video-cuebik: adapting image search to video shots
#@ Alexander G. Hauptmann;Norman D. Papernick
#t 2002
#c 14
#% 318785
#% 443889
#% 1854913
#% 1857495
#! We propose a new analysis for searching images in video libraries that goes beyond simple image search, which compares one still image frame to another. The key idea is to expand the definition of an image to account for the variability in the sequence of video frames that comprise a shot. A first implementation of this method for a QBIC-like image search engine shows a clear improvement over still image search. A combination of the traditional still image search and the new video image search provided the overall best results on the TREC video retrieval evaluation data.

#index 378501
#* Virtual multimedia libraries built from the web
#@ Neil C. Rowe
#t 2002
#c 14
#% 294842
#% 445548
#! We have developed a tool MARIE-4 for building virtual libraries of multimedia (images, video, and audio) by automatically exploring (crawling) a specified subdomain of the World Wide Web to create an index based on caption keywords. Our approach uses carefully-researched criteria to identify and rate caption text, and employs both an expert system and a neural network. We have used it to create a keyword-based interface to nearly all nontrivial captioned publicly-accessible U.S. Navy images (667,573), video (8,290), and audio (2,499), called the Navy Virtual Multimedia Library (NAVMULIB).

#index 378502
#* Multi-modal information retrieval from broadcast video using OCR and speech recognition
#@ Alexander G. Hauptmann;Rong Jin;Tobun Dorbin Ng
#t 2002
#c 14
#% 318785
#% 589728
#! We examine multi-modal information retrieval from broadcast video where text can be read on the screen through OCR and speech recognition can be performed on the audio track. OCR and speech recognition are compared on the 2001 TREC Video Retrieval evaluation corpus. Results show that OCR is more important that speech recognition for video retrieval. OCR retrieval can further improve through dictionary-based post-processing. We demonstrate how to utilize imperfect multi-modal metadata results to benefit multi-modal information retrieval.

#index 378503
#* Extending SDARTS: extracting metadata from web databases and interfacing with the open archives initiative
#@ Panagiotis G. Ipeirotis;Tom Barry;Luis Gravano
#t 2002
#c 14
#% 227891
#% 230432
#% 262063
#% 273926
#% 287463
#% 301225
#% 309783
#% 337235
#% 337277
#% 337479
#% 340146
#% 479642
#% 1499571
#! SDARTS is a protocol and toolkit designed to facilitate metasearching. SDARTS combines two complementary existing protocols, SDLIP and STARTS, to define a uniform interface that collections should support for searching and exporting metasearch-related metadata. SDARTS also includes a toolkit with wrappers that are easily customized to make both local and remote document collections SDARTS-compliant. This paper describes two significant ways in which we have extended the SDARTS toolkit. First, we have added a tool that automatically builds rich content summaries for remote web collections bym probing the collections with appropriate queries. These content summaries can then be used by a metasearcher to select over which collections to evaluate a given query. Second, we have enhanced the SDARTS toolkit so that all SDARTS-compliant collections export their metadata under the emerging Open Archives Initiative (OAI) protocol. Conversely, the SDARTS toolkit now also allows all OAI-compliant collections to be made SDARTS-compliant with minimal effort. As a result, we implemented a bridge between SDARTS and OAI, which will facilitate easy interoperability among a potentially large number of collections. The SDARTS toolkit, with all related documentation and source code, is publicly available at http://sdarts.cs.columbia.edu.

#index 378504
#* Using the open archives initiative protocols with EAD
#@ Christopher J. Prom;Thomas G. Habing
#t 2002
#c 14
#% 337235
#! The Open Archives Initiative Protocols present a promising opportunity to make metadata about archives, manuscript collections, and cultural heritage resources easier to locate and search. However, several technical barriers must be overcome before useful OAI records can be produced from the disparate metadata formats used to describe these resources. This paper examines Encoded Archival Description (EAD) as a test case of the issues to be addressed in transforming cultural heritage metadata to OAI. While EAD and OAI may appear to be incompatible, a mapping would be both useful and technically feasible. The authors suggest that it will be necessary to create numerous OAI records from one EAD file. In addition, the findings indicate that further standardization of EAD markup practices would enhance interoperability.

#index 378505
#* Preservation and transition of NCSTRL using an OAI-based architecture
#@ H. Anan;X. Liu;K. Maly;M. Nelson;M. Zubair;J. C. French;E. Fox;P. Shivakumar
#t 2002
#c 14
#% 294891
#% 337235
#! NCSTRL (Networked Computer Science Technical Reference Library) is a federation of digital libraries providing computer science materials. The architecture of the original NCSTRL was based largely on the Dienst software. It was implemented and maintained by the digital library group at Cornell University until September 2001. At that time, we had an immediate goal of preserving the existing NCSTRL collection and a long-term goal of providing a framework where participating organizations could continue to disseminate technical publications. Moreover, we wanted the new NCSTRL to be based on OAI (Open Archives Initiative) principles that provide a framework to facilitate the discovery of content in distributed archives. In this paper, we describe our experience in moving towards an OAI-based NCSTRL.

#index 378506
#* Integrating harvesting into digital library content
#@ David A. Smith;Anne Mahoney;Gregory Crane
#t 2002
#c 14
#% 249143
#% 337235
#% 337507
#% 343779
#% 815117
#! The Open Archives Initiative has gained success by aiming between complex federation schemes and low functionality web crawling. Much information still remains hidden inside documents catalogued by OAI metadata. We discuss how subdocument information can be exposed by data providers and exploited by service providers. We discuss services for citation reversal and name and term linking with harvested data in the Perseus Project's document management system and a proxy service for automatically adding these links to OAI documents outside Perseus.

#index 378507
#* Harvesting translingual vocabulary mappings for multilingual digital libraries
#@ Ray R. Larson;Fredric Gey;Aitao Chen
#t 2002
#c 14
#% 232648
#% 280826
#% 337234
#% 561150
#% 740900
#% 740915
#% 815097
#! This paper presents a method of information harvesting and consolidation to support the multilingual information requirements for cross-language information retrieval within digital library systems. We describe a way to create both customized bilingual dictionaries and multilingual query mappings from a source language to many target languages. We will describe a multilingual conceptual mapping resource with broad coverage (over 100 written languages can be supported) that is truly multilingual as opposed to bilingual parings usually derived from machine translation. This resource is derived from the 10+ million title online library catalog of the University of California. It is created statistically via maximum likelihood associations from word and phrases in book titles of many languages to human assigned subject headings in English. The 150,000 subject headings can form interlingua mappings between pairs of languages or from one language to several languages. While our current demonstration prototype maps between ten languages (English, Arabic, Chinese, French, German, Italian, Japanese, Portuguese, Russian, Spanish), extensions to additional languages are straightforward. We also describe how this resource is being expanded for languages where linguistic coverage is limited in our initial database, by automatically harvesting new information from international online library catalogs using the Z39.50 networked library search protocol.

#index 378508
#* Detecting events with date and place information in unstructured text
#@ David A. Smith
#t 2002
#c 14
#% 78171
#% 262042
#% 281375
#% 287196
#% 309096
#% 337507
#% 740900
#% 815099
#! Digital libraries of historical documents provide a wealth of information about past events, often in unstructured form. Once dates and place names are identified and disambiguated, using methods that can differ by genre, we examine collocations to detect events. Collocations can be ranked by several measures, which vary in effectiveness according to type of events, but the log-likelihood measure (-2 log &lgr;) offers a reasonable balance between frequently and infrequently mentioned events and between larger and smaller spatial and temporal ranges. Significant date-place collocations can be displayed on timelines and maps as an interface to digital libraries. More detailed displays can highlight key names and phrases associated with a given event.

#index 378509
#* Using sharable ontology to retrieve historical images
#@ Von-Wun Soo;Chen-Yu Lee;Jaw Jium Yeh;Ching-chih Chen
#t 2002
#c 14
#! We present a framework of utilizing sharable domain ontology and thesaurus to help the retrieval of historical images of the First Emperor of China's terracotta warriors and horses. Incorporating the sharable domain ontology in RDF and RDF schemas of semantic web and a thesaurus, we implement methods to allow easily annotating images into RDF instances and parsing natural language like queries into the query schema in XML format. We also implement a partial structural matching algorithm to match the query schema with images at the level of semantic schemas. Therefore the historical images can be retrieved by naïve users of domain specific history in terms of natural language like queries.

#index 378510
#* Towards an electronic variorum edition of Cervantes' Don Quixote:: visualizations that support preparation
#@ Rajiv Kochumman;Carlos Monroy;Richard Furuta;Arpita Goenka;Eduardo Urbina;Erendira Melgoza
#t 2002
#c 14
#% 126298
#! The Cervantes Project is creating an Electronic Variorum Edition (EVE) of Cervantes' well-known Don Quixote de la Mancha, published beginning in 1605. In this paper, we report on visualizations of features of a text collection that help us validate our text transcriptions and understand the relationships among the different printings of an edition.

#index 378511
#* Core services in the architecture of the national science digital library (NSDL)
#@ Carl Lagoze;William Arms;Stoney Gan;Diane Hillmann;Christopher Ingram;Dean Krafft;Richard Marisa;Jon Phipps;John Saylor;Carol Terrizzi;Walter Hoehn;David Millman;James Allan;Sergio Guzman-Lara;Tom Kalt
#t 2002
#c 14
#% 197531
#% 245815
#% 337235
#% 424292
#% 836050
#! We describe the core components of the architecture for the National Science Digital Library (NSDL). Over time the NSDL will include heterogeneous users, content, and services. To accommodate this, a design for a technical and organization infrastructure has been formulated based on the notion of a spectrum of interoperability. This paper describes the first phase of the interoperability infrastructure including the metadata repository, search and discovery services, rights management services, and user interface portal facilities.

#index 378512
#* Creating virtual collections in digital libraries: benefits and implementation issues
#@ Gary Geisler;Sarah Giersch;David McArthur;Marty McClelland
#t 2002
#c 14
#% 185274
#% 249151
#% 287597
#% 332737
#! Digital libraries have the potential to not only duplicate many of the services provided by traditional libraries but to extend them. Basic finding aids such as search and browse are common in most of today's digital libraries. But just as a traditional library provides more than a card catalog and browseable shelves of books, an effective digital library should offer a wider range of services. Using the traditional library concept of special collections as a model, in this paper we propose that explicitly defining sub-collections in the digital library-virtual collections-can benefit both the library's users and contributors and increase its viability. We first introduce the concept of a virtual collection, outline the costs and benefits for defining such collections, and describe an implementation of collection-level metadata to create virtual collections for two different digital libraries. We conclude by discussing the implications of virtual collections for enhancing interoperability and sharing across digital libraries, such as those that are part of the National SMETE Digital Library.

#index 378513
#* Ontology services for curriculum development in NSDL
#@ Amarnath Gupta;Bertram Ludäscher;Reagan W. Moore
#t 2002
#c 14
#% 156337
#% 342980
#% 535998
#! We describe our effort to develop an ontology service on top of an educational digital library. The ontology is developed by relating library holdings to the educational concepts they refer to. The ontology system supports basic services like ontology-based search and complex services such as comparison of multiple curricula.

#index 378514
#* Interactive digital library resource information system: a web portal for digital library education
#@ Ahmad Rafee Che Kassim;Thomas R. Kochtanek
#t 2002
#c 14
#! This paper describes a collaborative database project that focuses on access to materials on topics relating to digital libraries that are organized within an educational framework.

#index 378515
#* Cross-cultural usability of the library metaphor
#@ Elke Duncker
#t 2002
#c 14
#% 193783
#% 193785
#% 217826
#% 217827
#% 217843
#% 224578
#% 260105
#% 299122
#% 308828
#% 352920
#% 382885
#% 394790
#% 531584
#! Computing metaphors have become an integral part of information systems design, yet they are deeply rooted in cultural practices. This paper presents an investigation of the cross-cultural use and usability of such metaphors by studying the library metaphor of digital libraries in the cultural context of the Maori, the indigenous population of New Zealand. The ethnographic study examines relevant features of the Maori culture, their form of knowledge transfer and their use of physical and digital libraries. On this basis, the paper points out why and when the library metaphor fails Maori and other indigenous users, and indicates how this knowledge can contribute to the improvement of future designs.

#index 378516
#* Trust and epistemic communities in biodiversity data sharing
#@ Nancy A. Van House
#t 2002
#c 14
#% 82805
#% 237321
#% 260777
#% 297608
#% 300669
#% 316797
#% 316800
#% 319078
#% 319704
#% 319706
#% 322279
#% 324926
#% 330264
#% 386005
#% 387309
#% 739905
#% 1134818
#! Trust is a key element of knowledge work: what we know depends largely on others. This paper discusses the concepts of communities of practice and epistemic cultures, and their implication for design of digital libraries that support data sharing, with particular reference to practices of trust and credibility. It uses an empirical study of a biodiversity digital library of data from a variety of sources to illustrate implications digital library design and operation. It concludes that diversity and uncomfortable boundary areas typify, not only digital library user groups, but the design and operation of digital libraries.

#index 378517
#* Evaluation of digital community information systems
#@ K. T. Unruh;K. E. Pettigrew;J. C. Durrance
#t 2002
#c 14
#% 282914
#% 337252
#! Community information systems provide a critical link between local resources and residents. While online versions of these systems have potential benefits, a systematic evaluation framework is needed to analyze and document realized impacts. Based on data from a nation-wide study of digital community information systems, an evaluation framework is proposed.

#index 378518
#* Adapting digital libraries to continual evolution
#@ Bruce R. Barkstrom;Melinda Finch;Michelle Ferebee;Calvin Mackey
#t 2002
#c 14
#% 337484
#% 337486
#! In this paper, we describe five investment streams (data storage infrastructure, knowledge management, data production control, data transport and security, and personnel skill mix) that need to be balanced against short-term operating demands in order to maximize the probability of long-term viability of a digital library. Because of the rapid pace of information technology change, a digital library cannot be a static institution. Rather, it has to become a flexible organization adapted to continuous evolution of its infrastructure.

#index 378519
#* Localizing experience of digital content via structural metadata
#@ Naomi Dushay
#t 2002
#c 14
#% 337235
#% 342442
#% 673710
#! With the increasing technical sophistication of both information consumers and providers, there is increasing demand for more meaningful experiences of digital information. We present a framework that separates digital object experience, or rendering, from digital object storage and manipulation, so the rendering can be tailored to particular communities of users. Our framework also accommodates extensible digital object behaviors and interoperability. The two key components of our approach are 1) exposing structural metadata associated with digital objects - metadata about labeled access points within a digital object and 2) information intermediaries called context brokers that match structural characteristics of digital objects with mechanisms that produce behaviors. These context brokers allow for localized rendering of digital information stored externally.

#index 378520
#* Collection synthesis
#@ Donna Bergmark
#t 2002
#c 14
#% 46809
#% 210684
#% 249110
#% 255137
#% 255179
#% 262045
#% 262061
#% 268073
#% 268079
#% 281166
#% 281209
#% 281251
#% 281253
#% 300967
#% 301247
#% 309145
#% 309493
#% 309517
#% 309743
#% 309748
#% 309787
#% 330609
#% 337242
#% 338816
#% 340141
#% 340147
#% 420495
#% 424292
#% 480309
#% 836019
#! The invention of the hyperlink and the HTTP transmission protocol caused an amazing new structure to appear on the Internet -- the World Wide Web. With the Web, there came spiders, robots, and Web crawlers, which go from one link to the next checking Web health, ferreting out information and resources, and imposing organization on the huge collection of information (and dross) residing on the net. This paper reports on the use of one such crawler to synthesize document collections on various topics in science, mathematics, engineering and technology. Such collections could be part of a digital library.

#index 378521
#* 5SL: a language for declarative specification and generation of digital libraries
#@ Marcos André Gonçalves;Edward A. Fox
#t 2002
#c 14
#% 211520
#% 262249
#% 281256
#% 283883
#% 301247
#% 309729
#% 318990
#% 387427
#% 479981
#% 480121
#% 527395
#% 571038
#% 608347

#index 378522
#* A digital library of conversational expressions: helping profoundly disabled users communicate
#@ Hayley Dunlop;Sally Jo Cunningham;Matt Jones
#t 2002
#c 14
#% 194502
#! Digital libraries are for everyone. This paper describes the development of a digital library for a user who has a profound physical disability that means she cannot communicate verbally, and cannot use conventional communication tools.

#index 378523
#* Enhancing the ENVISION interface for digital libraries
#@ Jun Wang;Abhishek Agrawal;Anil Bazaza;Supriya Angle;Edward A. Fox;Chris North
#t 2002
#c 14
#% 641060
#% 856000
#! To enhance the ENVISION interface and facilitate user interaction, various techniques were considered for better rendering of search results with improved scalability. In this paper we discuss the challenges we encountered and our solutions to those problems.

#index 378524
#* A wearable digital library of personal conversations
#@ Wei-hao Lin;Alexander G. Hauptmann
#t 2002
#c 14
#% 199217
#% 251145
#% 592110
#% 592157
#% 592420
#! We have developed a wearable, personalized digital library system, which unobtrusively records the wearer's part of a conversation, recognizes the face of the current dialog partner and remembers his/her voice. The next time the system sees the same person and hears the same voice, it can replay parts of the last conversation in compressed form. Results from a prototype system show the effectiveness of combining of face recognition and speaker identification for retrieving conversations.

#index 378525
#* Collaborative visual interfaces to digital libraries
#@ Katy Börner;Ying Feng;Tamara McMahon
#t 2002
#c 14
#% 102726
#% 122797
#% 259946
#% 301269
#% 337564
#% 419107
#% 434896
#% 635091
#! This paper argues for the design of collaborative visual interfaces to digital libraries that support social navigation. As an illustrative example we present work in progress on the design of a three-dimensional document space for a scholarly community - namely faculty, staff, and students at the School of Library and Information Science, Indiana University.

#index 378526
#* Binding browsing and reading activities in a 3D digital library
#@ Pierre Cubaud;Pascal Stokowski;Alexandre Topol
#t 2002
#c 14
#% 214669
#% 249188
#% 323485
#! Browsing through digitalized books collections and reading activities are separated in most present WWW-based user's interfaces of digital libraries. This context break induces longer apprenticeship and navigation time within the interface. We study in this paper how 3D interaction metaphors provide a continuous navigation space for these two tasks.

#index 378527
#* DP9: an OAI gateway service for web crawlers
#@ Xiaoming Liu;Kurt Maly;Mohammad Zubair;Michael L. Nelson
#t 2002
#c 14
#% 337235
#! Many libraries and databases are closed to general-purpose Web crawlers, and they expose their content only through their own search engines. At the same time many researchers attempt to locate technical papers through general-purpose Web search engines. DP9 is an open source gateway service that allows general search engines, (e.g. Google, Inktomi) to index OAI-compliant archives. DP9 does this by providing consistent URLs for repository records, and converting them to OAI queries against the appropriate repository when the URL is requested. This allows search engines that do not support the OAI protocol to index the "deep Web" contained within OAI compliant repositories.

#index 378528
#* The Greenstone plugin architecture
#@ Ian H. Witten;David Bainbridge;Gordon Paynter;Stefan Boddie
#t 2002
#c 14
#% 301247
#! This note describes how the Greenstone digital library system uses "plugins" to import documents and metadata in different formats, and associate metadata with the appropriate documents. Plugins that import documents can perform their own format conversion internally, or take advantage of existing conversion programs. Metadata can be read from the input documents, or from separate metadata files, or are computed from the documents themselves. New plugins can be written for novel situations.

#index 378529
#* Building FLOW: federating libraries on the web
#@ Anna Keller Gold;Karen S. Baker;Jean-Yves LeMeur;Kim Baldridge
#t 2002
#c 14
#! Individuals, teams, organizations, and networks can be thought of as tiers or classes within the complex grid of technology and practice in which research documentation is both consumed and generated. The panoply of possible classes share with the others a common need for document management tools and practices. The distinctive document management tools and practices used within each represent boundaries across which information could flow openly if technology and metadata standards were to provide an accessible digital framework. The CERN Document Server (CDS), implemented by a research partnership at the San Diego Supercomputer Center (SDSC), establishes a prototype tiered repository system for such a panoply. Research suggests modifications to enable cross-domain information flow and is represented as a metadata grid.

#index 378530
#* JAFER ToolKit project: interfacing Z39.50 and XML
#@ Antony Corfield;Matthew Dovey;Richard Mawby;Colin Tatham
#t 2002
#c 14
#% 337426
#! In this paper, we describe the JAFER ToolKit project which is developing a simplified XML based API above the Z39.50 protocol[1]. The ToolKit allows the development of both Z39.50 based applications (both clients and servers) without detailed knowledge of the complexities of the protocol.

#index 378531
#* Schema extraction from XML collections
#@ Boris Chidlovskii
#t 2002
#c 14
#% 145336
#% 299944
#% 300157
#% 504573
#! XML Schema language has been proposed to replace Document Type Definitions (DTDs) as schema mechanism for XML data. This language consistently extends grammar-based constructions with constraint- and pattern-based ones and have a higher expressive power than DTDs. As schemas remain optional for XML, we address the problem of XML Schema extraction. We model the XML schema as extended context-free grammars and develop a novel extraction algorithm inspired by methods of grammatical inference. The algorithm copes also with the schema determinism requirement imposed by XML DTDs and XML Schema languages.

#index 378532
#* Mirroring an OAI archive on the I2-DSI channel
#@ Ashwini Pande;Malini Kothapalli;Ryan Richardson;Edward A. Fox
#t 2002
#c 14
#% 337235
#% 337236
#! The Open Archives Initiative (OAI) promotes interoperability among digital libraries and has created a protocol for data providers to easily export their metadata. One problem with this approach is that some of the more popular servers quickly become heavily loaded. The obvious solution is replication. Fortunately, the Internet-2 Distributed Storage Infrastructure (I2-DSI) has begun to develop technology for highly distributed transparent replication of servers. This paper presents our solution for transparent mirroring of OAI repositories within the I2-DSI.

#index 378533
#* HMM-based musical query retrieval
#@ Jonah Shifrin;Bryan Pardo;Colin Meek;William Birmingham
#t 2002
#c 14
#% 204646
#% 280845
#! We have created a system for music search and retrieval. A user sings a theme from the desired piece of music. Pieces in the database are represented as hidden Markov models (HMMs). The query is treated as an observation sequence and a piece is judged similar to the query if its HMM has a high likelihood of generating the query. The top pieces are returned to the user in rank-order. This paper reports the basic approach for the construction of the target database of themes, encoding and transcription of user queries, and the results of initial experimentation with a small set of sung queries.

#index 378534
#* A comparison of melodic database retrieval techniques using sung queries
#@ Ning Hu;Roger B. Dannenberg
#t 2002
#c 14
#% 137711
#% 194192
#% 204646
#% 261908
#! Query-by-humming systems search a database of music for good matches to a sung, hummed, or whistled melody. Errors in transcription and variations in pitch and tempo can cause substantial mismatch between queries and targets. Thus, algorithms for measuring melodic similarity in query-by-humming systems should be robust. We compare several variations of search algorithms in an effort to improve search precision. In particular, we describe a new frame-based algorithm that significantly outperforms note-by-note algorithms in tests using sung queries and a database of MIDI-encoded music.

#index 378535
#* Enhancing access to the levy sheet music collection: reconstructing full-text lyrics from syllables
#@ Brian Wingenroth;Mark Patton;Tim DiLauro
#t 2002
#c 14
#% 216017
#% 746903
#! The goal of the Lester S. Levy Sheet Music Collection, Phase Two project is to develop tools, processes, and systems that facilitate collection ingestion through automated processes that reduce, but not necessarily eliminate human intervention[1]. One of the major components of this project is an optical music recognition (OMR) system[2] that extracts musical information and lyric text from the page images that comprise each piece in a collection. It is often the case, as it is with the Levy Collection, that lyrics embedded in music notation are written in a syllabicated form so that each syllable lines up with the note or notes to which it corresponds. Searching the syllabicated form of words, however, would be counterintuitive and cumbersome for end-users. This paper describes the evolution of a tool that, using a simple algorithm, rebuilds complete words from lyric syllables and, in ambiguous cases, provides feedback to the collection builder. This system will be integrated into the workflow of the Levy Sheet Music Collection, but has broad applicability for any project ingesting musical scores with lyrics.

#index 378536
#* Evaluating automatic melody segmentation aimed at music information retrieval
#@ Massimo Melucci;Nicola Orio
#t 2002
#c 14
#% 278106
#% 281389
#% 395687
#! In this paper we investigate the effectiveness of a melody segmentation algorithm based on melodic feature. The segmentation produced by experienced music scholars have been compared with the algorithm, a random segmenter and a n-gram-based segmenter. Results showed that the algorithm is closer to manual segmentation than the other segmenters.

#index 378537
#* A methodology and system for preserving digital data
#@ Raymond A. Lorie
#t 2002
#c 14
#% 161323
#% 337483
#% 356167
#% 356606
#! This paper refers to a previous proposal made at the 1st Joint Conference on Digital Libraries, on a novel approach to the problem of the long-term archiving of digital data. It reports on ongoing work in refining the methodology and building an initial prototype. The method is based on the use of a Universal Virtual Computer (UVC) to specify the process that needs to be applied to the archived data in order to make it understandable for a future client. There is a certain amount of information (a Convention) that must be preserved for an indefinite time, to make sure that the client will be able to recover the information. A first version of this Convention is given here; it includes the architecture of the UVC. The paper also briefly mentions our current activities in implementation and evaluation.

#index 378538
#* Modeling web data
#@ James C. French
#t 2002
#c 14
#% 375076
#% 387427
#% 608625
#% 680663
#! We have created three testbeds of web data for use in controlled experiments in collection modeling. This short paper examines the applicability of Ziff's and Heaps' laws as applied to web data. We find extremely close agreement between observed vocabulary growth and Heaps' law. We find reasonable agreement with Ziff's law for medium to low frequency terms. Ziff's law is a poor predictor for high frequency terms. These findings hold for all three testbeds although we restrict ourselves to one here due to space limitations.

#index 378539
#* An evaluation model for a digital library services tool
#@ Jim Dorward;Derek Reinke;Mimi Recker
#t 2002
#c 14
#! This paper describes an evaluation model for a digital library tool, the Instructional Architect, which enables users to discover, select, reuse, sequence, and annotate digital library learning objects. By documenting our rapid-prototyping, iterative, and user-centered approach for evaluating a digital library service, we provide a model and set of methods that other developers may wish to employ. In addition, we provide preliminary results from our studies.

#index 378540
#* Why watermark?: the copyright need for an engineering solution
#@ Michael Seadle;J. R. Deller, Jr.;Aparna Gurijala
#t 2002
#c 14
#% 337420
#! An important research component in the creation of the National Gallery of the Spoken Word (NGSW) is the development of watermarking technologies for the audio library. In this paper we argue that audio watermarking is a particularly desirable means of intellectual property protection. There is evidence that the courts consider watermarks to be a legitimate form of copyright protection. Watermarking facilitates redress, and represents a form of copyright protection that universities can use without being inconsistent in their mission to disseminate knowledge.

#index 378541
#* Time as essence for photo browsing through personal digital libraries
#@ Adrian Graham;Hector Garcia-Molina;Andreas Paepcke;Terry Winograd
#t 2002
#c 14
#% 272902
#% 324983
#% 337553
#% 342528
#% 438054
#% 589969
#! We developed two photo browsers for collections with thousands of time-stamped digital images. Modern digital cameras record photo shoot times, and semantically related photos tend to occur in bursts. Our browsers exploit the timing information to structure the collections and to automatically generate meaningful summaries. The browsers differ in how users navigate and view the structured collections. We conducted user studies to compare the two browsers and an un-summarized image browser. Our results show that exploiting the time dimension and appropriately summarizing collections can lead to significant improvements. For example, for one task category, one of our browsers enabled a 33% improvement in speed of finding given images compared to the commercial browser. Similarly, users were able to complete 29% more tasks when using this same browser.

#index 378542
#* Toward a distributed terabyte text retrieval system in China-US million book digital library
#@ Bin Liu;Wen Gao;Ling Zhang;Tie-jun Huang;Xiao-ming Zhang;Jun Cheng
#t 2002
#c 14
#% 708700
#% 1834787
#! In China-US Million Book Digital Library, output of the digitalization process is more than one terabyte of text in OEB and PDF format. To access these data quickly and accurately, we are developing a distributed terabyte text retrieval system. With the query cache, system can search less data while maintaining acceptable retrieval accuracy. From the OEB package, we get its metadata and structural information to implement multi-scale indexing and retrieval. We are to explore some new retrieval models and text clustering approaches in the Digital Library.

#index 378543
#* Enhanced perspectives for historical and cultural documentaries using informedia technologies
#@ Howard D. Wactlar;Ching-chih Chen
#t 2002
#c 14
#% 239596
#% 286900
#% 337241
#% 438054
#! Speech recognition, image processing, and language understanding technologies have successfully been applied to broadcast news corpora to automate the extraction of metadata and make use of it in building effective video news retrieval interfaces. This paper discusses how these technologies can be adapted to cultural documentaries as represented by the award-winning First Emperor of China videodisc and multimedia CD. Through automated means, efficient interfaces into documentary contents can be built dynamically based on user needs. Such interfaces enable the assemblage of large video documentary libraries from component videodisc, CD, and videotape projects, with alternate views into the material complementing the original sequences authored by the materials' producers.

#index 378544
#* Interfaces for palmtop image search
#@ Mark Derthick
#t 2002
#c 14
#% 295137
#% 584921
#! Will current technology support search for video news or entertainment on mobile platforms? An Ipaq palmtop version of the Informedia Digital Video Library interface has already been developed at the Chinese University of Hong Kong. For these displays, the desktop technique of showing a large grid of images in parallel is not feasible. Perceptual psychology experiments suggest that time-multiplexing may be as effective as space-multiplexing for this kind of primed recognition task. In fact, it has been specifically suggested that image retrieval interfaces using Rapid Serial Visual Presentation (RSVP) may perform significantly better than parallel presentation even on a desktop computer [2]. In our experiments, we did not find this to be true. An important difference between previous RSVP experiments and our own is that image search engines rank retrievals, and correct answers are more likely to occur early in the list of results. Thus we found that scrolling (and low RSVP presentation rates) led to better recognition of answers that occur early, but worse for answers that occur far down the list. This split confounded the global effects that we hypothesized, yet in itself is an important consideration for future interface designs, which must adapt as search technology improves.

#index 378545
#* The ADEPT digital library architecture
#@ Greg Janée;James Frew
#t 2002
#c 14
#% 185267
#% 185268
#% 227891
#% 287597
#% 337246
#% 498511
#% 659976
#% 664819
#! The Alexandria Digital Earth ProtoType (ADEPT) architecture is a framework for building distributed digital libraries of georeferenced information. An ADEPT system comprises one or more autonomous libraries, each of which provides a uniform interface to one or more collections, each of which manages metadata for one or more items. The primary standard on which the architecture is based is the ADEPT bucket framework, which defines uniform client-level metadata query services that are compatible with heterogeneous underlying collections. ADEPT functionality strikes a balance between the simplicity of Web document delivery and the richness of Z39.50. The current ADEPT implementation runs as servlet-based middleware and supports collections housed in arbitrary relational databases.

#index 378546
#* G-Portal: a map-based digital library for distributed geospatial and georeferenced resources
#@ Ee-Peng Lim;Dion Hoe-Lian Goh;Zehua Liu;Wee-Keong Ng;Christopher Soo-Guan Khoo;Susan Ellen Higgins
#t 2002
#c 14
#% 204661
#% 249161
#% 301253
#% 333651
#% 333652
#% 337246
#% 337496
#% 437510
#% 665530
#! As the World Wide Web evolves into an immense information network, it is tempting to build new digital library services and expand existing digital library services to make use of web content. In this paper, we present the design and implementation of G-Portal, a web portal that aims to provide digital library services over geospatial and georeferenced content found on the World Wide Web. G-Portal adopts a map-based user interface to visualize and manipulate the distributed geospatial and georeferenced content. Annotation capabilities are supported, allowing users to contribute geospatial and georeferenced objects as well as their associated metadata. The other features included in G-Portal's design are query support, content classification, and content maintenance. This paper will mainly focus on the architecture design, visualization and annotation capabilities of G-Portal.

#index 378547
#* You mean I have to do what with whom: statewide museum/library DIGI collaborative digitization projects---the experiences of California, Colorado & North Carolina
#@ Nancy Allen;Liz Bishoff;Robin Chandler;Kevin Cherry
#t 2002
#c 14

#index 378548
#* Overcoming impediments to effective health and biomedical digital libraries
#@ William Hersh;Jan Velterop;Alexa McCray;Gunther Eynsenbach;Mark Boguski
#t 2002
#c 14
#! Digital libraries have great promise in the health and biomedical domains. Yet a variety of impediments exist to their more effective use. A series of panelists from a variety of backgrounds in health and biomedicine will explore these impediments and describe how they might be overcome.

#index 378549
#* The challenges of statistical digital libraries
#@ Cathryn Dippo;Patricia Cruse;Ann Green;Carol Hert
#t 2002
#c 14
#! What are statistical digital libraries? Who uses them? For what purpose? How do they differ from or resemble text-focused digital libraries? What are the research issues associated with their use and the implications for interface design?These are just some of the issues the panelists have been grappling with over the last few years as government agencies and academic libraries rush to make their holdings web-accessible to both the users they have always served and all kinds of new users with varying statistical and computing skills.The panelists represent a variety of user-oriented perspectives-some are developers, some are intermediaries, some are users themselves. Their primary user focus varies from university students and faculty to government policy analysts, but the casual or first-time user must also be served.The panelist will focus their remarks on the challenges of statistical libraries on a multitude of dimensions, including technical, social, behavioral, economic, organizational, etc. The discussion should both inform and entice the audience to pursue some difficult and interesting problems in digital library research.

#index 378550
#* Biodiversity and biocomplexity informatics: policy and implementation science versus citizen science
#@ P. Bryan Heidorn
#t 2002
#c 14
#! Biological science is one of the top ten social trends and the twenty-first Century has been defined as "The Age of Biology" [1]. One of the central themes of this age is biodiversity. Biodiversity is the richness of life. Biodiversity includes the variety of genes within one species through the complex interconnection of all life within an environment. One of the grand challenges of the twenty-first century is to document and understand the world's natural heritage. The management of the many kinds of information associated with this endeavor is "Biodiversity Informatics." There are many efforts developing worldwide to collect and distribute this information in digital collections. Some of these efforts are complementary; some efforts are in conflict and are just independent. There is a great need to integrate this information to increate its usefulness and value. Unfortunately, this integration is extremely difficult because of the diversity of the use and users of the information and the diversity of the information itself. The panelists will discuss different perspectives on the construction of global biodiversity digital libraries from the perspective of different goals and uses.

#index 378551
#* Panel on digital preservation
#@ Joyce Ray;Robin Dale;Reagan Moore;Vicky Reich;William Underwood;Alexa T. McCray
#t 2002
#c 14
#% 337483
#% 356167
#! Digital information in any form is at risk. Software and hardware become obsolete, and versions and file formats change, making data inaccessible. Data stored in even the simplest form are in danger due to computer media degradation and obsolescence. On-line information such as e-journals and databases are susceptible. They may become partially or entirely unreadable, and may not be recoverable by the time the problem is detected. Preservation strategies such as emulation (keeping alive the software and hardware needed to access a digital object), migration (converting the digital object to new versions and formats), and other long-term archival methods have been proposed [1-7]. Models such as the Open Archival Information System (OAIS) provide an architecture for conducting digital preservation research and experimentation [8-10]. The importance of preservation metadata has been recognized by a number of groups and efforts to develop and deploy metadata standards are underway [11-14].As more and more digital information is created, attention must be paid to what information should be preserved and how it can be preserved most economically and effectively. It is clear that for preservation to be successful, we need to pay attention not only to the format of digital objects, but also to the commitment we make to providing long-term access to the information. Thus, decisions about digital preservation will involve technical issues as well as economic, legal, social, and organizational ones. Is it possible or feasible to preserve all digital data automatically and in a cost effective way? How much functionality can or must be preserved? What type of metadata will be needed to ensure both access and preservation? What metrics do we use to evaluate whether our methods will be successful.Panelists will make short presentations about work in which they have been involved and which reflect a variety of aspects of digital preservation. Reagan Moore will discuss the levels of abstraction that are needed to create infrastructure independent representations for data, information, and knowledge, and he will discuss a prototype persistent digital archive. The persistent archive infrastructure has been developed for use by the National Archives and Records Administration and other Federal agencies. William Underwood will report on lessons learned in preserving digital records created on personal computers. The records being examined are the digital records created on personal computers during the administration of President George Bush (1988-1992). Vicky Reich will present work on the LOCKSS (Lots of Copies Keep Stuff Safe) project, which is a permanent web publishing and access system. LOCKSS software allows libraries to retain local collection control of materials delivered through the web while preserving the functionality of the original web based content. Robin Dale will report on activities of the preservation program of the Research Libraries Group (RLG). She will focus on the joint work of RLG and OCLC (Online Computer Library Center) on preservation metadata. Following the presentations by the four panelists, Alexa McCray will provide brief comments and then open the discussion for audience participation.

#index 378552
#* NSDL: from prototype to production to transformational national resource
#@ William Y. Arms;Edward Fox;Jeanne Narum;Ellen Hoffman
#t 2002
#c 14
#! This panel will discuss the first release of the National Science Digital Library and plans for growing it into a very large, comprehensive library of digital materials relevant to science education.

#index 378553
#* How important is metadata?
#@ Hector Garcia-Molina;Diane Hillmann;Carl Lagoze;Elizabeth Liddy;Stuart Weibel
#t 2002
#c 14
#! Metadata is expensive. Information services and digital library researchers spend considerable time, effort, and money on metadata. It is time to ask a number of important questions: How much metadata is really necessary and for what reason? What are the right metrics for metadata; its correctness, appropriateness, and return on investment? Is metadata harvesting really useful for the creation of digital library services? Are the assumptions about the utility, or even necessity, of metadata a legacy of years of library science and practice? Do these assumptions make sense in the current context of massive computing power and automatic analysis?.Clearly there is no one "correct' answer to these questions. The panel will provide the forum for practitioners and researchers from a number of areas to express their views and, hopefully, provoke stimulating discussions from the audience.

#index 378554
#* Planning for future digital libraries programs
#@ Stephen M. Griffin
#t 2002
#c 14
#! This panel will discuss alternatives for follow-on Federal program activities to the Interagency Digital Libraries Initiative - Phase 2 (DLI-2). The current Digital Libraries Initiative - Phase 2 awards receive final funding increments in FY 2003. The National Science Foundation and other interested agencies wish to begin informal planning for potential follow-on activities to DLI-2 at this time. As in the past, sponsoring agencies look to the various stakeholder communities to assist in the creation of funding programs that are responsive to values, needs and opportunities.Panelists will present viewpoints as to the most important topical elements and effective program structures in light of the continuing rapid evolution of digital libraries technologies, computing and communication infrastructures and dramatic increase in networked digital content. Audience remarks will be encouraged, particularly suggestions for enabling broad community involvement in the planning dialogue.

#index 378555
#* The Miguel de Cervantes Digital Library: a wide diversity of content, media, functionality and services
#@ Alejandro Bia
#t 2002
#c 14
#! This demo describes the philosophy behind what represents one of the most ambitious projects of its kind in the Spanish-speaking world: The Miguel de Cervantes Digital Library (http://cervantesvirtual.com/). It shows the new ground being explored in terms of the wide variety of contents, media, functionality and services it offers to a worldwide audience. These services are meant to be used in serious research, as teaching aids, or just for cultural amusement and enjoyment.We will also describe the technical underpinnings of this project reporting also ongoing research and development activities.

#index 378556
#* DSpace: durable digital documents
#@ Margret Branschofsky;Daniel Chudnov
#t 2002
#c 14
#% 337552
#! The DSpace system for long-term management of institutional scholarly research repositories is now in use at the MIT Libraries; we will demonstrate the system and provide more information about its design, use at MIT, and other potential uses.

#index 378557
#* NanoPort: a web portal for nanoscale science and technology
#@ Michael Chau;Hsinchun Chen;Jialun Qin;Yilu Zhou;Wai-Ki Sung;Yongchi Chen;Yi Qin;Daniel McDonald;Ann Lally;Matthew Landon
#t 2002
#c 14
#% 224706
#% 295520
#% 378497

#index 378558
#* Variations2: a digital music library system
#@ Jon W. Dunn;Eric J. Isaacson
#t 2002
#c 14
#% 281339
#% 378499
#! This demonstration will show version 1.0 of the Variations2 digital library system developed by Indiana University. Variations2 is being built to provide access to music in a variety of formats-sound recordings, scanned musical scores, computer score notation files, and video-and is designed to support research and learning in the field of music.

#index 378559
#* The learning matrix: cataloging resources with rich metadata
#@ Lyndsay R. Greer
#t 2002
#c 14
#! Effective searching of a digital library requires that the library keep rich metadata about each of its resources. Entering complex metadata efficiently, accurately, and consistently can be confusing and time consuming. A demonstration of the Learning Matrix's Cataloging Tool, a web-based solution for creating metadata while uploading resources to the digital library, will be presented.

#index 378560
#* Video retrieval with multiple image search strategies
#@ Alexander G. Hauptmann;Michael G. Christel;Norman D. Papernick
#t 2002
#c 14
#% 169940
#% 438054
#% 1854913

#index 378561
#* Reprocessing paper-based reference materials for the digital environment
#@ P. Bryan Heidorn
#t 2002
#c 14
#! One of the primary challenges for the creation of digital libraries is to enhance the value of paper-based publications by providing digital access to the materials. Simple full-text searching is just a first step in this process. Better functionality may be gained by exploiting the natural structure within text. The following paper describes the process of digital conversion and integration of encyclopedic publications, glossaries and thesauri. The Biological Information Browsing (http://www.biobrowser.org) team developed text-processing tools, and an information retrieval and visualization environment that provides greater functionality for these traditionally paper-based publications [1]. The process includes automatic text segmentation and structuring, automated XML markup, structure-based indexing, automatic thesaurus extraction for query expansion and on-line definitions. Very few other information systems provide complete services for publishing, indexing, XML query and retrieving documents.

#index 378562
#* A framework for collaborative information environments and unified access to distributed digital content
#@ Jon Herlocker;Janet Webster;Seikyung Jung;Anton Dragunov;Tim Holt;Tammy Culter;Sally Haerer
#t 2002
#c 14
#! In this demo, we will present two prototypes of digital information portals developed using a new common framework: The High Performance Computing Virtual Consultant and the Tsunami Digital Library. This framework supports the creation of digital library portals that include not only local data but distributed content that is not under the control of the portal maintainers, such as remote web sites. The framework provides a common user interface across all resources, even if the resources are served by a remote web site. Furthermore, the framework contains features that support effective low maintenance operation and intelligent learning search and layout algorithms.

#index 378563
#* Active netlib: an active mathematical software collection for inquiry-based computational science & engineering education
#@ Shirley Moore;A. J. Baker;Jack Dongarra
#t 2002
#c 14
#% 678550
#! A core subject in the undergraduate education of application scientists and engineers is the use of mathematical software to solve computational problems. To make effective use of mathematical software, application developers need a basic understanding of the underlying numerical methods and enough knowledge to be able to choose an appropriate solver, parameterize it correctly, and validate the computed results. Correct results are of course required, but good computational performance is desired as well. Most application scientists have neither the time nor the interest to read the current literature in numerical analysis. They solve numerical problems by relying on the methods and programs they learned about in previous coursework. This tendency has the unfortunate consequence that new methods with improved functionality and/or efficiency may go unused by practicing engineers. Application engineers need enough understanding of the underlying numerical methods to be able to detect and diagnose problems that occur and to modify or customize the methods if necessary.A large amount of mathematical software is both commercially and freely available. However, not all the software that is available is of high quality. It can also be difficult to locate the appropriate software by using web search engines, since the descriptions available for searching may be lacking or may not match the vocabulary used by the searcher. A good solution to these problems is to have experts in the field of numerical analysis maintain a moderated collection of high quality software which is organized and cataloged with appropriate metadata to enable easy searching. The Netlib mathematical software repository is such a collection that has been contributed to and managed by the numerical analysis community for the past fifteen years.Active Netlib provides an active collection of high-quality mathematical software resources in the context of an inquiry-based learning environment for computational science and engineering education. The Netlib collection is being extended in a number of ways to support the goals of this project. The NetSolve client-server system for accessing hardware and software resources over a network provides an active interface to the contents of Netlib. NetSolve essentially constructs network-accessible objects with executable content from the software packages in Netlib.By making the subroutines housed in Netlib available over the network on computational servers, NetSolve enables access to up-to-date mathematical software from a variety of client interfaces running on users' workstations, without requiring the users to download and install the software themselves.This demonstration will illustrate the following digital library technology:Searching and browsing the active mathematical software collection using the Repository In a Box (RIB) interface; once relevant software is located, it can be dynamically installed on demand on a computational server.Invoking executable content on NetSolve computational servers from the MATLAB client interfaceUse of an interactive adaptive user interface to guiding the user in learning about iterative methods for solving large sparse linear systemsFor more information, see the Active-Netlib home page at http://icl.cs.utk.edu/active-netlib/.

#index 378564
#* Stanford encyclopedia of philosophy: a dynamic reference work
#@ Uri Nodelman;Colin Allen;Edward N. Zalta
#t 2002
#c 14
#! The Recent work of the Stanford Encyclopedia of Philosophyproject http://plato.stanford.edu/ has been focused on fosteringand managing the growth of a dynamic reference work. Our particularproject is to produce an authoritative and comprehensive dynamicreference work devoted to the academic discipline of philosophythat will be kept up to date dynamically so as to remainuseful to those in academia and the general public.Our concept of a dynamic reference work is defined in away which distinguishes it from other online publishing projects,namely: (1) it is published in a continuously revisable electronicmedium, (2) it offers a comprehensive set of entries on topics in atarget discipline, (3) it provides the authors of the entrieswith electronic access to the reference work's central webserver, so that they can remotely edit and update private copies oftheir entries and submit them for publication according to aregular update schedule and at any other time it becomes necessaryto revise, (4) it maintains quality by way of a distinguished Boardof Editors, the members of which commission the entries and refereeboth the initial versions of the entries and subsequent substantivemodifications, prior to publication on the web, and (5) itcreates, and makes publicly available, archives of the entries onat least a quarterly basis (i.e., these contain fixed versions ofthe entries, which can be cited in scholarly publications). Adynamic reference work based on this model constantly evolves andbecomes responsive to new research.Thus, a dynamic reference work is not merely a revisable work orone that is published online. Successful implementation of thedynamic aspects of this definition depend upon the ease with whichthe authors, subject editors, and the principal editor have accessto the tools and information that allow entries at all stages ofthe work flow to be managed asynchronously. In such an environment,each entry has its own deadlines and it is necessary to trackelectronically the location of every entry in the work flow andprovide automated reminders to individuals with work pending.Over the past two years, the number of authors attached to ourproject has grown considerably -- from about 350 to 600. As aresult, the number of entries which are being submitted, reviewed,published, and updated at any given moment has grown rapidly. Inthe past year, the average rate at which we publish new entriesrose from approximately 2 entries per month to 10 entries permonth.In this context of rapid development, our work on managing andfostering growth means: (1) working to insure that the asynchronouspublication schedule for the entries is met even though there is nopre-determined publication date, (2) working to enable a smallsupport staff on a small budget (compared to traditional referencework publishing) to manage the project in the face of rapid growth,and (3) working to help our users more quickly access and navigatethe growing reference work as more entries become available.We will demonstrate how our password-protected web interfaces,back-end processing system, and new front-end features, worktogether to facilitate the collaborative effort of creating andmanaging the dynamic reference work. We will highlight the newestparts of the system which are centered on growth. These include:(1) enhanced automation of email reminders that is sensitive toauthor and board member responsiveness and (2) an automatedlink-rot detection and notification system. Also, new and improvedways to navigate the encyclopedia including: (1) an automateddynamic re-cross-referencing system which enables users to moreeasily navigate the encyclopedia thematically, (2) a dynamicallygenerated "What's New" page that summarizes the changes for updatedentries, and (3) a system which allows users to view the changes inthe updated versions of entries.When compared to other online publishing efforts of similarscale, we face some unique technical challenges. For example, mostserial publications do not require re-cross-referencing of theirdocuments as new articles are published. People who want tonavigate thematically do so through searches which can returnirrelevant results that are easily ignored. Because our documentscontain links to the related entries, we must maintain those linksproperly -- lest the irrelevant links become part of the documentitself.A more in-depth discussion of the concept of a dynamic referencework, our implementation of it, and a discussion of the currentstate and future of our project is available in our recent paper'The Stanford Encyclopedia of Philosophy: A Developed DynamicReference Work', by the present authors, forthcomingMetaphilosophy --- available at the URL:http://plato.stanford.edu/sep.pdf.Technical specifications are available at the URL:http://plato.stanford.edu/NSF/project-description.pdf This researchis supported by NSF grant #IIS-9981549.

#index 378565
#* Selected component technologies in digital libraries
#@ Joel Plutchak;Joe Futrelle;Jeff Gaynor
#t 2002
#c 14
#! The demonstration will illustrate digital library component technologies joined together to provide solutions to common data mining, parsing, and archiving problems.

#index 378566
#* Digital library system: capture, analysis, query, and display 3D data
#@ Jeremy Rowe;Anshuman Razdan
#t 2002
#c 14
#% 359641
#! This paper describes development of a storage, archival, and sketch-based query and retrieval system for 3D objects. The initial focus has been Native American ceramic vessels, scanned and defined as a set of three-dimensional triangulated meshes composed of points and triangles. The process involves modeling the data with parametric surfaces, and extracting relevant features to raise the level of abstraction of data. The project uses a class based XML schema to catalog and organize vessel data. A visual query process was developed to permit users to interact with the data using sketches or by selecting sample vessel shapes to augment text and metric search criteria to retrieve original and modeled data, and interactive 2D and 3D models.

#index 378567
#* Souvenir: flexible note-taking tool to pinpoint and share media in digital libraries
#@ Anselm Spoerri
#t 2002
#c 14
#! Digital media audio/video can be difficult to search and share in a personal way. Souvenir is a software system that offers users a flexible and comprehensive way to use their handwritten or text notes to retrieve and share specific media moments. Users can take notes on a variety of devices, such as the paper-based CrossPad, the Palm Pilot and standard keyboard devices. Souvenir segments handwritten notes into an effective media index without the need for handwriting recognition. Users can use their notes to create hyperlinks to random-access media stored in a digital library. Souvenir also has web publishing and email capabilities to enable anyone to access or email media moments directly from a web page. Souvenir annotations capture information that can not be easily inferred by automatic media indexing tools.

#index 378568
#* FACET: thesaurus retrieval with semantic term expansion
#@ Douglas Tudhope;Ceri Binding;Dorothee Blocks;Daniel Cunliffe
#t 2002
#c 14
#% 230535
#% 378488
#! There are many advantages for Digital Libraries in indexing with classifications or thesauri, but some current disincentive in the lack of flexible retrieval tools that deal with compound descriptors. This demonstration of a research prototype illustrates a matching function for compound descriptors, or multi-concept subject headings, that does not rely on exact matching but incorporates term expansion via thesaurus semantic relationships to produce ranked results that take account of missing and partially matching terms [5]. The matching function is based on a measure of semantic closeness between terms [4].The work is part of the EPSRC funded FACET project [2] in collaboration with the UK National Museum of Science and Industry (NMSI) which includes the National Railway Museum [3]. An export of NMSI's Collections Database is used as the dataset for the research. The J. Paul Getty Trust's Art and Architecture Thesaurus (AAT) [1] is the main thesaurus in the project. The AAT is a widely used thesaurus (over 120,000 terms). Descriptors are organised in 7 facets representing separate conceptual classes of terms.The FACET application is a multi tiered architecture accessing a SQL Server database, with an OLE DB connection. The thesauri are stored as relational tables in the Server's database. However, a key component of the system is a parallel representation of the underlying semantic network as an in-memory structure of thesaurus concepts (corresponding to preferred terms). The structure models the hierarchical and associative interrelationships of thesaurus concepts via weighted poly-hierarchical links. Its primary purpose is real-time semantic expansion of query terms, achieved by a spreading activation semantic closeness algorithm. Queries with associated results are stored persistently using XML format data. A Visual Basic interface combines a thesaurus browser and an initial term search facility that takes into account equivalence relationships. Terms are dragged to a direct manipulation Query Builder which maintains the facet structure.

#index 378569
#* Visualizing the archive of a computer mediated communication process
#@ Bin Zhu;Hsinchun Chen
#t 2002
#c 14
#! The archive of computer-mediated communication (CMC) process contains knowledge shared and information about participants' behavior patterns. However, most CMC systems focus only on organizing the content of discussions. We propose to demo a prototype system that integrates a social visualization technique with existing information analysis technologies to graphically summarize both the content and behavior of a CMC process.

#index 378570
#* MedTextus: an intelligent web-based medical meta-search system
#@ Bin Zhu;Gondy Leroy;Hsinchun Chen;Yongchi Chen
#t 2002
#c 14
#% 234978
#% 295520
#! We propose to demonstrate a web-based prototype system that integrates the meta-search approach with existing information analysis and visualization technologies to facilitate concept-based searching behavior over the medical domain. The system distinguishes itself from other meta-search engines through two features. It incorporates the co-occurrence analysis and existing ontology to understand user's query. It also utilizes the self-organizing map (SOM) to categorize and visualize search results.

#index 378571
#* Virtual Oregon: seamless access to distributed environmental information
#@ Dylan Keon;Cherri Pancake;Dawn Wright
#t 2002
#c 14
#! Virtual Oregon is a new data coordination center established at Oregon State University (OSU) in order to: (1) archive environmental and other place-based data on Oregon and associated areas; (2) make those data accessible to a broad spectrum of agencies and individuals via innovative web interfaces; (3) identify key data sets that are not yet available and encourage their collection and dissemination; and (4) facilitate development of statewide standards for archiving, documenting, and disseminating data. Rather than co-locating researchers and data in a physical center, Virtual Oregon employs a distributed architecture that occupies multiple locations while users are presented with the illusion of a single, centralized facility. This approach was selected not just to maximize the impact on campus students, faculty, and staff but also toservice broader interactions with extension agents and other members of OSU's statewide community.Virtual Oregon builds on regional GIS centers and databanks in a wide range of disciplines, providing decades of research data on topics as varied as climate, biodiversity, land ownership, water quality, wildfire, and agricultural production. Our proximity to agencies such as the Oregon Climate Service, Oregon Natural Heritage Program, Oregon Flora Project, OSU Herbarium, EPA, and Forest Service adds breadth to data type and availability. Designed as a distributed architecture, Virtual Oregon has four nodes, each of which serves as a center and clearinghouse for distinct types of information and services: Department of Geosciences (College of Science): geospatial coverages, digital aerial and orthoimagery and associated base data Forestry Sciences Laboratory (USDA Forest Service and College of Forestry): ecological and resource management databases; data analyses; data from computational simulations Northwest Alliance for Computational Science and Engineering (NACSE): databases based on specimen collections, field observation, images, or analysis of historical documents; user interface design Valley Library: published maps, books and archival publications, gray literature, photographs and video.Data are harvested from a variety of individuals and research centers and maintained in the distributed nodes using enterprise RDBMS products (Oracle, Sybase, and Microsoft SQL Server) residing on UNIX and Windows platforms. Query Markup Language (QML, a middleware product developed at NACSE) supports database-to-Web interactions by transparently performing queries across multiple RDBMSs and displaying the results as though from a single source. Web-based mapping interfaces (powered by ESRI's Internet Map Server and Spatial Database Engine products) can also be used to explore data visually.As the demonstration will show, users currently have the option of beginning with either the "thematic" or "place-based" interfaces. Ultimately, users will be able to move freely back and forth between the two paradigms, for example initially narrowing the scope of inquiry based on discipline or attributes, moving to the visual interface to refine the search based on location or some set of geospatial characteristics, then moving back to query-based exploration to delve to fine levels of detail. Usability engineering methodologies are being applied so that all navigation and query mechanisms are both maximally productive and easily learned by novices.

#index 378572
#* A DL server with OAI capabilities: LOVE
#@ Su-Shing Chen;Chee-Yoong Choo
#t 2002
#c 14
#! We describe integrating OAI (Open Archives Initiative) and DL (Digital Library) capabilities in the integrated prototype DL server: LOVE (Learning Object Virtual Exchange).

#index 378573
#* Evaluating a digital video library web interface
#@ Michael G. Christel;Pedro Cubilo;Junius Gunaratne;William Jerome;Eun-Ju O;Sohini Solanki
#t 2002
#c 14
#% 170375
#% 438054

#index 378574
#* Puget sound's MARS (media asset retrieval systems) digital library
#@ Efthimis N. Efthimiadis;Jens-Erik Mai
#t 2002
#c 14
#! The Corporation for Public Broadcasting (CPB) and public broadcasters consider Media Asset Management (MAM) of critical importance since without a concerted and cooperative plan to manage their vast library of content, broadcasters are unable to reach their potential for service in the digital age.The concerns for Media Asset Management, which are the Digital Libraries for broadcasters, human and technical, are myriad. Media Asset Management is the framework upon which many of the largest technology projects will be built, including the future interconnection system between and among CPB member stations. It is CPB's hope that its licensees and their partners in university, museum, and library communities, will work together to contribute to Media Asset Management solutions.This poster will present some of the complex issues around Media Asset Management and possible solutions to the problems as well as show the breath of research projects in the area. The issues include metadata, indexing, controlled vocabularies, storage and access methods, rights management, technological infrastructure requirements, and interoperability.To highlight these issues we will use as an example the Media Asset Retrieval System (MARS) project. The goal of this project is to create a model for representing, organizing, storing, and facilitating access to public audio (radio) and audiovisual (television) broadcast material via the Internet. The immediate goal for MARS is to produce a digital online resource that will provide access to material produced by public broadcasters in the Puget Sound Region (KUOW and KCTS). The material will be made available to students, teachers, media, and the general public through the King County Library System and Seattle Public Library System. The mission of the Convergence Consortium guides the MARS project. The Convergence Consortium is a working collaborative between public broadcasters, public libraries, K-12 schools and the Information School of the University of Washington that meet to assess the needs of their constituents and propose solutions that will be developed to meet those need.The MARS project is funded by a grant from the Corporation for Public Broadcasting Television Future Fund and it falls within the context of major decisions about Media Asset Management in public broadcasting. It is the intent that the MARS project will produce a reference document that will help public broadcast stations make decisions about media asset management as it relates to audio and audiovisual access as a community resource.The MARS team will analyze the current systems and their contexts and design a digital library system for the KUOW and KCTS broadcasters that will facilitate access to the broadcast material. The digital library will support advanced knowledge organization techniques and search algorithms to facilitate retrieval of the broadcast material. The MARS project ties together some of the critical issues in Digital Libraries and approaches these problems from a user-centered perspective.

#index 378575
#* Enki: open infrastructure for adaptive digital libraries
#@ James Farrell;Hilary J. Holz
#t 2002
#c 14

#index 378576
#* Argentinean historical heritage project
#@ María Feldgen;Osvaldo Clúa;Fernando Boro;Juan José Santos
#t 2002
#c 14
#% 433725
#! The digitalization effort of the Argentinean Heritage Project is described from its beginning, up to its present day form, as a framework of automatized, Web [1] operated and platform independent tools to assist historians to build and maintain digital libraries suited to their research needs. We show how low cost, labor intensive digital library building is possible using standard formats and tools.

#index 378577
#* Content-based filtering and personalization using structured metadata
#@ A. Mufit Ferman;James H. Errico;Peter van Beek;M. Ibrahim Sezan
#t 2002
#c 14
#% 260778
#% 283169
#! Structured descriptions of multimedia content and automatically generated user profiles are used to filter content.

#index 378578
#* Developing a digital library of reusable historical artifacts
#@ Dion Hoe-Lian Goh;Schubert Shou-Boon Foo
#t 2002
#c 14

#index 378579
#* Search facilities for internet relay chat
#@ Taher H. Haveliwala
#t 2002
#c 14
#% 262175
#! The Internet encompasses a diverse array of information sources that have been indexed for efficient search, including the Web, Usenet, and email (both personal mail and specialized mailing lists). One information source, publicly accessible over the Internet, yet unarchived and unindexed, is the Internet Relay Chat (IRC) system. We are archiving several of the more useful technical-support-oriented IRC channels, with the goal of extracting, archiving, and indexing information that would help satisfy users' information needs.

#index 378580
#* User uncertainties with tabular statistical data: identification and resolution
#@ Naybell Hernández;Carol A. Hert;Kristen Armstrong
#t 2002
#c 14
#! United States government services are becoming increasingly Web-based, creating opportunities to make useful, even vital, information and services more accessible to citizens than in the past. This opportunity has challenged Federal agencies as they work to provide information and services that are easy to use and understandable to an extremely diverse constituency. This paper reports the findings of a study examining the questions and uncertainties of users during investigation of statistical tables. The questions and uncertainties are categorized, mapped to an XML DTD for use in a table-browsing system. Implications of the approach and results are discussed.

#index 378581
#* Using the internet to communicate with immigrant/refugee communities about health
#@ Ellen Howard;Christine Wilson Owens
#t 2002
#c 14
#! Our poster describes the use of the Web for communication between ethnic communities and their care providers.

#index 378582
#* Unicode for multilingual representation in digital libraries from the indian perspective
#@ Devika P. Madalli
#t 2002
#c 14
#! One of the main issues in digital data sharing is tackling multi-lingual resources. Paper presents the problems of representation of Indian languages on Internet. It covers the efforts so far undertaken for multilingual data representation in India. It examines the applicability and advantages of adopting Unicode.

#index 378583
#* Marine realms information bank: a distributed geolibrary for the ocean
#@ Fausto Marincioni;Frances Lightsom
#t 2002
#c 14
#% 355239
#! The Marine Realms Information Bank (MRIB) is a prototype web-based distributed geolibrary that organizes, indexes, and delivers online information about the oceanic and coastal environments. The improvement of computer power and connectivity of the 1990s, by enabling very fast exchange of data online, has shown that effective information management does not automatically result from quicker connection or large broadband. Millions of web sites have been setup to provide information on every subject, and various information-gathering systems have been developed to locate information online. Unfortunately, these search engines often produce exhaustive bibliographic lists that mix first-quality scientific knowledge with irrelevant materials. To be really useful, information banks require not only quality control but also classification systems that integrate and organize the information. In 1999 the National Research Council proposed the concept of distributed geolibraries, which are online digital libraries able to provide a simple mechanism for searching and retrieving information in response to topical and geographically defined needs. Distributed geolibraries are beneficial for various reasons, the most important of which is the authoritative role they would come to assume as subject gateways. To be referenced through a scientific geolibrary, information sources must meet quality standards set by the library gatekeeper. Another important benefit of a distributed geolibrary comes from its "distributed" attribute. Without the need to collect information in one physical location, local curators can serve and update online information without the requirement of maintaining consistency among multiple copies. The MRIB prototype implements the distributed geolibrary concept to organize, index, and deliver online information about the oceanic and coastal environments. MRIB provides access to information, but it is not an information repository. It incorporates information that exists in remote sources, without modifying formats or content. This system succeeds by building a central index that consists of Electronic Index Cards containing metadata about the information sources, their geographical areas, and their network locations. The ontology of MRIB is expressed in the classification system through which users can explore the available information. MRIB currently classifies information with 13 types of categories (facets): Location, Geologic Time, Features, Biota, Discipline, Scientific Method, Hot Topics, Project Name, Agency Name, Author, Class, Format, and Audience. Classifying information is not automatic but is performed by a librarian, which is both the major benefit and the major operating cost of MRIB. The significance of MRIB lies both in the utility of the information bank and in the implementation of the distributed geolibraries concept. Distributed information banks, such as MRIB, can be applied widely as unifying portals for extensive or rapidly developing information bases, for which a centralized repository would be impractical. In addition, MRIB has a modular structure that allows a classification system to be easily modified, to expedite the development and testing of suitable classification systems for existing information bases.

#index 378584
#* Democratic access to information in a rapidly changing society: the case of Brazil
#@ Cavan McCarthy;Murilo Bastos da Cunha
#t 2002
#c 14
#! Identifies and characterizes the principal Brazilian digital library initiatives, which make available materials in two areas: Science and Research, and Literature and the Humanities.

#index 378585
#* Active netlib: an active mathematical software collection for inquiry-based computational science & engineering education
#@ Shirley Moore;A. J. Baker;Jack Dongarra
#t 2002
#c 14
#! A core subject in the undergraduate education of applicationscientists and engineers is the use of mathematical software tosolve computational problems. To make effective use of mathematicalsoftware, application developers need a basic understanding of theunderlying numerical methods and enough knowledge to be able tochoose an appropriate solver, parameterize it correctly, andvalidate the computed results. Correct results are of courserequired, but good computational performance is desired aswell.Most application scientists have neither the time nor theinterest to read the current literature in numerical analysis. Theysolve numerical problems by relying on the methods and programsthey learned about in previous coursework. This tendency has theunfortunate consequence that new methods with improvedfunctionality and/or efficiency may go unused by practicingengineers. Mathematical subroutine libraries can be highly complex.Few application scientists understand how they really work, and theusual practice is to treat the subroutines as "black boxes". Ablack box is a piece of software that can be used without knowledgeof its inner working; the user supplies the input, and the outputis more or less assumed to be correct. However, there are a numberof pitfalls in numerical computation (e.g., roundoff error,ill-conditioning, non-convergence). Application engineers needenough understanding of the underlying numerical methods to be ableto detect and diagnose problems that occur and to modify orcustomize the methods if necessary. This need is especially crucialin the use of iterative methods to solve large sparse linearsystems, where the problem may need to be properly preconditionedin order for convergence to occur and where the appropriate methodto employ depends on the nature of the problem being solved.A large amount of mathematical software is both commercially andfreely available. However, not all the software that is availableis of high quality. It can also be difficult to locate theappropriate software by using web search engines, since thedescriptions available for searching may be lacking or may notmatch the vocabulary used by the searcher. A good solution to theseproblems is to have experts in the field of numerical analysismaintain a moderated collection of high quality software which isorganized and cataloged with appropriate metadata to enable easysearching.The Netlib mathematical software repository is such a collectionthat has been contributed to and managed by the numerical analysiscommunity for the past fifteen years.To address the aforementioned problems, Active Netlib providesan active collection of high-quality mathematical softwareresources in the context of an inquiry-based learning environmentfor computational science and engineering education. The Netlibcollection is being extended in a number of ways to support thegoals of this project. The NetSolve client-server system foraccessing hardware and software resources over a network providesan active interface to the contents of Netlib. By making thesubroutines housed in Netlib available over the network oncomputational servers, NetSolve enables access to up-to-datemathematical software from a variety of client interfaces runningon users' workstations, without requiring the users to download andinstall the software themselves. Use of NetSolve seamlesslymaintains the currency and usability of the content as theunderlying hardware, operating systems, and software evolve.Furthermore, the NetSolve adaptive solver interface guides the userin selecting appropriate software, in setting parameters correctly,and in interpreting numerical results.The Netlib collection is being further extended through use ofthe Repository in a Box (RIB) toolkit, which enables an individualor organization to set up and maintain a repository that interactswith other RIB repositories. RIB will allow the Netlib collectionto be selectively mirrored and contributed to by all projectparticipants.In summary, the goals of the Active Netlib project are thefollowing:Remote executable content with highly interactive userinterfacesResource users becoming resource providersA growing network of software repositories and computationalservices drawn upon and contributed to by researchers, educators,and students.For more information, see the Active-Netlib home page athttp://icl.cs.utk.edu/active-netlib/.

#index 378586
#* Representing pulaar digitally
#@ Bartek Plichta;David Robinson
#t 2002
#c 14
#! This paper outlines a methodology for digital representation and preservation of Pulaar language data.

#index 378587
#* Components for constructing open archives
#@ Joel Plutchak;Joe Futrelle;Jeff Gaynor
#t 2002
#c 14
#! In this poster, we describe how components that implement emerging standards have been used to produce custom solutions to metadata archive problems.

#index 378588
#* Question types in digital reference: an evaluation of question taxonomies
#@ Jeffrey Pomerantz
#t 2002
#c 14
#! This study evaluates four taxonomies of question types to determine the expressiveness of each for questions received by digital reference services. The result is a faceted classification scheme that can be used as a basis for automating parts of the reference question answering process.

#index 378589
#* Integrating expertise into the NSDL: putting a human face on the digital library
#@ Jeffrey Pomerantz;R. David Lankes
#t 2002
#c 14
#! This paper describes work currently underway at the Information Institute of Syracuse to build an operational digital reference system to support the National Science, Mathematics, Engineering, and Technology Education Digital Library (NSDL).

#index 378590
#* Automatic removal of advertising from web-page display
#@ Neil C. Rowe;Jim Coffman;Yilmaz Degirmenci;Scott Hall;Shong Lee;Clifton Williams
#t 2002
#c 14
#! The usefulness of the World Wide Web as a digital library ofprecise and reliable information is reduced by the increasingpresence of advertising on Web pages. But no one is required toread or see advertising, and this cognitive censorship can beautomated by software. Such filters can be useful to the U.S.government which must permit its employees to use the Web but whichis prohibited by law from endorsing commercial products. While thetask would seem at first simpler than filtering of pornography orgeneral firewalls, subtleties in recognizing advertising make fullsuccess daunting.Our work is evaluating the quality of methods and products forautomatic ad censorship. Commercial products include AdKiller(www.adkiller.com), Ad Subtract Pro (www.adsubtract.com),Advertising Killer (www.buypin.com), AdWiper (www.adwiper.com),FilterGate (www.adscience .co.uk), and WebWasher(www.webwasher.com). Other products prevent the annoying popupwindows that are usually ads. Things these products do includeremoval of ad-like images embedded in the page, prevention of popupwindows and Javascript alert boxes, prevention of blinking text,and prevention of playing of embedded audio. Or so the vendorsclaim. Not a single one provides any statistics on the accuracy oftheir product (e.g. recall and precision) to support their grandclaims of removing ads.We are experimenting to determine how effective varioustechniques are in ad censoring. We constructed a censor of our own("Big Head") with manipulable features. We use Java servletsoftware to implement a page server that fetches HTML source textand edits it to create a modified page for display. The modifiedpage has blanks in the places of inferred ads, and substituteslocal links for remote links to permit further censoring. Blanksare made the same shape as the censored ads so that meaningful pagelayout can be preserved.We initially examined a variety of Web sites to develop a set ofclue properties for both image ads and their associated text,considering the text within a fixed-size window around the HTMLimage reference. We defined ads as information intended to arouse adesire to purchase or patronize something. It became clear thatidentification methods need to include both logical andprobabilistic methods to achieve high recall (fraction of adsremoved from pages), although high precision (fraction of ads amongthe items eliminated) was easy by simply picking the popup windowsand narrow banner-size images. Certain image dimensions are strongclues for ads, especially 480 by 60 banners and 150 by 500, 120 by600, and 160 by 600 images along the sides of the page. Imagesstored on sites different from the page's site (i.e. with differentfirst part of their URL) were also very likely to be ads, as wereimages whose file names contained long integers. These criteria aresufficiently strong to give 95% precision in identifying imageads.Additional weaker criteria used included the words of the imagefile name (the image URL), words of any directly associated text("alt" string), and other words within a fixed-size window aroundthe image reference. Good clue words and phrases were obtained froma study of random commercial Web pages. Examples are "ad", "buy","shop", "free", "join", "click", and "now". The strength of eachclue was estimated as the fraction of the time that the image wasan ad when the word was associated with it. In addition, image adswere usually larger than 2500 pixels, and "alt" text for ads wasusually less than 100 characters long; both tendencies can bemodeled by probability distributions derived from statistics fromexample pages. Evidence from these weaker clues was combined usinga linear model (or weighted average), and items were eliminated iftheir weighted sum exceeded a fixed threshold. In a quick test, ourprogram examined representative pages, and correctly recognized 19of 20 ads and 153 of 156 non-ads where ads were manually identifiedin advance. Public access is fromhttp://triton.cs.nps.navy.mil:8080/rowe/rowedemos.html.Text ads also have exploitable syntax. Analogously to what wedeveloped for finding image captions in our MARIE-4 Web crawler,incitements to purchase typically use a limited range ofgrammatical expressions recognizable by a partial parser. Goodexamples are expressions of the imperative form of verb indicatingacquiring ("buy", "get", "join", "click", etc. followed by a nounindicating a purchasable quantity (a physical object or a service),with optionally a qualifying adjective on the noun or an adverbindicating a desirable property of the acquisition ("now", "free","soon", etc.) Such a parser can approach semantic understanding ofadvertising text and improve precision of ad identification.Our research is ongoing. Future work will obtain more reliableperformance statistics on representative Web pages, and willinvestigate methods of identifying more difficult kinds of ads.Though we did not consider it yet, elimination of popup windows andJavascript applets is usually straightforward from analysis of theHTML source code. We hope to publish performance comparisons ofdifferent methods and different vendor products soon.

#index 378591
#* Structured models of scientific concepts for organizing, accessing, and using learning materials
#@ Terence R. Smith;Marcia L. Zeng;Olga Agapova;Olha Buchel;Michael Freeston;Jim Frew;Linda Hill;Laura Smart;Tim Tierney;Alex Ushakov
#t 2002
#c 14
#! Concepts and their interrelationships are the fundamental building blocks for representing the phenomena investigated in mathematics, science, and engineering (MSE). The knowledge represented in learning materials for the sciences is typically organized around term-based or "weakly-structured" models of concepts and their interrelationships. We introduce a "strongly-structured" model of scientific concepts that provides the foundation for a knowledge base (KB) of concept representations. It focuses on such attributes as the objective representations, operational semantics, use, and interrelationships of concepts, all of which play important roles in constructing representations of phenomena that further understanding of MSE domains of knowledge.We have developed a strongly-structured model of concepts for SME domains in terms of a frame-based KRS with slots and attribute-value fillers. The model, whose framework is shown in Figure 1, is implemented as an XML schema. This schema is used as the basis for creating domain-specific KBs containing XML records of concepts.The Alexandria Digital Library (ADL) Digital Earth Testbed system (http://www.alexandria.ucsb.edu) has been extended with: (1) a KB of scientific concepts, from the domain of physical geography, that are represented in terms of our XML schema for concept representation; (2) a collection of heterogeneous learning materials exemplifying the concepts and their properties in various contexts; and (3) services that provide a variety of views of the content of the KB and associated collection. (Please refer to the JCDL paper "The ADEPT Digital Library Architecture" by Janee and Frew.) This extension to ADL is being deployed in teaching an introductory course in physical geography in Fall, 2002.

#index 378592
#* StandardConnection: correlating educational resources in digital libraries to content standards
#@ Stuart A. Sutton;Elizabeth D. Liddy;John Kendall
#t 2002
#c 14
#! The goal of our two year NSF National Science Digital Library-funded project is to develop Natural Language Processing technology that will automatically produce metadata values that correlate individual educational resources in digital libraries to content standards. The goal is to assign this metadata to the descriptive metadata records for resources in support of standards-based discovery and retrieval. The project will utilize the Achieve/McREL Compendix, a comprehensive knowledgebase of K-12 content standards derived from over 137 state, national and international content standards documents. The test collection of educational resources being analyzed is drawn from the more than 400 Web-based collections represented in the Gateway to Educational Materials catalog.The significance of this project in terms of the Digital Library movement is that high-quality automatic correlation of educational resources to content standards is essential to meet the demands for searching and retrieving such resources based on those correlations. This demand will increase as the national focus on greater accountability in our K-12 institutions increases. While human correlations of resources to content standards characterize current practice, it is clear that the scale of the need for such correlations calls for sophisticated means for automatic mapping. This project is intended to provide an NLP-based solution to the problem.Briefly, our NLP approach in this project is to analyze language utilizing all the levels through which humans extract meaning-morphological, lexical, syntactic, semantic, discourse, and pragmatic. The extent to which an individual technology includes these levels, particularly the higher-level ones determines the capability and sophistication of the resultant application. Having incorporated each of these levels into our baseline NLP document-processing module, we are extending the system's capabilities in this project to the task of learning the linguistic features that can be relied on to indicate what content standard an educational resource supports.We are applying a sublanguage analysis framework to automatically identify clues that can be recognized in the mathematics and science educational materials to indicate to which standards the resources apply. Based on the discourse model, the system learns from recognizing these linguistic clues in the training set. The system will then be able to process new resources as they are added to the digital library and appropriately assign to the metadata for those resources the learning standards to which they are applicable.This work is a continuation of our NSF NSDL project "Breaking the Metadata Generation Bottleneck" where we were successful in processing text to automatically assign metadata tags for the descriptive and subject aspects of educational resources.

#index 378593
#* Quantitatively evaluating the influence of online social interactions in the community-assisted digital library
#@ YongHong Tian;TieJun Huang;Wen Gao
#t 2002
#c 14
#! Online social interactions are useful in information seekingfrom digital libraries, but how to measure their influence on theuser's information access actions has not yet been revealed.Studies on this problem give us interesting insights into theworkings of human dynamics in the context of information accessfrom digital libraries. On the basis, we wish to improve thetechnological supports to provide more intelligent services in theongoing China-America Million Books Digital Library so that it canreach its potential in serving human needs.Our research aims at developing a common framework to modelonline social interaction process in community-assisted digitallibraries. The underlying philosophy of our work is that the onlinesocial interaction can be viewed as a dynamic process, and the nextstate of each participant in this process (e.g., personalinformation access competency) depends on the value of the previousstates of all participants involving interactions in the period.Hence, considering the dynamics of interaction process, we modeleach participant with a Hidden Markov Model (HMM) chain and thenemploy the Influence Model, which was developed by C.Asavathiratham as a Dynamic Bayes Net (DBN) of representing theinfluences a number of Markov chains have on each other, to analyzethe effects of participants influencing each other. Therefore, onecan think of the entire interaction process as a DBN frameworkhaving two levels of structure: the local level and the networklevel. Each participant i has a local HMM chain&Ggr;(A) which characterizes the transition of hisinternal states in the interaction process with state-transitionprobability&Sum;overjdijP(Sit|Sjt-1) (Here states are hispersonal information access competence in different periods, whileobservations are his information access actions). Meanwhile, thenetwork level, which is described by a network graph&Ggr;(DT) whereD={dij} is the influence factormatrix, represents the interacting relations betweenparticipants. The strength of each connection,dij, describes the influence factor of theparticipant j at its begin on the one i at its end.Hence, this model describes the dynamic inter-influence process ofthe internal states of all participants involving onlineinteractions.To automatically build the model, we need firstly to extractobserved features from the data of online social interactions andinformation access actions. Obviously, the effects of interactionsare stronger if messages are exchanged more frequently, or theparticipants access more information in the online digitallibraries during the period of time. Based on this consideration,we select the interaction measureIMi,jt and the amount ofinformation IAjt as the estimationfeatures of xit. The interactionmeasure IAit and the amount ofinformation parameterize the features calculated automatically fromthe data of online social interactions between the participantsi and j, and the features calculated from the data ofinformation access actions respectively. Secondly, we need todevelop a mechanism for learning the parametersdij andP(Sit|Sjt-1.Given sequences of observations {xit}for each chain i, we may easily utilize theExpectation-Maximization algorithm or the gradient-based learningalgorithm to get their estimation equations.We ran our experiments in the online digital library of W3CConsortium (www.w3c.org), which contains a mass of news, electronicpapers or other materials related to web technologies. Users mayaccess and download any information and materials in this digitallibrary, and also may free discuss on any related technologicalproblems by means of its mailing lists. Six users were selected inour experiments to collaboratively perform paper -gathering tasksrelated to four given topics. Any user might call for help from theothers through the mailing lists when had difficulties in thisprocess. All participants were required to record subjectiveevaluations of the effects that the others influenced his tasks.Each experiment was scheduled by ten phases. And in each phase, wesampled IMi,jt andIAit for each participant and then fedthem into the learning algorithms to automatically build theinfluence model. By comparing with the subjective influence graphs,the experimental results show that the influence model can estimateapproximately the influences of online social interactions.

#index 378594
#* Shuhai Wenyuan interactive internet worktable: studying ancient chinese philosophy online
#@ Mary Tiles;Brian Bruya
#t 2002
#c 14
#! There are four major digital library projects in East Asia thatpublish digital versions of parts of the vast pre-modern Chinesecorpus on the World Wide Web. All of these are targeted atprofessional sinologists, with no accommodation for the user who isnot expertly proficient in Chinese. As a result, anyone interestedin seriously engaging Chinese thought must either set aside a fewyears to learn Classical Chinese or remain beholden to thesinologist for both information and interpretation. At ShuhaiWenyuan, a project funded by the National Science Foundation'sDigital Libraries Initiative (Phase II), we strive to capitalize onthe advantages of digitization to allow the non-sinologist entryinto the conceptual world of ancient Chinese thought.Begun in October of 2000, Shuhai Wenyuan will offer a set ofChinese classics, English translations of these classics, ahyperlinked lexicon, a grammar, a philosophical resource, and asearch engine for rapidly viewing the full contexts of importantterms in a variety a texts. The aim is access--most immediately forscholars and students to be able to read Classical Chinese textswith enough resources that they will be able to reach their ownconclusions about interpretation and then employ the texts inoriginal scholarly pursuits; and in the longer term for teachers tobe able to provide courses in Chinese Philosophy, either online orin the classroom, without having to be concerned about theavailability of appropriate resources.There are four salient features of Shuhai Wenyuan that we willpresent in our poster:SOFTWARE: As a project developed by humanists rather thancomputer scientists, and as a project intended to be replicated byother humanists, Shuhai Wenyuan employs powerful off-the-shelfdatabase software called 4D. We will demonstrate how this resultsin streamlined and cost-effective administration and modularreplicability without compromising design flexibility,expandability, or data integrity.WORKTABLE: Our user interface employs frames to replicate thescholar's worktable on which one may have open several books atonce for simultaneous perusal. We will demonstrate how side-by-sidetextual viewing enhances the research usability and how theWorktable can be customized by individual users in a variety ofways.TOOLS: A portion of the Worktable is devoted to textual viewingand another to viewing research tools, specifically, a grammar, anencyclopedic lexicon, and a search engine. We will demonstrate howeach of these tools is easily put to work using hyperlinks betweenthe texts and tools and among tools.PHILOSOPHY: One of the most difficult parts of working withforeign language texts is that philosophically-laden terms losetheir conceptual contexts in translation and acquire misleadingconceptual contexts in the target language, so that a term such astian in Chinese inevitably becomes Heaven in English, capitalizedand with built-in Judeo-Christian connotations of an omnipotent,anthropomorphic deity and the promise of salvation.One of the most significant features of Shuhai Wenyuan is our workorganizing and presenting secondary literature on key philosophicalterms. If one were to research the term tian in an analog library,it would take days of paging through book and periodical indexes tofind significant treatments of it in the secondary literature. Weare bringing these resources into our own library, digitizing them,and culling the relevant passages for inclusion under individualentries in the lexicon. The textual tools and texts themselves,when combined with our philosophical resource, allow the novicereader of Chinese thought unprecedented access to this importantbody of texts. Instead of providing the reader with a singlelimited interpretation of a text, we offer users the entireconceptual universe of Chinese thought at their fingertips,allowing them to work creatively from it.

#index 378595
#* Breathing life into digital archives: use of natural language processing to revitalize the grey literature of public health
#@ Anne M. Turner;Elizabeth D. Liddy;Jana Bradley
#t 2002
#c 14
#! The goal of our 2-year Robert Wood Johnson-funded project is to apply Natural Language Processing (NLP) technology to improve access and use of the digitalized public health "grey" literature. Much public health information, such as meeting notes, think-tank reports, policy statements, and data sets, is not available through traditional commercial pathways and is considered grey or fugitive literature. Although grey literature documents are increasingly posted in digital archives on the Web, the unstructured and varied nature of grey literature makes accessing useful content difficult at best.In an effort to help make the content of public health digital collections more accessible to public health providers, we will use proven NLP techniques to identify and extract key elements of digital documents. NLP techniques can be used to identify and tag key elements from full-text documents. Once tagged, the content of various documents can be extracted and summarized in tables and charts for comparison and review. The ability of NLP to recognize and represent both the explicit and implicit content of full text documents makes it a powerful technique for interpreting the language of text documents. Our NLP information access system has been used in other domains to extract individual entities and events, as well as draw relationships between entities and events to build a content representation.The goal is to develop a model of public health interventions and identify key entities and events from these digital archives. Key elements may include type of study and population demographics as well as more traditional bibliographic elements such as author, title and publication date.NLP technology will be used to search, identify and extract key elements based on the user's request. Key elements can be extracted across multiple documents for summary and comparison. For example, the user can extract key elements from annual reports about "teenage smoking cessation programs" to compare method of intervention, demographic population, and outcome. Such comparisons will help public health professionals to determine how a particular intervention fits with similar interventions reported in the grey literature. This system holds great promise for improving access to public health information through digital archives.

#index 378596
#* Building a digital collection of manuscripts from the library of the royal palace of Spain
#@ Soledad Vélez;Manuel Sánchez-Quero;Juan Carlos García;Alejandro Bia
#t 2002
#c 14
#! With an aim of bringing cultural contents to cyberspace and spreading some unknown aspects of the history of the Americas, the Miguel de Cervantes Digital Library has embarked in a joint effort with the Library of the Royal Palace of Spain, to develop the digital web publication of the Manuscripts of the Americas in the Royal Collections funds. In this joint venture, the Library of Royal Palace supplied its invaluable contents for digitization, and the Miguel de Cervantes DL its technology and experience as a digital publisher. The goal was to join the ancient and the new, the most precious and carefully preserved documents with the new electronic publishing technologies. The result was to make freely available to a worldwide public those otherwise unreachable treasures of the Royal Collections.

#index 378597
#* By the people now, for the people later: using transitory metadata to anchor a digital archive
#@ Anne Washington
#t 2002
#c 14
#! The Congressional Research Service (CRS) serves Congress by providing timely, objective and non_partisan research, analysis and information services. The Legislative Information Office within CRS fulfills that mandate by maintaining a digital library of legislative documents known as the Legislative Information System.An ongoing challenge is designing these full text and structured databases for both promptness and permanence. This is accomplished by metadata and interface design. This foundation prepares for the impending incorporation of more complex born_digital formats such as XML, audio and video.Legislative Information System (LIS) clients are those who have access to Capitol Hill intranet systems. (The public version is the THOMAS site http://thomas.loc.gov.) LIS adds value to public domain legislative data with advanced text retrieval tools and the benefit of a portal site.The content of LIS is composed of several collections of documents. The House of Representatives and the Senate create and update legislative information, which is the bulk of LIS. The Government Printing Office publishes text and PDF formats of congressional documents, building up LIS's catalog of full_text documents. The CRS Bill Digest section, established by law in 1935 to index and summarize bills, adds additional metadata. In partnership with the user community, a high degree of data quality control is actively maintained.The primary entry point is a database called Bill Summary and Status. From there, links are available into the full text collections: text of bills, committee reports and the Congressional Record. These are large_scale collections. LIS maintains every published bill version since 1989. This session, Congress already has introduced more than 6000 bills and important bills often have up to five versions. The search pages have been carefully crafted to accommodate both novice and advanced users. A number of prepared searches are built underneath the search page interface. These gather bills on nebulous topics such as "national security.LIS's primary role is as a prompt deliverer of legislative events and documents. For instance, a senator needs a current list of all co-sponsors on her bill. A staffer needs to read yesterday's floor debate. Legislative events in LIS are updated regularly to accommodate this fast_paced need for data. Searchers are able to specify narrowly defined legislative status steps in order to track current legislation. The LIS alert service sends out email notification when selected legislation is updated.LIS data is also used retrospectively to piece together a legislative history. A legislative history attempts to establish the intent of a current law by compiling documents created during the legislative process. A legislative history could include conference reports, congressional hearings, debates and early drafts of bills. All of these documents are available in electronic format in LIS. Each legislative step has embedded links to LIS full_text documents, creating an easy_to_maintain web of legislative history. In addition, a text analysis tool has been developed which allows paragraph level comparison of legislation. This tool allows us to closely track the evolution of legislative language.Future developments of LIS involve displaying full-text documents in XML, linking to video of congressional proceedings, and completing a retrospective conversion of past congressional content.The prompt recording of current legislative events provides the key to long_term access into our growing digital archive of legislative documents. Our primary designated community is the congressional staff, but the results benefit individual citizens, the courts and businesses who are trying to interpret the rules that govern how we live.

#index 378598
#* Introduction to the open archives initiative protocol for metadata harvesting
#@ Hussein Suleman
#t 2002
#c 14
#! The Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) [1] is a relatively new interoperability standard that is gaining much attention from existing and new digital libraries. It is currently advocated by many communities (including NDLTD, NCSTRL, and NSDL) to fulfill their metadata interoperability requirements.This tutorial is aimed at introducing individuals to the concepts underlying the OAI and the harvesting protocol, as well as providing sufficient information to allow attendees to almost immediately implement the current standard (OAI-PMH v2.0) on their own archives or in their own communities. Attendees will be introduced to both organizational and technical issues that need to be addressed when building new systems or extending existing systems, either in the capacity of being providers of data, users of data, or both. Wherever appropriate, references will be made to best practices that have emerged in the community of OAI implementers since the initial release of the protocol. Attendees will also be familiarized with tools developed within the OAI community to support the implementation of the protocol.

#index 378599
#* Thesauri and ontologies in digital libraries: 1. structure and use in knowledge-based assistance to users
#@ Dagobert Soergel
#t 2002
#c 14
#! This introductory tutorial is intended for anyone concerned with subject access to digital libraries. It provides a bridge by presenting methods of subject access as treated in an information studies program for those coming to digital libraries from other fields. It will elucidate through examples the conceptual and vocabulary problems users face when searching digital libraries. It will then show how a well-structured thesaurus / ontology can be used as the knowledge base for an interface that can assist users with search topic clarification (for example through browsing well-structured hierarchies and guided facet analysis) and with finding good search terms (through query term mapping and query term expansion - synonyms and hierarchic inclusion). It will touch on cross-database and cross-language searching as natural extensions of these functions. The workshop will cover the thesaurus structure needed to support these functions: Concept-term relationships for vocabulary control and synonym expansion, conceptual structure (semantic analysis, facets, and hierarchy) for topic clarification and hierarchic query term expansion). It will introduce a few sample thesauri and some thesaurus-supported digital libraries and Web sites to illustrate these principles.

#index 378600
#* How to build a digital library using open-source software
#@ Ian H. Witten
#t 2002
#c 14

#index 378601
#* Overview of digital libraries
#@ Edward A. Fox
#t 2002
#c 14
#! This tutorial will start with an overview of definitions, foundations, scenarios, and perspectives. It will cover a variety of issues, including search, retrieval, and resource discovery; multimedia/hypermedia; metadata (e.g., Dublin Core); electronic publishing; document models and representations; SGML and XML; database approaches; agents and distributed processing; 2D and 3D interfaces and visualizations; metrics; architectures and interoperability; educational and social concerns; commerce and intellectual property rights, among others.

#index 378602
#* Advanced overview of version 2.0 of the open archives initiative protocol for metadata harvesting
#@ Michael L. Nelson;Herbert Van de Sompel;Simeon Warner
#t 2002
#c 14
#% 337235
#! This tutorial is a follow-on to "Introduction to the Open Archives Initiative Protocol for Metadata Harvesting" (OAI-PMH), given earlier the same day. It is appropriate for those who have completed the earlier tutorial or are already familiar with OAI-PMH. The tutorial will begin by highlighting the differences between versions 1.1 and 2.0 of the OAI-PMH, and then discuss possible migration strategies for 1.1 harvesters and repositories. Advanced topics and deployment scenarios will also be discussed, including: flow control, load balancing, error recovery, hierarchical harvesting, sets and alternate metadata formats.

#index 378603
#* Thesauri and ontologies in digital libraries: 2. design, evaluation, and development
#@ Dagobert Soergel
#t 2002
#c 14
#! This tutorial is intended for people who have a basic familiarity with the function and structure of thesauri and ontologies. It will introduce criteria for the design and evaluation of thesauri and ontologies and then deal with methods and tools for their development: Locating sources; collecting concepts, terms. and relationships to reuse existing knowledge; developing and refining thesaurus/ontology structure; software and database structure for the development and maintenance of thesauri and ontologies; collaborative development of thesauri and ontologies; developing crosswalks / mappings between thesauri/ontologies. In summing up, the tutorial will address the question of the amount of resources needed to develop and maintain a thesaurus or ontology.

#index 378604
#* Hands-on workshop: build your own digital library collections
#@ Ian H. Witten;David Bainbridge
#t 2002
#c 14

#index 378605
#* Bioinformatics and digital libraries
#@ William Hersh;Christopher Dubay
#t 2002
#c 14
#! The goal of this tutorial is to provide a basic introduction to bioinformatics and electronic biological data resources for the digital library community.

#index 378606
#* Document search interface design for large-scale collections and intelligent access
#@ Javed Mostafa
#t 2002
#c 14
#! As the universe of documents has enlarged from those available via the online catalog to a larger cluster of databases and web-accessible resources, interfaces are being created that can search multiple document collections simultaneously. Also, searching for document surrogates is losing favor as more documents are digitized and distributed in full-text form. Availability of full-text makes it possible for document components such as tables, illustrations, citations, and references -- components that traditionally remained outside the scope of document searching -- to be considered and exploited by search interface designers. Additionally, due to the popularity of web-hyperlinking people are beginning to expect linking of documents across different collections based on common semantic or non-semantic attributes. Increased research activity on artificial intelligence techniques for document access is leading to more fundamental changes in document searching. It is now possible to delegate 100% of the search effort to online search agents. Agents have been also created for performing tasks such as selecting appropriate collections, refining queries, and sorting results to assist with searches conducted in distributed environments. The broad scope of the workshop is on the impact of above technological changes on search interface design.

#index 378607
#* Developing digital libraries education and training programs
#@ Javed Mostafa;Kris Brancolini
#t 2002
#c 14
#! Gaining education and training in the field of Digital Libraries is a difficult prospect. Relevant courses and experiences are usually scattered among different programs and institutions. Often, course content does not include the necessary mix of the theoretical and practical treatment. The workshop is aimed at developers, researchers, educators, and administrators interested in educational programs for training next generation of digital library professionals - both information technologists and librarians.

#index 378608
#* Usability for digital libraries
#@ Ann Blandford;George Buchanan
#t 2002
#c 14
#! As digital libraries are becoming increasingly available to, and used by, diverse user communities who do not have background or training in information sciences, the need to ensure that such libraries are usable and useful is becoming increasingly urgent. Usability issues can be tackled from various directions - technical, cognitive, social, design-oriented - and it is important to bring these different perspectives together, to share views, experiences and insights.

#index 378609
#* Visual interfaces to digital libraries
#@ Katy Börner;Chaomei Chen
#t 2002
#c 14
#% 337564
#% 378609
#! Today's digital libraries (DLs) are content rich, multimedia, multilingual collections that are distributed and accessed worldwide. Designing useful interfaces to access, understand, and manage this knowledge has become an active and challenging field of study. Visual interfaces to DLs aim to shift the user's mental load from slow reading to faster perceptual processes such as visual pattern recognition. They draw on progress in the new field of Information Visualization.The workshop in 2002 continues the theme started at JCDL 2001. In addition, the growth of the field warrants new perspectives on some of the issues we have addressed last year.

#index 378610
#* Workshop on the creation of standardized test collections, tasks and metrics for music information retrieval (MIR) and music digital library (MDL) evaluation
#@ J. Stephen Downie
#t 2002
#c 14
#! This workshop is designed to engage the participation of all those interested in MIR and MDL research and evaluation. Interested parties have been encouraged to submit formal "White Papers" outlining their individual perspectives on what needs to be done to create meaningful MIR and MDL test collections, retrieval tasks and evaluation metrics. Interested parties include musicologists, music theorists, audio-retrieval experts, symbolic-retrieval experts, librarians, lawyers, and business representatives. The compilation of these perspectives and the discussion that follows at the workshop are intended to form the bedrock upon which a solid foundation of future research can be built.

#index 378611
#* Digital gazetteers: integration into distributed digital library services
#@ Linda L. Hill;Gail Hodge;David Smith
#t 2002
#c 14
#! This NKOS workshop for JCDL (the 5th in the series: http://nkos.slis.kent.edu/) will focus on work-in-progress on gazetteer services and gazetteer-related projects in connection with distributed digital library services. It builds on the Digital Gazetteer Information Exchange (DGIE) workshop funded by the NSF in October 1999.Digital gazetteers are specialized KOS that map placenames and types of places to map-based locations and thus integrate word-based georeferencing to map-based georeferencing. The format consists of invited and selected presentations and discussion sessions, with the goal of developing collaborations for future research and development.Participants may provide handouts describing their own gazetteer and other NKOS related projects and will be given the opportunity to introduce their work and their interests briefly.

#index 378612
#* Text retrieval conference (TREC) genomics pre-track workshop
#@ William Hersh
#t 2002
#c 14
#! The goal of this workshop is to allow individuals interested in the Text Retrieval Conference (TREC, trec.nist.gov) Genomics Pre-Track to come together to discuss common goals and interests for the pre-track. The workshop will be designed to generate a plan for developing a common set of tasks, databases, and evaluation measures for the pre-track. The morning will be devoted to presentations by attendees, with the topics to be covered determined by selection by the program committee. The afternoon will be geared towards developing a plan for the pre-track, with the structure based on the number of attendees (i.e., if attendance is large, we will break into small groups).

#index 614032
#* Proceedings of the 3rd ACM/IEEE-CS joint conference on Digital libraries
#@ Lois Delcambre;Geneva Henry;Catherine C. Marshall
#t 2003
#c 14
#! Welcome to JCDL 2003! This is the third in a series of IEEE-CS/ACM joint conferences on digital library research and development. The joint conference brings together the diversity and range of two well-established digital library conferences, ACM DL and IEEE ADL, to provide a major international forum focusing on digital libraries and associated technical, practical, theoretical, and social issues. A decade of progress from the field's early days is readily apparent in the impressive cross-institutional and interdisciplinary collaborations, as well as in the growing number of digital libraries that represent real collections in everyday use. Befitting the conference's beautiful venue, Rice University's Shepherd School of Music, the opening paper session is one about music and digital libraries and runs the gamut from ethnography to algorithms. Other sessions tackle the formidable problem of creating metadata and managing digital resources and services. Humanities digital libraries collections representing cultural heritage and museum artifacts stand alongside scientific and business digital libraries. As always, education and evaluation are vital parts of the conference program. This year, there were 216 submissions from 21 countries. From 91 full papers and 77 short papers, the program committee selected 23 full papers and 32 31 short papers for presentation at the conference; these papers have been revised according to the reviewers' thoughtful comments and are included in the proceedings. The full papers were each assigned to 4 reviewers and the short papers to 3. As in past years, we will be awarding the Vannevar Bush Best Paper Award, sponsored by Knowledge Systems and its president Rob Akscyn, to the paper chosen by the program committee as this year's standout from a set of 23 already outstanding papers. Nominees will be announced at the opening session of the conference and the award will be presented at the banquet.

#index 614033
#* An ethnographic study of music information seeking: implications for the design of a music digital library
#@ Sally Jo Cunningham;Nina Reeves;Matthew Britland
#t 2003
#c 14
#% 60635
#% 281391
#% 378515
#! At present, music digital library systems are being developed based on anecdotal evidence of user needs, intuitive feelings for user information seeking behavior, and a priori assumptions of typical usage scenarios. Emphasis has been placed on basic research into music document representation, efficient searching, and audio-based searching, rather than on exploring the music information needs or information behavior of a target user group. This paper focuses on eliciting the native music information strategies employed by people searching for popular music (that is, music sought for recreational or enjoyment purposes rather than to support a serious or scientific exploration of some aspect of music). To this end, we conducted an ethnographic study of the searching/browsing techniques employed by people in the researchers local communities, as they use two common sources of music: the public library and music stores. We argue that the insights provided by this type of study can inform the development of searching/browsing support for music digital libraries.

#index 614034
#* Content-based indexing of musical scores
#@ Richard A. Medina;Lloyd A. Smith;Deborah R. Wagner
#t 2003
#c 14
#% 248480
#% 309101
#% 422958
#% 631989
#! This paper describes a method of automatically creating a content-based index of musical scores. The goal is to capture the themes, or motifs, that appear in the music. The method was tested by building an index of 25 orchestral movements from the classical music literature. For every movement, the system captured the primary theme, or a variation of the primary theme. In addition, it captured 13 of 28 secondary themes. The resulting index was 14% of the size of the database. A further reduction of 2% is possible; however, this discards secondary themes. A listening experiment using five orchestral movements showed that people can reliably recognize secondary themes after listening to a piece of music-therefore, it may be necessary to retain secondary themes in a score index.

#index 614035
#* Structural analysis of musical signals for indexing and thumbnailing
#@ Wei Chai;Barry Vercoe
#t 2003
#c 14
#% 119431
#% 286746
#% 360631
#% 970451
#% 1775124
#! A musical piece typically has a repetitive structure. Analysis of this structure will be useful for music segmentation, indexing and thumbnailing. This paper presents an algorithm that can automatically analyze the repetitive structure of musical signals. First, the algorithm detects the repetitions of each segment of fixed length in a piece using dynamic programming. Second, the algorithm summarizes this repetition information and infers the structure based on heuristic rules. The performance of the approach is demonstrated visually using figures for qualitative evaluation, and by two structural similarity measures for quantitative evaluation. Based on the structural analysis result, this paper also proposes a method for music thumbnailing. The preliminary results obtained using a corpus of Beatles' songs show that automatic structural analysis and thumbnailing of music are possible.

#index 614036
#* Automatic document metadata extraction using support vector machines
#@ Hui Han;C. Lee Giles;Eren Manavoglu;Hongyuan Zha;Zhenyue Zhang;Edward A. Fox
#t 2003
#c 14
#% 245815
#% 249151
#% 260001
#% 262059
#% 269217
#% 309208
#% 340903
#% 378692
#% 397137
#% 420495
#% 438103
#% 464434
#% 465754
#% 466892
#% 578773
#% 614058
#% 716156
#% 722934
#% 816080
#% 853701
#% 854815
#% 854824
#! Automatic metadata generation provides scalability and usability for digital libraries and their collections. Machine learning methods offer robust and adaptable automatic metadata extraction. We describe a Support Vector Machine classification-based method for metadata extraction from header part of research papers and show that it outperforms other machine learning methods on the same task. The method first classifies each line of the header into one or more of 15 classes. An iterative convergence procedure is then used to improve the line classification by using the predicted class labels of its neighbor lines in the previous round. Further metadata extraction is done by seeking the best chunk boundaries of each line. We found that discovery and use of the structural patterns of the data and domain based word clustering can improve the metadata extraction performance. An appropriate feature normalization also greatly improves the classification performance. Our metadata extraction method was originally designed to improve the metadata extraction quality of the digital libraries Citeseer [17] and EbizSearch[24]. We believe it can be generalized to other digital libraries.

#index 614037
#* Bibliographic attribute extraction from erroneous references based on a statistical model
#@ Atsuhiro Takasu
#t 2003
#c 14
#% 23985
#% 34250
#% 45041
#% 131061
#% 131580
#% 237316
#% 249143
#% 271128
#% 438103
#% 567144
#% 625357
#% 627852
#! In this paper, we propose a method for extracting bibliographic attributes from reference strings captured using Optical Character Recognition (OCR) and an extended hidden Markov model. Bibliographic attribute extraction can be used in two ways. One is reference parsing in which attribute values are extracted from OCR-processed references for bibliographic matching. The other is reference alignment in which attribute values are aligned to the bibliographic record to enrich the vocabulary of the bibliographic database. In this paper, we first propose a statistical model for attribute extraction that represents both the syntactical structure of references and OCR error patterns. Then, we perform experiments using bibliographic references obtained from scanned images of papers in journals and transactions and show that useful attribute values are extracted from OCR-processed references. We also show that the proposed model has advantages in reducing the cost of preparing training data, a critical problem in rule-based systems.

#index 614038
#* Automated semantic annotation and retrieval based on sharable ontology and case-based learning techniques
#@ Von-Wun Soo;Chen-Yu Lee;Chung-Cheng Li;Shu Lei Chen;Ching-chih Chen
#t 2003
#c 14
#% 46803
#% 318785
#% 378509
#% 413603
#% 433879
#% 445449
#% 478186
#% 482334
#% 494448
#% 501730
#% 840583
#! Effective information retrieval (IR) using domain knowledge and semantics is one of the major challenges in IR. In this paper we propose a framework that can facilitate image retrieval based on a sharable domain ontology and thesaurus. In particular, case-based learning (CBL) using a natural language phrase parser is proposed to convert a natural language query into resource description framework (RDF) format, a semantic-web standard of metadata description that supports machine readable semantic representation. This same parser also is extended to perform semantic annotation on the descriptive metadata of images and convert metadata automatically into the same RDF representation. The retrieval of images then can be conducted by matching the semantic and structural descriptions of the user query with those of the annotated descriptive metadata of images. We tested in our problem domain by retrieving the historical and cultural images taken from Dr. Ching-chih Chen's "First Emperor of China" CD-ROM [25] as part of our productive international digital library collaboration. We have constructed and implemented the domain ontology, a Mandarin Chinese thesaurus, as well as the similarity match and retrieval algorithms in order to test our proposed framework. Our experiments have shown the feasibility and usability of these approaches.

#index 614039
#* Towards a cultural heritage digital library
#@ Gregory Crane;Clifford Wulfman
#t 2003
#c 14
#% 204644
#% 247317
#% 301217
#% 301283
#% 330016
#% 332733
#% 337507
#% 337508
#% 340914
#% 366371
#% 378478
#% 378484
#% 378506
#% 378508
#% 378510
#% 397132
#% 485969
#% 508266
#% 508271
#% 508274
#% 508281
#% 508287
#% 508419
#% 740916
#% 815103
#% 815115
#% 815117
#% 818038
#! This paper surveys research areas relevant to cultural heritage digital libraries. The emerging National Science Digital Library promises to establish the foundation on which those of us beyond the scientific and engineering community will likely build. This paper thus articulates the particular issues that we have encountered in developing cultural heritage collections. We provide a broad overview of audiences, collections, and services.

#index 614040
#* The DSpace institutional digital repository system: current functionality
#@ Robert Tansley;Mick Bass;David Stuve;Margret Branschofsky;Daniel Chudnov;Greg McClellan;MacKenzie Smith
#t 2003
#c 14
#% 344929
#% 534148
#! In this paper we describe DSpace™, an open source system that acts as a repository for digital research and educational material produced by an organization or institution. DSpace was developed during two years' collaboration between the Hewlett-Packard Company and MIT Libraries. The development team worked closely with MIT Libraries staff and early adopter faculty members to produce a 'breadth-first' system, providing all of the basic features required by a digital repository service. As well as functioning as a live service, DSpace is intended as a base for extending repository functionality, particularly to address long-term preservation concerns. We describe the functionality of the current DSpace system, and briefly describe its technical architecture. We conclude with some remarks about the future development and operation of the DSpace system.

#index 614041
#* Metis: lightweight, flexible, and Web-based workflow services for digital libraries
#@ Kenneth M. Anderson;Aaron Andersen;Neet Wadhwani;Laura M. Bartolo
#t 2003
#c 14
#% 32599
#% 179755
#% 208411
#% 220238
#% 221591
#% 227825
#% 232229
#% 272679
#% 314008
#% 314025
#% 314027
#% 338354
#% 418878
#% 420040
#% 440708
#% 562058
#% 640948
#% 1303528
#! The Metis project is developing workflow technology designed for use in digital libraries by avoiding the assumptions made by traditional workflow systems. In particular, digital libraries have highly distributed sets of stake-holders who nevertheless must work together to perform shared activities. Hence, traditional assumptions that all members of a workflow belong to the same organization, work in the same fashion, or have access to similar computing platforms are invalid. The Metis approach makes use of event-based workflows to support the distributed nature of digital library workflow and employs techniques to make the resulting technology lightweight, flexible, and integrated with the Web. This paper describes the conceptual framework behind the Metis approach as well as a prototype which implements the framework. The prototype represents a "proof-of-concept" of the Metis framework and approach as we show how it can both model and execute a peer review workflow drawn from a "real-world" digital library. After describing related work, the paper concludes with a discussion of future research opportunities in the area of digital library workflow and outlines how Metis is being deployed to a small set of digital libraries for additional evaluation.

#index 614042
#* Protein association discovery in biomedical literature
#@ Yueyu Fu;Javed Mostafa;Kazuhiro Seki
#t 2003
#c 14
#% 257145
#% 406493
#% 413664
#% 742087
#! Protein association discovery can directly contribute toward developing protein pathways; hence it is a significant problem in bioinformatics. LUCAS (Library of User-Oriented Concepts for Access Services) was designed to automatically extract and determine associations among proteins from biomedical literature. Such a tool has notable potential to automate database construction in biomedicine, instead of relying on experts' analysis. This paper reports on the mechanisms for automatically generating clusters of proteins. A formal evaluation of the system, based on a subset of 2000 MEDLINE titles and abstracts, has been conducted against Swiss-Prot database in which the associations among concepts are entered by experts manually.

#index 614043
#* Genescene: biomedical text and data mining
#@ Gondy Leroy;Hsinchun Chen;Jesse D. Martinez;Shauna Eggers;Ryan R. Falsey;Kerri L. Kislin;Zan Huang;Jiexun Li;Jie Xu;Daniel M. McDonald;Gavin Ng
#t 2003
#c 14
#! To access the content of digital texts efficiently, it is necessary to provide more sophisticated access than keyword based searching. Genescene provides biomedical researchers with research findings and background relations automatically extracted from text and experimental data. These provide a more detailed overview of the information available. The extracted relations were evaluated by qualified researchers and are precise. A qualitative ongoing evaluation of the current online interface indicates that this method to search the literature is more useful and efficient than keyword based searching.

#index 614044
#* Taxonomies for automated question triage in digital reference
#@ Jeffrey Pomerantz;R. David Lankes
#t 2003
#c 14
#! This study identifies (1) several taxonomies of questions at different levels of linguistic analysis, according to which questions received by digital reference services are classified, and (2) a simple categorization of triage recipients. The utility of these taxonomies and categorizations of triage recipients is discussed as the basis for systems for automating triage and other steps in the digital reference process.

#index 614045
#* Topic detection and interest tracking in a dynamic online news source
#@ Andrew J. Kurtz;Javed Mostafa
#t 2003
#c 14
#% 267589
#% 305859
#% 320432
#! Digital libraries in the news domain may contain frequently updated data. Providing personalized access to such dynamic resources is an important goal. In this paper, we investigate the area of filtering online dynamic news sources based on personal profiles. We experimented with an intelligent news-sifting system that tracks topic development in a dynamic online news source. Vocabulary discovery and clustering are used to expose current news topics. User interest profiles, generated from explicit and implicit feedback are used to customize the news retrieval system's interface.

#index 614046
#* Methods for precise named entity matching in digital collections
#@ Peter T. Davis;David K. Elson;Judith L. Klavans
#t 2003
#c 14
#% 184073
#% 210985
#% 337250
#% 350522
#% 742449
#% 748722
#% 815876
#% 840583
#! In this paper, we describe an interactive system, built within the context of CLiMB project, which permits a user to locate the occurrences of named entities within a given text. The named entity tool was developed to identify references to a single art object (e.g. a particular building) with high precision in text related to images of that object in a digital collection. We start with an authoritative list of art objects, and seek to match variants of these named entities in related text. Our approach is to "decay" entities into progressively more general variants while retaining high precision. As variants become more general, and thus more ambiguous, we propose methods to disambiguate intermediate results. Our results will be used to select records into which automatically generated metadata will be loaded.

#index 614047
#* An application of multiple viewpoints to content-based image retrieval
#@ James C. French;A. C. Chapin;Worthy N. Martin
#t 2003
#c 14
#% 443261
#! Content-based image retrieval uses features that can be extracted from the images themselves. Using more than one representation of the images in a collection can improve the results presented to a user without changing the underlying feature extraction or search technologies. We present an example of this "multiple viewpoint" approach, multiple image channels, and discuss its advantages for an image-seeking user. This approach has also been shown to dramatically improve retrieval effectiveness in content-based image retrieval systems[3].

#index 614048
#* Convergence of knowledge management and E-learning: the GetSmart experience
#@ Byron Marshall;Yiwen Zhang;Hsinchun Chen;Ann Lally;Rao Shen;Edward Fox;Lillian N. Cassel
#t 2003
#c 14
#% 27049
#% 177234
#% 201210
#% 290648
#% 438356
#% 489749
#! The National Science Digital Library (NSDL), launched in December 2002, is emerging as a center of innovation in digital libraries as applied to education. As a part of this extensive project, the GetSmart system was created to apply knowledge management techniques in a learning environment. The design of the system is based on an analysis of learning theory and the information search process. Its key notion is the integration of search tools and curriculum support with concept mapping. More than 100 students at the University of Arizona and Virginia Tech used the system in the fall of 2002. A database of more than one thousand student-prepared concept maps has been collected with more than forty thousand relationships expressed in semantic, graphical, node-link representations. Preliminary analysis of the collected data is revealing interesting knowledge representation patterns.

#index 614049
#* Acquisition, representation, query and analysis of spatial data: a demonstration 3D digital library
#@ Jeremy Rowe;Anshuman Razdan;Arleyn Simon
#t 2003
#c 14
#% 342287
#% 401848
#% 434549
#% 434552
#% 664407
#! The increasing power of techniques to model complex geometry and extract meaning from 3D information create complex data that must be described, stored, and displayed to be useful to researchers. Responding to the limitations of two-dimensional (2D) data representations perceived by discipline scientists, the Partnership for Research in Spatial Modeling (PRISM) project at Arizona State University (ASU) developed modeling and analytic tools that raise the level of abstraction and add semantic value to 3D data. The goals are to improve scientific communication, and to assist in generating new knowledge, particularly for natural objects whose asymmetry limit study using 2D representations. The tools simplify analysis of surface and volume using curvature and topology to help researchers understand and interact with 3D data. The tools produced automatically extract information about features and regions of interest to researchers, calculate quantifiable, replicable metric data, and generate metadata about the object being studied. To help researchers interact with the information, the project developed prototype interactive, sketch-based interfaces that permit researchers to remotely search, identify and interact with the detailed, highly accurate 3D models of the objects. The results support comparative analysis of contextual and spatial information, and extend research about asymmetric manmade and natural objects.

#index 614050
#* Leveraging a common representation for personalized search and summarization in a medical digital library
#@ Kathleen R. McKeown;Noemie Elhadad;Vasileios Hatzivassiloglou
#t 2003
#c 14
#% 46803
#% 51052
#% 316515
#% 337277
#% 337479
#% 342786
#% 350148
#% 741216
#! Despite the large amount of online medical literature, it can be difficult for clinicians to find relevant information at the point of patient care. In this paper, we present techniques to personalize the results of search, making use of the online patient record as a sophisticated, pre-existing user model. Our work in PERSIVAL, a medical digital library, includes methods for re-ranking the results of search to prioritize those that better match the patient record. It also generates summaries of the re-ranked results which highlight information that is relevant to the patient under the physician's care. We focus on the use of a common representation for the articles returned by search and the patient record which facilitates both the re-ranking and the summarization tasks. This common approach to both tasks has a strong positive effect on the ability to personalize information.

#index 614051
#* Visualizing and exploring Picasso's world
#@ Carlos Monroy;Richard Furuta;Enrique Mallen
#t 2003
#c 14
#% 301234
#% 467757
#% 467763
#! We discuss the preliminary use of a visualization tool called Interactive Timeline Viewer (ItLv) in visualizing and exploring a collection of art works by Pablo Ruiz Picasso. Our data set is composed of a subset of the On-line Picasso Project, a significantly-sized on-line art repository of the renowned Spanish artist. We also include a brief discussion about how this visualization tool can help art scholars to study and analyze an artist's life and works.

#index 614052
#* Graded access to sensitive materials at the archive of the indigenous languages of Latin America
#@ Heidi Johnson
#t 2003
#c 14
#! The Archive of the Indigenous Languages of Latin America (AILLA) is a web-accessible repository of multi-media resources in and about the indigenous languages of Latin America. In this paper, I describe the Graded Access System developed at AILLA to protect sensitive materials by allowing resource producers - academics and indigenous people - finely-grained control over the resources they house in the archive.

#index 614053
#* Learning digital library technology across borders
#@ Sílvia Barcellos Southwick;Richard Southwick
#t 2003
#c 14
#! This paper describes the background context and initial findings from an ongoing case study of an electronic theses and dissertations (ETD) digital library (DL) project in Brazil. The specific focus of the case study centers on the activities of a Brazilian government agency acting as a mediator between software developers - primarily academic institutions in the United States - and university clients in Brazil. The authors highlight the loosely integrated nature of the DL technology, and the uncertain relationship between developers and users in terms of support. These circumstances reinforce a view of technology transfer as a process of organizational learning. As a consequence, the mediating institution in the study is viewed as assuming multiple roles in advancing the project.

#index 614054
#* Personal spaces in the context of OAI
#@ Natalia Reyes-Farfán;J. Alfredo Sánchez
#t 2003
#c 14
#% 301268
#! We describe MiBiblio 2.0, a highly personalizable user interface for a federation of digital libraries under the OAI Protocol for Metadata Harvesting. (OAI-PMH). MiBiblio 2.0 allows users to personalize their personal space by choosing the resources and services they need, as well as to organize, classify and manage their workspaces including resources from any of the federated libraries. Results can be kept in personal spaces and organized into categories using a drag-and-drop interface.

#index 614055
#* PoPS: mobile access to digital library resources
#@ Nohema Castellanos;J. Alfredo Sánchez
#t 2003
#c 14
#% 281448
#% 316255
#% 330780
#% 390155
#! Mobile devices represent new opportunities for accessing digital libraries (DLs) but also pose a number of challenges given the diversity of their hardware and software features. We describe a framework aimed at facilitating the generation of interfaces for access to DL resources from a wide range of mobile devices.

#index 614056
#* How to turn the page
#@ Yi-Chun Chu;Ian H. Witten;Richard Lobb;David Bainbridge
#t 2003
#c 14
#% 341590
#% 645984
#! Can digital libraries provide a reading experience that more closely resembles a real book than a scrolled or paginated electronic display? This paper describes a prototype page-turning system that realistically animates full three-dimensional page-turns. The dynamic behavior is generated by a mass-spring model defined on a rectangular grid of particles. The prototype takes a PDF or E-book file, renders it into a sequence of PNG images representing individual pages, and animates the pageturns under user control. The simulation behaves fairly naturally, although more computer graphics work is required to perfect it.

#index 614057
#* Repository synchronization in the OAI framework
#@ Xiaoming Liu;Kurt Maly;Mohammad Zubair;Michael L. Nelson
#t 2003
#c 14
#% 197531
#% 227891
#% 294891
#% 300139
#% 319078
#% 337237
#% 378511
#% 480816
#% 632999
#% 715251
#% 716156
#! The Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) began as an alternative to distributed searching of scholarly eprint repositories. The model embraced by the OAI-PMH is that of metadata harvesting, where value-added services (by a "service provider") are constructed on cached copies of the metadata extracted from the repositories of the harvester's choosing. While this model dispenses with the well known problems of distributed searching, it introduces the problem of synchronization. Stated simply, this problem arises when the service provider's copy of the metadata does not match the metadata currently at the constituent repositories. We define some metrics for describing the synchronization problem in the OAI-PMH. Based on these metrics, we study the synchronization problem of the OAI-PMH framework and propose several approaches for harvesters to implement better synchronization. In particular, if a repository knows its update frequency, it can publish it in an OAI-PMH Identify response using an optional About container that borrows from RDF Site Syndication (RSS) Format.

#index 614058
#* eBizSearch: an OAI-compliant digital library for eBusiness
#@ Yves Petinot;Pradeep B. Teregowda;Hui Han;C. Lee Giles;Steve Lawrence;Arvind Rangaswamy;Nirmal Pal
#t 2003
#c 14
#% 204644
#% 237303
#% 249143
#% 251919
#% 252750
#% 268078
#% 271128
#% 281251
#% 281446
#% 337235
#% 338577
#% 378505
#% 378511
#% 458379
#% 480309
#% 614036
#! Niche Search Engines offer an efficient alternative to traditional search engines when the results returned by general-purpose search engines do not provide a sufficient degree of relevance and when nontraditional search features are required. Niche search engines can take advantage of their domain of concentration to achieve higher relevance and offer enhanced features. We discuss a new digital library niche search engine, eBizSearch, dedicated to e-business and e-business documents. The ground technology for eBizSearch is CiteSeer, a special-purpose automatic indexing document digital library and search engine developed at NEC Research Institute. We present here the integration of CiteSeer in the framework of eBizSearch and the process necessary to tune the whole system towards the specific area of e-business. We show how using machine learning algorithms we generate metadata to make eBizSearch Open Archives compliant. eBizSearch is a publicly available service and can be reached at [13].

#index 614059
#* The OAI-PMH static repository and static repository gateway
#@ Patrick Hochstenbach;Henry Jerez;Herbert Van de Sompel
#t 2003
#c 14
#% 337235
#% 337236
#% 567146
#! Although the OAI-PMH specification is focused on making it straightforward for data providers to expose metadata, practice shows that in certain significant situations deployment of OAI-PMH conformant repository software remains problematic. In this paper, we report on research aimed at devising solutions to further lower the barrier to make metadata collections harvestable. We provide an in depth description of an approach in which a data provider makes a metadata collection available as an XML file with a specific format -- an OAI Static Repository - which is made OAI-PMH harvestable through the intermediation of software - an OAI Static Repository Gateway - operated by a third party. We describe the properties of both components, and provide insights in our experience with an experimental implementation of a Gateway.

#index 614060
#* How fast is too fast?: evaluating fast forward surrogates for digital video
#@ Barbara M. Wildemuth;Gary Marchionini;Meng Yang;Gary Geisler;Todd Wilkens;Anthony Hughes;Richard Gruss
#t 2003
#c 14
#% 157744
#% 237331
#% 238915
#% 247287
#% 247291
#% 249146
#% 281362
#% 287179
#% 343129
#% 378286
#% 437509
#% 508277
#% 584921
#% 608390
#% 725496
#! To support effective browsing, interfaces to digital video libraries should include video surrogates (i.e., smaller objects that can stand in for the videos in the collection, analogous to abstracts standing in for documents). The current study investigated four variations (i.e., speeds) of one form of video surrogate: a fast forward created by selecting every Nth frame from the full video. In addition, it tested the validity of six measures of user performance when interacting with video surrogates. Forty-five study participants interacted with all four versions of the fast forward surrogate, and completed all six performance tasks with each. Surrogate speed affected performance on four of the measures: object recognition (graphical), action recognition, linguistic gist comprehension (full text), and visual gist comprehension. Based on these results, we recommend a fast forward default speed of 1:64 of the original video keyframes. In addition, users should control the choice of fast forward speed to adjust for content characteristics and personal preferences.

#index 614061
#* Event-based retrieval from a digital library containing medical streams
#@ Mohamed Kholief;Kurt Maly;Stewart Shen
#t 2003
#c 14
#! We describe a digital library that contains streams and supports event-based retrieval. Streams used in the digital library are CT scan, medical text, and audio streams. Events, such as 'tumor appeared', were generated and represented in the user interface to enable doctors to retrieve and playback segments of the streams. This paper concentrates on describing the data organization and the user interface.

#index 614062
#* Music representation in a digital music library
#@ Donald Byrd;Eric Isaacson
#t 2003
#c 14
#% 248486
#% 691479
#! The Variations2 digital music library currently supports music in audio and score-image formats. In a future version, we plan to add music in a symbolic form. This paper describes our work defining a music representation suitable for the needs of our users.

#index 614063
#* A quantified fidelity criterion for parameter-embedded watermarking of audio archives
#@ A. R. Gurijala;J. R. Deller
#t 2003
#c 14
#% 342904
#% 395959
#! A novel algorithm for speech watermarking through parametric modeling is enhanced by inclusion of a quantified fidelity criterion. Watermarking is effected through solution of a set-membership filtering (SMF) problem, subject to an l∞ fidelity criterion in the signal space. The SMF approach provides flexibility in obtaining watermark solutions that trade-off watermark robustness and stegosignal fidelity.

#index 614064
#* Fourth-phase digital libraries: pacing, linking, annotating and citing in multimedia collections
#@ J. Alfredo Sánchez;J. Aníbal Arias
#t 2003
#c 14
#% 378498
#% 437509
#% 614054
#! We discuss the implications of the use of current multimedia collections and posit that it is possible to build what we term fourth-phase digital libraries (4PDLs). In 4PDLs users can take advantage of both the powerful audiovisual channels and the proven practices developed for media such as text. We demonstrate how various technologies can be integrated to produce a 4PDL.

#index 614065
#* On querying geospatial and georeferenced metadata resources in G-portal
#@ Zehua Liu;Ee-Peng Lim;Wee-Keong Ng;Dion H. Goh
#t 2003
#c 14
#% 252304
#% 281404
#% 281487
#% 337246
#% 337496
#% 378546
#% 427199
#% 437510
#% 463595
#% 489734
#% 770338
#! G-Portal is a web portal system providing a range of digital library services to access geospatial and georeferenced resources on the Web. Among them are the storage and query subsystems that provide a central repository of metadata resources organized under different projects. In GPortal, all metadata resources are represented in XML (Extensible Markup Language) and they are compliant to some resource schemas defined by their creators. The resource schemas are extended versions of a basic resource schema making it easy to accommodate all kinds of metadata resources while maintaining the portability of resource data. To support queries over the geospatial and georeferenced metadata resources, a XQuery-like query language known as RQL (Resource Query Language) has been designed. In this paper, we present the RQL language features and provide some experimental findings about the storage design and query evaluation strategies for RQL queries.

#index 614066
#* A scientific digital library in context: an Earth Radiation Budget Experiment collection in the atmospheric sciences data center digital library
#@ Michelle Ferebee;Gregory Boeshaar;Kathryn Bush;Judy Hertz
#t 2003
#c 14
#% 237336
#% 249150
#% 332739
#% 337235
#! At the NASA Langley Research Center, the Earth Radiation Budget Experiment (ERBE) Data Management Team and the Atmospheric Sciences Data Center are developing a digital collection for the ERBE project. The main goal is long-term preservation of a comprehensive information environment. The secondary goal is to provide a context for these data products by centralizing the 25-year research project's scattered information elements. The development approach incorporates elements of rapid prototyping and user-centered design in a standards-based implementation. A working prototype is in testing with a small number of users.

#index 614067
#* Designing a language for creating conceptual browsing interfaces for digital libraries
#@ Tamara Sumner;Sonal Bhushan;Faisal Ahmad;Qianyi Gu
#t 2003
#c 14
#% 358412
#! Conceptual browsing interfaces can help educators and learners to locate and use learning resources in educational digital libraries; in particular, resources that are aligned with nationally-recognized learning goals. Towards this end, we are developing a Strand Map Library Service, based on the maps published by the American Association for the Advancement of Science (AAAS). This service includes two public interfaces: (1) a graphical user interface for use by teachers and learners and (2) a programmatic interface that enables developers to construct conceptual browsing interfaces using dynamically generated components. Here, we describe our iterative, rapid prototyping design methodology, and the initial round of language type components that have been implemented and evaluated.

#index 614068
#* Content access characterization in digital libraries
#@ Greg Janée;James Frew;David Valentine
#t 2003
#c 14
#% 378545
#! To support non-trivial clients, such as data exploration and analysis environments, digital libraries must be able to describe the access modes that their contents support. We present a simple scheme that distinguishes four content accessibility classes: download (byte-stream retrieval), service (API), web interface (interactive), and offline. These access modes may recursively nest in alternative (semantically equivalent) or multipart (component) hierarchies. This scheme is simple enough to be easily supported by DL content providers, yet rich enough to allow programmatic clients to automatically identify appropriate access point(s).

#index 614069
#* SCENS: a system for the mediated sharing of sensitive data
#@ Song Ye;Fillia Makedon;Tilmann Steinberg;Li Shen;James Ford;Yuhang Wang;Yan Zhao;Sarantos Kapidakis
#t 2003
#c 14
#% 508288
#! This paper introduces SCENS, a Secure Content Exchange Negotiation System suitable for the exchange of private digital data that reside in distributed digital repositories. SCENS is an open negotiation system with flexibility, security and scalability. SCENS is currently being designed to support data sharing in scientific research, by providing incentives and goals specific to a research community. However, it can easily be extended to apply to other communities, such as government, commercial and other types of exchanges. It is a trusted third party software infrastructure enabling independent entities to interact and conduct multiple forms of negotiation.

#index 614070
#* Understanding educator perceptions of "quality" in digital libraries
#@ Tamara Sumner;Michael Khoo;Mimi Recker;Mary Marlino
#t 2003
#c 14
#% 324925
#% 324926
#% 332756
#% 337256
#% 337496
#% 337545
#% 378491
#% 378539
#% 378545
#! The purpose of the study was to identify educators' expectations and requirements for the design of educational digital collections for classroom use. A series of five focus groups was conducted with practicing teachers, pre-service teachers, and science librarians, drawn from different educational contexts (i.e., K-5, 6--12, College). Participants' expect that the added value of educational digital collections is the provision of: (1) 'high quality' teaching and learning resources, and (2) additional contextual information beyond that in the resource. Key factors that influence educators' perceptions of quality were identified: scientific accuracy, bias, advertising, design and usability, and the potential for student distraction. The data showed that participants judged these criteria along a continuum of tolerance, combining consideration of several factors in their final judgements. Implications for collections accessioning policies, peer review, and digital library service design are discussed.

#index 614071
#* Integrating digital libraries into learning environments: the LEBONED approach
#@ Frank Oldenettel;Michael Malachinski;Dennis Reil
#t 2003
#c 14
#% 334867
#% 334868
#% 350896
#% 411230
#% 648980
#% 658716
#% 673710
#! This paper presents the project LEBONED that focuses on the integration of digital libraries and their contents into web-based learning environments. We describe in general how the architecture of a standard learning management system has to be modified to enable the integration of digital libraries. An important part of this modification is the LEBONED Metadata Architecture which depicts the handling of metadata and documents imported from digital libraries. The main components of this architecture and their interrelation are presented in detail. Afterwards we show a practical application of the concepts described before: The integration of the digital library eVerlage into the learning management system Blackboard.

#index 614072
#* The interactive shared educational environment: user interface, system architecture and field study
#@ Xiangming Mu;Gary Marchionini;Amy Pattee
#t 2003
#c 14
#% 297591
#% 319694
#% 334871
#% 334872
#% 341260
#% 351983
#% 373996
#% 1775134
#! The user interface and system architecture of a novel Interactive Shared Educational Environment (ISEE) are presented. Based on a lightweight infrastructure, ISEE enables relatively low bandwidth network users to share videos as well as text messages. Smartlink is a new concept introduced in this paper. Individual information presentation components, like the video player and text chat room, are "smartly" linked together through video timestamps and hyperlinks. A field study related to children book selections using ISEE was conducted. The results indicated that the combination of three information presentation components, including video player with storyboard, shared browser, and text chat room, provided an effective and more comfortable collaboration and learning environment for the given tasks than text reviews or text chat alone or in combination. The video player was the most preferred information component. Text comments in the chat room that did not synchronize with the video content distracted some participants due to limited cognitive capacity. Using smartlink to synchronize various information components or "channels" is our attempt to reduce the user's working memory load in information enriched distance learning environments made possible by digital libraries.

#index 614073
#* XML semantics and digital libraries
#@ Allen Renear;David Dubin;C. M. Sperberg-McQueen;Claus Huitfeldt
#t 2003
#c 14
#% 27046
#% 206899
#% 402429
#% 413769
#% 445460
#! The lack of a standard formalism for expressing the semantics of an XML vocabulary is a major obstacle to the development of high-function interoperable digital libraries. XML document type definitions (DTDs) provide a mechanism for specifying the syntax of an XML vocabulary, but there is no comparable mechanism for specifying the semantics of that vocabulary --- where semantics simply means the basic facts and relationships represented by the occurrence of XML constructs. A substantial loss of functionality and interoperability in digital libraries results from not having a common machine-readable formalism for expressing these relationships for the XML vocabularies currently being used to encode content. Recently a number of projects and standards have begun taking up related topics. We describe the problem and our own project.

#index 614074
#* Utility of an OAI service provider search portal
#@ Sarah L. Shreeves;Christine Kirkham;Joanne Kaczmarek;Timothy W. Cole
#t 2003
#c 14
#% 337235
#! The Open Archives Initiative (OAI) Protocol for Metadata Harvesting (PMH) facilitates efficient interoperability between digital collections, in particular by enabling service providers to construct, with relatively modest effort, search portals that present aggregated metadata to specific communities. This paper describes the experiences of the University of Illinois at Urbana-Champaign Library as an OAI service provider. We discuss the creation of a search portal to an aggregation of metadata describing cultural heritage resources. We examine several key challenges posed by the aggregated metadata and present preliminary findings of a pilot study of the utility of the portal for a specific community (student teachers). We also comment briefly on the potential for using text analysis tools to uncover themes and relationships within the aggregated metadata.

#index 614075
#* The Dienst-OAI gateway
#@ Terry L. Harrison;Michael L. Nelson;Mohammad Zubair
#t 2003
#c 14
#% 294891
#% 378505
#% 508284
#% 567146
#! Though the Open Archive Initiative Protocol for Metadata Harvesting (OAI-PMH) is becoming the de facto standard for digital libraries, some of its predecessors are still in use. Although a limited number of Dienst repositories continue to be populated, others are precariously unsupported. The Dienst Open Archive Gateway (DOG) is a gateway between the OAI-PMH and the Dienst (version 4.1) protocol. DOG allows OAIPMH harvesters to extract metadata records (in RFC-1807 or Dublin Core) from Dienst servers.

#index 614076
#* The XML log standard for digital libraries: analysis, evolution, and deployment
#@ Marcos André Gonçalves;Ganesh Panchanathan;Unnikrishnan Ravindranathan;Aaron Krowne;Edward A. Fox;Filip Jagodzinski;Lillian Cassel
#t 2003
#c 14
#% 503226
#% 508283
#% 716459
#! We describe current efforts and developments building on our proposal for an XML log standard format for digital library (DL) logging analysis and companion tools. Focus is given to the evolution of formats and tools, based on analysis of deployment in several DL systems and testbeds. Recent development of analysis tools also is discussed.

#index 614077
#* A quantitative analysis of unqualified dublin core metadata element set usage within data providers registered with the open archives initiative
#@ Jewel Ward
#t 2003
#c 14
#% 287602
#! This research describes an empirical study of how the unqualified Dublin Core Metadata Element Set (DC or DCMES) is used by 100 Data Providers (DPs) registered with the Open Archives Initiative (OAI). The research was conducted to determine whether or not the DCMES is used to its full capabilities. Eighty-two of 100 DPs have metadata records available for analysis. DCMES usage varies by type of DP. The average number of Dublin Core elements per record is eight, with an average of 91, 785 Dublin Core elements in each DP. Five of the 15 elements of the DCMES are used 71% of the time. The results show the unqualified DCMES is not used to its fullest extent within DPs registered with the OAI.

#index 614078
#* Extracting geometry from digital models in a cultural heritage digital library
#@ Thomas L. Milbank
#t 2003
#c 14
#% 399609
#% 416060
#% 665129
#! This paper describes research to enhance the integration between digital models and the services provided by the document management systems of digital libraries. Processing techniques designed for XML texts are applied to X3D models, allowing specific geometry to be automatically retrieved and displayed. The research demonstrates that models designed on object-oriented paradigms are most easily exploited by XML document management systems.

#index 614079
#* Assembling and enriching digital library collections
#@ David Bainbridge;John Thompson;Ian H. Witten
#t 2003
#c 14
#% 236033
#% 262246
#% 301247
#% 301252
#% 301283
#% 337242
#% 645984
#! People who create digital libraries need to gather together the raw material, add metadata as necessary, and design and build new collections. This paper sets out the requirements for these tasks and describes a new tool that supports them interactively, making it easy for users to create their own collections from electronic files of all types. The process involves selecting documents for inclusion, coming up with a suitable metadata set, assigning metadata to each document or group of documents, designing the form of the collection in terms of document formats, searchable indexes, and browsing facilities, building the necessary indexes and data structures, and putting the collection in place for others to use. Moreover, different situations require different workflows, and the system must be flexible enough to cope with these demands. Although the tool is specific to the Greenstone digital library software, the underlying ideas should prove useful in more general contexts.

#index 614080
#* A system for building expandable digital libraries
#@ Donatella Castelli;Pasquale Pagano
#t 2003
#c 14
#% 378511
#% 508276
#% 508284
#% 645984
#% 648965
#! Expandability is one of the main requirements of future digital libraries. This paper introduces a digital library service system, OpenDLib, that has been designed to be highly expandable in terms of content, services and usage. The paper illustrates the mechanisms that enable expandability and discusses their impact on the development of the system architecture.

#index 614081
#* The Web-DL environment for building digital libraries from the Web
#@ Pável P. Calado;Marcos A. Gonçalves;Edward A. Fox;Berthier Ribeiro-Neto;Alberto H. F. Laender;Altigran S. da Silva;Davi C. Reis;Pablo A. Roberto;Monique V. Vieira;Juliano P. Lage
#t 2003
#c 14
#% 197531
#% 219098
#% 249148
#% 301247
#% 333932
#% 337235
#% 342703
#% 378520
#% 378521
#% 397605
#% 413642
#% 424931
#% 438103
#% 503226
#% 503234
#% 533930
#! The Web contains a huge volume of unstructured data, which is difficult to manage. In digital libraries, on the other hand, information is explicitly organized, described, and managed. Community-oriented services are built to attend specific information needs and tasks. In this paper, we describe an environment, Web-DL, that allows the construction of digital libraries from the Web. The Web-DL environment will allow us to collect data from the Web, standardize it, and publish it through a digital library system. It provides support to services and organizational structure normally available in digital libraries, but benefiting from the breadth of the Web contents. We experimented with applying the Web-DL environment to the Networked Digital Library of Theses and Dissertations (NDLTD), thus demonstrating that the rapid construction of DLs from the Web is possible. Also, Web-DL provides an alternative as a largescale solution for interoperability between independent digital libraries.

#index 614082
#* Distributed proofreading
#@ Gregory B. Newby;Charles Franks
#t 2003
#c 14
#! Distributed proofreading allows many people working individually across the Internet to contribute to the proofreading of a new electronic book. This paper describes Project Gutenberg's Distributed Proofreading project, along with our general procedures for creating an electronic book from a physical book. Distributed proofreading has promise for the future of Project Gutenberg, and is likely to be a useful strategy for other digital library projects.

#index 614083
#* Correcting broken characters in the recognition of historical printed documents
#@ Michael Droettboom
#t 2003
#c 14
#% 378479
#% 443939
#% 504885
#! This paper presents a new technique for dealing with broken characters, one of the major challenges in the optical character recognition (OCR) of degraded historical printed documents. A technique based on graph combinatorics is used to rejoin the appropriate connected components. It has been applied to real data with successful results.

#index 614084
#* Correcting common distortions in camera-imaged library materials
#@ Michael S. Brown;Desmond Tsoi
#t 2003
#c 14
#% 337510
#% 359641
#! We present a technique to correct image distortion that can occur when library materials are imaged by cameras. Our approach provides a general framework to undo a variety of common distortions, including binder curl, fold distortion, and combinations of the two. Our algorithm is described and demonstrated on several examples.

#index 614085
#* Link attachment (preferential and otherwise) in contributor-run digital libraries
#@ Miles Efron;Donald Sizemore
#t 2003
#c 14
#% 332737
#% 351376
#! Ibiblio is a digital library whose materials are submitted and maintained by volunteer contributors. This study analyzes the emergence of hyperlinke d structures within the ibiblio collection. In the context of ibiblio, we analyze the suitability of Barabasi's model of preferential attachment to describe the distribution of incoming links. We find that the degree of maintainer activity for a given site (as measured by the voluntary development ofdescriptive metadata) is a stronger link count predictor for ibiblio than is a site's age, as the standard model predicts. Thus we argue that the efforts of ibiblio's contributors positively affectthe popularity of their materials.

#index 614086
#* Automatic disambiguation of Latin abbreviations in early modern texts for humanities digital libraries
#@ Jeffrey A. Rydberg-Cox
#t 2003
#c 14
#% 301283
#! Early modern books written in Latin contain many abbreviations of common words that are derived from earlier manuscript practice. While these abbreviations are usually easily deciphered by a reader well-versed in Latin, they pose technical problems for full text digitization: they are difficult to OCR or have typed and --- if they are not expanded correctly --- they limit the effectiveness of information retrieval and reading support tools in the digital library. In this paper, I will describe a method for the automatic expansion and disambiguation of these abbreviations.

#index 614087
#* Educational tools in support of the Stanford MediaServer
#@ Derek Stevenson;Chih-Chien Chao;Sakti Srivastava;Jeremy C. Durack;Amy Ladd;Kevin Montgomery;Jenn Stringer;Parvati Dev
#t 2003
#c 14
#! Medical media resources exist in a variety of analog and digital formats. Collections are generally organized and stored by their owners, each of whom utilizes their own method of cataloging and retrieval. As faculty retire, move on, or pass away, institutions risk losing the expertise that enhances the value media. The Stanford MediaServer has previously been deployed to catalog, organize, and centralize management of such media collections via the World Wide Web. Educational tools have been developed on top of existing MediaServer infrastructure to address a range of pedagogical models, and to promote widespread adoption within the Stanford Medical School curriculum and departments. These tools include Slide Show, Export to PowerPoint, Teaching File, and e-Books. With the exception of e-Books, these tools use web-based wizards to lead the user through the steps for creating each component.Slide Shows consist of an ordered set of images and provide the underpinning data structures for PowerPoint and Teaching File creation. Slide Shows can be assembled from any accessible media in the MediaServer and shared with other users of the system.Export to PowerPoint is a utility function to address the widespread use of PowerPoint in medical education and multimedia presentation. It allows Slide Shows to be converted to PowerPoint and downloaded to the client system for offline use, easing the process of assembling media and creating a PowerPoint document. This function leverages XML Web Services and the SOAP protocol to achieve the desired outputs.Teaching Files are used to illustrate a particular educational topic, and consist of a multi-page interface. Each page contains media and annotations specific to the educational topic at hand. Annotations are stored with the Teaching File and not with the collated media. Individual pages are assembled by choosing existing Slide Shows and further annotating the media.E-Books are web-based books built on a particular design template provided by the MediaServer. Authors can integrate media from the MediaServer into these e-Books, which are assembled through the use of 3rd party tools such as Macromedia Dreamweaver.MediaServer resources were deployed in a gross anatomy course through the use of these tools and integration with third party applications, including a three-dimensional stereo viewing system. This pilot project was well received by the course participants and evaluation of usage data is ongoing.These educational media tools must be further evaluated for their teaching efficacy. These tools will be evaluated with volunteer faculty contributing media and creating Slide Shows, PowerPoint documents, Teaching Files, and e-Books. These educational modules will then be used for medical school classes. Feedback will be integrated into further development of new educational tools, providing new views into the large Stanford MediaServer dataset.Access rights management and security is paramount for the protection of digital media. The existing MediaServer security system will be enhanced to address privacy concerns, while providing faculty the flexibility to appropriately create and share educational units with their students and colleagues. Standard APIs will also be created to allow third-party developers to access the media in the MediaServer and deliver it through their own web-based applications.This work was partially funded by gifts from the Yamazaki-Yang Family Foundation, the Siminoff Family Foundation, Sun Microsystems, and Silicon Graphics.

#index 614088
#* Processing and formatting system for digital collections
#@ Frances Webb
#t 2003
#c 14
#! This system is being used to build structure data for the HEARTH digital collection and to manage the collection under the DLXS system. It allows student workers or unskilled employees to build structure metadata from scanned images for both monographs and serials, and manages the process of delivering the titles under DLXS once prepared. It allows supervisors to manage the work, simplifying tasks like re-assigning the in-progress work of graduated students.

#index 614089
#* CMedPort: a cross-regional Chinese medical portal
#@ Yilu Zhou;Jialun Qin;Hsinchun Chen;Zan Huang;Yiwen Zhang;Wingyan Chung;Gang Wang
#t 2003
#c 14
#% 345119
#% 378481
#! CMedPort is a cross-regional Chinese medical Web portal developed in the AI Lab at the University of Arizona. We will demonstrate the major system functionalities.

#index 614090
#* V2V: a second variation on query-by-humming
#@ William P. Birmingham;Kevin O'Malley;Jon W. Dunn;Ryan Scherle
#t 2003
#c 14
#% 378499

#index 614091
#* A digital collections management system based on open source software
#@ Allison Zhang;Don Gourley
#t 2003
#c 14
#! Robust and flexible digital collections management and presentation software is essential for creating and delivering digital collections. But digital library technologies and contents are not static. Continual evolution and investment are required to maintain the digital library. Few commercial digital library products are comprehensive and extensible enough to support this evolution. Many of these systems are in early release and have not been used and tested widely. Some require an initial investment in license fees or staff time that we could not afford. None of the products covered the full range of functionality needed for our digital library.

#index 614092
#* Object-oriented modeling, import and query processing of digital documents
#@ Andre Zeitz;Ilvio Bruder
#t 2003
#c 14

#index 614093
#* Stanford encyclopedia of philosophy: a dynamic reference work
#@ Colin Allen;Uri Nodelman;Edward N. Zalta
#t 2003
#c 14

#index 614094
#* Digital library service integration
#@ Xin Chen;Dong-ho Kim;Nikechi Nnadi;Himanshu Shah;Prateek Shrivastava;Michael Bieber;Il Im;Yi-Fang Wu
#t 2003
#c 14

#index 614095
#* 5SGraph demo: a graphical modeling tool for digital libraries
#@ Qinwei Zhu;Marcos André Gonçalves;Edward A. Fox
#t 2003
#c 14
#% 205440
#% 262249
#% 378521
#! The current demand from non-experts who wish to build digital libraries is strong worldwide. However, since DLs are complex systems, it usually takes a huge amount of effort and time to create and tailor a digital library to satisfy specific needs and requirements of target communities/societies. What is desired is a simplified modeling process and rapid generation of digital libraries. To enable this, digital libraries should be modeled with descriptive domain-specific languages [1]. In a domain-specific modeling language, the models are made up of elements representing concepts, rules, and terminology that are part of the domain world, as opposed to the code world or generic modeling languages (e.g., UML [2]). A visual modeling tool would be helpful to non-experts so they may model a digital library without knowing the theoretical foundations and the syntactical details of the descriptive language.In this demonstration, we present a domain-specific visual modeling tool, 5SGraph, aimed at modeling digital libraries. 5SGraph is based on a metamodel that describes DLs using the 5S theory [3]. The output from 5SGraph is a digital library model that is an instance of the metamodel, expressed in the 5S description language (5SL) [4].5SGraph presents the metamodel in a structured toolbox, and provides a top-down visual building environment for designers (see Figure 1). The visual proximity of the metamodel and instance model facilitates requirements gathering and simplifies the modeling process. Furthermore, 5SGraph maintains semantic constraints specified by the 5S metamodel and enforces these constraints over the instance model to ensure semantic consistency and correctness. 5SGraph enables component reuse to reduce the time and efforts of designers. 5SGraph also is designed to be flexible and extensible, able to accommodate and integrate several other complementary tools (e.g., to model scenarios or complex digital objects), reflecting the interdisciplinary nature of digital libraries. The tool has been tested with real users and several modeling tasks in a usability experiment [5] and its usefulness and learnability have been demonstrated.

#index 614096
#* ICON (Innovation Curriculum Online Network): the national digital library for technological literacy
#@ Quentin M. Briggs
#t 2003
#c 14
#! The International Technology Education (ITEA), in partnership with the Eisenhower National Clearinghouse (ENC) and funded by the National Science Foundation has created a comprehensive digital library collection for K-12 technological literacy in an accessible virtual environment. ICON, or the Innovation Curriculum Online Network, is a central source for information dealing with technology and innovation.ICON serves as a national electronic roadmap to connect users, such as teachers, professors, students, museum staff, and parents with information about our human built and innovated world. Users may use the digital library to access resources ranked according to technological literacy content and pedagogy, interact with quality instructional resources, and to enhance online search capabilities relevant to the needs of the user population. The focused digital library contains online resources including websites, electronic files, information about professional organizations, government agencies, public and private foundations, and commercial enterprises. Identification and selection of these resources are in alignment with national standards, grade and age level appropriateness, sound instructional and disciplinary content, and current availability of and access to materials.ENC has built a robust electronic infrastructure to support: the development of relevant and appropriate metadata (in conjunction with other synergistic NSDL projects); the processing of records and abstracts; the development of value-added user interfaces; and the maintenance of computer services for optimum and continuous digital library operations. An advisory board is providing annual input into digital library development and identification of quality digital resources. Formal evaluation of the ICON project is being conducted by Horizon Research.Field testing of the collection and its services is being undertaken with diverse groups of users to evaluate ease of navigation and discovery of content-rich, pedagogically sound resources.A variety of methods of sustainability for the collection are being explored including public and/or private sponsorship and subscriber support. ICON was officially launched March 2003 (www.icontechlit.org) and presented in a special interest session on March 13, 2003 at the ITEA Conference in Nashville, Tennessee. Currently, ICON has established tools for simple search, advance search, and browse by technology concepts. The technology concepts are classified and based from the National Standards for Technological Literacy initially driven by the Technology for All Americans Project (http://www.iteawww.org/TAA/Listing.htm). Continuous user feedback will be monitored through a "contact us" link established to receive not only communications on problems with the digital library but to allow user questions and site evaluations. Users may also "Suggest a Resource" to ICON to be considered for inclusion in the collection.

#index 614097
#* NanoPort: an example for building knowledge portals for scientific domains
#@ Jialun Qin;Zan Huang;Yilu Zhou;Michael Chau;Chunju Tseng;Alan Yip;T. Gavin Ng;Fei Guo;Zhi-Kai Chen;Hsinchun Chen
#t 2003
#c 14
#% 295520
#! We describe the NanoPort (www.nanoport.org) system to demonstrate a general framework of building domain-specific knowledge portals. These portals consolidate diverse information resources and provide rich functionalities to support effective information retrieval and knowledge discovery.

#index 614098
#* EconPort: a digital library for Microeconomics education
#@ Hsinchun Chen;Daniel Zeng;Riyad Kalla;Zan Huang;James C. Cox;J. Todd Swarthout
#t 2003
#c 14
#! We present the EconPort system (www.econport.org), a digital library for Microeconomics education that incorporates experimental economics software and automated e-commerce agents

#index 614099
#* Displaying resources in context: using digital libraries to support changes in undergraduate education
#@ Cathryn A. Manduca;Sean Fox
#t 2003
#c 14
#! Education digital libraries strive to foster major improvements in education by supporting adoption of more effective teaching methods. We present initial efforts to assist faculty in changing teaching practice by displaying digital library resources in portals that address a specific educational issue and provide the full spectrum of resources needed to both motivate and implement a change in practice.

#index 614100
#* A proposal for digital library protection
#@ Hideyasu Sasaki;Yasushi Kiyoki
#t 2003
#c 14
#% 489592
#! We propose systematic digital library protection by patentable content-based retrieval processes, especially on image digital libraries in specified domains, without any excessively exclusive protection in general domains.

#index 614101
#* Content-based summarization for personal image library
#@ Joo-Hwee Lim;Jun Li;Philippe Mulhem;Qi Tian
#t 2003
#c 14
#! With the accumulation of consumer's personal image library, the problem of managing, browsing, querying and presenting photos effectively and efficiently would become critical. We propose a framework for automatic organization of personal image libraries based on analysis of image creation time stamps and image contents to facilitate browsing and summarization of images.

#index 614102
#* Modularization framework for digital museum exhibition
#@ Bai-Hsun Chen;Sheng-Hao Hung;Jen-Shin Hong
#t 2003
#c 14
#! Conventionally, digital museum online exhibitions are constructed using handcrafted HTML pages which require tedious hypermedia composing. This paper proposes a sophisticated modularization framework for exhibition website construction by integrating XML and Flash MX. A typical exhibition page is differentiated into several "layers" containing specific types of "media elements". Several categories of modularized Flash-based "mediah-andlers" are used to process and present the layers containing media elements. A complete set of media-handlers presenting the content are then integrated together to give the final page presentation. Based on this modularization framework, the workflow for exhibition construction and management are significant improved.

#index 614103
#* Sustainability issues and activities for the NSDL
#@ David J. McArthur;Sarah Giersch;Howard Burrows
#t 2003
#c 14
#% 391684
#! This poster will review the work on sustainability of digital libraries in the context of the NSF-supported National Science Digital Library (NSDL) program. Applied to digital libraries, sustainability is a broad term, referring to everything from technical issues about the digital preservation of materials, to the social questions surrounding the long-term accessibility of resources to the public at large.

#index 614104
#* Contribution and collaboration strategies for the National Science Digital Library (nsdl.org): investigating technological solutions to facilitate social evolution of a collaborative infrastructure
#@ Elly Cramer;Dean Krafft;Diane Hillmann;John Saylor;Carol Terrizzi
#t 2003
#c 14
#! The NSDL community consists of large, discipline diverse, and decentralized user groups made up of collaborator communities who create, aggregate, and contribute digital resources to the NSDL. NSDL Core Integration provides "wholesale" services to NSDL collaborator communities who may "retail" those services through their own portals, perhaps packaged with additional content selected to meet their specialized users' needs. NSDL "wholesale" services will support rich representations of complex data relation-ships. NSDL will distribute access to aggregations and annotations stored in the NSDL metadata repository that have been harvested, normalized (based on the scaleable library production model in use at nsdl.org), and exposed for re-harvest. "Retailers" may use the Open Archives Initiative (OAI) for Metadata Harvesting Protocol to harvest these structured data relationships and make them available for use in other library services.

#index 614105
#* FLOW: co-constructing low barrier repository infrastructure in support of heterogeneous knowledge collection(s)
#@ Karen S. Baker;Anna K. Gold;Frank Sudholt
#t 2003
#c 14
#% 378529
#! Institutional repositories are being constructed today to address the needs of scholarly communication in a digital environment [1, 2]. The success of such institutional infrastructures as knowledge collections depends in part on offering low barriers for participation and on supporting heterogeneous knowledge inputs and outputs. The San Diego Supercomputer Center (SDSC) in partnership with CERN (European Center for Nuclear Research), the Scripps Institution of Oceanography (SIO), and the University of California, San Diego (UCSD) Science & Engineering Library, has modified CERN's CDSware software to initiate the process of creating a local low barrier repository.

#index 614106
#* MetaTest: evaluation of metadata from generation to use
#@ Elizabeth D. Liddy;Eileen E. Allen;Christina M. Finneran;Geri Gay;Helene Hembrooke;Laura A. Granka
#t 2003
#c 14

#index 614107
#* Finding and using data in educational digital libraries
#@ Rajul Pandya;Ben Domenico;Mary Marlino
#t 2003
#c 14
#! THREDDS (THematic Real-time Earth Distributed Data Servers) services catalog geophysical data and other data services to support discovery and use by researchers. THREDDS, however, doesn't support data discovery and use by learners and educators (i.e. novices). Educational digital libraries, like DLESE (Digital Library for Earth System Eduation) provide rich metadata descriptions that are effective in helping novices locate and use most types of learning resources. DLESE, however, doesn't provide a way for novices to discover geophysical data in immediately usable forms. The VGEE (Visual Geophysical Exploration Environment) supports novices' discovery and use of geophysical data by linking THREDDS services with educational curricula and learner-centered data tools. The curricula are cataloged in DLESE and so can be discovered in educational settings. These curricula then guide novices to the appropriate tools and illustrate meaningful use of the data. More generally, by coupling data to curricular documents, text-based discovery tools (e.g. search engines) can be extended to data.

#index 614108
#* An XQuery engine for digital library systems
#@ Ji-Hoon Kang;Chul-Soo Kim;Eun-Jeong Ko
#t 2003
#c 14
#! XML is now a standard markup language for web information. Many application areas are producing XML documents on the web. This situation urges digital library systems to deal with not only typical text documents but also XML documents. XML documents are semi-structured. Some queries based on the structures are useful and necessary.MPEG-7 is a metadata standard for multimedia objects. MPEG-7 metadata can describe some features such as color histogram of image, so that a multimedia digital library system using MPEG-7 for metadata representation can provide content-based search for multimedia objects. MPEG-7 is defined by XML schema. In order to retrieve MPEG-7 metadata, a query language for XML data is required.A standard query language is very helpful for interoperability among digital library systems over the Internet. XQuery, which has been influenced from most of the previous XML query languages, is a forthcoming standard for querying XML data.In this paper we propose an XQuery Engine as depicted in the figure that can be used as an XQuery processing module in a digital library system that supports XML documents. We assume generic digital library system architecture. It consists of four modules: a user interface, an XQuery Engine, an Information retrieval Engine, and an XML Repository. The user interface module gives a user an easy way to search XML documents and transforms a given user query to an equivalent XQuery. The XQuery Engine module takes an XQuery as input and provides a query plan for an information retrieval module as output. The information retrieval engine executes a query plan by communicating with the XML repository, which stores XML documents.The XQuery Engine parses an input XQuery and constructs a syntax tree for the query. Then, it transforms the syntax tree into a query plan, called a Primitive Operation Tree (POT). Each node of a POT represents an atomic operation in terms of the information retrieval engine and can be interpreted and processed by the information retrieval engine. The result set is given back to the XQuery engine, which in turn transforms the result into an XML document of the form being required by the user interface. The final result in XML is returned back to the user interface.Our approach has the following useful aspects. First, any user interface that generates XQuery is able to access any digital library system including our XQuery Engine. Second, we define a set of primitive operations for POTs so that they can become a standard interface between an XQuery Engine and an Information Retrieval Engine for our generic digital library system that supports XML documents. Third, some query optimizations over POTs can be done in the XQuery Engine so that better searching performance is expected.Currently we are developing an XQuery Engine prototype. It will be installed inside an MPEG-7 based Digital Library System that supports content-based searching for images. The XQuery Specification is an ongoing working draft and is not completed yet. Since the current version of the XQuery specification does not define full functions for information retrieval, we need to extend XQuery syntax by adding some functions such as rankby().

#index 614109
#* CephSchool: a pedagogic portal for teaching biological principles with cephalopod molluscs
#@ James B. Wood;Caitlin M. H. Shaw
#t 2003
#c 14

#index 614110
#* VIVO: a Video Indexing and Visualization Organizer
#@ Meng Yang;Xiangming Mu;Gary Marchionini
#t 2003
#c 14

#index 614111
#* The roadies take the stage: on-going development and maintenance of the legacy tobacco documents library at the University of California San Francisco
#@ Heidi Schmidt
#t 2003
#c 14

#index 614112
#* BiosCi Education Network (BEN) collaborative
#@ Linda Akli;Cal T. Collins;Jason Smith;Ron Butler;Amy Chang;Yolanda George;Nancy Gough;Melinda Lowy;Marsha Matyas;Brandon Muramatsu;Susan Musante;Jason Taylor
#t 2003
#c 14

#index 614113
#* Palau Community College-Belau National Museum image archives digitization and access project
#@ Imengel Mad
#t 2003
#c 14
#! This poster presentation will describe a collaboration project between the Palau Community College (PCC) Library and the Belau National Museum (BNM). The project, funded by a two-year U.S. Institute of Museum and Library Services (IMLS) National Leadership Grant, will enhance access to the BNM Media Collection. The Media Collection is in great demand, and the pressures of human use exacerbate an already tenuous situation for the long-term preservation of the images. While digitization is not viewed as the preservation solution, it will assist the Museum to lessen the impact of human handling. By making the Media Collection more accessible through integration of the PCC Library's online catalog, a much wider audience will be reached, and mishandling of the original images will be significantly reduced.The PCC website, currently under final development will link the Library WebCollection Plus which will contain digitized images selected from the extensive photo archives, as well as digitized images of the ethnographic and other objects in the Museum's collection, including contemporary art. This poster session will enable viewers to see the range of images included in the project.This poster presentation will enable researchers to learn how this project will support scholarly research.

#index 614114
#* Steps towards establishing shared evaluation goals and procedures in the National Science Digital Library
#@ Tamara Sumner;Sarah Giersch;Casey Jones
#t 2003
#c 14
#! A community-based process was used to develope shared evaluation goals and instruments to begin evaluating the National Science Digital Library (NSDL). Results from a pilot study examining library usage, collections growth, and library governance processes are reported. The methods used in the pilot included web log usage analysis, collections assessment techniques, survey instruments, and semi-structured interviews.

#index 614115
#* A comparison of two educational resource discovery systems
#@ Tamara Sumner;Sonal Bhushan;Faisal Ahmad;Lynne Davis
#t 2003
#c 14
#% 280851
#! We describe the results from a pilot study that compared two different discovery systems designed and built to operate in the same educational digital library -- one based on searching over metadata records and another hybrid system which combined metadata and content-based indexing.

#index 614116
#* Collections and access policies of the digital material of ten national libraries
#@ Alexandros Koulouris;Sarantos Kapidakis
#t 2003
#c 14

#index 614117
#* Cross-cultural usability for digital libraries
#@ Nadia Caidi;Anita Komlodi
#t 2003
#c 14
#% 378515
#! The scope and reach of digital libraries (DL) is truly global, spanning geographical and cultural boundaries, yet few scholars have investigated the influence of culture as it pertains to the design and use of digital libraries. This workshop will examine cross-cultural issues around the use and development of DLs, especially as they relate to supporting cross-cultural usability of DLs.

#index 614118
#* International workshop on Information Visualization Interfaces for Retrieval and Analysis (IVIRA) at the Joint Conference on Digital Libraries 2003
#@ Javed Mostafa;Katy Börner
#t 2003
#c 14
#! The IVIRA workshop has been organized to attract cutting-edge efforts that concentrate on improving information retrieval and analysis by applying visualization techniques in interface design.

#index 614119
#* Building a meaningful Web: from traditional knowledge organization systems to new semantic tools
#@ Gail M. Hodge;Marcia Lei Zeng;Dagobert Soergel
#t 2003
#c 14
#! This Networked Knowledge Organization Systems/Services (NKOS) workshop focused on the transformation of traditional knowledge organization systems (KOSs) to new forms of knowledge representation that are being developed to support a more semantic-based, meaningful Web environment. The goal of the workshop was to identify principles from more traditional practices that can contribute to the design of new knowledge organization systems and ways to exploit the extensive intellectual capital available in traditional KOSs when developing new KOS tools.Traditional KOSs include a broad range of system types from term lists to classification systems and complex thesauri. Term lists may be simple authority lists. Classification systems put resources in broad groups or "buckets". Traditional thesauri are built on broader-narrower, synonymous and associative (or related term) relationships. These and other traditional KOSs were developed in a print environment or in the early days of computerized databases to control the vocabulary used when indexing and searching a specific product, such as a bibliographic database, or when organizing a physical collection such as a library.New forms of knowledge representation include ontologies, topic maps, and other semantic Web components. The relationships between concepts in these tools are richer. In particular, the associative relationships and broader-narrower relationships are defined in more detail. New semantic tools emphasize the ability of the computer to process the KOS against a body of text, rather than support the human indexer or trained searcher. These tools are intended for use in the broader, more uncontrolled context of the Web to support information discovery by a larger community of interest or by Web users in general.While the traditional KOSs and newer tools are related, the development of the newer forms of KOS tools has, on the whole, not taken advantage of traditional KOSs. There is little understanding of how traditional tools can be transformed for the demands of the Web environment and whether there are lessons that can be learned from the decades of development and maintenance of these traditional systems.This workshop compared the traditional KOSs and new approaches to improving the semantic capabilities of the Web. Best practices and lessons learned from the development, maintenance and use of traditional KOSs were identified. Descriptions of projects involving the transformation of traditional KOSs to newer forms emphasized the transition process, including the analysis of the traditional KOS, and the characteristics of the KOS that could be carried through to the new tool. The presenters also discussed the degree to which the traditional KOS and the new tool would be used together in the future, whether there would be parallel or separate maintenance activities, etc.Presenters described the development of specific Web service functionality applicable to KOSs. The benefits of this service-based approach and the possibility of universal or community-based KOS services were explored.In addition to formal presentations, the workshop participants gave brief updates on their work or interest in this area. A facilitated discussion identified areas where standards, best practices, technologies, or more research are needed to take advantage of the investment in traditional KOSs when developing new tools.NKOS is an ad hoc group devoted to the discussion of KOSs as networked interactive information services to support the description and retrieval of diverse information resources through the Internet. This is the 6th in a series of NKOS workshops held in conjunction with JCDL. More information about NKOS is available from http://nkos.slis.kent.edu/.

#index 614120
#* OAI metadata harvesting workshop
#@ Simeon Warner
#t 2003
#c 14
#! This workshop will bring together people with Open Archives Initiative (OAI) [1] metadata harvesting experience to discuss problems, their solutions, and to identify best practices. The focus will be on near-to medium-term practical issues. Participants will have the opportunity to discuss problems or raise issues that they have encountered and will benefit from the shared experience of the other participants. The workshop will combine and distill the OAI harvesting knowledge and experience of the participants to detail 1) best practices and existing solutions to particular harvesting problems; and 2) unresolved problems and issues with current implementations, the specification, or limitations of version 2.0 the OAI protocol for metadata harvesting (OAI-PMH) [2]. The conclusions of the workshop will be disseminated to the wider OAI community.

#index 760813
#* Proceedings of the 4th ACM/IEEE-CS joint conference on Digital libraries
#@ Hsinchun Chen;Howard Wactlar;Ching-chih Chen;Ee-Peng Lim;Mike Christel
#t 2004
#c 14
#! Welcome to JCDL 2004! This is the fourth in a series of IEEE-CS/ACM joint conferences on digital library research and development. "Global reach" and "diverse impact" are the two themes of this year's international forum focusing on digital libraries and the associated technical, practical, theoretical and social issues.This year's conference boasts a record number of 249 submissions and will present papers, posters, and demonstrations from Australia, Brazil, Canada, China and Taiwan, Japan, the Netherlands, New Zealand, Portugal, the United Kingdom, and the United States. From 114 full papers and 90 short papers, the Program Committee selected 34 full and 27 short papers for presentation; these papers have been revised with input from the panel of reviewers and are included in the proceedings. As in previous years, the prestigious Vannevar Bush Best Paper Award will be presented by the Program Committee in honor of Dr. Bush, the founder of the National Science Foundation who developed the idea of the "Memex," an early conceptualization of a scholar's workstation and data store. JCDL 2004 is host to three other awards as well:oIEEE-CS Technical Committee on Digital Libraries, Best Student Paper Award for the JCDL 2004 Conference, oBest International Paper Award, to be presented by the University of Arizona, oBest Poster Award, to be presented by the University of Arizon.In addition to the full and short papers, the conference presentations will include 15 demonstrations, 35 posters and 4 panels, which explore an especially broad selection of topics. The tutorials and workshops also add an important dimension for many conference participants and provide in-depth treatment of emerging and relevant topics. The program's keynote addresses, by Vint Cerf and Joel Birnbaum, provide conference participants with further intellectual stimulation. This year, a closing panel discussion entitled "Digital Libraries Settling the Score: 10 Years Hence and 10 Years Before," by acknowledged experts in the field, will examine future funding options and set the stage for further dialogue and research.The purpose of JCDL is to provide a forum where researcher and practitioner alike may learn about novel and important developments, exchange ideas, and discover something new, whether in computer science, librarianship, or the social sciences. We hope that these proceedings will further extend the spread of ideas presented at the conference and provide a true "global reach."

#index 760814
#* Taking internet's temperature: prescriptions for the 21st century
#@ Vint Cerf
#t 2004
#c 14
#! This talk will discuss the current state of the Internet, near term projections, the importance of security and privacy on the Internet especially for health care applications, the impact of RFID, and the effect of Internet--enabling everything ("at home, in your car, in the operating room, in the office, and all the stuff you hang on your body").

#index 760815
#* Cybersecurity considerations for digital libraries in an era of pervasive computing
#@ Joel Birnbaum
#t 2004
#c 14
#! Information technology is becoming pervasive in our society; soon, its absence will be more noticeable than its presence, and for most people it will be an unavoidable part of everyday life. This talk will trace this evolution to the present day and make projections to an era later this decade when the prevailing system architecture may consist of information utilities accessed intuitively through a wide variety of specialized information appliances, many of them mobile. Principal among the challenges still impeding this emerging popular view of the future are the reliability and security of such global systems.Digital libraries, already playing an essential role in today's information-rich world, will assume central positions of even more significance in such pervasive systems Not only will they serve as repositories of knowledge and information, and as the primary mechanism for its retrieval and distribution, but they will be the focal point for the integration of information and scholarship across all boundaries of application, language, and media Since they will also inevitably become the target of malicious attack by people seeking unauthorized information, and by terrorists seeking to disrupt the global information infrastructure and the physical infrastructures built upon it, it is both timely and essential to study the cybersecurity characteristics future digital libraries will have to support.

#index 760816
#* Architecting an extensible digital repository
#@ Anoop Kumar;Ranjani Saigal;Robert Chavez;Nikolai Schwertner
#t 2004
#c 14
#% 337507
#% 614039
#! The Digital Collection and Archives (DCA) in partnership with Academic Technology (AT) at Tufts University developed a digital library solution for long-term storage and integration of existing digital collections, such as Perseus, TUSK, Bolles and Artifact. In this paper, we describe the Tufts Digital Library (TDL) architecture TDL is an extensible, modular, flexible and scalable architecture that uses Fedora at its core. The extensible nature of the TDL architecture allows for seamless integration of collections that may be developed in the future, while leveraging the extensive tools that are available as part of individual digital library applications at Tufts. We describe the functionality and implementation details of the individual components of TDL. Two applications that have successfully interfaced with TDL are presented. We conclude with some remarks about the future development of TDL.

#index 760817
#* The multi-faceted use of the OAI-PMH in the lanl repository
#@ Henry N. Jerez;Xiaoming Liu;Patrick Hochstenbach;Herbert Van de Sompel
#t 2004
#c 14
#% 268079
#! This paper focuses on the multifaceted use of the OAI-PMH in a repository architecture designed to store digital assets at the Research Library of the Los Alamos National Laboratory (LANL), and to make the stored assets available in a uniform way to various downstream applications. In the architecture, the MPEG-21 Digital Item Declaration Language is used as the XML-based format to represent complex digital objects. Upon ingestion, these objects are stored in a multitude of autonomous OAI-PMH repositories An OAI--PMH compliant Repository Index keeps track of the creation and location of all those repositories, whereas an Identifier Resolver keeps track of the location of individual objects. An OAI-PMH Federator is introduced as a single-point-of-access to downstream harvesters. It hides the complexity of the environment to those harvesters, and allows them to obtain transformations of stored objects While the proposed architecture is described in the context of the LANL library, the paper will also touch on its more general applicability.

#index 760818
#* BND: the architecture of a national digital library
#@ José Borbinha;Nuno Freire;João Neves
#t 2004
#c 14
#! This paper describes the architecture and components of the infrastructure in construction for the National Digital Library in Portugal. The requirements emerged from the definition of the services to support, with a special focus on scalability, and from the decision to give a special attention to community building standards, open solutions, and reusable and cost effective components. The generic bibliographic metadata format in this project is UNIMARC, and the structural metadata is METS. The URN identifiers are processed and resolved as simple but very effective PURL identifiers. The storage for immediate access is provided by the LUSTRE file system, and by ARCO, a locally developed GRID architecture, for long term preservation All these components run on Linux servers, as also the middleware for access based in the FEDORA framework.

#index 760819
#* BDBComp: building a digital library for the Brazilian computer science community
#@ Alberto H. F. Laender;Marcos André Gonçalves;Pablo A. Roberto
#t 2004
#c 14
#% 503213
#% 614081
#% 716459
#% 729887
#% 750866
#! This paper reports initial efforts towards building BDBComp, a digital library for the Brazilian computer science community BDBComp is based on a number of standards (e.g., OAI, Dublin Core, SQL) as well as on new technologies (e.g., Web data extraction tools), which allowed fast and easy prototyping. The paper focuses on architectural issues and specific challenges faced during the construction of this digital library as well as on proposed solutions.

#index 760820
#* Integration of biomedical text and sequence OAI repositories
#@ Yueyu Fu;Javed Mostafa
#t 2004
#c 14
#! Archived biomedical literature and sequence data are growing rapidly. The Open Archives Initiative's Protocol for Metadata Harvesting (OAI-PMH) [1]. provides a convenient way for data sharing But it has not been tested in the biomedical domain, especially in dealing with different types of data, such as protein, and gene sequences. We built four individual OAI--PMH repositories based on different biomedical resources. Using the harvested data from the four repositories we created an integrated OAI-PMH repository, which hosts the linked literature and sequence data in a single place.

#index 760821
#* Analytical usability evaluation for digital libraries: a case study
#@ Ann Blandford;Suzette Keith;Iain Connell;Helen Edwards
#t 2004
#c 14
#% 131456
#% 170383
#% 170388
#% 249146
#% 280060
#% 297586
#% 301982
#% 337261
#% 378515
#% 378608
#% 387027
#% 450039
#% 508269
#% 590535
#! There are two main kinds of approach to considering usability of any system: empirical and analytical. Empirical techniques involve testing systems with users, whereas analytical techniques involve usability personnel assessing systems using established theories and methods. We report here on a set of studies in which four different techniques were applied to various digital libraries, focusing on the strengths, limitations and scope of each approach. Two of the techniques, Heuristic Evaluation and Cognitive Walkthrough, were applied in text-book fashion, because there was no obvious way to contextualize them to the Digital Libraries (DL) domain. For the third, Claims Analysis, it was possible to develop a set of re-usable scenarios and personas that relate the approach specifically to DL development. The fourth technique, CASSM, relates explicitly to the DL domain by combining empirical data with an analytical approach. We have found that Heuristic Evaluation and Cognitive Walkthrough only address superficial aspects of interface design (but are good for that), whereas Claims Analysis and CASSM can help identify deeper conceptual difficulties (but demand greater skill of the analyst). However, none fit seamlessly with existing digital library development practices, highlighting an important area for further work to support improved usability.

#index 760822
#* Developing a digital learning environment: an evaluation of design and implementation processes
#@ Leslie Champeny;Christine L. Borgman;Gregory H. Leazer;Anne J. Gilliland-Swetland;Kelli A. Millwood;Leonard D'Avolio;Jason R. Finley;Laura J. Smart;Patricia D. Mautone;Richard E. Mayer;Richard A. Johnson
#t 2004
#c 14
#% 294888
#% 332733
#% 337177
#% 351983
#% 378545
#% 388392
#% 614048
#% 643824
#% 729422
#% 739905
#% 804812
#! The Alexandria Digital Earth Prototype (ADEPT) Project (1999--2004) builds upon the Alexandria Digital Library Project (1994--1999) to add functions and services for undergraduate teaching to a digital library of geospatial resources. The 'Digital Learning Environment' (DLE) services are being developed and evaluated iteratively over the course of this research project. In the 2002--2003 academic year, the DLE was implemented during the fall and spring terms in undergraduate geography courses at the University of California, Santa Barbara (UCSB). Evaluation of the fall term implementation identified design issues of time and complexity for creating and organizing course domain knowledge. The spring term implementation added new services to integrate course content into class presentation formats. The implementation was evaluated via interviews with the course instructor, development staff, and students, and by observations (in person and videotaped) of the course. Results indicated that usability and functionality for the instructor had increased between the two course offerings Students found classroom presentations to be useful for understanding concepts, and Web access to the presentations useful for study and review. Assessments of student learning suggest modest improvements over time Developers are now applying lessons learned during these implementations to improve the system for subsequent implementation in the 2003--2004 academic year.

#index 760823
#* How people describe their image information needs: a grounded theory analysis of visual arts queries
#@ Sally Jo Cunningham;David Bainbridge;Masood Masoodian
#t 2004
#c 14
#% 329434
#% 580076
#! When people are looking for visual arts information-information related to images-how do they characterize their needs? We analyze a set of 404 queries to identify the attributes that people provide to the Google Answers™ 'ask an expert' online reference system. The results suggest directions to take in developing an effective organization and features for an image digital library.

#index 760824
#* Improving video browsing with an eye-tracking evaluation of feature-based color bars
#@ Neema Moraveji
#t 2004
#c 14
#% 571360
#% 614060
#% 1389561
#! This paper explains a method for leveraging the standard video time line widget as an interactive visualization of image features. An eye-tracking experiment is described with results that indicate that such a widget increases task efficiency without increasing complexity while being easily learned by experiment participants .

#index 760825
#* Measuring the user's experience with digital libraries
#@ Elaine G. Toms;Christine Dufour;Susan Hesemeier
#t 2004
#c 14
#% 246771
#% 283550
#% 307264
#! In this paper, we propose a method for assessing user experience. Normally evaluation is based on usability or on the efficiency of or effectiveness of focused information search tasks. Yet all experiences with libraries (whether physical or virtual) need not be for the explicit purpose of finding, acquiring and using information. The experience and its playfulness and pleasure have equal value. To assess this experience, we modified a experiential value scale developed for online shopping and have tested it in the context of culture and heritage websites.

#index 760826
#* Automatic organization for digital photographs with geographic coordinates
#@ Mor Naaman;Yee Jiun Song;Andreas Paepcke;Hector Garcia-Molina
#t 2004
#c 14
#% 278106
#% 378541
#% 397186
#% 415112
#% 448786
#% 451127
#% 452641
#% 452642
#% 641934
#% 730144
#% 730188
#% 760870
#! We describe PhotoCompas, a system that utilizes the time and location information embedded in digital photographs to automatically organize a personal photo collection PhotoCompas produces browseable location and event hierarchies for the collection. These hierarchies are created using algorithms that interleave time and location to produce an organization that mimics the way people think about their photo collections. In addition, our algorithm annotates the generated hierarchy with geographical names. We tested our approach in case studies of three real--world collections and verified that the results are meaningful and useful for the collection owners.

#index 760827
#* Digital trail libraries
#@ Scott Morris;Alan Morris;Kobus Barnard
#t 2004
#c 14
#% 337481
#! We propose the idea of an online, user submitted digital library of recreation trails. Digital libraries of trails offer advantages over paper guidebooks in that they are more accurate, dynamic and not limited to the experience of the author(s). The basic representation of a trail is a GPS track log, recorded as recreators travel on trails. As users complete trips, the GPS track logs of their trips are submitted to the central library voluntarily. A major problem is that track logs will overlap and intersect each other. We present a method for the combination of overlapping and intersecting GPS track logs to create a network of GPS trails. Each trail segment in the network can then be characterized by automatic and manual means, producing a digital library of trails. We also describe the TopoFusion system which creates, manages and visualizes GPS data, including GPS networks.

#index 760828
#* A query interface for an event gazetteer
#@ Robert B. Allen
#t 2004
#c 14
#% 214715
#% 246003
#% 287210
#% 301212
#% 725502
#! We introduce an event gazetteer which stores and presents "locations in time". Each event is coded with attributes of event type, location, actor, and beginning and ending times. Events can also contain sets of other events. This paper reports the development of an interface for generating searches to these "part-of" relationships. For instance, we can search for all named Battles in the event database which occurred during the Civil War. Ultimately, we envision a flexible, broad-based service that is a resource for users ranging from students to genealogists and researchers interested in historical events.

#index 760829
#* Accessing the alexandria digital library from geographic information systems
#@ D. Ancona;J. Frew;G. Janée;D. Valentine
#t 2004
#c 14
#% 240327
#% 378545
#% 467761
#% 467889
#% 614068
#! We describe two experimental desktop library clients that offer improved access to geospatial data via the Alexandria Digital Library (ADL): ArcADL, an extension to ESRI's ArcView GIS, and vtADL, an extension to the Virtual Terrain Project's Enviro terrain visualization package ArcADL provides a simplified user interface to ADL's powerful underlying distributed geospatial search technology. Both clients use the ADL Access Framework to access library data that is available in multiple formats and retrievable by multiple methods Issues common to both clients and future scenarios are also considered.

#index 760830
#* ETANA-DL: a digital library for integrated handling of heterogeneous archaeological data
#@ Unni Ravindranathan;Rao Shen;Marcos André Gonçalves;Weiguo Fan;Edward A. Fox;James W. Flanagan
#t 2004
#c 14
#% 716459
#% 750866
#! Archaeologists have to deal with vast quantities of information, generated both in the field and laboratory. That information is heterogeneous in nature, and different projects have their own systems to store and use it. This adds to the challenges regarding collaborative research between such projects as well as information retrieval for other more general purposes. This paper describes our approach towards creating ETANA--DL, a digital library (DL) to help manage these vast quantities of information and to provide various kinds of services. The 5S framework for modeling a DL gives us an edge in understanding this vast and complex information space, as well as in designing and prototyping a DL to satisfy information needs of archaeologists and other user communities.

#index 760831
#* Realistic books: a bizarre homage to an obsolete medium?
#@ Yi-Chun Chu;David Bainbridge;Matt Jones;Ian H. Witten
#t 2004
#c 14
#% 127574
#% 201992
#% 214669
#% 249158
#% 303395
#% 325182
#% 341590
#% 378526
#% 446865
#% 607792
#% 614056
#% 645984
#! For many readers, handling a physical book is an enjoyably exquisite part of the information seeking process. Many physical characteristics of a book-its size, heft, the patina of use on its pages and so on-communicate ambient qualities of the document it represents. In contrast, the experience of accessing and exploring digital library documents is often dull. The emphasis is utilitarian; technophile rather than bibliophile. We have extended the page-turning algorithm we reported at last year's JCDL into a scaleable, systematic approach that allows users to view and interact with realistic visualizations of any textual-based document in a Greenstone collection. Here, we further motivate the approach, illustrate the system in use, discuss the system architecture and present a user evaluation Our work leads us to believe that far from being a whimsical gimmick, physical book models can usefully complement conventional document viewers and increase the perceived value of a digital library system.

#index 760832
#* A document corpus browser for in-depth reading
#@ Eric Bier;Lance Good;Kris Popat;Alan Newberger
#t 2004
#c 14
#% 127574
#% 149109
#% 173738
#% 218990
#% 232679
#% 237319
#% 249143
#% 259946
#% 297551
#% 301234
#% 301236
#% 337225
#% 337231
#% 342442
#% 343769
#% 415107
#% 641118
#% 642983
#% 731013
#! Software tools, including Web browsers, e-books, electronic document formats, search engines, and digital libraries are changing the way people read, making it easier for them to find and view documents. However, while these tools provide significant help with short-term reading projects involving small numbers of documents, they provide less help with longer-term reading projects, in which a topic is to be understood in depth by reading many documents. For such projects, readers must find and manage many documents and citations, remember what has been read, and prioritize what to read next. This paper describes three integrated software tools that facilitate in-depth reading. A first tool extracts citation information from documents. A second finds on-line documents from their citations. The last is a document corpus browser that uses a zoomable user interface to show a corpus at multiple granularities while supporting reading tasks that take days, weeks, or longer. We describe these tools and the design principles that motivated them.

#index 760833
#* The virtual and the real: panel on current research on museum audiences and library users
#@ Howard Besser;Liz Bishoff;Kati Geber;Jose-Marie Griffiths;Joyce Ray
#t 2004
#c 14
#! This panel will discuss current research on museum audiences and library users in both the physical and digital environments Do online resources enhance or inhibit museum visits? Will physical libraries continue to have value? To what extent do museum audiences and library users merge in the online environment? Will online users want "virtual experiences" or "digital libraries"? What opportunities for lifelong learning are provided by non-traditional library and museum dissemination technologies, such as broadband, gaming environments, and public broadcasting? Panelists will discuss a variety of recently completed and in-progress studies with implications for digital library development and learning applications.

#index 760834
#* The effectiveness of automatically structured queries in digital libraries
#@ Marcos André Gonçalves;Edward A. Fox;Aaron Krowne;Pável Calado;Alberto H. F. Laender;Altigran S. da Silva;Berthier Ribeiro-Neto
#t 2004
#c 14
#% 44876
#% 83269
#% 86371
#% 109190
#% 144007
#% 169729
#% 219047
#% 219048
#% 232679
#% 237053
#% 237305
#% 237319
#% 249136
#% 260001
#% 262069
#% 262084
#% 262097
#% 262102
#% 309104
#% 309726
#% 340911
#% 340914
#% 342709
#% 345712
#% 387427
#% 406493
#% 413551
#% 479782
#% 504581
#% 659990
#% 726741
#% 730061
#% 740768
#% 764560
#% 1650570
#! Structured or fielded metadata is the basis for many digital library services, including searching and browsing. Yet, little is known about the impact of using structure on the effectiveness of such services. In this paper, we investigate a key research question: do structured queries improve effectiveness in DL searching? To answer this question, we empirically compared the use of unstructured queries to the use of structured queries. We then tested the capability of a simple Bayesian network system, built on top of a DL retrieval engine, to infer the best structured queries from the keywords entered by the user. Experiments performed with 20 subjects working with a DL containing a large collection of computer science literature clearly indicate that structured queries, either manually constructed or automatically generated, perform better than their unstructured counterparts, in the majority of cases. Also, automatic structuring of queries appears to be an effectiveand viable alternative to manual structuring that may significantly reduce the burden on users.

#index 760835
#* Translating unknown cross-lingual queries in digital libraries using a web-based approach
#@ Jenq-Haur Wang;Jei-Wen Teng;Pu-Jen Cheng;Wen-Hsiang Lu;Lee-Feng Chien
#t 2004
#c 14
#% 93113
#% 99650
#% 115467
#% 211043
#% 232650
#% 280826
#% 288578
#% 316880
#% 378507
#% 397145
#% 400061
#% 740901
#% 747947
#% 750865
#% 786574
#! Users' cross-lingual queries to a digital library system might be short and not included in a common translation dictionary (unknown terms). In this paper, we investigate the feasibility of exploiting the Web as the corpus source to translate unknown query terms for cross-language information retrieval (CLIR) in digital libraries. We propose a Web-based term translation approach to determine effective translations for unknown query terms by mining bilingual search-result pages obtained from a real Web search engine. This approach can enhance the construction of a domain-specific bilingual lexicon and benefit CLIR services in a digital library that only has monolingual document collections Very promising results have been obtained in generating effective translation equivalents for many unknown terms, including proper nouns, technical terms and Web query terms.

#index 760836
#* Digital restoration using volumetric scanning
#@ W. B. Seales;Yun Lin
#t 2004
#c 14
#% 80318
#% 252785
#% 301220
#% 311061
#% 336441
#% 336456
#% 337510
#% 625119
#! In this paper we present a new, nondestructive method for revealing inaccessible text buried within damaged books and scrolls. The method is based on volumetric scanning followed by data modeling and physically-based simulation. We show by experiment that it is possible to recover readable text from objects without physically opening or damaging them. In handling damaged collections, conservators often face a choice between two frustrating alternatives: indefinite preservation without analysis, or irreversible physical harm for the sake of potential discovery. We believe that this work creates a new opportunity that embraces both the need to preserve and the possibility for complete analysis.

#index 760837
#* The 3D vase museum: a new approach to context in a digital library
#@ Horn-yeu Shiaw;Robert J. K. Jacob;Gregory R. Crane
#t 2004
#c 14
#% 112673
#% 115181
#% 202036
#% 254101
#% 270633
#% 358412
#% 595981
#% 641120
#% 641151
#% 746328
#% 856142
#! We present a new approach to displaying and browsing a digital library collection, a set of Greek vases in the Perseus digital library. Our design takes advantage of three-dimensional graphics to preserve context even while the user focuses in on a single item. In a typical digital library user interface, a user can either get an overview for context or else see a single selected item, sacrificing the context view. In our 3D Vase Museum, the user can navigate seamlessly from a high level scatterplot-like plan view to a perspective overview of a subset of the collection, to a view of an individual item, to retrieval of data associated with that item, all within the same virtual room and without any mode change or special command. We present this as an example of a solution to the problem of focus-plus-context in information visualization. We developed 3D models from the 2D photographs in the collection and placed them in our 3D virtual room. We evaluated our approach by comparing it to the conventional interface in Perseus using tasks drawn from archaeology courses and found a clear improvement Subjects who used our 3D Vase Museum performed the tasks 33% better and did so nearly three times faster.

#index 760838
#* Building domain-specific web collections for scientific digital libraries: a meta-search enhanced focused crawling method
#@ Jialun Qin;Yilu Zhou;Michael Chau
#t 2004
#c 14
#% 55490
#% 161754
#% 249110
#% 249208
#% 268079
#% 275776
#% 281209
#% 281214
#% 281251
#% 282905
#% 310514
#% 338816
#% 343768
#% 378520
#% 378557
#% 479969
#% 508272
#% 578242
#% 979688
#% 1394202
#! Collecting domain-specific documents from the Web using focused crawlers has been considered one of the most important strategies to build digital libraries that serve the scientific community. However, because most focused crawlers use local search algorithms to traverse the Web space, they could be easily trapped within a limited sub-graph of the Web that surrounds the starting URLs and build domain-specific collections that are not comprehensive and diverse enough to scientists and researchers. In this study, we investigated the problems of traditional focused crawlers caused by local search algorithms and proposed a new crawling approach, meta-search enhanced focused crawling, to address the problems. We conducted two user evaluation experiments to examine the performance of our proposed approach and the results showed that our approach could build domain-specific collections with higher quality than traditional focused crawling techniques.

#index 760839
#* Panorama: extending digital libraries with topical crawlers
#@ Gautam Pant;Kostas Tsioutsiouliklis;Judy Johnson;C. Lee Giles
#t 2004
#c 14
#% 118771
#% 176502
#% 262061
#% 266215
#% 268087
#% 281186
#% 281214
#% 281251
#% 281366
#% 290482
#% 290830
#% 297550
#% 311040
#% 330599
#% 337239
#% 340924
#% 348138
#% 378520
#% 400648
#% 406493
#% 413608
#% 413610
#% 465754
#% 480309
#% 508272
#% 593994
#% 614036
#% 614081
#% 840583
#! A large amount of research, technical and professional documents are available today in digital formats Digital libraries are created to facilitate search and retrieval of information supplied by the documents. These libraries may span an entire area of interest (e.g., computer science) or be limited to documents within a small organization. While tools that index, classify, rank and retrieve documents from such libraries are important, it would be worthwhile to complement these tools with information available on the Web. We propose one such technique that uses a topical crawler driven by the information extracted from a research document. The goal of the crawler is to harvest a collection of Web pages that are focused on the topical subspaces associated with the given document. The collection created through Web crawling is further processed using lexical and linkage analysis. The entire process is automated and uses machine learning techniques to both guide the crawler as well as analyze the collection it fetches. A report is generated at the end that provides visual cues and information to the researcher.

#index 760840
#* Machine learning for information architecture in a large governmental website
#@ Miles Efron;Jonathan Elsas;Gary Marchionini;Junliang Zhang
#t 2004
#c 14
#% 115478
#% 127860
#% 190581
#% 252011
#% 296738
#% 309141
#% 376266
#% 387427
#% 458379
#% 465895
#! This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries. Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection. The goal of this discovery is twofold. First we desire a practical aid for information architects. Second, automatically derived document-concept relationships are a necessary precondition for real-world deployment of many dynamic interfaces. The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text. In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.

#index 760841
#* Managing distributed collections: evaluating web page changes, movement, and replacement
#@ Zubin Dalal;Suvendu Dash;Pratik Dave;Luis Francisco-Revilla;Richard Furuta;Unmil Karadkar;Frank Shipman
#t 2004
#c 14
#% 240748
#% 249201
#% 309746
#% 324926
#% 327115
#% 343786
#% 420487
#% 438136
#% 480136
#% 577370
#% 679872
#! Distributed collections of Web materials are common. Bookmark lists, paths, and catalogs such as Yahoo! Directories require human maintenance to keep up to date with changes to the underlying documents. The Walden's Paths Path Manager is a tool to support the maintenance of distributed collections. Earlier efforts focused on recognizing the type and degree of change within Web pages and identifying pages no longer accessible. We now extend this work with algorithms for evaluating drastic changes to page content based on context. Additionally, we expand on previous work to locate moved pages and apply the modified approach to suggesting page replacements when the original page cannot be found Based on these results we are redesigning the Path Manager to better support the range of assessments necessary to manage distributed collections.

#index 760842
#* Digital libraries and educational practice: a case for new models
#@ Tamara Sumner;Mary Marlino
#t 2004
#c 14
#% 172803
#% 177474
#% 282914
#% 296947
#% 315451
#% 332756
#% 334928
#% 337229
#% 337256
#% 337496
#% 358196
#% 378516
#% 378539
#% 393507
#% 438148
#% 452619
#% 607968
#% 614067
#% 1134816
#! Educational digital libraries can benefit from theoretical and methodological approaches that enable lessons learned from design and evaluation projects performed in one particular setting to be applied to other settings within the library network. Three promising advances in design theory are reviewed - reference tasks, design experiments, and design genres. Each approach advocates the creation of 'intermediate' constructs as vehicles for knowledge building and knowledge sharing across design and research projects. One purpose of an intermediate construct is to formulate finer-grained models that describe and explain the relationship between key design features and the cognitive and social dimensions of the context of use. Three models are proposed and used as thought experiments to analyze the utility of these approaches to educational digital library design and evaluation: digital libraries as cognitive tools, component repositories, and knowledge networks.

#index 760843
#* How geography professors select materials for classroom lectures: implications for the design of digital libraries
#@ Christine L. Borgman;Gregory H. Leazer;Anne Gilliland-Swetland;Kelli Millwood;Leslie Champeny;Jason Finley;Laura J. Smart
#t 2004
#c 14
#% 157132
#% 282914
#% 301982
#% 332733
#% 337247
#% 351213
#% 378506
#! A goal of the Alexandria Digital Earth Prototype (ADEPT) project is to make primary resources in geography useful for undergraduate instruction in ways that will promote inquiry learning. The ADEPT education and evaluation team interviewed professors about their use of geography information as they prepare for class lectures, as compared to their research activities. We found that professors desired the ability to search by concept (erosion, continental drift, etc ) as well as geographic location, and that personal research collections were an important source of instructional materials. Resources in geo-spatial digital libraries are typically described by location, but are rarely described by concept or educational application. This paper presents implications for the design of an educational digital library from our observations of the lecture preparation process. Findings include functionality requirements for digital libraries and implications for the notion of digital libraries as a shared information environment. The functional requirements include definitions and enhancements of searching capabilities, the ability to contribute and to share personal collections of resources, and the capability to manipulate data and images.

#index 760844
#* Element matching in concept maps
#@ Byron Marshall;Therani Madhusudan
#t 2004
#c 14
#% 27049
#% 614048
#% 660001
#% 1781098
#! Concept maps (CM) are informal, semantic, node-link conceptual graphs used to represent knowledge in a variety of applications. Algorithms that compare concept maps would be useful in supporting educational processes and in leveraging indexed digital collections of concept maps. Map comparison begins with element matching and faces computational challenges arising from vocabulary overlap, informality, and organizational variation. Our implementation of an adapted similarity flooding algorithm improves matching of CM knowledge elements over a simple string matching approach.

#index 760845
#* Usability, learning, and subjective experience: user evaluation of K-MODDL in an undergraduate class
#@ Bing Pan;Geri Gay;John Saylor;Helene Hembrooke;David Henderson
#t 2004
#c 14
#% 441756
#% 749630
#! Based on the CIAO! framework, this paper describes the initial evaluation of the Kinematic Model for Design Digital Library (K-MODDL), which is being used in an undergraduate mathematics class. Along with revealing general usability problems, our results describe users' subjective experiences and highlight the usefulness of various physical and digital models in facilitating learning. Interesting relationships among usability, learning, and subjective experience were discovered.

#index 760846
#* Use of MatML with software applications for e-learning
#@ Laura M. Bartolo;Cathy S. Lowe;Adam C. Powell, IV;Donald R. Sadoway;Jorge Vieyra;Kyle Stemen
#t 2004
#c 14
#! This pilot project investigates facilitating the development of the Semantic Web for e-learning through a practical example, using Materials Property Data Markup Language (MatML) to provide materials property data to a web-based application program Property data for 100 materials is marked up with MatML and used as an input format for an application program. Students use the program to generate graphs showing selected properties for different materials Selected graphs are submitted to the Materials Digital Library (MatDL) so that successive classes may be informed by earlier work to encourage new discoveries.

#index 760847
#* Semantic video classification and feature subset selection under context and concept uncertainty
#@ Jianping Fan;Hangzai Luo;Jing Xiao;Lide Wu
#t 2004
#c 14
#% 156430
#% 190581
#% 194202
#% 311027
#% 318851
#% 385564
#% 420064
#% 434806
#% 438054
#% 466263
#% 592438
#% 730122
#% 730148
#% 730214
#% 737989
#% 757618
#% 884718
#% 899467
#% 1289281
#% 1562578
#% 1562579
#% 1775110
#% 1775174
#% 1775175
#% 1855648
#% 1857512
#% 1857581
#! As large collections of videos become one key component of digital libraries, there is an urgent need of semantic video classification and feature subset selection to enable more effective video database organization and retrieval. However, most existing techniques for classifier training require a large number of labeled samples to learn correctly and suffer from the problems of context and concept uncertainty when only a limited number of labeled samples are available. To address the problems of context and concept uncertainty, we have proposed a novel framework to achieve incremental classifier training by integrating a limited number of labeled samples with a large number of unlabeled samples. Specifically, the contributions of this paper include: (a) Using the salient objects to achieve a middle-level understanding of video contents and enhance the quality of features on discriminating among different semantic video concepts; (b) Modeling the semantic video concepts by using the finite mixture models to approximate the class distributions of the relevant salient objects; (c) Developing an adaptive EM algorithm to integratethe unlabeled samples to enable incremental classifier training and address the problem of context uncertainty; (d) Proposing a cost-sensitive video classification technique to address the problem of concept uncertainty over time; (e) Supporting automatic video annotation via semantic classification Our experimental results in a certain domain of medical education videos have also been provided a convincing proof of our conclusions.

#index 760848
#* Generating fuzzy semantic metadata describing spatial relations from images using the R-histogram
#@ Yuhang Wang;Fillia Makedon;James Ford;Li Shen;Dina Goldin
#t 2004
#c 14
#% 113437
#% 120270
#% 170727
#% 181409
#% 213673
#% 278206
#% 279094
#% 279098
#% 301236
#% 340903
#% 345848
#% 397193
#% 428926
#% 428930
#% 437405
#% 451642
#% 578773
#% 614036
#% 614037
#% 614038
#% 614050
#% 730178
#% 1780771
#% 1781070
#% 1898684
#! Automatic generation of semantic metadata describing spatial relations is highly desirable for image digital libraries Relative spatial relations between objects in an image convey important information about the image. Because the perception of spatial relations is subjective, we propose a novel framework for automatic metadata generation based on fuzzy k-NN classification that generates fuzzy semantic metadata describing spatial relations between objects in an image. For each pair of objects of interest, the corresponding R-Histogram is computed and used as input for a set of fuzzy k--NN classifiers. The R-Histogram is a quantitative representation of spatial relations between two objects The outputs of the classifiers are soft class labels for each of the following eight spatial relations: 1) LEFT OF, 2) RIGHT OF, 3) ABOVE, 4) BELOW, 5) NEAR, 6) FAR, 7) INSIDE, 8) OUTSIDE Because the classifier-training stage involves annotating the training images manually, it is desirable to use as few training images as possible. To address this issue, we applied existing prototype selection techniques and also devised two new extensions. We evaluated the performance of different fuzzy k-NN algorithms and prototype selection algorithms empirically on both synthetic and real images. Preliminary experimental results show that our system is able to obtain good annotation accuracy (92%--98% on synthetic images and 82%--93% on real images) using only a small training set (4--5 images).

#index 760849
#* Multi-modal classification in digital news libraries
#@ Ming-yu Chen;Alexander Hauptmann
#t 2004
#c 14
#% 379602
#% 735069
#! This paper describes a comprehensive approach to construct robust multi-modal video classification on a specific digital source, broadcast news. Broadcast news has a very stable structure and every segment has its specific purpose. Video classification can support fundamental understanding of the structure of the video and the content. The variety of video content makes it hard to classify; however, it also provides multimodal information Our approach tries to solve two important issues of multimodal classification. The first one is to select few discriminative features from many raw features and the second one is to efficiently combine multiple sources. We applied Fisher's Linear Discriminant (FLD) for feature selection and concatenated the projections into a single synthesized feature vector as the combination strategy. Experimental results on the 2003 TRECVID news video archive show that our approach achieves very robust and accurate performance.

#index 760850
#* Question answering on lecture videos: a multifaceted approach
#@ Jinwei Cao;Jay F. Nunamaker
#t 2004
#c 14
#% 571493
#% 730232
#! In this paper, we introduce a multifaceted approach for question answering on lecture videos Text extracted from PowerPoint slides associated with the lecture videos is used as a source of domain knowledge to boost the answer extraction performance on these domain specific videos. The three steps of this approach are described and the evaluation plan is discussed.

#index 760851
#* Video grammar for locating named people
#@ Jun Yang;Alexander Hauptmann
#t 2004
#c 14
#% 592110
#! Finding a named person in broadcast news video is important to video retrieval. Relying on the text information such as video tran-script and OCR text, this task suffers from the temporal mismatch between a person's visual appearance and his/her name occurred in text. By exploring video grammar on the concurrence pattern between faces and names, we propose an extended text-based IR method to overcome this problem and yield superior performance.

#index 760852
#* Sharing encountered information: digital libraries get a social life
#@ Catherine C. Marshall;Sara Bly
#t 2004
#c 14
#% 151471
#% 240180
#% 240514
#% 261351
#% 297605
#% 319710
#% 341397
#% 399446
#% 415127
#% 575739
#! As part of a more extensive study of reading-related practices, we have explored how people share information they encounter in their everyday reading as a complement to the more traditional digital library focus on sharing intentionally retrieved materials. In twenty contextual interviews in home and work place settings, we investigated how people encounter and save published material in the form of paper and electronic clippings. We found that sharing forms a significant use for encountered materials. Furthermore, the function of these clippings extends far beyond a simple exchange of content to inform the recipient; in fact, the content itself may have little immediate value to the recipient. We also found the practice to be ubiquitous: all of our participants had both shared clippings with others and received them themselves. Specifically, this paper reports on: (1) how sharing encountered items fits into the broader spectrum of clipping practices; (2) the function and value of the shared information; and (3) the social role of sharing the encountered information We conclude that from a technological standpoint, we should think beyond an email model for sharing encountered information and, from a social perspective, we should attend to how sharing this sort of material contributes to the strength of social ties outside of a traditional information needs framework.

#index 760853
#* Enhancing digital libraries with TechLens+
#@ Roberto Torres;Sean M. McNee;Mara Abel;Joseph A. Konstan;John Riedl
#t 2004
#c 14
#% 46803
#% 173879
#% 202011
#% 220709
#% 258826
#% 280852
#% 281366
#% 297551
#% 414514
#% 415107
#% 567950
#% 1650569
#! The number of research papers available is growing at a staggering rate. Researchers need tools to help them find the papers they should read among all the papers published each year. In this paper, we present and experiment with hybrid recommender algorithms that combine Collaborative Filtering and Content-based. Filtering to recommend research papers to users. Our hybrid algorithms combine the strengths of each filtering approach to address their individual weaknesses. We evaluated our algorithms through offline experiments on a database of 102, 000 research papers, and through an online experiment with 110 users. For both experiments we used a dataset created from the CiteSeer repository of computer science research papers. We developed separate English and Portuguese versions of the interface and specifically recruited American and Brazilian users to test for cross-cultural effects. Our results show that users value paper recommendations, that the hybrid algorithms can be successfully combined, that different algorithms are more suitable for recommending different kinds of papers, and that users with different levels of experience perceive recommendations differently These results can be applied to develop recommender systems for other types of digital libraries.

#index 760854
#* Light-weight communal digital libraries
#@ Kurt J. Maly;Michael L. Nelson;Mohammad Zubair;Ashraf Amrou;S. Kothasama;Lan Wang;Richard Luce
#t 2004
#c 14
#% 337235
#! We describe Kepler, a collection of light-weight utilities that allow for simple and quick digital library construction. Kepler bridges the gap between established, organization-backed digital libraries and groups of researchers that wish to publish their findings under their control, anytime, anywhere yet have the advantage of their personal libraries. The personal libraries, or "archivelets", are Open Archives Initiative (OAI) compliant and thus available for harvesting from OAI service providers. A Kepler archivelet can be installed in the order of minutes by an author on a personal machine and a Kepler group server in the order of hours.

#index 760855
#* Collaborative extensions for the UpLib system
#@ William C. Janssen
#t 2004
#c 14
#% 3904
#% 87515
#% 731013
#! The UpLib personal digital library system is specifically designed for secure use by a single individual. However, collaborative operation of multiple UpLib repositories is still possible. This paper describes two mechanisms that have been added to UpLib to facilitate community building around individual document collections.

#index 760856
#* Metaextract: an NLP system to automatically assign metadata
#@ Ozgur Yilmazel;Christina M. Finneran;Elizabeth D. Liddy
#t 2004
#c 14
#% 397193
#% 614036
#! We have developed MetaExtract, a system to automatically assign Dublin Core + GEM metadata using extraction techniques from our natural language processing research MetaExtract is comprised of three distinct processes: eQuery and HTML-based Extraction modules and a Keyword Generator module. We conducted a Web-based survey to have users evaluate each metadata element's quality. Only two of the elements, Title and Keyword, were shown to be significantly different, with the manual quality slightly higher. The remaining elements for which we had enough data to test were shown not to be significantly different; they are: Description, Grade, Duration, Essential Resources, Pedagogy-Teaching Method, and Pedagogy-Group.

#index 760857
#* Looking for new, not known music only: music retrieval by melody style
#@ Fang-Fei Kuo;Man-Kwan Shan
#t 2004
#c 14
#% 194192
#% 204646
#% 280845
#% 378534
#% 397165
#% 413599
#% 463903
#% 481290
#% 629680
#% 730141
#% 746727
#! With the growth of digital music, content-based music retrieval (CBMR) has attracted increasingly attention. For most CBMR systems, the task is to return music objects similar to query in syntactic properties such as pitch and interval contour sequence. These approaches provide users the capability to look for music that has been heard. However, sometimes, listeners are looking, not for music they have been known, but for music that is new to them. Moreover, people sometimes want to retrieve music that "feels like" another music object or a music style. To the best of our knowledge, no published work investigates the content-based music style retrieval. This paper describes an approach for CBMR by melody style. We proposed four types of query specification for melody style query. The output of the melody style query is a music list ranked by the degree of relevance, in terms of music style, to the query. We developed the melody style mining algorithm to obtain the melody style classification rules. The style ranking is determined by the style classification rules. The experiment showed the proposed approach provides a satisfactory way for query by melody style.

#index 760858
#* Discovery of retrograde and inverted themes for indexing musical scores
#@ Xiaona Ren;Lloyd A. Smith;Richard A. Medina
#t 2004
#c 14
#% 614034
#! This paper describes extensions to a musical score indexing program that enable it to discover sequences of notes that appear in retrograde and/or inverted form. The program was tested over a set of 50 orchestral movements by several composers of the Baroque, Classical, and Romantic periods. The retrograde and inversion discovery algorithm added an average of 3.76 patterns per movement to the index, increasing the number of notes in the index by 6.5%, and the number of entries by 8.2%. Among the patterns added to the index were variations of 3 themes in retrograde, 5 themes in inversion, and 3 themes in retrograde inversion.

#index 760859
#* A tree-based method for fast melodic retrieval
#@ Charles L. Parker
#t 2004
#c 14
#% 194192
#! The evolution of aurally queryable melodic databases (so-called query-by-humming systems) has reached a point where retrieval accuracy is relatively high, even at large database sizes. With this accuracy has come a decrease in retrieval speed as methods have become more sophisticated and computationally expensive. In this paper, we turn our attention to heuristically culling songs from our database that are unlikely given a sung query, in hopes that we can increase speed by reducing the number of matching computations necessary to reach the proper target song.

#index 760860
#* Error anaylsis of Chinese text segmentation using statistical approach
#@ Christopher C. Yang;Kar Wing Li
#t 2004
#c 14
#% 295519
#% 345738
#! The Chinese text segmentation is important for the indexing of Chinese documents, which has significant impact on the performance of Chinese information retrieval. The statistical approach overcomes the limitations of the dictionary based approach. The statistical approach is developed by utilizing the statistical information about the association of adjacent characters in Chinese text collected from the Chinese corpus Both known words and unknown words can be segmented by the statistical approach. However, errors may occur due to the limitation of the corpus. In this work, we have conducted the error analysis of two Chinese text segmentation techniques using statistical approach, namely, boundary detection and heuristic method Such error analysis is useful for the future development of the automatic text segmentation of Chinese text or other text in oriental languages. It is also helpful to understand the impact of these errors on the information retrieval system in digital libraries.

#index 760861
#* Demonstrating education impact: challenges in the years ahead
#@ Tamara Sumner;Mary Marlino
#t 2004
#c 14
#! The purpose of this panel is to stimulate thought and debate about the legacy of educational digital libraries.

#index 760862
#* Mediating team work for digital heritage archiving
#@ Jyi-shane Liu;Mu-Hsi Tseng
#t 2004
#c 14
#% 235452
#% 287064
#% 332757
#% 413708
#% 413709
#% 413730
#% 413734
#% 413751
#% 614039
#% 614079
#! Building digital heritage requires substantial resources in materials, expertise, tools, and cost. Projects supported by governments and academics can only cover a small part of the world's heritage in both time and space dimensions. The preservation coverage problem is most serious in domains where sources of intellectual and cultural heritage may diminish or disappear over time. A central notion that helps resolve these issues is to facilitate global reach of digital technology to sources of valuable heritage. We propose an approach to exploit non-institutional resources for wider participation and coverage in digital heritage endeavor. The approach attempts to replicate institutional digital heritage work by teaming up non-institutional resources and providing standard practice.

#index 760863
#* A semi-automated digital preservation system based on semantic web services
#@ Jane Hunter;Sharmin Choudhury
#t 2004
#c 14
#% 310844
#% 1112729
#! This paper describes a Web-services-based system which we have developed to enable organizations to semi-automatically preserve their digital collections by dynamically discovering and invoking the most appropriate preservation service, as it is required. By periodically comparing preservation metadata for digital objects in a collection with a software version registry, potential object obsolescence can be detected and a notification message sent to the relevant agent. By making preservation software modules available as Web services and describing them semantically using a machine-processable ontology (OWL-S), the most appropriate preservation service(s) for each object can then be automatically discovered, composed and invoked by software agents (with optional human input at critical decision-making steps). We believe that this approach represents a significant advance towards providing a viable, cost-effective solution to the long term preservation of large-scale collections of digital objects.

#index 760864
#* Preservation functionality in a digital archive
#@ Erik Oltmans;Raymond van Diessen;Hilde van Wijngaarden
#t 2004
#c 14
#% 25475
#! Early 2003 the digital archiving system of the National Library of the Netherlands (KB) was taken into production. This system is called the e-Depot and its technical heart is the IBM system called Digital Information Archiving System (DIAS). The e-Depot is built according to the recommendations in the OAIS reference model and is dedicated to the long-term storage of and access to large quantities of digital publications. To control safe storage and provide for future rendering of the digital documents, extra functionality was needed. Therefore, at the same time the system was taken into production, a joint KB/IBM project group started with the design, development and implementation of the Preservation Manager. This system provides the functionality for defining and managing the technical environment needed to render the electronic resources stored in DIAS. In this paper we present the design of the Preservation Manager, its rationale, and the way it is used within the operational digital archiving environment of the KB e-Depot.

#index 760865
#* Mining events and new name translations from online daily news
#@ Wai Lam;Pik-Shan Cheung;Ruizhang Huang
#t 2004
#c 14
#% 196896
#% 235941
#% 262090
#% 278107
#% 350859
#% 400061
#% 747947
#% 804876
#% 815233
#% 854812
#! We develop a system for mining events and unseen name translations from online daily Web news. This system first automatically discovers bilingual events by analyzing the content of the news stories. The discovered event can be treated as comparable bilingual news and can be used for generating name candidates. A name matching algorithm is developed to discover new unseen name translations based on phonetic and context clues. The experimental results show that our system is effective for mining new knowledge and information from online Web news.

#index 760866
#* Two supervised learning approaches for name disambiguation in author citations
#@ Hui Han;Lee Giles;Hongyuan Zha;Cheng Li;Kostas Tsioutsiouliklis
#t 2004
#c 14
#% 32357
#% 144034
#% 190581
#% 249143
#% 262059
#% 283136
#% 287222
#% 309208
#% 310516
#% 310533
#% 310546
#% 337227
#% 340903
#% 342659
#% 420072
#% 532186
#% 577247
#% 614036
#% 614037
#% 614058
#% 722934
#% 729911
#% 748465
#% 748619
#% 815297
#% 854824
#% 855106
#% 870896
#% 1279275
#% 1650298
#! Due to name abbreviations, identical names, name misspellings, and pseudonyms inpublications or bibliographies (citations), an author may have multiple names and multiple authors may share the same name. Such name ambiguity affects the performance of document retrieval, web search, database integration, and may cause improper attribution to authors. This paper investigates two supervised learning approaches to disambiguate authors in the citations. One approach uses the naive Bayes probability model, a generative model; the other uses Support Vector Machines(SVMs) and the vector space representation of citations, a discriminative model. Both approaches utilize three types of citation attributes: co-author names, the title of the paper, and the title of the journal or proceeding. We illustrate these two approaches on two types of data, one collected from the web, mainly publication lists from homepages, the other collected from the DBLPcitation databases.

#index 760867
#* Finding authoritative people from the web
#@ Masanori Harada;Shin-ya Sato;Kazuhiro Kazama
#t 2004
#c 14
#% 115462
#% 218978
#% 220708
#% 262155
#% 268079
#% 330616
#% 378538
#% 406493
#% 451536
#% 757453
#! Today's web is so huge and diverse that it arguably reflects the real world. For this reason, searching the web is a promising approach to find things in the real world. This paper presents NEXAS, an extension to web search engines that attempts to find real-worldentities relevant to a topic. Its basic idea is to extract proper names from the web pages retrieved for the topic. A main advantage of this approach is that users can query any topic and learn about relevant real-world entities without dedicated databases for the topic. In particular, we focus on an application for finding authoritative people from the web. This application is practically important because once personal names are obtained, they can lead users from the web to managed information stored in digital libraries. To explore effective ways of finding people, we first examine the distribution of Japanese personal names by analyzing about 50 million Japanese web pages. We observe that personal names appear frequently on the web, but the distribution is highly influenced by automatically generated texts. To remedy the bias and find widely acknowledged people accurately, we utilize the number of web servers containing a name instead of the number of web pages. We show its effectiveness by an experiment covering a wide range oftopics. Finally, we demonstrate several examples and suggest possible applications.

#index 760868
#* Library leaders on digital libraries and the future of the research library: a panel discussion
#@ Clifford Lynch;Charles Henry;Sarah Pritchard;Betsy L. Humphreys;Brian Schottlaender
#t 2004
#c 14
#! This panel presents perspectives from a group of research library leaders on the evolving relationships between the body of systems, services and technologies associated with digital libraries and the institution of the research library. Four panelists and the moderator will consider many questions, including whether libraries are being too timid or overly aggressive in engaging the world of digital libraries; the extent to which digital library technologies may threaten the future of the research library; and how changes in the practices of science and scholarship due to information technology and digital content will help shape the future of the research library and the integration of digital library technologies. We will also examine the possible roles of research libraries in helping to make digital library projects sustainable. The panel will also include time for questions from the audience.

#index 760869
#* Enhancing usability in CITIDEL: multimodal, multilingual, and interactive visualization interfaces
#@ Saverio Perugini;Kathleen McDevitt;Ryan Richardson;Manuel A. Pérez-Quiñones;Rao Shen;Naren Ramakrishnan;Chris Williams;Edward A. Fox
#t 2004
#c 14
#% 118771
#% 131610
#% 173424
#% 232698
#% 281186
#% 308828
#% 318929
#% 337235
#% 342061
#% 352920
#% 378523
#% 399056
#% 467889
#% 571820
#% 641060
#% 710604
#% 754079
#! We describe four usability-enhancing interfaces to CITIDEL aimed at improving the user experience and supporting personalized information access by targeted communities. These comprise: a multimodal interaction facility with capability for out-of-turn input, interactive visualizations for exploratory analysis, a translation center exposing multilingual interfaces, as well as traditional usability enhancements. Pilot studies demonstrate the resulting improvements in quality, as measured across a number of metrics.

#index 760870
#* Lost in memories: interacting with photo collections on PDAs
#@ Susumu Harada;Mor Naaman;Yee Jiun Song;QianYing Wang;Andreas Paepcke
#t 2004
#c 14
#% 272902
#% 297600
#% 340889
#% 342528
#% 378541
#% 415112
#% 449536
#% 452641
#% 452642
#! We developed two browsers to support large personal photo collections on PDAs. Our first browser is based on a traditional, folder-based layout that utilizes either the user's manually created organization structure, or a system-generated structure. Our second browser uses a novel interface that is based on a vertical, zoomable timeline. This timeline browser does not require users to organize their photos, but instead, relies solely on system-generated structure. Our system creates a hierarchical structure of the user's photos by applying time-based clustering to identify subsets of photos that are likely to be related. In a user experiment, we compared users' searching and browsing performance across these browsers, using each user's own photo collection. Photo collection sizes varied between 500 and 3000 photographs Our results show that our timeline browser is at least as effective for searching and browsing tasks as a traditional browser that requires users to manually organize their photos.

#index 760871
#* Collection understanding
#@ Michelle Chang;John J. Leggett;Richard Furuta;Andruid Kerne;J. Patrick Williams;Samuel A. Burns;Randolph G. Bias
#t 2004
#c 14
#% 1335
#% 18033
#% 25448
#% 170383
#% 170385
#% 185282
#% 232679
#% 232824
#% 258255
#% 270633
#% 272902
#% 281382
#% 287136
#% 289587
#% 290703
#% 296999
#% 301234
#% 301247
#% 308901
#% 324983
#% 325211
#% 334628
#% 342528
#% 342536
#% 378065
#% 378541
#% 399056
#% 451655
#% 452597
#% 452612
#% 452641
#% 467760
#% 467888
#% 531867
#% 645984
#% 856129
#! Collection understanding shifts the traditional focus of retrieval in large collections from locating specific artifacts to gaining a comprehensive view of the collection. Visualization tools are critical to the process of efficient collection understanding By presenting simple visual interfaces and intuitive methods of interacting with a collection, users come to understand the essence of the collection by focusing on the artifacts. This paper discusses a practical approach for enhancing collection understanding in image collections.

#index 760872
#* Combined searching of web and oai digital library resources
#@ Aaron Krowne;Martin Halbert
#t 2004
#c 14
#% 281251
#% 378527
#! In this paper, we describe an experiment in combined searching of web pages and digital library resources, exposed via an Open Archives metadata provider and web gateway service. We utilize only free/open source software components for our investigation, in order to demonstrate feasibility of deployment for all institutions.

#index 760873
#* Ontology acquisition and semantic retrieval from semantic annotated chinese poetry
#@ Wun Von Soo;Yao Shih Yang;Lei Shu Chen;Ting Yi Fu
#t 2004
#c 14
#% 614038
#! This research aims to utilize semantic web[1]. technology to the semantic annotation of classical Chinese poetry. We investigate the feasibilities and advantages of semantic retrieval and automated ontology acquisition from semantically annotated poems based on a Chinese thesaurus. We have induced a set of semantic composition rules for pair-wise character (word) patterns that can be used to parse the poem sentences and recursively generate RDF[2]. triple relations among the pair of characters (words). We have also defined a scoring scheme to assess semantic similarity for semantic retrieval. We showed that the semantic retrieval method significantly outperformed the keyword-based retrieval method.

#index 760874
#* Web question answering through automatically learned patterns
#@ Dmitri Roussinov;Jose Robles
#t 2004
#c 14
#% 330619
#% 348163
#% 397160
#% 401086
#% 855048
#! While being successful in providing keyword based access to web pages, commercial search portals, such as Google, Yahoo, AltaVista, and AOL, still lack the ability to answer questions expressed in a natural language. We explore the feasibility of a completely trainable approach to the automated question answering on the Web or large scale digital libraries. By using the inherent redundancy of large scale collections, each candidate answer found by the system is triangulated (confirmed or disconfirmed) against other possible answers. Since our approach is entirely self-learning and does not involve any linguistic resources it can be easily implemented within digital libraries or Web search portals.

#index 760875
#* Exploring the relationship between personal and public annotations
#@ Catherine C. Marshall;A. J. Bernheim Brush
#t 2004
#c 14
#% 200271
#% 232895
#% 237318
#% 247295
#% 247296
#% 247297
#% 281359
#% 296728
#% 297605
#% 319710
#% 319712
#% 341397
#% 345362
#% 402076
#% 452639
#% 579439
#% 672630
#% 730088
#% 1303064
#! Today people typically read and annotate printed documents even if they are obtained from electronic sources like digital libraries If there is a reason for them to share these personal annotations online, they must re-enter them. Given the advent of better computer support for reading and annotation, including tablet interfaces, will people ever share their personal digital ink annotations as is, or will they make substantial changes to them? What can we do to anticipate and support the transition from personal to public annotations? To investigate these questions, we performed a study to characterize and compare students' personal annotations as they read assigned papers with those they shared with each other using an online system. By analyzing over 1, 700 annotations, we confirmed three hypotheses: (1) only a small fraction of annotations made while reading are directly related to those shared in discussion; (2) some types of annotations - those that consist of anchors in the text coupled with margin notes - are more apt to be the basis of public commentary than other types of annotations; and (3) personal annotations undergo dramatic changes when they are shared in discussion, both in content and in how they are anchored to the source document. We then use these findings to explore ways to support the transition from personal to public annotations.

#index 760876
#* Supporting personal collections across digital libraries in spatial hypertext
#@ Frank M. Shipman;Haowei Hsieh;J. Michael Moore;Anna Zacchi
#t 2004
#c 14
#% 4013
#% 148396
#% 172806
#% 185254
#% 187989
#% 214525
#% 231034
#% 237319
#% 240744
#% 249095
#% 275839
#% 337496
#% 348140
#% 349405
#% 378511
#% 402098
#% 467765
#! Creating, maintaining, or using a digital library requires the manipulation of digital documents. Information workspaces provide a visual representation allowing users to collect, organize, annotate, and author information. The Visual Knowledge Builder(VKB) helps users access, collect, annotate, and combine materials from digital libraries and other sources into a personal information workspace VKB has been enhanced to include direct search interfaces for NSDL and Google. Users create a visualization of search results while selecting and organizing materials for their current activity. Additionally, metadata applicators have been added to VKB. This interface allows the rapid addition of metadata to documents and aids the user in the extraction of existing metadata for application to other documents. A study was performed to compare the selection and organization of documents in VKB to the commonly used tools ofa Web browser and a word processor. This study shows the value of visual workspaces for such effort but points to the need for subdocument level objects, ephemeral visualizations, and support for moving from visual representations to metadata.

#index 760877
#* Tools for a new generation of scholarly edition unified by a tei-based interchange format
#@ Rajiv Kochumman;Carlos Monroy;Jie Deng;Richard Furuta;Eduardo Urbina
#t 2004
#c 14
#% 298159
#% 301229
#% 614039
#! We report on experience gained from our ongoing multi-year project to produce an Electronic Variorum Edition of Cervantes' Don Quixote de la Mancha. Initially designed around a custom database representation, the project's evolution has lead to the adoption of a TEI-based format for information interchange among the project's major components. We discuss the mechanics of this approach and its benefits.

#index 760878
#* Toward information retrieval web services for digital libraries
#@ Y. Fu;J. Mostafa
#t 2004
#c 14
#% 623192
#% 1112726
#! Information retrieval (IR) functions serve a critical role in many digital library systems. There are numerous mature IR algorithms that have been implemented and it will be a waste of resources and time to re-implement them. The implemented IR algorithms can be distributed or their functions made available through the framework of web services. Web services in the IR domain have not been widely tested. Concept extraction is an important area in traditional IR. We demonstrated that it can be easily adopted as IR web services and can be accessed in multiple ways. For the IR web services, we take advantage of a term representation database which was created as a result of a previous digital library project containing 31, 928, 892 terms found on 49, 602, 191 pages of the web.

#index 760879
#* Enabling interoperability for autonomous digital libraries: an API to citeseer services
#@ Yves Petinot;Clyde Lee Giles;Vivek Bhatnagar;Pradeep B. Teregowdae;Hui Han
#t 2004
#c 14
#% 249141
#% 249143
#% 281446
#% 614058
#! We introduce CiteSeer-API, a public API to CiteSeer-like services CiteSeer-API is SOAP/WSDL based and allows for easy programatical access to all the specific functionalities offered by CiteSeer services, including full text search of documents and citations and citation--based document discovery. CiteSeer-API is currently showcased on SMEALSearch [10]. a digital library search engine for business academic publications.

#index 760880
#* Digital libraries settling the score: 10 years hence and 10 before
#@ Edward A. Fox;Gregory R. Crane;Stephen M. Griffin;Ronald L. Larsen;David M. Levy;David J. McArthur;Sugimoto Shigeo
#t 2004
#c 14
#! Six panelists and a moderator leverage knowledge of the first ten years of the digital libraries field, to suggest key future directions.

#index 760881
#* Alessandro kraus music pamphlet digitization
#@ Estelle Paskausky
#t 2004
#c 14
#! The Alessandro Kraus Pamphlets project completed in Fall 2003 is among the first major digitization projects at Boston College. This poster describes the process of selecting and digitizing pamphlets from the Alessandro Kraus music pamphlet collection for inclusion in the Boston College Digital Library, and serves as an example for planning and choosing future digital library projects.

#index 760882
#* Applying web analysis in web page filtering
#@ Michael Chau
#t 2004
#c 14
#% 458379
#% 578242

#index 760883
#* Bricoleurs: exploring digital library evaluation as participant interactions, research, and processes
#@ Anita S. Coleman;Laura Bartolo;Casey Jones
#t 2004
#c 14
#! The NSF-funded National Science Digital Library (NSDL) is working to develop community-based processes for implementing shared evaluation goals and instruments among its distributed library network to examine library usage, collections growth, and library governance processes. The bricoleur modality of evaluation research is one that integrates scientific methods as well as humanistic values. These activities are helping to provide the foundation for the development of a scientific program of digital library evaluation that crosses disciplinary boundaries.

#index 760884
#* Browsing and searching behavior in the renardus web service a study based on log analysis
#@ Traugott Koch;Anders Ardö;Koraljka Golub
#t 2004
#c 14

#index 760885
#* Capturing content for virtual museums: from pieces to exhibits
#@ Bradley M. Hemminger;Gerald Bolas;David Carr;Paul Jones;Doug Schiff;Nick England
#t 2004
#c 14
#! Virtual museums provide ways to capture the content of a real museum in a digital (electronic) form and make this digital form more universally available. This poster describes a novel method for digitally recording not only individual museum pieces, but entire museum exhibits (consisting of one or more rooms or spaces). The methodology allows anyone with access to the internet or a PC to experience anywhere, anytime, any part of the museum's collection or exhibits (past, present and future). Users can explore the museum exhibits in a virtual reality that is both spatially accurate and visually compelling. All objects and 3D scenes are seen in precise full color photographic quality detail. The scene and objects are polygonal meshes representing the surfaces of objects. This permits making measurements directly on the scene with millimeter precision. The methodology, its application to capturing museum exhibits, and examples of exhibits recorded using this technique are described. This work is part of the Virseum project (http://ils unc edu/bmh/virseum) at the School of Information and Library Science at the University of North Carolina at Chapel Hill (UNC). In addition to the standard capture of items and exhibits for virtual access, this methodology opens the door for many other applications, including the design of virtual (never physically implemented) exhibits and pieces.

#index 760886
#* Collaboration in digital libraries: a conceptual framework
#@ Lee Iverson
#t 2004
#c 14
#! New classes of services for digital libraries have been explored in there search community with many now being tested and deployed in real-world settings. Unfortunately, there have been problems, some predicted and some unforeseen, in the development of these services. Moreover, a number of problems have been identified as becoming critical in the future, especially the difficulties as sociated with preservation of archives of digital content when data formats and media both have limited life spans. We have analyzed a number of these services in a research library (personal collection management, annotation, institutional repositories, and learning object repositories) in terms of their user and task requirements for three prototypical users: a researcher, a teacher and a student. Given these, we develop a unified conceptual model of how these services should work together in collaborative situations and some of the requirements for systems and service organizations that might implement them. This model centers around a vision of the digital library as the hub of a personalized, integrated information management environment. In particular we note the importance of: a flexible collection model that encompasses traditional collections managed by librarians, community collections managed by either professionals or users, and private, individual collections; both synchronous and asynchronous interactions between users and data; integration between library services and tools for using the information managed by the library user annotations as metadata associated with documents and document fragments and the integration of this facility with metadata search; a data model that provides universal, granular access to the contents of documents and other resources whether they are structured, semi-structured or unstructured; a data security model that provides full support for a range of private to semi-public to fully public data and metadata for users and user communities; and simple, flexible and integrated control of privacy, security, and integrity of all such data and metadata. Beyond these, one significant observation that deserves greater emphasis is the need to provide direct and sophisticated support for a variety of epistemic communities in any such digital library. In particular, both users and communities need new tools to organize and use the information they are collecting in the context of their personal and collective knowledge. The claim is that for these patterns of use, it is less useful to provide universal ontological models orcategory hierarchies than it is to provide sophisticated tools to allow both automatic and user-directed semantic categories and relations to be defined, refined and adapted for information management in context. Finally, this analysis reveals a set oftechnical requirements that highlight a number of critical gaps in the conceptual integration of the services and in the infrastructure underlying theircurrent implementations. One model for building such set of facilities takes the traditional three-tier enterprise application model and adapts it for use as a layered application model for integrated data-driven applications We then consider current and potential technologies for implementing this model and suggest that the best hope for a solution that meets both user and technical needs lies in a combination of integrated services built on a document modelling and collaboration infrastructure thatwe call NODAL, the Network-Oriented Document Abstraction Language. We illustrate how this model may enable even the most ambitious visions of the potential of the collaborative digital library.

#index 760887
#* Communication channels and the adoption of digital libraries for electronic theses and dissertations
#@ Suzie Allard
#t 2004
#c 14
#! This research used diffusion of innovation theory to explore factors that influence adoption of digital libraries for electronic theses and dissertations (ETD-DL) among members of the Networked Digital Library of Theses and Dissertations (NDLTD) Communication channels were categorized as being either interpersonal or mediated, and the perceived importance of these channels was assessed both within and between organizations. A web-based survey collected data from the 133 universities in 26 countries that were NDLTD members in December 2002. Respondents were members of the university's 'ETD Committee' and represented academic administrators, faculty, librarians, and computer systems specialists. Surveys were received from 95 respondents representing 65 universities in 14 countries. Twenty-one of these universities were outside the United States, and represented countries with a wide range of economic development.Results provide insights into university attitudes towards distributed digital libraries. For example, results suggest that interpersonal channels of communication about digital library adoption are more important than mediated channels within the organization. However, mediated channels of communication are more important for those universities that have decided to adopt the ETD-DL but have not yet implemented the DL. There were also significant differences in the importance attributed to these channels by individuals in different jobs. The results suggest strategies that could encourage development of digital libraries within other social systems. The study also illustrates the importance of planning for the human factor in digital library management. Carefully constructed strategies that address all the parties involved in DL adoption and that account for differences in communication style will more readily facilitate successful adoption of distributed digital libraries.

#index 760888
#* The concept space interchange protocol
#@ Sonal Bhushan;Qianyi Gu;Tamara Sumner
#t 2004
#c 14
#% 349957
#% 614067
#! The Concept Space Interchange Protocol supports the deployment of conceptual browsing interfaces in digital libraries. The protocol provides a programmatic interface to dynamically generate interactive visual components that enable users to navigate a concept space, request information about concepts, and request library resources aligned with concepts. The Concept Space Interchange Protocol has been implemented as part of the NSDL Strand Map Service, which enables digital library developers to create user interfaces and services based on nationally recognized K-12 science learning goals developed by the American Association for the Advancement of Science. The protocol, the principles underpinning its design, and the problem-centered design methodology used to create it are described.

#index 760889
#* Cross-lingual searching and visualization for greek and latin and old norse texts
#@ Jeffrey A. Rydberg-Cox;Lara Vetter;Stefan Rüger;Daniel Heesch
#t 2004
#c 14
#! We explore approaches to multi--lingual information retrieval for Greek, Latin, and Old Norse texts and an innovative visualization facility for the results.

#index 760890
#* Coupling browse and search in highly interactive user interfaces: a study of the relation browser++
#@ J. Zhang;G. Marchionini
#t 2004
#c 14

#index 760891
#* DialogPlus: digital libraries in support of innovative approaches to learning and teaching in geography
#@ Michael Freeston;Hugh Davis
#t 2004
#c 14
#! DialogPlus is one of four international projects, supported in the US by the NSF International Collaborative Research Program in Digital Libraries, and in the UK by the Joint Information Systems Committee of the UK Higher Education Funding Councils. The two primary objectives of the project are to develop: a distributed enabling information infrastructure for the support of learning and teaching in Geography; innovative approaches to teaching and learning, based on this infrastructure. Specifically, the project aims to show how: the undergraduate and postgraduate programs of study in Geography in the consortium universities can be enriched and developed through cross--national collaboration and on--line delivery; different virtual learning environments can be supported by a common, open and distributed digital library infrastructure; major geospatial resources relevant for the study of the environment and landscape and for the study of human populations in cities and the countryside can be used in student programs of study; important skills in the analysis of spatial information through use of Geographical Information Science and Earth Observation software and functions can be taught on--line and made available in undergraduate programs. The project plans to deliver shared UK/US electronic resources associated with four courses across four topic areas, namely: Human Geography (based on the Census); Geographical Information Science (applied to retailing); Geomorphology (based on river catchments); and Earth Observation (for land cover and land use inference). The project will capitalize on a variety of rich digital resources which have been created by both official agencies and universities and which can be used to enhance student learning, knowledge and skills in each of these topic areas. These electronic resources will be made available through interoperable digital library technology and integrated directly into course units in undergraduate programs supported by Virtual Learning Environments within each institution. A distributed version of the Alexandria geo--referenced digital library, developed at UCSB within the DLI1 and DLI2 programs of the NSF, will be used as the foundation of the technical infrastructure to support the project. A major aim of the project will be to show that several different pedagogic approaches, and a wide variety of data collections and teaching resources, can be supported and shared within this common infrastructure.

#index 760892
#* Digital libraries and community networking: the canadian experience
#@ Nadia Caidi;Andrew Clement
#t 2004
#c 14
#! We describe integrating DLs with community networking initiatives as part of the Canadian Research Alliance for Community Innovation and Networking.

#index 760893
#* A digital library for health sciences educators: the health education assets library (heal)
#@ Sandra A. McIntyre;Sharon E. Dennis;Sebastian H. J. Uijtdehaage;Chris S. Candler
#t 2004
#c 14
#! Health sciences educators have the need but neither the time nor the resources to create and index digital multimedia materials suitable for use in educational settings. The primary mission of the Health Education Assets Library (HEAL) is to address this need by providing health sciences educators with free access over the Internet to high--quality multimedia materials, including such items as images, videos, and animations The project team is working with other organizations to establish an international network of distributed databases containing high--quality teaching resources in a variety of health sciences--related subject areas HEAL's resources are freely available on the Web for use by health sciences faculty, students, and staff, as well as patients and their families. The digital library includes interfaces for searching, downloading, contributing, and browsing through materials. A custom metadata schema based on the Educause Instructional Management Systems (IMS) standard has been extended by HEAL to include additional health sciences--related elements Intellectual property issues are handled through the use of the Creative Commons set of licenses; most commonly, contributors grant free use of the library's resources for non--commercial purposes with clear attribution. The HEAL project has attracted the interest of over sixty organizational and individual partners, and by February 2004 there were over 4000 registered users. The collection is growing as new partner collections are being added by the end of late 2004, the national multimedia repository/referatory created by the HEAL team at www.healcentral.org will offer health sciences educators access to a large, diverse collection of health science materials appropriate for use in a variety of educational settings.

#index 760894
#* The digital ideakeeper: integrating digital libraries with a scaffolded environment for online inquiry
#@ Chris Quintana;Meilan Zhang
#t 2004
#c 14
#! Online inquiry is an important way of engaging learners in information--rich activities using online sources to explore questions in different fields, such as science. Online inquiry involves a set of interrelated activities, such as planning an investigation; seeking, analyzing, and making sense of online information; and synthesizing information into a final argument. However, learners may encounter several obstacles in trying to tackle an open--ended, complex process like online inquiry. Therefore, using a learner--centered design approach, we are developing the Digital Idea Keeper environment to extend digital libraries by integrating different tools and incorporating different scaffolding approaches to help learners effectively engage in online inquiry.

#index 760895
#* Digitally modeling, visualizing and preserving archaeological sites
#@ Peter K. Allen;Steve Feiner;Lynn Meskell;Ken Ross;Alejandro J. Troccoli;Hrvoje Benko;Edward Ishak;Benjamin Smith;James Conlon
#t 2004
#c 14

#index 760896
#* DLIST: opening lis research and practice
#@ Paul J. Bracke;Anita Sundaram Coleman;Shawn Nelson
#t 2004
#c 14
#! In this paper we describe DLIST, a digital library for Library and Information Science Research and Practice and for Information Technology as it relates to LIS It is built upon the open access eprints model, but that extends materials in the collection beyond the formal, scholarly literature to include other types of content created by researchers and practitioners. DLIST is intended to promote resource sharing in LIS and IT and to attempt to bridge the gap between research and practice. The notion of open access is briefly discussed as a central tenet for the development of the intellectual commons as an interactive space for learning.

#index 760897
#* Dynamically generating conceptual browsing interfaces for digital libraries
#@ Qianyi Gu;Tamara Sumner;Sonal Bhushan;Faisal Ahmad
#t 2004
#c 14
#% 218102
#% 385505
#% 614067
#! A system is described that supports the dynamic generation of conceptual browsing interfaces. These interfaces are comprised of interacting visual components that contain different views onto a concept space that can be modeled as nodes and links. This algorithm uses a combined approach of tree--based processing with a grid--based drawing system to automatically generate the visual components. This algorithm is part of a larger digital library service, the NSDL Strand Map Service, which aims to provide educators and learners with conceptual browsing interfaces that help them to locate and use learning resources in educational digital libraries.

#index 760898
#* Ensuring quality in peer review
#@ F. P. McMartin;M. Wetzel;G. Hanley
#t 2004
#c 14
#! Faculty users of education digital libraries require contents that are high quality and that are effective teaching and learning materials. Faculty use peer reviews of these materials to select those that they wish to use. MERLOT has developed a scalable, effective peer review system that meets the needs of its users. This paper describes evaluation research conducted to ensure that as the process is reliable, trusted and useable.

#index 760899
#* An evaluation methodology for coordinated event visualization in digital libraries
#@ Wingyan Chung;Luis G. Chaboya;Christopher D. O'Toole;Homa Atabakhsh
#t 2004
#c 14
#% 1414759
#! Event visualization holds the promise of alleviating information overload in digital libraries. We propose a methodology for evaluating a coordinated event visualization tool called COPLINK Spatio--Temporal Visualizer (STV) The methodology examines different event dimensions and compares STV with another frequently used crime analysis tool (Microsoft Excel). We briefly describe the experimental procedure and results, and discuss future directions.

#index 760900
#* How to annotate an image?: the need of an image annotation guide agent
#@ Chen-Yu Lee;Von-Wun Soo;Yi-Ting Fu
#t 2004
#c 14
#! The performance of retrieving an image in terms of text--type of queries depends heavily on the quality of the annotated descriptive metadata that describes the content of the images. However, effective annotation of an image can often be a laborious task that requires consistent domain knowledge. We showed that the critical property and common sense heuristics used by an annotation guide agent to aid the annotation of images could significantly lead to the improvement of the recall and precision of image retrieval.

#index 760901
#* A hybrid approach to generating and utilizing faceted vocabulary for knowledge discovery on the web
#@ Kiduk Yang;Elin Jacob
#t 2004
#c 14

#index 760902
#* If you build it, will they come?: lessons learned from the workshop on participant interaction in digital libraries
#@ Brandon Muramatsu;Sarah Gierschi;Flora McMartin;Steve Weimar;Gene Klotz
#t 2004
#c 14
#! A workshop in early February 2004, hosted by the Math Forum, brought together over thirty experts from the National Science Digital Library (NSDL) program and representatives from online communities to discuss and identify promising models of participant involvement for the NSDL and NSDL--funded projects [see pidlworkshop comm nsdl org]. The workshop leveraged the expertise of attendees to identify tools and reporting mechanisms, develop strategies and formulate recommendations that will help NSDL projects incorporate, support and grow the communities who use their digital libraries Workshop attendees also provided a rich set of examples of how users are currently involved in building and maintaining NSDL digital libraries and the potential impact of their involvement Participant involvement is a critical factor not only in developing educational digital libraries, but also in sustaining the resources, the technology and most importantly, the communities who use them Without converting casual or one--time users into recurring, involved participants, or even members of a community, educational digital libraries will simply be yet another example of, 'If you build it, will they come'.

#index 760903
#* Integrating knowledge components for writer identification in a digital archive of historical music scores
#@ Ilvio Bruder;Temenushka Ignatova;Lars Milewski
#t 2004
#c 14
#! The integration of domain- and user-specific specialized services, for the management and representation of information, is an important step towards efficiently usable digital libraries and archives. However, specialized services have not yet become an integral part of digital archive systems. Here we represent some of the recently achieved milestones towards developing a digital archive of historical music scores, providing specialized services for the identification of writers of music scores, based on their handwriting characteristics.

#index 760904
#* The materials digital library: MatDL.org
#@ Laura M. Bartolo;Sharon C. Glotzer;Javed I. Khan;Adam C. Powell;Donald R. Sadoway;Kenneth M. Anderson;James A. Warren;Vinod Tewary;Cathy S. Lowe;Cecilia Robinson
#t 2004
#c 14
#! The Materials Digital Library project, as part of the National Science Foundation's National Science Digital Library program, researches efficient creation and dissemination of materials information using a multifaceted approach: collection of materials content, with an emphasis on soft matter; construction of authoring tools for improved delivery, and; use of materials content in a digital library.

#index 760905
#* NIKE: integrating workflow, digital library, and online catalog systems
#@ Nancy Allmang;Jo Ann Remshard
#t 2004
#c 14

#index 760906
#* The OAI-PMH NASA technical report server
#@ Micheal L. Nelson;JoAnne R. Calhoun;Calvin E. Mackey
#t 2004
#c 14
#% 332742
#! The NASA Technical Report Server (NTRS) is now based on the Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH). This metadata harvesting version of NTRS represents a significant improvement over the previous distributed searching implementation of NTRS. In addition to being an OAI-PMH service provider, the new version of NTRS is also an OAI-PMH aggregator. This allows NTRS to serve as a one-stop shop for harvesting of NASA metadata.

#index 760907
#* Scholars portal: beyond simple metasearch
#@ Krisellen Maloney;John R. James
#t 2004
#c 14
#! The Scholars Portal Project is a collaborative venture joining seven ARL Libraries and a software vendor to develop an integrated web--based system that will connect researchers, instructors and students with appropriate, vetted information resources. The Project's initial focus has been on the meta--search discovery" and direct linking "delivery" tools that provide the software and metadata foundation for the Scholars Portal This paper will provide the current progress of implementation and plans for the future".

#index 760908
#* Sharing culture shock through a collection of experiences
#@ Babatunde Azeez;Andruid Kerne;Joseph Southern;Bridgette Summerfield;Isaac Aholu;Eshita Sharmin
#t 2004
#c 14
#! Culture shock and cultural adaptation are phenomena that international students experience, while crossing boundaries On their arrival to the U.S. displaced students from the Third World often feel isolated, afraid, inferior, and insecure. Digital collections can serve as a medium for sharing sensations and experiences. They can help overcome the sense of isolation and culture shock, by illustrating to an individual how others have similar experiences We are building a digital collection to support this exchange of experiences In collecting experiences, we found that first person ethnographic interviews are more effective as a method for data collection, when they are conducted with a sense of informality Woezor, a prototype system, was developed to structure and present these collections, using the Greenstone digital libraries software.

#index 760909
#* Tools and techniques for harvesting the world wide web
#@ J. L. Marill;A. Boyko;M. Ashenfelder;L. Graham
#t 2004
#c 14
#! Recently the Library of Congress began developing a strategy for the preservation of digital content. Efforts have focused on the need to select, harvest, describe, access and preserve Web resources. This poster focuses on the Library's initial investigation and evaluation of Web harvesting software tools.

#index 760910
#* Toolkits for visualizing co-authorship graph
#@ Xiaoming Liu;Johan Bollen;Michael L. Nelson;Herbert Van de Sompel;Jeremy Hussell;Rick Luce;Linn Marks
#t 2004
#c 14
#! Visualization eases insight into complex systems such as co-authorship networks. We present an initial deployment of an author navigator application for convenient visual examination of JCDL and LANL co--authorship networks.

#index 760911
#* Towards a unified framework for assessing the complexity of digital libraries
#@ Christine Dufour;Pierrette Bergeron
#t 2004
#c 14
#% 657317
#! This poster presents a unified Web information system (WIS) framework developed to study the impact of WIS introduction on a digital" organization's information environment. As digital libraries can be seen as information systems and are often based on Web technologies we suggest that this framework is also useful to assess their complexity".

#index 760912
#* Toward melodic access and title uniformity in the chopin early editions music digital library
#@ J. S. Downie;T. Olson
#t 2004
#c 14
#% 309101

#index 760913
#* Usability of digital libraries: an evaluation model
#@ Judy H. Jeng
#t 2004
#c 14
#! This research proposes methods and instruments for assessing usability of academic digital libraries. Criteria in this study are effectiveness, efficiency, satisfaction, and learnability. It is found that there exist interlocking relationships among effectiveness, efficiency, and satisfaction.

#index 760914
#* Using digital library components for biodiversity systems
#@ Ricardo da Silva Torres;Claudia Bauzer Medeiros;Renata Queiroz Dividino;Mauricio Augusto Figueiredo;Marcos Andre Goncalves;Edward A. Fox;Ryan Richardson
#t 2004
#c 14
#% 716459
#! Biodiversity information systems (BISs) involve all kinds of heterogeneous data, which include ecological and geographical features However, available information systems offer very limited support for managing such data in an integrated fashion, and such integration is often based on geographic coordinates alone. Furthermore, such systems do not fully support image content management (e.g. photos of landscapes or living organisms), a requirement of many BIS end--users. In order to meet their needs, these users -- e.g. biologists, environmental experts -- often have to alternate between distinct biodiversity and image information systems to combine information extracted from them. This cumbersome operational procedure is forced on users by lack of interoperability among these systems. This hampers the addition of new data sources, as well as cooperation among scientists. The approach provided in this project to meet these issues is based on taking advantage of advances in Digital Library (DL) innovations to integrate networked collections of heterogeneous data. It focuses on creating the basis for a biodiversity information system under the digital library perspective, combining new techniques of content--based image retrieval and database query processing mechanisms. This approach solves the problem of system switching, and provides users with a flexible platform from which to tailor a BIS to their needs. The main contributions of this project are the following: (a) a generic architecture for managing heterogeneous collections, based ondigital library components, to access heterogeneous biodiversity data sources (text and images), that allows combining text--based andcontent--based queries in a seamless way; and (b) a new component, for content--based image search, integrated into that architecture. The proposed architecture has been implemented by using DL components which are mostly new or recently developed. Furthemore, its implementation uses the Open Archives Initiative (OAI) protocol as a basis for interoperability. This architecture is easily extensible, and provides users a considerable degree of flexibility in data management. To illustrate our claim that this architecture can be applied to several domains, we are investigating its application in building a biodiversity information system on fish species. This solution solves many current problems in this kind of system, allowing handling of images and textual information in an integrated fashion. A new Content-Based Image Search Component has been developed to support queries on image collections. Since this component is based onthe OAI principles, it provides an easy-to-install search engine toquery images by content. It can be readily tailored for a particular collection by a trained designer, who carries out a clearly definedset of pilot experiments. It supports the use of different image descriptors, which can be chosen from the pilot experiment, and theneasily combined to yield improved effectiveness. In addition, it encapsulates a multidimensional index structure to speed up the search process, that also can be easily configured for different image collections.

#index 760915
#* The University of North Texas libraries' portal to Texas history: archival challenges and solutions
#@ K. E. Nordstrom;C. N. Hartman;M. Phillips
#t 2004
#c 14
#! The UNT Texas History Portal Project strives to balance the goals of accessibility of information and long--term preservation of digital objects. This poster details the system that automates the collection of metadata records to coordinate access to web--viewable files and preservation of archived master files.

#index 760916
#* The Alexandria Digital Library and the alexandria digital earth prototype
#@ Michael Freeston
#t 2004
#c 14
#% 337246
#! The Alexandria Digital Library, together with its follow-on -- the Alexandria Digital Earth Prototype Project -- is one of the flagship projects of the NSF/NASA/ Digital Library Initiative Uniquely among these projects, ADL is a georeferenced library i.e. a library in which the principal mode of access to information is by specifying the location of the information on the surface of the Earth. The most immediate application of this technology is in support of a library of maps, aerial photographs and remote sensing images, and ADL is now run as an operational service by UCSB's Map and Image Library, one of the largest such libraries in the US.But the longer term objective is to provide georeferenced search as an alternative way of accessing conventional libraries i.e. libraries of textual information With the aid of a natural language parser and the ADL gazetteer, the locations (lat, long) of places named in a text can be identified This functionality offers a quantum leap in information retrieval performance in the many cases in which locational information is involved For example, it becomes possible to discover documents about California, even if the name California" does not appear explicitly in the text. It also offers a foundation technology for the concept of the Digital Earth able to answer questions such as: "What information do you have about this place?The primary focus of the ADEPT project, however, is on the development of digital learning environments (DLEs) for undergraduate education There are two particularly innovative strands to this research: first the use of digital library technology to provide curated learning and teaching resources for the DLEs; and second a pedagogic approach based on an explicit concept model of the chosen field of study ADEPT has naturally chosen Geography as the experimental field of study but the approach is quite general and could be applied to any other field A first course using this approach was given at UCSB in Fall 2003".

#index 760917
#* Building metadata-based navigation using semantic web standards: the Dublin Core 2003 conference proceedings
#@ Bradley P. Allen;Joseph T. Tennis
#t 2004
#c 14
#! One of the touted benefits of the Semantic Web is that it will make searches more precise and efficient by leveraging metadata about web--delivered content. Faceted metadata retrieval is an approach to providing users access to large collections of semi--structured data and content that promises an improvement in usability over that available using more traditional search methods. In this demonstration we illustrate how the on--line proceedings for the 2003 Dublin Core Conference were implemented by combining traditional and innovative knowledge organization techniques. The 2003 Dublin Core Conference Proceedings served as a test--bed for generating a faceted metadata retrieval interface from instance metadata, ontologies, and controlled vocabularies expressed in RDF and RDF Schema. We share lessons learned in the design and implementation of the proceedings, and in particular focus on emerging best practices for representing and sharing metadata using Dublin Core Metadata recommendations, new interpretations of traditional Library and Information Science information retrieval techniques, and implementations of Semantic Web standards.

#index 760918
#* Digital library access via image similarity search
#@ D. C. Heesch;M. J. Pickering;P. Howarth;A. Yavlinsky;S. M. Rueger
#t 2004
#c 14
#! We present an image library with similarity--based searching and novelbrowsing structures and a news video library with content--based search andsummarisation features.

#index 760919
#* eLibrary and ARTE: two opendlib digital libraries
#@ Donatella Castelli;Pasquale Pagano;Manuele Simi
#t 2004
#c 14
#% 508284
#% 614080
#! This demonstration shows two experimental digital libraries, e--Library and ARTE, which have been built by configuring appropriately the OpenDLib digital library system and then acquiring content with different approaches. Through these DLs we intend to demonstrate the capability of the OpenDLib system to be exploited in different application contexts.

#index 760920
#* ETANA-DL: managing complex information applications -- an archaeology digital library
#@ Unni Ravindranathan;Rao Shen;Marcos Andre Goncalves;Weiguo Fan;Edward A. Fox;James W. Flanagan
#t 2004
#c 14
#% 716459
#% 750866
#! Archaeological research results in the generation of large quantities of heterogeneous information managed by different projects using custom information systems. We will demonstrate a prototype Digital Library (DL) for integrating and managing archaeological data and providing services useful to various user communities ETANA--DL is a model--based, componentized, extensible, archaeological DL that manages complex information sources using the client--server paradigm of the Open Archives Initiative Protocol for Metadata Harvesting (OAI--PMH).

#index 760921
#* Geographic information retrieval (GIR) ranking methods for digital libraries
#@ Ray R. Larson;Patricia Frontiera
#t 2004
#c 14
#! This demo will presents results from an evaluation of algorithms forranking results by probability of relevance for Geographic Information Retrieval (GIR) applications. We will demonstrate an algorithm for GIR ranking based on logistic regression from samples of the test collection We also show the effects of different representations of the geographic regions being searched, including minimumbounding rectangles, convex hulls, and complex polygons.

#index 760922
#* Greenstone digital library software: current research
#@ David Bainbridge;Ian H. Witten
#t 2004
#c 14
#! The Greenstone digital library software (www.greenstone.org)provides a flexible way of organizing information and publishing it on the Internet or removable media such as CDROM. Its aim is to empower users, particularly in universities, libraries and other public service institutions, to build their own digital libraries. It is open-source software, issued under the terms of the GNU General Public License. It isproduced by the New Zealand Digital Library Project atthe University of Waikato, and developed and distributed incooperation with UNESCO and the Human Info NGO.

#index 760923
#* Mobile image capture and management
#@ Michael A. Smith;Andy Choi;Serge Aublant
#t 2004
#c 14

#index 760924
#* An OAI compliant content-based image search component
#@ Ricardo da Silva Torres;Claudia Bauzer Medeiros;Marcos Andre Goncalves;Edward A. Fox
#t 2004
#c 14
#% 479462
#! Advances in data storage and image acquisition technologies haveenabled the creation of large image datasets In order to deal withthese data, appropriate information systems (e.g. image digital libraries) have been developed to efficiently manage such collections. One of the most common retrieval approaches is to employ so--called Content--Based Image Retrieval (CBIR) systems. Basically, these systems try to retrieve images similar to auser--defined pattern (e.g. image example). Their goal is to supportimage retrieval based on content properties (e.g. shape, color, or texture), which are often encoded in terms of imagedescriptors This demonstration presents a new CBIR system based on configurable components. The main novelty resides in its Content--Based ImageSearch Component (CBISC) that supports queries on image collections CBISC is based on the OAIprinciples, and thus provides an easy--to--install search engine tosupport querying images by content As with the OAI protocol, queriesare posed via HTTP requests and the responses are encoded in XML CBISC encapsulates multidimensional indexstructures to speed up the searchprocess. Furthermore, it supports the use of different imagedescriptors (metric and non--metric; color, texture, and shapedescriptors; with 1D or 2D feature vectors), which canbe easily combined to yield improved effectiveness. We will show thatthis search component can be tailored for particular image collectionsby a trained designer, who carries out a clearly defined set of pilot experiments to select the appropriate descriptors. Image descriptors are typically domain and usage--dependent Further, agiven image can be associated with very many descriptors However, standard CBIR methods only support a fixed set of descriptors CBISC, instead, allows progressive extension of thedescriptor base Figure 1 presents a screen shotshowing the CBISC Configuration Tool developed to support CBISC designers in the configuration process Basically, this processconcerns the description/definition of both the image descriptors thatwill be used to retrieve images by content, and the image database to which the CBISC is related The XML file generated in thisprocess is used during CBISC execution.

#index 760925
#* OCLC digital archive demonstration
#@ Leah Houser
#t 2004
#c 14
#! The demonstration shows the functionality of OCLC's new Digital Archive, which became publicly available in September 2002. This system is an implementation of the ISO Reference Model for an Open Archival Information System (OAIS). This product uses an implementation of the OCLC/RLG Preservation Metadata element set, tailored for web documents Front--end workflow and harvester components allow users to archive web content.

#index 760926
#* Services for a customizable authority linking environment
#@ M. S. Patton;D. M. Mimno
#t 2004
#c 14
#! The SCALE -- Services for a Customizable Authority Linking Environment-- project is developing tools to help integrate collections within the National Science Foundation's National Science Digital Library(NSDL) through terminological linking. These tools will transparentlyprovide reading support to NSDL collections by automatically linkingphrases in the content of one collection to relevant material in another collection. This will enhance the user experience in the NSDL and encourage greater integration of collections by increasing thevalue of each collection to other collections.

#index 760927
#* Using digital libraries to build educational communities: the chemcollective
#@ David Yaron;Michael Karabinos;Gaea Leinhardt
#t 2004
#c 14
#! The ChemCollective is a new project in the targeted research track of the National Science Digital Library (NSDL). The project (http://www chemcollective org) was launched in spring 2004 at the National American Chemical Society (ACS) and National Science Teachers Association (NSTA) meetings. The research goal is to explore the degree to which digital library structures can attract and support a community of educators working towards a common vision of educational reform.

#index 760928
#* Variations2: improving music findability in a digital library through work--centric metadata
#@ Mark Notess;Jon Dunn
#t 2004
#c 14
#% 378499
#! The Variations2 Indiana University Digital Music Library is a large test-bed project funded in part by Phase 2 of the Digital Libraries Initiative, with support from the National Science Foundation and the National Endowment for the Humanities. This demonstration will show the current state of the Variations2 test-bed software, focusing on the search user interface.

#index 760929
#* Visiting virtual reality museum exhibits
#@ Bradley M. Hemminger;Gerald Bolus;Doug Schiff
#t 2004
#c 14
#! Virtual museums provide ways to capture the content of a real museum in a digital (electronic) form and make this digital form more universally available. This exhibit demonstrates a novel method for digitally recording entire museum exhibits and allowing them to be explored in virtual reality. The methodology allows anyone with access to the Internet or a PC to experience anywhere, anytime, any part of the museum's collection or exhibits (past, present and future). Users can explore the museum exhibits in a virtual reality that is both spatially accurate and visually compelling. All objects and 3D scenes are seen in precise full color photographic quality detail. The scene and objects are polygonal meshes representing the surfaces of objects as recorded by a laser range finder. This permits making measurements directly on the scene with millimeter precision. The methodology, its application to capturing museum exhibits, and examples of exhibits recorded using this technique are demonstrated on a laptop PC. Visitors to the demonstration will be able to: Learn about the process of digitizing 3D environments like museum exhibits and creating virtual reality environments from them; Place themselves in one of three virtual reality exhibits and explore the multiple rooms and artifacts comprising the exhibits (Ackland Art Museum, living room, Clue murder scene).

#index 760930
#* Zoomable user interface for in-depth reading
#@ Eric Bier;Kris Popat;Lance Good;Alan Newberger
#t 2004
#c 14
#% 731013
#% 760832
#! The Instant Bookplex system includes a zoomable user interface (ZUI) for navigating through a spatial representation of a document collection. This ZUI supports extended reading in the collection using semantic zooming, graphical presentation of metadata, animated transitions, and an integrated reading tool It helps users find and re-find documents, choose good documents to read next, and navigate between documents.

#index 809401
#* Proceedings of the 5th ACM/IEEE-CS joint conference on Digital libraries
#@ Mary Marlino;Tamara Sumner;Frank Shipman
#t 2005
#c 14
#! Welcome to JCDL 2005. The ACM/IEEE Joint Conference on DigitalLibraries (JCDL) is a major international forum that focuses ondigital libraries and associated educational, technical and socialissues. The theme of JCDL 2005 highlights the powerful role ofdigital libraries as cyberinfrastructure.We received over 270 submissions this year (a new record), andthe resulting program reflects the high quality of research beingconducted on digital libraries in many disciplines. From 105 fullpapers and 80 short papers, the Program Committee selected 33 longpapers and 26 short papers for presentation and inclusion in theconference proceedings. To provide a conceptual framework, thepresentations and panels comprising the technical program have beenorganized into three tracks:Digital Libraries and Cyberinfrastructure Track: These sessionshighlight the rich variety of roles that digital libraries continueto play in transforming research and education within the sciencesand the humanities. Sessions also focus on issues associated withbuilding digital libraries to transform practice in theseareas.Users and Interaction Track: These sessions focus onunderstanding user needs, how people work and learn with digitallibrary technologies, and how innovative user interfaces andinteraction mechanisms can help people to better use and comprehenddigital library resources, collections, and services.Tools and Techniques Track: These sessions focus on newarchitectures and frameworks for building digital libraries, aswell as discussing emerging algorithms and techniques for improvinginformation retrieval, automatic approaches for resource andcollection characterization, and applications of machine learningto a rich variety of digital library problems.Each day of the conference includes a keynote address thatprovides context for and furthers the dialog about the role ofdigital libraries within the evolving framework of a nationalcyberinfrastructure.JCDL 2005 continues the tradition of supportingdigital library developers with eight tutorials that cover a rangeof important and timely issues including building and evaluatingdigital libraries and examining how ontologies, interoperabilityapproaches, standards, copyright and preservation are applied indeveloping and scaling digital libraries. The program also includesfive workshops, which provide a venue for a cross-section ofdisciplines to explore focused, cutting-edge topics such asinternational scientific data and standards; socio-technicalapproaches to evaluating digital libraries; providing contexts forlearning in educational digital libraries; and preparing libraryprofessionals to work in a digital library environment.JCDL 2005 continues the tradition of supporting digital librarydevelopers with eight tutorials that cover a range of important andtimely issues including building and evaluating digital librariesand examining how ontologies, interoperability approaches,standards, copyright and preservation are applied in developing andscaling digital libraries. The program also includes fiveworkshops, which provide a venue for a cross-section of disciplinesto explore focused, cutting-edge topics such as internationalscientific data and standards; socio-technical approaches toevaluating digital libraries; providing contexts for learning ineducational digital libraries; and preparing library professionalsto work in a digital library environment.The One-Minute Madness session provides a brief overview of 41posters and 15 demonstrations, which can be viewed during theposter reception and whose abstracts are included here. At the endof the reception, the Best Poster Award, sponsored by theUniversity of Arizona, will be presented.The following awards will be presented during the ConferenceBanquet, to be held at the Denver Museum of Nature &Science:Vannevar Bush Best Paper Award(sponsored by ACM)Best Student Paper Award(sponsored by IEEE-CS Technical Committee on DigitalLibraries)Best International Paper Award(sponsored by the University ofArizona)..

#index 809402
#* You can lead a horse to water: teacher development and use of digital library resources
#@ Mimi Recker;Jim Dorward;Deonne Dawson;Sam Halioris;Ye Liu;Xin Mao;Bart Palmer;Jaeyang Park
#t 2005
#c 14
#% 228328
#% 332756
#% 364906
#% 378511
#% 378539
#% 614070
#% 760822
#% 760842
#% 760902
#! This article presents findings from approximately 150 users who created instructional projects using educational digital library resources. One hundred of these users were teachers participating in professional development workshops on the topic of digital libraries. Our iterative approach to tool and workshop development and implementation was based on a framework that characterizes several input, output, and process variables affecting dissemination of such technologies in educational contexts. Data sources involved a mix of qualitative and quantitative methods, including electronic surveys, interviews, participant observations, and server log file and artifact analyses. These multiple and complementary levels of analyses reveal that despite teachers reporting great value in learning resources and educational digital libraries, significant and lasting impact on teaching practice remains difficult to obtain.

#index 809403
#* Comprehensive personalized information access in an educational digital library
#@ Peter Brusilovsky;Rosta Farzan;Jae-wook Ahn
#t 2005
#c 14
#% 234793
#% 314733
#% 333674
#% 337230
#% 378511
#% 677644
#% 757157
#% 757159
#% 1214032
#! This paper explores two ways to help students locate most relevant resources in educational digital libraries. One method gives a more comprehensive access to educational resources, through multiple pathways of information access, including browsing and information visualization. The second method is to access personalized information through social navigation support. This paper presents the details of the Knowledge Sea II system for comprehensive personalized access to educational resources and also presents the results of a classroom study. The study delivered a convincing argument for the importance of providing multiple information presentations modes, showing that only about 10% of all resource accesses were made through the traditional search interface. We have also collected some solid evidence in favor of the social navigation support.

#index 809404
#* Facilitating middle school students' sense making process in digital libraries
#@ Meilan Zhang;Chris Quintana
#t 2005
#c 14
#% 752119
#! Previous research on using digital libraries in science classrooms indicated that middle school students tend to passively find answers rather than actively make sense of information they find in digital libraries. In response to this challenge, we designed a scaffolded software tool, the Digital IdeaKeeper, to support middle school students in making sense of digital library resources during online inquiry. This study describes preliminary results from a study to see how middle school students use different IdeaKeeper features. Initial data analysis indicates that IdeaKeeper can facilitate online learners to engage in sense-making process in online inquiry.

#index 809405
#* Evaluating G-portal for geography learning and teaching
#@ Chew-Hung Chang;John G. Hedberg;Yin-Leng Theng;Ee-Peng Lim;Tiong-Sa Teh;Dion Hoe-Lian Goh
#t 2005
#c 14
#% 378546
#% 790700
#! This paper describes G-Portal, a geospatial digital library of geographical assets, providing an interactive platform to engage students in active manipulation and analysis of information resources and collaborative learning activities. Using a G-Portal application in which students conducted a field study of an environmental problem of beach erosion and sea level rise, we describe a pilot study to evaluate usefulness and usability issues to support the learning of geographical concepts, and in turn teaching.

#index 809406
#* A new framework for building digital library collections
#@ George Buchanan;David Bainbridge;Katherine J. Don;Ian H. Witten
#t 2005
#c 14
#% 281480
#% 290703
#% 294891
#% 301263
#% 337493
#% 489725
#% 508276
#% 508404
#% 645984
#! This paper introduces a new framework for building digital library collections and contrasts it with existing systems. It describes a significant new step in the development of a widely-used open-source digital library system, Greenstone, which has evolved over many years. It is supported by a fresh implementation, which forced us to rethink the entire design rather than making incremental improvements. The redesign capitalizes on the best ideas from the existing system, which have been refined and developed to open new avenues through which digital librarians can tailor their collections. We demonstrate its flexibility by showing how digital library collections can be extended and altered to satisfy new requirements.

#index 809407
#* Using collection descriptions to enhance an aggregation of harvested item-level metadata
#@ Muriel Foulonneau;Timothy W. Cole;Thomas G. Habing;Sarah L. Shreeves
#t 2005
#c 14
#% 319875
#% 378504
#% 801839
#% 1069048
#! As an increasing number of digital library projects embrace the harvesting of item-level descriptive metadata, issues of description granularity and concerns about potential loss of context when harvesting item-level metadata take on greater significance. Collection-level description can provide valuable context for item-level metadata records harvested from disparate and heterogeneous providers. This paper describes an ongoing experiment using collection-level description in concert with item-level metadata to improve quality of search and discovery across an aggregation of metadata describing resources held by a consortium of large academic research libraries. We present details of approaches implemented so far and preliminary analyses of the potential utility of these approaches. The paper concludes with a brief discussion of related issues and future work plans.

#index 809408
#* A web service framework for embedding discovery services in distributed library interfaces
#@ John Weatherley
#t 2005
#c 14
#! Significant barriers deter web page designers and developers from incorporating dynamic content from web services into their page designs. Web services typically require designers to learn service protocols and have access to and knowledge of dynamic application servers or CGI in order to incorporate dynamic content into their pages. This paper describes a framework for embedding discovery services in distributed interfaces that seeks to simplify this process and eliminate these barriers, making the use of the dynamic content available to a wider audience and increasing its potential for adoption and use in educational design.

#index 809409
#* xTagger: a new approach to authoring document-centric XML
#@ Ionut E. Iacob;Alex Dekhtyar
#t 2005
#c 14
#% 772033
#! The process of authoring document-centric XML documents in humanities disciplines is very different from the approach espoused by the standard XML editing software with the data-centric view of XML. Where data-centric XML is generated by first describing a tree structure of the encoding and then providing the content for the leaf elements, document-centric encodings start with content which is then marked up. In the paper we describe our approach to authoring document-centric XML documents and the tool, xTagger, originally developed for this purpose within the Electronic Boethius project [2], otherwise enhanced within the ARCHway project [5], an interdisciplinary project devoted to development of methods and software for preparation of image-based electronic editions of historic manuscripts.

#index 809410
#* Enhancing access to research data: the challenge of crystallography
#@ Monica Duke;Michael Day;Rachel Heery;Leslie A. Carr;Simon J. Coles
#t 2005
#c 14
#% 246341
#% 1069035
#! This paper describes an ongoing collaborative effort across digital library and scientific communities in the UK to improve access to research data. A prototype demonstrator service supporting the discovery and retrieval of detailed results of crystallography experiments has been deployed within an Open Archives digital library service model. Early challenges include the understanding of requirements in this specialized area of chemistry and reaching consensus on the design of a metadata model and schema. Future plans encompass the exploration of commonality and overlap with other schemas and across disciplines, working with publishers to develop mutually beneficial service models, and investigation of the pedagogical benefits. The potential improved access to experimental data to enrich scholarly communication from the perspective of both research and learning provides the driving force to continue exploring these issues.

#index 809411
#* Information synthesis: a new approach to explore secondary information in scientific literature
#@ Catherine Blake
#t 2005
#c 14
#% 761645
#! Advances in both technology and publishing practices continue to increase the quantity of scientific literature that is available electronically. In this paper, we introduce the Information Synthesis process, a new approach that enables scientists to visualize, explore, and resolve contradictory findings that are inevitable when multiple empirical studies explore the same natural phenomena. Central to the Information Synthesis approach is a cyber-infrastructure that provides a scientist with both primary and secondary information from an article and structured information resources. To demonstrate this approach, we have developed the Multi-User, Information Extraction for Information Synthesis (METIS) System. METIS is an interactive system that automates critical tasks within the Information Synthesis process. We provide two case-studies that demonstrate the utility of the Information Synthesis approach.

#index 809412
#* Comparative interoperability project: configurations of community, technology, organization
#@ David Ribes;Karen S. Baker;Florence Millerand;Geoffrey C. Bowker
#t 2005
#c 14
#% 791959
#% 1075810
#! In this paper we describe the methods, goals and early findings of the research endeavor 'Comparative Interoperability Project' (CIP). The CIP is an extended interdisciplinary collaboration of information and social scientists with the shared goal of understanding the diverse range of interoperability strategies within information infrastructure building activities. We take interoperability strategies to be the simultaneous mobilization of community, organizational and technical resources to enable data integration. The CIP draws together work with three ongoing collaborative scientific projects (GEON, LTER, Ocean Informatics) that are building information infrastructures for the natural sciences.

#index 809413
#* Visualizing aggregated biological pathway relations
#@ Byron Marshall;Karin Quiñones;Hua Su;Shauna Eggers;Hsinchun Chen
#t 2005
#c 14
#% 763874
#% 832960
#! The Genescene development team has constructed an aggregation interface for automatically-extracted biomedical pathway relations that is intended to help researchers identify and process relevant information from the vast digital library of abstracts found in the National Library of Medicine's PubMed collection. Users view extracted relations at various levels of relational granularity in an interactive and visual node-link interface. Anecdotal feedback reported here suggests that this multi-granular visual paradigm aligns well with various research tasks, helping users find relevant articles and discover new information.

#index 809414
#* Addressing the challenge of visual information access from digital image and video libraries
#@ Michael G. Christel;Ronald M. Conescu
#t 2005
#c 14
#% 170383
#% 262089
#% 318785
#% 420476
#% 452641
#% 452642
#% 522598
#% 560984
#% 614038
#% 614047
#% 780761
#% 780821
#% 780829
#% 789793
#% 895004
#! While it would seem that digital video libraries should benefit from access mechanisms directed to their visual contents, years of TREC Video Retrieval Evaluation (TRECVID) research have shown that text search against transcript narrative text provides almost all the retrieval capability, even with visually oriented generic topics. A within-subjects study involving 24 novice participants on TRECVID 2004 tasks again confirms this result. The study shows that satisfaction is greater and performance is significantly better on specific and generic information retrieval tasks from news broadcasts when transcripts are available for search. Additional runs with 7 expert users reveal different novice and expert interaction patterns with the video library interface, helping explain the novices' lack of success with image search and visual feature browsing for visual information needs. Analysis of TRECVID visual features well suited for particular tasks provides additional insights into the role of automated feature classification for digital image and video libraries.

#index 809415
#* Assessing tools for use with webcasts
#@ Elaine G. Toms;Christine Dufour;Jonathan Lewis;Ron Baecker
#t 2005
#c 14
#% 243752
#% 247287
#% 280811
#% 281362
#% 297556
#% 297558
#% 337454
#% 341270
#% 378560
#% 438054
#% 614060
#% 732858
#% 760824
#% 773038
#% 802703
#! This research assessed the effectiveness of selected interface tools in helping people respond to classic information tasks with webcasts. Rather than focus on a classic search/browse task to locate an appropriate webcast to view, our work takes place at the level of an individual webcast to assess interactivity within the contents of a single webcast. The questions guiding our work are: 1) Which tool(s) are the most effective in achieving the best response? 2) How do users use those tools for task completion? In this study, 16 participants responded to a standard set of information tasks using ePresence, a webcasting system that handles both live and stored video, and provides multiple techniques for accessing content. Using questionnaires, screen capture and interviews, we evaluated the interaction, assessed the tools, and based on our results, make suggestions for improving access to the content of stored webcasts.

#index 809416
#* Exploring user perceptions of digital image similarity
#@ Unmil P. Karadkar;Richard Furuta;Jeevan Joseph John;Jin-Cheon Na
#t 2005
#c 14
#% 415109
#% 420581
#% 769115
#! The MIDAS project is developing infrastructure and policies for optimal display of digital information on devices with diverse characteristics. In this paper we present the preliminary results of a study that explored the effects of scaling and color-depth variation in digital photographs on user perceptions of similarity. Our results indicate general trends in user preferences and can serve as guidelines for designing policies and systems that display digital images optimally on various information devices.

#index 809417
#* Detecting and supporting known item queries in online public access catalogs
#@ Min-Yen Kan;Danny C. C. Poo
#t 2005
#c 14
#% 85443
#% 252472
#% 267755
#% 290482
#% 305902
#% 323131
#% 349286
#% 642992
#% 754059
#% 815902
#% 816178
#! When users seek to find specific resources in a digital library, they often use the library catalog to locate them. These catalog queries are defined as known item queries. As known item queries search for specific resources, it is important to manage them differently from other search types, such as area searches. We study how to identify known item queries in the context of a large academic institution's online public access catalog (OPAC), in which queries are issued via a simple keyword interface. We also examine how to recognize when a known item query has retrieved the item in question. Our approach combines techniques in machine learning, language modeling and machine translation evaluation metrics to build a classifier capable of distinguishing known item queries and correctly classifies titles for whether they are the known item sought with an 80% and 95% correlation to human performance, respectively on each task. To our knowledge, this is the first report of such work, which has the potential to streamline the user interface of both OPACs and digital libraries in support of known item searches.

#index 809418
#* Downloading textual hidden web content through keyword queries
#@ Alexandros Ntoulas;Petros Zerfos;Junghoo Cho
#t 2005
#c 14
#% 255137
#% 261741
#% 268114
#% 273926
#% 300176
#% 333932
#% 337235
#% 340146
#% 378527
#% 410276
#% 480479
#% 607815
#% 654459
#% 754058
#% 993964
#! An ever-increasing amount of information on the Web today is available only through search interfaces: the users have to type in a set of keywords in a search form in order to access the pages from certain Web sites. These pages are often referred to as the Hidden Web or the Deep Web. Since there are no static links to the Hidden Web pages, search engines cannot discover and index such pages and thus do not return them in the results. However, according to recent studies, the content provided by many Hidden Web sites is often of very high quality and can be extremely valuable to many users.In this paper, we study how we can build an effective Hidden Web crawler that can autonomously discover and download pages from the Hidden Web. Since the only "entry point" to a Hidden Web site is a query interface, the main challenge that a Hidden Web crawler has to face is how to automatically generate meaningful queries to issue to the site. Here, we provide a theoretical framework to investigate the query generation problem for the Hidden Web and we propose effective policies for generating queries automatically. Our policies proceed iteratively, issuing a different query in every iteration. We experimentally evaluate the effectiveness of these policies on 4 real Hidden Web sites and our results are very promising. For instance, in one experiment, one of our policies downloaded more than 90% of a Hidden Web site (that contains 14 million documents) after issuing fewer than 100 queries.

#index 809419
#* SpidersRUs: automated development of vertical search engines in different domains and languages
#@ Michael Chau;Jialun Qin;Yilu Zhou;Chunju Tseng;Hsinchun Chen
#t 2005
#c 14
#% 176502
#% 301247
#% 340141
#% 979688
#! In this paper we discuss the architecture of a tool designed to help users develop vertical search engines in different domains and different languages. The design of the tool is presented and an evaluation study was conducted, showing that the system is easier to use than other existing tools.

#index 809420
#* Grid-based digital libraries: cheshire3 and distributed retrieval
#@ Ray R. Larson;Robert Sanderson
#t 2005
#c 14
#% 206512
#% 760777
#! The University of California, Berkeley and the University of Liverpool are developing a Information Retrieval and Digital Library system (Cheshire3) that operates in both single-processor and "Grid" distributed computing environments. This paper discusses the architecture of the system and how it performs Digital Library tasks in a Grid computing environment.

#index 809421
#* Integrating digital libraries and electronic publishing in the DART project
#@ Gordon Dahlquist;Brian Hoffman;David Millman
#t 2005
#c 14
#! The Digital Anthropology Resources for Teaching (DART) project integrates the content acquisition and cataloging initiatives of a federated digital repository with the development of scholarly publications and the creation of digital tools to facilitate classroom teaching. The project's technical architecture and unique publishing model create a teaching context where students move easily between primary and secondary source material and between authored environments and independent research, and raise specific issues with regard to metadata, object referral, rights, and exporting content. The model also addresses the loss of provenance and catalog information for digital objects embedded in "born-digital" publications. The DART project presents a practical methodology to combine repository and publication that is both exportable and discipline-neutral.

#index 809422
#* Annotating illuminated manuscripts: an effective tool for research and education
#@ Maristella Agosti;Nicola Ferro;Nicola Orio
#t 2005
#c 14
#% 64900
#% 86375
#% 151693
#% 173670
#% 211513
#% 230519
#% 237318
#% 245819
#% 249090
#% 296047
#% 330770
#% 345362
#% 379567
#% 508271
#% 508421
#% 755035
#% 755042
#% 760875
#% 770451
#% 792821
#% 1677428
#% 1719581
#! The aim of this paper is to report the research results of an ongoing project that deals with the exploitation of a digital archive of drawings and illustrations of historic documents for research and educational purposes. According to the results on a study of user requirements, we have designed tools to provide researchers with innovative ways for accessing the digital manuscripts, sharing, and transferring knowledge in a collaborative environment. We have found that the results of scientific research on the relationships between images of manuscripts produced over the centuries can be rendered explicit by using annotations. For this purpose, a taxonomy for linking annotation is introduced, together with a conceptual schema which represents annotations and links them to digital objects.

#index 809423
#* A generic alerting service for digital libraries
#@ George Buchanan;Annika Hinze
#t 2005
#c 14
#% 124004
#% 301253
#% 337487
#% 466290
#% 504879
#% 508414
#% 543874
#% 631927
#% 645984
#% 760821
#% 769143
#% 836019
#% 978507
#! Users of modern digital libraries (DLs) can keep themselves up-to-date by searching and browsing their favorite collections, or more conveniently by resorting to an alerting service. The alerting service notifies its clients about new or changed documents. Proprietary and mediating alerting services fail to fluidly integrate information from differing collections. This paper analyses the conceptual requirements of this much-sought after service for digital libraries. We demonstrate that the differing concepts of digital libraries and its underlying technical design has extensive influence (a) the expectations, needs and interests of users regarding an alerting service, and (b) on the technical possibilities of the implementation of the service. Our findings will show that the range of issues surrounding alerting services for digital libraries, their design and use is greater than one may anticipate. We also show that, conversely, the requirements for an alerting service have considerable impact on the concepts of DL design. Our findings should be of interest for librarians as well as system designers. We highlight and discuss the far-reaching implications for the design of, and interaction with, libraries. This paper discusses the lessons learned from building such a distributed alerting service. We present our prototype implementation as a proof-of-concept for an alerting service for open DL software.

#index 809424
#* Link prediction approach to collaborative filtering
#@ Zan Huang;Xin Li;Hsinchun Chen
#t 2005
#c 14
#% 730089
#% 734593
#! Recommender systems can provide valuable services in a digital library environment, as demonstrated by its commercial success in book, movie, and music industries. One of the most commonly-used and successful recommendation algorithms is collaborative filtering, which explores the correlations within user-item interactions to infer user interests and preferences. However, the recommendation quality of collaborative filtering approaches is greatly limited by the data sparsity problem. To alleviate this problem we have previously proposed graph-based algorithms to explore transitive user-item associations. In this paper, we extend the idea of analyzing user-item interactions as graphs and employ link prediction approaches proposed in the recent network modeling literature for making collaborative filtering recommendations. We have adapted a wide range of linkage measures for making recommendations. Our preliminary experimental results based on a book recommendation dataset show that some of these measures achieved significantly better performance than standard collaborative filtering algorithms.

#index 809425
#* Sentiment-based search in digital libraries
#@ Jin-Cheon Na;Christopher S. G. Khoo;Syin Chan;Norraihan Bte Hamzah
#t 2005
#c 14
#% 337521
#% 755835
#% 766433
#! Several researchers have developed tools for classifying/ clustering Web search results into different topic areas (such as sports, movies, travel, etc.), and to help users identify relevant results quickly in the area of interest. This study follows a similar approach, but is in the area of sentiment classification -- automatically classifying on-line review documents according to the overall sentiment expressed in them. This paper presents a prototype system that has been developed to perform sentiment categorization of Web search results. It assists users to quickly focus on recommended (or non-recommended) information by classifying Web search results into four categories: positive, negative, neutral, and non-review documents, by using an automatic classifier based on a supervised machine learning algorithm, Support Vector Machine (SVM).

#index 809426
#* Automatic extraction of titles from general documents using machine learning
#@ Yunhua Hu;Hang Li;Yunbo Cao;Dmitriy Meyerzon;Qinghua Zheng
#t 2005
#c 14
#% 197394
#% 211044
#% 246836
#% 301236
#% 319666
#% 397193
#% 464434
#% 464612
#% 466892
#% 495126
#% 578773
#% 595992
#% 614036
#% 634963
#% 643004
#% 643046
#% 738494
#% 747788
#% 760856
#% 766442
#% 783474
#% 854636
#% 1264984
#! In this paper, we propose a machine learning approach to title extraction from general documents. By general documents, we mean documents that can belong to any one of a number of specific genres, including presentations, book chapters, technical papers, brochures, reports, and letters. Previously, methods have been proposed mainly for title extraction from research papers. It has not been clear whether it could be possible to conduct automatic title extraction from general documents. As a case study, we consider extraction from Office including Word and PowerPoint. In our approach, we annotate titles in sample documents (for Word and PowerPoint respectively) and take them as training data, train machine learning models, and perform title extraction using the trained models. Our method is unique in that we mainly utilize formatting information such as font size as features in the models. It turns out that the use of formatting information can lead to quite accurate extraction from general documents. Precision and recall for title extraction from Word is 0.810 and 0.837 respectively, and precision and recall for title extraction from PowerPoint is 0.875 and 0.895 respectively in an experiment on intranet data. Other important new findings in this work include that we can train models in one domain and apply them to another domain, and more surprisingly we can even train models in one language and apply them to another language. Moreover, we can significantly improve search ranking results in document retrieval by using the extracted titles.

#index 809427
#* HiBO: a system for automatically organizing bookmarks
#@ Pavlos Kokosis;Vlassis Krikos;Sofia Stamou;Dimitris Christodoulakis
#t 2005
#c 14
#% 209690
#% 274149
#% 1394412
#% 1698586
#! In this paper, we introduce the HiBO bookmark management system. HiBO aims at extending the populated personal repositories (aka bookmarks) by automatically organizing their contents into topics, through the use of a built-in subject hierarchy. HiBO offers customized personalized services, such as the meaningful grouping and ordering of bookmarks within the hierarchy's topics in terms of the bookmarks' conceptual similarity to each other. HiBO also provides a framework that allows the user to customize and assist the categorization process.

#index 809428
#* Automated text classification using a multi-agent framework
#@ Yueyu Fu;Weimao Ke;Javed Mostafa
#t 2005
#c 14
#% 194284
#% 280817
#% 720202
#% 763708
#! Automatic text classification is an important operational problem in digital library practice. Most text classification efforts so far concentrated on developing centralized solutions. However, centralized classification approaches often are limited due to constraints on knowledge and computing resources. In addition, centralized approaches are more vulnerable to attacks or system failures and less robust in dealing with them. We present a de-centralized approach and system implementation (named MACCI) for text classification using a multi-agent framework. Experiments are conducted to compare our multi-agent approach with a centralized approach. The results show multi-agent classification can achieve promising classification results while maintaining its other advantages.

#index 809429
#* Is digital preservation an oxymoron?
#@ Taylor Surface;Priscilla Caplan;Robert Horton;Martin Halbert
#t 2005
#c 14
#! Techniques for the long-term preservation of digital materials are increasingly critical as more and more intellectual content is meaningful only in electronic form. Terry Kuny, in his often quoted paper "A Digital Dark Ages?" concluded, "Digital collections facilitate access, but do not facilitate preservation. ... Although tremendous work has been undertaken in defining the problems and challenges, much more remains to be done, and the tough task of actually doing digital preservation (and digital rescue) remains ahead."[1]

#index 809430
#* Digital libraries' support for the user's 'information journey'
#@ Anne Adams;Ann Blandford
#t 2005
#c 14
#% 104636
#% 198056
#% 204649
#% 222009
#% 237321
#% 237336
#% 247295
#% 281363
#% 297926
#% 303395
#% 337261
#% 378567
#% 415130
#% 489744
#% 722848
#% 760827
#% 760828
#% 760839
#% 760851
#% 760852
#% 760872
#% 769103
#! The temporal elements of users' information requirements are a continually confounding aspect of digital library design. No sooner have users' needs been identified and supported than they change. This paper evaluates the changing information requirements of users through their 'information journey' in two different domains (health and academia). In-depth analysis of findings from interviews, focus groups and observations of 150 users have identified three stages to this journey: information initiation, facilitation (or gathering) and interpretation. The study shows that, although digital libraries are supporting aspects of users' information facilitation, there are still requirements for them to better support users' overall information work in context. Users are poorly supported in the initiation phase, as they recognize their information needs, especially with regard to resource awareness; in this context, interactive press-alerts are discussed. Some users (especially clinicians and patients) also require support in the interpretation of information, both satisfying themselves that the information is trustworthy and understanding what it means for a particular individual.

#index 809431
#* Interviews with NSDL grantees on core values and service perspectives
#@ David W. Fulker
#t 2005
#c 14
#% 489748
#% 508266
#! We analyze information from interviews with NSDL awardees. One purpose is to inform potential NSDL membership models, and a second is to better understand infrastructure needs, including capacity for integrating services. Our results shed light on social and architectural aspects of the NSDL as a distributed library-building endeavor.

#index 809432
#* Developing the DigiQUAL protocol for digital library evaluation
#@ Martha Kyrillidou;Sarah Giersch
#t 2005
#c 14
#% 614114
#! The distributed, project-oriented nature of digital libraries (DLs) has made them difficult to evaluate in aggregate. By modifying the methods and tools used to evaluate physical libraries' content and services, measures can be developed whose results can be used across a variety of DLs. The DigiQUAL protocol being developed by the Association of Research Libraries (ARL) has the potential to provide the National Science Digital Library (NSDL) with a standardized methodology and survey instrument with which to evaluate not only its distributed projects but also to gather data to assess the value and impact of the NSDL.

#index 809433
#* Language preference in a bi-language digital library
#@ Te Taka Keegan;Sally Jo Cunningham
#t 2005
#c 14
#% 342066
#% 760869
#! This paper examines user choice of interface language in a bi-language digital library (English and Maori, the language of the indigenous people of New Zealand). The majority of collection documents are in Maori, and the interface is available in both Maori and English. Log analysis shows three categories of preference for interface language: primarily English, primarily Maori, and bilingual (switching back and forth between the two).

#index 809434
#* A usability evaluation study of a digital library self-archiving service
#@ Lena Veiga e Silva;Alberto H. F. Laender;Marcos André Gonçalves
#t 2005
#c 14
#% 760819
#! In this paper 1, we describe an evaluation study of a self-archiving service for the Brazilian Digital Library of Computing (BDBComp). We conducted an extensive usability experiment with several potential users, including graduate students, professors, and archivists/librarians. The results of the study are described and analyzed, following sound statistical principles.

#index 809435
#* Leveraging context to resolve identity in photo albums
#@ Mor Naaman;Ron B. Yeh;Hector Garcia-Molina;Andreas Paepcke
#t 2005
#c 14
#% 272902
#% 344667
#% 378541
#% 635092
#% 729344
#% 730144
#% 730186
#% 755194
#% 760826
#% 780133
#% 780722
#% 780723
#% 780827
#! Our system suggests likely identity labels for photographs in a personal photo collection. Instead of using face recognition techniques, the system leverages automatically available context, like the time and location where the photos were taken.Based on time and location, the system automatically computes event and location groupings of photos. As the user annotates some of the identities of people in their collection, patterns of re-occurrence and co-occurrence of different people in different locations and events emerge. The system uses these patterns to generate label suggestions for identities that were not yet annotated. These suggestions can greatly accelerate the process of manual annotation and improve the quality of retrieval from the collection.We obtained ground-truth identity annotation for four different photo albums, and used them to test our system. The system proved effective, making very accurate label suggestions, even when the number of suggestions for each photo was limited to five names, and even when only a small subset of the photos was annotated.

#index 809436
#* Meaningful presentations of photo libraries: rationale and applications of bi-level radial quantum layouts
#@ Jack Kustanowitz;Ben Shneiderman
#t 2005
#c 14
#% 232829
#% 324983
#% 378541
#% 401849
#% 438441
#% 449536
#% 641166
#% 662863
#% 734962
#% 751818
#% 752138
#% 760826
#! Searching photo libraries can be made more satisfying and successful if search results are presented in a way that allows users to gain an overview of the photo categories. Since photo layouts on computer displays are the primary way that users get an overview, we propose a novel approach to show more photos in meaningful groupings. Photo layouts can be linear strips, or zoomable three dimensional arrangements, but the most common form is the two-dimensional grid. This paper introduces a novel bi-level hierarchical layout with motivating examples. In a bi-level hierarchy, one region is designated for primary content - an image, text, or combination. Adjacent to that region, groups of photos are placed radially in an ordered fashion, such that the relationship of the single primary region to its many secondary regions is apparent. A compelling aspect is the interactive experience in which the layout is dynamically resized, allowing users to rapidly, incrementally, and reversibly alter the dimensions and content. It can accommodate hundreds of photos in dozens of regions, can be customized in a corner or center layout, and can scale from an element on a web page to a large poster size. On typical displays (1024 x 1280 or 1200 x 1600 pixels), bi-level radial quantum layouts can conveniently accommodate 2-20 regions with tens or hundreds of photos per region.

#index 809437
#* On the extraction of vocal-related information to facilitate the management of popular music collections
#@ Wei-Ho Tsai;Hsin-Min Wang
#t 2005
#c 14
#% 55490
#% 204646
#% 281391
#% 389559
#% 413600
#% 614033
#% 643010
#% 849873
#! With the explosive growth of networked collections of musical material, there is a need to establish a mechanism like a digital library to manage music data. This paper presents a content-based processing paradigm of popular song collections to facilitate the realization of a music digital library. The paradigm is built on the automatic extraction of information of interest from music audio signals. Because the vocal part is often the heart of a popular song, we focus on developing techniques to exploit the solo vocal signals underlying an accompanied performance. This supports the necessary functions of a music digital library, namely, music data organization, music information retrieval/recommendation, and copyright protection.

#index 809438
#* From playful exhibits to LOM: lessons from building an exploratorium digital library
#@ Holly Fait;Sherry Hsi
#t 2005
#c 14
#% 301291
#% 320030
#% 337230
#% 430682
#% 451609
#! The Exploratorium, an interactive hand-on science museum, is developing an online collection of science learning and teaching resources to better serve educators' needs for pedagogically-rich instructional resources via the Web. Several challenges arise when designing a digital library for formal K12 education audiences using the Learning Object Metadata standard. These problems are multiplied when attempting to catalog the wide variety of informal learning digital resources from the Exploratorium's ever growing website and exhibit-based resource collections. This paper shares key challenges and early solutions for the creation of an educational metadata scheme, new vocabularies, and strategies for retrofitting existing informal learning science resources into learning objects.

#index 809439
#* Tacit user and developer frames in user-led collection development: the case of the digital water education library
#@ Michael Khoo
#t 2005
#c 14
#% 38979
#% 177474
#% 337256
#% 840578
#! This paper discusses the impact that developers' and users' tacit understandings can have on digital library development. It draws on three years of ethnographic research with the Digital Water Education Library (DWEL) that focused on the observation, collection, and analysis of the project's face-to-face and electronic organizational communication. The DWEL project involved formal and informal educators in the development of its collection, and experienced problems at the start of the project with getting these educators to complete their cataloguing tasks. The research showed that despite having spent several days in face-to-face workshops, the project's PIs and the educators had different tacit understandings of what digital libraries were, that were impeding the project's organizational communication and workflow. I describe how these differences were identified and analyzed, and subsequently addressed and mediated through the design and development of online tools that acted as boundary objects between the PIs and the educators.

#index 809440
#* Experimenting with the automatic assignment of educational standards to digital library content
#@ Anne R. Diekema;Jiangping Chen
#t 2005
#c 14
#% 318412
#! This paper describes exploratory research concerning the automatic assignment of educational standards to lesson plans. An information retrieval based solution was proposed, and the results of several experiments are discussed. Results suggest the optimal solution would be a recommender tool where catalogers receive suggestions from the system but humans make the final decision.

#index 809441
#* Turning the page on navigation
#@ Catherine C. Marshall;Sara Bly
#t 2005
#c 14
#% 127574
#% 149109
#% 183522
#% 232895
#% 237329
#% 247264
#% 247297
#% 378484
#% 438039
#% 531867
#% 579439
#% 760831
#% 760852
#! In this paper, we discuss the findings of an in-depth observational study of reading and within-document navigation and add to these findings the results of a second analysis of how people read comparable digital materials on the screen, given limited navigational functionality. We chose periodicals as our initial foil since they represent a type of material that invites many different kinds of reading and strategies for navigation. Using multiple sources of evidence from the data, we first characterize readers' navigation strategies and specific practices as they make their way through the magazines. We then focus on two observed phenomena that occur when people read paper magazines, but are absent in their digital equivalents: the lightweight navigation that readers use unselfconsciously when they are reading a particular article and the approximate navigation readers engage in when they flip multiple pages at a time. Because page-turning is so basic and seems deceptively simple, we dissect the turn of a page, and use it to illustrate the importance and invisibility of lightweight navigation. Finally, we explore the significance of our results for navigational interfaces to digital library materials.

#index 809442
#* In the company of readers: the digital library book as "practiced place"
#@ Nancy Kaplan;Yoram Chisik
#t 2005
#c 14
#% 80398
#% 128268
#% 273165
#% 281359
#% 301217
#% 337243
#% 337493
#% 349405
#% 360024
#% 362454
#% 370648
#% 376197
#% 679856
#% 760852
#% 760875
#% 772531
#% 772556
#% 783875
#% 783883
#! Most digital libraries (DLs) necessarily focus on the complex issues that arise when library collections are freed from their physical anchors in buildings and on paper. Typical investigations look at supporting adults in work settings, such as school or research. Much less attention has been paid to younger generations of readers. As ever more digital venues cater to youngsters' attentions, a role for the DL as a catalyst of social interactions around traditional literacy practices begins to take shape. Based on prior research on annotation systems, constructive hypertexts, and computer support for cooperative work coupled with our contextual inquiries with children, we have developed a prototype for a digital book that supports social interactions through annotations. By placing and sharing notes, groups of readers transform the book from an artifact into a living record of communal experience. A system of support for marks and notes in the context of reading for pleasure can turn the digital library book into a "practiced place," a location that is not only accessible, but also welcoming, engaging and supportive of the activities children are interested in and therefore likely to engage in. Our experience with Alph, a prototype book-reader supporting a range of rhetorical marks and note-writing, suggests that future DLs need to look beyond augmenting work-based literacy practices by creating dynamic and social reading environments.

#index 809443
#* Digitization and 3D modeling of movable books
#@ Pierre Cubaud;Jérôme Dupire;Alexandre Topol
#t 2005
#c 14
#% 301220
#% 378526
#% 752060
#% 760831
#! Movable books provide interesting challenges for digitization and user interfaces design. We report in this paper some preliminary results in the building of a 3D visualization workbench for such books.

#index 809444
#* An initial evaluation of automated organization for digital library browsing
#@ Aaron Krowne;Martin Halbert
#t 2005
#c 14
#% 262059
#% 344447
#% 397147
#% 406493
#% 458379
#% 465747
#% 643008
#% 809520
#! In this article we present an evaluation of text clustering and classification methods for creating digital library browse interfaces, focusing on the particular case of collections made up of heterogeneous metadata records. This situation is common in "portal" style digital libraries, which are built by harvesting content from many disparate sources, typically using the Open Archives Protocol for Metadata Harvesting (OAI-PMH). By studying the activity of users in an experimental system, we find that taxonomies built or populated using machine-learning (or "AI") techniques provide a potentially useful avenue for browsing in this digital library scenario.

#index 809445
#* Using concept maps in digital libraries as a cross-language resource discovery tool
#@ Ryan Richardson;Edward A. Fox
#t 2005
#c 14
#% 179796
#% 281694
#% 413640
#% 481290
#! The concept map, first suggested by Joseph Novak, has been extensively studied as a way for learners to increase understanding. We are automatically generating and translating concept maps from electronic theses and dissertations, for both English and Spanish, as a DL aid to discovery and summarization.

#index 809446
#* Collection understanding for OAI-PMH compliant repositories
#@ TeongJoo Ong;John J. Leggett
#t 2005
#c 14
#% 760871
#! We briefly discuss the architecture and design of a collection understanding tool that utilizes information visualization and the Open Archives Initiative Protocol for Metadata Harvesting to help users in understanding the essence of image collections in OAI-PMH compliant repositories.

#index 809447
#* A focus-context browser for multiple timelines
#@ Robert B. Allen
#t 2005
#c 14
#% 214715
#% 287210
#% 301212
#% 309096
#% 760828
#! Events may be best understood in the context of other events. We can call a set of related events a "timeline", because of the temporal ordering. Such timelines are themselves best understood in the context of other timelines. To facilitate the exploration of a collection of events and timelines, a visualization tool has been developed that facilitates the user's ability to compare and browse across events and timelines. In this model, each event is accompanied by a text description and links to related resources such as articles from digitized historical newspapers.

#index 809448
#* Semantics and syntax of dublin core usage in open archives initiative data providers of cultural heritage materials
#@ Arwen Hutt;Jenn Riley
#t 2005
#c 14
#% 1069039
#! This study analyzes metadata shared by cultural heritage institutions via the Open Archives Initiative Protocol for Metadata Harvesting. The syntax and semantics of metadata appearing in the Dublin Core fields creator, contributor, and date are examined. Preliminary conclusions are drawn regarding the effectiveness of Dublin Core in the Open Archives Initiative environment for cultural heritage materials.

#index 809449
#* Finding a catalog: generating analytical catalog records from well-structured digital texts
#@ David Mimno;Alison Jones;Gregory Crane
#t 2005
#c 14
#% 281169
#% 301236
#% 301257
#% 337235
#% 614036
#% 614046
#% 614082
#% 760848
#% 760856
#% 788796
#! One of the criticisms library users often make of catalogs is that they rarely include information below the bibliographic level. It is generally impossible to search a catalog for the titles and subjects of particular chapters or volumes. There has been no way to add this information to catalog records without exponentially increasing the workload of catalogers. At the same time, well-structured full-text XML transcriptions of printed works are becoming increasingly available. This paper describes how existing investments in full text digitization and structural markup combined with current named-entity extraction technology can efficiently generate the detailed level of catalog data that users want, at no significant additional cost. This system is demonstrated on an existing digital collection within the Perseus Digital Library.

#index 809450
#* To grow in wisdom: vannevar bush, information overload, and the life of leisure
#@ David M. Levy
#t 2005
#c 14
#% 117811
#% 117819
#% 117828
#% 395302
#! It has been nearly sixty years since Vannevar Bush's essay, "As We May Think," was first published in The Atlantic Monthly, an article that foreshadowed and possibly invented hypertext. While much has been written about this seminal piece, little has been said about the argument Bush presented to justify the creation of the memex, his proposed personal information device. This paper revisits the article in light of current technological and social trends. It notes that Bush's argument centered around the problem of information overload and observes that in the intervening years, despite massive technological innovation, the problem has only become more extreme. It goes on to argue that today's manifestation of information overload will require not just better management of information but the creation of space and time for thinking and reflection, an objective that is consonant with Bush's original aims.

#index 809451
#* Integrating collections at the cervantes project
#@ Neal Audenaert;Richard Furuta;Eduardo Urbina;Jie Deng;Carlos Monroy;Rosy Sáenz;Doris Careaga
#t 2005
#c 14
#% 614039
#! Unlike many efforts that focus on supporting scholarly research by developing large-scale, general resources for a wide range of audiences, we at the Cervantes Project have chosen to focus more narrowly on developing resources in support of ongoing research about the life and works of a single author, Miguel de Cervantes Saavedra (1547-1616). This has lead to a group of hypertextual archives, tightly integrated around the narrative and thematic structure of Don Quixote. This project is typical of many humanities research efforts and we discuss how our experiences inform the broader challenge of developing resources to support humanities research.

#index 809452
#* Icon abacus: positional display of document attributes
#@ Eric A. Bier;Adam Perer
#t 2005
#c 14
#% 18610
#% 218990
#% 259946
#% 301234
#% 401849
#% 641118
#% 760832
#! This paper presents icon abacus, a space-efficient technique for displaying document attributes by automatic positioning of document icons. It displays the value of an attribute by using position on a single axis, allowing the other axis to display different metadata simultaneously The layout is stable enough to support navigation using spatial memory.

#index 809453
#* Developing practical automatic metadata assignment and evaluation tools for internet resources
#@ Gordon W. Paynter
#t 2005
#c 14
#% 280866
#% 337255
#% 401408
#% 420487
#% 466078
#% 495937
#% 608647
#% 614036
#% 645984
#% 707580
#% 751593
#% 760856
#% 777400
#% 816173
#% 993986
#% 1279276
#% 1673007
#! This paper describes the development of practical automatic metadata assignment tools to support automatic record creation for virtual libraries, metadata repositories and digital libraries, with particular reference to library-standard metadata. The development process is incremental in nature, and depends upon an automatic metadata evaluation tool to objectively measure its progress. The evaluation tool is based on and informed by the metadata created and maintained by librarian experts at the INFOMINE Project, and uses different metrics to evaluate different metadata fields. In this paper, we describe the form and function of common metadata fields, and identify appropriate performance measures for these fields. The automatic metadata assignment tools in the iVia virtual library software are described, and their performance is measured. Finally, we discuss the limitations of automatic metadata evaluation, and cases where we choose to ignore its evidence in favor of human judgment.

#index 809454
#* What's there and what's not?: focused crawling for missing documents in digital libraries
#@ Ziming Zhuang;Rohit Wagle;C. Lee Giles
#t 2005
#c 14
#% 255161
#% 268087
#% 281251
#% 309787
#% 330599
#% 330609
#% 340924
#% 342080
#% 348173
#% 480309
#% 503216
#% 760839
#% 783439
#% 1272335
#% 1656131
#! Some large scale topical digital libraries, such as CiteSeer, harvest online academic documents by crawling open-access archives, university and author homepages, and authors' self-submissions. While these approaches have so far built reasonable size libraries, they can suffer from having only a portion of the documents from specific publishing venues. We propose to use alternative online resources and techniques that maximally exploit other resources to build the complete document collection of any given publication venue.We investigate the feasibility of using publication metadata to guide the crawler towards authors' homepages to harvest what is missing from a digital library collection. We collect a real-world dataset from two Computer Science publishing venues, involving a total of 593 unique authors over a time frame of 1998 to 2004. We then identify the missing papers that are not indexed by CiteSeer. Using a fully automatic heuristic-based system that has the capability of locating authors' homepages and then using focused crawling to download the desired papers, we demonstrate that it is practical to harvest using a focused crawler academic papers that are missing from our digital library. Our harvester achieves a performance with an average recall level of 0.82 overall and 0.75 for those missing documents. Evaluation of the crawler's performance based on the harvest rate shows definite advantages over other crawling approaches and consistently outperforms a defined baseline crawler on a number of measures.

#index 809455
#* Resolving the unencoded character problem for chinese digital libraries
#@ Derming Juang;Jenq-Haur Wang;Chen-Yu Lai;Ching-Chun Hsieh;Lee-Feng Chien;Jan-Ming Ho
#t 2005
#c 14
#% 224135
#% 854710
#! Constructing a Chinese digital library, especially for a historical article archiving, is often bothered by the small character sets supported by the current computer systems. This paper is aimed at resolving the unencoded character problem with a practical and composite approach for Chinese digital libraries. The proposed approach consists of the glyph expression model, the glyph structure database, and supporting tools. With this approach, the following problems can be resolved. First, the extensibility of Chinese characters can be preserved. Second, it would be as easy to generate, input, display, and search unencoded characters as existing ones. Third, it is compatible with existing encoding schemes that most computers use.This approach has been utilized by organizations and projects in various application domains including archeology, linguistics, ancient texts, calligraphy and paintings, and stone and bronze rubbings. For example, in Academia Sinica, a very large full-text database of ancient texts called Scripta Sinica has been created using this approach. The Union Catalog of National Digital Archives Project (NDAP) dealt with the unencoded characters encountered when merging the metadata of 12 different thematic domains from various organizations. Also, in Bronze Inscriptions Research Team (BIRT) of Academia Sinica, 3,459 Bronze Inscriptions were added, which is very helpful to the education and research in historic linguistics.

#index 809456
#* E-library of medieval chant manuscript transcriptions
#@ Louis W. G. Barton;John A. Caldwell;Peter G. Jeavons
#t 2005
#c 14
#% 248432
#% 1548074
#! In this paper we present our rationale and design principles for a distributed e-library of medieval chant manuscript transcriptions. We describe the great variety in neumatic notations, in order to motivate a standardised data representation that is lossless and universal with respect to these musical artefacts. We present some details of the data representation and an XML Schema for describing and delivering transcriptions via the Web. We argue against proposed data formats that look simpler, on the grounds that they will inevitably lead to fragmentation of digital libraries. We plan to develop applications software that will allow users to take full advantage of the carefully designed representation we describe, while shielding users from its complexity. We argue that a distributed e-library of this kind will greatly facilitate scholarship, education, and public appreciation of these artefacts.

#index 809457
#* Toward a metadata standard for digitized historical newspapers
#@ Ray L. Murray
#t 2005
#c 14
#! This paper is a case study of metadata development in the early stages of the National Digital Newspaper Program, a twenty-year digital initiative to expand access to historical newspapers in support of research and education. Some of the issues involved in newspaper metadata are examined, and a new XML-based standard is described that is suited to the large volume of data, while remaining flexible into the future.

#index 809458
#* The challenges in developing digital collections of phonograph records
#@ Catherine Lai;Ichiro Fujinaga;Cynthia A. Leive
#t 2005
#c 14
#! To facilitate long-term preservation and sustain the utility of phonograph records, an efficient and economical workflow management system for digitization is necessary. We describe in this paper the digitization process for building an online digital collection of phonograph records and our procedure for creating the ground-truth data, which is essential for developing an efficient metadata and content capturing system. We also discuss the challenges of defining metadata for phonograph records and their packaging to enhance access and use across traditional boundaries.

#index 809459
#* Name disambiguation in author citations using a K-way spectral clustering method
#@ Hui Han;Hongyuan Zha;C. Lee Giles
#t 2005
#c 14
#% 32357
#% 65958
#% 74120
#% 115462
#% 249143
#% 262059
#% 282481
#% 283136
#% 287222
#% 310516
#% 310533
#% 310546
#% 313959
#% 337227
#% 338443
#% 342659
#% 387427
#% 420072
#% 532186
#% 577247
#% 594009
#% 614036
#% 614037
#% 643008
#% 643018
#% 722934
#% 747735
#% 748465
#% 748619
#% 760866
#% 815267
#% 815297
#% 816185
#% 870896
#% 1279275
#! An author may have multiple names and multiple authors may share the same name simply due to name abbreviations, identical names, or name misspellings in publications or bibliographies 1. This can produce name ambiguity which can affect the performance of document retrieval, web search, and database integration, and may cause improper attribution of credit. Proposed here is an unsupervised learning approach using K-way spectral clustering that disambiguates authors in citations. The approach utilizes three types of citation attributes: co-author names, paper titles, and publication venue titles 2. The approach is illustrated with 16 name datasets with citations collected from the DBLP database bibliography and author home pages and shows that name disambiguation can be achieved using these citation attributes.

#index 809460
#* Comparative study of name disambiguation problem using a scalable blocking-based framework
#@ Byung-Won On;Dongwon Lee;Jaewoo Kang;Prasenjit Mitra
#t 2005
#c 14
#% 201889
#% 258870
#% 309208
#% 310516
#% 333943
#% 350103
#% 438103
#% 503213
#% 577238
#% 577309
#% 654467
#% 668675
#% 760866
#% 870896
#% 993980
#! In this paper, we consider the problem of ambiguous author names in bibliographic citations, and comparatively study alternative approaches to identify and correct such name variants (e.g., "Vannevar Bush" and "V. Vush"). Our study is based on a scalable two-step framework, where step 1 is to substantially reduce the number of candidates via blocking, and step 2 is to measure the distance of two names via coauthor information. Combining four blocking methods and seven distance measures on four data sets, we present extensive experimental results, and identify combinations that are scalable and effective to disambiguate author names in citations.

#index 809461
#* On assigning place names to geography related web pages
#@ Wenbo Zong;Dan Wu;Aixin Sun;Ee-Peng Lim;Dion Hoe-Lian Goh
#t 2005
#c 14
#% 378546
#% 615785
#% 766441
#% 815280
#% 855305
#% 855310
#% 855312
#! In this paper, we attempt to give spatial semantics to web pages by assigning them place names. The entire assignment task is divided into three sub-problems, namely place name extraction, place name disambiguation and place name assignment. We propose our approaches to address these sub-problems. In particular, we have modified GATE, a well-known named entity extraction software, to perform place name extraction using a US Census gazetteer. A rule-based place name disambiguation method and a place name assignment method capable of assigning place names to web page segments have also been proposed. We have evaluated our proposed disambiguation and assignment methods on a web page collection referenced by the DLESE metadata collection. The results returned by our methods are compared with manually disambiguated place names and place name assignment. It is shown that our proposed place name disambiguation method works well for geo/geo ambiguities. The preliminary results of our place name assignment method indicate promising results given the existence of geo/non-geo ambiguities among place names.

#index 809462
#* A reciprocal platform for archiving interview videos about arts and crafts
#@ Kenro Aihara;Atsuhiro Takasu
#t 2005
#c 14
#! This paper proposes a platform for portal and local repositories. Our methodology aims not only at construction of portal site but also at supporting capture of digital contents transformed from interview videos with intellectuals.

#index 809463
#* BEN collaborative poster
#@ Linda Akli;Cal Collins;Yolanda George
#t 2005
#c 14
#! In 1999, the American Association for the Advancement of Science (AAAS) Directorate for Education and Human Resources (EHR) Programs and Science's Signal Transduction Knowledge Environment (STKE) --- with 11 other professional societies and coalitions for biological sciences -established the BiosciEdNet (BEN) Collaborative with limited funding from the US National Science Foundation (NSF) National Sciences Education Digital Library Program (NSDL). Since its inception, BEN has grown from its original 11 to 24 Collaborators.Currently, the digital library collections of BEN Collaborators provide a rich array of materials for undergraduate biological sciences educators, including ones that prepare K-12 teachers. The materials that users find via the BEN portal are unique in several ways.First, BEN resources have been reviewed by the individual societies for standards of quality and accuracy. Although each BEN collaborator has unique review criteria, overall users find resources that are scientifically accurate and educationally sound.Second, the BEN portal provides an extended set of search parameters to allow more productive searches by users.Finally, due to the collaborative establishment of its metadata structure, the user can easily conduct productive interdisciplinary searches across the diverse biological sciences topics covered by the BEN Collaborators.In general contributors can submit resources through the digital library of a BEN collaborator or directly to the BEN portal. Submissions to the BEN portal are sent to the Collaborators that are maintaining discipline specific resources. AAAS catalogs submissions that do not fit discipline specific Collaborators. Contributors enter the cataloging information at the time of submission and a BEN digital library provider or AAAS validates the metadata.Biological sciences educators, particularly in high schools and community colleges and regional comprehensive institutions, have student bodies diverse in every respect - learning styles and ability, geography, economics, race, gender, physical disabilities, and experience. To this end, BEN Collaborators are building digital collections that are inclusive of all educators and students.Biological sciences educators, particularly in high schools and community colleges and regional comprehensive institutions, have student bodies diverse in every respect - learning styles and ability, geography, economics, race, gender, physical disabilities, and experience. To this end, BEN Collaborators are building digital collections that are inclusive of all educators and students. In summary, BEN has already developed tools and services that can be shared to leverage technologies across societies, coalitions, and collections affilaites. BEN has a documentation site --- http://www.biosciednet.org/project_site/ that includes all its technical standards and specifications:BEN metadata Repository Database Specification;XML specification and schema for transferring BEN LOM metadata; Search Engine Specifications;Metadata Harvester Software Specifications using the OAI Protocol; andCataloging Software Specifications.For long-term sustainability the BEN Collaborative goal is to design and develop digital library collections that are valued by the members of professional societies, thereby eventually ensuring inclusion in the ongoing operating budgets of societies. Some societies are already providing in- kind support for staff and dollars for development.

#index 809464
#* PDLib: personal digital libraries with universal access
#@ Francisco Alvarez-Cavazos;David A. Garza-Salazar;Juan C. Lavariega-Jarquin
#t 2005
#c 14
#! We propose a universally available personal digital library system. It is "personal" in the sense that each user is provided with a general purpose document repository (i.e. a personal digital library). It is "universally available" in the sense that it allows the user to access her/his personal personal digital library from most computing devices connected to the Internet, including mobile phones, PDAs and laptops, therefore granting access "from anyplace at anytime."

#index 809465
#* Large introductory science courses & digital libraries
#@ Laura M. Bartolo;Cathy S. Lowe;Donald R. Sadoway;Patrick E. Trapa
#t 2005
#c 14
#! Student self-assessment survey results indicate that a virtual lab experience improved understanding of many key laboratory learning objectives and that the Materials Digital Library (MatDL) has potential value in supporting a virtual lab.

#index 809466
#* aDORe: a modular and standards-based digital object repository at the los alamos national laboratory
#@ Jeroen Bekaert;Xiaoming Liu;Herbert Van de Sompel
#t 2005
#c 14
#! This paper describes the aDORe repository architecture, designed and implemented for ingesting, storing, and accessing a vast collection of Digital Objects at the Research Library of the Los Alamos National Laboratory.

#index 809467
#* A signal/semantic framework for image retrieval
#@ Mohammed Belkhatir;Yves Chiaramella;Philippe Mulhem
#t 2005
#c 14
#% 262095
#% 318785
#% 563749
#! This poster presents an approach for integrating perceptual signal features (i.e. color and texture) and semantic information within an integrated architecture for image retrieval. It relies on an expressive knowledge representation formalism handling high-level image descriptions and a full-text query framework. It consequently brings the level of image retrieval closer to users' needs by translating low-level signal features to high-level data and coupling it with semantics within index and query structures.

#index 809468
#* Video recommendations for the open video project
#@ Johan Bollen;Michael L. Nelson;Raquel Araujo;Gary Geisler
#t 2005
#c 14
#% 280852
#% 330687
#! We describe a DL multimedia recommender system implemented for the Open Video project. Recommendations are generated by a spreading activation algorithm operating on a video network created from log download sequences. We compared the system's recommendations to those generated by a collaborative filtering technique.

#index 809469
#* The DLESE evaluation services group: a framework for evaluation within a digital library
#@ Susan Buhr;Lecia Barker;Thomas C. Reeves
#t 2005
#c 14
#! The Digital Library for Earth System Education (DLESE) Evaluation Services Core (ESC) team has been established to:Provide evaluation support for DLESE core team activities.Establish pilot studies with key user audiences (e.g. K-12 teachers and undergraduate faculty),Implement studies designed to better characterize DLESE users and user needs.Offer evaluation support and opportunities for the DLESE community through workshops and grant opportunities.This poster is intended to describe the breadth and depth of our work; selected aspects of our work are described in accompanying posters.One of the key roles for the DLESE Evaluation Services team is to provide evaluation support for major DLESE activities and initiatives. The Evaluation team focuses upon major activities such as conference-based outreach, the DLESE Ambassadors program, DLESE Data Workshops, state-based digital teaching units, and the developing scientific accuracy review process. Work within these projects allows us to not only provide needed formative evaluation information to DLESE teams, but offer study sites to better understand user needs. For example, the California pilot study to develop state-based digital teaching units provides information to support that project, but also gives us insight into how teachers choose resources, what challenges exist for teachers using digital units, and what opportunities exist for DLESE to further an Earth system perspective.The DLESE vision is to serve a broad and diverse group of users; however, our initial pilot work is focused upon two key intended audiences: undergraduate faculty and K-12 teachers. Tom Reeves and students seek to understand the needs of undergraduate students and faculty who use DLESE. Their work has brought new immediacy to the development of hybrid search mechanisms within DLESE that will accommodate not only novice learner search terms but specialized scientific terms used by more advanced learners.Pilot studies within K-12 classrooms are providing new understanding of the ways DLESE can contribute to K-12 teachers' needs. In addition to the digital teaching unit study mentioned previously, the ATLAS team seeks to understand the ways in which a reviewed collection, the Digital Water Education Library (DWEL), enables instruction in Jamestown, VA classrooms and what opportunities exist to increase the utility of such collections.For the first time, all users of the DLESE search and browse system are being asked to voluntarily state the purpose of their visit, their user role and their geographic location. Many choose to offer more detail on the nature of their search and their experiences with DLESE. Results from this survey are described in a separate poster. Over time, this survey will be used to ask different questions of users about their experiences with DLESE.The DLESE ESC seeks to build the evaluation capacity of the DLESE community through several means. Evaluation workshops are offered at scientific conferences and DLESE meetings, team members review and comment on the evaluation components of geoscience education proposals, and the Evaluation Toolkit thematic collection for geoscience education evaluation is available in DLESE. A new minigrants program is under development, to provide seed funds for evaluation projects of interest to DLESE.

#index 809470
#* Using strand maps to engage digital library users with science content
#@ Kirsten R. Butcher;Sonal Bhushan
#t 2005
#c 14
#% 186518
#! Our research examined whether using strand maps as an interface for digital library search tasks would change learners' cognitive processes when seeking educational resources. Results demonstrated that strand maps can help learners engage with science content and that semantic-spatial interfaces can support meaningful search processes.

#index 809471
#* Impact: the last frontier in digital library evaluation
#@ Anita S. Coleman;Laura M. Bartolo;Casey Jones
#t 2005
#c 14
#% 614114
#% 760883
#! The NSF-funded National Science Digital Library (NSDL) is engaged in an ongoing discourse about digital library evaluation. The Educational Impact and Evaluation Standing Committee (EIESC) has successfully identified desirable features in digital libraries such as usability and usage, but the hardest measure is impact. What is the impact of a DL? Members of the EIESC have engaged in pilots and feasibility studies using bricolage (a blend of qualitative and quantitative approaches to evaluation), and these activities are moving NSDL toward a richer understanding of impact.

#index 809472
#* An approach to modeling content for digital repositories
#@ Robert Chavez;Nikolai Schwertner
#t 2005
#c 14

#index 809473
#* Take note: academic note-taking and annotation behavior
#@ Sally Jo Cunningham;Chris Knowles
#t 2005
#c 14
#% 760875
#% 790223
#! This paper describes an exploratory study of note taking at academic conferences.

#index 809474
#* Teaching boxes and web services: optimizing the digital library for earth system education for the classroom
#@ Lynne Davis;Shelley Olds
#t 2005
#c 14
#! A recent pilot program pioneered the development of Teaching Boxes by the Digital Library for Earth System Education (DLESE) with the Univ. of CA. Berkeley Museum of Paleontology, SF State Univ., USGS, and seven San Francisco area middle/high school teachers. This poster shares the current DLESE Teaching Box effort, explains the pilot program, and highlights the use of web services to create a context within which teachers can find, immediately use, or adapt relevant teaching and learning resources.

#index 809475
#* Music-to-knowledge (M2K): a prototyping and evaluation environment for music digital library research
#@ J. Stephen Downie;Andreas F. Ehmann;Xiao Hu
#t 2005
#c 14

#index 809476
#* Real-time genre classification for music digital libraries
#@ J. Stephen Downie;Andreas F. Ehmann;David Tcheng
#t 2005
#c 14
#! This poster describes a real-time audio-based automatic music genre classifier for use in organizing, browsing, and searching musical digital libraries. A decision tree classifier trained on a 40-dimension feature space is used to categorize music into one of 14 different genres with the results being displayed to a continuously updating user interface.

#index 809477
#* CQE: a collaborative querying environment
#@ Lin Fu;Dion Hoe-Lian Goh;Schubert Shou-Boon Foo
#t 2005
#c 14
#% 282427

#index 809478
#* Música colonial: 18th century music score meets 21st century digitalization technology
#@ Ting Gan
#t 2005
#c 14
#! The Música Colonial project is an initiative to preserve, digitize, and provide online access to the sole copy of a handwritten Colonial times cathedral music scores with Spanish lyrics collection in microfilm format archived at the Mesoamerican Center for Regional Research (CIRMA) located in Antigua, Guatemala. Various fields and methodologies of research can be done on this collection because of its multi-faceted and culturally rich content. This poster mainly focuses on the music aspect of the collection and illustrates the different stages of making the musical content of the collection accessible to the public. Digitization is the most affective and promising way to display this special collection to the rest of the world.

#index 809479
#* MyPDL: a web-based personal digital library
#@ Wu He;Demei Shen
#t 2005
#c 14
#! In recent years we have witnessed a dramatic increase in the volume of electronic and digital information that has been produced and as a result we feel increasingly overwhelmed by the amount of digital information that needs to be managed. This paper describes a Web-based personal digital library system, myPDL, which was designed and developed to allow individual users to create, store, organize, and retrieve their own personal digital information collections. The major distinctions between the developed tool and digital libraries in general were that major considerations were put on the functionalities of user customization and user personalization.

#index 809480
#* JISC metadata schema registry
#@ Rachel Heery;Pete Johnston;Dave Beckett;Nikki Rogers
#t 2005
#c 14

#index 809481
#* Applying verification, validation, and accreditation processes to digital libraries
#@ David Joiner;Steven Gordon;Scott Lathrop;Marilyn McClelland;D. E. Stevenson
#t 2005
#c 14
#% 614070
#% 783178
#! We propose to address the issue of quality of digital library objects in the Computational Science Education Reference Desk by applying a verification, validation, and accreditation workflow to the review of learning objects.

#index 809482
#* Task difficulty in information searching behavior: expected difficulty and experienced difficulty
#@ Jeonghyun Kim
#t 2005
#c 14
#% 378486
#! The purpose of the work is to better understand the issue of task difficulty from the perspective of the user. To investigate the relationship between task difficulty and information searching behavior, two types of task difficulty are considered: expected difficulty and experienced difficulty. Information searching behavior was observed via time spent, pages viewed, pages saved, search efficiency and the number of query reformulations.

#index 809483
#* An information network overlay architecture for the NSDL
#@ Carl Lagoze;Dean B. Krafft;Susan Jesuroga;Tim Cornwell;Ellen J. Cramer;Edwin Shin
#t 2005
#c 14
#! We describe the underlying data model and implementation of a new architecture for the National Science Digital Library (NSDL) by the Core Integration Team (CI). The architecture is based on the notion of an information network overlay. This network, implemented as a graph of digital objects in a Fedora repository, allows the representation of multiple information entities and their relationships. The architecture provides the framework for contextualization and reuse of resources, which we argue is essential for the utility of the NSDL as a tool for teaching and learning.

#index 809484
#* Metadata for phonograph records: facilitating new forms of use and access to analog sound recordings
#@ Catherine Lai;Ichiro Fujinaga;Cynthia A. Leive
#t 2005
#c 14
#! A new metadata schema for analog sound recordings is described.

#index 809485
#* Facilitating the effective use of earth science data in education through digital libraries: bridging the gap between scientists and educators
#@ Tamara Shapiro Ledley;LuAnn Dahlman;Ben Domenico;Michael R. Taber
#t 2005
#c 14
#! Creating learning modules that utilize Earth data is a difficult task, requiring knowledge about the data, science, curriculum design, and the educational context. The Digital Library for Earth System Education (DLESE) Data Services group hosted a workshop to bridge the knowledge gap between data providers and educators by assembling teams of experts in these areas to create data-rich learning modules. Face-to-face collaboration allowed the sharing of perspectives and encouraged the contribution of individual expertise, facilitating development of data-rich modules.

#index 809486
#* Digital libraries on handhelds for autistic children
#@ Gondy Leroy;Serena Chuang;John Huang;Marjorie H. Charlop-Christy
#t 2005
#c 14
#% 751795
#! Autism is a wide spectrum developmental disorder. Its prevalence has increased enormously. Each autistic child has different needs and requires individual therapy. Information technology can help these children and their families by augmenting therapy and providing communication tools. We are developing a digital library that provides such a communication tool on a Pocket PC. The tool will be integrated into the therapy sessions and the children will be able use it daily. Additionally, all the interactions with the tool are logged, allowing the therapist a detailed view of the effects of therapy on the children's communication.

#index 809487
#* A study of annotations for a consumer health portal
#@ Lili Luo;David West;Gary Marchionini;Catherine Blake
#t 2005
#c 14
#! This paper presents a study of annotations made by cataloguers of consumer health websites in order to better understand the website cataloging process.

#index 809488
#* Motivating and supporting faculty use of educational digital libraries: an example from the geosciences
#@ Cathy A. Manduca;Ellen R. Iverson;Sean Fox;Flora McMartin
#t 2005
#c 14
#% 809488

#index 809489
#* Innovative training solutions for digitization
#@ Amy Lynn Maroso
#t 2005
#c 14
#! The benefits of digitizing library collections are important and diverse. Patrons outside traditional geographic boundaries can be served along side local patrons. Access to local history, a vibrant part of many library holdings, and original, rare, and/or valuable materials can be greatly expanded. However, the practice of digitization can fall short of its promise due to poor planning and a lack of digitization skills. Moreover, quality digitization training is not always accessible or feasible given the time, expense, and staff limitations for many institutions.The Basics and Beyond digitization training program offers a novel solution for this problem. Funded by an Institute of Museum and Library Services National Leadership grant and administered by the University of Illinois at Urbana-Champaign Library, the Illinois State Library, and the Illinois Heritage Association, Basics and Beyond offers three digitization training options to cultural heritage institutions: one-day on-site workshops, three-week online training, and three-week online training followed by a hands-on workshop.The content of the workshops provides participants with an overview of the digitization process. Topics presented include: project planning, equipment selection, metadata, and standards and best practices for digitizing materials. The online courses expand greatly on the material covered in the workshops and provide the participants with an in-depth look at the digitization process. They cover material such as using digitization as a preservation practice, selection of materials for digitization, project planning, metadata schemes, equipment needs, and standards and best practices. The online courses are accessible to anyone with a Web connection and provide institutions around the world with access to innovative digitization training. The online training is affordable to most organizations, and its asynchronous format allows librarians and staff to easily fit the course into their work schedules.The effectiveness of the workshops and courses has been determined by participant evaluations conducted both during the workshops and courses and several months after completion. Evaluations include pre- and post-course surveys, essay questions, and quizzes as well as follow-up telephone interviews conducted several months after course or workshop completion. Evaluations are designed to determine the quality of training and to what degree the training assisted in the implementation and practice of newly formed or revamped digital projects.Evaluation results have been overwhelmingly positive for all courses and workshops. Over 200 people have taken the one-day workshop. A nine-question pre-workshop quiz indicates that 80% of participants missed three or more questions before being exposed to the workshop material. As expected, participants score significantly higher when given the same quiz after the workshop-only 14% missed more than two questions. Over 130 people have taken one of the online courses. In addition to quizzes, objective evaluation is also done in the online courses and show that students are able to apply the information they learn in "real world" situations, such as equipment purchases and metadata creation. Evaluations and participants' comments indicate that the workshops and courses are highly successful and have accomplished the chief goal of the project-to educate cultural heritage institution professionals on the best practices for digitization to ensure the success and longevity of their digitized collections.

#index 809490
#* Down on the OCR farm: how we produced searchable PDFs for 7 million documents in a student computer lab
#@ Robert Mason;Heidi Schmidt;Richard Trott
#t 2005
#c 14
#! Utilizing idle workstations in a student computer lab, 7 million searchable PDF documents were generated from 42 million TIF page images.

#index 809491
#* The climate change collection: a case study on digital library collection review and the integration of research, education and evaluation
#@ Mark McCaffrey;Tim Weston
#t 2005
#c 14
#! Validating the scientific quality and potential of digital resources use in classroom settings has become a major focus of recent digital library efforts such as the Digital Library for Earth System Education (DLESE). The Climate Change Collection is thematic collection of digital resources relating to the topic of global climate change and natural climate variability designed as a pilot project for reviewing the scientific quality and pedagogical potential of selected digital resources using a focused and streamlined approach. The collection offers a case-study in integrating research and education through the collaborative efforts of an interdisciplinary review team made up of professionals from the fields of climate research, geoscience education, cognitive psychology, and evaluation. Each participant received a stipend for their involvement in the process. Designed as an experiment in streamlined collection development, it is anticipated that the experience of the Climate Change Collection effort will help inform future digital library review and collection-building efforts.

#index 809492
#* If you harvest arXiv.org, will they come?
#@ Michael L. Nelson;Johan Bollen
#t 2005
#c 14
#! We examine which NASA Technical Report Server (NTRS) repositories have received the most downloads during 15 months of operation. In particular, we explore the collection development policy of including non-NASA scientific, technology and medicine (STM) repositories. We found that three of the four non-NASA repositories included in NTRS contributed little to the overall download totals.

#index 809493
#* Creating the infrastructure for collaboration between digital reference services and researchers: the digital reference electronic warehouse (DREW) project
#@ Scott Nicholson;R. David Lankes
#t 2005
#c 14
#! The Digital Reference Electronic Warehouse (DREW) project is a collection of digital reference transactions from different services and different communication channels that live in a single space. Reference services work with DREW to submit transactions using the DREW schema, which is conceptually similar to the MARC record format for bibliographic materials. Researchers can then receive records from DREW to improve our knowledge of digital reference. These researchers then use the results of their research to create tools, reports, and models based on the DREW schema, and place those items into a management information system (MIS). The services can then access the MIS and apply those tools to their own archives. The result is that services can benefit directly and rapidly from research, and are then more likely to continue their involvement with the project. This infrastructure creates a collaborative space where researchers and practitioners can benefit from the work of each other and aid us in advancing the field of digital reference.

#index 809494
#* Building lite-weight EAD repositories
#@ Terry Reese
#t 2005
#c 14
#! University Archives and museums traditional haven't been viewed as a bastion for innovative technology development, but for a number of years now, it has been university archives and museums that have made the most significant moves towards adopting and utilizing XML-based metadata schemas for bibliographic description. Unlike the general library profession, which has been able to rely on MARC throughout the years as its primary vehicle for bibliographic description, museums and archives have traditionally had no formal metadata structure to create portable metadata records. It is likely that for this reason that museums and archives were quick to embrace EAD (Encoded Archival Description) as the defacto method for creating portable finding aids. However, while EAD has provided a vehicle for portability, institutions have found that actually using these finding aids within a database or for display can be quite daunting. Often times, individual institutions creating finding aids have no idea how to make use of them within their institution's current infrastructure - often relying on larger organizations like the California Digital Library or the Northwest Digital Archive (NWDA) to provide a vehicle for distributing their materials. And while the consortia method of distribution offers a number of benefits, it does come at a cost of individual institutional identity.Oregon State University currently is one of the participating libraries in the NWDA. This has been a tremendous relationship in terms of creating a resource that provides exposure to a wide number of collections at OSU in relation to other archive collections at other participating NWDA libraries. However, the cost has been a loss of identity in regards to how OSU presents its finding aids to its own user community. As a result, the OSU Archives was creating multiple finding aids - an EAD record for use within the NWDA and a static HTML page for use at OSU.In January 2005, OSU Valley Library started work on a lite-weight EAD repository with the following goals in mind: 1) that the solution be portable to other NWDA institutions, 2) be built on top of current open source technologies (like MySQL, PHP, etc.), 3) provided a method for federated searching of the repository and 4) that it be flexible enough to eventually include other metadata schemas. This lite-weight EAD repository is the first product of this development, which uses PHP, MySQL and Saxon to produce an easily replicable database environment for querying and serving EAD records on the web. Likewise, by building SRU functionality into the EAD repository - this lite-weight solution can also expose it's own resources to the outside world through a standard query and retrieval language.This poster session will discuss the method used to generate a lite-weight search and discovery solution and demonstrate the resulting finished product. This poster session will also discuss the implications of this type of repository solution - particularly the ability for institutions to quickly move EAD elements into a searchable, web-based environment as well as the ability for institutions to include their EAD repositories in a federated search infrastructure using a standard search and retrieval language.

#index 809495
#* Osprey: peer-to-peer enabled content distribution
#@ John Reuning;Paul Jones
#t 2005
#c 14
#% 723444
#% 791020
#! As the size of data and files increases, digital repositories face a growing problem in content distribution. High quality multimedia and research data sets can range from 100's of megabytes to over a terabyte. Web-based digital repositories may exper ience a substantial increase in operating and bandwidth costs when providing materials to the public. Peer-to-peer networks are sometimes suggested as an alternative to traditional centralized repositories [2]. However, critical issues such as data inte grity, access control, and content availability exist when using peer-to-peer technologies [1].Osprey (http://osprey.ibiblio.org) addresses these problems by combining a flexible metadata management system with the BitTorrent peer-to-peer protocol. A Web database application provides searching and browsing of collection objects, and the peer-to-peer component lowers the bandwidth costs by employing distributed downloading. The Permaseed application supplies reliable, persistent peer-to-peer access to files in the digital repository.

#index 809496
#* Integrating image-rich biological information with a web search tool: the inside wood model
#@ Shirley Rodgers;Elisabeth Wheeler;Troy Simpson;Jeff Bartlett
#t 2005
#c 14
#! North Carolina State University is collaborating with global partners to produce a comprehensive Internet-accessible wood anatomy reference, research, and teaching tool incorporating images, taxonomy, and anatomical information sets. With its multiple search capabilities, content types, and user options, InsideWood serves as a model for image-intensive, searchable biological collections. http://insidewood.lib.ncsu.edu/search/

#index 809497
#* What type of page is this?: genre as web descriptor
#@ Mark A. Rosso
#t 2005
#c 14
#% 292563
#% 608365
#% 608646
#! Many have suggested the use of genres to ameliorate the problem of web search, e.g. [1,3,4,5,6,7]. A central issue in the implementation of this idea is the choice of genres to be used as web page descriptors. Several studies have explored user terminology for and recognition of several types of digital documents, e.g., various types of office documents [8], personal homepages [2], and pages returned by user web searches [4,6]. This poster reports on a series of three user studies with the purpose of developing a genre "palette" for use in web retrieval. Pages viewed by participants in these studies were limited to the edu domain, as in [5].In the first study, three participants, an information technology professional, an oncology social worker and a computer science professor, in separate sessions, were given a stack of 102 web page printouts, and were asked to separate the pages into piles according to genre. They were also asked to name the genres by writing the names on sticky notes and placing them on the piles. After the piles were complete, participants were asked to provide a short, one or two sentence, description of each genre, and then to describe the page characteristics that led them to place a page in that genre.A list of 49 genre names and definitions was developed from the work of the three participants, keeping the terminology as similar as possible to the original, while combining definitions which were nearly identical in wording. In a second user study, each of ten participants was given this list of genre name/definition pairs, the same stack of 102 printed web pages (arranged in a different random order for each participant), and a data collection form on which he/she recorded a genre for each web page. For each of the 102 web pages, the participant was given the option to either write a number from the list corresponding to a genre/definition pair which best described the page; or to provide his/her own suggestion for a genre name and definition, if none of those in the list seemed adequate. The participants were drawn from a convenience sample of approximately 10 college graduates of various occupations. Given that participants chose genres from a list of 48, many of which were extremely similar in nature, the resulting level of agreement (half or more of the participants agreeing on one genre for a given page in 60% of the instances) is quite acceptable. A set of five principles for creating a genre palette from individuals' sortings was developed. Based on those principles, the original list was trimmed down to 18 genres.The third study was an online experiment in which 257 college, faculty, students, and staff from two schools categorized a new set of 55 pages using the 18 genres. On average, over 70% agreed on the genre of each page. No study of this scale is known to report user recognition of web genres. This user validation is necessary to set upper bounds for machine categorization efforts. Also, because genre is usually considered to be "socially defined", genre studies using researcher-defined a priori categories (e.g., [5]) may not be able to show genres' usefulness for web search.Interestingly, the genres in this palette, although developed independently, are similar to 7 of 8 Internet-wide genres based on user input reported in [7], and similar to 8 of 11 Internet-wide genres as reported in [3]. Based on these observations, one might infer that some substantial amount of genre knowledge exists among users, even from different cultures (in this case, the United States, Germany, and Sweden).

#index 809498
#* Negotiating identity in the math forum's online mentoring project
#@ Wesley Shumar;Craig Bach
#t 2005
#c 14
#! Drawing on current thinking about identity, social group boundary and informational technology, the research presented in this poster discusses a unique online interactive project at the Math Forum called The Online Mentoring Project. The importance of this work for digital libraries will be highlighted.

#index 809499
#* User centred interactive search in the humanities
#@ Claire Warwick;Jon Rimmer;Ann Blandford;George Buchanan
#t 2005
#c 14
#% 337261
#! This poster describes research on the needs and behaviours of Humanities users of both digital libraries and more traditional information environments.

#index 809500
#* Tools for managing collaboration, communication, and website content development in a distributed digital library community
#@ Marianne Weingroff;Sonal Bhushman
#t 2005
#c 14
#! This poster showcases tools that the Digital Library for Earth System Education (DLESE) has developed to address the needs of its distributed community members to manage collaboration and communication, as well as the development of their own websites using DLESE templates. DLESE has customized several open source content management systems and has integrated its suite of Web services into them. These services enable developers to add customized search services, smart links, and RSS feeds, etc. to their sites.

#index 809501
#* Studying the presence of terrorism on the web: an knowledge portal approach
#@ Yilu Zhou;Jialun Qin;Edna Reid;Guanpi Lai;Hsinchun Chen
#t 2005
#c 14
#% 295520

#index 809502
#* Personalized project space for managing metadata of geography learning objects
#@ Wenbo Zong;Dan Wu;Aixin Sun;Ee-Peng Lim;Dion Hoe-Lian Goh;Yin-Leng Theng;John Hedberg;Chew-Hung Chang
#t 2005
#c 14
#% 378546

#index 809503
#* Icon abacus and ghost icons
#@ Eric A. Bier;Adam Perer
#t 2005
#c 14
#% 760832
#! We present two techniques that make document collection visualizations more informative. Icon abacus uses the horizontal position of icon groups to communicate document attributes. Ghost icons show linked documents by adding temporary icons and by highlighting or dimming existing ones.

#index 809504
#* Measuring the quality of network visualization
#@ Chaomei Chen
#t 2005
#c 14
#% 925087
#! A quantitative method is developed for measuring the quality of network visualizations in terms of log-likelihood metrics resulted from Expectation Maximization (EM) clustering intrinsic and extrinsic attributes of network nodes.

#index 809505
#* Building image-based electronic editions using the edition production technology
#@ Alex Dekhtyar;Ionut E. Iacob;Jerzy Jaromczyk;Kevin Kiernan;Neil Moore;Dorothy C. Porter
#t 2005
#c 14
#! We demonstrate the Edition Production Technology (EPT), an integrated development environment for building Image-based Electronic Editions (IBEE). EPT is developed in Java on top of Eclipse platform and benefits from the openness of Eclipse's plugin architecture and its portability (currently EPT runs on Windows XP, Linux, and Mac OS X). EPT provides software support for building image-based digital libraries of historic documents. Starting with high resolution images of manuscripts and transcriptions of them, EPT tools provide support for creating XML encoding of the electronic edition, searching the electronic edition, linking text and images, and publishing the electronic edition (using filters and XSLT).

#index 809506
#* EVIADA: ethnomusicological video for instruction and analysis digital archive
#@ Jon W. Dunn;William G. Cowan
#t 2005
#c 14
#! The field of ethnomusicology depends heavily on ethnographic research or "fieldwork" by researchers that often involves the capture and subsequent analysis of audio and video information, to help document and understand the musical practices of people all over the world. Ethnomusicologists have used a variety of recording technologies over the years to capture film and video, and much of this footage lies in researchers' offices and home basements. No systematic mechanism exists for preserving and providing access to this video for other students and scholars.The Ethnomusicological Video for Instruction and Analysis Digital Archive (EVIADA) [1] is a multi-year collaborative project between Indiana University and the University of Michigan to create a digital archive for field video recordings captured by ethnomusicology researchers. This digital archive will serve both to preserve this content for future generations of scholars and also to provide a resource to support teaching and learning in ethnomusicology, anthropology, and related disciplines. The creation of EVIADA has involved a unique collaboration between ethnomusicologists, librarians, archivists, and technologists in carrying out all stages of the project, including video digitization, metadata creation, and system and user interface design.As part of the project, we are developing several software tools: The Segmentation/Annotation Tool is a Java Swing application written using Apple's QuickTime for Java API. It allows an ethnomusicologist who is contributing a video collection to the archive to divide that video into a hierarchy of segments, attach free-text descriptions and controlled vocabulary terms to each segment, and output this information in the form of a METS [3] XML document incorporating MODS [2] descriptive metadata records. This METS document can then be ingested into downstream archival and delivery systems. We hope to evolve this software into a more general-purpose tool for the creation of METS documents for video objects.We are also building a web-based user interface on top of the Fedora digital repository system to allow users to search and browse video content in the collection via the descriptive metadata and annotations, making appropriate use of controlled vocabulary thesauri to increase search recall.

#index 809507
#* A fluid treemap interface for personal digital libraries
#@ Lance Good;Ashok C. Popat;William C. Janssen;Eric Bier
#t 2005
#c 14
#! The UC system employs hybrid quantum/continuous treemaps for fluidly interacting with documents in a personal digital library. By incorporating a document reader application within the visualization workspace, UC supports multi-document reading tasks that have been traditionally accomplished by laying out documents on a physical desk. One of the overall goals of the system is to eliminate the boundary between acquiring and using documents.

#index 809508
#* Processing XML documents with overlapping hierarchies
#@ Ionut E. Iacob;Alex Dekhtyar
#t 2005
#c 14
#% 772033
#% 783695
#% 806624
#! The problem of overlapping markup hierarchies, first mentioned in the context of SGML, often occurs in XML text encoding applications for humanities. Previous solutions to the problem rely on manual maintenance of the markup and address only the problem of representing overlapping features in XML, leaving the issues of automated maintenance and querying open. As a consequence, traditional XML tools are of little practical use when dealing with overlapping markup. In this work we demonstrate the implementation of our framework for management of concurrent XML hierarchies from a computer science perspective. We propose an underlying model, data structures, APIs, and algorithms so that the most of the burden of managing concurrent XML hierarchies would be born by the software.

#index 809509
#* The UpLib personal digital library system
#@ William C. Janssen
#t 2005
#c 14
#% 731013
#% 760855
#! We demonstrate the operation of UpLib, a visually-oriented personal digital library system.

#index 809510
#* Evaluation of mobile information retrieval strategies
#@ Joemon M. Jose;Stephen Downes
#t 2005
#c 14
#! In this paper we describe and evaluate three strategies for information retrieval on mobile devices. Results show the effectiveness of our adaptive approach.

#index 809511
#* Media matrix: a digital library research tool
#@ Mark Kornbluh;Michael Fegan;Dean Rehberger
#t 2005
#c 14
#! Media Matrix (version 1.0)- an online, server side tool that helps users to find, segment, annotate, organize, and publish streaming media found in digital libraries on the Internet.

#index 809512
#* Visual understanding environment
#@ Anoop Kumar;Ranjani Saigal
#t 2005
#c 14
#! The Visual Understanding Environment (VUE) project at Tufts' Academic Technology department provides faculty and students with tools to successfully integrate digital resources into their teaching and learning. VUE provides a visual environment for structuring, presenting, and sharing digital information and an OKI-compliant software bridge for connecting to FEDORA-based digital repositories. Using VUE's concept mapping interface, faculty and students design customized semantic networks of digital resources drawing from digital libraries, local files and the Web. The resulting content maps can then be viewed and exchanged online.

#index 809513
#* Schema mapper: a visualization tool for DL integration
#@ Ananth Raghavan;Divya Rangarajan;Rao Shen;Marcos André Gonçalves;Naga Srinivas Vemuri;Weiguo Fan;Edward A. Fox
#t 2005
#c 14
#! Schema mapping is a challenging problem. It has come to the fore in recent years; there are important applications like database schema integration and, more recently, digital library merging of heterogeneous data. Previous studies have approached the schema mapping process either from algorithmic or visualization perspectives, with few integrating both. With Schema Mapper we demonstrate a semi-automatic tool for schema integration that combines a novel visual interface with an algorithm-based recommendation engine. Schemas are visualized as hyperbolic trees (see Fig. 1), thus allowing more schema nodes to be displayed at one time. Matches to selections are recommended to the user, which makes the mapping operation easier and faster.

#index 809514
#* Using concept maps as a cross-language resource discovery tool for large documents in digital libraries
#@ Ryan Richardson;Edward A. Fox
#t 2005
#c 14
#% 481290
#! Project Gutenburg, the Million Book Project, the Networked Digital Library of Theses and Dissertations, Amazon's book search service, and the recently announced collaboration of Google and leading libraries, all aim to make available large numbers of book-length objects, in a variety of languages. Traditional approaches to discovering a suitable book for a particular purpose have generally relied on catalog records, sometimes enhanced with abstracts. Full-text searching - popular, e.g., with legal and government documents - and passage retrieval techniques, suitable for encyclopedias and reference works, have not been adequately tested with large collections of large objects.

#index 809515
#* Terror tracker system: a web portal for terrorism research
#@ Robert P. Schumaker;Hsinchun Chen;Tao Wang;Jerod Wilkerson
#t 2005
#c 14
#% 295520
#% 750039

#index 809516
#* Mining and analyzing digital archive usage data to support collection development decisions
#@ Jewel Ward;Johan Bollen;Jeffrey Pearson;Shing-Cheung Chan;Hui-Hsien Chi;Marie Chi;Kristine Guevara;Hsiao-han Huang;Genesan Kim;Maks Krivokon;Bo H. Lee;Pei-Han Li;Fenny Muliawan;Vu Nguyen;Barry W. Boehm;A. Winsor Brown;Edward Colbert;Alex Lam;Mayur Patel
#t 2005
#c 14
#% 760910
#! We demonstrate a "collection development decision support tool" that mines digital archive usage data. We want to better understand the University of Southern California (USC) Digital Archive's collection structure by analyzing the objects' characteristics, by analyzing the relationships between viewed objects, and by understanding usage trends over time. By relying on implicit patterns of usage data, such as co-retrievals, rather than explicit data, such as hit counts, we believe we can make more informed decisions about where to expend our resources.

#index 809517
#* BioPortal: a case study in infectious disease informatics
#@ Daniel Zeng;Hsinchun Chen;Chunju Tseng;Wei Chang;Millicent Eidson;Ivan Gotham;Cecil Lynch
#t 2005
#c 14
#% 859626
#! We present the BioPortal system, an integrated cross-jurisdictional data sharing and analysis environment to facilitate detection, prevention, and management of infectious disease outbreaks.

#index 809518
#* Introduction to (teaching/learning about) digital libraries
#@ Edward A. Fox;Marcos André Gonçalves
#t 2005
#c 14
#% 750866
#! This tutorial provides a thorough and deep introduction to the DL field, building upon a firm theoretical foundation (starting with "5S": Streams, Structures, Spaces, Scenarios, Societies [1]), giving careful definitions and explanations of all the key parts of a "minimal digital library", and expanding from that basis to cover key DL issues, illustrated with a well-chosen set of case studies.

#index 809519
#* Evaluating digital libraries
#@ Thomas C. Reeves;Susan Buhr;Lecia Barker
#t 2005
#c 14
#! "So far, evaluation has not kept pace with efforts in digital libraries (or with digital libraries themselves), has not become part of their integral activity, and has not been even specified as to what it means, and how to do it." - [1]Conducting a comprehensive evaluation of a digital library requires a "triangulation" approach including multiple models, procedures, and tools. Carrying out valid evaluations of digital libraries in a timely and efficient manner is the focus of this tutorial. Why is evaluation of digital libraries so important? Each year sees the introduction of new digital libraries promoted as valuable resources for education and other needs. Yet systematic evaluation of the implementation and efficacy of these digital library systems is often lacking. This tutorial is specifically designed to establish evaluation as a key strategy throughout the design, development, and implementation of digital libraries. The tutorial focuses on a decision-oriented model for evaluating digital libraries using multiple methods such as: service evaluation, usability evaluation, information retrieval, biometrics evaluation, transaction log analysis survey methods, interviews and focus groups, observations, and experimental methods. Participants in this tutorial will learn how to implement models and procedures for evaluating digital libraries at all levels of education. The tutorial includes presentations with actual case studies that are focused on a variety of digital library evaluation strategies. Participants will also receive a copy of Evaluating Digital Libraries: A User-Friendly Guide.

#index 809520
#* Thesauri and ontologies in digital libraries
#@ Dagobert Soergel
#t 2005
#c 14

#index 809521
#* Copyright transfer agreements and self-archiving
#@ Anita S. Coleman;Cheryl Knott Malone
#t 2005
#c 14
#! Concerns about intellectual property rights are a significant barrier to the practice of scholarly self-archiving in institutional and other types of digital repositories. This introductory level, half-day tutorial will demystify the journal copyright transfer agreements (CTAs) that often are the source of these rights concerns of scholars. In addition, participants will be introduced to the deposit processes of self-archiving in an interdisciplinary repository and open access archive (OAA), such as DLIST, Digital Library for Information Science and Technology.

#index 809522
#* Using standards in digital library design & development
#@ Jeroen Bekaert;Xiaoming Liu;Herbert Van de Sompel
#t 2005
#c 14
#! This tutorial will cover a set of Standards and defacto Standards that can play a role in the design and development of Digital Library applications. The Standards that will be discussed are the ISO MPEG-21 Digital Item Declaration, the ISO MPEG-21 Digital Item Identification, the ISO MPEG-21 Digital Item Processing, the Open Archives Protocol for Metadata Harvesting, the Internet Archive ARC file format, the NISO OpenURL Framework for Context-Sensitive Services, and the proposed info URI scheme. The tutorial will discuss these Standards by illustrating how they have been used in the context of the aDORe Digital Object repository. aDORe [8] has been designed and implemented for ingesting, storing, and accessing a vast collection of Digital Objects at the Research Library of the Los Alamos National Laboratory. Since aDORe is not a product, the tutorial is not a product advertisement. Rather, it is an opportunity for designers and developers to learn about Standards that can help addressing real-life challenges in DL design and development, and help increase interoperability across systems. The presenters are actively involved in all of the standardization efforts that are discussed.

#index 809523
#* Building preservation environments
#@ Reagan W. Moore;Richard Marciano
#t 2005
#c 14
#! The preservation of digital entities requires data management technologies that are provided by digital libraries and data grids. Digital libraries provide standard data organization and presentation mechanisms. Data grids provide support for infrastructure independence, the ability to incorporate new technology as it becomes available. Preservation environments integrate these technologies to assure the authenticity and integrity of digital entities. We will describe the concepts behind preservation and illustrate the concepts with three data preservation environments based on the NARA research prototype persistent archive, the NHPRC Persistent Archive Testbed, and the NSF NSDL persistent archive.

#index 809524
#* Building digital library collections with greenstone
#@ Ian H. Witten;David Bainbridge
#t 2005
#c 14
#! This tutorial will demonstrate how to build a variety of different kinds of digital library collections with the Greenstone digital library software, a comprehensive, open-source system for constructing, presenting, and maintaining information collections. Collections will be built from HTML documents; Word, PDF and PostScript documents; images in various formats; MP3 and MIDI audio; MARC records; and more. For each collection, various different full-text search indexes and metadata-based browsers will be created.Attendees who wish to are encouraged to bring their laptops, install Greenstone from a CD-ROM that we will provide, along with various sample files, and follow along with the demonstrations on their own machine.

#index 809525
#* Practical digital library interoperability standards
#@ David Bainbridge;Ian H. Witten
#t 2005
#c 14
#! As the field of digital libraries matures and new systems and standards develop, the ability to interoperate between systems becomes paramount. This tutorial gives a practical introduction to many recent standards and de facto standards for interoperability, and illustrates them using open source digital library software-including online demonstrations of interoperation issues and solutions. Core standards that are discussed include Dublin Core, OAI-PMH, METS, and MODS. We use interoperation between Greenstone and DSpace as a motivating case study.For those demonstrations that involve Greenstone, attendees who wish to may bring their laptops, install Greenstone from a CD-ROM that we will provide, along with various sample files, and follow along with the demonstrations on their own machine.

#index 809526
#* Developing a digital library education program
#@ Javed Mostafa;Kristine Brancolini;Linda C. Smith;William Mischo
#t 2005
#c 14

#index 809527
#* International scientific data, standards, & digital libraries
#@ Laura M. Bartolo;John R. Rumble
#t 2005
#c 14
#% 480469
#% 807028
#! This workshop explores the various models used successfully to develop internationals standards for languages and tools, as well as scientific & technical information for use of data on the emerging Semantic Web. The advantages and disadvantages of the models will be highlighted in a manner that allows emerging standards to benefit from existing experience.

#index 809528
#* Studying digital library users in the wild: theories, methods, and analytical approaches
#@ Michael Khoo;David Ribes
#t 2005
#c 14
#% 739905
#! As digital libraries continue the transition from research to operational status, understanding how they impact on the educational and learning practices of their users becomes an increasingly important objective for both library developers and evaluators. This workshop will examine the theoretical and methodological issues involved in the qualitative, naturalistic, and/or longitudinal study of the users of digital libraries. It will focus on the methodologies that can be used to capture the behaviors of digital library users, and the theoretical frameworks that can be used to analyze these behaviors, including ethnography, ethnomethodology, grounded theory, discourse analysis, scenarios, in-depth interviews and focus groups.

#index 809529
#* Next generation knowledge organization systems: integration challenges and strategies
#@ Gail Hodge;Linda Hill;Marcia Lei Zeng;Jian Qin;Douglas Tudhope
#t 2005
#c 14
#! This year's Networked Knowledge Organization Systems (NKOS) workshop built on seven years of workshops in the U.S. and Europe on issues regarding enabling networked knowledge organization systems (KOS), such as classification systems, thesauri, gazetteers, taxonomies, and ontologies, to support the description, retrieval, and use of diverse information resources. Now, many efforts are underway to research the issues and implement solutions to the challenges of networking and integrating KOS across somewhat isolated domains: indexing services and thesaurus builders; computer scientists and systems integrators; ontologists; taxonomists; and others. In many cases, requirements to solve these integration issues have become mission critical; the need to support computational, programmatic integration to handle masses of data from independent sources is pushing the research and development agenda. The need to move forward to meet these challenges while at the same time applying the best practices and "wisdom" developed through years of practical experience is acute.The JCDL-NKOS workshop for 2005 brought together researchers and implementers from diverse international communities who are developing new models, conducting research, and implementing practical solutions for networking KOS and integrating the associated information and data resources.

#index 874452
#* Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries
#@ Gary Marchionini;Michael L. Nelson;Catherine C. Marshall
#t 2006
#c 14
#! Welcome to JCDL 2006. The ACM/IEEE Joint Conference on Digital Libraries (JCDL) is a major international forum focusing on digital libraries and associated technical, practical, and social issues. JCDL encompasses the many meanings of the term "digital libraries," including (but not limited to) new forms of information institutions; operational information systems with all manner of digital content; new means of selecting, collecting, organizing, and distributing digital content; digital preservation and archiving; and theoretical models of information media, including document genres and electronic publishing.The conference theme is "Opening Information Horizons". This theme is explored in the two keynote addresses, one covering the technological, economic and social issues of putting books online and the other covering open information and the threats, challenges and responsibilities it entails. The conference also features two panels: an update on the National Digital Information Infrastructure and Preservation Program and the other covering an emerging effort regarding scholarly repositories.This year, there were 248 total submissions from 22 countries. From 107 full papers and 81 short papers, the program committee selected 28 full papers and 29 short papers for presentation at the conference. In addition, 37 posters and 13 demonstrations will be presented in a special evening session. As in past years, we will be awarding the: Vannevar Bush Best Paper Award (sponsored by ACM) Best Student Paper (sponsored by IEEE-CS Technical Committee on Digital Libraries) Best Poster (sponsored by University of North Carolina, School of Information and Library Science). Nominees for the best paper awards will be announced at the opening session of the conference and the award will be presented at the banquet. The best poster award is determined by popular vote during the poster and demo session. As in previous JCDL conferences, the conference opened with tutorials and will conclude with workshops. JCDL 2006 continues with the doctoral consortium, introduced in last year's conference.

#index 874453
#* Exploring digital libraries: integrating browsing, searching, and visualization
#@ Rao Shen;Naga Srinivas Vemuri;Weiguo Fan;Ricardo da S. Torres;Edward A. Fox
#t 2006
#c 14
#% 1260
#% 29585
#% 56449
#% 142618
#% 186518
#% 249142
#% 294893
#% 434818
#% 482087
#% 528056
#% 659998
#% 717133
#% 750866
#% 809317
#% 856157
#% 857481
#% 979688
#% 1709391
#! Exploring services for digital libraries (DLs) include two major paradigms, browsing and searching, as well as other services such as clustering and visualization. In this paper, we formalize and generalize DL exploring services within a DL theory. We develop theorems to indicate that browsing and searching can be converted or mapped to each other under certain conditions. The theorems guide the design and implementation of exploring services for an integrated archaeological DL, ETANA-DL. Its integrated browsing and searching can support users in moving seamlessly between these operations, minimizing context switching, and keeping users focused. It also integrates browsing and searching into a single visual interface for DL exploration. A user study to evaluate ETANA-DL's exploring services helped validate our hypotheses.

#index 874454
#* combinFormation: a mixed-initiative system for representing collections as compositions of image and text surrogates
#@ Andruid Kerne;Eunyee Koh;Blake Dworaczyk;J. Michael Mistrot;Hyun Choi;Steven M. Smith;Ross Graeber;Daniel Caruso;Andrew Webb;Rodney Hill;Joel Albea
#t 2006
#c 14
#% 68659
#% 173738
#% 214673
#% 238524
#% 240805
#% 272793
#% 281362
#% 344930
#% 406493
#% 446934
#% 480309
#% 679853
#% 712938
#% 760871
#% 769227
#% 789234
#% 802751
#% 1389375
#! People need to find, work with, and put together information. Diverse activities, such as scholarly research, comparison shopping, and entertainment involve collecting and connecting information resources. We need to represent collections in ways that promote understanding of individual information resources and also their relationships. Representing individual resources with images as well as text makes good use of human cognitive facilities. Composition, an alternative to lists, means putting representations of elements in a collection together using design principles to form a connected whole.We develop combinFormation, a mixed-initiative system for representing collections as compositions of image and text surrogates. The system provides a set of direct manipulation facilities for forming, editing, organizing, and distributing collections as compositions. Additionally, to assist users in sifting through the vast expanse of potentially relevant information resources, the system also includes a generative agent that can proactively engage in processes of collecting information resources and forming image and text surrogates. A generative temporal visual composition agent develops the collection and its visual representation over time, enabling users to see more possibilities. To keep the user in control, we develop interactive techniques that enable the user to direct the agent.For evaluation, we conducted a field study in an undergraduate general education course offered in the architecture department. Alternating groups of students used combinFormation as an aid in preparing one of two major assignments involving information discovery to support processes of invention. The students that used combinFormation were found to perform better.

#index 874455
#* InfoGallery: informative art services for physical library spaces
#@ Kaj Grønbæk;Anne Rohde;BalaSuthas Sundararajah;Sidsel Bech-Petersen
#t 2006
#c 14
#% 15452
#% 173738
#% 192065
#% 316404
#% 342536
#% 349624
#% 428542
#% 446908
#% 447005
#% 452620
#% 579881
#% 752149
#% 769204
#% 777856
#% 784067
#! Much focus in digital libraries research has been devoted to new online services rather than services for the visitors in the physical library. This paper describes InfoGallery, which is a web-based infrastructure for enriching the physical library space with informative art "exhibitions" of digital library material and other relevant information, such as RSS news streams, event announcements etc. InfoGallery presents information in an aesthetically attractive manner on a variety of surfaces in the library, including cylindrical displays and floors. The infrastructure consists of a server structure, an editor application and a variety of display clients. The paper discusses the design of the infrastructure and its utilization of RSS, podcasts and manually edited news. Applications in the library domain are described and the experiences are discussed.

#index 874456
#* The challenge of virginia banks: an evaluation of named entity analysis in a 19th-century newspaper collection
#@ Gregory Crane;Alison Jones
#t 2006
#c 14
#% 287210
#% 378508
#% 397132
#% 452448
#% 508419
#% 580076
#% 760828
#% 770448
#% 782760
#% 809447
#% 809457
#% 1387578
#% 1709410
#! This paper evaluates automatic extraction of ten named entity classes from a 19th century newspaper, the Civil War years of the Richmond Times Dispatch, digitized with IMLS support by the University of Richmond. This paper analyzes success with ten categories of entities prominent in these newspapers and the particular problems that these classes of named entities raise. Personal and place names are familiar but some more important categories (such as ship names and military units) illustrate some of the challenges that named entity identification confronts as it evolves into a fundamental tool not only for automatic metadata generation but also for searching and browsing as well. We conclude by suggesting the kinds of knowledge sources that digital libraries need to assemble as part of their machine readable reference collections to support named entity identification as a core service.

#index 874457
#* Learning to deduplicate
#@ Moisés G. de Carvalho;Marcos André Gonçalves;Alberto H. F. Laender;Altigran S. da Silva
#t 2006
#c 14
#% 124073
#% 252473
#% 271128
#% 314740
#% 348165
#% 350103
#% 387427
#% 438103
#% 501231
#% 577263
#% 654467
#% 729887
#% 729913
#% 819552
#% 870896
#% 1016182
#! Identifying record replicas in Digital Libraries and other types of digital repositories is fundamental to improve the quality of their content and services as well as to yield eventual sharing efforts. Several deduplication strategies are available, but most of them rely on manually chosen settings to combine evidence used to identify records as being replicas. In this paper, we present the results of experiments we have carried out with a novel Machine Learning approach we have proposed for the deduplication problem. This approach, based on Genetic Programming (GP), is able to automatically generate similarity functions to identify record replicas in a given repository. The generated similarity functions properly combine and weight the best evidence available among the record fields in order to tell when two distinct records represent the same real-world entity. The results of the experiments show that our approach outperforms the baseline method by Fellegi and Sunter by more than 12% when identifying replicas in a data set containing researcher's personal data, and by more than 7%, in a data set with article citation data.

#index 874459
#* Also by the same author: AKTiveAuthor, a citation graph approach to name disambiguation
#@ Duncan M. McRae-Spencer;Nigel R. Shadbolt
#t 2006
#c 14
#% 375017
#% 438103
#% 760866
#% 830526
#! The desire for definitive data and the semantic web drive for inference over heterogeneous data sources requires co-reference resolution to be performed on those data. In particular, name disambiguation is required to allow accurate publication lists, citation counts and impact measures to be determined. This paper describes a graph-based approach to author disambiguation on large-scale citation networks. Using self-citation, co-authorship and document source analyses, AKTiveAuthor clusters papers, achieving precision of 0.997 and recall of 0.818 over a test group of eight surname clusters.

#index 874460
#* Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries
#@ Gary Marchionini;Michael L. Nelson;Catherine C. Marshall
#t 2006
#c 14
#! Welcome to JCDL 2006. The ACM/IEEE Joint Conference on Digital Libraries (JCDL) is a major international forum focusing on digital libraries and associated technical, practical, and social issues. JCDL encompasses the many meanings of the term "digital libraries," including (but not limited to) new forms of information institutions; operational information systems with all manner of digital content; new means of selecting, collecting, organizing, and distributing digital content; digital preservation and archiving; and theoretical models of information media, including document genres and electronic publishing.The conference theme is "Opening Information Horizons". This theme is explored in the two keynote addresses, one covering the technological, economic and social issues of putting books online and the other covering open information and the threats, challenges and responsibilities it entails. The conference also features two panels: an update on the National Digital Information Infrastructure and Preservation Program and the other covering an emerging effort regarding scholarly repositories.This year, there were 248 total submissions from 22 countries. From 107 full papers and 81 short papers, the program committee selected 28 full papers and 29 short papers for presentation at the conference. In addition, 37 posters and 13 demonstrations will be presented in a special evening session. As in past years, we will be awarding the: Vannevar Bush Best Paper Award (sponsored by ACM) Best Student Paper (sponsored by IEEE-CS Technical Committee on Digital Libraries) Best Poster (sponsored by University of North Carolina, School of Information and Library Science). Nominees for the best paper awards will be announced at the opening session of the conference and the award will be presented at the banquet. The best poster award is determined by popular vote during the poster and demo session. As in previous JCDL conferences, the conference opened with tutorials and will conclude with workshops. JCDL 2006 continues with the doctoral consortium, introduced in last year's conference.

#index 874461
#* Probabilistic, object-oriented logics for annotation-based retrieval in digital libraries
#@ Ingo Frommholz;Norbert Fuhr
#t 2006
#c 14
#% 186080
#% 249090
#% 262094
#% 280809
#% 330770
#% 360717
#% 458744
#% 567134
#% 665856
#% 755035
#% 760875
#% 766456
#% 770451
#% 809422
#% 854646
#% 1715610
#% 1719581
#% 1914885
#! In this paper we introduce POLAR, a probabilistic object-oriented logical framework for annotation-based information retrieval. In POLAR, the knowledge about digital objects, annotations and their relationships in a digital library repository can be modelled considering certain characteristics of annotations and annotated objects. Insights about these characteristics are gained by an analysis of the annotation models behind existing systems and a discussion of an object-oriented, logical view on relevant objects in a digital library. Retrieval methods applied in a digital library should take annotations into account to satisfy users' information needs. POLAR thus supports a wide range of flexible and powerful annotation-based fact and content queries by making use of knowledge and relevance augmentation. An evaluation of our approach on email discussions shows performance improvements when annotation characteristics are considered.

#index 874462
#* Bibliometric impact measures leveraging topic analysis
#@ Gideon S. Mann;David Mimno;Andrew McCallum
#t 2006
#c 14
#% 11997
#% 249143
#% 420495
#% 635091
#% 722904
#% 788094
#% 788107
#% 846234
#% 852014
#% 874707
#% 1289476
#! Measurements of the impact and history of research literature provide a useful complement to scientific digital library collections. Bibliometric indicators have been extensively studied, mostly in the context of journals. However, journal-based metrics poorly capture topical distinctions in fast-moving fields, and are increasingly problematic with the rise of open-access publishing. Recent developments in latent topic models have produced promising results for automatic sub-field discovery. The fine-grained, faceted topics produced by such models provide a clearer view of the topical divisions of a body of research literature and the interactions between those divisions. We demonstrate the usefulness of topic models in measuring impact by applying a new phrase-based topic discovery model to a collection of 300,000 Computer Science publications, collected by the Rexa automatic citation indexing system.

#index 874463
#* A comparative study of citations and links in document classification
#@ Thierson Couto;Marco Cristo;Marcos André Gonçalves;Pável Calado;Nivio Ziviani;Edleno Moura;Berthier Ribeiro-Neto
#t 2006
#c 14
#% 46803
#% 169718
#% 248810
#% 268079
#% 271128
#% 281209
#% 281214
#% 288306
#% 290830
#% 309142
#% 348178
#% 413663
#% 430761
#% 458379
#% 464267
#% 617186
#% 730061
#% 819772
#% 846237
#% 1387536
#% 1558464
#! It is well known that links are an important source of information when dealing with Web collections. However, the question remains on whether the same techniques that are used on the Web can be applied to collections of documents containing citations between scientific papers. In this work we present a comparative study of digital library citations and Web links, in the context of automatic text classification. We show that there are in fact differences between citations and links in this context. For the comparison, we run a series of experiments using a digital library of computer science papers and a Web directory. In our reference collections, measures based on co-citation tend to perform better for pages in the Web directory, with gains up to 37% over text based classifiers, while measures based on bibliographic coupling perform better in a digital library. We also propose a simple and effective way of combining a traditional text based classifier with a citation-link based classifier. This combination is based on the notion of classifier reliability and presented gains of up to 14% in micro-averaged F1 in the Web collection. However, no significant gain was obtained in the digital library. Finally, a user study was performed to further investigate the causes for these results. We discovered that misclassifications by the citation-link based classifiers are in fact difficult cases, hard to classify even for humans.

#index 874464
#* Augmenting interoperability across scholarly repositories
#@ Tony Hey;Herbert Van de Sompel;Don Waters;Cliff Lynch;Carl Lagoze
#t 2006
#c 14
#! The panel will discuss various aspects related to an invitational meeting held at the Mellon Foundation On April 20th and 21st 2006 aimed at identifying concrete steps that can be taken to reach new levels of interoperability across scholarly repositories. The focus of the meeting was specifically on repository interfaces that support locating, identifying, harvesting, retrieving and submitting complex digital objects.

#index 874465
#* Quantifying software requirements for supporting archived office documents using emulation
#@ Thomas Reichherzer;Geoffrey Brown
#t 2006
#c 14
#% 187218
#% 304014
#% 325723
#% 332739
#% 332890
#% 378537
#% 577061
#% 578065
#% 597429
#% 1709412
#! This paper addresses the issues associated with building software images to support a collection of archived documents using machine emulators. Emulation has been proposed as a strategy for preservation of digital documents that require their original software for access. The creation of software images is a critical component in archiving documents via emulation. The software images include the operating system, application software, and supporting software artifacts such as fonts and Codecs (Compression-Decompression algorithm). A practical emulation environment to support a digital document requires both an emulator and a software image. This paper considers the issues associated with creating such software images to support Microsoft Office documents. In particular, we discuss a set of software tools and strategies that we developed to automatically analyze the dependencies of Microsoft Office documents on software resources and supporting files. As a proof of concept, the tools and strategies have been applied to establish dependencies of Office documents from a document library containing approximately 200,000 documents and to automatically collect missing resources such as fonts. The software tools are a first step toward an interactive system that aids in the construction of robust emulation environments for preserving digital artifacts. However, they may also be used in other contexts, for example, to support screening of documents for archiving and migration to new platforms to ensure correct visualization.

#index 874466
#* Building a research library for the history of the web
#@ William Y. Arms;Selcuk Aya;Pavel Dmitriev;Blazej J. Kot;Ruth Mitchell;Lucia Walle
#t 2006
#c 14
#% 268079
#% 282905
#% 378520
#% 723279
#! This paper describes the building of a research library for studying the Web, especially research on how the structure and content of the Web change over time. The library is particularly aimed at supporting social scientists for whom the Web is both a fascinating social phenomenon and a mirror on society.The library is built on the collections of the Internet Archive, which has been preserving a crawl of the Web every two months since 1996. The technical challenges in organizing this data for research fall into two categories: high-performance computing to transfer and manage the very large amounts of data, and human-computer interfaces that empower research by non-computer specialists.

#index 874467
#* The processing of digitized works
#@ José Borbinha;João Gil;Gilberto Pedrosa;João Penas
#t 2006
#c 14
#% 760818
#! This paper describes the processing of digitised works at the National Library of Portugal, as done in the scope of the National Digital Library initiate (BND). This comprises the normalization of the names of the images, the creation of technical metadata, image processing, OCR, indexing, and the creation of derived copies for preservation and copies for access in PNG, JPG, GIF, and PDF. The structural descriptions of all the objects are done in METS.

#index 874468
#* Document level interoperability for collection creators
#@ David Bainbridge;Kaun Yu (Jeffrey) Ke;Ian H. Witten
#t 2006
#c 14
#% 337235
#% 809524
#! Digital library interoperability for both documents and metadata is a critical and complex issue. Although many relevant standards have been developed, and continue to evolve, in practice things are not quite so easy as they seem. We have built a software environment called the Exchange Center that helps digital librarians manage the process of sourcing documents and metadata from various repositories, adding local content where necessary, and exporting the resulting collection into formats that are suitable for digital library repositories. This paper describes the software, which is built on Greenstone but does not require its use as the final digital library server.

#index 874469
#* Repository software evaluation using the audit checklist for certification of trusted digital repositories
#@ Joanne S. Kaczmarek;Thomas G. Habing;Janet Eke
#t 2006
#c 14
#% 657347
#! The NDIIPP ECHO DEPository project [1] digital repository evaluation will use an augmented version of the draft Audit Checklist for Certification of Trusted Digital Repositories (Audit Checklist) [2] to provide a framework for examining how well currently popular repository software applications support the notion of a "trusted digital repository." The evaluation will also demonstrate the application of a scoring software evaluation methodology similar to one developed by the Center for Data Insight (CDI) at Northern Arizona University [3], used for evaluation data mining software. This scoring methodology in conjunction with the Audit Checklist can be used as a tool by librarians, archivists, and other data custodians to make informed decisions as they develop digital preservation management services.

#index 874470
#* A hierarchical, HMM-based automatic evaluation of OCR accuracy for a digital library of books
#@ Shaolei Feng;R. Manmatha
#t 2006
#c 14
#% 288885
#% 289942
#% 295899
#% 318125
#% 445331
#% 624580
#% 738466
#% 740903
#% 1502445
#% 1740416
#! A number of projects are creating searchable digital libraries of printed books. These include the Million Book Project, the Google Book project and similar efforts from Yahoo and Microsoft. Content-based on line book retrieval usually requires first converting printed text into machine readable (e.g. ASCII) text using an optical character recognition (OCR) engine and then doing full text search on the results. Many of these books are old and there are a variety of processing steps that are required to create an end to end system. Changing any step (including the scanning process) can affect OCR performance and hence a good automatic statistical evaluation of OCR performance on book length material is needed. Evaluating OCR performance on the entire book is non-trivial. The only easily obtainable ground truth (the Gutenberg e-texts) must be automatically aligned with the OCR output over the entire length of a book. This may be viewed as equivalent to the problem of aligning two large (easily a million long) sequences. The problem is further complicated by OCR errors as well as the possibility of large chunks of missing material in one of the sequences. We propose a Hidden Markov Model (HMM) based hierarchical alignment algorithm to align OCR output and the ground truth for books. We believe this is the first work to automatically align a whole book without using any book structure information. The alignment process works by breaking up the problem of aligning two long sequences into the problem of aligning many smaller subsequences. This can be rapidly and effectively done. Experimental results show that our hierarchical alignment approach works very well even if OCR output has a high recognition error rate. Finally, we evaluate the performance of a commercial OCR engine over a large dataset of books based on the alignment results.

#index 874471
#* Combining DOM tree and geometric layout analysis for online medical journal article segmentation
#@ Jie Zou;Daniel Le;George R. Thoma
#t 2006
#c 14
#% 131580
#% 150644
#% 251159
#% 296377
#% 309741
#% 324987
#% 330765
#% 443727
#% 480135
#% 577281
#% 625351
#% 645505
#% 1394469
#! We describe an HTML web page segmentation algorithm, which is applied to segment online medical journal articles (regular HTML and PDF-Converted-HTML files). The web page content is modeled by a zone tree structure based primarily on the geometric layout of the web page. For a given journal article, a zone tree is generated by combining DOM tree analysis and recursive X-Y cut algorithm. Combining with other visual cues, such as background color, font size, font color and so on, the page is segmented into homogeneous regions. Evaluation is conducted with 104 articles from 11 journals. Out of 9726 ground-truth zones, 9376 zones are correctly segmented, for an accuracy of 96.40%. Segmenting the entire web page into zones can significantly expedite and increase the accuracy of the subsequent information retrieval steps.

#index 874472
#* Automatic categorization of figures in scientific documents
#@ Xiaonan Lu;Prasenjit Mitra;James Z. Wang;C. Lee Giles
#t 2006
#c 14
#% 8153
#% 181378
#% 249143
#% 258854
#% 263214
#% 269217
#% 318785
#% 321652
#% 345848
#% 384905
#% 444004
#% 614036
#% 629589
#% 721163
#% 783681
#% 800197
#% 809414
#% 809426
#% 809435
#% 809437
#% 809459
#% 809460
#% 840455
#% 1855070
#% 1856088
#! Figures are very important non-textual information contained in scientific documents. Current digital libraries do not provide users tools to retrieve documents based on the information available within the figures. We propose an architecture for retrieving documents by integrating figures and other information. The initial step in enabling integrated document search is to categorize figures into a set of pre-defined types. We propose several categories of figures based on their functionalities in scholarly articles. We have developed a machine-learning-based approach for automatic categorization of figures. Both global features, such as texture, and part features, such as lines, are utilized in the architecture for discriminating among figure categories. The proposed approach has been evaluated on a testbed document set collected from the CiteSeer scientific literature digital library. Experimental evaluation has demonstrated that our algorithms can produce acceptable results for realworld use. Our tools will be integrated into a scientific document digital library.

#index 874473
#* XML views for electronic editions
#@ Ionut E. Iacob;Alex Dekhtyar
#t 2006
#c 14
#% 809409
#! In this paper we discuss the implementation of user-defined views over multihierarchical document-centric XML documents.

#index 874474
#* Exploring erotics in Emily Dickinson's correspondence with text mining and visual interfaces
#@ Catherine Plaisant;James Rose;Bei Yu;Loretta Auvil;Matthew G. Kirschenbaum;Martha Nell Smith;Tanya Clement;Greg Lord
#t 2006
#c 14
#% 126298
#% 127640
#% 172811
#% 201992
#% 280817
#% 290482
#% 301229
#% 301234
#% 334582
#% 392362
#% 392816
#% 458379
#% 529155
#% 571360
#% 641060
#% 720191
#% 730283
#% 780683
#% 786497
#% 789237
#% 797994
#% 802859
#% 858577
#! This paper describes a system to support humanities scholars in their interpretation of literary work. It presents a user interface and web architecture that integrates text mining, a graphical user interface and visualization, while attempting to remain easy to use by non specialists. Users can interactively read and rate documents found in a digital libraries collection, prepare training sets, review results of classification algorithms and explore possible indicators and explanations. Initial evaluation steps suggest that there is a rationale for "provocational" text mining in literary interpretation.

#index 874475
#* Time period directories: a metadata infrastructure for placing events in temporal and geographic context
#@ Vivien Petras;Ray R. Larson;Michael Buckland
#t 2006
#c 14
#% 206512
#! Metadata is ordinarily used to describe documents, but it can also constitute a form of infrastructure for access to networked resources and for traversal of those resources. One problematic area for access to digital library resources has been the search for time periods or events. If there is a capability to search for time, it is usually a date search - a standardized and precise form but unfortunately rarely used in common chronological expressions. For example, a user interested in the "Vietnam war", "Clinton Administration" or the "Elizabethan Period" must either know the corresponding dates, or rely on simple keyword matching for those period names. We consider the ability to interpret user statements of periods or eras as ranges of dates and to associate them with particular locations an important feature of an information system. This paper describes the Time Period Directory, a metadata infrastructure for named time periods linking them with their geographic location as well as a canonical time period range.

#index 874476
#* ETANA-ADD: an interactive tool for integrating archaeological DL collections
#@ Naga Srinivas Vemuri;Rao Shen;Sameer Tupe;Weiguo Fan;Edward A. Fox
#t 2006
#c 14
#% 614079
#% 716459
#% 760830
#% 1709403
#! ETANA-DL is an archaeology digital library built based on the principles of Open Digital Libraries. A key challenge addressed in ETANA-DL is integration of new archaeological sites. To enable archaeologists to build OAI data providers for easy integration, we developed an interactive software tool for database-to-XML generation, schema mapping, and global archive generation. This tool greatly enhances our ability to build new Open Archives. We tested the tool with data from the Umm el-Jimal site.

#index 874477
#* Enabling exploration: travelers in the middle east archive
#@ Lisa Spiro;Marie Wise;Geneva Henry;Chuck Bearden;Sid Byrd;Eva Garza;Michael Decker
#t 2006
#c 14
#% 1709412
#! In this paper, we describe the Travelers in the Middle East Archive (TIMEA), a digital archive focused on Western explorations in the Middle East between the 18th and early 20th centuries 7. TIMEA brings together TEI-encoded texts and digital images stored in DSpace, research and teaching materials in Connexions, and GIS maps made available online through ArcIMS. By using the functionality of three distinct systems, TIMEA enables users to more fully understand the materials, place them in context, and conduct queries. We outline the rationale for this architecture, the challenges it presents, and our approach to providing an integrated user experience.

#index 874478
#* Digital library education: the current status
#@ Yongqing Ma;Warwick Clegg;Ann O'Brien
#t 2006
#c 14
#% 378607
#% 809526
#! In this paper, we review and examine the current status of digital library education and compare the range of provision with that found in earlier studies [1, 2, 3]. It is found that the number of institutions offering programmes or courses in digital library education is still increasing. About 43% of these programmes or courses are stand-alone rather than integrated with wider material. The curriculum design and focused teaching areas appear more systematic and comprehensive than in earlier studies. Over half the institutions examined in this study have posted their detailed course information on-line. Most courses offered are now based on a combination of theory and practice, and are available at different levels. There are increasing opportunities for funding for developing new initiatives in digital library education. However, since digital library education is still at an early stage, an optimized model of best practice in digital library education has not yet emerged.

#index 874479
#* Curriculum development for digital libraries
#@ Jeffrey Pomerantz;Barbara M. Wildemuth;Seungwon Yang;Edward A. Fox
#t 2006
#c 14
#% 91615
#% 195322
#% 245815
#% 246956
#% 301266
#% 378521
#% 437506
#% 614048
#% 683308
#% 716459
#% 750866
#% 834991
#% 1801556
#! The Virginia Tech Department of Computer Science (VT CS) and the University of North Carolina at Chapel Hill School of Information and Library Science (UNC SILS) have launched a curriculum development project in the area of digital libraries. Educational resources will be developed based on the ACM/IEEE-CS Computing Curriculum 2001. Lesson plans and modules will be developed in a variety of areas (that cover the topics of papers and conference sessions in the field), evaluated by experts in those areas, and then pilot tested in CS and LIS courses. An analysis of papers on digital library-related topics from several corpora was performed, to identify the areas in which more and less work has already been performed on these topics; this analysis will guide the initial stages of this curriculum development.

#index 874480
#* Learning by building digital libraries
#@ David M. Nichols;David Bainbridge;J. Stephen Downie;Michael B. Twidale
#t 2006
#c 14
#% 645984
#% 809526
#% 834992
#! The implications of using digital library software in educational contexts, for both students and software developers, are discussed using two case studies of students building digital libraries.

#index 874481
#* What do digital librarians do
#@ Youngok Choi;Edie Rasmussen
#t 2006
#c 14
#% 282914
#! Without well-educated digital librarians, digital libraries cannot reach their full potential. In order to offer relevant courses and programs to train digital librarians, educators need feedback from practitioners. Current digital library professionals in academic libraries in the United States were surveyed to determine their activities, skills and training gaps. The findings have implications for the design of digital library education in order to meet workplace needs.

#index 874482
#* The NDIIPP preservation network: progress, problems, and promise
#@ Laura E. Campbell;Helen R. Tibbo;Peter Leousis
#t 2006
#c 14

#index 874483
#* Windowing time in digital libraries
#@ Michael G. Christel
#t 2006
#c 14
#% 337444
#% 378508
#! This paper discusses the specification, organization, and utility of time references identified in digital library materials, emphasizing how to treat date references that cannot be resolved to a single day. The HistoryMakers oral history archive is used to illustrate the concept of windowing such time in digital library interfaces.

#index 874484
#* Concept maps to support oral history search and use
#@ Ryen W. White;Hyunyoung Song;Jay Liu
#t 2006
#c 14
#% 227769
#% 237319
#% 285015
#% 723396
#% 809445
#! In this paper we describe a novel technique to support information seeking in oral history archives using concept maps. We conducted a pilot study with teachers engaged in work tasks using a prototype concept mapping tool. Results suggest that concept maps can help searchers, especially when tasks are complex.

#index 874485
#* Facilitating access to large digital oral history archives through informedia technologies
#@ Michael G. Christel;Julieanna Richardson;Howard D. Wactlar
#t 2006
#c 14
#% 249196
#% 378480
#% 378543
#% 452602
#! This paper discusses the application of speech alignment, image processing, and language understanding technologies to build efficient interfaces into large digital oral history archives, as exemplified by a thousand hour HistoryMakers corpus. Browsing, querying, and navigation features are discussed.

#index 874486
#* Review mining for music digital libraries: phase II
#@ J. Stephen Downie;Xiao Hu
#t 2006
#c 14
#% 300120
#! We continue our work on the automatic mining of user-created music reviews towards the goal of connecting user opinions to music objects in Music Digital Libraries (MDL). We demonstrate an experimental system which automatically discovered the key descriptive patterns that differentiated positive from negative reviews which helps us to better understand our successful Phase I results. Comparison to an earlier study indicates an important consistency across projects that warrants further investigation.

#index 874487
#* Looking for a picture: an analysis of everyday image information searching
#@ Sally Jo Cunningham;Masood Masoodian
#t 2006
#c 14
#% 329434
#% 580076
#% 760823
#! There is at present a dearth of information on the everyday image information behavior of ordinary people. Analysis of a set of 64 image-related searches provides insight into potentially useful facilities for an image digital library.

#index 874488
#* Image-based evaluation of video-acquired research skills
#@ Unmil P. Karadkar;Marlo Nordt;Richard Furuta;Cody Lee;Christopher Quick
#t 2006
#c 14
#% 452642
#% 635091
#% 760837
#% 760870
#% 760871
#% 809436
#! We are exploring the use of image interfaces for testing video-acquired research skills. We studied user performance on three testing image layouts that differ in their use of the available display real estate and in the flexibility of managing the time available to them. Our results confirm that image layout affects user performance on particular tasks and that experts use different strategies from novices. These alternative layouts will be useful for viewing and understanding digital image collections.

#index 874489
#* Keyphrase extraction-based query expansion in digital libraries
#@ Min Song;Il Yeol Song;Robert B. Allen;Zoran Obradovic
#t 2006
#c 14
#% 136350
#% 144029
#% 169729
#% 235288
#% 262084
#% 282424
#% 283138
#% 298183
#% 330787
#% 340882
#% 375017
#% 443052
#% 453324
#% 495937
#% 766440
#% 768903
#% 779853
#% 853813
#! In pseudo-relevance feedback, the two key factors affecting the retrieval performance most are the source from which expansion terms are generated and the method of ranking those expansion terms. In this paper, we present a novel unsupervised query expansion technique that utilizes keyphrases and POS phrase categorization. The keyphrases are extracted from the retrieved documents and weighted with an algorithm based on information gain and co-occurrence of phrases. The selected keyphrases are translated into Disjunctive Normal Form (DNF) based on the POS phrase categorization technique for better query refomulation. Furthermore, we study whether ontologies such as WordNet and MeSH improve the retrieval performance in conjunction with the keyphrases. We test our techniques on TREC 5, 6, and 7 as well as a MEDLINE collection. The experimental results show that the use of keyphrases with POS phrase categorization produces the best average precision.

#index 874490
#* Categorizing web search results into meaningful and stable categories using fast-feature techniques
#@ Bill Kules;Jack Kustanowitz;Ben Shneiderman
#t 2006
#c 14
#% 85272
#% 218992
#% 232698
#% 248810
#% 249093
#% 262045
#% 283055
#% 287204
#% 290801
#% 309141
#% 344447
#% 344928
#% 348178
#% 413663
#% 447946
#% 577373
#% 590523
#% 642534
#% 665561
#% 754077
#% 760840
#% 769395
#% 793018
#% 805898
#% 818224
#% 857477
#! When search results against digital libraries and web resources have limited metadata, augmenting them with meaningful and stable category information can enable better overviews and support user exploration. This paper proposes six fast-feature techniques that use only features available in the search result list, such as title, snippet, and URL, to categorize results into meaningful categories. They use credible knowledge resources, including a US government organizational hierarchy, a thematic hierarchy from the Open Directory Project (ODP) web directory, and personal browse histories, to add valuable metadata to search results. In three tests the percent of results categorized for five representative queries was high enough to suggest practical benefits: general web search (76-90%), government web search (39-100%), and the Bureau of Labor Statistics website (48-94%). An additional test submitted 250 TREC queries to a search engine and successfully categorized 66% of the top 100 using the ODP and 61% of the top 350. Fast-feature techniques have been implemented in a prototype search engine. We propose research directions to improve categorization rates and make suggestions about how web site designers could re-organize their sites to support fast categorization of search results.

#index 874491
#* A comprehensive comparison study of document clustering for a biomedical digital library MEDLINE
#@ Illhoi Yoo;Xiaohua Hu
#t 2006
#c 14
#% 46809
#% 118771
#% 198016
#% 218992
#% 228097
#% 262045
#% 273891
#% 280404
#% 375017
#% 397148
#% 413610
#% 465747
#% 466657
#% 577257
#% 591613
#% 766432
#% 766434
#% 842709
#! Document clustering has been used for better document retrieval, document browsing, and text mining in digital library. In this paper, we perform a comprehensive comparison study of various document clustering approaches such as three hierarchical methods (single-link, complete-link, and complete link), Bisecting K-means, K-means, and Suffix Tree Clustering in terms of the efficiency, the effectiveness, and the scalability. In addition, we apply a domain ontology to document clustering to investigate if the ontology such as MeSH improves clustering qualify for MEDLINE articles. Because an ontology is a formal, explicit specification of a shared conceptualization for a domain of interest, the use of ontologies is a natural way to solve traditional information retrieval problems such as synonym/hypernym/ hyponym problems. We conducted fairly extensive experiments based on different evaluation metrics such as misclassification index, F-measure, cluster purity, and Entropy on very large article sets from MEDLINE, the largest biomedical digital library in biomedicine.

#index 874492
#* Metadata aggregation and "automated digital libraries": a retrospective on the NSDL experience
#@ Carl Lagoze;Dean Krafft;Tim Cornwell;Naomi Dushay;Dean Eckstrom;John Saylor
#t 2006
#c 14
#% 378511
#% 616528
#% 809407
#% 809423
#% 1069039
#% 1069089
#! Over three years ago, the Core Integration team of the National Science Digital Library (NSDL) implemented a digital library based on metadata aggregation using Dublin Core and OAI-PMH. The initial expectation was that such low-barrier technologies would be relatively easy to automate and administer. While this architectural choice permitted rapid deployment of a production NSDL, our three years of experience have contradicted our original expectations of easy automation and low people cost. We have learned that alleged "low-barrier" standards are often harder to deploy than expected. In this paper we report on this experience and comment on the general cost, the functionality, and the ultimate effectiveness of this architecture.

#index 874493
#* Using resources across educational digital libraries
#@ Mimi Recker;Bart Palmer
#t 2006
#c 14
#% 809402
#! This article reports on analyses of usage and design activities by users of the Instructional Architect (IA), an end-user authoring tool designed to support easy access to and use of NSDL and online resources in creating instructional materials. This analysis provides a unique window for understanding how users use resources from multiple digital libraries, and the related issues of resource granularity and context dependence. Analyses suggest that active use and design with online resources is relegated to 'early adopters'. These users designed significantly more instructional projects with more content and more online resources than less-active users. Users in general appeared to value digital library resources, and at a smaller granularity than cataloged.

#index 874494
#* Template-based authoring of educational artifacts
#@ Sarah Davis;Paul Bogen;Lauren Cifuentes;Luis Francisco-Revilla;Richard Furuta;Takeisha Hubbard;Unmil P. Karadkar;Daniel Pogue;Frank Shipman
#t 2006
#c 14
#! The Walden's Paths project is developing tools for leveraging student learning with the incredible amount of educational material on the Web. Specialized templates based on established educational frameworks, learning theories, or activities aid path authors in creating pedagogically sound paths by guiding them in collecting and structuring the information included in the path. We describe a template based on the Inquiry-Based Learning educational framework and an implementation that provides support in applying the template to the path authoring process.

#index 874495
#* EcoPod: a mobile tool for community based biodiversity collection building
#@ YuanYuan Yu;Jeannie A. Stamberger;Aswath Manoharan;Andreas Paepcke
#t 2006
#c 14
#% 343127
#% 452651
#% 576214
#% 760826
#! Biological studies rely heavily on large collections of species observations. All of these collections cannot be compiled by biology professionals alone. Skilled amateurs can assist by contributing observations they make in the field. The challenge with such contributions is their potentially questionable quality. We present our PDA-based application EcoPod, which replaces traditional paper field guides with a mobile computing platform. EcoPod aims both to increase the efficiency of the identification process and its reliability. The application solicits as little information from the user as possible. At the same time it places no restrictions on the sequencing of the identification process. This approach is to make our solution attractive to both skilled amateurs and professionals. The tool creates a record of the identification process, thereby providing an audit trail for quality assurance. EcoPod's user interface driver computes information gain over identification metadata to maximize screen utilization. The tool ingests SDD, an international standard for XML datasets that describe organisms.

#index 874496
#* Factors motivating use of digital libraries
#@ Flora McMartin;Ellen Iverson;Cathryn Manduca;Alan Wolf;Glenda Morgan
#t 2006
#c 14
#% 760843
#! Knowledge about how users use digital libraries and their contents is inextricably tied to a library's ability to sustain itself, grow its services and meet the needs of its users. This paper reports on the preliminary results of a study of how science, technology, engineering and mathematics (STEM) instructors perceive and use digital libraries. Preliminary findings indicate that: they do not differentiate between digital libraries and other kinds of content that comes from the web, they seek content to supplement traditional teaching methods and their reliance on Google and personal networks impedes their ability to recall the primary sources of useful content.

#index 874497
#* Scaffolding the infrastructure of the computational science digital library
#@ Diana Tanase;Michael Bruce;Jonathan Stuart-Moore;David A. Joiner, PhD
#t 2006
#c 14
#% 378511
#% 743209
#% 809481
#! This paper describes from a developer's point of view the integration of a content management system (Plone) and a metadata repository (CWIS) in order to create an interactive online digital library for publishing and evaluation of computational science materials. It explains how CSERD's project requirements were addressed by setting up a framework for collaboration between the two systems mentioned above.

#index 874498
#* Dynamic generation of OAI servers
#@ J. Alfredo Sánchez;Antonio Razo;Juan Manuel Córdova;Abraham Villegas
#t 2006
#c 14
#! We describe Voai and Xoai, two software environments that facilitate the automatic construction of OAI servers for collections managed via relational and XML databases, respectively. We have used Voai and Xoai to generate OAI servers for diverse collections. We use freely available tools and do not impose programming requirements upon the users. By making this software publicly available, we aim to facilitate the process of joining the OAI community and becoming data providers.

#index 874499
#* FRBR: enriching and integrating digital libraries
#@ George Buchanan
#t 2006
#c 14
#% 201993
#% 290703
#% 301247
#% 301539
#% 508276
#% 614040
#% 614079
#% 760912
#% 760922
#% 809406
#% 809423
#% 1671626
#% 1709410
#% 1709412
#! FRBR (Functional Requirements for Bibliographic Records) is a promising framework for supporting rich indexation, and therefore rich interaction, in digital libraries. However, it is poorly reported in the digital library research literature and practical examples of its use are seldom discussed. In this paper, we introduce an implemented architecture for FRBR support that can supplement existing digital library systems. We also demonstrate the benefits gained by the user when FRBR data is used to enrich the user's interaction with the digital library.

#index 874500
#* Learning from artifacts: metadata utilization analysis
#@ William E. Moen;Shawne D. Miksa;Amy Eklund;Serhiy Polyakov;Gregory Snyder
#t 2006
#c 14
#% 1069040
#! Describes the MARC Content Designation Utilization Project, which is examining a very large set of metadata records as artifacts of the library cataloging enterprise. This is the first large-scale examination of descriptive metadata utilization. Presents an overview of study activities and suggests the study's significance to the broader use of metadata in digital libraries.

#index 874501
#* Looking back, looking forward: a metadata standard for LANL's aDORe repository
#@ Beth Goldsmith;Frances Knudson
#t 2006
#c 14
#% 400995
#! Although often disparaged or dismissed in the library community, the MARC standard, notably the MARCXML standard, provides surprising flexibility and robustness for mapping disparate metadata to a vendor-neutral format for storage, exchange, and downstream use.

#index 874502
#* Measuring inter-indexer consistency using a thesaurus
#@ Olena Medelyan;Ian H. Witten
#t 2006
#c 14
#% 187998
#! When professional indexers independently assign terms to a given document, the term sets generally differ between indexers. Studies of inter-indexer consistency measure the percentage of matching index terms, but none of them consider the semantic relationships that exist amongst these terms. We propose to represent multiple-indexers data in a vector space and use the cosine metric as a new consistency measure that can be extended by semantic relations between index terms. We believe that this new measure is more accurate and realistic than existing ones and therefore more suitable for evaluation of automatically extracted index terms.

#index 874503
#* Learning metadata from the evidence in an on-line citation matching scheme
#@ Isaac G. Councill;Huajing Li;Ziming Zhuang;Sandip Debnath;Levent Bolelli;Wang Chien Lee;Anand Sivasubramaniam;C. Lee Giles
#t 2006
#c 14
#% 44876
#% 249143
#% 281446
#% 310516
#% 316528
#% 438103
#% 649163
#% 722474
#% 738490
#% 748020
#% 748026
#% 777329
#% 786875
#% 788107
#% 809459
#% 1264970
#! Citation matching, or the automatic grouping of bibliographic references that refer to the same document, is a data management problem faced by automatic digital libraries for scientific literature such as CiteSeer and Google Scholar. Although several solutions have been offered for citation matching in large bibliographic databases, these solutions typically require expensive batch clustering operations that must be run offline. Large digital libraries containing citation information can reduce maintenance costs and provide new services through efficient online processing of citation data, resolving document citation relationships as new records become available. Additionally, information found in citations can be used to supplement document metadata, requiring the generation of a canonical citation record from merging variant citation subfields into a unified "best guess" from which to draw information. Citation information must be merged with other information sources in order to provide a complete document record. This paper outlines a system and algorithms for online citation matching and canonical metadata generation. A Bayesian framework is employed to build the ideal citation record for a document that carries the added advantages of fusing information from disparate sources and increasing system resilience to erroneous data.

#index 874504
#* Using controlled query generation to evaluate blind relevance feedback algorithms
#@ Chris Jordan;Carolyn Watters;Qigang Gao
#t 2006
#c 14
#% 115608
#% 262084
#% 287253
#% 340899
#% 340901
#% 340948
#% 340964
#% 342707
#% 342709
#% 387427
#% 397161
#% 561315
#% 643000
#% 766471
#% 766474
#% 818260
#! Currently in document retrieval there are many algorithms each with different strengths and weakness. There is some difficulty, however, in evaluating the impact of the test query set on retrieval results. The traditional evaluation process, the Cranfield evaluation paradigm, which uses a corpus and a set of user queries, focuses on making the queries as re-alistic as possible. Unfortunately such query sets lack the fine grained control necessary to test algorithm properties. We present an approach called Controlled Query Generation (CQG) that creates query sets from documents in the corpus in a way that regulates the theoretic information quality of each query. This allows us to generate reproducible and well defined sets of queries of varying length and term specificity. Imposing this level of control over the query sets used for testing retrieval algorithms enables the rigorous simulation of different query environments to identify specific algorithm properties before introducing user queries. In this work, we demonstrate the usefulness of CQG by generating three dif-ferent query environments to investigate characteristics of two blind relevance feedback approaches.

#index 874505
#* Thesaurus based automatic keyphrase indexing
#@ Olena Medelyan;Ian H. Witten
#t 2006
#c 14
#% 260001
#% 281480
#! We propose a new method that enhances automatic keyphrase extraction by using semantic information on terms and phrases gleaned from a domain-specific thesaurus. We evaluate the results against keyphrase sets assigned by a state-of-the-art keyphrase extraction system and those assigned by six professional indexers.

#index 874506
#* An architecture for the aggregation and analysis of scholarly usage data
#@ Johan Bollen;Herbert Van de Sompel
#t 2006
#c 14
#% 247316
#% 268079
#% 330687
#% 342870
#% 508283
#% 577220
#% 799632
#% 841613
#! Although recording of usage data is common in scholarly information services, its exploitation for the creation of value-added services remains limited due to concerns regarding, among others, user privacy, data validity, and the lack of accepted standards for the representation, sharing and aggregation of usage data. This paper presents a technical, standards-based architecture for sharing usage information, which we have designed and implemented. In this architecture, OpenURL-compliant linking servers aggregate usage information of a specific user community as it navigates the distributed information environment that it has access to. This usage information is made OAI-PMH harvestable so that usage information exposed by many linking servers can be aggregated to facilitate the creation of value-added services with a reach beyond that of a single community or a single information service. This paper also discusses issues that were encountered when implementing the proposed approach, and it presents preliminary results obtained from analyzing a usage data set containing about 3,500,000 requests aggregated by a federation of linking servers at the California State University system over a 20 month period.

#index 874507
#* An experimental framework for comparative digital library evaluation: the logging scheme
#@ Claus-Peter Klas;Norbert Fuhr;Sascha Kriewel;Hanne Albrechtsen;Giannis Tsakonas;Sarantos Kapidakis;Christos Papatheodorou;Preben Hansen;Laszlo Kovacs;Andras Micsik;Elin Jacob
#t 2006
#c 14
#% 508283
#! Evaluation of digital libraries assesses their effectiveness, quality and overall impact. In this paper we present a novel, multi-level logging framework that will provide complete coverage of the different aspects of DL usage for user-system interactions. Based on this framework, we can analyse for various DL stakeholders the logging data according to their specific interests. In addition, analysis tools and a freely accessible log data repository will yield synergies and sustainability in DL evaluation and encourage a community for DL evaluation by providing for discussion on a common ground.

#index 874508
#* Insights into collections gaps through examination of null result searches in DLESE
#@ Barbara DeFelice;Kim A. Kastens;Constance Rinaldo;John Weatherley
#t 2006
#c 14
#! We describe the analysis of zero result searches in DLESE, the Digital Library for Earth System Education, with the intent to use the information to discover gaps in the collection. Close examination of null result searches reveals insights into the kinds of information sought by users but which is missing from the collection. Although it is not possible to consistently isolate collection gaps as a cause for null result searches, it is possible to define a set of null result searches that are very likely to have been caused by collections gaps. This information can be used to improve a collection in specific subject areas. We recommend using this method, along with other inputs, for a digital library with a specific collection scope but a broad and mostly unknown user base, and we recognize the need for automating this analysis.

#index 874509
#* The social life of books in the humane library
#@ Yoram Chisik;Nancy Kaplan
#t 2006
#c 14
#% 297605
#% 717331
#% 809442
#! The development of public libraries may have inadvertently brought the age of marginalia to a close but now that digital copies no longer require us to refrain from writing in a shared text, it is possible to create sociable books, texts that sustain communities of readers. How might people respond to opportunities to share their readings through marginalia and how might the process of reading for pleasure be altered by situating it in a more social space? The current study examining sociable reading among a small group of middle-school girls demonstrates the potential of reading sociably and affirms the value of developing digital library books to support social exchanges among readers.

#index 874510
#* Search engine driven author disambiguation
#@ Yee Fan Tan;Min Yen Kan;Dongwon Lee
#t 2006
#c 14
#% 249143
#% 503213
#% 809459
#% 819552
#! In scholarly digital libraries, author disambiguation is an important task that attributes a scholarly work with specific authors. This is critical when individuals share the same name. We present an approach to this task that analyzes the results of automatically-crafted web searches. A key observation is that pages from rare web sites are stronger source of evidence than pages from common web sites, which we model as Inverse Host Frequency (IHF). Our system is able to achieve an average accuracy of 0.836.

#index 874511
#* Tagging of name records for genealogical data browsing
#@ Mike Perrow;David Barber
#t 2006
#c 14
#% 44876
#% 95730
#% 278107
#% 333943
#% 389155
#% 742092
#% 742368
#% 760866
#% 801412
#% 806734
#% 809459
#% 839728
#! In this paper we present a method of parsing unstructured textual records briefly describing a person and their direct relatives, which we use in the construction of a browsing tool for genealogical data. The records have been created by researchers who are currently digitising a collection of historical archives stored at the Abbaye de Saint-Maurice, Switzerland. The string 'Beatrix, daughter of Johannes Trona, of Saillon' is a typical example of a record. We wish to annotate every term (word and symbol) in our records with a label which describes whether the term is a name (e.g. 'Beatrix'), a place (e.g. 'Saillon'), or a relationship (e.g. 'daughter'). Using this information, we are able to derive both a canonical form for each name (e.g. 'Beatrix Trona'), and the relationships between people. We build upon work developed for the cleaning and standardization of names for record linkage corpora, adding several enhancements to deal with our more difficult data, which contains common name structures of French, Italian and Latin, over hundreds of years. We present an approach to this problem that works interactively with a user to annotate the data set accurately, greatly reducing the human effort required. We do this by learning a Hidden Markov Model representing a record structure, and finding structural patterns in new records. Finally, we present a brief overview of a tool we are developing to help genealogical researchers browse and search the data.

#index 874512
#* Automatic feature thesaurus enrichment: extracting generic terms from digital gazetteer
#@ Jun Wang;Ning Ge
#t 2006
#c 14
#% 67565
#% 185288
#% 295519
#% 309113
#% 337433
#% 437510
#% 647628
#% 741939
#% 748241
#% 757850
#% 817963
#! ADL Gazetteer is a digitalized worldwide gazetteer developed in the Alexandria Digital Library (ADL) Project, which contains millions of geographic names (placenames). The placenames are indexed with type terms from the ADL Feature Type Thesaurus (FTT), a hierarchical category scheme. The paper proposes a two-step method to enrich the category scheme automatically: to discover frequent generic terms by detecting phase boundaries with a mutual information-based method, and to correlate the generic terms with the relevant type terms by hierarchical clustering. The correlation pair established can then be used to supplement the FTT with the generic terms found. The extensive experiments conducted on millions of ADLG placenames demonstrated the effectiveness of the proposed methods. Besides the thesaurus enrichment, the potential applications of this research include: to suggest likely type terms when categorizing new placenames, and to help users choose likely search terms.

#index 874513
#* An assessment of access and use rights for licensed scholarly digital resources
#@ Kristin R. Eschenfelder;Ian Benton
#t 2006
#c 14
#! This research in progress investigates how what types of technological protection measures are being used on collections of licensed scholarly resources. It seeks to ascertain the range and variation in access and rights restrictions, and whether observed restrictions were described in acceptable use statements and resource licenses.

#index 874514
#* Information seeking in academic learning environments: an exploratory factor analytic approach to understanding design features
#@ Shu-Shing Lee;Yin-Leng Theng;Dion Hoe-Lian Goh;Schubert Shou-Boon Foo
#t 2006
#c 14
#% 260245
#% 311866
#% 1740018

#index 874515
#* A performance support systems approach to digital publishing in libraries
#@ Chuck Thomas;Robert H. McDonald
#t 2006
#c 14
#! Electronic performance support tools are used in many workplaces, but digital libraries have not evaluated their potential usefulness. In a pilot project, the Florida State University Libraries developed inexpensive performance support tools for three types of in-house digital publishing. This strategy improved productivity and quality control.

#index 874516
#* Selecting books: a performance-based study
#@ Nina Wacholder;Lu Liu;Ying-Hsang Liu
#t 2006
#c 14
#! Our research compares the impact of paper vs. electronic presentation of text on the book selection process. Our focus is on the stage of book selection in which users study the content of a book to decide whether it will be useful for their intended purpose. Effectiveness is operationalized as accurate determination of whether a non-fiction book contains enough discussion of a particular topic to be useful for a research paper. 24 undergraduates participated in a balanced study in which they were given a topic-book pair and asked to decide whether the book was useful for the topic. We explore the differences in performance, with specific reference to the role of the search function, table-of-contents and index.

#index 874517
#* User perceptions of a federated search system
#@ Ingrid Hsieh-Yee;Rong Tang;Shanyun Zhang
#t 2006
#c 14
#! To examine how users make sense of a federated search system we collected data from professional and novice searchers, using a survey instrument that contained simulated searches. A main task of participants was to provide a narrative and a drawing of their understanding of how MetaLib works. The poster presents the methodology and findings, identifies design issues related to federated search systems, and discusses strategies for increasing information literacy in federated search.

#index 874518
#* Automatic extraction of table metadata from digital documents
#@ Ying Liu;Prasenjit Mitra;C. Lee Giles;Kun Bai
#t 2006
#c 14
#% 625351
#% 643004
#! Tables are used to present, list, summarize, and structure important data in documents. In scholarly articles, they are often used to present the relationships among data and high-light a collection of results obtained from experiments and scientific analysis. In digital libraries, extracting this data automatically and understanding the structure and content of tables are very important to many applications. Automatic identification extraction, and search for the contents of tables can be made more precise with the help of metadata. In this paper, we propose a set of medium-independent table metadata to facilitate the table indexing, searching, and exchanging. To extract the contents of tables and their metadata, an automatic table metadata extraction algorithm is designed and tested on PDF documents.

#index 874519
#* A tool for teaching principles of image metadata generation
#@ Palakorn Achananuparp;Katherine W. McCain;Robert B. Allen
#t 2006
#c 14
#% 345197
#! We developed a simple web-based prototype to familiarize students with digital library tools. To assist the students with the indexing task, the prototype provided basic functionalities, including metadata input form, photo search interface. The students generally expressed a positive feedback toward the use of digital library tools in their image indexing project.

#index 874520
#* Evaluating the national science digital library
#@ Michael Khoo
#t 2006
#c 14
#! NSDL Core Integration is conducting a program-wide evaluation of all NSDL program activities. The evaluation will inventory and describe NSDL achievements to date, and identify directions for future development. The scale and complexity of the NSDL program - 200 projects over 5 years - poses significant challenges for the evaluation. The poster outlines the theoretical and practical approaches being used to guide and coordinate evaluation activities.

#index 874521
#* Multi-linguistic collaborative distance learning: from information translation to knowledge translation
#@ Xiangming Mu
#t 2006
#c 14
#% 614072
#! A new Video-based Muti-linguistic Collaborative Distance Learning (VMC-DE) was proposed to support knowledge translation by integrating information, translation, interactive learning, knowledge and context into an interactive learning environment. Two types of user interfaces are under development.

#index 874522
#* Metadata data dictionary for analog sound recordings
#@ Catherine Lai;Ichiro Fujinaga
#t 2006
#c 14
#% 809484
#! This paper introduces a new metadata data dictionary design to assist in the consistent creation of digital libraries of analog sound recording and to promote their interoperability.

#index 874523
#* Feasibility of developing curriculum standards metadata
#@ Ron T. Brown;Sharon W. Bowers
#t 2006
#c 14
#! We asked 18 teachers about their use of video and digital video in the classroom. In general teachers desired digital collections organized by curriculum objectives because curriculum objectives allowed them to quickly narrow search results based on particular units and objectives. To understand the implications for creating metadata, an example video was tagged according to 3 different state curricular standards. The time intensive task required both in-depth knowledge of the video and of the standards. This finding has implications for third party metadata generation.

#index 874524
#* On-demand metadata extraction network (OMEN)
#@ Ichiro Fuinaga;Daniel McEnnis
#t 2006
#c 14
#% 1857845
#! A new method for federated searching of music archives using a grid-based dynamic feature extraction system is proposed.

#index 874525
#* Managing intellectual property issues in a commons of geographic data
#@ James Campbell;Marilyn Lutz;David McCurry;Harlan Onsrud;Kenton Williams
#t 2006
#c 14

#index 874526
#* scientific research groups, digital libraries, & education: metadata from nanoscale simulation code
#@ Laura M. Bartolo;Cathy S. Lowe;Sharon C. Glotzer;Christopher R. Iacovella
#t 2006
#c 14
#! The NSDL Materials Digital Library Pathway (MatDL) is working with materials scientists to capture, in Dublin Core XML format, optimal description of nanoscale computer simulation output as research codes are executed. The long term goal of the work is to enable users, such as research groups and students, to efficiently and effectively manage their results for internal use, for exchange with outside collaborators, for use in educational settings, and for submissions to digital libraries.

#index 874527
#* Interface design for browsing faceted metadata
#@ Jonathan Stuart-Moore;Monte Evans;Patricia Jacobs
#t 2006
#c 14
#% 345271
#% 452641
#! The team developing the new version of the Computational Science Education Reference Desk (CSERD) has recognized the need for, and implemented, a more flexible and interactive system for finding resources using a combination of browsing and searching.

#index 874528
#* Developing a metadata schema for CSERD: a computational science digital library
#@ D. E. Swain;Jill Wagy;Marilyn McClelland;Patricia Jacobs
#t 2006
#c 14
#% 809481
#% 814051
#! The poster traces ongoing efforts to develop and refine a metadata schema for the Computational Science Education Reference Desk (CSERD). Design and development is informed by evolving metadata standards for educational resources, usability studies, audience analysis, and interoperability guidelines for National Science Digital Library (NSDL), NSDL Metadata Registry, and digital libraries, such as Merlot. The poster will illustrate and define each of these as "facets" of metadata structures.

#index 874529
#* Creating a multi disciplinary digital library in the 5S framework
#@ Michael Drutar;Charles Coleman;Edward Fox
#t 2006
#c 14
#! This study identifies (1) the steps involved in framing a multi disciplinary digital library to the 5S Model, a formal model for digital libraries. (2) the major benefits the 5S Model delivers toward simplifying a digital library's resource info structure; including the creation of simplified resource classification trees and development of a user interface which interacts with such trees to enable the best in browse ability.This poster presents a graphical mapping of how individual naming functions of the spatial temporal organization (Fnodes) are mapped to the user interface. More so, the poser will display the importance of the examples of how the spaces element is used to create "HTML HELPERS" which eventually result in the ultimate in ease of usability on the user end. The blending of these components to suffice for all disciplines of a digital library are the fundamental ingredients to creating an established online repository.

#index 874530
#* An analysis of the bid behavior of the 2005 JCDL program committee
#@ Marko A. Rodriguez;Johan Bollen;Hebert Van de Sompel
#t 2006
#c 14
#% 46803

#index 874531
#* Supporting biological information work: research and education for digital resources and long-lived data
#@ Carole L. Palmer;Melissa H. Cragin;P. Bryan Heidorn
#t 2006
#c 14
#! New practices are emerging in all stages of biological research, from data collection through dissemination of results. Through a series of cooperative projects with biologists working in data-intensive and informatics-based domains, we have documented requirements for digital libraries, tool development, and data management techniques to support contemporary scientific practice. This research is now serving as the foundation for a new biological informatics master's program to train scientific information specialists to manage and integrate scientific information and tools to support scientific problem solving and communication.

#index 874532
#* Finding a metaphor for collecting and disseminating distributed NSDL content and communications
#@ Carol Minton Morris;Helene Hembrooke;Lynette Rayle
#t 2006
#c 14
#% 835045
#! The National Science Digital Library (NSDL) dramatically broadens the information about STEM resources that it can accept and make available to its users with the introduction of the NSDL Data Repository (NDR) architecture. [1].On Ramp is a platform for managing workflow, and creating, editing, distributing and storing content from multiple users and groups in a variety of formats to transform information into knowledge by enabling the NSDL community to engage in a rich exchange of information. [2] Flexible content that is small, modular, and adaptable is favored to promote this type of distributed reusable and multilayered information in an educational digital library such as NSDL.In this poster we trace the process used to determine a metaphor for the NSDL On Ramp (ONR) content and communications system by exhibiting iterative designs for a user interface derived from ONR User Survey results.

#index 874533
#* A curated harvesting approach to establishing a multi-protocol online subject portal
#@ Robert Sanderson;John Harrison;Clare Llewellyn
#t 2006
#c 14
#! We describe a curated harvesting approach to creating and maintaining a subject portal, comprising selected records harvested from remote services via information retrieval standards such as SRU, Z39.50 and OAI-PMH. The result was a web-based data curation interface where administrative users can configure access to remote resources, queries to be performed at them, and review records for inclusion in end user searches.

#index 874534
#* Incorporating computational science activities in high school algebra
#@ Joseph DeLuca;David A. Joiner
#t 2006
#c 14
#% 178981
#% 462543
#% 809481
#! Despite great increases in the role of computation in Science, Technology, Engineering and Mathematics (STEM), there has been no comprehensive curriculum for computational science in K-12 education [5]. The June 2005 President's Information Technology Advisory Committee (PITAC) report stated that "only a small fraction of the potential of computational science is being realized", and "the diverse technical skills and technologies ... constitute a critical U.S. infrastructure that we under appreciate and undervalue at our peril [4]." Despite a growing focus on STEM education, a substantial shortage exists of Americans qualified to work in STEM professions, including scientific research [1]. Progress in training computational scientists is lagging demand in the U.S. today. As this decade is seeing growth in the number of graduate, undergraduate, and teacher training programs in computational science [7], it is vital that the curriculum and materials to infuse computation into K-12 schools are made avail.Previous studies have shown how interactive learning objects can be incorporated into teaching, allowing teachers to make classrooms more engaging and student active, provided faculty using the resources have adequate training, a willingness to modify their teaching styles, and access to or time to create quality interactive assignments [6]. The Computational Science Education Reference Desk (CSERD), a Pathway project of the National Science Digital Library, collects learning objects for teaching about and teaching with computation, reviewing items in its catalog on the basis of verification, validation, and accreditation to help provide faculty with information regarding the quality of the learning objects [3].This study attempts to determine the effectiveness of a set of interactive learning materials from the CSERD collection in teaching concepts in a freshman Algebra I class. Materials from the CSERD resource Project Interactivate [2] will be used in a series of 4 lessons through February and March 2006 at a parochial school in Northeastern New Jersey. Students will take a pre- and post-test on topics covered in this period. Students and teachers will be surveyed to determine their attitudes towards the use of computation in learning and towards mathematics in general. Additionally, students will submit a daily feedback statement after each augmented lesson.

#index 874535
#* Adapting peer verification, validation and accreditation processes for digital libraries
#@ Linda Schmalbeck;Jonathan Stuart-Moore;Monte Evans
#t 2006
#c 14
#% 809481
#! This poster describes an on-going process to adapt a public access peer-based verification, validation and accreditation system for a digital library that is designed to serve the science, technology, engineering and mathematics (STEM) education community.

#index 874536
#* Quantifying the accuracy of relational statements in Wikipedia: a methodology
#@ Gabriel Weaver;Barbara Strickland;Gregory Crane
#t 2006
#c 14
#! An initial evaluation of the English Wikipedia indicates that it may provide accurate data for disambiguating and finding relations among named entities.

#index 874537
#* The ingest and maintenance of electronic records: moving from theory to practice
#@ Kevin L. Glick;Eliot Wilczek;Robert Dockins
#t 2006
#c 14
#! This poster will present the findings of an NHPRC electronic records research grant conducted by Tufts University and Yale University.

#index 874538
#* Technical architecture overview: tools for acquisition, packaging and ingest of web objects into multiple repositories
#@ Shweta Rani;Jay Goodkin;Judy Cobb;Tom Habing;Richard Urban;Janet Eke;Richard Pearce-Moses
#t 2006
#c 14
#! This poster describes a model for acquiring, packaging and ingesting web objects for archiving in multiple repositories. This ongoing work is part of the ECHO DEPository Project, a 3-year NDIIPP-partner digital preservation project at the University of Illinois at Urbana-Champaign with partners OCLC, a consortium of content provider partners, and the Library of Congress.

#index 874539
#* Browsing affordance designs for the human-centered computing education digital library
#@ Edward Clarkson;James D. Foley
#t 2006
#c 14
#% 717133
#% 726086
#! Browsing is a widespread user behavior in the digital library (DL) environment; there are an array of existing techniques that afford browsing and are readily applicable to digital libraries. We outline the designs of two such methods based on well-known techniques: treemaps and ScentTrails.

#index 874540
#* Indexing institutional data to promote library resource discovery
#@ Tito Sierra
#t 2006
#c 14
#! Most academic research libraries provide subject guides or data-driven subject portals on their websites to help users find information resources by topical research area. Unfortunately, these guides and portals are underutilized because users fail to discover them in their information search process. We describe an approach in development at NCSU to increase the discovery of library subject portals, and topically organized library resources in general. This approach exploits the rich topical content in available institutional data stores to generate subject recommendations related to the user's search query.

#index 874541
#* Keeping the context: an investigation in preserving collections of digital video
#@ Christopher A. Lee;Helen R. Tibbo;Dawne Howard;Yaxiao Song;Terrell Russell;Paul Jones
#t 2006
#c 14
#! There has been a recent dramatic shift from analog to digital creation, management and use of video, creating unprecedented opportunities to develop rich, interactive collections, but without proper care, much of this digital video could be inaccessible or incomprehensible in the future. Several projects have explored technical challenges and potential strategies for ensuring long-term access to digital video collections. A number of initiatives have also generated sets of proposed metadata for digital video. Most of the above activities have focused on ensuring that videos can be discovered, accessed and rendered over time.Another active steam of research has examined how users can best navigate, understand, view, interact with and annotate collections of digital video. This research has generated valuable lessons, tools and observations to support current users. However, it has generally not investigated how the components of a digital video collection might support or fail to support future users of videos.The Preserving Video Objects and Context (VidArch) project -- NSF Grant # IIS 0455970, involving the authors, Gary Marchionini and Gary Geisler -- lies at the intersection between the two streams of research described above. We are developing a preservation framework for digital video context. Among other issues, we are considering: Are there interface elements from current collections (e.g. surrogates, navigation aids, behaviors) that should be retained over time, in order to support long-term use and understanding of the videos? How might curators of digital video collections decide which contextual elements are important and then devise strategies for preserving them.According to the glossary of the Society of American Archivists, context is the "organizational, functional, and operational circumstances surrounding materials' creation, receipt, storage, or use, and its relationship to other materials." Documents derive value and meaning from relationships with other documents within the same collection. Rather than treating each item as a discrete entity, archival theory and practice suggests that digital videos should be managed, preserved and presented to users in a way that reflects the social and documentary context in which they were originally embedded.Access systems for text-based collections often rely on surrogates, such as indices, catalogs, and abstracts. In addition to facilitating information navigation, discovery and retrieval, surrogates also provide valuable contextual information about the documents. In archival descriptive practices, attention to context is expressed through the creation of finding aids, which include not only inventories of the contents of collections, but also background information about the actors and activities that generated the materials, and the ways they were organized by their original creators or recipients. Recent research has produced and investigated an analogous set of surrogates for digital video collections. These include textual descriptions, title, captions, and annotations, but they also include surrogates that are themselves still or moving images: video segments, keyframes, slide shows, and fast forwards.VidArch is focused on two collections within the Open Video repository: the complete set of videos that National Aeronautic and Space Administration (NASA) produces and broadcasts to advance learning and appreciation for science; and a set of videos of juried presentations to various annual Association for Computing Machinery (ACM) conferences. The two collections reflect several forms of documentation that may be valuable to preserve in order to convey the context of the videos: text-based surrogates, image-based surrogates (story boards and fast forwards), links to related videos, use history data, and supporting documents (e.g. lesson plans). We have generated archival finding aids to the two collections in order to reflect contextual information that is not readily available within Open Video. Such documentary elements should not simply be treated as part of the current interface to the collection but should also be considered as potential targets of long-term preservation in their own rig.This poster presents an information model for digital video context and places the information model within the context of recent guidance on metadata for digital video, metadata for digital preservation, and the Reference Model for an Open Archival Information System (OAIS).

#index 874542
#* cloudalicious: folksonomy over time
#@ Terrell Russell
#t 2006
#c 14
#! Cloudalicious is an online visualization tool that has been designed to give insight into how Òtag cloudsÓ, or folksonomies, develop over time. A folksonomy is an organic system of text labels attributed to an object by the users of that object. The most common object so far to be the subject of this tagging has been the online bookmark. Stabilization of a URL's tag cloud over time is the clearest result of this type of visualization. Any diagonal movement on the graphs, indicative of a change in the tags being used to describe a URL, should garner further discussion.

#index 874543
#* Apparatus and methods for production of printed aromatic and gustative information
#@ Berg P. Hyacinthe
#t 2006
#c 14
#% 836032
#! As we advance with the implementation of novel technologies, apparati and protocols that combine existing technologies with emergent ones are becoming more relevant to ensure smoother transitions and overcome challenges that new technologies alone can not address. The author essentially suggests a new type of information exchange which focuses on the olfactory/gustatory perceptual realm of smell and taste. In principle, a printing module transforms signals received from the processing unit into olfactory documents that can, in turn, be stored and preserved as scented texts on thin layers of a gustative medium.

#index 874544
#* Teaching box builder: customizing pedagogical contexts for use of digital library resources in classrooms
#@ Huda J. Khan;Keith E. Maull
#t 2006
#c 14
#% 809474
#! This poster and accompanying demonstration introduces the Teaching Box Builder application that, as being implemented, supports the development of pedagogically rich inquiry-based earth science lessons using digital library resources.

#index 874545
#* ClaimID: a system for personal identity management
#@ Frederic Stutzman;Terrell Russell
#t 2006
#c 14
#! In this poster, the authors describe a system, that enables individuals to create representation of their online identity. Realizing that online identity, especially personal identity as represented in search, is difficult to collect and verify, the authors propose a system that enables individuals to collect and self-classify the information that is about them online.

#index 874546
#* Pathways core: a data model for cross-repository services
#@ Jeroen Bekaert;Xiaoming Liu;Herbert Van de Sompel;Carl Lagoze;Sandy Payette;Simeon Warner
#t 2006
#c 14
#! As part of the NSF-funded Pathways project, we have created an interoperable data model to facilitate object re-use and a broad spectrum of cross-repository services. The resulting Pathways Core data model is designed to be lightweight to implement, and to be widely applicable as a shared profile or as an overlay on data models currently used in repository systems and applications. We consider the data models underlying the Fedora, Dspace and aDORe repository systems, and a number of XML-based formats used for the representation of compound objects, including MPEG-21 DIDL, METS, and IMS/CP.At the heart of the Pathways Core data model (Fig. 1) are the entity and datastream elements. entity elements model the abstract aspects of digital objects and align with works and expressions in FRBR [1]. An entity can model anything from a digital object to a collection of digital objects (other entities), to a node created merely to express abstract properties. Core properties of entities are hasIdentifier, hasProviderInfo, hasLineage, and hasProvider-Persistence. If a repository attaches providerInfo to an entity, it provides a handle to access the entity from the repository, supporting its use and re-use. Persistence of this handle may be indicated with providerPersistence. The hasLineage property is used to indicate the entity (or entities) from which the entity to which the hasLineage is attached was derived. Other properties, such as hasSemantic, that convey the intellectual genre of the entity (i.e. journal article), can be added. datastream elements model the concrete aspects of a digital object; these align with items in FRBR, and can be thought of as aspects at the level of bitstreams. An entity may have any number of datastreams. Two properties of datastream have been defined as part of the Pathways Core: hasLocation conveys a URI that can be resolved to yield a bitstream; and hasFormat conveys the digital format of the bitstream. If a datastream has multiple hasLocation properties, resolution of the conveyed URIs yields bit-equivalent bitstreamsThe Pathways Core data model can be serialized in a variety of ways, and, an RDF serialization as well as a profile of MPEG-21 DIDL have been created as reference implementations. We have also conducted the following experiment to illustrate the power of the Pathways Core. A number of heterogeneous repositories implemented an OpenURL-based obtain interface from which, given the providerInfo of an entity, an RDF serialization of the entity compliant with the Pathways Core could be retrievedUsing this interface, an overlay journal can collect serializations of some entities (scholarly papers) from the different collaborating repositories, and assemble those into a new issue of the journal. The overlay journal then itself implemented the same obtain interface, and as a result, an RDF serialization of the entire journal, an issue, and an article could be extracted. This interface could then, for example, be used by a preservation repository to collect content from the overlay journal for ingest and mirroring. This experiment illustrates how cross-repository services and workflows can be facilitated through support of an interoperable data model (the Pathways Core) and an interoperable service interface (the OpenURL-based obtain interface)

#index 874547
#* Pilot testing the DigiQUAL™ protocol: lessons learned
#@ Martha Kyrillidou;Sarah Giersch
#t 2006
#c 14
#% 809432
#! The Association of Research Libraries is developing the DigiQUAL™ protocol to assess the service quality provided by digital libraries (DLs). In 2005, statements about DL service quality were put through a two-step validation process with DL developers and then with users in an online survey..

#index 874548
#* Using citations for ranking in digital libraries
#@ Birger Larsen;Peter Ingwersen
#t 2006
#c 14
#% 137475
#% 378495
#% 397191

#index 874549
#* LexiURL web link analysis for digital libraries
#@ Alesia Zuccala;Mike Thelwall
#t 2006
#c 14
#! The purpose of this demonstration is to show how LexiURL may be used with a search engine to download links to and colinks with a digital library site for "Web intelligence" purposes..

#index 874550
#* Exploring content-actor paired network data using iterative query refinement with NetLens
#@ Hyunmo Kang;Catherine Plaisant;Bongshin Lee;Benjamin B. Bederson
#t 2006
#c 14
#% 322954
#% 434557
#! Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper demonstrates a tool, NetLens, to explore a Content-Actor paired network data model. The NetLens interface was designed to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify in node-link visualizations. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract Content-Actor data model

#index 874551
#* A content-based video browsing system based on visual neighbor similarity
#@ Xiangming Mu
#t 2006
#c 14
#! A new interactive shot level video navigation system is developed to support three types of content-based browsing functions: Neighbor clustering, Visual similarity, and Visual Neighbor Similarity (VNS) browsing..

#index 874552
#* OpenArXiv = arXiv + RDBMS + web services
#@ Justin Fisher;Hyunyoung Kil;Dongwon Lee
#t 2006
#c 14
#% 810746

#index 874553
#* Real-time collaboration through visual search and voice-over-IP
#@ Cathal Hoare;Humphrey Sorensen
#t 2006
#c 14
#% 845252
#! Numerous digital libraries (DLs), electronic archives (EAs) and portal services have been developed. These services allow online structured access to digitised information, facilitating remote access for educators and students. Often, DL users and information are remotely located - so too are their users. The authors can envision numerous circumstances where two remotely located parties may wish to opportunistically examine an online resource - e-learning environments for example. We are particularly interested in assisting users whose collaboration resolves around discussion of a common visual resource (documents and collections of documents in the case under discussion). By providing a single tool for information seeking and multi-user collaboration, we believe that the amount of preparation required for an online session is reduced, while the flexibility allowed to parties to conduct ad-hoc examinations of a resource is increased. This paper proposes a framework to address this functionality deficit by describing a document foraging tool that provides facilities for both visual exploration of a document set and Voiceover-IP (VoIP) based collaborative features.

#index 874554
#* Demonstrating the use of a SenseCam in two domains
#@ Seungwon Yang;Ben Congleton;George Luc;Manuel A. Pérez-QuiÑones;Edward A. Fox
#t 2006
#c 14
#% 451595
#% 845339
#! MyLifeBits is both an application and a framework to manage a personal lifetime of memories. We will demonstrate the use of a small digital library that manages data from two Microsoft SenseCams, used by: 1) students in the Virginia-Maryland Regional College of Veterinary Medicine, and 2) students supported by our Assistive Technologies office.

#index 874555
#* SIMPEL: a superimposed multimedia presentation editor and player
#@ Uma Murthy;Kapil Ahuja;Sudarshan Murthy;Edward A. Fox
#t 2006
#c 14
#% 743927

#index 874556
#* Extended XQuery for digital libraries
#@ Alex Dekhtyar;Ionut E. Iacob;Kevin Kiernan;Dorothy C. Porter
#t 2006
#c 14
#% 809505
#% 809508
#! Documents have, in general, a multihierarchical structure (such as physical organization in the form of pages and lines, content organization in the form of paragraphs and sentences, etc.). Searching multihierarchical XML encoding presents a number of unique challenges for both computer scientists and document experts. We present an extension of the XQuery language suitable for searching multihierarchical XML.

#index 874557
#* ETANA-GIS: GIS for archaeological digital libraries
#@ Douglas Gorton;Rao Shen;Naga Srinivas Vemuri;Weiguo Fan;Edward A. Fox
#t 2006
#c 14
#! With the growing importance of mapping land, regions, and their related features, Geographic Information Systems (GIS) has become an ever important standard in fields where such detailed study of land features is required. Our archaeology digital library, ETANA-DL (http://etana.dlib.vt.edu), contains thousands of records from eight member excavations. Here, we draw on the Space aspect of the 5S meta-model [1] for digital libraries and demonstrate a methodology used to integrate archaeological GIS data with the wealth of information within ETANA-DL. ETANAGIS connects the digital library's textual records with a spatial representation of their original locations, enhancing users' understanding of the find.Using a dataset of the University of Toronto's Tell Madaba excavation project [2], we developed an interactive, Web-based representation of the original ArcGIS document (accessible from ETANA-DL homepage). For dynamic generation of maps from geospatial data, we use the MapServer [3] project, a mature, project which boasts a rich toolset of features for cartographicrelated image generation. MapServer can directly utilize ArcGIS layer resources but some translation and additional authoring must occur for proper image generation. Then, using PHP, the MapScript MapServer API, and navigation tools, the map was ported to an interactive, Web-accessible format. Based on a study of alternatives, the technology we chose for our technique seemed to be the best suited for digital library integration and is also completely open source.To explore the presentation of the map, a user employs the navigation tools displayed in the corner of the main view (see Figure 1). In addition, full control of displayed layers, a smaller map showing overall view and context, as well as a dynamic scale bar are available for use. To integrate the Web-based version of the Tell Madaba GIS map with the existing digital library, the layers depicting archaeological divisions are clickable and labeled for easy identification. Any area queried results in a pop-up box with ETANA-DL's records and artifacts for that area.While this integration connects the digital library with the spatial representation of the region, the unique quality of various GIS maps causes certain difficulties. The lack of standard in denoting spatial divisions in GIS is one hindrance to producing a more automated technique. Future work will include more automation, usability evaluation, and integration of additional excavations. We hope integration of the digital library and GIS greatly aids users' understanding of the spatial organization of the included data.

#index 874558
#* MANGAS infrastructure
#@ Hugo Manguinhas;José Borbinha
#t 2006
#c 14
#! This demonstration shows a set of tools for managing and performing quality control processes to monitor and enforce quality over UNIMARC descriptive metadata records. These tools share a common infrastructure consisting mainly on information coded in XML and tools to process it. This system is currently being used on the National Library of Portugal in production services for the quality control and maintenance of the national union catalogue.

#index 874559
#* How science web sites are leveraging DLESE search web services to extend value to their users
#@ Lynne Davis;John Weatherley
#t 2006
#c 14
#% 809408
#! This demonstration illustrates the use of two search services offered by the Digital Library for Earth System Education (DLESE) and shows how they have been used to create customized discovery interfaces for library resources in science Web sites.

#index 874560
#* Unsupervised structure discovery for biodiversity information
#@ Hong Cui;Richard M. McCourt;Monique Feist
#t 2006
#c 14
#% 617167
#% 911856

#index 874561
#* Visualizing an enterprise social network from email
#@ Weizhong Zhu;Chaomei Chen;Robert B. Allen
#t 2006
#c 14
#% 643723
#% 657181

#index 967243
#* Proceedings of the 7th ACM/IEEE-CS joint conference on Digital libraries
#@ Edie Rasmussen;Ray R. Larson;Elaine Toms;Shigeo Sugimoto
#t 2007
#c 14
#! Welcome to JCDL 2007! It is our great pleasure to welcome you to the 7th annual meeting of the ACM/IEEE Joint Conference on Digital Libraries (JCDL). JCDL is one of the primary international forums for the presentation and discussion of research, practice and social issues related to digital libraries. The conference theme this year is "Building and Sustaining the Digital Environment" and the program reflects these themes as well as the broader context of digital libraries and the boundary spanning research that supports their design, development and operation. This year we had a record number of submissions for the conference with 279 total submissions from digital library researchers in 31 countries. From 119 Full papers submissions and 68 short paper submissions the program committee selected 43 Full papers and 28 Short papers for presentation at the conference. In addition, 30 posters and 14 demonstrations were selected for presentation at the special poster and demo evening session. As in previous years we will be awarding the Vannevar Bush Best Paper Award (sponsored by ACM). In addition to the main meeting, a full schedule of tutorials and workshops has been arranged bracketing the main meeting. This year we also host the largest Doctoral Consortium yet held at JCDL, where student researchers in digital library topics work with an international panel of faculty mentors on exploring and refining their thesis research.

#index 967244
#* World explorer: visualizing aggregate data from unstructured text in geo-referenced collections
#@ Shane Ahern;Mor Naaman;Rahul Nair;Jeannie Hui-I Yang
#t 2007
#c 14
#% 281487
#% 378546
#% 437510
#% 730144
#% 780722
#% 784438
#% 860118
#% 869482
#% 874453
#% 881054
#% 903606
#! The availability of map interfaces and location-aware devices makes a growing amount of unstructured, geo-referenced information available on the Web. This type of information can be valuable not only for browsing, finding and making sense of individual items, but also in aggregate form to help understand data trends and features. In particular, over twenty million geo-referenced photos are now available on Flickr, a photo-sharing website - the first major collection of its kind. These photos are often associated with user-entered unstructured text labels (i.e., tags). We show how we analyze the tags associated with the geo-referenced Flickr images to generate aggregate knowledge in the form of "representative tags" for arbitrary areas in the world. We use these tags to create a visualization tool, World Explorer, tha tcan help expose the content of the data, using a map interface to display the derived tags and the original photo items. We perform a qualitative evaluation of World Explorer that outlines the visualization's benefits in browsing this type of content. We provide insights regarding the aggregate versus individual-item requirements in browsing digital geo-referenced material.

#index 967245
#* Categorization and analysis of text in computer mediated communication archives using visualization
#@ Ahmed Abbasi;Hsinchun Chen
#t 2007
#c 14
#% 118040
#% 238395
#% 260001
#% 289566
#% 308630
#% 324960
#% 343151
#% 344439
#% 344440
#% 445317
#% 449256
#% 501651
#% 591796
#% 722308
#% 733847
#% 832136
#% 832960
#% 843652
#% 852013
#% 854646
#% 857465
#% 874453
#% 995831
#% 1603196
#% 1678441
#% 1788189
#! Digital libraries (DLs) for online discourse contain large amounts of valuable information that is difficult to navigate and analyze. Visualization systems developed to facilitate improved CMC archive analysis and navigation primarily focus on interaction information, with little emphasis on textual content. In this paper we present a system that provides DL exploration services such as visualization, categorization, and analysis for CMC text. The system incorporates an extended feature set comprised of stylistic, topical, and sentiment related features to enable richer content representation. The system also includes the Ink Blot technique which utilizes decision tree models and text overlay to visualize CMC messages. Ink Blots can be used for text categorization and analysis across forums, authors, threads, messages, and over time. The proposed system's analysis capabilities were evaluated with a series of examples and a qualitative user study. Empirical categorization experiments comparing the Ink Blot technique against a benchmark support vector machine classifier were also conducted. The results demonstrated the efficacy of the Ink Blot technique for text categorization and also highlighted the effectiveness of the extended feature set for improved text categorization.

#index 967246
#* Delineating the citation impact of scientific discoveries
#@ Chaomei Chen;Jian Zhang;Weizhong Zhu;Michael Vogeley
#t 2007
#c 14
#% 136350
#% 247507
#% 277646
#% 451484
#% 466240
#% 577220
#% 577360
#% 740900
#% 769906
#% 771924
#% 804886
#% 852014
#% 889880
#! Identifying the significance of specific concepts in the diffusion of scientific knowledge is a challenging issue concerning many theoretical and practical areas. We introduce an innovative visual analytic approach to integrate microscopic and macroscopic perspectives of a rapidly growing scientific knowledge domain. Specifically, our approach focuses on statistically unexpected phrases extracted from unstructured text of titles and abstracts at the microscopic level in association with the magnitude and timeliness of their citation impact at the macroscopic level. The H-index, originally defined to measure individual scientists. productivity in terms of their citation profiles, is extended in two ways: 1) to papers and terms as a means of dividing these items into two groups so as to replace the less optimal threshold-based divisions, and 2) to take into account the timeliness of the impact of knowledge diffusion in terms of the timing of citations and publications so that attention is particularly drawn towards potentially significant and timely papers. The selected terms are connected to higher-level performance indicators, such as measures derived from the H-index, in the form of decision trees. A top-down traversal of such decision trees provides an intuitive walkthrough of concepts and phrases that may underline potentially significant but currently still latent scientific discoveries. Timeliness measures can also help to identify institutions that are at the forefront of a research field. We illustrate how widely accessible tools such as Google Earth can be utilized to disseminate such insights. The practical significance for digital libraries and fostering scientific discoveries is demonstrated through the astronomical literature related to the Sloan Digital Sky Survey (SDSS).

#index 967247
#* How to choose a digital preservation strategy: evaluating a preservation planning procedure
#@ Stephan Strodl;Christoph Becker;Robert Neumayer;Andreas Rauber
#t 2007
#c 14
#% 356167
#% 614040
#% 760863
#% 803131
#% 859916
#% 874465
#% 1656108
#% 1734591
#% 1794258
#! An increasing number of institutions throughout the world face legal obligations or business needs to collect and preserve digital objects over several decades. A range of tools exists today to support the variety of preservation strategies such as migration or emulation. Yet, different preservation requirements across institutions and settings make the decision on which solution to implement very diffcult. This paper presents the PLANETS Preservation Planning approach. It provides an approved way to make informed and accountable decisions on which solution to implement in order to optimally preserve digital objects for a given purpose. It is based on Utility Analysis to evaluate the performance of various solutions against well-defined requirements and goals. The viability of this approach is shown in a range of case studies for different settings. We present its application to two scenarios of web archives, two collections of electronic publications, and a collection of multimedia art. This work focuses on the different requirements and goals in the various preservation settings.

#index 967248
#* Factors affecting website reconstruction from the web infrastructure
#@ Frank McCown;Norou Diawara;Michael L. Nelson
#t 2007
#c 14
#% 255137
#% 267667
#% 309746
#% 438365
#% 577370
#% 754058
#% 754060
#% 754090
#% 760841
#% 773040
#% 807320
#% 863312
#% 869499
#% 881071
#% 881072
#% 906804
#% 907439
#% 907442
#% 967290
#% 978374
#! When a website is suddenly lost without a backup, it maybe reconstituted by probing web archives and search engine caches for missing content. In this paper we describe an experiment where we crawled and reconstructed 300 randomly selected websites on a weekly basis for 14 weeks. The reconstructions were performed using our web-repository crawler named Warrick which recovers missing resources from the Web Infrastructure (WI), the collective preservation effort of web archives and search engine caches. We examine several characteristics of the websites over time including birth rate, decay and age of resources. We evaluate the reconstructions when compared to the crawled sites and develop a statistical model for predicting reconstruction success from the WI. On average, we were able to recover 61% of each website's resources. We found that Google's PageRank, number of hops and resource age were the three most significant factors in determining if a resource would be recovered from the WI.

#index 967249
#* Defining what digital curators do and what they need to know: the digccurr project
#@ Christopher A. Lee;Helen R. Tibbo;John C. Schaefer
#t 2007
#c 14
#! The DigCCurr (Digital Curation Curriculum) project is developing a graduate level curricular framework, course modules, and experiential components to prepare students for digital curation in various environments. This paper summarizes a draft and guiding principles behind a matrix of digital curation knowledge and competencies, which are serving as the basis for our curriculum design efforts.

#index 967250
#* Generating best-effort preservation metadata for web resources at time of dissemination
#@ Joan A. Smith;Michael L. Nelson
#t 2007
#c 14
#% 859918
#% 907439
#! HTTP and MIME, while sufficient for contemporary webpage access, do not provide enough forensic information to enable the long-term preservation of the resources they describe and transport. But what if the originating web server automatically provided preservation metadata encapsulated with the resource at time of dissemination? Perhaps the ingestion process could be streamlined, with additional forensic metadata available to future information archeologists. We have adapted an Apache web server implementation of OAI-PMH which can utilize third-party metadata analysis tools to provide a metadata-rich description of each resource. The resource and its forensic metadata are packaged together as a complex object, expressed in plain ASCII and XML. The result is a CRATE: a self-contained preservation-ready version of the resource, created at time of dissemination.

#index 967251
#* Document clustering using small world communities
#@ Brant W. Chee;Bruce Schatz
#t 2007
#c 14
#% 46809
#% 248058
#% 279755
#% 281350
#% 296738
#% 309128
#% 413360
#% 574791
#% 748499
#% 769963
#% 1742083
#! Words in natural language documents exhibit a small world network structure. Thus the physics community provides us with an extensive supply of algorithms for extracting community structure. We present a novel method for semantically clustering a large collection of documents using small world communities. This method combines modified physics algorithms with traditional information retrieval techniques. A term network is generated from the document collection, the terms are clustered into small world communities, the semantic term clusters are used to generate overlapping document clusters. The algorithm combines the speed of single link with the quality of complete link. Clustering takes place in nearly real-time and the results are judged to be coherent by expert users. Our algorithm occupies a middle ground between speed and quality of document clustering.

#index 967252
#* Efficient summarization-aware search for online news articles
#@ Wisam Dakka;Luis Gravano
#t 2007
#c 14
#% 11646
#% 190581
#% 218992
#% 227486
#% 262045
#% 269217
#% 281186
#% 309131
#% 375017
#% 402289
#% 427921
#% 445243
#% 766430
#% 766433
#% 815133
#% 995468
#% 995508
#! News portals gather and organize news articles published daily on the Internet. Typically, news articles are clustered into 'events' and each cluster is displayed with a short description of its contents. A particularly interesting choice for describing the contents of a cluster is a machine-generated multi-document summary of the articles in the cluster. Such summaries are informative and help news readers to identify and explore only clusters of interest. Naturally, multi-document clusters and summaries are also valuable to help users navigate the results of keyword-search queries. Unfortunately, current document summarizers are still slow; as a result, search strategies that define document clusters and their multi-document summaries online, in a query-specific manner, are prohibitively expensive. In contrast, search strategies that only return offline, query-independent document clusters are efficient, but might return clusters whose (query-independent) summaries are of little relevance to the queries. In this paper, we present an efficient Hybrid search strategy to address the limitations of fully online and fully offline summarization-aware search approaches. Extensive experiments involving user relevance judgments and real news articles show that the quality of our Hybrid results is high, and that these results are computed in substantially less time than with the fully online strategy. We have implemented our strategy and made it available on the Newsblaster news summarization system, which crawls and summarizes news articles from a variety of web sources on a daily basis.

#index 967253
#* Integrating data and text mining processes for digital library applications
#@ Robert Sanderson;Paul Watry
#t 2007
#c 14
#% 614036
#% 729417
#% 786497
#% 809420
#% 878626
#% 879708
#% 939912
#% 1558464
#! This paper explores the integration of text mining and data mining techniques, digital library systems, and computational and data grid technologies with the objective of developing an online classification service exemplar. We discuss the current research issues relating to the use of data mining algorithms and toolkits for textual data; the necessary changes within the Cheshire3 Information Framework to accommodate analysis workflows; the outcomes of a demonstrator based on the National Library of Medicine's Medline dataset; and the provision of comparable metrics for evaluation purposes. The prototype has resulted in extremely accurate online classification services and offers a novel method of supporting text mining and data mining within a highly scaled computational environment, integrated seamlessly into the digital library architecture.

#index 967254
#* The OAI-ORE effort: progress, challenges, synergies
#@ Cliff Lynch;Savas Parastatidis;Neil Jacobs;Herbert Van de Sompel;Carl Lagoze
#t 2007
#c 14
#! The panel will discuss various aspects of the ongoing Object Re-Use and Exchange (ORE) effort of the Open Archives Initiative (OAI). OAI-ORE is funded by the Andrew W. Mellon Foundation and is a result of the "Augmenting Interoperability across Scholarly Repositories" meeting that took place in April 2006 at the Mellon Foundation. A panel at JCDL 2006 reported on this meeting. The goal of OAI-ORE is to develop, identify, and profile extensible standards and protocols that allow repositories, agents, and services to interoperate in the context of use and reuse of compound digital objects beyond the boundaries of the holding repositories.

#index 967255
#* SlideSeer: a digital library of aligned document and presentation pairs
#@ Min-Yen Kan
#t 2007
#c 14
#% 310516
#% 342080
#% 449751
#% 748342
#% 748343
#% 748593
#% 769446
#% 780725
#% 783477
#% 844945
#% 1250576
#% 1656131
#! Research findings are often transmitted both as written documents and narrated slide presentations. As these two forms of media contain both unique and replicated information, it is useful to combine and align these two views to create a single synchronized medium. We introduce SlideSeer, a digital library that discovers, aligns and presents such presentation and document pairs. We discuss the three major system components of the SlideSeer DL: 1) the resource discovery, 2) the fine-grained alignment and 3) the user interface. For resource discovery, we have bootstrapped our collection building process using metadata from DBLP and CiteSeer. For alignment, we modify maximum similarity alignment to favor monotonic alignments and incorporate a classifier to handle slides which should not be aligned. For the user interface, we allow the user to seamlessly switch between four carefully motivated views of the resulting synchronized media pairs.

#index 967256
#* TableSeer: automatic table metadata extraction and searching in digital libraries
#@ Ying Liu;Kun Bai;Prasenjit Mitra;C. Lee Giles
#t 2007
#c 14
#% 46803
#% 237328
#% 348147
#% 493837
#% 544484
#% 625351
#% 643004
#% 658655
#% 658656
#% 703070
#% 718869
#% 755816
#% 781729
#% 786564
#% 807369
#% 874518
#% 1269719
#! Tables are ubiquitous in digital libraries. In scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. However, current search engines do not support table search. The difficulty of automatic extracting tables from un-tagged documents, the lack of a universal table metadata specification, and the limitation of the existing ranking schemes make table search problem challenging. In this paper, we describe TableSeer, a search engine for tables. TableSeer crawls digital libraries, detects tables from documents, extracts tables metadata, indexes and ranks tables, and provides a user-friendly search interface. We propose an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information. In addition, we devise a novel page box-cutting method to improve the performance of the table detection. Given a query, TableSeer ranks the matched tables using an innovative ranking algorithm - TableRank. TableRank rates each ⃭query, tableℂ pair with a tailored vector space model and a specific term weighting scheme. Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables. We demonstrate the value of TableSeer with empirical studies on scientific documents.

#index 967257
#* CiteSearch: next-generation citation analysis
#@ Kiduk Yang;Lokman Meho
#t 2007
#c 14
#% 277646
#% 876532
#! The coverage of citations in citation databases of today is disjoint and incomplete, which can result in conflicting quality assessment outcomes across different data sources. Fusion approach to quality assessment that employs a range of citation-based methods to analyze data from multiple sources is one way to address this limitation. The paper discusses a citation analysis pilot study that measured the impact of scholarly publications based on the data mined from Web of Science, Scopus, and Google Scholar.

#index 967258
#* Retrieval effectiveness of table of contents and subject headings
#@ Youngok Choi;Ingrid Hsieh-Yee;Bill Kules
#t 2007
#c 14
#! The effectiveness of two modes of subject representation - table of contents (TOC) and subject headings - in subject searching in an online public access catalog (OPAC) system was investigated. The retrieval difference between TOC and the Library of Congress subject headings (LCSH) was statistically significant; the effect of subject domain was not statistically significant; users had better success matching their keywords to TOC than to LCSH; but their keywords often failed to retrieve items similar to the target items. These findings underscore the need to bridge user keywords to both TOC and LCSH.

#index 967259
#* Mining a digital library for influential authors
#@ David Mimno;Andrew McCallum
#t 2007
#c 14
#% 722904
#% 874462
#% 879587
#! When browsing a digital library of research papers, it is natural to ask which authors are most influential in a particular topic. We present a probabilistic model that ranks authors based on their influence in particular areas of scientific research. This model combines several sources of information: citation information between documents as represented by PageRank scores, authorship data gathered through automatic information extraction, and the words in paper abstracts. We compare the performance of a topic model versus a smoothed language model by assessing the number of major award winners in the resulting ranked list of researchers.

#index 967260
#* Can social bookmarking enhance search in the web?
#@ Yusuke Yanbe;Adam Jatowt;Satoshi Nakamura;Katsumi Tanaka
#t 2007
#c 14
#% 46803
#% 290830
#% 348155
#% 449219
#% 577370
#% 641979
#% 769488
#% 807658
#% 810054
#% 855601
#% 869504
#% 877579
#% 881054
#% 881055
#% 881061
#% 881065
#% 1712595
#% 1730013
#! Social bookmarking is an emerging type of a Web service that helps users share, classify, and discover interesting resources. In this paper, we explore the concept of an enhanced search, in which data from social bookmarking systems is exploited for enhancing search in the Web. We propose combining the widely used link-based ranking metric with the one derived using social bookmarking data. First, this increases the precision of a standard link-based search by incorporating popularity estimates from aggregated data of bookmarking users. Second, it provides an opportunity for extending the search capabilities of existing search engines. Individual contributions of bookmarking users as well as the general statistics of their activities are used here for a new kind of a complex search where contextual, temporal or sentiment-related information is used. We investigate the usefulness of social bookmarking systems for the purpose of enhancing Web search through a series of experiments done on datasets obtained from social bookmarking systems. Next, we show the prototype system that implements the proposed approach and we present some preliminary results.

#index 967261
#* Task-based interaction with an integrated multilingual, multimedia information system: a formative evaluation
#@ Pengyi Zhang;Lynne Plettenberg;Judith L. Klavans;Douglas W. Oard;Dagobert Soergel
#t 2007
#c 14
#% 49490
#% 214709
#% 313719
#% 345371
#% 381263
#% 424008
#% 424015
#% 571493
#% 575570
#% 607985
#% 720198
#% 784153
#% 848640
#% 881944
#% 939694
#% 1015007
#% 1674924
#! This paper describes a formative evaluation of an integrated multilingual, multimedia information system, a series of user studies designed to guide system development. The system includes automatic speech recognition for English, Chinese, and Arabic, automatic translation from Chinese and Arabic into English, and query-based and profile-based search options. The study design emphasizes repeated evaluation with the same (increasingly experienced) participants, exploration of alternative task designs, rich qualitative and quantitative data collection, and rapid analysis to provide the timely feedback needed to support iterative and responsive development. Results indicate that users presented with materials in a language that they do not know can generate remarkably useful work products, but that integration of transcription, translation, search and profile management poses challenges that would be less evident were each technology to be evaluated in isolation.

#index 967262
#* Modeling personal and social network context for event annotation in images
#@ Bageshree Shevade;Hari Sundaram;Lexing Xie
#t 2007
#c 14
#% 420175
#% 443698
#% 730148
#% 739767
#% 751818
#% 752138
#% 783633
#% 809435
#% 839949
#% 974035
#% 1858012
#! This paper describes a framework to annotate images using personal and social network contexts. The problem is important as the correct context reduces the number of image annotation choices.. Social network context is useful as real-world activities of members of the social network are often correlated within a specific context. The correlation can serve as a powerful resource to effectively increase the ground truth available for annotation. There are three main contributions of this paper: (a) development of an event context framework and definition of quantitative measures for contextual correlations based on concept similarity in each facet of event context; (b) recommendation algorithms based on spreading activations that exploit personal context as well as social network context; (c) experiments on real-world, everyday images that verified both the existence of inter-user semantic disagreement and the improvement in annotation when incorporating both the user and social network context. We have conducted two user studies, and our quantitative and qualitative results indicate that context (both personal and social) facilitates effective image annotation.

#index 967263
#* Longitudinal study of changes in blogs
#@ Paul Logasa Bogen, II;Luis Francisco-Revilla;Richard Furuta;Takeisha Hubbard;Unmil P. Karadkar;Frank Shipman
#t 2007
#c 14
#% 231522
#% 240748
#% 337690
#% 760841
#% 869596
#% 881051
#! Web-based distributed collections often include links to documents that are expected to change frequently, such as blogs. The study reported here demonstrates that blog changes follow specific patterns. The results also illustrate the substantial role of standardized templates in blog pages. These results extend our earlier models that assess the significance of Web page change from a human perspective. These improved models will enable software systems to assist human collection managers in identifying unexpected changes and aberrant events.

#index 967264
#* SearchGen: a synthetic workload generator for scientific literature digital libraries and search engines
#@ Huajing Li;Wang-Chien Lee;Anand Sivasubramaniam;Lee Giles
#t 2007
#c 14
#% 243929
#% 249143
#% 250201
#% 335945
#% 348074
#% 348151
#% 404849
#% 420132
#% 611109
#% 710344
#% 727917
#% 754110
#% 815376
#% 820265
#% 869573
#% 1015315
#! Due to the popularity of web applications and their heavy usage, it is important to obtain a good understanding of their workloads in order to improve performance of search services. Existing works have typically focused on generic web workloads without putting emphasis on specific domains. In this paper, we analyze the usage logs of CiteSeer, a scientific literature digital library and search engine, to characterize workloads for both robots and users. Essential ingredients that contribute to workloads are proposed. Among them we find the access intervals show high variance, and thus cannot be predicted well with time-series models. On the other hand, client visiting path and semantics can be well captured with probabilistic models and Zipf-law. Based on the findings, we propose SearchGen, a synthetic workload generator to output traces for scientific literature digital libraries and search engines. A comparison between synthetic workloads and actual logged traces suggests that the synthetic workload fits well.

#index 967265
#* A retrospective look at Greenstone: lessons from the first decade
#@ Ian H. Witten;David Bainbridge
#t 2007
#c 14
#% 429991
#% 809420
#% 824484
#% 859913
#% 874469
#! The Greenstone Digital Library Software has helped spread the practical impact of digital library technology throughout the world, with particular emphasis on developing countries. As Greenstone enters its second decade, this article takes a retrospective look at its development, the challenges that have been faced, and the lessons that have been learned in developing and deploying a comprehensive open-source system for the construction of digital libraries internationally. Not surprisingly, the most difficult challenges have been political, educational, and sociological, echoing that old programmers' blessing "may all your problems be technical ones.".

#index 967266
#* A unified platform for archival description and access
#@ Christopher J. Prom;Christopher A. Rishel;Scott W. Schwartz;Kyle J. Fox
#t 2007
#c 14
#! The archival community has developed content and data structure standards to facilitate access to the diverse and unique sets of archival records, personal papers, and manuscript collections that are held by archival repositories and special collections libraries. However, these standards are difficult for archivists to use and are often implemented in ways that negatively affect materials-handling workflows, depriving archival users of the best possible access to the totality of materials available within an individual repository. The authors propose that archival descriptive problems can be addressed by implementing a web/database application that is tailored specifically to archival needs and can be implemented with little technical knowledge. This paper describes the system architecture of one such tool, the Archon software package, which was developed at the University of Illinois at Urbana-Champaign. Archon automates many technical tasks, such as producing a searchable website, an EAD instance or a MARC record. Although the system utilizes sophisticated algorithms and optimizations, it is easily extensible because most development takes place in an easy-to-use, object-oriented environment.

#index 967267
#* Children's interests and concerns when using the international children's digital library: a four-country case study
#@ Allison Druin;Ann Weeks;Sheri Massey;Benjamin B. Bederson
#t 2007
#c 14
#! This paper presents a case study of 12 children who used the International Children's Digital Library (ICDL) over four years and live in one of four countries: Germany, Honduras, New Zealand, and the United States. By conducting interviews, along with collecting drawings and book reviews, this study describes these children's interests in books, libraries, technology and the world around them. Findings from this study include: these young people increased the variety of books they read online; still valued their physical libraries as spaces for social interaction and reading; showed increased reading motivation; and showed interest in exploring different cultures.

#index 967268
#* Digital library education in computer science programs
#@ Jeffrey Pomerantz;Sanghee Oh;Barbara M. Wildemuth;Seungwon Yang;Edward A. Fox
#t 2007
#c 14
#% 750866
#% 874479
#! In an effort to identify the "state of the art" in digital library education in computer science (CS) programs, we analyzed CS courses on digital libraries and digital library-related topics. Fifteen courses that mention digital libraries in the title or short description were identified; of these, five are concerned with digital libraries as the primary topic of the course. The readings from these five courses were analyzed further, in terms of their authors and the journals in which they were published.

#index 967269
#* A study of how online learning resource are used
#@ Mimi Recker;Sarah Giersch;Andrew Walker;Sam Halioris;Xin Mao;Bart Palmer
#t 2007
#c 14
#% 809402
#! This paper defines a model of teacher practice ("teaching as design"), and describes a professional development curriculum in which K-12 teachers design learning activities using resources and tools from education digital libraries. It then presents preliminary findings from an application of this model in which teachers' artifacts are analyzed to learn how online learning resources are used in situ. Initial results suggest that learning resources of a smaller granularity are more likely to be adapted or improvised upon in teacher-designed learning activities, which further supports teachers' becoming contributors of online resources and active participants in an education cyberinfrastructure.

#index 967270
#* Standards or semantics for curriculum search?
#@ Byron B. Marshall;René F. Reitsma;Martha N. Cyr
#t 2007
#c 14
#% 809402
#% 809440
#! Aligning digital library resources with national and state educational standards to help K-12 teachers search for relevant curriculum is an important issue in the digital library community. Aligning standards from different states promises to help teachers in one state find appropriate materials created and cataloged elsewhere. Although such alignments provide a powerful means for crosswalking standards and curriculum across states, alignment matrices are intrinsically sparse. Hence, we hypothesize that such sparseness may cause significant numbers of false negatives when used for searching curriculum. Our preliminary results confirm the false negative hypothesis, demonstrate the usefulness of term-based techniques in addressing the false negative problem, and explore ways to combine term occurrence data with standards correlations.

#index 967271
#* Information behavior of small groups: implications for design of digital libraries
#@ Nan Zhou;Gerry Stahl
#t 2007
#c 14
#% 282914
#! We report findings of a study that investigates the information behavior of online small groups engaged in math problem solving and discuss the implications for designing digital libraries that can support learning of younger students and their broader information practices.

#index 967272
#* Adaptive sorted neighborhood methods for efficient record linkage
#@ Su Yan;Dongwon Lee;Min-Yen Kan;Lee C. Giles
#t 2007
#c 14
#% 201889
#% 310516
#% 328186
#% 337227
#% 438103
#% 577238
#% 577309
#% 654467
#% 809460
#% 844199
#% 870896
#% 993980
#% 1250576
#! Traditionally, record linkage algorithms have played an important role in maintaining digital libraries - i.e., identifying matching citations or authors for consolidation in updating or integrating digital libraries. As such, a variety of record linkage algorithms have been developed and deployed successfully. Often, however, existing solutions have a set of parameters whose values are set by human experts off-lineand are fixed during the execution. Since finding the ideal values of such parameters is not straightforward, or no such single ideal value even exists, the applicability of existing solutions to new scenarios or domains is greatly hampered. To remedy this problem, we argue that one can achieve significant improvement by adaptively and dynamically changing such parameters of record linkage algorithms. To validate our hypothesis, we take a classical record linkage algorithm, the sorted neighborhood method (SNM), and demonstrate how we can achieve improved accuracy and performance by adaptively changing its fixed sliding window size. Our claim is analytically and empirically validated using both real and synthetic data sets of digital libraries and other domains.

#index 967273
#* Distributed web search efficiency by truncating results
#@ Christopher T. Fallen;Gregory B. Newby
#t 2007
#c 14
#% 100699
#% 115462
#% 169780
#% 309253
#% 340892
#% 359132
#% 480479
#% 879564
#% 879619
#% 1678502
#! A large set of Web documents (the TREC GOV2 collection) comes from many separate Internet hosts, such as www.nih.gov and travel.state.gov. There is considerable variability in the number of Web pages (i.e., documents) from each host. In this paper, we present and evaluate a method for setting a maximum number of "hits" that may be presented for each web host. Federated search environments are increasingly common components of digital libraries and in these environments, the benefit of such a maximum is that it can reduce the number of possibly relevant documents presented by each subcollection, without hurting early precision measures such as P@20. Derivation of a maximum number, which is proportional to the subcollection size but not sensitive to different search topics, is made possible by an analysis of patterns of relevance judgment across approximately 17,000 web hosts in GOV2.

#index 967274
#* Adaptive graphical approach to entity resolution
#@ Zhaoqi Chen;Dmitri V. Kalashnikov;Sharad Mehrotra
#t 2007
#c 14
#% 22412
#% 201889
#% 271128
#% 310516
#% 577238
#% 577247
#% 577263
#% 729913
#% 760866
#% 766199
#% 805885
#% 809460
#% 810014
#% 810107
#% 819550
#% 830275
#% 838435
#% 868091
#% 871766
#% 874503
#% 879568
#% 915273
#% 993980
#% 1250185
#% 1408793
#! Entity resolution is a very common Information Quality (IQ) problem with many different applications. In digital libraries, it is related to problems of citation matching and author name disambiguation; in Natural Language Processing, it is related to coreference matching and object identity; in Web application, it is related to Web page disambiguation. The problem of Entity Resolution arises because objects/entities in real world datasets are often referred to by descriptions, which might not be unique identifiers of these entities, leading to ambiguity. The goal is to group all the entity descriptions that refer to the same real world entities. In this paper we present a graphical approach for entity resolution. It complements the traditional methodology with the analysis of the entity-relationship graph constructed for the dataset being analyzed. The paper demonstrates that a technique that measures the degree of interconnectedness between various pairs of nodes in the graph can significantly improve the quality of entity resolution. Furthermore, the paper presents an algorithm for making that technique self-adaptive to the underlying data, thus minimizing the required participation from the domain-analyst and potentially further improving the disambiguation quality.

#index 967275
#* Cyberinfrastructure for the humanities and social sciences: advancing the humanities research agenda
#@ Joyce Ray;Clifford Lynch;Brett Bobley;Gregory Crane;Steven Wheatley
#t 2007
#c 14
#! In 2006 the American Council of Learned Societies (ACLS) released Our Cultural Commonwealth, the final report of the Commission on Cyberinfrastructure for the Humanities and Social Sciences. The report, based on a study funded by the Mellon Foundation, explored how research environments might be created for the humanities and social sciences to complement those being developed to support scientific research. The report includes key recommendations addressed to universities, funding agencies, scholarly societies, academic libraries, publishers, Congress, state legislatures, and others. Implementation of the recommendations could potentially transform scholarship and exponentially increase access to resources and new scholarship in the humanities and social sciences. But the report has not been universally embraced. How will humanities scholarship be advanced by new technologies and research practices, and how will the academic community recognize new forms of scholarship? How will funding agencies respond to the challenges and issues raised? What does cyberinfrastructure mean for different domains within the humanities? These questions will be addressed by panelists and discussed by participants.

#index 967276
#* FLUX-CIM: flexible unsupervised extraction of citation metadata
#@ Eli Cortez;Altigran S. da Silva;Marcos André Gonçalves;Filipe Mesquita;Edleno S. de Moura
#t 2007
#c 14
#% 268079
#% 275915
#% 278109
#% 300288
#% 312860
#% 397605
#% 424931
#% 431536
#% 438103
#% 480824
#% 531459
#% 614036
#% 654469
#% 729978
#% 754108
#% 760856
#% 809426
#% 809453
#% 846237
#% 874463
#% 948374
#% 1020797
#% 1329635
#! In this paper we propose a knowledge-base approach to help extracting the correct components of citations in any given format. Differently from related approaches that rely on manually built knowledge-bases (KBs) for recognizing the components of a citation, in our case, such a KB is automatically constructed from an existing set of sample metadata records from a given area (e.g., computer science or health sciences). Our approach does not rely on patterns encoding specific delimitators of a particular citation style. It is also unsupervised, in the sense that it does not rely on a learning method that requires a training phase. These features assign to our technique a high degree of automation and flexibility. To demonstrate the effectiveness and applicability of our proposed approach we have run experiments in which we applied it to extract information from citations in papers of two different domains. Results of these experiments indicate precision and recall levels above 94% and perfect extraction for the large majority of citations tested.

#index 967277
#* Measuring conference quality by mining program committee characteristics
#@ Ziming Zhuang;Ergin Elmacioglu;Dongwon Lee;C. Lee Giles
#t 2007
#c 14
#% 136350
#% 235377
#% 269207
#% 722474
#% 824757
#% 824797
#% 835342
#% 841613
#% 845353
#% 869471
#% 874462
#% 874548
#% 1133983
#% 1290045
#% 1499573
#! Bibliometrics are important measures for venue quality in digital libraries. Impacts of venues are usually the major consideration for subscription decision-making, and for ranking and recommending high-quality venues and documents. For digital libraries in the Computer Science literature domain, conferences play a major role as an important publication and dissemination outlet. However, with a recent profusion of conferences and rapidly expanding fields, it is increasingly challenging for researchers and librarians to assess the quality of conferences. We propose a set of novel heuristics to automatically discover prestigious (and low-quality) conferences by mining the characteristics of Program Committee members. We examine the proposed cues both in isolation and combination under a classification scheme. Evaluation on a collection of 2,979 conferences and 16,147 PC members shows that our heuristics, when combined, correctly classify about 92% of the conferences, with a low false positive rate of 0.035 and a recall of more than 73% for identifying reputable conferences. Furthermore, we demonstrate empirically that our heuristics can also effectively detect a set of low-quality conferences, with a false positive rate of merely 0.002. We also report our experience of detecting two previously unknown low-quality conferences. Finally, we apply the proposed techniques to the entire quality spectrum by ranking conferences in the collection.

#index 967278
#* Toward alternative measures for ranking venues: a case of database research community
#@ Su Yan;Dongwon Lee
#t 2007
#c 14
#% 348173
#% 841613
#% 841615
#% 845353
#% 874462
#% 874548
#! Ranking of publication venues is often closely related with important issues such as evaluating the contributions of individual scholars/research groups, or subscription decision making. The development of large-scale digital libraries and the availability of various meta data provide the possibility of building new measures more efficiently and accurately. In this work, we propose two novel measures for ranking the impacts of academic venues an easy-to-implement seed-based measure that does not use citation analysis, and a realistic browsing-based measure that takes an article reader's behavior into account. Both measures are computationally efficient yet mimic the results of the widely accepted Impact Factor. In particular, our proposal exploits the fact that: (1)in most disciplines, there are "top" venues that most people agree on; and (2) articles that appeared in good venues are more likely to be viewed by readers. Our proposed measures are extensively evaluated on a test case of the Database research community using two real bibliography data sets - ACM and DBLP. Finally, ranks of venues by our proposed measures are compared against the Impact Factor using the Spearman's rank correlation coefficient, and their positive rank order relationship is proved with a statistical significance test.

#index 967279
#* A model for inclusive design of digital libraries
#@ Sambhavi Chandrashekar;Nadia Caidi
#t 2007
#c 14
#% 755685
#% 879434
#% 1303215
#! Digital libraries (DLs) must cater not only to the varied needs of its target users but also to their differing abilities, and to the adaptive technologies used by persons whose computing capabilities are restricted due to disabilities. This paper proposes a model for DL design that includes optimization of the usability of the search process and ensures accessibility of the content for users of DLs with disabilities.

#index 967280
#* Representing aggregate works in the digital library
#@ George Buchanan;Jeremy Gow;Ann Blandford;Jon Rimmer;Claire Warwick
#t 2007
#c 14
#% 151427
#% 290703
#% 301247
#% 301539
#% 337261
#% 401406
#% 402429
#% 508276
#% 616528
#% 809406
#% 874499
#% 1709410
#% 1709412
#! This paper studies the challenge of representing aggregate works such as encyclopedias, collected poems and journals in heterogenous digital library collections. Reflecting on the materials used by humanities academics, we demonstrate the varied range of aggregate types and the problems of faithfully representing this in the DL interface. Aggregates are complex and pervasive, challenge common assumptions and confuse boundaries within organisational structures. Existing DL systems can only provide imperfect representation of aggregates, and alterations to document encoding are insufficient to create a faithful reproduction of the physical library. The challenge is amplified through concrete examples, and solutions are demonstrated in a well-known DL system and related to standard DL architecture.

#index 967281
#* StoryBank: an indian village community digital library
#@ Matt Jones;Will Harwood;George Buchanan;Mounia Lalmas
#t 2007
#c 14
#% 332757
#% 760871
#% 872287
#! This paper considers information access styles for a community digital library in an Indian village. We present our impressions of the community gathered during a field-study and show how these have influenced the interaction design. The prototype aims to overcome low-textual literacy and lack of computing experience by combining touch-based interaction, engaging visual presentations and drawing on villagers' familiarity with radio listening.

#index 967282
#* The gray lady gets a new dress: a field study of the times news reader
#@ Catherine C. Marshall
#t 2007
#c 14
#% 201992
#% 202011
#% 249090
#% 249158
#% 258826
#% 281379
#% 287210
#% 316796
#% 760852
#% 802867
#% 806363
#% 809507
#% 860065
#% 1387559
#! Increasingly individuals are turning to online sources for their daily news. Traditional newspapers have developed significant web presences to compete with newer services such as news aggregators and emerging genres such as blogs and other forms of citizen journalism. This paper reports the results of a field study to investigate the use of a new RSS-driven, template-based presentation mechanism that delivers a daily newspaper to subscribers' laptops and desktops; the Times News Reader hybridizes elements of print newspapers with aspects of online news. We explore how this application compares with print and web-based news reading and evaluate functionality developed to draw in readers from both audiences. Finally we examine three general technological implications drawn from current use: how the news reader may adapt to different styles of reading; how the news reader's functionality may be extended to highlight the timeliness of the content and to personalize the application; and how long-term use of the news reader can result in a personal news archive.

#index 967283
#* Drowning in data: digital library architecture to support scientific use of embedded sensor networks
#@ Christine L. Borgman;Jillian C. Wallis;Matthew S. Mayernik;Alberto Pepe
#t 2007
#c 14
#% 739905
#% 769709
#% 787883
#% 1000935
#% 1021630
#% 1682001
#! New technologies for scientific research are producing a deluge of data that is overwhelming traditional tools for data capture, analysis, storage, and access. We report on a study of scientific practices associated with dynamic deployments of embedded sensor networks to identify requirements for data digital libraries. As part of continuing research on scientific data management, we interviewed 22 participants in 5 environmental science projects to identify data types and uses, stages in their data life cycle, and requirements for digital library architecture. We found that scientists need continuous access to their data from the time that field experiments are designed through final analysis and publication, thus reflecting a broader notion of "digital library." Six categories of requirements are discussed: the ability to obtain and maintain data in the field, verify data in the field, document data context for subsequent interpretation, integrate data from multiple sources, analyze data, and preserve data. Three digital library efforts currently underway within the Center for Embedded Networked Sensing are addressing these requirements, with the goal of a tightly coupled interoperable framework that, in turn, will be a component of cyberinfrastructure for science.

#index 967284
#* A practical ontology for the large-scale modeling of scholarly artifacts and their usage
#@ Marko A. Rodriguez;Johan Bollen;Herbert Van de Sompel
#t 2007
#c 14
#% 309789
#% 508283
#% 534148
#% 787654
#% 804874
#% 841613
#% 867267
#% 874506
#! The large-scale analysis of scholarly artifact usage is constrained primarily by current practices in usage data archiving, privacy issues concerned with the dissemination of usage data, and the lack of a practical ontology for modeling the usage domain. As a remedy to the third constraint, this article presents a scholarly ontology that was engineered to represent those classes for which large-scale bibliographic and usage data exists, supports usage research, and whose instantiation is scalable to the order of 50 million articles along with their associated artifacts (e.g. authors and journals) and an accompanying 1 billion usage events. The real world instantiation of the presented abstract ontology is a semantic network model of the scholarly community which lends the scholarly process to statistical analysis and computational support. We present the ontology, discuss its instantiation, and provide some example inference rules for calculating various scholarly artifact metrics.

#index 967285
#* A dynamic ontology for a dynamic reference work
#@ Mathias Niepert;Cameron Buckner;Colin Allen
#t 2007
#c 14
#% 67565
#% 279755
#% 280849
#% 300981
#% 376266
#% 387427
#% 442814
#% 464434
#% 481290
#% 543376
#% 722914
#% 729918
#% 756964
#% 853531
#% 935763
#% 1098441
#% 1272078
#% 1682143
#! The successful deployment of digital technologies by humanities scholars presents computer scientists with a number of unique scientific and technological challenges. The task seems particularly daunting because issues in the humanities are presented in abstract language demanding the kind of subtle interpretation often thought to be beyond the scope of artificial intelligence, and humanities scholars themselves often disagree about the structure of their disciplines. The future of humanities computing depends on having tools for automatically discovering complex semantic relationships among different parts of a corpus. Digital library tools for the humanities will need to be capable of dynamically tracking the introduction of new ideas and interpretations and applying them to older texts in ways that support the needs of scholars and students. This paper describes the design of new algorithms and the adjustment of existing algorithms to support the automated and semi-automated management of domain-rich metadata for an established digital humanities project, the Stanford Encyclopedia of Philosophy. Our approach starts with a "hand-built" formal ontology that is modified and extended by a combination of automated and semi-automated methods, thus becoming a "dynamic ontology". We assess the suitability of current information retrieval and information extraction methods for the task of automatically maintaining the ontology. We describe a novel measure of term-relatedness that appears to be particularly helpful for predicting hierarchical relationships in the ontology. We believe that our project makes a further contribution to information science by being the first to harness the collaboration inherent in a expert-maintained dynamic reference work to the task of maintaining and verifying a formal ontology. We place special emphasis on the task of bringing domain expertise to bear on all phases of the development and deployment of the system, from the initial design of the software and ontology to its dynamic use in a fully operational digital reference work.

#index 967286
#* Preparing resource discovery for digitized music: an analysis of an australian application
#@ Jennifer A. Thomas;Michael R. Middleton;Margaret Warren
#t 2007
#c 14
#! This paper examines procedures for the creation and delivery of digital music that are being undertaken by contributors to the National Library of Australia's federated music gateway MusicAustralia. The case study discusses access to and preservation of digital material as key drivers of the digitization movement, and compares projects being undertaken worldwide. Also analyzed are the underlying digitization principles and standards, and metadata schemas for the description and exchange of digital objects which facilitate record exchange and improve audience reach. The paper provides an overview of some individual contributing institutions, however particular focus is placed on the State Library of Queensland's (SLQ) approach to preparing its unique Queensland music collection for digital resource discovery in MusicAustralia. A detailed analysis of SLQ's strategy is presented, including its risk management approach to copyright implications,and consideration of infrastructure issues affecting the creation, preservation and online delivery of its digital music objects. Whilst SLQ's current digital music collection is relatively small, it has become core business of SLQ's Arts and Humanities branch, and the collection will expand with the continued incorporation of music material unique to Queensland into the collection. SLQ has developed a sound foundation for digitization based on widely endorsed principles and standards which should allow this to effectively occur.

#index 967287
#* Goal-directed evaluation for the improvement of optical music recognition on early music prints
#@ Laurent Pugin;John Ashley Burgoyne;Ichiro Fujinaga
#t 2007
#c 14
#% 443939
#% 900288
#% 958575
#! Optical music recognition (OMR) systems are promising tools for the creation of searchable digital music libraries. Using an adaptive OMR system for early music prints based on hidden Markov models, we leverage an edit distance evaluation metric to improve recognition accuracy. Baseline results are computed with new labeled training and test sets drawn from a diverse group of prints. We present two experiments based on this evaluation technique. The first resulted in a significant improvement to the feature extraction function for these images. The second is a goal-directed comparison of several popular adaptive binarization algorithms, which are often evaluated only subjectively. Accuracy increased by as much as 55% for some pages, and the experiments suggest several avenues for further research.

#index 967288
#* Annotation functionality for digital libraries supporting collaborative performance: an example of musical scores
#@ Megan Winget
#t 2007
#c 14
#% 237318
#! This paper describes the findings of an ethnographic study that examined the annotation behaviors of musicians working with musical scores for the purpose of performance. Annotation was found to be an important part of the rehearsal process, and specific annotation functionalities are recommended for future digital library development.

#index 967289
#* Toward an understanding of similarity judgments for music digital library evaluation
#@ J. Stephen Downie;Jin Ha Lee;Anatoliy A. Gruzd;M. Cameron Jones
#t 2007
#c 14
#% 757548
#! This paper presents an analysis of 7,602 similarity judgments collected for the Symbolic Melodic Similarity (SMS) and Audio Music Similarity and Retrieval (AMS) evaluation tasks in the 2006 Music Information Retrieval Evaluation eXchange (MIREX). We discuss the influence of task definitions, as well as evaluation metrics on user perceptions of music similarity, and provide recommendations for future Music Digital Library/Music Information Retrieval research pertaining to music similarity.

#index 967290
#* Agreeing to disagree: search engines and their public interfaces
#@ Frank McCown;Michael L. Nelson
#t 2007
#c 14
#% 268114
#% 298221
#% 345720
#% 378520
#% 508272
#% 662756
#% 728107
#% 728195
#% 760839
#% 773039
#% 807320
#% 809454
#% 841618
#% 863312
#% 869499
#% 879738
#% 881955
#% 907547
#% 954300
#% 967331
#% 1709421
#! Google, Yahoo and MSN all provide both web user interfaces (WUIs) and application programming interfaces (APIs) to their collections. Whether building collections of resources or studying the search engines themselves, the search engines request that researchers use their APIs and not "scrape" the WUIs. However, anecdotal evidence suggests the interfaces produce different results. We provide the first in depth quantitative analysis of the results produced by the Google, MSN and Yahoo API and WUI interfaces. We have queried both interfaces for five months and found significant discrepancies between the interfaces in several categories. In general, we found MSN to produce the most consistent results between their two interfaces. Our findings suggest that the API indexes are not older, but they are probably smaller for Google and Yahoo. We also examined how search results decay over time and built predictive models based on the observed decay rates. Based on our findings, it can take over a year for half of the top 10 results to a popular query to be replaced in Google and Yahoo; for MSN it may take only 2-3 months.

#index 967291
#* Static reformulation: a user study of static hypertext for query-based reformulation
#@ Michael Huggett;Joel Lanir
#t 2007
#c 14
#% 1260
#% 29587
#% 131450
#% 186518
#% 230519
#% 240738
#% 252328
#% 282003
#% 309515
#% 309533
#% 375017
#% 441035
#% 443305
#% 717133
#% 751830
#% 771914
#% 824588
#! Hypertext allows users to navigate between related materials in digital libraries. The most fundamental automated hypertexts are those constructed on the basis of semantic similarity. Such hypertexts have been evaluated by a variety of means, but seldom by real users given simulated real-world tasks. We claim that while other methods exist, one of the best ways to prove the usefulness of hypertext is to show the benefits for users performing realistic tasks. We compare the reformulation of queries that users perform in keyword searching, to the query reformulation implicit in browsing between documents linked by similarity of content. We find that a static automatically-constructed similarity hypertext provides useful linking between related items, improving the retrieval of targets when used to augment standard keyword search.

#index 967292
#* A rich OPAC user interface with AJAX
#@ Jesse Prabawa Gozali;Min-Yen Kan
#t 2007
#c 14
#% 809417
#! Open Public Access Catalogs (OPACs) provide patrons with a user interface (UI) to help their information seeking tasks. Even though many OPAC UIs are now web-based, their architectures are often static, which does not allow them to integrate user assistance modules dynamically. We report on a UI that supports integration of such modules, while providing a usable and rich environment. We explore how Asynchronous JavaScript + XML (AJAX) can be employed to create an OPAC UI that offers a better user experience and task support. Our developed UI features a modular architecture that combines several Natural Language Processing (NLP) modules employed to enhance information seeking. Our UI manages queries in a novel way with a tabbed interface featuring an overview/details presentation model, and an AJAX query results data grid. Preliminary user testing results are also presented.

#index 967293
#* Constructing digital library interfaces
#@ David M. Nichols;David Bainbridge;Michael B. Twidale
#t 2007
#c 14
#% 351921
#% 645984
#% 874480
#% 1734614
#! The software technologies used to create web interfaces for digital libraries are discussed using examples from Greenstone 3.

#index 967294
#* Retrieval in text collections with historic spelling using linguistic and spelling variants
#@ Andrea Ernst-Gerlach;Norbert Fuhr
#t 2007
#c 14
#% 219033
#% 221974
#% 461072
#% 925961
#% 1742073
#% 1742103
#! We present a new approach for the retrieval of texts with non-standard spelling, which is important for historic texts e.g. in English or German. In this paper, we describe the overall architecture of our system, followed by its evaluation. Given a search term as lemma, we use a dictionary of contemporary German for finding all inflected and derived forms of the lemma. Then we apply transformation rules (derived from training data) for generating historic spelling variants. For the evaluation, we regard the resulting retrieval quality. The experimental results show that we can improve the retrieval quality for historic collections substantially.

#index 967295
#* Efficient topic-based unsupervised name disambiguation
#@ Yang Song;Jian Huang;Isaac G. Councill;Jia Li;C. Lee Giles
#t 2007
#c 14
#% 249143
#% 280819
#% 643007
#% 722904
#% 760866
#% 769895
#% 788094
#% 788107
#% 805885
#% 809459
#% 812535
#% 819552
#% 823639
#% 836717
#% 836843
#% 855094
#% 869525
#% 879587
#% 881498
#% 1663664
#! Name ambiguity is a special case of identity uncertainty where one person can be referenced by multiple name variations in different situations or even share the same name with other people. In this paper, we focus on the problem of disambiguating person names within web pages and scientific documents. We present an efficient and effective two-stage approach to disambiguate names. In the first stage, two novel topic-based models are proposed by extending two hierarchical Bayesian text models, namely Probabilistic Latent Semantic Analysis (PLSA) and Latent Dirichlet Allocation (LDA). Our models explicitly introduce a new variable for persons and learn the distribution of topics with regard to persons and words. After learning an initial model, the topic distributions are treated as feature sets and names are disambiguated by leveraging a hierarchical agglomerative clustering method. Experiments on web data and scientific documents from CiteSeer indicate that our approach consistently outperforms other unsupervised learning methods such as spectral clustering and DBSCAN clustering and could be extended to other research fields. We empirically addressed the issue of scalability by disambiguating authors in over 750,000 papers from the entire CiteSeer dataset.

#index 967296
#* Using bilingual ETD collections to mine phrase translations
#@ Ryan Richardson;Edward A. Fox
#t 2007
#c 14
#% 1226
#% 807751
#! Phrase translation lists can enhance cross-language information retrieval. However, finding translations for technical phrases is difficult. Bilingual dictionaries have limited coverage for specialized fields, and even more limited coverage of technical phrases. Since phrases can have very specific meanings in technical fields, this limits the quality of translations produced by generic machine translation systems. We hypothesize that digital libraries of electronic theses and dissertations (ETDs) are a good source of technical phrase translations. We have acquired a collection of 3,086 Spanish ETDs about computer science from Scirus, the Universidad Nacional Autónoma de México (Mexico City), and Universidad de las Américas (Puebla). By using English ETDs from NDLTD, we have a comparable corpus of computing-related documents from which to mine phrase translations. We describe our method and its formative evaluation.

#index 967297
#* Evaluation of kernel-based link analysis measures on research paper recommendation
#@ Masashi Shimbo;Takahiko Ito;Yuji Matsumoto
#t 2007
#c 14
#% 290830
#% 466574
#% 823388
#% 975021
#% 1663636
#! We compare various kernel-based link analysis measures on graph nodes to evaluate their utility as a research paper recommendation system. The compared measures include the Kandola et al.'s von Neumann kernel, its extension that takes communities into account, and Smola and Kondor's regularized Laplacian. Chebotarev and Shamis' matrix forest-based algorithm, Kleinberg's HITS authority ranking, and classic co-citation coupling are also evaluated. The experimental result shows that kernel-based methods outperform HITS and co-citation coupling, with the community-based von Neumann kernel achieving the highest score.

#index 967298
#* A new generation of textual corpora: mining corpora from very large collections
#@ Gordon Stewart;Gregory Crane;Alison Babeu
#t 2007
#c 14
#% 136350
#% 332733
#% 467757
#% 508287
#% 614082
#% 738470
#% 738472
#% 808980
#% 809449
#% 824590
#% 828566
#% 835829
#% 844777
#% 844969
#% 846154
#% 855269
#% 874456
#% 874470
#% 1682016
#% 1709404
#% 1740410
#! While digital libraries based on page images and automatically generated text have made possible massive projects such as the Million Book Library, Open Content Alliance, Google, and others, humanists still depend upon textual corpora expensively produced with labor-intensive methods such as double-keyboarding and manual correction. This paper reports the results from an analysis of OCR-generated text for classical Greek source texts. Classicists have depended upon specialized manual keyboarding that costs two or more times as much as keyboarding of English both for accuracy and because classical Greek OCR produced no usable results. We found that we could produce texts by OCR that, in some cases, approached the 99.95% professional data entry accuracy rate. In most cases, OCR-generated text yielded results that, by including the variant readings that digital corpora traditionally have left out, provide better recall and, we argue, can better serve many scholarly needs than the expensive corpora upon which classicists have relied for a generation. As digital collections expand, we will be able to collate multiple editions against each other, identify quotations of primary sources, and provide a new generation of services.

#index 967299
#* Subject metadata enrichment using statistical topic models
#@ David Newman;Kat Hagedorn;Chaitanya Chemudugunta;Padhraic Smyth
#t 2007
#c 14
#% 279755
#% 329562
#% 329569
#% 722904
#% 779875
#% 809444
#% 859499
#% 874462
#% 876017
#% 1678444
#! Creating a collection of metadata records from disparate and diverse sources often results in uneven, unreliable and variable quality subject metadata. Having uniform, consistent and enriched subject metadata allows users to more easily discover material, browse the collection, and limit keyword search results by subject. We demonstrate how statistical topic models are useful for subject metadata enrichment. We describe some of the challenges of metadata enrichment on a huge scale (10 million metadata records from 700 repositories in the OAIster Digital Library) when the metadata is highly heterogeneous (metadata about images and text, and both cultural heritage material and scientific literature). We show how to improve the quality of the enriched metadata, using both manual and statistical modeling techniques. Finally, we discuss some of the challenges of the production environment, and demonstrate the value of the enriched metadata in a prototype portal.

#index 967300
#* Organizing the OCA: learning faceted subjects from a library of digital books
#@ David Mimno;Andrew McCallum
#t 2007
#c 14
#% 569858
#% 722904
#% 751593
#% 769967
#% 809444
#% 840903
#% 840951
#% 857482
#% 875981
#% 879587
#! Large scale library digitization projects such as the Open Content Alliance are producing vast quantities of text, but little has been done to organize this data. Subject headings inherited from card catalogs are useful but limited, while full-text indexing is most appropriate for readers who already know exactly what they want. Statistical topic models provide a complementary function. These models can identify semantically coherent "topics" that are easily recognizable and meaningful to humans, but they have been too computationally intensive to run on library-scale corpora. This paper presents DCM-LDA, a topic model based on Dirichlet Compound Multinomial distributions. This model is simultaneously better able to represent observed properties of text and more scalable to extremely large text collections. We train individual topic models for each book based on the cooccurrence of words within pages. We then cluster topics across books. The resulting topical clusters can be interpreted as subject facets, allowing readers to browse the topics of a collection quickly, find relevant books using topically expanded keyword searches, and explore topical relationships between books. We demonstrate this method finding topics on a corpus of 1.49 billion words from 42,000 books in less than 20 hours, and it easily could scale well beyond this.

#index 967301
#* Trends in metadata practices: a longitudinal study of collection federation
#@ Carole L. Palmer;Oksana L. Zavalina;Megan Mustafoff
#t 2007
#c 14
#% 319875
#% 647582
#% 647586
#% 809407
#% 874492
#% 1069055
#! With the increasing focus on interoperability for distributed digital content, resource developers need to take into consideration how they will contribute to large federated collections, potentially at the national and international level. At the same time, their primary objectives are usually to meet the needs of their own institutions and user communities. This tension between local practices and needs and the more global potential of digital collections has been an object of study for the IMLS Digital Collections and Content (IMLS DCC) project. Our practical aim has been to provide integrated access to over 160 IMLS-funded digital collections through a centralized collection registry and metadata repository. During the course of development, the research team has investigated how collections and items can best be represented to meet the needs of local resource developers and aggregators of distributed content, as well as the diverse user communities they may serve. This paper presents results from a longitudinal analysis of IMLS DCC development trends between 2003 and 2006. Changes in metadata applications have not been pronounced. However, multi-scheme use has become less common, and use of Dublin Core remains high, even as recognition of its limitations grows. Locally developed schemes are used as much as MARC, and may be on the increase as new collections are incorporating less traditional library and museum materials, and more interactive and multimedia content. Based on our empirical understanding of metadata use in practice, patterns in new content development, and user community indicators, our research has turned toward identifying metadata relationships between items and collections to preserve context and enhance functionality and usefulness for scholarly user communities.

#index 967302
#* Induced tagging: promoting resource discovery and recommendation in digital libraries
#@ J. Alfredo Sánchez;Adriana Arzamendi-Pétriz;Omar Valdiviezo
#t 2007
#c 14
#% 868093
#% 881054
#% 905320
#! We introduce the notion of "induced tagging" in the context of learning communities that are supported by digital libraries. We also describe an environment aimed to foster discovery and recommendation of digital library resources based on induced tagging.

#index 967303
#* Standards alignment for metadata assignment
#@ Anne R. Diekema;Ozgur Yilmazel;Jennifer Bailey;Sarah C. Harwell;Elizabeth D. Liddy
#t 2007
#c 14
#% 318412
#% 465747
#% 714701
#% 980041
#! The research in this paper describes a Machine Learning technique called hierarchical text categorization which is used to solve the problem of finding equivalents from among different state and national education standards. The approach is based on a set of manually aligned standards and utilizes the hierarchical structure present in the standards to achieve a more accurate result. Details of this approach and its evaluation are presented.

#index 967304
#* Identifying personal photo digital library features
#@ Sally Jo Cunningham;Masood Masoodian
#t 2007
#c 14
#% 378541
#% 452642
#% 824531
#% 1709408
#! At present, little evidence is available about how people want to interact with their photos in a personal photo digital library. Analysis of a set of 22 user needs summaries and critiques of existing photo management systems provides insight into potentially useful features.

#index 967305
#* Locating thematic pinpoints in narrative texts with short phrases: a test study on Don Quixote
#@ Jie Deng;Richard Furuta;Eduardo Urbina
#t 2007
#c 14
#% 169729
#% 169809
#% 198058
#% 232677
#% 345085
#% 375017
#% 402784
#% 589958
#% 642979
#% 766440
#% 853813
#! Traditional implementations provide only limited assistance for locating the information in narrative texts relevant to a certain point of interest. We are investigating providing a "reading wheel" for such purposes. The first step of the bigger picture, as inspired by the editorial compilation of a textbook's index, is an attempt to locate thematically coherent sentences to a given short phrase. In this paper, we propose a two-step methodology to increase the search performance and examine its effectiveness in a test study. We describe the experimental setup and report on the quantitative evaluation of the techniques involved.

#index 967306
#* Digital Donne: workflow, editing tools, and the reader.s interface of a collection of 17th-century english poetry
#@ Carlos Monroy;Richard Furuta;Gary Stringer
#t 2007
#c 14
#! We describe a multidisciplinary effort in the creation of an electronic repository of poems of John Donne - the renowned 17th-century English poet. We discuss the workflow we have adopted and the Web-based tools we have developed for maintaining a collection of transcriptions and images, a concordance of poems, a list of press variants, and a browsing interface that enables readers to access these materials. A complement to the multi-volume Variorum Edition of the Poetry of John Donne, this endeavor shows how a traditional scholarly edition can be enhanced by resources made available by computers and the Internet.

#index 967307
#* A multilingual approach to technical manuscripts: 16th and 17th-century Portuguese shipbuilding treatises
#@ Carlos Monroy;Richard Furuta;Filipe Castro
#t 2007
#c 14
#% 301229
#% 760830
#% 874511
#! Shipbuilding treatises are technical manuscripts written in a variety of languages and spanning several centuries that describe the construction of ships. Given their technical content, understanding terms, concepts, and construction sequences is a challenging task. In this paper we describe a scalable approach and a multilingual web-based interface for enabling a group of scholars to edit a glossary of nautical terms in multiple languages.

#index 967308
#* First class objects and indexes for chant manuscripts
#@ Louis W. G. Barton;Peter G. Jeavons;John A. Caldwell;Koon Shan Barry Ng
#t 2007
#c 14
#% 809456
#% 1548074
#! We discuss a crucial part of infrastructure for the Web-delivery of medieval chant resources. Although widely accepted by software professionals, the distributed-content model is sharply opposed by some chant scholars. We advocate for a paradigm of the Web as a massive database where each "first class object" acts like a record; metadata about, and links to such objects are compiled in virtual libraries. Scholarly-edited indexes determine which objects are in libraries, and unreliable content is excluded. Special metadata ontologies can be defined without modifying the primary content.

#index 967309
#* Recommending related papers based on digital library access records
#@ Stefan Pohl;Filip Radlinski;Thorsten Joachims
#t 2007
#c 14
#% 330687
#% 387427
#% 415107
#% 818221
#! An important goal for digital libraries is to enable researchers to more easily explore related work. While citation data is often used as an indicator of relatedness, in this paper we demonstrate that digital access records (e.g. http-server logs) can be used as indicators as well. In particular, we show that measures based on co-access provide better coverage than co-citation, that they are available much sooner, and that they are more accurate for recent papers.

#index 967310
#* Automatic patent classification using citation network information: an experimental study in nanotechnology
#@ Xin Li;Hsinchun Chen;Zhu Zhang;Jiexun Li
#t 2007
#c 14
#% 248810
#% 268079
#% 281396
#% 290830
#% 309142
#% 318412
#% 344447
#% 430761
#% 464267
#% 723326
#% 731607
#% 740762
#% 833065
#% 846237
#% 1558464
#% 1860761
#! Classifying and organizing documents in repositories is an active research topic in digital library studies. Manually classifying the large volume of patents and patent applications managed by patent offices is a labor-intensive task. Many previous studies have employed patent contents for patent classification with the aim of automating this process. In this research we propose to use patent citation information, especially the citation network structure information, to address the patent classification problem. We adopt a kernel-based approach and design kernel functions to capture content information and various citation-related information in patents. These kernels. performances are evaluated on a testbed of patents related to nanotechnology. Evaluation results show that our proposed labeled citation graph kernel, which utilized citation network structures, significantly outperforms the kernels that use no citation information or only direct citation information.

#index 967311
#* Collaborative classifier agents: studying the impact of learning in distributed document classification
#@ Weimao Ke;Javed Mostafa;Yueyu Fu
#t 2007
#c 14
#% 118032
#% 194284
#% 234793
#% 245815
#% 252758
#% 280817
#% 281395
#% 286675
#% 294891
#% 300599
#% 302089
#% 309257
#% 321635
#% 334101
#% 344447
#% 387427
#% 438136
#% 588824
#% 602150
#% 635424
#% 641254
#% 720202
#% 723963
#% 731617
#% 760880
#% 763708
#% 809428
#% 810770
#% 810821
#% 926881
#! We developed a multi-agent framework where agents had limited/distributed knowledge for document classification and collaborated with each other to overcome the knowledge distribution. Each agent was equipped with a certain learning algorithm for predicting potential collaborators, or helping agents. We conducted experimental research on a standard news corpus to examine the impact of two learning algorithms: Pursuit Learning and Nearest Centroid Learning. For a fundamental retrieval operation, namely classification, both algorithms achieved competitive classification effectiveness and efficiency. Subsequently, the impact of the learning exploration rate and the maximum collaboration range on classification effectiveness and efficiency were examined. Close investigation of agent learning dynamics revealed increasing and stabilizing patterns that were enhanced by the learning algorithms.

#index 967312
#* UpdateNews: a news clustering and summarization system using efficient text processing
#@ Takaharu Takeda;Atsuhiro Takasu
#t 2007
#c 14
#% 350859
#% 995468
#! This paper proposes a news articles clustering and summarization system. It provides integrated access to news articles from various news sites. The system consists of a crawler, topic detector, and summarizer. This paper describes its efficient summarization technique to handle large amounts of crawled news articles.

#index 967313
#* Automatic syllabus classification
#@ Xiaoyan Yu;Manas Tungare;Weiguo Fan;Manuel Perez-Quinones;Edward A. Fox;William Cameron;GuoFang Teng;Lillian Cassel
#t 2007
#c 14
#% 458379
#% 791713
#% 902457
#% 945047
#! Syllabi are important educational resources. However, searching for a syllabus on the Web using a generic search engine is an error-prone process and often yields too many non-relevant links. In this paper, we present a syllabus classifier to filter noise out from search results. We discuss various steps in the classification process, including class definition, training data preparation, feature selection, and classifier building using SVM and Naïve Bayes. Empirical results indicate that the best version of our method achieves a high classification accuracy, i.e., an F1 value of 83% on average.

#index 967314
#* Effects of structure and interaction style on distinct search tasks
#@ Robert Capra;Gary Marchionini;Jung Sun Oh;Fred Stutzman;Yan Zhang
#t 2007
#c 14
#% 127860
#% 135038
#% 303510
#% 344930
#% 393843
#% 441058
#% 452641
#% 623959
#% 643004
#% 750348
#% 760840
#% 809317
#% 857478
#% 857482
#% 860087
#! In this paper we present the results of a study that investigates the relationships between search tasks, information architecture, and interaction style. Three kinds of search tasks (simple lookup, complex lookup and exploratory) were performed using three different user interfaces (standard web site, hierarchical text-based faceted interface, and dynamic query faceted interface) for a large-scale public corpus containing semi-structured statistical data and reports. Twenty-eight people conducted the three kinds of searches in a between-subjects study and twelve others conducted the three kinds of searches on all three systems in a within-subjects study. Quantitative results demonstrate that the alternative general-purpose user interfaces that accept automated structuring of data offer comparable effectiveness, efficiency, and aesthetics to manually constructed architectures. Qualitative results demonstrate the manual architectures are favored.

#index 967315
#* Towards automatic conceptual personalization tools
#@ Faisal Ahmad;Sebastian de la Chica;Kirsten Butcher;Tamara Sumner;James H. Martin
#t 2007
#c 14
#% 337262
#% 614036
#% 614048
#% 614050
#% 760844
#% 760856
#% 809430
#! This paper describes the results of a study designed to validate the use of domain competency models to diagnose student scientific misconceptions and to generate personalized instruction plans using digital libraries. Digital library resources provided the content base for human experts to construct a domain competency model for earthquakes and plate tectonics encoded as a knowledge map. The experts then assessed student essays using comparisons against the constructed domain competency model and prepared personalized instruction plans using the competency model and digital library resources. The results from this study indicate that domain competency models generated from select digital library resources may provide the desired degree of content coverage to support both automated diagnosis and personalized instruction in the context of nationally-recognized science learning goals. These findings serve to inform the design of personalized instruction tools for digital libraries.

#index 967316
#* Mobile G-Portal supporting collaborative sharing and learning in geography fieldwork: an empirical study
#@ Yin-Leng Theng;Kuah-Li Tan;Ee-Peng Lim;Jun Zhang;Dion Hoe-Lian Goh;Kalyani Chatterjea;Chew Hung Chang;Aixin Sun;Han Yu;Nam Hai Dang;Yuanyuan Li;Minh Chanh Vo
#t 2007
#c 14
#% 61637
#% 190285
#% 325176
#% 590657
#% 731368
#% 739191
#% 751795
#% 797500
#% 860073
#% 890838
#! Integrated with G-Portal, a Web-based geospatial digital library of geography resources, this paper describes the implementation of Mobile G-Portal, a group of mobile devices as learning assistant tools supporting collaborative sharing and learning for geography fieldwork. Based on a modified Technology Acceptance Model and a Task-Technology Fit model, an initial study with Mobile G-Portal was conducted involving 39 students in a local secondary school. The findings suggested positive indication of acceptance of Mobile G-Portal for geography fieldwork. The paper concludes with a discussion on technological challenges, recommendations for refinement of Mobile G-Portal, and design implications in general for digital libraries and personal digital assistants supporting mobile learning.

#index 967317
#* Highly structured scientific publications
#@ Robert B. Allen
#t 2007
#c 14
#% 910908
#% 1740016
#! Science is a complex, but highly structured, activity. We propose that reports about science would benefit by reflecting that structure. We provide an example based on the research paradigm and we explore more complex examples in which workflow models describe the conceptual model, the research procedure, the data analysis, and the conclusions.

#index 967318
#* Cooperative collection building in NSDL MatDL pathway through IVIa data fountains
#@ Laura M. Bartolo;Cathy S. Lowe;Johannes Ruscheinski;Diane Bisom
#t 2007
#c 14
#! This poster describes a collaboration involving two NSDL projects: the Materials Digital Library Pathway (MatDL) and the iVia Data Fountains Project. MatDL is testing and providing feedback for refinement of the iVia tools while streamlining its metadata assignment process.

#index 967319
#* MESUR: usage-based metrics of scholarly impact
#@ Johan Bollen;Marko A. Rodriguez;Herbert Van de Sompel
#t 2007
#c 14
#% 804874
#% 841613
#% 967284

#index 967320
#* A publisher of last resort: enduring document access
#@ George Buchanan
#t 2007
#c 14
#% 301247
#! Ensuring long-term access to valuable online content is complicated by legal constraints and practical difficulties. We introduce a new technique for ensuring the long-term availability of digital content on the internet. The technique combines legal and technical measures to guarantee that a document remains available when its original goes offline, either permanently or long-term: a "publisher of last resort".

#index 967321
#* Educational application integration with digital repository
#@ Robert Chavez;Anoop Kumar;Nikolai Schwertner
#t 2007
#c 14
#! The value of a digital repository increases tremendously when applications use the content in innovative ways. Tufts University has developed its repository based on the Fedora framework using the principles of service oriented architecture. The repository features innovative content models allowing the digital objects within the Tufts Digital Repository to be accessible through a variety of applications, including Perseus, Artifact, Tufts Digital Library (TDL) and Visual Understanding Environment (VUE). The poster will present the underlying architecture including latest services and their use in Educational Applications.

#index 967322
#* Blogger perceptions on digital preservation
#@ Carolyn Hank;Songphan Choemprayong;Laura Sheble
#t 2007
#c 14
#! Blogs have emerged as valuable records of current social and political events. In response, calls in the literature have advocated that these new vehicles of communication and information dissemination are valuable additions to the human record worthy of stewardship [1,2,3]. The intent of this research is to study the requirements and feasibility of impacting stewardship of blogs at the level of creation. This will be accomplished by surveying blogger perceptions on digital preservation. Expected outcomes of this study include the development of a framework for constructing a digital preservation program for blogs. A survey will be administered to bloggers to assess perceptions of digital preservation issues as related to their own blogging activities and the blogosphere in general. The instrument is organized into five categories: demographics, awareness, appraisal, impact, and investment. Participants will be recruited through established contacts in the blogging community, with the intent of a resulting snowball effect for gathering additional participation. The demographics section collects basic characteristics of respondents, characteristics of their blogs (e.g., topic areas, platforms, linkages, content types, permissions for reuse), and their blogging practices (e.g., motivations, frequency of updates). The awareness section surveys current preservation-related activities performed by bloggers such as measures taken to ensure duplication of blog content; and whether, why, and how bloggers engage in practices that result in post-publication content changes. The appraisal section assesses perceptions of issues related to persistent storage and access. Respondents are asked to evaluate the importance of researcher-supplied blog characteristics that could be used to appraise blogs and their components. These characteristics include social and cultural factors such as perceived blog popularity, social linkages, and artifactual significance as well as structural components and content types. In addition to seeking clarification of the types and components of blogs that are perceived to be important with respect to preservation, the appraisal section addresses issues related to content ownership. The impact section focuses on the perceived importance of blogs to authors, preserving access to blogs, and blogs as a part of the human record. In the investment section, respondents are asked to quantify resources that they would be willing to expend to preserve their own blogs and their willingness to extend these expenditures to the blogs of others. Data collection will begin April 2007 and continue for one month. Following closure of the survey, data will be analyzed using descriptive statistics and qualitative evaluation methods. An initial assessment report will include a summary analysis of results and initial calls for recommendations. Future works include further development of these recommendations, development of benchmarks for planning ingest of blogs into a repository system, and the design and pilot testing of a user interface for deposit, storage, and access. This research is intended to promote digital preservation activities for continued access to blogs and to raise awareness of digital preservation issues among a population of users removed from the walls of academia and research. Bloggers constitute a significant producer type in that they have produced culturally and socially significant works, including those that contribute to wider public discourse. Furthermore, bloggers have the potential to become significant contributors to the dissemination of preservation awareness because they are vital actors in networks of communities that often span the borders of institutional, commercial, grassroots and personal communications.

#index 967323
#* Evolution of a data archive
#@ Jonathan D. Crabtree;David Sheaves
#t 2007
#c 14

#index 967324
#* Examining perception of digital information space
#@ John A. D'Ignazio;Joseph D. Ryan;Sarah C. Harwell;Anne R. Diekema;Elizabeth D. Liddy
#t 2007
#c 14
#% 257634
#% 319110
#! A study using a modified think aloud protocol of University of Rochester undergraduate students' interactions with a general, humanities scholarly database helped a research team gain insight into their information-seeking behavior and thus the impact of the digital library.

#index 967325
#* Tagging video: conventions and strategies of the YouTube community
#@ Gary Geisler;Sam Burns
#t 2007
#c 14
#% 318785
#% 881054
#! This poster summarizes the results from a quantitative analysis of the tags and associated metadata used to describe more than one million videos by 537,246 contributors at the YouTube video sharing site. Results from this work suggest methodological and design considerations that could enhance the effectiveness of sharing within communities devoted to online video.

#index 967326
#* DRIADE: a data repository for evolutionary biology
#@ Jed Dube;Sarah Carrier;Jane Greenberg
#t 2007
#c 14
#! NESCent (The National Evolutionary Synthesis Center) is developing DRIADE (Digital Repository of Information and Data for Evolution) to address synthetic research challenges fundamental to advancing the field of evolutionary biology. This poster highlights results from a survey of selected repositories' functionalities, DRIADE's functional requirements, and DRIADE's functional model. We also summarize ongoing research activities, studying evolutionary biologists' data preservation practices and use requirements.

#index 967327
#* AlouetteCanada metadata toolkit
#@ Mark Jordan
#t 2007
#c 14
#! This poster provides an overview of the AlouetteCanada Metadata Toolkit.

#index 967328
#* Building a digital library of traditional mongolian historical documents
#@ Garmaabazar Khaltarkhuu;Akira Maeda
#t 2007
#c 14
#% 1734608
#! This paper describes technique of converting modern Mongolian text input to traditional Mongolian script and integrating the result into the Greenstone Digital Library (GSDL). This work is part of on-going research to create a digital library of traditional Mongolian historical documents.

#index 967329
#* Evaluating digital libraries with webmetrics
#@ Michael Khoo;Robert A. Donahue
#t 2007
#c 14
#% 874492
#% 882326
#! We report preliminary lessons from a year of webmetrics research with two digital libraries. Despite the apparent 'plug-and-play-and-report' nature of webmetrics tools, much work was required to extract useful data from the tools used.

#index 967330
#* Tagging for health information organisation and retrieval
#@ Margaret E. I. Kipp
#t 2007
#c 14

#index 967331
#* Augmenting OAI-PMH repository holdings using search engine APIs
#@ Martin Klein;Michael L. Nelson;Juliet Z. Pao
#t 2007
#c 14
#% 378520
#% 1682045
#! In this poster, we give the preliminary results of our project to acquire Atmospheric Science Data Center (ASDC) project-related web resources, not with focused crawling, but by using the search engine (SE) APIs directly. We aggregate the results and create archive-ready complex objects.

#index 967332
#* The cyberinfrastructure for scholars project: componentized architecture for sustainable scholarly portals
#@ Aaron Krowne;Stacey Martin;Urvashi Gadi;Micah Wedemeyer;Martin Halbert
#t 2007
#c 14

#index 967333
#* Social bookmarking in digital library systems: framework and case study
#@ Fiftarina Puspitasari;Ee-Peng Lim;Dion Hoe-Lian Goh;Chew-Hung Chang;Jun Zhang;Aixin Sun;Yin-Leng Theng;Kalyani Chatterjea;Yuanyuan Li
#t 2007
#c 14
#% 378546

#index 967334
#* Automated collection strength analysis
#@ Clare Lllewellyn;Robert Sanderson;Brian Rea
#t 2007
#c 14
#! The strengths within six library collections were automatically determined through automated enrichment and analysis of bibliographic level metadata records, with a view towards efficient resource sharing and collaborative collection management. This involved very large scale deduplicantion, enrichment and automatic reclassification of records using machine learning processes.

#index 967335
#* Digital library education: some international course structure comparisons
#@ Yongqing Ma;Ann O'Brien;Warwick Clegg
#t 2007
#c 14
#% 874478
#! Following our recent review of progress in Digital Library (DL) education [1], we present here a brief overview of current work to investigate the commonality/diversity of course structure between ten institutions outside North America which offer DL education in their library schools. The weighting of specifically DL module topic credits as a proportion of the overall course taught credits varies between 13% and 63%, and coverage of a proposed core topic set [2] is as high as 85%.

#index 967336
#* PIM through a 5S perspective
#@ Yi Ma;Edward A. Fox;Marcos A. Gonçalves
#t 2007
#c 14
#% 90954
#% 750866

#index 967337
#* Use vs. access: design and use in educational digital libraries
#@ Flora McMartin;Brandon Muramatsu
#t 2007
#c 14
#! The poster will compare and contrast the design and usage assumptions of existing educational digital libraries and repositories to challenge digital library developers to meet the needs of their increasingly sophisticated users. Traditionally, assumptions have focused on access to a site and discovery of content, whereas we define use as content and its application (context, audience, etc.). In this poster we will review the assumptions that have driven the design of digital libraries, their services and evaluation. Measures of success such as page views of metadata rest on assumptions associated with access, i.e., the number of times a metadata record is displayed. This measure provides a very limited view of how a digital library is used. We believe that educational digital libraries need to go beyond such a limited view and think about what people actually do with material: Are they using it? Are they returning to it? Are they modifying it? Are they sharing it with others? We will explore an alternate set of metrics for determining the success (or failure) of educational digital libraries by examining metrics focused on use of the contents of educational digital libraries.

#index 967338
#* What do faculty need and want from digital libraries?
#@ Flora P. McMartin;Alan Wolf;Ellen Iverson;Cathrynn Manduca;Glenda Morgan;Joshua Morrill
#t 2007
#c 14
#! In this paper, we report on the results of a national survey of faculty members concerning their use of digital resources (DRs), collections of resources and digital libraries (DLs). The research reported here explored issues such as: value of DRs, motivation for using DRs and barriers to use of these resources in teaching. The results have implications for how DLs might develop education and outreach efforts to increase visibility and use of their collections.

#index 967339
#* Building cross-browser interfaces for digital libraries with scalable vector graphics (SVG)
#@ Francis Molina;Brian Sweeney;Ted Willard;André Winter
#t 2007
#c 14
#% 760897
#! We share our experience with developing interactive, crossbrowser strand maps using SVG. These maps will provide educators with free and easy access to carefully selected instructional resources linked to national and state learning goals. We will show the interface in at least two browsers, Internet Explorer with Adobe's SVG Viewer plug-in and Mozilla Firefox.

#index 967340
#* Understanding target users of a digital reference library
#@ Daniela K. Rosner;John Mark Josling;Andrea Moed;Elisa Oreglia
#t 2007
#c 14
#! Through an investigation of the needs and practices of researchers in the humanities and social sciences, we identify key issues in the use of an online digital reference library, the Electronic Cultural Atlas Initiatives' "Support for the Learner: What, When, Where and Who". In this poster we present an examination of results from survey data and user tasks, and discuss implications for future design and implementation based on our findings.

#index 967341
#* Capturing relevant information for digital curation
#@ Chirag Shah;Gary Marchionini
#t 2007
#c 14

#index 967342
#* Merging the Norwegian gazetteer with the ADL gazetteer
#@ Øyvind Vestavik;Ingeborg T. Sølvberg
#t 2007
#c 14
#! We report on work in progress on the merging of the Norwegian Gazetteer and the ADL gazetteer to create a gazetteer with both detailed local coverage and global scope suitable for indexing articles from a local newspaper. We describe a mapping on the schema level, a strategy for identifying duplicates in the merged gazeetteer and some identified challenges.

#index 967343
#* Information system media education (ISM): cooperating for media literacy
#@ Heike vom Orde
#t 2007
#c 14
#! The Information System Media Education (in German: Informationssystem Medienpaedagogik ISM) is the most extensive digital reference tool on the topic of media education in the German-speaking area.

#index 967344
#* Digitizing & providing access to contextual cultural materials: the liner notes digitization project
#@ Megan Winget
#t 2007
#c 14
#! This paper describes a digitization project focused on developing a metadata modeling schema for album liner notes.

#index 967345
#* Use of online digital learning materials and digital libraries: comparison by discipline
#@ Alan J. Wolf;Ellen R. Iverson;Cathryn Manduca;Flora McMartin;Glenda Morgan;Joshua Morrill
#t 2007
#c 14
#! In this paper, we describe the results of a national survey of higher education faculty concerning their use of digital resources and collections of these resources. We explore the differences in resource use by discipline groups and suggest implications for development of discipline specific libraries and faculty development practices.

#index 967346
#* XML as the articulation between information retrieval and multimedia in a musical heritage dissemination
#@ Rodolphe Bailly
#t 2007
#c 14
#! The Cité de la musique in Paris has recently opened a new media Library. One of the Library's assignments is the dissemination of the Cité de la musique's collection of recorded concerts. This paper presents the concert's description model implemented into the MARC Catalogue and emphasizes the central position in the library information system architecture of automatically generated XML representations of each concert.

#index 967347
#* Lightweight realistic books: the greenstone connection
#@ Veronica Liesaputra;Ian H. Witten;David Bainbridge
#t 2007
#c 14
#% 342538
#% 760831

#index 967348
#* Rapid document navigation for information triage support
#@ George Buchanan
#t 2007
#c 14
#% 720192
#% 848656
#! This paper introduces a novel interaction for supporting rapid between-page comparison of texts within a limited screen estate. In comparison with existing interfaces and interactions, it gives a high degree of visual feedback and allows rapid between-page flicking, similar to what is readily achieved in physical environments using the fingers and thumbs of a reader as they flip between related pages.

#index 967349
#* Fluid interaction for the document in context
#@ Pierre Cubaud;Jérôme Dupire;Alexandre Topol
#t 2007
#c 14
#% 378526
#% 752060
#% 760831
#! We explore in this paper the interface requirements for user's navigation within a mixed collection of 3D digitalized objects and textual documents. A specific application is history of technology where 3D and 2D documents are most of the time inter-related.

#index 967350
#* Demonstrating the semantic growbag: automatically creating topic facets for faceteddblp
#@ Jörg Diederich;Wolf-Tilo Balke;Uwe Thaden
#t 2007
#c 14
#! The FacetedDBLP demonstrator allows to search computer science publications starting from some keyword and shows the result set along with a set of facets, e.g., distinguishing publication years, authors, or conferences. Furthermore, it uses GrowBag graphs, i.e., automatically created categorization systems, to create a topic facet, with which a user can characterize the result set in terms of main research topics and filter it according to certain subtopics.

#index 967351
#* The David L. Bassett stereoscopic atlas of human anatomy: developing a specialized collection within the stanford mediaserver digital library
#@ Jeremy C. Durack;Amy L. Ladd;Shyh-Yuan Kung;Margaret Krebs;Robert A. Chase;Parvati Dev
#t 2007
#c 14
#% 614087
#! We describe the creation of a specialized media collection in the Stanford MediaServer highlighting the David L. Bassett Stereoscopic Atlas of Human Anatomy. Previous reports have outlined the underlying architecture and features of the MediaServer developed to support biomedical media-based education 1,2. Here we focus on specific design principles and technical aspects of a focused project that may be beneficial to those developing digital media collections.

#index 967352
#* Evalutron 6000: collecting music relevance judgments
#@ Anatoliy A. Gruzd;J. Stephen Downie;M. Cameron Jones;Jin Ha Lee
#t 2007
#c 14

#index 967353
#* VCenter: a digital video management system with mobile search service
#@ Jen-Hao Hsiao;Yu-Zheng Wang
#t 2007
#c 14
#% 479973
#% 555469
#% 760805
#! Digital video data have proliferated in recent years due to the rapid development of multimedia computing and computer technologies. Management of video data is thus becoming an indispensable part in digital library. However, currently most digital video library systems are lack of the support of content-based video search and an easy-to-use query interface. In this work, we develop a digital video management system called VCenter, which provides lightweight mobile search functionality based on image taken from camera phone. By the proposed framework, both end user and content owner are easier to enjoy the multimedia contents in digital video libraries.

#index 967354
#* Creativity support: the mixed-initiative composition space
#@ Andruid Kerne;Eunyee Koh
#t 2007
#c 14
#% 769227
#% 874454
#! Creativity support is an important and challenging emerging area of research. combinFormation is being developed as a tool to support creativity through a mixed-initiative composition space. The system combines searches and information feeds, representing relevant information collections as compositions of image and text surrogates. The composition space affords human manipulation. This method has been shown to support information discovery in The Design Process, an interdisciplinary undergraduate course. In this demo, we demonstrate how combinFormation can be used to explore and discover information in digital libraries such as ACM Digital Library and the International Children's Digital Library.

#index 967355
#* Visual understanding environment
#@ Anoop Kumar
#t 2007
#c 14
#! The Visual Understanding Environment (VUE) project at Tufts' Academic Technology department aims at providing faculty and students with tools to successfully integrate digital resources into their teaching and learning. VUE not only provides a visual environment for structuring, presenting, and sharing digital information but also viewing digital resources along with their metadata. The demonstration will showcase the federated search capabilities of VUE that enable users to search across multiple digital repositories. We will also present concept maps created using digital objects from repositories.

#index 967356
#* Mobile digital libraries for geography education
#@ Minh-Chanh Vo;Fiftarina Puspitasari;Ee-Peng Lim;Chew-Hung Chang;Yin-Leng Theng;Dion Hoe-Lian Goh;Kalyani Chatterjea;Jun Zhang;Aixin Sun;Yuanyuan Li
#t 2007
#c 14

#index 967357
#* The internet public library: an online learning laboratory for digital libraries
#@ Lorri Mon;Larry Dennis;Kyunghye Kim
#t 2007
#c 14
#% 263939
#! This demonstration explores the Internet Public Library (www.ipl.org), a shared online facility for testing innovations in digital libraries and for training a skilled work force in digital library services, systems, and collections. Hypatia 2.0 and QRC software used in IPL's digital library collections and services are shown, with discussion of IPL in education, digital collections, digital reference services, digital library systems, and research.

#index 967358
#* 5SQual: a quality assessment tool for digital libraries
#@ Bárbara Lagoeiro Moreira;Marcos André Gonçalves;Alberto Henrique Frade Laender;Edward A. Fox
#t 2007
#c 14
#% 750866

#index 967359
#* ContextMiner: a tool for digital library curators
#@ Chirag Shah;Gary Marchionini
#t 2007
#c 14

#index 967360
#* From kinescope to rich media: 50 years (ago) with Mike Wallace
#@ Quinn Stewart;Grete Pasch;Rodrigo Arias
#t 2007
#c 14
#! What do Eleanor Roosevelt, Frank Lloyd Wright, Margaret Sanger, and Henry Kissinger have in common? All of them, and 55 other celebrities were interviewed by Mike Wallace in 1957-58, and the corresponding kinescopes have resided in the Harry Ransom Humanities Research Center at the University of Texas since the early 1960's. This demonstration will showcase an online searchable video digital library of the Wallace interviews created by researchers, staff, and students at the University of Texas School of Information and the Universidad Francisco Marroquín.

#index 1065240
#* Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries
#@ Ronald Larsen;Andreas Paepcke;José Borbinha;Mor Naaman
#t 2008
#c 14
#! Welcome to JCDL 2008! Authors from 27 countries submitted technical papers to the conference this year. A large number of reviewing and organizing volunteers then worked hard to bring this meeting together. Thanks to their efforts we have assembled a program that should keep you busy at the conference. For the first time we also decided to expose ourselves to the realities of digital information by distributing the proceedings as USB memory sticks. The materials you find on your stick will also be available on the ACM Digital Library. Over the past decades, joint efforts of computing and library communities worldwide have resulted in information technologies way beyond online catalogs and scanned materials. The result has been a raised level of attention to the incorporation of digital video, geographically anchored information, economic models of digital publishing, novel user interfaces to online resources, and a number of further aspects that broadened the notion of librarianship. The World-Wide Web added additional dimensions. Large interlinked document networks, citizen authorship, extreme rates of content production, and the internationalization of the Web 'collection' are some of the additional challenges the Web contributed to our field. The 117 full papers and 61 short papers we received this year covered all of these aspects. The submissions demonstrated that the interdisciplinary spirit of Digital Libraries as an academic and industry discipline is vibrantly alive. We could, of course, accept but a small fraction of the submissions. The program committee selected 33 of the full papers and 21 of the shorts. The acceptance rate was thus 28% for full papers, and 34% for short format submissions. Our program this year also includes a room full of posters and demonstrations, as well as panels and three invited keynote speakers. Tutorials, workshops, and the Doctoral Consortium frame the core program, making for a very full experience all around.

#index 1065241
#* Enhancing digital libraries using missing content analysis
#@ David Carmel;Elad Yom-Tov;Haggai Roitman
#t 2008
#c 14
#% 232713
#% 281251
#% 342653
#% 348137
#% 348148
#% 397161
#% 508272
#% 642975
#% 729437
#% 760839
#% 766447
#% 805879
#% 809423
#% 809454
#% 818267
#% 869481
#% 879613
#% 879614
#% 907544
#% 978763
#! This work shows how the content of a digital library can be enhanced to better satisfy its users' needs. Missing content is identified by finding missing content topics in the system's query log or in a pre-defined taxonomy of required knowledge. The collection is then enhanced with new relevant knowledge, which is extracted from external sources that satisfy those missing content topics. Experiments we conducted measure the precision of the system before and after content enhancement. The results demonstrate a significant improvement in the system effectiveness as a result of content enhancement and the superiority of the missing content enhancement policy over several other possible policies.

#index 1065242
#* Building a dynamic lexicon from a digital library
#@ David Bamman;Gregory Crane
#t 2008
#c 14
#% 284883
#% 332733
#% 452983
#% 740900
#% 740916
#% 747958
#% 748499
#% 756845
#% 786521
#% 786572
#% 939344
#% 939919
#% 1682016
#! We describe here in detail our work toward creating a dynamic lexicon from the texts in a large digital library. By leveraging a small structured knowledge source (a 30,457 word treebank), we are able to extract selectional preferences for words from a 3.5 million word Latin corpus. This is promising news for low-resource languages and digital collections seeking to leverage a small human investment into much larger gain. The library architecture in which this work is developed allows us to query customized subcorpora to report on lexical usage by author, genre or era and allows us to continually update the lexicon as new texts are added to the collection.

#index 1065243
#* On content-driven search-keyword suggesters for literature digital libraries
#@ Sulieman A. Bani-Ahmad;Gultekin Ozsoyoglu
#t 2008
#c 14
#% 268079
#% 328523
#% 577273
#% 587716
#% 746872
#% 805878
#% 879610
#% 1019150
#% 1207239
#% 1914863
#! We propose and evaluate a "content-driven search keyword suggester" for keyword-based search in literature digital libraries. Suggesting search keywords at an early stage, i.e., while the user is entering search terms, is helpful for constructing more accurate, less ambiguous, and focused search keywords for queries. Our search keyword suggestion approach is based on an a priori analysis of the publication collection in the digital library at hand, and consists of the following steps. We (i) parse the document collection using the Link Grammar parser, a syntactic parser of English, (ii) group publications based on their "most-specific" research topics, (iii) use the parser output to build a hierarchical structure of simple and compound tokens to be used to suggest search terms, (iv) use TextRank, a text summarization tool, to assign topic-sensitive scores to keywords, and (v) use the identified research-topics to help user aggregate search keywords prior to the actual search query execution. We experimentally show that the proposed framework, which is optimized to work on literature digital libraries, promises a more scalable, high quality, and user-friendly search-keyword suggester when compared to its competitors. We validate our proposal experimentally using a subset of the ACM SIGMOD Anthology digital library as a testbed, and by employing the research-pyramid model to identify the "most-specific" research topics.

#index 1065244
#* Unsupervised semantic markup of literature for biodiversity digital libraries
#@ Hong Cui
#t 2008
#c 14
#% 617167
#% 911856
#! This paper reports the further development of machine learning techniques for semantic markup of biodiversity literature, especially morphological descriptions of living organisms such as those hosted at efloras.org and algaebase.org. Syntactic parsing and supervised machine learning techniques have been explored by earlier research. Limitations of these techniques promoted our investigation of an unsupervised learning approach that combines the strength of earlier techniques and avoids the limitations. Semantic markup at the organ and character levels is discussed. Research on semantic markup of natural heritage literature has direct impact on the development of semantic-based access in biodiversity digital libraries.

#index 1065245
#* Seeking information in realistic books: a user study
#@ Veronica Liesaputra;Witten H. Ian
#t 2008
#c 14
#% 7798
#% 47788
#% 232895
#% 237318
#% 342538
#% 679856
#% 760831
#% 809441
#% 967347
#! There are opposing views on whether readers gain any advantage from using a computer model of a 3D physical book. There is enough evidence, both anecdotal and from formal user studies, to suggest that the usual HTML or PDF presentation of documents is not always the most convenient, or the most comfortable, for the reader. On the other hand it is quite clear that while 3D book models have been prototyped and demonstrated, none are in routine use in today's digital libraries. And how do 3D book models compare with actual books? This paper reports on a user study designed to compare the performance of a practical Realistic Book implementation with conventional formats (HTML and PDF) and with physical books. It also evaluates the annotation features that the implementation provides.

#index 1065246
#* Understanding cultural heritage experts' information seeking needs
#@ Alia Amin;Jacco van Ossenbruggen;Lynda Hardman;Annelies van Nispen
#t 2008
#c 14
#% 343130
#% 378478
#% 390429
#% 415107
#% 446934
#% 452641
#% 590523
#% 754059
#% 760853
#% 809499
#% 875402
#% 954945
#% 967340
#% 1124986
#% 1696303
#% 1696353
#! We report on our user study on the information seeking behavior of cultural heritage experts and the sources they use to carry out search tasks. Seventeen experts from nine cultural heritage institutes in the Netherlands were interviewed and asked to answer questionnaires about their daily search activities. The interviews helped us to better understand their search motivations, types, sources and tools. A key finding of our study is that the majority of search tasks involve relatively complex information gathering. This is in contrast to the relatively simple fact-finding oriented support provided by current tools. We describe a number of strategies that experts have developed to overcome the inadequacies of their tools. Finally, based on the analysis, we derive general trends of cultural heritage experts' information seeking needs and discuss our preliminary experiences with potential solutions.

#index 1065247
#* The myth of find: user behaviour and attitudes towards the basic search feature
#@ Fernando Loizides;George R. Buchanan
#t 2008
#c 14
#% 186518
#% 438557
#% 735074
#% 925730
#% 1387559
#% 1914893
#! The ubiquitous within-document text search feature (Ctrl-F) is considered by users to be a key advantage in electronic information seeking [1]. However what people say they do and what they actually do are not always consistent. It is necessary to understand, acknowledge and identify the cause of this inconsistency. We must identify the physical and cognitive factors to develop better methods and tools, assisting with the search process. This paper discusses the limitations and myths of Ctrl-f in information seeking. A prototype system for within-document search is introduced. Three user studies portray shared behaviour and attitudes, common between participants regarding within-document searching.

#index 1065248
#* A longitudinal study of exploratory and keyword search
#@ Max L. Wilson;m.c. schraefel
#t 2008
#c 14
#% 109190
#% 614060
#% 643001
#% 857479
#% 857482
#% 967314
#% 1124068
#% 1224728
#% 1406352
#! Digital libraries are concerned with improving the access to collections to make their service more effective and valuable to users. In this paper, we present the results of a four-week longitudinal study investigating the use of both exploratory and keyword forms of search within an online video archive, where both forms of search were available concurrently in a single user interface. While we expected early use to be more exploratory and subsequent use to be directed, over the whole period there was a balance of exploratory and keyword searches and they were often used together. Further, to support the notion that facets support exploration, there were more than five times as many facet clicks than more complex forms of keyword search (boolean and advanced). From these results, we can conclude that there is real value in investing in exploratory search support, which was shown to be both popular and useful for extended use of the system.

#index 1065249
#* Exploring educational standard alignment: in search of 'relevance'
#@ René Reitsma;Byron Marshall;Michael Dalton;Martha Cyr
#t 2008
#c 14
#% 809440
#% 859913
#% 967270
#% 1015625
#% 1015626
#% 1021108
#! The growing availability of online K-12 curriculum is increasing the need for meaningful alignment of this curriculum with state-specific standards. Promising automated and semi-automated alignment tools have recently become available. Unfortunately, recent alignment evaluation studies report low inter-rater reliability, e.g., 32% with two raters and 35 documents. While these results are in line with studies in other domains, low reliability makes it difficult to accurately train automatic systems and complicates comparison of different services. We propose that inter-rater reliability of broadly defined, abstract concepts such as 'alignment' or 'relevance' must be expected to be low due to the real-world complexity of teaching and the multidimensional nature of the curricular documents. Hence, we suggest decomposing these concepts into less abstract, more precise measures anchored in the daily practice of teaching. This article reports on the integration of automatic alignment results into the interface of the Teach Engineering collection and on an evaluation methodology intended to produce more consistent document relevance ratings. Our results (based on 14 raters x 6 documents) show high inter-rater reliability (61 - 95%) on less abstract relevance dimensions while scores on the overall 'relevance' concept are (as expected) lower (64%). Despite a relatively small sample size, regression analysis of our data resulted in an explanatory (R2 = .75) and statistically stable (p-values

#index 1065250
#* From nsdl 1.0 to nsdl 2.0: towards a comprehensive cyberinfrastructure for teaching and learning
#@ David J. McArthur;Lee L. Zia
#t 2008
#c 14
#% 809402
#% 967269
#% 1682014
#! NSDL is a premier provider of digital educational collections and services, which has been supported by NSF for eight years. As a mature program, NSDL has reached a point where it could either change direction or wind down. In this paper we argue there are reasons to continue the program and we outline several possible new program directions. These build on NSDL's learning platform, and they also look towards NSF's emerging interest in supporting work at the intersection of cyberinfrastructure and education. We consider NSDL's potential roles in several grand challenges that confront education, including: tailoring educational resources to students' needs, providing educators with a cyber-teaching environment, developing a cyber-workbench for researchers, and integrating education research and practice.

#index 1065251
#* Cross-disciplinary molecular science education in introductory science courses: an nsdl matdl collection
#@ David J. Yaron;Jodi L. Davenport;Michael Karabinos;Gaea L. Leinhardt;Laura M. Bartolo;John J. Portman;Cathy S. Lowe;Donald R. Sadoway;W. Craig Carter;Colin Ashe
#t 2008
#c 14
#% 337229
#% 337496
#% 760842
#! This paper discusses a digital library designed to help undergraduate students draw connections across disciplines, beginning with introductory discipline-specific science courses (including chemistry, materials science, and biophysics). The collection serves as the basis for a design experiment for interdisciplinary educational libraries and is discussed in terms of the three models proposed by Sumner and Marlino. As a cognitive tool, the library is organized around recurring patterns in molecular science, with one such pattern being developed for this initial design experiment. As a component repository, the library resources support learning of these patterns and how they appear in different disciplines. As a knowledge network, the library integrates design with use and assessment.

#index 1065252
#* Curriculum overlay model for embedding digital resources
#@ Huda Khan;Keith Maull;Tamara Sumner
#t 2008
#c 14
#% 809402
#% 809483
#% 859913
#% 874544
#! This paper describes the design and implementation of a curriculum overlay model for the representation of adaptable curriculum using educational digital library resources. We focus on representing curriculum to enable the incorporation of digital resources into curriculum and curriculum sharing and customization by educators. We defined this model as a result of longitudinal studies on educators' development and customization of curriculum and user interface design studies of prototypes representing curriculum. Like overlay journals or the information network overlay model, our curriculum overlay model defines curriculum as a compound object with internal semantic relationships and relationships to digital library metadata describing resources. We validated this model by instantiating the model using science curriculum which uses digital library resources and using this instantiation within an application that, built on FEDORA, supports curriculum customization. Findings from this work can support the design of digital library services for customizing curriculum which embeds digital resources.

#index 1065253
#* Gazetiki: automatic creation of a geographical gazetteer
#@ Adrian Popescu;Gregory Grefenstette;Pierre Alain Moëllic
#t 2008
#c 14
#% 280849
#% 953415
#% 967244
#% 987205
#% 1409954
#! Geolocalized databases are becoming necessary in a wide variety of application domains. Thus far, the creation of such databases has been a costly, manual process. This drawback has stimulated interest in automating their construction, for example, by mining geographical information from the Web. Here we present and evaluate a new automated technique for creating and enriching a geographical gazetteer, called Gazetiki. Our technique merges disparate information from Wikipedia, Panoramio, and web search engines in order to identify geographical names, categorize these names, find their geographical coordinates and rank them. The information produced in Gazetiki enhances and complements the Geonames database, using a similar domain model. We show that our method provides a richer structure and an improved coverage compared to another known attempt at automatically building a geographic database and, where possible, we compare our Gazetiki to Geonames.

#index 1065254
#* Discovering gis sources on the web using summaries
#@ Ramaswamy Hariharan;Bijit Hore;Sharad Mehrotra
#t 2008
#c 14
#% 68091
#% 115465
#% 273887
#% 287463
#% 319273
#% 333948
#% 340146
#% 466425
#% 632072
#% 659976
#% 745472
#% 760921
#% 766536
#% 835018
#% 838407
#% 874993
#% 930734
#% 982560
#% 993964
#% 1015256
#! In this paper, we consider the problem of discovering GIS data sources on the web. Source discovery queries for GIS data are specified using keywords and a region of interest. A source is considered relevant if it contains data that matches the keywords in the specified region. Existing techniques simply rely on textual metadata accompanying such datasets to compute relevance to user-queries. Such approaches result in poor search results, often missing the most relevant sources on the web. We address this problem by developing more meaningful summaries of GIS datasets that preserve the spatial distribution of keywords. We conduct experiments showing the effectiveness of proposed summarization techniques by significantly improving the quality of query results over baseline approaches, while guaranteeing scalability and high performance.

#index 1065255
#* Socialtrust: tamper-resilient trust establishment in online communities
#@ James Caverlee;Ling Liu;Steve Webb
#t 2008
#c 14
#% 342695
#% 348160
#% 355107
#% 543383
#% 577367
#% 754098
#% 762654
#% 762655
#% 805881
#% 840675
#% 869469
#% 869525
#% 872770
#% 881460
#% 881523
#% 956516
#% 956544
#% 956589
#% 958000
#% 989505
#% 996883
#% 1016177
#% 1269378
#! Web 2.0 promises rich opportunities for information sharing, electronic commerce, and new modes of social interaction, all centered around the "social Web" of user-contributed content, social annotations, and person-to-person social connections. But the increasing reliance on this "social Web" also places individuals and their computer systems at risk, creating opportunities for malicious participants to exploit the tight social fabric of these networks. With these problems in mind, we propose the SocialTrust framework for tamper-resilient trust establishment in online communities. SocialTrust provides community users with dynamic trust values by (i) distinguishing relationship quality from trust; (ii) incorporating a personalized feedback mechanism for adapting as the community evolves; and (iii) tracking user behavior. We experimentally evaluate the SocialTrust framework using real online social networking data consisting of millions of MySpace profiles and relationships. We find that SocialTrust supports robust trust establishment even in the presence of large-scale collusion by malicious participants.

#index 1065256
#* Personal & soho archiving
#@ Stephan Strodl;Florian Motlik;Kevin Stadler;Andreas Rauber
#t 2008
#c 14
#% 301256
#% 356167
#% 582491
#% 749246
#% 795390
#% 845325
#% 849899
#% 859581
#% 860038
#% 967247
#% 1052572
#! Digital objects require appropriate measures for digital preservation to ensure that they can be accessed and used in the near and far future. While heritage institutions have been addressing the challenges posed by digital preservation needs for some time, private users and SOHOs (Small Office/Home Office) are less prepared to handle these challenges. Yet, both have increasing amounts of data that represent considerable value, be it office documents or family photographs. Backup, common practice of home users, avoids the physical loss of data, but it does not prevent the loss of the ability to render and use the data in the long term. Research and development in the area of digital preservation is driven by memory institutions and large businesses. The available tools, services and models are developed to meet the demands of these professional settings. This paper analyses the requirements and challenges of preservation solutions for private users and SOHOs. Based on the requirements and supported by available tools and services, we are designing and implementing a home archiving system to provide digital preservation solutions specifically for digital holdings in the small office and home environment. It hides the technical complexity of digital preservation challenges and provides simple and automated services based on established best practice examples. The system combines bit preservation and logical preservation strategies to avoid loss of data and the ability to access and use them. A first software prototype, called Hoppla, is presented in this paper.

#index 1065257
#* Recovering a website's server components from the web infrastructure
#@ Frank McCown;Michael L. Nelson
#t 2008
#c 14
#% 54037
#% 237822
#% 389077
#% 508280
#% 629107
#% 668681
#% 859917
#% 863312
#% 881072
#% 904271
#% 907442
#% 954492
#% 967248
#% 967322
#% 1065291
#% 1246535
#! Our previous research has shown that the collective behavior of search engine caches (e.g., Google, Yahoo, Live Search) and web archives (e.g., Internet Archive) results in the uncoordinated but large-scale refreshing and migrating of web resources. Interacting with these caches and archives, which we call the Web Infrastructure (WI), allows entire websites to be reconstructed in an approach we call lazy preservation. Unfortunately, the WI only captures the client-side view of a web resource. While this may be useful for recovering much of the content of a website, it is not helpful for restoring the scripts, web server configuration, databases, and other server-side components responsible for the construction of the website's resources. This paper proposes a novel technique for storing and recovering the server-side components of a website from the WI. Using erasure codes to embed the server-side components as HTML comments throughout the website, we can effectively reconstruct all the server components of a website when only a portion of the client-side resources have been extracted from the WI. We present the results of a preliminary study that baselines the lazy preservation of ten EPrints repositories and then examines the preservation of an EPrints repository that uses the erasure code technique to store the server-side EPrints software throughout the website. We found nearly 100% of the EPrints components were recoverable from the WI just two weeks after the repository came online, and it remained recoverable four months after it was "lost".

#index 1065258
#* A data model and architecture for long-term preservation
#@ Greg Janée;Justin Mathena;James Frew
#t 2008
#c 14
#% 378545
#% 614068
#% 859913
#% 1709417
#! The National Geospatial Digital Archive, one of eight initial projects funded under the Library of Congress's NDIIPP program, has been researching how geospatial data can be preserved on a national scale and be made available to future generations. In this paper we describe an archive architecture that provides a minimal approach to the long-term preservation of digital objects based on co-archiving of object semantics, uniform representation of objects and semantics, explicit storage of all objects and semantics as files, and abstraction of the underlying storage system. This architecture ensures that digital objects can be easily migrated from archive to archive over time and that the objects can, in principle, be made usable again at any point in the future; its primary benefit is that it serves as a fallback strategy against, and as a foundation for, more sophisticated (and costly) preservation strategies. We describe an implementation of this architecture in a protoype archive running at UCSB that also incorporates a suite of ingest and access components.

#index 1065259
#* Shakespeare, god, and lonely hearts: transforming data access with many eyes
#@ Fernanda Viégas;Martin Wattenberg
#t 2008
#c 14
#! Data visualization has historically been accessible only to the technological elite. It is, after all, "serious" technology done by experts for experts. But recent web-based visualizations - ranging from political art projects to news stories - have reached millions. Unfortunately, while lay users can view sophisticated visualizations, they have few ways to create them. In order to "democratize" visualization, we have built Many Eyes, a web site where people may upload their own data, create interactive visualizations, and carry on conversations. By making these tools available to anyone on the web, the site fosters a social style of data analysis that empowers users to engage with public data through discussion and collaboration. Political discussions, citizen activism, religious conversations, game playing, and educational exchanges are all happening on Many Eyes. The public nature of these visualizations provides users with a transformative path to information literacy.

#index 1065260
#* Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries
#@ Ronald Larsen;Andreas Paepcke;José Borbinha;Mor Naaman
#t 2008
#c 14

#index 1065261
#* Harvana: harvesting community tags to enrich collection metadata
#@ Jane Hunter;Imran Khan;Anna Gerber
#t 2008
#c 14
#% 249090
#% 330770
#% 348182
#% 754123
#% 760817
#% 810743
#% 851317
#% 855601
#% 878640
#% 879704
#% 914629
#% 1029800
#% 1039357
#% 1098450
#% 1379016
#% 1409941
#% 1668087
#% 1728181
#! Collaborative, social tagging and annotation systems have exploded on the Internet as part of the Web 2.0 phenomenon. Systems such as Flickr, Del.icio.us, Technorati, Connotea and LibraryThing, provide a community-driven approach to classifying information and resources on the Web, so that they can be browsed, discovered and re-used. Although social tagging sites provide simple, user-relevant tags, there are issues associated with the quality of the metadata and the scalability compared with conventional indexing systems. In this paper we propose a hybrid approach that enables authoritative metadata generated by traditional cataloguing methods to be merged with community annotations and tags. The HarvANA (Harvesting and Aggregating Networked Annotations) system uses a standardized but extensible RDF model for representing the annotations/tags and OAI-PMH to harvest the annotations/tags from distributed community servers. The harvested annotations are aggregated with the authoritative metadata in a centralized metadata store. This streamlined, interoperable, scalable approach enables libraries, archives and repositories to leverage community enthusiasm for tagging and annotation, augment their metadata and enhance their discovery services. This paper describes the HarvANA system and its evaluation through a collaborative testbed with the National Library of Australia using architectural images from PictureAustralia.

#index 1065262
#* Semi automated metadata extraction for preprints archives
#@ Emma Tonkin;Henk L. Muller
#t 2008
#c 14
#% 249143
#% 322318
#% 451356
#% 818405
#! In this paper we present a system called paperBase that aids users in entering metadata for preprints. PaperBase extracts metadata from the preprint. Using a Dublin-Core based REST API, third-party repository software populates a web form that the user can then proofread and complete. PaperBase also predicts likely key words for the preprints, based on a controlled vocabulary of keywords that the archive uses and a Bayesian classifier. We have tested the system on 12 individuals, and measured the time that it took them to enter data, and the accuracy of the entered metadata. We find that our system appears to be faster than manual entry, but a larger sample needs to be tested before it can be deemed statistically significant. All but two participants perceived it to be faster. Some metadata, in particular the title of preprints, contains significantly fewer mistakes when entered automatically; even though the automatic system is not perfect, people tend to correct mistakes that paperBase makes, but would leave their own mistakes in place.

#index 1065263
#* A metadata generation system for scanned scientific volumes
#@ Xiaonan Lu;Brewster Kahle;James Z. Wang;C. Lee Giles
#t 2008
#c 14
#% 249143
#% 269217
#% 301236
#% 378519
#% 614036
#% 738494
#% 786875
#% 809426
#% 998622
#! Large scale digitization projects have been conducted at digital libraries to preserve cultural artifacts and to provide permanent access. The increasing amount of digitized resources, including scanned books and scientific publications, requires development of tools and methods that will efficiently analyze and manage large collections of digitized resources. In this work, we tackle the problem of extracting metadata from scanned volumes of journals. Our goal is to extract information describing internal structures and content of scanned volumes, which is necessary for providing effective content access functionalities to digital library users. We propose methods for automatically generating volume level, issue level, and article level metadata based on format and text features extracted from OCRed text. We show the performance of our system on scanned bound historical documents nearly two centuries old. We have developed the system and integrated it into an operational digital library, the Internet Archive, for real-world usage.

#index 1065264
#* Exploring a digital library through key ideas
#@ Bill N. Schilit;Okan Kolak
#t 2008
#c 14
#% 115679
#% 309541
#% 835045
#% 1023420
#% 1065411
#! Key Ideas is a technique for exploring digital libraries by navigating passages that repeat across multiple books. From these popular passages emerge quotations that authors have copied from book to book because they capture an idea particularly well: Jefferson on liberty; Stanton on women's rights; and Gibson on cyberpunk. We augment Popular Passages by extracting key terms from the surrounding context and computing sets of related key terms. We then create an interaction model where readers fluidly explore the library by viewing popular quotations on a particular key term, and follow links to quotations on related key terms. In this paper we describe our vision and motivation for Key Ideas, present an implementation running over a massive, real-world digital library consisting of over a million scanned books, and describe some of the technical and design challenges. The principal contribution of this paper is the interaction model and prototype system for browsing digital libraries of books using key terms extracted from the aggregate context of popularly quoted passages.

#index 1065265
#* Math information retrieval: user requirements and prototype implementation
#@ Jin Zhao;Min-Yen Kan;Yin Leng Theng
#t 2008
#c 14
#% 248216
#% 249137
#% 286302
#% 347706
#% 378478
#% 397141
#% 536403
#% 590523
#% 783709
#% 1099064
#% 1099068
#% 1394469
#% 1681910
#% 1709410
#% 1728015
#! We report on the user requirements study and preliminary implementation phases in creating a digital library that indexes and retrieves educational materials on math. We first review the current approaches and resources for math retrieval, then report on the interviews of a small group of potential users to properly ascertain their needs. While preliminary, the results suggest that meta-search and resource categorization are two basic requirements for a math search engine. In addition, we implement a prototype categorization system and show that the generic features work well in identifying the math contents from the webpage but perform less well at categorizing them. We discuss our long term goals, where we plan to investigate how math expressions and text search may be best integrated.

#index 1065266
#* A competitive environment for exploratory query expansion
#@ David Milne;David M. Nichols;Ian H. Witten
#t 2008
#c 14
#% 306468
#% 643001
#% 751818
#% 828972
#% 837691
#% 985820
#% 1019105
#! Most information workers query digital libraries many times a day. Yet people have little opportunity to hone their skills in a controlled environment, or compare their performance with others in an objective way. Conversely, although search engine logs record how users evolve queries, they lack crucial information about the user's intent. This paper describes an environment for exploratory query expansion that pits users against each other and lets them compete, and practice, in their own time and on their own workstation. The system captures query evolution behavior on predetermined information-seeking tasks. It is publicly available, and the code is open source so that others can set up their own competitive environments.

#index 1065267
#* How people find videos
#@ Sally Jo Cunningham;David M. Nichols
#t 2008
#c 14
#% 751569
#% 802836
#% 809414
#% 816596
#% 879445
#% 967325
#% 993076
#! At present very little is known about how people locate and view videos 'in the wild'. This study draws a rich picture of everyday video seeking strategies and video information needs, based on an ethnographic study of New Zealand university students. These insights into the participants' activities and motivations suggest potentially useful facilities for a video digital library.

#index 1065268
#* Selection and context scoping for digital video collections: an investigation of youtube and blogs
#@ Robert G. Capra;Christopher A. Lee;Gary Marchionini;Terrell Russell;Chirag Shah;Fred Stutzman
#t 2008
#c 14
#% 378520
#% 480479
#% 809418
#% 868089
#% 881955
#% 931994
#% 999285
#% 1073359
#! Digital curators are faced with decisions about what part of the ever-growing, ever-evolving space of digital information to collect and preserve. The recent explosion of web video on sites such as YouTube presents curators with an even greater challenge - how to sort through and filter a large amount of information to find, assess and ultimately preserve important, relevant, and interesting video. In this paper, we describe research conducted to help inform digital curation of on-line video. Since May 2007, we have been monitoring the results of 57 queries on YouTube related to the 2008 U.S. presidential election. We report results comparing these data to blogs that point to candidate videos on YouTube and discuss the effects of query-based harvesting as a collection development strategy.

#index 1065269
#* A study of awareness in multimedia search
#@ Robert Villa;Nicholas Gildea;Joemon M. Jose
#t 2008
#c 14
#% 128268
#% 414507
#% 414513
#% 766531
#% 813966
#% 848012
#% 903632
#% 998795
#% 1715628
#! Awareness of another's activity is an important aspect of facilitating collaboration between users, enabling an "understanding of the activities of others"[1]. Techniques such as collaborative filtering enable a form of asynchronous awareness, providing recommendations generated from the past activity of a community of users. In this paper we investigate the role of awareness and its effect on search behavior in collaborative multimedia retrieval. We focus on the scenario where two users are searching at the same time on the same task, and via the interface, can see the activity of the other user. The main research question asks: does awareness of another searcher aid a user when carrying out a multimedia search session? To encourage awareness, an experimental study was designed where two users were asked to find as many relevant video shots as possible under different awareness conditions. These were individual search (no awareness of each other), mutual awareness (where both user's could see each other's search screen), and unbalanced awareness (where one user is able to see the other's screen, but not vice-versa). Twelve pairs of users were recruited, and the four worst performing TRECVID 2006 search topics were used as search tasks, under four different awareness conditions. We present the results of this study, followed by a discussion of the implications for multimedia digital library systems.

#index 1065270
#* Towards usage-based impact metrics: first results from the mesur project.
#@ Johan Bollen;Herbert Van de Sompel;Marko A. Rodriguez
#t 2008
#c 14
#% 122797
#% 330687
#% 401104
#% 783703
#% 804874
#% 804886
#% 841613
#% 874506
#% 967284
#% 1026319
#! Scholarly usage data holds the potential to be used as a tool to study the dynamics of scholarship in real time, and to form the basis for the definition of novel metrics of scholarly impact. However, the formal groundwork to reliably and validly exploit usage data is lacking, and the exact nature, meaning and applicability of usage-based metrics is poorly understood. The MESUR project funded by the Andrew W. Mellon Foundation constitutes a systematic effort to define, validate and cross-validate a range of usage-based metrics of scholarly impact. MESUR has collected nearly 1 billion usage events as well as all associated bibliographic and citation data from significant publishers, aggregators and institutional consortia to construct a large-scale usage data reference set. This paper describes some major challenges related to aggregating and processing usage data, and discusses preliminary results obtained from analyzing the MESUR reference data set. The results confirm the intrinsic value of scholarly usage data, and support the feasibility of reliable and valid usage-based metrics of scholarly impact.

#index 1065271
#* Evaluating the contributions of video representation for a life oral history collection
#@ Michael G. Christel;Michael H. Frisch
#t 2008
#c 14
#% 378480
#% 809414
#% 857477
#% 857478
#% 874485
#% 896070
#% 1389561
#! A digital video library of over 900 hours of video and 18000 stories from The HistoryMakers is used to investigate the role of motion video for users of recorded life oral histories. Stories in the library are presented in one of two ways in two within-subjects experiments: either as audio accompanied by a single still photographic image per story, or as the same audio within a motion video of the interviewee speaking. Twenty-four participants given a treasure-hunt fact-finding task, i.e., very directed search, showed no significant preference for either the still or video treatment, and no difference in task performance. Fourteen participants in a second study worked on an exploratory task in the same within-subjects experimental framework, and showed a significant preference for video. For exploratory work, video has a positive effect on user satisfaction. Implications for use of video in collecting and accessing recorded life oral histories, in student assignments and more generally, are discussed, along with reflections on long term user studies to complement the ones presented here.

#index 1065272
#* From writing and analysis to the repository: taking the scholars' perspective on scholarly archiving
#@ Catherine C. Marshall
#t 2008
#c 14
#% 480326
#% 845344
#% 859913
#% 1000935
#! This paper reports the results of a qualitative field study of the scholarly writing, collaboration, information management, and long-term archiving practices of researchers in five related subdisciplines. The study focuses on the kinds of artifacts the researchers create in the process of writing a paper, how they exchange and store materials over the short term, how they handle references and bibliographic resources, and the strategies they use to guarantee the long term safety of their scholarly materials. The findings reveal: (1) the adoption of a new CIM infrastructure relies crucially on whether it compares favorably to email along six critical dimensions; (2) personal scholarly archives should be maintained as a side-effect of collaboration and the role of ancillary material such as datasets remains to be worked out; and (3) it is vital to consider agency when we talk about depositing new types of scholarly materials into disciplinary repositories.

#index 1065273
#* Scientific publishing in the era of Petabyte data
#@ Alexander S. Szalay
#t 2008
#c 14
#! Today's scientific datasets are growing into Petabytes. A similar transition is happening in industry and society. Web search companies have to deal routinely with tens of Petabytes, a substantial fraction of the world's computers go into data warehouses of the Big 5. Scientists, librarians and publishers are just beginning to grasp the magnitude and multi-faceted nature of the problems facing us. Every step of the usual scientific process will need to change and change soon. Science in the 21st century will require a different set of skills than previously, more computational and algorithmic thinking and more interdisciplinary interaction will be hallmarks of a successful scientist. The talk will present the challenges and trends in this 'brave new world'.

#index 1065274
#* User-assisted ink-bleed correction for handwritten documents
#@ Yi Huang;Michael S. Brown
#t 2008
#c 14
#% 57628
#% 206560
#% 337555
#% 378535
#% 392851
#% 444019
#% 729437
#% 760836
#% 774927
#% 781730
#% 809505
#% 967306
#% 1740412
#% 1855194
#! We describe a user-assisted framework for correcting ink-bleed in old handwritten documents housed at the National Archives of Singapore (NAS). Our approach departs from traditional correction techniques that strive for full automation. Fully-automated approaches make assumptions about ink-bleed characteristics that are not valid for all inputs. Furthermore, fully-automated approaches often have to set algorithmic parameters that have no meaning for the end-user. In our system, the user needs only to provide simple examples of ink-bleed, foreground ink, and background. These training examples are used to classify the remaining pixels in the document to produce a computer-generated result that is equal to or better than existing fully-automated approaches. To offer a complete system, we also provide tools that allow any errors in the computer-generated results to be quickly "cleaned up" by the user. The initial training markup, together with the computer-generated results, and manual edits are all recorded with the final output, allowing subsequent viewers to see how a corrected document was created and to make changes or updates. While an ongoing project, our feedback from the NAS staff has been overwhelmingly positive that this user-assisted framework is a practical way to address the ink-bleed problem.

#index 1065275
#* Crf-based authors' name tagging for scanned documents
#@ Manabu Ohta;Atsuhiro Takasu
#t 2008
#c 14
#% 126613
#% 131580
#% 464434
#% 625357
#% 894517
#! Authors' names are a critical bibliographic element when searching or browsing academic articles stored in digital libraries. Therefore, those creating metadata for digital libraries would appreciate an automatic method to extract such bibliographic data from printed documents. In this paper, we describe an automatic author name tagger for academic articles scanned with optical character recognition (OCR) mark-up. The method uses conditional random fields (CRF) for labeling the unsegmented character strings in authors' blocks as those of either an author or a delimiter. We applied the tagger to Japanese academic articles. The results of the experiments showed that it correctly labeled more than 99% of the author name strings, which compares favorably with the under 96% correct rate of our previous tagger based on a hidden Markov model (HMM).

#index 1065276
#* Segregating and extracting overlapping data points in two-dimensional plots
#@ William Browuer;Saurabh Kataria;Sujatha Das;Prasenjit Mitra;C. Lee Giles
#t 2008
#c 14
#% 249143
#% 297159
#% 321652
#% 420077
#% 768774
#% 874472
#% 1006513
#% 1558464
#% 1855070
#! Most search engines index the textual content of documents in digital libraries. However, scholarly articles frequently report important findings in figures for visual impact and the contents of these figures are not indexed. These contents are often invaluable to the researcher in various fields, for the purposes of direct comparison with their own work. Therefore, searching for figures and extracting figure data are important problems. To the best of our knowledge, there exists no tool to automatically extract data from figures in digital documents. If we can extract data from these images automatically and store them in a database, an end-user can query and combine data from multiple digital documents simultaneously and efficiently. We propose a framework based on image analysis and machine learning to extract information from 2-D plot images and store them in a database. The proposed algorithm identifies a 2-D plot and extracts the axis labels, legend and the data points from the 2-D plot. We also segregate overlapping shapes that correspond to different data points. We demonstrate performance of individual algorithms, using a combination of generated and real-life images.

#index 1065277
#* A simple method for citation metadata extraction using hidden markov models
#@ Erik Hetzner
#t 2008
#c 14
#% 333943
#% 363592
#% 438103
#% 495944
#% 738490
#% 742424
#% 775853
#% 874511
#% 942406
#% 967276
#% 1006608
#% 1656120
#! This paper describes a simple method for extracting metadata fields from citations using hidden Markov models. The method is easy to implement and can achieve levels of precision and recall for heterogeneous citations comparable to or greater than other HMM-based methods. The method consists largely of string manipulation and otherwise depends only on an implementation of the Viterbi algorithm, which is widely available, and so can be implemented by diverse digital library systems.

#index 1065278
#* Identification of time-varying objects on the web
#@ Satoshi Oyama;Kenichi Shirasuna;Katsumi Tanaka
#t 2008
#c 14
#% 36672
#% 255161
#% 281251
#% 378497
#% 495944
#% 577238
#% 577247
#% 577263
#% 578242
#% 615723
#% 729622
#% 729913
#% 760838
#% 760866
#% 783704
#% 805885
#% 805896
#% 838408
#% 855094
#% 870896
#% 878159
#% 956501
#% 1398185
#% 1655504
#% 1663673
#% 1914862
#! We have developed a method for determining whether data found on the Web are for the same or different objects that takes into account the possibility of changes in their attribute values over time. Specifically, we estimate the probability that observed data were generated for the same object that has undergone changes in its attribute values over time and the probability that the data are for different objects, and we define similarities between observed data using these probabilities. By giving a specific form to the distributions of time-varying attributes, we can calculate the similarity between given data and identify objects by using agglomerative clustering on the basis of the similarity. Experiments in which we compared identification accuracies between our proposed method and a method that regards all attribute values as constant showed that the proposed method improves the precision and recall of object identification.

#index 1065279
#* Using web information for creating publication venue authority files
#@ Denilson Alves Pereira;Berthier Ribeiro-Neto;Nivio Ziviani;Alberto H. F. Laender
#t 2008
#c 14
#% 249143
#% 301261
#% 305903
#% 337227
#% 438137
#% 451536
#% 614046
#% 760866
#% 783484
#% 809460
#% 869500
#% 869502
#% 874510
#% 956570
#% 967295
#% 991819
#% 1663664
#! Citations to publication venues in the form of journal, conference and workshop contain spelling variants, acronyms, abbreviated forms and misspellings, all of which make more difficult to retrieve the item of interest. The task of discovering and reconciling these variant forms of bibliographic references is known as authority work. The key goal is to create the so called authority files, which maintain, for any given bibliographic item, a list of variant labels (i.e., variant strings) used as a reference to it. In this paper we propose to use information available on the Web to create high quality publication venue authority files. Our idea is to recognize (and extract) references to publication venues in the text snippets of the answers returned by a search engine. References to a same publication venue are then reconciled in an authority file. Each entry in this file is composed of a canonical name for the venue, an acronym, the venue type (i.e., journal, conference, or workshop), and a mapping to various forms of writing its name in bibliographic citations. Experimental results show that our Web-based method for creating authority files is superior to previous work based on straight string matching techniques. Considering the average precision in finding correct venue canonical names, we observe gains up to 41.7%.

#index 1065280
#* Application of kalman filters to identify unexpected change in blogs
#@ Paul Logasa Bogen, II;Joshua Johnston;Unmil P. Karadkar;Richard Furuta;Frank Shipman
#t 2008
#c 14
#% 231522
#% 327115
#% 344929
#% 791708
#% 835232
#% 838523
#% 855160
#% 869596
#% 875959
#% 876007
#% 881051
#% 881498
#% 936928
#% 967263
#! Information on the Internet, especially blog content, changes rapidly. Users of information collections, such as the blogs hosted by technorati.com, have little, if any, control over the content or frequency of these changes. However, it is important for users to be able to monitor content for deviations in the expected pattern of change. If a user is interested in political blogs and a blog switches subjects to a literary review blog, the user would want to know of this change in behavior. Since pages may change too frequently for manual inspection for "unwanted" changes, an automated approach is wanted. In this paper, we explore methods for indentifying unexpected change by using Kalman filters to model blog behavior over time. Using this model, we examine the history of several blogs and determine methods for flagging the significance of a blog's change from one time step to the next. We are able to predict large deviations in blog content, and allow user-defined sensitivity parameters to tune a statistical threshold of significance for deviation from expectation.

#index 1065281
#* Ncore: architecture and implementation of a flexible, collaborative digital library
#@ Dean B. Krafft;Aaron Birkland;Ellen J. Cramer
#t 2008
#c 14
#% 287597
#% 319875
#% 332756
#% 378512
#% 752076
#% 790699
#% 804812
#% 843084
#% 859913
#% 874492
#% 935959
#% 967265
#% 967280
#% 976775
#% 1407691
#% 1682014
#% 1682016
#! NCore is an open source architecture and software platform for creating flexible, collaborative digital libraries. NCore was developed by the National Science Digital Library (NSDL) project, and it serves as the central technical infrastructure for NSDL. NCore consists of a central Fedora-based digital repository, a specific data model, an API, and a set of backend services and frontend tools that create a new model for collaborative, contributory digital libraries. This paper describes NCore, presents and analyzes its architecture, tools and services; and reports on the experience of NSDL in building and operating a major digital library on it over the past year and the experience of the Digital Library for Earth Systems Education in porting their existing digital library and tools to the NCore platform.

#index 1065282
#* Acceptance and use of electronic library services in ugandan universities
#@ Prisca K.G. Tibenderana;Patrick J. Ogao
#t 2008
#c 14
#% 61637
#% 190282
#% 242223
#% 406695
#% 449264
#% 508270
#% 573875
#% 716375
#% 739191
#% 782161
#% 808236
#% 847338
#% 860311
#% 860326
#% 952547
#% 967316
#% 1021467
#% 1029738
#% 1040931
#% 1193919
#% 1603155
#! University libraries in Developing Countries (DCs), hampered by developmental problems, find it hard to provide electronic services. Donor communities have come in to bridge this technology gap by providing funds to university libraries for information technology infrastructure, enabling these university libraries to provide electronic library services to patrons. However, for these services to be utilized effectively, library end-users must accept and use them. To investigate this process in Uganda, this study modifies "The Unified Theory of Acceptance and Use of Technology" (UTAUT) by replacing "effort expectancy" and "voluntariness" with "relevancy", "awareness" and "benefits" factors. In so doing, we developed the Service Oriented UTAUT (SOUTAUT) model whose dependent constructs predict 133% of the variances in user acceptance and use of e-library services. The study revealed that relevancy moderated by awareness plays a major factor in acceptance and use of e-library services in DCs.

#index 1065283
#* Portable digital libraries on an ipod
#@ David Bainbridge;Steve Jones;Sam McIntosh;Matt Jones;Ian H. Witten
#t 2008
#c 14
#% 337454
#% 345349
#% 645984
#% 826457
#! This paper describes the facilities we built to run a self-contained digital library on an iPod. The digital library software used was the open source package Greenstone, and the paper highlights the technical problems that were encountered and solved. It attempts to convey a feeling for the kind of issues that must be faced when adapting standard DL software for non-standard, leading-edge devices.

#index 1065284
#* Annotated program examples as first class objects in an educational digital library
#@ Peter Brusilovsky;I-Han Hsiao;Michael V. Yudelson
#t 2008
#c 14
#% 760869
#% 1674829
#! This paper analyzes problems encountered by our team while creating an educational digital library of program examples. We present approaches to resolving these problems, and evaluations of the suggested approaches.

#index 1065285
#* Annotating historical archives of images
#@ Xiaoyue Wang;Lexiang Ye;Eamonn Keogh;Christian Shelton
#t 2008
#c 14
#% 269217
#% 622077
#% 716621
#% 792257
#% 812540
#% 893161
#% 952731
#% 952742
#% 967294
#% 1100414
#% 1207074
#% 1775675
#! Recent initiatives like the Million Book Project and Google Print Library Project have already archived several million books in digital format, and within a few years a significant fraction of world's books will be online. While the majority of the data will naturally be text, there will also be tens of millions of pages of images. Many of these images will defy automation annotation for the foreseeable future, but a considerable fraction of the images may be amiable to automatic annotation by algorithms that can link the historical image with a modern contemporary, with its attendant metatags. In order to perform this linking we must have a suitable distance measure which appropriately combines the relevant features of shape, color, texture and text. However the best combination of these features will vary from application to application and even from one manuscript to another. In this work we propose a simple technique to learn the distance measure by perturbing the training set in a principled way. We show the utility of our ideas on archives of manuscripts containing images from natural history and cultural artifacts.

#index 1065286
#* slab: smart labeling of family photos through an interactive interface
#@ Ehsan Fazl-Ersi;I. Scott MacKenzie;John K. Tsotsos
#t 2008
#c 14
#% 272902
#% 452642
#% 780133
#% 954944
#% 1112584
#! A novel technique for semi-automatic photo annotation is proposed and evaluated. The technique, sLab, uses face processing algorithms and a simplified user interface for labeling family photos. A user study compared our system with two others. One was Adobe Photoshop Element. The other was an in-house implementation of a face clustering interface recently proposed in the research community. Nine participants performed an annotation task with each system on faces extracted from a set of 150 images from their own family photo albums. As the faces were all well known to participants, accuracy was near perfect with all three systems. On annotation time, sLab was 25% faster than Photoshop Element and 16% faster than the face clustering interface.

#index 1065287
#* Autotagging to improve text search for 3d models
#@ Corey Goldfeder;Peter Allen
#t 2008
#c 14
#% 46803
#% 238545
#% 416060
#% 581284
#% 905280
#! Text search on libraries of 3D models has traditionally worked poorly, as text annotations on 3D models are often unreliable or incomplete. We attempt to improve the recall of text search by automatically assigning appropriate tags to models. Our algorithm finds relevant tags by appealing to a large corpus of partially labeled example models, which does not have to be preclassified or otherwise prepared. For this purpose we use a copy of Google 3DWarehouse, a library of user contributed models which is publicly available on the Internet. Given a model to tag, we find geometrically similar models in the corpus, based on distances in a reduced dimensional space derived from Zernike descriptors. The labels of these neighbors are used as tag candidates for the model with probabilities proportional to the degree of geometric similarity. We show experimentally that text based search for 3D models using our computed tags can approach the quality of geometry based search. Finally, we describe our 3D model search engine that uses this algorithm.

#index 1065288
#* Slide image retrieval: a preliminary study
#@ Guo Min Liew;Min-Yen Kan
#t 2008
#c 14
#% 626558
#% 629566
#% 866264
#% 926881
#% 1727360
#! We consider the task of automatic slide image retrieval, in which slide images are ranked for relevance against a textual query. Our implemented system, SLIDIR caters specifically for this task using features specifically designed for synthetic images embedded within slide presentation. We show promising results in both the ranking and binary relevance task and analyze the contribution of different features in the task performance.

#index 1065289
#* Perception-oriented online news extraction
#@ Jinlin Chen;Keli Xiao
#t 2008
#c 14
#% 330765
#% 397605
#% 431536
#% 531458
#% 536403
#% 754108
#% 775853
#% 1269910
#% 1279275
#! A novel online news extraction approach based on human perception is presented in this paper. The approach simulates how a human perceives and identifies online news content. It first detects news areas based on content function, space continuity, and formatting continuity of news information. It further identifies detailed news content based on the position, format, and semantic of detected news areas. Experiment results show that our approach achieves much better performance (in average more than 99% in terms of F1 Value) compared to previous approaches such as Tree Edit Distance and Visual Wrapper based approaches. Furthermore, our approach does not assume the existence of Web templates in the tested Web pages as required by Tree Edit Distance based approach, nor does it need training sets as required in Visual Wrapper based approach. The success of our approach demonstrates the strength of the perception-oriented Web information extraction methodology and represents a promising approach for automatic information extraction from sources with presentation design for humans.

#index 1065290
#* Plato: a service oriented decision support system for preservation planning
#@ Christoph Becker;Hannes Kulovits;Andreas Rauber;Hans Hofman
#t 2008
#c 14
#% 859916
#% 967247
#% 991818
#% 1052572
#% 1406460
#% 1407694
#! The fast changes of technologies in today's information landscape have considerably shortened the lifespan of digital objects. Digital preservation has become a pressing challenge. Different strategies such as migration and emulation have been proposed; however, the decision for a specific tool e.g. for format migration or an emulator is very complex. The process of evaluating potential solutions against specific requirements and building a plan for preserving a given set of objects is called preservation planning. So far, it is a mainly manual, sometimes ad-hoc process with little or no tool support. This paper presents a service-oriented architecture and decision support tool that implements a solid preservation planning process and integrates services for content characterisation, preservation action and automatic object comparison to provide maximum support for preservation planning endeavours.

#index 1065291
#* Usage analysis of a public website reconstruction tool
#@ Frank McCown;Michael L. Nelson
#t 2008
#c 14
#% 881071
#% 881072
#% 907442
#% 954492
#% 967248
#% 1246535
#! The Web is increasingly the medium by which information is published today, but due to its ephemeral nature, web pages and sometimes entire websites are often "lost" due to server crashes, viruses, hackers, run-ins with the law, bankruptcy and loss of interest. When a website is lost and backups are unavailable, an individual or third party can use Warrick to recover the website from several search engine caches and web archives (the Web Infrastructure). In this short paper, we present Warrick usage data obtained from Brass, a queueing system for Warrick hosted at Old Dominion University and made available to the public for free. Over the last six months, 520 individuals have reconstructed more than 700 websites with 800K resources from the Web Infrastructure. Sixty-two percent of the static web pages were recovered, and 41% of all website resources were recovered. The Internet Archive was the largest contributor of recovered resources (78%).

#index 1065292
#* Using web metrics to analyze digital libraries
#@ Michael Khoo;Joe Pagano;Anne L. Washington;Mimi Recker;Bart Palmer;Robert A. Donahue
#t 2008
#c 14
#% 212496
#% 301982
#% 614070
#% 616104
#% 739905
#% 807653
#% 809402
#% 874492
#% 882326
#% 907249
#% 961627
#% 967329
#% 998713
#% 1002203
#! This paper discusses the use of web metrics tools at four digital libraries, the Instructional Architect, the Library of Congress, the National Science Digital Library, and WGBH Teachers' Domain. We describe some of the issues involved in using web metrics to report on ongoing web site performance. We also describe how web metrics can be used for focused data mining, using session length metrics as our example; and here, we recommend that session length metrics, which were developed to track e-commerce, need to be carefully considered when they are applied in non-e-commerce settings, such as digital libraries. We conclude by discussing some of the current limitations and possibilities of using web metrics to analyze and evaluate digital library use and impact.

#index 1065293
#* A lightweight metadata quality tool
#@ David M. Nichols;Chu-Hsiang Chan;David Bainbridge;Dana McKay;Michael B. Twidale
#t 2008
#c 14
#% 172811
#% 337236
#% 645984
#% 755044
#% 999300
#% 1037731
#% 1048531
#% 1069039
#% 1666144
#! We describe a Web-based metadata quality tool that provides statistical descriptions and visualisations of Dublin Core metadata harvested via the OAI protocol. The lightweight nature of development allows it to be used to gather contextualized requirements and some initial user feedback is discussed.

#index 1065294
#* Improving navigation interaction in digital documents
#@ George Buchanan;Tom Owen
#t 2008
#c 14
#% 149109
#% 184763
#% 349416
#% 735116
#% 809441
#% 860007
#% 967348
#! This paper investigates novel interactions for supporting within-document navigation. We focus on one specific interaction: the following of figure references. Through this interaction we illuminate factors also found in other forms of navigation. Three alternative interactions for supporting figure navigation are described and evaluated through a user study. Experimentation proves the advantages of our interaction design, and the degree to which the interaction of existing reader software can be improved.

#index 1065295
#* Keeping narratives of a desktop to enhance continuity of on-going tasks
#@ Youngjoo Park;Richard Furuta
#t 2008
#c 14
#% 32599
#% 172777
#% 214715
#% 289567
#% 378541
#% 452635
#% 579901
#% 642983
#% 751800
#% 860038
#% 881054
#% 936919
#! We describe a novel interface by which a user can browse, bookmark and retrieve previously used working environments, i.e., desktop status, enabling the retention of the history of use of various sets of information. Significant tasks often require reuse of (sets of) information that was used earlier. Particularly, if a task involves extended interaction, then the task's environment has been through a lot of changes and can get complex. Under the current prevailing desktop-based computing environment, after an interruption to the task users can gain little assistance to get back to the context that they previously worked on. A user thus encounters increased discontinuity in continuing extended tasks.

#index 1065296
#* Note-taking, selecting, and choice: designing interfaces that encourage smaller selections
#@ Aaron Bauer;Kenneth R. Koedinger
#t 2008
#c 14
#% 249090
#% 249158
#% 301217
#% 437156
#% 760875
#% 809403
#% 809441
#% 886215
#% 955011
#% 997475
#! Our research develops note-taking applications for educational environments. Previous studies found that while copy-pasting notes can be more efficient than typing, for some users it reduces attention and learning. This paper presents two studies aimed at designing and evaluating interfaces that encourage focusing. While we were able to produce interfaces that increased desirable behaviors and improved satisfaction, the new interfaces did not improve learning. We suggest design recommendations derived from these studies, and describe a "selecting-to-read" behavior we encountered, which has implications for the design of reading and note-taking applications.

#index 1065297
#* A fedora librarian interface
#@ David Bainbridge;Ian H. Witten
#t 2008
#c 14
#% 378528
#% 859913
#% 967265
#! The Fedora content management system embodies a powerful and flexible digital object model. This paper describes a new open-source software front-end that enables end-user librarians to transfer documents and metadata in a variety of formats into a Fedora repository. The main graphical facility that Fedora itself provides for this task operates on one document at a time and is not librarian-friendly. A batch driven alternative is possible, but requires documents to be converted beforehand into the XML format used by the repository, necessitating a need for programming skills. In contrast, our new scheme allows arbitrary collections of documents residing on the user's computer (or the web at large) to be ingested into a Fedora repository in one operation, without a need for programming expertise. Provision is also made for editing existing documents and metadata, and adding new ones. The documents can be in a wide variety of different formats, and the user interface is suitable for practicing librarians. The design capitalizes on our experience in building the Greenstone librarian interface and participating in dozens of workshops with librarians worldwide.

#index 1065298
#* Broadening participation in computing with the k-gray engineering pathway digital library
#@ Alice Agogino;Michael Smith
#t 2008
#c 14
#! This demonstration presents a digital library for educators at all levels to easily identify, select, and use educational resources that have been shown through research to be effective for increasing the participation of women and under-represented minorities in information technology. The library consists of practices from the Broadening Participation in Computing (BPC) program in NSF CISE and elsewhere that have been researched or evaluated for their promise or effectiveness to recruit, retain, or advance under-represented groups in IT fields of study or research careers. We do not develop the practices, but instead describe them and make them easy for users to find and evaluate in a central location.

#index 1065299
#* Increasing the visibility of web-based information systems via client-side mash-ups
#@ Godmar Back;Annette Bailey
#t 2008
#c 14

#index 1065300
#* Running greenstone on an ipod
#@ David Bainbridge;Steve Jones;Sam McIntosh;Matt Jones;Ian H. Witten
#t 2008
#c 14
#% 645984
#! The open source digital library software Greenstone is demonstrated running on an iPod. The standalone configuration supports browsing, searching and displaying documents in a range of media formats. Plugged in to a host computer (Mac, Linux, or Windows), the exact same facilities are made available to the world through a built-in web server.

#index 1065301
#* The relation browser tool for faceted exploratory search
#@ Robert G. Capra;Gary Marchionini
#t 2008
#c 14
#% 967314
#! The Relation Browser (RB) is a tool developed by the Interaction Design Lab at the University of North Carolina at Chapel Hill for understanding relationships between items in a collection and for exploring an information space (e.g., a set of documents or webpages). The RB has been through a number of major design revisions. At JCDL 2007, we reported on two studies of information seeking that we conducted using the RB++ version of the Relation Browser software. Based on the results of those studies, we developed a set of design changes and implemented these in a new version called RB07. We will demonstrate the new RB07 interface and describe the rationale for our design changes.

#index 1065302
#* An application for semantic markup of biodiversity documents
#@ Hong Cui
#t 2008
#c 14
#% 911856
#! We would like to demonstrate a machine-learning based semantic markup system that may be used to reformat free-text biodiversity documents in XML format for digital libraries. We named the system MARTT II. It is built on the MARTT engine described in [1], but with new components for example a parallel markup engine using the unsupervised learning algorithm described in [2]. The double Is in the name stand for Intuitive Interaction, which is our goal to make the system truly easy to use. They also mean the system supports two different automated markup engines, allowing the user to choose either one to use and make comparisons between the two.

#index 1065303
#* Dynamic classification explorer for music digital libraries
#@ J. Stephen Downie;Kris West;Xiao Hu
#t 2008
#c 14
#% 809476
#! This paper outlines a dynamic classification explorer for music digital library users and researchers. System provides multiple simultaneous classification visualizations and synchronized audio.

#index 1065304
#* Novel interface services for bioacoustic digital libraries
#@ J. Stephen Downie;David K. Tcheng;Xin Xiang
#t 2008
#c 14
#! This paper introduces the CARDINAL (Computer Assisted Recognition and Discovery in Natural Acoustic Landscapes) interface system for use in Bioacoustic Digital Libraries (BADL).

#index 1065305
#* Direct: applying the DIKW hierarchy to large-scale evaluation campaigns
#@ Marco Dussin;Nicola Ferro
#t 2008
#c 14
#% 1407686
#% 1709436
#! We describe the effort of designing and developing a digital library system able to manage the different types of information resources produced during a large-scale evaluation campaign and to support the different stages of it. In this context, we present DIRECT, the system which has been adopted to manage the CLEF evaluation campaigns since 2005.

#index 1065306
#* Semtinel: interactive supervision of automatic indexing
#@ Kai Eckert;Heiner Stuckenschmidt;Magnus Pfeffer
#t 2008
#c 14
#% 1002101

#index 1065307
#* Dilight: providing flexible and knowledge rich access to support digital library learning
#@ Daqing He;Ming Mao;Yefei Peng;Jongdo Park
#t 2008
#c 14

#index 1065308
#* Computational linguistics for metadata building
#@ Judith L. Klavans;Carolyn Sheffield;Jimmy Lin;Tandeep Sidhu
#t 2008
#c 14
#! In this paper, we describe a downloadable text-mining tool for enhancing subject access to image collections in digital libraries.

#index 1065309
#* Plato: a preservation planning tool
#@ Hannes Kulovits;Christoph Becker;Michael Kraxner;Florian Motlik;Kevin Stadler;Andreas Rauber
#t 2008
#c 14
#% 967247
#% 991818
#% 1406460
#! Creating a concrete plan for preserving an institution's collection of digital objects requires the evaluation of available solutions against clearly defined and measurable criteria. Preservation planning aids in this decision making process to find the best preservation strategy considering the institution's requirements, the planning context and possible actions applicable to the objects contained in the repository. Performed manually, this evaluation of possible solutions against requirements takes a good deal of time and effort. In this demonstration, we present Plato, an interactive software tool aimed at creating preservation plans.

#index 1065310
#* InPhO: a system for collaboratively populating and extending a dynamic ontology
#@ Mathias Niepert;Cameron Buckner;Jaimie Murdock;Colin Allen
#t 2008
#c 14
#% 967285
#! InPhO is a system that combines statistical text processing, information extraction, human expert feedback, and logic programming to populate and extend a dynamic ontology for the field of philosophy. Integrated in the editorial workflow of the Stanford Encyclopedia of Philosophy (SEP), it will provide important metadata features such as automated generation of cross-references, semantic search, and ontology driven conceptual navigation.

#index 1065311
#* The vocalsearch music search engine
#@ Bryan Pardo;David Little;Rui Jiang;Hagai Livni;Jinyu Han
#t 2008
#c 14
#% 947821
#% 1411724
#! The VocalSearch system is a music search engine developed at Northwestern University and available on the internet (vocalsearch.org). This system lets the user query for the desired song in a number of ways: sung queries, queries entered as music notation, and text-based lyrics search. Users are also able to contribute songs to the system, making them searchable for future users. The result is a flexible system that lets the user find the song using their preferred modality (music notation, text, music notation). This demonstration lets users try out the VocalSearch system.

#index 1065312
#* Digmap: a service for searching and browsing old maps
#@ Gilberto Pedrosa;João Luzio;Hugo Manguinhas;Bruno Martins
#t 2008
#c 14
#! DIGMAP aims to become the main international resource discovery service for digitized old maps existing in libraries. The service reuses metadata from European national libraries and other relevant third party metadata sources. The gathered metadata is enhanced locally with geographical indexing and with record linking/clustering, leveraging on geographic gazetteers and authority files. When available, the images of the maps are also processed to extract potentially relevant features. This made it possible to develop a rich integrated environment for searching and browsing services with four perspectives: image's features, textual, geographic and temporal information.

#index 1065313
#* See the world with themexplorer
#@ Adrian Popescu;Sofiane Souidi;Pierre-Alain Moëllic
#t 2008
#c 14
#% 967244
#! We demonstrate ThemExplorer1:, a mash-up for geographic image retrieval. The application combines: Geonames, a geographic thesaurus; TagMaps, a tool for visualizing tags on a map; PIRIA - a visual search engine, and pictures collected from Flickr and Google images. The user can query ThemExplorer using both keywords and example images.

#index 1065314
#* Tubekit: a query-based youtube crawling toolkit
#@ Chirag Shah
#t 2008
#c 14
#% 967341
#% 967359

#index 1065315
#* Bringing lives to light: lives and event representation in temporal and geographic context
#@ Ryan Shaw;Ray R. Larson
#t 2008
#c 14
#! Our demonstration system consists of a set of tools for identifying life events in biographical texts and linking them to relevant contextual resources.

#index 1065316
#* Data visualization applications in virtual globe software
#@ Situ Studio;William Cotton;Nate Hill;Alicia Gibb
#t 2008
#c 14
#! Focusing on the intersection of visual data mapping and virtual globe software, this application is part digital library and part analytical tool. It combines data sets into a collaborative database and visualizes the information through Google Earth overlays. This user-centered interface makes previously hard-to-use public information (e.g. census data) accessible and easily interpretable. We are presenting an interactive application named GeoDatum that allows users to upload their databases and display this information through a number of visualization tools, either individually or comparatively. The software is an open source web application with multiple goals. Primarily, it is a central repository for both geographic boundaries and the data related to those boundaries. In addition, it gives users the ability to create dynamic visualizations viewable in Google Earth's extensible KML environment, complete with full 3D renderings and animations. The trade-off is that anyone who wants to use the application to generate visualizations will leave their data for public use. The software's core functionality is to allow users to import their own Shapefiles as well as CSVs containing data about the geographic areas. Shapefiles are an industry standard GIS format supported by numerous software applications including ArcGIS. This software will convert this information into KML files and Google Earth overlays. While it can display publicly available data sets, it also allows a user to include their own information, thus making it a useful internal analytic tool for private interests as well. We will present a case study done with the Brooklyn Public Library that utilizes this tool in the service of a project on urban planning and analysis.

#index 1065317
#* Metaarchive/lockss distributed preservation networks
#@ Martin Halbert;Katherine Skinner;Tyler Walters
#t 2008
#c 14
#! The Workshop will provide information and training for institutions seeking to build or join LOCKSS-based distributed digital preservation networks. Such Private LOCKSS Networks (PLNs) enable groups of institutions to establish collaborative partnerships to securely preserve collections. Instructors will address the technical implementation as well as important organizational and legal elements of distributed digital preservation. Attendees will gain an understanding of how to produce and manage a private LOCKSS network.

#index 1065318
#* Collaborative information retrieval
#@ Jeremy Pickens;Gene Golovchinsky;Meredith Ringel Morris
#t 2008
#c 14
#% 848012
#% 998795
#! The goal of the workshop is to bring together researchers interested in various aspects of small-team collaborative search to share ideas, to stimulate research in the area, and to increase the visibility of this emerging area. We expect to identify promising directions for further exploration and to establish collaborative links among research groups.

#index 1065319
#* Education for digital stewardship: librarians, archivists or curators?
#@ Joyce Ray
#t 2008
#c 14
#! The large-scale digital repositories that are emerging today and expected to increase exponentially during this century will require information managers with the skills to archive, preserve, and organize massive amounts of data for use and re-use by a variety of interdisciplinary scholarly communities over time. Where will these managers come from, and what skills will they need? This workshop, organized by the US Institute of Museum and Library Services (IMLS) will address these questions through presentations and discussion among educators and other interested participants. IMLS has invested more than $100 million since 2003 in the education of librarians, archivists and data curators through both formal and continuing education programs. This timely funding has enabled graduate schools of library and information science to reshape their curricula to address the emerging need for digital data managers. Are we prepared to meet the challenge?

#index 1065320
#* Interface effects on digital library credibility judgments
#@ Paul R. Aumer-Ryan
#t 2008
#c 14
#% 451513
#% 1015619
#! In digital library search engines, "no results found" is a misleading phrase because it masquerades as a definitive answer; in reality, the collection being searched may in fact contain content that matches a user's query. This research examines the effect of null result sets on search behavior and on the perception of contents in digital libraries. In particular, this research supports the hypothesis that interface and design flaws have an effect on the perceived authority and credibility (here defined in terms of being authentic, factual, trustworthy, scholarly, and accurate) of the information being communicated by the interface in question. In short, interface design and the "form" of information (or, alternatively, the messenger) can negatively impact the perception of the quality of the "content" of information (the message).

#index 1065321
#* A ranking and exploration service based on large-scale usage data.
#@ Johan Bollen;Herbert Van de Sompel;Lyudmilla Balakireva;Ryan Chute
#t 2008
#c 14
#% 841613
#! This poster presents the architecture and user interface of a prototype service that was designed to allow end-users to explore the structure of science and perform assessments of scholarly impact on the basis of large-scale usage data. The underlying usage data set was constructed by the MESUR project which collected 1 billion usage events from a wide range of publishers, aggregators, and institutional consortia.

#index 1065322
#* Self-arranging preservation networks
#@ Charles L. Cartledge;Michael L. Nelson
#t 2008
#c 14
#% 31686
#! We pose the question: what if digital library objects could self-arrange without intervention from repositories and minimal intervention from administrators? We present background information about networks, techniques on how networks can be created based on locally discovered information, and how a small set of controlling policies can profoundly affect network configuration. This poster reflects a work in progress, providing information about the project's genesis, current status and future efforts.

#index 1065323
#* Tagging semantics: investigations with wordnet
#@ Michael J. Cole;Jacek Gwizdka
#t 2008
#c 14
#! The content of a tag sequence references both a user's concepts and the user's conceptualization of an information object. The tagging history of 823 users of the Delicious social tagging service is analyzed using WordNet. Three semantic measures of the tagging content are developed: the level of category references, the changes in category level for each noun as the tagging sequence unfolds, and the scope of concept coverage as the compactness of the WordNet subgraph for the noun senses. Observed patterns of concept reference as a function of sequence position hint at dynamic properties of the tag production process by marking a trace of cognitive activity. If tagging is object categorization, these measures provide a view of the personal categorization behavior of non-professionals and illuminate biases in the production of 'folksonomies' due to tag production processes.

#index 1065324
#* Isovera digital library
#@ Cal Collins;Sergey Demidenko;Shakib Mostafa
#t 2008
#c 14
#! IsoveraDL is a digital library and peer review system. IsoveraDL allows you to upload and serve your learning resources along with associated record metadata in a very organized and dynamic way. IsoveraDL uses a resource publication workflow that models the existing off-line record management workflow in use by different AAAS BEN partners. In addition IsoveraDL also provides a Peer Review module which allows users to create and use dynamic Peer Review workflows. Using IsoveraDL, permitted users can upload records and metadata for Peer Reviewed by others. Metadata records can be validated by a different set of users before they are published. The record submission forms used in IsoveraDL for adding resources are highly customizable and administrative users have the option of setting up as many of these forms as required. The Controlled Vocabularies and metadata fields used in IsoveraDL conform to AAAS BEN Learning Object Metadata specification. Administrative users have the ability to edit or add to these vocabularies and fields if needed. Optionally, the IsoveraDL Peer Review module may be used in conjunction with IsoveraDL's record submission forms. If a record submission form is set up for Peer Review then all records submitted through the form are Peer Reviewed before they can be validated. Administrative users can create workflows, associated forms and reviewer groups for the Peer Review module. The Peer Review module also has a reporting interface through which administrative users can easily monitor the progress and workload of all records and users associated with the module. Once a record is validated and published, users are able to discover resources through IsoveraDL's search and browse functionality. Records published through IsoveraDL can be easily harvested to the AAAS BEN portal through the built-in Harvester module using OAI-PHM.

#index 1065325
#* Museum materials in a digital library context and beyond
#@ Stephen Davison;Elizabeth McAulay;Murtha Baca
#t 2008
#c 14
#! This poster will present an overview of metadata mappings needed to support access, collaboration, preservation and aggregation of museum content within and beyond a digital library context.

#index 1065326
#* Oer recommender: linking nsdl pathways and opencourseware repositories
#@ Joel Duffin;Brandon Muramatsu
#t 2008
#c 14
#! The OER Recommender (www.oerrecommender.org) is a web service that helps people find relevant open educational resources. It links the digital learning resources in the National Science Digital Library (NSDL) disciplinary pathways with courses in OpenCourseWare repositories thereby providing critical contextual information. When a person browses a web page in a participating NSDL Pathway or OpenCourseWare repository, the recommender annotates the page with a "Recommended resources" link. The poster will describe the motivations for the project, provide detail on the recommendation engine, display recommendations for participating collections, and describe how other collections can participate in the project.

#index 1065327
#* The role of the dikw hierarchy in the design of a digital library system for the scientific data of large-scale evaluation campaigns
#@ Marco Dussin;Nicola Ferro
#t 2008
#c 14
#% 1099929
#! This paper exploit the DIKW hierarchy as a framework for modelling the scientific data produced during large-scale evaluation campaigns for information retrieval systems in order to design a digital library system able to manage and support the course of such evaluation campaigns.

#index 1065328
#* Translation of on-screen text into visual expressions
#@ Kumiko Fujisawa;Kenro Aihara
#t 2008
#c 14
#! To support the user's on-screen reading, we propose a methodology to translate text into visual expressions. Our prototype system analyses the text and translates them into image and adds movement to the image.

#index 1065329
#* Creating a searchable map library via data mining
#@ Judith Gelernter;Michael Lesk
#t 2008
#c 14
#% 893868
#! Maps in journal articles are difficult to access since they are rarely indexed apart from the articles themselves. Our prototype of a searchable map library was built by extracting maps and harvesting metadata from scanned articles to classify each map.

#index 1065330
#* The dcc curation lifecycle model
#@ Sarah Higgins
#t 2008
#c 14
#! The scientific record and the documentary heritage are increasingly created in digital form. The UK based Digital Curation Centre supports institutions who store, manage and preserve such data to help ensure its enhancement and continuing long-term use. The DCC (Digital Curation Centre) Curation Lifecycle Model provides a generic graphical high-level overview of the stages required for successful curation and preservation of digital material from initial conceptualisation. The model can be used to plan curation and preservation activities, to ensure sustainability of repository content or other digital material, within an organisation or consortium. It will help to ensure that all necessary stages are undertaken, each in the correct sequence. The model enables granular functionality to be mapped against it to define roles and responsibilities, and build a framework of standards and technologies to implement. It can help with the process of identifying additional steps which may be required, or actions which are not required by certain situations or disciplines, and of ensuring that processes and policies are adequately documented. Digital Curation Centre staff developed the model before undertaking a period of public consultation, which was recently completed. The newly ratified model will shortly be used by the DCC to ensure that information, services and advisory material cover all areas of the lifecycle. Domain-specific variations of the model will be developed, with greater levels of granularity, to help ensure that advice and information are easily accessible from the website. One planned utilisation is the development of domain specific standards frameworks within the DCC DIFFUSE Standards Frameworks, to help practitioners identify which standards they should be using and where they would be appropriately implemented. This poster will present the DCC Curation Lifecycle Model, incorporating the results of the public consultation period held during December 2007 to February 2008.

#index 1065331
#* Exploiting log files in video retrieval
#@ Frank Hopfgartner;Thierry Urruty;Robert Villa;Nicholas Gildea;Joemon M. Jose
#t 2008
#c 14
#% 996182
#! While research into user-centered text retrieval is based on mature evaluation methodologies, user evaluation in multimedia retrieval is still in its infancy. User evaluations can be expensive and are also often non-repeatable. An alternative way of evaluating such systems is the use of simulations. In this poster, we present an evaluation methodology which is based on exploiting log files recorded from a user-study we conducted.

#index 1065332
#* Building a story tracer out of a web archive
#@ Lian'en Huang;Jonathan J. H. Zhu;Xiaoming Li
#t 2008
#c 14
#! There are quite a few web archives around the world, such as Internet Archive and Web InfoMall (http://www.infomall.cn). Nevertheless, we have not seen substantial mechanism built on top of the archives to render the value of the data beyond what the Wayback machine offers. One of the reasons for this situation is the lack of a system vision and design which encompasses the oceanic data in a meaningful and cost-effective way. This paper describes an effort in this direction.

#index 1065333
#* Caspar: cultural, artistic and scientific knowledge for preservation, access and retrieval
#@ David Lamb;Daniel Lucchesi
#t 2008
#c 14
#! CASPAR (Cultural, Artistic, and Scientific knowledge for Preservation, Access, and Retrieval) aims at providing secure, reliable and cost-effective access for digitally encoded information for an indefinite time frame. From digital pictures to museum archives, from music to scientific data sets, technology is constantly changing. CASPAR is being developed to address this situation, and provide people and organisations with a user-oriented preservation framework.

#index 1065334
#* Developing a review process for online resources
#@ Sarah Giersch;Heather Leary;Bart Palmer;Mimi Recker
#t 2008
#c 14
#% 918842
#! The democratization of content creation via ubiquitous Internet tools and infrastructure [1] has fueled an explosion of user-generated content in the commercial and educational markets. Indeed, funding agencies such as the National Science Foundation (NSF) are actively seeking ways to integrate teachers and learners into the education cyber-infrastructure, whereby they become co-creators of educational content [2]. The ease with which this content, often in the form of online learning resources of varying levels of granularity, can be created and disseminated places it outside the usual peer review processes employed by publishers and professional societies. To date, digital library (DL) developers, teachers and school administrators, concerned whether teachers are using peerreviewed online learning resources, have depended on one or a combination of the following proxies to establish an imprimatur of quality: the reputation and oversight of a funding organization (e.g., NSF's peer review process), the credentials of the content creator (e.g., National Science Teachers Association) or the collection development policies of specific DLs (e.g., DLESE). Now more than ever, though, sites such as YouTube, Flickr and ccMixter and the evolving education cyber-infrastructure, have created an environment where user-generated content is beyond the reach of even these proxy review processes. However, in the omnipresent climate of accountability within K12 education at U.S. federal, state and local levels, education DLs are being challenged to identify the value: of the resources they hold and services they provide to users; and, of what their users create with those resources. For all of these reasons, it is useful, and necessary, to develop a standardized rubric and process to review online education resources. In particular, this work should leverage social and technical networks to enrich, facilitate, and automate the review process. The Digital Libraries go to School project was funded by NSF in 2006 to develop a professional development workshop curriculum that enables teachers to use the Instructional Architect (IA; http://ia.usu.edu) to design their own learning activities for classrooms using online STEM resources from the National Science Digital Library (NSDL.org) and the wider Web. One component of the project is to examine the criteria and approaches for reviewing the quality of teacher-created online learning resources in order to develop a rubric and workflow process. Work to date includes conducting focus groups and surveys with teachers and a 5-person Expert Review Committee, complemented by a literature review to identify elements for a review rubric incorporating the work of other education DLs (e.g., DLESE, MERLOT, NEEDS, among others). Findings are being synthesized, and based on analysis, a draft list of elements has been identified for further testing in Spring 2008. At the same time, a workflow process for conducting reviews with teacher-created resources will be piloted. It will combine human-generated reviews with machine-generated information about online resources (e.g., image and word count; educational standards alignment; currency of updates, provenance) [3]. Further work will identify areas for improving the review rubric and scaling and standardizing the workflow process for Fall 2008. We will also evaluate the usefulness of the reviews to teachers, and to stakeholders such as the IA, NSDL, NSF and other DLs, in providing access to high-quality online content.

#index 1065335
#* Building federation of digital libraries basing on concept of atomic services
#@ Cezary Mazurek;Tomasz Parkola;Marcin Werla
#t 2008
#c 14
#% 750866
#% 1087225
#! Our poster presents recent results from an ongoing research project entitled "Mechanisms of atomic services for distributed digital libraries".

#index 1065336
#* Early returns on an institutional repository: an exploration of the validity and functionality of pocketknowledge
#@ Marcelle Mentor;Eric Strome;Stephen Asunka;Giovannina Agnitti;Gary Natriello
#t 2008
#c 14
#! This poster presentation will reflect qualitatively on the challenges and opportunities of PocketKnowledge (http://pocketknowledge.tc.columbia.edu/home.php) as an institutional repository. The main question explored is whether such repositories are best understood as new competitors in the academic publishing world or as on-going documentations of the larger intellectual life of the institution. The early experience of one such repository, PocketKnowledge - a social archive developed and implemented by EdLab, a research unit of the Gottesman Libraries, Teachers College Columbia University - reveals that users are motivated not only to participate in an institutional repository, but also to document their intellectual life understood more broadly than publication. This suggests that the latter understanding of an institutional repository is a more reasonable, incremental expectation in what is surely an uphill battle against the long-established prestige of publishing in printed academic journals, and that institutional repositories such as PocketKnowledge should consider the strategic addition of functionalities that can highlight the intellectual life of the institution, not simply the intellectual production of its members.

#index 1065337
#* Harvesting needed to maintain scientific literature online
#@ Nikolay Nikolov;Peter Stoehr
#t 2008
#c 14
#% 956646
#! Millions of scientific articles are accessible freely on the web. While some of them are stored in institutional repositories many are made available on personal pages which are exposed to the net's transience. We found that nearly 11% of URLs of PDF documents containing references to life science publications were not accessible within 5 months after being harvested using a search engine's (SE) API. For most of them (8.4%) no SE cache backup could be found. Although we have yet to estimate the exact rate at which the scientific literature disappears and the duration of its disappearance the results so far are a clear indicator that web harvesting is needed to preserve the online scientific literature.

#index 1065338
#* Modeling korean clinical records as a simple temporal constraint satisfaction problem
#@ Heekyong Park;Jinwook Choi
#t 2008
#c 14
#% 107137
#! Temporal information is especially crucial in medical text processing. The simple temporal constraint satisfaction problem (STP) has been evaluated as sufficient to represent most English clinical temporal assertions. We aimed to test expressive power of STP in representing Korean clinical documents and to find out any encoding issues dependent on Korean language. This paper shows that STP is sufficient. Some distinctive characteristics were found but they did not affect the encoding work.

#index 1065339
#* Evaluation of a curriculum for digital libraries
#@ Jeffrey Pomerantz;Barbara M. Wildemuth;Sanghee Oh;Seungwon Yang;Edward A. Fox
#t 2008
#c 14

#index 1065340
#* Considering users and their opinions in knowledge management systems
#@ Katharina Probst;Kelly Dempski
#t 2008
#c 14
#% 734589
#% 869536
#% 955712
#! We describe a Knowledge Management System that shifts the focus from the traditional document-centric to a user-centric view. It takes into account users' query and download behavior, opinions, reputations, and social connections.

#index 1065341
#* The return of the trivial: problems formalizing collection/item metadata relationships
#@ Allen H. Renear;Karen M. Wickett;Richard J. Urban;David Dubin
#t 2008
#c 14
#% 259459
#% 259460
#% 809407
#! Formalizing collection/item metadata relationships encounters the problem of trivial satisfaction. We offer a solution related to current work in IR and ontology evaluation.

#index 1065342
#* The dspace repository: can multiple institutions live in one space? a different approach
#@ Christina Richison
#t 2008
#c 14
#! In late 2006, NITLE launched a pilot program for managed institutional repository services designed for smaller colleges and universities and the non-profit organizations that serve them. Twenty-six participating institutions helped pioneer this pilot effort, which laid the foundation for the development of production-level DSpace Services. These DSpace Services allowed campuses to start and grow their digital repositories with a minimal level of investment, with no hardware to purchase and very little application support expertise to develop. Campuses were able to focus on the work of building digital repositories within the context of a community of campuses sharing ideas and best practices. Lessons learned and next steps will be discussed.

#index 1065343
#* A unique insight into department of energy research accomplishments: a special collection
#@ Mary V. Schorn
#t 2008
#c 14
#! This poster describes online access to a unique collection of Department of Energy (DOE) Research and Development (R&D) accomplishments. The collection features research of DOE and its predecessor agencies, the Energy Research and Development Administration (ERDA) and the Atomic Energy Commission (AEC). This special collection contains historically significant government documents, including items from the Manhattan Project era, that have been specially selected and digitized to make them accessible via the Web. Landmark documents in the collection include The Eightfold Way: A Theory of Strong Interaction Symmetry (authored by Nobel prize winner Murray Gell-Mann) and The First Weighing of Plutonium (authored by Nobel prize winner Glenn Seaborg). In addition to a database of approximately 250 specially-selected documents, all related aspects of the collection (documents, research areas, and/or Nobel Laureate information) are combined in Feature Topic pages for the added value of a single point of access to each compilation. Over sixty (60) Feature Topic pages include diverse topics such as "Video Games - Did They Begin at Brookhaven?" and "Human Genome Research: Decoding DNA". This collection features a large number of DOE-associated Nobel Laureates, including Enrico Fermi, winner of the 1938 Nobel prize in physics, and George Smoot, winner of the 2006 Nobel prize in physics, and showcases a diversity in DOE research areas, including solar energy (with related educational materials) and Radioisotope Thermoelectric Generators (RTGs) that are used to power spacecraft. Easy access to this unique collection is provided via DOE R&D Accomplishments at http://www.osti.gov/accomplishments. This special collection is continually growing, with additional Nobel Laureate and/or research topic documents and features being added on a regular basis.

#index 1065344
#* The ncsu catalog research testbed: a tool for evaluating faceted library catalog interfaces
#@ Tito Sierra;Joseph Ryan;Jason Casden
#t 2008
#c 14
#! Many libraries have recently been devoting significant efforts to modernizing their library catalog web interfaces. One popular approach is to create a faceted search interface to the library catalog. Faceted search interfaces can be complex, requiring designers to make many decisions about the placement and display of faceted search design elements on the page. Unfortunately little empirical research exists on how to optimize faceted search interfaces for library catalogs. To facilitate research in this area, the NCSU Libraries has developed the NCSU Catalog Research Testbed, a tool for developing and evaluating faceted library catalog interfaces.

#index 1065345
#* Computer classification system usage in citeseer
#@ Mirco Speretta;Susan Gauch;Praveen Lakkaraju
#t 2008
#c 14
#! The ACM society for computing and professionals provides a digital library whose Computer Classification System (CCS) is based on a taxonomy that has been continuously updated over the years. The CiteSeer digital library contains a large collection of computer science research papers, many of which are tagged with categories from the CCS taxonomy. By analyzing CiteSeer's tagged documents and by considering different time frames, we extracted statistics that shows how the CCS taxonomy covers the publications in computer and information science research sub-fields. We also studied size and growth of categories over the last four available years. We believe that the identification of such trends within taxonomies would greatly help to improve the structure of classification systems and would help the construction of more efficient browsing and searching systems.

#index 1065346
#* A workbench for information quality evaluation
#@ Besiki Stvilia
#t 2008
#c 14
#% 999300
#! This paper describes the architecture of an Information Quality Evaluation Workbench for rapid design and operationalization of information quality assessment models.

#index 1065347
#* Automatic extraction of morphological information from botanical collections
#@ Xiaoya Tang
#t 2008
#c 14
#% 278109
#% 815327
#! Specific morphological information is often used by users to search botanical collections. However, traditional systems based on statistical models are often not effective for such search. This study automatically extracts morphological information from botanical collections using an adapted and enhanced information extraction system. Experimental results indicate this approach is promising. This study also indicates that this approach is generalizable to similar collections in the same domain and even to different domains with adaptation of the pattern recognition and knowledge base in the new domain.

#index 1065348
#* Releasing the power of digital metadata: examining large networks of co-related publications
#@ David Tarrant;Les Carr;Terry Payne
#t 2008
#c 14
#! Bibliographic metadata plays a key role in scientific literature, not only to summarise and establish the facts of the publication record, but also to track citations between publications and hence to establish the impact of individual articles within the literature. Commercial secondary publishers have typically taken on the role of rekeying, mining and analysing this huge corpus of linked data, but as the primary literature has moved to the world of the digital repository, this task is now undertaken by new services such as Citeseer, Citebase or Google Scholar. As institutional and subject-based repositories proliferate and Open Access mandates increase, more of the literature will become openly available in well managed data islands containing a much greater amount of detailed bibliometric metadata in formats such as RDF. Through the use of efficient extraction and inference techniques, complex relations between data items can be established. In this paper we explain the importance of the co-relation in enabling new techniques to rate the impact of a paper or author within a large corpus of publications.

#index 1065349
#* A cluster-based simulation of facet-based search
#@ Thierry Urruty;Frank Hopfgartner;Robert Villa;Nicholas Gildea;Joemon M. Jose
#t 2008
#c 14
#% 996182
#! The recent increase of online video has challenged the research in the field of video information retrieval. Video search engines are becoming more and more interactive, helping the user to easily find what he or she is looking for. In this poster, we present a new approach of using an iterative clustering algorithm on text and visual features to simulate users creating new facets in a facet-based interface. Our experimental results prove the usefulness of such an approach.

#index 1065350
#* Integrating ddi metadata into the nara transcontinental persistent archive prototype via the oai-pmh
#@ Jewel H. Ward;Jonathan Crabtree
#t 2008
#c 14
#! The H.W. Odum Institute for Research in Social Science (Odum), the Renaissance Computing Institute (RENCI), and the School of Information and Library Science (SILS), all part of the University of North Carolina at Chapel Hill (UNC-CH), are collaborating with the San Diego Supercomputer Center (SDSC) on an extension of the National Archives and Records Administration's (NARA) transcontinental persistent archive prototype (TPAP) data grid with the new integrated Rule Oriented Data System (iRODS). The goal of the project is to enable collection interoperability between UNC-CH and SDSC using an iRODS environment. This poster presents the results of one part of that project, which is the development of a crosswalk between the Odum Institute Data Archive (OIDA) Data Document Initiative (DDI) metadata and the NARA TPAP iRODS metadata catalogue (iCAT) via the OAI-PMH.

#index 1065351
#* The working scientist and the realities of data curation: a qualitative study addressing attitudes and needs
#@ Megan Winget
#t 2008
#c 14
#! This poster describes a nascent ethnographic study to examine working scientists' attitudes and perform a needs assessment regarding data collection, representation, and dissemination in terms of cyberinfrastructure initiatives.

#index 1065352
#* Knowledge representation from information extraction
#@ Tan Xu;Douglas W. Oard;Tamer Elsayed;Asad Sayeed
#t 2008
#c 14
#% 782759

#index 1065353
#* A formal ontology for temporal entities and its application in knowledge extraction
#@ Chunxia Zhang;Guiping Wang;Zhendong Niu
#t 2008
#c 14
#! This poster will present a formal ontology of temporal entities for knowledge sharing and interoperability. This ontology captures the semantic intensions, attributes and properties of temporal entities and their relationships. And it has been applied into temporal knowledge acquisition from un-annotated Chinese texts.

#index 1213407
#* Proceedings of the 9th ACM/IEEE-CS joint conference on Digital libraries
#@ Fred Heath;Mary Lynn Rice-Lively;Richard Furuta
#t 2009
#c 14
#! Welcome to JCDL 2009! We are delighted to welcome you back to Texas for the 9 th annual international Joint Conference on Digital Libraries. Since its initiation in 2001, JCDL has continued to be the major international forum for research, practice, and social issues in Digital Libraries. We trust that you will find that this year's conference maintains previous conferences' commitment to excellence and reflection of the area's multi-faceted interests. This year's conference will be held in the new AT&T Executive Education and Conference Center. The center is unique in Austin as it is designed as a high technology residential executive-learning environment, as well as a comfortable, luxurious hotel accommodation. Situated conveniently at the gateway to The University of Texas at Austin, the center offers inspiring views of the university's Tower and the State Capitol, or a serene central courtyard. Convening and sleeping in the shadows of these two great symbols, conferees can feel the extension of promise and power in the university's slogan, "What starts here, changes the world." We are excited by the two excellent speakers who have agreed to provide keynote talks at this year's conference. Christine Borgman, Professor and Presidential Chair in Information Studies, University of California, Los Angeles, will speak on "Digital Libraries: Now Here or Nowhere?" She will be introduced by Edward Fox. Gerhard Fischer, Professor of Computer Science, a Fellow of the Institute of Cognitive Science, and the Director of the Center for Lifelong Learning and Design (L3D) at the University of Colorado at Boulder will speak on "Cultures of Participation: Opportunities and Challenges for the Future of Digital Libraries." He will be introduced by Tamara Sumner. The program committee worked hard to build a program that reflects JCDL's reputation for high quality. Each paper (both full and short) was reviewed in advance of a day and a half long in-person paper selection meeting. The program contains 29 full papers selected from the 102 submitted (a selection rate of 28%) and 13 short papers selected from the 43 submitted. Additionally, 5 papers originally submitted in the full format were converted to the short format by the program committee, for a total of 18 short papers to be presented at the conference. The papers are augmented by a robust collection of posters and demonstrations whose abstracts may be found in these proceedings. One of the demonstration activities this year is especially interesting - a virtual JCDL poster exhibition will be available in Second Life! Program committee members also were asked to nominate full papers for consideration for awards from the conference. Nine papers were identified and were reevaluated once the final versions had been submitted. You can find the nominated papers in paper sessions 5, 6, and 8. From the finalists, contained in session 8, two awards will be announced at the conference -- the Vannevar Bush Best Paper award and the award for the Best Student Paper. You can find the names of the awardees on the JCDL Web site (http://www.jcdl.org/) after the conference. We would like to thank the selection committee for the awards: Geneva Henry, Christine Borgman, Gary Marchionini, and Andreas Paepcke. The conference's program also contains two panels: "What should we preserve from a born-digital world?" with Bob Allen, Anne Gilliland, Michael Lesk, Catherine Marshall, and Megan Winget, and "Google as Library Redux," with panelists Michael Lesk, Clifford Lynch, and Gretchen Hoffman.

#index 1213408
#* Science teachers' use of online resources and the digital library for Earth system education
#@ Lecia J. Barker
#t 2009
#c 14
#% 332756
#% 337496
#% 614070
#% 614107
#% 760842
#% 803834
#% 809470
#% 809485
#% 874508
#% 967315
#% 1039846
#% 1065252
#% 1584684
#! A three-part study of teachers' use of online resources and of the Digital Library for Earth System Education (DLESE) was conducted from 2004 through summer 2006. The first two phases were qualitative and informed a survey administered to 622 science teachers across the U.S., one-fifth of whom had used DLESE. The findings present a profile of teachers and their access to Internet-connected computers and other hardware/electronic media devices in their classrooms; and teachers' preferences for resource formats (e.g., customizability) and educational web site features (e.g., tagged reading level). Analysis of variance showed that teachers with more than one working computer and teachers with more other devices valued the Internet more highly for teaching than did their less equipped peers. DLESE users valued the Internet more highly for their teaching, had more years teaching experience, and valued customizable resources more than their non-DLESE using peers. Most believed that resources catalogued in DLESE were scientifically accurate. Teachers used DLESE most often for finding hands-on activities, still images and other visual aids, and hand-outs; they were least likely to seek people, games, or assessment tools. The findings provide guidance for developers of K12 educational resources.

#index 1213409
#* Dimensional standard alignment in K-12 digital libraries: assessment of self-found vs. recommended curriculum
#@ Byron Marshall;René Reitsma;Malinda Zarske
#t 2009
#c 14
#% 311866
#% 720198
#% 837656
#% 881945
#% 1015625
#% 1021108
#% 1065249
#! Enhancing the experience of digital library users depends, in part, on recognizing and understanding user tasks. In the context of K-12 educational libraries this means that we must understand how K-12 teachers interact with such libraries and how they assess the relevance of documents found or encountered. This paper presents the results of an experiment in which K-12 teachers scored the relevance of curriculum they found themselves and the relevance of documents their colleagues found and recommended. We found that teachers apply a significantly more detailed notion of relevance, both qualitatively and quantitatively, when searching for as compared to evaluating recommended curricula. Differences were observed in both relevance judgments and system interaction logs. These variations may be useful in identifying user intent and in dynamically adapting the behavior of digital libraries of educational material.

#index 1213410
#* Helping students with information fragmentation, assimilation and notetaking
#@ Yolanda Jacobs Reimer;Melissa Bubnash;Matthew Hagedal;Peter Wolf
#t 2009
#c 14
#% 816702
#% 845346
#% 860037
#% 1026430
#% 1047408
#% 1174568
#! The problem of information fragmentation is especially acute for today's college students who manage and assimilate information in various forms while completing many of their academic tasks, and who must do so within the confines of standard software applications. The goal of this research is to provide students with a novel information assimilation and notetaking tool that helps them more efficiently manage their electronic information and overcome some of the fragmentation challenges they routinely experience. Our Global Information Gatherer prototype allows students to view, edit and store files of different types from within a single interface, and provides an integrated web browser and notetaking functionality.

#index 1213411
#* Topic model methods for automatically identifying out-of-scope resources
#@ Steven Bethard;Soumya Ghosh;James H. Martin;Tamara Sumner
#t 2009
#c 14
#% 344447
#% 402289
#% 574600
#% 715258
#% 722904
#% 763708
#% 825817
#% 840882
#% 840951
#% 967299
#% 967300
#% 967620
#% 989611
#% 1184331
#% 1289531
#% 1412307
#% 1860547
#! Recent years have seen the rise of subject-themed digital libraries, such as the NSDL pathways and the Digital Library for Earth System Education (DLESE). These libraries often need to manually verify that contributed resources cover topics that fit within the theme of the library. We show that such scope judgments can be automated using a combination of text classification techniques and topic modeling. Our models address two significant challenges in making scope judgments: only a small number of out-of-scope resources are typically available, and the topic distinctions required for digital libraries are much more subtle than classic text classification problems. To meet these challenges, our models combine support vector machine learners optimized to different performance metrics and semantic topics induced by unsupervised statistical topic models. Our best model is able to distinguish resources that belong in DLESE from resources that don't with an accuracy of around 70%. We see these models as the first steps towards increasing the scalability of digital libraries and dramatically reducing the workload required to maintain them.

#index 1213412
#* Automatically generating high quality metadata by analyzing the document code of common file types
#@ Lars Fredrik Høimyr Edvardsen;Ingeborg Torvik Sølvberg;Trond Aalberg;Hallvard Trætteberg
#t 2009
#c 14
#% 159252
#% 301236
#% 397193
#% 805894
#% 838501
#% 839904
#% 955490
#% 967256
#% 1069086
#% 1406468
#! A major challenge for content management in intranets and other large scale document storage and retrieval services is the generation of high quality metadata. Manual generation of metadata is resource demanding and is often viewed by collection managers and document authors as inefficient use of their time, and there is a desire for other ways to create the needed metadata. Automatic Metadata Generation (AMG) is methods for generating metadata without manual interaction using computer program(s) to interpret the document and possibly the document context. Current AMG research has been limited to collection of similarly formatted documents. The research presented in this paper expands the field of AMG by presenting an approach that is independent of a common visualization scheme; AMG based on document code analysis. This is done by showing AMG possibilities from Latex, Word and PowerPoint documents and how this approach can significantly increase the quality of the generated metadata. This by avoiding common quality reducing factors as missing completeness, low accuracy, logical consistency and coherence and timeliness by giving AMG algorithms direct access to the user specified intellectual content and the file formatting. This research shows how this AMG approach can be combined with other AMG approaches, drawing on their strengths in order to achieve the desired high quality metadata entities.

#index 1213413
#* Disambiguating authors in academic publications using random forests
#@ Pucktada Treeratpituk;C. Lee Giles
#t 2009
#c 14
#% 129979
#% 201889
#% 310516
#% 310533
#% 350103
#% 400847
#% 587758
#% 740995
#% 760866
#% 804877
#% 805885
#% 809293
#% 809459
#% 809460
#% 870896
#% 915242
#% 967295
#% 981634
#% 1019087
#% 1663664
#! Users of digital libraries usually want to know the exact author or authors of an article. But different authors may share the same names, either as full names or as initials and last names (complete name change examples are not considered here). In such a case, the user would like the digital library to differentiate among these authors. Name disambiguation can help in many cases; one being a user in a search of all articles written by a particular author. Disambiguation also enables better bibliometric analysis by allowing a more accurate counting and grouping of publications and citations. In this paper, we describe an algorithm for pair-wise disambiguation of author names based on a machine learning classification algorithm, random forests. We define a set of similarity profile features to assist in author disambiguation. Our experiments on the Medline database show that the random forest model outperforms other previously proposed techniques such as those using support-vector machines (SVM). In addition, we demonstrate that the variable importance produced by the random forest model can be used in feature selection with little degradation in the disambiguation accuracy. In particular, the inverse document frequency of author last name and the middle name's similarity alone achieves an accuracy of almost 90%.

#index 1213414
#* Using web information for author name disambiguation
#@ Denilson Alves Pereira;Berthier Ribeiro-Neto;Nivio Ziviani;Alberto H.F. Laender;Marcos André Gonçalves;Anderson A. Ferreira
#t 2009
#c 14
#% 387427
#% 503213
#% 760866
#% 783704
#% 805885
#% 809459
#% 809460
#% 819552
#% 874510
#% 967295
#% 991819
#% 1020797
#% 1055818
#% 1065279
#% 1090229
#% 1133176
#% 1223300
#% 1663664
#! In digital libraries, ambiguous author names may occur due to the existence of multiple authors with the same name (polysemes) or different name variations for the same author (synonyms). We proposed here a new method that uses information available on the Web to deal with both problems at the same time. Our idea consists of gathering information from input citations and submitting queries to a Web search engine, aiming at finding curricula vitae and Web pages containing publications of the ambiguous authors. From the content of documents in the answer sets returned by the Web search engine, useful information that can help in the disambiguation process is extracted. Using this information, author names are disambiguated by leveraging a hierarchical clustering method that groups citations in the same document together in a bottom-up fashion. Experimental results show that the our method yields results that outperform those of two state-of-the-art unsupervised methods and are statistically comparable with those of a supervised one, but requiring no training. We observe gains of up to 65.2% in the pairwise F1 metric when compared with our best unsupervised baseline method.

#index 1213415
#* Whetting the appetite of scientists: producing summaries tailored to the citation context
#@ Stephen Wan;Cécile Paris;Robert Dale
#t 2009
#c 14
#% 406493
#% 449747
#% 755863
#% 967256
#% 1026306
#% 1065265
#% 1143790
#% 1143792
#% 1215287
#% 1251672
#% 1264797
#% 1338737
#% 1406467
#! The amount of scientific material available electronically is forever increasing. This makes reading the published literature, whether to stay up-to-date on a topic or to get up to speed on a new topic, a difficult task. Yet, this is an activity in which all researchers must be engaged on a regular basis. Based on a user requirements analysis, we developed a new research tool, called the Citation-Sensitive In-Browser Summariser (CSIBS), which supports researchers in this browsing task. CSIBS enables readers to obtain information about a citation at the point at which they encounter it. This information is aimed at enabling the reader to determine whether or not to invest the time in exploring the cited article further, thus alleviating information overload. CSIBS builds a summary of the cited document, bringing together meta-data about the document and a citation-sensitive preview that exploits the citation context to retrieve the sentences from the cited document that are relevant at this point. This paper briefly presents our user requirements analysis, then describes the system and, finally, discusses the observations from an initial pilot study. We found that CSIBS facilitates the relevancy judgment task, by increasing the users' self-reported confidence in making such judgements.

#index 1213416
#* Finding topic trends in digital libraries
#@ Levent Bolelli;Seyda Ertekin;Ding Zhou;C. Lee Giles
#t 2009
#c 14
#% 769906
#% 957171
#% 1663619
#% 1835183
#! We propose a generative model based on latent Dirichlet allocation for mining distinct topics in document collections by integrating the temporal ordering of documents into the generative process. The document collection is divided into time segments where the discovered topics in each segment is propagated to influence the topic discovery in the subsequent time segments. We conduct experiments on the collection of academic papers from CiteSeer repository. We augment the text corpus with the addition of user queries and tags and integrate the citation graph to boost the weight of the topical terms. The experiment results show that segmented topic model can effectively detect distinct topics and their evolution over time.

#index 1213417
#* CEBBIP: a parser of bibliographic information in chinese electronic books
#@ Liangcai Gao;Zhi Tang;Xiaofan Lin
#t 2009
#c 14
#% 252750
#% 296738
#% 614036
#% 614037
#% 718532
#% 942406
#% 967276
#% 1006684
#% 1078010
#! Bibliographic information is essential for many digital library applications, such as citation analysis, academic searching and topic discovery. And bibliographic data extraction has attracted a great deal of attention in recent years. In this paper, we address the problem of automatic extraction of bibliographic data in Chinese electronic book and propose a tool called CEBBIP* for the task, which includes three main systems: data preprocessing, data parsing and data postprocessing. In the data preprocessing system, the tool adopts a rules-based method to locate citation data in a book and to segment citation data into citation strings of individual referencing literature. And a learning-based approach, Conditional Random Fields (CRF), is employed to parse citation strings in the data parsing system. Finally, the tool takes advantage of document intrinsic local format consistency to enhance citation data segmentation and parsing through clustering techniques. CEBBIP has been used in a commercial E-book production system. Experimental results show that CEBBIP's precision rate is very high. More specially, adopting the document intrinsic local format consistency obviously improves the citation data segmenting and parsing accuracy.

#index 1213418
#* Query parameters for harvesting digital video and associated contextual information
#@ Gary Marchionini;Chirag Shah;Christopher A. Lee;Robert Capra
#t 2009
#c 14
#% 330609
#% 577245
#% 835231
#% 1065268
#! Video is increasingly important to digital libraries and archives as both primary content and as context for the primary objects in collections. Services like YouTube not only offer large numbers of videos but also usage data such as comments and ratings that may help curators today make selections and aid future generations to interpret those selections. A query-based harvesting strategy is presented and results from daily harvests for six topics defined by 145 queries over a 20-month period are discussed with respect to, query specification parameters, topic, and contribution patterns. The limitations of the strategy and these data are considered and suggestions are offered for curators who wish to use query-based harvesting.

#index 1213419
#* ViGOR: a grouping oriented interface for search and retrieval in video libraries
#@ Martin Halvey;David Vallet;David Hannah;Joemon M. Jose
#t 2009
#c 14
#% 187999
#% 316156
#% 318785
#% 420474
#% 780821
#% 840424
#% 871566
#% 888942
#% 905164
#% 987222
#% 993076
#% 997197
#% 1047296
#% 1071149
#% 1074182
#% 1131866
#% 1727314
#% 1727315
#! In this paper, we present ViGOR (Video Grouping, Organisation and Retrieval) a video retrieval system that allows users to group videos in order to facilitate video retrieval tasks. In this way users are able to visualise and conceptualise many aspects of their search tasks and carry out a localised search in order to solve a more global search problem. The main objective of this work is to aid users while carrying out explorative video retrieval tasks; these tasks can be often ambiguous and multi-faceted. Two user evaluations were carried out in order to evaluate the usefulness of this grouping paradigm for assisting users. The first evaluation involved users carrying out broad tasks on YouTube, and gave insights into the application of our interface to a vast online video collection. The second evaluation involved users carrying out focused tasks on the TRECVID 2007 video collection, allowing a comparison over a local collection, on which we could extract a number of content-based features. The results of our evaluations show that the use of the ViGOR system results in an increase in user performance and user satisfaction, showing the potential of a grouping paradigm for video search for various tasks in a variety of diverse video collections.

#index 1213420
#* Developing a flexible content model for media repositories: a case study
#@ Christopher A. Beer;Peter D. Pinch;Karen Cariani
#t 2009
#c 14
#% 584869
#% 649144
#! This article describes the process and challenges of developing a content model that can support the content and metadata present in a complex media archive. Media archives have some of the most diverse requirements in an effort to catalog, preserve, and make accessible a wide range of content with multifaceted relationships between works. We focus particularly on the design and implementation of the WGBH Media Library and Archives' Fedora digital access repository for scholars, educational users and the public. It is our hope that the process and findings from this work can support the architecture and development of other media archives.

#index 1213421
#* An alignment based system for chord sequence retrieval
#@ Pierre Hanna;Matthias Robine;Thomas Rocher
#t 2009
#c 14
#% 235941
#% 1404871
#! Music retrieval systems for Western tonal music digital ibraries have to consider rhythmic, timbral, melodic and harmonic information. Most existing retrieval systems only take into account melodies. Melody comparison may induce errors since two musical pieces can be very similar whereas their melodies may differ in a significant way. In this paper, we propose to investigate and experiment a retrieval system based on the comparison of chord progressions. The definition of chords may be ambiguous but their properties can be precisely described and represented. We detail the adaptations of alignment algorithms, successfully applied for the estimation of symbolic melodic similarity, for chord progression retrieval. Several experiments, performed on symbolic databases, show that the system described is robust to variations and outperforms a recent chord retrieval system.

#index 1213422
#* Query-page intention matching using clicked titles and snippets to boost search rankings
#@ Masaya Murata;Hiroyuki Toda;Yumiko Matsuura;Ryoji Kataoka
#t 2009
#c 14
#% 46803
#% 309095
#% 348155
#% 387427
#% 577224
#% 783482
#% 818221
#% 869548
#% 879565
#% 879567
#% 987209
#% 989578
#% 1130811
#% 1187378
#% 1715593
#! Users of text retrieval systems input only a few keywords or sometimes just one keyword to the systems even if they had complex information needs. Due to the lack of query keywords, it becomes hard to return relevant search results that satisfy the demands of each user. Because digital documents, in contrast to queries, are generally composed of many kinds of keywords, it is also difficult to estimate the main topic or grasp the inherent intentions of the documents. In this paper, we present techniques to represent users' search intentions and the intentions that digital documents can satisfy by making use of clicked titles and snippets acquired from a click log analysis. We then present a method to match these intentions to boost search result rankings. Through experiments that use click logs and indexes of a commercial search engine, we verified our method's capability of significantly improving search precision.

#index 1213423
#* Supporting analysis of future-related information in news archives and the web
#@ Adam Jatowt;Kensuke Kanazawa;Satoshi Oyama;Katsumi Tanaka
#t 2009
#c 14
#% 823332
#% 987268
#% 1016337
#% 1019066
#% 1065403
#% 1398185
#! A lot of future-related information is available in news articles or Web pages. This information can however differ to large extent and may fluctuate over time. It is therefore difficult for users to manually compare and aggregate it, and to re-construct the most probable course of future events. In this paper we approach a problem of automatically generating summaries of future events related to queries using data obtained from news archive collections or from the Web. We propose two methods, explicit and implicit future-related information detection. The former is based on analyzing the context of future temporal expressions in documents, while the latter relies on detecting periodical patterns in historical document collections. We present a graph-based visualization of future-related information and demonstrate its usefulness through several examples.

#index 1213424
#* Generalized formal models for faceted user interfaces
#@ Edward C. Clarkson;Shamkant B. Navathe;James D. Foley
#t 2009
#c 14
#% 123589
#% 287631
#% 452641
#% 572459
#% 769134
#% 797999
#% 824586
#% 824755
#% 943881
#% 967314
#% 1116214
#% 1124068
#% 1696323
#! Faceted metadata and navigation have become major topics in library science, information retrieval and Human-Computer Interaction (HCI). This work surveys a range of extant approaches in this design space, classifying systems along several relevant dimensions. We use that survey to analyze the organization of data and its querying within faceted browsing systems. We contribute formal entity-relationship (ER) and relational data models that explain that organization and relational query models that explain systems' browsing functionality. We use these types of models since they are widely used to conceptualize data and to model back-end data stores. Their structured nature also suggests ways in which both the models and faceted systems might be extended.

#index 1213425
#* Large-scale ETD repositories: a case study of a digital library application
#@ Adam Mikeal;James Creel;Alexey Maslov;Scott Phillips;John Leggett;Mark McFarland
#t 2009
#c 14
#% 185274
#% 249150
#% 332739
#% 356167
#% 358412
#% 378537
#% 614040
#% 614059
#% 901499
#% 1389815
#! We describe the implementation of a statewide system for managing and preserving electronic theses and dissertations (ETDs) from Texas universities. We further explain the theoretical, technical and political issues that arose during the implementation of this system. These issues range from technical components developed by TDL 'such as a customized workflow management application and adding OAI-ORE capabilities to DSpace' to human-centered issues such as stakeholder engagement and participation. Our experiences reflect the challenges, expected and unexpected, that others will face when attempting to build digital library applications to scale.

#index 1213426
#* Style-consistency calligraphy synthesis system in digital library
#@ Kai Yu;Jiangqin Wu;Yueting Zhuang
#t 2009
#c 14
#% 658560
#% 813035
#% 1022674
#% 1269921
#% 1298005
#% 1677496
#! There are lots of digitized calligraphy works written by ancient famous calligraphists in CADAL (China-America Digital Academic Library) digital library. To make use of these resources, users want to generate a tablet or a piece of calligraphic works written by some ancient famous calligraphist. But some characters in the tablet or the calligraphic work hadn't been written by the calligraphist or though were ever written but are hard to read because of long time weathering. In this paper, a novel approach is proposed to synthesize Chinese calligraphic characters which are in the same style of some calligraphist, and a corresponding system is developed for calligraphy works generation and tablets design. Calligraphic character is represented by a three-level hierarchical model. A novel approach for determining the character structure is proposed, which takes advantage of both the structure of the same characters of different styles and the structure of similar characters of the same style. A style evaluation model (SEM) is presented to evaluate whether the calligraphic character generated is in the same style of the specified calligraphist and to adjust the calligraphic character generated. Our experiments show that this system is effective.

#index 1213427
#* Generative model-based metasearch for data fusion in information retrieval
#@ Miles Efron
#t 2009
#c 14
#% 71772
#% 144076
#% 184496
#% 194246
#% 232703
#% 309133
#% 309211
#% 316534
#% 337235
#% 340890
#% 340934
#% 340936
#% 413613
#% 577224
#% 643020
#% 728355
#% 879327
#% 879582
#% 893639
#% 948378
#% 985820
#% 987317
#% 1016344
#% 1026303
#% 1076651
#% 1203693
#! "Data fusion" refers to the problem in information retrieval (IR) where several lists of documents ranked against a query are to be merged into a single ranked list for presentation to a user. Data fusion is also known as "metasearch." In a digital library setting data fusion may support operations such as federated search based on multiple repository representations. This paper presents a novel approach to the fusion problem: generative model-based Metasearch (GeM). We suggest viewing the appearance of documents in a return set as the outcome of a probabilistic process; some documents are likely to occur in the model, while others are unlikely. Using Bayesian parameter estimation to fit a multinomial distribution based on the return sets to be merged, GeM achieves a final ranking by listing documents in decreasing probability of generation under the induced model. We also introduce what we call "the impatient reader" approach to normalizing document ranks in service to the fusion operation. We report results from several experiments on TREC data suggesting that GeM, informed with impatient reader document scores, operates at state-of-the-art levels of effectiveness.

#index 1213428
#* EnTag: enhancing social tagging for discovery
#@ Koraljka Golub;Jim Moon;Douglas Tudhope;Catherine Jones;Brian Matthews;BartBomiej PuzoD;Marianne Lykke Nielsen
#t 2009
#c 14
#% 1065261
#% 1089337
#% 1112960
#! The EnTag (Enhanced Tagging for Discovery) project investigated the effect on indexing and retrieval when using only social tagging versus when using social tagging in combination with suggestions from a controlled vocabulary. Two different contexts were explored: tagging by readers of a digital collection and tagging by authors in an institutional repository; also two different controlled vocabularies were examined, Dewey Decimal Classification and ACM Computing Classification Scheme. For each context a separate demonstrator was developed and a user study conducted. The results showed the importance of controlled vocabulary suggestions for both indexing and retrieval: to help produce ideas of tags to use, to make it easier to find focus for the tagging, as well as to ensure consistency and increase the number of access points in retrieval. The value and usefulness of the suggestions proved to be dependent on the quality of the suggestions, both in terms of conceptual relevance to the user and in appropriateness of the terminology. The participants themselves could also see the advantages of controlled vocabulary terms for retrieval if the terms used were from an authoritative source.

#index 1213429
#* Review-oriented metadata enrichment: a case study
#@ Liang Zhang;Jiangqin Wu;Yueting Zhuang;Yin Zhang;Chenxing Yang
#t 2009
#c 14
#% 4178
#% 268079
#% 769892
#% 853649
#% 855293
#% 855601
#% 907489
#% 975019
#% 1065261
#! Book reviews contributed by readers in social sites contain valuable information on books' content, style and merit, many informative words in which can be used to enrich metadata of books in China-Us Million Book Digital Library. In this paper, we present a system for review-oriented metadata enrichment and propose an Book-Centric Diverse Random Walk algorithm on a four-partite graph containing three kinds of relations among authors, books, reviews and words, in order to produce highly relevant as well as diverse keywords for a book. Experimental results of a user study show that our approach significantly outperforms other methods in terms of relevance and diversity. The metadata generated by our approach also has a large overlap with popular social tags and brief introductions from DouBan for books in the coverage experiments.

#index 1213430
#* Using timed-release cryptography to mitigate the preservation risk of embargo periods
#@ Rabia Haq;Michael L. Nelson
#t 2009
#c 14
#% 210011
#% 319994
#% 337235
#% 668681
#% 859918
#% 1393811
#! Due to temporary access restrictions, embargoed data cannot be refreshed to unlimited parties during the embargo time interval. A solution to mitigate the risk of data loss has been developed that uses a data dissemination framework, the Timed-Locked Embargo Framework (TLEF), that allows data refreshing of encrypted instances of embargoed content in an open, unrestricted scholarly community. TLEF exploits implementations of existing technologies to "time-lock" data using timed-release cryptology so that TLEF can be deployed as digital resources encoded in a complex object format suitable for metadata harvesting. The framework successfully demonstrates dynamic record identification, time-lock puzzle encryption, encapsulation and dissemination as XML documents. We implement TLEF and provide a quantitative analysis of its successful data harvest of time-locked embargoed data with minimum time overhead without compromising data security and integrity.

#index 1213431
#* Learning to assess the quality of scientific conferences: a case study in computer science
#@ Waister Silva Martins;Marcos André Gonçalves;Alberto H.F. Laender;Gisele L. Pappa
#t 2009
#c 14
#% 387427
#% 400847
#% 465754
#% 786836
#% 841613
#% 967277
#% 967278
#% 1065270
#% 1069293
#% 1409427
#% 1499573
#! Assessing the quality of scientific conferences is an important and useful service that can be provided by digital libraries and similar systems. This is specially true for fields such as Computer Science and Electric Engineering, where conference publications are crucial. However, the majority of the existing approaches for assessing the quality of publication venues has been proposed for journals. In this paper, we characterize a large number of features that can be used as criteria to assess the quality of scientific conferences and study how these several features can be automatically combined by means of machine learning techniques to effectively perform this task. Within the features studied are citations, submission and acceptance rates, tradition of the conference, and reputation of the program committee members. Among our several findings, we can cite that: (1) separating high quality conferences from medium and low quality ones can be performed quite effectively, but separating the last two types is a much harder task; and (2) citation features followed by those associated with the tradition of the conference are the most important ones for the task.

#index 1213432
#* CARES: a ranking-oriented CADAL recommender system
#@ Chenxing Yang;Baogang Wei;Jiangqin Wu;Yin Zhang;Liang Zhang
#t 2009
#c 14
#% 173879
#% 268079
#% 348173
#% 406493
#% 411762
#% 420515
#% 420539
#% 528156
#% 577329
#% 730049
#% 734592
#% 818216
#% 987197
#% 1074061
#% 1074124
#% 1272396
#% 1650569
#! A recommender system is useful for a digital library to suggest the books that are likely preferred by a user. Most recommender systems using collaborative filtering approaches leverage the explicit user ratings to make personalized recommendations. However, many users are reluctant to provide explicit ratings, so ratings-oriented recommender systems do not work well. In this paper, we present a recommender system for CADAL digital library, namely CARES, which makes recommendations using a ranking-oriented collaborative filtering approach based on users' access logs, avoiding the problem of the lack of user ratings. Our approach employs mean AP correlation coefficients for computing similarities among users' implicit preference models and a random walk based algorithm for generating a book ranking personalized for the individual. Experimental results on real access logs from the CADAL web site show the effectiveness of our system and the impact of different values of parameters on the recommendation performance.

#index 1213433
#* Recommendation as link prediction: a graph kernel-based machine learning approach
#@ Xin Li;Hsinchun Chen
#t 2009
#c 14
#% 304425
#% 734592
#% 734593
#% 771846
#% 833065
#% 955712
#% 967310
#% 975021
#% 1000869
#% 1006328
#% 1275197
#! Recommender systems have demonstrated commercial success in multiple industries. In digital libraries they have the potential to be used as a support tool for traditional information retrieval functions. Among the major recommendation algorithms, the successful collaborative filtering (CF) methods explore the use of user-item interactions to infer user interests. Based on the finding that transitive user-item associations can alleviate the data sparsity problem in CF, multiple heuristic algorithms were designed to take advantage of the user-item interaction networks with both direct and indirect interactions. However, the use of such graph representation was still limited in learning-based algorithms. In this paper, we propose a graph kernel-based recommendation framework. For each user-item pair, we inspect its associative interaction graph (AIG) that contains the users, items, and interactions n steps away from the pair. We design a novel graph kernel to capture the AIG structures and use them to predict possible user-item interactions. The framework demonstrates improved performance on an online bookstore dataset, especially when a large number of suggestions are needed.

#index 1213434
#* A polyrepresentational approach to interactive query expansion
#@ Abdigani Diriye;Ann Blandford;Anastasios Tombros
#t 2009
#c 14
#% 27049
#% 262036
#% 346553
#% 643001
#% 657203
#% 818260
#% 832356
#% 835027
#% 881943
#% 943042
#! Interactive Query Expansion (IQE) presents suggested terms to the user during their search to enable better Information Retrieval (IR). However, IQE terms are poorly used, and tend to lack information meaningful to the user. The lack of cognitive and functional support during query refinement is a well documented problem, and despite the work carried out, it is still an under researched area. This stagnation in progress has been partly due to the long held belief that users are able to make good IQE term selections, and that the de facto way IQE terms are presented is effective. In this paper, we introduce a novel method to improve the presentation of IQE terms by providing supplementary information alongside them. We describe a user study that compared our novel polyrepresentational approach to IQE against a conventional IQE system and a baseline system. Our findings have shown that a polyrepresentational approach to IQE can address the ambiguity and uncertainty surrounding IQE, and improve the perceived usefulness of the terms.

#index 1213435
#* Automatically characterizing resource quality for educational digital libraries
#@ Steven Bethard;Philipp Wetzer;Kirsten Butcher;James H. Martin;Tamara Sumner
#t 2009
#c 14
#% 269217
#% 309150
#% 324925
#% 324926
#% 344928
#% 614070
#% 679851
#% 780030
#% 956520
#% 1055779
#% 1055812
#% 1065249
#% 1168662
#! With the rise of community-generated web content, the need for automatic characterization of resource quality has grown, particularly in the realm of educational digital libraries. We demonstrate how identifying concrete factors of quality for web-based educational resources can make machine learning approaches to automating quality characterization tractable. Using data from several previous studies of quality, we gathered a set of key dimensions and indicators of quality that were commonly identified by educators. We then performed a mixed-method study of digital library curation experts, showing that our characterization of quality captured the subjective processes used by the experts when assessing resource quality for classroom use. Using key indicators of quality selected from a statistical analysis of our expert study data, we developed a set of annotation guidelines and annotated a corpus of 1000 digital resources for the presence or absence of these key quality indicators. Agreement among annotators was high, and initial machine learning models trained from this corpus were able to identify some indicators of quality with as much as an 18% improvement over the baseline.

#index 1213436
#* Improving optical character recognition through efficient multiple system alignment
#@ William B. Lund;Eric K. Ringger
#t 2009
#c 14
#% 241
#% 1722
#% 710859
#% 817577
#% 844924
#% 867981
#% 968363
#% 1141108
#% 1261572
#% 1272067
#% 1272157
#! Individual optical character recognition (OCR) engines vary in the types of errors they commit in recognizing text, particularly poor quality text. By aligning the output of multiple OCR engines and taking advantage of the differences between them, the error rate based on the aligned lattice of recognized words is significantly lower than the individual OCR word error rates. This lattice error rate constitutes a lower bound among aligned alternatives from the OCR output. Results from a collection of poor quality mid-twentieth century typewritten documents demonstrate an average reduction of 55.0% in the error rate of the lattice of alternatives and a realized word error rate (WER) reduction of 35.8% in a dictionary-based selection process. As an important precursor, an innovative admissible heuristic for the A* algorithm is developed, which results in a significant reduction in state space exploration to identify all optimal alignments of the OCR text output, a necessary step toward the construction of the word hypothesis lattice. On average 0.0079% of the state space is explored to identify all optimal alignments of the documents.

#index 1213437
#* No bull, no spin: a comparison of tags with other forms of user metadata
#@ Catherine C. Marshall
#t 2009
#c 14
#% 249151
#% 751818
#% 802743
#% 855601
#% 881054
#% 905319
#% 955010
#% 955275
#% 990328
#% 1055704
#% 1112960
#% 1150163
#! User-contributed tags have shown promise as a means of indexing multimedia collections by harnessing the combined efforts and enthusiasm of online communities. But tags are only one way of describing multimedia items. In this study, I compare the characteristics of public tags with other forms of descriptive metadata'titles and narrative captions'that users have assigned to a collection of very similar images gathered from the photo-sharing service Flickr. The study shows that tags converge on different descriptions than the other forms of metadata do, and that narrative metadata may be more effective than tags for capturing certain aspects of images that may influence their subsequent retrieval and use. The study also examines how photographers use peoples' names to personalize the different types of metadata and how they tell stories across short sequences of images. The study results are then brought to bear on design recommendations for user tagging tools and automated tagging algorithms and on using photo sharing sites as de facto art and architecture resources.

#index 1213438
#* What happens when facebook is gone?
#@ Frank McCown;Michael L. Nelson
#t 2009
#c 14
#% 840722
#% 967290
#% 1065268
#% 1080079
#! Web users are spending more of their time and creative energies within online social networking systems. While many of these networks allow users to export their personal data or expose themselves to third-party web archiving, some do not. Facebook, one of the most popular social networking websites, is one example of a "walled garden" where users' activities are trapped. We examine a variety of techniques for extracting users' activities from Facebook (and by extension, other social networking systems) for the personal archive and for the third-party archiver. Our framework could be applied to any walled garden where personal user data is being locked.

#index 1213439
#* Improving historical research by linking digital library information to a global genealogical database
#@ Douglas J. Kennard;William B. Lund;Bryan S. Morse
#t 2009
#c 14
#% 874456
#! Journals, letters, and other writings are of great value to historians and those who research their own family history; however, it can be difficult to find writings by specific people, and even harder to find what others wrote about them. We present a prototype web-based system that enables users to discover information about historical people (including their own ancestors) by linking digital library content to unique PersonIDs from a genealogical database. Users can contribute content such as scanned journals or information about where items can be found. They can also transcribe content and tag it with PersonIDs to identify who it is about. Additional features provide tools for users to explore historical contexts and relationships. These include the ability to tag places and to create a historical social network by specifying non-family relationships or by using a mechanism we call rosters to imply participation in some group or event.

#index 1213440
#* Collecting fragmentary authors in a digital library
#@ Monica Berti;Matteo Romanello;Alison Babeu;Gregory Crane
#t 2009
#c 14
#% 874470
#% 967300
#% 1019080
#% 1065411
#% 1392432
#! This paper discusses new work to represent, in a digital library of classical sources, authors whose works themselves are lost and who survive only where surviving authors quote, paraphrase or allude to them. It describes initial works from a digital collection of such fragmentary authors designed not only to capture but to extend the ontologies that traditional scholarship has developed over generations: the aim is representing every nuance of print conventions while using the capabilities of digital libraries to extend our ability to identify fragments, to represent what we have identified, and to render the results of that work intellectually and physically more accessible than was possible in print culture.

#index 1213441
#* Robust registration of manuscript images
#@ Ryan Baumann;W. Brent Seales
#t 2009
#c 14
#% 35901
#% 131055
#% 261100
#% 319464
#% 321455
#% 658338
#% 760805
#% 772874
#% 1013693
#! In this paper we present an application of image registration techniques to the specific domain of manuscript images. We show the application of this technique to images of the Venetus A, a 10th century manuscript of Homer's Iliad. The same algorithm is used to register images of the MS across time (including photographs separated by over a century), as well as across imaging modalities.

#index 1213442
#* Cost and benefit analysis of mediated enterprise search
#@ Mingfang Wu;James A. Thom;Andrew Turpin;Ross Wilkinson
#t 2009
#c 14
#% 23323
#% 38977
#% 280793
#% 401098
#% 411762
#% 577224
#% 742666
#% 754099
#% 754126
#% 803556
#% 818207
#% 835027
#% 907516
#% 946521
#% 954949
#% 1064771
#! The utility of an enterprise search system is determined by three key players: the information retrieval (IR) system (the search engine), the enterprise users, and the service provider who delivers the tailored IR service to its designated enterprise users. Currently, evaluations of enterprise search have been focused largely on the IR system effectiveness and efficiency, only a relatively small amount of effort on the user's involvement, and hardly any effort on the service provider's role. This paper will investigate the role of the service provider. We propose a method that evaluates the cost and benefit for a service provider of using a mediated search engine - in particular, where domain experts intervene on the ranking of the search results from a search engine. We test our cost and benefit evaluation method in a case study and conduct user experiments to demonstrate it. Our study shows that: 1) by making use of domain experts' relevance assessments in search result ranking, the precision and the discount cumulated gain of ranked lists have been improved significantly (144% and 40% respectively); 2) the service provider gains substantial return on investment and higher search success rate by investing in domain experts' relevance assessments; and 3) the cost and benefit evaluation also indicates the type of queries to be selected from a query log for evaluating an enterprise search engine.

#index 1213443
#* Document relevance assessment via term distribution analysis using fourier series expansion
#@ Patricio Galeas;Ralph Kretschmer;Bernd Freisleben
#t 2009
#c 14
#% 115608
#% 169806
#% 200694
#% 218992
#% 232677
#% 280850
#% 289079
#% 298183
#% 342963
#% 355154
#% 387427
#% 411760
#% 577301
#% 627788
#% 643028
#% 730007
#% 742513
#% 744786
#% 766424
#% 766464
#% 853854
#% 879612
#% 987229
#! In addition to the frequency of terms in a document collection, the distribution of terms plays an important role in determining the relevance of documents for a given search query. In this paper, term distribution analysis using Fourier series expansion as a novel approach for calculating an abstract representation of term positions in a document corpus is introduced. Based on this approach, two methods for improving the evaluation of document relevance are proposed: (a) a function-based ranking optimization representing a user defined document region, and (b) a query expansion technique based on overlapping the term distributions in the top-ranked documents. Experimental results demonstrate the effectiveness of the proposed approach in providing new possibilities for optimizing the retrieval process.

#index 1213444
#* How do you feel about "dancing queen"?: deriving mood & theme annotations from user tags
#@ Kerstin Bischoff;Claudiu S. Firan;Wolfgang Nejdl;Raluca Paiu
#t 2009
#c 14
#% 643010
#% 643027
#% 869608
#% 905319
#% 956515
#% 987205
#% 1017565
#% 1055704
#% 1055739
#% 1074117
#% 1112960
#% 1130827
#% 1190231
#! Web 2.0 enables information sharing, collaboration among users and most notably supports active participation and creativity of the users. As a result, a huge amount of manually created metadata describing all kinds of resources is now available. Such semantically rich user generated annotations are especially valuable for digital libraries covering multimedia resources such as music, where these metadata enable retrieval relying not only on content-based (low level) features, but also on the textual descriptions represented by tags. However, if we analyze the annotations users generate for music tracks, we find them heavily biased towards genre. Previous work investigating the types of user provided annotations for music tracks showed that the types of tags which would be really beneficial for supporting retrieval - usage (theme) and opinion (mood) tags - are often neglected by users in the annotation rocess. In this paper we address exactly this problem: in order to support users in tagging and to fill these gaps in the tag space, we develop algorithms for recommending mood and theme annotations. Our methods exploit the available user annotations, the lyrics of music tracks, as well as combinations of both. We also compare the results for our recommended mood / theme annotations against genre and style recommendations - a much easier and already studied task. Besides evaluating against an expert (AllMusic.com) ground truth, we evaluate the quality of our recommended tags through a Facebook-based user study. Our results are very promising both in comparison to experts as well as users and provide interesting insights into possible extensions for music tagging systems to support music search.

#index 1213445
#* Automatic quality assessment of content created collaboratively by web communities: a case study of wikipedia
#@ Daniel Hasan Dalip;Marcos André Gonçalves;Marco Cristo;Pável Calado
#t 2009
#c 14
#% 137257
#% 190581
#% 268079
#% 309095
#% 376266
#% 387309
#% 754117
#% 761334
#% 933558
#% 956520
#% 987245
#% 1019083
#% 1125907
#% 1558464
#% 1682183
#! The old dream of a universal repository containing all the human knowledge and culture is becoming possible through the Internet and the Web. Moreover, this is happening with the direct collaborative, participation of people. Wikipedia is a great example. It is an enormous repository of information with free access and edition, created by the community in a collaborative manner. However, this large amount of information, made available democratically and virtually without any control, raises questions about its relative quality. In this work we explore a significant number of quality indicators, some of them proposed by us and used here for the first time, and study their capability to assess the quality of Wikipedia articles. Furthermore, we explore machine learning techniques to combine these quality indicators into one single assessment judgment. Through experiments, we show that the most important quality indicators are the easiest ones to extract, namely, textual features related to length, structure and style. We were also able to determine which indicators did not contribute significantly to the quality assessment. These were, coincidentally, the most complex features, such as those based on link analysis. Finally, we compare our combination method with state-of-the-art solution and show significant improvements in terms of effective quality prediction.

#index 1213446
#* Designing the reading experience for scanned multi-lingual picture books on mobile phones
#@ Benjamin B. Bederson;Alex Quinn;Allison Druin
#t 2009
#c 14
#% 198056
#% 237329
#% 272925
#% 332740
#% 332757
#% 337490
#% 342528
#% 345349
#% 508265
#% 802858
#% 967281
#% 982625
#% 1047377
#% 1065283
#% 1065294
#! This paper reports on an adaption of the existing PopoutText and ClearText display techniques to mobile phones. It explains the design rationale for a freely available iPhone application to read books from the International Children's Digital Library. Through a combination of applied image processing, a zoomable user interface, and a process of working with children to develop the detailed design, we present an interface that supports clear reading of scanned picture books in multiple languages on a mobile phone.

#index 1213447
#* Mobility, digital libraries and a rural indian village
#@ Matt Jones;Emma Thom;David Bainbridge;David Frohlich
#t 2009
#c 14
#% 345349
#% 860071
#% 874738
#% 951913
#% 1077227
#! Millions of people in developed countries routinely create and share digital content; but what about the billions of others in on the wrong side of what has been called the 'global digital divide'? This paper considers three mobile platforms to illustrate their potential in enabling rural Indian villagers to make and share digital stories. We describe our experiences in creating prototypes using mobile phones; high-end media-players; and, paper. Interaction designs are discussed along with findings from various trials within the village and elsewhere. Our approach has been to develop prototypes that can work together in an integrated fashion so that content can flow freely and in interesting ways through the village. While our work has particular relevance to those users in emerging world contexts, we see it also informing needs and practices in the developed world for user-generated content.

#index 1213448
#* What do exploratory searchers look at in a faceted search interface?
#@ Bill Kules;Robert Capra;Matthew Banta;Tito Sierra
#t 2009
#c 14
#% 85443
#% 187999
#% 238524
#% 303510
#% 345591
#% 399056
#% 452641
#% 766472
#% 801383
#% 857477
#% 857478
#% 874715
#% 954948
#% 955306
#% 967314
#% 1039833
#% 1065248
#% 1065344
#! This study examined how searchers interacted with a web-based, faceted library catalog when conducting exploratory searches. It applied eye tracking, stimulated recall interviews, and direct observation to investigate important aspects of gaze behavior in a faceted search interface: what components of the interface searchers looked at, for how long, and in what order. It yielded empirical data that will be useful for both practitioners (e.g., for improving search interface designs), and researchers (e.g., to inform models of search behavior). Results of the study show that participants spent about 50 seconds per task looking at (fixating on) the results, about 25 seconds looking at the facets, and only about 6 seconds looking at the query itself. These findings suggest that facets played an important role in the exploratory search process.

#index 1213449
#* Aligning METS with the OAI-ORE data model
#@ Jerome P. McDonough
#t 2009
#c 14
#! The Open Archives Initiative - Object Reuse and Exchange (OAI-ORE) specifications provide a flexible set of mechanisms for transferring complex data objects between different systems. In order to serve as an exchange syntax, OAI-ORE must be able to support the import of information from localized data structures serving various communities of practice. In this paper, we examine the Metadata Encoding & Transmission Standard (METS) and the issues that arise when trying to map from a localized structural metadata schema into the OAI-ORE data model and serialization syntaxes.

#index 1213450
#* EverLast: a distributed architecture for preserving the web
#@ Avishek Anand;Srikanta Bedathur;Klaus Berberich;Ralf Schenkel;Christos Tryfonopoulos
#t 2009
#c 14
#% 58371
#% 225004
#% 287070
#% 340175
#% 342374
#% 505869
#% 571296
#% 674137
#% 754058
#% 859778
#% 874466
#% 963605
#% 978765
#% 987257
#% 1006337
#% 1022339
#% 1036079
#% 1053117
#% 1065256
#% 1113158
#% 1124069
#% 1127420
#% 1422719
#! The World Wide Web has become a key source of knowledge pertaining to almost every walk of life. Unfortunately, much of data on the Web is highly ephemeral in nature, with more than 50-80% of content estimated to be changing within a short time. Continuing the pioneering efforts of many national (digital) libraries, organizations such as the International Internet Preservation Consortium (IIPC), the Internet Archive (IA) and the European Archive (EA) have been tirelessly working towards preserving the ever changing Web. However, while these web archiving efforts have paid significant attention towards long term preservation of Web data, they have paid little attention to developing an global-scale infrastructure for collecting, archiving, and performing historical analyzes on the collected data. Based on insights from our recent work on building text analytics for Web Archives, we propose EverLast, a scalable distributed framework for next generation Web archival and temporal text analytics over the archive. Our system is built on a loosely-coupled distributed architecture that can be deployed over large-scale peer-to-peer networks. In this way, we allow the integration of many archival efforts taken mainly at a national level by national digital libraries. Key features of EverLast include support of time-based text search & analysis and the use of human-assisted archive gathering. In this paper, we outline the overall architecture of EverLast, and present some promising preliminary results.

#index 1213451
#* A framework for describing web repositories
#@ Frank McCown;Michael L. Nelson
#t 2009
#c 14
#% 504572
#% 772018
#% 869499
#% 874466
#% 907442
#% 1056495
#% 1065291
#! In prior work we have demonstrated that search engine caches and archiving projects like the Internet Archive's Wayback Machine can be used to "lazily preserve" website and reconstruct them when they are lost. We use the term "web repositories" for collections of automatically refreshed and migrated content, and collectively we refer to these repositories as the "web infrastructure". In this paper we present a framework for describing web repositories and the status of web resources in them. This includes an abstract API for web repository interaction, the concepts of deep vs. flat and light/dark/grey repositories and terminology of describing the recoverability of a web resource. Our API may serve as a foundation for future web repository interfaces.

#index 1213452
#* Preserving digital data in heterogeneous environments
#@ Gonçalo Antunes;José Barateiro;Manuel Cabral;José Borbinha;Rodrigo Rodrigues
#t 2009
#c 14
#% 159275
#% 496160
#% 938081
#% 960126
#% 1016620
#! Digital preservation aims at maintaining digital objects accessible over a long period of time, regardless of the challenges of organizational or technological changes or failures. In particular, data produced in e-Science domains could be reliably stored in today's data grids, taking advantage of the natural properties of this kind of infrastructure to support redundancy. However, to achieve reliability we must take into account failure interdependency. Taking into account the fact that correlated failures can affect multiple components and potentially cause complete loss of data, we propose a solution to evaluate redundancy strategies in the context of heterogeneous environments such as data grids. This solution is based on a simulation engine that can be used not only to support the process of designing the preservation environment and related policies, but also later on to observe and control the deployed system.

#index 1213453
#* Unsupervised creation of small world networks for the preservation of digital objects
#@ Charles L. Cartledge;Michael L. Nelson
#t 2009
#c 14
#% 31686
#% 300078
#% 332742
#% 337580
#% 340176
#% 342375
#% 345086
#% 433953
#% 446439
#% 508266
#% 508281
#% 610818
#% 760863
#% 795390
#% 813736
#% 834582
#% 859911
#% 872867
#% 879541
#% 967248
#% 1213453
#! The prevailing model for digital preservation is that archives should be similar to a "fortress": a large, protective infrastructure built to defend a relatively small collection of data from attack by external forces. Such projects are a luxury, suitable only for limited collections of known importance and requiring significant institutional commitment for sustainability. In previous research, we have shown the web infrastructure (i.e., search engine caches, web archives) refreshes and migrates web content in bulk as side-effects of their user-services, and these results can be mined as a useful, but passive preservation service. Our current research involves a number of questions resulting from removing the implicit assumption that web-based data objects must passively await curatorial services: What if data objects were not tethered to repositories? What are the implications if the content were actively seeking out and injecting itself into the web infrastructure (i.e., search engine caches, web archives)? All of this leads to our primary research question: Can we create objects that preserve themselves more effectively than repositories or web infrastructure can?

#index 1213454
#* Towards a virtual organization for data cyberinfrastructure
#@ Christine L. Borgman;Geoffrey C. Bowker;Thomas A. Finholt;Jillian C. Wallis
#t 2009
#c 14
#% 730976
#% 905354
#% 967283
#% 1021630
#! We report on the exploratory stages of multi-university, multi-research-site, multi-year effort to investigate and compare data practices in multiple cyberinfrastructure projects and their emerging virtual organizations. Our long-term goal is to understand the data practices and data management requirements of virtual organizations and their implications for the design and development of data digital libraries. We have constructed our own virtual organization as a participant-observer approach to the research. Results to date suggest that collaborative technologies are emergent and that defining and scoping the data products of collaborations continues to be problematic.

#index 1213455
#* Expanding the search for digital preservation solutions: adopting PREMIS in cultural heritage institutions
#@ Daniel Gelaw Alemneh
#t 2009
#c 14
#! This paper will present some preliminary result on factors that affect the adoption of PREMIS (Preservation Metadata Implementation Strategies) in cultural heritage institutions. The study employed a web-based survey to collect data from 123 participants in 20 countries as well as a semi-structured, follow-up telephone interview with a smaller sample of the survey respondents. Roger's diffusion of innovation theory was used as a theoretical framework. The main constructs considered for the study were relative advantage, compatibility, complexity, trialability, observability, and institution readiness. The study yielded both qualitative and quantitative data, and preliminary analysis showed that all six factors influence the adoption of PREMIS in varying degrees.

#index 1213456
#* Collaborative digital library: enhancing digital collections to improve learning in educational programs
#@ Ali Sajedi Badashian;Asghar Dehghani Firouzabadi;Iman Khalkhali;Hamidreza Afzali;Morteza Ashurzad Delcheh;Mohammad Shoja Shafiei;Mahdi Alipour
#t 2009
#c 14
#% 874479
#! In this article, a universal collaborative and competitive approach is introduced for deployment of digital collections in an ideal Digital Library (DL) for future's educational system. The collaborative and open-source aspects of the system guarantee its growth and the competitive aspects guarantee the accuracy.

#index 1213457
#* Digitizing the flea market: eBay as a data source for historic collections
#@ Snowden Becker
#t 2009
#c 14
#! The online auction site eBay has overtaken face-to-face transactions as the primary means of doing business for collectors and sellers of unique and ephemeral materials. Historical societies, museums, and archives also increasingly collect ephemera as records of social and cultural history. This presentation argues that the digitized flea market, as epitomized by eBay, replaces in-person sales while also providing a stream of rich information about a previously invisible, unquantifiable marketplace. Furthermore, identifying factors that influence collectibles buyers' behavior in online auction sales can also shed light on factors affecting user behaviors in digital libraries. Data from a survey of over 1,000 recent home movie auction listings on eBay suggest how eBay may be used as a data source by collectors, as well as the users and designers of digital libraries.

#index 1213458
#* Semantic alerting for digital libraries
#@ George Buchanan;Annika Hinze
#t 2009
#c 14
#% 337487
#% 809423
#% 874499
#% 1671626
#! We previously investigated the support of alerting services across networks of heterogeneous digital libraries. We now report the first generation of semantically enhanced digital library alerting systems. Where previous alerting services have provided users with notifications of new library content using traditional metadata, we demonstrate the advantages and challenges of using semantic technologies. This uncovers key issues that are not yet fully understood in general event-based systems (including alerting systems).

#index 1213459
#* Addressing researchers' needs through the data curation profile
#@ Jake Carlson;Deborah Leiter
#t 2009
#c 14
#! This poster describes a study currently in progress that seeks to identify and address the needs of researchers from multiple disciplines in managing, curating and preserving their data. One output of this study, which is still in its early stages, will be the "data curation profile," a methodological tool designed to enable the comparison of needs across disciplines and help librarians build digital libraries that accurately reflect and address the needs of data producers.

#index 1213460
#* Implementation and evaluation of palm leaf manuscript metadata schema (PLMM)
#@ Nisachol Chamnongsri;Lampang Manmart;Vilas Wuwongse
#t 2009
#c 14
#! The evaluation of Palm Leaf Manuscripts Metadata Schema (PLMM) aims to examine whether the PLMM satisfactorily meets the user requirements in searching for the PLMs and managing the PLMs collection. (1) An examination of the PLMM's capability in describing the particular characteristics of Northeastern Thai Palm Leaf Manuscripts, and its usefulness in the palm leave manuscripts preservation and rights control management (2) an investigation of users' satisfaction when using PLMM to search for the PLMs and managing the PLMs collection. The evaluation process began with the development of the prototype of PLMs management system to implement the PLMM. Then, more than 200 metadata records describing all types of sample PLMs (with variations in sizes, scripts, languages, titles, and number of content subjects contained in a fascicle) were provided in Extensible Markup Language (XML) format, while system interfaces and queries were developed with Hypertext Preprocessor (PHP). This was followed by the trials with end users and staff in their workplace in order to evaluate the usefulness of PLMM in user tasks according to the FRBR tasks: find, identify, select, and obtain; and collection development tasks. The research found that 'somewhat high' efficiency of the PLMM was perceived among the participants in the two tasks. The finding also suggests that perceived efficiency of the PLMM was significantly higher with more years of users' experience with the PLMs. The status of users is another factor which positively affected the perceived efficiency of the PLMM.

#index 1213461
#* A personalized learning environment
#@ Sebastian de la Chica;Faisal Ahmad;Qianyi Gu;Ifi Okoye;Keith Maull;Tamara Sumner;Kirsten R. Butcher
#t 2009
#c 14
#! We report on the current research activities and results obtained through the Concept Learning service for Concept Knowledge (CLICK) and present a demonstration of the system. This poster session will focus on a demonstration of the CLICK system and the results of the learning study

#index 1213462
#* Analysis of transaction logs for insights into use of life oral histories
#@ Michael G. Christel;Bryan S. Maher;Huan Li
#t 2009
#c 14
#% 1065271
#! A digital video library of over 900 hours of video and 18000 stories from The HistoryMakers was used by 214 students, faculty, librarians, and life-long learners interacting with a system providing multiple search and viewing capabilities over a trial period of several months. User demographics and actions were logged, providing metrics on how the system was used. This poster overviews a few highlights from these transaction logs of the Informedia digital video library system for life oral histories.

#index 1213463
#* Summarizing user-generated reviews in digital libraries: a visual clustering approach
#@ Wingyan Chung
#t 2009
#c 14
#! In this paper, we describe a visual clustering approach to summarizing user-generated reviews of digital library items and services. The approach consists of the steps of sentence extraction, aspect identification, opinion classification, and review summarization. Our work augments existing work by considering non-standard input and by incorporating clustering and visualization in summarization.

#index 1213464
#* An interoperability service framework for high-resolution image applications
#@ Ryan Chute;Stephan Dresher;Luda Balakireva;Herbert Van de Sompel
#t 2009
#c 14
#! This poster presents a prototype architecture and potential use-cases for a standards-based service framework to simplify development of high-resolution image viewing clients.

#index 1213465
#* Tailoring greenstone for seniors
#@ Sally Jo Cunningham;Erin K. Bennett
#t 2009
#c 14
#! We present a re-design of Greenstone to support seniors (aged over 65) in managing documents reflecting their life history.

#index 1213466
#* A mixed digital / physical snapshot of early internet / web usage in New Zealand
#@ Sally Jo Cunningham;Jillene Bydder
#t 2009
#c 14
#! We are in the early stages of developing a unique physical and digital record of New Zealand's early experience of the Internet.

#index 1213467
#* Mashing up life science literature resources
#@ Richard Easty;Nikolay Nikolov
#t 2009
#c 14
#% 964311
#% 1065337
#% 1114605
#! In the life sciences one of the pronounced problems is the deluge of new results and data that are produced on a daily basis. This data can take many different forms, e.g. microarray probes, gene sequences, protein structures and is added by hundreds of research centers world-wide in a largely uncoordinated fashion. Thus integration of life science data is growing in importance. Unfortunately, most research centers do not have particular incentive to spend efforts on integrating their data with data produced by others. This task is largely left to large publicly-sponsored institutions like the US National Library of Medicine and similar institutions in other countries. Unfortunately, despite their work in this area, the integration of web-based life science resources is still an open issue (and one ever growing in importance) as these organizations cannot cope with the information deluge that is happening on a daily basis in the life sciences. Thus it becomes essential that as many as possible third parties are engaged in the process. Here we demonstrate a simple prototype of a browser plugin that creates a platform for third parties to contribute to cross-linking related online life science data resources and thus improving the search experience and the productivity of the life science community. The plugin creates a convenient programming interface that minimizes the effort that arises for such third-party contributors. We have provided reference implementations using the plugin that cross-link life science literature resources and illustrate the potential for third parties to create mashups that could be applied also in areas other than the life sciences.

#index 1213468
#* Representing publication and distribution practices for scholarly materials: a cross-disciplinary comparison
#@ Phillip M. Edwards
#t 2009
#c 14
#% 872036
#! This poster presents a pluralistic approach for representing discipline-specific, cross-disciplinary, and discipline-independent work practices related to scholarly communication. This approach has been applied to qualitative analysis from an investigation of publication and distribution practices of scholars within the biological sciences and the field of communication. The resulting representations illustrate shared work practices and areas where diverse practices exist, both of which can guide the development of digital collections of scholarly materials. This poster also considers challenges related to aligning data collection methods with the application of these representational techniques.

#index 1213469
#* Inferring intra-organizational collaboration from cosine similarity distributions in text documents
#@ Maria Esteva;Hai Bi
#t 2009
#c 14
#% 46803
#! We present a method that uses text mining methods and statistical distributions to infer degrees of collaboration between staff members in an organization, based on the similarity of the documents that that they wrote and exchanged over time.

#index 1213470
#* Personal name-matching through name transformation
#@ Jun Gong;Lidan Wang;Douglas W. Oard
#t 2009
#c 14
#! A graph theory based method is proposed to exploit name transformation for personal name-matching. Experiment results on three personal name datasets show that the method is effective.

#index 1213471
#* EMU: the emory user behavior data management system for automatic library search evaluation
#@ Qi Guo;Ryan P. Kelly;Selden Deemer;Arthur Murphy;Joan A. Smith;Eugene Agichtein
#t 2009
#c 14
#! We describe EMU, a system for collecting, managing, and mining the behavior data collected in the Emory libraries search system. We describe the data capture system based on the LibX browser plugin, the database management system for successfully storing, searching and exploring millions of resulting user interactions, and preliminary results of interesting queries and statistics that we are using to evaluate the effectiveness of library search tools.

#index 1213472
#* Building a thailand researcher network based on a bibliographic database
#@ Choochart Haruechaiyasak;Alisa Kongthon;Santipong Thaiprayoon
#t 2009
#c 14
#% 879570
#% 956516
#% 1275180
#! Among many practical and domain-specific tasks, expertise retrieval (ER) has recently gained increasing attention in the information retrieval and knowledge management communities. This paper describes our ongoing project to design and implement an expert retrieval system with the scope on researchers who work in Thailand. In our current system prototype, we assume that the areas of expertise among researchers can be extracted from bibliographic databases. We use the Science Citation Index (SCI) database to provide the information for representing the expert profiles. From the SCI database, we queried and retrieved publications covering from the year 2001 to 2008 by specifying the affiliation equal to "Thailand". The results contain a set of approximately 23,000 publications. We downloaded and extracted four related fields including authors (denoted by AU), controlled terms (denoted by ID), keywords (denoted by DE) and subject category (denoted by SC). To build a researcher network, we consider two types of relationships: direct and indirect. The direct (or social) relationship is defined as the co-authoring degree between one researcher to others. The co-authoring degree between two researchers, co-authoring(A,B), can be calculated based on the co-occurrence frequency between A and B found in the field AU of 23,000 retrieved records. The indirect (or topical relationship is defined when two researchers have publications under the same topics. The topical degree between two researchers, topical(A,B), can be calculated based on the similarity measure between two sets of extracted keywords, keyword(A) and keyword(B), representing researcher A and B, respectively. The keyword set can be extracted from the fields ID, DE and SC. An author with high frequencies on particular keywords is considered an expert in the corresponding research topics.

#index 1213473
#* Building a MARC-to-OLAC crosswalk: repurposing library catalog data for the language resources community
#@ Christopher Hirt;Gary Simons;Joan Spanne
#t 2009
#c 14
#! The Open Language Archives Community (OLAC) is an international partnership of institutions which are building a network of interoperating repositories and services to create a worldwide virtual library of language resources (that is, resources that document, describe, or develop the more than 7,000 known languages of the world). OLAC uses a community-specific refinement of qualified Dublin Core [http://www.language-archives.org/OLAC/metadata.htm] along with a community-specific refinement of the OAI Protocol for Metadata Harvesting [http://www.language-archives.org/OLAC/repositories.htm] to maintain an aggregated catalog of the holdings of the 35 participating archives. OLAC recognizes that the language resources of interest to the community come not only from sources within the community but also from many sources outside the community. This poster describes one approach we have developed for addressing this issue, namely, a crosswalk that transforms the MARC21 catalog for a library or archive into an OAI static repository that holds an OLAC metadata record for each MARC record identified as describing a language resource.

#index 1213474
#* Locating text in scanned books
#@ Chang Hu;Anne Rose;Benjamin B. Bederson
#t 2009
#c 14
#% 1047377
#! In this paper, we describe a work flow to extract and verify text locations using commercial software, along with free software products and human proofing. To help mid-sized digital libraries, we are making our solution available as open source software.

#index 1213475
#* Remote usability testing: a practice
#@ Sheng-Cheng Huang;Randolph G. Bias;Tanya L. Payne;Jay B. Rogers
#t 2009
#c 14
#! For increasingly frequent use of library resources by remote users, remote usability testing has become a valuable tool for those who would pursue an empirical, user-centered design of the interfaces to their electronic resources and services. This paper describes our implementation of remote usability tests to evaluate prototypes of a web content management application developed by Vignette Corporation, and reports sample results to illustrate the utility of such an approach that can help designing and improving interfaces of digital library projects and their usability.

#index 1213476
#* Scientific digital libraries, interoperability, and ontologies
#@ J. Steven Hughes;Daniel J. Crichton;Chris A. Mattmann
#t 2009
#c 14
#% 790851
#! Scientific digital libraries serve complex and evolving research communities. Justifications for the development of scientific digital libraries include the desire to preserve science data and the promises of information interconnectedness, correlative science, and system interoperability. Research [1] suggests single shared ontologies are fundamental to fulfilling these promises. We present a tool framework, a set of principles, and a real world case study where shared ontologies are used to develop and manage science information models and subsequently guide the implementation of scientific digital libraries. The tool framework, based on an ontology modeling tool as illustrated in Figure 1, was configured to develop, manage, and keep shared ontologies relevant within changing domains and to promote the interoperability, interconnectedness, and correlation desired by scientists.

#index 1213477
#* The landscape of information science: 1996-2008
#@ Fidelia Ibekwe-SanJuan;Eric SanJuan
#t 2009
#c 14
#% 889881
#! We propose a methodology combining symbolic and numeric information to map the structure of research in Information Science between 1996-2008. The visualization of the resulting maps showed that while the two-camp structure of Information Science observed in previous studies is still valid, other research poles like web and user-oriented studies are building bridges between the two hitherto isolated poles.

#index 1213478
#* Forging the future: new tools for variable media art preservation
#@ Jon Ippolito;Richard Rinehart;Marilyn Lutz;Sharon Fitzgerald
#t 2009
#c 14

#index 1213479
#* Analyzing OPAC use with screen views and eye tracking
#@ Emi Ishita;Shinji Mine;Masanori Koizumi;Yosuke Miyata;Chihiro Kunimoto;Junko Shiozaki;Keiko Kurata;Shuichi Ueda
#t 2009
#c 14
#% 967258
#% 1053505
#! Eye tracking was used to analyze which elements of which screens were viewed by users searching an Online Public Access Catalog (OPAC). Eye tracking data was obtained for 32 participants performing a known-item search task. The results show that more than 30% of participants did not make effective use of screens offering additional details, and that participants who did, and found the correct answer, gazed at specific screen elements more frequently than participants who gave incorrect answers.

#index 1213480
#* A user-friendly metadata quality control tool for the internet public library
#@ Michael Khoo;Xia Lin;Jung-ran Park
#t 2009
#c 14
#% 508408
#% 1069027
#! The Internet Public Library (IPL) is crosswalking its metadata to Dublin Core. The quality of the crosswalked metadata will be unknown. The IPL is therefore developing a tool for metadata quality control suitable for use by LIS students who have little previous metadata quality control experience.

#index 1213481
#* Using an institutional repository for personal digital collections of retired faculty members
#@ Sarah Kim
#t 2009
#c 14
#! In this poster, I address practical issues related to using IRs for personal digital collections of retired faculty members.

#index 1213482
#* Exploitation of the wikipedia category system for enhancing the value of LCSH
#@ Yoji Kiyota;Hiroshi Nakagawa;Satoshi Sakai;Tatsuya Mori;Hidetaka Masuda
#t 2009
#c 14
#! This paper addresses an approach that integrates two different types of information resources: the Web and libraries. Our method begins from any keywords in Wikipedia, and induces related subject headings of LCSH through the Wikipedia category system.

#index 1213483
#* Inter-search engine lexical signature performance
#@ Martin Klein;Michael L. Nelson
#t 2009
#c 14
#% 735137
#% 781168
#! We generate lexical signatures (LSs) from web pages and acquire the mandatory document frequency values from three dierent search engine (SE) indexes. We cross-query the LSs against the two SEs they were not generated from and compare the retrieval performance by parsing the result set and analyzing the rank of the source URL.

#index 1213484
#* Correlation of music charts and search engine rankings
#@ Martin Klein;Olena Hunsicker;Michael L. Nelson
#t 2009
#c 14
#% 309151
#% 1215442
#! We investigate the question whether expert rankings of real-world entities correlate with search engine (SE) rankings of corresponding web resources. We compare Billboards "Hot 100 Airplay" music charts with SE rankings of associated web resources. Out of nine comparisons we found two strong, two moderate, two weak and one negative correlation. The remaining two comparisons were inconclusive.

#index 1213485
#* Toward automatic generation of image-text document surrogates to optimize cognition
#@ Eunyee Koh;Andruid Kerne;Jon Moeller
#t 2009
#c 14
#% 1095879
#! The representation of information collections needs to be optimized for human cognition. Growing information collections play a crucial role in human experiences. While documents often include rich visual components, collections, including personal collections and those generated by search engines, are typically represented lists of text-only surrogates. By concurrently invoking complementary components of human cognition, combined image-text surrogates help people to more effectively see, understand, think about, and remember information collection. This research develops algorithmic methods that use the structural context of images in HTML documents to associate meaningful text and thus derive combined image-text surrogates.

#index 1213486
#* Designing exploratory search tasks for user studies of information seeking support systems
#@ Bill Kules;Robert Capra
#t 2009
#c 14
#% 857477
#! This poster describes a procedure for designing exploratory tasks for use in laboratory evaluations of information seeking interfaces. This procedure is grounded in the literature on information seeking and information retrieval and has been refined by an evaluation of four tasks designed for a study of a faceted library catalog. The procedure is intended to be extensible to generate exploratory tasks for other types of interfaces and domains.

#index 1213487
#* Developing a review rubric for learning resources in digital libraries
#@ Heather Leary;Sarah Giersch;Andrew Walker;Mimi Recker
#t 2009
#c 14
#% 1213487

#index 1213488
#* From harvesting to cultivating: transformation of a web collecting system into a robust curation environment
#@ Christopher A. Lee;Richard Marciano;Chien-yi Hou;Chirag Shah
#t 2009
#c 14
#! Much has been written about the lifecycle of digital objects. This study is instead concerned with the lifecycle of collections and associated services. Online collection environments are built to fulfill specific collecting objectives and constraints. If a collection proves useful within its original hosting environment, it will often be necessary or desirable to move the collection to new environments, in order to support new forms of use and re-aggregation or extract resources from legacy data environments. Such a transformation can be extremely expensive, challenging and prone to error, especially if the collections include complex internal structures and services. When "services make the repository" [1], moving raw data from one location to another will often not be sufficient. Digital curators can pre-empt costly and problematic system migration efforts by integrating collections into environments specifically designed to support long-term preservation, scalability and interoperability [2]. We report on an integration of content and functionality of a feature-rich collecting environment (ContextMiner) into a robust data curation environment (iRODS). ContextMiner is a web-based service for building collections, through the execution and management of "campaigns" (i.e. sets of associated queries and parameters to harvest content over time). As a part of the VidArch project, we have been using the ContextMiner framework and services for harvesting YouTube videos and associated contextual information on a variety of topics. In July 2008, we released a public beta of ContextMiner, allowing anyone to run similar crawls. There are now more than 100 users. The current implementation - based on a single MySQL database and associated code - has served its intended purposes very well, but it is not a scalable or sustainable basis for offering wide-scale collecting services in support of the diverse array of potential users and use cases. iRODS (integrated Rule-Oriented Data System), is adaptive policy-driven data grid middleware, which addresses aspects of growth, evolution, openness, and closure - fundamental requirements for digital preservation [3]. iRODS currently scales to hundreds of millions of files, tens of thousands of users, and petabytes of data. It operates in a highly distributed environment with heterogeneous storage resources and allows for growth through federation. It supports evolution through the virtualization of the underlying technology and supports changing business requirements through customization of repository behaviors. It supports openness through a data type agnostic treatment of content. iRODS can be instrumented with policies that support the management of the lifecycle of digital assets and will serve as a unique platform to study repository integration. One key feature is the automation of policy enforcement across distributed data that have been organized into a shared collection. The coupling of other open repositories and iRODS can create greater efficiencies and new types of repository services. We discuss various repository integration scenarios, their potential benefits, and implications for collection life cycles. The approaches co-locate metadata and content in varied ways and rely on efficiencies found in one repository only, or on the ability to combine policies in both spaces: (1) iRODS to ContexMiner data migration, (2) Policy-based data management for ContextMiner collections, and (3) Policy interchange between ContextMiner and iRODS collections.

#index 1213489
#* A semi-automatic system for managing multiple digital preservation risks of digital libraries in china
#@ Chao Li;Chunxiao Xing;Li Dong;Michael Bailou Huang
#t 2009
#c 14
#! While many research projects in the world have been addressing challenges posed by digital preservation, digital libraries in China have their own native problems that have never been addressed before. Similar problems may occur in other countries, and their memory institutions may be less prepared to handle them. This poster analyses the requirements and challenges of digital libraries in China and describes an integrated and flexible digital preservation system -- AOMS.

#index 1213490
#* What patrons want: supporting interaction for novice information seeking scholars
#@ Fernando Loizides;George R. Buchanan
#t 2009
#c 14
#% 240744
#% 438557
#% 1914893
#! In this paper, we undertake a study of inexperienced information seeking scholars, identifying areas for improvement in their electronic information seeking and document triage process[3]. We propose a software aid, currently under development.

#index 1213491
#* Selective harvesting of regional digital libraries and national metadata aggregators
#@ Cezary Mazurek;Marcin Mielnicki;Marcin Werla
#t 2009
#c 14
#! The poster presents the concept, implementation and practical application of the OAI-PMH protocol extension which allows OAI-PMH service providers to dynamically create and harvest sets of items from OAI-PMH data providers. The implementation of the presented concept is based on the encoding of dynamic set specifications in OAI-PMH requests with the CQL language. The extension was developed and widely applied in Poland and now it is used in several projects funded by the European Commission.

#index 1213492
#* User search behaviors within a library gateway
#@ William H. Mischo;Mary C. Schlembach;Michael A. Norman
#t 2009
#c 14
#! This poster reports on user searching behavior within two information gateways developed at the University of Illinois at Urbana-Champaign Library. These gateways are built around a locally developed metasearch engine and are designed to assist users with search query formulation and modification. Search behavior data is being collected in custom transaction logs that gather user search arguments along with any system actions and contextual search assistance suggestions.

#index 1213493
#* Users' adjustments to unsuccessful queries in biomedical search
#@ G. Craig Murray;Jimmy Lin;John Wilbur;Zhiyong Lu
#t 2009
#c 14
#! Biomedical researchers depend on on-line databases and digital libraries for up to date information. We introduce a pilot project aimed at characterizing adjustments made to biomedical queries that improve search results. Specifically we focus on queries submitted to PubMed®, a large sophisticated search engine that facilitates Web access to abstracts of articles in over 5,200 biomedical journals. On average 2 million users search PubMed each day. During their search, nearly 20% will experience a result page from one of their queries that has zero results. In some cases there really is no document or abstract that will satisfy a particular query. However, in analyzing one month of queries submitted to PubMed, we find that more often than not, queries that retrieved no results are queries that would retrieve something relevant if they were constructed differently. This paper describes a new effort to identify some of the characteristics of a query that produces zero results, and the changes that users most often apply in constructing new, "corrected" queries. Zero-result queries afford us an opportunity to examine changes made to queries that we know did not return relevant data, because they did not return any data. An investigation of the changes users make under these circumstances can yield insight into users' search processes.

#index 1213494
#* Species identification: fish images with CBIR and annotations
#@ Uma Murthy;Edward A. Fox;Yinlin Chen;Eric Hallerman;Ricardo Torres;Evandro J. Ramos;Tiago R.C. Falcao
#t 2009
#c 14

#index 1213495
#* Kindle usage among LIS students: an exploratory study
#@ Debbie L. Rabina;Maria Cristina Pattuelli
#t 2009
#c 14

#index 1213496
#* Metababble: a clash of metadata cultures
#@ Monica Rivero;Geneva Henry
#t 2009
#c 14
#! A tension exists between making digitized resources available to users quickly and providing detailed, item-level metadata and semantic markup that make those resources more discoverable. The Our Americas Archive Partnership (OAAP) project, funded by IMLS in the fall of 2007, is facing these challenges as the project progresses. This poster presents a summary of our approach and future thoughts about descriptive approaches for digital resources.

#index 1213497
#* Evaluation of OAI-ORE via large-scale information topology visualization
#@ Robert Sanderson;Clare Llewellyn;Richard Jones
#t 2009
#c 14
#! This poster evaluates the OAI-ORE specifications through experiments providing access to the JSTOR digital archive and the Flickr website. A browser-based dynamic graph visualization tool was designed and tested to determine if making the topology of the information available would provide end-user benefits in terms of navigation and discovery.

#index 1213498
#* Empirical analysis on chinese academic plagiarism
#@ Yang Shen;Huijuan Fu;Zitao Liu;Pengpeng Liu;Qingchuan Fu
#t 2009
#c 14
#! This poster, from angels of subjects, authors' social network, authors' combination, and students' plagiarism law, apply self-developed ROST Anti-plagiarism Software to check 3781 papers, do a survey among 450 students, quantitatively analyzed academic plagiarism conditions in China, and draw several conclusions.

#index 1213499
#* Adaptive personalized eLearning on top of existing LCMS
#@ Naimdjon Takhirov;Ingeborg T. Sølvberg
#t 2009
#c 14
#% 536383
#! The next generation of eLearning systems should tailor the learning experience to each individual's learning needs and preferences. PEDAL-NG is a system that supports personalization in an existing, operational eLearning environment, based on prior knowledge and the learning style of users. It is built as a front-end of an existing LMS. The prototype is tested by a group of students. The test results are favorable regarding the personalized course and give valuable feedback for future research.

#index 1213500
#* User search characteristics on a specialized digital collection fordomain- and task-specific information
#@ Xiaoya Tang
#t 2009
#c 14
#% 876540
#% 947827
#% 1043041
#! Domain-specialized digital collections have been growing rapidly in recent years. A good understanding of how users interact with such collections to accomplish domain-specific information tasks would help inform the design of effective systems. This study investigates users' interaction with a Web-based botanical collection by examining search logs recorded during an experiment. The findings indicate that while users' interactions with such collections demonstrate similar characteristics to those with general purpose search systems, they also demonstrate a domain- and task-specific nature.

#index 1213501
#* MetRe: supporting the metadata revision process
#@ Emma Tonkin
#t 2009
#c 14
#% 1065262
#! MetRe is a prototype interface and service designed to support the metadata revision process. Improving consistency of metadata records within an environment is a common repository management task, due to potential for user error when submitting, as well as of other sources of error, such as systematic error resulting from the chosen deposit process. Evidence to support the metadata correction process may be gathered by automated metadata extraction tools, evidence from within the repository, or by comparison with best practice across the repository landscape. MetRe (Metadata Revision) is a prototype demonstrator that is able to identify several characteristic classes of error, twinned with an interface able to highlight several types of individual and systematic error, including a notion of local (intra-repository) and general (inter-repository) best practice.

#index 1213502
#* Finding centuries-old hyperlinks with a novel semi-supervised learning technique
#@ Xiaoyue Wang;Eamonn Keogh
#t 2009
#c 14
#% 952732
#! Hyperlinks are so useful for searching and browsing modern digital collections that researchers have longer wondered if it is possi-ble to retroactively add hyperlinks to digitized historical documents. There has already been significant research into this endeavor for historical text; however, in this work we consider the problem of adding hyperlinks among graphic elements. While such a system would not have the ubiquitous utility of text-based hyperlinks, there are several domains where it can potentially significantly augment textual information.

#index 1213503
#* Journal ranking based on social information
#@ Jinlong Wang;Ke Gao;Yongli Ren;Gang Li
#t 2009
#c 14
#% 1269909
#! Recently, literature analysis has become a hot issue in academic studies. In order to quantify the importance of journals and provide researchers with target vehicles for their work, this poster proposes a novel approach based on the social information through considering the potential relationship between journals quality and authors' affiliation. Based on the formula proposed in this work, the importance of journals can be estimated and ranked.

#index 1213504
#* The variety of ways in which instructors implement a modular digital library curriculum
#@ Barbara M. Wildemuth;Jeffrey P. Pomerantz;Sanghee Oh;Seungwon Yang;Edward A. Fox
#t 2009
#c 14
#! With support from the National Science Foundation, researchers at Virginia Tech and the University of North Carolina developed a curriculum framework and a number of modules for instruction in the area of digital libraries. In 2008, 15 different modules were field tested by 11 instructors at 10 different institutions. As might be expected, instructors adapted these modules to fit the context of their courses, some of which are described here.

#index 1213505
#* GRE: hybrid recommendations for NSDL collections
#@ Todd C. Will;Anand Srinivasan;Michael Bieber;Il Im;Vincent Oria;Yi-Fang (Brook) Wu
#t 2009
#c 14
#! Recommendation systems have been proven to reduce the time and effort required by users to find relevant items, but there are only sporadic reports on their application in digital libraries. The General Recommendation Engine (GRE) is composed of the text search system Lucene augmented by the well-understood content based and collaborative filtering techniques and the first application of knowledge based recommendation in digital libraries to recommend items from 22 National Science Digital Library collections. In this study comprised of 60 subjects, the GRE outperformed the baseline system Lucene in all areas of evaluation.

#index 1213506
#* Archiving the videogame industry: collecting primary materials of new media artifacts
#@ Megan A. Winget
#t 2009
#c 14
#! This paper describes the initial deposits in The Videogame Archive at the Center for American History at the University of Texas at Austin.

#index 1213507
#* Analyzing user's book-loan behaviors in Peking university library from social network perspective
#@ Fei Yan;Ming Zhang;Tao Sun;Yang Lu;Naiyue Zhang;Long Xiao
#t 2009
#c 14
#! In a university library, students from different background are connected by co-borrowing behaviors which form a knowledge sharing network. This poster presents a novel idea to study the users' book-loan behavior patterns (knowledge sharing patterns) from the social network perspective which enable us to understand the patterns in both the macro-level and micro-level analysis.

#index 1213508
#* An ajax-based digital music stand for greenstone
#@ David Bainbridge;Tim C. Bell
#t 2009
#c 14
#! This extended abstract describes a digital music stand integrated with the Greenstone digital library software. It features text annotation and an animated fast-to-slow page wipe. Figure 1 illustrates both these features, although it is best appreciated in a live demonstration. Digital annotation provides a non-destructive alternative to a musician's habit of penciling in notes. In Figure 1, slightly over half way down the page, there is a note to watch the fingering. A user can have as many of these as they like, positioned anywhere on the page. The animated page wipe alleviates (somewhat) the issue of when to turn to the next page. Unlike its physical counterpart, where turning to the next page means you can no longer see the current page, with a digital music stand the next page can gradually be overlaid. The page transition occurring in Figure 1 can be seen as a marked horizontal bar not quite half-way down the page. The speed of the wipe is initially fast, but when it reaches the point where the scroll-bar marker is on the right-hand side of the page, it slows down significantly. This is to give the musician time to finishing playing the last line of the current page. In the event they have already finished playing that line, they will have naturally moved on to playing the top of the next page (which is already displayed). Rather than adopt a traditional client-side "helper" application for the digital music stand, we have integrated it within Greenstone using AJAX. For instance: next and previous pages are asynchronously loaded in the background; when generating a page, the dimensions of the user's screen is sent to the DL server so it can produce a version that maximizes the available space; and interactions such as adding an annotation, or altering the position of the animation-break are immediately stored as metadata associated with that document. Initially the animated page breaks are set to be between the last two staff systems. This is accomplished as part of the DL ingest process, leveraging off the staff detection step of Optical Music Recognition software.

#index 1213509
#* Accessing the densho and historymakers oral history collections via informedia technologies
#@ Michael G. Christel;Robert V. Baron;Geoff Froh;Dan Benson;Julieanna Richardson
#t 2009
#c 14
#% 874485
#% 1055317
#% 1065271
#! Densho is a nonprofit organization started in 1996 with the goal of documenting oral histories from Japanese Americans who were incarcerated during World War II. The HistoryMakers is a nonprofit established in 1999 with the goal of documenting video life oral history interviews highlighting the accomplishments of individual African Americans and African-American-led groups and movements. Both collections share the goal of broader, deeper use of the oral history content through digitization and automated processing where appropriate. This demonstration showcases the application of Carnegie Mellon Informedia digital video library processing and interfaces to enhance access into the interview segments.

#index 1213510
#* Text mining for indexing
#@ Judith Gelernter;Michael Lesk
#t 2009
#c 14
#% 1016363
#% 1024568
#! This paper describes techniques for automatically extracting and classifying maps found within articles. The process uses image analysis to find text in maps, document structure to find captions and titles, and then text mining to assign each map to a subject category, a geographical place, and a time period. The text analysis is based on authority lists taken from gazetteers and from library classifications.

#index 1213511
#* Our Americas archive partnership demonstration
#@ Geneva Henry;Monica Rivero
#t 2009
#c 14
#! The Our Americas Archive Partnership (OAAP) project is in year 2 of a 3-year IMLS funded grant led by Rice University in Partnership with the University of Maryland's Maryland Institute for Technology in the Humanities (MITH). Designed to meet the needs of American studies scholars researching the Americas from a hemispheric perspective, OAAP is developing an integrated framework for the discovery of digital resources that are managed in heterogeneous distributed repositories. This demonstration will show the current state of the project's common interface to support resource discovery.

#index 1213512
#* Mapping life events: temporal and geographic context for biographical information
#@ Ray R. Larson;Ryan Shaw
#t 2009
#c 14
#% 1065315
#! Digital Libraries often fail to connect their contents to the wider context of information resources available that are about the same persons, related persons, places, or time periods and the events that happen to those persons, at those places and in a given time period. This demostration will show prototype systems that can perform these tasks, linking the user to relevant contextual information.

#index 1213513
#* Virtual DL poster sessions in second life
#@ Spencer J. Lee;Edward A. Fox;Gary Marchionini;Javier Velacso;Gonçalo Antunes;José Borbinha
#t 2009
#c 14
#% 1070520
#! In Second Life (SL), a popular general-purpose 3D virtual world, we are supporting the Digital Library community in a variety of ways, including through virtual poster sessions. This brings together the interests of those involved in JCDL 2009, IEEE-TCDL, and NSF-supported work in SL aimed to assist education, training, and dissemination in the digital preservation area.

#index 1213514
#* ContextMiner: building context-rich digital collections
#@ Chirag Shah
#t 2009
#c 14

#index 1213515
#* Using university collections in digital library education
#@ Quinn Stewart;David Todd
#t 2009
#c 14

#index 1213516
#* A curriculum customization service
#@ Tamara Sumner;Holly Devaul;Lynne Davis;John Weatherley
#t 2009
#c 14
#! We demonstrate a prototype Curriculum Customization Service designed and developed with significant teacher input. This prototype illustrates a model for embedding digital library resources into mainstream classroom use. A 10 week pilot study suggests that this Service can increase teachers' use of digital library resources in their class, and encourage them to use resources to customize instruction.

#index 1213517
#* XEB: a markup language document container format suitable for handheld devices
#@ Zhi Tang;Liangcai Gao;Aixia Jia;Xiaofan Lin
#t 2009
#c 14
#! We propose a new document container format (XEB, eXtensible Electronic Book) based on block mechanism to efficiently process markup language documents in handheld devices. And random document access is also supported in the format through a pagination mechanism. The format has already been applied to a number of handheld devices' Chinese E-book readersand XEB documents can be downloaded from a Chinese E-book store.

#index 1213518
#* AskDragon: a redundancy-based factoid question answering system with lightweight local context analysis
#@ Xiaohua Zhou;Palakorn Achananuparp;E. K. Park;Xiaohua Hu;Xiaodan Zhang
#t 2009
#c 14
#! We introduce our QA system AskDragon which employs a novel lightweight local context analysis technique to handling two broad classes of factoid questions, entity and numeric questions. The local context analysis module dramatically improves the efficiency of QA systems without sacrificing high accuracy performance.

#index 1213519
#* Knowledge extraction and integration for semi-structural information in digital libraries
#@ Wenhao Zhu;Baogang Wei;Jiangqin Wu;Shaomin Shi;Yan Yang
#t 2009
#c 14

#index 1434120
#* Proceedings of the 10th annual joint conference on Digital libraries
#@ Jane Hunter;Carl Lagoze;Lee Giles;Yuan-Fang Li
#t 2010
#c 14
#! Welcome to JCDL 2010! As a participant in the digital library community for more than a decade, I am delighted and proud to be the program chair of the 10th Annual Joint Conference on Digital Libraries. For the past decade, JCDL has continued to mature and maintain its position as the premier international forum for research and practice in the dynamic and multidisciplinary field of digital library research. I'm happy to report that the papers and presentations that form the basis of this year's conference continue to exemplify both the breadth and depth of the field and the superb scholarship taking place within it. The theme of JCDL 2010, "Digital Libraries -- 10 Years Past, 10 Years Forward, A 2020 Vision", addresses both the historical legacy of this conference and the challenges that lie ahead as the technical, cultural, political, and social contexts in which the field is situated continue to change. During the past 10 years, we have witnessed dramatic changes in the broader information context and in our perception of the nature of information and the institutions responsible for its dissemination, management, and preservation. The World Wide Web, the development of which is coincident with the history of digital libraries as a research area, has dramatically evolved from a read-only document space to a semantically rich, participatory and dynamic global database. This rate of change will only accelerate. The positioning of digital libraries and the institutional and technical models that they embody in this volatile context is an area that we as a community must address. I look forward to seeing the next decade unfold as we define this position and contribute to the networked information context. This JCDL has a number of "firsts." It is the first JCDL held outside of North America, moving literally almost halfway across the world to the Gold Coast of Australia. This is an exciting opportunity for more international participation in the conference and the inevitable cross-fertilization of ideas resulting from that. In addition, this is the first JCDL to be held in conjunction with ICADL, the International Conference on Asian Digital Libraries. There will be ample opportunity for mixing of conference attendees and I look forward to the possibility of new research collaborations that cross and investigate cultural boundaries. The authors of the papers that were selected by the program committee for presentation at the conference should be very proud of their achievement. This 2010 version maintains the competitive nature of JCDL, with 110 long papers submitted and 32 accepted. This computes to an acceptance rate of around 29%. The acceptance rate for short papers was equally competitive with 13 of 45 papers accepted. While there are a number of familiar names (to me) amongst the authors of the accepted papers, it is exciting to see the number of new, young researchers entering the field and look forward to their fresh perspectives. Mixed in with the presentations of these papers, the conference program includes excellent keynote speakers and panels, both of which we have designed to challenge existing assumptions and provoke new questions and thinking. Like any research field, the future of digital libraries as an active intellectual context depends on facing these challenges and, as a community, shifting course when necessary.

#index 1434121
#* Making web annotations persistent over time
#@ Robert Sanderson;Herbert Van de Sompel
#t 2010
#c 14
#% 237318
#% 249090
#% 301777
#% 309724
#% 325002
#% 402076
#% 878626
#% 997475
#% 1211586
#% 1728181
#% 1914908
#! As Digital Libraries (DL) become more aligned with the web architecture, their functional components need to be fundamentally rethought in terms of URIs and HTTP. Annotation, a core scholarly activity enabled by many DL solutions, exhibits a clearly unacceptable characteristic when existing models are applied to the web: due to the representations of web resources changing over time, an annotation made about a web resource today may no longer be relevant to the representation that is served from that same resource tomorrow. We assume the existence of archived versions of resources, and combine the temporal features of the emerging Open Annotation data model with the capability offered by the Memento framework that allows seamless navigation from the URI of a resource to archived versions of that resource, and arrive at a solution that provides guarantees regarding the persistence of web annotations over time. More specifically, we provide theoretical solutions and proof-of-concept experimental evaluations for two problems: reconstructing an existing annotation so that the correct archived version is displayed for all resources involved in the annotation, and retrieving all annotations that involve a given archived version of a web resource.

#index 1434122
#* Transferring structural markup across translations using multilingual alignment and projection
#@ David Bamman;Alison Babeu;Gregory Crane
#t 2010
#c 14
#% 284883
#% 378507
#% 557187
#% 579944
#% 740915
#% 760835
#% 816082
#% 817596
#% 828568
#% 854846
#% 874456
#% 874470
#% 1270223
#% 1271719
#% 1275639
#% 1292487
#% 1299495
#% 1369580
#% 1431357
#% 1682016
#% 1688064
#% 1914870
#! We present here a method for automatically projecting structural information across translations, including canonical citation structure (such as chapters and sections), speaker information, quotations, markup for people and places, and any other element in TEI-compliant XML that delimits spans of text that are linguistically symmetrical in two languages. We evaluate this technique on two datasets, one containing perfectly transcribed texts and one containing errorful OCR, and achieve an accuracy rate of 88.2% projecting 13,023 XML tags from source documents to their transcribed translations, with an 83.6% accuracy rate when projecting to texts containing uncorrected OCR. This approach has the potential to allow a highly granular multilingual digital library to be bootstrapped by applying the knowledge contained in a small, heavily curated collection to a much larger but unstructured one.

#index 1434123
#* ProcessTron: efficient semi-automated markup generation for scientific documents
#@ Guido Sautter;Klemens Böhm;Conny Kühne;Tobias Mathäß
#t 2010
#c 14
#% 451429
#% 740916
#% 744539
#% 750565
#% 1041854
#% 1914888
#! Digitizing legacy documents and marking them up with XML is important for many scientific domains. However, creating comprehensive semantic markup of high quality is challenging. Respective processes consist of many steps, with automated markup generation and intermediate manual correction. These corrections are extremely laborious. To reduce this effort, this paper makes two contributions: First, it proposes ProcessTron, a lightweight markup-process-control mechanism. ProcessTron assists users in two ways: It ensures that the steps are executed in the appropriate order, and it points the user to possible errors during manual correction. Second, ProcessTron has been deployed in real-world projects, and this paper reports on our experiences. A core observation is that ProcessTron more than halves the time users need to mark up a document. Results from laboratory experiments, which we have conducted as well, confirm this finding.

#index 1434124
#* Scholarly paper recommendation via user's recent research interests
#@ Kazunari Sugiyama;Min-Yen Kan
#t 2010
#c 14
#% 124010
#% 173879
#% 220708
#% 220709
#% 220711
#% 266281
#% 309095
#% 314933
#% 406493
#% 415107
#% 578684
#% 642616
#% 679872
#% 754126
#% 760853
#% 818207
#% 818259
#% 881537
#% 881540
#% 961613
#% 987245
#% 1019124
#% 1074131
#% 1155623
#% 1190124
#% 1213432
#% 1227622
#% 1392484
#% 1650569
#! We examine the effect of modeling a researcher's past works in recommending scholarly papers to the researcher. Our hypothesis is that an author's published works constitute a clean signal of the latent interests of a researcher. A key part of our model is to enhance the profile derived directly from past works with information coming from the past works' referenced papers as well as papers that cite the work. In our experiments, we differentiate between junior researchers that have only published one paper and senior researchers that have multiple publications. We show that filtering these sources of information is advantageous -- when we additionally prune noisy citations, referenced papers and publication history, we achieve statistically significant higher levels of recommendation accuracy.

#index 1434125
#* Effective self-training author name disambiguation in scholarly digital libraries
#@ Anderson A. Ferreira;Adriano Veloso;Marcos André Gonçalves;Alberto H.F. Laender
#t 2010
#c 14
#% 152934
#% 197394
#% 375017
#% 376266
#% 387427
#% 760866
#% 804877
#% 805885
#% 809459
#% 809460
#% 810635
#% 874458
#% 907508
#% 915347
#% 937552
#% 957814
#% 967295
#% 1015618
#% 1020797
#% 1090229
#% 1133176
#% 1211086
#% 1213413
#% 1213414
#% 1274820
#% 1549965
#% 1663664
#! Name ambiguity in the context of bibliographic citation records is a hard problem that affects the quality of services and content in digital libraries and similar systems. Supervised methods that exploit training examples in order to distinguish ambiguous author names are among the most effective solutions for the problem, but they require skilled human annotators in a laborious and continuous process of manually labeling citations in order to provide enough training examples. Thus, addressing the issues of (i) automatic acquisition of examples and (ii) highly effective disambiguation even when only few examples are available, are the need of the hour for such systems. In this paper, we propose a novel two-step disambiguation method, SAND (Self-training Associative Name Disambiguator), that deals with these two issues. The first step eliminates the need of any manual labeling effort by automatically acquiring examples using a clustering method that groups citation records based on the similarity among coauthor names. The second step uses a supervised disambiguation method that is able to detect unseen authors not included in any of the given training examples. Experiments conducted with standard public collections, using the minimum set of attributes present in a citation (i.e., author names, work title and publication venue), demonstrated that our proposed method outperforms representative unsupervised disambiguation methods that exploit similarities between citation records and is as effective as, and in some cases superior to, supervised ones, without manually labeling any training example.

#index 1434126
#* Citing for high impact
#@ Xiaolin Shi;Jure Leskovec;Daniel A. McFarland
#t 2010
#c 14
#% 268079
#% 290830
#% 937549
#% 956541
#! The question of citation behavior has always intrigued scientists from various disciplines. While general citation patterns have been widely studied in the literature we develop the notion of citation projection graphs by investigating the citations among the publications that a given paper cites. We investigate how patterns of citations vary between various scientific disciplines and how such patterns reflect the scientific impact of the paper. We find that idiosyncratic citation patterns are characteristic for low impact papers; while narrow, discipline-focused citation patterns are common for medium impact papers. Our results show that crossing-community, or bridging citation patters are high risk and high reward since such patterns are characteristic for both low and high impact papers. Last, we observe that recently citation networks are trending toward more bridging and interdisciplinary forms.

#index 1434127
#* Evaluating methods to rediscover missing web pages from the web infrastructure
#@ Martin Klein;Michael L. Nelson
#t 2010
#c 14
#% 249108
#% 268310
#% 281209
#% 309145
#% 309534
#% 309748
#% 321635
#% 327115
#% 344929
#% 427304
#% 438365
#% 577300
#% 674852
#% 679872
#% 735137
#% 781168
#% 809454
#% 869570
#% 881071
#% 907442
#% 991817
#% 1055708
#% 1056495
#% 1130827
#% 1131150
#% 1193638
#% 1213483
#% 1684792
#! Missing web pages (pages that return the 404 "Page Not Found error) are part of the browsing experience. The manual use of search engines to rediscover missing pages can be frustrating and unsuccessful. We compare four automated methods for rediscovering web pages. We extract the page's title, generate the page's lexical signature (LS), obtain the page's tags from the bookmarking website delicious.com and generate a LS from the page's link neighborhood. We use the output of all methods to query Internet search engines and analyze their retrieval performance. Our results show that both LSs and titles perform fairly well with over 60% URIs returned top ranked from Yahoo!. However, the combination of methods improves the retrieval performance. Considering the complexity of the LS generation, querying the title first and in case of insufficient results querying the LSs second is the preferable setup. This combination accounts for more than 75% top ranked URIs.

#index 1434128
#* Search behaviors in different task types
#@ Jingjing Liu;Michael J. Cole;Chang Liu;Ralf Bierig;Jacek Gwizdka;Nicholas J. Belkin;Jun Zhang;Xiangmin Zhang
#t 2010
#c 14
#% 56825
#% 169803
#% 187999
#% 303510
#% 349274
#% 766454
#% 766472
#% 802845
#% 818206
#% 874715
#% 907516
#% 954949
#% 955711
#% 1053505
#% 1093793
#% 1173627
#% 1797227
#! Personalization of information retrieval tailors search towards individual users to meet their particular information needs by taking into account information about users and their contexts, often through implicit sources of evidence such as user behaviors. Task types have been shown to influence search behaviors including usefulness judgments. This paper reports on an investigation of user behaviors associated with different task types. Twenty-two undergraduate journalism students participated in a controlled lab experiment, each searching on four tasks which varied on four dimensions: complexity, task product, task goal and task level. Results indicate regular differences associated with different task characteristics in several search behaviors, including task completion time, decision time (the time taken to decide whether a document is useful or not), and eye fixations, etc. We suggest these behaviors can be used as implicit indicators of the user's task type.

#index 1434129
#* Exploiting time-based synonyms in searching document archives
#@ Nattiya Kanhabua;Kjetil Nørvåg
#t 2010
#c 14
#% 577220
#% 755899
#% 854890
#% 877569
#% 987257
#% 987333
#% 1019061
#% 1019105
#% 1022339
#% 1074073
#% 1074113
#% 1117027
#% 1227584
#% 1269107
#% 1443174
#% 1683873
#! Query expansion of named entities can be employed in order to increase the retrieval effectiveness. A peculiarity of named entities compared to other vocabulary terms is that they are very dynamic in appearance, and synonym relationships between terms change with time. In this paper, we present an approach to extracting synonyms of named entities over time from the whole history of Wikipedia. In addition, we will use their temporal patterns as a feature in ranking and classifying them into two types, i.e., time-independent or time-dependent. Time-independent synonyms are invariant to time, while time-dependent synonyms are relevant to a particular time period, i.e., the synonym relationships change over time. Further, we describe how to make use of both types of synonyms to increase the retrieval effectiveness, i.e., query expansion with time-independent synonyms for an ordinary search, and query expansion with time-dependent synonyms for a search wrt. temporal criteria. Finally, through an evaluation based on TREC collections, we demonstrate how retrieval performance of queries consisting of named entities can be improved using our approach.

#index 1434130
#* Using word sense discrimination on historic document collections
#@ Nina Tahmasebi;Kai Niklas;Thomas Theuerkauf;Thomas Risse
#t 2010
#c 14
#% 198058
#% 577285
#% 741083
#% 747738
#% 756964
#% 811281
#% 939538
#% 939842
#% 967294
#% 1275285
#! Word sense discrimination is the first, important step towards automatic detection of language evolution within large, historic document collections. By comparing the found word senses over time, we can reveal and use important information that will improve understanding and accessibility of a digital archive. Algorithms for word sense discrimination have been developed while keeping today's language in mind and have thus been evaluated on well selected, modern datasets. The quality of the word senses found in the discrimination step has a large impact on the detection of language evolution. Therefore, as a first step, we verify that word sense discrimination can successfully be applied to digitized historic documents and that the results correctly correspond to word senses. Because accessibility of digitized historic collections is influenced also by the quality of the optical character recognition (OCR), as a second step we investigate the effects of OCR errors on word sense discrimination results. All evaluations in this paper are performed on The Times Archive, a collection of newspaper articles from 1785 - 1985.

#index 1434131
#* Chinese calligraphy specific style rendering system
#@ Zhenting Zhang;Jiangqin Wu;Kai Yu
#t 2010
#c 14
#% 12184
#% 173198
#% 613608
#% 776553
#% 778605
#% 813035
#% 874593
#% 1022674
#% 1028731
#% 1147385
#% 1213426
#% 1269921
#% 1298005
#% 1775795
#! Manifesting the handwriting characters with the specific style of a famous artwork is fascinating. In this paper, a system is built to render the user's handwriting characters with a specific style. A stroke database is established firstly. When rendering a character, the strokes are extracted and recognized, then proper radicals and strokes are filtered, finally these strokes are deformed and the result is generated. The Special Nine Grid (SNG) is presented to help recognize radicals and strokes. The Rule-base Stroke Deformation Algorithm (RSDA) is proposed to deform the original strokes according to the handwriting strokes. The rendering result manifests the specific style with high quality. It is feasible for people to generate the tablet or other artworks with the proposed system.

#index 1434132
#* Translating handwritten bushman texts
#@ Kyle Williams;Hussein Suleman
#t 2010
#c 14
#% 196977
#% 239578
#% 375017
#% 381397
#% 718597
#% 724766
#% 738474
#% 952730
#% 952732
#% 990455
#% 1090208
#% 1248564
#% 1302840
#% 1914891
#! The Bleek and Lloyd Collection is a collection of artefacts documenting the life and language of the Bushman people of southern Africa in the 19th century. Included in this collection is a handwritten dictionary that contains English words and their corresponding |xam Bushman language translations. This dictionary allows for the manual translation of |xam words that appear in the notebooks of the Bleek and Lloyd collection. This, however, is not practical due to the size of the dictionary, which contains over 14000 entries. To solve this problem a content-based image retrieval system was built that allows for the selection of a |xam word from a notebook and returns matching words from the dictionary. The system shows promise with some search keys returning relevant results.

#index 1434133
#* Do Wikipedians follow domain experts?: a domain-specific study on Wikipedia knowledge building
#@ Yi Zhang;Aixin Sun;Anwitaman Datta;Kuiyu Chang;Ee-Peng Lim
#t 2010
#c 14
#% 751850
#% 878916
#% 880716
#% 936705
#% 956520
#% 961564
#% 1001088
#% 1019083
#% 1035586
#% 1166528
#% 1190128
#% 1288489
#! Wikipedia is one of the most successful online knowledge bases, attracting millions of visits daily. Not surprisingly, its huge success has in turn led to immense research interest for a better understanding of the collaborative knowledge building process. In this paper, we performed a (terrorism) domain-specific case study, comparing and contrasting the knowledge evolution in Wikipedia with a knowledge base created by domain experts. Specifically, we used the Terrorism Knowledge Base (TKB) developed by experts at MIPT. We identified 409 Wikipedia articles matching TKB records, and went ahead to study them from three aspects: creation, revision, and link evolution. We found that the knowledge building in Wikipedia had largely been independent, and did not follow TKB - despite the open and online availability of the latter, as well as awareness of at least some of the Wikipedia contributors about the TKB source. In an attempt to identify possible reasons, we conducted a detailed analysis of contribution behavior demonstrated by Wikipedians. It was found that most Wikipedians contribute to a relatively small set of articles each. Their contribution was biased towards one or very few article(s). At the same time, each article's contributions are often championed by very few active contributors including the article's creator. We finally arrive at a conjecture that the contributions in Wikipedia are more to cover knowledge at the article level rather than at the domain level.

#index 1434134
#* Spatiotemporal mapping of Wikipedia concepts
#@ Adrian Popescu;Gregory Grefenstette
#t 2010
#c 14
#% 987213
#% 1019189
#% 1024551
#% 1055916
#% 1190131
#% 1250381
#% 1269107
#% 1269899
#% 1275012
#% 1292475
#% 1338653
#% 1409954
#% 1720754
#! Space and time are important dimensions in the representation of a large number of concepts. However there exists no available resource that provides spatiotemporal mappings of generic concepts. Here we present a link-analysis based method for extracting the main locations and periods associated to all Wikipedia concepts. Relevant locations are selected from a set of geotagged articles, while relevant periods are discovered using a list of people with associated life periods. We analyze article versions over multiple languages and consider the strength of a spatial/temporal reference to be proportional to the number of languages in which it appears. To illustrate the utility of the spatiotemporal mapping of Wikipedia concepts, we present an analysis of cultural interactions and a temporal analysis of two domains. The Wikipedia mapping can also be used to perform rich spatiotemporal document indexing by extracting implicit spatial and temporal references from texts.

#index 1434135
#* Crowdsourcing the assembly of concept hierarchies
#@ Kai Eckert;Mathias Niepert;Christof Niemann;Cameron Buckner;Colin Allen;Heiner Stuckenschmidt
#t 2010
#c 14
#% 751818
#% 860015
#% 967285
#% 1039354
#% 1039357
#% 1047347
#% 1083692
#% 1130829
#% 1150163
#% 1220996
#% 1264744
#% 1302750
#! The "wisdom of crowds" is accomplishing tasks that are cumbersome for individuals yet cannot be fully automated by means of specialized computer algorithms. One such task is the construction of thesauri and other types of concept hierarchies. Human expert feedback on the relatedness and relative generality of terms, however, can be aggregated to dynamically construct evolving concept hierarchies. The InPhO (Indiana Philosophy Ontology) project bootstraps feedback from volunteer users unskilled in ontology design into a precise representation of a specific domain. The approach combines statistical text processing methods with expert feedback and logic programming to create a dynamic semantic representation of the discipline of philosophy. In this paper, we show that results of comparable quality can be achieved by leveraging the workforce of crowdsourcing services such as the Amazon Mechanical Turk (AMT). In an extensive empirical study, we compare the feedback obtained from AMT's workers with that from the InPhO volunteer users providing an insight into qualitative differences of the two groups. Furthermore, we present a set of strategies for assessing the quality of different users when gold standards are missing. We finally use these methods to construct a concept hierarchy based on the feedback acquired from AMT workers.

#index 1434136
#* A user-centered design of a personal digital library for music exploration
#@ David Bainbridge;Brook J. Novak;Sally Jo Cunningham
#t 2010
#c 14
#% 24624
#% 41664
#% 187989
#% 204872
#% 265181
#% 281391
#% 411348
#% 434821
#% 769128
#% 824584
#% 852342
#% 1183158
#% 1434731
#% 1879456
#! We describe the evaluation of a personal digital library environment designed to help musicians capture, enrich and store their ideas using a spatial hypermedia paradigm. The target user group is musicians who primarily use audio and text for composition and arrangement, rather than with formal music notation. Using the principle of user-centered design, the software implementation was guided by a diary study involving nine musicians which suggested five requirements for the software to support: capturing, overdubbing, developing, storing, and organizing. Moreover, the underlying spatial data-model was exploited to give raw audio compositions a hierarchical structure, and - to aid musicians in retrieving previous ideas - a search facility is available to support both query by humming and text-based queries. A user evaluation of the completed design with eleven subjects indicated that musicians, in general, would find the hypermedia environment useful for capturing and managing their moments of musical creativity and exploration. More specifically they would make use of the query by humming facility and the hierarchical track organization, but not the overdubbing facility as implemented.

#index 1434137
#* Improving mood classification in music digital libraries by combining lyrics and audio
#@ Xiao Hu;J. Stephen Downie
#t 2010
#c 14
#% 428246
#% 729957
#% 795274
#% 1127964
#% 1131848
#% 1159898
#% 1213444
#% 1767413
#% 1788189
#! Mood is an emerging metadata type and access point in music digital libraries (MDL) and online music repositories. In this study, we present a comprehensive investigation of the usefulness of lyrics in music mood classification by evaluating and comparing a wide range of lyric text features including linguistic and text stylistic features. We then combine the best lyric features with features extracted from music audio using two fusion methods. The results show that combining lyrics and audio significantly outperformed systems using audio-only features. In addition, the examination of learning curves shows that the hybrid lyric + audio system needed fewer training samples to achieve the same or better classification accuracies than systems using lyrics or audio singularly. These experiments were conducted on a unique large-scale dataset of 5,296 songs (with both audio and lyrics for each) representing 18 mood categories derived from social tags. The findings push forward the state-of-the-art on lyric sentiment analysis and automatic music mood classification and will help make mood a practical access point in music digital libraries.

#index 1434138
#* Visualizing personal digital collections
#@ Weijia Xu;Maria Esteva;Suyog Dott Jain
#t 2010
#c 14
#% 801412
#% 860038
#% 860118
#% 1083903
#% 1137815
#% 1232588
#! This paper describes the use of relational database management system (RDBMS) and treemap visualization to represent and analyze a group of personal digital collections created in the context of work and with no external metadata. We evaluated the visualization vis a vis the results of previous personal information management (PIM) studies. We suggest that this visualization supports analysis that allow understanding PIM practices overtime.

#index 1434139
#* Interpretation of web page layouts by blind users
#@ Luis Francisco-Revilla;Jeff Crow
#t 2010
#c 14
#% 249202
#% 781543
#% 988465
#% 1198376
#% 1215453
#! Digital libraries must support assistive technologies that allow people with disabilities such as blindness to use, navigate and understand their documents. Increasingly, many documents are Web-based and present their contents using complex layouts. However, approaches that translate two-dimensional layouts to one-dimensional speech produce a very different user experience and loss of information. To address this issue, we conducted a study of how blind people navigate and interpret layouts of news and shopping Web pages using current assistive technology. The study revealed that blind people do not parse Web pages fully during their first visit, and that they can miss important parts. The study also provided insights for improving assistive technologies.

#index 1434140
#* Supporting document triage via annotation-based multi-application visualizations
#@ Soonil Bae;DoHyoung Kim;Konstantinos Meintanis;J. Michael Moore;Anna Zacchi;Frank Shipman;Haowei Hsieh;Catherine C. Marshall
#t 2010
#c 14
#% 118771
#% 157698
#% 187989
#% 240744
#% 247297
#% 260778
#% 272917
#% 320432
#% 343769
#% 349405
#% 741058
#% 760876
#% 790699
#% 802864
#% 848656
#% 869536
#% 1214048
#% 1656148
#% 1677914
#% 1704290
#% 1728992
#% 1914893
#! For open-ended information tasks, users must sift through many potentially relevant documents, a practice we refer to as document triage. Normally, people perform triage using multiple applications in concert: a search engine interface presents lists of potentially relevant documents; a document reader displays their contents; and a third tool--a text editor or personal information management application--is used to record notes and assessments. To support document triage, we have developed an extensible multi-application architecture that initially includes an information workspace and a document reader. An Interest Profile Manager infers users' interests from their interactions with the triage applications, coupled with the characteristics of the documents they are interacting with. The resulting interest profile is used to generate visualizations that direct users' attention to documents or parts of documents that match their inferred interests. The novelty of our approach lies in the aggregation of activity records across applications to generate fine-grained models of user interest.

#index 1434141
#* Flexible access to photo libraries via time, place, tags, and visual features
#@ Andreas Girgensohn;Frank Shipman;Thea Turner;Lynn Wilcox
#t 2010
#c 14
#% 118771
#% 137473
#% 194174
#% 324983
#% 342528
#% 391311
#% 452641
#% 635092
#% 730144
#% 755102
#% 760871
#% 780723
#% 802851
#% 860092
#% 869558
#% 954942
#% 1047296
#% 1047501
#% 1071134
#% 1169611
#% 1194252
#! Photo libraries are growing in quantity and size, requiring better support for locating desired photographs. MediaGLOW is an interactive visual workspace designed to address this concern. It uses attributes such as visual appearance, GPS locations, user-assigned tags, and dates to filter and group photos. An automatic layout algorithm positions photos with similar attributes near each other to support users in serendipitously finding multiple relevant photos. In addition, the system can explicitly select photos similar to specified photos. We conducted a user evaluation to determine the benefit provided by similarity layout and the relative advantages offered by the different layout similarity criteria and attribute filters. Study participants had to locate photos matching probe statements. In some tasks, participants were restricted to a single layout similarity criterion and filter option. Participants used multiple attributes to filter photos. Layout by similarity without additional filters turned out to be one of the most used strategies and was especially beneficial for geographical similarity. Lastly, the relative appropriateness of the single similarity criterion to the probe significantly affected retrieval performance.

#index 1434142
#* Interactively browsing movies in terms of action, foreshadowing and resolution
#@ Stewart Greenhill;Brett Adams;Svetha Venkatesh
#t 2010
#c 14
#% 238915
#% 451585
#% 1065179
#% 1775174
#! We describe a novel video player that uses Temporal Semantic Compression (TSC) to present a compressed summary of a movie. Compression is based on tempo which is derived from film rhythms. The technique identifies periods of action, drama, foreshadowing and resolution, which can be mixed in different amounts to vary the kind of summary presented. The compression algorithm is embedded in a video player, so that the summary can be interactively recomputed during playback.

#index 1434143
#* Timeline interactive multimedia experience (time): on location access to aggregate event information
#@ Jeff Crow;Eryn Whitworth;Ame Wongsa;Luis Francisco-Revilla;Swati Pendyala
#t 2010
#c 14
#% 168485
#% 343115
#% 783844
#% 847992
#% 904001
#% 955031
#% 956704
#% 1016117
#% 1043273
#% 1047446
#% 1047454
#% 1065421
#% 1183211
#% 1190086
#% 1213418
#! Attending a complex scheduled social event, such as a multi-day music festival, requires a significant amount of planning before and during its progression. Advancements in mobile technology and social networks enable attendees to contribute content in real-time that can provide useful information to many. Currently access to and presentation of such information is challenging to use during an event. The Timeline Interactive Multimedia Experience (TIME) system aggregates information posted to multiple social networks and presents the flow of information in a multi-touch timeline interface. TIME was designed to be placed on location to allow real-time access to relevant information that helps attendees to make plans and navigate their crowded surroundings.

#index 1434144
#* Domain-specific iterative readability computation
#@ Jin Zhao;Min-Yen Kan
#t 2010
#c 14
#% 277480
#% 281480
#% 290830
#% 309779
#% 907541
#% 939396
#% 1065265
#% 1072493
#% 1264737
#! We present a new algorithm to measure domain-specific readability. It iteratively computes the readability of domain-specific resources based on the difficulty of domain-specific concepts and vice versa, in a style reminiscent of other bipartite graph algorithms such as Hyperlink-Induced Topic Search (HITS) and the Stochastic Approach for Link-Structure Analysis (SALSA). While simple, our algorithm outperforms standard heuristic measures and remains competitive among supervised-learning approaches. Moreover, it is less domain-dependent and portable across domains as it does not rely on an annotated corpus or expensive expert knowledge that supervised or domain-specific methods require.

#index 1434145
#* Evaluating topic models for digital libraries
#@ David Newman;Youn Noh;Edmund Talley;Sarvnaz Karimi;Timothy Baldwin
#t 2010
#c 14
#% 722904
#% 788043
#% 875959
#% 967299
#% 967300
#% 989620
#% 1211693
#% 1292526
#% 1470574
#! Topic models could have a huge impact on improving the ways users find and discover content in digital libraries and search interfaces through their ability to automatically learn and apply subject tags to each and every item in a collection, and their ability to dynamically create virtual collections on the fly. However, much remains to be done to tap this potential, and empirically evaluate the true value of a given topic model to humans. In this work, we sketch out some sub-tasks that we suggest pave the way towards this goal, and present methods for assessing the coherence and interpretability of topics learned by topic models. Our large-scale user study includes over 70 human subjects evaluating and scoring almost 500 topics learned from collections from a wide range of genres and domains. We show how scoring model -- based on pointwise mutual information of word-pair using Wikipedia, Google and MEDLINE as external data sources - performs well at predicting human scores. This automated scoring of topics is an important first step to integrating topic modeling into digital libraries

#index 1434146
#* FRBRization of MARC records in multiple catalogs
#@ Hugo Miguel Álvaro Manguinhas;Nuno Miguel Antunes Freire;José Luis Brinquete Borbinha
#t 2010
#c 14
#% 1734587
#! This paper addresses the problem of using the FRBR model to support the presentation of results. It describes a service implementing new algorithms and techniques for transforming existing MARC records into the FRBR model for this specific purpose. This work was developed in the context of the TELPlus project and processed 100,000 bibliographic and authority records from multilingual catalogs of 12 European countries.

#index 1434147
#* Exposing the hidden web for chemical digital libraries
#@ Sascha Tönnies;Benjamin Köhncke;Oliver Koepler;Wolf-Tilo Balke
#t 2010
#c 14
#% 43862
#% 744553
#% 906433
#% 956519
#% 1055745
#% 1227960
#% 1682486
#! In recent years, the vast amount of digitally available content has lead to the creation of many topic-centered digital libraries. Also in the domain of chemistry more and more digital collections are available, but the complex query formulation still hampers their intuitive adoption. This is because information seeking in chemical documents is focused on chemical entities, for which current standard search relies on complex structures which are hard to extract from documents. Moreover, although simple keyword searches would often be sufficient, current collections simply cannot be indexed by Web search providers due to the ambiguity of chemical substance names. In this paper we present a framework for automatically generating metadata-enriched index pages for all documents in a given chemical collection. All information is then linked to the respective documents and thus provides an easy to crawl metadata repository promising to open up digital chemical libraries. Our experiments, indexing an open access journal, show that not only the documents can be found using a simple Google search via the automatically created index pages, but also that the quality of the search is much more efficient than fulltext indexing in terms of both precision/recall and performance. Finally, we compare our indexing against a classical structure search and figured out that keyword-based search can indeed solve at least some of the daily tasks in chemical workflows. To use our framework thus promises to expose a large part of the currently still hidden chemical Web, making the techniques employed interesting for chemical information providers like digital libraries and open access journals.

#index 1434148
#* oreChem ChemXSeer: a semantic digital library for chemistry
#@ Na Li;Leilei Zhu;Prasenjit Mitra;Karl Mueller;Eric Poweleit;C. Lee Giles
#t 2010
#c 14
#% 420077
#% 614036
#% 769406
#% 805901
#% 859913
#% 874499
#% 874518
#% 1055745
#% 1270273
#% 1338741
#% 1475144
#% 1698925
#! Representing the semantics of unstructured scientific publications will certainly facilitate access and search and hopefully lead to new discoveries. However, current digital libraries are usually limited to classic flat structured metadata even for scientific publications that potentially contain rich semantic metadata. In addition, how to search the scientific literature of linked semantic metadata is an open problem. We have developed a semantic digital library oreChem ChemxSeer that models chemistry papers with semantic metadata. It stores and indexes extracted metadata from a chemistry paper repository Chemx Seer using "compound objects". We use the Open Archives Initiative Object Reuse and Exchange (OAI-ORE) (http://www.openarchives.org/ore/ standard to define a compound object that aggregates metadata fields related to a digital object. Aggregated metadata can be managed and retrieved easily as one unit resulting in improved ease-of-use and has the potential to improve the semantic interpretation of shared data. We show how metadata can be extracted from documents and aggregated using OAI-ORE. ORE objects are created on demand; thus, we are able to search for a set of linked metadata with one query. We were also able to model new types of metadata easily. For example, chemists are especially interested in finding information related to experiments in documents. We show how paragraphs containing experiment information in chemistry papers can be extracted and tagged based on a chemistry ontology with 470 classes, and then represented in ORE along with other document-related metadata. Our algorithm uses a classifier with features that are words that are typically only used to describe experiments, such as "apparatus", "prepare", etc. Using a dataset comprised of documents from the Royal Society of Chemistry digital library, we show that the our proposed methodperforms well in extracting experiment-related paragraphs from chemistry documents.

#index 1434149
#* BinarizationShop: a user-assisted software suite for converting old documents to black-and-white
#@ Fanbo Deng;Zheng Wu;Zheng Lu;Michael S. Brown
#t 2010
#c 14
#% 368150
#% 378535
#% 718842
#% 729437
#% 760836
#% 809505
#% 940212
#% 967306
#% 1065274
#! Converting a scanned document to a binary format (black and white) is a key step in the digitization process. While many existing binarization algorithms operate robustly for well-kept documents, these algorithms often produce less than satisfactory results when applied to old documents, especially those degraded with stains and other discolorations. For these challenging documents, user assistance can be advantageous in directing the binarization procedure. Many existing algorithms, however, are poorly designed to incorporate user assistance. In this paper, we discuss a software framework, BinarizationShop, that combines a series of binarization approaches that have been tailored to exploit user assistance. This framework provides a practical approach for converting difficult documents to black and white.

#index 1434150
#* Using an ontology and a multilingual glossary for enhancing the nautical archaeology digital library
#@ Carlos Monroy;Richard Furuta;Filipe Castro
#t 2010
#c 14
#% 337553
#% 508271
#% 874485
#% 967307
#% 1184929
#% 1707923
#% 1914875
#! Access to materials in digital collections has been extensively studied within digital libraries. Exploring a collection requires customized indices and novel interfaces to allow users new exploration mechanisms. Materials or objects can then be found by way of full-text, faceted, or thematic indexes. There has been a marked interest not only in finding objects in a collection, but in discovering relationships and properties. For example, multiple representations of the same object enable the use of visual aids to augment collection exploration. Depending on the domain and characteristics of the objects in a collection, relationships among components can be used to enrich the process of understanding their contents. In this context, the Nautical Archaeology Digital Library (NADL) includes multilingual textual- and visual-rich objects (shipbuilding treatises, illustrations, photographs, and drawings). In this paper we describe an approach for enhancing access to a collection of ancient technical documents, illustrations, and photographs documenting archaeological excavations. Because of the nature of our collection, we exploit a multilingual glossary along with an ontology. Preliminary tests of our prototype suggest the feasibility of our method for enhancing access to the collection.

#index 1434151
#* In-depth utilization of Chinese ancient maps: a hybrid approach to digitizing map resources in CADAL
#@ Zhenchao Ye;Ling Zhuang;Jiangqin Wu;Chenyang Du;Baogang Wei;Yin Zhang
#t 2010
#c 14
#% 309208
#% 743284
#% 878492
#% 957217
#% 1032572
#% 1656114
#! Digital map is getting increasingly popular as an intuitive and interactive platform for data presentation recently. Thus applications integrated with digital map have attracted much attention. But no offtheshelf systems or services could we use if the time span of maps be extended to historical ones. There are a large number of valuable ancient atlases in CADAL digital library. However, they are seldom made use of because the ones which are in image format are not convenient for users to read or search. In this paper, we propose a novel hybrid approach to utilizing these atlases directly and constructing some applications based on ancient maps. We call it CAMAME which means Chinese Ancient Maps Automatic Marking and Extraction. We create a gazetteer to store the geographic information of sites which will be project on the map, then use kernel method to do the regression and correct the estimated results with image processing and local regression methods. The empirical results show that CAMAME is effective and efficient, by which most valuable data in the map images is marked and identified. Some Chinese literary chronicle applications that exhibit ancient literary and related historical information over those digitized atlas resources in CADAL digital library were developed.

#index 1434152
#* The fused library: integrating digital and physical libraries with location-aware sensors
#@ George R. Buchanan
#t 2010
#c 14
#% 301247
#% 301539
#% 345048
#% 378526
#% 420175
#% 679840
#% 756878
#% 808481
#% 860704
#% 874455
#% 882916
#% 1182249
#% 1302973
#% 1309621
#% 1671688
#% 1681995
#% 1714637
#! This paper reports an investigation into the connection of the workspace of physical libraries with digital library services. Using simple sensor technology, we provide focused access to digital resources on the basis of the user's physical context, including the topic of the stacks they are next to, and the content of books on their reading desks. Our research developed the technological infrastructure to support this fused interaction, investigated current patron behavior in physical libraries, and evaluated our system in a user-centred pilot study. The outcome of this research demonstrates the potential utility of the fused library, and provides a starting point for future exploitation.

#index 1434153
#* What humanists want: how scholars use source materials
#@ Neal Audenaert;Richard Furuta
#t 2010
#c 14
#% 63196
#% 173738
#% 291980
#% 378478
#% 378510
#% 1043047
#% 1709410
#! Despite the growing prominence of digital libraries as tools to support humanities scholars, little is known about the work practices and needs of these scholars as they pertain to working with source documents. In this paper we present our findings from a formative user study consisting of semi-structured interviews with eight scholars. We find that the use of source materials (by which we mean the original physical documents or digital facsimiles with minimal editorial intervention) in scholarship is not a simple, straight-forward examination of a document in isolation. Instead, scholars study source materials as an integral part of a complex ecosystem of inquiry that seeks to understand both the text being studied and the context in which that text was created, transmitted and used. Drawing examples from our interviews, we address critical questions of why scholars use source documents and what information they hope to gain by studying them. We also briefly summarize key note-taking practices as a means for assessing the potential to design user interfaces that support scholarly work-practices.

#index 1434154
#* Context identification of sentences in related work sections using a conditional random field: towards intelligent digital libraries
#@ M. A. Angrosh;Stephen Cranefield;Nigel Stanger
#t 2010
#c 14
#% 464434
#% 466892
#% 744553
#% 816181
#% 853844
#% 855119
#% 858614
#% 910908
#% 1273862
#% 1299617
#% 1309355
#% 1389718
#% 1669901
#! Identification of contexts associated with sentences is becoming increasingly necessary for developing intelligent information retrieval systems. This article describes a supervised learning mechanism employing a conditional random field (CRF) for context identification and sentence classification. Specifically, we focus on sentences in related work sections in research articles. Based on a generic rhetorical pattern, a framework for modelling the sequential flow in these sections is proposed. Adopting a generalization strategy, each of these sentences is transformed into a set of features, which forms our dataset. We distinguish between two kinds of features for each of these sentences viz., citation features and sentence features. While an overall accuracy of 96.51% is achieved by using a combination of both citation and sentence features, the use of sentence features alone yields an accuracy of 93.22%. The results also show F-Scores ranging from 0.99 to 0.90 for various classes indicating the robustness of our application.

#index 1434155
#* Can an intermediary collection help users search image databases without annotations?
#@ Robert Villa;Martin Halvey;Hideo Joho;David Hannah;Joemon M. Jose
#t 2010
#c 14
#% 239576
#% 318785
#% 457912
#% 476215
#% 645687
#% 751818
#% 860013
#% 871566
#% 905168
#% 1338321
#! Developing methods for searching image databases is a challenging and ongoing area of research. A common approach is to use manual annotations, although generating annotations can be expensive in terms of time and money, and therefore may not be justified in many situations. Content-based search techniques which extract visual features from image data can be used, but users are typically forced to express their information need using example images, or through sketching interfaces. This can be difficult if no visual example of the information need is available, or when the information need cannot be easily drawn. In this paper, we consider an alternative approach which allows a user to search for images through an intermediate database. In this approach, a user can search using text in the intermediate database as a way of finding visual examples of their information need. The visual examples can then be used to search a database that lacks annotations. Three experiments are presented which investigate this process. The first experiment automatically selects the image queries from the intermediary database; the second instead uses images which have been hand-picked by users. A third experiment, an interactive study, is then presented this study compares the intermediary interface to text search, where we consider text as an upper bound of performance. For this last study, an interface which supports the intermediary search process is described. Results show that while performance does not match manual annotations, users are able to find relevant material without requiring collection annotations.

#index 1434156
#* Social network document ranking
#@ Liang Gou;Xiaolong (Luke) Zhang;Hung-Hsuan Chen;Jung-Hyun Kim;C. Lee Giles
#t 2010
#c 14
#% 46803
#% 68247
#% 268079
#% 290830
#% 309095
#% 324129
#% 340928
#% 397155
#% 406493
#% 451407
#% 503218
#% 577224
#% 577329
#% 641979
#% 805877
#% 818233
#% 818335
#% 956544
#% 956690
#% 1074116
#% 1247781
#% 1366206
#% 1375817
#% 1396090
#% 1667787
#! In search engines, ranking algorithms measure the importance and relevance of documents mainly based on the contents and relationships between documents. User attributes are usually not considered in ranking. This user-neutral approach, however, may not meet the diverse interests of users, who may demand different documents even with the same queries. To satisfy this need for more personalized ranking, we propose a ranking framework. Social Network Document Rank (SNDocRank), that considers both document contents and the relationship between a searched and document owners in a social network. This method combined the traditional tf-idf ranking for document contents with out Multi-level Actor Similarity (MAS) algorithm to measure to what extent document owners and the searcher are structurally similar in a social network. We implemented our ranking method in simulated video social network based on data extracted from YouTube and tested its effectiveness on video search. The results show that compared with the traditional ranking method like tf-idfs the SNDocRank algorithm returns more relevant documents. More specifically, a searcher can get significantly better results be being in a larger social network, having more friends, and being associated with larger local communities in a social network.

#index 1434157
#* A mathematical framework for modeling and analyzing migration time
#@ Feng Luan;Mads Nygård;Thomas Mestl
#t 2010
#c 14
#% 337486
#% 378537
#% 508405
#% 770362
#% 813277
#% 859916
#% 945806
#% 967247
#% 991818
#! File format obsolescence has so far been considered the major risk in long-term storage of digital objects. There are, however, growing indications that file transfer may be a real threat as the migration time, i.e., the time required to migrate Petabytes of data, may easily spend years. However, hardware support is usually limited to 3-4 years and a situation can emerge when a new migration has to be started although the previous one is still not finished yet. This paper chooses a process modeling approach to obtain estimates of upper and lower bounds for the required migration time. The advantage is that information about potential bottlenecks can be acquired. Our theoretical considerations are validated by migration tests at the National Library of Norway (NB) as well as at our department.

#index 1434158
#* Digital libraries for scientific data discovery and reuse: from vision to practical reality
#@ Jillian C. Wallis;Matthew S. Mayernik;Christine L. Borgman;Alberto Pepe
#t 2010
#c 14
#% 755707
#% 967283
#% 1000935
#% 1021630
#% 1383238
#% 1682001
#% 1914890
#! Science and technology research is becoming not only more distributed and collaborative, but more highly instrumented. Digital libraries provide a means to capture, manage, and access the data deluge that results from these research enterprises. We have conducted research on data practices and participated in developing data management services for the Center for Embedded Networked Sensing since its founding in 2002 as a National Science Foundation Science and Technology Center. Over the course of eight years, our digital library strategy has shifted dramatically in response to changing technologies, practices, and policies. We report on the development of several DL systems and on the lessons learned, which include the difficulty of anticipating data requirements from nascent technologies, building systems for highly diverse work practices and data types, the need to bind together multiple single-purpose systems, the lack of incentives to manage and share data, the complementary nature of research and development in understanding practices, and sustainability.

#index 1434159
#* Ensemble PDP-8: eight principles for distributed portals
#@ Edward A. Fox;Yinlin Chen;Monika Akbar;Clifford A. Shaffer;Stephen H. Edwards;Peter Brusilovsky;Dan Garcia;Lois Delcambre;Felicia Decker;David Archer;Richard Furuta;Frank Shipman;Stephen Carpenter;Lillian Cassel
#t 2010
#c 14
#% 243752
#% 1183359
#% 1332521
#! Ensemble, the National Science Digital Library (NSDL) Pathways project for Computing, builds upon a diverse group of prior NSDL, DL-I, and other projects. Ensemble has shaped its activities according to principles related to design, development, implementation, and operation of distributed portals. Here we articulate 8 key principles for distributed portals (PDPs). While our focus is on education and pedagogy, we expect that our experiences will generalize to other digital library application domains. These principles inform, facilitate, and enhance the Ensemble R&D and production activities. They allow us to provide a broad range of services, from personalization to coordination across communities. The eight PDPs can be briefly summarized as: (1) Articulation across communities using ontologies. (2) Browsing tailored to collections. (3) Integration across interfaces and virtual environments. (4) Metadata interoperability and integration. (5) Social graph construction using logging and metrics. (6) Superimposed information and annotation integrated across distributed systems. (7) Streamlined user access with IDs. (8) Web 2.0 multiple social network system interconnection.

#index 1434160
#* Discovering Australia's research data
#@ Stefanie Kethers;Xiaobin Shen;Andrew E. Treloar;Ross G. Wilkinson
#t 2010
#c 14
#% 1157358
#% 1316070
#% 1360443
#! Access to data crucial to research is often slow and difficult. When research problems cross disciplinary boundaries, problems are exacerbated. This paper argues that it is important to make it easier to find and access data that might be found in an institution, in a disciplinary data store, in a government department, or held privately. We explore how to meet ad hoc needs that cannot easily be supported by a disciplinary ontology, and argue that web pages that describe data collections with rich links and rich text are valuable. We describe the approach followed by the Australian National Data Service (ANDS) in making such pages available. Finally, we discuss how we plan to evaluate this approach.

#index 1434161
#* This is what i'm doing and why: reflections on a think-aloud study of dl users' information behaviour
#@ Stephann Makri;Ann Blandford;Anna L. Cox
#t 2010
#c 14
#% 60635
#% 337261
#% 402112
#% 425644
#% 1014998
#% 1135989
#! Many user-centred studies of digital libraries (DLs) include a think-aloud element and are usually conducted with the purpose of identifying usability issues related to the DLs used or understanding aspects of users' information behaviour. However, few of these studies present detailed accounts of how their think-aloud data was collected and analysed or reflect on this process. In this paper, we discuss and reflect on the decisions made when planning and conducting a think-aloud study of lawyers' interactive information behaviour. Our discussion is framed by Blandford et al.'s PRET A Rapporter ('ready to report') framework - a framework that can be used to plan, conduct and describe user-centred studies of DL use from an information work perspective.

#index 1434162
#* Customizing science instruction with educational digital libraries
#@ Tamara Sumner;CCS Team
#t 2010
#c 14
#% 809402
#% 809408
#! The Curriculum Customization Service enables science educators to customize their instruction with interactive digital library resources. Preliminary results from a field trial with 124 middle and high school teachers suggest that the Service offers a promising model for embedding educational digital libraries into teaching practices and for supporting teachers to integrate customizing into their curriculum planning.

#index 1434163
#* Impact and prospect of social bookmarks for bibliographic information retrieval
#@ Kazuhiro Seki;Huawei Qin;Kuniaki Uehara
#t 2010
#c 14
#% 179060
#% 1035588
#% 1055743
#% 1064154
#% 1130827
#% 1292538
#! This paper presents our ongoing study of the current/future impact of social bookmarks (or social tags) on information retrieval (IR). Our main research question asked in the present work is "How are social tags compared with conventional, yet reliable manual indexing from the viewpoint of IR performance?". To answer the question, we look at the biomedical literature and begin with examining basic statistics of social tags from CiteULike in comparison with Medical Subject Headings (MeSH) annotated in the Medline bibliographic database. Then, using the data, we conduct various experiments in an IR setting, which reveals that social tags work complementarily with MeSH and that retrieval performance would improve as the coverage of CiteULike grows.

#index 1434164
#* Merging metadata: a sociotechnical study of crosswalking and interoperability
#@ Michael Khoo;Catherine Hall
#t 2010
#c 14
#% 314022
#% 378512
#% 397193
#% 508408
#% 571509
#% 614077
#% 809439
#% 874492
#% 874500
#% 1069027
#% 1069028
#% 1134773
#% 1213480
#! Digital library interoperability relies on the use of a common metadata format. However, implementing a common metadata format among multiple digital libraries is not always a straightforward exercise. This paper reviews some of the metadata issues that arose during the merger of two digital libraries, the Internet Public Library and the Librarian's Internet Index. As part of the merger, each library's metadata was crosswalked to Dublin Core. This required considerable work. A sociotechnical analysis suggests that the metadata for each library had been shaped in complex ways over time by local factors, and that this complexity negatively impacted the efficiency of the crosswalk. Some implications of this finding for digital library interoperability are discussed.

#index 1434165
#* Emulation based services in digital preservation
#@ Klaus Rechert;Dirk von Suchodoletz;Randolph Welte
#t 2010
#c 14
#% 1431349
#! The creation of most digital objects occurs solely in interactive graphical user interfaces which were available at the particular time period. Archiving and preservation organizations are posed with large amounts of such objects of various types. At some point they will need to process these automatically to make them available to their users or convert them to a commonly used format. A substantial problem is to provide a wide range of different users with access to ancient environments and to allow using the original environment for a given object. We propose an abstract architecture for emulation services in digital preservation to provide remote user interfaces to emulation over computer networks without the need to install additional software components. Furthermore, we describe how these ideas can be integrated in a framework of web services for common preservation tasks like viewing or migrating digital objects.

#index 1434166
#* Many-to-many information connection connections in a distributed digital library portal
#@ Lillian N. Cassel;Edward A. Fox;Richard Furuta;Lois M.L. Delcambre
#t 2010
#c 14
#! The Ensemble computing education portal is part of the US NSF's National Science Digital Library (NSDL). The underlying assumption in Ensemble's design is that people will not come just because we build something new. The information must be available from wherever potential users are. This poster describes early efforts to provide multiple community oriented entry points to multiple sources relevant to computing educators.

#index 1434167
#* SPIRO-V: a collaborative approach to controlled vocabularies gathering and management
#@ Lina Huang;Rahul A. Deshmukh;Javed Mostafa;Jane Greenberg
#t 2010
#c 14
#% 179060
#% 413664
#! This paper describes SPIRO-V, a collaborative controlled vocabulary development system integrating automatic and manual approaches for domain-specific vocabulary acquisition, and leveraging the knowledge of field experts.

#index 1434168
#* Generating citation digests for scientific publications
#@ Richard Easty;Nikolay Nikolov
#t 2010
#c 14
#% 1065337
#% 1213467
#% 1309925
#! Science is characterized nowadays by unprecedented growth in the number of publications. Thus it would be helpful if there were a way to summarize the contents of the publications or explain the argumentative relationship between them (e.g. support, further improvement, critique). Such semantic analysis might involve analyzing the citation contexts (the paragraphs where a certain publication is referred to by another publication). Here we present our work on a system that creates the pre-requisites for such analysis by harvesting publications from the web, extracting the contexts from them, and aggregating them into citation digests that are retrieved in the context of user interactions with web sites that mention these publications.

#index 1434169
#* AIRFrame: integrating diverse digital collections in astrobiology
#@ Rich Gazan
#t 2010
#c 14
#% 32599
#! Astrobiology is an inherently interdisciplinary field concerned with questions of life in the universe. This paper describes the design and ongoing implementation of the Astrobiology Integrative Research Framework (AIRFrame), an open source, ontology-driven information system designed to ingest and analyze heterogeneous inputs of both published and unpublished data, and to identify and illustrate latent connections between research in astrobiology's diverse constituent fields.

#index 1434170
#* A public education tool for tsunami disasters based on walking tours in TDL
#@ Sayaka Imai;Yoshinari Kanamori;Nobuo Shuto
#t 2010
#c 14
#% 1914917
#! As described in this paper, we proposed a public education tools for Tsunami Disasters based on TDL.

#index 1434171
#* A search engine for Japanese academic papers
#@ Emi Ishita;Teru Agata;Atsushi Ikeuchi;Nozue Michiko;Miyata Yosuke;Shuichi Ueda
#t 2010
#c 14
#! A search engine for Japanese academic papers rendered in PDF is described. Evaluation results indicate fewer zero-result queries and higher precision in the top-10 documents than was obtained for the same Japanese queries using Google Scholar or Scirus.

#index 1434172
#* Analyzing viewing patterns while reading picture books
#@ Emi Ishita;Shinji Mine;Chihiro Kunimoto;Junko Shiozaki;Keiko Kurata;Shuichi Ueda
#t 2010
#c 14
#! We examine the eye movements of children who can read books on their own as they read printed picture books. Our analysis focuses on two points; 1) Is it the pictures or the text that they most frequently gaze at?, and 2) In what sequence do they read picture books? Our results indicate that children look at both text and pictures, but that there are large variations in the ratio of viewing time for each child. Both circular and linear patterns are found in the sequence of eye movements.

#index 1434173
#* Personalizing information retrieval for people with different levels of topic knowledge
#@ Jingjing Liu;Nicholas J. Belkin
#t 2010
#c 14
#% 378486
#% 766454
#% 907516
#% 1077044

#index 1434174
#* Rethinking preservation validation with the preserved object and repository risks ontology (PORRO)
#@ Andrew McHugh;Mounia Lalmas
#t 2010
#c 14
#! For securing digital longevity, the processes of preservation planning and evaluation are fundamentally implicit and share similar complexity. Means are required for the identification, documentation and association of those properties of data, representation and management mechanisms that in combination lend value, facilitate interaction and influence the preservation process. These properties may be almost limitless in terms of diversity, but are integral to the establishment of classes of risk exposure, and the planning and deployment of appropriate preservation strategies. We present PORRO, an ontology based approach for documenting objects, repositories and risk information, intended to support preservation decision making and evaluation.

#index 1434175
#* ForeCite: towards a reader-centric scholarly digital library
#@ Thuy Dung Nguyen;Min-Yen Kan;Dinh-Trung Dang;Markus Hänse;Ching Hoi Andy Hong;Minh-Thang Luong;Jesse Prabawa Gozali;Kazunari Sugiyama;Yee Fan Tan
#t 2010
#c 14
#! We present ForeCite (FC), a prototype reader-centric digital library that supports the scholar in using scholarly documents. FC integrates three user interfaces: a bibliometric component, a document reader and annotation system, and a bibliographic management application.

#index 1434176
#* An architecture for a distributed digital library from the desktop up: the fascinator
#@ Peter Sefton;Duncan Dickinson
#t 2010
#c 14
#! This poster describes the architecture of a new kind of digital repository service that includes components that run on desktop computers, designed to close the gap between Institutional Repositories (IRs) and the day-to-day electronic work environment used by researchers, and to address the too-often heard cry from repository managers of "we built it but they didn't come. The team at the Australian Digital Futures Institute are working with researchers to provide software that can (a) index and expose the research data content on their hard disks (b) extract metadata from files (c) automatically process data according to highly configurable workflows including producing web-ready renditions of research objects including documents, domain specific data visualizations (such as chemical molecules) and converting video and images so that they may be easily previewed. The architecture is inspired by the success of consumer software in two ways; the way entertainment programs organize content via faceted browse and search interfaces using embedded metadata, and the way photographic software allows content to be grouped into collections and pushed to online services, which are essentially repositories.

#index 1434177
#* A digital library architecture supporting massive small files and efficient replica maintenance
#@ Chunhui Shen;Weiming Lu;Jiangqin Wu;Baogang Wei
#t 2010
#c 14
#! In this paper, we presented a service infrastructure based on distributed file system for massive storage in digital library. In addition, we addressed the small-file problem by merging small files into big ones, and proposed a novel dynamic replica number adjustment scheme to ensure the maximal availability and reliability in a limited storage space.

#index 1434178
#* Text clustering with important words using normalization
#@ Shunyao Wu;Jinlong Wang;Huy Quan Vu;Gang Li
#t 2010
#c 14
#% 987328
#! Important words, which usually exist in part of Title, Subject and Keywords, can briefly reflect the main topic of a document. In recent years, it is a common practice to exploit the semantic topic of documents and utilize important words to achieve document clustering, especially for short texts such as news articles. This paper proposes a novel method to extract important words from Subject and Keywords of articles, and then partition documents only with those important words. Considering the fact that frequencies of important words are usually low and the scale matrix dataset for important words is small, a normalization method is then proposed to normalize the scale dataset so that more accurate results can be achieved by sufficiently exploiting the limited information. The experiments validate the effectiveness of our method.

#index 1434179
#* Liquid journals: scientific journals in the Web 2.0 era
#@ Marcos Baez;Alejandro Mussi;Fabio Casati;Aliaksandr Birukou;Maurizio Marchese
#t 2010
#c 14
#! In this demo we introduce a platform and a model of journal in the age of the Web called liquid journal. The goal of the model (and of the supporting platform) is to disseminate knowledge in the best possible way while also supporting scientists in the credit attribution. In a nutshell, liquid journals are collections of "interesting" links to scientific contributions, such as papers, blogs, datasets, that are related to certain topics. The content gets to the journal either by querying both conventional and non conventional sources on the Web or manually by the group of editors. Liquid journals combines depth and breath in bringing a wider spectrum of scientific contributions from different communities, while also focusing editors' and readers' attention on the things they care about. The demo illustrates the features and benefits of the proposed platform.

#index 1434180
#* Multiple sources with multiple portals: a demonstration of the ensemble computing portal in second life
#@ B. Stephen Carpenter, II;Richard Furuta;Frank Shipman;Allison Huie;Daniel Pogue;Edward A. Fox;Spencer Lee;Peter Brusilovsky;Lillian Cassel;Lois Delcambre
#t 2010
#c 14
#% 1213513
#% 1280180
#! This demonstration is an overview of our Ensemble pathway project with group members on-location at the conference and in the virtual world of Second Life from remote locations providing a live walk-through tour of our project online. This approach allows the demonstration to extend beyond the allocated conference session as a means to attract people to JCDL/ICADL.

#index 1434181
#* Capturing and curating published data
#@ Tim DiLauro;Mark Cyzyk;Elliot Metsger;Mark Patton
#t 2010
#c 14
#! Verifiability and reproducibility are core tenets of the scholarly communication process. For many scientific publications, however, it is often the case that supporting datasets are not preserved, even when the article text is. And when they are, it is usually as a collection of files without relationships amongst one another or to the articles with which they are associated. There are some existing approaches that attempt to link datasets with articles after the fact (e.g.,NED ), but they are relatively few and involve substantial human intervention. The Digital Research and Curation Center in the Johns Hopkins University Sheridan Libraries, in conjunction with its partners has developed a proof-of-concept system that demonstrates an approach to capturing datasets during the process of submitting the associated article. As part of this process, linkages are established between the datasets and the article.

#index 1434182
#* OntoFrame S3: academic research information portal service using semantic web technologies and linguistic knowledge
#@ Seungwoo Lee;Mikyoung Lee;Pyung Kim;Hanmin Jung;Won-Kyung Sung
#t 2010
#c 14
#! In this paper, we show how Semantic Web technologies can be used for information connection and fusion in academic research information service and empowered by linguistic knowledge.

#index 1434183
#* Entertainment history museums in virtual worlds: video game and music preservation in second life
#@ Spencer Lee;Bradley Willis;Joseph S. Bourne, Jr.;Edward A. Fox
#t 2010
#c 14
#! This research explores and demonstrates the use of Second Life (the popular 3D virtual world) for the purpose of digitally preserving various aspects of video game and music history. Physical game interfaces like joysticks, advertisements used for games, and famous game characters and cultural icons over the history are displayed and preserved in multiple video game exhibits for different eras. Selected game characters are digitally recreated in 3D format as Second Life avatar appearances. Historical changes of musical instruments, musicians, and genres are displayed and preserved likewise. Selected musical instruments are digitally recreated as 3D models playing their real sounds. Some of them will be available for the visitors to play in basic ways.

#index 1434184
#* Integrating greenstone with an interactive map visualizer
#@ Sam McIntosh;David Bainbridge
#t 2010
#c 14
#! This extended abstract describes recent work in combining interactive map functionality with the Greenstone 3 digital library software research framework.

#index 1434185
#* Subject metadata support powered by Maui
#@ Olena Medelyan;Vye Perrone;Ian H. Witten
#t 2010
#c 14

#index 1434186
#* Recommender system for MIR research community
#@ Yi Yu;Vincent Oria;J. Stephen Downie
#t 2010
#c 14
#! In this demonstration, we show a recommender system for the Music Information Retrieval (MIR) research community. We extract the key topics and tags by analyzing the ten-year cumulative ISMIR proceedings, and recommend papers and research colleagues to users in an interactive way.

#index 1588346
#* Proceedings of the 11th annual international ACM/IEEE joint conference on Digital libraries
#@ Glen Newton;Michael Wright;Lillian Cassel
#t 2011
#c 14
#! Welcome and Bienvenue to JCDL 2011! We are delighted to welcome you to Canada's capital, Ottawa, for the 11th annual international ACM/IEEE Joint Conference on Digital Libraries (JCDL). JCDL is a major international forum that focuses on digital libraries and associated educational, technical and social issues. The conference theme this year is "Digital Libraries: Bringing Together Scholars, Scholarship and Research Data", and the program reflects the theme as well as the broader context of digital libraries. We trust that you will find that this year's conference maintains previous conferences' commitment to excellence and reflection of the area's multi-faceted interests. This year's conference is hosted by the University of Ottawa on their campus next to the historic Rideau Canal and just 10 minutes walk from the Parliament buildings, the National Gallery, the Royal Canadian Mint, the National War Memorial and the Byward Market. Slightly further you will find the Governor General's Residence (Rideau Hall), the Museum of Nature, the War Museum, the Aviation and Space Museum, the Science and Tech Museum, and the Deifenbunker. Just across the Ottawa River, the city of Gatineau in Quebec hosts the Museum of Civilization, the Casino du Lac-Leamy, many excellent restaurants and act as the gateway to the Gatineau Park. Just a 15 minute drive from Ottawa, the park offers 125 kilometres of hiking trails, 50 glacial lakes and 356 square kilometres of Canadian Shield inhabited by white tailed deer, coyotes, black bear, timber wolves and beaver. On behalf of the Organizing Committee, we would like to thank the local organizing committee, students and volunteers who supported the conference in its various stages. A special mention has to be made regarding the local support of Patrick Labelle and Cynthia Bail, on whom much of the local organization rested. Each day of the main conference will begin with a keynote. The opening keynote will be given by Daniel J. Caron, the Librarian and Archivist of Canada. Our second speaker is Joan Morris DiMicco from the Visual Communication Lab of IBM Research and our closing keynote will be given by Christopher Barnes, the current Director of the NEPTUNE project, a major Canadian ocean sciences initiative. This year, we received 243 submissions that went through rigorous review resulting in a program that reflects the high quality of research being conducted on digital libraries in many disciplines. From 99 full papers and 78 short papers, the Program Committee selected 28 full papers and 29 short papers for presentation and inclusion in the conference proceedings. In addition, 32 posters and 15 demonstrations will be presented, and abstracts for these also appear in the proceedings. Demonstrations will be viewable during the lunch period on the first day of the main conference. Posters, and accompanying minute madness, will be viewable during the poster reception. The Vannevar Bush Best Paper Award, and the Best Student Paper Award will be presented at the conference banquet. JCDL 2011 continues the tradition of supporting digital library developers with 6 tutorials that cover a range of timely issues including user studies, preservation planning, and topics on teaching about digital libraries. The program also includes 6 workshops, which provide a venue for a cross-section of disciplines to explore focused, cutting-edge topics including disciplinary repositories, web archives and preservation, and visualization.

#index 1588347
#* Measuring historical word sense variation
#@ David Bamman;Gregory Crane
#t 2011
#c 14
#% 81669
#% 211043
#% 579944
#% 642994
#% 740915
#% 766439
#% 815895
#% 817476
#% 817596
#% 854625
#% 854743
#% 939511
#% 967300
#% 995019
#% 1269524
#% 1271719
#% 1275666
#% 1434122
#% 1470574
#! We describe here a method for automatically identifying word sense variation in a dated collection of historical books in a large digital library. By leveraging a small set of known translation book pairs to induce a bilingual sense inventory and labeled training data for a WSD classifier, we are able to automatically classify the Latin word senses in a 389 million word corpus and track the rise and fall of those senses over a span of two thousand years. We evaluate the performance of seven different classifiers both in a tenfold test on 83,892 words from the aligned parallel corpus and on a smaller, manually annotated sample of 525 words, measuring both the overall accuracy of each system and how well that accuracy correlates (via mean square error) to the observed historical variation.

#index 1588348
#* Structure extraction from PDF-based book documents
#@ Liangcai Gao;Zhi Tang;Xiaofan Lin;Ying Liu;Ruiheng Qiu;Yongtao Wang
#t 2011
#c 14
#% 25998
#% 202029
#% 280817
#% 442840
#% 493646
#% 658716
#% 718609
#% 721140
#% 844833
#% 844970
#% 874518
#% 1065294
#% 1078010
#% 1141106
#% 1141110
#% 1213417
#% 1283451
#% 1283612
#% 1433495
#% 1740420
#! Nowadays PDF documents have become a dominating knowledge repository for both the academia and industry largely because they are very convenient to print and exchange. However, the methods of automated structure information extraction are yet to be fully explored and the lack of effective methods hinders the information reuse of the PDF documents. To enhance the usability for PDF-formatted electronic books, we propose a novel computational framework to analyze the underlying physical structure and logical structure. The analysis is conducted at both page level and document level, including global typographies, reading order, logical elements, chapter/section hierarchy and metadata. Moreover, two characteristics of PDF-based books, i.e., style consistency in the whole book document and natural rendering order of PDF files, are fully exploited in this paper to improve the conventional image-based structure extraction methods. This paper employs the bipartite graph as a common structure for modeling various tasks, including reading order recovery, figure and caption association, and metadata extraction. Based on the graph representation, the optimal matching (OM) method is utilized to find the global optima in those tasks. Extensive benchmarking using real-world data validates the high efficiency and discrimination ability of the proposed method.

#index 1588349
#* Word order matters: measuring topic coherence with lexical argument structure
#@ Steve Spagnola;Carl Lagoze
#t 2011
#c 14
#% 722904
#% 876067
#% 1434145
#% 1592095
#! Topic models are emerging tools for improved browsing and searching within digital libraries. These techniques collapse words within documents into unordered "bags of words," ignoring word order. In this paper, we present a method that examines syntactic dependency parse trees from Wikipedia article titles to learn expected patterns between relative lexical arguments. This process is highly dependent on the global word ordering of a sentence, modeling how each word interacts with other words to gain an aggregate perspective on how words interact over all 3.2 million titles. Using this information, we analyze how coherent a given topic is by comparing the relative usage vectors between the top 5 words in a topic. Results suggest that this technique can identify poor topics based on how well the relative usages align with each other within a topic, potentially aiding digital library indexing.

#index 1588350
#* Phrases as subtopical concepts in scholarly text
#@ Asif-ul Haque;Paul Ginsparg
#t 2011
#c 14
#% 281480
#% 420487
#% 534271
#% 823348
#% 989608
#% 1214671
#! Retrieval of subtopical concepts from scholarly communication systems is now possible through a combination of text and metadata analysis, augmented by user search queries and click logs. Here we investigate how a "phrase", defined as a variable length sequence of vocabulary words, can be used to represent a concept. We present a method to extract such phrases from a text corpus, and rank them using a citation network measure, the compensated normalized link count (CNLC), which measures the extent to which they are propagated along the citation structure of articles. We validate the ranking with actively and passively determined metrics: comparison with human-assigned keywords, and comparison with passively harvested terms from search query logs. This method is demonstrated on full texts and abstracts from 7 years of high energy physics articles from the arXiv preprint database.

#index 1588351
#* Game development documentation and institutional collection development policy
#@ Megan A. Winget;Wiliam Walker Sampson
#t 2011
#c 14
#% 740229
#% 759201
#% 839390
#% 930001
#% 1058838
#% 1202183
#% 1260246
#% 1487221
#! Videogames and other new media artifacts constitute an important part of our cultural and economic landscape and collecting institutions have a responsibility to collect and preserve these materials for future access. Unfortunately, these kinds of materials present unique challenges for collecting institutions including problems of collection development, technological preservation, and access. This paper presents findings from a grant-funded project focused on examining documentation of the creative process in game development. Data includes twelve qualitative interviews conducted with individuals involved in the game development process, spanning a number of different roles and institution types. The most pressing findings are related to the nature of documentation in the videogame industry: project interviews indicate that the game development process does produce significant and important documentation as traditionally conceived by collecting institutions, ranging from game design documents to email correspondence and business reports. However, while it does exist, traditional documentation does not adequately, or even, at times, truthfully represent the project or the game creation process as a whole. In order to adequately represent the development process, collecting institutions also need to seek out and procure numerous versions of games and game assets as well as those game assets that are natural byproducts of the design process like gamma and beta versions of the game, for example, vertical slices, or different renderings of graphical elements.

#index 1588352
#* That's 'é' not 'þ' '?' or '◓': a user-driven context-aware approach to erroneous metadata in digital libraries
#@ David Bainbridge;Michael B. Twidale;David M. Nichols
#t 2011
#c 14
#% 874492
#% 919391
#% 1090229
#% 1211086
#% 1213414
#% 1495103
#% 1549965
#% 1550660
#! In this paper we present a novel system for user-driven integration of name variants when interacting with web-based information systems. The growth and diversity of online information means that many users experience disambiguation and collocation errors in their information searching. We approach these issues via a client-side JavaScript browser extension that can reorganise web content and also integrate remote data sources. The system is illustrated through three worked examples using existing digital libraries.

#index 1588353
#* FRBR and facets provide flexible, work-centric access to items in library collections
#@ Kelley McGrath;Bill Kules;Chris Fitzpatrick
#t 2011
#c 14
#! This paper explores a technique to improve searcher access to library collections by providing a faceted search interface built on a data model based on the Functional Requirements for Bibliographic Records (FRBR). The prototype provides a Work-centric view of a moving image collection that is integrated with bibliographic and holdings data. Two sets of facets address important user needs: "what do you want?" and "how/where do you want it?" enabling patrons to narrow, broaden and pivot across facet values instead of limiting them to the tree-structured hierarchy common with existing FRBR applications. The data model illustrates how FRBR is being adapted and applied beyond the traditional library catalog.

#index 1588354
#* What do you call it?: a comparison of library-created and user-created tags
#@ Catherine E. Hall;Michael A. Zarro
#t 2011
#c 14
#% 263939
#% 881054
#% 955010
#% 1190008
#% 1399985
#% 1434164
#% 1491125
#% 1495092
#% 1497579
#! In this paper, we describe an exploratory study comparing the abstracting and indexing practices of a semi-expert LIS community (metadata creators for the digital library, ipl2) and the social tags generated by Delicious users for the same corpus of materials. We find over 88% of the resources in the ipl2 History collection were tagged at least once in Delicious. Overlap between the tags applied to ipl2 resources and indexing shows terms that the two groups are similar enough to be useful, yet dissimilar enough to provide new access points and description.

#index 1588355
#* Extending digital repository architectures to support disk image preservation and access
#@ Kam Woods;Christopher A. Lee;Simson Garfinkel
#t 2011
#c 14
#% 642012
#% 760864
#% 793401
#% 952356
#% 1046190
#% 1325863
#% 1542823
#! Disk images (bitstreams extracted from physical media) can play an essential role in the acquisition and management of digital collections by serving as containers that support data integrity and chain of custody, while ensuring continued access to the underlying bits without depending on physical carriers. Widely used today by practitioners of digital forensics, disk images can serve as baselines for comparison for digital preservation activities, as they provide fail-safe mechanisms when curatorial actions make unexpected changes to data; enable access to potentially valuable data that resides below the file system level; and provide options for future analysis. We discuss established digital forensics techniques for acquiring, preserving and annotating disk images, provide examples from both research and educational collections, and describe specific forensic tools and techniques, including an object-oriented data packaging framework called the Advanced Forensic Format (AFF) and the Digital Forensics XML (DFXML) metadata representation.

#index 1588356
#* Preservation decisions: terms and conditions apply
#@ Christoph Becker;Andreas Rauber
#t 2011
#c 14
#% 1065290
#% 1395495
#% 1406451
#! Decisions in digital preservation pose the delicate mission of balancing desired goals of authentic long-term access with the technical means available to date. Organisations with a commitment to the long-term value of information and knowledge have to take decisions on several levels to achieve their business goals with the evolving technology of the day. This article explores the decision space in digital preservation, with a focus on what can be called the core decision: how to preserve content information. We undertake a critical analysis of the challenges, constraints and objectives of decision making, and discuss the experience in applying the Planets preservation planning method, supported by the planning tool Plato, to real-world business decisions. Based on this methodology and substantial real-world experience in decision making, we present a set of observation points that address issues frequently raised in decision making. The conclusions shall contribute to a clarified understanding of the state of the art and future challenges in scalable decision making for long-term preservation.

#index 1588357
#* Ember: a case study of a digital memorial museum of born-digital artifacts
#@ Paul Logasa Bogen, II;Richard Furuta
#t 2011
#c 14
#% 235916
#% 342044
#% 378480
#% 378515
#% 750866
#% 874485
#! This paper discusses the creation of Ember, a collection of borndigital artifacts generated in the aftermath of the 1999 Aggie Bonfire collapse. Ember is an example of a previously unexamined class of cultural heritage digital libraries, which we describe as a digital memorial museum. Ember's artifacts consist of emails, photos, documents, and web pages that the communities surrounding the tragedy created. Due to the community investment and the personal nature of the artifacts, concerns arise on how the collection should be properly handled, which leads us to propose "Sensitivity" as an addition to the 5S model. Initially, we are focusing on the email portion of the collection, which can be viewed as the basis of an emerging oral tradition surrounding the Bonfire tragedy.

#index 1588358
#* SimDL: a model ontology driven digital library for simulation systems
#@ Jonathan Leidig;Edward A. Fox;Kevin Hall;Madhav Marathe;Henning Mortveit
#t 2011
#c 14
#% 1434148
#% 1434150
#% 1434158
#% 1434160
#! We propose a digital library design to support epidemic and public health simulation experiments in which model ontologies direct collection organization, user interface construction, and discovery. We have developed a SimDL instantiation of the ontological design tailored for a typical experimentation workflow. SimDL relies on an XML Schema description of a simulation model to form a domain and model specific ontology. We show this approach useful in building digital libraries to support collaborative simulation efforts.

#index 1588359
#* Eliminating the redundancy in blocking-based entity resolution methods
#@ George Papadakis;Ekaterini Ioannou;Claudia Niederée;Themis Palpanas;Wolfgang Nejdl
#t 2011
#c 14
#% 201889
#% 310516
#% 479973
#% 480654
#% 577247
#% 760866
#% 809459
#% 809460
#% 810014
#% 819552
#% 830529
#% 871766
#% 875066
#% 913783
#% 915242
#% 931291
#% 967272
#% 967295
#% 1213413
#% 1217163
#% 1250576
#% 1292496
#% 1372726
#% 1536558
#% 1587729
#! Entity resolution is the task of identifying entities that refer to the same real-world object. It has important applications in the context of digital libraries, such as citation matching and author disambiguation. Blocking is an established methodology for efficiently addressing this problem; it clusters similar entities together, and compares solely entities inside each cluster. In order to effectively deal with the current large, noisy and heterogeneous data collections, novel blocking methods that rely on redundancy have been introduced: they associate each entity with multiple blocks in order to increase recall, thus increasing the computational cost, as well. In this paper, we introduce novel techniques that remove the superfluous comparisons from any redundancy-based blocking method. They improve the time-efficiency of the latter without any impact on the end result. We present the optimal solution to this problem that discards all redundant comparisons at the cost of quadratic space complexity. For applications with space limitations, we also present an alternative, lightweight solution that operates at the abstract level of blocks in order to discard a significant part of the redundant comparisons. We evaluate our techniques on two large, real-world data sets and verify the significant improvements they convey when integrated into existing blocking methods.

#index 1588360
#* Detecting and exploiting stability in evolving heterogeneous information spaces
#@ George Papadakis;George Giannakopoulos;Claudia Niederée;Themis Palpanas;Wolfgang Nejdl
#t 2011
#c 14
#% 201889
#% 480654
#% 587758
#% 875066
#% 913783
#% 926881
#% 1055715
#% 1055761
#% 1063536
#% 1065278
#% 1090361
#% 1166533
#% 1190247
#% 1217163
#% 1217173
#% 1292496
#% 1301004
#% 1355017
#% 1399992
#% 1482241
#% 1494946
#% 1536558
#! Individuals contribute content on the Web at an unprecedented rate, accumulating immense quantities of (semi-)structured data. Wisdom of the Crowds theory advocates that such information (or parts of it) is constantly overwritten, updated, or even deleted by other users, with the goal of rendering it more accurate, or up-to-date. This is particularly true for the collaboratively edited, semi-structured data of entity repositories, whose entity profiles are consistently kept fresh. Therefore, their core information that remain stable with the passage of time, despite being reviewed by numerous users, are particularly useful for the description of an entity. Based on the above hypothesis, we introduce a classification scheme that predicts, on the basis of statistical and content patterns, whether an attribute (i.e., name-value pair) is going to be modified in the future. We apply our scheme on a large, real-world, versioned dataset and verify its effectiveness. Our thorough experimental study also suggests that reducing entity profiles to their stable parts conveys significant benefits to two common tasks in computer science: information retrieval and information integration.

#index 1588361
#* Classification of user interest patterns using a virtual folksonomy
#@ Ricardo Kawase;Eelco Herder
#t 2011
#c 14
#% 186340
#% 233808
#% 268079
#% 954970
#% 1047435
#% 1128907
#% 1130827
#% 1355035
#% 1355036
#% 1399957
#% 1399989
#% 1426509
#% 1536522
#% 1667787
#! User interest in topics and resources is known to be recurrent and to follow specific patterns, depending on the type of topic or resource. Traditional methods for predicting reoccurring patterns are based on ranking and associative models. In this paper we identify several 'canonical' patterns by clustering keywords related to visited resources, making use of a large repository of Web usage data. The keywords are derived from a 'virtual' folksonomy of tags assigned to these resources using a collaborative bookmarking system.

#index 1588362
#* Tags in domain-specific sites: new information?
#@ Jeremy Steinhauer;Lois M.L. Delcambre;David Maier;Marianne Lykke;Vu H. Tran
#t 2011
#c 14
#% 855601
#% 956544
#% 1131169
#% 1155912
#% 1166510
#% 1213428
#% 1213437
#% 1227592
#! If researchers use tags in retrieval applications they might assume, implicitly, that tags represent novel information, e.g., when they attribute performance improvement in their retrieval algorithm(s) to the use of tags. In this work, we investigate whether this assumption is true. We focus on the use of tags in domain-specific websites because such websites are more likely to have a coherent, discernible website structure and because the users that are searching for and tagging pages in such a site may have specific information needs (as opposed to the broad range of information needs that users have when browsing/searching the Internet at large). For this study, we assume that the application of the same tag to multiple pages provides an indication that those pages are related. To determine whether this indication of relatedness is contributing new information, we first measure whether pages with common tag(s) could have been deemed as related based on site structure as measured by shortest navigational distance between pages. Second, we measure whether or not tags could have been determined algorithmically based on standard tf-idf scores of terms on the page. Based on our analysis of two different sites, we found that tags contribute novel information that is not discernible from site structure or site/page content.

#index 1588363
#* Archiving the web using page changes patterns: a case study
#@ Myriam Ben Saad;Stéphane Gançarski
#t 2011
#c 14
#% 268087
#% 309746
#% 330604
#% 348137
#% 438251
#% 480136
#% 508280
#% 630984
#% 640706
#% 731406
#% 754078
#% 754107
#% 785872
#% 805879
#% 835872
#% 874209
#% 917970
#% 963679
#% 982751
#% 985041
#% 1015260
#% 1055715
#% 1166533
#% 1181189
#% 1183221
#% 1190280
#% 1328158
#% 1384880
#% 1490109
#! A pattern is a model or a template used to summarize and describe the behavior (or the trend) of a data having generally some recurrent events. Patterns have received a considerable attention in recent years and were widely studied in the data mining field. Various pattern mining approaches have been proposed and used for different applications such as network monitoring, moving object tracking, financial or medical data analysis, scientific data processing, etc. In these different contexts, discovered patterns were useful to detect anomalies, to predict data behavior (or trend), or more generally, to simplify data processing or to improve system performance. However, to the best of our knowledge, patterns have never been used in the context of web archiving. Web archiving is the process of continuously collecting and preserving portions of the World Wide Web for future generations. In this paper, we show how patterns of page changes can be useful tools to efficiently archive web sites. We first define our pattern model that describes the changes of pages. Then, we present the strategy used to (i) extract the temporal evolution of page changes, to (ii) discover patterns and to (iii) exploit them to improve web archives. We choose the archive of French public TV channels « France Télévisions » as a case study in order to validate our approach. Our experimental evaluation based on real web pages shows the utility of patterns to improve archive quality and to optimize indexing or storing.

#index 1588364
#* On identifying academic homepages for digital libraries
#@ Sujatha Das Gollapalli;C. Lee Giles;Prasenjit Mitra;Cornelia Caragea
#t 2011
#c 14
#% 268114
#% 503216
#% 590523
#% 614036
#% 641770
#% 722904
#% 766414
#% 769953
#% 855602
#% 869499
#% 878641
#% 907547
#% 967259
#% 989661
#% 1030805
#% 1083734
#% 1117023
#% 1130819
#% 1131829
#% 1176887
#% 1226275
#% 1275180
#% 1301004
#% 1318658
#% 1400108
#% 1663664
#% 1734617
#! Academic homepages are rich sources of information on scientific research and researchers. Most researchers provide information about themselves and links to their research publications on their homepages. In this study, we address the following questions related to academic homepages: (1) How many academic homepages are there on the web? (2) Can we accurately discriminate between academic homepages and other webpages? and (3) What information can be extracted about researchers from their homepages? For addressing the first question, we use mark-recapture techniques commonly employed in biometrics to estimate animal population sizes. Our results indicate that academic homepages comprise a small fraction of the Web making automatic methods for discriminating them crucial. We study the performance of content-based features for classifying webpages. We propose the use of topic models for identifying content-based features for classification and show that a small set of LDA-based features out-perform term features selected using traditional techniques such as aggregate term frequencies or mutual information. Finally, we deal with the extraction of name and research interests information from an academic homepage. Term-topic associations obtained from topic models are used to design a novel, unsupervised technique to identify short segments corresponding to research interests of the researchers specified in academic homepages. We show the efficacy of our proposed methods on all the three tasks by experimentally evaluating them on multiple publicly-available datasets.

#index 1588365
#* How much of the web is archived?
#@ Scott G. Ainsworth;Ahmed Alsum;Hany SalahEldeen;Michele C. Weigle;Michael L. Nelson
#t 2011
#c 14
#% 608625
#% 807320
#% 967290
#% 1091268
#% 1682003
#! The Memento Project's archive access additions to HTTP have enabled development of new web archive access user interfaces. After experiencing this web time travel, the in- evitable question that comes to mind is "How much of the Web is archived?" This question is studied by approximating the Web via sampling URIs from DMOZ, Delicious, Bitly, and search engine indexes and measuring number of archive copies available in various public web archives. The results indicate that 35%-90% of URIs have at least one archived copy, 17%-49% have two to five copies, 1%-8% have six to ten copies, and 8%-63% at least ten copies. The number of URI copies varies as a function of time, but only 14.6-31.3% of URIs are archived more than once per month.

#index 1588366
#* Rediscovering missing web pages using link neighborhood lexical signatures
#@ Martin Klein;Jeb Ware;Michael L. Nelson
#t 2011
#c 14
#% 340928
#% 577300
#% 674852
#% 679872
#% 754090
#% 773040
#% 781168
#% 818221
#% 881570
#% 967290
#% 1107070
#! For discovering the new URI of a missing web page, lexical signatures, which consist of a small number of words chosen to represent the "aboutness" of a page, have been previously proposed. However, prior methods relied on computing the lexical signature before the page was lost, or using cached or archived versions of the page to calculate a lexical signature. We demonstrate a system of constructing a lexical signature for a page from its link neighborhood, that is the "backlinks", or pages that link to the missing page. After testing various methods, we show that one can construct a lexical signature for a missing web page using only ten backlink pages. Further, we show that only the first level of backlinks are useful in this effort. The text that the backlinks use to point to the missing page is used as input for the creation of a four-word lexical signature. That lexical signature is shown to successfully find the target URI in more than half of the test cases.

#index 1588367
#* That's news to me: the influence of perceived gratifications and personal experience on news sharing in social media
#@ Long Ma;Chei Sian Lee;Dion Hoe-Lian Goh
#t 2011
#c 14
#% 297994
#% 1264592
#% 1332666
#% 1332667
#% 1411416
#% 1411585
#% 1432763
#% 1485929
#! Sharing news is a popular activity in social media and influence both individuals and society. However, little empirical research has been conducted to explore the motivations underlying users' news sharing behavior. Adopting the uses and gratifications perspective, this study examined the role of gratification factors and user experience in explaining users' news sharing intention on social media. Hierarchical regression was employed to analyze the data collected from 144 undergraduate and graduate students. The results show that status seeking was the strongest motivation in predicting news sharing intention, followed by sociality and informativeness. However, entertainment/escapism was not a significant predictor in contrast to prior work. Further, we examined user experience in predicting news sharing intention and identified it as a significant factor.

#index 1588368
#* Facilitating content creation and content research in building the city of lit digital library
#@ Haowei Hsieh;Bridget Draxler;Nicole Dudley;Jim Cremer;Lauren Haldeman;Dat Nguyen;Peter Likarish;Jon Winet
#t 2011
#c 14
#% 881134
#% 1001086
#% 1213410
#% 1467158
#% 1588447
#! In conjunction with Iowa City's designation as a UNESCO "City of Literature," an interdisciplinary research team at The University of Iowa collaborated to develop a digital library featuring important Iowa City authors and locations. The "City of Lit" digital library consists of a mobile application for the general public and a set of web-based interfaces for researchers and content creators. This paper explains the motivation and describes the design and implementation of the digital library, its framework, the user-side mobile app and our future plans. We also outline a pilot study, in which undergraduate students conducted scholarly research and created content for the digital collection.

#index 1588369
#* Towards a new reading experience via semantic fusion of text and music
#@ Ling Zhuang;Zhenchao Ye;Jiangqin Wu;Feng Zhou;Jian Shao
#t 2011
#c 14
#% 724320
#% 1121528
#% 1171193
#% 1298156
#% 1434136
#% 1434137
#% 1484424
#% 1495095
#% 1693366
#% 1775936
#! In CADAL, there preserve a lot of Chinese classical literatures, including graceful prose and verse. These works written in ancient Chinese comparatively are concise in vocabulary and sentence patterns. But they express rich feelings and convey a wealth of information. Although can be explained in modern Chinese, the aesthetic sense in those works disappears. So we aim to illustrate the feeling in these works using Chinese traditional music which is also another part of Chinese culture. This is an interesting and challenging work. In this paper, the correlation between the text and music is studied. A novel approach is proposed to model the latent semantic association underlying the two medium. Based on the correlation model we learned from training data, we can associate a literary work (mainly verse and prose in our digital library) with a few music pieces automatically. When a reader is appreciating a literary work, a piece of background music is playing meanwhile, the information and emotion implied by the work and music blend together. The reader may be immersed into the emotion and obtain aesthetic enjoyment intensively. We implement the proposed method and design experiments to evaluate the performance of it. The experimental result substantiates the feasibility of the proposed approach in this paper.

#index 1588370
#* Indexing musical pieces using their major repetition
#@ Benjamin Martin;Pierre Hanna;Matthias Robine;Pascal Ferraro
#t 2011
#c 14
#% 546096
#% 917087
#% 1021652
#% 1767273
#% 1767355
#% 1775325
#! With the growing presence of large collections of musical content, methods for facilitating efficient browsing and fast comparisons of audio pieces become more and more useful. Notably, methods that isolate relevant parts in audio pieces give an insight of the musical content and can be used to improve similarity evaluation systems. In this context, we propose an indexing method that allows retrieving in audio signals particular parts, namely a major repetition. We use harmonic representations together with string matching techniques to strictly define and isolate such segments. Experiments on state-of-the-art structural datasets show a strong correlation between the retrieved parts and the perceived structure of pieces.

#index 1588371
#* The ownership and reuse of visual media
#@ Catherine C. Marshall;Frank M. Shipman
#t 2011
#c 14
#% 127790
#% 1047347
#% 1384267
#% 1384364
#% 1469901
#% 1573469
#! This paper presents the results of a study of the ownership and reuse of visual media. A survey was administered to 250 social media-savvy respondents to investigate their attitudes about saving, sharing, publishing, and removing online photos; the survey also explored participants' current photo-sharing and reuse practices, and their general expectations of photo reuse. Our probe of respondent attitudes revealed that respondents felt: (1) people should be able to save visual media, regardless of its source; (2) people have slightly less right to reuse photos than they do to save them; (3) a photo's subject has a slightly greater right than the photographer to reuse the photo in non-commercial situations; (4) removal is controversial, but trends more positive when it involves only metadata (e.g. tags); and (5) access to institutional archives of personal photos is better deferred for 50 years. Participants explained their own reuse of online photos in pragmatic terms that included the nature of the content, the aim and circumstances of reuse, their sense of the photo's original use, and their understanding of existing laws and restrictions. In the abstract, the same general question revealed a 'reuse paradox'; while respondents trust themselves to make this judgment, they do not trust the reciprocal judgment of unknown others.

#index 1588372
#* Using national bibliographies for rights clearance
#@ Nuno Freire;Andreas Juffinger
#t 2011
#c 14
#% 1153234
#% 1153244
#% 1406461
#% 1434146
#% 1734587
#! In the process of digitizing a book, a library needs to clear the rights associated with it. Rights clearance is a time consuming process, and possibly, with higher costs than the actual digitization. To analyze the rights situation, a range of information is required, which is distributed across several national databases hosted in national libraries, publishers and collective rights organizations. National bibliographies are key data sources in these processes, as they are the only source to identify all the publications of a specific intellectual work per country. However, national bibliographies are not built for rights clearance purposes. The information in bibliographic records results from cataloguing practices with users and library management in mind, and links between different publications of a single intellectual work are not available. This paper presents a study on the implications of data quality problems of national bibliographies for the identification of all publications of a work. It also presents an approach for work data extraction and matching based on similarity of the most discriminatory attributes of works. Evaluation has shown that the data quality problems are difficult to overcome, as our best approach achieved an F0,5-measure of 0,91. These results help to speed up the process of discovering all relevant publications per work significantly, with sufficient recall.

#index 1588373
#* SharedCanvas: a collaborative model for medieval manuscript layout dissemination
#@ Robert Sanderson;Benjamin Albritton;Rafael Schwemmer;Herbert Van de Sompel
#t 2011
#c 14
#% 809441
#% 1006543
#% 1065245
#% 1187624
#% 1213441
#% 1434121
#% 1434153
#% 1472885
#! In this paper we present a model based on the principles of Linked Data that can be used to describe the interrelationships of images, texts and other resources to facilitate the interoperability of repositories of medieval manuscripts or other culturally important handwritten documents. The model is designed from a set of requirements derived from the real world use cases of some of the largest digitized medieval content holders, and instantiations of the model are intended as the input to collection-independent page turning and scholarly presentation interfaces. A canvas painting paradigm, such as in PDF and SVG, was selected based on the lack of a one to one correlation between image and page, and to fulfill complex requirements such as when the full text of a page is known, but only fragments of the physical object remain. The model is implemented using technologies such as OAI-ORE Aggregations and OAC Annotations, as the fundamental building blocks of emerging Linked Digital Libraries. The model and implementation are evaluated through prototypes of both content providing and consuming applications. Although the system was designed from requirements drawn from the medieval manuscript domain, it is applicable to any layout-oriented presentation of images of text.

#index 1588374
#* Use of subimages in fish species identification: a qualitative study
#@ Uma Murthy;Lin Tzy Li;Eric Hallerman;Edward A. Fox;Manuel A. Perez-Quinones;Lois M. Delcambre;Ricardo da S. Torres
#t 2011
#c 14
#% 32599
#% 201906
#% 237318
#% 536334
#% 743927
#% 874493
#% 1074244
#% 1107042
#% 1431371
#! Many scholarly tasks involve working with subdocuments, or contextualized fine-grain information, i.e., with information that is part of some larger unit. A digital library (DL) facilitates management, access, retrieval, and use of collections of data and metadata through services. However, most DLs do not provide infrastructure or services to support working with subdocuments. Superimposed information (SI) refers to new information that is created to reference subdocuments in existing information resources. We combine this idea of SI with traditional DL services, to define and develop a DL with SI (SI-DL). We explored the use of subimages and evaluated the use of SuperIDR, a prototype SI-DL, in fish species identification, a scholarly task that involves working with subimages. The contexts and strategies of working with subimages in SuperIDR suggest new and enhanced support (SI-DL services) for scholarly tasks that involve working with subimages, including new ways of querying and searching for subimages and associated information. The main conceptual contributions of our work are the insights gained from these findings of the use of subimages and of SuperIDR, which lead to recommendations for the design of digital libraries with superimposed information.

#index 1588375
#* Persistent annotations deserve new URIs
#@ Abdulla Alasaadi;Michael L. Nelson
#t 2011
#c 14
#% 1211586
#% 1434121
#! Some digital libraries support annotations, but sharing these annotations with other systems or across the web is difficult because of the need of special applications to read and decode these annotations. Due to the frequent change of web resources, the annotation's meaning can change if the underlying resources change. This project concentrates on minting a new URI for every annotation and creating a persistent and independent archived version of all resources. Users should be able to select a segment of an image or a video to be part of the annotation. The media fragment URIs described in the Open Annotation Collaboration data model can be used, but in practice they have limits, and they face the lack of support by the browsers. So in this project the segments of images, and videos can be used in the annotations without using media fragment URIs.

#index 1588376
#* Semantically augmented annotations in digitized map collections
#@ Rainer Simon;Bernhard Haslhofer;Werner Robitza;Elaheh Momeni
#t 2011
#c 14
#% 284884
#% 330770
#% 867366
#% 1211586
#% 1454306
#% 1549963
#! Historic maps are valuable scholarly resources that record information often retained by no other written source. With the YUMA Map Annotation Tool we want to facilitate collaborative annotation for scholars studying historic maps, and allow for semantic augmentation of annotations with structured, contextually relevant information retrieved from Linked Open Data sources. We believe that the integration of Web resource linkage into the scholarly annotation process is not only relevant for collaborative research, but can also be exploited to improve search and retrieval. In this paper, we introduce the COMPASS Experiment, an ongoing crowdsourcing effort in which we are collecting data that can serve as a basis for evaluating our assumption. We discuss the scope and setup of the experiment framework and report on lessons learned from the data collected so far.

#index 1588377
#* Integrating implicit structure visualization with authoring promotes ideation
#@ Andrew M. Webb;Andruid Kerne
#t 2011
#c 14
#% 51395
#% 68659
#% 147960
#% 151395
#% 187989
#% 214669
#% 232895
#% 237318
#% 259946
#% 270633
#% 291980
#% 295522
#% 337490
#% 406493
#% 579901
#% 614060
#% 769227
#% 789234
#% 801381
#% 857478
#% 874453
#% 896064
#% 967244
#% 967245
#% 1013546
#% 1015205
#% 1070496
#% 1095879
#% 1214211
#% 1434138
#% 1584685
#! We need to harness the growing wealth of information in digital libraries to support intellectual work involving creative and exploratory processes. Prior research on hypertext authoring shifted the focus from explicit structure to direct presentation of content aided by "implicit" spatial representation of structure. We likewise shift the field of information visualization. Using hypertext's rubric, we redefine what most people think of as "information visualization" as explicit structure visualization. We alternatively address implicit structure visualization, presenting content directly, representing structure with spatiality and other visual features. We integrate authoring to emphasize the role of human thought in learning and ideation. Prior research has shown that people iteratively collect and organize information by clipping magazines, piling clippings in somewhat messy ways, and organizing them. MessyOrganizer is an iterative implicit structure visualization algorithm which, like human practice, gradually collects and organizes information clippings. Content is depicted directly. Structural relationships are visualized implicitly through spatial positioning of related elements, with overlap and translucence. The simulated annealing algorithm is applied to a model of semantic relatedness over a spatial grid. We develop an experiment comparing products created with the integrated environment versus separated visualization and authoring spaces. Results reveal that participants have more novel and varied ideas when visualization is integrated with authoring.

#index 1588378
#* Visualizing collaboration networks implicit in digital libraries using OntoStarFish
#@ J. Alfredo Sánchez;Ofelia Cervantes;Alfredo Ramos;María Auxilio Medina;Juan Carlos Lavariega;Eric Balam
#t 2011
#c 14
#% 18033
#% 270702
#% 270713
#% 343135
#% 434557
#% 619859
#% 722624
#% 764282
#% 805202
#% 810660
#% 994152
#% 1047327
#% 1083737
#% 1214211
#% 1396151
#% 1541731
#! This paper presents the design rationale and initial findings derived from preliminary usage of OntoStarFish, a visualization technique aimed at taking advantage of implicit relationships that can be inferred from large collections of documents in digital libraries. OntoStarFish makes such relationships explicit so users may visualize them and detect potential collaboration networks. Users that may be interested in exploring collaboration networks include researchers looking for partners for specific projects as well as funding agencies concerned with the strength of associations among participants of competing proposals. OntoStarFish is based upon the use of multiple fisheye views that can be placed on top of starfields, dynamic scatter plots for which each axis is determined by a lightweight ontology of attributes associated to potential collaborators.

#index 1588379
#* A link-based visual search engine for Wikipedia
#@ David N. Milne;Ian H. Witten
#t 2011
#c 14
#% 322995
#% 340739
#% 1158429
#% 1279761
#% 1404603
#% 1439717
#! This paper introduces HMpara, a new search engine that aims to make Wikipedia easier to explore. It works on top of the encyclopedia's existing link structure, abstracting away from document content and allowing users to navigate the resource at a higher level. It utilizes semantic relatedness measures to emphasize articles and connections that are most likely to be of interest, visualization to expose the structure of how the available information is organized, and lightweight information extraction to explain itself.

#index 1588380
#* Supporting revisitation with contextual suggestions
#@ Ricardo Kawase;George Papadakis;Eelco Herder
#t 2011
#c 14
#% 152934
#% 233808
#% 249125
#% 400726
#% 729885
#% 754064
#% 954970
#% 1046514
#% 1047435
#% 1231242
#% 1355035
#% 1356234
#% 1407019
#! Web browsers provide only little support for users to revisit pages that they do not visit very often. We developed a browser toolbar that reminds users of visited pages related to the page that they currently viewing. The recommendation method combines ranking with propagation methods. A user evaluation shows that on average 22.7% of the revisits were triggered by the toolbar, a considerable change on the participants' revisitation routines. In this paper we discuss the value of the recommendations and the implications derived from the evaluation.

#index 1588381
#* CollabSeer: a search engine for collaboration discovery
#@ Hung-Hsuan Chen;Liang Gou;Xiaolong Zhang;Clyde Lee Giles
#t 2011
#c 14
#% 58616
#% 67565
#% 281480
#% 290830
#% 330687
#% 577273
#% 835018
#% 1002007
#% 1035580
#% 1153867
#% 1213413
#% 1292521
#% 1372721
#% 1375817
#% 1399975
#% 1434124
#% 1434156
#% 1446948
#% 1506229
#! Collaborative research has been increasingly popular and important in academic circles. However, there is no open platform available for scholars or scientists to effectively discover potential collaborators. This paper discusses CollabSeer, an open system to recommend potential research collaborators for scholars and scientists. CollabSeer discovers collaborators based on the structure of the coauthor network and a user's research interests. Currently, three different network structure analysis methods that use vertex similarity are supported in CollabSeer: Jaccard similarity, cosine similarity, and our relation strength similarity measure. Users can also request a recommendation by selecting a topic of interest. The topic of interest list is determined by CollabSeer's lexical analysis module, which analyzes the key phrases of previous publications. The CollabSeer system is highly modularized making it easy to add or replace the network analysis module or users' topic of interest analysis module. CollabSeer integrates the results of the two modules to recommend collaborators to users. Initial experimental results over a subset of the CiteSeerX database show that CollabSeer can efficiently discover prospective collaborators.

#index 1588382
#* Resolving author name homonymy to improve resolution of structures in co-author networks
#@ Theresa A. Velden;Asif-ul Haque;Carl Lagoze
#t 2011
#c 14
#% 760866
#% 804877
#% 809459
#% 874459
#% 937552
#% 967295
#% 1133176
#% 1434125
#% 1549965
#% 1663664
#! We investigate how author name homonymy distorts clustered large-scale co-author networks, and present a simple, effective, scalable and generalizable algorithm to ameliorate such distortions. We evaluate the performance of the algorithm to improve the resolution of mesoscopic network structures, that is those meso-level structures of a network resulting from groupings of nodes and their interlinking. To this end, we establish the ground truth for a sample of author names that is statistically representative of different types of nodes in the co-author network, distinguished by their role for the connectivity of the network. We finally observe that this distinction of node roles based on the mesoscopic structure of the network, in combination with a quantification of the commonality of last names, suggests a new approach to assess network distortion by homonymy and to analyze the reduction of distortion in the network after disambiguation, without requiring ground truth sampling.

#index 1588383
#* Ranking authors in digital libraries
#@ Sujatha Das Gollapalli;Prasenjit Mitra;C. Lee Giles
#t 2011
#c 14
#% 290830
#% 348173
#% 660011
#% 662755
#% 805896
#% 875063
#% 879570
#% 881457
#% 907525
#% 918685
#% 967259
#% 987261
#% 1077150
#% 1083734
#% 1116996
#% 1130922
#% 1176887
#% 1176930
#% 1195845
#% 1275180
#% 1348087
#% 1544149
#% 1871099
#! Searching for people with expertise on a particular topic also known as expert search is a common task in digital libraries. Most models for this task use only documents as evidence for expertise while ranking people. In digital libraries, other sources of evidence are available such as a document's association with venues and citation links with other documents. We propose graph-based models that accommodate multiple sources of evidence in a PageRank-like algorithm for ranking experts. Our studies on two publicly-available datasets indicate that our model despite being general enough to be directly useful for ranking other types of objects performs on par with probabilistic models commonly used for expert ranking.

#index 1588384
#* Comparative evaluation of text- and citation-based plagiarism detection approaches using guttenplag
#@ Bela Gipp;Norman Meuschke;Joeran Beel
#t 2011
#c 14
#% 301264
#% 571725
#% 1429439
#% 1544119
#% 1558411
#! Various approaches for plagiarism detection exist. All are based on more or less sophisticated text analysis methods such as string matching, fingerprinting or style comparison. In this paper a new approach called Citation-based Plagiarism Detection is evaluated using a doctoral thesis, in which a volunteer crowd-sourcing project called GuttenPlag identified substantial amounts of plagiarism through careful manual inspection. This new approach is able to identify similar and plagiarized documents based on the citations used in the text. It is shown that citation-based plagiarism detection performs significantly better than text-based procedures in identifying strong paraphrasing, translation and some idea plagiarism. Detection rates can be improved by combining citation-based with text-based plagiarism detection.

#index 1588385
#* Understanding digital library adoption: a use diffusion approach
#@ Keith E. Maull;Manuel Gerardo Saldivar;Tamara Sumner
#t 2011
#c 14
#% 809408
#% 1291617
#% 1383463
#% 1427770
#% 1434162
#% 1505294
#! With the growth in operational digital libraries, the need for automatic methods capable of characterizing adoption and use has grown. We describe a computational methodology for producing two, inter-related, user typologies based on use diffusion. Use diffusion theory views technology adoption as a process that can lead to widely different patterns of use across a given population of potential users; these models use measures of frequency and variety to characterize and describe these usage patterns. The methodology uses computational techniques such as clickstream entropy and clustering to produce both coarse-grained and fine-grained user typologies. A case study demonstrates the utility and applicability of the method: it is used to understand how middle and high school science teachers participating in an academic year-long field trial adopted and integrated digital library resources into their instructional planning and teaching. The resulting fine-grained user typology identified five different types of teacher-users, including "interactive resource specialists" and "community seeker specialists" This typology was validated through comparison with qualitative and quantitative data collected using traditional educational field research methods.

#index 1588386
#* In the bookshop: examining popular search strategies
#@ George Buchanan;Dana McKay
#t 2011
#c 14
#% 235292
#% 237318
#% 237336
#% 281363
#% 378515
#% 420524
#% 508110
#% 575738
#% 614033
#% 732739
#% 751596
#% 924078
#% 1314946
#% 1448510
#% 1709410
#! Users' search tactics often appear naïve. Much research has endeavored to understand the rudimentary query typically seen in log analyses and user studies. Researchers have tested a number of approaches to supporting query development, including information literacy training and interaction design these have tried and often failed to induce users to use more complex search strategies. To further investigate this phenomenon, we combined established HCI methods with models from cultural studies, and observed customers' mediated searches for books in bookstores. Our results suggest that sophisticated search techniques demand mental models that many users lack.

#index 1588387
#* World vs. method: educational standard formulation impacts document retrieval
#@ Byron Marshall;René Reitsma
#t 2011
#c 14
#% 722935
#% 857180
#% 1021108
#% 1213409
#% 1385743
#% 1511821
#% 1550725
#! Although initiatives are underway in the educational community to consolidate disparate collections of educational standards, little has been done to explore the impact of educational standard formulation on information retrieval. Recent research contrasts two categories of educational standards: 'World' (topical domain-related concepts) and 'Method' (investigative and epistemological principles). This paper explores the information retrieval implications of the World vs. Method distinction. We find that experts are more likely to agree about which educational resources align with a Method standard but that a typical automatic standard assignment tool is more likely to assign a World standard to an educational resource. Further, a text-based information retrieval system is more likely to be accurate in retrieving documents relevant to a World standard as compared to a Method standard. These findings have implications both for educational standard formulation (combining World and Method components in a standard may improve retrieval) and for digital library builders who want to help teachers identify useful, standards-aligned learning objects.

#index 1588388
#* Automating open educational resources assessments: a machine learning generalization study
#@ Heather Leary;Mimi Recker;Andrew Walker;Philipp Wetzler;Tamara Sumner;James Martin
#t 2011
#c 14
#% 614070
#% 809402
#% 935278
#% 1065250
#% 1213435
#! Assessing the quality of online educational resources in a cost effective manner is a critical issue for educational digital libraries. This study reports on the approach for extending the Open Educational Resource Assessments (OPERA) algorithm from assessing vetted to peer-produced content. This article reports details of changes to the algorithm, comparisons between human raters and the algorithm, and the extent the algorithm can automate the review process.

#index 1588389
#* A social network-aware top-N recommender system using GPU
#@ Ruifeng Li;Yin Zhang;Haihan Yu;Xiaojun Wang;Jiangqin Wu;Baogang Wei
#t 2011
#c 14
#% 420539
#% 528156
#% 734592
#% 734594
#% 766448
#% 818216
#% 842605
#% 956521
#% 1001279
#% 1074061
#% 1213432
#% 1214661
#% 1287242
#% 1380732
#% 1459172
#% 1535255
#! A book recommender system is very useful for a digital library. Good book recommender systems can effectively help users find interesting and relevant books from the massive resources, by providing individual recommendation book list for each end-user. By now, a variety of collaborative filtering algorithms have been invented, which are the cores of most recommender systems. However, because of the explosion of information, especially in the Internet, the improvement of the efficiency of the collaborative filting (CF) algorithm becomes more and more important. In this paper, we first propose a parallel Top-N recommendation algorithm in CUDA (Compute Unified Device Architecture) which combines the collaborative filtering and trust-based approach to deal with the cold-start user problem. Then based on this algorithm, we present a parallel book recommender system on a GPU (Graphics Processor unit) for CADAL digital library platform. Our experimental results show our algorithm is very efficient to process the large-scale datasets with good accuracy, and we report the impact of different values of parameters on the recommendation performance.

#index 1588390
#* A source independent framework for research paper recommendation
#@ Cristiano Nascimento;Alberto H.F. Laender;Altigran S. da Silva;Marcos André Gonçalves
#t 2011
#c 14
#% 173879
#% 202011
#% 248218
#% 258826
#% 268114
#% 280852
#% 378485
#% 387427
#% 397133
#% 411762
#% 415107
#% 420121
#% 760853
#% 783474
#% 813966
#% 874506
#% 905318
#% 961613
#% 967309
#% 987287
#% 1074112
#% 1106097
#% 1166508
#% 1287254
#% 1292536
#% 1399975
#% 1434124
#% 1676113
#! As the number of research papers available on the Web has increased enormously over the years, paper recommender systems have been proposed to help researchers on automatically finding works of interest. The main problem with the current approaches is that they assume that recommending algorithms are provided with a rich set of evidence (e.g., document collections, citations, profiles) which is normally not widely available. In this paper we propose a novel source independent framework for research paper recommendation. The framework requires as input only a single research paper and generates several potential queries by using terms in that paper, which are then submitted to existing Web information sources that hold research papers. Once a set of candidate papers for recommendation is generated, the framework applies content-based recommending algorithms to rank the candidates in order to recommend the ones most related to the input paper. This is done by using only publicly available metadata (i.e., title and abstract). We evaluate our proposed framework by performing an extensive experimentation in which we analyzed several strategies for query generation and several ranking strategies for paper recommendation. Our results show that good recommendations can be obtained with simple and low cost strategies.

#index 1588391
#* Serendipitous recommendation for scholarly papers considering relations among researchers
#@ Kazunari Sugiyama;Min-Yen Kan
#t 2011
#c 14
#% 262112
#% 805841
#% 1127465
#% 1183298
#% 1213432
#% 1287706
#% 1434124
#% 1450855
#% 1450856
#% 1482273
#! Serendipity occurs when one finds an interesting discovery while searching for something else. While search engines seek to report work relevant to a targeted query, recommendation engines are particularly well-suited for serendipitous recommendations as such processes do not need to fulfill a targeted query. Junior researchers can use such an engine to broaden their horizon and learn new areas, while senior researchers can discover interdisciplinary frontiers to apply integrative research. We adapt a state-of-the-art scholarly paper recommendation system's user profile construction to make use of information drawn from 1) dissimilar users and 2) co-authors to specifically target serendipitous recommendation.

#index 1588392
#* Product review summarization from a deeper perspective
#@ Duy Khang Ly;Kazunari Sugiyama;Ziheng Lin;Min-Yen Kan
#t 2011
#c 14
#% 198058
#% 262112
#% 372188
#% 481290
#% 741106
#% 769892
#% 805873
#% 939848
#% 939896
#% 1035591
#% 1250237
#% 1299639
#! With product reviews growing in depth and becoming more numerous, it is growing challenge to acquire a comprehensive understanding of their contents, for both customers and product manufacturers. We built a system that automatically summarizes a large collection of product reviews to generate a concise summary. Importantly, our system not only extracts the review sentiments but also the underlying justification for their opinion. We solve this problem through a novel application of clustering and validate our approach through an empirical study, obtaining good performance as judged by F-measure (the harmonic mean of purity and inverse purity).

#index 1588393
#* Do graphical search interfaces support effective search for and evaluation of digital library resources
#@ Kirsten R. Butcher;Sarah Davies;Ashley Crockett;Aaron Dewald;Robert Zheng
#t 2011
#c 14
#% 185273
#% 186518
#% 228328
#% 574303
#% 723632
#% 857478
#% 1213408
#% 1264572
#% 1709421
#! This paper explores the cognitive processes and online behaviors in which preservice teachers engage when seeking educational resources for classroom instruction. Participants used graphical and keyword search interfaces provided by a large-scale digital library (NSDL.org) and a keyword search interface from a large, commercial search engine (Google.com) to complete searches for online materials that would support classroom instruction. Overall, findings from the current work indicate that a graphical search interface can support comprehension by providing a conceptual organization of domain content during digital search and evaluation. Findings also show that digital libraries allow users to offload processing related to resource trustworthiness, thereby increasing cognitive capacity for other purposes.

#index 1588394
#* Taking chemistry to the task: personalized queries for chemical digital libraries
#@ Sascha Tönnies;Benjamin Köhncke;Wolf-Tilo Balke
#t 2011
#c 14
#% 43862
#% 956519
#% 1016618
#% 1055745
#% 1434147
#% 1682486
#! Nowadays, the information access is conducted almost exclusively using the Web. Simple keyword based Web search engines, e.g. Google or Yahoo!, offer suitable retrieval and ranking features. In contrast, for highly specialized domains, represented by digital libraries, these features are insufficient. Considering the domain of chemistry, where searching for relevant literature is essentially centered on chemical entities. Beside commercial information providers such as Chemical Abstract Service (CAS) numerous groups are working on building free chemical search engines to overcome the expensive access to chemical literature. However, due to the nature of chemical queries these are often overspecialized. Often we need meaningful similarity measures for chemical entities for query relaxation. In chemistry, the similarity measures are vast; more than 40 similarity measures are available and focus on different aspects of chemical entities. This vast number of similarity measures is obvious, because the desired search results highly depend on the working field of the chemist. In this paper we present a personalized retrieval system for chemical documents taking into account the background knowledge of the individual chemist. This is done by a query relaxation for chemical entities using similar substances. We evaluate our approach extensively by analyzing the correlation of commonly used chemical similarity measures and fingerprint representations. All uncorrelated measures are finally used by our feedback engine to learn preferred similarity measures for each user. We also conducted a user study with domain experts showing that our system can assign a unique similarity measure for 75% of the users after only 10 feedback cycles.

#index 1588395
#* Physics pathway: a digital library filled with synthetic interviews
#@ Michael G. Christel;Scott M. Stevens;Dean Zollman
#t 2011
#c 14
#% 1338197
#% 1447923
#! Physics Pathway is a digital library available through an Adobe Flash portal whose contents are a series of interviews with four experts who answer questions about the pedagogy of teaching physics. The answers were collected over a broad time span, but are presented to the user as if he or she is conducting the personal interview, similar to naturally conversing with the expert. This "synthetic interview" style is discussed in this paper, with a mixed methods evaluation by 19 high school teachers who used Physics Pathway for a 14-week period at the end of 2010. The evaluation with teachers showed that the synthetic interviews validated or reinforced their ideas on their course materials and delivery. As these are teachers who are relatively new to physics instruction, confirmation that they are teaching well is important. Physics Pathway is linked with comPADRE, a member of the National Science Digital Library.

#index 1588396
#* A metadata geoparsing system for place name recognition and resolution in metadata records
#@ Nuno Freire;José Borbinha;Pável Calado;Bruno Martins
#t 2011
#c 14
#% 290148
#% 400847
#% 464434
#% 466892
#% 742424
#% 766441
#% 786528
#% 855312
#% 864415
#% 1016365
#% 1099937
#% 1166537
#% 1223735
#% 1288161
#% 1673770
#! This paper describes an approach for performing recognition and resolution of place names mentioned over the descriptive metadata records of typical digital libraries. Our approach exploits evidence provided by the existing structured attributes within the metadata records to support the place name recognition and resolution, in order to achieve better results than by just using lexical evidence from the textual values of these attributes. In metadata records, lexical evidence is very often insufficient for this task, since short sentences and simple expressions are predominant. Our implementation uses a dictionary based technique for recognition of place names (with names provided by Geonames), and machine learning for reasoning on the evidences and choosing a possible resolution candidate. The evaluation of our approach was performed in data sets with a metadata schema rich in Dublin Core elements. Two evaluation methods were used. First, we used cross-validation, which showed that our solution is able to achieve a very high precision of 0,99 at 0,55 recall, or a recall of 0,79 at 0,86 precision. Second, we used a comparative evaluation with an existing commercial service, where our solution performed better on any confidence level (p

#index 1588397
#* Event detection with spatial latent Dirichlet allocation
#@ Chi-Chun Pan;Prasenjit Mitra
#t 2011
#c 14
#% 262042
#% 340883
#% 466501
#% 722904
#% 730043
#% 783535
#% 788094
#% 812535
#% 816132
#% 836717
#% 884059
#% 948909
#% 967295
#% 1019144
#% 1117049
#% 1269909
#! A large number of news articles are generated every day on the Web. Automatically identifying events from a large document collection is a challenging problem. In this paper, we propose two event detection approaches using generative models. We combine the popular LDA model with temporal segmentation and spatial clustering. In addition, we adapt an image segmentation model, SLDA, for spatial-temporal event detection on text. The results of our experiments show that both approaches outperform the traditional content-based clustering approaches on our datasets.

#index 1588398
#* A new video text detection method
#@ Jie Yuan;Baogang Wei;Weiming Lu;Lidong Wang
#t 2011
#c 14
#% 294976
#% 774915
#% 775165
#% 844883
#% 997226
#% 1301834
#% 1347058
#% 1858271
#! Nowadays, digital libraries contain more and more videos in them, and how to organize and retrieve those videos effectively has become very urgent. Text in videos is a very meaningful clue for video semantic understanding, and it can be used for video organization and retrieval. However, existing text recognizing methods can not deal with multilingual texts or texts embedded in a complex background very well. In this paper, we propose a novel video text detection method. Edge detection and candidate region extraction are firstly used to obtain all rough candidate text regions, and then region refinement is used to obtain the accurate location of each region. Based on our observation that a real text region has a uniform distribution with its non-zero pixels in its binary image, an entropy filter is used to remove non-text regions. Experiments on various videos show that our method is effective and robust against different languages, background complexities and font styles.

#index 1588399
#* Retrieval and exploratory search in multivariate research data repositories using regressional features
#@ Maximilian Scherer;Jürgen Bernard;Tobias Schreck
#t 2011
#c 14
#% 301247
#% 391311
#% 451048
#% 508284
#% 859913
#% 1099851
#% 1212422
#% 1251453
#% 1316070
#% 1378458
#% 1383023
#% 1495120
#% 1495122
#% 1512955
#! Increasing amounts of data are collected in many areas of research and application. The degree to which this data can be accessed, retrieved, and analyzed is decisive to obtain progress in fields such as scientific research or industrial production. We present a novel method supporting content-based retrieval and exploratory search in repositories of multivariate research data. In particular, functional dependencies are a key characteristic of data that researchers are often interested in. Our methods are able to describe the functional form of such dependencies, e.g., the relationship between inflation and unemployment in economics. Our basic idea is to use feature vectors based on the goodness-of-fit of a set of regression models, to describe the data mathematically. We denote this approach Regressional Features and use it for content-based search and, since our approach motivates an intuitive definition of interestingness, for exploring the most interesting data. We apply our method on considerable real-world research datasets, showing the usefulness of our approach for user-centered access to research data in a Digital Library system.

#index 1588400
#* A research agenda for data curation cyberinfrastructure
#@ Carl Lagoze;Karin Patzke
#t 2011
#c 14
#% 173739
#% 185274
#% 241963
#% 269636
#% 760866
#% 818729
#% 859913
#% 879809
#% 1071450
#% 1107051
#% 1405710
#% 1523465
#% 1529337
#% 1533892
#% 1533894
#! In 2008, the National Science Foundation released the DataNet solicitation, which presents an ambitious vision for a comprehensive data curation cyberinfrastructure in support of fourth paradigm science. The program subsequently funded two projects, DataONE and the Data Conservancy. The authors put forth an uncertainty framework for understanding the larger socio-cultural issues that influence the progress of DataNet projects and cyberinfrastructure projects in general. This framework highlights the key technical, organizational, scientific, and institutional contexts that the projects must consider as they mature.

#index 1588401
#* When use cases are not useful: data practices, astronomy, and digital libraries
#@ Laura Wynholds;David S. Fearon, Jr.;Christine L. Borgman;Sharon Traweek
#t 2011
#c 14
#% 619032
#% 824999
#% 1021630
#% 1434153
#% 1434158
#% 1523465
#! As science becomes more dependent upon digital data, the need for data curation and for data digital libraries becomes more urgent. Questions remain about what researchers consider to be their data, their criteria for selecting and trusting data, and their orientation to data challenges. This paper reports findings from the first 18 months of research on astronomy data practices from the Data Conservancy. Initial findings suggest that issues for data production, use, preservation, and sharing revolve around factors that rarely are accommodated in use cases for digital library system design including trust in data, funding structures, communication channels, and perceptions of scientific value.

#index 1588402
#* An exploration of pattern-based subtopic modeling for search result diversification
#@ Wei Zheng;Xuanhui Wang;Hui Fang;Hong Cheng
#t 2011
#c 14
#% 46803
#% 248791
#% 340948
#% 879579
#% 1292596
#% 1400021
#% 1650298
#! Traditional information retrieval models do not necessarily provide users with optimal search experience because the top ranked documents may contain the same piece of relevant information, i.e., the same subtopic of a query. The goal of search result diversification is to return search results that not only are relevant to the query but also cover different subtopics. Therefore, the subtopic modeling is an important research topic in search result diversification. In this paper, we propose a novel pattern based method to extract subtopics from retrieved documents. The basic idea is to explicitly model a query subtopic as a semantically meaningful text unit in relevant documents. We apply a frequent pattern mining algorithm to efficiently extract these text units (patterns) from retrieved documents. We then model a query subtopic with a single pattern and rank subtopics based on their similarity with the query. These pattern based subtopics are then used to diversify search results.

#index 1588403
#* A very efficient approach to news title and content extraction on the web
#@ Hualiang Yan;Jianwu Yang
#t 2011
#c 14
#% 754108
#% 1190152
#% 1214756
#% 1269910
#! We consider the problem of efficient and template-independent news extraction on the Web. The popular news extraction methods are based on visual information, and they can achieve good accuracy performance, but the computational efficiency is poor, because it is very time-consuming to render web page to obtain visual information. In this paper we propose an efficient and effective news extraction approach based on novel features. Our approach neither needs training nor needs visual information, so it is simple and very efficient. And it can extract news information from various news sites without using templates. In our experiments, the proposed approach achieves 99% accuracy over 5,671 news pages from 20 different news sites. And the efficiency is much faster than the baseline machine learning method using visual information.

#index 1588404
#* Web video search by mutual boosting between the inside and outside text of video
#@ Yuxin Peng;Zhiguo Yang;Jian Yi
#t 2011
#c 14
#% 780874
#% 997226
#% 1858271
#! This paper proposes a new idea and approach for the web video search. Instead of only using the surrounding text of video in webpage, our approach boosts mutually and utilizes jointly the inside and outside text of video to support the video-based and frame-based search. In our approach, the inside text is the video caption, while the outside text is the surrounding text of video in webpage. In our view, the caption text, although has some wrong characters and words caused by the automatic caption recognition, is a useful indicator for the content of video. While the relevant surrounding texts of video, although is difficult to locate and confirm, have the correct characters and words which usually indicate the video content, especially the title and introduction of video. In this paper, we integrate their advantages and alleviate their disadvantages by the mutual boosting idea, that is, to employ the inside text to confirm the relevance of outside text, and to utilize the relevant outside text to correct the inside text. Mutual boosting not only enhances the query-by-text video search, but also further supports the query-by-text frame search with the corrected caption. Based on the above idea, our approach can be divided into three phases: Firstly, we proposed a new approach for automatic caption detection and extraction. Then, we extract the surrounding text candidates of video. Finally, the mutual boosting approach is employed to get the relevant and accurate text of web video. The experiments show the proposed approach can achieve good performance.

#index 1588405
#* Visual interfaces for stimulating exploratory search
#@ Ralf Krestel;Gianluca Demartini;Eelco Herder
#t 2011
#c 14
#% 590523
#% 1147592
#% 1213448
#! Exploration is an activity that people undertake to broaden their knowledge on a certain topic. In contrast to regular search, which is typically aimed at obtaining a specific answer to a specific question, exploratory search should give a more complete overview of a topic. Further it should enable the discovery of related aspects, such as people, places, times and locations. Exploration demands more time, effort and creativity from the user, but rewards the user with deeper knowledge. Therefore, users need to be stimulated to bring exploration in regular goal-directed search activities. In this paper we present a user study in which we investigate different kinds of exploratory behavior and goals, as well as different kinds of visualizations to support exploration.

#index 1588406
#* Designing interconnected distributed resources for collaborative inquiry based science education
#@ Anne Adams;Tim Coughlan;John Lea;Yvonne Rogers;Sarah Davies;Trevor Collins
#t 2011
#c 14
#% 378562
#% 760843
#% 789830
#% 1366585
#% 1384251
#% 1434159
#! This paper describes the design and evaluation of a distributed information resource system (IRS) shared between field and laboratory settings for higher education geology students. An investigation of geo-science scholarship and technical pilot studies highlighted the importance of situational specific and distributed information usage. To advance our understanding of novel resource approaches (i.e. from tabletops to tablets) and collaborative learning, two in-depth field trials evaluated 21 students' information journeys (i.e. initiating information needs, facilitating information and collaborative interpretation). Analysis identified how a designing for a varied device ecology supported information filtering and empathy between locations provoking deeper reflection and abstract understanding in the field, while live collaborative remote interaction provided an engaging yet distinct learning experience for those in the laboratory.

#index 1588407
#* Retrieving attributes using web tables
#@ Arlind Kopliku;Karen Pinel-Sauvagnat;Mohand Boughanem
#t 2011
#c 14
#% 889107
#% 1127393
#% 1450836
#! In this paper we propose an attribute retrieval approach which extracts and ranks attributes from Web tables. We combine simple heuristics to filter out improbable attributes and we rank attributes based on frequencies and a table match score. Ranking is reinforced with external evidence from Web search, DBPedia and Wikipedia. Our approach can be applied to whatever instance (e.g. Canada) to retrieve its attributes (capital, GDP). It is shown it has a much higher recall than DBPedia and Wikipedia and that it works better than lexico-syntactic rules for the same purpose.

#index 1588408
#* Towards a model of the e-science data environment
#@ Stacy T. Kowalczyk
#t 2011
#c 14
#! Building digital libraries for preserving scientific digital data, ensuring its continued access, has emerged as a major initiative for funding agencies and academic institutions. Understanding the environments in which data is created, quality is assessed, and data is managed is a necessary antecedent to developing appropriate technologies to support the preservation and ongoing access to data. This paper reports on a study of 11 laboratories and research centers at three U.S. universities. Using the grounded theory methodology, this paper develops a new, generalized view of the e-Science data that attempts to explain the environment in which data is created, managed, documented, and preserved.

#index 1588409
#* Social reference: aggregating online usage of scientific literature in CiteULike for clustering academic resources
#@ Jiepu Jiang;Daqing He;Chaoqun Ni
#t 2011
#c 14
#% 1523459
#% 1844556
#! Citation-based methods have been widely studied and employed for clustering academic resources and mapping science. Although effective, these methods suffer from citation delay. In this study, we extend reference and citation analysis to a broader notion from social perspective. We coin the term "social reference" to refer to the references of literatures in social academic web environment. We propose clustering methods using social reference information from CiteULike. We experiment for journal clustering and author clustering using social reference and compare with citation-based methods. Our experiments indicate: first, social reference implies connections among literatures which are as effective as citation in clustering academic resources; second, in practical settings, social reference-based clustering methods are not as effective as citation-based ones due to the sparseness of social reference data, but they can outperform in clustering new resources that have few citation.

#index 1588410
#* Digital archives of taiwan agricultural history during the japanese colonial period
#@ Li-Ping Chen;Chunsheng Huang;Yi-Hui Chang
#t 2011
#c 14
#% 1406436
#! The National Chung Hsing University Library has built a digital archive about Taiwan agricultural history. The content is unique in that it covers historical materials about Taiwan during the Japanese colonial period from 1895 to 1945, and that they are all available in full text, in addition to metadata. To make these materials more accessible to the research and education community, a user-centered retrieval system incorporated with multi-language, subject browsing, cluster analysis, topic map, post-query classification methods was developed to help users find the inter-relationships among documents and the collective meaning of a sub-collection. Such system is anticipated to help advance research in Taiwan agricultural history and set a model for other similar endeavor.

#index 1588411
#* Developing a concept extraction technique with ensemble pathway
#@ Prat Tanapaisankit;Min Song;Edward A. Fox
#t 2011
#c 14
#% 464434
#% 643004
#% 653190
#% 741208
#% 1280180
#% 1434159
#! In this paper, we describe our Concept Extraction technique for Educational Digital libraries (CEED) which applies Conditional Random Fields (CRFs) to extract concepts from the Ensemble Pathway collection. In addition, we discuss how we implement RESTful APIs for concept extraction.

#index 1588412
#* SCOR/IODE/MBLWHOI library collaboration on data publication
#@ Lisa Raymond;Linda Pikula;Roy Lowry;Ed Urban;Gwenaëlle Moncoiffé;Peter Pissierssens;Cathy Norton
#t 2011
#c 14
#! This poster describes the development of international standards to publish oceanographic datasets. Research areas include the assignment of persistent identifiers, tracking provenance, linking datasets to publications, attributing credit to data providers, and best practices for the physical composition and semantic description of the content.

#index 1588413
#* A content analysis of institutional data policies
#@ Kayleigh Ayn Bohémier;Thea Atwood;Andreas Kuehn;Jian Qin
#t 2011
#c 14
#% 1440178
#% 1440363
#! The newly issued requirement for a data management plan in proposals submitted to the U.S. National Science Foundation and other federal funding agencies prompted many institutions to develop their own policies to conform to this new requirement as well as to more effectively manage, share, publish, and provide access to research data. While the need for guidelines or a framework in developing such data policies is imminent, research is lacking in this area. The study reported here addresses this need by using a content analysis of 58 policy documents from 20 institutions. Our preliminary findings reveal an uneven distribution of data policies among the institutions and disciplines included in this study. We are currently analyzing our results.

#index 1588414
#* Are learned topics more useful than subject headings
#@ Youn Noh;Katrina Hagedorn;David Newman
#t 2011
#c 14
#% 722904
#% 967299
#% 967300
#% 1434145
#! Topic models, through their ability to automatically learn and assign topics to documents in a collection, have the potential to greatly improve how content is organized and searched in digital libraries. However, much remains to be done to assess the value of topic models in digital library applications. In this work, we present results from a user study, in which participants evaluated the similarity of books clustered using matched topics and Library of Congress Subject Headings (LCSH). Topics outperformed LCSH in 11 cases; LCSH outperformed topics in 4. These results suggest that topics are a viable alternative to LCSH.

#index 1588415
#* Detecting academic papers on the web
#@ Emi Ishita;Teru Agata;Atsushi Ikeuchi;Miyata Yosuke;Shuichi Ueda
#t 2011
#c 14
#% 1434171
#! Our research goal is to develop a search engine for open access to academic papers. English and Japanese test sets were built for detection of academic papers from 20,000 PDF files in each language using five annotators. Six classifiers were trained using similar features for each language. We report F1 of 0.74 for English and 0.54 for Japanese and argue that similar features could easily be generated for other languages as well.

#index 1588416
#* Improving scalability by self-archiving
#@ Zhiwu Xie;Jinyang Liu;Herbert Van de Sompel;Johann van Reenen;Ramiro Jordan
#t 2011
#c 14
#% 9241
#% 210179
#% 287268
#% 1111848
#! The newer generation of web browsers supports the client-side database, making it possible to run the full web application stacks entirely in the web clients. Still, the server side database is indispensable as the central hub for exchanging persistent data between the web clients. Assuming this characterization, we propose a novel web application framework in which the server archives its database states at predefined periods then makes them available on the web. The clients then use these archives to synchronize their local databases. Although the main purpose is to reduce the database scalability bottleneck, this approach also promotes self-archiving and can be used for time traveling. We discuss the consistency properties provided by this framework, as well as the tradeoffs imposed.

#index 1588417
#* An analysis of personal collections among users of social media
#@ Paul Logasa Bogen, II;Frank Shipman;Richard Furuta
#t 2011
#c 14
#% 805898
#% 869504
#% 954970
#% 955711
#% 1055810
#% 1065280
#! We have been developing a system to support the management of collections of web-based resources called the Distributed Collection Manager (DCM). As work on DCM has progressed, questions about the characteristics of people's collections of web pages have arisen. Simultaneously, work in the area of social media technology has ignored investigating how people are trying to maintain their collections. In order to address these concerns, we performed an online user study of 125 individuals from a variety of online and offline communities. From this study we were able to examine the needs for a system to manage web-based distributed collections, how current tools affect maintenance, and the characteristics of current practices and problems in maintaining web-based collections.

#index 1588418
#* WPv4: a re-imagined Walden's paths to support diverse user communities
#@ Paul Logasa Bogen, II;Daniel Pogue;Faryaneh Poursardar;Yuangling Li;Richard Furuta;Frank Shipman
#t 2011
#c 14
#% 240748
#% 679852
#% 769136
#% 1495098
#! The Walden's Paths Project, as part of our philosophy of continual evaluation, seeks out user communities who may find our tool useful. However, our users, in the last few years, have reported a series of common issues and desired features. In order to support our users, we initiated a redesign of Walden's Paths to solve these problems and enable us to rapidly prototype and experiment with features and interfaces. In order to accomplish these goals, we have created a web service that handles the storage and representation of our Path data structure. This service is isolated from user interface layers, allowing multiple interface designs to be implemented on top of the same Path data structures. Our prototype interfaces also represent new areas for Paths such as collaborative work, offline presentation, and mobile computing.

#index 1588419
#* Is tagging multilingual?: a case study with BibSonomy
#@ Juliane Stiller;Maria Gäde;Vivien Petras
#t 2011
#c 14
#% 855601
#% 881054
#% 1001314
#! This paper investigates the occurrence of tags in different languages in a collaborative bookmarking and publication sharing service - BibSonomy. Social tags assigned to URLs in multiple languages and users tagging these URLs multilingually are the main focus of this study. The results show that multilingual tags occur for the same URL and that users tag in different languages. Furthermore, the results give indications that the language of the content of a URL does not imply that its tags are in the same language.

#index 1588420
#* Creating meta-indexes for digital domains
#@ Michael Huggett;Edie Rasmussen
#t 2011
#c 14
#% 56449
#% 1415729
#% 1431397
#! The back-of-book indexes for test collections of digital books in the domains of Economics and Geology have been deconstructed and analyzed, and the entries aggregated to create domain-level meta-indexes. Metrics comparing the two domains are presented.

#index 1588421
#* Analytic potential of data: assessing reuse value
#@ Carole L. Palmer;Nicholas M. Weber;Melissa H. Cragin
#t 2011
#c 14
#% 290792
#% 1000928
#% 1000935
#% 1483595
#% 1523547
#! Realizing the vision of networked data collections and services requires large bodies of scientific data that can be used in new ways. Adapting the concept of epistemological potential, we illustrate an approach for assessing the value of data for reuse in new domains. Two criteria for this analytic potential - integrity and fit-for-purpose - are recognized aspects of data curation, however identifying potential domains of interest for reuse requires knowledge of practices and needs across disciplines. Evaluating analytic potential will become increasingly important for libraries and repositories to make informed decisions about recruitment and curation of data for interdisciplinary science.

#index 1588422
#* Building a research social network from an individual perspective
#@ Alberto H.F. Laender;Mirella M. Moro;Marcos André Gonçalves;Clodoveu A. Davis, Jr.;Altigran S. da Silva;Allan J.C. Silva;Carolina A.S. Bigonha;Daniel Hasan Dalip;Eduardo M. Barbosa;Eli Cortez;Peterson S. Procópio, Jr.;Rafael Odon de Alencar;Thiago N.C. Cardoso;Thiago Salles
#t 2011
#c 14
#% 1083734
#% 1598877
#! In this poster paper, we present an overview of CiênciaBrasil, a research social network involving researchers within the Brazilian INCT program. We describe its architecture and the solutions adopted for data collection, extraction, and deduplication, and for materializing and visualizing the network.

#index 1588423
#* Designing map-based visualizations for collection understanding
#@ Olga (Olha) Buchel
#t 2011
#c 14
#% 18600
#% 287597
#% 319875
#% 760871
#% 1153254
#% 1221188
#! This paper describes a conceptualization of collection understanding task and its implementation in a map-based visualization (MBV) prototype that represents a library collection. Unlike previous conceptualizations that treat a collection as a whole composed of documents, our conceptualization is grounded in widely-researched concepts "collection" and "understanding.

#index 1588424
#* How children find books for leisure reading: implications for the digital library
#@ Sally Jo Cunningham
#t 2011
#c 14
#% 999301
#% 1182249
#! Finding a good book can be difficult, particularly for young readers. This paper adds to our understanding of how children select books for recreational reading by exploring the 'native' strategies (both successful and ineffective) that children employ in bookstores and libraries.

#index 1588425
#* Repurposing data across disciplines: a study of data reuse issues between climate science and social science
#@ Lynne K. Davis;Peter Alston;John D'Ignazio
#t 2011
#c 14
#! Repurposing of data raises a number of issues for use across the disciplines of climate science and social science. The issues we present are results of the work we are currently carrying out as part of the Data Conservancy Project1 which aims to preserve data for long-term known and unanticipated use over time, across disciplines and over a variety of spatial, temporal and organizational scales.

#index 1588426
#* Improving simulation management systems through ontology generation and utilization
#@ Jonathan Leidig;Edward A. Fox;Kevin Hall;Madhav Marathe;Henning Mortveit
#t 2011
#c 14
#% 767436
#% 879803
#% 879809
#% 967283
#% 1588358
#! Content from simulation systems is useful in defining domain ontologies. We describe a digital library process to generate and leverage domain ontologies to support simulation systems tasks. Workflow ontologies may be used to define compositions of simulation-related services. Simulation model ontologies may be used in customizing collection management systems for tasks such as organization, interface construction, and metadata record generation.

#index 1588427
#* CTRnet DL for disaster information services
#@ Seungwon Yang;Andrea Kavanaugh;Nádia P. Kozievitch;Lin Tzy Li;Venkat Srinivasan;Steven D. Sheetz;Travis Whalen;Donald Shoemaker;Ricardo da S Torres;Edward A. Fox
#t 2011
#c 14
#% 1375827
#% 1620158
#! We describe our work in collecting, analyzing and visualizing online information (e.g., Web documents, images, tweets), which are to be maintained by the Crisis, Tragedy and Recovery Network (CTRnet) digital library. We have been collecting resources about disaster events, as well as campus and other major shooting events, in collaboration with the Internet Archive (IA). Social media data (e.g., tweets, Facebook data) also have been collected and analyzed. Analyzed results are visualized using graphs and tag clouds. Exploratory content-based image retrieval has been applied in one of our image collections. We explain our CTR ontology development methodology and collaboration with Arlington County, VA and IBM, in a Center for Community Security and Resilience funded project.

#index 1588428
#* Representing educational content in digital library resources
#@ Kirsten R. Butcher;Ashley Crockett;Sarah Davies
#t 2011
#c 14
#% 337496
#% 351983
#! A rubric for representing the educational content of digital resources was developed and tested in an experiment with preservice teachers. The ADMIRE (Analyzing Digital Materials In Resources for Education) rubric codes 11 types of digital content organized into five major categories; codes and categories are drawn from learning science and instructional research. The ADMIRE rubric was used to analyze the types of content present in digital resources that preservice teachers accepted or rejected for classroom use during instructional planning. Results show that the ADMIRE rubric provides a useful method to understand teachers' success in online search and the types of educational content that they value during instructional planning.

#index 1588429
#* Units of evidence for analyzing subdisciplinary difference in data practice studies
#@ Melissa H. Cragin;Tiffany C. Chao;Carole L. Palmer
#t 2011
#c 14
#% 967283
#% 1434158
#% 1523547
#! Digital libraries (DLs) are adapting to accommodate research data and related services. The complexities of this new content spans the elements of DL development, and there are questions concerning data selection, service development, and how best to align these with local, institutional initiatives for cyberinfrastructure, data-intensive research, and data stewardship. Small science disciplines are of particular relevance due to the prevalence of this mode of research in the academy, and the anticipated magnitude of data production. To support data acquisition into DLs - and subsequent data reuse - there is a need for new knowledge on the range and complexities inherent in practice-data-curation arrangements for small science research. We present a flexible methodological approach crafted to generate data units to analyze these relationships and facilitate cross-disciplinary comparisons.

#index 1588430
#* E-informing the public: communicative intents in the production of online government information
#@ Luanne Freund;Justyna Berzowska;Leah Hopton
#t 2011
#c 14
#% 1210543
#% 1914501
#! Governments produce vast amounts of electronic information geared for the public, but research points to a mismatch between the communicative intents of the government and the information needs of the public. Initial results of semi-structured interviews with government content creators suggest that learning more about why and how government information is produced may lead to the establishment of greater common ground.

#index 1588431
#* Using a hidden Markov model to transcribe handwritten bushman texts
#@ Kyle Williams;Hussein Suleman
#t 2011
#c 14
#% 658580
#% 753296
#% 1010488
#% 1092554
#% 1914891
#! The Bushman texts in the Bleek and Lloyd Collection contain complex diacritics that make automatic transcription difficult. Transcriptions of these texts would allow for enhanced digital library services to be created for interacting with the collection. In this study, an investigation into automatic transcription of the Bushman texts was performed using the popular method of using a Hidden Markov Model for text line recognition. The results show that while this technique may be well suited to well-constrained and understood scripts, its application to more complex scripts introduces a number of difficulties that need to be overcome.

#index 1588432
#* Connecting research data and indigenous communities
#@ Elizabeth Mulhollann;Kirsten Thorpe;Gabrielle Gardiner
#t 2011
#c 14
#! This poster demonstrates the program of consultation and associated technical workflow developed by the Aboriginal and Torres Strait Islander Data Archive (ATSIDA) to support the digital return of research data to Indigenous Australian communities, while also facilitating data preservation and reuse in the research community and by the general public.

#index 1588433
#* RFV: interactive geographical visualization for citation network exploration
#@ Christopher Aikens;George Lucchese;Patrick Webster;Andruid Kerne
#t 2011
#c 14
#% 750348
#! Research Field Visualizer (RFV) is a system designed to visualize citation chains for publications within specific disciplines. RFV overlays publication information on geographical displays to aid in locating dense areas of research based on different search criteria, thus exposing a network of interconnected ideas across the world. Within this geographical context, RFV provides an interactive visualization of citation networks, allowing the user to explore chains of publication Our intention is to help people that want to learn about a field, such as prospective graduate students, understand current research directions, track research history, and ultimately find the places where authors are conducting relevant and interesting research.

#index 1588434
#* Liquid benchmarks: benchmarking-as-a-service
#@ Sherif Sakr;Fabio Casati
#t 2011
#c 14
#% 765429
#% 1193640
#% 1545216
#! Experimental evaluation and comparison of techniques, algorithms or complete systems is a crucial requirement to assess the practical impact of research results. The quality of published experimental results is usually limited due to several reasons such as: limited time, unavailability of standard benchmarks or shortage of computing resources. Moreover, achieving an independent, consistent, complete and insightful assessment for different alternatives in the same domain is a time and resource consuming task. We demonstrate Liquid Benchmark as a cloud-based service that provides collaborative platforms to simplify the task of peer researchers in performing high quality experimental evaluations and guarantee a transparent scientific crediting process. The service allows building repositories of competing research implementations, sharing testing computing platforms, collaboratively building the specifications of standard benchmarks and allowing end-users to easily create and run testing experiments and share their results.

#index 1588435
#* Exploring Wikipedia with HMpara
#@ David N. Milne;Ian H. Witten
#t 2011
#c 14

#index 1588436
#* FRBRPedia: a tool for FRBRizing web products and linking FRBR entities to DBpedia
#@ Fabien Duchateau;Naimdjon Takhirov;Trond Aalberg
#t 2011
#c 14
#% 924747
#! The FRBR model has received much attention due to its potential for greatly improving user interaction with digital libraries. However, the amount of information found on the Web is far larger than in digital libraries. In this demo, we present an approach to transform Web-based resources to a FRBR compatible form, a process known as FRBRization. The FRBRized collection is then linked to DBpedia, thus providing a basis for information sharing and verification.

#index 1588437
#* An interactive flash website for oral histories
#@ Michael G. Christel;Bryan S. Maher;Julieanna Richardson
#t 2011
#c 14
#% 1065271
#% 1183296
#% 1213448
#% 1484633
#! Automatic speech alignment and natural language processing technologies provide full content search and retrieval access into oral history collections. These tools have been field-tested with The HistoryMakers and Harrisburg Living Legacy oral history archives, showing the value of an Adobe Flash front-end interface. Built with Adobe Flex 3, the interface works across browsers and operating systems, supports deep linking and browser-based navigation, provides synchronized transcripts that can be fully searched and tracked while watching the interviews, and incorporates filtering by facets, a menu bar breadcrumb interface, and a user play list to collect stories of interest. Refinements to the interface are discussed following the first six months of web deployment, with suggestions offered for other digital video libraries, particularly oral histories.

#index 1588438
#* When personalization meets socialization: an iCADAL approach
#@ Yin Zhang;Xiaojun Wang;Haihan Yu;Ruifeng Li;Baogang Wei;Jing Pan
#t 2011
#c 14
#% 1129444
#% 1194140
#% 1399992
#% 1400975
#! CADAL has been a large-scale non-profit digital library. Besides various search facilities in the CADAL portal, we designed and implemented the iCADAL system for providing the user-oriented micro-content services on one million books in CADAL. Users of iCADAL can receive the stream of short messages of lending, annotation and the other reading activities shared by their followees in a twitter-like way, which combines socialization with personalization. Our implementation makes extensive use of open source softwares, i.e. Pylons, Cassandra, in order to support the high-traffic online micro-content services.

#index 1588439
#* Supporting creative work in educational digital libraries
#@ Naimdjon Takhirov
#t 2011
#c 14
#% 332138
#% 1434162
#! Educational digital libraries have become an effective source of sharing information and dissemination of knowledge. Like paintings, personal stories containing pictures, music, and text will exist for a long time to come and will be enjoyed long after their creation. In this demo, we present a system called Creaza Education. The system offers an engaging suit of are user-friendly web-based applications where users can use their imagination by creating, publishing and sharing digital stories.

#index 1588440
#* Introducing Mr. DLib, a Machine-readable Digital Library
#@ Joeran Beel;Bela Gipp;Stefan Langer;Marcel Genzmehr;Erik Wilde;Andreas Nürnberger;Jim Pitman
#t 2011
#c 14
#% 711965
#% 1524389
#! In this demonstration-paper we present Mr. DLib, a machine-readable digital library. Mr. DLib provides access to several millions of articles in full-text and their metadata in XML and JSON format via a RESTful Web Service. In addition, Mr. DLib provides related documents for given academic articles. The service is intended to serve researchers who need bibliographic data and full-text of scholarly literature for their analyses (e.g. impact and trend analysis); providers of academic services who need additional information to enhance their own services (e.g. literature recommendations); and providers who want to build their own services based on data from Mr. DLib.

#index 1588441
#* Docear: an academic literature suite for searching, organizing and creating academic literature
#@ Joeran Beel;Bela Gipp;Stefan Langer;Marcel Genzmehr
#t 2011
#c 14
#% 760853
#% 1588440
#! In this demonstration-paper we introduce Docear, an 'academic literature suite'. Docear offers to scientists what an office suite like Microsoft Office offers to office workers. While an office suite bundles various applications for office workers (word processing, spreadsheets, presentation software, etc.), Docear bundles several applications for scientists: academic search engine, PDF reader, reference manager, word processor, mind mapping module, and recommender system. Besides Docear's general concept, its special features are presented in this paper, namely a modular composition, free full-text access to literature, information management as mind map, automatic metadata extraction of PDFs and recommendations.

#index 1588442
#* The digital library of historical cartography of the University of São Paulo
#@ Rogerio Toshiaki Kondo;Maria de Lourdes Rebucci Lirani;Anderson Canale Garcia;Iris Kantor;Caetano Traina, Jr.
#t 2011
#c 14
#! The Digital Library of Historical Cartography of the University of São Paulo makes available a set of high-resolution digital versions of maps printed between the XV and the XIX centuries belonging to the University's collections. Each map is available along with extensive carto-bibliographic and biographic references, and relevant technical, editorial and historical information for cartographic documents analysis. The Digital Library was also conceived to pursue data from other similar sites, constituting itself as a useful research tool. It provides facilities to gather relevant information to acknowledge the production, circulation and appropriation of historical maps in different contexts and media.

#index 1588443
#* GreenWiki: a tool to support users' assessment of the quality of Wikipedia articles
#@ Daniel Hasan Dalip;Raquel Lara Santos;Diogo Rennó Oliveira;Valéria Freitas Amaral;Marcos André Gonçalves;Raquel Oliveira Prates;Raquel C.M. Minardi;Jussara Marques de Almeida
#t 2011
#c 14
#% 1213445
#% 1589580
#% 1682183
#! In this work, we present GreenWiki, which is a wiki with a panel of quality indicators to assist the reader of a Wikipedia article in assessing its quality.

#index 1588444
#* Perambulating libraries: demonstrating how a victorian idea can help OLPC users share books
#@ David Bainbridge;Ian H. Witten
#t 2011
#c 14
#% 967265
#% 1153238
#% 1434731
#! In this extended abstract we detail how the open source digital library toolkit Greenstone [4] can help users of the XOlaptop produced by the One Laptop Per Child Foundation manage and share electronic documents. The idea draws upon mobile libraries (bookmobiles) for its inspiration, which first appeared in Victorian times. The implemented technique works by building on the mesh network that is instrumental to the XO-laptop approach. To use the technique, on each portable XO-laptop a version of Greenstone is installed, allowing the owner to develop and manage their own set of books. The version of Greenstone has been adapted to support a form of interoperability we have called Digital Library Talkback. On the mesh, when two XO-laptops "see" each other, the two users can search and browse the other user's digital library; when they see a book they like, they can have it transferred to their library with a single click using the Digital Library Talkback mechanism.

#index 1588445
#* SNAC: the social networks and archival context project
#@ Ray R. Larson
#t 2011
#c 14
#! This demonstration will show the prototype access and search system for the Social Networks and Archival Context project. The system is built on a database of merged Encoded Archival Context - Corporate Bodies, Persons, and Families (EAC-CPF) records derived from Encoded Archival Description (EAD) records held by the Library of Congress, the California Digital Library, the Northwest Digital Archives, and Virginia Heritage, combined with information from name authority files from the Library of Congress, OCLC Research, and the Getty Vocabulary Program. The database merges information from each instance of an individual name in these resources, along with variant names, biographical notes and their topical descriptions. The prototype interface makes this information searchable while retaining links to the various data sources, other resources (such as books by or about a person) and to other individuals, families and organizations associated with that name.

#index 1588446
#* Synchronicity: automatically rediscover missing web pages in real time
#@ Martin Klein;Moustafa Aly;Michael L. Nelson
#t 2011
#c 14
#% 1130827
#% 1434127
#! Missing web pages (pages that return the 404 "Page Not Found" error) are part of the browsing experience. The manual use of search engines to rediscover such pages can be frustrating and unsuccessful. We introduce Synchronicity, a Mozilla Firefox add-on that supports the Internet user in (re-)discovering missing web pages in real time.

#index 1588447
#* The Iowa City UNESCO City of literature digital library
#@ Haowei Hsieh;Bridget Draxler;Nicole Dudley;Jim Cremer;Lauren Haldeman;Dat Nguyen;Peter Likarish;Jon Winet
#t 2011
#c 14
#% 1588368
#! Iowa City is one of only four designated Cities of Literature worldwide by UNESCO. To highlight the city's rich local literary history, a University of Iowa interdisciplinary research team de-veloped a digital library featuring Iowa City authors and locations. The Iowa City UNESCO City of Literature "City of Lit" digital library consists of a mobile application for the general public and a web-based information system for researcher/content creators.

#index 1588448
#* Exploiting music structures for digital libraries
#@ Andreas F. Ehmann;Mert Bay;J. Stephen Downie;Ichiro Fujinaga;David De Roure
#t 2011
#c 14
#! This demonstration presents a music structure-based audio/visual interface for the navigation of very large scale music digital libraries. This work is a product of the Structural Analysis of Large Amounts of Music Information (SALAMI) project.

#index 1787032
#* Proceedings of the 12th ACM/IEEE-CS joint conference on Digital Libraries
#@ Karim B. Boughida;Barrie Howard;Michael L. Nelson;Herbert Van de Sompel;Ingeborg Sølvberg
#t 2012
#c 14
#! It is our great pleasure to welcome you to Washington, D.C., for the 12th ACM/IEEE Joint Conference on Digital Libraries (JCDL 2012). JCDL is the premiere international conference focused on digital libraries, and associated organizational, practical, social, and technical issues. The event addresses a broad spectrum of topical areas, and is open to all emerging and established educators, industry leaders, researchers, and students working in the field of digital library research and development. This year's conference is hosted by The George Washington University and coorganized with The Library of Congress. We have chosen a number of keynotes to amplify our conference themes of #preserving #linking #using #sharing. The opening keynote will be given by Jason Scott of textfiles.com. On the second day the keynote will be delivered by Carole Goble of the University of Manchester, and on the third day a closing keynote will be presented by George Dyson, a frequent contributor to The Edge Foundation. This year, we received 201 submissions (with authors from 32 countries) that went through a rigorous review process with Program Committee members from 22 countries. The result is a program that reflects the high quality of research being conducted in the breadth of disciplines that comprise digital libraries. We accepted 25 of 91 full paper submissions (27%) and 22 of 70 short papers (34%). In addition, there will be 43 posters and 9 demos following the now legendary "minute madness" on the first day of the conference. The Vannevar Bush Best Paper Award and the Best Student Paper Award will be presented at the conference banquet. JCDL 2012 continues the tradition of supporting digital library developers with four tutorials that cover a range of timely issues including user studies, building digital libraries, and teaching about digital libraries. The program also includes five workshops, which provide a venue for a crosssection of disciplines to explore focused, cutting-edge topics including disciplinary repositories, emergency informatics, and institutional repositories. JCDL 2012 opens with a Doctoral Consortium, a forum where Ph.D. students receive feedback and advice from a committee of internationally recognized researchers and practitioners.

#index 1787033
#* On the institutional archiving of social media
#@ Catherine C. Marshall;Frank M. Shipman
#t 2012
#c 14
#% 173739
#% 1040837
#% 1047347
#% 1355303
#% 1384222
#% 1384364
#% 1403509
#% 1480225
#% 1573469
#% 1588371
#% 1620116
#% 1662924
#% 1765204
#! Social media records the thoughts and activities of countless cultures and subcultures around the globe. Yet institutional efforts to archive social media content remain controversial. We report on 988 responses across six surveys of social media users that included questions to explore this controversy. The quantitative and qualitative results show that the way people think about the issue depends on how personal and ephemeral they view the content to be. They use concepts such as creator privacy, content characteristics, technological capabilities, perceived legal rights, and intrinsic social good to reason about the boundaries of institutional social media archiving efforts.

#index 1787034
#* To envisage and design the transition from a digital archive system developed for domain experts to one for non-domain users
#@ Maristella Agosti;Nicola Orio
#t 2012
#c 14
#% 809422
#% 874259
#! Diverse digital resources are commonly used by different types of users. It is common practice to develop those application having in mind a set of requirements for a specific target category of users. We envisaged and designed the IPSA archive and system using a similar approach: the identification of a set of requirements for researchers in illuminated manuscripts as a target group of domain professional users. The IPSA system has been in use as a research tool by domain professionals. The consideration that the content of the archive managed by the IPSA system could be of interest for other types of users suggested reconsidering its approach to envisage a new system designed around the same archive of illuminated manuscripts for their access by diverse categories of users. The paper reports on the work that was conducted to re-design and re-engineer the system to match requirements and expectations of non-domain users.

#index 1787035
#* Visualizing digital collections at archive-it
#@ Kalpesh Padia;Yasmin AlNoamany;Michele C. Weigle
#t 2012
#c 14
#% 172811
#% 399056
#% 838469
#% 869570
#% 1286769
#! Archive-It, a subscription service from the Internet Archive, allows users to create, maintain and view digital collections of web resources. The current interface of Archive-It is largely text-based, supporting drill-down navigation using lists of URIs. To provide an overview of each collection and highlight the collection's underlying characteristics, we present four alternate visualizations (image plot with histogram, wordle, bubble chart and timeline). The sites in an Archive-It collection may be organized by the collection curator into groups for easier navigation. However, many collections do not have such groupings, making them difficult to explore. We introduce a heuristics-based categorization for such collections.

#index 1787036
#* Data, data use, and scientific inquiry: two case studies of data practices
#@ Laura A. Wynholds;Jillian C. Wallis;Christine L. Borgman;Ashley Sands;Sharon Traweek
#t 2012
#c 14
#% 1000935
#% 1434158
#% 1588401
#% 1682001
#% 1914890
#! Data are proliferating far faster than they can be captured, managed, or stored. What types of data are most likely to be used and reused, by whom, and for what purposes? Answers to these questions will inform information policy and the design of digital libraries. We report findings from semi-structured interviews and field observations to investigate characteristics of data use and reuse and how those characteristics vary within and between scientific communities. The two communities studied are researchers at the Center for Embedded Network Sensing (CENS) and users of the Sloan Digital Sky Survey (SDSS) data. The data practices of CENS and SDSS researchers have implications for data curation, system evaluation, and policy. Some data that are important to the conduct of research are not viewed as sufficiently valuable to keep. Other data of great value may not be mentioned or cited, because those data serve only as background to a given investigation. Metrics to assess the value of documents do not map well to data.

#index 1787037
#* Digital preservation and knowledge discovery based on documents from an international health science program
#@ Dharitri Misra;Robert H. Hall;Susan M. Payne;George R. Thoma
#t 2012
#c 14
#% 137711
#% 197394
#% 1433488
#! Important biomedical information is often recorded, published or archived in unstructured and semi-structured textual form. Artificial intelligence and knowledge discovery techniques may be applied to large volumes of such data to identify and extract useful metadata, not only for providing access to these documents, but also for conducting analyses and uncovering patterns and trends in a field. The System for Preservation of Electronic Resources (SPER), an information management tool developed at the U.S. National Library of Medicine, provides these capabilities by integrating machine learning, data mining and digital preservation techniques. In this paper, we present an overview of SPER and its ability to retrieve information from one such dataset. We show how SPER was applied to the semi-structured records of an international health science program, the 46-year continuous archive of conference publications and related documents from the Joint Cholera Panel of the U.S.-Japan Cooperative Medical Science Program (CMSP). We explain the techniques by which metadata was extracted automatically from the semi-structured document contents to preserve these publications, and show how such data was used to quantitatively describe the activity of a research community toward a preliminary study of a subset of its specific health science program goals.

#index 1787038
#* Teacher sociality and information diffusion in educational digital libraries
#@ Ogheneovo Dibie;Keith E. Maull;Tamara Sumner
#t 2012
#c 14
#% 1434162
#% 1535333
#! Understanding the social aspects of digital resource utilization is an area of active research. In this study, we examine the digital library resource utilization and social behaviors of middle and high school Earth Science teachers of a large United States urban school district. We present the results of three analysis based on teachers using an online curriculum planning tool called the Curriculum Customization Service (CCS), and examine the social networks that emerge among the participating teachers. We explore these networks in the context of the digital library resources that were part of the CCS and the use of socio-centric features around those resources. Our initial findings show promise toward developing a broader understanding of the social networks of teachers, their behaviors around and usage of digital library resources, as well as the diffusion of information through those networks.

#index 1787039
#* Is it time to change the OER repositories role?
#@ Christo Dichev;Darina Dicheva
#t 2012
#c 14
#% 883712
#% 1721599
#! The growing number of digital libraries providing open educational resources (OER) requires effective resource discovery mechanisms to optimally exploit the benefits of their openness. This paper discusses the OER repositories role and presents a study aimed at understanding how educators find OER by seeking answers to questions such as: what proportion of users seeking OER go directly to OER repositories and what proportion uses search engines or some other means and why. Understanding how and with what tools users discover and access resources can have an impact on the OER repositories strategic development.

#index 1787040
#* Identifying core concepts in educational resources
#@ James M. Foster;Md. Arafat Sultan;Holly Devaul;Ifeyinwa Okoye;Tamara Sumner
#t 2012
#c 14
#% 967315
#% 1077328
#% 1223706
#% 1226568
#% 1301004
#% 1558464
#! This paper describes the results of a study designed to assess human expert ratings of educational concept features for use in automatic core concept extraction systems. Digital library resources provided the content base for human experts to annotate automatically extracted concepts on seven dimensions: coreness, local importance, topic, content, phrasing, structure, and function. The annotated concepts were used as training data to build a machine learning classifier as part of a tool used to predict the core concepts in the document. These predictions were compared with the experts' judgment of concept coreness.

#index 1787041
#* Deduced social networks for an educational digital library
#@ Monika Akbar;Clifford A. Shaffer;Edward A. Fox
#t 2012
#c 14
#% 204676
#% 452563
#% 573896
#% 578684
#% 722904
#% 805906
#% 1001306
#% 1077150
#% 1116284
#% 1383247
#% 1733883
#! By analyzing the behavior of previous users, digital libraries can be made to provide new users with more support to find the best information. The AlgoViz Portal collects metadata on algorithm visualizations and associated research literature. We show how logs can be used to discover latent relationships between users, deducing an implicit social network. By clustering the log data, we find different page-viewing patterns, which provide practical information about the different groups of users.

#index 1787042
#* A tale of two studies: is dissemination working?
#@ Flora McMartin;Sarah Giersch;Joseph Tront;Wesley Shumar
#t 2012
#c 14
#% 967345
#% 1751540
#! In this paper we describe preliminary results from two ongoing research projects that investigate the dissemination practices surrounding digital STEM learning materials for undergraduates. This research consists of two related studies, : 1) survey research about the dissemination practices of NSF-funded PIs; and, 2) a case study on the dissemination practices of courseware developers who won the Premier Award for Excellence in Engineering Education. The vast majority of PIs reported in the survey that they do not take advantage of digital dissemination methods such as education digital libraries. Premier Award-winning innovators reported using multiple dissemination methods - traditional and digital. Recommendations are provided regarding how digital library developers might work with PIs to improve dissemination.

#index 1787043
#* To better stand on the shoulder of giants
#@ Rui Yan;Congrui Huang;Jie Tang;Yan Zhang;Xiaoming Li
#t 2012
#c 14
#% 722904
#% 748017
#% 867267
#% 891549
#% 907511
#% 983833
#% 1063592
#% 1083684
#% 1214702
#% 1313757
#% 1392484
#% 1404878
#% 1434126
#% 1482198
#% 1482239
#% 1642061
#! Usually scientists breed research ideas inspired by previous publications, but they are unlikely to follow all publications in the unbounded literature collection. The volume of literature keeps on expanding extremely fast, whilst not all papers contribute equal impact to the academic society. Being aware of potentially influential literature would put one in an advanced position in choosing important research references. Hence, estimation of potential influence is of great significance. We study a challenging problem of identifying potentially influential literature. We examine a set of hypotheses on what are the fundamental characteristics for highly cited papers and find some interesting patterns. Based on these observations, we learn to identify potentially influential literature via Future Influence Prediction (FIP), which aims to estimate the future influence of literature. The system takes a series of features of a particular publication as input and produces as output the estimated citation counts of that article after a given time period. We consider several regression models to formulate the learning process and evaluate their performance based on the coefficient of determination (R2). Experimental results on a real-large data set show a mean average predictive performance of 83.6% measured in R^2. We apply the learned model to the application of bibliography recommendation and obtain prominent performance improvement in terms of Mean Average Precision (MAP).

#index 1787044
#* BibRank: a language-based model for co-ranking entities in bibliographic networks
#@ Laure Soulier;Lamjed Ben Jabeur;Lynda Tamine;Wahiba Bahsoun
#t 2012
#c 14
#% 169781
#% 262096
#% 290830
#% 309779
#% 507656
#% 751595
#% 879567
#% 879576
#% 879587
#% 1116996
#% 1121274
#% 1176930
#% 1348087
#% 1523395
#% 1537469
#% 1537470
#% 1694262
#! Bibliographic documents are basically associated with many entities including authors, venues, affiliations, etc. While bibliographic search engines addressed mainly relevant document ranking according to a query topic, ranking other related relevant bibliographic entities is still challenging. Indeed, document relevance is the primary level that allows inferring the relevance of the other entities regardless of the query topic. In this paper, we propose a novel integrated ranking model, called BibRank, that aims at ranking both document and author entities in bibliographic networks. The underlying algorithm propagates entity scores through the network by means of citation and authorship links. Moreover, we propose to weight these relationships using content-based indicators that estimate the topical relatedness between entities. In particular, we estimate the common similarity between homogeneous entities by analyzing marginal citations. We also compare document and author language models in order to evaluate the level of author's knowledge on the document topic and the document representativeness of author's knowledge. Experiment results on the representative CiteSeerX dataset show that BibRank model outperforms baseline ranking models with a significant improvement.

#index 1787045
#* Modeling and exploiting heterogeneous bibliographic networks for expertise ranking
#@ Hongbo Deng;Jiawei Han;Michael R. Lyu;Irwin King
#t 2012
#c 14
#% 262096
#% 268079
#% 290830
#% 730082
#% 750863
#% 766409
#% 805896
#% 838464
#% 838528
#% 879570
#% 907525
#% 956516
#% 1055681
#% 1055685
#% 1116996
#% 1176887
#% 1190060
#% 1195844
#% 1214701
#% 1227644
#% 1227654
#% 1348087
#% 1392465
#% 1400002
#% 1587391
#% 1606070
#% 1868015
#! Recently expertise retrieval has received increasing interests in both academia and industry. Finding experts with demonstrated expertise for a given query is a nontrivial task especially from a large-scale Web 2.0 systems, such as question answering and bibliography data, where users are actively publishing useful content online, interacting with each other, and forming social networks in various ways, leading to heterogeneous networks in addition to the large amounts of textual content information. Many approaches have been proposed and shown to be useful for expertise ranking. However, most of these methods only consider the textual documents while ignoring heterogeneous network structures or can merely integrate with one additional kind of information. None of them can fully exploit the characteristics of heterogeneous networks. In this paper, we propose a joint regularization framework to enhance expertise retrieval by modeling heterogeneous networks as regularization constraints on top of document-centric model. We argue that multi-typed linking edges reveal valuable information which should be treated differently. Motivated by this intuition, we formulate three hypotheses to capture unique characteristics for different graphs, and mathematically model those hypotheses jointly with the document and other information. To illustrate our methodology, we apply the framework to expert finding applications using a bibliography dataset with 1.1 million papers and 0.7 million authors. The experimental results show that our proposed approach can achieve significantly better results than the baseline and other enhanced models.

#index 1787046
#* Live television in a digital library
#@ Maxime Roüast;David Bainbridge
#t 2012
#c 14
#% 185265
#% 318858
#% 385946
#% 437509
#% 438054
#% 441058
#% 727501
#% 730997
#% 768761
#% 893758
#% 948453
#% 1213420
#% 1455248
#! The number of channels of digital television is increasing, particularly the number that are free-to-air. However due to the nature of broadcasting, this morass of information is not, for the main part, organized---it is principally a succession of images and sound transmitted as multiplexed streams of data. Compare this deluge that terrestrially bombards our homes with the information available in the digital libraries we access over the Internet---stored using software purpose built to help organize carefully curated sets of documents. This project brings together these two seemingly incompatible concepts to develop a software environment that concurrently captures all the available live television channels---so a user does not need to proactively choose what to record---and segments them into files which are then imported into a digital video library with a user interface designed to work from a multimedia remote control. A shifting time-based "window" of all recordings is maintained---we settled on from the last two weeks so as to be practicably operable on a regular desktop PC. The system leverages off the information contained in the electronic program guide and the video recordings to generate metadata suitable for the digital library. A user evaluation of the developed prototype showed a high level of participant satisfaction across a range of attributes, notably date-based searching.

#index 1787047
#* Transforming Japanese archives into accessible digital books
#@ Tatsuya Ishihara;Toshinari Itoko;Daisuke Sato;Asaf Tzadok;Hironobu Takagi
#t 2012
#c 14
#% 614082
#% 784526
#% 1093617
#% 1093622
#% 1164069
#% 1266421
#% 1283415
#% 1283437
#% 1301913
#% 1387045
#% 1588348
#% 1619970
#% 1645220
#! Digitized physical books offer access to tremendous amounts of knowledge, even for people with print-related disabilities. Various projects and standard activities are underway to make all of our past and present books accessible. However digitizing books requires extensive human efforts such as correcting the results of OCR (optical character recognition) and adding structural information such as headings. Some Asian languages need extra efforts for the OCR errors because of their many and varied character sets. Japanese has used more than 10,000 characters compared with a few hundred in English. This heavy workload is inhibiting the creation of accessible digital books. To facilitate digitization, we are developing a new system for processing physical books. We reduce and disperse the human efforts and accelerate conversions by combining automatic inference and human capabilities. Our system preserves the original page images for the entire digitization process to support gradual refinement and distributes the work as micro-tasks. We conducted trials with the Japanese National Diet Library (NDL) to evaluate the required effort for digitizing books with a variety of layouts and years of publication. The results showed old Japanese books had specific problems when correcting the OCR errors and adding structures. Drawing on our results, we discuss further workload reductions and future directions for international digitization systems.

#index 1787048
#* IPKB: a digital library for invertebrate paleontology
#@ Yuanliang Meng;Junyan Li;Patrick Denton;Yuxin Chen;Bo Luo;Paul Selden;Xue-wen Chen
#t 2012
#c 14
#% 8153
#% 176246
#% 185253
#% 185274
#% 218982
#% 249143
#% 345848
#% 614058
#% 769906
#% 837641
#% 869573
#% 874481
#% 989633
#% 1016618
#% 1083730
#% 1213408
#% 1213425
#% 1213432
#% 1213439
#% 1213447
#% 1434148
#% 1588368
#% 1588373
#% 1588381
#% 1656095
#% 1739983
#! In this paper, we present the Invertebrate Paleontology Knowledgebase (IPKB), an effort to digitize and share the Treatise on Invertebrate Paleontology. The Treatise is the most authoritative compilation of invertebrate fossil records. Unfortunately, the PDF version is simply a clone of paper publications and the content is in no way organized to facilitate search and knowledge discovery. We extracted texts and images from the Treatise, stored them in a database, and built a system for efficient browsing and searching. For image processing in particular, we segmented fossil photos from figures, recognized the embedded labels, and linked the images to the corresponding data entries. The detailed information of each genus, including fossil images, is delivered to users through a web access module. Some external applications (e.g. Google Earth) are acquired through web services APIs to improve user experience. Given the rich information in the Treatise, analyzing, modeling and understanding paleontological data are significant in many areas, such as: understanding evolution; understanding climate change; finding fossil fuels, etc. IPKB builds a general framework that aims to facilitate knowledge discovery activities in invertebrate paleontology, and provides a solid foundation for future explorations. In this article, we report our initial accomplishments. The specific techniques we employed in the project, such as those involved in text parsing, image-label association and meta data extraction, can be insightful and serve as examples for other researchers.

#index 1787049
#* Descriptive metadata, iconclass, and digitized emblem literature
#@ Timothy W. Cole;Myung-Ja K. Han;Jordan A. Vannoy
#t 2012
#c 14
#% 1434153
#! Early Modern emblems combined text and image. Though there were many variants, the archetypical emblem literary form (mid-sixteenth through mid-eighteenth centuries) consisted of an image (the pictura), a text inscription (the inscriptio), and a text epigram (the subscriptio), the last usually in verse. Digitized emblem literature poses interesting challenges as regards content and metadata granularity, the use of interdisciplinary controlled vocabularies, and the need to present digitized primary sources in a complex network of associated sources, derivatives, and contemporaneous context. In this paper, we describe a digital library Web application designed to better support the ways emblem scholars search for and use digitized emblem books, focusing on metadata design, issues of resource granularity and identification, and the use of Linked Data Web services for Iconclass, a multilingual classification system for cultural heritage art and images. Outcomes to date, achieved by emblem scholars and librarians working in collaboration, provide a case study for multi-faceted, interactive approaches to curating mixed text-image digital resources and the use of Linked Data vocabulary services. Lessons learned highlight the value of librarian-scholar collaboration and help to illustrate why digital libraries need to move beyond merely disseminating digitized book surrogates.

#index 1787050
#* Categorization of computing education resources with utilization of crowdsourcing
#@ Yinlin Chen;Paul Logasa Bogen, II;Haowei Hsieh;Edward A. Fox;Lillian N. Cassel
#t 2012
#c 14
#% 296738
#% 344447
#% 1046710
#% 1047347
#% 1469956
#% 1478133
#! The Ensemble Portal harvests resources from multiple heterogeneous federated collections. Managing these dynamically increasing collections requires an automatic mechanism to categorize records in to corresponding topics. We propose an approach to use existing ACM DL metadata to build classifiers for harvested resources in the Ensemble project. We also present our experience with utilizing the Amazon Mechanical Turk platform to build ground truth training data sets from Ensemble collections.

#index 1787051
#* Re-ranking bibliographic records for personalized library search
#@ Tadashi Nomoto
#t 2012
#c 14
#% 1227664
#% 1272267
#! This work will introduce a new approach to ranking bibliographic records in library search, which is currently dominated by an OPAC style search paradigm, where results are typically not ranked by relevance. The approach we propose in the paper provides the user with the ability to access bibliographic records in a way responsive to his or her preferences, which is essentially done by looking at a community or a group of people who share interests with the user and making use of their publication records to re-rank search results. The experiment found that the present approach gives a clear edge over conventional search methods.

#index 1787052
#* Generating ground truth for music mood classification using mechanical turk
#@ Jin Ha Lee;Xiao Hu
#t 2012
#c 14
#% 207677
#% 1047347
#% 1213444
#% 1264744
#% 1434137
#% 1700607
#% 1767356
#% 1767413
#! Mood is an important access point in music digital libraries and online music repositories, but generating ground truth for evaluating various music mood classification algorithms is a challenging problem. This is because collecting enough human judgments is time-consuming and costly due to the subjectivity of music mood. In this study, we explore the viability of crowdsourcing music mood classification judgments using Amazon Mechanical Turk (MTurk). Specifically, we compare the mood classification judgments collected for the annual Music Information Retrieval Evaluation eXchange (MIREX) with judgments collected using MTurk. Our data show that the overall distribution of mood clusters and agreement rates from MIREX and MTurk were comparable. However, Turkers tended to agree less with the pre-labeled mood clusters than MIREX evaluators. The system evaluation results generated using both sets of data were mostly the same except for detecting one statistically significant pair using Friedman's test. We conclude that MTurk can potentially serve as a viable alternative for ground truth collection, with some reservation with regards to particular mood clusters.

#index 1787053
#* Content-based layouts for exploratory metadata search in scientific research data
#@ Jürgen Bernard;Tobias Ruppert;Maximilian Scherer;Jörn Kohlhammer;Tobias Schreck
#t 2012
#c 14
#% 301247
#% 508138
#% 643518
#% 729437
#% 760853
#% 809410
#% 859913
#% 860956
#% 874506
#% 885130
#% 1000935
#% 1041734
#% 1185582
#% 1228255
#% 1407675
#% 1409954
#% 1441640
#% 1588399
#% 1624233
#% 1624253
#% 1646406
#% 1702283
#% 1939281
#! Today's digital libraries (DLs) archive vast amounts of information in the form of text, videos, images, data measurements, etc. User access to DL content can rely on similarity between metadata elements, or similarity between the data itself (content-based similarity). We consider the problem of exploratory search in large DLs of time-oriented data. We propose a novel approach for overview-first exploration of data collections based on user-selected metadata properties. In a 2D layout representing entities of the selected property are laid out based on their similarity with respect to the underlying data content. The display is enhanced by compact summarizations of underlying data elements, and forms the basis for exploratory navigation of users in the data space. The approach is proposed as an interface for visual exploration, leading the user to discover interesting relationships between data items relying on content-based similarity between data items and their respective metadata labels. We apply the method on real data sets from the earth observation community, showing its applicability and usefulness.

#index 1787054
#* Refactoring HUBzero for linked data
#@ Michael Witt;Yongyang Yu
#t 2012
#c 14
#% 1123812
#% 1776062
#% 1920360
#! The HUBzero cyberinfrastructure provides a virtual research environment that includes a set of tools for web-based, scientific collaboration and a platform for publishing and using resources such as executable software, source code, images, learning modules, videos, documents, and datasets. Released as open source in 2010, HUBzero has been implemented on a typical LAMP stack (Linux, Apache, MySQL, and PHP) and utilizes the Joomla! content management system. This paper describes the subsequent refactoring of HUBzero to produce and expose Linked Data from its backend, relational database, altering the external expression of the data without changing its internal structure. The Open Archives Initiative Object Reuse and Exchange (OAI-ORE) specification is applied to model the basic structural semantics of HUBzero resources as Nested Aggregations, and data and metadata are mapped to vocabularies such as Dublin Core and published within the web representations of the resources using RDFa. Resource Maps can be harvested using an RDF crawler or an OAI-PMH data provider that were bundled for demonstration purposes. A visualization was produced to browse and navigate the relations among data and metadata from an example hub.

#index 1787055
#* Treating data like software: a case for production quality data
#@ Jennifer M. Schopf
#t 2012
#c 14
#! In this short paper, we describe the production data approach to data curation. We argue that by treating data in a similar fashion to how we build production software, that data will be more readily accessible and available for broad re-use. We should be treating data as an ongoing process. This includes considering third-party contributions; planning for cyclical releases; bug fixes, tracking, and versioning; and issuing licensing and citation information with each release.

#index 1787056
#* A quantitative evaluation of techniques for detection of abnormal change events in blogs.
#@ Paul L. Bogen;Richard Furuta;Frank Shipman
#t 2012
#c 14
#% 231522
#% 240748
#% 309208
#% 327115
#% 337690
#% 342671
#% 344929
#% 748005
#% 760841
#% 791708
#% 835232
#% 838523
#% 891559
#% 941670
#% 967263
#% 1034713
#% 1065280
#% 1588363
#% 1588417
#% 1811362
#! While most digital collections have limited forms of change--primarily creation and deletion of additional resources--there exists a class of digital collections that undergoes additional kinds of change. These collections are made up of resources that are distributed across the Internet and brought together into a collection via hyperlinking. Resources in these collections can be expected to change as time goes on. Part of the difficulty in maintaining these collections is determining if a changed page is still a valid member of the collection. Others have tried to address this problem by measuring change and defining a maximum allowed threshold of change, however, these methods treat all change as a potential problem and treat web content as a static document despite its intrinsically dynamic nature. Instead, we approach the significance of change on the web as a normal part of a web document's life-cycle and determine the difference between what a maintainer expects a page to do and what it actually does. In this work we evaluate the different options for extractors and analyzers in order to determine the best options from a suite of techniques. The evaluation used a human-generated ground-truth set of blog changes. The results of this work showed a statistically significant improvement over a range of traditional threshold techniques when applied to our collection of tagged blog changes.

#index 1787057
#* Similar researcher search in academic environments
#@ Sujatha Das Gollapalli;Prasenjit Mitra;C. Lee Giles
#t 2012
#c 14
#% 324129
#% 722904
#% 758200
#% 879570
#% 891559
#% 967259
#% 987261
#% 987345
#% 1015008
#% 1083734
#% 1130922
#% 1176887
#% 1195845
#% 1275180
#% 1399975
#% 1432785
#% 1588364
#% 1588381
#% 1588383
#! Entity search is an emerging IR and NLP task that involves the retrieval of entities of a specific type in response to a query. We address the similar researcher search" or the "researcher recommendation" problem, an instance of similar entity search" for the academic domain. In response to a researcher name' query, the goal of a researcher recommender system is to output the list of researchers that have similar expertise as that of the queried researcher. We propose models for computing similarity between researchers based on expertise profiles extracted from their publications and academic homepages. We provide results of our models for the recommendation task on two publicly-available datasets. To the best of our knowledge, we are the first to address content-based researcher recommendation in an academic setting and demonstrate it for Computer Science via our system, ScholarSearch.

#index 1787058
#* An analysis of the named entity recognition problem in digital library metadata
#@ Nuno Freire;José Borbinha;Pável Calado
#t 2012
#c 14
#% 466892
#% 757350
#% 815864
#% 855108
#% 939376
#% 1016365
#% 1166537
#% 1588396
#! Information resources in digital libraries are usually described, along with their context, by structured data records, commonly referred as metadata. Those records often contain unstructured information in natural language text, since they typically follow a data model which defines generic semantics for its data elements, or includes data elements modeled to contain free text. The information contained in these data elements, although machine readable, resides in unstructured natural language texts that are difficult to process by computers. This paper addresses a particular task of information extraction, typically called named entity recognition, which deals with the references to entities made by names occurring in the texts. This paper presents the results of a study of how the named entity recognition problem manifests itself in digital library metadata. In particular, we present the main differences between performing named entity recognition in natural language and in the text within metadata. The paper finalizes with a novel approach for named entity recognition in metadata.

#index 1787059
#* Active associative sampling for author name disambiguation
#@ Anderson A. Ferreira;Rodrigo Silva;Marcos André Gonçalves;Adriano Veloso;Alberto H.F. Laender
#t 2012
#c 14
#% 152934
#% 236729
#% 246831
#% 376266
#% 722797
#% 760866
#% 804877
#% 809459
#% 810635
#% 823360
#% 907508
#% 915273
#% 915347
#% 916781
#% 937552
#% 967295
#% 1020797
#% 1073903
#% 1090229
#% 1107051
#% 1133176
#% 1195836
#% 1206818
#% 1211086
#% 1213413
#% 1213414
#% 1274820
#% 1434125
#% 1450862
#% 1467901
#% 1498542
#% 1564417
#% 1617356
#% 1663664
#% 1688430
#% 1755323
#% 1777687
#% 1787748
#! One of the hardest problems faced by current scholarly digital libraries is author name ambiguity. This problem occurs when, in a set of citation records, there are records of a same author under distinct names, or citation records belonging to distinct authors with similar names. Among the several proposed methods, the most effective ones seem to be based on the direct assignment of the records to their respective authors by means of the application of supervised machine learning techniques. The effectiveness of such methods is usually directly correlated with the amount of supervised training data available. However, the acquisition of training examples requires skilled human annotators to manually label references. Aiming to reduce the set of examples needed to produce the training data, in this paper we propose a new active sampling strategy based on association rules for the author name disambiguation task. We compare our strategy with state-of-the-art supervised baselines that use the complete labeled training dataset and other active methods and show that very competitive results in terms of disambiguation effectiveness can be obtained with reductions in the training set of up to 71%.

#index 1787060
#* AckSeer: a repository and search engine for automatically extracted acknowledgments from digital libraries
#@ Madian Khabsa;Pucktada Treeratpituk;C. Lee Giles
#t 2012
#c 14
#% 157492
#% 162460
#% 162470
#% 249143
#% 290830
#% 578773
#% 614036
#% 655499
#% 815207
#% 815922
#% 828959
#% 853701
#% 854824
#% 874510
#% 967256
#% 1006513
#% 1213413
#% 1223735
#% 1269719
#% 1270273
#% 1400044
#% 1472135
#% 1578576
#% 1806146
#! Acknowledgments are widely used in scientific articles to express gratitude and credit collaborators. Despite suggestions that indexing acknowledgments automatically will give interesting insights, there is currently, to the best of our knowledge, no such system to track acknowledgments and index them. In this paper we introduce AckSeer, a search engine and a repository for automatically extracted acknowledgments in digital libraries. AckSeer is a fully automated system that scans items in digital libraries including conference papers, journals, and books extracting acknowledgment sections and identifying acknowledged entities mentioned within. We describe the architecture of AckSeer and discuss the extraction algorithms that achieve a F1 measure above 83%. We use multiple Named Entity Recognition (NER) tools and propose a method for merging the outcome from different recognizers. The resulting entities are stored in a database then made searchable by adding them to the AckSeer index along with the metadata of the containing paper/book. We build AckSeer on top of the documents in CiteSeerx digital library yielding more than 500,000 acknowledgments and more than 4 million mentioned entities.

#index 1787061
#* Learning topics and related passages in books
#@ David Newman;Youn Noh;Kat Hagedorn;Arun Balagopalan
#t 2012
#c 14
#% 722904
#% 741058
#! The number of books available online is increasing, but user interfaces may not be taking full advantage of advances in machine learning techniques that could help users navigate, explore, discover and understand interesting and useful content in books. Using a group of ten students and over one thousand crowdsourced judgments, we conducted multiple user studies to evaluate topics and related passages in books, all learned by topic modeling. Using ten books, selected from humanities (e.g. Plato's Republic), social sciences (e.g. Marx's Capital) and sciences (e.g. Einstein's Relativity), and four different evaluation experiments, we show that users agree that the learned topics are coherent and important to the book, and related to the automatically generated passages. We show how crowdsourced evaluations are useful, and can complement more focused evaluations using students who have studied the texts. This work provides a framework for (1) learning topics and related passages in books, and (2) evaluating those learned topics and passages, and moves one step toward automatic annotation to support topic navigation of books.

#index 1787062
#* Emphasis on examining results in fiction searches contributes to finding good novels
#@ Suvi Oksanen;Pertti Vakkari
#t 2012
#c 14
#! We studied how an enriched public library catalogue is used to access novels. 58 users searched for interesting novels to read in a simulated situation where they had only a vague idea of what they would like to read. Data consist of search logs, pre and post search questionnaires and observations. Results show, that investing effort on examining results improves search success, i.e. finding interesting novels, whereas effort in querying has no bearing on it. In designing systems for fiction retrieval, enriching result presentation with detailed book information would benefit users.

#index 1787063
#* The "City of Lit" digital library: a case study of interdisciplinary research and collaboration
#@ Haowei Hsieh;Bridget Draxler;Nicole J. Dudley;Jon Winet
#t 2012
#c 14
#% 874480
#% 881134
#% 967271
#% 1001086
#% 1065251
#% 1213410
#% 1213512
#% 1213515
#% 1467158
#% 1588368
#! In 2008, Iowa City was designated as one of only five"Cities of Literature worldwide by UNESCO. To take advantage of our rich local literary history, an interdisciplinary research team from the University of Iowa collaborated to develop a digital library featuring Iowa City authors and locations. The UNESCO City of Literature digital library (referred to internally as "City of Lit") consists of a mobile application for the general public to access the database and a set of web-based interfaces for researcher and content creators to contribute to the database. Members of the research team have developed undergraduate literature courses to study the feasibility of using young scholars for digital content creation, and the pedagogical effect of including digital research in traditional literary courses. Students in the courses were trained to conduct scholarly research and generate a variety of digital resources to be included in the digital collection. This paper reports our experience building the City of Lit digital library and the results from evaluations and studies of the students in the courses. We also outline the implementation and development of the digital library, its framework, and the client-side mobile application.

#index 1787064
#* Student researchers, citizen scholars and the trillion word library
#@ Gregory Crane;Bridget Almas;Alison Babeu;Lisa Cerrato;Matthew Harrington;David Bamman;Harry Diakoff
#t 2012
#c 14
#% 249090
#% 330770
#% 760875
#% 997475
#% 1187624
#% 1213440
#% 1434121
#% 1434122
#% 1588347
#% 1624272
#% 1723623
#% 1939253
#! The surviving corpora of Greek and Latin are relatively compact but the shift from books and written objects to digitized texts has already challenged students of these languages to move away from books as organizing metaphors and to ask, instead, what do you do with a billion, or even a trillion, words? We need a new culture of intellectual production in which student researchers and citizen scholars play a central role. And we need as a consequence to reorganize the education that we provide in the humanities, stressing participatory learning, and supporting a virtuous cycle where students contribute data as they learn and learn in order to contribute knowledge. We report on five strategies that we have implemented to further this virtuous cycle: (1) reading environments by which learners can work with languages that they have not studied, (2) feedback for those who choose to internalize knowledge about a particular language, (3) methods whereby those with knowledge of different languages can collaborate to develop interpretations and to produce new annotations, (4) dynamic reading lists that allow learners to assess and to document what they have mastered, and (5) general e-portfolios in which learners can track what they have accomplished and document what they have contributed and learned to the public or to particular groups.

#index 1787065
#* Event-centric search and exploration in document collections
#@ Jannik Strötgen;Michael Gertz
#t 2012
#c 14
#% 766460
#% 815280
#% 855309
#% 874475
#% 956497
#% 1024551
#% 1035400
#% 1077150
#% 1120965
#% 1278145
#% 1335426
#% 1358020
#% 1471259
#% 1472106
#% 1472167
#% 1480777
#% 1481624
#% 1523942
#% 1560217
#% 1562901
#% 1562902
#% 1598429
#! Textual data ranging from corpora of digitized historic documents to large collections of news feeds provide a rich source for temporal and geographic information. Such types of information have recently gained a lot of interest in support of different search and exploration tasks, e.g., by organizing news along a timeline or placing the origin of documents on a map. However, for this, temporal and geographic information embedded in documents is often considered in isolation. We claim that through combining such information into (chronologically ordered) event-like features interesting and meaningful search and exploration tasks are possible. In this paper, we present a framework for the extraction, exploration, and visualization of event information in document collections. For this, one has to identify and combine temporal and geographic expressions from documents, thus enriching a document collection by a set of normalized events. Traditional search queries then can be enriched by conditions on the events relevant to the search subject. Most important for our event-centric approach is that a search result consists of a sequence of events relevant to the search terms and not just a document hit-list. Such events can originate from different documents and can be further explored, in particular events relevant to a search query can be ordered chronologically. We demonstrate the utility of our framework by different (multilingual) search and exploration scenarios using a Wikipedia corpus.

#index 1787066
#* Dynamic online views of meta-indexes
#@ Michael Huggett;Edie Rasmussen
#t 2012
#c 14
#% 56449
#% 1415729
#% 1431397
#% 1607918
#! For a collection of digitized monographs in a subject domain, a domain meta-index provides a summary of domain concepts, and a structured vocabulary to support a scholar's navigation and search. We present a prototype of a Meta-index User Interface (MUI) that provides views of a domain at three levels: summarizing and comparing domains, exposing the regularities of a domain's vocabulary, and displaying book information and page content related both to objectively-representative books, and to specific user searches.

#index 1787067
#* Topic models for taxonomies
#@ Anton Bakalov;Andrew McCallum;Hanna Wallach;David Mimno
#t 2012
#c 14
#% 722904
#% 788094
#% 983883
#% 1211828
#% 1334659
#% 1338553
#% 1481540
#% 1482284
#! Concept taxonomies such as MeSH, the ACM Computing Classification System, and the NY Times Subject Headings are frequently used to help organize data. They typically consist of a set of concept names organized in a hierarchy. However, these names and structure are often not sufficient to fully capture the intended meaning of a taxonomy node, and particularly non-experts may have difficulty navigating and placing data into the taxonomy. This paper introduces two semi-supervised topic models that automatically augment a given taxonomy with many additional keywords by leveraging a corpus of multi-labeled documents. Our experiments show that users find the topics beneficial for taxonomy interpretation, substantially increasing their cataloging accuracy. Furthermore, the models provide a better information rate compared to Labeled LDA.

#index 1787068
#* Concept chaining utilizing meronyms in text characterization
#@ Lori Watrous-deVersterre;Chong Wang;Min Song
#t 2012
#c 14
#% 321635
#% 342615
#% 443305
#% 786515
#% 896039
#% 949209
#% 955502
#% 1002315
#% 1026936
#% 1075802
#% 1193593
#% 1328333
#! For most, the web is the first source to answer a question formulated by curiosity, need, or research reasons. This phenomenon is due to the internet's ubiquitous access, ease of use, and the extensive and ever expanding content. The problem is no longer the need to acquire content to encourage use, but to provide organizational tools to support content categorization that will facilitate improved access methods. This paper presents the results of a new text characterization algorithm that combines semantic and linguistic techniques utilizing domain-based ontology background knowledge. It explores the combination of meronym, synonym, and hypernym linguistic relationships to create a set of concept chains used to represent concepts found in a document. The experiments show improved accuracy over bag-of-words based term weighting methods and reveal characteristics of the meronym contribution to document representation.

#index 1787069
#* Improving multi-faceted book search by incorporating sparse latent semantic analysis of click-through logs
#@ Deng Yi;Yin Zhang;Haihan Yu;Yanfei Yin;Jing Pan;Baogang Wei
#t 2012
#c 14
#% 298183
#% 310567
#% 317485
#% 330617
#% 345271
#% 348155
#% 452641
#% 590523
#% 591792
#% 754059
#% 783482
#% 805878
#% 838531
#% 869501
#% 869517
#% 1043040
#% 1588438
#% 1682107
#% 1712595
#! Multi-faceted book search engine presents diverse category-style options to allow users to refine search results without re-entering a query. In this paper, we propose a novel multi-faceted book search engine that utilizes users' query-related latent intents mined from click-through logs as multiple facets for books. The latent query intents can be effectively and efficiently discovered by applying the Sparse Latent Semantic Analysis (LSA) model to users' query and clicking behaviors in the click-through logs. This paper presents the details to improve the multi-faceted book search by incorporating the compact representation of query-intent-book relationships generated by Sparse LSA into the off-line and online processing procedures. The specificity of latent query intents can be flexibly changed by adjusting the sparsity level of projection matrix in the Sparse LSA model. We evaluated our approach on CADAL click-through logs containing 45,892 queries and 164,822 books. The experimental results show the Sparse LSA model with more sparse projection matrix tends to discover the more specific latent query intents. The latent query intents suggested by our approach usually gain the high user satisfaction ratio.

#index 1787070
#* Personalized query expansion in the QIC system
#@ Prat Tanapaisankit;Lori Watrous-deVersterre;Min Song
#t 2012
#c 14
#% 131434
#% 249143
#% 262096
#% 306468
#% 399057
#% 641976
#% 766428
#% 818262
#% 855119
#% 896031
#% 910657
#% 948366
#% 987193
#% 987231
#% 1280180
#% 1415737
#! Query In Context (QIC) is a personalized search system that enhances individual search by incorporating user preferences in query expansion, capturing meanings embedded in documents, and ranking search results with context-enriched features. In this paper, we propose a new technique for QIC's Query Expansion module, which reformulates user queries by using novel statistical-based and knowledge-based query expansion techniques to improve the returned results. The promising preliminary results analyzed through precision and recall metrics show better alignment between the user's interests and the results retrieved.

#index 1787071
#* Investigating keyphrase indexing with text denoising
#@ Rushdi Shams;Robert E. Mercer
#t 2012
#c 14
#% 281480
#% 505044
#% 874502
#% 1053504
#! In this paper, we report on indexing performance by a state-of-the-art keyphrase indexer, Maui, when paired with a text extraction procedure called text denoising. Text denoising is a method that extracts the denoised text, comprising the content-rich sentences, from full texts. The performance of the keyphrase indexer is demonstrated on three standard corpora collected from three domains, namely food and agriculture, high energy physics, and biomedical science. Maui is trained using the full texts and denoised texts. The indexer, using its trained models, then extracts keyphrases from test sets comprising full texts, and their denoised and noise parts (i.e., the part of texts that remains after denoising). Experimental findings show that against a gold standard, the denoised-text-trained indexer indexing full texts, performs either better than or as good as its benchmark performance produced by a full-text-trained indexer indexing full texts.

#index 1787072
#* Exploiting real-time information retrieval in the microblogosphere
#@ Feng Liang;Runwei Qiang;Jianwu Yang
#t 2012
#c 14
#% 340901
#% 342707
#% 730070
#% 750863
#% 879585
#% 982760
#% 1024569
#% 1040837
#% 1130999
#% 1184648
#% 1292730
#% 1399966
#% 1404888
#% 1450901
#% 1618642
#! Information seeking behavior in microblogging environments such as Twitter differs from traditional web search. The best performing microblog retrieval techniques attempt to utilize both semantic and temporal aspects of documents. In this paper, we present an effective approach, including the query modeling, the document modeling and the temporal re-ranking, to discover the most recent but relevant information to the query. For the query modeling, we introduce a two-stage pseudo-relevance feedback query expansion to overcome the severe vocabulary-mismatch problem of short message retrieval in microblog. For the document modeling, we propose two ways to expand document with the help of the shortened URL. For the temporal re-ranking, we suggest several methods to evaluate the temporal aspects of documents. Experimental results demonstrate that our approach obtains significant improvements compared with baseline systems. Specifically, the proposed system gives 26.37% and 9.94% further increases in P@30 and MAP over the best performing result on highrel in the TREC'11 Real-Time Search Task.

#index 1787073
#* Improving algorithm search using the algorithm co-citation network
#@ Suppawong Tuarob;Prasenjit Mitra;C. Lee Giles
#t 2012
#c 14
#% 1292757
#% 1301004
#% 1400044
#% 1578576
#% 1667278
#! Algorithms are an essential part of computational science. An algorithm search engine, which extracts pseudo-codes and their metadata from documents, and makes it searchable, has recently been developed as part of the CiteseerX suite. However, this algorithm search engine only retrieves and ranks relevant algorithms solely on textual similarity. Here, we propose a method for using the algorithm co-citation network to infer the similarity between algorithms. We apply a graph clustering algorithm on the network for algorithm recommendation and make suggestions on how to improve the current CiteseerX algorithm search engine.

#index 1787074
#* Evaluating and ranking patents using weighted citations
#@ Sooyoung Oh;Zhen Lei;Prasenjit Mitra;John Yen
#t 2012
#c 14
#! Citation counts have been widely used in a digital library for purposes such as ranking scientific publications and evaluating patents. This paper demonstrates that distinguishing different types of citations could rank better for these purposes. We differentiate patent citations along two dimensions (assignees and technologies) into four types, and propose a weighted citation approach for assessing and ranking patents. We investigate five weight learning methods and compare their performance. Our weighted citation method performs consistently better than simple citation counts, in terms of rank correlations with patent renewal status. The estimated weights on different citations are consistent with economic insights on patent citations. Our study points to an interesting and promising research line on patent citation and network analysis that has not been explored.

#index 1787075
#* A hybrid two-stage approach for discipline-independent canonical representation extraction from references
#@ Sung Hee Park;Roger W. Ehrich;Edward A. Fox
#t 2012
#c 14
#% 197394
#% 300288
#% 438103
#% 464434
#% 614036
#% 656285
#% 747762
#% 874707
#% 937552
#% 939527
#% 942406
#% 967276
#% 983878
#% 1005279
#% 1022360
#% 1065277
#% 1130834
#% 1246525
#% 1269815
#% 1338742
#% 1434213
#% 1478186
#% 1550728
#! In education and research, references play a key role. However, extracting and parsing references are difficult problems. One concern is that there are many styles of references; hence, given a surface form, identifying what style was employed is problematic, especially in heterogeneous collections of theses and dissertations, which cover many fields and disciplines, and where different styles may be used even in the same publication. We address these problems by drawing upon suitable knowledge found in the WWW. In particular, we research a two-stage classifier approach, involving multi-class classification with respect to reference styles, and partially solve the problem of parsing surface representations of references. We describe empirical evidence for the effectiveness of our approach and plans for improvement of our methods.

#index 1787076
#* Web-based citation parsing, correction and augmentation
#@ Liangcai Gao;Xixi Qi;Zhi Tang;Xiaofan Lin;Ying Liu
#t 2012
#c 14
#% 252750
#% 614036
#% 614037
#% 718532
#% 832344
#% 942406
#% 967276
#% 1006684
#% 1020797
#% 1065277
#% 1078010
#% 1134173
#% 1213417
#% 1283525
#% 1642305
#! Considering the tremendous value of citation metadata, many methods have been proposed to automate Citation Metadata Extraction (CME). The existing methods primarily rely on the content analysis of citation text. However, the results from such content-based methods are often unreliable. Moreover, the extracted citation metadata is only a small part of the relevant metadata that spreads across the Internet. As opposed to the content-based CME methods, this paper proposes a Web-based CME approach and a citation enriching system, called as BibAll, which is capable of correcting the parsing results of content-based CME methods and augmenting citation metadata by leveraging relevant bibliographic data from digital repositories and cited-by publications on the Web. BibAll consists of four main components: citation parsing, Web-based bibliographic data retrieval, irrelevant bibliographic data filtering, and relevant bibliographic data integration. The system has been tested on the publicly available FLUX-CIM dataset. Experimental results show that BibAll significantly improves the citation parsing accuracy and augments the metadata of the original citation.

#index 1787077
#* Book selection behavior in the physical library: implications for ebook collections
#@ Annika Hinze;Dana McKay;Nicholas Vanderschantz;Claire Timpany;Sally Jo Cunningham
#t 2012
#c 14
#% 142252
#% 186518
#% 197968
#% 237336
#% 247296
#% 280793
#% 301234
#% 337262
#% 614033
#% 809441
#% 881951
#% 1065245
#% 1093782
#% 1153254
#% 1440204
#% 1448510
#% 1482553
#% 1588386
#% 1624261
#% 1648591
#% 1671626
#% 1914893
#! Little is known about how readers select books, whether they be print books or ebooks. In this paper we present a study of how people select physical books from academic library shelves. We use the insights gained into book selection behavior to make suggestions for the design of ebook-based digital libraries in order to better facilitate book selection behavior.

#index 1787078
#* How do people organize their photos in each event and how does it affect storytelling, searching and interpretation tasks?
#@ Jesse Prabawa Gozali;Min-Yen Kan;Hari Sundaram
#t 2012
#c 14
#% 214715
#% 231605
#% 272902
#% 297630
#% 342528
#% 378541
#% 415112
#% 452642
#% 755102
#% 760826
#% 802851
#% 860092
#% 998806
#% 998826
#% 1299625
#% 1356217
#% 1401420
#% 1406484
#% 1434141
#% 1498570
#% 1538238
#% 1588377
#% 1649279
#% 1742099
#% 1783152
#% 1886415
#! This paper explores photo organization within an event photo stream, i.e. the chronological sequence of photos from a single event. The problem is important: with the advent of inexpensive, easy-to-use photo capture devices, people can take a large number of photos per event. A family trip, for example, may include hundreds of photos. In this work, we have developed a photo browser that uses automatically segmented groups of photos---referred to as chapters---to organize such photos. The photo browser also affords users with a drag-and-drop interface to refine the chapter groupings. We conducted an exploratory study of 23 college students with their 8096 personal photos from 92 events, to understand the role of different spatial organization strategies in our chapter-based photo browser, in performing storytelling, photo search and photo set interpretation tasks. We also report novel insights on how the subjects organized their photos into chapters. We tested three layout strategies: bi-level, grid-stacking and space-filling, against a baseline plain grid layout. We found that subjects value the chronological order of the chapters more than maximizing screen space usage and that they value chapter consistency more than the chronological order of the photos. For automatic chapter groupings, having low chapter boundary misses is more important than having low chapter boundary false alarms; the choice of chapter criteria and granularity for chapter groupings are very subjective; and subjects found that chapter-based photo organization helps in all three tasks of the user study. Users preferred the chapter-based layout strategies to the baseline at a statistically significant level, with the grid-stacking strategy preferred the most.

#index 1787079
#* Co-reading: investigating collaborative group reading
#@ Jennifer Pearson;Tom Owen;Harold Thimbleby;George R. Buchanan
#t 2012
#c 14
#% 85726
#% 232895
#% 237318
#% 247296
#% 281359
#% 377387
#% 507834
#% 816596
#% 867337
#% 967348
#% 1015011
#% 1047489
#% 1107033
#% 1131077
#% 1153240
#% 1183274
#% 1189153
#% 1355323
#% 1366911
#% 1384269
#% 1434152
#% 1440204
#% 1573718
#% 1649152
#% 1939251
#! Collaborative reading, or co-reading as we call it, is ubiquitous; it occurs, for instance, in classrooms, book-clubs, and in less coordinated ways through mass media. While individual digital reading has been the subject of much investigation, research into co-reading is scarce. We report a two-phase field study of group reading to identify an initial set of user requirements. A co-reading interface is then designed that facilitates the coordination of group reading by providing temporary `Point-out' markers to indicate specific locations within documents. A user study compared this new system with collaborative reading on paper, with a positive outcome; the differences in user behavior between paper and the new interface reveal intriguing insights into user needs and the potential benefits of digital media for co-reading.

#index 1787080
#* A digital library for water main break identification and visualization
#@ Sunshin Lee;Noha Elsherbiny;Edward A. Fox
#t 2012
#c 14
#% 1400018
#% 1472942
#! This paper describes a prototype of a digital library for water main break identification and visualization. Many utilities rely on an emergency call to detect water main breaks, because breaks are difficult to predict. Collecting the information by call requires time consuming human efforts. Furthermore, it is not archived and not shared with others. Collecting and archiving the information by tweets, news, and web resources helps users to identify relevant water main breaks efficiently. In developing this prototype, we extracted location information from text instead of using GPS data. We also describe the importance of tweet visualization by location, and how we visualize tweets on a map.

#index 1787081
#* A preliminary analysis of FRBR's bibliographic relationships for path based associative rules
#@ Ya-Ning Chen;Hui-Pin Chen;Fei-Yen Tu
#t 2012
#c 14
#% 967280
#% 1651639
#! The Functional Requirements for Bibliographic Records (hereafter FRBR) has been adopted to address the relationships for bibliographic records and the related aggregate works. However, an approach to transform FRBR-based bibliographic relationships and their patterns into path-based rules for retrieval, navigation, display and data mining in the bibliographic space is still lacking. This study used the FRBR as a basis to analyze bibliographic relationships and their path-based rules. The novel "Harry Potter and the Philosopher's Stone" was used as a case study. Up until now, 87 unique records were retrieved from OCLC's Open WorldCat for analysis. Two specialists in library and information science familiar with FRBR conducted in-depth analysis to achieve inter-reliability agreement. This study generalizes several patterns of path-based rules for associating bibliographic records and outlines related issues for future study.

#index 1787082
#* A qualitative analysis of information dissemination through twitter in a digital library
#@ Hae Min Kim;Christopher C. Yang;Eileen G. Abels;Mi Zhang
#t 2012
#c 14
#% 1040837
#% 1158333
#% 1355297
#% 1512437
#! This study examines the use of Twitter in a digital library, the Internet Public Library (ipl2), to understand the content and dissemination patterns of Twitter messages posted by the ipl2. We conducted a content analysis on ipl2's messages on Twitter to develop a categorization of the type of tweets, and examined retweets and the active users who retweeted ipl2 tweets. We present our analysis of four areas related to the tweets: motivation, content, audience, and sources. Active users are categorized into eight groups. The research findings contribute to a further understanding of the actual use of Twitter in a digital library.

#index 1787083
#* A study of automation from seed URL generation to focused web archive development: the CTRnet context
#@ Seungwon Yang;Kiran Chitturi;Gregory Wilson;Mohamed Magdy;Edward A. Fox
#t 2012
#c 14
#% 1400077
#! In the event of emergencies and disasters, massive amounts of web resources are generated and shared. Due to the rapidly changing nature of those resources, it is important to start archiving them as soon as a disaster occurs. This led us to develop a prototype system for constructing archives with minimum human intervention using the seed URLs extracted from tweet collections. We present the details of our prototype system. We applied it to five tweet collections that had been developed in advance, for evaluation. We also identify five categories of non- relevant files and conclude with a discussion of findings from the evaluation.

#index 1787084
#* A system for indexing tables, algorithms and figures
#@ Pradeep B. Teregowda;Madian Khabsa;Clyde L. Giles
#t 2012
#c 14
#% 348155
#% 533966
#% 642975
#% 967256
#% 1400044
#% 1475144
#! Indexing objects such as documents, figures, tables and algorithms in a single system presents challenges in schema mapping, detecting overlapping objects in documents, presenting results from such an system to users. We propose a federated approach to indexing and retrieving such objects in academic papers

#index 1787085
#* A technique for suggesting related Wikipedia articles using link analysis
#@ Christopher Markson;Min Song
#t 2012
#c 14
#% 1512625
#! With more than 3.7 million articles, Wikipedia has become an important social medium for sharing knowledge. However, with this enormous repository of information, it can often be difficult to locate fundamental topics that support lower-level articles. By exploiting the information stored in the links between articles, we propose that related companion articles can be automatically generated to help further the reader's understanding of a given topic. This approach to a recommendation system uses tested link analysis techniques to present users with a clear path to related high-level articles, furthering the understanding of low-level topics.

#index 1787086
#* An exploration of the research trends in the digital library evaluation domain
#@ Giannis Tsakonas;Angelos Mitrelis;Leonidas Papachristopoulos;Christos Papatheodorou
#t 2012
#c 14
#% 723329
#% 1072522
#% 1454231
#% 1495108
#% 1608932
#! Evaluation is a vital research area in the digital library domain, demonstrating a growing literature in conference and journal papers. In this poster we present the research trends that governed the field within the decade 2001--2010 in the JCDL and ECDL conferences. The DL evaluation literature was annotated using the domain ontology DiLEO, which defines explicitly the main concepts of the digital library evaluation field and their correlations. Several findings from this study underline the persistent character of quantitative research in evaluation initiatives.

#index 1787087
#* An iterative reliability measure for semi-anonymous annotators
#@ Peter Organisciak
#t 2012
#c 14
#% 1264744
#% 1470586
#% 1477589
#! This study addresses problems of reliability in the creation of tagged corpora by self-selected semi-anonymous raters. In order to account for both strong and weak raters, this paper contributes a recursive technique for scoring rater reliability. By assigning raters trust scores in the proposed method, candidate labels can be weighted by a confidence score and low-confidence ratings can be routed to an expert rater or additional amateur raters for further action.

#index 1787088
#* An unsupervised technical difficulty ranking model based on conceptual terrain in the latent space
#@ Shoaib Jameel;Wai Lam;Xiaojun Qian;Ching-man Au Yeung
#t 2012
#c 14
#% 321635
#% 838547
#! Search results of the existing general-purpose search engines usually do not satisfy domain-specific information retrieval tasks as there is a mis-match between the technical expertise of a user and the results returned by the search engine. In this paper, we investigate the problem of ranking domain-specific documents based on the technical difficulty. We propose an unsupervised conceptual terrain model using Latent Semantic Indexing (LSI) for re-ranking search results obtained from a similarity based search system. We connect the sequences of terms under the latent space by the semantic distance between the terms and compute the traversal cost for a document indicating the technical difficulty. Our experiments on a domain-specific corpus demonstrate the efficacy of our method.

#index 1787089
#* Longitudinal analysis of historical texts' readability
#@ Adam Jatowt;Katsumi Tanaka
#t 2012
#c 14
#! Digital libraries often contain historical documents of varying age. The degree to which users can understand their content depends much on their reading difficulty. In this poster paper we report the results of our studies on the readability of historical documents from the viewpoint of present users. We investigate the correlation between the outcomes of different readability measurements and publication dates of prose texts on the basis of two datasets, the Victorian Women's Writers Project and the Corpus of Late Modern English Texts.

#index 1787090
#* Bi2SoN: a digital library for supporting biomedical research
#@ Benjamin Köhncke;Sascha Tönnies;Wolf-Tilo Balke
#t 2012
#c 14
#! In the domain of biology a huge amount of different data sources is available. Therefore, information gathering and searching are challenging tasks. To avoid a manual assessment of all relevant data sources, their knowledge has to be integrated. The presented system focuses on all aspects needed for suitable data integration and retrieval for domain experts from the field of biology. The knowledge from different data sources is combined and further used for, e.g. synonym enrichment of the query term. The resulting prototype was presented to a group of domain experts who confirmed that the system delivers suitable results supporting the scientists by their literature search.

#index 1787091
#* CADAL digital calligraphy system
#@ Pengcheng Gao;Jiangqin Wu;Yang Xia;Yuan Lin
#t 2012
#c 14
#! CADAL(China Academic Digital Associate Library) plays a primary role in Universal Digital Library. By the end of 2011, CADAL has digitized 1.85 million books. Chinese calligraphy occupies an important place in Chinese culture, and the collection of digitized Chinese calligraphy is the large part of CADAL resources. So, the services of making full use of the collections are required for diverse users, such as art historians, students and the public. Here we propose a CADAL Digital Calligraphy System, in which over 1,100 works and 100,000 characters are included, the services of multi-level metadata-based search(metadata-based books search, works search and characters search) and multi-grain calligraphic character search(content-based search and radical-based search) are provided. In the end, some search-related applications of CADAL Digital Calligraphy System are discussed.

#index 1787092
#* Characterize scientific domain and domain context
#@ Jinsong Zhang;Chun Guo;Xiaozhong Liu
#t 2012
#c 14
#% 400649
#% 740301
#% 975019
#% 1338553
#! Domain knowledge map construction as an important method can describe the significant characters of a selected domain. In this research, we will address three problems for knowledge graph generation. Firstly, this paper will construct domain (core journals and conference proceedings) knowledge and domain context (domain citation) knowledge graphs, and propose a novel method to integrate those graphs. Secondly, two different methods will be investigated to associate keywords on the graph: Co-occur Domain Distance and Citation Probability Distribution Distance. Last but not least, the paper will propose an innovative method to evaluate the accuracy and coverage of knowledge graphs based on training keyword oriented Labeled-LDA model and validate different domain or domain context graphs.

#index 1787093
#* Collaboration and communication tools used by the biodiversity heritage library
#@ Trish-Rose Sandler;Constance Rinaldo;Keri Thompson;William Ulate;Martin Kalfatovic
#t 2012
#c 14
#! Through the application of multiple strategies and tools, the Biodiversity Heritage Library has created an effective and collaborative multi-institutional virtual organization. The purpose of this paper is to explore the communication and collaboration strategies used by the BHL to create, maintain, and provide open access to its corpus of biodiversity literature. BHL, in its seventh year, is a mature service and no longer a pilot project. Largely driven from the ground up, and without any institutional mandate, the BHL has successfully and organically fostered an organizational model that has encouraged innovation, user engagement, and global expansion.

#index 1787094
#* Data determination, disambiguation, and referencing in molecular biology
#@ Shuheng Wu;Besiki Stvilia;Dong Joon Lee
#t 2012
#c 14
#% 799685
#% 999300
#! Entity and instance determination, disambiguation, and referencing, referred to as authority control in libraries, are essential for scientific research. This study examines the authority control practices and issues in molecular biology using literature and scenario analyses. The analyses imply that the concept of authority control in molecular biology is associated with three tasks: named entity recognition, disambiguation, and unification. The identified authority control issues were conceptualized as quality problems caused by four sources: inconsistent or incomplete mapping, context changes, entity changes, and changes in entity metadata. This study can inform librarians and repository curators of the needs and issues of authority control in molecular biology and other related disciplines.

#index 1787095
#* Digital libraries for computational journalism
#@ Luis Francisco-Revilla
#t 2012
#c 14
#% 769144
#% 1214671
#% 1588438
#! Computational journalism is driving the evolution of news media, devising new ways for collecting and analyzing large numbers of digital artifacts such as tweets and memes. This paper presents Breadcrumbs PDL, a specialized Personal Digital Library system that helps readers and journalists to access and use a collection of user-detected memes. PDL is part of Project Breadcrumbs, which aims to capitalize on public participation in the news media cycle. PDL supports browsing and exploration, and supports recommendations services that suggest alternative memes to read and ways to organize the users' personal workspace. Based on the users' clipping and organizational behaviors and textual similarities between clips, PDL can infer relationships between memes that computers alone cannot easily detect.

#index 1787096
#* Comparison of three digital library interfaces: open library, Google books, and Hathi Trust
#@ Matthew Miller;Gilok Choi;Lindsay Chell
#t 2012
#c 14
#% 185254
#% 762422
#! Digital libraries often require very specialized interfaces in order to present various types of digital content. It is therefore critical to create interfaces that improve presentation of digital information and maximize user experience with digital collections. In this respect, this research aims to examine interfaces of three digital libraries that provide collections of digital text. The three digital libraries include Open Library, Google Books, and Hathi Trust. An evaluation matrix was developed to measure usability, aesthetics and interface components. The overall findings of the study showed that the majority of the participants preferred the Open Library interface followed by Google Books. The statistical analysis indicated that Open Library is significantly better than Google Books and Hathi Trust in terms of usability, aesthetics, and interface components. The preference for the Open Library stemmed largely from aesthetic choices. Participants also appreciated the use of elements that are analogous to their physical counterparts.

#index 1787097
#* Digital preservation in a box: outreach resources for digital stewardship
#@ Butch Lazorchak;Susan Manus;Dever Powell;Jane Zhang
#t 2012
#c 14
#! "Digital Preservation in a Box" is a major activity of the National Digital Stewardship Alliance (NDSA) Outreach Working Group. This toolkit of digital stewardship outreach resources can be utilized by diverse communities as a gentle introduction to the concepts of preserving digital information.

#index 1787098
#* Distinguishing venues by writing styles
#@ Zaihan Yang;Brian D. Davison
#t 2012
#c 14
#% 428405
#% 740416
#! A principal goal for most research scientists is to publish. There are different kinds of publications covering different topics and requiring different writing formats. While authors tend to have unique personal writing styles, no work has been carried out to find out whether publication venues are distinguishable by their writing styles. Our work takes the first step into exploring this problem. Using the traditional classification approach and carrying out experiments on real data from the CiteSeer digital library, we demonstrate that venues are also distinguished by their writing styles.

#index 1787099
#* Do public library websites consider the disabled or senior citizens?
#@ Yong Jeong Yi;Ji Hei Kang
#t 2012
#c 14
#% 907119
#! The issues of mobility and sight impairment with respect to virtual accessibility are as important as physical accessibility when it comes to using public library services. However, few studies have discussed public library website accessibility from the perspective of underrepresented user groups. The purpose of this study is to evaluate the accessibility of websites of public libraries and further identify the association between accessibility and public libraries' budgets. The study selected 20 public library systems that have the highest percentages of the disabled or senior citizen patrons. The study employed the Pearson correlation test in order to investigate the correlation between the accessibility and the budgets of public libraries. Preliminary findings show that most current public library websites do not comply with the Section 508. The findings indicate that public libraries did not consider their users or potential users with physical disabilities when designing their websites. Therefore, the findings suggest that public library websites are not suited to deliver effective information services for underrepresented user populations who need special assistance. Furthermore, this study finds that there is no significant association between the public library websites' accessibility and the budgets.

#index 1787100
#* Electronic records processing: it's a CINCH!
#@ Amy Rudersdorf;Dean Farrell;Lisa Gregory
#t 2012
#c 14
#! In August 2011, five project partners (the State Library of North Carolina, the North Carolina State Archives, North Carolina Libraries for Virtual Education, Elon University, and the University of North Carolina at Charlotte) began a collaboration to develop a computer application that collects, ingests, and authenticates the electronic records that libraries and archives are often mandated to maintain. The application, called "CINCH," incorporates existing digital curation technologies, but adds to their functionality by creating a pull-down (or capture) utility to gather content available from the Internet. The final product will be a lightweight, open-source software tool that institutions required to collect and authenticate records on ingest can employ to retrieve and process their digital content.

#index 1787101
#* Exploiting canonical structures to transmit complex objects from a digital library to a portal
#@ Scott Britell;Lois Delcambre;Lillian Cassel;Edward Fox;Richard Furuta
#t 2012
#c 14
#% 287631

#index 1787102
#* Global web archive integration with memento
#@ Robert Sanderson
#t 2012
#c 14
#% 878626
#! In this poster, we describe the approach taken to designing and implementing a tera-scale multi-repository index of archived web resources using massively parallel processing.

#index 1787103
#* GROTOAP: ground truth for open access publications
#@ Dominika Tkaczyk;Artur Czeczko;Krzysztof Rusek;Lukasz Bolikowski;Roman Bogacewicz
#t 2012
#c 14
#% 879673
#% 1283548
#% 1779561
#! The field of digital document content analysis includes many important tasks, for example page segmentation or zone classification. It is impossible to build effective solutions for such problems and evaluate their performance without a reliable test set, that contains both input documents and expected results of segmentation and classification. In this paper we present GROTOAP --- a test set useful for training and performance evaluation of page segmentation and zone classification tasks. The test set contains input articles in a digital form and corresponding ground truth files. All input documents included in the test set have been selected from DOAJ database, which indexes articles published under CC-BY license. The whole test set is available under the same license.

#index 1787104
#* Has it been already digitized?: how to find information about digitized documents
#@ Tomas Foltyn;Martin Lhotak;Pavel Kocourek
#t 2012
#c 14
#! The Digitization Registry of the Czech Republic is a research project the aim of which is to create a national registry of digitized documents to avoid unwanted duplications in the digitization as well as to share digitization results throughout the Czech Republic. This could make the digitization more effective and also economize financial resources of participating institutions.

#index 1787105
#* How can spreaders affect the indirect infuence on twitter?
#@ Xin Shuai;Ying Ding;Jerome Busemeyer
#t 2012
#c 14
#% 1214702
#% 1400031
#% 1560424
#! Most studies on social influence have focused on direct influence, while another interesting question can be raised as whether indirect influence exists between two users who're not directly connected in the network and what affects such influence. In addition, the theory of complex contagion tells us that more spreaders will enhance the indirect influence between two users. Our observation of intensity of indirect influence, propagated by n parallel spreaders and quantified by retweeting probability on Twitter , shows that complex contagion is validated globally but is violated locally. In other words, the retweeting probability increases non-monotonically with some local drops.

#index 1787106
#* Improving a hybrid literary book recommendation system through author ranking
#@ Paula Cristina Vaz;David Martins de Matos;Bruno Martins;Pavel Calado
#t 2012
#c 14
#% 1227721
#% 1396096
#% 1642345
#! Literary reading is an important activity for individuals and can be a long term commitment, making book choice an important task for book lovers and public library users. In this paper, we present a hybrid recommendation system to help readers decide which book to read next. We study book and author recommendations in a hybrid recommendation setting and test our algorithm on the LitRec data set. Our hybrid method combines two item-based collaborative filtering algorithms to predict books and authors that the user will like. Author predictions are expanded into a booklist that is subsequently aggregated with the former book predictions. Finally, the resulting booklist is used to yield the top-n book recommendations. By means of various experiments, we demonstrate that author recommendation can improve overall book recommendation.

#index 1787107
#* Introducing high performance computing in digital library processing workflows
#@ Bill Barth;Maria Esteva;Jon Gibson;Ladd Hanson;Christopher Jordan
#t 2012
#c 14
#! As larger collections need to be processed for digital library projects, libraries have to adopt technologies of scale. We present a case that involved creating image derivatives using High Performance Computing (HPC) resources. This experience opens up possibilities to conduct various processing tasks effectively and in reasonable time frames. Most importantly, it enables library IT staff access to cyberinfrastructure that can address the computing challenges of large-scale digital library projects.

#index 1787108
#* Investigating user perceptions of engagement and information quality in mobile human computation games
#@ Dion Goh;Khasfariyati Razikin;Chei Sian Lee;Alton Chua
#t 2012
#c 14
#% 1048264
#% 1183081
#% 1203772
#% 1432763
#% 1591666
#! We investigate user perceptions of engagement and information quality of a mobile human computation game (HCG) by comparing it against a non-game-based application. Results suggest that the mobile HCG enabled participants to occupy their leisure time but the information contributed was perceived to be not as relevant. Implications of this study are discussed.

#index 1787109
#* Lessons learned from developing and evaluating a comprehensive digital library for engineering education
#@ Yunlu Zhang;Alice M. Agogino;Shijun Li
#t 2012
#c 14
#% 1573589
#! Educating the engineering education community in today's digital world requires straightforward yet flexible access to high-quality educational resources. The Teach Engineering and NEEDS (National Engineering Education Delivery System) digital libraries collaborated in 2005 to create and steward the K-Gray Engineering Pathway (EP), a premier portal to comprehensive engineering and computing education resources within the greater National Science Digital Library (NSDL). We collaborated to design navigation, implement features, and find imagery that could effectively address both K-12 and higher education audiences. A system was designed to serve both target audiences, including an expanded simple search on every page to include grade/audience level search fields. This search, on all main pages, also includes a choice of learning resource type and a link to the Advanced Search with expanded search fields. EP tailored many features such as community pages and cataloging to be distinguishable by K-12 versus higher education users. Evaluation studies show that our current strength is a consistent interface with strong usability features. In this paper, we a provide retrospective and summarize our lessons learned and evaluation results, along with our directions for future research and development.

#index 1787110
#* Meta-line: lineage information for improved metadata quality
#@ Sascha Tönnies;Benjamin Köhncke;Wolf-Tilo Balke
#t 2012
#c 14
#% 632040
#% 765161
#% 875015
#% 1153449
#! Controlled content quality also in terms of indexing is one of the major advantages of using digital libraries in contrast to general Web sources or Web search engines. However, considering today's information flood the mostly manual effort in acquiring new sources and creating suitable (semantic) metadata for content indexing and retrieval is already prohibitive. A recent solution is given by automatic generation of metadata, where various methods currently become more widespread. But in this case neglecting quality assurance is even more problematic, because heuristic generation often fails and the resulting low-quality metadata will directly diminish the quality of service that a digital library provides. To address this problem, we propose a metadata quality model to determine the overall quality of a metadata set and validate individual requirements imposed on that metadata set. Furthermore, lineage information is provided to trace the quality evolution of a metadata set.

#index 1787111
#* Multi-view of the ACM classification system
#@ Xia Lin;Mi Zhang;Haozhen Zhao;Jan Buzydlowski
#t 2012
#c 14
#% 106409
#! The ACM Computing Classification System (CCS) is a hierarchical classification system used to index and classify all the published literature of ACM. They reflect major areas and topics of the computing field and they often serve as an overview and navigational guide to the field. However, similar to all the traditional classification systems and subject domain thesauri, such an overview and navigational guide is static and sketchy, representing only a top-down representation of a domain. In this paper, we look into a 10-year period of ACM literature and examine how the CCS terms are actually used in the ACM digital library and how the patterns of term usages show different term relationships than those defined in the CCS. By comparing the dynamic statistical patterns of term usage with the static hierarchical structures of the terms, we show that much can be gained by integrating both of them into an interactive interface to provide better overview maps and navigational guides to the domain of computing.

#index 1787112
#* National digital newspaper program: a case study in sharing, linking, and using data
#@ Nathan Yarasavage;Robin Butterhof;Christopher Ehrman
#t 2012
#c 14
#% 809457
#! This poster presents a case study describing how the National Digital Newspaper Program's (NDNP) metadata specification and public website, Chronicling America, have been designed to promote a wide range of data sharing. Through use of the website's extensive application programming interface (API) and open-source software counterpart, several institutions are benefiting from the publicly-funded program's data.

#index 1787113
#* Responsibility for research data quality in open access: a slovenian case
#@ Janez Stebe
#t 2012
#c 14
#! In the framework of a project aiming to realize a strategy of open research data access in Slovenia in accordance with OECD principles, we conducted a series of interviews with different target audiences in order to assess the initial conditions in the area of data handling. The data creators and data services expressed a high level of awareness about data quality issues, especially in relation to good publication potential. Barriers to ensuring the greater accessibility of data in the future include the little recognition and reputation for doing the related extra work involved in preparing data and documentation, the need for financial rewards for such additional work, and the undeveloped culture of data exchange in general. The motivation to provide open access to such data will involve a combination of requirements prescribed for data delivery, and the provision of support services and financial rewards, in particular changing the views held by the professional scientific community about the benefits of open data for research activities.

#index 1787114
#* Scientific cyberlearning resources referential metadata creation via information retrieval
#@ Xiaozhong Liu;Han Jia
#t 2012
#c 14
#% 268078
#% 330769
#% 340936
#% 1111833
#% 1586576
#! The goal of this research is to describe an innovative method of creating scientific referential metadata for a cyberinfrastructure-enabled learning environment to enhance student and scholar learning experiences. By using information retrieval and meta-search approaches, different types of referential metadata, such as related Wikipedia Pages, Datasets, Source Code, Video Lectures, Presentation Slides, and (online) Tutorials, for an assortment of publications and scientific topics will be automatically retrieved, associated, and ranked.

#index 1787115
#* Sheer curation for experimental data and provenance
#@ Mark Hedges;Tobias Blanke
#t 2012
#c 14
#% 1564179

#index 1787116
#* Web2MARC: sharing and using STEM digital content in school libraries
#@ Marcia A. Mardis;Casey McLaughlin;Grant Gingell
#t 2012
#c 14
#! Digital content can benefit K-12 science, technology, engineering, and mathematics (STEM) teaching and learning, but it is not widely integrated. Many school librarians are not sure how to build upon their expertise to share and link digital learning resources in their roles as resource providers and instructional collaborators. This poster will present Web2MARC, a web-based application for integration of digital resources into school library collections. Further work on the state of school library STEM collections, survey analysis, and Web2MARC is slated to be complete in 2013.

#index 1787117
#* Social network-based recommendation: a graph random walk kernel approach
#@ Xin Li;Xin Su;Mengyue Wang
#t 2012
#c 14
#% 464615
#% 975021
#% 1215465
#% 1287244
#! Traditional recommender system research often explores customer, product, and transaction information in providing recommendations. Social relationships in social networks are related to individuals' preferences. This study investigates the product recommendation problem based solely on people's social network information. Taking a kernel-based approach, we capture consumer social influence similarities into a graph random walk kernel and build SVR models to predict consumer opinions. In experiments on a dataset from a movie review website, our proposed model outperforms trust-based models and state-of-the-art graph kernels.

#index 1787118
#* The David Livingstone spectral imaging project
#@ Stephen Davison;Adrian S. Wisnicki;Elizabeth McAulay
#t 2012
#c 14
#! The David Livingstone Spectral Imaging Project is a collaborative, international effort to use spectral imaging technology and digital publishing to make available a series of faded, illegible texts produced by the famous Victorian explorer when he was stranded without ink or writing paper in Central Africa. The poster describes existing achievements of the project, plans for an innovative portal providing access to images and data, and preservation challenges.

#index 1787119
#* The logical form of the proposition expressed by a metadata record
#@ Karen M. Wickett;Allen H. Renear
#t 2012
#c 14
#! Metadata records are a ubiquitous and foundational feature of contemporary information systems. However, while their simple surface structure may lead us to think that the semantics of a metadata record is unproblematic and easily discerned, our analysis of an example record suggests otherwise. We show three possibilities for the logical form of the proposition expressed by a metadata record. All three are substantially different in the first order constructs utilized, and no two can be recognized as equivalent for the purposes of information organization. The semantics of the common metadata record is elusive. The main source of this problem appears to be the identifier attribute. Although identifier attributes have the syntactic appearance of any other attribute in the metadata vocabulary, this uniformity conceals their potential for assuming a distinctive semantic role, and one which appears to cross the traditional object language / metalanguage boundary, suggesting that translation of colloquial metadata records into logic-based knowledge representations does not take place entirely at a first-order level.

#index 1787120
#* Toponym extraction and resolution in a digital library
#@ James S. Creel;Katherine Weimer
#t 2012
#c 14
#! Geospatial metadata enable rich and varied interfaces to digital collections, and present unique challenges and affordances for automated extraction. We describe our findings developing and utilizing a geoparser for the Texas A&M University Libraries' Institutional Repository.

#index 1787121
#* Pinterest: social collecting for #linking #using #sharing
#@ Michael Zarro;Catherine Hall
#t 2012
#c 14
#% 881054
#% 1588371

#index 1787122
#* YADDA2: assemble your own digital library application from LEGO bricks
#@ Wojtek Sylwestrzak;Tomasz Rosiek;Lukasz Bolikowski
#t 2012
#c 14
#% 301247
#% 859913
#% 869573
#% 1065281
#% 1107055
#% 1143795
#% 1434731
#% 1682036
#! YADDA2 is an open software platform which facilitates creation of digital library applications. It consists of versatile building blocks providing, among others: storage, relational and full-text indexing, process management, and asynchronous communication. Its loosely-coupled service-oriented architecture enables deployment of highly-scalable, distributed systems.

#index 1787123
#* An integrated participatory platform for human evaluation of machine translation
#@ Jiangping Chen;Olajumoke Azogu;Wenqian Zhao
#t 2012
#c 14
#% 1480000
#! We describe the functions of HeMT, a multilingual participatory platform for Human Evaluation of Machine Translation. HeMT is used by three types of users including translators, evaluators, and reviewers. It consists of six major modules: User Management, Manual Translation, User Training, Evaluation, Result Visualization, and Multilingual Lexicon Management. HeMT can be used by Digital Libraries and Machine Translation communities for conducting manual translation, machine translation evaluation, and computer-assisted translation tasks.

#index 1787124
#* 'Erasmus': an organization- and user-centered dublin core metadata tool
#@ Michael Khoo;Craig M. MacDonald;Joon Park
#t 2012
#c 14
#% 268067
#% 508408
#% 571509
#% 1069028
#% 1434164
#% 1611939
#! Digital library interoperability is supported by good quality metadata. The design of metadata creation and management tools is therefore an important component of overall digital library design. A number of factors affect metadata tool usability, including task complexity, interface usability, and organizational context of use. These issues are being addressed in the user-centered design of a metadata tool for the Internet Public Library.

#index 1787125
#* Faceted search for heterogeneous digital collections
#@ Hui Zhang;Mike Durbin;Jon Dunn;Will Cowan;Brian Wheeler
#t 2012
#c 14
#! The idea of faceted search has received growing attentions in the digital library field for its potential of improving user satisfaction by combing the query and browse strategies interactively. Furthermore, with the trend of using digital repositories as the central infrastructure for curation and preservation, there is a demand for a single search interface providing public access to all the diversified content stored in the repositories. In this demo, we present Digital Collections Search, a system that is designed to assist users who are unfamiliar with the subject of their information needs locating relevant items as well exploring related but unknown collections in the repository.

#index 1787126
#* NLM video search
#@ John P. Doyle;Doron Shalvi;Edward C. Luczak
#t 2012
#c 14
#! In this demo, we will demonstrate usage of NLM Video Search, open-source software which facilitates the dissemination of video content by combining traditional web video playback controls with on-demand seeking using text selected from a corresponding transcript (see Figure 1). NLM Video Search has been implemented in NLM's Fedora-based digital repository, which provides preservation and access to a growing number of rare, historical films and digitized texts.

#index 1787127
#* Research discovery through linked open data
#@ Paul Albert;Kristi L. Holmes;Katy Borner;MIke Conlon
#t 2012
#c 14
#! VIVO is an open source semantic web platform that contains information about scholars and their interests and activities. This demonstration will highlight the platform and ontology, data sources, features of the software and the ways that VIVO data can be leveraged for a variety of purposes within and beyond an institution to facilitate collaboration and research discovery.

#index 1787128
#* Structured audio content analysis and metadata in a digital library
#@ David Bainbridge;John Stephen Downie;Andreas F. Ehmann
#t 2012
#c 14
#! This work illustrates how audio content analysis of music and manually assigned structural temporal metadata can be used to form a digital library designed for musicological exploration. In addition to text-based searching and browsing, the document view is enriched with an interactive structured audio time-line that shows ground-truth data representing the logical segments to the song, and a version that was automatically generated for comparison. A self-similarity "heat" map is also displayed, and is interactive. Clicking within the map at a co-ordinate (x,y) results in the audio being played simultaneous at time offset x and y, panned left and right, respectively, to make it easier for the listener to separate out the differences. The musicologist can also initiate an audio content based query starting at any point in the song. This produces a ranked result set which can be further studied through their respective document views. Alternatively they can perform a musical structure search (for example, for songs that contain the structure b, b, c, b, c).

#index 1787129
#* The profiles in science digital library: behind the scenes
#@ Marie E. Gallagher;Christie Moffatt
#t 2012
#c 14
#% 332739
#% 584910
#! This demonstration shows the Profiles in Science® digital library. Profiles in Science contains digitized selections from the personal manuscript collections of prominent biomedical researchers, medical practitioners, and those fostering science and health. The Profiles in Science Web site is the delivery mechanism for content derived from the digital library system. The system is designed according to our basic principles for digital library development [1]. The digital library includes the rules and software used for digitizing items, creating and editing database records and performing quality control as well as serving the digital content to the public. Among the types of data managed by the digital library are detailed item-level, collection-level and cross-collection metadata, digitized photographs, papers, audio clips, movies, born-digital electronic files, optical character recognized (OCR) text, and annotations (see Figure 1). The digital library also tracks the status of each item, including digitization quality, sensitivity of content, and copyright. Only items satisfying all required criteria are released to the public through the World Wide Web. External factors have influenced all aspects of the digital library's infrastructure.

#index 1787130
#* The ResultsSpace collaborative search environment
#@ Robert Capra;Jaime Arguello;Annie Chen;Katie Hawthorne;Gary Marchionini;Lee Shaw
#t 2012
#c 14
#% 998795
#% 1047490
#% 1074090
#% 1183271
#% 1384196
#% 1441676
#% 1480247
#% 1642353
#! The ResultsSpace Collaborative Search Environment is a tool to support asynchronous collaborative information retrieval among a small group of collaborators. It is designed to promote awareness of collaborators' searches and the documents they have rated. Awareness is supported through several mechanisms: an area that shows a history of queries, a summary display of collaborators' ratings next to each search result, and changes in the visual salience of search results based on their aggregate rating from all collaborators. Faceted controls allow users to filter results based on specific ratings (relevant, not relevant, and maybe) and on specific collaborator(s) who have rated an item. We describe features of the system, how they are implemented, and give insights into the design rationale.

#index 1787131
#* WARCreate: create wayback-consumable WARC files from any webpage
#@ Mat Kelly;Michele C. Weigle
#t 2012
#c 14
#! The Internet Archive's Wayback Machine is the most common way that typical users interact with web archives. The Internet Archive uses the Heritrix web crawler to transform pages on the publicly available web into Web ARChive (WARC) files, which can then be accessed using the Wayback Machine. Because Heritrix can only access the publicly available web, many personal pages (e.g. password-protected pages, social media pages) cannot be easily archived into the standard WARC format. We have created a Google Chrome extension, WARCreate, that allows a user to create a WARC file from any webpage. Using this tool, content that might have been otherwise lost in time can be archived in a standard format by any user. This tool provides a way for casual users to easily create archives of personal online content. This is one of the first steps in resolving issues of "long term storage, maintenance, and access of personal digital assets that have emotional, intellectual, and historical value to individuals".

#index 1974517
#* Proceedings of the 13th ACM/IEEE-CS joint conference on Digital libraries
#@ J. Stephen Downie;Robert H. McDonald;Timothy W. Cole;Robert Sanderson;Frank Shipman
#t 2013
#c 14
#! Welcome to the 13th ACM/IEEE Joint Conference on Digital Libraries -- JCDL 2013. It has been our pleasure to work with the Program Committee and with our colleagues on the Organizing Committee to build a program for this year's conference consistent with JCDL's long-standing reputation for high quality. JCDL remains the premier international forum for exploring research, practice, and social issues in digital libraries. The Program Committee has selected a diverse array of papers, panels, posters and demonstrations that illustrate both the breadth and depth of ongoing digital library scholarship. Some themes explored in this year's 13 sessions of full and short papers are familiar from JCDLs of the recent past (e.g., Digital Preservation, Metadata, Name Entity Extraction) and some themes are new this year, reflecting emerging and shifting foci of interest (e.g., Information Ranking, Information Clustering, Specialist DLs, Historical DLs). Presentations of the papers included in this proceedings volume will be complemented by 36 posters and 10 demonstrations showcasing a broad range of innovative research and practical digital library applications. The extended abstracts for these Posters and Demonstrations are also included in this proceeding volume. This year's Poster & Demonstration Reception on the second evening of the main conference (Wednesday) will be preceded the ever-popular 'Minute-Madness' session. As in past years, reception attendees will vote to determine the winner of the Best Poster Award. Additionally this year, the Vannevar Bush Best Paper Award and the Best Student Paper Award will be presented at the Poster Reception. This year's program also includes three panel sessions. Wednesday's panel, chaired by Dan Cohen (Digital Public Library of America), will feature JCDL 2013 keynote speakers Jill Cousins, Cliff Lynch and David De Roure. Distinguished panels also have been assembled to discuss Managing Big Data and Big Metadata: Contributions from Digital Libraries (Tuesday) and to tackle the issues surrounding Volume, Variety, and Velocity: Big Data Collection and Curation in Cultural Heritage Repositories (Thursday). Of course the essential pre-requisite for a conference of this quality and breadth is high quality submissions that span the full range of digital library scholarship. Again this year JCDL received a wealth of quality submissions. Each paper was read and rated by 3 reviewers. Each paper was then read by 2 additional meta-reviewers who reconciled first level reviews and formulated a recommendation for the Program Committee as a whole. During a day and a half in-person meeting in Chicago, the Program Committee made final selections. For this year's conference 28 of 95 full paper submissions (29%) and 22 of 72 short paper submissions (31%) were accepted. We wish to recognize the accomplishment of accepted paper authors and to acknowledge the many others who submitted strong paper proposals. An additional 13 papers submitted, a mix of both full and short, were converted to and accepted as Posters or Demonstrations on the advice of the Program Committee. Finally, we wish to thank Program Committee members for again meeting the challenge of reviewing a large number of papers both quickly and well; this conference would not be possible without their dedication and generous contribution of effort.

#index 1974518
#* Non-linear book manifolds: learning from associations the dynamic geometry of digital libraries
#@ Richard Nock;Frank Nielsen;Eric Briys
#t 2013
#c 14
#% 458379
#% 481758
#% 729418
#% 760837
#% 769910
#% 874455
#% 881478
#% 1108890
#% 1227637
#% 1464823
#% 1739441
#% 1775225
#% 1974519
#! Mainstream approaches in the design of virtual libraries basically exploit the same ambient space as their physical twins. Our paper is an attempt to rather capture automatically the actual space on which the books live, and learn the virtual library as a non-linear book manifold. This tackles tantalizing questions, chief among which whether modeling should be static and book focused (e.g.using bag of words encoding) or dynamic and user focused (e.g. relying on what we define as a bag of readers encoding). Experiments on a real-world digital library display that the latter encoding is a serious challenger to the former. Our results also show that the geometric layers of the manifold learned bring sizeable advantages for retrieval and visualization purposes. For example, the topological layer of the manifold allows to craft Manifold association rules; experiments display that they bring dramatic improvements over conventional association rules built from the discrete topology of book sets.Improvements embrace each of the following major standpoints on association rule mining: computational, support, confidence, lift, and leverage standpoint.

#index 1974519
#* Information-theoretic term weighting schemes for document clustering
#@ Weimao Ke
#t 2013
#c 14
#% 227819
#% 266215
#% 296738
#% 309106
#% 411760
#% 413610
#% 465754
#% 723542
#% 763708
#% 818205
#% 879615
#% 926881
#% 969377
#% 991230
#% 1077150
#% 1343447
#% 1450858
#% 1598421
#! We propose a new theory to quantify information in probability distributions and derive a new document representation model for text clustering. By extending Shannon entropy to accommodate a non-linear relation between information and uncertainty, the proposed Least Information theory (LIT) provides insight into how terms can be weighted based on their probability distributions in documents vs. in the collection. We derive two basic quantities in the document clustering context: 1) LI Binary (LIB) which quantifies information due to the observation of a term's (binary) occurrence in a document; and 2) LI Frequency (LIF) which measures information for the observation of a randomly picked term from the document. Both quantities are computed given term distributions in the document collection as prior knowledge and can be used separately or combined to represent documents for text clustering. Experiments on four benchmark text collections demonstrate strong performances of the proposed methods compared to classic TF*IDF. Particularly, the LIB*LIF weighting scheme, which combines LIB and LIF, consistently outperforms TF*IDF in terms of multiple evaluation metrics. The least information measure has a potentially broad range of applications beyond text clustering.

#index 1974520
#* WikiMirs: a mathematical information retrieval system for wikipedia
#@ Xuan Hu;Liangcai Gao;Xiaoyan Lin;Zhi Tang;Xiaofan Lin;Josef B. Baker
#t 2013
#c 14
#% 453357
#% 1065265
#% 1099068
#% 1253863
#% 1616123
#% 1680510
#% 1716011
#% 1728015
#% 1918407
#! Mathematical formulae in structural formats such as MathML and LaTeX are becoming increasingly available. Moreover, repositories and websites, including ArXiv and Wikipedia, and growing numbers of digital libraries use these structural formats to present mathematical formulae. This presents an important new and challenging area of research, namely Mathematical Information Retrieval (MIR). In this paper, we propose WikiMirs, a tool to facilitate mathematical formula retrieval in Wikipedia. WikiMirs is aimed at searching for similar mathematical formulae based upon both textual and spatial similarities, using a new indexing and matching model developed for layout structures. A hierarchical generalization technique is proposed to generate sub-trees from presentation trees of mathematical formulae, and similarity is calculated based upon matching at different levels of these trees. Experimental results show that WikiMirs can efficiently support sub-structure matching and similarity matching of mathematical formulae. Moreover, WikiMirs obtains both higher accuracy and better ranked results over Wikipedia in comparison to Wikipedia Search and Egomath. We conclude that WikiMirs provides a new, alternative, and hopefully better service for users to search mathematical expressions within Wikipedia.

#index 1974521
#* Comparative appraisal: systematic assessment of expressive qualities
#@ Melanie Feinberg
#t 2013
#c 14
#% 85708
#% 793421
#% 798018
#% 834186
#% 943606
#% 1002203
#% 1338762
#% 1384237
#% 1384327
#% 1384348
#% 1624263
#% 1647562
#% 1787063
#% 1846465
#% 1853559
#% 1853569
#% 1853575
#% 1853599
#! Clifford Lynch describes the value of digital libraries as adding interpretive layers to collections of cultural heritage materials. However, standard forms of evaluation, which focus on the degree to which a system solves problems, are insufficient assessments of the expressive qualities that distinguish such interpretive content. This paper describes a form of comparative, structured appraisal that supplements the existing repertoire of assessment techniques. Comparative appraisal uses a situationally defined set of procedures to be followed by multiple assessors in examining a group of artifacts. While this approach aims for a goal of systematic comparison based on selected dimensions, it is grounded in the recognition that expressive qualities are not conventionally measurable and that absolute agreement between assessors is neither possible nor desirable. The conceptual basis for this comparative method is drawn from the literature of writing assessment.

#index 1974522
#* Exploiting potential citation papers in scholarly paper recommendation
#@ Kazunari Sugiyama;Min-Yen Kan
#t 2013
#c 14
#% 280852
#% 309095
#% 760853
#% 961613
#% 987287
#% 1130858
#% 1213432
#% 1251672
#% 1292577
#% 1399975
#% 1434124
#% 1450991
#% 1482239
#% 1482257
#% 1482271
#% 1536580
#% 1588390
#% 1605962
#% 1605963
#! To help generate relevant suggestions for researchers, recommendation systems have started to leverage the latent interests in the publication profiles of the researchers themselves. While using such a publication citation network has been shown to enhance performance, the network is often sparse, making recommendation difficult. To alleviate this sparsity, we identify "potential citation papers" through the use of collaborative filtering. Also, as different logical sections of a paper have different significance, as a secondary contribution, we investigate which sections of papers can be leveraged to represent papers effectively. On a scholarly paper recommendation dataset, we show that recommendation accuracy significantly outperforms state-of-the-art recommendation baselines as measured by nDCG and MRR, when we discover potential citation papers using imputed similarities via collaborative filtering and represent candidate papers using both the full text and assigning more weight to the conclusion sections.

#index 1974523
#* User-centered approach in creating a metadata schema for video games and interactive media
#@ Jin Ha Lee;Hyerim Cho;Violet Fox;Andrew Perti
#t 2013
#c 14
#% 387027
#% 1432791
#% 1498534
#% 1615410
#% 1914925
#% 1924149
#% 1984863
#! Video games and interactive media are increasingly becoming important part of our culture and everyday life, and subsequently, of archival and digital library collections. However, existing organizational systems often use vague or inconsistent terms to describe video games or attempt to use schemas designed for textual bibliographic resources. Our research aims to create a standardized metadata schema and encoding scheme that provides an intelligent and comprehensive way to represent video games. We conducted interviews with 24 gamers, focusing on their video game-related information needs and seeking behaviors. We also performed a domain analysis of current organizational systems used in catalog records and popular game websites, evaluating metadata elements used to describe games. With these results in mind, we created a list of elements which form a metadata schema for describing video games, with both a core set of 16 elements and an extended set of 46 elements providing more flexibility in expressing the nature of a game.

#index 1974524
#* Extracting and matching authors and affiliations in scholarly documents
#@ Huy Hoang Nhat Do;Muthu Kumar Chandrasekaran;Philip S. Cho;Min Yen Kan
#t 2013
#c 14
#% 464434
#% 614036
#% 967276
#% 1213417
#% 1475144
#% 1483764
#% 1558464
#% 1588348
#% 1596020
#% 1685572
#% 1692328
#% 1787076
#% 1950480
#! We introduce Enlil, an information extraction system that discovers the institutional affiliations of authors in scholarly papers. Enlil consists of two steps: one that first identifies authors and affiliations using a conditional random field; and a second support vector machine that connects authors to their affiliations. We benchmark Enlil in three separate experiments drawn from three different sources: the ACL Anthology Corpus, the ACM Digital Library, and a set of cross-disciplinary scientific journal articles acquired by querying Google Scholar. Against a state-of-the-art production baseline, Enlil reports a statistically significant improvement in F_1 of nearly 10% (p 90%) and automatically-acquired input (F_1 80%). We have deployed Enlil in a case study involving Asian genomics research publication patterns to understand how government sponsored collaborative links evolve. Enlil has enabled our team to construct and validate new metrics to quantify the facilitation of research as opposed to direct publication.

#index 1974525
#* LSH-based large scale chinese calligraphic character recognition
#@ Yuan Lin;Jiangqin Wu;Pengcheng Gao;Yang Xia;Tianjiao Mao
#t 2013
#c 14
#% 219979
#% 249321
#% 328321
#% 397637
#% 424085
#% 479973
#% 482658
#% 632029
#% 710231
#% 724164
#% 734867
#% 738487
#% 762054
#% 898309
#% 986037
#% 1171209
#% 1292851
#! Chinese calligraphy is the art of handwriting and is an important part of Chinese traditional culture. But due to the complexity of shape and styles of calligraphic characters, it is difficult for com-mon people to recognize them. So it would be great if a tool is provided to help users to recognize the unknown calligraphic characters. But the well-known OCR (Optical Character Recogni-tion) technology can hardly help people to recognize the unknown characters because of their deformation and complexity. Numerous collections of historical Chinese calligraphic works are digitized and stored in CADAL (China Academic Digital Associate Library) calligraphic system [1], and a huge database CCD (Calligraphic Character Dictionary) is built, which contains character images labeled with semantic meaning. In this paper, a LSH-based large scale Chinese calligraphic character recognition method is proposed basing on CCD. In our method, GIST descriptor is used to represent the global features of the calligraphic character images, LSH (Locality-sensitive hashing) is used to search CCD to find the similar character images to the recognized calligraphic character image. The recognition is based on the semantic probability which is computed according to the ranks of retrieved images and their distances to the recognized image in the Gist feature space. Our experiments show that our method is effective and efficient for recognizing Chinese calligraphic character image.

#index 1974526
#* Visual-interactive querying for multivariate research data repositories using bag-of-words
#@ Maximilian Scherer;Tatiana von Landesberger;Tobias Schreck
#t 2013
#c 14
#% 46803
#% 280819
#% 430101
#% 619859
#% 643518
#% 722904
#% 724320
#% 760805
#% 840455
#% 844310
#% 860956
#% 996168
#% 1127609
#% 1185582
#% 1279761
#% 1354888
#% 1383023
#% 1495122
#% 1588399
#% 1624253
#% 1702283
#% 1744885
#% 1787053
#% 1861495
#% 1910985
#% 1924120
#% 1924140
#% 1924150
#% 1924160
#! Large amounts of multivariate data are collected in different areas of scientific research and industrial production. These data are collected, archived and made publicly available by research data repositories. In addition to meta-data based access, content-based approaches are highly desirable to effectively retrieve, discover and analyze data sets of interest. Several such methods, that allow users to search for particular curve progressions, have been proposed. However, a major challenge when providing content-based access -- interactive feedback during query formulation -- has not received much attention yet. This is important because it can substantially improve the user's search effectiveness. In this paper, we present a novel interactive feedback approach for content-based access to multivariate research data. Thereby, we enable query modalities that were not available for multivariate data before. We provide instant search results and highlight query patterns in the result set. Real-time search suggestions give an overview of important patterns to look for in the data repository. For this purpose, we develop a bag-of-words index for multivariate data as the back-end of our approach. We apply our method to a large repository of multivariate data from the climate research domain. We describe a use-case for the discovery of interesting patterns in maritime climate research using our new visual-interactive query tools.

#index 1974527
#* Automatic tag recommendation for metadata annotation using probabilistic topic modeling
#@ Suppawong Tuarob;Line C. Pouchard;C. Lee Giles
#t 2013
#c 14
#% 281480
#% 722904
#% 766409
#% 869608
#% 874505
#% 967299
#% 1023420
#% 1074115
#% 1074117
#% 1077150
#% 1176853
#% 1190091
#% 1287227
#% 1417055
#% 1451206
#% 1481571
#% 1624266
#% 1711869
#% 1919842
#! The increase of the complexity and advancement in ecological and environmental sciences encourages scientists across the world to collect data from multiple places, times, and thematic scales to verify their hypotheses. Accumulated over time, such data not only increases in amount, but also in the diversity of the data sources spread around the world. This poses a huge challenge for scientists who have to manually search for information. To alleviate such problems, ONEMercury has recently been implemented as part of the DataONE project to serve as a portal for accessing environmental and observational data across the globe. ONEMercury harvests metadata from the data hosted by multiple repositories and makes it searchable. However, harvested metadata records sometimes are poorly annotated or lacking meaningful keywords, which could affect effective retrieval. Here, we develop algorithms for automatic annotation of metadata. We transform the problem into a tag recommendation problem with a controlled tag library, and propose two variants of an algorithm for recommending tags. Our experiments on four datasets of environmental science metadata records not only show great promises on the performance of our method, but also shed light on the different natures of the datasets.

#index 1974528
#* Ranking experts using author-document-topic graphs
#@ Sujatha Das Gollapalli;Prasenjit Mitra;C. Lee Giles
#t 2013
#c 14
#% 280819
#% 324129
#% 643024
#% 722904
#% 788094
#% 879570
#% 907525
#% 918685
#% 987261
#% 987345
#% 1077150
#% 1083734
#% 1130922
#% 1176887
#% 1176930
#% 1195845
#% 1214668
#% 1275180
#% 1399975
#% 1432785
#% 1588381
#% 1588383
#% 1631006
#! Expert search or recommendation involves the retrieval of people (experts) in response to a query and on occasion, a given set of constraints. In this paper, we address expert recommendation in academic domains that are different from web and intranet environments studied in TREC. We propose and study graph-based models for expertise retrieval with the objective of enabling search using either a topic (e.g. "Information Extraction") or a name (e.g. "Bruce Croft"). We show that graph-based ranking schemes despite being "generic" perform on par with expert ranking models specific to topic-based and name-based querying.

#index 1974529
#* Automatic extraction of core learning goals and generation of pedagogical sequences through a collection of digital library resources
#@ Ifeyinwa Okoye;Tamara Sumner;Steven Bethard
#t 2013
#c 14
#% 424010
#% 641789
#% 947241
#% 967315
#% 1062340
#% 1251608
#% 1301004
#% 1467459
#% 1490019
#% 1548982
#% 1656547
#% 1665467
#% 1710311
#% 1787040
#! A key challenge facing educational technology researchers is how to provide structure and guidance when learners use unstructured and open tools such as digital libraries for their own learning. This work attempts to use computational methods to identify that structure in a domain independent way and support learners as they navigate and interpret the information they find. This article highlights a computational methodology for generating a pedagogical sequence through core learning goals extracted from a collection of resources which in this case, are resources from the Digital Library for Earth System Education (DLESE). This article describes how we use the technique of multi-document summarization to extract the core learning goals from the digital library resources and how we create a supervised classifier that performs a pair-wise classification of the core learning goals; the judgments from these classifications are used to automatically generate pedagogical sequences. Results show that we can extract good core learning goals and make pair-wise classifications that are up to 76% similar to the pair-wise classifications generated from pedagogical sequences created by two science education experts. Thus we can dynamically generate pedagogically meaningful learning paths through digital library resources.

#index 1974530
#* A relevance feedback approach for the author name disambiguation problem
#@ Thiago A. Godoi;Ricardo da S. Torres;Ariadne M.B.R. Carvalho;Marcos A. Gonçalves;Anderson A. Ferreira;Weiguo Fan;Edward A. Fox
#t 2013
#c 14
#% 341704
#% 375017
#% 512125
#% 760866
#% 809459
#% 809460
#% 810635
#% 915273
#% 937552
#% 967295
#% 987242
#% 1126935
#% 1133176
#% 1202135
#% 1211086
#% 1213413
#% 1213414
#% 1277368
#% 1375808
#% 1418196
#% 1434125
#% 1467901
#% 1483217
#% 1498542
#% 1564417
#% 1614800
#% 1618548
#% 1625929
#% 1663664
#% 1688430
#% 1701800
#% 1755323
#% 1777687
#% 1787059
#% 1787748
#% 1880313
#! This paper presents a new name disambiguation method that exploits user feedback on ambiguous references across iterations. An unsupervised step is used to define pure training samples, and a hybrid supervised step is employed to learn a classification model for assigning references to authors. Our classification scheme combines the Optimum-Path Forest (OPF) classifier with complex reference similarity functions generated by a Genetic Programming framework. Experiments demonstrate that the proposed method yields better results than state-of-the-art disambiguation methods on two traditional datasets.

#index 1974531
#* A distributed archival network for process-oriented autonomic long-term digital preservation
#@ Ivan Subotic;Lukas Rosenthaler;Heiko Schuldt
#t 2013
#c 14
#% 614040
#% 1065290
#% 1139129
#% 1467737
#% 1495099
#% 1587657
#% 1763874
#% 1901428
#! The reliable and consistent long-term preservation of digital content and metadata is becoming increasingly important -- even though the storage media used are potentially subject to failures, or the data formats may become obsolete over time. A common approach is to replicate data across several sites to increase their availability. Nevertheless, network, software, or hardware failures as well as the evolution of data formats have to be coped with in a timely and, ideally, an autonomous way, without intervention of an administrator. In this paper we present DISTARNET, a distributed, autonomous long-term digital preservation system. Essentially, DISTARNET exploits dedicated processes to ensure the integrity and consistency of data with a given replication degree. At the data level, DISTARNET supports complex data objects, the management of collections, annotations, and arbitrary links between digital objects. At process level, dynamic replication management, consistency checking, and automated recovery of the archived digital objects is provided utilizing autonomic behavior governed by preservation policies without any centralized component. We present the concepts and implementation of the distributed DISTARNET preservation approach. Most importantly, we provide details of the qualitative and quantitative evaluation of the DISTARNET system. The former addresses the effectiveness of the internal preservation processes while the latter evaluates DISTARNET's performance regarding the overall archiving storage capacity and scalability.

#index 1974532
#* Identification of useful user comments in social media: a case study on flickr commons
#@ Elaheh Momeni;Ke Tao;Bernhard Haslhofer;Geert-Jan Houben
#t 2013
#c 14
#% 722904
#% 939897
#% 956515
#% 990210
#% 1035587
#% 1055704
#% 1074111
#% 1131843
#% 1183138
#% 1183152
#% 1190069
#% 1261574
#% 1400002
#% 1434163
#% 1560422
#% 1588354
#% 1693915
#% 1765771
#% 1972130
#! Cultural institutions are increasingly opening up their repositories and contribute digital objects to social media platforms such as Flickr. In return they often receive user comments containing information that could be incorporated in their catalog records. Since judging the usefulness of a large number of user comments is a labor-intensive task, our aim is to provide automated support for filtering potentially useful social media comments on digital objects. In this paper, we discuss the notion of usefulness in the context of social media comments and compare it from end-users as well as expertusers perspectives. Then we present a machine-learning approach to automatically classify comments according to their usefulness. Our approach makes use of syntactic and semantic comment features and also considers user context. We present the results of an experiment we did on user comments received in six different Flickr Commons collections. They show that a few relatively straightforward features can be used to infer useful comments with up to 89% accuracy.

#index 1974533
#* The challenges of digging data: a study of context in archaeological data reuse
#@ Ixchel Faniel;Eric Kansa;Sarah Whitcher Kansa;Julianna Barrera-Gomez;Elizabeth Yakel
#t 2013
#c 14
#% 731213
#% 1055319
#% 1107062
#% 1483595
#% 1914890
#! Field archaeology only recently developed centralized systems for data curation, management, and reuse. Data documentation guidelines, standards, and ontologies have yet to see wide adoption in this discipline. Moreover, repository practices have focused on supporting data collection, deposit, discovery, and access more than data reuse. In this paper we examine the needs of archaeological data reusers, particularly the context they need to understand, verify, and trust data others collect during field studies. We then apply our findings to the existing work on standards development. We find that archaeologists place the most importance on data collection procedures, but the reputation and scholarly affiliation of the archaeologists who conducted the original field studies, the wording and structure of the documentation created during field work, and the repository where the data are housed also inform reuse. While guidelines, standards, and ontologies address some aspects of the context data reusers need, they provide less guidance on others, especially those related to research design. We argue repositories need to address these missing dimensions of context to better support data reuse in archaeology.

#index 1974534
#* Charting the digital library evaluation domain with a semantically enhanced mining methodology
#@ Eleni Afiontzi;Giannis Kazadeis;Leonidas Papachristopoulos;Michalis Sfakakis;Giannis Tsakonas;Christos Papatheodorou
#t 2013
#c 14
#% 246831
#% 458369
#% 760873
#% 765521
#% 960938
#% 1383238
#% 1491555
#% 1608932
#% 1719980
#% 1787086
#% 1924148
#! The digital library evaluation field has an evolving nature and it is characterized by a noteworthy proclivity to enfold various methodological orientations. Given the fact that the scientific literature in the specific domain is vast, researchers require tools that will exhibit either commonly acceptable practices, or areas for further investigation. In this paper, a data mining methodology is proposed to identify prominent patterns in the evaluation of digital libraries. Using Machine Learning techniques, all papers presented in the ECDL and JCDL conferences between the years 2001 and 2011 were categorized as relevant or non-relevant to the DL evaluation domain. Then, the relevant papers were semantically annotated according to the Digital Library Evaluation Ontology (DiLEO) vocabulary. The produced set of annotations was clustered to evaluation patterns for the most frequently used tools, methods and goals of the domain. Our findings highlight the expressive nature of DiLEO, place emphasis on semantic annotation as a necessary step in handling domain-centric corpora and underline the potential of the proposed methodology in the profiling of evaluation activities.

#index 1974535
#* Vertical selection in the information domain of children
#@ Sergio Duarte Torres;Djoerd Hiemstra;Theo Huibers
#t 2013
#c 14
#% 397127
#% 643012
#% 878624
#% 879604
#% 907495
#% 987255
#% 987329
#% 1130852
#% 1227616
#% 1227734
#% 1267046
#% 1355038
#% 1450915
#% 1450995
#% 1455269
#% 1482194
#% 1536555
#% 1565813
#% 1587348
#% 1641960
#% 1642923
#% 1827236
#% 1879036
#% 1919862
#% 1924115
#! In this paper we explore the vertical selection methods in aggregated search in the specific domain of topics for children between 7 and 12 years old. A test collection consisting of 25 verticals, 3.8K queries and relevant assessments for a large sample of these queries mapping relevant verticals to queries was built. We gather relevant assessment by envisaging two aggregated search systems: one in which the Web vertical is always displayed and in which each vertical is assessed independently from the web vertical. We show that both approaches lead to a different set of relevant verticals and that the former is prone to bias of visually oriented verticals. In the second part of this paper we estimate the size of the verticals for the target domain. We show that employing the global size and domain specific size estimation of the verticals lead to significant improvements when using state-of-the art methods of vertical selection. We also introduce a novel vertical and query representation based on tags from social media and we show that its use lead to significant performance gains.

#index 1974536
#* Aggregating productivity indices for ranking researchers across multiple areas
#@ Harlley Lima;Thiago H.P. Silva;Mirella M. Moro;Rodrygo L.T. Santos;Wagner Meira, Jr.;Alberto H.F. Laender
#t 2013
#c 14
#% 306468
#% 411762
#% 915347
#% 1020797
#% 1040934
#% 1100186
#% 1153647
#% 1228207
#% 1467901
#% 1503853
#% 1559489
#% 1593271
#% 1694271
#% 1878248
#% 1880313
#! The impact of scientific research has traditionally been quantified using productivity indices such as the well-known h-index. On the other hand, different research fields---in fact, even different research areas within a single field---may have very different publishing patterns, which may not be well described by a single, global index. In this paper, we argue that productivity indices should account for the singularities of the publication patterns of different research areas, in order to produce an unbiased assessment of the impact of scientific research. Inspired by ranking aggregation approaches in distributed information retrieval, we propose a novel approach for ranking researchers across multiple research areas. Our approach is generic and produces cross-area versions of any global productivity index, such as the volume of publications, citation count and even the h-index. Our thorough evaluation considering multiple areas within the broad field of Computer Science shows that our cross-area indices outperform their global counterparts when assessed against the official ranking produced by CNPq, the Brazilian National Research Council for Scientific and Technological Development. As a result, this paper contributes a valuable mechanism to support the decisions of funding bodies and research agencies, for example, in any research assessment effort.

#index 1974537
#* Redeye: a digital library for forensic document triage
#@ Paul L. Bogen;Amber McKenzie;Rob Gillen
#t 2013
#c 14
#% 240744
#% 434557
#% 760876
#% 763294
#% 894249
#% 915700
#% 967348
#% 1093782
#% 1246130
#% 1434140
#% 1455285
#% 1677914
#% 1687249
#! Forensic document analysis has become an important aspect of investigation of many different kinds of crimes from money laundering to fraud and from cybercrime to smuggling. The current workflow for analysts includes powerful tools, such as Palantir and Analyst's Notebook, for moving from evidence to actionable intelligence and tools for finding documents among the millions of files on a hard disk, such as Forensic Toolkit (FTK). Analysts often leave the process of sorting through collections of seized documents to filter out noise from actual evidence to highly labor-intensive manual efforts. This paper presents the Redeye Analysis Workbench, a tool to help analysts move from manual sorting of a collection of documents to performing intelligent document triage over a digital library. We will discuss the tools and techniques we build upon in addition to an in-depth discussion of our tool and how it addresses two major use cases we observed analysts performing. Finally, we also include a new layout algorithm for radial graphs that is used to visualize clusters of documents in our system.

#index 1974538
#* An evaluation of caching policies for memento timemaps
#@ Justin F. Brunelle;Michael L. Nelson
#t 2013
#c 14
#% 344720
#% 438251
#% 480136
#% 754058
#% 756015
#% 759523
#% 907442
#% 978365
#% 978374
#% 1196584
#% 1303525
#% 1588365
#% 1974584
#! As defined by the Memento Framework, TimeMaps are machine-readable lists of time-specific copies -- called "mementos" -- of an archived original resource. In theory, as an archive acquires additional mementos over time, a TimeMap should be monotonically increasing. However, there are reasons why the number of mementos in a TimeMap would decrease, for example: archival redaction of some or all of the mementos, archival restructuring, and transient errors of one or more archives. We study TimeMaps for 4,000 original resources over a three month period, note their change patterns, and develop a caching algorithm for TimeMaps suitable for a reverse proxy in front of a Memento aggregator. We show that TimeMap cardinality is constant or monotonically increasing for 80.2% of all TimeMap downloads in the observation period. The goal of the caching algorithm is to exploit the ideally monotonically increasing nature of TimeMaps and not cache responses with fewer mementos than the already cached TimeMap. This new caching algorithm uses conditional cache replacement and a Time To Live (TTL) value to ensure the user has access to the most complete TimeMap available. Based on our empirical data, a TTL of 15 days will minimize the number of mementos missed by users, and minimize the load on archives contributing to TimeMaps.

#index 1974539
#* Evaluating sliding and sticky target policies by measuring temporal drift in acyclic walks through a web archive
#@ Scott G. Ainsworth;Michael L. Nelson
#t 2013
#c 14
#% 754100
#% 1190280
#% 1328158
#% 1588363
#% 1588365
#% 1618383
#% 1624271
#% 1974543
#! When a user views an archived page using the archive's user interface (UI), the user selects a datetime to view from a list. The archived web page, if available, is then displayed. From this display, the web archive UI attempts to simulate the web browsing experience by smoothly transitioning between archived pages. During this process, the target datetime changes with each link followed; drifting away from the datetime originally selected. When browsing sparsely-archived pages, this nearly-silent drift can be many years in just a few clicks. We conducted 200,000 acyclic walks of archived pages, following up to 50 links per walk, comparing the results of two target datetime policies. The Sliding Target policy allows the target datetime to change as it does in archive UIs such as the Internet Archive's Wayback Machine. The Sticky Target policy, represented by the Memento API, keeps the target datetime the same throughout the walk. We found that the Sliding Target policy drift increases with the number of walk steps, number of domains visited, and choice (number of links available). However, the Sticky Target policy controls temporal drift, holding it to less than 30 days on average regardless of walk length or number of domains visited. The Sticky Target policy shows some increase as choice increases, but this may be caused by other factors. We conclude that based on walk length, the Sticky Target policy generally produces at least 30 days less drift than the Sliding Target policy.

#index 1974540
#* Free benchmark corpora for preservation experiments: using model-driven engineering to generate data sets
#@ Christoph Becker;Kresimir Duretec
#t 2013
#c 14
#% 310844
#% 840743
#% 1006566
#% 1283557
#% 1431372
#% 1581258
#% 1588356
#% 1741003
#% 1787103
#! Digital preservation is an active area of research, and recent years have brought forward an increasing number of characterisation tools for the object-level analysis of digital content. However, there is a profound lack of objective, standardised and comparable metrics and benchmark collections to enable experimentation and validation of these tools. While fields such as Information Retrieval have for decades been able to rely on benchmark collections annotated with ground truth to enable systematic improvement of algorithms and systems along objective metrics, the digital preservation field is yet unable to provide the necessary ground truth for such benchmarks. Objective indicators, however, are the key enabler for quantitative experimentation and innovation. This paper presents a systematic model-driven benchmark generation framework that aims to provide realistic approximations of real-world digital information collections with fully known ground truth that enables systematic quantitative experimentation, measurement and improvement against objective indicators. We describe the key motivation and idea behind the framework, outline the technological building blocks, and discuss results of the generation of page-based and hierarchical documents from a ground truth model. Based on a discussion of the benefits and challenges of the approach, we outline future work.

#index 1974541
#* A search engine approach to estimating temporal changes in gender orientation of first names
#@ Brittany N. Smith;Mamta Singh;Vetle I. Torvik
#t 2013
#c 14
#% 722308
#% 783529
#% 804877
#% 816159
#% 844509
#% 1190108
#% 1211086
#% 1249538
#% 1482215
#% 1587203
#% 1913233
#! This paper presents an approach for predicting the gender orientation of any given first name over time based on a set of search engine queries with the name prefixed by masculine and feminine markers (e.g., "Uncle Taylor"). We hypothesize that these markers can capture the great majority of variability in gender orientation, including temporal changes. To test this hypothesis, we train a logistic regression model, with time-varying marker weights, using marker counts from Bing.com to predict male/female counts for 85,406 names in US Social Security Administration (SSA) data during 1880-2008. The model misclassifies 2.25% of the people in the SSA dataset (slightly worse than the 1.74% pure error rate) and provides accurate predictions for names beyond the SSA. The misclassification rate is higher in recent years (due to increasing name diversity), for general English words (e.g., Will), for names from certain countries (e.g., China), and for rare names. However, the model tends to err on the side of caution by predicting neutral/unknown rather than false positive. As hypothesized, the markers also capture temporal patterns of androgyny. For example, Daughter is a stronger female predictor for recent years while Grandfather is a stronger male predictor around the turn of the 20th century. The model has been implemented as a web-tool called Genni (available via http://abel.lis.illinois.edu/) that displays the predicted proportion of females vs. males over time for any given name. This should be a valuable resource for those who utilize names in order to discern gender on a large scale, e.g., to study the roles of gender and diversity in scholarly work based on digital libraries and bibliographic databases where the authors? names are listed.

#index 1974542
#* Reading the correct history?: modeling temporal intention in resource sharing
#@ Hany M. SalahEldeen;Michael L. Nelson
#t 2013
#c 14
#% 347225
#% 424335
#% 640706
#% 754058
#% 754090
#% 760841
#% 854140
#% 875414
#% 956622
#% 1040837
#% 1074093
#% 1107070
#% 1166533
#% 1292693
#% 1355016
#% 1355060
#% 1429402
#% 1560426
#% 1588363
#% 1588366
#% 1598373
#% 1598393
#% 1624234
#% 1787052
#% 1872257
#% 1912918
#% 1917329
#% 1924133
#! The web is trapped in the "perpetual now", and when users traverse from page to page, they are seeing the state of the web resource (i.e., the page) as it exists at the time of the click and not necessarily at the time when the link was made. Thus, a temporal discrepancy can arise between the resource at the time the page author created a link to it and the time when a reader follows the link. This is especially important in the context of social media: the ease of sharing links in a tweet or Facebook post allows many people to author web content, but the space constraints combined with poor awareness by authors often prevents sufficient context from being generated to determine the intent of the post. If the links are clicked as soon as they are shared, the temporal distance between sharing and clicking is so small that there is little to no difference in content. However, not all clicks occur immediately, and a delay of days or even hours can result in reading something other than what the author intended. We introduce the concept of a user's temporal intention upon publishing a link in social media. We investigate the features that could be extracted from the post, the linked resource, and the patterns of social dissemination to model this user intention. Finally, we analyze the historical integrity of the shared resources in social media across time. In other words, how much is the knowledge of the author's intent beneficial in maintaining the consistency of the story being told through social posts and in enriching the archived content coverage and depth of vulnerable resources?

#index 1974543
#* Access patterns for robots and humans in web archives
#@ Yasmin A. AlNoamany;Michele C. Weigle;Michael L. Nelson
#t 2013
#c 14
#% 186340
#% 420132
#% 630984
#% 642985
#% 739634
#% 744735
#% 881072
#% 921691
#% 948478
#% 1040772
#% 1168478
#% 1293112
#% 1348355
#% 1399989
#% 1538187
#% 1741050
#% 1879026
#% 1899086
#! Although user access patterns on the live web are well-understood, there has been no corresponding study of how users, both humans and robots, access web archives. Based on samples from the Internet Archive's public Wayback Machine, we propose a set of basic usage patterns: Dip (a single access), Slide (the same page at different archive times), Dive (different pages at approximately the same archive time), and Skim (lists of what pages are archived, i.e., TimeMaps). Robots are limited almost exclusively to Dips and Skims, but human accesses are more varied between all four types. Robots outnumber humans 10:1 in terms of sessions, 5:4 in terms of raw HTTP accesses, and 4:1 in terms of megabytes transferred. Robots almost always access TimeMaps (95% of accesses), but humans predominately access the archived web pages themselves (82% of accesses). In terms of unique archived web pages, there is no overall preference for a particular time, but the recent past (within the last year) shows significant repeat accesses.

#index 1974544
#* Building a search engine for computer science course syllabi
#@ Nakul Rathod;Lillian Cassel
#t 2013
#c 14
#% 387427
#% 449588
#% 458379
#% 465754
#% 676895
#% 791713
#% 902457
#% 945047
#% 1353991
#% 1417363
#% 1924157
#! Syllabi are rich educational resources. However, finding Computer Science syllabi on a generic search engine does not work well. Towards our goal of building a syllabus collection we have trained various Machine Learning classifiers to recognize Computer Science syllabi from other web pages and the discipline that they represent (AI or SE for instance) among other things. We have crawled 50 Computer Science departments in the US and gathered 100,000 candidate pages. Our best classifiers are more than 90% accurate at identifying syllabi from real-world data. The syllabus repository we created is live for public use (at http://syllabus.sdakak.com) and contains more than 3000 syllabi that our classifiers filtered out from the crawl data. We present an analysis of the various feature selection methods and classifiers used.

#index 1974545
#* Tipple: location-triggered mobile access to a digital library for audio books
#@ Annika Hinze;David Bainbridge
#t 2013
#c 14
#% 201618
#% 343156
#% 345048
#% 418617
#% 434937
#% 508117
#% 737419
#% 760922
#% 809423
#% 826454
#% 830065
#% 839756
#% 925730
#% 1065300
#% 1183270
#% 1389408
#% 1399830
#% 1406463
#% 1681995
#! This paper explores the role of audio as a means to access books in a digital library while being at the location referred to in the books. The books are sourced from the digital library and can either be accompanied by pre-recorded audio or synthesized using text-to-speech. The paper details the functional requirements, design and implementation of Tipple. The concept was extensively tested in three field studies.

#index 1974546
#* Medusa at the university of Illinois at Urbana-Champaign: a digital preservation service based on PREMIS
#@ Kyle R. Rimkus;Thomas Habing
#t 2013
#c 14
#! The Medusa digital preservation service at the University of Illinois at Urbana-Champaign provides a storage environment for digital content selected for long-term retention by content managers and producers affiliated with the Library in order to ensure its enduring access and use. This paper reports on Medusa development, with emphasis on the research processes that informed key decisions related to its design, the central role of PREMIS metadata in its architecture, and future directions of integrating PREMIS management into a Fedora repository architecture. In so doing, it describes a strategy of digital preservation content management that draws strength from the creation and management of comprehensive PREMIS preservation metadata records.

#index 1974547
#* Interactive search result clustering: a study of user behavior and retrieval effectiveness
#@ Xuemei Gong;Weimao Ke;Yan Zhang;Ramona Broussard
#t 2013
#c 14
#% 118771
#% 214711
#% 218992
#% 245740
#% 375017
#% 935767
#% 1039831
#% 1227579
#% 1262695
#% 1301004
#! Scatter/Gather is a document browsing and information retrieval method based on document clustering. It is designed to facilitate user articulation of information needs through iterative clustering and interactive browsing. This paper reports on a study that investigated the effectiveness of Scatter/Gather browsing for information retrieval. We conducted a within-subject user study of 24 college students to investigate the utility of a Scatter/Gather system, to examine its strengths and weaknesses, and to receive feedback from users on the system. Results show that the clustering-based Scatter/Gather method was more difficult to use than the classic information retrieval systems in terms of user perception. However, clustering helped the subjects accomplish the tasks more efficiently. Scatter/Gather clustering was particularly useful in helping users finish tasks that they were less familiar with and allowed them to search with fewer words. Scatter/Gather tended to be more useful when it was more difficult for the user to do query specification for an information need. Topic familiarity and specificity had significant influences on user perceived retrieval effectiveness. The influences appeared to be greater with the Scatter/Gather system compared to a classic search system. Topic familiarity also had significant influences on query formulation.

#index 1974548
#* Domain-specific image geocoding: a case study on Virginia tech building photos
#@ Lin Tzy Li;Otávio A.B. Penatti;Edward A. Fox;Ricardo da S. Torres
#t 2013
#c 14
#% 724320
#% 760916
#% 1107782
#% 1446867
#% 1464094
#% 1538244
#% 1667643
#% 1738236
#% 1859407
#% 1941043
#! The use of map-based browser services is of great relevance in numerous digital libraries. The implementation of such services, however, demands the use of geocoded data collections. This paper investigates the use of image content local representations in geocoding tasks. Performed experiments demonstrate that some of the evaluated descriptors yield effective results in the task of geocoding VT building photos. This study is the first step to geocode multimedia material related to the VT April 16, 2007 school shooting tragedy.

#index 1974549
#* Instrument distribution and music notation search for enhancing bibliographic music score retrieval
#@ Laurent Pugin;Rodolfo Zitellini
#t 2013
#c 14
#! Because of the unique characteristics of music scores, searching bibliographical music collections using traditional library systems can be a challenge. In this paper, we present two specific search functionalities added to the Swiss RISM data-base and describe how they improve the user experience. The first is a search functionality for instrument and vocal part distribution that leverages coded information available in the MarcXML records of the database. It enables scores for precise ensemble distribution to be retrieved. The second is a search functionality of music notation excerpts transcribed from the beginning of the pieces, known as music incipits. The incipit search is achieved using a well-known music information retrieval (MIR) tool, Themefinder. A novelty of our implementation is that it can operate at three different levels (pitch, duration and metric), singularly or combined, and that it is performed through a specifically-developed intuitive graphical interface for note input and parameter selection. The two additions illustrate why it is important to take into consideration the particularities of music scores when designing a search system and how MIR tools can be beneficially integrated into existing heterogeneous bibliographic score collections.

#index 1974550
#* A scalable, distributed and dynamic workflow system for digitization processes
#@ Hendrik Schöneberg;Hans-Günter Schmidt;Winfried Höhn
#t 2013
#c 14
#! Creating digital representations of ancient manuscripts, prints and maps is a challenging task due to the sources' fragile and heterogeneous natures. Digitization requires a very specialized set of scanning hardware in order to cover the sources' diversity. The central task is obtaining the maximum reproduction quality while minimizing the error rate, which is difficult to achieve due to the large amounts of image data resulting from digitization, putting huge computational loads on image processing modules, error-detection and information retrieval heuristics. As digital copies initially do not contain any information about their sources' semantics, additional efforts have to be made to extract semantic metadata. This is an error-prone, time-consuming manual process, which calls for automated mechanisms to support the user. This paper introduces a decentralized, event-driven workflow system designed to overcome the above mentioned challenges. It leverages dynamic routing between workflow components, thus being able to quickly adapt to the sources' unique requirements. It provides a scalable approach to soften out high computational loads on single units by using distributed computing and provides modules for automated image pre-/post-processing, error-detection heuristics, data mining, semantic analysis, metadata augmentation, quality assurance and an export functionality to established publishing platforms or long-term storage facilites.

#index 1974551
#* Constructing an anonymous dataset from the personal digital photo libraries of mac app store users
#@ Jesse Prabawa Gozali;Min-Yen Kan;Hari Sundaram
#t 2013
#c 14
#% 577220
#% 589969
#% 1478138
#% 1583874
#% 1775216
#% 1787052
#% 1787078
#% 1886415
#! Personal digital photo libraries embody a large amount of information useful for research into photo organization, photo layout, and development of novel photo browser features. Even when anonymity can be ensured, amassing a sizable dataset from these libraries is still difficult due to the visibility and cost that would be required from such a study. We explore using the Mac App Store to reach more users to collect data from such personal digital photo libraries. More specifically, we compare and discuss how it differs from common data collection methods, e.g. Amazon Mechanical Turk, in terms of time, cost, quantity, and design of the data collection application. We have collected a large, openly available photo feature dataset using this manner. We illustrate the types of data that can be collected. In 60 days, we collected data from 20,778 photo sets (473,772 photos). Our study with the Mac App Store suggests that popular application distribution channels is a viable means to acquire massive data collections for researchers.

#index 1974552
#* Identification of works of manga using LOD resources: an experimental FRBRization of bibliographic data of comic books
#@ Wenling He;Tetsuya Mihara;Mitsuharu Nagamori;Shigeo Sugimoto
#t 2013
#c 14
#% 1312870
#% 1588436
#% 1624259
#! Manga -- a Japanese term meaning graphic novel or comic -- has been globally accepted. In Japan, there are a huge number of monographs and magazines of manga published. The work entity defined in Functional Requirements of Bibliographic Records (FRBR) is useful to identify and find manga. This paper examines how to identify manga works in a set of bibliographic records maintained by Kyoto International Manga Museum. It is known that authority data is useful to identify works from the bibliographic records. However, the authority data of manga is not rich, because manga has been recognized as a sub-culture resource and is generally not included in library collections. In this study, we used DBpedia, which is a large Linked Open Data (LOD) resource created from Wikipedia, to identify FRBR manga entities in bibliographic records. The results of this study show that using LOD resources is a reasonable way to identify works from bibliographic records. It also shows the accuracy and efficiency of work identification depending on the quality of the LOD resources used.

#index 1974553
#* Following bibliometric footprints: the ACM digital library and the evolution of computer science
#@ Shion Guha;Stephanie Steinhardt;Syed Ishtiaque Ahmed;Carl Lagoze
#t 2013
#c 14
#% 89354
#% 172803
#% 597769
#% 597944
#% 606920
#% 783884
#% 1183146
#% 1184448
#% 1198578
#% 1434126
#% 1741067
#! Using bibliometric methods, this exploratory work shows evidence of transitions in the field of computer science since the emergence of HCI as a distinct sub-discipline. We mined the ACM Digital Library in order to expose relationships between sub-disciplines in computer science, focusing in particular on the transformational nature of the SIG Computer-Human Interaction (CHI) in relation to other SIGs. Our results suggest shifts in the field due to broader social, economic and political changes in computing research and are intended as a prolegomena to further investigations.

#index 1974554
#* Extending sitemaps for ResourceSync
#@ Martin Klein;Herbert Van de Sompel
#t 2013
#c 14
#% 577370
#% 640706
#% 754058
#! The documents used in the ResourceSync synchronization framework are based on the widely adopted document format defined by the Sitemap protocol. In order to address requirements of the framework, extensions to the Sitemap format were necessary. This short paper describes the concerns we had about introducing such extensions, the tests we did to evaluate their validity, and aspects of the framework to address them.

#index 1974555
#* Semiautomatic recognition and georeferencing of places in early maps
#@ Winfried Höhn;Hans-Günter Schmidt;Hendrik Schöneberg
#t 2013
#c 14
#% 1558906
#% 1588376
#! Early maps are a valuable resource for historical research, this is why digital libraries for early maps become a necessary tool for research support in the age of information. In this article we introduce the Referencing and Annotation Tool (RAT), designed to extract information about all places displayed in a map and link them to a place on a modern map. RAT automatically recognizes place markers in an early map according to a template specified by the user and estimates the position of the annotated place in the modern map, thus making georeferencing easier. After a brief summary on related projects, we describe the functionality of the system. We discuss the most important implementation details and factors influencing recognition accuracy and performance. The advantages of our semiautomatic approach are high accuracy and a significant decrease of the user's cognitive load.

#index 1974556
#* First steps in archiving the mobile web: automated discovery of mobile websites
#@ Richard Schneider;Frank McCown
#t 2013
#c 14
#% 534048
#% 754090
#% 1055762
#% 1264902
#% 1954341
#! Smartphones and tablets are increasingly used to access the Web, and many websites now provide alternative sites tailored specifically for these mobile devices. Web archivists are in need of tools to aid in archiving this equally ephemeral Mobile Web. We present Findmobile, a tool for automating the discovery of mobile websites. We tested our tool in an experiment examining 10K popular websites and found that the most frequently used technique used by popular websites to direct mobile users to mobile sites was by automated client and server-side redirection. We found that nearly half of mobile web pages differ dramatically from their stationary web counterparts and that the most popular websites are those most likely to have mobile-specific pages.

#index 1974557
#* IFME: information filtering by multiple examples with under-sampling in a digital library environment
#@ Mingzhu Zhu;Chao Xu;Yi-Fang Brook Wu
#t 2013
#c 14
#% 266292
#% 464641
#% 729621
#% 879567
#% 936239
#% 1154321
#% 1481557
#% 1558464
#! With the amount of digitalized documents increasing exponentially, it is more difficult for users to keep up to date with the knowledge in their domain. In this paper, we present a framework named IFME (Information Filtering by Multiple Examples) in a digital library environment to help users identify the literature related to their interests by leveraging the Positive Unlabeled learning (PU learning). Using a few relevant documents provided by a user and considering the documents in an online database as unlabeled data (called U), it ranks the documents in U using a PU learning algorithm. From the experimental results, we found that while the approach performed well when a large set of relevant feedback documents were available, it performed relatively poor when the relevant feedback documents were few. We improved IFME by combining PU learning with under-sampling to tune the performance. Using Mean Average Precision (MAP), our experimental results indicated that with under-sampling, the performance improved significantly even when the size of P was small. We believe the PU learning based IFME framework brings insights to develop more effective digital library systems.

#index 1974558
#* Modeling heterogeneous data resources for social-ecological research: a data-centric perspective
#@ Miao Chen;Umashanthi Pavalanathan;Scott Jensen;Beth Plale
#t 2013
#c 14
#% 1153233
#% 1383238
#% 1976770
#! Digital repositories are grappling with an influx of scientific data brought about by the well publicized "data deluge" in science, business, and society. One particularly perplexing problem is the long-term archival and reuse of complex data sets. This paper presents an integrated approach to data discovery over heterogeneous data resources in social-ecological systems research. Social-ecological systems data is complex because the research draws from both social and natural sciences. Using a sample set of data resources from the domain, we explore an approach to discovery and representation of this data. Specifically, we develop an ontology-based process of organization and visualization from a data-centric perspective. We define data resources broadly and identify six key categories of resources that include data collected from site visits to shared ecological resources, the structure of research instruments, domain concepts, research designs, publications, theories and models. We identify the underlying relationships and construct an ontology that captures these relationships using semantic web languages. The ontology and a NoSQL data store at the back end store the data resource instances. These are integrated into a portal architecture we refer to as the Integrated Visualization of Social-Ecological Resources (IViSER) that allows users to both browse the relationships captured in the ontology and easily visualize the granular details of data resources.

#index 1974559
#* Mendeley group as a new source of interdisciplinarity study: how do disciplines interact on mendeley?
#@ Jiepu Jiang;Chaoqun Ni;Daqing He;Wei Jeng
#t 2013
#c 14
#% 1588409
#% 1747149
#% 1844556
#! In this paper, we studied interdisciplinary structures by looking into how online academic groups of different disciplines share members and followers. Results based on Mendeley online groups show clear interdisciplinary structures, indicating Mendeley online groups as a promising data source and a new perspective of disciplinarity and interdisciplinarity studies.

#index 1974560
#* The user-centered development and testing of a dublin core metadata tool
#@ Catherine Hall;Michael Khoo
#t 2013
#c 14
#% 508408
#% 571509
#% 809439
#% 1069028
#% 1924120
#! Digital libraries are supported by good quality metadata, and thus by the use of good quality metadata tools. The design of metadata tools can be supported by following user-centered design processes. In this paper we discuss the application and evaluation of several cognitively-based rules, derived from the work of Donald Norman, to the design of a metadata tool for administering Dublin Core metadata. One overall finding was that while the use of the rules supported users in their immediate interactions with the tool interface, they provided less support for the more cognitively intensive tasks associated with developing a wider conceptual understanding of the purpose of metadata. The findings have implications for the wider development of tools to support metadata work in digital libraries and allied contexts.

#index 1974561
#* Addressing diverse corpora with cluster-based term weighting
#@ Peter Organisciak
#t 2013
#c 14
#% 321635
#% 324129
#% 766430
#% 1077150
#! Highly heterogeneous collections present difficulties to term weighting models that are informed by corpus-level frequencies. Collections which span multiple languages or large time periods do not provide realistic statistics on which words are interesting to a system. This paper presents a case where diverse corpora can frustrate term weighting and proposes a modification that weighs documents according to their class or cluster within the collection. In cases of diverse corpora, the proposed modification better represents the intuitions behind corpus-level document frequencies.

#index 1974562
#* Multimodal alignment of scholarly documents and their presentations
#@ Bamdad Bahrani;Min-Yen Kan
#t 2013
#c 14
#% 812418
#% 967255
#% 1065288
#% 1164326
#% 1249537
#% 1269907
#% 1392432
#% 1510664
#% 1651407
#! We present a multimodal system for aligning scholarly docu- ments to corresponding presentations in a fine-grained man- ner (i.e., per presentation slide and per paper section). Our method improves upon a state-of-the-art baseline that em- ploys only textual similarity. Based on an analysis of base- line errors, we propose a three-pronged alignment system that combines textual, image, and ordering information to establish alignment. Our results show a statistically sig- nificant improvement of 25%, confirming the importance of visual content in improving alignment accuracy.

#index 1974563
#* Local histories in global digital libraries: identifying demand and evaluating coverage
#@ Katrina Fenlon;Virgil E. Varvel, Jr.
#t 2013
#c 14
#% 1523427
#% 1702281
#! Digital collections of primary source materials have potential to change how citizen historians and scholars research and engage with local history. The problem at the heart of this study is how to evaluate local history coverage, particularly among large-scale, distributed collections and aggregations. As part of an effort to holistically evaluate one such national aggregation, the Institute of Museum and Library Services (IMLS) Digital Collections and Content (DCC), we conducted a national survey of reference service providers at academic and public libraries throughout the United States. In this paper, we report the results of this survey that appear relevant to local history and collection evaluation, and consider the implications for scalable evaluation of local history coverage in massive, aggregative digital libraries.

#index 1974564
#* Can't see the forest for the trees?: a citation recommendation system
#@ Cornelia Caragea;Adrian Silvescu;Prasenjit Mitra;C. Lee Giles
#t 2013
#c 14
#% 92145
#% 249143
#% 415107
#% 722904
#% 1083684
#% 1195999
#% 1261537
#% 1399975
#% 1482239
#% 1642168
#% 1919842
#! Scientists continue to find challenges in the ever increasing amount of information that has been produced on a world wide scale, during the last decades. When writing a paper, an author searches for the most relevant citations that started or were the foundation of a particular topic, which would very likely explain the thinking or algorithms that are employed. The search is usually done using specific keywords submitted to literature search engines such as Google Scholar and CiteSeer. However, finding relevant citations is distinctive from producing articles that are only topically similar to an author's proposal. In this paper, we address the problem of citation recommendation using a singular value decomposition approach. The models are trained and evaluated on the Citeseer digital library. The results of our experiments show that the proposed approach achieves significant success when compared with collaborative filtering methods on the citation recommendation task.

#index 1974565
#* Automatic performance evaluation of dewarping methods in large scale digitization of historical documents
#@ Maryam Rahnemoonfar;Beth Plale
#t 2013
#c 14
#% 718501
#% 899639
#% 1006721
#% 1013693
#% 1283634
#% 1645159
#% 1791109
#% 1856060
#% 1856898
#! Geometric distortions are among the major challenging issues in the analysis of historical document images. Such distortions appear as arbitrary warping, folds and page curl, and have detrimental effects upon recognition (OCR) and readability. While there are many dewarping techniques discussed in the literature, there exists no standard method by which their performance can be evaluated against each other. In particular, there is not any satisfactory method capable of comparing the results of existing dewarping techniques on arbitrary wrapped documents. The existing methods either rely on the visual comparison of the output and input images or depend on the recognition rate of an OCR system. In the case of historical documents, OCR either is not available or does not generate an acceptable result. In this paper, an objective and automatic evaluation methodology for document image dewarping technique is presented. In the first step, all the baselines in the original distorted image as well as dewarped image are modelled precisely and automatically. Then based on the mathematical function of each line, a comprehensive metric which calculates the performance of a dewarping technique is introduced. The presented method does not require user interference in any stage of evaluation and therefore is quite objective. Experimental results, applied to two state-of-the art dewarping methods and an industry-standard commercial system, demonstrate the effectiveness of the proposed dewarping evaluation method.

#index 1974566
#* Interacting with and through a digital library collection: commenting behavior in Flickr's the commons
#@ Sally Jo Cunningham;Malika Mahoui
#t 2013
#c 14
#% 760852
#% 855601
#% 1497569
#% 1497579
#! There is growing interest by digital collection providers to engage collection users in interacting with the collection (e.g. by tagging or annotating collection contents) and with the collection organizers and other users (e.g. to form loose "communities" associated with the collection). At present, little has been documented as to the uptake of these mechanisms in specific collections, or the range of behaviors that emerge as users bend existing facilities to their own needs. This paper is one step in that direction: it describes the social information behaviors exhibited in a cultural heritage photography collection in The Commons on Flickr, and suggests implications for digital library design in response to these behaviors.

#index 1974567
#* A comparative study of academic and Wikipedia ranking
#@ Xin Shuai;Zhuoren Jiang;Xiaozhong Liu;Johan Bollen
#t 2013
#c 14
#% 1183237
#! In addition to its broad popularity Wikipedia is also widely used for scholarly purposes. Many Wikipedia pages pertain to academic papers, scholars and topics providing a rich ecology for scholarly uses. Scholarly references and mentions on Wikipedia may thus shape the "societal impact" of a certain scholarly communication item, but it is not clear whether they shape actual "academic impact". In this paper we compare the impact of papers, scholars, and topics according to two different measures, namely scholarly citations and Wikipedia mentions. Our results show that academic and Wikipedia impact are positively correlated. Papers, authors, and topics that are mentioned on Wikipedia have higher academic impact than those are not mentioned. Our findings validate the hypothesis that Wikipedia can help assess the impact of scholarly publications and underpin relevance indicators for scholarly retrieval or recommendation systems.

#index 1974568
#* Pretty as a pixel: issues and challenges in developing a controlled vocabulary for video game visual styles
#@ Andy Donovan;Hyerim Cho;Chris Magnifico;Jin Ha Lee
#t 2013
#c 14
#! Despite the increase in interest in video games across commercial and academic areas, organizational systems for classifying them remain inadequate, particularly in describing the visual styles of video games. Because video games are by and large a visual medium, the ability to describe their visual "look" coherently and consistently greatly contributes to their discovery through classification. A set of controlled terms would be instrumental in complementing game recommendation engines and search applications in digital libraries to meet users' content-related information needs. In our study we examine the academic and user-generated content about video games' visual styles in order to extract potentially useful controlled vocabulary terms. These terms are then organized into facets and arranged into a classified schedule. In this poster, we discuss the challenges in our controlled vocabulary term definitions and their application.

#index 1974569
#* Full-text and topic based authorrank and enhanced publication ranking
#@ Jinsong Zhang;Xiaozhong Liu
#t 2013
#c 14
#% 641979
#% 662755
#% 1338553
#% 1392465
#% 1919855
#! The idea behind AuthorRank is that a content created by more popular authors should rank higher than the content created by less popular authors. This paper brings this idea into scientific publications analysis to test whether the optimized topical AuthorRank can replace or enhance topical PageRank for publication ranking. First, the PageRank with Priors (PRP) algorithm was employed to rank topic-based publications and authors. Second, the first author's reputation was used for generating an AuthorRank score. Additionally, linear combination method of topical AuthorRank and PageRank were compared with several baselines. Finally, as shown in our evaluation results, the performance of topical AuthorRank combined with topic-based PageRank is better than other baselines for publication ranking.

#index 1974570
#* Investigating influential factors influencing users to share news in social media: a diffusion of innovations perspective
#@ Long Ma;Chei Sian Lee;Dion Hoe-Lian Goh
#t 2013
#c 14
#% 1680193
#! This study aims to investigate the factors influencing news sharing in social media. Drawing from the diffusion of innovations theory (DOI), the influential factors identified are opinion leadership, homophily, tie strength, and news attributes. By incorporating social network analysis with multiple regression analysis, our results indicate that opinion leadership was the strongest factor predicting users' news sharing, followed by news attribute and tie strength. Unexpectedly, we also found that homophily hampered news sharing in social media. Implications are discussed

#index 1974571
#* CSSeer: an expert recommendation system based on CiteseerX
#@ Hung-Hsuan Chen;Pucktada Treeratpituk;Prasenjit Mitra;C. Lee Giles
#t 2013
#c 14
#% 1213413
#! We propose CSSeer, a free and publicly available keyphrase based recommendation system for expert discovery based on the CiteSeerX digital library and Wikipedia as an auxiliary resource. CSSeer generates keyphrases from the title and the abstract of each document in CiteSeerX. These keyphrases are then utilized to infer the authors' expertise. We compared CSSeer with the other two state-of-the-art expert recommenders and found that the three systems have moderately divergent recommendations on 20 benchmark queries. Thus, we recommend users to browse through several different recommenders to obtain a more complete expert list.

#index 1974572
#* ArcLink: optimization techniques to build and retrieve the temporal web graph
#@ Ahmed AlSum;Michael L. Nelson
#t 2013
#c 14
#% 1974543
#! We present ArcLink, a proof-of-concept system that complements open source Wayback Machine installations by optimizing the construction, storage, and access to the temporal web graph. We divide the web graph construction into four stages (filtering, extraction, storage, and access) and explore optimization for each stage. ArcLink extends the current web archive interfaces to return content and structural metadata for each URI.

#index 1974573
#* TheAdvisor: a webservice for academic recommendation
#@ Onur Küçüktunç;Erik Saule;Kamer Kaya;Ümit V. Çatalyürek
#t 2013
#c 14
#% 1966768
#% 1992451
#! The academic community has published millions of research papers to date, and the number of new papers has been increasing with time. To discover new research, researchers typically rely on manual methods such as keyword-based search, reading proceedings of conferences, browsing publication lists of known experts, or checking the references of the papers they are interested. Existing tools for the literature search are suitable for a first-level bibliographic search. However, they do not allow complex second-level searches. In this paper, we present a web service called TheAdvisor (http://theadvisor.osu.edu) which helps the users to build a strong bibliography by extending the document set obtained after a first-level search. The service makes use of the citation graph for recommendation. It also features diversification, relevance feedback, graphical visualization, venue and reviewer recommendation. In this work, we explain the design criteria and rationale we employed to make the TheAdvisor a useful and scalable web service along with a thorough experimental evaluation.

#index 1974574
#* Evaluation of header metadata extraction approaches and tools for scientific PDF documents
#@ Mario Lipinski;Kevin Yao;Corinna Breitinger;Joeran Beel;Bela Gipp
#t 2013
#c 14
#% 1495130
#% 1588440
#% 1796744
#% 1974609
#! This paper evaluates the performance of tools for the extraction of metadata from scientific articles. Accurate metadata extraction is an important task for automating the management of digital libraries. This comparative study is a guide for developers looking to integrate the most suitable and effective metadata extraction tool into their software. We shed light on the strengths and weaknesses of seven tools in common use. In our evaluation using papers from the arXiv collection, GROBID delivered the best results, followed by Mendeley Desktop. SciPlore Xtract, PDFMeat, and SVMHeaderParse also delivered good results depending on the metadata type to be extracted.

#index 1974575
#* A classification scheme for algorithm citation function in scholarly works
#@ Suppawong Tuarob;Prasenjit Mitra;C. Lee Giles
#t 2013
#c 14
#% 722904
#% 1261537
#% 1578576
#% 1787073
#! Algorithms are ubiquitous in the computer science literature. A search engine for algorithms has been tested as part of the CiteseerX suite; however, it only retrieves algorithms whose metadata is textually matched with the search query. Such a limitation occurs because a traditional search engine does not have the ability to understand what algorithms are and how they work. Here, we present an initial effort in understanding the semantics of algorithms. Specifically, we identify how an existing algorithm can be used in scholarly works and propose a classification scheme for algorithm function.

#index 1974576
#* Institutional structures for research data and metadata curation
#@ Matthew S. Mayernik
#t 2013
#c 14
#% 358065
#% 1480238
#% 1540752
#% 1827706
#% 1875835

#index 1974577
#* A figure search engine architecture for a chemistry digital library
#@ Sagnik Ray Choudhury;Suppawong Tuarob;Prasenjit Mitra;Lior Rokach;Andi Kirk;Silvia Szep;Donald Pellegrino;Sue Jones;Clyde Lee Giles
#t 2013
#c 14
#% 879637
#% 967256
#% 1685572
#% 1787060
#! Academic papers contain multiple figures representing important findings and experimental results; we present a search engine specifically focused on figures in academic documents. This search engine allows users to search on figures in approximately 150,000 chemistry journal articles though the method is easily extendable to other domains. Our system indexes figure caption and mentions extracted from the PDF in documents using a custom built extractor. Recall and precision performance of extracted figures is in the 80 to 90% range. We give the frame work for the extraction algorithm, architecture and ranking function.

#index 1974578
#* Publishing earthquake engineering research data
#@ Stanislav Pejşa;Cheng Song
#t 2013
#c 14
#% 1595781
#! Earthquake engineering brings together researchers from seismology, structural, mechanical, and geotechnical engineering whose research results in saving lives and protecting property during earthquakes and tsunamis. Such diversity poses unique challenges for data management, data archiving, preservation, and data publication. The poster demonstrates new innovative approaches to curation, visualization, and publishing of earthquake engineering research data in the NEEShub, a collaborative platform that provides a combined virtual research environment and data repository to researchers participating in the Network for Earthquake Engineering Simulations (NEES) and to the earthquake engineering community in general. The poster provides graphical depictions demonstrating the curation workflows established in NEES, the progression of data from unprocessed sensor measurements to datasets that can be analyzed by a variety of analytical and visualization tools, and finally their transformation into a citable published product. It documents ways in which NEEShub exposes research data and facilitates collaboration and sharing, as well as re-use and repurposing of the datasets. Furthermore, the poster illustrates some of the successes of the NEEShub in its four years of existence including continuous growth in uploaded files, users, number of downloaded files, curated projects, and published datasets.

#index 1974579
#* A retrospective review on a decade of building a national science digital library to transform STEM education
#@ Sarah Giersch;Flora McMartin
#t 2013
#c 14
#! Since 2000, the National Science Foundation's NSDL program has made many direct contributions to digital library research and STEM education. Originally called the National STEM Digital Library (and now National STEM Distributed Learning), the program catalyzed significant technology developments and served to advance state-of-the-art teaching and learning practices during a period of dramatic technological change. This poster describes the results of a three-day writing workshop, convened in April 2012, which generated a retrospective report and a series of interviews on the NSDL building process.

#index 1974580
#* Exploring the usability of folksonomies in the online art museum community
#@ Crystal N. Boston-Clay;Malika Mahoui;Kyle Jaebker
#t 2013
#c 14
#% 855601
#% 1885285
#% 1924137
#! This paper presents a usability evaluation of the Indianapolis Museum of Art website - as a typical art museum website supporting both tag-based search and user tagging of artwork - in an effort to explore how users access artwork while interacting with the museum online search and retrieval system. The usability study examined the extent of usage of Steve Tagger capabilities (annotation and use of tags in the process of searching/accessing artwork resources) deployed on the website. The usability test results showed that 55% of the users were able to successfully locate information on the website using both traditional searching techniques and folksonomies. However, only 34% of the users were able to successfully locate artwork using tags only. On the other hand, 95% of the participants were able to annotate an object by adding a term or tag to describe the artwork.

#index 1974581
#* How do users' search tactic selections influence search outputs in exploratory search tasks?
#@ Soohyung Joo;Iris Xie
#t 2013
#c 14
#% 857477
#% 1213448
#% 1268490
#% 1480202
#% 1714300
#! This study investigates the relationships between users' search tactic selections and search outputs while conducting exploratory searches in digital libraries. Frequencies of different types of search tactics applied in an exploratory search task were counted. Based on correlation analysis and multiple regression analysis, we identified types of search tactics that are associated with aspectual recall. Preliminary results indicate that browsing and evaluating item tactics affect aspectual recall in exploratory search tasks.

#index 1974582
#* The SEAD DataNet prototype: data preservation services for sustainability science
#@ Beth Plale;Robert H. McDonald;Kavitha Chandrasekar;Inna Kouper;Robert Light;Stacy R. Konkiel;Margaret Hedstrom;James Myers;Praveen Kumar
#t 2013
#c 14
#! In this poster we will present the SEAD project [1] and its prototype software and describe how SEAD approaches long-term data preservation and access through multiple partnerships and how it supports sustainability science researchers in their data management, analysis and archival needs. SEAD's initial prototype system currently is being tested by ingesting datasets from the National Center for Earth Surface Dynamics (1.6 terabyte of data containing over 450,000 files) [2] and packaging them for transmission to long-term archival storage.

#index 1974583
#* A roadmap for data services
#@ Inna Kouper;Katherine G. Akers;Natsuko H. Nicholls;Fe C. Sferdean
#t 2013
#c 14
#! This poster describes our experiences as four CLIR/DLF postdoctoral fellows in developing data services at our respective universities. We report on our particular activities and achievements, which we synthesize into a common framework that can guide the development of data services at other academic institutions. The analysis of our experiences suggests the necessity of stronger cooperation of units within universities as well as increased and more diverse collaborations among universities.

#index 1974584
#* A memento web browser for iOS
#@ Heather Tweedy;Frank McCown;Michael L. Nelson
#t 2013
#c 14
#% 1190280
#% 1588365
#% 1974556
#! The Memento framework allows web browsers to request and view archived web pages in a transparent fashion. However, Memento is still in the early stages of adoption, and browser-plugins are often required to enable Memento support. We report on a new iOS app called the Memento Browser, a web browser that supports Memento and gives iPhone and iPad users transparent access to the world's largest web archives.

#index 1974585
#* Semi-automated rediscovery of lost YouTube music videos
#@ Daniel Sebastian;Frank McCown;Michael L. Nelson
#t 2013
#c 14
#% 1065267
#% 1065314
#% 1213418
#% 1434127
#% 1614573
#% 1624245
#! Users frequently post popular material to YouTube, and in response, others link to these videos from social media, blogs, forums, and email. However, this content may be removed for numerous reasons, only to resurface again at another URL. This continuous movement and breaking of the web graph makes it difficult for users to relocate content that has moved in YouTube. We present Volitrax, an add-on for FireFox which redirects users to YouTube music videos that have moved to a different URL within YouTube. Volitrax acts as an intermediary that corrects the web graph transparently so YouTube links continue to work even after the content has changed locations.

#index 1974586
#* Flickr feedback framework: a service model for leveraging user interactions
#@ Jacob Jett;Megan Senseney;Carole L. Palmer
#t 2013
#c 14
#% 1495092
#% 1523543
#! It has been well documented that cultural heritage institutions can enhance their metadata by sharing content through popular web services such as Flickr. Through the Flickr Feasibility Study, the IMLS Digital Collections and Content project examined how an aggregation service can facilitate participation of cultural heritage institutions in popular web services. This poster presents a proposed feedback framework through which an aggregation service can facilitate and increase the impact of Web user interactions with shared cultural heritage collections through direct metadata enhancement and user analysis.

#index 1974587
#* HathiTrust research center: computational access for digital humanities and beyond
#@ Beth Plale;Robert McDonald;Yiming Sun;Inna Kouper;Ryan Cobine;J. Stephen Downie;Beth Sandore Namachchivaya;John Unsworth
#t 2013
#c 14
#! Academic libraries are increasingly looking to provide services that allow their users to work with digital collections in innovative ways, for example, to analyze large volumes of digitized collections. The HathiTrust Research Center (HTRC) is a large collaborative that provides an innovative research infrastructure for dealing with massive amounts of digital texts. In this poster, we report on the technical progress of the HTRC as well as on the efforts to build a user community around our cyberinfrastructure.

#index 1974588
#* Providing context for digital library content
#@ Pamela Campbell;Katrina Stierholz
#t 2013
#c 14
#! In 2004, the Federal Reserve Bank of St. Louis created FRASER (Federal Reserve Archival System for Economic Research, http://fraser.stlouisfed.org), a digital library of economic, financial, and banking data and policy documents. The history of American economic policy is documented in these publications, records, and archival materials. It has become evident that FRASER's growing user base needs additional context to improve users? ability to navigate, select, and understand the continually growing content. We have taken three approaches to improve the accessibility of our content: changes to the database, integration with other web databases, and addition of material to support teaching activities. We hope that these changes will broaden our audience and increase site traffic.

#index 1974589
#* Streamlining user interaction in tag-based conversational navigation of knowledge resource libraries
#@ Jinyue Xia;David C. Wilson
#t 2013
#c 14
#% 136350
#% 418152
#% 449588
#% 478470
#% 490774
#! This paper presents an approach for helping users more quickly discover relevant information resources in a tag based system, where each resource is associated with a number of descriptive meta-data tags. Our approach builds an adaptive conversational decision-tree structure to minimize the number of interactive cues required to help a user navigate to resources of interest. Initial experiments demonstrate the potential of the approach, with shallower decision trees supporting better overall interaction performance.

#index 1974590
#* Using google analytics to explore ETDs use
#@ Midge Coates
#t 2013
#c 14
#% 1065292
#! This poster presents preliminary Google Analytics usage data for a collection of electronic theses and dissertations (ETDs). Correlation of page views with page type, user location, and source (referring link) shows that, during the study period, most in-state users found the collection via internal sources (University links) and viewed mostly home and navigation pages, while most out-of-state users found the collection via external sources (search engines, databases) and viewed mostly bibliographic information pages. Nearly all of those who viewed actual ETDs were out-of-state "direct" users who may have bookmarked the collection during a previous visit.

#index 1974591
#* MOOD-lighting: massive open online discovery using solr and blacklight
#@ Juliet L. Hardesty;Courtney Greene
#t 2013
#c 14
#! In this poster, we present findings from the user experience and metadata perspectives of using Blacklight and Solr to combine large and distinct resource sets. We also share results of a survey of academic and educational institutions on their approaches to Solr indexing and end-user options and identify next steps toward articulating best practices for user experience around discovery in the context of metadata.

#index 1974592
#* Information visualization of nuclear decay chain libraries
#@ Electra Sutton;Charles Wang;David Weisz;Fredric Gey;Ray R. Larson
#t 2013
#c 14
#% 860067
#% 1375918
#% 1924135
#! This poster presents multiple information visualization techniques for scientific visualization of the nuclear isotope decay process, including (but not limited to) circle packing and directed graphs. The practical goal of this visualization process is to support nuclear forensics, the identification of the origin of intercepted smuggled nuclear materials.

#index 1974593
#* Environmental studies faculty attitudes towards sharing of research data
#@ Nathan F. Hall
#t 2013
#c 14
#! This research explores the attitudes of Environmental Studies faculty towards sharing research data. The findings are drawn from a broader unpublished study in progress on information behavior of Environmental Studies faculty in e-science and scholarly communications. The author conducted fourteen semi-structured interviews with tenure-track and tenured faculty in various environmental studies and earth science disciplines at two large state universities. Early findings and areas for further analysis are described.

#index 1974594
#* Formal foundations for systematic digital library generation
#@ Jonathan P. Leidig;Edward A. Fox
#t 2013
#c 14
#% 750866
#% 1090728
#% 1431371
#% 1551326
#% 1898005
#! Many digital library design, development, and deployment processes are not based on systematic generation activities. The utilization of generation processes enables the precise definition of digital libraries, identification of existing software components, co-generation of multiple digital libraries, and evaluation of a digital library's coverage and completeness. The foundation of a digital library generation process is in the formal framework in which it is described. Two notable formal frameworks have previously been proposed for describing digital libraries and their content, architecture, functionality, and related societies. These two frameworks are merged in this effort to provide the foundation for a generation framework in support of an emerging class of scientific digital libraries.

#index 1974595
#* Checking out: customizing and downloading complex and compound digital library resources
#@ Scott Britell;Lois Delcambre
#t 2013
#c 14
#% 1787101
#% 1924165
#% 1943536

#index 1974596
#* OmniMea: an approach to improved content recruitment for institutional repositories
#@ James C. French;Allison L. Powell
#t 2013
#c 14
#! A common complaint of providers of institutional repository services is that they have low utilization by their intended user base. The reasons are varied, but two are germane to our project: lack of individual incentives among potentially participating faculty; and a perceived high barrier to entry. The OmniMea project adopts a user-centric focus by advocating for personal repositories as a more appealing concept and by directing relevant intellectual output placed in these personal repositories to the institutional repository for long-term curation. While our approach was explicitly aimed and capturing long-tail data, it has turned out to be more generally applicable.

#index 1974597
#* Mapping the intersection of science and philosophy
#@ Jaimie Murdock;Robert Light;Colin Allen;Katy Börner
#t 2013
#c 14
#! This poster presents what we believe to be the first attempt to empirically measure and visualize the cross-pollination of science and philosophy through citation patterns. Using the Stanford Encyclopedia of Philosophy as a proxy for the philosophical literature, we plot SEP citations onto the UCSD Map of Science to highlight areas of science which overlap with philosophical discussion. An outline of further studies is also discussed.

#index 1974598
#* The nuestra Iowa project: creating a digital collection as a tool for history education
#@ Audrey Altman;Kelly Thompson;Haowei Hsieh
#t 2013
#c 14
#% 1353996
#! This poster describes the progress of a research project exploring how public digital publishing affects undergraduate research and learning. Participants are students in "Latina/o Immigration", an undergraduate-level history course at the University of Iowa. Students use a custom web interface to create a digital exhibit about the history of Latino/as in Iowa, using multimedia primary-source materials from the Iowa Women's Archives (IWA). Students also use the tool to learn the concepts related to metadata and digital libraries.

#index 1974599
#* The open parks network
#@ Yongyang Yu;Michael Witt;Mohamed Saber Abdelfattah;Christopher Vinson;Scott Hammel
#t 2013
#c 14
#% 1123812
#% 1776062
#% 1787054
#! The goal of the Open Parks Network (OPN) is to create a portal that connects park managers, researchers, policy makers, and citizens to each other and to valuable cultural resources related. Led by Clemson University in collaboration with the National Parks Service and Purdue University, OPN is designed to provide a virtual community of professionals in parks and protected areas with the tools, resources, and knowledge base they need to conduct intensive research, perform their jobs duties effectively, and share information with colleagues and users on an international scale. To date, 80,000 of 200,000 archival images and 500,000 out of 2 million bound pages have been digitized from various parks, and a beta version of the platform will be available for demonstration in March 2013. The project includes the integration of a Fedora repository with the Joomla! content management system with extensions to enable GIS functionality, expose metadata as Linked Data and for harvest using OAI-PMH, and enable users to create their own custom collections.

#index 1974600
#* The new ACM CCS and a computing ontology
#@ Lillian N. Cassel;Sudhamsha Palivela;Srikanth Marepalli;AhiMahidhara Padyala;Rahul Deep;Siddhartha Terala
#t 2013
#c 14
#% 344361
#% 344385
#% 725416
#% 795012
#% 1219996
#% 1493562
#! This poster presents an overview of the new ACM Computing Classification system and compares it with work done in creating an ontology of all computing-related topics. There are similarities and differences and the differences lead to conclusions about both approaches.

#index 1974601
#* Studying the data practices of a scientific community
#@ Besiki Stvilia;Charles C. Hinnant;Shuheng Wu;Adam Worrall;Dong Joon Lee;Kathleen Burnett;Gary Burnett;Michelle M. Kazmer;Paul F. Marty
#t 2013
#c 14
#% 999300
#! To be effective and at the same time sustainable, a community data curation model has to be aligned with the community's current work organization: practices and activities; divisions of labor; data and collaborative relationships; and the community's value structure, norms, and conventions for data, quality assessment, and data sharing. This poster discusses a framework for developing a community data curation model, using a case of the scientific community gathered around the National High Magnetic Field Laboratory, a large national lab. The poster also reports findings of preliminary research based on semi-structured interviews with a sample of the main stakeholder groups of the community.

#index 1974602
#* Recovering missing citations in a scholarly network: a 2-step citation analysis to estimate publication importance
#@ Zhuoren Jiang;Xiaozhong Liu
#t 2013
#c 14
#% 729936
#! Citation relationships between publications are important for assessing the importance of scholarly components (e.g., authors, publications, and venues) within a network. Missing citation metadata in scholarly databases, however, creates problems for classical citation-based ranking algorithms. In the ACM database, for example, 18.5% of publications don't have citation metadata. In this research we propose an innovative, 2-step method of citation analysis, to investigate the importance of publications for which citation data is missing. Preliminary evaluation results show that this method can effectively uncover the importance of publications without using citation metadata.

#index 1974603
#* User interface evaluation of meta-indexes for search
#@ Michael Huggett;Edie Rasmussen
#t 2013
#c 14
#% 56449
#% 1415729
#% 1431397
#% 1787066
#% 1879107
#! In the Indexer's Legacy Project, we have created meta-indexes for domain-oriented collections of digital books in order to promote searching, navigation and browsing in digital collections. Because the meta-index is a new knowledge structure, we have used focus groups and sample tasks to collect information on user's perception and use of meta-indexes. User's responses were positive and their suggestions led to improvements in our online Meta-Dex User Interface (MUI) tool, which will be tested in subsequent user studies.

#index 1974604
#* Modeling search assistance mechanisms within web-scale discovery systems
#@ William H. Mischo;Mary C. Schlembach;Michael A. Norman
#t 2013
#c 14
#% 966981
#% 966993
#! The University of Illinois Library has been conducting transaction log analyses to model user search behaviors within our Library gateway. These analyses have informed the development and implementation of various search assistance mechanisms designed to facilitate search strategy modification and enhance user search navigation methods. This paper discusses the efforts to effectively overlay search assistance mechanisms into the web-scale discovery system environment. These search assistance mechanisms seek to meet user search needs and to address known issues with web-scale systems. This paper describes an evolving search assistance model being deployed in a web-scale environment and reports our findings from transaction log studies and user surveys.

#index 1974605
#* Docear4Word: reference management for microsoft word based on BibTeX and the citation style language (CSL)
#@ Joeran Beel;Marcel Genzmehr;Stefan Langer
#t 2013
#c 14
#% 1588441
#! In this demo-paper we introduce Docear4Word which enables researchers to insert and format their references and bibliographies in Microsoft Word. Docear4Word is based on BibTeX and the Citation Style Language (CSL), features over 1,700 citation styles (Harvard, IEEE, ACM, etc.), is published as open source tool on http://docear.org, and runs with Microsoft Word 2002 (and later) on Windows XP (and later). Docear4Word is similar to the MS-Word add-ons that reference managers like Endnote, Zotero, or Citavi offer with the difference that it is being developed to work with the de-facto standard BibTeX and hence to work with almost any reference manager.

#index 1974606
#* Introducing Docear's research paper recommender system
#@ Joeran Beel;Stefan Langer;Marcel Genzmehr;Andreas Nürnberger
#t 2013
#c 14
#% 252750
#% 760853
#% 967309
#% 1106097
#% 1127486
#% 1588441
#! In this demo paper we present Docear's research paper recommender system. Docear is an academic literature suite to search, organize, and create research articles. The users' data (papers, references, annotations, etc.) is managed in mind maps and these mind maps are utilized for the recommendations. Using content-based filtering methods, Docear's recommender achieves click-through rates around 6%, in some scenarios even over 10%.

#index 1974607
#* CORE: aggregation use cases for open access
#@ Petr Knoth;Zdenek Zdrahal
#t 2013
#c 14
#! The push for free online availability of research outputs promoted by the Open Access (OA) movement is undoubtedly transforming the publishing industry. However, the mere availability of research outputs is insufficient. To exploit the full potential of OA, it must be possible to search, discover, mine, analyse, etc. this content. To achieve this, it is essential to improve the existing OA technical infrastructure to effectively support these functionalities. Many of the vital benefits of OA are expected to come with the ability to reuse OA content in unanticipated ways. Access to the OA content must therefore be flexible, yet practical, content-based and not just metadata based. In this demonstration, we present the CORE system, which aggregates millions of OA resources from hundreds of OA repositories and journals. We discuss the use cases aggregations should support and demonstrate how the CORE system addresses them, including searching, discovering, mining and analyzing content. We also show how aggregated OA content can be reused to build new applications on top of CORE's functionality.

#index 1974608
#* Greenbug: a hybrid web-inspector, debugger and design editor for greenstone
#@ David Bainbridge;Sam J. McIntosh;David M. Nichols
#t 2013
#c 14
#% 967293
#! In this paper we present Greenbug: a hybrid web inspector, debugger and design editor developed for use with the open source digital library software Greenstone 3. Inspired by the web development tool Firebug, Greenbug is more tightly coupled with the underlying (digital library) server than that provided by Firebug; for example, Greenbug has a fine-grained knowledge of the connection between the underlying file system and the rendered web content, and also provides the ability to commit any changes made through the web interface back to the underlying file system. Moreover, because web page production in Greenstone 3 is the result of an XSLT processing pipeline, the necessarily well-formed hierarchical XML content can be manipulated into a graphical representation, which can then be manipulated directly through a visual interface supplied by Greenbug. We showcase the interface in use, provide a brief overview of implementation details, and conclude with a discussion on how the approach can be adapted to other XSLT transformation-based content management systems, such as DSpace.

#index 1974609
#* Docear's PDF inspector: title extraction from PDF files
#@ Joeran Beel;Stefan Langer;Marcel Genzmehr;Christoph Müller
#t 2013
#c 14
#% 614036
#% 881949
#% 1495130
#% 1588441
#! In this demo-paper we present Docear's PDF Inspector (DPI). DPI extracts titles from academic PDF files by applying a simple heuristic: the largest text on the first page of a PDF is assumed to be the title. This simple heuristic achieves accuracies around 70% and outperforms the tools ParsCit and SciPlore Xtract in both run-time and accuracy. In addition, DPI is released under the free open source license GPL 2+ at http://www.docear.org, written in JAVA, and runs on any major operating system.

#index 1974610
#* The avalon media system: a platform for access-controlled delivery of time-based media
#@ Jon W. Dunn;Stuart L. Baker
#t 2013
#c 14
#% 877322
#! This demonstration will show version 1.0 of the Avalon Media System, an open source system being developed by Indiana University and Northwestern University to allow libraries and archives to provide online access to audio and video collections.

#index 1974611
#* FishTraits version 2: integrating ecological, biogeographic and bibliographic information
#@ Zhiwu Xie;Emmanual A. Frimpong;Sunshin Lee
#t 2013
#c 14
#! In this paper we describe the new development of FishTraits. Originating from an ecological database that documents and consolidates more than 100 traits for 809 fish species, the new version focuses on the integration of these traits data with the bibliographic and biogeographic information. We explain the overall design as well as the implementation details.

#index 1974612
#* The digital atlas of American religion
#@ Sharon M. Kandris;Neil Devadasan;Malika Mahoui;David J. Bodenhamer
#t 2013
#c 14
#! In this demonstration-paper we introduce DAAR, the Digital Atlas of American Religion (www.religionatlas.org). The DAAR is a web-based research platform with innovative data exploration and visualization tools to support research in the humanities. Using a user-centered design approach, we incorporated historic religion data on adherence, membership, and congregations with historic census data and new religion typologies as the test-bed for the tools that we developed to establish the technology infrastructure and framework that can be used for other humanities data.

#index 1974613
#* IssueLab: the social sector's digital library
#@ Lisa Brooks;Gabriela Fitz
#t 2013
#c 14
#! In this paper, we describe IssueLab, a digital library and distribution network for social sector publications and resources.

#index 1974614
#* The apollo archive explorer
#@ Douglas W. Oard;Joseph Malionek
#t 2013
#c 14
#! A system for exploring the rich recorded legacy of the Apollo missions to the Moon, using the event structure of each mission as an organizing principle, will be demonstrated. A scalable implementation is achieved by automating temporal, spatial, and topical content alignment across diverse media. Multiple access points are supported, including event-based access through the flight plan, time-based access using event timelines, and content-based access using information retrieval techniques.

#index 2001284
#* Proceedings of the 1st International Workshop on Digital Preservation of Research Methods and Artefacts
#@ Kevin Page;Jun Zhao;David De Roure;Andreas Rauber
#t 2013
#c 14
#! Welcome to DPRMA 2013, the 1st International Workshop on the Digital Preservation of Research Methods and Artefacts. The process of research in both the sciences and humanities has, and continues, to undergo significant change in addressing the needs of our ever more digital world. Researchers are adapting to the opportunities presented by working at scale with increasingly large datasets, creating methodologies and tooling for assistance and automation, and undertaking multidisciplinary collaboration with colleagues and specialisations distributed around the globe. This brings with it challenges for the capture, publication, and preservation of research output. In this world a single document or journal paper perhaps by a single author with a narrow subject focussed bibliography is no longer sufficient for useful encapsulation of the complete research output. This is particularly the case when considering the need to disseminate, reproduce and reuse methods and findings as the foundation of ongoing scholarly research and academic discourse. This first DPRMA workshop will consider how Digital Libraries can adapt to meet these needs. Starting with the complex digital objects needed to store the multiformat artefacts such as datasets, workflows, results and publications, we discuss how they be captured, stored, associated, retrieved, and visualised. Can, or should, Digital Libraries address the needs of scale presented by big data directly and wholly, or play a well-defined role within an ecosystem of interoperable services? What are the challenges for curation of dynamic resources often more akin to software than documents, where iterative experiments comprise of changing datasets, codes, and authors? What additional research context should be preserved in addition to traditional dissemination mechanisms? What models and semantics can capture this context, and what role can provenance, versioning, and dependency analysis play in their preservation? How will researchers access and reuse these preserved artefacts?

