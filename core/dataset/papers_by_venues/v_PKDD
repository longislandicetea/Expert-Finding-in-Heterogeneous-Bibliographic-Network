#index 454495
#* Proceedings of the First European Symposium on Principles of Data Mining and Knowledge Discovery
#@ Henryk Jan Komorowski;Jan M. Zytkow
#t 1997
#c 21

#index 454496
#* Proceedings of the Second European Symposium on Principles of Data Mining and Knowledge Discovery
#@ Jan M. Zytkow;Mohamed Quafafou
#t 1998
#c 21

#index 454497
#* Proceedings of the Third European Conference on Principles of Data Mining and Knowledge Discovery
#@ Jan M. Zytkow;Jan Rauch
#t 1999
#c 21

#index 454498
#* Proceedings of the 4th European Conference on Principles of Data Mining and Knowledge Discovery
#@ Djamel A. Zighed;Henryk Jan Komorowski;Jan M. Zytkow
#t 2000
#c 21
#! From the Publisher: "This book constitutes the refereed proceedings of the 4th European Conference on Principles and Practice of Knowledge Discovery in Databases, PKDD 2000, held in Lyon, France in September 2000. The 86 revised papers included in the book correspond to the 29 oral presentations and 57 posters presented at the conference. They were carefully reviewed and selected from 147 submissions. The book offers topical sections on new directions, rules and trees, databases and reward-based learning, classification, association rules and exceptions, instance-based discovery, clustering, and time series analysis."--BOOK JACKET.

#index 454499
#* Proceedings of the 5th European Conference on Principles of Data Mining and Knowledge Discovery
#@ Luc De Raedt;Arno Siebes
#t 2001
#c 21

#index 454500
#* Proceedings of the 6th European Conference on Principles of Data Mining and Knowledge Discovery
#@ Tapio Elomaa;Heikki Mannila;Hannu Toivonen
#t 2002
#c 21

#index 477466
#* Using Neural Network to Extract Knowledge from Database
#@ Yuanhui Zhou;Yuchang Lu;Chunyi Shi
#t 1997
#c 21

#index 477467
#* techniques and Applications of KDD (Abstract)
#@ Willi Klösgen;Jan M. Zytkow
#t 1997
#c 21

#index 477468
#* Knowledge Discovery - A Control Theory Perspective
#@ Bjarne A. Foss
#t 1997
#c 21

#index 477469
#* Recognizing Reliability of Discovered Knowledge
#@ Petr Berka
#t 1997
#c 21

#index 477470
#* On Meta Levels of an Organized Society of KDD Agents
#@ Ning Zhong;Setsuo Ohsuga;Chunnian Liu;Yoshitsugu Kakemoto;Xiaosong Zhang
#t 1997
#c 21

#index 477471
#* Generation of Rules from Incomplete Information Systems
#@ Marzena Kryszkiewicz
#t 1997
#c 21

#index 477472
#* The Pronciple of Transformation between Efficiency and Effectiveness: Towards a Fair Evaluation of the Cost-Effectiveness of KDD Techniques
#@ Alex Alves Freitas
#t 1997
#c 21

#index 477473
#* Attribute Discovery and Rough Sets
#@ Jaroslaw Stepaniuk
#t 1997
#c 21

#index 477474
#* Extraction of Experts' Decision Process from Clinical Databases Using Rough Set Model
#@ Shusaku Tsumoto
#t 1997
#c 21

#index 477475
#* TOAS Intelligence Mining; Analysis of Natural Language Processing and Computational Linguistics
#@ Robert J. Watts;Alan L. Porter;Scott Cunningham;Donghua Zhu
#t 1997
#c 21

#index 477476
#* Knowledge Discovery from Software Engineering Data: Rough Set Analysis and Its Interaction with Goal-Oriented Measurement
#@ Günther Ruhe
#t 1997
#c 21

#index 477477
#* SNOUT: An Intelligent Assistant for Exploratory Data Anaylsis
#@ P. D. Scott;A. P. M. Coxon;M. H. Hobbs;R. J. Williams
#t 1997
#c 21

#index 477478
#* Algorithms for Constructing of Decision Trees
#@ Mikhail Moshkov
#t 1997
#c 21

#index 477479
#* Finding Similar Time Series
#@ Gautam Das;Dimitrios Gunopulos;Heikki Mannila
#t 1997
#c 21

#index 477480
#* Parallel Knowledge Discovery Using Domain Generalization Graphs
#@ Robert J. Hilderman;Howard J. Hamilton;Robert J. Kowalchuk;Nick Cercone
#t 1997
#c 21

#index 477481
#* Logical Calculi for Knowledge Discovery in Databases
#@ Jan Rauch
#t 1997
#c 21

#index 477482
#* Using Signature Files for Querying Time-Series Data
#@ Henrik André-Jönsson;Dushan Z. Badal
#t 1997
#c 21

#index 477483
#* Efficient Multisplitting on Numerical Data
#@ Tapio Elomaa;Juho Rousu
#t 1997
#c 21

#index 477484
#* Discovery of Health Risks and Case-Based Forecasting of Epidemics in a Health Surveillance System
#@ Mathias Bull;Günther Kundt;Lothar Gierl
#t 1997
#c 21

#index 477485
#* Pattern Based Browsing in Document Collections
#@ Ronen Feldman;Willi Klösgen;Yaniv Ben-Yehuda;Gil Kedar;Vladimir Reznikov
#t 1997
#c 21

#index 477486
#* Modelling Customer Retention with Rough Data Models
#@ Wojciech Kowalczyk;Frank Slisser
#t 1997
#c 21

#index 477487
#* Regression-Based Classification Methods and Their Comparisons with Desision Tree Algorithms
#@ Mikhail V. Kiselev;Sergei M. Ananyan;Sergei B. Arseniev
#t 1997
#c 21

#index 477488
#* Exploratory Analysis of Biochemical Processes Using Hybrid Modeling Methods
#@ Rimvydas Simutis
#t 1997
#c 21

#index 477489
#* Rough Sets for Data Mining and Knowledge Discovery (Abstract)
#@ Henryk Jan Komorowski;Lech Polkowski;Andrzej Skowron
#t 1997
#c 21

#index 477490
#* Induction of Strong Feature Subsets
#@ Mohamed Quafafou;Moussa Boussouf
#t 1997
#c 21

#index 477491
#* Towards Process-Oriented Tool Support for Knowledge Discovery in Databases
#@ Rüdiger Wirth;Colin Shearer;Udo Grimmer;Thomas P. Reinartz;Jörg Schlösser;Christoph Breitner;Robert Engels;Guido Lindner
#t 1997
#c 21

#index 477492
#* Searching for Relational Patterns in Data
#@ Sinh Hoa Nguyen;Andrzej Skowron
#t 1997
#c 21

#index 477493
#* Data Mining in the Telecommunications Industry (Abstract)
#@ Leo Carbonara;Huw Roberts;Blaise Egan
#t 1997
#c 21

#index 477494
#* A New and Versatile Method for Association Generation
#@ Amihood Amir;Ronen Feldman;Reuven Kashi
#t 1997
#c 21

#index 477495
#* Finding Spatial Clusters
#@ Friedrich Gebhardt
#t 1997
#c 21

#index 477496
#* Interactive Interpretation of Hierarchical Clustering
#@ Eric Boudaillier;Georges Hebrail
#t 1997
#c 21

#index 477497
#* An Algorithm for Multi-relational Discovery of Subgroups
#@ Stefan Wrobel
#t 1997
#c 21

#index 477498
#* Exploration of Document Collections with Self-Organizing Maps: A Novel Approach to Similarity Representation
#@ Dieter Merkl
#t 1997
#c 21

#index 477499
#* Mining Time Series Using Rough Sets - A Case Study
#@ Anders Torvill Bjorvand
#t 1997
#c 21

#index 477622
#* Rough Set Theory and Rule Induction Techniques for Discovery of Attribute Dependencies in Medical Information Systems
#@ Jerzy Stefanowski;Krzysztof Slowinski
#t 1997
#c 21

#index 477623
#* Bivariate Decision Trees
#@ Jan C. Bioch;Onno van der Meer;Rob Potharst
#t 1997
#c 21

#index 477624
#* Share Based Measures for Itemsets
#@ Colin L. Carter;Howard J. Hamilton;Nick Cercone
#t 1997
#c 21

#index 477625
#* Induction of Fuzzy Characteristic Rules
#@ Dan Rasmussen;Ronald R. Yager
#t 1997
#c 21

#index 477626
#* Clustering Techniques in Biological Sequence Analysis
#@ Anna M. Manning;Andy Brass;Carole A. Goble;John A. Keane
#t 1997
#c 21

#index 477627
#* Mining in the Phrasal Frontier
#@ Helena Ahonen;Oskari Heinonen;Mika Klemettinen;A. Inkeri Verkamo
#t 1997
#c 21

#index 477628
#* A Connectionist Approach to Structural Simiarity Determination as a Basis of Clustering, Classification and Feature Detection
#@ Kristina Schädler;Fritz Wysotzki
#t 1997
#c 21

#index 477629
#* Efficient Construction of Comprehensible Hierarchical Clusterings
#@ Luis Talavera;Javier Béjar
#t 1998
#c 21

#index 477630
#* CLASITEX: A Tool for Knowledge Discovery from Texts
#@ José Francisco Martínez Trinidad;Beatriz Beltrán Martínez;Adolfo Guzmán-Arenas;José Ruiz-Shulcloper
#t 1998
#c 21

#index 477631
#* Scalable, High-Performance Data Mining with Parallel Processing
#@ Alex Alves Freitas
#t 1998
#c 21

#index 477632
#* Resampling in an Indefinite Database to Approximate Functional Dependencies
#@ Ethan Collopy;Mark Levene
#t 1998
#c 21

#index 477633
#* Interactive Visualization for Predictive Modelling with Decision Tree Induction
#@ Tu Bao Ho;Trong Dung Nguyen
#t 1998
#c 21

#index 477634
#* Overcoming Fragmentation in Decision Trees Through Attribute Value Grouping
#@ K. M. Ho;P. D. Scott
#t 1998
#c 21

#index 477635
#* Knowledge Discovery with Qualitative Influences and Synergies
#@ Jesús Cerquides;Ramon López de Mántaras
#t 1998
#c 21

#index 477636
#* Representative Association Rules and Minimum Condition Maximum Consequence Association Rules
#@ Marzena Kryszkiewicz
#t 1998
#c 21

#index 477637
#* Discretization and Grouping: Preprocessing Steps for Data Mining
#@ Petr Berka;Ivan Bruha
#t 1998
#c 21

#index 477638
#* Discovery of Approximate Medical Knowledge Based on Rough Set Model
#@ Shusaku Tsumoto
#t 1998
#c 21

#index 477639
#* Data Transformation and Rough Sets
#@ Jaroslaw Stepaniuk;Marcin Maj
#t 1998
#c 21

#index 477640
#* Inducing Cost-Sensitive Trees via Instance Weighting
#@ Kai Ming Ting
#t 1998
#c 21

#index 477641
#* Practical Text Mining
#@ Ronen Feldman
#t 1998
#c 21

#index 477642
#* Text Mining at the Term Level
#@ Ronen Feldman;Moshe Fresko;Yakkov Kinar;Yehuda Lindell;Orly Liphstat;Martin Rajman;Yonatan Schler;Oren Zamir
#t 1998
#c 21

#index 477643
#* Language Support for Temporal Data Mining
#@ Xiaodong Chen;Ilias Petrounias
#t 1998
#c 21

#index 477644
#* From the Data Mine to the Knowledge Mill: Applying the Principles of Lexical Analysis to the Data Mining and Knowledge Discovery Process
#@ Jean Moscarola;Richard Bolden
#t 1998
#c 21

#index 477645
#* Industrial Applications of Data Mining
#@ Gholamreza Nakhaeizadeh
#t 1998
#c 21

#index 477646
#* For Visualization-Based Analysis Tools in Knowledge Discovery Process: A Multilayer Perceptron versus Principal Components Analysis: A Comparative Study
#@ Xavier Polanco;Claire Francois;Mohamed Aly Ould Louly
#t 1998
#c 21

#index 477647
#* Preprocessing of Missing Values Using Robust Association Rules
#@ Arnaud Ragel
#t 1998
#c 21

#index 477648
#* A Hybrid Approach to Feature Selection
#@ Moussa Boussouf
#t 1998
#c 21

#index 477649
#* Classes of Four-Fold Table Quantifiers
#@ Jan Rauch
#t 1998
#c 21

#index 477650
#* Data Mining at a Major Bank: Lessons from a Large Marketing Application
#@ Petra Hunziker;Andreas Maier;Alex Nippe;Markus Tresch;Douglas Weers;Peter Zemp
#t 1998
#c 21

#index 477651
#* Postponing the Evaluation of Attributes with a High Number of Boundary Points
#@ Tapio Elomaa;Juho Rousu
#t 1998
#c 21

#index 477652
#* Exploratory Attributes Search for Time-Series Data: An Experimental System for Agricultural Application
#@ Kazunori Matsumoto
#t 1998
#c 21

#index 477653
#* Trend Graphs: Visualizing the Evolution of Concept Relationships in Large Document Collections
#@ Ronen Feldman;Yonatan Aumann;Amir Zilberstein;Yaron Ben-Yehuda
#t 1998
#c 21

#index 477654
#* Ranked Rules and Data Visualization
#@ Leon Bobrowski;Tomasz Sowinski
#t 1998
#c 21

#index 477655
#* PolyAnalyst Data Analysis Technique and Its Specialization for Processing Data Organized as a Set of Attribute Values
#@ Mikhail V. Kiselev;Sergei M. Ananyan;Sergei B. Arseniev
#t 1998
#c 21

#index 477656
#* A New Algorithm for Faster Mining of Generalized Association Rules
#@ Jochen Hipp;Andreas Myka;Rüdiger Wirth;Ulrich Güntzer
#t 1998
#c 21

#index 477657
#* Similarity-Driven Sampling for Data Mining
#@ Thomas P. Reinartz
#t 1998
#c 21

#index 477658
#* Model Switching for Bayesian Classification Trees with Soft Splits
#@ Jörg Kindermann;Gerhard Paass
#t 1998
#c 21

#index 477659
#* TextVis: An Integrated Visual Environment for Text Mining
#@ David Landau;Ronen Feldman;Yonatan Aumann;Moshe Fresko;Yehuda Lindell;Orly Liphstat;Oren Zamir
#t 1998
#c 21

#index 477660
#* Extended Functional Dependencies as a Basis for Linguistic Summaries
#@ Patrick Bosc;Ludovic Lietard;Olivier Pivert
#t 1998
#c 21

#index 477661
#* Conceptual Knowledge Discovery in Databases Using Formal Concept Analysis Methods
#@ Gerd Stumme;Rudolf Wille;Uta Wille
#t 1998
#c 21

#index 477784
#* Discovery of Surprising Exception Rules Based on Intensity of Implication
#@ Einoshin Suzuki;Yves Kodratoff
#t 1998
#c 21

#index 477785
#* Discovery of Common Subsequences in Cognitive Evoked Potentials
#@ Arthur Flexer;Herbert Bauer
#t 1998
#c 21

#index 477786
#* Improving the Discovery of Association Rules with Intensity of Implication
#@ Sylvie Guillaume;Fabrice Guillet;Jacques Philippe
#t 1998
#c 21

#index 477787
#* Knowledge Discovery with Clustering Based on Rules. Interpreting Results
#@ Karina Gibert;Tomàs Aluja;Ulises Cortés
#t 1998
#c 21

#index 477788
#* Knowledge Discovery in Spatial Data by Means of ILP
#@ Lubos Popelínsky
#t 1998
#c 21

#index 477789
#* Detection of Interdependences in Attribute Selection
#@ Javier Lorenzo;Mario Hernández;Juan Méndez
#t 1998
#c 21

#index 477790
#* Querying Inductive Databases: A Case Study on the MINE RULE Operator
#@ Jean-Francois Boulicaut;Mika Klemettinen;Heikki Mannila
#t 1998
#c 21

#index 477791
#* The PSP Approach for Mining Sequential Patterns
#@ Florent Masseglia;Fabienne Cathala;Pascal Poncelet
#t 1998
#c 21

#index 477792
#* A Metric for Selection of the Most Promising Rules
#@ Pedro Gago;Carlos Bento
#t 1998
#c 21

#index 477793
#* A Procedure to Compute Prototypes for Data Mining in Non-structured Domains
#@ Juan Méndez;Mario Hernández;Javier Lorenzo
#t 1998
#c 21

#index 477794
#* Discovery of Diagnostic Patterns from Protein Sequence Databases
#@ Björn Olsson;Kim Laurio
#t 1998
#c 21

#index 477795
#* Fuzzy Spatial OQL for Fuzzy Knowledge Discovery in Databases
#@ Nara Martini Bigolin;Christophe Marsala
#t 1998
#c 21

#index 477796
#* Handling KDD Process Changes by Incremental Replanning
#@ Ning Zhong;Chunnian Liu;Yoshitsugu Kakemoto;Setsuo Ohsuga
#t 1998
#c 21

#index 477797
#* Knowledge Discovery from Client-Server Databases
#@ Neil Dewhurst;Simon H. Lavington
#t 1998
#c 21

#index 477798
#* Modeling the Business Process by Mining Multiple Databases
#@ Arun P. Sanjeev;Jan M. Zytkow
#t 1998
#c 21

#index 477799
#* Discovery of Decision Rules from Databases: An Evolutionary Approach
#@ Wojciech Kwedlo;Marek Kretowski
#t 1998
#c 21

#index 477800
#* A Relational Data Mining Tool Based On Genetic Programming
#@ Lionel Martin;Frédéric Moal;Christel Vrain
#t 1998
#c 21

#index 477801
#* Cost Sensitive Discretization of Numeric Attributes
#@ Tom Brijs;Koen Vanhoof
#t 1998
#c 21

#index 477802
#* Generalization Lattices
#@ Howard J. Hamilton;Robert J. Hilderman;Liangchun Li;Dee Jay Randall
#t 1998
#c 21

#index 477803
#* Using Loglinear Clustering for Subcategorization Identification
#@ Nuno Miguel Marques;José Gabriel Pereira Lopes;Carlos Agra Coelho
#t 1998
#c 21

#index 477804
#* An Innovative GA-Based Decision Tree Classifier in Large Scale Data Mining
#@ Zhiwei Fu
#t 1999
#c 21

#index 477805
#* Automated Discovery of Rules and Exeptions from Distributed Databases Using Aggregates
#@ Rónán Páircéir;Sally I. McClean;Bryan W. Scotney
#t 1999
#c 21

#index 477806
#* Applying Data Mining Techniques to Wafer Manufacturing
#@ Elisa Bertino;Barbara Catania;Eleonora Caglio
#t 1999
#c 21

#index 477807
#* Using Genetic Algorithms to Evolve a Rule Hierarchy
#@ Robert Cattral;Franz Oppacher;Dwight Deugo
#t 1999
#c 21

#index 477808
#* Rule Induction in Cascade Model Based on Sum of Squares Decomposition
#@ Takashi Okada
#t 1999
#c 21

#index 477809
#* Unsupervised Profiling for Identifying Superimposed Fraud
#@ Uzi Murad;Gadi Pinkas
#t 1999
#c 21

#index 477810
#* Logics and Statistics for Association Rules and Beyond Abstract of Tutorial
#@ Petr Hájek;Jan Rauch
#t 1999
#c 21

#index 477811
#* Relational Learning and Inductive Logic Programming Made Easy Abstract of Tutorial
#@ Luc De Raedt;Hendrik Blockeel
#t 1999
#c 21

#index 477812
#* Mining Text Archives: Creating Readable Maps to Structure and Describe Document Collections
#@ Andreas Rauber;Dieter Merkl
#t 1999
#c 21

#index 477813
#* Peculiarity Oriented Multi-database Mining
#@ Ning Zhong;Y. Y. Yao;Setsuo Ohsuga
#t 1999
#c 21

#index 477814
#* Learning of Simple Conceptual Graphs from Positive and Negative Examples
#@ Sergei O. Kuznetsov
#t 1999
#c 21

#index 477815
#* Discovering Rules in Information Trees
#@ Zbigniew W. Ras
#t 1999
#c 21

#index 477816
#* Enhancing Rule Interestingness for Neuro-fuzzy Systems
#@ Thomas Wittmann;Johannes Ruhland;Matthias Eichholz
#t 1999
#c 21

#index 477817
#* Circle Graphs: New Visualization Tools for Text-Mining
#@ Yonatan Aumann;Ronen Feldman;Yaron Ben Yehuda;David Landau;Orly Lipshtat;Yonatan Schler
#t 1999
#c 21

#index 477818
#* A Divise Initialisation Method for Clustering Algorithms
#@ Clara Pizzuti;Domenico Talia;Giorgio Vonella
#t 1999
#c 21

#index 477819
#* Maintenance of Discovered Knowledge
#@ Michal Pechoucek;Olga Stepánková;Petr Miksovský
#t 1999
#c 21

#index 477820
#* Support Vector Machines for Knowledge Discovery
#@ Shinsuke Sugaya;Einoshin Suzuki;Shusaku Tsumoto
#t 1999
#c 21

#index 477821
#* OPTICS-OF: Identifying Local Outliers
#@ Markus M. Breunig;Hans-Peter Kriegel;Raymond T. Ng;Jörg Sander
#t 1999
#c 21

#index 477822
#* An Application of Data Mining to the Problem of the University Students' Dropout Using Markov Chains
#@ S. Massa;P. P. Puliafito
#t 1999
#c 21

#index 477823
#* Query Languages for Knowledge Discovery in Databases
#@ Jean-Francois Boulicaut
#t 1999
#c 21

#index 477824
#* Classification Algorithms Based on Linear Combinations of Features
#@ Dominik Slezak;Jakub Wroblewski
#t 1999
#c 21

#index 477825
#* The Haar Wavelet Transform in the Time Series Similarity Paradigm
#@ Zbigniew R. Struzik;Arno Siebes
#t 1999
#c 21

#index 477947
#* On the Consistency of Information Filters for Lazy Learning Algorithms
#@ Henry Brighton;Chris Mellish
#t 1999
#c 21

#index 477948
#* Rule Discovery in Large Time-Series Medical Databases
#@ Shusaku Tsumoto
#t 1999
#c 21

#index 477949
#* Discovery of "Interesting" Data Dependencies from a Workload of SQL Statements
#@ Stéphane Lopes;Jean-Marc Petit;Farouk Toumani
#t 1999
#c 21

#index 477950
#* Contribution of Boosting in Wrapper Models
#@ Marc Sebban;Richard Nock
#t 1999
#c 21

#index 477951
#* Querying Inductive Databases via Logic-Based User-Defined Aggregates
#@ Fosca Giannotti;Giuseppe Manco
#t 1999
#c 21

#index 477952
#* Mining Temporal Features in Association Rules
#@ Xiaodong Chen;Ilias Petrounias
#t 1999
#c 21

#index 477953
#* Boolean Reasoning Scheme with Some Applications in Data Mining
#@ Andrzej Skowron;Hung Son Nguyen
#t 1999
#c 21

#index 477954
#* Towards Discovery of Information Granules
#@ Andrzej Skowron;Jaroslaw Stepaniuk
#t 1999
#c 21

#index 477955
#* Studying the Behavior of Generalized Entropy in Induction Trees Using a M-of-N Concept
#@ R. Rakotomalala;Stéphane Lallich;S. Di Palma
#t 1999
#c 21

#index 477956
#* Bisiness Focused Evaluation Methods: A Case Study
#@ Piew Datta
#t 1999
#c 21

#index 477957
#* Efficient Mining of High Confidience Association Rules without Support Thresholds
#@ Jinyan Li;Xiuzhen Zhang;Guozhu Dong;Kotagiri Ramamohanarao;Qun Sun
#t 1999
#c 21

#index 477958
#* A Comparison of Model Selection Procedures for Predicting Turning Points in Financial Time Series
#@ Thorsten Podding;Claus Huber
#t 1999
#c 21

#index 477959
#* Analyzing an Email Collection Using Formal Concept Analysis
#@ Richard J. Cole, II;Peter W. Eklund
#t 1999
#c 21

#index 477960
#* ZigZag, a New Clustering Algorithm to Analyze Categorical Variable Cross-Classification Tables
#@ Stéphane Lallich
#t 1999
#c 21

#index 477961
#* Discovering and Visualizing Attribute Associations Using Bayesian Networks and Their Use in KDD
#@ Gou Masuda;Rei Yano;Norihiro Sakamoto;Kazuo Ushijima
#t 1999
#c 21

#index 477962
#* Heuristic Measures of Interestingness
#@ Robert J. Hilderman;Howard J. Hamilton
#t 1999
#c 21

#index 477963
#* Efficient Shared Near Neighbours Clustering of Large Metric Data Sets
#@ Stefano Lodi;Luisella Reami;Claudio Sartori
#t 1999
#c 21

#index 477964
#* On the Use of Self-Organizing Maps for Clustering and Visualization
#@ Arthur Flexer
#t 1999
#c 21

#index 477965
#* Data Mining for Robust Business Intelligence Solutions
#@ Jan Mrazek
#t 1999
#c 21

#index 477966
#* The Improvement of Response Modeling: Combining Rule-Induction and Case-Based Reasoning
#@ Filip Coenen;Gilbert Swinnen;Koen Vanhoof;Geert Wets
#t 1999
#c 21

#index 477967
#* LA - A Clustering Algorithm with an Automated Selection of Attributes, wich is Invariant to Functional Transformations of Coordinates
#@ Mikhail V. Kiselev;Sergei M. Ananyan;Sergei B. Arseniev
#t 1999
#c 21

#index 477968
#* Scaling up Dynamic Time Warping to Massive Dataset
#@ Eamonn J. Keogh;Michael J. Pazzani
#t 1999
#c 21

#index 477969
#* Selective Propositionalization for Relational Learning
#@ Érick Alphonse;Céline Rouveirol
#t 1999
#c 21

#index 477970
#* Regression by Feature Projections
#@ Ilhan Uysal;H. Altay Güvenir
#t 1999
#c 21

#index 477971
#* Text Mining via Information Extraction
#@ Ronen Feldman;Yonatan Aumann;Moshe Fresko;Orly Lipshtat;Binyamin Rosenfeld;Yonatan Schler
#t 1999
#c 21

#index 477972
#* A Logical Approach to Fuzzy Data Analysis
#@ Churn-Jung Liau;Duen-Ren Liu
#t 1999
#c 21

#index 477973
#* Experiments on a Representation-Independent "Top-Down and Prune" Induction Scheme
#@ Richard Nock;Marc Sebban;Pascal Jappy
#t 1999
#c 21

#index 477974
#* The ESPRIT Project CreditMine and Its Relevance for the Internet Market
#@ Susanne Köhler;Michael Krieger
#t 1999
#c 21

#index 477975
#* Taming Large Rule Models in Rough Set Approaches
#@ Thomas Ågotnes;Henryk Jan Komorowski;Terje Løken
#t 1999
#c 21

#index 477976
#* On the Correspondence between Classes of Implicational and Equivalence Quantifiers
#@ Jirí Ivánek
#t 1999
#c 21

#index 477977
#* Learning from Highly Structured Data by Decomposition
#@ René Mac Kinney-Romero;Christophe G. Giraud-Carrier
#t 1999
#c 21

#index 477978
#* Multi-relational Decision Tree Induction
#@ Arno J. Knobbe;Arno Siebes;Danïel van der Wallen
#t 1999
#c 21

#index 477979
#* Data Mining for the Web
#@ Myra Spiliopoulou
#t 1999
#c 21

#index 477980
#* Simultaneous Prediction of Mulriple Chemical Parameters of River Water Quality with TILDE
#@ Hendrik Blockeel;Saso Dzeroski;Jasna Grbovic
#t 1999
#c 21

#index 477981
#* Taxonomy Formation by Approximate Equivalence Relations, Revisited
#@ F. A. El-Mouadib;J. Koronacki;Jan M. Zytkow
#t 1999
#c 21

#index 477982
#* Optimizing Disjunctive Association Rules
#@ Dmitry Zelenko
#t 1999
#c 21

#index 477983
#* Adding Temporal Semantics to Association Rules
#@ Chris P. Rainsford;John F. Roddick
#t 1999
#c 21

#index 477984
#* TopCat: Data Mining for Topic Identification in a Text Corpus
#@ Chris Clifton;Robert Cooley
#t 1999
#c 21

#index 477985
#* Managing Interesting Rules in Sequence Mining
#@ Myra Spiliopoulou
#t 1999
#c 21

#index 477986
#* Handling Missing Data in Trees: Surrogate Splits or Statistical Imputation
#@ A. J. Feelders
#t 1999
#c 21

#index 477987
#* Neuro-fuzzy Data Mining for Target Group Selection in Retail Banking
#@ Johannes Ruhland;Thomas Wittmann
#t 1999
#c 21

#index 478104
#* Mining Lemma Disambiguation Rules from Czech Corpora
#@ Lubos Popelínsky;Tomás Pavelek
#t 1999
#c 21

#index 478105
#* A Fuzzy Beam-Search Rule Induction Algorithm
#@ Christina S. Fertig;Alex Alves Freitas;Lucia V. R. Arruda;Celso A. A. Kaestner
#t 1999
#c 21

#index 478106
#* Selection and Statistical Validation of Features and Prototypes
#@ Marc Sebban;Djamel A. Zighed;S. Di Palma
#t 1999
#c 21

#index 478107
#* Experiments in Meta-level Learning with ILP
#@ Ljupco Todorovski;Saso Dzeroski
#t 1999
#c 21

#index 478108
#* Rough Dependencies as a Particular Case of Correlation: Application to the Calculation of Approximative Reducts
#@ María C. Fernández-Baizán;Ernestina Menasalvas Ruiz;José M. Peña Sánchez;Socorro Millán;Eloina Mesa
#t 1999
#c 21

#index 478109
#* Combining Data and Knowledge by MaxEnt-Optimization of Probability Distributions
#@ Wolfgang Ertel;Manfred Schramm
#t 1999
#c 21

#index 478110
#* Mining Possibilistic Set-Valued Rules by Generating Prime Disjunctions
#@ Alexandr A. Savinov
#t 1999
#c 21

#index 478111
#* Extension to C-means Algorithm for the Use of Similarity Functions
#@ Javier Raymundo García-Serrano;José Francisco Martínez Trinidad
#t 1999
#c 21

#index 478112
#* AST: Support for Algorithm Selection with a CBR Approach
#@ Guido Lindner;Rudi Studer
#t 1999
#c 21

#index 478113
#* Association Rule Selection in a Data Mining Environment
#@ Mika Klemettinen;Heikki Mannila;A. Inkeri Verkamo
#t 1999
#c 21

#index 478114
#* Predicting Chemical Carcinogenesis Using Structural Information Only
#@ Claire J. Kennedy;Christophe G. Giraud-Carrier;Douglas W. Bristol
#t 1999
#c 21

#index 478115
#* Combinatorial Approach for Data Binarization
#@ Eddy Mayoraz;Miguel Moreira
#t 1999
#c 21

#index 478116
#* An Evolutionary Algorithm Using Multivariate Discretization for Decision Rule Induction
#@ Wojciech Kwedlo;Marek Kretowski
#t 1999
#c 21

#index 478117
#* Generating Linguistic Fuzzy Rules for Pattern Classification with Genetic Algorithms
#@ N. Xiong;Lothar Litz
#t 1999
#c 21

#index 478118
#* Automated Discovery of Polynomials by Inductive Genetic Programming
#@ Nikolay I. Nikolaev;Hitoshi Iba
#t 1999
#c 21

#index 478119
#* A User-Driven Process for Mining Association Rules
#@ Pascale Kuntz;Fabrice Guillet;Rémi Lehn;Henri Briand
#t 2000
#c 21
#% 176999
#% 232106
#% 232108
#% 232110
#% 232136
#% 278289
#% 305628
#% 443086
#% 477786
#% 563596
#! This paper describes the components of a human-centered process for discovering association rules where the user is considered as a heuristic which drives the mining algorithms via a well-adapted interface. In this approach, inspired by experimental works on behaviors during a discovery stage, the rule extraction is dynamic : at each step, the user can focus on a subset of potentially interesting items and launch an algorithm for extracting the relevant associated rules according to statistical measures. The discovered rules are represented by a graph updated at each step, and the mining algorithm is an adaptation of the well-known A Priori algorithm where rules are computed locally. Experimental results on a real corpus built from marketing data illustrate the different steps of this process.

#index 478120
#* Context-Based Similarity Measures for Categorical Databases
#@ Gautam Das;Heikki Mannila
#t 2000
#c 21
#% 191581
#% 210173
#% 227857
#% 232117
#% 249110
#% 280419
#% 282905
#% 460862
#% 479659
#% 480964
#% 481281
#% 481609
#% 481758
#% 534183
#% 631985
#% 741081
#! Similarity between complex data objects is one of the central notions in data mining. We propose certain similarity (or distance) measures between various components of a 0/1 relation. We define measures between attributes, between rows, and between subrelations of the database. They find important applications in clustering, classification, and several other data mining processes. Our measures are based on the contexts of individual components. For example, two products (i.e., attributes) are deemed similar if their respective sets of customers (i.e., subrelations) are similar. This reveals more subtle relationships between components, something that is usually missing in simpler measures. Our problem of finding distance measures can be formulated as a system of nonlinear equations. We present an iterative algorithm which, when seeded with random initial values, converges quickly to stable distances in practice (typically requiring less than five iterations). The algorithm requires only one database scan. Results on artificial and real data show that our method is efficient, and produces results with intuitive appeal.

#index 478121
#* Accurate Recasting of Parameter Estimation Algorithms Using Sufficient Statistics for Efficient Parallel Speed-Up: Demonstrated for Center-Based Data Clustering Algorithms
#@ Bin Zhang;Meichun Hsu;George Forman
#t 2000
#c 21
#% 95989
#% 114667
#% 140385
#% 183231
#% 210173
#% 220706
#% 269825
#! Fueled by advances in computer technology and online business, data collection is rapidly accelerating, as well as the importance of its analysis--data mining. Increasing database sizes strain the scalability of many data mining algorithms. Data clustering is one of the fundamental techniques in data mining solutions. The many clustering algorithms developed face new challenges with growing data sets. Algorithms with quadratic or higher computational complexity, such as agglomerative algorithms, drop out quickly. More efficient algorithms, such as K-Means EM with linear cost per iteration, still need work to scale up to large data sets. This paper shows that many parameter estimation algorithms, including K-Means, K-Harmonic Means and EM, can be recast without approximation in terms of Sufficient Statistics, yielding an superior speed-up efficiency. Estimates using today's workstations and local area network technology suggest efficient speed-up to several hundred computers, leading to effective scale-up for clustering hundreds of gigabytes of data. Implementation of parallel clustering has been done in a parallel programming language, ZPL. Experimental results show above 90% utilization.

#index 478122
#* Empirical Evaluation of Feature Subset Selection Based on a Real-World Data Set
#@ Petra Perner;Chidanand Apté
#t 2000
#c 21
#% 80995
#% 92537
#% 136350
#% 170393
#% 177826
#! Selecting the right set of features for classification is one of the most important problems in designing a good classifier. Decision tree induction algorithms such as C4.5 have incorporated in their learning phase an automatic feature selection strategy while some other statistical classification algorithm require the feature subset to be selected in a preprocessing phase. It is well know that correlated and irrelevant features may degrade the performance of the C4.5 algorithm. In our study, we evaluated the influence of feature preselection on the prediction accuracy of C4.5 using a real-world data set. We observed that accuracy of the C4.5 classifier can be improved with an appropriate feature preselection phase for the learning algorithm.

#index 478123
#* Discovery of Ambiguous Patterns in Sequences: Application to Bioinformatics
#@ Gerard Ramstein;Pascal Bunelle;Yannick Jacques
#t 2000
#c 21
#% 459006
#% 463903
#! An important issue in data mining concerns the discovery of patterns presenting a user-specified minimum support. We generalize this problematics by introducing the concept of ambiguous event. An ambiguous event can be substituated for another without modifying the substance of the concerned pattern. For instance, in molecular biology, researchers attempt to identify conserved patterns in a family of proteins for which they know that they have evolved from a common ancestor. Such patterns are flexible in the sense that some residues may have been substituated for others during evolution. A[B C] is an example of notation of an ambiguous pattern representing the event A, followed by either the event B or C. A new scoring scheme is proposed for the computation of the frequency of ambiguous patterns, based on substitution matrices. A substitution matrix expresses the probability of the replacement of an event by another. We propose to adapt the Winepi algorithm [1] to ambiguous events. Finally, we give an application to the discovery of conserved patterns in a particular family of proteins, the cytokine receptors.

#index 478124
#* Discovering Association Rules in Large, Dense Databases
#@ Tudor Teusan;Gilles Nachouki;Henri Briand;Jacques Philippe
#t 2000
#c 21
#% 152934
#% 201894
#% 280436
#% 280487
#% 369236
#% 420067
#% 462238
#% 481290
#% 481754
#% 631970
#! In this paper we propose an approach for mining association rules in large, dense databases. For finding such rules, frequent itemsets must first be discovered. As finding all the frequent itemsets is very time-consuming for dense databases, we propose an algorithm that is able to quickly discover an image of the complete set containing all the frequent itemsets. We define what an image is, and we present a genetic algorithm for discovering such an image. To monitor the discovery process we introduce the notion of dynamics of the algorithm. To measure the performances of our frequent itemsets discovery algorithm, we introduce the notion of efficiency of the discovery process.

#index 478125
#* Using Background Knowledge as a Bias to Control the Rule Discovery Process
#@ Ning Zhong;Juzhen Dong;Setsuo Ohsuga
#t 2000
#c 21
#% 136350
#% 449588
#% 452747
#! This paper investigates a way of using background knowledge in the rule discovery process. This technique is based on Generalization Distribution Table (GDT for short), in which the probabilistic relationships between concepts and instances over discrete domains are represented. We describe how to use background knowledge as a bias to adjust the prior distribution so that the better knowledge can be discovered.

#index 478126
#* Efficient Score-Based Learning of Equivalence Classes of Bayesian Networks
#@ Paul Munteanu;Denis Cau
#t 2000
#c 21
#% 197387
#% 527830
#% 1650771
#! The use of bayesian networks for knowledge discovery requires learning algorithms which emphasize not only the predictive power but also the structural fidelity of the discovered networks. Previous work on score-based methods for learning equivalence classes of bayesian networks showed that they generally provide better results than classical algorithms, that explore the space of bayesian networks. However, they are considerably slower, mainly because they use more complicated search operators and because they have to build instances of the equivalence classes in order to check their consistency and in order to calculate their score. We propose here a new greedy learning algorithm that explores the space of equivalence classes with a reduced set of operators and realizes the verification of the consistency and the computation of the score without any need for instantiation. We show on five experimental tasks that this algorithm is rather efficient, obtains better scores and discovers structures closer to the "gold-standard" than classical greedy and tabu search in the space of bayesian networks.

#index 478127
#* Inductive Logic Programming in Clementine
#@ Sam Brewer;Tom Khabaza
#t 2000
#c 21
#% 252221
#! This paper describes the integration of ILP with Clementine. Background on ILP and Clementine is provided, with a description of Clementine's target users. The benefits of ILP to data mining are outlined, and ILP is compared with pre-existing data mining algorithms. Issues of integration between ILP and Clementine are discussed. The implementation is then described, showing how the key issues are addressed, and describing in brief the Clementine mechanisms used to integrate ILP.

#index 478128
#* Centroid-Based Document Classification: Analysis and Experimental Results
#@ Eui-Hong Han;George Karypis
#t 2000
#c 21
#% 67565
#% 136350
#% 169777
#% 229972
#% 262050
#% 262059
#% 280817
#% 304423
#% 458369
#% 458379
#! In this paper we present a simple linear-time centroid-based document classification algorithm, that despite its simplicity and robust performance, has not been extensively studied and analyzed. Our experiments show that this centroidbased classifier consistently and substantially outperforms other algorithms such as Naive Bayesian, k-nearest-neighbors, and C4.5, on a wide range of datasets. Our analysis shows that the similarity measure used by the centroid-based scheme allows it to classify a new document based on how closely its behavior matches the behavior of the documents belonging to different classes. This matching allows it to dynamically adjust for classes with different densities and accounts for dependencies between the terms in the different classes

#index 478129
#* Fast Hierarchical Clustering Based on Compressed Data and OPTICS
#@ Markus M. Breunig;Hans-Peter Kriegel;Jörg Sander
#t 2000
#c 21
#% 210173
#% 273890
#% 280402
#% 481956
#% 527022
#! One way to scale up clustering algorithms is to squash the data by some intelligent compression technique and cluster only the compressed data records. Such compressed data records can e.g. be produced by the BIRCH algorithm. Typically they consist of the sufficient statistics of the form (N, X, X2) where N is the number of points, X is the (vector-)sum, and X2 is the square sum of the points. They can be used directly to speed up k-means type of clustering algorithms, but it is not obvious how to use them in a hierarchical clustering algorithm. Applying a hierarchical clustering algorithm e.g. to the centers of compressed subclusters produces a very weak result. The reason is that hierarchical clustering algorithms are based on the distances between data points and that the interpretaion of the result relies heavily on a correct graphical representation of these distances. In this paper, we introduce a method by which the sufficient statistics (N, X, X2) of sub-clusters can be utilized in the hierarchical clustering method OPTICS. We show how to generate appropriate distance information about compressed data points, and how to adapt the graphical representation of the clustering result. A performance evaluation using OPTICS in combination with BIRCH demonstrates that our approach is extremely efficient (speed-up factors up to 1700) and produces high quality results.

#index 478130
#* Mining Generalized Multiple-Level Association Rules
#@ Show-Jane Yen
#t 2000
#c 21
#% 201894
#% 443310
#% 481290
#% 481758
#! Mining association rules is an important task for knowledge discovery. We can analyze past transaction data to discover customer behaviors such that the quality of business decision can be improved. The strategy of mining association rules focuses on discovering large itemsets which are groups of items which appear together in a sufficient number of transactions. In this paper, we propose a graph-based approach to generate generalized multiple-level association rules from a large database of customer transactions, which describes the associations among items in any concept level. This approach is to scan the database once to construct an association graph, and then traverse the graph to generate large itemsets.

#index 478131
#* Observational Logic Integrates Data Mining Based on Statistics and Neural Networks
#@ Martin Holena
#t 2000
#c 21
#% 160857
#% 232219
#% 256299
#% 261604
#% 267537
#% 361100
#% 380342
#% 443090
#% 477481
#% 501224
#% 545730
#% 1860171
#% 1860390
#! In data mining, artificial neural networks have become one of important competitors of traditional statistical methods. They increase the potential of discovering useful knowledge in data, but only if the differences between both kinds of methods are well understood. Therefore, integrative frameworks are urgently needed. In this paper, a framework based on the calculus of observational logic is presented. Basic concepts of that framework are outlined, and it is explained how generalized quantifiers can be defined in an observational calculus to capture data mining with statistical and ANN-based methods.

#index 478132
#* CEM-Visualisation and Discovery in Email
#@ Richard J. Cole, II;Peter W. Eklund;Gerd Stumme
#t 2000
#c 21
#% 384416
#% 477959
#% 501190
#% 538873
#! This paper presents a lattice metaphor for knowledge discovery in electronic mail. It allows a user to navigate email using a lattice rather than a tree structure. By using such a conceptual multi-hierarchy, the content and shape of the lattice can be varied to accommodate queries against the email collection. This paper presents the underlying mathematical structures, and a number of examples of the lattice and multihierarchy working with a prototypical email collection.

#index 478133
#* Instance-Based Classification by Emerging Patterns
#@ Jinyan Li;Guozhu Dong;Kotagiri Ramamohanarao
#t 2000
#c 21
#% 92533
#% 136350
#% 246832
#% 280409
#% 280439
#% 449588
#% 466426
#! Emerging patterns (EPs), namely itemsets whose supports change significantly from one class to another, capture discriminating features that sharply contrast instances between the classes. Recently, EP-based classifiers have been proposed, which first mine as many EPs as possible (called eager-learning) from the training data and then aggregate the discriminating power of the mined EPs for classifying new instances. We propose here a new, instance-based classifier using EPs, called DeEPs, to achieve much better accuracy and efficiency than the previously proposed EP-based classifiers. High accuracy is achieved because the instance-based approach enables DeEPs to pinpoint all EPs relevant to a test instance, some of which are missed by the eager-learning approaches. High efficiency is obtained using a series of data reduction and concise data-representation techniques. Experiments show that DeEPs' decision time is linearly scalable over the number of training instances and nearly linearly over the number of attributes. Experiments on 40 datasets also show that DeEPs is superior to other classifiers on accuracy.

#index 478134
#* Discovery of Generalized Association Rules with Multiple Minimum Supports
#@ Chung-Leung Lui;Fu-Lai Chung
#t 2000
#c 21
#% 49242
#% 172386
#% 280487
#% 443310
#% 481290
#% 481588
#% 481758
#! Mining association rules at multiple concept levels leads to the discovery of more concrete knowledge. Nevertheless, setting an appropriate minsup for cross-level itemsets is still a non-trivial task. Besides, the mining process is computationally expensive and produces many redundant rules. In this work, we propose an efficient algorithm for mining generalized association rules with multiple minsup. The method scans appropriately k+1 times of the number of original transactions and once of the extended transactions where k is the largest itemset size. Encouraging simulation results were reported.

#index 478135
#* Mining with Cover and Extension Operators
#@ Marzena Kryszkiewicz
#t 2000
#c 21
#% 152934
#% 232136
#% 501193
#! Mining around association rules discovered in a large database is an important problem. In the paper, we consider the case, when a user wants to mine around the given set of association rules, but does not have access to the original database. We show how to reason with a set of rules by means of the cover and extension operators. Since the number of association rules can be huge, we introduce the concept of maximal covering rules. The algorithms for mining with the cover and extension operators are offered.

#index 478136
#* Clustering Distributed Homogeneous Datasets
#@ Srinivasan Parthasarathy;Mitsunori Ogihara
#t 2000
#c 21
#% 22982
#% 191581
#% 216500
#% 232136
#% 460862
#% 462238
#% 479803
#% 481290
#% 614619
#% 678196
#! In this paper we present an elegant and effective algorithm for measuring the similarity between homogeneous datasets to enable clustering. Once similar datasets are clustered, each cluster can be independently mined to generate the appropriate rules for a given cluster. The algorithm presented is efficient in storage and scale, has the ability to adjust to time constraints, and can provide the user with likely causes of similarity or dis-similarity. The proposed similarity measure is evaluated and validated on real datasets from the Census Bureau, Reuters, and synthetic datasets from IBM.

#index 478137
#* Supporting Discovery in Medicine by Association Rule Mining of Bibliographic Databases
#@ Dimitar Hristovski;Saso Dzeroski;Borut Peterlin;Anamarija Rozic-Hristovski
#t 2000
#c 21
#% 226545
#% 232136
#! The paper presents an interactive discovery support system for the field of medicine. The intended users of the system are medical researchers. The goal of the system is: for a given starting concept of interest, discover new, potentially meaningful relations with other concepts that have not been published in the medical literature before. We performed two types of preliminary evaluation of the system: 1) by a medical doctor and 2) by automatic means. The preliminary evaluation showed that our approach for supporting discovery in medicine is promising, but also that some further work is needed, especially on limiting the number of potential discoveries the system generates.

#index 478138
#* Some Enhencements of Decision Tree Bagging
#@ Pierre Geurts
#t 2000
#c 21
#% 191910
#% 357521
#% 420054
#% 424996
#% 424997
#% 458195
#% 565528
#! This paper investigates enhancements of decision tree bagging which mainly aim at improving computation times, but also accuracy. The three questions which are reconsidered are: discretization of continuous attributes, tree pruning, and sampling schemes. A very simple discretization procedure is proposed, resulting in a dramatic speedup without significant decrease in accuracy. Then a new method is proposed to prune an ensemble of trees in a combined fashion, which is significantly more effective than individual pruning. Finally, different resampling schemes are considered leading to different CPU time/accuracy tradeoffs. Combining all these enhancements makes it possible to apply tree bagging to very large datasets, with computational performances similar to single tree induction. Simulations are carried out on two synthetic databases and four real-life datasets.

#index 478139
#* Clinical Knowledge Discovery in Hospital Information Systems: Two Case Studies
#@ Shusaku Tsumoto
#t 2000
#c 21
#% 216500
#% 275064
#% 384978
#% 386105
#% 477948
#! Since early 1980's, the rapid growth of hospital information systems stores the large amount of laboratory examinations as databases. Thus, it is highly expected that knowledge discovery and data mining(KDD) methods will find interesting patterns from databases as reuse of stored data and be important for medical research and practice because human beings cannot deal with such a huge amount of data. However, there are still few empirical approaches which discuss the whole data mining process from the viewpoint of medical data. In this paper, KDD process from a hospital information system is presented by using two medical datasets. This empirical study show that preprocessing and data projection are the most time-consuming processes, in which very few data mining researches have not dicussed yet and that application of rule induction methods is much easier than preprocessing.

#index 478140
#* Action-Rules: How to Increase Profit of a Company
#@ Zbigniew W. Ras;Alicja Wieczorkowska
#t 2000
#c 21
#! Decision tables classifying customers into groups of different profitability are used for mining rules classifying customers. Attributes are divided into two groups: stable and flexible. By stable attributes we mean attributes which values can not be changed by a bank (age, marital status, number of children are the examples). On the other hand attributes (like percentage rate or loan approval to buy a house in certain area) which values can be changed or influenced by a bank are called flexible. Rules are extracted from a decision table given preference to flexible attributes. This new class of rules forms a special repository of rules from which new rules called actionrules are constructed. They show what actions should be taken to improve the profitability of customers.

#index 478141
#* Trees and Induction Graphs for Multivariate Response
#@ Antonio Ciampi;Djamel A. Zighed;Jérémy Clech
#t 2000
#c 21
#! We show that induction graphs can be generalized to treat more general prediction problems than those usually treated: prediction of a class variable or of a one dimensional continuous variable. We treat here the case in which the prediction concerns a multivariate continuous response. The approach used, called here GENIND1, is a combination of previous work by two of the authors (RECPAM and SIPINA). We show also that in the GENIND1 framework, clustering (unsupervised learning) as well as prediction (supervised learning) can be treated. The approach is applied to nutritional data.

#index 478142
#* Application of Data-Mining and Knowledge Discovery in Automotive Data Engineering
#@ Jörg Keller;Valerij Bauer;Wojciech Kwedlo
#t 2000
#c 21
#% 478116
#! In this paper the authors present a powerful and efficient alternative to Neural Networks (NN) by application of Knowledge Discovery and Data-Mining (KDD) methods for real world data in vehicle design, particularly for automotive Data Engineering (DE) mechanisms and processes. Typical tasks in automotive engineering are dependency analysis, classification of concepts and prediction of characteristic design parameters. From the point of view of a design engineer the main drawback of a NN-based approach is a lack of clear interpretation of the results. For classical, statistical tasks an application of an instance-based method, e.g. K-Nearest-Neighbors (KNN), represents an appropriate alternative for the engineer. By application of rule-based methods the authors demonstrate an alternate in conceptual design, which, in contrast to NN, allows to interpret the results and proof or enhance designers knowledge. The approach of this paper is based on a novel application of an Evolutionary Decision Rule Learner with Multivariate Discretization (EDRL-MD) for classification, and of M6 for regression learning.

#index 478143
#* Contribution of Dataset Reduction Techniques to Tree-Simplification and Knowledge Discovery
#@ Marc Sebban;Richard Nock
#t 2000
#c 21
#% 136350
#% 214236
#% 252009
#% 449588
#% 465760
#% 466562
#% 528000
#% 743911
#% 1499584
#! In the Knowledge Discovery in Databases (KDD) field, the human comprehensibility of models is as important as the accuracy optimization. To address this problem, many methods have been proposed to simplify decision trees and improve their understandability. Among different classes of methods, we find strategies which deal with this problem by a priori reducing the database, either through feature selection or case selection. At the same time, many other efficient selection algorithms have been developed in order to reduce storage requirments of case-based learning algorithms. Therefore, their original aim is not the tree simplification. Surprisingly, as far as we know, few works have attempted to exploit this wealth of efficient algorithms in favor of knowledge discovery. This is the aim of this paper. we analyze through large experiments and discussions the contribution of the state-of-the-art reduction techniques and instances. We show that in some cases, this algorithms is very efficient to improve the standard post-pruning performances, used to combat the overfitting problem.

#index 478144
#* Fast Feature Selection Using Partial Correlation for Multi-vaslued Attributes
#@ Stéphane Lallich;Ricco Rakotomalala
#t 2000
#c 21
#% 129212
#% 156186
#% 243727
#% 243728
#% 315438
#% 385563
#% 385564
#% 466234
#% 477955
#! We propose a fast feature selection method in supervised learning for multi-valued attributes. The main idea is to rewrite the multi-valued problem in the space of examples into a boolean problem in the space of pairwise examples. On basis of this approach, we can use point correlation coefficient which is null in the case of conditional independence, and verifies a formula connecting partial coefficients with marginal coefficients. This property allows to reduce considerably the computing times because a single pass over the database is necessary to compute all coefficients. We test our algorithm on benchmark databases.

#index 478267
#* Learning from Labeled and Unlabeled Documents: A Comparative Study on Semi-Supervised Text Classification
#@ Carsten Lanquillon
#t 2000
#c 21
#% 67565
#% 260001
#% 280817
#% 311027
#% 458192
#% 458379
#% 465754
#% 465895
#% 466263
#! Supervised learning algorithms usually require large amounts of training data to learn reasonably accurate classifiers. Yet, for many text classification tasks, providing labeled training documents is expensive, while unlabeled documents are readily available in large quantities. Learning from both, labeled and unlabeled documents, in a semi-supervised framework is a promising approach to reduce the need for labeled training documents. This paper compares three commonly applied text classifiers in the light of semi-supervised learning, namely a linear support vector machine, a similarity-based tfidf and a Naïve Bayes classifier. Results on a real-world text datasets show that these learners may substantially benefit from using a large amount of unlabeled documents in addition to some labeled documents.

#index 478268
#* Image Access and Data Mining: An Approach
#@ Chabane Djeraba
#t 2000
#c 21
#% 57485
#% 336335
#% 375017
#% 443889
#% 462216
#% 836019
#% 1286533
#! In this paper, we propose an approach that discovers automatically visual relations in order to make more powerful the image access. The visual relationships are discovered automatically from images. They are statistical rules in the form of a → b which means: if the visual feature "a" is true in an image then the visual feature "b" is true in the same image with a precision value. The rules concern symbols that are extracted from image numerical features. The transformation of image numerical features into image symbolic features needs a visual feature book in which each book feature is the gravity center of similar features. The approach presents the clustering algorithm that creates the feature book.

#index 478269
#* Zoomed Ranking: Selection of Classification Algorithms Based on Relevant Performance Information
#@ Carlos Soares;Pavel Brazdil
#t 2000
#c 21
#% 126842
#% 169653
#% 191910
#% 232108
#% 376266
#% 458220
#% 459716
#% 465740
#% 478107
#! Given the wide variety of available classification algorithms and the volume of data today's organizations need to analyze, the selection of the right algorithm to use on a new problem is an important issue. In this paper we present a combination of techniques to address this problem. The first one, zooming, analyzes a given dataset and selects relevant (similar) datasets that were processed by the candidate algoritms in the past. This process is based on the concept of "distance", calculated on the basis of several dataset characteristics. The information about the performance of the candidate algorithms on the selected datasets is then processed by a second technique, a ranking method. Such a method uses performance information to generate advice in the form of a ranking, indicating which algorithms should be applied in which order. Here we propose the adjusted ratio of ratios ranking method. This method takes into account not only accuracy but also the time performance of the candidate algorithms. The generalization power of this ranking method is analyzed. For this purpose, an appropriate methodology is defined. The experimental results indicate that on average better results are obtained with zooming than without it.

#index 478270
#* Expert Constrained Clustering: A Symbolic Approach
#@ Fabrice Rossi;Frédérick Vautrain
#t 2000
#c 21
#% 210558
#% 389795
#! A new constrained model is discussed as a way of incorporating efficiently a priori expert knowledge into a clustering problem of a given individual set. The first innovation is the combination of fusion constraints, which request some individuals to belong to one cluster, with exclusion constraints, which separate some individuals in different clusters. This situation implies to check the existence of a solution (ie if no pair of individuals are connected by fusion and exclusion constraints). The second novelty is that the constraints are expressed in a symbolic language that allows compact description of group of individuals according to a given interpretation. This paper studies the coherence of such constraints at individual and symbolic levels. A mathematical framework, close to the Symbolic Data Analysis[3], is built in order to define how a symbolic description space may be interpreted on a given individual set. A partial order on symbolic descriptions (which is an usual assumption of Artificial Intelligence), allows a symbolic analysis of the constraints. Our results provide an individual but also a symbolic clustering.

#index 478271
#* Sampling Strategies for Targeting Rare Groups from a Bank Customer Database
#@ Jean-Hugues Chauchat;R. Rakotomalala;Didier Robert
#t 2000
#c 21
#% 327
#% 57456
#% 290482
#% 376266
#% 466234
#% 743911
#! This paper presents various balanced sampling strategies for building decision trees in order to target rare groups. A new coefficient to compare targeting performances of various learning strategies is introduced. A real life application of targeting specific bank customer group for marketing actions is described. Results shows that local sampling on the nodes while constructing the tree requires small samples to achieve the performance of processing the complete base, with dramatically reduced computing times.

#index 478272
#* An Efficient Approach to Discovering Sequential Patterns in Large Databases
#@ Show-Jane Yen;Chung-Wen Cho
#t 2000
#c 21
#% 248792
#% 340289
#% 459006
#% 463903
#% 481754
#! Mining sequential patterns is to discover sequential purchasing behaviors of most customers from a large amount of customer transactions. The previous approaches for mining sequential patterns need to repeatedly scan the large database, and take a large amount of computation time to find frequent sequences, which are very time consuming. In this paper, we present an algorithm SSLP to find sequential patterns, which can significantly reduce the number of the database scans. The experimental results show that our algorithms are more efficient than the other algorithms.

#index 478273
#* Mining Association Rules: Deriving a Superior Algorithm by Analyzing Today's Approaches
#@ Jochen Hipp;Ulrich Güntzer;Gholamreza Nakhaeizadeh
#t 2000
#c 21
#% 152934
#% 227917
#% 477656
#% 481290
#% 481754
#% 481758
#% 631970
#! Since the introduction of association rules, many algorithms have been developed to perform the computationally very intensive task of association rule mining. During recent years there has been the tendency in research to concentrate on developing algorithms for specialized tasks, e.g. for mining optimized rules or incrementally updating rule sets. Here we return to the "classic" problem, namely the efficient generation of all association rules that exist in a given set of transactions with respect to minimum support and minimum confidence. From our point of view, the performance problem concerning this task is still not adequately solved. In this paper we address two topics: First of all, today there is no satisfying comparison of the common algorithms. Therefore we identify the fundamental strategies of association rule mining and present a general framework that is independent of any particular approach and its implementation. Based on this we carefully analyze the algorithms. We explain differences and similarities in performance behavior and complete our theoretic insights by runtime experiments. Second, the results are quite surprising and enable us to derive a new algorithm. This approach avoids the identified pitfalls and at the same time profits from the strengths of known approaches. It turns out that it achieves remarkably better runtimes than the previous algorithms.

#index 478274
#* An Apriori-Based Algorithm for Mining Frequent Substructures from Graph Data
#@ Akihiro Inokuchi;Takashi Washio;Hiroshi Motoda
#t 2000
#c 21
#% 420062
#% 481290
#% 1268739
#% 1273674
#! This paper proposes a novel approach named AGM to efficiently mine the association rules among the frequently appearing substructures in a given graph data set. A graph transaction is represented by an adjacency matrix, and the frequent patterns appearing in the matrices are mined through the extended algorithm of the basket analysis. Its performance has been evaluated for the artificial simulation data and the carcinogenesis data of Oxford University and NTP. Its high efficiency has been confirmed for the size of a real-world problem.

#index 478275
#* Application of Reinforcement Learning to Electrical Power System Closed-Loop Emergency Control
#@ Christophe Druet;Damien Ernst;Louis Wehenkel
#t 2000
#c 21
#% 384911
#% 647111
#! This paper investigates the use of reinforcement learning in electric power system emergency control. The approach consists of using numerical simulations together with on-policy Monte Carlo control to determine a discrete switching control law to trip generators so as to avoid loss of synchronism. The proposed approach is tested on a model of a real large scale power system and results are compared with a quasi-optimal control law designed by a brute force approach for this system.

#index 478276
#* Algorithm for Matching Sets of Time Series
#@ Iztok Savnik;Georg Lausen;Hans-Peter Kahle;Heinrich Spiecker;Sebastian Hein
#t 2000
#c 21
#% 136350
#% 172949
#% 232122
#% 236692
#% 280482
#% 376266
#% 477479
#% 481609
#! Time series are time-stamped sequences of values which represent a parameter of the observed processes in subsequent time points. Given a set of time series describing a set of similar processes, the model of the behavior of processes is constructed as a range of classification trees which describe the characteristics of each particular time point in series. An algorithm for matching a sequence of values with the model is used for searching common patterns in the sets of time series, and for predicting the starting time points of undated time series. The algorithm was developed and analyzed in the frame of the study of tree-ring time series. The implementation and the empirical analysis of the algorithm on the tree-ring time series are presented.

#index 478277
#* Quality Scheme Assessment in the Clustering Process
#@ Maria Halkidi;Michalis Vazirgiannis;Yannis Batistakis
#t 2000
#c 21
#% 58646
#% 104472
#% 207945
#% 216499
#% 232102
#% 248790
#% 260970
#% 296738
#% 393792
#% 479799
#% 501225
#! Clustering is mostly an unsupervised procedure and most of the clustering algorithms depend on assumptions and initial guesses in order to define the subgroups presented in a data set. As a consequence, in most applications the final clusters require some sort of evaluation. The evaluation procedure has to tackle difficult problems, which can be qualitatively expressed as: i. quality of clusters, ii. the degree with which a clustering scheme fits a specific data set, iii. the optimal number of clusters in a partitioning. In this paper we present a scheme for finding the optimal partitioning of a data set during the clustering process regardless of the clustering algorithm used. More specifically, we present an approach for evaluation of clustering schemes (partitions) so as to find the best number of clusters, which occurs in a specific data set. A clustering algorithm produces different partitions for different values of the input parameters. The proposed approach selects the best clustering scheme (i.e., the scheme with the most compact and well-separated clusters), according to a quality index we define. We verified our approach using two popular clustering algorithms on synthetic and real data sets in order to evaluate its reliability. Moreover, we study the influence of different clustering parameters to the proposed quality index.

#index 478278
#* Temporal Machine Learning for Switching Control
#@ Pierre Geurts;Louis Wehenkel
#t 2000
#c 21
#% 357521
#% 386314
#% 466260
#% 705649
#! In this paper, a temporal machine learning method is presented which is able to automatically construct rules allowing to detect as soon as possible an event using past and present measurements made on a complex system. This method can take as inputs dynamic scenarios directly described by temporal variables and provides easily readable results in the form of detection trees. The application of this method is discussed in the context of switching control. Switching (or discrete event) control of continuous systems consists in changing the structure of a system in such a way as to control its behavior. Given a particular discrete control switch, detection trees are applied to the induction of rules which decide based on the available measurements whether or not to operate a switch. Two practical applications are discussed in the context of electrical power systems emergency control.

#index 478279
#* Predictive Performance of Weghted Relative Accuracy
#@ Ljupco Todorovski;Peter A. Flach;Nada Lavrac
#t 2000
#c 21
#% 166120
#% 449566
#% 458178
#% 545856
#! Weighted relative accuracy was proposed in [4] as an alternative to classification accuracy typically used in inductive rule learners. Weighted relative accuracy takes into account the improvement of the accuracy relative to the default rule (i.e., the rule stating that the same class should be assigned to all examples), and also explicitly incorporates the generality of a rule (i.e., the number of examples covered). In order to measure the predictive performance of weighted relative accuracy, we implemented it in the rule induction algorithm CN2. Our main results are that weighted relative accuracy dramatically reduces the size of the rule sets induced with CN2 (on average by a factor 9 on the 23 datasets we used), at the expense of only a small average drop in classification accuracy.

#index 478280
#* Providing Advice to Website Designers Towards Effective Websites Re-Organization
#@ Peter Tselios;Agapios Platis;George A. Vouros
#t 2000
#c 21
#% 40796
#% 186340
#% 266283
#% 312874
#% 631914
#% 1273676
#! This paper presents a method to help website designers to reorganize sites towards making pages that are "hidden" from site visitors but contain information that is of high importance for them, more accessible to future visitors. Towards this aim we present a method for computing the probability of visitors to be in a page and page's attractability. The computation of these indicators is based on transitions made to page and on the information interest that the side designers assigns to pages. Based on this method, the paper presents DesignersAdvisor, which computes pages' attractability. DesignersAdvisor aims to assist the re-organization of any existing website without posing any additional effort to site visitors and without posing particular requirements concerning the form or the content of web pages.

#index 478281
#* Generalized Entropy and Projection Clustering of Categorical Data
#@ Dan A. Simovici;Dana Cristofor;Laurentiu Cristofor
#t 2000
#c 21
#% 232136
#% 248792
#% 280417
#% 380104
#% 420093
#% 638933
#! We generalize the notion of entropy for a set of attributes of a table and we study its applications to clustering of categorical data. This new concept allows greater flexibility in identifying sets of attributes and, in a certain case, is naturally related to the average distance between the records that are the object of clustering. An algorithm that identifies clusterable sets of attributes (using several types of entropy) is also presented as well as experimental results obtained with this algorithm.

#index 478282
#* Applying Objective Interestingness Measures in Data Mining Systems
#@ Robert J. Hilderman;Howard J. Hamilton
#t 2000
#c 21
#% 280433
#% 280456
#% 304180
#% 443193
#% 477480
#% 477962
#% 481758
#% 566862
#! One of the most important steps in any knowledge discovery task is the interpretation and evaluation of discovered patterns. To address this problem, various techniques, such as the chi-square test for independence, have been suggested to reduce the number of patterns presented to the user and to focus attention on those that are truly statistically significant. However, when mining a large database, the number of patterns discovered can remain large even after adjusting significance thresholds to eliminate spurious patterns. What is needed, then, is an effective measure to further assist in the interpretation and evaluation step that ranks the interestingness of the remaining patterns prior to presenting them to the user. In this paper, we describe a two-step process for ranking the interestingness of discovered patterns that utilizes the chi-square test for independence in the first step and objective measures of interestingness in the second step. We show how this two-step process can be applied to ranking characterized/generalized association rules and data cubes.

#index 478283
#* Automatic Category Structure Generation and Categorization of Chinese Text Documents
#@ Hsin-Chang Yang;Chung-Hong Lee
#t 2000
#c 21
#% 234978
#% 287045
#! Recently knowledge discovery and data mining in unstructured or semi-structured texts(text mining) has been attracted lots of attention from both commercial and research fields. One aspect of text mining is on automatic text categorization, which assigns a text document to some predefined category according to the correlation between the document and the category. Traditionally the categories are arranged in hierarchical manner to achieve effective searching and indexing as well as easy comprehension for human. The determination of categories and their hierarchical structures were most done by human experts. In this work, we developed an approach to automatically generate categories and reveal the hierarchical structure among them. We also used the generated structure to categorize text documents. The document collection is trained by a self-organizing map to form two feature maps. We then analyzed the two maps to obtain the categories and the structure among them. Although the corpus contains documents written in Chinese, the proposed approach can be applied to documents written in any language and such documents can be transformed into a list of separated terms.

#index 478284
#* Materialized Data Mining Views
#@ Tadeusz Morzy;Marek Wojciechowski;Maciej Zakrzewicz
#t 2000
#c 21
#% 152934
#% 216508
#% 280454
#% 464204
#% 481290
#% 481779
#% 481954
#% 486879
#% 1782845
#! Data mining is a useful decision support technique, which can be used to find trends and regularities in warehouses of corporate data. A serious problem of its practical applications is long processing time required by data mining algorithms. Current systems consume minutes or hours to answer simple queries. In this paper we present the concept of materialized data mining views. Materialized data mining views store selected patterns discovered in a portion of a database, and are used for query rewriting, which transforms a data mining query into a query accessing a materialized view. Since the transformation is transparent to a user, materialized data mining views can be created and used like indexes.

#index 478285
#* Confirmation Rule Sets
#@ Dragan Gamberger;Nada Lavrac
#t 2000
#c 21
#% 81838
#% 209021
#% 218961
#% 232136
#% 251145
#% 445217
#% 466249
#% 1499573
#! The concept of confirmation rule sets represents a framework for reliable decision making that combines two principles that are effective for increasing the predictive accuracy: consensus in an ensemble of classifiers and indecisive or probabilistic predictions in cases when reliable decisions are not possible. The confirmation rules concept uses a separate classifier set for every class of the domain. In this decision model different rules can be incorporated: either those obtained by applying one or more inductive learning algorithms or even rules representing human encoded expert domain knowledge. The only conditions for the inclusion of a rule into the confirmation rule set are its high predictive value and relative independence of other rules in the confirmation rule set. This paper introduces the concept of confirmation rule sets, together with an algorithm for selecting relatively independent rules from a set of all acceptable confirmation rules and an algorithm for the systematic construction of a set of confirmation rules.

#index 478286
#* Algorithms for Mining Share Frequent Itemsets Containing Infrequent Subsets
#@ Brock Barber;Howard J. Hamilton
#t 2000
#c 21
#% 152934
#% 210160
#% 232136
#% 248785
#% 420073
#% 477624
#% 481290
#! The share measure for itemsets provides useful information about numerical values associated with transaction items, that the support measure cannot. Finding share frequent itemsets is difficult because share frequency is not downward closed when it is defined in terms of the itemset as a whole. The Item Add-back and Combine All Counted algorithms do not rely on downward closure and thus, are able to find share frequent itemsets that have infrequent subsets. These heuristic algorithms predict which itemsets should be counted in the current pass using information available at no additional processing cost.

#index 478287
#* An Application of Association Rules Discovery to Geographic Information Systems
#@ Ansaf Salleb;Christel Vrain
#t 2000
#c 21
#% 481290
#% 527021
#% 527160
#% 550412
#% 630974
#% 712001
#! In this paper, we are interested in the problem of extracting spatial association rules in Geographic Information Systems (GIS). We propose an algorithm that extends existing methods to deal with spatial and non-spatial data over multiple layers. It handles hierarchical, multi-valued attributes, and produces general spatial association rules. We also present a prototype, which has been applied on a real and large geographic database in the field of mineral exploration.

#index 478288
#* Multi-Relational Data Mining, Using UML for ILP
#@ Arno J. Kobbe;Arno Siebes;Hendrik Blockeel;Danïel van der Wallen
#t 2000
#c 21
#% 217072
#% 226437
#% 238187
#% 264771
#% 360348
#% 477497
#% 477978
#% 543238
#% 550391
#% 567899
#% 1290272
#% 1499586
#! Although there is a growing need for multi-relational data mining solutions in KDD, the use of obvious candidates from the field of Inductive Logic Programming (ILP) has been limited. In our view this is mainly due to the variation in ILP engines, especially with respect to input specification, as well as the limited attention for relational database issues. In this paper we describe an approach which uses UML as the common specification language for a large range of ILP engines. Having such a common language will enable a wide range of users, including non-experts, to model problems and apply different engines without any extra effort. The process involves transformation of UML into a language called CDBL, that is then translated to a variety of input formats for different engines.

#index 478289
#* Clustering Large, Multi-level Data Sets: An Apporach Based on Kohonen Self Organizing Maps
#@ Antonio Ciampi;Yves Lechevallier
#t 2000
#c 21
#% 185328
#% 234978
#% 269521
#% 389795
#! Standard clustering methods do not handle truly large data sets and fail to take into account multi-level data structures. This work outlines an approach to clustering that integrates the Kohonen Self Organizing Map (SOM) with other clustering methods. Moreover, in order to take into account multi-level structures, a statistical model is proposed, in which a mixture of distributions may have mixing coefficients depending on higher-level variables. Thus, in a first step, the SOM provides a substantial data reduction, whereby a variety of ascending and divisive clustering algorithms become accessible. As a second step, statistical modelling provides both a direct means to treat multi-level structures and a framework for model-based clustering. The interplay of these two steps is illustrated on an example of nutritional data from a multicenter study on nutrition and cancer, known as EPIC

#index 478290
#* Induction of Multivariate Decision Trees by Using Dipolar Criteria
#@ Leon Bobrowski;Marek Kretowski
#t 2000
#c 21
#% 111349
#% 136350
#% 182686
#% 314784
#% 420084
#% 633058
#% 1272358
#! A new approach to the induction of multivariate decision trees is proposed. A linear decision function (hyper-plane) is used at each non-terminal node of a binary tree for splitting the data. The search strategy is based on the dipolar criterion functions and exploits the basis exchange algorithm as an optimization procedure. The feature selection is used to eliminate redundant and noisy features at each node. To avoid the problem of over-fitting the tree is pruned back after the growing phase. The results of experiments on some real-life datasets are presented and compared with obtained by state-of-art decision trees.

#index 478291
#* Bagging and Boosting with Dynamic Integration of Classifiers
#@ Alexey Tsymbal;Seppo Puuronen
#t 2000
#c 21
#% 73372
#% 136350
#% 140588
#% 209021
#% 232102
#% 312728
#% 424997
#% 498130
#% 520224
#% 590068
#% 590114
#% 637522
#% 1273928
#! One approach in classification tasks is to use machine learning techniques to derive classifiers using learning instances. The co-operation of several base classifiers as a decision committee has succeeded to reduce classification error. The main current decision committee learning approaches boosting and bagging use resampling with the training set and they can be used with different machine learning techniques which derive base classifiers. Boosting uses a kind of weighted voting and bagging uses equal weight voting as a combining method. Both do not take into account the local aspects that the base classifiers may have inside the problem space. We have proposed a dynamic integration technique to be used with ensembles of classifiers. In this paper, the proposed dynamic integration technique is applied with AdaBoost and bagging. The comparison results using several datasets of the UCI machine learning repository show that boosting and bagging with dynamic integration of classifiers results often better accuracy than boosting and bagging result with their original voting techniques.

#index 478292
#* Discovery of Characteristic subgraph Patterns Using Relative Indexing and the Cascade Model
#@ Takashi Okada;Mayumi Oyama
#t 2000
#c 21
#% 184048
#% 477808
#! Relational representation of objects using graphs reveals much information that cannot be obtained by attribute value representations alone. There are already many databases that incorporate graph expressions. We focus on syntactic trees in language sentences, and we attempt to mine characteristic subgraph patterns. The mining process employs two methods: relative indexing of graph vertices and the cascade model. The former extracts many linear subgraphs from the database. An instance is then represented by a set of items, each of which indicates whether a specific linear subgraph is contained within the graph of the instance. The cascade model is a rule induction method that uses levelwise expansion of a lattice. The basic assumption of this mining process is that characteristic subgraphs may be well represented by the concurrent appearance of linear subgraphs. The resulting rules are shown to be a good guide for obtaining valuable knowledge in linguistics.

#index 478293
#* Supporting Case Acquisition and Labelling in the Cotext of Web Mining
#@ Vojtech Svátek;Martin Kavalec
#t 2000
#c 21
#% 262045
#% 266215
#% 271060
#% 478104
#! Case acquisition and labelling are important bottlenecks for predictive data mining. In the web context, a cascade of supporting techniques can be used, from general ones such as user interfaces, through filtering based on keyword frequency, to web-specific techniques exploiting public search engines. We show how a synergistic application of multiple techniques can be helpful in obtaining and pre-processing textual data, in particular for ILP-based web mining. The (two-fold) learning task itself consist in construction and disambiguation of categorisation rules, which are to process the results returned by web search engines.

#index 478294
#* Improving an Association Rule Based Classifier
#@ Bing Liu;Yiming Ma;Ching Kian Wong
#t 2000
#c 21
#% 136350
#% 153021
#% 280439
#% 481290
#! Existing classification algorithms in machine learning mainly use heuristic search to find a subset of regularities in data for classification. In the past few years, extensive research was done in the database community on learning rules using exhaustive search under the name of association rule mining. Although the whole set of rules may not be used directly for accurate classification, effective classifiers have been built using the rules. This paper aims to improve such an exhaustive search based classification system CBA (Classification Based on Associations). The main strength of this system is that it is able to use the most accurate rules for classification. However, it also has weaknesses. This paper proposes two new techniques to deal with these weaknesses. This results in remarkably accurate classifiers. Experiments on a set of 34 benchmark datasets show that on average the new techniques reduce the error of CBA by 17% and is superior to CBA on 26 of the 34 datasets. They reduce the error of C4.5 by 19%, and improve performance on 29 datasets. Similar good results are also achieved against RIPPER, LB and a Naïve-Bayes classifier.

#index 478295
#* Schema Mining: Finding Structural Regularity among Semistructured Data
#@ P. A. Laur;Florent Masseglia;Pascal Poncelet
#t 2000
#c 21
#% 152934
#% 210214
#% 227917
#% 232102
#% 248809
#% 262071
#% 443349
#% 459006
#% 463903
#% 477791
#% 481290
#% 481602
#% 481754
#% 481779
#! Motivated by decision support problems, data mining has been extensively addressed in the few past years. Nevertheless, the proposed approaches mainly concern flat representation of the data and to the best of our knowledge, not much effort has been spent on mining interesting patterns from such structures. In this paper we address the problem of mining structural association of semistructured data, or in other words the discovery of structural regularities among a large database of semistructured objects. This problem is much more complicated than the classical association rule one, since complex structures in the form of a labeled hirearchical objects partially ordered has to be taken into account.

#index 478296
#* Collective Principal Component Analysis from Distributed, Heterogeneous Data
#@ Hillol Kargupta;Weiyun Huang;Krishnamoorthy Sivakumar;Byung-Hoon Park;Shuren Wang
#t 2000
#c 21
#% 243790
#% 290137
#% 420083
#! Principal component analysis (PCA) is a statistical technique to identify the dependency structure of multivariate stochastic observations. PCA is frequently used in data mining applications. This paper considers PCA in the context of the emerging network-based computing environments. It offers a technique to perform PCA from distributed and heterogeneous data sets with relatively small communication overhead. The technique is evaluated against different data sets, including a data set for a web mining application. This approach is likely to facilitate the development of distributed clustering, associative link analysis, and other heterogeneous data mining applications that frequently use PCA.

#index 478297
#* Unified Algorithm for Undirected Discovery of Execption Rules
#@ Einoshin Suzuki;Jan M. Zytkow
#t 2000
#c 21
#% 232136
#% 286669
#% 442814
#% 443092
#% 477784
#% 479791
#% 479957
#! This paper presents an algorithm that seeks every possible exception rule which violates a common sense rule and satisfies several assumptions of simplicity. Exception rules, which represent systematic deviation from common sense rules, are often found interesting. Discovery of pairs that consist of a common sense rule and an exception rule, resulting from undirected search for unexpected exception rules, was successful in various domains. In the past, however, an exception rule represented a change of conclusion caused by adding an extra condition to the premise of a common sense rule. That approach formalized only one type of exceptions, and failed to represent other types. In order to provide a systematic treatment of exceptions, we categorize exception rules into eleven categories, and we propose a unified algorithm for discovering all of them. Preliminary results on fifteen real-world data sets provide an empirical proof of effectiveness of our algorithm in discovering interesting knowledge. The empirical results also match our theoretical analysis of exceptions, showing that the eleven types can be partitioned in three classes according to the frequency with which they occur in data.

#index 478298
#* Indirect Association: Mining Higher Order Dependencies in Data
#@ Pang-Ning Tan;Vipin Kumar;Jaideep Srivastava
#t 2000
#c 21
#% 227919
#% 280442
#% 280456
#% 452821
#! This paper introduces a novel pattern called indirect association and examines its utility in various application domains. Existing algorithms for mining associations, such as Apriori, will only discover itemsets that have support above a user-defined threshold. Any itemsets with support below the minimum support requirement are filtered out. We believe that an infrequent pair of items can be useful if the items are related indirectly via some other set of items. In this paper, we propose an algorithm for deriving indirectly associated itempairs and demonstrate the potential application of these patterns in the retail, textual and stock market domains.

#index 478299
#* Knowledge Discovery Using Least Squares Support Vector Machine Classifiers: A Direct Marketing Case
#@ Stijn Viaene;Bart Baesens;Tony Van Gestel;Johan A. K. Suykens;Dirk Van den Poel;Jan Vanthienen;Bart De Moor;Guido Dedene
#t 2000
#c 21
#% 269207
#% 292664
#% 309208
#! The case involves the detection and qualification of the most relevant predictors for repeat-purchase modelling in a direct marketing setting. Analysis is based on a wrapped form of feature selection using a sensitivity based pruning heuristic to guide a greedy, step-wise and backward traversal of the input space. For this purpose, we make use of a powerful and promising least squares version (LS-SVM) for support vector machine classification. The set-up is based upon the standard R(ecency) F(requency) M(onetary) modelling semantics. Results indicate that elimination of redundant/irrelevant features allows to significantly reduce model complexity. The empirical findings also highlight the importance of Frequency and Monetary variables, whilst the Recency variable category seems to be of lesser importance. Results also point to the added value of including non-RFM variables for improving customer profiling.

#index 478300
#* Determination of Screening Descriptors for Chemical Reaction Databases
#@ Laurent Dury;Laurence Leherte;Daniel P. Vercauteren
#t 2000
#c 21
#% 29345
#% 367271
#! The development of chemical reaction databases has become crucially important for many chemical synthesis laboratories. However the size of these databases has dramatically increased, leading consequently to perfect more and more powerful search engines. In this sense, the speed and the efficiency of screening processes of the chemical information are essential criteria. Looking forward for powerful algorithms dedicated to information retrieval in chemical reaction databases, we have thus developed several new graph descriptors to find efficient indexation and classification criteria of chemical reactions.

#index 478301
#* MSTS: A System for Mining Sets of Time Series
#@ Georg Lausen;Iztok Savnik;Aldar Dougarjapov
#t 2000
#c 21
#% 136350
#% 172949
#% 232122
#% 420063
#% 477479
#% 478276
#% 481609
#% 617843
#! A system to support the mining task of sets of time series is presented. A model of a set of time series is constructed by a series of classifiers each defining certain consecutive time points based on the characteristics of particular time points in the series. Matching a previously unknown series with respect to a model is discussed. The architecture of the MSTS-System (Mining of Sets of Time Series) is described. As a distinctive feature the system is implemented as a database application: time series and the models, i.e. series of classifiers, are database objects. As a consequence of this integration, advanced functionality as the manipulation of models and various forms of meta learning can be easily build on top of MSTS.

#index 478302
#* Approximation of Frequency Queris by Means of Free-Sets
#@ Jean-Francois Boulicaut;Artur Bykowski;Christophe Rigotti
#t 2000
#c 21
#% 232136
#% 248785
#% 248791
#% 279120
#% 420062
#% 481290
#% 632030
#! Given a large collection of transactions containing items, a basic common data mining problem is to extract the so-called frequent itemsets (i.e., set of items appearing in at least a given number of transactions). In this paper, we propose a structure called free-sets, from which we can approximate any itemset support (i.e., the number of transactions containing the itemset) and we formalize this notion in the framework of Ɛ-adequate representation [10]. We show that frequent free-sets can be efficiently extracted using pruning strategies developed for frequent item-set discovery, and that they can be used to approximate the support of any frequent itemset. Experiments run on real dense data sets show a significant reduction of the size of the output when compared with standard frequent itemsets extraction. Furthermore, the experiments show that the extraction of frequent free-sets is still possible when the extraction of frequent itemsets becomes intractable. Finally, we show that the error made when approximating frequent itemset support remains very low in practice.

#index 478303
#* Relative Unsupervised Discretization for Association Rule Mining
#@ Marcus-Christopher Ludl;Gerhard Widmer
#t 2000
#c 21
#% 210160
#% 280458
#% 373671
#% 452821
#% 458208
#% 481290
#% 631971
#! The paper describes a context-sensitive discretization algorithm that can be used to completely discretize a numeric or mixed numeric-categorical dataset. The algorithm combines aspects of unsupervised (class-blind) and supervised methods. It was designed with a view to the problem of finding association rules or functional dependencies in complex, partly numerical data. The paper describes the algorithm and presents systematic experiments with a synthetic data set that contains a number of rather complex associations. Experiments with varying degrees of noise and "fuzziness" demonstrate the robustness of the method. An application to a large real-world dataset produced interesting preliminary results, which are currently the topic of specialized investigations.

#index 478304
#* Web Usage Mining: How to Efficiently Manage New Transactions and New Clients
#@ Florent Masseglia;Pascal Poncelet;Maguelonne Teisseire
#t 2000
#c 21
#% 459006
#% 504568
#% 584891
#% 661023
#! With the growing popularity of the World Wide Web (Web), large volumes of data such as user address or URL requested are gathered automatically by Web servers and collected in access log files. Recently, many interesting works have been published in the Web Usage Mining context. Nevertheless, the large amount of input data poses a maintenance problem. In fact, maintaining global patterns is a non-trivial task after access log file update because new data may invalidate old client behavior and creates new ones.

#index 478305
#* Towards Knowledge Discovery from cDNA Microarray Gene Expression Data
#@ Henryk Jan Komorowski;Torgeir R. Hvidsten;Tor-Kristian Jenssen;Dyre Tjeldvoll;Eivind Hovig;Arne K. Sanvik;Astrid Lægreid
#t 2000
#c 21
#! The advent of the so-called cDNA microarrays has offered the first possibility to obtain a global understanding of biological processes in living organisms by simultaneous readouts of tens of thousands of genes. Initial experiments suggest that genes with similar function have similar expression patterns in microarray experiments. Until now, most approaches to computational analysis of gene expressions have used unsupervised learning. Although in some cases unsupervised methods may be sufficient, the complexity of the biological processes is so high that it is unlikely that purely syntactical analyses are capable of fully exploiting the richness of the microarray data. In addition, it seems natural to re-use the existing biological (background) knowledge. In this paper, we present some elements of a methodology for knowledge discovery from microarray experiments. Two source of bio-medical knowledge are used: Ashburner's gene ontology and our own literature-derived network of gene-gene relations obtained by analysing Medline citation records. Predictive models can be induced and their classification quality validated through the ROC/AUC analysis and applied to provide hypotheses regarding the function of unclassified genes. The methodology has been so far tested on publicly available gene expression data and its results evaluated by molecular biologists and medical researchers.

#index 478306
#* A Genetic Algorithm-Based Solution for the Problem of Small Disjuncts
#@ Deborah R. Carvalho;Alex Alves Freitas
#t 2000
#c 21
#% 103051
#% 115608
#% 136350
#% 204528
#% 207252
#% 287570
#% 382327
#% 1273395
#! In essence, small disjuncts are rules covering a small number of examples. Hence, these rules are usually error-prone, which contributes to a decrease in predictive accuracy. The problem is particularly serious because, although each small disjuncts covers few examples, the set of small disjuncts can cover a large number of examples. This paper proposes a solution to the problem of discovering accurate small-disjunct rules based on genetic algorithms. The basic idea of our method is to use a hybrid decision tree / genetic algorithm approach for classification. More precisely, examples belonging to large disjuncts are classified by rules produced by a decision-tree algorithm, while examples belonging to small disjuncts are classified by a new genetic algorithm, particularly designed for discovering small-disjunct rules.

#index 478307
#* Leightweight Document Clustering
#@ Sholom M. Weiss;Brian F. White;Chidanand Apté
#t 2000
#c 21
#% 118771
#% 248217
#% 248221
#% 248226
#% 280404
#% 445372
#% 466395
#! A lightweight document clustering method is described that operates in high dimensions, processes tens of thousands of documents and groups them into several thousand clusters, or by varying a single parameter, into a few dozen clusters. The method uses a reduced indexing view of the original documents, where only the k best keywords of each document are indexed. An efficient procedure for clustering is speci fied in two parts (a) compute k most similar documents for each document in the collection and (b) group the documents into clusters using these similarity scores. The method has been evaluated on a database of over 50,000 customer service problem reports that are reduced to 3,000 clusters and 5,000 exemplar documents. Results demonstrate efficient clustering performance with excellent group similarity measures.

#index 478430
#* Interestingness in Attribute-Oriented Induction (AOI): Multiple-Level Rule Generation
#@ Maybin K. Muyeba;John A. Keane
#t 2000
#c 21
#% 449588
#% 497971
#% 500400
#% 565968
#! Attribute-Oriented Induction (AOI) is a data mining technique that produces simplified descriptive patterns. Classical AOI uses a predictive strategy to determine distinct values of an attribute but generalises attributes indiscriminately i.e. the value 'ANY' is replaced like any other value without restrictions. AOI only produces interesting rules by using interior concepts of attribute hierarchies. The COMPARE algorithm that integrates predictive and lookahead methods and of order complexity O(np), where n and p are input and generalised tuples respectively, is introduced. The latter method determines distinct values of attribute clusters and greatest number of attribute values with a 'common parent' (except parent 'ANY'). When generating rules, a rough set approach to eliminate redundant attributes is used leading to more interesting multiple-level rules with fewer 'ANY' values than classical AOI.

#index 478431
#* Prior Knowledge in Economic Applications of Data Mining
#@ A. J. Feelders
#t 2000
#c 21
#% 136350
#% 182684
#! A common form of prior knowledge in economic modelling concerns the monotonicity of relations between the dependent and explanatory variables. Monotonicity may also be an important requirement with a view toward explaining and justifying decisions based on such models. We explore the use of monotonicity constraints in classification tree algorithms. We present an application of monotonic classification trees to a problem in house pricing. In this preliminary study we found that the monotonic trees were only slightly worse in classification performance, but were much simpler than their non-monotonic counterparts.

#index 478432
#* Discovering Differences in Patients with Uveitis Through Typical Testors by Class
#@ José Francisco Martínez Trinidad;Miriam Velasco-Sánchez;Edgar E. Contreras-Aravelo
#t 2000
#c 21
#% 195875
#% 1807343
#! An analysis of clinical features on patients with uveitis attending to their localization through typical testors is presented. The main goal for the physician was to discover feature sets such that distinguish four groups of patients with uveitis. In order to solve the problem was used the Testor Theory in the Logical Combinatorial Pattern Recognition context.

#index 478433
#* Mining Weighted Association Rules for Fuzzy Quantitative Items
#@ Attlila Gyenesei
#t 2000
#c 21
#% 152934
#% 210160
#% 412588
#% 481290
#% 481779
#% 641014
#% 673320
#! During the last ten years, data mining, also known as knowledge discovery in databases, has established its position as a prominent and important research area. Mining association rules is one of the important research problems in data mining. Many algorithms have been proposed to find association rules in large databases containing both categorical and quantitative attributes. We generalize this to the case where part of attributes are given weights to reflect their importance to the user. In this paper, we introduce the problem of mining weighted quantitative association rules based on fuzzy approach. Using the fuzzy set concept, the discovered rules are more understandable to a human. We propose two different definitions of weighted support: with and without normalization. In the normalized case, a subset of a frequent itemset may not be frequent, and we cannot generate candidate k-itemsets simply from the frequent (k-1)-itemsets. We tackle this problem by using the concept of z-potential frequent subset for each candidate itemset. We give an algorithm for mining such quantitative association rules. Finally, we describe the results of using this approach on a real-life dataset.

#index 478434
#* Transparency and Predicive Power: Explaining Complex Classification Models
#@ Gerhard Paass;Jörg Kindermann
#t 2000
#c 21
#% 364386
#% 403980
#% 477658
#% 703975
#! Complex classification models like neural networks usually have lower errors than simple models. They often have very many interdependent parameters, whose effects no longer can be understood by the user. For many applications, especially in the financial industry, it is vital to understand the reasons why a classification model arrives at a specific decision. We propose to use the full model for the classification and explain its predictive distribution by an explanation model capturing its main functionality. For a real world credit scoring application we investigate a spectrum of explanation models of different type and complexity.

#index 478435
#* Combining Multiple Models with Meta Decision Trees
#@ Ljupco Todorovski;Saso Dzeroski
#t 2000
#c 21
#% 99396
#% 132938
#% 136350
#% 191919
#% 209021
#% 225872
#% 424994
#% 458347
#% 466096
#% 478107
#% 700962
#! The paper introduces meta decision trees (MDTs), a novel method for combining multiple models. Instead of giving a prediction, MDT leaves specify which model should be used to obtain a prediction. We present an algorithm for learning MDTs based on the C4.5 algorithm for learning ordinary decision trees (ODTs). An extensive experimental evaluation of the new algorithm is performed on twenty-one data sets, combining models generated by five learning algorithms: two algorithms for learning decision trees, a rule learning algorithm, a nearest neighbor algorithm and a naive Bayes algorithm. In terms of performance, MDTs combine models better than voting and stacking with ODTs. In addition, MDTs are much more concise than ODTs used for stacking and are thus a step towards comprehensible combination of multiple models.

#index 478436
#* Aggregation and Association in Cross Tables
#@ Gilbert Ritschard;Nicolas Nicoloyannis
#t 2000
#c 21
#! The strength of association between the row and column variables in a cross table varies with the level of aggregation of each variable. In many settings like the simultaneous discretization of two variables, it is useful to determine the aggregation level that maximizes the association. This paper deals with the behavior of association measures with respect to the aggregation of rows and columns and proposes an heuristic algorithm to (quasi-)maximize the association through aggregation.

#index 478437
#* Discovering Task Neighbourhoods Through Landmark Learning Performances
#@ Hilan Bensusan;Christophe G. Giraud-Carrier
#t 2000
#c 21
#% 126842
#% 136350
#% 191910
#% 197060
#% 380342
#% 458220
#% 458366
#% 466722
#% 478112
#! Arguably, model selection is one of the major obstacles, and a key once solved, to the widespread use of machine learning/data mining technology in business. Landmarking is a novel and promising metalearning approach to model selection. It uses accuracy estimates from simple and efficient learners to describe tasks and subsequently construct meta-classifiers that predict which one of a set of more elaborate learning algorithms is appropriate for a given problem. Experiments show that landmarking compares favourably with the traditional statistical approach to meta-learning.

#index 478438
#* Learning First Order Logic Time Series Classifiers: Rules and Boosting
#@ Juan J. Rodríguez;Carlos Alonso González;Henrik Boström
#t 2000
#c 21
#% 232122
#% 283138
#% 312727
#% 380466
#% 424997
#% 465751
#% 466260
#% 497964
#% 550417
#% 564956
#% 1272165
#% 1273928
#! A method for learning multivariate time series classifiers by inductive logic programming is presented. Two types of background predicate that are suited for this task are introduced: interval based predicates, such as always, and distance based, such as the euclidean distance. Special purpose techniques are presented that allow these predicates to be handled efficiently when performing top-down induction. Furthermore, by employing boosting, the accuracy of the resulting classifiers can be improved significantly. Experiments on several different datasets show that the proposed method is highly competitive with previous approaches.

#index 478439
#* Decision Tree Toolkit: A Component-Based Library of Decision Tree Algorithms
#@ Nikos Drossos;Athanassios Papagelis;Dimitrios Kalles
#t 2000
#c 21
#% 92533
#% 136350
#% 290482
#% 449588
#% 458307
#% 1650665
#! This paper reports on the development of a library of decision tree algorithms in Java. The basic model of a decision tree algorithm is presented and then used to justify the design choices and system architecture issues. The library has been designed for flexibility and adaptability. Its basic goal was an open system that could easily embody parts of different conventional as well as new algorithms, without the need of knowing the inner organization of the system in detail. The system has an integrated interface (ClassExplorer), which is used for controlling and combining components that comprise decision trees. The ClassExplorer can create objects "on the fly", from classes unknown during compilation time. Conclusions and considerations about extensions towards a more visual system are also described.

#index 478440
#* Hierarchical Document Clustering Based on Tolerance Rough Set Model
#@ Saori Kawasaki;Ngoc Binh Nguyen;Tu Bao Ho
#t 2000
#c 21
#% 115462
#% 366687
#% 386105
#! Clustering is a powerful tool for knowledge discovery in text collections. The quality of document clustering depends not only on clustering algorithms but also on document representation models. We develop a hierarchical document clustering algorithm based on a tolerance rough set model (TRSM) for representing documents, which offers a way of considering semantics relatedness between documents. The results of validation and evaluation of this method suggest that this clustering algorithm can be well adapted to text mining.

#index 478441
#* Basis of Fuzzy Knowledge Discovery System
#@ Maurice Bernadet
#t 2000
#c 21
#% 95224
#% 119164
#% 125635
#% 182919
#% 194767
#! Considering a fuzzy knowledge discovery system we have realized we describe here the main features of such systems. First, we consider possible methods to define fuzzy partitions on numerical attributes in order to replace continuous or symbolic attributes by fuzzy ones. We explain then how to generalize statistical indexes to evaluate fuzzy rules, detailing a special index, the intensity of implication and its generalization to fuzzy rules. We describe then one algorithm use to extract fuzzy rules. Since many fuzzy operators are available, we propose a method to choose one fuzzy conjunction, one fuzzy implication and one fuzzy aggregation, and we explain how this choice may be validated by comparing the results of the Generalized Modus Ponens applied on the premises of the examples to the effective conclusions in the database. To reduce the important number of fuzzy rules extracted, we consider also some methods to aggregate fuzzy rules, showing that usage of classical reduction schemes requires specific choices of fuzzy operators.

#index 478442
#* Learning Right Sized Belief Networks by Means of a Hybrid Methodology
#@ Silvia Acid;Luis M. de Campos
#t 2000
#c 21
#% 129987
#% 197387
#% 370075
#% 527851
#% 1650282
#% 1650754
#! Previous algoritms for the construction of belief networks structures from data are mainly based either on independence criteria or on scoring metrics. The aim of this paper is to present a hybrid methodology that is a combination of these two approaches, which benefits from characteristics of each one, and to introduce an operative algoritm based on this methodology. We dedicate a special attention to the problem of getting the 'right' size of the belief network induced from data, i.e. finding a trade-off between network complexity and accuracy. We propose several approaches to tackle this matter. Results of the evaluation of the algorithm on the well-known Alarm network are also presented.

#index 478443
#* Mining Relational Databases
#@ Frédéric Moal;Teddy Turmeaux;Christel Vrain
#t 2000
#c 21
#% 136347
#% 232102
#% 449508
#% 545856
#! In this paper, we propose a classification system to induce an intentional definition of a relation from examples, when background knowledge is stored in a relational database composed of several tables and views. Refinement operators have been defined to integrate in a uniform way different induction tools learning numeric and symbolic constraints. The particularity of our approach is to use integrity constraints over the database (keys and foreign keys) to explore the hypotheses space. Moreover new attributes can be introduced, relying on the aggregation operator "group by".

#index 478444
#* Improving Dissimilarity Functions with Domain Knowledge, Applications with IKBS System
#@ David Grosser;Jean Diatta;Noël Conruyt
#t 2000
#c 21
#% 232106
#% 232174
#% 1272304
#! Some of the fundamental and theoretical issues in Knowledge Discovery in Database (KDD) rely on knowledge representation and the use of prior and domain knowledge to extract useful information from data. In many data exploration algorithms, dissimilarity functions do not use domain knowledge for the cases comparison. The Iterative Knowledge Base System (IKBS) has been designed to improve generalization accuracy of exploration algorithms through the use of structural properties of domain models. A general mathematical framework for utilizing structural properties of the domain model encompassing the definition of a Dissimilarity Function for Structured Descriptions is proposed. Applications are conducted with the help of IKBS on a set of databases from the UCI machine learning repository and on structured domain definition data.

#index 478445
#* Biological Sequence Data Mining
#@ Yuh-Jyh Hu
#t 2001
#c 21
#% 196811
#% 251253
#% 271246
#% 466099
#% 469571
#% 469577
#! Biologists have determined that the control and regulation of gene expression is primarily determined by relatively short sequences in the region surrounding a gene. These sequences vary in length, position, redundancy, orientation, and bases. Finding these short sequences is a fundamental problem in molecular biology with important applications. Though there exist many different approaches to signal/motif (i.e. short sequence) finding, in 2000 Pevzner and Sze reported that most current motif finding algorithms are incapable of detecting the target signals in their so-called Challenge Problem. In this paper, we show that using an iterative-restart design, our new algorithm can correctly find the targets. Furthermore, taking into account the fact that some transcription factors form a dimer or even more complex structures, and transcription process can sometimes involve multiple factors, we extend the original problem to an even more challenging one. We address the issue of combinatorial signals with gaps of variable lengths. To demonstrate the efficacy of our algorithm, we tested it on a series of the original and the new challenge problems, and compared it with some representative motif-finding algorithms. In addition, to verify its feasibility in real-world applications, we also tested it on several regulatory families of yeast genes with known motifs. The purpose of this paper is two-fold. One is to introduce an improved biological data mining algorithm that is capable of dealing with more variable regulatory signals in DNA sequences. The other is to propose a new research direction for the general KDD community.

#index 478446
#* Parametric Approximation Algorithms for High-Dimensional Euclidean Similarity
#@ Ömer Egecioglu
#t 2001
#c 21
#% 131062
#% 169805
#% 172949
#% 236692
#% 237187
#% 316526
#% 427199
#% 460862
#% 464195
#% 481609
#% 481947
#% 481956
#% 482109
#% 632089
#! We introduce a spectrum of algorithms for measuring the similarity of high-dimensional vectors in Euclidean space. The algorithms proposed consist of a convex combination of two measures: one which contains summary data about the shape of a vector, and the other about the relative magnitudes of the coordinates. The former is based on a concept called bin-score permutations and a metric to quantify similarity of permutations, the latter on another novel approximation for inner-product computations based on power symmetric functions, which generalizes the Cauchy-Schwarz inequality. We present experiments on time-series data on labor statistics unemployment figures that show the effectiveness of the algorithm as a function of the parameter that combines the two parts.

#index 478447
#* Non-crisp Clustering by Fast, Convergent, and Robust Algorithms
#@ Vladimir Estivill-Castro;Jianhua Yang
#t 2001
#c 21
#% 4249
#% 208207
#% 240208
#% 266283
#% 308767
#% 379504
#% 393792
#% 466425
#% 466427
#% 481281
#% 482213
#% 501066
#% 528156
#% 614610
#% 630264
#% 630984
#% 1273676
#% 1393578
#! We provide sub-quadratic clustering algorithms for generic dissimilarity. Our algorithms are robust because they use medians rather than means as estimators of location, and the resulting representative of a cluster is actually a data item. We demonstrate mathematically that our algorithms converge. The methods proposed generalize approaches that allow a data item to have a degree of membership in a cluster. Because our algorithm is generic to both, fuzzy membership approaches and probabilistic approaches for partial membership, we simply name it non-crisp clustering. We illustrate our algorithms with categorizing WEB visitation paths. We outperform previous clustering methods since they are all of quadratic time complexity (they essentially require computing the dissimilarity between all pairs of paths).

#index 478448
#* Computing Association Rules Using Partial Totals
#@ Frans Coenen;Graham Goulbourne;Paul H. Leng
#t 2001
#c 21
#% 152934
#% 227917
#% 248791
#% 300120
#% 310507
#% 481290
#% 481754
#% 481779
#% 631970
#% 678196
#! The problem of extracting all association rules from within a binary database is well-known. Existing methods may involve multiple passes of the database, and cope badly with densely- packed database records because of the combinatorial explosion in the number of sets of attributes for which incidence-counts must be computed. We describe here a class of methods we have introduced that begin by using a single database pass to perform a partial computation of the totals required, storing these in the form of a set enumeration tree, which is created in time linear to the size of the database. Algorithms for using this structure to complete the count summations are discussed, and a method is described, derived from the well-known Apriori algorithm. Results are presented demonstrating the performance advantage to be gained from the use of this approach.

#index 478449
#* Interesting Fuzzy Association Rules in Quantitative Databases
#@ Jeannette M. de Graaf;Walter A. Kosters;Jeroen J. W. Witteman
#t 2001
#c 21
#% 172386
#% 210160
#% 232136
#% 246002
#% 280436
#% 420112
#% 443310
#% 477962
#% 478303
#% 481758
#% 565963
#! In this paper we examine association rules and their interestingness. Usually these rules are discussed in the world of basket analysis. Instead of customer data we now study the situation with data records of a more general but fixed nature, incorporating quantitative (nonboolean) data. We propose a method for finding interesting rules with the help of fuzzy techniques and taxonomies for the items/attributes. Experiments show that the use of the proposed interestingness measure substantially decreases the number of rules.

#index 478450
#* Internet Document Filtering Using Fourier Domain Scoring
#@ Laurence A. F. Park;Marimuthu Palaniswami;Kotagiri Ramamohanarao
#t 2001
#c 21
#% 205045
#% 255165
#% 255177
#% 255179
#% 290703
#% 616105
#% 678757
#! Most search engines return a lot of unwanted information. A more thorough filtering process can be performed on this information to sort out the relevant documents. A new method called Frequency Domain Scoring (FDS), which is based on the Fourier Transform is proposed. FDS performs the filtering by examining the locality of the keywords throughout the documents. This is examined and compared to the well known techniques Latent Semantic Indexing (LSI) and Cosine measure. We found that FDS obtains better results of how relevant the document is to the query. The other two methods (cosine measure, LSI) do not perform as well mainly because they need a wider variety of documents to determine the topic.

#index 478451
#* Algorithms for the Construction of Concept Lattices and Their Diagram Graphs
#@ Sergei O. Kuznetsov;Sergei A. Obiedkov
#t 2001
#c 21
#% 39702
#% 139183
#% 146099
#% 209020
#% 296633
#% 384416
#% 407822
#% 458222
#% 466166
#% 477661
#! Several algorithms that generate the set of all formal concepts and graphs of line (Hasse) diagrams of concept lattices are considered. Some modifications of well-known algorithms are proposed. Algorithmic complexity of the algorithms is studied both theoretically (in the worst case) and experimentally. Conditions of preferable use of some algorithms are given in terms of density/sparsity of underlying formal contexts.

#index 478452
#* Using Grammatical Inference to Automate Information Extraction from the Web
#@ Theodore W. Hong;Keith L. Clark
#t 2001
#c 21
#% 238555
#% 240955
#% 283050
#% 312860
#% 312861
#% 464720
#% 511733
#% 634970
#% 1348757
#! The World-Wide Web contains a wealth of semistructured information sources that often give partial/overlapping views on the same domains, such as real estate listings or book prices. These partial sources could be used more effectively if integrated into a single view; however, since they are typically formatted in diverse ways for human viewing, extracting their data for integration is a difficult challenge. Existing learning systems for this task generally use hardcoded ad hoc heuristics, are restricted in the domains and structures they can recognize, and/or require manual training. We describe a principled method for automatically generating extraction wrappers using grammatical inference that can recognize general structures and does not rely on manually-labelled examples. Domain-specific knowledge is explicitly separated out in the form of declarative rules. The method is demonstrated in a test setting by extracting real estate listings from web pages and integrating them into an interactive data visualization tool based on dynamic queries.

#index 478453
#* Text Categorization and Semantic Browsing with Self-Organizing Maps on Non-euclidean Spaces
#@ Jörg Ontrup;Helge Ritter
#t 2001
#c 21
#% 46803
#% 114736
#% 173425
#% 202036
#% 234978
#% 316508
#% 318412
#% 458379
#! This paper introduces a new type of Self-Organizing Map (SOM) for Text Categorization and Semantic Browsing. We propose a "hyperbolic SOM" (HSOM) based on a regular tesselation of the hyperbolic plane, which is a non-euclidean space characterized by constant negative gaussian curvature. This approach is motivated by the observation that hyperbolic spaces possess a geometry where the size of a neighborhood around a point increases exponentially and therefore provides more freedom to map a complex information space such as language into spatial relations. These theoretical findings are supported by our experiments, which show that hyperbolic SOMs can successfully be applied to text categorization and yield results comparable to other state-of-the-art methods. Furthermore we demonstrate that the HSOM is able to map large text collections in a semantically meaningful way and therefore allows a "semantic browsing" of text databases.

#index 478454
#* A Data Set Oriented Approach for Clustering Algorithm Selection
#@ Maria Halkidi;Michalis Vazirgiannis
#t 2001
#c 21
#% 203462
#% 232102
#% 248790
#% 248792
#% 260970
#% 296738
#% 393792
#% 478277
#% 479658
#% 479799
#% 481281
#% 631985
#! In the last years the availability of huge transactional and experimental data sets and the arising requirements for data mining created needs for clustering algorithms that scale and can be applied in diverse domains. Thus, a variety of algorithms have been proposed which have application in different fields and may result in different partitioning of a data set, depending on the specific clustering criterion used. Moreover, since clustering is an unsupervised process, most of the algorithms are based on assumptions in order to define a partitioning of a data set. It is then obvious that in most applications the final clustering scheme requires some sort of evaluation. In this paper we present a clustering validity procedure, which taking in account the inherent features of a data set evaluates the results of different clustering algorithms applied to it. A validity index, S_Dbw, is defined according to well-known clustering criteria so as to enable the selection of the algorithm providing the best partitioning of a data set. We evaluate the reliability of our approach both theoretically and experimentally, considering three representative clustering algorithms ran on synthetic and real data sets. It performed favorably in all studies, giving an indication of the algorithm that is suitable for the considered application.

#index 478455
#* Discovery of Temporal Patterns. Learning Rules about the Qualitative Behaviour of Time Series
#@ Frank Höppner
#t 2001
#c 21
#% 59341
#% 166232
#% 232102
#% 232122
#% 232136
#% 319244
#% 459006
#% 481609
#% 549584
#% 1776221
#! Recently, association rule mining has been generalized to the discovery of episodes in event sequences. In this paper, we additionally take durations into account and thus present a generalization to time intervals. We discover frequent temporal patterns in a single series of such labeled intervals, which we call a state sequence. A temporal pattern is defined as a set of states together with their interval relationships described in terms of Allen's interval logic, for instance "A before B, A overlaps C, C overlaps B" or equivalently "state A ends before state B starts, the gap is covered by state C". As an example we consider the problem of deriving local weather forecasting rules that allow us to conclude from the qualitative behaviour of the air-pressure curve to the wind-strength. Here, the states have been extracted automatically from (multivariate) time series and characterize the trend of the time series locally within the assigned time interval.

#index 478456
#* Temporal Rule Discovery for Time-Series Satellite Images and Integration with RDB
#@ Rie Honda;Osamu Konishi
#t 2001
#c 21
#% 152934
#% 232166
#% 260148
#% 361966
#% 427199
#% 481290
#! Feature extraction and knowledge discovery from a large amount of image data such as remote sensing images have become highly required recent years. In this study, a framework for data mining from a set of time-series images including moving objects was presented. Time-series images are transformed into time-series cluster addresses by using clustering by two-stage SOM (Self-organizing map) and time-dependent association rules were extracted from it. Semantically indexed data and extracted rules are stored in the object-relational database, which allows high-level queries by entering SQL through the user interface. This method was applied to weather satellite cloud images taken by GMS-5 and its usefulness was evaluated.

#index 478457
#* Automatic Construction and Refinement of a Class Hierarchy over Multi-valued Data
#@ Nathalie Pernelle;Marie-Christine Rousset;Véronique Ventos
#t 2001
#c 21
#% 131422
#% 170418
#% 248792
#% 279120
#% 466073
#% 481290
#! In many applications, it becomes crucial to help users to access to a huge amount of data by clustering them in a small number of classes described at an appropriate level of abstraction. In this paper, we present an approach based on the use of two languages of description of classes for the automatic clustering of multi-valued data. The first language of classes has a high power of abstraction and guides the construction of a lattice of classes covering the whole set of the data. The second language, more expressive and more precise, is the basis for the refinement of a part of the lattice that the user wants to focus on.

#index 478458
#* Implication-Based Fuzzy Association Rules
#@ Eyke Hüllermeier
#t 2001
#c 21
#% 130919
#% 201894
#% 210160
#% 222212
#% 227953
#% 246002
#% 461909
#% 478441
#% 481290
#% 481754
#% 637609
#! Fuzzy association rules provide a data mining tool which is especially interesting from a knowledge-representational point of view since fuzzy attribute values allow for expressing rules in terms of natural language. In this paper, we show that fuzzy associations can be interpreted in different ways and that the interpretation has a strong influence on their assessment and, hence, on the process of rule mining. We motivate the use of multiple-valued implication operators in order to model fuzzy association rules and propose quality measures suitable for this type of rule. Moreover, we introduce a semantic model of fuzzy association rules which suggests to consider them as a convex combination of simple association rules. This model provides a sound theoretical basis and gives an explicit meaning to fuzzy associations. Particularly, the aforementioned quality measures can be justified within this framework.

#index 478459
#* Distinguishing Natural Language Processes on the Basis of fMRI-Measured Brain Activation
#@ Francisco Pereira;Marcel Just;Tom M. Mitchell
#t 2001
#c 21
#! We present a method for distinguishing two subtly different mental states, on the basis of the underlying brain activation measured with fMRI. The method uses a classifier to learn to distinguish between brain activation in a set of selected voxels (volume elements) during the processing of two types of sentences, namely ambiguous versus unambiguous sentences. The classifier is then used to distinguish the two states in untrained instances. The method can be generalized to accomplish knowledge discovery in cases where the contrasting brain activation profiles are not known a priori.

#index 478460
#* Pattern Extraction for Time Series Classification
#@ Pierre Geurts
#t 2001
#c 21
#% 232122
#% 302383
#% 310502
#% 310545
#% 357521
#% 466260
#% 701402
#% 705649
#! In this paper, we propose some new tools to allow machine learning classifiers to cope with time series data. We first argue that many time-series classification problems can be solved by detecting and combining local properties or patterns in time series. Then, a technique is proposed to find patterns which are useful for classification. These patterns are combined to build interpretable classification rules. Experiments, carried out on several artificial and real problems, highlight the interest of the approach both in terms of interpretability and accuracy of the induced classifiers.

#index 478461
#* The Musical Expression Project: A Challenge for Machine Learning and Knowledge Discovery
#@ Gerhard Widmer
#t 2001
#c 21
#% 236497
#% 458621
#% 1289265
#! This paper reports on a long-term inter-disciplinary research project that aims at analysing the complex phenomenon of expressive music performance with machine learning and data mining methods. The goals and general research framework of the project are briefly explained, and then a number of challenges to machine learning (and also to computational music analysis) are discussed that arise from the complexity and multi-dimensionality of the musical phenomenon being studied. We also briefly report on first experiments that address some of these issues.

#index 478462
#* Discovery of Temporal Knowledge in Medical Time-Series Databases Using Moving Average, Multiscale Matching, and Rule Induction
#@ Shusaku Tsumoto
#t 2001
#c 21
#% 8175
#% 152934
#% 168559
#% 191680
#% 232102
#% 384978
#% 478468
#% 564391
#! Since hospital information systems have been introduced in large hospitals, a large amount of data, including laboratory examinations, have been stored as temporal databases. The characteristics of these temporal databases are: (1) Each record are inhomogeneous with respect to time-series, including short-term effects and long-term effects. (2) Each record has more than 1000 attributes when a patient is followed for more than one year. (3) When a patient is admitted for a long time, a large amount of data is stored in a very short term. Even medical experts cannot deal with these large databases, the interest in mining some useful information from the data are growing. In this paper, we introduce a combination of extended moving average method, multiscale matching and rule induction method to discover new knowledge in medical temporal databases. This method was applied to a medical dataset, the results of which show that interesting knowledge is discovered from each database.

#index 478463
#* Combining Discrete Algorithmic and Probabilistic Approaches in Data Mining
#@ Heikki Mannila
#t 2001
#c 21
#! Data mining research has approached the problems of analyzing large data sets in two ways. Simplifying a lot, the approaches can be characterized as follows. The database approach has concentrated on figuring out what types of summaries can be computed fast, and then finding ways of using those summaries. The model-based approach has focused on first finding useful model classes and then fast ways of fitting those models. In this talk I discuss some examples of both and describe some recent developments which try to combine the two approaches.

#index 478464
#* Self-Similar Layered Hidden Markov Models
#@ Jafar Adibi;Wei-Min Shen
#t 2001
#c 21
#% 44876
#% 51999
#% 149237
#% 246836
#% 251460
#% 280482
#% 292235
#% 300160
#% 363744
#% 384911
#% 592062
#% 1271882
#% 1290043
#! Hidden Markov Models (HMM) have proven to be useful in a variety of real world applications where considerations for uncertainty are crucial. Such an advantage can be more leveraged if HMM can be scaled up to deal with complex problems. In this paper, we introduce, analyze and demonstrate Self-Similar Layered HMM (SSLHMM), for a certain group of complex problems which show self-similar property, and exploit this property to reduce the complexity of model construction. We show how the embedded knowledge of self-similar structure can be used to reduce the complexity of learning and increase the accuracy of the learned model. Moreover, we introduce three different types of self-similarity in SSLHMM, and investigate their performance in the context of synthetic data and real-world network databases. We show that SSLHMM has several advantages comparing to conventional HMM techniques and it is more efficient and accurate than one-step, flat method for model construction.

#index 478465
#* Identification of ECG Arrhythmias Using Phase Space Reconstruction
#@ Felice M. Roberts;Richard J. Povinelli;Kristina M. Ropella
#t 2001
#c 21
#% 376266
#% 710509
#! Changes in the normal rhythmicity of a human heart may result in different cardiac arrhythmias, which may be immediately fatal or cause irreparable damage to the heart when sustained over long periods of time. The ability to automatically identify arrhythmias from ECG recordings is important for clinical diagnosis and treatment, as well as, for understanding the electrophysiological mechanisms of the arrhythmias. This paper proposes a novel approach to efficiently and accurately identify normal sinus rhythm and various ventricular arrhythmias through a combination of phase space reconstruction and machine learning techniques. Data was recorded from patients experiencing spontaneous arrhythmia, as well as, induced arrhythmia. The phase space attractors of the different rhythms were learned from both inter- and intra-patient arrhythmic episodes. Out-of-sample ECG rhythm recordings were classified using the learned attractor probability distributions with an overall accuracy of 83.0%.

#index 478466
#* Fusion of Meta-knowledge and Meta-data for Case-Based Model Selection
#@ Melanie Hilario;Alexandros Kalousis
#t 2001
#c 21
#% 17144
#% 18378
#% 169767
#% 176887
#% 191910
#% 380342
#% 466722
#% 565970
#% 1051405
#! Meta-learning for model selection, as reported in the symbolic machine learning community, can be described as follows. First, it is cast as a purely data-driven predictive task. Second, it typically relies on a mapping of dataset characteristics to some measure of generalization performance (e.g., error). Third, it tends to ignore the role of algorithm parameters by relying mostly on default settings. This paper describes a case-based system for model selection which combines knowledge and data in selecting a (set of) algorithm(s) to recommend for a given task. The knowledge consists mainly of the similarity measures used to retrieve records of past learning experiences as well as profiles of learning algorithms incorporated into the conceptual meta-model. In addition to the usual dataset characteristics and error rates, the case base includes objects describing the evaluation strategy and the learner parameters used. These have two major roles: they ensure valid and meaningful comparisons between independently reported findings, and they facilitate replication of past experiments. Finally, the case-based meta-learner can be used not only as a predictive tool but also as an exploratory tool for gaining further insight into previously tested algorithms and datasets.

#index 478467
#* Bloomy Decision Tree for Multi-objective Classification
#@ Einoshin Suzuki;Masafumi Gotoh;Yuta Choki
#t 2001
#c 21
#% 136350
#% 179768
#% 236497
#% 420084
#% 449531
#% 449588
#% 706402
#! This paper presents a novel decision-tree induction for a multi-objective data set, i.e. a data set with a multi-dimensional class. Inductive decision-tree learning is one of the frequently-used methods for a single-objective data set, i.e. a data set with a single-dimensional class. However, in a real data analysis, we usually have multiple objectives, and a classifier which explains them simultaneously would be useful and would exhibit higher readability. A conventional decision-tree inducer requires transformation of a multi-dimensional class into a single-dimensional class, but such a transformation can considerably worsen both accuracy and readability. In order to circumvent this problem we propose a bloomy decision tree which deals with a multi-dimensional class without such transformations. A bloomy decision tree has a set of split nodes each of which splits examples according to their attribute values, and a set of flower nodes each of which predicts a class dimension of examples. A flower node appears not only at the fringe of a tree but also inside a tree. Our pruning is executed during tree construction, and evaluates each class dimension based on CramÉr's V. The proposed method has been implemented as D3-B (Decision tree in Bloom), and tested with eleven data sets. The experiments showed that D3-B has higher accuracies in nine data sets than C4.5 and tied with it in the other two data sets. In terms of readability, D3-B has a smaller number of split nodes in all data sets, and thus outperforms C4.5.

#index 478468
#* Mining Positive and Negative Knowledge in Clinical Databases Based on Rough Set Model
#@ Shusaku Tsumoto
#t 2001
#c 21
#% 20701
#% 136350
#% 154305
#% 168559
#% 275064
#% 369349
#% 404362
#! One of the most important problems on rule induction methods is that extracted rules partially represent information on experts' decision processes, which makes rule interpretation by domain experts difficult. In order to solve this problem, the characteristics of medical reasoning is discussed positive and negative rules are introduced which model medical experts' rules. Then, for induction of positive and negative rules, two search algorithms are provided. The proposed rule induction method was evaluated on medical databases, the experimental results of which show that induced rules correctly represented experts' knowledge and several interesting patterns were discovered.

#index 478469
#* Discovering Fuzzy Classification Rules with Genetic Programming and Co-evolution
#@ Roberto R. F. Mendes;Fabricio de B. Voznika;Alex Alves Freitas;Júlio C. Nievola
#t 2001
#c 21
#% 160831
#% 182919
#% 232106
#% 252473
#% 284608
#% 382327
#% 389460
#% 478105
#% 478117
#% 683563
#% 743911
#% 1022823
#! In essence, data mining consists of extracting knowledge from data. This paper proposes a co-evolutionary system for discovering fuzzy classification rules. The system uses two evolutionary algorithms: a genetic programming (GP) algorithm evolving a population of fuzzy rule sets and a simple evolutionary algorithm evolving a population of membership function definitions. The two populations co-evolve, so that the final result of the co-evolutionary process is a fuzzy rule set and a set of membership function definitions which are well adapted to each other. In addition, our system also has some innovative ideas with respect to the encoding of GP individuals representing rule sets. The basic idea is that our individual encoding scheme incorporates several syntactical restrictions that facilitate the handling of rule sets in disjunctive normal form. We have also adapted GP operators to better work with the proposed individual encoding scheme.

#index 478470
#* Knowledge Discovery in Multi-label Phenotype Data
#@ Amanda Clare;Ross D. King
#t 2001
#c 21
#% 136350
#% 191910
#% 251240
#% 277919
#% 310564
#% 311034
#% 465747
#% 466078
#% 471586
#% 1290045
#! The biological sciences are undergoing an explosion in the amount of available data. New data analysis methods are needed to deal with the data. We present work using KDD to analyse data from mutant phenotype growth experiments with the yeast S. cerevisiae to predict novel gene functions. The analysis of the data presented a number of challenges: multi-class labels, a large number of sparsely populated classes, the need to learn a set of accurate rules (not a complete classification), and a very large amount of missing values. We developed resampling strategies and modified the algorithm C4.5 to deal with these problems. Rules were learnt which are accurate and biologically meaningful. The rules predict function of 83 putative genes of currently unknown function at an estimated accuracy of ≥ 80%.

#index 478593
#* Detecting Temporal Change in Event Sequences: An Application to Demographic Data
#@ Hendrik Blockeel;Johannes Fürnkranz;Alexia Prskawetz;Francesco Billari
#t 2001
#c 21
#% 232136
#% 280436
#% 310505
#% 320944
#% 392781
#% 420063
#% 420087
#% 420126
#% 459006
#% 463903
#% 479785
#% 481611
#! In this paper, we discuss an approach for discovering temporal changes in event sequences, and present first results from a study on demographic data. The data encode characteristic events in a person's life course, such as their birth date, the begin and end dates of their partnerships and marriages, and the birth dates of their children. The goal is to detect significant changes in the chronology of these events over people from different birth cohorts. To solve this problem, we encoded the temporal information in a first-order logic representation, and employed Warmr, an ILP system that discovers association rules in a multi-relational data set, to detect frequent patterns that show significant variance over different birth cohorts. As a case study in multirelational association rule mining, this work illustrates the flexibility resulting from the use of first-order background knowledge, but also uncovers a number of important issues that hitherto received little attention.

#index 478594
#* A General Measure of Rule Interestingness
#@ Szymon Jaroszewicz;Dan A. Simovici
#t 2001
#c 21
#% 93250
#% 280436
#% 290482
#% 304319
#% 372603
#% 380104
#% 420073
#% 479643
#% 545870
#! The paper presents a new general measure of rule interestingness. Many known measures such as chi-square, gini gain or entropy gain can be obtained from this measure by setting some numerical parameters, including the amount of trust we have in the estimation of the probability distribution of the data. Moreover, we show that there is a continuum of measures having chi-square, Gini gain and entropy gain as boundary cases. Therefore our measure generalizes both conditional and unconditional classical measures of interestingness. Properties and experimental evaluation of the new measure are also presented.

#index 478595
#* Automatic Text Summarization Using Unsupervised and Semi-supervised Learning
#@ Massih-Reza Amini;Patrick Gallinari
#t 2001
#c 21
#% 131258
#% 194251
#% 218978
#% 252011
#% 262112
#% 266292
#% 266370
#% 280835
#% 309116
#% 741106
#% 757855
#% 1306081
#! This paper investigates a new approach for unsupervised and semi-supervised learning. We show that this method is an instance of the Classification EM algorithm in the case of gaussian densities. Its originality is that it relies on a discriminant approach whereas classical methods for unsupervised and semi-supervised learning rely on density estimation. This idea is used to improve a generic document summarization system, it is evaluated on the Reuters news-wire corpus and compared to other strategies.

#index 478596
#* Propositionalisation and Aggregates
#@ Arno J. Knobbe;Marc de Haas;Arno Siebes
#t 2001
#c 21
#% 224755
#% 420087
#% 458159
#% 477969
#% 478107
#% 478288
#% 550390
#% 550551
#% 1273915
#! The fact that data is scattered over many tables causes many problems in the practice of data mining. To deal with this problem, one either constructs a single table by hand, or one uses a Multi-Relational Data Mining algorithm. In this paper, we propose a different approach in which the single table is constructed automatically using aggregate functions, which repeatedly summarise information from different tables over associations in the datamodel. Following the construction of the single table, we apply traditional data mining algorithms. Next to an in-depth discussion of our approach, the paper presents results of experiments on three well-known data sets.

#index 478597
#* Scalability, Search, and Sampling: From Smart Algorithms to Active Discovery
#@ Stefan Wrobel
#t 2001
#c 21
#! The focus on scalability to very large datasets has been a distinguishing feature of the KDD endeavour right from the start of the area. In the present stage of its development, the field has begun to seriously approach the issue, and a number of different techniques for scaling up KDD algorithms have emerged. Traditionally, such techniques are concentrating on the search aspects of the problem, employing algorithmic techniques to avoid searching parts of the space or to speed up processing by exploiting properties of the underlying host systems. Such techniques guarantee perfect correctness of solutions, but can never reach sublinear complexity. In contrast, researchers have recently begun to take a fresh and principled look at stochastic sampling techniques which give only an approximate quality guarantee, but can make runtimes almost independent of the size of the database at hand. In the talk, we give an overview of both of these classes of approaches, focusing on individual examples from our own work for more detailed illustrations of how such techniques work. We briefly outline how active learning elements may enhance KDD approaches in the future.

#index 478598
#* Lightweight Collaborative Filtering Method for Binary-Encoded Data
#@ Sholom M. Weiss;Nitin Indurkhya
#t 2001
#c 21
#% 124010
#% 173879
#% 406493
#% 445372
#% 478307
#% 722754
#% 1650569
#% 1650705
#! A lightweight method for collaborative filtering is described that processes binary encoded data. Examples of transactions that can be described in this manner are items purchased by customers or web pages visited by individuals. As with all collaborative filtering, the objective is to match a person's records to customers with similar records. For example, based on prior purchases of a customer, one might recommend new items for purchase by examining stored records of other customers who made similar purchases. Because the data are binary (true-or-false) encoded, and not ranked preferences on a numerical scale, efficient and lightweight schemes are described for compactly storing data, computing similarities between new and stored records, and making recommendations tailored to an individual.

#index 478599
#* Finding Association Rules That Trade Support Optimally against Confidence
#@ Tobias Scheffer
#t 2001
#c 21
#% 152934
#% 172386
#% 227917
#% 232136
#% 310494
#% 310554
#% 398840
#% 458210
#% 459020
#% 562961
#! When evaluating association rules, rules that differ in both support and confidence have to compared; a larger support has to be traded against a higher confidence. The solution which we propose for this problem is to maximize the expected accuracy that the association rule will have for future data. In a Bayesian framework, we determine the contributions of confidence and support to the expected accuracy on future data. We present a fast algorithm that finds the n best rules which maximize the resulting criterion. The algorithm dynamically prunes redundant rules and parts of the hypothesis space that cannot contain better solutions than the best ones found so far. We evaluate the performance of the algorithm (relative to the Apriori algorithm) on realistic knowledge discovery problems.

#index 478600
#* Support Vectors for Reinforcement Learning
#@ Thomas G. Dietterich;Xin Wang
#t 2001
#c 21
#! Support vector machines introduced three important innovations to machine learning research: (a) the application of mathematical programming algorithms to solve optimization problems in machine learning, (b) the control of overfitting by maximizing the margin, and (c) the use of Mercer kernels to convert linear separators into non-linear decision boundaries in implicit spaces. Despite their attractiveness in classification and regression, support vector methods have not been applied to the problem of value function approximation in reinforcement learning. This paper presents three ways of combining linear programming with kernel methods to find value function approximations for reinforcement learning. One formulation is based on the standard approach to SVM regression; the second is based on the Bellman equation; and the third seeks only to ensure that good actions have an advantage over bad actions. All formulations attempt to minimize the norm of the weight vector while fitting the data, which corresponds to maximizing the margin in standard SVM classification. Experiments in a difficult, synthetic maze problem show that all three formulations give excellent performance. However, the third formulation is much more efficient to train and also converges more reliably. Unlike policy gradient and temporal difference methods, the kernel methods described here can easily adjust the complexity of the function approximator to fit the complexity of the value function.

#index 478601
#* Interestingness Measures for Fuzzy Association Rules
#@ Attila Gyenesei
#t 2001
#c 21
#% 152934
#% 210160
#% 246002
#% 280436
#% 412588
#% 458178
#% 478433
#% 478441
#% 481290
#% 501346
#% 545870
#! Data mining tries to discover interesting and surprising patterns among a given data set. An important task is to develop effective measures of interestingness for evaluating and ranking the discovered patterns. A good measure should give a high rank to patterns, which have strong evidence among data, but which yet are not too obvious. Thereby the initial set of patterns can be pruned before human inspection. In this paper we study interestingness measures for generalized quantitative association rules, where the attribute domains can be fuzzy. Several interestingness measures have been developed for the discrete case, and it turns out that many of them can be generalized to fuzzy association rules, as well. More precisely, our goal is to compare the fuzzy version of confidence to some other measures, which are based on statistics and information theory. Our experiments show that although the rankings of rules are relatively similar for most of the methods, also some anomalies occur. Our suggestion is that the information-theoretic measures are a good choice when estimating the interestingness of rules, both for fuzzy and non-fuzzy domains.

#index 478602
#* Gaphyl: A Genetic Algorithms Approach to Cladistics
#@ Clare Bates Congdon
#t 2001
#c 21
#% 207535
#% 369236
#! This research investigates the use of genetic algorithms to solve problems from cladistics - a technique used by biologists to hypothesize the evolutionary relationships between organisms. Since exhaustive search is not practical in this domain, typical cladistics software packages use heuristic search methods to navigate through the space of possible trees in an attempt to find one or more "best" solutions. We have developed a system called Gaphyl, which uses the genetic algorithm approach as a search technique for finding cladograms, and a tree evaluation metric from a common cladistics software package (Phylip). On a nontrivial problem (49 species with 61 attributes), Gaphyl is able to find more of the best known trees with less computational effort than Phylip is able to find (corresponding to more equally plausible evolutionary hypotheses).

#index 478603
#* Error Correcting Codes with Optimized Kullback-Leibler Distances for Text Categorization
#@ Jörg Kindermann;Gerhard Paass;Edda Leopold
#t 2001
#c 21
#% 260001
#% 279755
#% 425047
#% 458379
#% 466737
#% 562950
#% 578558
#% 633657
#% 1272365
#! We extend a multi-class categorization scheme proposed by Dietterich and Bakiri 1995 for binary classifiers, using error correcting codes. The extension comprises the computation of the codes by a simulated annealing algorithm and optimization of Kullback-Leibler (KL) category distances within the code-words. For the first time, we apply the scheme to text categorization with support vector machines (SVMs) on several large text corpora with more than 100 categories. The results are compared to 1-of-N coding (i.e. one SVM for each text category). We also investigate codes with optimized KL distance between the text categories which are merged in the code-words. We find that error correcting codes perform better than 1-of-N coding with increasing code length. For very long codes, the performance is in some cases further improved by KL-distance optimization.

#index 478604
#* Sentence Filtering for Information Extraction in Genomics, a Classification Problem
#@ Claire Nedellec;Mohamed Ould Abdel Vetah;Philippe Bessières
#t 2001
#c 21
#% 136350
#% 243728
#% 278109
#% 376266
#% 465754
#% 469402
#% 471758
#% 755821
#! In some domains, Information Extraction (IE) from texts requires syntactic and semantic parsing. This analysis is computationally expensive and IE is potentially noisy if it applies to the whole set of documents when the relevant information is sparse. A preprocessing phase that selects the fragments which are potentially relevant increases the efficiency of the IE process. This phase has to be fast and based on a shallow description of the texts. We applied various classification methods -- IVI, a Naive Bayes learner and C4.5 -- to this fragment filtering task in the domain of functional genomics. This paper describes the results of this study. We show that the IVI and Naive Bayes methods with feature selection gives the best results as compared with their results without feature selection and with C4.5 results.

#index 478605
#* Data Reduction Using Multiple Models Integration
#@ Aleksandar Lazarevic;Zoran Obradovic
#t 2001
#c 21
#% 280406
#% 369236
#% 708179
#% 1272328
#! Large amount of available information does not necessarily imply that induction algorithms must use all this information. Samples often provide the same accuracy with less computational cost. We propose several effective techniques based on the idea of progressive sampling when progressively larger samples are used for training as long as model accuracy improves. Our sampling procedures combine all the models constructed on previously considered data samples. In addition to random sampling, controllable sampling based on the boosting algorithm is proposed, where the models are combined using a weighted voting. To improve model accuracy, an effective pruning technique for inaccurate models is also employed. Finally, a novel sampling procedure for spatial data domains is proposed, where the data examples are drawn not only according to the performance of previous models, but also according to the spatial correlation of data. Experiments performed on several data sets showed that the proposed sampling procedures outperformed standard progressive sampling in both the achieved accuracy and the level of data reduction.

#index 478606
#* Specifying Mining Algorithms with Iterative User-Defined Aggregates: A Case Study
#@ Fosca Giannotti;Giuseppe Manco;Franco Turini
#t 2001
#c 21
#% 77944
#% 244336
#% 248785
#% 287461
#% 420101
#% 420108
#% 443446
#% 477951
#% 481954
#% 704492
#! We present a way of exploiting domain knowledge in the design and implementation of data mining algorithms, with special attention to frequent patterns discovery, within a deductive framework. In our framework domain knowledge is represented by deductive rules, and data mining algorithms are constructed by means of iterative user-defined aggregates. Iterative user-defined aggregates have a fixed scheme that allows the modularization of data mining algorithms, thus providing a way to exploit domain knowledge in the right point. As a case study, the paper presents user-defined aggregates for specifying a version of the apriori algorithm. Some performance analyses and comparisons are discussed in order to show the effectiveness of the approach.

#index 478607
#* The TwoKey Plot for Multiple Association Rules Control
#@ Antony Unwin;Heike Hofmann;Klaus Bernt
#t 2001
#c 21
#% 152934
#% 280433
#% 280442
#% 310525
#% 405949
#% 464712
#! Association rules have been popular in theory, though it is unclear how much success they have had in practice. Very many association rules are found in any application by any approach and they require effective pruning and filtering. There has been much research in this area recently, but less with the goal of providing a global overview and summary of all rules, which may then be used to explore the rules and to evaluate their worth. The unusual feature of association rules is that those with the highest objective values for the two key criteria (support and confidence) are not usually those with the most subjective interest (because we know the obvious results already). The TwoKey plot is a way of displaying all discovered association rules at once, while also providing the means to review and manage them. It is a powerful tool in order to get a first overview of the distribution of confidence and support. Features such as separate groups of rules or outliers are detected immediately. By exploiting various ancestor relationship structures among the rules, we can use the TwoKey Plot also as a visual assessment tool, closely related to pruning methods - e.g. those proposed by Bing Liu (1999). The concept will be illustrated using the interactive software MARC (Multiple Association Rules Control).

#index 478608
#* A Study on the Hierarchical Data Clustering Algorithm Based on Gravity Theory
#@ Yen-Jen Oyang;Chien-Yu Chen;Tsui-Wei Yang
#t 2001
#c 21
#% 36672
#% 72854
#% 91910
#% 152902
#% 210173
#% 248790
#% 262045
#% 296738
#% 314119
#% 316709
#% 438137
#% 462243
#% 481281
#% 631985
#! This paper discusses the clustering quality and complexities of the hierarchical data clustering algorithm based on gravity theory. The gravity-based clustering algorithm simulates how the given N nodes in a K-dimensional continuous vector space will cluster due to the gravity force, provided that each node is associated with a mass. One of the main issues studied in this paper is how the order of the distance term in the denominator of the gravity force formula impacts clustering quality. The study reveals that, among the hierarchical clustering algorithms invoked for comparison, only the gravity-based algorithm with a high order of the distance term neither has a bias towards spherical clusters nor suffers the well-known chaining effect. Since bias towards spherical clusters and the chaining effect are two major problems with respect to clustering quality, eliminating both implies that high clustering quality is achieved. As far as time complexity and space complexity are concerned, the gravity-based algorithm enjoys either lower time complexity or lower space complexity, when compared with the most well-known hierarchical data clustering algorithms except single-link.

#index 478609
#* Statistification or Mystification? The Need for Statistical Thought in Visual Data Mining
#@ Antony Unwin
#t 2001
#c 21
#! Many graphics are used for decoration rather than for conveying information. Some purport to display information, but provide insufficient supporting evidence. Others are so laden with information that it is hard to see either the wood or the trees. Analysing large data sets is difficult and requires technically efficient procedures and statistically sound methods to generate informative visualisations. Results from big data sets are statistics and they should be statistically justified. Graphics on their own are indicative, but not substantive. They should inform and neither confuse nor mystify. This paper will NOT introduce any new innovative graphics, but will discuss the statistification of graphics - why and how statistical content should be added to graphic displays of large data sets. (There will, however, be illustrations of the Ugly, the Bad and the possibly Good.).

#index 478610
#* Choose Your Words Carefully: An Empirical Study of Feature Selection Metrics for Text Classification
#@ George Forman
#t 2002
#c 21
#% 280817
#% 465754
#% 466266
#% 478128
#% 722935
#! Good feature selection is essential for text classification to make it tractable for machine learning, and to improve classification performance. This study benchmarks the performance of twelve feature selection metrics across 229 text classification problems drawn from Reuters, OHSUMED, TREC, etc. using Support Vector Machines. The results are analyzed for various objectives. For best accuracy, F-measure or recall, the findings reveal an outstanding new feature selection metric, "Bi-Normal Separation" (BNS). For precision alone, however, Information Gain (IG) was superior. A new evaluation methodology is offered that focuses on the needs of the data mining practitioner who seeks to choose one or two metrics to try that are mostly likely to have the best performance for the single dataset at hand. This analysis determined, for example, that IG and Chi-Squared have correlated failures for precision, and that IG paired with BNS is a better choice.

#index 478611
#* A Kernel Approach for Learning from Almost Orthogonal Patterns
#@ Bernhard Schölkopf;Jason Weston;Eleazar Eskin;Christina Leslie;William Stafford Noble
#t 2002
#c 21
#% 116149
#% 197394
#% 269222
#% 304917
#% 397654
#% 425048
#% 722803
#% 837668
#! In kernel methods, all the information about the training data is contained in the Gram matrix. If this matrix has large diagonal values, which arises for many types of kernels, then kernel methods do not perform well. We propose and test several methods for dealing with this problem by reducing the dynamic range of the matrix while preserving the positive definiteness of the Hessian of the quadratic programming problem that one has to solve when training a Support Vector Machine.

#index 478612
#* A Novel Web Text Mining Method Using the Discrete Cosine Transform
#@ Laurence A. F. Park;Marimuthu Palaniswami;Kotagiri Ramamohanarao
#t 2002
#c 21
#% 132779
#% 224728
#% 253191
#% 290703
#% 478450
#% 744786
#% 1010488
#! Fourier Domain Scoring (FDS) has been shown to give a 60% improvement in precision over the existing vector space methods, but its index requires a large storage space. We propose a new Web text mining method using the discrete cosine transform (DCT) to extract useful information from text documents and to provide improved document ranking, without having to store excessive data. While the new method preserves the performance of the FDS method, it gives a 40% improvement- in precision over the established text mining methods when using only 20% of the storage space required by FDS.

#index 478613
#* Spatial Subgroup Mining Integrated in an Object-Relational Spatial Database
#@ Willi Klösgen;Michael May
#t 2002
#c 21
#% 232126
#% 420101
#% 420108
#% 420111
#% 465029
#% 477497
#% 478596
#% 526851
#% 550740
#% 550742
#% 579526
#! SubgroupMiner is an advanced subgroup mining system supporting multirelational hypotheses, efficient data base integration, discovery of causal subgroup structures, and visualization based interaction options. When searching for dependencies between subgroups and a target group, spatial subgroups with multirelational descriptions are explored. Search strategies of data mining algorithms are efficiently integrated with queries in an object-relational query language and executed in a database to enable scalability for spatial data.

#index 478614
#* Clustering Ontology-Based Metadata in the Semantic Web
#@ Alexander Maedche;Valentin Zacharias
#t 2002
#c 21
#% 156337
#% 279755
#% 550556
#! The Semantic Web is an extension of the current web in which information is given well-defined meaning, better enabling computersr and people to work in cooperation. Recently, different applications based on this vision have been designed, e.g. in the fields of knowledge management, community web portals, e-learning, multimedia retrieval, etc. It is obvious that the complex metadata descriptions generated on the basis of pre-defined ontologies serve as perfect input data for machine learning techniques. In this paper we propose an approach for clustering ontology-based metadata. Main contributions of this paper are the definition of a set of similarity measures for comparing ontology-based metadata and an application study using these measures within a hierarchical clustering algorithm.

#index 478615
#* Geography of Differences between Two Classes of Data
#@ Jinyan Li;Limsoon Wong
#t 2002
#c 21
#% 136350
#% 178515
#% 243706
#% 280409
#% 290482
#% 379331
#% 420077
#% 466426
#% 546047
#! Easily comprehensible ways of capturing main differences between two classes of data are investigated in this paper. In addition to examining individual differences, we also consider their neighbourhood. The new concepts are applied to three gene expression datasets to discover diagnostic gene groups. Based on the idea of prediction by collective likelihoods (PCL), a new method is proposed to classify testing samples. Its performance is competitive to several state-of-the-art algorithms.

#index 478616
#* Finding Hidden Factors UsingIndependent Component Analysis
#@ Erkki Oja
#t 2002
#c 21
#! Independent Component Analysis (ICA) is a computational technique for revealing hidden factors that underlie sets of measurements or signals. ICA assumes a statistical model whereby the observed multivariate data, typically given as a large database of samples, are assumed to be linear or nonlinear mixtures of some unknown latent variables. The mixing coeffcients are also unknown. The latent variables are non-gaussian and mutually independent, and they are called the independent components of the observed data. By ICA, these independent components, also called sources or factors, can be found. Thus ICA can be seen as an extension to Principal Component Analysis and Factor Analysis. ICA is a much richer technique, however, capable of finding the sources when these classical methods fail completely.In many cases, the measurements are given as a set of parallel signals or time series. Typical examples are mixtures of simultaneous sounds or human voices that have been picked up by several microphones, brain signal measurements from multiple EEG sensors, several radio signals arriving at a portable phone, or multiple parallel time series obtained from some industrial process. The term blind source separation is used to characterize this problem.The lecture will first cover the basic idea of demixing in the case of a linear mixing model and then take a look at the recent nonlinear demixing approaches.Although ICA was originally developed for digital signal processing applications, it has recently been found that it may be a powerful tool for analyzing text document data as well, if the documents are presented in a suitable numerical form. A case study on analyzing dynamically evolving text is covered in the talk.

#index 478617
#* Explaining Predictions from a Neural Network Ensemble One at a Time
#@ Robert Wall;Padraig Cunningham;Paul Walsh
#t 2002
#c 21
#% 136350
#% 181878
#% 209021
#% 301773
#% 443616
#% 564199
#% 1843680
#! This paper introduces a new method for explaining the predictions of ensembles of neural networks on a case by case basis. The approach of explaining individual examples differs from much of the current research which focuses on producing a global model of the phenomenon under investigation. Explaining individual results is accomplished by modelling each of the networks as a rule-set and computing the resulting coverage statistics for each rule given the data used to train the network. This coverage information is then used to choose the rule or rules that best describe the example under investigation. This approach is based on the premise that ensembles perform an implicit problem space decomposition with ensemble members specialising in different regions of the problem space. Thus explaining an ensemble involves explaining the ensemble members that best fit the example.

#index 478618
#* Association Rules for Expressing Gradual Dependencies
#@ Eyke Hüllermeier
#t 2002
#c 21
#% 152934
#% 210160
#% 213977
#% 280458
#% 420112
#% 420126
#% 478458
#! Data mining methods originally designed for binary attributes can generally be extended to quantitative attributes by partitioning the related numeric domains. This procedure, however, comes along with a loss of information and, hence, has several disadvantages. This paper shows that fuzzy partitions can overcome some of these disadvantages. Particularly, fuzzy partitions allow for the representation of association rules expressing a tendency, that is, a gradual dependence between attributes. This type of rule is introduced and investigated from a conceptual as well as a computational point of view. The evaluation and representation of a gradual association is based on linear regression analysis. Furthermore, a complementary type of association, expressing Absolute deviations rather than tendencies, is discussed in this context.

#index 478619
#* Iterative Data Squashing for Boosting Based on a Distribution-Sensitive Distance
#@ Yuta Choki;Einoshin Suzuki
#t 2002
#c 21
#% 210173
#% 280402
#% 310547
#% 317933
#% 391410
#% 403035
#! This paper proposes, for boosting, a novel method which prevents deterioration of accuracy inherent to data squashing methods. Boosting, which constructs a highly accurate classification model by combining multiple classification models, requires long computational time. Data squashing, which speeds-up a learning method by abstracting the training data set to a smaller data set, typically lowers accuracy. Our SB (Squashing-Boosting) loop, based on a distribution-sensitive distance, alternates data squashing and boosting, and iteratively refines an SF (Squashed-Feature) tree, which provides an appropriately squashed data set. Experimental evaluation with artificial data sets and the KDD Cup 1999 data set clearly shows superiority of our method. compared with conventional methods. We have also empirically evaluated our distance measure as well as our SF tree, and found them superior to alternatives.

#index 478620
#* Mining Hierarchical Decision Rules from Clinical Databases Using Rough Sets aaand Medical Diagnostic Model
#@ Shusaku Tsumoto
#t 2002
#c 21
#% 92533
#% 136350
#% 154305
#% 168559
#% 237867
#% 275064
#% 449566
#! One of the most important problems on rule induction methods is that they cannot extract rules, which plausibly represent experts' decision processes. On one hand, rule induction methods induce probabilistic rules, the description length of which is too short, compared with the experts' rules. On the other hand, construction of Bayesian networks generates too lengthy rules. In this paper, the characteristics of experts' rules are closely examined and a new approach to extract plausible rules is introduced, which consists of the following three procedures. First, the characterization of decision attributes (given classes) is extracted from databases and the classes are classified into several groups with respect to the characterization. Then, two kinds of sub-rules, characterization rules for each group and discrimination rules for each class in the group are induced. Finally, those two parts are integrated into one rule for each decision attribute. The proposed method was evaluated on a medical database, the experimental results of which show that induced rules correctly represent experts' decision processes.

#index 478621
#* Iteratively Selecting Feature Subsets for Mining from High-Dimensional Databases
#@ Hiroshi Mamitsuka
#t 2002
#c 21
#% 116165
#% 136350
#% 243728
#% 252402
#% 269217
#% 385564
#% 420091
#% 424996
#% 464444
#% 465905
#% 466586
#! We propose a new data mining method that is effective for mining from extremely high-dimensional databases. Our proposed method iteratively selects a subset of features from a database and builds a hypothesis with the subset. Our selection of a feature subset has two steps, i.e. selecting a subset of instances from the database, to which predictions by multiple hypotheses previously obtained are most unreliable, and then selecting a subset of features, the distribution of whose values in the selected instances varies the most from that in all instances of the database. We empirically evaluate the effectiveness of the proposed method by comparing its performance with those of two other methods, including Xing et al.'s one of the latest feature subset selection methods. The evaluation was performed on a real-world data set with approximately 140,000 features. Our results show that the performance of the proposed method exceeds those of the other methods, both in terms of the final predictive accuracy and the precision attained at a recall given by Xing et al.'s method. We have also examined the effect of noise in the data and found that the advantage of the proposed method becomes more pronounced for larger noise levels.

#index 478622
#* Optimized Substructure Discovery for Semi-structured Data
#@ Kenji Abe;Shinji Kawasoe;Tatsuya Asai;Hiroki Arimura;Setsuo Arikawa
#t 2002
#c 21
#% 136350
#% 156186
#% 162950
#% 178511
#% 210162
#% 248791
#% 299985
#% 341672
#% 407822
#% 443349
#% 462234
#% 478274
#% 481290
#% 501667
#% 501840
#% 545870
#% 546033
#% 562937
#! In this paper, we consider the problem of discovering interesting substructures from a large collection of semi-structured data in the framework of optimized pattern discovery. We model semi-structured data and patterns with labeled ordered trees, and present an efficient algorithm that discovers the best labeled ordered trees that optimize a given statistical measure, such as the information entropy and the classification accuracy, in a collection of semi-structured data. We give theoretical analyses of the computational complexity of the algorithm for patterns with bounded and unbounded size. Experiments show that the algorithm performs well and discovered interesting patterns on real datasets.

#index 478623
#* Reasoning with Classifiers
#@ Dan Roth
#t 2002
#c 21
#% 97615
#% 239245
#% 266368
#% 271294
#% 464434
#% 722754
#% 815304
#% 1290050
#% 1650318
#! Research in machine learning concentrates on the study of learning single concepts from examples. In this framework the learner attempts to learn a single hidden function from a collection of examples, assumed to be drawn independently from some unknown probability distribution. However, in many cases - as in most natural language and visual processing situations - decisions depend on the outcomes of several different but mutually dependent classifiers. The classifiers' outcomes need to respect some constraints that could arise from the sequential nature of the data or other domain specific conditions,thus requiring a level of inference on top the predictions.We will describe research and present challenges related to Inference with Classifiers - a paradigm in which we address the problem of using the outcomes of several different classifiers in making coherent inferences - those that respect constraints on the outcome of the classifiers. Examples will be given from the natural language domain.

#index 478624
#* Fast Outlier Detection in High Dimensional Spaces
#@ Fabrizio Angiulli;Clara Pizzuti
#t 2002
#c 21
#% 64431
#% 86951
#% 300136
#% 300183
#% 310552
#% 316709
#% 333929
#% 342641
#% 459025
#% 479791
#% 650942
#% 1499584
#! In this paper we propose a new definition of distance-based outlier that considers for each point the sum of the distances from its k nearest neighbors, called weight. Outliers are those points having the largest values of weight. In order to compute these weights, we find the k nearest neighbors of each point in a fast and efficient way by linearizing the search space through the Hilbert space filling curve. The algorithm consists of two phases, the first provides an approximated solution, within a small factor, after executing at most d + 1 scans of the data set with a low time complexity cost, where d is the number of dimensions of the data set. During each scan the number of points candidate to belong to the solution set is sensibly reduced. The second phase returns the exact solution by doing a single scan which examines further a little fraction of the data set. Experimental results show that the algorithm always finds the exact solution during the first phase after d 驴 d + 1 steps and it scales linearly both in the dimensionality and the size of the data set.

#index 478625
#* Efficiently Mining Approximate Models of Associations in Evolving Databases
#@ Adriano Veloso;Bruno Gusmão;Wagner Meira, Jr.;Márcio de Carvalho;Srinivasan Parthasarathy;Mohammed Javeed Zaki
#t 2002
#c 21
#% 250046
#% 287242
#% 300120
#% 334041
#% 379325
#% 391356
#% 420067
#% 464204
#% 466664
#% 481290
#% 511333
#% 564478
#% 632036
#% 678196
#! Much of the existing work in machine learning and data mining has relied on devising efficient techniques to build accurate models from the data. Research on how the accuracyof a model changes as a function of dynamic updates to the databases is very limited. In this work we show that extracting this information: knowing which aspects of the model are changing; and how theyare changing as a function of data updates; can be verye effective for interactive data mining purposes (where response time is often more important than model qualityas long as model qualityi s not too far off the best (exact) model.In this paper we consider the problem of generating approximate models within the context of association mining, a keyda ta mining task. We propose a new approach to incrementallyg enerate approximate models of associations in evolving databases. Our approach is able to detect how patterns evolve over time (an interesting result in its own right), and uses this information in generating approximate models with high accuracy at a fraction of the cost (of generating the exact model). Extensive experimental evaluation on real databases demonstrates the effectiveness and advantages of the proposed approach.

#index 478626
#* On the Discovery of Weak Periodicities in Large Time Series
#@ Christos Berberidis;Ioannis P. Vlahavas;Walid G. Aref;Mikhail J. Atallah;Ahmed K. Elmagarmid
#t 2002
#c 21
#% 58369
#% 172949
#% 341100
#% 460862
#% 463903
#% 481609
#% 487838
#% 631923
#% 631926
#! The search for weak periodic signals in time series data is an active topic of research. Given the fact that rarely a real world dataset is perfectly periodic, this paper approaches this problem in terms of data mining, trying to discover weak periodic signals in time series databases, when no period length is known in advance. In existing time series mining algorithms, the period length is user-specified. We propose an algorithm for finding approximate periodicities in large time series data, utilizing autocorrelation function and FFT. This algorithm is an extension to the partial periodicity detection algorithm presented in a previous paper of ours. We provide some mathematical background as well as experimental results.

#index 478627
#* Long-Term Learning for Web Search Engines
#@ Charles Kemp;Kotagiri Ramamohanarao
#t 2002
#c 21
#% 54970
#% 65946
#% 65947
#% 67565
#% 111304
#% 185289
#% 218982
#% 253188
#% 253191
#% 288166
#% 309093
#% 310567
#% 396728
#% 648114
#! This paper considers how web search engines can learn from the successful searches recorded in their user logs.Document Transformation is a feasible approach that uses these logs to improve document representations. Existing test collections do not allow an adequate investigation of Document Transformation, but we show how a rigorous evaluation of this method can be carried out using the referer logs kept by web servers. We also describe a new strategy for Document Transformation that is suitable for long-term incremental learning.Our experiments show that Document Transformation improves retrieval performance over a medium sized collection of webpages.Commercial search engines may be able to achieve similar improvements by incorporating this approach.

#index 478628
#* Generating Actionable Knowledge by Expert-Guided Subgroup Discovery
#@ Dragan Gamberger;Nada Lavrac
#t 2002
#c 21
#% 81838
#% 232126
#% 232136
#% 331909
#% 449566
#% 464617
#% 477497
#% 478279
#% 478285
#% 557128
#! This paper discusses actionable knowledge generation. Actionable knowledge is explicit symbolic knowledge, typically presented in the form of rules, that allows the decision maker to recognize some important relations and to perform an action, such as targeting a direct marketing campaign, or planning a population screening campaign aimed at targeting individuals with high disease risk. The disadvantages of using standard classification rule learning for this task are discussed, and a subgroup discovery approach proposed. This approach uses a novel definition of rule quality which is extensively discussed.

#index 478629
#* Information Extraction in Structured Documents Using Tree Automata Induction
#@ Raymond Kosala;Jan Van den Bussche;Maurice Bruynooghe;Hendrik Blockeel
#t 2002
#c 21
#% 697
#% 145336
#% 210985
#% 238555
#% 266216
#% 275915
#% 278109
#% 283050
#% 283136
#% 378389
#% 431536
#% 450951
#% 451056
#% 458186
#% 464425
#% 478452
#% 531458
#% 531459
#% 543990
#! Information extraction (IE) addresses the problem of extracting specific information from a collection of documents. Much of the previous work for IE from structured documents formatted in HTML or XML uses techniques for IE from strings, such as grammar and automata induction. However, such documents have a tree structure. Hence it is natural to investigate methods that are able to recognise and exploit this tree structure. We do this by exploring the use of tree automata for IE in structured documents. Experimental results on benchmark data sets show that our approach compares favorably with previous approaches.

#index 478630
#* Privacy-Oriented Data Mining by Proof Checking
#@ Amy P. Felty;Stan Matwin
#t 2002
#c 21
#% 300184
#% 333876
#% 541957
#% 565325
#! This paper shows a new method which promotes ownership of data by people about whom the data was collected. The data owner may preclude the data from being used for some purposes, and allow it to be used for other purposes. We show an approach, based on checking the proofs of program properties, which implements this idea and provides a tool for a verifiable implementation of the Use Limitation Principle. This paper discusses in detail a scheme which implements data privacy following the proposed approach, presents the technical components of the solution, and shows a detailed example. We also discuss a mechanism by which the proposed method could be introduced in industrial practice.

#index 478631
#* A Scalable Constant-Memory Sampling Algorithm for Pattern Discovery in Large Databases
#@ Tobias Scheffer;Stefan Wrobel
#t 2002
#c 21
#% 145224
#% 211583
#% 222442
#% 232126
#% 232136
#% 252042
#% 310500
#% 464294
#% 477497
#% 481779
#% 562961
#% 722920
#! Many data mining tasks can be seen as an instance of the problem of finding the most interesting (according to some utility function) patterns in a large database. In recent years, significant progress has been achieved in scaling algorithms for this task to very large databases through the use of sequential sampling techniques. However, except for sampling-based greedy algorithms which cannot give absolute quality guarantees, the scalability of existing approaches to this problem is only with respect to the data, not with respect to the size of the pattern space: it is universally assumed that the entire hypothesis space fits in main memory. In this paper, we describe how this class of algorithms can be extended to hypothesis spaces that do not fit in memory while maintaining the algorithms' precise 驴 - 驴 quality guarantees. We present a constant memory algorithm for this task and prove that it possesses the required properties. In an empirical comparison, we compare variable memory and constant memory sampling.

#index 478632
#* Dependency Detection in MobiMine and Random Matrices
#@ Hillol Kargupta;Krishnamoorthy Sivakumar;Samiran Ghosh
#t 2002
#c 21
#% 345861
#% 360500
#% 394543
#! This paper describes a novel approach to detect correlation from data streams in the context of MobiMine -- an experimental mobile data mining system. It presents a brief description of the MobiMine and identifies the problem of detecting dependencies among stocks from incrementally observed financial data streams. This is a non-trivial problem since the stock-market data is inherently noisy and small incremental volumes of data makes the estimation process more vulnerable to noise. This paper presents EDS, a technique to estimate the correlation matrix from data streams by exploiting some properties of the distribution of eigenvalues for random matrices. It separates the "information" from the "noise" by comparing the eigen-spectrum generated from the observed data with that of random matrices. The comparison immediately leads to a decomposition of the covariance matrix into two matrices: one capturing the "noise" and the other capturing useful "information." The paper also presents experimental results using Nasdaq 100 stock data.

#index 478633
#* Predicting Rare Classes: Comparing Two-Phase Rule Induction to Cost-Sensitive Boosting
#@ Mahesh V. Joshi;Ramesh C. Agarwal;Vipin Kumar
#t 2002
#c 21
#% 85334
#% 136350
#% 169777
#% 280817
#% 283138
#% 302391
#% 333934
#% 375017
#% 466268
#% 466561
#% 466654
#! Learning good classifier models of rare events is a challenging task. On such problems, the recently proposed two-phase rule induction algorithm, PNrule, outperforms other non-meta methods of rule induction. Boosting is a strong meta-classifier approach, and has been shown to be adaptable to skewed class distributions. PNrule's key feature is to identify the relevant false positives and to collectively remove them. In this paper, we qualitatively argue that this ability is not guaranteed by the boosting methodology. We simulate learning scenarios of varying difficulty to demonstrate that this fundamental qualitative difference in the two mechanisms results in existence of many scenarios in which PNrule achieves comparable or significantly better performance than AdaCost, a strong cost-sensitive boosting algorithm. Even a comparable performance by PNrule is desirable because it yields a more easily interpretable model over an ensemble of models generated by boosting. We also show similar supporting results on real-world and benchmark datasets.

#index 478759
#* Support Approximations Using Bonferroni-Type Inequalities
#@ Szymon Jaroszewicz;Dan A. Simovici
#t 2002
#c 21
#% 232136
#% 478463
#% 492767
#% 528023
#! The purpose of this paper is to examine the usability of Bonferroni-type combinatorial inequalities to estimation of support of itemsets as well as general Boolean expressions. Families of inequalities for various types of Boolean expressions are presented and evaluated experimentally.

#index 478760
#* Multiscale Comparison of Temporal Patternsin Time-Series Medical Databases
#@ Shoji Hirano;Shusaku Tsumoto
#t 2002
#c 21
#% 8175
#% 210173
#% 227924
#% 248790
#% 248792
#% 366687
#% 374537
#% 460862
#% 466661
#% 631923
#% 829139
#! This paper presents a method for analyzing time-series data on laboratory examinations based on phase-constraint multiscale matching and rough clustering. Multiscale matching compares two subsequences throughout various scales of view. It has an advantage of preserving connectivity of subsequences even if the subsequences are represented at different scales. Rough clustering groups up objects according not to the topographic measures such as the center or deviance of objects in a cluster but to the relative similarity and indiscernibility of objects. We use multiscale matching to obtain similarity of sequences and rough clustering to cluster the sequences according to the obtained similarity. We slightly modified dissimilarity measure in multiscale matching so that it suppresses excessive shift of phase that may cause incorrect matching of the sequences. Experimental results on the hepatitis dataset show that the proposed method successfully clustered similar sequences into an independent cluster, and that correspondence of subsequences are also successfully captured.

#index 478761
#* Finding Association Rules with Some Very Frequent Attributes
#@ Frans Coenen;Paul Leng
#t 2002
#c 21
#% 152934
#% 227917
#% 248791
#% 280487
#% 300120
#% 310507
#% 393792
#% 478448
#% 481290
#% 481754
#% 481779
#% 631970
#! A key stage in the discovery of Association Rules in binary databases involves the identification of the "frequent sets", i.e. those sets of attributes that occur together often enough to invite further attention. This stage is also the most computationally demanding, because of the exponential scale of the search space. Particular difficulty is encountered in dealing with very densely-populated data. A special case of this is that of, for example, demographic or epidemiological data, which includes some attributes with very frequent instances, because large numbers of sets involving these attributes will need to be considered. In this paper we describe methods to address this problem, using methods and heuristics applied to a previously-presented generic algorithm, Apriori-TFP. The results we present demonstrate significant performance improvements over the original Apriori-TFP in datasets which include subsets of very frequently-occurring attributes.

#index 478762
#* Involving Aggregate Functions in Multi-relational Search
#@ Arno J. Knobbe;Arno Siebes;Bart Marseille
#t 2002
#c 21
#% 392781
#% 477978
#% 478596
#% 550574
#% 550575
#% 550740
#! The fact that data is scattered over many tables causes many problems in the practice of data mining. To deal with this problem, one either constructs a single table by propositionalisation, or uses a Multi-Relational Data Mining algorithm. In either case, one has to deal with the non-determinacy of one-to-many relationships. In propositionali-sation, aggregate functions have already proven to be powerful tools to handle this non-determinacy. In this paper we show how aggregate functions can be incorporated in the dynamic construction of patterns of Multi-Relational Data Mining

#index 478763
#* Learning with Mixture Models: Concepts and Applications
#@ Padhraic Smyth
#t 2002
#c 21
#! Probabilistic mixture models have been used in statistics for well over a century as flexible data models. More recently these techniques have been adopted by the machine learning and data mining communities in a variety of application settings. We begin this talk with a review of the basic concepts of finite mixture models: what can they represent? how can we learn them from data? and so on. We will then discuss how the traditional mixture model (defined in a fixed dimensional vector space) can be usefully generalized to model non-vector data, such as sets of sequences and sets of curves. A number of real-world applications will be used to illustrate how these techniques can be applied to large-scale real-world data exploration and prediction problems, including clustering of visitors to a Web site based on their sequences of page requests, modeling of sparse high-dimensional "market basket" data for retail forecasting, and clustering of storm trajectories in atmospheric science.

#index 478764
#* Structuring Domain-Specific Text Archives by Deriving a Probabilistic XML DTD
#@ Karsten Winkler;Myra Spiliopoulou
#t 2002
#c 21
#% 291299
#% 312726
#% 320937
#% 352180
#% 391322
#% 443349
#% 463903
#% 466672
#% 474483
#% 477642
#% 478295
#% 479465
#% 1911097
#! Domain-specific documents often share an inherent, though undocumented structure. This structure should be made explicit to facilitate efficient, structure-based search in archives as well as information integration. Inferring a semantically structured XML DTD for an archive and subsequently transforming its texts into XML documents is a promising method to reach these objectives. Based on the KDD-driven DIAs-DEM framework, we propose a new method to derive an archive-specific structured XML document type definition (DTD). Our approach utilizes association rule discovery and sequence mining techniques to structure a previously derived flat, i.e. unstructured DTD. We introduce the notion of a probabilistic DTD that is derived by discovering associations among and frequent sequences of XML tags, respectively.

#index 478765
#* Separability Index in Supervised Learning
#@ Djamel A. Zighed;Stéphane Lallich;Fabrice Muhlenbach
#t 2002
#c 21
#% 36672
#% 136350
#% 376266
#% 566793
#! We propose a new statistical approach for characterizing the class separability degree in Rp. This approach is based on a nonparametric statistic called "the Cut Edge Weight". We show in this paper the principle and the experimental applications of this statistic. First, we build a geometrical connected graph like the Relative Neighborhood Graph of Toussaint on all examples of the learning set. Second, we cut all edges between two examples of a different class. Third, we calculate the relative weight of these cut edges. If the relative weight of the cut edges is in the expected interval of a random distribution of the labels on all the neighborhood graph's vertices, then no neighborhood-based method will give a reliable prediction model. We will say then that the classes to predict are non-separable.

#index 478766
#* A Classification Approach for Prediction of Target Events in Temporal Sequences
#@ Carlotta Domeniconi;Chang-Shing Perng;Ricardo Vilalta;Sheng Ma
#t 2002
#c 21
#% 248798
#% 251654
#% 269217
#% 269218
#% 342592
#% 522023
#! Learning to predict significant events from sequences of data with categorical features is an important problem in many application areas. We focus on events for system management, and formulate the problem of prediction as a classification problem. We perform co-occurrence analysis of events by means of Singular Value Decomposition (SVD) of the examples constructed from the data. This process is combined with Support Vector Machine (SVM) classification, to obtain efficient and accurate predictions. We conduct an analysis of statistical properties of event data, which explains why SVM classification is suitable for such data, and perform an empirical study using real data.

#index 478767
#* Algebraic Techniques for Analysis of Large Discrete-Valued Datasets
#@ Mehmet Koyutürk;Ananth Grama;Naren Ramakrishnan
#t 2002
#c 21
#% 200694
#% 262217
#% 280819
#% 282481
#% 314054
#% 319234
#% 570885
#! With the availability of large scale computing platforms and instrumentation for data gathering, increased emphasis is being placed on efficient techniques for analyzing large and extremely high-dimensional datasets. In this paper, we present a novel algebraic technique based on a variant of semi-discrete matrix decomposition (SDD), which is capable of compressing large discrete-valued datasets in an error bounded fashion. We show that this process of compression can be thought of as identifying dominant patterns in underlying data. We derive efficient algorithms for computing dominant patterns, quantify their performance analytically as well as experimentally, and identify applications of these algorithms in problems ranging from clustering to vector quantization. We demonstrate the superior characteristics of our algorithm in terms of (i) scalability to extremely high dimensions; (ii) bounded error; and (iii) hierarchical nature, which enables multiresolution analysis. Detailed experimental results are provided to support these claims.

#index 478768
#* Unsupervised Learning: Self-aggregation in Scaled Principal Component Space
#@ Chris Ding;Xiaofeng He;Hongyuan Zha;Horst D. Simon
#t 2002
#c 21
#% 60576
#% 74120
#% 266426
#% 296738
#% 313959
#% 342622
#% 356892
#% 466675
#% 729437
#% 1308039
#! We demonstrate that data clustering amounts to a dynamic process of self-aggregation in which data objects move towards each other to form clusters, revealing the inherent pattern of similarity. Self-aggregation is governed by connectivity and occurs in a space obtained by a nonlinear scaling of principal component analysis (PCA). The method combines dimensionality reduction with clustering into a single framework. It can apply to both square similarity matrices and rectangular association matrices.

#index 478769
#* Data Mining in Schizophrenia Research - Preliminary Analysis
#@ Stefan Arnborg;Ingrid Agartz;Håkan Hall;Erik Jönsson;Anna Sillén;Göran Sedvall
#t 2002
#c 21
#% 14749
#% 232117
#% 309208
#% 420055
#! We describe methods used and some results in a study of schizophrenia in a population of affected and unaffected participants, called patients and controls. The subjects are characterized by diagnosis, genotype, brain anatomy (MRI), laboratory tests on blood samples, and basic demographic data. The long term goal is to identify the causal chains of processes leading to disease. We describe a number of preliminary findings, which confirm earlier results on deviations of brain tissue volumes in schizophrenia patients, and also indicate new effects that are presently under further investigation. More importantly, we discuss a number of issues in selection of methods from the very large set of tools in data mining and statistics.

#index 478770
#* Mining All Non-derivable Frequent Itemsets
#@ Toon Calders;Bart Goethals
#t 2002
#c 21
#% 152934
#% 248791
#% 333877
#% 338594
#% 342643
#% 464873
#% 466491
#% 478302
#% 481290
#% 501536
#! Recent studies on frequent itemset mining algorithms resulted in significant performance improvements. However, if the minimal support threshold is set too low, or the data is highly correlated, the number of frequent itemsets itself can be prohibitively large. To overcome this problem, recently several proposals have been made to construct a concise representation of the frequent itemsets, instead of mining all frequent itemsets. The main goal of this paper is to identify redundancies in the set of all frequent itemsets and to exploit these redundancies in order to reduce the result of a mining operation. We present deduction rules to derive tight bounds on the support of candidate itemsets. We show how the deduction rules allow for constructing a minimal representation for all frequent itemsets. We also present connections between our proposal and recent proposals for concise representations and we give the results of experiments on real-life datasets that show the effectiveness of the deduction rules. In fact, the experiments even show that in many cases, first mining the concise representation, and then creating the frequent itemsets from this representation outperforms existing frequent set mining algorithms.

#index 478771
#* SVM Classification Using Sequences of Phonemes and Syllables
#@ Gerhard Paass;Edda Leopold;Martha Larson;Jörg Kindermann;Stefan Eickeler
#t 2002
#c 21
#% 118751
#% 260001
#% 279755
#% 425047
#% 458379
#% 1860547
#! In this paper we use SVMs to classify spoken and written documents. We show that classification accuracy for written material is improved by the utilization of strings of sub-word units with dramatic gains for small topic categories. The classification of spoken documents for large categories using sub-word units is only slightly worse than for written material, with a larger drop for small topicc ategories. Finally it is possible, without loss, to train SVMs on syllables generated from written material and use them to classify audio documents. Our results confirm the strong promise that SVMs hold for robust audio document classification, and suggest that SVMs can compensate for speech recognition error to an extent that allows a significant degree of topic independence to be introduced into the system.

#index 478772
#* The Need for Low Bias Algorithms in Classification Learning from Large Data Sets
#@ Damien Brain;Geoffrey I. Webb
#t 2002
#c 21
#% 91868
#% 136350
#% 204528
#% 209021
#% 235377
#% 280406
#% 312728
#% 420054
#% 424997
#% 465582
#% 479787
#% 481945
#% 1272326
#! This paper reviews the appropriateness for application to large data sets of standard machine learning algorithms, which were mainly developed in the context of small data sets. Sampling and parallelisation have proved useful means for reducing computation time when learning from large data sets. However, such methods assume that algorithms that were designed for use with what are now considered small data sets are also fundamentally suitable for large data sets. It is plausible that optimal learning from large data sets requires a different type of algorithm to optimal learning from small data sets. This paper investigates one respect in which data set size may affect the requirements of a learning algorithm - the bias plus variance decomposition of classification error. Experiments show that learning from large data sets may be more effective when using an algorithm that places greater emphasis on bias management, rather than variance management.

#index 478773
#* Rule Induction for Classification of Gene Expression Array Data
#@ Per Lidén;Lars Asker;Henrik Boström
#t 2002
#c 21
#% 61792
#% 129980
#% 297463
#% 425048
#% 449559
#% 449566
#% 449588
#% 458229
#% 550582
#% 1290052
#! Gene expression array technology has rapidly become a standard tool for biologists. Its use within areas such as diagnostics, toxicology, and genetics, calls for good methods for finding patterns and prediction models from the generated data. Rule induction is one promising candidate method due to several attractive properties such as high level of expressiveness and interpretability. In this work we investigate the use of rule induction methods for mining gene expression patterns from various cancer types. Three different rule induction methods are evalu-tedoon two public tumor tissue data sets. The methods are shown to obtain as good prediction accuracy as the best current methods, at the same time allowing for straightforward interpretation of the prediction models. These models typically consist of small sets of simple rules, which associate a few genes and expression levels with specific types of cancer. We also show that information gain is a useful measure for ranked feature selection in this domain.

#index 478774
#* Clustering Transactional Data
#@ Fosca Giannotti;Cristian Gozzi;Giuseppe Manco
#t 2002
#c 21
#% 61552
#% 300121
#% 316709
#% 329562
#% 586827
#% 631985
#% 704492
#! In this paper we present a partitioning method capable to manage transactions, namelyt uples of variable size of categorical data. We adapt the standard definition of mathematical distance used in the K- Means algorithm to represent dissimilarityam ong transactions, and redefine the notion of cluster centroid. The cluster centroid is used as the representative of the common properties of cluster elements. We show that using our concept of cluster centroid together with Jaccard distance we obtain results that are comparable in qualityw ith the most used transactional clustering approaches, but substantial improve their efficiency.

#index 478775
#* Using Condensed Representations for Interactive Association Rule Mining
#@ Baptiste Jeudy;Jean-Francois Boulicaut
#t 2002
#c 21
#% 232136
#% 248785
#% 279120
#% 280454
#% 310494
#% 333877
#% 338594
#% 420062
#% 420076
#% 458827
#% 478284
#% 478302
#% 484862
#% 487532
#% 495270
#% 501536
#% 998627
#! Association rule mining is a popular data mining task. It has an interactive and iterative nature, i.e., the user has to refine his mining queries until he is satisfied with the discovered patterns. To support such an interactive process, we propose to optimize sequences of queries by means of a cache that stores information from previous queries. Unlike related works, we use condensed representations like free and closed itemsets for both data mining and caching. This results in a much more efficient mining technique in highly correlated data and a much smaller cache than in previous approaches.

#index 564391
#* Knowledge Discovery in Medical Multi-databases: A Rough Set Approach
#@ Shusaku Tsumoto
#t 1999
#c 21

#index 564396
#* An Experimental Study of Partition Quality Indices in Clustering
#@ Céline Robardet;Fabien Feschet;Nicolas Nicoloyannis
#t 2000
#c 21
#% 36672
#% 92537
#% 451052
#% 477629
#% 1272283
#! We present a preliminary study to define a comparison protocol to evaluate different quality measures used in supervised and unsupervised clustering as objective functions. We first define an order on the set of partitions to capture the common notion of a good partition towards the knowing of the ideal one. We demonstrate the efficiency of this approach by providing several experiments.

#index 564401
#* Fast Algorithms for Mining Emerging Patterns
#@ James Bailey;Thomas Manoukian;Kotagiri Ramamohanarao
#t 2002
#c 21
#% 136350
#% 248791
#% 262097
#% 279120
#% 280409
#% 300120
#% 342604
#% 420062
#% 481290
#% 501540
#% 501982
#% 1289265
#! Emerging Patterns are itemsets whose supports change significantly from one dataset to another. They are useful as a means of discovering distinctions inherently present amongst a collection of datasets and have been shown to be a powerful technique for constructing accurate classifiers. The task of finding such patterns is challenging though, and efficient techniques for their mining are needed.In this paper, we present a new mining method for a particular type of emerging pattern known as a jumping emerging pattern. The basis of our algorithm is the construction of trees, whose structure specifically targets the likely distribution of emerging patterns. The mining performance is typically around 5 times faster than earlier approaches. We then examine the problem of computing a useful subset of the possible emerging patterns. We show that such patterns can be mined even more efficiently (typically around 10 times faster), with little loss of precision.

#index 565961
#* Neural Networks Design: Rough Set Approach to Continuous Data
#@ Hung Son Nguyen;Marcin S. Szczuka;Dominik Slezak
#t 1997
#c 21

#index 565962
#* A Tutorial Introduction to High Performance Data Mining (Abstract)
#@ Robert L. Grossman
#t 1997
#c 21

#index 565963
#* On Objective Measures of Rule Surprisingness
#@ Alex Alves Freitas
#t 1998
#c 21

#index 565964
#* A Comparison of Batch and Incremental Supervised Learning Algorithms
#@ Leonardo Carbonara;Alastair Borrowman
#t 1998
#c 21

#index 565965
#* Object Mining: A Practical Application of Data Mining for the Construction and Maintenance of Software Components
#@ Anders Torvill Bjorvand
#t 1998
#c 21

#index 565966
#* Diagnosing Acute Appendicitis with Very Simple Classification Rules
#@ Aleksander Øhrn;Henryk Jan Komorowski
#t 1999
#c 21

#index 565967
#* Speeding Up the Search for Optimal Partitions
#@ Tapio Elomaa;Juho Rousu
#t 1999
#c 21

#index 565968
#* Extending Attribute-Oriented Induction as a Key-Preserving Data Mining Method
#@ Maybin K. Muyeba;John A. Keane
#t 1999
#c 21

#index 565969
#* Learning Dynamic Bayesian Belief Networks Using Conditional Phase-Type Distributions
#@ Adele Marshall;Sally I. McClean;Mary Shapcott;Peter Millard
#t 2000
#c 21
#% 75936
#% 128629
#% 185079
#% 443025
#% 1273675
#% 1290046
#% 1349495
#% 1650655
#% 1650757
#% 1650887
#! In this paper, we introduce the Dynamic Bayesian Belief Network (DBBN) and show how it can be used in data mining. DBBNs generalise the concept of Bayesian Belief Networks (BBNs) to include a time dimension. We may thus represent a stochastic (or probabilistic) process along with causal information. The approach combines BBNs for modelling causal information with a latent Markov model for dealing with temporal (survival) events. It is assumed that the model includes both qualitative (causal) and quantitative (survival) variables. We introduce the idea of conditional phase-type (C-Ph) distributions to model such data. These models describe duration until an event occurs in terms of a process consisting of a sequence of phases - the states of a latent Markov model. Our approach is illustrated using data on hospital spells (the process) of geriatric patients along with personal details, admissions reasons, dependency levels and destination (the causal network).

#index 565970
#* Quantifying the Resilience of Inductive Classification Algorithms
#@ Melanie Hilario;Alexandros Kalousis
#t 2000
#c 21
#% 85573
#% 92533
#% 132583
#% 191910
#% 240847
#% 361100
#% 380342
#% 459716
#% 637522
#% 1051405
#! Selecting the most appropriate learning algorithm for a given task has become a crucial research issue since the advent of multiparadigm data mining tool suites. To address this issue, researchers have tried to extract dataset characteristics which might provide clues as to the most appropriate learning algorithm. We propose to extend this research by extracting inducer profiles, i.e., sets of metalevel features which characterize learning algorithms from the point of view of their representation and functionality, efficiency, practicality, and resilience. Values for these features can be determined on the basis of author specifications, expert consensus or previous case studies. However, there is a need to characterize learning algorithms in more quantitative terms on the basis of extensive, controlled experiments. This paper illustrates the proposed approach and reports empirical findings on one resilience-related characteristic of learning algorithms for classification, namely their tolerance to irrelevant variables in training data.

#index 565971
#* A Mixed Similarity Measure in Near-Linear Computational Complexity for Distance-Based Methods
#@ Ngoc Binh Nguyen;Tu Bao Ho
#t 2000
#c 21
#% 136350
#! Many methods of knowledge discovery and data mining are distance-based such as nearest neighbor classification or clustering where similarity measures between objects play an essential role. While real-world databases are often heterogeneous with mixed numeric and symbolic attributes, most available similarity measures can only be applied to either symbolic or numeric data. In such cases, data mining methods often require transforming numeric data into symbolic ones by discretization techniques. Mixed similarity measures (MSMs) without discretization of numeric values are desirable alternatives for objects with mixed symbolic and numeric data. However, the time and space complexities of computing available MSMs are often very high that make MSMs not applicable to large datasets. In the framework of Goodall's MSM inspired by biological taxonomy, computing methods have been done but their time and space complexities so far are at least O(n2 log n2) and O(n2), respectively. In this work, we propose a new and efficient method for computing this MSM with O(n log n) time and O(n) space complexities. We demonstrate experimentally the applicability of new method to large datasets and suggest meta-knowledge on the use of this MSM. Practically, the experimental results show that only the near-linear time and space MSM could be applicable to mining large heterogeneous datasets.

#index 565972
#* Data Structures for Minimization of Total Within-Group Distance for Spatio-temporal Clustering
#@ Vladimir Estivill-Castro;Michael E. Houle
#t 2001
#c 21
#% 21150
#% 34077
#% 68091
#% 122797
#% 210173
#% 277035
#% 277036
#% 481281
#% 527022
#% 551620
#% 566128
#% 1393578
#! Statistical principles suggest minimization of the total within-group distance (TWGD) as a robust criterion for clustering point data associated with a Geographical Information System [17]. This NP-hard problem must essentially be solved using heuristic methods, although admitting a linear programming formulation. Heuristics proposed so far require quadratic time, which is prohibitively expensive for data mining applications. This paper introduces data structures for the management of large bi-dimensional point data sets and for fast clustering via interchange heuristics. These structures avoid the need for quadratic time through approximations to proximity information. Our scheme is illustrated with two-dimensional quadtrees, but can be extended to use other structures suited to three dimensional data or spatial data with time-stamps. As a result, we obtain a fast and robust clustering method.

#index 565973
#* Comparison of Three Objective Functions for Conceptual Clustering
#@ Céline Robardet;Fabien Feschet
#t 2001
#c 21
#% 36672
#% 93262
#% 324276
#% 451052
#% 1272283
#! Unsupervised clustering algorithms aims to synthesize a dataset such that similar objects are grouped together whereas dissimilar ones are separated. In the context of data analysis, it is often interesting to have tools for interpreting the result. There are some criteria for symbolic attributes which are based on the frequency estimation of the attribute-value pairs. Our point of view is to integrate the construction of the interpretation inside the clustering process. To do this, we propose an algorithm which provides two partitions, one on the set of objects and the second on the set of attribute-value pairs such that those two partitions are the most associated ones. In this article, we present a study of several functions for evaluating the intensity of this association.

#index 565974
#* Answering the Most Correlated N Association Rules Efficiently
#@ Jun Sese;Shinichi Morishita
#t 2002
#c 21
#% 152934
#% 201894
#% 227917
#% 227919
#% 248012
#% 248791
#% 280433
#% 280436
#% 299985
#% 300120
#% 300124
#% 310494
#% 310505
#% 481290
#% 631986
#! Many algorithms have been proposed for computing association rules using the support-confidence framework. One drawback of this framework is its weakness in expressing the notion of correlation. We propose an efficient algorithm for mining association rules that uses statistical metrics to determine correlation. The simple application of conventional techniques developed for the support-confidence framework is not possible, since functions for correlation do not meet the anti-monotonicity property that is crucial to traditional methods. In this paper, we propose the heuristics for the vertical decomposition of a database, for pruning unproductive itemsets, and for traversing a set-enumeration tree of itemsets that is tailored to the calculation of the N most significant association rules, where N can be specified by the user. We experimentally compared the combination of these three techniques with the previous statistical approach. Our tests confirmed that the comutational performance improves by several orders of magnitude.

#index 799597
#* Summarization of dynamic content in web collections
#@ Adam Jatowt;Mitsuru Ishizuka
#t 2004
#c 21
#% 168251
#% 207272
#% 217578
#% 272249
#% 287616
#% 357908
#% 411775
#% 445834
#! This paper describes a new research proposal of multi-document summarization of dynamic content in web pages. Much information is lost in the Web due to the temporal character of web documents. Therefore adapting summarization techniques to the web genre is a promising task. The aim of our research is to provide methods for summarizing volatile content retrieved from collections of topically related web pages over defined time periods. The resulting summary ideally would reflect the most popular topics and concepts found in retrospective web collections. Because of the content and time diversities of web changes, it is necessary to apply different techniques than standard methods used for static documents. In this paper we propose an initial solution to this summarization problem. Our approach exploits temporal similarities between web pages by utilizing sliding window concept over dynamic parts of the collection.

#index 799734
#* Proceedings of the 8th European Conference on Principles and Practice of Knowledge Discovery in Databases
#@ Jean-François Boulicaut;Floriana Esposito;Fosca Giannotti;Dino Pedreschi
#t 2004
#c 21

#index 799735
#* Random matrices in data analysis
#@ Dimitris Achlioptas
#t 2004
#c 21
#! We show how carefully crafted random matrices can achieve distance-preserving dimensionality reduction, accelerate spectral computations, and reduce the sample complexity of certain kernel methods.

#index 799736
#* Data privacy
#@ Rakesh Agrawal
#t 2004
#c 21
#! There is increasing need to build information systems that protect the privacy and ownership of data without impeding the flow of information. We will present some of our current work to demonstrate the technical feasibility of building such systems.

#index 799737
#* Breaking through the syntax barrier: searching with entities and relations
#@ Soumen Chakrabarti
#t 2004
#c 21
#! The next wave in search technology will be driven by the identification, extraction, and exploitation of real-world entities represented in unstructured textual sources. Search systems will either let users express information needs naturally and analyze them more intelligently, or allow simple enhancements that add more user control on the search process. The data model will exploit graph structure where available, but not impose structure by fiat. First generation Web search, which uses graph information at the macroscopic level of inter-page hyperlinks, will be enhanced to use fine-grained graph models involving page regions, tables, sentences, phrases, and real-world-entities. New algorithms will combine probabilistic evidence from diverse features to produce responses that are not URLs or pages, but entities and their relationships, or explanations of how multiple entities are related.

#index 799738
#* Real-world learning with Markov logic networks
#@ Pedro Domingos
#t 2004
#c 21
#! Machine learning and data mining systems have achieved many impressive successes, but to become truly widespread they must be able to work with less help from people. This requires automating the data cleaning and integration process, handling multiple types of objects and relations at once, and easily incorporating domain knowledge. In this talk, I describe how we are pursuing these aims using Markov logic networks, a representation that combines first-order logic and probabilistic graphical models. Data from multiple sources is integrated by automatically learning mappings between the objects and terms in them. Rich relational structure is learned using a combination of ILP and statistical techniques. Knowledge is incorporated by viewing logic statements as soft constraints on the models to be learned. Application to a real-world university domain shows our approach to be accurate, efficient, and less labor-intensive than traditional ones.

#index 799739
#* Strength in diversity: the advance of data analysis
#@ David J. Hand
#t 2004
#c 21
#! The scientific analysis of data is only around a century old. For most of that century, data analysis was the realm of only one discipline - statistics. As a consequence of the development of the computer, things have changed dramatically and now there are several such disciplines, including machine learning, pattern recognition, and data mining. This paper looks at some of the similarities and some of the differences between these disciplines, noting where they intersect and, perhaps of more interest, where they do not. Particular issues examined include the nature of the data with which they are concerned, the role of mathematics, differences in the objectives, how the different areas of application have led to different aims, and how the different disciplines have led sometimes to the same analytic tools being developed, but also sometimes to different tools being developed. Some conjectures about likely future developments are given.

#index 799740
#* Mining positive and negative association rules: an approach for confined rules
#@ Maria-Luiza Antonie;Osmar R. Zaïane
#t 2004
#c 21
#! Typical association rules consider only items enumerated in transactions. Such rules are referred to as positive association rules. Negative association rules also consider the same items, but in addition consider negated items (i.e. absent from transactions). Negative association rules are useful in market-basket analysis to identify products that conflict with each other or products that complement each other. They are also very convenient for associative classifiers, classifiers that build their classification model based on association rules. Many other applications would benefit from negative association rules if it was not for the expensive process to discover them. Indeed, mining for such rules necessitates the examination of an exponentially large search space. Despite their usefulness, and while they were referred to in many publications, very few algorithms to mine them have been proposed to date. In this paper we propose an algorithm that extends the support-confidence framework with sliding correlation coefficient threshold. In addition to finding confident positive rules that have a strong correlation, the algorithm discovers negative association rules with strong negative correlation between the antecedents and consequents.

#index 799741
#* An experiment on knowledge discovery in chemical databases
#@ Sandra Berasaluce;Claude Laurenço;Amedeosw Napoli;Gilles Niel
#t 2004
#c 21
#! In this paper, we present an experiment on knowledge discovery in chemical reaction databases. Chemical reactions are the main elements on which relies synthesis in organic chemistry, and this is why chemical reactions databases are of first importance. From a problem-solving process point of view, synthesis in organic chemistry must be considered at several levels of abstraction: mainly a strategic level where general synthesis methods are involved, and a tactic level where actual chemical reactions are applied. The research work presented in this paper is aimed at discovering general synthesis methods from chemical reaction databases in order to design generic and reusable synthesis plans. The knowledge discovery process relies on frequent levelwise itemset search and association rule extraction, but also on chemical knowledge involved within every step of the knowledge discovery process. Moreover, the overall process is supervised by an expert of the domain. The principles of this original periment on mining chemical reaction databases and its results are detailed and discussed.

#index 799742
#* Shape and size regularization in expectation maximization and fuzzy clustering
#@ Christian Borgelt;Rudolf Kruse
#t 2004
#c 21
#! The more sophisticated fuzzy clustering algorithms, like the Gustafson-Kessel algorithm [11] and the fuzzy maximum likelihood estimation (FMLE) algorithm [10] offer the possibility of inducing clusters of ellipsoidal shape and different sizes. The same holds for the EM algorithm for a mixture of Gaussians. However, these additional degrees of freedom often reduce the robustness of the algorithm, thus sometimes rendering their application problematic. In this paper we suggest shape and size regularization methods that handle this problem effectively.

#index 799743
#* Combining multiple clustering systems
#@ Constantinos Boulis;Mari Ostendorf
#t 2004
#c 21
#! Three methods for combining multiple clustering systems are presented and evaluated, focusing on the problem of finding the correspondence between clusters of different systems. In this work, the clusters of individual systems are represented in a common space and their correspondence estimated by either clustering clusters or with Singular Value Decomposition. The approaches are evaluated for the task of topic discovery on three major corpora and eight different clustering algorithms and it is shown experimentally that combination schemes almost always offer gains compared to single systems, but gains from using a combination scheme depend on the underlying clustering systems.

#index 799744
#* Reducing data stream sliding windows by cyclic tree-like histograms
#@ Francesco Buccafurri;Gianluca Lax
#t 2004
#c 21
#! Data reduction is a basic step in a KDD process useful for delivering to successive stages more concise and meaningful data. When mining is applied to data streams, that are continuous data flows, the issue of suitably reducing them is highly interesting, in order to arrange effective approaches requiring multiple scans on data, that, in such a way, may be performed over one or more reduced sliding windows. A class of queries, whose importance in the context of KDD is widely accepted, corresponds to sum range queries. In this paper we propose a histogram-based technique for reducing sliding windows supporting approximate arbitrary (i.e., non biased) sum range queries. The histogram, based on a hierarchical structure (opposed to the flat structure of traditional ones), results suitable for directly supporting hierarchical queries, and, thus, drill-down and roll-up operations. In addition, the structure well supports sliding window shifting and quick query answering (both these operations are loarithmic in the sliding window size). Experimental analysis shows the superiority of our method in terms of accuracy w.r.t. the state-of-the-art approaches in the context of histogram-based sliding window reduction techniques.

#index 799745
#* A framework for data mining pattern management
#@ Barbara Catania;Anna Maddalena;Maurizio Mazza;Elisa Bertino;Stefano Rizzi
#t 2004
#c 21
#! To represent and manage data mining patterns, several aspects have to be taken into account: (i) patterns are heterogeneous in nature; (ii) patterns can be extracted from raw data by using data mining tools (a-posteriori patterns) but also defined by the users and used for example to check how well they represent some input data source (a-priori patterns); (iii) since source data change frequently, issues concerning pattern validity and synchronization are very important; (iv) patterns have to be manipulated and queried according to specific languages. Several approaches have been proposed so far to deal with patterns, however all of them lack some of the previous characteristics. The aim of this paper is to present an overall framework to cope with all these features.

#index 799746
#* Spatial associative classification at different levels of granularity: a probabilistic approach
#@ Michelangelo Ceci;Annalisa Appice;Donato Malerba
#t 2004
#c 21
#! In this paper we propose a novel spatial associative classifier method based on a multi-relational approach that takes spatial relations into account. Classification is driven by spatial association rules discovered at multiple granularity levels. Classification is probabilistic and is based on an extension of naive Bayes classifiers to multi- relational data. The method is implemented in a Data Mining system tightly integrated with an object relational spatial database. It performs the classification at different granularity levels and takes advantage from domain specific knowledge in form of rules that support qualitative spatial reasoning. An application to real-world spatial data is reported. Results show that the use of different levels of granularity is beneficial.

#index 799747
#* AutoPart: parameter-free graph partitioning and outlier detection
#@ Deepayan Chakrabarti
#t 2004
#c 21
#! Graphs arise in numerous applications, such as the analysis of the Web, router networks, social networks, co-citation graphs, etc. Virtually all the popular methods for analyzing such graphs, for example, k-means clustering, METIS graph partitioning and SVD/PCA, require the user to specify various parameters such as the number of clusters, number of partitions and number of principal components. We propose a novel way to group nodes, using information-theoretic principles to choose both the number of such groups and the mapping from nodes to groups. Our algorithm is completely parameter-free, and also scales practically linearly with the problem size. Further, we propose novel algorithms which use this node group structure to get further insights into the data, by finding outliers and computing distances between groups. Finally, we present experiments on multiple synthetic and real-life datasets, where our methods give excellent, intuitive results.

#index 799748
#* Properties and benefits of calibrated classifiers
#@ Ira Cohen;Moises Goldszmidt
#t 2004
#c 21
#! A calibrated classifier provides reliable estimates of the true probability that each test sample is a member of the class of interest. This is crucial in decision making tasks. Procedures for calibration have already been studied in weather forecasting, game theory, and more recently in machine learning, with the latter showing empirically that calibration of classifiers helps not only in decision making, but also improves classification accuracy. In this paper we extend the theoretical foundation of these empirical observations. We prove that (1) a well calibrated classifier provides bounds on the Bayes error (2) calibrating a classifier is guaranteed not to decrease classification accuracy, and (3) the procedure of calibration provides the threshold or thresholds on the decision rule that minimize the classification error. We also draw the parallels and differences between methods that use receiver operating characteristic (ROC) curves and calibration based procedures that are aimed at findig a threshold of minimum error. In particular, calibration leads to improved performance when multiple thresholds exist.

#index 799749
#* A tree-based approach to clustering XML documents by structure
#@ Gianni Costa;Giuseppe Manco;Riccardo Ortale;Andrea Tagarelli
#t 2004
#c 21
#! We propose a novel methodology for clustering XML documents on the basis of their structural similarities. The idea is to equip each cluster with an XML cluster representative, i.e. an XML document subsuming the most typical structural specifics of a set of XML documents. Clustering is essentially accomplished by comparing cluster representatives, and updating the representatives as soon as new clusters are detected. We present an algorithm for the computation of an XML representative based on suitable techniques for identifying significant node matchings and for reliably merging and pruning XML trees. Experimental evaluation performed on both synthetic and real data shows the effectiveness of our approach.

#index 799750
#* Discovery of regulatory connections in microarray data
#@ Michael Egmont-Petersen;Wim de Jonge;Arno Siebes
#t 2004
#c 21
#! In this paper, we introduce a new approach for mining regulatory interactions between genes in microarray time series studies. A number of preprocessing steps transform the original continuous measurements into a discrete representation that captures salient regulatory events in the time series. The discrete representation is used to discover interactions between the genes. In particular, we introduce a new across-model sampling scheme for performing Markov Chain Monte Carlo sampling of probabilistic network classifiers. The results obtained from the microarray data are promising. Our approach can detect interactions caused both by co-regulation and by control-regulation.

#index 799751
#* Learning from little: comparison of classifiers given little training
#@ George Forman;Ira Cohen
#t 2004
#c 21
#! Many real-world machine learning tasks are faced with the problem of small training sets. Additionally, the class distribution of the training set often does not match the target distribution. In this paper we compare the performance of many learning models on a substantial benchmark of binary text classification tasks having small training sets. We vary the training size and class distribution to examine the learning surface, as opposed to the traditional learning curve. The models tested include various feature selection methods each coupled with four learning algorithms: Support Vector Machines (SVM), Logistic Regression, Naive Bayes, and Multinomial Naive Bayes. Different models excel in different regions of the learning surface, leading to meta-knowledge about which to apply in different situations. This helps guide the researcher and practitioner when facing choices of model and feature selection methods in, for example, information retrieval settings and others.

#index 799752
#* Geometric and combinatorial tiles in 0-1 data
#@ Aristides Gionis;Heikki Mannila;Jouni K. Seppänen
#t 2004
#c 21
#! In this paper we introduce a simple probabilistic model, hierarchical tiles, for 0-1 data. A basic tile (X,Y,p) specifies a subset X of the rows and a subset Y of the columns of the data, i.e., a rectangle, and gives a probability p for the occurrence of 1s in the cells of X × Y. A hierarchical tile has additionally a set of exception tiles that specify the probabilities for subrectangles of the original rectangle. If the rows and columns are ordered and X and Y consist of consecutive elements in those orderings, then the tile is geometric; otherwise it is combinatorial. We give a simple randomized algorithm for finding good geometric tiles. Our main result shows that using spectral ordering techniques one can find good orderings that turn combinatorial tiles into geometric tiles. We give empirical results on the performance of the methods.

#index 799753
#* Document classification through interactive supervision of document and term labels
#@ Shantanu Godbole;Abhay Harpale;Sunita Sarawagi;Soumen Chakrabarti
#t 2004
#c 21
#! Effective incorporation of human expertise, while exerting a low cognitive load, is a critical aspect of real-life text classification applications that is not adequately addressed by batch-supervised high-accuracy learners. Standard text classifiers are supervised in only one way: assigning labels to whole documents. They are thus deprived of the enormous wisdom that humans carry about the significance of words and phrases in context. We present HIClass, an interactive and exploratory labeling package that actively collects user opinion on feature representations and choices, as well as whole-document labels, while minimizing redundancy in the input sought. Preliminary experience suggests that, starting with essentially an unlabeled corpus, very little cognitive labor suffices to set up a labeled collection on which standard classifiers perform well.

#index 799754
#* Classifying protein fingerprints
#@ Melanie Hilario;Alex Mitchell;Jee-Hyub Kim;Paul Bradley;Terri Attwood
#t 2004
#c 21
#! Protein fingerprints are groups of conserved motifs which can be used as diagnostic signatures to identify and characterize collections of protein sequences. These fingerprints are stored in the prints database after time-consuming annotation by domain experts who must first of all determine the fingerprint type, i.e., whether a fingerprint depicts a protein family, superfamily or domain. To alleviate the annotation bottleneck, a system called PRECIS has been developed which automatically generates prints records, provisionally stored in a supplement called preprints. One limitation of PRECIS is that its classification heuristics, handcoded by proteomics experts, often misclassify fingerprint type; their error rate has been estimated at 40%. This paper reports on an attempt to build more accurate classifiers based on information drawn from the fingerprints themselves and from the SWISS-PROT database. Extensive experimentation using 10-fold cross-validation led to the selection of a model combiing the ReliefF feature selector with an SVM-RBF learner. The final models error rate was estimated at 14.1% on a blind test set, representing a 26% accuracy gain over PRECIS handcrafted rules.

#index 799755
#* Finding interesting pass patterns from soccer game records
#@ Shoji Hirano;Shusaku Tsumoto
#t 2004
#c 21
#! This paper presents a novel method for finding interesting pass patterns from soccer game records. Taking two features of the pass sequence "temporal irregularity and requirements for multiscale observation" into account, we have developed a comparison method of the sequences based on multiscale matching. The method can be used with hierarchical clustering, that brings us a new style of data mining in sports data. Experimental results on 64 game records of FIFA world cup 2002 demonstrated that the method could discover some interesting pass patterns that may be associated with successful goals.

#index 799756
#* Discovering unexpected information for technology watch
#@ François Jacquenet;Christine Largeron
#t 2004
#c 21
#! The purpose of technology watch is to gather, process and integrate the scientific and technical information that is useful to economic players. In this article, we propose to use text mining techniques to automate processing of data found in scientific text databases. The watch activity introduces an unusual difficulty compared with conventional areas of application for text mining techniques since, instead of searching for frequent knowledge hidden in the texts, the target is unexpected knowledge. As a result, the usual measures used for knowledge discovery have to be revised. For that purpose, we have developed the UnexpectedMiner system using new measures for to estimate the unexpectedness of a document. Our system is evaluated using a base that contains articles relating to the field of machine learning.

#index 799757
#* Scalable density-based distributed clustering
#@ Eshref Januzaj;Hans-Peter Kriegel;Martin Pfeifle
#t 2004
#c 21
#! Clustering has become an increasingly important task in analysing huge amounts of data. Traditional applications require that all data has to be located at the site where it is scrutinized. Nowadays, large amounts of heterogeneous, complex data reside on different, independently working computers which are connected to each other via local or wide area networks. In this paper, we propose a scalable density-based distributed clustering algorithm which allows a user-defined trade-off between clustering quality and the number of transmitted objects from the different local sites to a global server site. Our approach consists of the following steps: First, we order all objects located at a local site according to a quality criterion reflecting their suitability to serve as local representatives. Then we send the best of these representatives to a server site where they are clustered with a slightly enhanced density-based clustering algorithm. This approach is very efficient, because the local detemination of suitable representatives can be carried out quickly and independently from each other. Furthermore, based on the scalable number of the most suitable local representatives, the global clustering can be done very effectively and efficiently. In our experimental evaluation, we will show that our new scalable density-based distributed clustering approach results in high quality clusterings with scalable transmission cost.

#index 799758
#* Summarization of dynamic content in web collections
#@ Adam Jatowt;Mitsuru Ishizuka
#t 2004
#c 21
#! This paper describes a new research proposal of multi-document summarization of dynamic content in web pages. Much information is lost in the Web due to the temporal character of web documents. Therefore adapting summarization techniques to the web genre is a promising task. The aim of our research is to provide methods for summarizing volatile content retrieved from collections of topically related web pages over defined time periods. The resulting summary ideally would reflect the most popular topics and concepts found in retrospective web collections. Because of the content and time diversities of web changes, it is necessary to apply different techniques than standard methods used for static documents. In this paper we propose an initial solution to this summarization problem. Our approach exploits temporal similarities between web pages by utilizing sliding window concept over dynamic parts of the collection.

#index 799759
#* Mining thick skylines over large databases
#@ Wen Jin;Jiawei Han;Martin Ester
#t 2004
#c 21
#! People recently are interested in a new operator, called skyline [3], which returns the objects that are not dominated by any other objects with regard to certain measures in a multi-dimensional space. Recent work on the skyline operator [3,15,8,13,2] focuses on efficient computation of skylines in large databases. However, such work gives users only thin skylines, i.e., single objects, which may not be desirable in some real applications. In this paper, we propose a novel concept, called thick skyline, which recommends not only skyline objects but also their nearby neighbors within -distance. Efficient computation methods are developed including (1) two efficient algorithms, Sampling-and-Pruning and Indexing-and-Estimating, to find such thick skyline with the help of statistics or indexes in large databases, and (2) a highly efficient Microcluster-based algorithm for mining thick skyline. The Microcluster-based method not only leads to substantial savings in computation but also provides a cocise representation of the thick skyline in the case of high cardinalities. Our experimental performance study shows that the proposed methods are both efficient and effective.

#index 799760
#* Ensemble feature ranking
#@ Kees Jong;Jérémie Mary;Antoine Cornuéjols;Elena Marchiori;Michèle Sebag
#t 2004
#c 21
#! A crucial issue for Machine Learning and Data Mining is Feature Selection, selecting the relevant features in order to focus the learning search. A relaxed setting for Feature Selection is known as Feature Ranking, ranking the features with respect to their relevance. This paper proposes an ensemble approach for Feature Ranking, aggregating feature rankings extracted along independent runs of an evolutionary learning algorithm named ROGER. The convergence of ensemble feature ranking is studied in a theoretical perspective, and a statistical model is devised for the empirical validation, inspired from the complexity framework proposed in the Constraint Satisfaction domain. Comparative experiments demonstrate the robustness of the approach for learning (a limited kind of) non-linear concepts, specifically when the features significantly outnumber the examples.

#index 799761
#* Privately computing a distributed k-nn classifier
#@ Murat Kantarcioglu;Chris Clifton
#t 2004
#c 21
#! The ability of databases to organize and share data often raises privacy concerns. Data warehousing combined with data mining, bringing data from multiple sources under a single authority, increases the risk of privacy violations. Privacy preserving data mining provides a means of addressing this issue, particularly if data mining is done in a way that doesnt disclose information beyond the result. This paper presents a method for privately computing k-nn classification from distributed sources without revealing any information about the sources or their data, other than that revealed by the final classification result.

#index 799762
#* Incremental nonlinear PCA for classification
#@ Byung Joo Kim;Il Kon Kim
#t 2004
#c 21
#! The purpose of this study is to propose a new online and nonlinear PCA(OL-NPCA) method for feature extraction from the incremental data. Kernel PCA(KPCA) is widely used for nonlinear feature extraction, however, it has been pointed out that KPCA has the following problems. First, applying KPCA to patterns requires storing and finding the eigenvectors of a kernel matrix, which is infeasible for a large number of data N. Second problem is that in order to update the eigenvectors with an another data, the whole eigenspace should be recomputed. OL-NPCA overcomes these problems by incremental eigenspace update method with a feature mapping function. According to the experimental results, which comes from applying OL-NPCA to a toy and a large data problem, OL-NPCA shows following advantages. First, OL-NPCA is more efficient in memory requirement than KPCA. Second advantage is that OL-NPCA is comparable in performance to KPCA. Furthermore, performance of OL-NPCA can be easily improved by re-learning the data. For classification extracted features are used as input for least squares support vector machine. In our experiments we show that proposed feature extraction method is comparable in performance to a Kernel PCA and proposed classification system shows a high classification performance on UCI benchmarking data and NIST handwritten data set.

#index 799763
#* A spectroscopy of texts for effective clustering
#@ Wenyuan Li;Wee-Keong Ng;Kok-Leong Ong;Ee-Peng Lim
#t 2004
#c 21
#! For many clustering algorithms, such as k-means, EM, and CLOPE, there is usually a requirement to set some parameters. Often, these parameters directly or indirectly control the number of clusters to return. In the presence of different data characteristics and analysis contexts, it is often difficult for the user to estimate the number of clusters in the data set. This is especially true in text collections such as Web documents, images or biological data. The fundamental question this paper addresses is: "How can we effectively estimate the natural number of clusters in a given text collection?". We propose to use spectral analysis, which analyzes the eigenvalues (not eigenvectors) of the collection, as the solution to the above. We first present the relationship between a text collection and its underlying spectra. We then show how the answer to this question enhances the clustering process. Finally, we conclude with empirical results and related work.

#index 799764
#* Constraint-based mining of episode rules and optimal window sizes
#@ Nicolas Méger;Christophe Rigotti
#t 2004
#c 21
#! Episode rules are patterns that can be extracted from a large event sequence, to suggest to experts possible dependencies among occurrences of event types. The corresponding mining approaches have been designed to find rules under a temporal constraint that specifies the maximum elapsed time between the first and the last event of the occurrences of the patterns (i.e., a window size constraint). In some applications the appropriate window size is not known, and furthermore, this size is not the same for different rules. To cope with this class of applications, it has been recently proposed in [2] to specifying the maximal elapsed time between two events (i.e., a maximum gap constraint) instead of a window size constraint. Unfortunately, we show that the algorithm proposed to handle the maximum gap constraint is not complete. In this paper we present a sound and complete algorithm to mine episode rules under the maximum gap constraint, and propose to find, for each rule, the window size corresponding to a local maximum of confidence. We show that the extraction can be efficiently performed in practice on real and synthetic datasets. Finally the experiments show that the notion of local maximum of confidence is significant in practice, since no local maximum are found in random datasets, while they can be found in real ones.

#index 799765
#* Analysing customer Churn in insurance data: a case study
#@ Katharina Morik;Hanna Köpcke
#t 2004
#c 21
#! Designing a new application of knowledge discovery is a very tedious task. The success is determined to a great extent by an adequate example representation. The transformation of given data to the example representation is a matter of feature generation and selection. The search for an appropriate approach is difficult. In particular, if time data are involved, there exist a large variety of how to handle them. Reports on successful cases can provide case designers with a guideline for the design of new, similar cases. In this paper we present a complete knowledge discovery process applied to insurance data. We use the TF/IDF representation from information retrieval for compiling time-related features of the data set. Experimental reasults show that these new features lead to superior results in terms of accuracy, precision and recall. A heuristic is given which calculates how much the feature space is enlarged or shrinked by the transformation to TF/IDF.

#index 799766
#* Nomograms for visualization of naive Bayesian classifier
#@ Martin Možina;Janez Demšar;Michael Kattan;Blaž Zupan
#t 2004
#c 21
#! Besides good predictive performance, the naive Bayesian classifier can also offer a valuable insight into the structure of the training data and effects of the attributes on the class probabilities. This structure may be effectively revealed through visualization of the classifier. We propose a new way to visualize the naive Bayesian model in the form of a nomogram. The advantages of the proposed method are simplicity of presentation, clear display of the effects of individual attribute values, and visualization of confidence intervals. Nomograms are intuitive and when used for decision support can provide a visual explanation of predicted probabilities. And finally, with a nomogram, a naive Bayesian model can be printed out and used for probability prediction without the use of computer or calculator.

#index 799767
#* Using a hash-based method for apriori-based graph mining
#@ Phu Chien Nguyen;Takashi Washio;Kouzou Ohara;Hiroshi Motoda
#t 2004
#c 21
#! The problem of discovering frequent subgraphs of graph data can be solved by constructing a candidate set of subgraphs first, and then, identifying within this candidate set those subgraphs that meet the frequent subgraph requirement. In Apriori-based graph mining, to determine candidate subgraphs from a huge number of generated adjacency matrices is usually the dominating factor for the overall graph mining performance since it requires to perform many graph isomorphism tests. To address this issue, we develop an effective algorithm for the candidate set generation. It is a hash-based algorithm and was confirmed effective through experiments on both real-world and synthetic graph data.

#index 799768
#* Evaluation of rule interestingness measures with a clinical dataset on hepatitis
#@ Miho Ohsaki;Shinya Kitaguchi;Kazuya Okamoto;Hideto Yokoi;Takahira Yamaguchi
#t 2004
#c 21
#! This research empirically investigates the performance of conventional rule interestingness measures and discusses their practicality for supporting KDD through human-system interaction in medical domain. We compared the evaluation results by a medical expert and those by selected measures for the rules discovered from a dataset on hepatitis. Recall, Jaccard, Kappa, CST, X2-M, and Peculiarity demonstrated the highest performance, and many measures showed a complementary trend under our experimental conditions. These results indicate that some measures can predict really interesting rules at a certain level and that their combinational use will be useful.

#index 799769
#* Classification in geographical information systems
#@ Salvatore Rinzivillo;Franco Turini
#t 2004
#c 21
#! The paper deals with the problem of knowledge discovery in spatial databases. In particular, we explore the application of decision tree learning methods to the classification of spatial datasets. Spatial datasets, according to the Geographic Information System approach, are represented as stack of layers, where each layer is associated with an attribute. We propose an ID3-like algorithm based on an entropy measure, weighted on a specific spatial relation (i.e. overlap). We describe an application of the algorithm to the classification of geographical areas for agricultural purposes.

#index 799770
#* Digging into acceptor splice site prediction: an iterative feature selection approach
#@ Yvan Saeys;Sven Degroeve;Yves Van de Peer
#t 2004
#c 21
#! Feature selection techniques are often used to reduce data dimensionality, increase classification performance, and gain insight into the processes that generated the data. In this paper, we describe an iterative procedure of feature selection and feature construction steps, improving the classification of acceptor splice sites, an important subtask of gene prediction. We show that acceptor prediction can benefit from feature selection, and describe how feature selection techniques can be used to gain new insights in the classification of acceptor sites. This is illustrated by the identification of a new, biologically motivated feature: the AG-scanning feature.The results described in this paper contribute both to the domain of gene prediction, and to research in feature selection techniques, describing a new wrapper based feature weighting method that aids in knowledge discovery when dealing with complex datasets.

#index 799771
#* Itemset classified clustering
#@ Jun Sese;Shinichi Morishita
#t 2004
#c 21
#! Clustering results could be comprehensible and usable if individual groups are associated with characteristic descriptions. However, characterization of clusters followed by clustering may not always produce clusters associated with special features, because the first clustering process and the second classification step are done independently, demanding an elegant way that combines clustering and classification and executes both simultaneously.In this paper, we focus on itemsets as the feature for characterizing groups, and present a technique called itemset classified clustering, which divides data into groups given the restriction that only divisions expressed using a common itemset are allowed and computes the optimal itemset maximizing the interclass variance between the groups. Although this optimization problem is generally intractable, we develop techniques that effectively prune the search space and efficiently compute optimal solutions in practice. We remark that itemset classified clusters are likely to be overlooked by traditional clustering algorithms such as two-clustering or k-means, and demonstrate the scalability of our algorithm with respect to the amount of data by the application of our method to real biological datasets.

#index 799772
#* Combining winnow and orthogonal sparse bigrams for incremental spam filtering
#@ Christian Siefkes;Fidelis Assis;Shalendra Chhabra;William S. Yerazunis
#t 2004
#c 21
#! Spam filtering is a text categorization task that has attracted significant attention due to the increasingly huge amounts of junk email on the Internet. While current best-practice systems use Naive Bayes filtering and other probabilistic methods, we propose using a statistical, but non-probabilistic classifier based on the Winnow algorithm. The feature space considered by most current methods is either limited in expressivity or imposes a large computational cost. We introduce orthogonal sparse bigrams (OSB) as a feature combination technique that overcomes both these weaknesses. By combining Winnow and OSB with refined preprocessing and tokenization techniques we are able to reach an accuracy of 99.68% on a difficult test corpus, compared to 98.88% previously reported by the CRM114 classifier on the same test corpus.

#index 799773
#* Asynchronous and anticipatory filter-stream based parallel algorithm for frequent itemset mining
#@ Adriano Veloso;Wagner Meira, Jr.;Renato Ferreira;Dorgival Guedes Neto;Srinivasan Parthasarathy
#t 2004
#c 21
#! In this paper we propose a novel parallel algorithm for frequent itemset mining. The algorithm is based on the filter-stream programming model, in which the frequent itemset mining process is represented as a data flow controlled by a series of producer and consumer components (called filters), and the data flow (communication) between such filters is made via streams. When production rate matches consumption rate, and communication overhead between producer and consumer filters is minimized, a high degree of asynchrony is achieved. Following this strategy, our algorithm employs an asynchronous candidate generation, and minimizes communication between filters by transferring only the necessary aggregated information. Another nice feature of our algorithm is a look forward approach which accelerates frequent itemset determination. Extensive evaluation shows the parallel performance and scalability of our algorithm.

#index 799774
#* A quantification of cluster novelty with an application to Martian topography
#@ Ricardo Vilalta;Tom Stepinski;Muralikrishna Achari;Francisco Ocegueda-Hernandez
#t 2004
#c 21
#! Automated tools for knowledge discovery are frequently invoked in databases where objects already group into some known classification scheme. In the context of unsupervised learning or clustering, such tools delve inside large databases looking for alternative classification schemes that are both meaningful and novel. A quantification of cluster novelty can be looked upon as the degree of separation between each new cluster and its most similar class. Our approach models each cluster and class as a Gaussian distribution and estimates the degree of overlap between both distributions by measuring their intersecting area. Unlike other metrics, our method quantifies the novelty of each cluster individually, and enables us to rank classes according to its similarity to each new cluster. We test our algorithm on Martian landscapes using a set of known classes called geological units; experimental results show a new interpretation for the characterization of Martian landscapes.

#index 799775
#* Density-based spatial clustering in the presence of obstacles and facilitators
#@ Xin Wang;Camilo Rostoker;Howard J. Hamilton
#t 2004
#c 21
#! In this paper, we propose a new spatial clustering method, called DBRS+, which aims to cluster spatial data in the presence of both obstacles and facilitators. It can handle datasets with intersected obstacles and facilitators. Without preprocessing, DBRS+ processes constraints during clustering. It can find clusters with arbitrary shapes and varying densities. DBRS+ has been empirically evaluated using synthetic and real data sets and its performance has been compared to DBRS, AUTOCLUST+, and DBCLuC*.

#index 799776
#* Text mining for finding functional community of related genes using TCM knowledge
#@ Zhaohui Wu;Xuezhong Zhou;Baoyan Liu;Junli Chen
#t 2004
#c 21
#! We present a novel text mining approach to uncover the functional gene relationships, maybe, temporal and spatial functional modular interaction networks, from MEDLINE in large scale. Other than the regular approaches, which only consider the reductionistic molecular biological knowledge in MEDLINE, we use TCM knowledge(e.g. Symptom Complex) and the 50,000 TCM bibliographic records to automatically congregate the related genes. A simple but efficient bootstrapping technique is used to extract the clinical disease names from TCM literature, and term co-occurrence is used to identify the disease-gene relationships in MEDLINE abstracts and titles. The underlying hypothesis is that the relevant genes of the same Symptom Complex will have some biological interactions. It is also a probing research to study the connection of TCM with modern biomedical and post-genomics studies by text mining. The preliminary results show that Symptom Complex gives a novel top-down view of functional genomics research, and it is a promising research field while connecting TCM with modern life science using text mining.

#index 799777
#* Dealing with predictive-but-unpredictable attributes in noisy data sources
#@ Ying Yang;Xindong Wu;Xingquan Zhu
#t 2004
#c 21
#! Attribute noise can affect classification learning. Previous work in handling attribute noise has focused on those predictable attributes that can be predicted by the class and other attributes. However, attributes can often be predictive but unpredictable. Being predictive, they are essential to classification learning and it is important to handle their noise. Being unpredictable, they require strategies different from those of predictable attributes. This paper presents a study on identifying, cleansing and measuring noise for predictive-but-unpredictable attributes. New strategies are accordingly proposed. Both theoretical analysis and empirical evidence suggest that these strategies are more effective and more efficient than previous alternatives.

#index 799778
#* A new scheme on privacy preserving association rule mining
#@ Nan Zhang;Shengquan Wang;Wei Zhao
#t 2004
#c 21
#! We address the privacy preserving association rule mining problem in a system with one data miner and multiple data providers, each holds one transaction. The literature has tacitly assumed that randomization is the only effective approach to preserve privacy in such circumstances. We challenge this assumption by introducing an algebraic techniques based scheme. Compared to previous approaches, our new scheme can identify association rules more accurately but disclose less private information. Furthermore, our new scheme can be readily integrated as a middleware with existing systems.

#index 799779
#* A unified and flexible framework for comparing simple and complex patterns
#@ Ilaria Bartolini;Paolo Ciaccia;Irene Ntoutsi;Marco Patella;Yannis Theodoridis
#t 2004
#c 21
#! One of the most important operations involving Data Mining patterns is computing their similarity. In this paper we present a general framework for comparing both simple and complex patterns, i.e., patterns built up from other patterns. Major features of our framework include the notion of structure and measure similarity, the possibility of managing multiple coupling types and aggregation logics, and the recursive definition of similarity for complex patterns.

#index 799780
#* Constructing (Almost) phylogenetic trees from developmental sequences data
#@ Ronnie Bathoorn;Arno Siebes
#t 2004
#c 21
#! In this paper we present a new way of constructing almost phylogenetic trees. Almost since we reconstruct the tree, but without the timestamps. Rather than basing the tree on genetic sequence data ours is based on developmental sequence data. Using frequent episode discovery and clustering we reconstruct the consensus tree from the literature almost completely.

#index 799781
#* Learning from multi-source data
#@ Élisa Fromont;Marie-Odile Cordier;René Quiniou
#t 2004
#c 21
#! This paper proposes an efficient method to learn from multi source data with an Inductive Logic Programming method. The method is based on two steps. The first one consists in learning rules independently from each source. In the second step the learned rules are used to bias a new learning process from the aggregated data. We validate this method on cardiac data obtained from electrocardiograms or arterial blood pressure measures. Our method is compared to a single step learning on aggregated data.

#index 799782
#* The anatomy of SnakeT: a hierarchical clustering engine for web-page snippets
#@ Paolo Ferragina;Antonio Gullì
#t 2004
#c 21
#! The purpose of a search engine is to retrieve from a given textual collection the documents deemed relevant for a user query. Typically a user query is modeled as a set of keywords, and a document is a Web page, a pdf file or whichever file can be parsed into a set of tokens (words). Documents are ranked in a flat list according to some measure of relevance to the user query. That list contains hyperlinks to the relevant documents, their titles, and also the so called (page or web) snippets, namely document excerpts allowing the user to understand if a document is indeed relevant without accessing it.

#index 799783
#* COCOA: compressed continuity analysis for temporal databases
#@ Kuo-Yu Huang;Chia-Hui Chang;Kuo-Zui Lin
#t 2004
#c 21
#! A continuity is a kind of inter-transaction association which describes the relationships among different transactions. Since it breaks the boundaries of transactions, the number of potential itemsets and the number of rules will increase drastically. In this paper we consider the problem of discovering frequent compressed continuity patterns, which have the same power as mining the complete set of frequent continuity patterns. We devised a three-phase algorithm, COCOA, for frequent compressed continuity mining.

#index 799784
#* Discovering interpretable muscle activation patterns with the temporal data mining method
#@ Fabian Mörchen;Alfred Ultsch;Olaf Hoos
#t 2004
#c 21
#! The understanding of complex muscle coordination is an important goal in human movement science. There are numerous applications in medicine, sports, and robotics. The coordination process can be studied by observing complex, often cyclic movements, which are dynamically repeated in an almost identical manner. In this paper we demonstrate how interpretable temporal patterns can be discovered within raw EMG measurements collected from tests in professional In-Line Speed Skating. We show how the Temporal Data Mining Method, a general framework to discover knowledge in multivariate time series, can be used to extract such temporal patterns. This representation of complex muscle coordination opens up new possibilities to optimize, manipulate, or imitate the movements.

#index 799785
#* A tolerance rough set approach to clustering web search results
#@ Chi Lang Ngo;Hung Son Nguyen
#t 2004
#c 21
#! Two most popular approaches to facilitate searching for information on the web are represented by web search engine and web directories. Although the performance of search engines is improving every day, searching on the web can be a tedious and time-consuming task due to the huge size and highly dynamic nature of the web. Moreover, the user's "intention behind the search" is not clearly expressed which results in too general, short queries. Results returned by search engine can count from hundreds to hundreds of thousands of documents. One approach to manage the large number of results is clustering. Search results clustering can be defined as a process of automatical grouping search results into to thematic groups. However, in contrast to traditional document clustering, clustering of search results are done on-the-fly (per user query request) and locally on a limited set of results return from the search engine. Clustering of search results can help user navigate through large set of documents more efficiently. By providing concise, accurate description of clusters, it lets user localizes interesting document faster.In this paper, we proposed an approach to search results clustering based on Tolerance Rough Set following the work on document clustering [4,3]. Tolerance classes are used to approximate concepts existed in documents. The application of Tolerance Rough Set model in document clustering was proposed as a way to enrich document and cluster representation with the hope of increasing clustering performance.

#index 799787
#* Mining history of changes to web access patterns
#@ Qiankun Zhao;Sourav S. Bhowmick
#t 2004
#c 21
#! Recently, a lot of work has been done in web usage mining [2]. Among them, mining of frequent Web Access Pattern (WAP) is the most well researched issue [1]. The idea is to transform web logs into sequences of events with user identifications and timestamps, and then extract association and sequential patterns from the events data with certain metrics. The frequent WAPs have been applied to a wide range of applications such as personalization, system improvement, site modification, business intelligence, and usage characterization [2]. However, most of the existing techniques focus only on mining frequent WAP from snapshot web usage data, while web usage data is dynamic in real life. While the frequent WAPs are useful in many applications, knowledge hidden behind the historical changes of web usage data, which reflects how WAPs change, is also critical to many applications such as adaptive web, web site maintenance, business intelligence, etc.In this paper, we propose a novel approach to discover hidden knowledge from historical changes to WAPs. Rather than focusing on the occurrence of the WAPs, we focus on the frequently changing web access patterns. We define a novel type of knowledge, Frequent Mutating WAP (FM-WAP), based on the historical changes of WAPs. The FM-WAP mining process consists of three phases. Firstly, web usage data is represented as a set of WAP trees and partitioned into a sequence of WAP groups ( subsets of the WAP trees) according to a user-defined calendar pattern, where each WAP group is represented as a WAP forest. Consequently, the log data is represented by a sequence of WAP forests called WAP history. Then, changes among the WAP history are detected and stored in the global forest. Finally, the FM-WAP is extracted by a traversal of the global forest. Extensive experiments show that our proposed approach can produce novel knowledge of web access patterns efficiently with good scalability.

#index 799788
#* Visual mining of spatial time series data
#@ Gennady Andrienko;Natalia Andrienko;Peter Gatalsky
#t 2004
#c 21
#! CommonGIS is a system comprising a number of tools for visual data analysis. In this paper we demonstrate our recent developments for analysis of spatial time series data.

#index 799789
#* Detecting driving awareness
#@ Bruno Apolloni;Andrea Brega;Dario Malchiodi;Cristian Mesiano
#t 2004
#c 21
#! We consider the task of monitoring the awareness state of a driver engaged in attention demanding manoeuvres. A Boolean normal form launches a flag when the driver is paying special attention to his guiding. The contrasting analysis of these flags with the physical parameters of the car may alert a decision system whenever the driver awareness is judged unsatisfactory. The paper presents preliminary results showing the feasibility of the task.

#index 799790
#* An effective recommender system for highly dynamic and large web sites
#@ Ranieri Baraglia;Francesco Merlo;Fabrizio Silvestri
#t 2004
#c 21
#! In this demo we show a recommender system, called SUGGEST, that dynamically generates links to pages that have not yet been visited by a user and might be of his potential interest. Usually other recommender systems exploit a kind of two-phase architecture composed by an off-line component that analyzes Web server access logs and generates information used by a successive online component that generates recommendations. SUGGEST collapse the two-phase into a single online Apache module. The component is able to manage very large Web sites made up of dinamically generated pages by means of an efficient LRU-based database management strategy. The demo will show the way SUGGEST is able to anticipate users requests that will be made farther in the future, introducing a limited overhead on the Web server activity.

#index 799791
#* SemanticTalk: software for visualizing brainstorming sessions and thematic concept trails on document collections
#@ Chris Biemann;Karsten Böhm;Gerhard Heyer;Ronny Melz
#t 2004
#c 21
#! In this demonstration we introduce a technology to support knowledge structuring processes already at the time of their creation by building up concept structures in real time. Our focus was set on the design of a minimal invasive system, which ideally requires no human interaction and thus gives the maximum freedom to the participants of a knowledge creation or exchange processes. The system captures and displays spoken dialogs as well as text documents for further use in knowledge engineer's tools.

#index 799792
#* Orange: from experimental machine learning to interactive data mining
#@ Janez Demšar;Blaž Zupan;Gregor Leban;Tomaz Curk
#t 2004
#c 21
#! Orange (www.ailab.si/orange) is a suite for machine learning and data mining. For researchers in machine learning, Orange offers scripting to easily prototype new algorithms and experimental procedures. For explorative data analysis, it provides a visual programming framework with emphasis on interactions and creative combinations of visual components.

#index 799793
#* Terrorist detection system
#@ Yuval Elovici;Abraham Kandel;Mark Last;Bracha Shapira;Omer Zaafrany;Moti Schneider;Menahem Friedman
#t 2004
#c 21
#! Terrorist Detection System (TDS) is aimed at detecting suspicious users on the Internet by the content of information they access. TDS consists of two main modules: a training module activated in batch mode, and an on-line detection module. The training module is provided with web pages that include terror related content and learns the typical interests of terrorists by applying data mining algorithms to the training data. The detection module performs real-time monitoring on users traffic and analyzes the content of the pages they access. An alarm is issued upon detection of a user whose content of accessed pages is "too" similar to typical terrorist content. TDS feasibility was tested in a network environment. Its detection rate was better than the rate of a state of the art Intrusion Detection System based on anomaly detection.

#index 799794
#* Experimenting SnakeT: A hierarchical clustering engine for web-page snippets
#@ Paolo Ferragina;Antonio Gullì
#t 2004
#c 21
#! Current search engines return a ranked list of web pages represented by page excerpts called the web snippets. The ranking is computed according to some relevance criterium that takes into account textual and hyperlink information about the web pages (see e.g. [1]). This approach is very well-known and a lot of research is pushing towards the design of better and faster ranking criteria. However, it is nowadays equally known that a flat list of results limits the retrieval of precise answers because of many factors. First, the relevance of the query results is a subjective and time-varying concept that strictly depends on the context in which the user is formulating the query. Second, the ever growing web is enlarging the number and heterogeneity of candidate query answers. Third, the web users have limited patience so that they usually just look at the top ten results. The net outcome of this scenario is that the retrieval of the correct answer by a standard user is getting more and more diffcult, if not impossible.

#index 799795
#* HIClass: hyper-interactive text classification by interactive supervision of document and term labels
#@ Shantanu Godbole;Abhay Harpale;Sunita Sarawagi;Soumen Chakrabarti
#t 2004
#c 21
#! We present the HIClass (Hyper Interactive text Classification) system, an interactive text classification system which combines the cognitive power of humans with the power of automated learners to make statistically sound classification decisions. HIClass is based on active learning principles and has aids for detailed analysis and fine tuning of text classifiers while exerting a low cognitive load on the user.

#index 799796
#* Balios: the engine for Bayesian logic programs
#@ Kristian Kersting;Uwe Dick
#t 2004
#c 21
#! Inductive Logic Programming (ILP) [4] combines techniques from machine learning with the representation of logic programming. It aims at inducing logical clauses, i.e, general rules from specific observations and background knowledge. Because of focusing on logical clauses, traditional ILP systems do not model uncertainty explicitly. On the other hand, state-of-the-art probabilistic models such as Bayesian networks (BN) [5], hidden Markov models, and stochastic context-free grammars have a rigid structure and therefore have problems representing a variable number of objects and relations among these objects. Recently, various relational extensions of traditional probabilistic models have been proposed, see [1] for an overview. The newly emerging field of stochastic relational learning (SRL) studies learning such rich probabilistic models.

#index 799797
#* SEWeP: a web mining system supporting semantic personalization
#@ Stratos Paulakis;Charalampos Lampos;Magdalini Eirinaki;Michalis Vazirgiannis
#t 2004
#c 21
#! We present SEWeP, a Web Personalization prototype system that integrates usage data with content semantics, expressed in taxonomy terms, in order to produce a broader yet semantically focused set of recommendations.

#index 799798
#* SPIN! Data mining system based on component architecture
#@ Alexandr Savinov
#t 2004
#c 21
#! The SPIN! data mining system has a component-based architecture, where each component encapsulates some specific functionality such as a data source, an analysis algorithm or visualization. Individual components can be visually linked within one workspace for solving different data mining tasks. The SPIN! friendly user interface and flexible underlying component architecture provide a powerful integrated environment for executing main tasks constituting a typical data mining cycle: data preparation, analysis, and visualization.

#index 921704
#* Knowledge Discovery in Databases: PKDD 2006: 10th European Conference on Principles and Practice of Knowledge Discovery in Databases, Berlin, Germany, September ... (Lecture Notes in Computer Science)
#@ Johannes Fürnkranz;Tobias Scheffer;Myra Spiliopoulou
#t 2006
#c 21

#index 936470
#* Knowledge Discovery in Databases: PKDD 2005: 9th European Conference on Principles and Practice of Knowledge Discovery in Databases, Porto, Portugal, October ... / Lecture Notes in Artificial Intelligence)
#@ Alípio Jorge;Luís Torgo;Pavel Brazdil;Rui Camacho;João Gama
#t 2005
#c 21

#index 1100122
#* Proceedings of the 11th European conference on Principles and Practice of Knowledge Discovery in Databases
#@ Joost N. Kok;Jacek Koronacki;Ramon Lopez De Mantaras;Stan Matwin;Dunja Mladenič;Andrzej Skowron
#t 2007
#c 21

#index 1100123
#* Learning, Information Extraction and the Web
#@ Tom M. Mitchell
#t 2007
#c 21
#! Significant progress has been made recently in semi-supervised learning algorithms that require less labeled training data by utilizing unlabeled data. Much of this progress has been made in the context of natural language analysis (e.g., semi-supervised learning for named entity recognition and for relation extraction). This talk will overview progress in this area, present some of our own recent research, and explore the possibility that now is the right time to mount a community-wide effort to develop a never-ending natural language learning system.

#index 1100124
#* Putting Things in Order: On the Fundamental Role of Ranking in Classification and Probability Estimation
#@ Peter A. Flach
#t 2007
#c 21
#% 464606
#% 799748
#% 840913
#% 976824
#% 1100094
#% 1705505
#! While a binary classifier aims to distinguish positives from negatives, a ranker orders instances from high to low expectation that the instance is positive. Most classification models in machine learning output some score of `positiveness', and hence can be used as rankers. Conversely, any ranker can be turned into a classifier if we have some instance-independent means of splitting the ranking into positive and negative segments. This could be a fixed score threshold; a point obtained from fixing the slope on the ROC curve; the break-even point between true positive and true negative rates; to mention just a few possibilities.These connections between ranking and classification notwithstanding, there are considerable differences as well. Classification performance on nexamples is measured by accuracy, an O(n) operation; ranking performance, on the other hand, is measured by the area under the ROC curve (AUC), an O(nlogn) operation. The model with the highest AUC does not necessarily dominate all other models, and thus it is possible that another model would achieve a higher accuracy for certain operating conditions, even if its AUC is lower.However, within certain model classes good ranking performance and good classification performance are more closely related than suggested by the previous remarks. For instance, there is evidence that certain classification models, while designed to optimise accuracy, in effect optimise an AUC-based loss function [1]. It has also been known for some time that decision tree yield convex training set ROC curves by construction [2], and thus optimising training set accuracy is likely to lead to good training set AUC. In this talk I will investigate the relation between ranking and classification more closely.I will also consider the connection between ranking and probability estimation. The quality of probability estimates can be measured by, e.g., mean squared error in the probability estimates (the Brier score). However, like accuracy, this is an O(n) operation that doesn't fully take ranking performance into account. I will show how a novel decomposition of the Brier score into calibration loss and refinement loss [3] sheds light on both ranking and probability estimation performance. While previous decompositions are approximate [4], our decomposition is an exact one based on the ROC convex hull. (The connection between the ROC convex hull and calibration was independently noted by [5]). In the case of decision trees, the analysis explains the empirical evidence that probability estimation trees produce well-calibrated probabilities [6].

#index 1100125
#* Mining Queries
#@ Ricardo Baeza-Yates
#t 2007
#c 21
#! User queries in search engines and Websites give valuable information on the interests of people. In addition, clicks after queries relate those interests to actual content. Even queries without clicks or answers imply important missing synonyms or content. In this talk we show several examples on how to use this information to improve the performance of search engines, to recommend better queries, to improve the information scent of the content of a Website and ultimately to capture knowledge, as Web queries are the largest wisdom of crowds in Internet.

#index 1100126
#* Adventures in Personalized Information Access
#@ Barry Smyth
#t 2007
#c 21
#! Access to information plays an increasingly important role in our everyday lives and we have come to rely more and more on a variety of information access services to bring us the right information at the right time. Recently the traditional one-size-fits-all approach, which has informed the development of the majority of today's information access services, from search engines to portals, has been brought in to question as researchers consider the advantages of more personalized services. Such services can respond to the learned needs and preferences of individuals and groups of like-minded users. They provide for a more proactive model of information supply in place of today's reactive models of information search. In this talk we will consider the key challenges that motivate the need for a new generation of personalized information services, as well as the pitfalls that lie in wait. We will focus on a number of different information access scenarios, from e-commerce recommender systems and personalized mobile portals to community-based web search. In each case we will describe how different machine learning and data mining ideas have been harnessed to take advantage of key domain constraints in order to deliver information access interfaces that are capable of adapting to the changing needs and preferences of their users. In addition, we will describe the results of a number of user studies that highlight the potential for such technologies to significantly enhance the user experience and the ability of users to locate relevant information quickly and reliably.

#index 1100127
#* Experiment Databases: Towards an Improved Experimental Methodology in Machine Learning
#@ Hendrik Blockeel;Joaquin Vanschoren
#t 2007
#c 21
#% 156186
#% 191910
#% 533644
#% 543947
#% 577221
#% 723244
#% 926881
#% 961134
#% 1403608
#% 1742004
#! Machine learning research often has a large experimental component. While the experimental methodology employed in machine learning has improved much over the years, repeatability of experiments and generalizability of results remain a concern. In this paper we propose a methodology based on the use of experiment databases. Experiment databases facilitate large-scale experimentation, guarantee repeatability of experiments, improve reusability of experiments, help explicitating the conditions under which certain results are valid, and support quick hypothesis testing as well as hypothesis generation. We show that they have the potential to significantly increase the ease with which new results in machine learning can be obtained and correctly interpreted.

#index 1100128
#* Using the Web to Reduce Data Sparseness in Pattern-Based Information Extraction
#@ Sebastian Blohm;Philipp Cimiano
#t 2007
#c 21
#% 278109
#% 301241
#% 577339
#% 722926
#% 735133
#% 869521
#% 938677
#% 938706
#% 939515
#% 939517
#% 956564
#% 1269879
#% 1289318
#% 1379016
#% 1698580
#! Textual patterns have been used effectively to extract information from large text collections. However they rely heavily on textual redundancy in the sense that facts have to be mentioned in a similar manner in order to be generalized to a textual pattern. Data sparseness thus becomes a problem when trying to extract information from hardly redundant sources like corporate intranets, encyclopedic works or scientific databases.We present results on applying a weakly supervised pattern induction algorithm to Wikipedia to extract instances of arbitrary relations. In particular, we apply different configurations of a basic algorithm for pattern induction on seven different datasets. We show that the lack of redundancy leads to the need of a large amount of training data but that integrating Web extraction into the process leads to a significant reduction of required training data while maintaining the accuracy of Wikipedia. In particular we show that, though the use of the Web can have similar effects as produced by increasing the number of seeds, it leads overall to better results. Our approach thus allows to combine advantages of two sources: The high reliability of a closed corpus and the high redundancy of the Web.

#index 1100129
#* A Graphical Model for Content Based Image Suggestion and Feature Selection
#@ Sabri Boutemedjet;Djemel Ziou;Nizar Bouguila
#t 2007
#c 21
#% 173879
#% 207019
#% 261550
#% 280819
#% 301259
#% 345829
#% 424807
#% 465905
#% 528182
#% 722929
#% 760805
#% 771842
#% 772864
#% 798820
#% 1013662
#% 1499473
#% 1856154
#! Content based image retrieval systems provide techniques for representing, indexing and searching images. They address only the user's short term needs expressed as queries. From the importance of the visual information in many applications such as advertisements and security, we motivate in this paper, the Content Based Image Suggestion. It targets the user's long term needs as a recommendation of products based on the user preferences in different situations, and on the visual content of images. We propose a generative model in which the visual features and users are clustered into separate classes. We identify the number of both user and image classes with the simultaneous selection of relevant visual features. The goal is to ensure an accurate prediction of ratings for multidimensional images. This model is learned using the minimum message length approach. Experiments with an image collection showed the merits of our approach.

#index 1100130
#* Efficient AUC Optimization for Classification
#@ Toon Calders;Szymon Jaroszewicz
#t 2007
#c 21
#% 464606
#% 770788
#% 840882
#% 881519
#% 1378224
#! In this paper we show an efficient method for inducing classifiers that directly optimize the area under the ROC curve. Recently, AUC gained importance in the classification community as a mean to compare the performance of classifiers. Because most classification methods do not optimize this measure directly, several classification learning methods are emerging that directly optimize the AUC. These methods, however, require many costly computations of the AUC, and hence, do not scale well to large datasets. In this paper, we develop a method to increase the efficiency of computing AUC based on a polynomial approximation of the AUC. As a proof of concept, the approximation is plugged into the construction of a scalable linear classifier that directly optimizes AUC using a gradient descent method. Experiments on real-life datasets show a high accuracy and efficiency of the polynomial approximation.

#index 1100131
#* Finding Transport Proteins in a General Protein Database
#@ Sanmay Das;Milton H. Saier, Jr.;Charles Elkan
#t 2007
#c 21
#% 471758
#% 879632
#! The number of specialized databases in molecular biology is growing fast, as is the availability of molecular data. These trends necessitate the development of automatic methods for finding relevant information to include in specialized databases. We show how to use a comprehensive database (SwissProt) as a source of new entries for a specialized database (TCDB, the Transport Classification Database). Even carefully constructed keyword-based queries perform poorly in determining which SwissProt records are relevant to TCDB; we show that a machine learning approach performs well. We describe a maximum-entropy classifier, trained on SwissProt records, that achieves high precision and recall in cross-validation experiments. This classifier has been deployed as part of a pipeline for updating TCDB that allows a human expert to examine only about 2% of SwissProt records for potential inclusion in TCDB. The methods we describe are flexible and general, so they can be applied easily to other specialized databases.

#index 1100132
#* Classification of Web Documents Using a Graph-Based Model and Structural Patterns
#@ Andrzej Dominik;Zbigniew Walczak;Jacek Wojciechowski
#t 2007
#c 21
#% 260974
#% 280409
#% 288990
#% 466644
#% 478274
#% 546047
#% 629603
#% 718611
#% 727896
#% 858905
#% 1096310
#! The problem of classifying web documents is studied in this paper. A graph-based instead of traditional vector-based model is used for document representation. A novel classification algorithm which uses two different types of structural patterns (subgraphs): contrast and common is proposed. This approach is strongly associated with the classical emerging patterns techniques known from decision tables. The presented method is evaluated on three different benchmark web documents collections for measuring classification accuracy. Results show that it can outperform other existing algorithms (based on vector, graph, and hybrid document representation) in terms of accuracy and document model complexity. Another advantage is that the introduced classifier has a simple, understandable structure and can be easily extended by the expert knowledge.

#index 1100133
#* Context-Specific Independence Mixture Modelling for Protein Families
#@ Benjamin Georgi;Jörg Schultz;Alexander Schliep
#t 2007
#c 21
#% 246834
#% 269198
#% 282732
#% 682591
#% 833714
#% 906029
#% 906314
#% 1650767
#! Protein families can be divided into subgroups with functional differences. The analysis of these subgroups and the determination of which residues convey substrate specificity is a central question in the study of these families. We present a clustering procedure using the context-specific independencemixture framework using a Dirichlet mixture prior for simultaneous inference of subgroups and prediction of specificity determining residues based on multiple sequence alignments of protein families. Application of the method on several well studied families revealed a good clustering performance and ample biological support for the predicted positions. The software we developed to carry out this analysis PyMix - the Python mixture packageis available from http://www.algorithmics.molgen.mpg.de/pymix.html.

#index 1100134
#* An Algorithm to Find Overlapping Community Structure in Networks
#@ Steve Gregory
#t 2007
#c 21
#% 905901
#% 1663671
#% 1719412
#! Recent years have seen the development of many graph clustering algorithms, which can identify community structure in networks. The vast majority of these only find disjoint communities, but in many real-world networks communities overlap to some extent. We present a new algorithm for discovering overlapping communities in networks, by extending Girvan and Newman's well-known algorithm based on the betweennesscentrality measure. Like the original algorithm, ours performs hierarchical clustering -- partitioning a network into any desired number of clusters -- but allows them to overlap. Experiments confirm good performance on randomly generated networks based on a known overlapping community structure, and interesting results have also been obtained on a range of real-world networks.

#index 1100135
#* Privacy Preserving Market Basket Data Analysis
#@ Ling Guo;Songtao Guo;Xintao Wu
#t 2007
#c 21
#% 300184
#% 333876
#% 479484
#% 539744
#% 576111
#% 577233
#% 727815
#% 727904
#% 800513
#% 810010
#% 835018
#% 843878
#% 844360
#% 874169
#% 881472
#% 993988
#% 1393141
#% 1663641
#% 1663662
#! Randomized Response techniques have been empirically investigated in privacy preserving association rule mining. However, previous research on privacy preserving market basket data analysis was solely focused on support/ confidence framework. Since there are inherent problems with the concept of finding rules based on their support and confidence measures, many other measures (e.g., correlation, lift, etc.) for the general market basket data analysis have been studied. How those measures are affected due to distortion is not clear in the privacy preserving analysis scenario.In this paper, we investigate the accuracy (in terms of bias and variance of estimates) of estimates of various rules derived from the randomized market basket data and present a general framework which can conduct theoretical analysis on how the randomization process affects the accuracy of various measures adopted in market basket data analysis. We also show several measures (e.g., correlation) have monotonic property, i.e., the values calculated directly from the randomized data are always less or equal than those original ones. Hence, some market basket data analysis tasks can be executed on the randomized data directly without the release of distortion probabilities, which can better protect data privacy.

#index 1100136
#* Feature Extraction from Sensor Data Streams for Real-Time Human Behaviour Recognition
#@ Julia Hunter;Martin Colley
#t 2007
#c 21
#% 643518
#% 661923
#% 662750
#% 745513
#% 1678450
#! In this paper we illustrate the potential of motion behaviour analysis in assessing the wellbeing of unsupervised, vulnerable individuals. By learning the routine motion behaviour of the subject (i.e. places visited, routes taken between places) we show it is possible to detect unusual behaviours while they are happening. This requires the processing of continuous sensor data streams, and real-time recognition of the subject's behaviour. To address privacy concerns, analysis will be performed locally to the subject on a small computing device. Current data mining techniques were not developed for restricted computing environments, nor for the demands of real-time behaviour recognition. In this paper we present a novel, online technique for discretizing a sensor data stream that supports both unsupervised learning of human motion behaviours and real-time recognition. We performed experiments using GPS data and compared the results of Dynamic Time Warping.

#index 1100137
#* Generating Social Network Features for Link-Based Classification
#@ Jun Karamon;Yutaka Matsuo;Hikaru Yamamoto;Mitsuru Ishizuka
#t 2007
#c 21
#% 136350
#% 420495
#% 496116
#% 616104
#% 729926
#% 853532
#% 853535
#% 855601
#% 868089
#% 881460
#! There have been numerous attempts at the aggregation of attributes for relational data mining. Recently, an increasing number of studies have been undertaken to process social network data, partly because of the fact that so much social network data has become available. Among the various tasks in link mining, a popular task is link-based classification, by which samples are classified using the relations or links that are present among them. On the other hand, we sometimes employ traditional analytical methods in the field of social network analysis using e.g., centrality measures, structural holes, and network clustering. Through this study, we seek to bridge the gap between the aggregated features from the network data and traditional indices used in social network analysis. The notable feature of our algorithm is the ability to invent several indices that are well studied in sociology. We first define general operators that are applicable to an adjacent network. Then the combinations of the operators generate new features, some of which correspond to traditional indices, and others which are considered to be new. We apply our method for classification to two different datasets, thereby demonstrating the effectiveness of our approach.

#index 1100138
#* An Empirical Comparison of Exact Nearest Neighbour Algorithms
#@ Ashraf M. Kibriya;Eibe Frank
#t 2007
#c 21
#% 103743
#% 238545
#% 249321
#% 321455
#% 528164
#% 580511
#% 762054
#% 875957
#! Nearest neighbour search (NNS) is an old problem that is of practical importance in a number of fields. It involves finding, for a given point q, called the query, one or more points from a given set of points that are nearest to the query q. Since the initial inception of the problem a great number of algorithms and techniques have been proposed for its solution. However, it remains the case that many of the proposed algorithms have not been compared against each other on a wide variety of datasets. This research attempts to fill this gap to some extent by presenting a detailed empirical comparison of three prominent data structures for exact NNS: KD-Trees, Metric Trees, and Cover Trees. Our results suggest that there is generally little gain in using Metric Trees or Cover Trees instead of KD-Trees for the standard NNS problem.

#index 1100139
#* Site-Independent Template-Block Detection
#@ Aleksander Kołcz;Wen-Tau Yih
#t 2007
#c 21
#% 271060
#% 348180
#% 420487
#% 729939
#% 754078
#% 807298
#% 821872
#% 869484
#% 874265
#% 1273825
#% 1279218
#% 1279276
#! Detection of template and noise blocks in web pages is an important step in improving the performance of information retrieval and content extraction. Of the many approaches proposed, most rely on the assumption of operating within the confines of a single website or require expensive hand-labeling of relevant and non-relevant blocks for model induction. This reduces their applicability, since in many practical scenarios template blocks need to be detected in arbitrary web pages, with no prior knowledge of the site structure. In this work we propose to bridge these two approaches by using within-site template discovery techniques to drive the induction of a site-independent template detector. Our approach eliminates the need for human annotation and produces highly effective models. Experimental results demonstrate the usefulness of the proposed methodology for the important applications of keyword extraction, with relative performance gain as high as 20%.

#index 1100140
#* Statistical Model for Rough Set Approach to Multicriteria Classification
#@ Krzysztof Dembczyński;Salvatore Greco;Wojciech Kotłowski;Roman Słowiński
#t 2007
#c 21
#% 129270
#% 501011
#% 729437
#% 958632
#% 1395726
#% 1696102
#% 1699445
#! In order to discover interesting patterns and dependencies in data, an approach based on rough set theory can be used. In particular, Dominance-based Rough Set Approach (DRSA) has been introduced to deal with the problem of multicriteria classification. However, in real-life problems, in the presence of noise, the notions of rough approximations were found to be excessively restrictive, which led to the proposal of the Variable Consistency variant of DRSA. In this paper, we introduce a new approach to variable consistency that is based on maximum likelihood estimation. For two-class (binary) problems, it leads to the isotonic regression problem. The approach is easily generalized for the multi-class case. Finally, we show the equivalence of the variable consistency rough sets to the specific risk-minimizing decision rule in statistical decision theory.

#index 1100141
#* Classification of Anti-learnable Biological and Synthetic Data
#@ Adam Kowalczyk
#t 2007
#c 21
#% 203129
#% 235377
#% 309208
#% 331909
#% 575980
#% 765525
#% 1051405
#% 1673682
#% 1734400
#! We demonstrate a binary classification problem in which standard supervised learning algorithms such as linear and kernel SVM, naive Bayes, ridge regression, k-nearest neighbors, shrunken centroid, multilayer perceptron and decision trees perform in an unusual way. On certain data sets they classify a randomly sampled training subset nearly perfectly, but systematically perform worse than random guessing on cases unseen in training. We demonstrate this phenomenon in classification of a natural data set of cancer genomics microarrays using cross-validation test. Additionally, we generate a range of synthetic datasets, the outcomes of 0-sum games, for which we analyse this phenomenon in the i.i.d. setting.Furthermore, we propose and evaluate a remedy that yields promising results for classifying such data as well as normal datasets. We simply transform the classifier scores by an additional 1-dimensional linear transformation developed, for instance, to maximize classification accuracy of the outputs of an internal cross-validation on the training set. We also discuss the relevance to other fields such as learning theory, boosting, regularization, sample bias and application of kernels.

#index 1100142
#* Improved Algorithms for Univariate Discretization of Continuous Features
#@ Jussi Kujala;Tapio Elomaa
#t 2007
#c 21
#% 35065
#% 115608
#% 129980
#% 246831
#% 272995
#% 420146
#% 458174
#% 500836
#% 725436
#% 738958
#% 1650665
#% 1699622
#! In discretization of a continuous variable its numerical value range is divided into a few intervals that are used in classification. For example, Naïve Bayes can benefit from this processing. A commonly-used supervised discretization method is Fayyad and Irani's recursive entropy-based splitting of a value range. The technique uses ent-mdlas a model selection criterion to decide whether to accept the proposed split.We argue that theoretically the method is not always close to ideal for this application. Empirical experiments support our finding. We give a statistical rule that does not use the ad-hoc rule of Fayyad and Irani's approach to increase its performance. This rule, though, is quite time consuming to compute. We also demonstrate that a very simple Bayesian method performs better than ent-mdlas a model selection criterion.

#index 1100143
#* Efficient Weight Learning for Markov Logic Networks
#@ Daniel Lowd;Pedro Domingos
#t 2007
#c 21
#% 33917
#% 138308
#% 169353
#% 333797
#% 450888
#% 647057
#% 816181
#% 840890
#% 850430
#% 854636
#% 876066
#% 915340
#% 1000502
#% 1250579
#% 1269496
#! Markov logic networks (MLNs) combine Markov networks and first-order logic, and are a powerful and increasingly popular representation for statistical relational learning. The state-of-the-art method for discriminative learning of MLN weights is the voted perceptron algorithm, which is essentially gradient descent with an MPE approximation to the expected sufficient statistics (true clause counts). Unfortunately, these can vary widely between clauses, causing the learning problem to be highly ill-conditioned, and making gradient descent very slow. In this paper, we explore several alternatives, from per-weight learning rates to second-order methods. In particular, we focus on two approaches that avoid computing the partition function: diagonal Newton and scaled conjugate gradient. In experiments on standard SRL datasets, we obtain order-of-magnitude speedups, or more accurate models given comparable learning times.

#index 1100144
#* Classification in Very High Dimensional Problems with Handfuls of Examples
#@ Mark Palatucci;Tom M. Mitchell
#t 2007
#c 21
#% 236495
#% 236497
#% 267031
#% 420054
#% 466080
#% 768668
#% 875999
#% 952612
#% 961183
#% 1671289
#! Modern classification techniques perform well when the number of training examples exceed the number of features. If, however, the number of features greatly exceed the number of training examples, then these same techniques can fail. To address this problem, we present a hierarchical Bayesian framework that shares information between features by modeling similarities between their parameters. We believe this approach is applicable to many sparse, high dimensional problems and especially relevant to those with both spatial and temporal components. One such problem is fMRI time series, and we present a case study that shows how we can successfully classify in this domain with 80,000 original features and only 2 training examples per class.

#index 1100145
#* Domain Adaptation of Conditional Probability Models Via Feature Subsetting
#@ Sandeepkumar Satpal;Sunita Sarawagi
#t 2007
#c 21
#% 464434
#% 466266
#% 770847
#% 816181
#% 875989
#% 916788
#% 939527
#% 940000
#% 1250570
#% 1261539
#! The goal in domain adaptation is to train a model using labeled data sampled from a domain different from the target domain on which the model will be deployed. We exploit unlabeled data from the target domain to train a model that maximizes likelihood over the training sample while minimizing the distance between the training and target distribution. Our focus is conditional probability models used for predicting a label structure ygiven input xbased on features defined jointly over xand y. We propose practical measures of divergence between the two domains based on which we penalize features with large divergence, while improving the effectiveness of other less deviant correlated features. Empirical evaluation on several real-life information extraction tasks using Conditional Random Fields (CRFs) show that our method of domain adaptation leads to significant reduction in error.

#index 1100146
#* Learning to Detect Adverse Traffic Events from Noisily Labeled Data
#@ Tomáš Šingliar;Miloš Hauskrecht
#t 2007
#c 21
#% 75936
#% 788047
#! Many deployed traffic incident detection systems use algorithms that require significant manual tuning. We seek machine learning incident detection solutions that reduce the need for manual adjustments by taking advantage of massive databases of traffic sensor network measurements. First, we show that a rather straightforward supervised learner based on the SVM model outperforms a fixed detection model used by state-of-the-art traffic incident detectors. Second, we seek further improvements of learning performance by correcting misaligned incident times in the training data. The misalignment is due to an imperfect incident logging procedure. We propose a label realignment model based on a dynamic Bayesian network to re-estimate the correct position (time) of the incident in the data. Training on the automatically realigned data consistently leads to improved detection performance in the low false positive region.

#index 1100147
#* IKNN: Informative K-Nearest Neighbor Pattern Classification
#@ Yang Song;Jian Huang;Ding Zhou;Hongyuan Zha;C. Lee Giles
#t 2007
#c 21
#% 209623
#% 252009
#% 444007
#% 458216
#% 501975
#% 722816
#% 812365
#% 838739
#% 883981
#! The K-nearest neighbor (KNN) decision rule has been a ubiquitous classification tool with good scalability. Past experience has shown that the optimal choice of Kdepends upon the data, making it laborious to tune the parameter for different applications. We introduce a new metric that measures the informativeness of objects to be classified. When applied as a query-based distance metric to measure the closeness between objects, two novel KNN procedures, Locally Informative-KNN (LI-KNN) and Globally Informative-KNN (GI-KNN), are proposed. By selecting a subset of most informative objects from neighborhoods, our methods exhibit stability to the change of input parameters, number of neighbors(K) and informative points (I). Experiments on UCI benchmark data and diverse real-world data sets indicate that our approaches are application-independent and can generally outperform several popular KNN extensions, as well as SVM and Boosting methods.

#index 1100148
#* Finding Outlying Items in Sets of Partial Rankings
#@ Antti Ukkonen;Heikki Mannila
#t 2007
#c 21
#% 881472
#% 972249
#! Partial rankings are totally ordered subsets of a set of items. For example, the sequence in which a user browses through different parts of a website is a partial ranking. We consider the following problem. Given a set Dof partial rankings, find items that have strongly different status in different parts of D. To do this, we first compute a clustering of Dand then look at items whose average rank in the cluster substantially deviates from its average rank in D. Such items can be seen as those that contribute the most to the differences between the clusters. To test the statistical significance of the found items, we propose a method that is based on a MCMC algorithm for sampling random sets of partial rankings with exactly the same statistics as D. We also demonstrate the method on movie rankings and gene expression data.

#index 1100149
#* Speeding Up Feature Subset Selection Through Mutual Information Relevance Filtering
#@ Gert Dijck;Marc M. Hulle
#t 2007
#c 21
#% 68777
#% 177826
#% 243728
#% 246831
#% 593043
#% 778736
#% 878207
#% 1012295
#% 1694687
#! A relevance filter is proposed which removes features based on the mutual information between class labels and features. It is proven that both feature independence and class conditional feature independence are required for the filter to be statistically optimal. This could be shown by establishing a relationship with the conditional relative entropy framework for feature selection. Removing features at various significance levels as a preprocessing step to sequential forward search leads to a huge increase in speed, without a decrease in classification accuracy. These results are shown based on experiments with 5 high-dimensional publicly available gene expression data sets.

#index 1100150
#* A Comparison of Two Approaches to Classify with Guaranteed Performance
#@ Stijn Vanderlooy;Ida G. Sprinkhuizen-Kuyper
#t 2007
#c 21
#% 331909
#% 446658
#% 806981
#! The recently introduced transductive confidence machine approach and the ROC isometrics approach provide a framework to extend classifiers such that their performance can be set by the user prior to classification. In this paper we use the k-nearest neighbour classifier in order to provide an extensive empirical evaluation and comparison of the approaches. From our results we may conclude that the approaches are competing and promising generally applicable machine learning tools.

#index 1100151
#* Towards Data Mining Without Information on Knowledge Structure
#@ Alexandre Vautier;Marie-Odile Cordier;René Quiniou
#t 2007
#c 21
#% 80998
#% 125635
#% 216508
#% 234979
#% 369349
#% 406964
#% 459006
#% 480318
#% 769896
#% 796213
#% 993995
#! Most knowledge discovery processes are biased since some part of the knowledge structure must be given before extraction. We propose a framework that avoids this bias by supporting all major model structures e.g. clustering, sequences, etc., as well as specifications of data and DM (Data Mining) algorithms, in the same language. A unification operation is provided to match automatically the data to the relevant DM algorithms in order to extract models and their related structure. The MDL principle is used to evaluate and rank models. This evaluation is based on the covering relation that links the data to the models. The notion of schema, related to the category theory, is the key concept of our approach. Intuitively, a schema is an algebraic specification enhanced by the union of types, and the concepts of list and relation. An example based on network alarm mining illustrates the process.

#index 1100152
#* Relaxation Labeling for Selecting and Exploiting Efficiently Non-local Dependencies in Sequence Labeling
#@ Guillaume Wisniewski;Patrick Gallinari
#t 2007
#c 21
#% 211044
#% 246162
#% 431103
#% 464434
#% 794508
#% 818244
#% 829043
#% 840927
#% 844290
#% 853697
#% 858035
#% 885468
#% 939376
#% 961193
#% 1275085
#% 1289513
#% 1289530
#% 1532599
#! We consider the problem of sequence labeling and propose a two steps method which combines the scores of local classifiers with a relaxation labeling technique. This framework can account for sparse dynamically changing dependencies, which allows us to efficiently discover relevant non-local dependencies and exploit them. This is in contrast to existing models which incorporate only local relationships between neighboring nodes. Experimental results show that the proposed method gives promising results.

#index 1100153
#* Bridged Refinement for Transfer Learning
#@ Dikan Xing;Wenyuan Dai;Gui-Rong Xue;Yong Yu
#t 2007
#c 21
#% 236497
#% 269217
#% 348173
#% 458369
#% 465754
#% 466263
#% 770847
#% 1016177
#% 1290055
#! There is usually an assumption in traditional machine learning that the training and test data are governed by the same distribution. This assumption might be violated when the training and test data come from different time periods or domains. In such situations, traditional machine learning methods not aware of the shift of distribution may fail. This paper proposes a novel algorithm, namely bridged refinement, to take the shift into consideration. The algorithm corrects the labels predicted by a shift-unaware classifier towards a target distribution and takes the mixture distribution of the training and test data as a bridge to better transfer from the training data to the test data. In the experiments, our algorithm successfully refines the classification labels predicted by three state-of-the-art algorithms: the Support Vector Machine, the naïve Bayes classifier and the Transductive Support Vector Machine on eleven data sets. The relative reduction of error rates is about 50% in average.

#index 1100154
#* A Prediction-Based Visual Approach for Cluster Exploration and Cluster Validation by HOV3
#@ Ke-Bing Zhang;Mehmet A. Orgun;Kang Zhang
#t 2007
#c 21
#% 201893
#% 234978
#% 252533
#% 273890
#% 296738
#% 333543
#% 342601
#% 487844
#% 501678
#% 511800
#% 546511
#% 729925
#% 879448
#% 1693326
#% 1786334
#! Predictive knowledge discovery is an important knowledge acquisition method. It is also used in the clustering process of data mining. Visualization is very helpful for high dimensional data analysis, but not precise and this limits its usability in quantitative cluster analysis. In this paper, we adopt a visual technique called HOV3to explore and verify clustering results with quantified measurements. With the quantified contrast between grouped data distributions produced by HOV3, users can detect clusters and verify their validity efficiently.

#index 1100155
#* Flexible Grid-Based Clustering
#@ Marc-Ismaël Akodjènou-Jeannin;Kavé Salamatian;Patrick Gallinari
#t 2007
#c 21
#% 248792
#% 479962
#% 551620
#% 566128
#% 722902
#% 729985
#% 785549
#% 900049
#% 937189
#! Grid-based clustering is particularly appropriate to deal with massive datasets. The principle is to first summarize the dataset with a grid representation, and then to merge grid cells in order to obtain clusters. All previous methods use grids with hyper-rectangular cells. In this paper we propose a flexible grid built from arbitrary shaped polyhedra for the data summary. For the clustering step, a graph is then extracted from this representation. Its edges are weighted by combining density and spatial informations. The clusters are identified as the main connected components of this graph. We present experiments indicating that our grid often leads to better results than an adaptive rectangular grid method.

#index 1100156
#* Polyp Detection in Endoscopic Video Using SVMs
#@ Luís A. Alexandre;João Casteleiro;Nuno Nobreinst
#t 2007
#c 21
#% 519003
#% 820132
#% 1558464
#! Colon cancer is one of the most common cancers in developed countries. Most of these cancers start with a polyp. Polyps are easily detected by physicians. Our goal is to mimic this detection ability so that endoscopic videos can be pre-scanned with our algorithm before the physician analyses them. The method will indicate which part of the video needs attention (polyps were detected there) and hence can speedup the procedures. In this paper we present a method for polyp detection in endoscopic images that uses SVM for classification. Our experiments yielded a result of 93.16 ± 0.09% of area under the Receiver Operating Characteristic (ROC) curve on a database of 4620 images indicating that the approach proposed is well suited to the detection of polyps in endoscopic video.

#index 1100157
#* A Density-Biased Sampling Technique to Improve Cluster Representativeness
#@ Ana Paula Appel;Adriano Arantes Paterlini;Elaine P. Sousa;Agma J. Traina;Caetano Traina, Jr.
#t 2007
#c 21
#% 300132
#% 721137
#% 873885
#% 957741
#! The volume and complexity of data collected by modern applications has grown significantly, leading to increasingly costly operations for both data manipulation and analysis. Sampling is an useful technique to support manager a more sensible volume in the data reduction process. Uniform sampling has been widely used but, in datasets exhibiting skewed cluster distribution, biased sampling shows better results. This paper presents the BBS - Biased Box Samplingalgorithm which aims at keeping the skewed tendency of the clusters from the original data. We also present experimental results obtained with the proposed BBS algorithm.

#index 1100158
#* Expectation Propagation for Rating Players in Sports Competitions
#@ Adriana Birlutiu;Tom Heskes
#t 2007
#c 21
#% 132779
#% 420065
#% 715096
#! Rating players in sports competitions based on game results is one example of paired comparison data analysis. Since an exact Bayesian treatment is intractable, several techniques for approximate inference have been proposed in the literature. In this paper we compare several variants of expectation propagation (EP). EP generalizes assumed density filtering (ADF) by iteratively improving the approximations that are made in the filtering step of ADF. Furthermore, we distinguish between two variants of EP: EP-Correlated, which takes into account the correlations between the strengths of the players and EP-Independent, which ignores those correlations. We evaluate the different approaches on a large tennis dataset to find that EP does significantly better than ADF (iterative improvement indeed helps) and EP-Correlated does significantly better than EP-Independent (correlations do matter).

#index 1100159
#* Efficient Closed Pattern Mining in Strongly Accessible Set Systems (Extended Abstract)
#@ Mario Boley;Tamás Horváth;Axel Poigné;Stefan Wrobel
#t 2007
#c 21
#% 39702
#% 279120
#% 335253
#% 641694
#! Many problems in data mining can be viewed as a special case of the problem of enumerating the closed elements of an independence system with respect to some specific closure operator. Motivated by real-world applications, e.g., in track mining, we consider a generalization of this problem to strongly accessible set systems and arbitrary closure operators. For this more general problem setting, the closed sets can be enumerated with polynomial delay if deciding membership in the set system and computing the closure operator can be solved in polynomial time. We discuss potential applications in graph mining.

#index 1100160
#* Discovering Emerging Patterns in Spatial Databases: A Multi-relational Approach
#@ Michelangelo Ceci;Annalisa Appice;Donato Malerba
#t 2007
#c 21
#% 152934
#% 280409
#% 310550
#% 420062
#% 748640
#! Spatial Data Mining (SDM) has great potential in supporting public policy and in underpinning society functioning. One task in SDM is the discovery of characterization and peculiarities of communities sharing socio-economic aspects in order to identify potentialities, needs and public intervention. Emerging patterns (EPs) are a special kind of pattern which contrast two classes. In this paper, we face the problem of extracting EPs from spatial data. At this aim, we resort to a multi-relational approach in order to deal with the degree of complexity of discovering EPs from spatial data (i.e., (i) the spatial dimension implicitly defines spatial properties and relations, (ii) spatial phenomena are affected by autocorrelation). Experiments on real datasets are described.

#index 1100161
#* Realistic Synthetic Data for Testing Association Rule Mining Algorithms for Market Basket Databases
#@ Colin Cooper;Michele Zito
#t 2007
#c 21
#% 227917
#% 300120
#% 342643
#% 481290
#% 481754
#% 800615
#% 894393
#! We investigate the statistical properties of the databases generated by the IBM QUEST program. Motivated by the claim (also supported empirical evidence) that item occurrences in real life market basket databases follow a rather different pattern, we propose an alternative model for generating artificial data.

#index 1100162
#* Learning Multi-dimensional Functions: Gas Turbine Engine Modeling
#@ Chris Drummond
#t 2007
#c 21
#% 445343
#% 494443
#% 503632
#% 1271966
#% 1927660
#! This paper shows how multi-dimensional functions, describing the operation of complex equipment, can be learned. The functions are points in a shape space, each produced by morphing a prototypical function located at its origin. The prototypical function and the space's dimensions, which define morphological operations, are learned from a set of existing functions. New ones are generated by averaging the coordinates of similar functions and using these to morph the prototype appropriately. This paper discusses applying this approach to learning new functions for components of gas turbine engines. Experiments on a set of compressor maps, multi-dimensional functions relating the performance parameters of a compressor, show that it more accurately transforms old maps, into new ones, than existing methods.

#index 1100163
#* Constructing High Dimensional Feature Space for Time Series Classification
#@ Victor Eruhimov;Vladimir Martyanov;Eugene Tuv
#t 2007
#c 21
#% 876074
#% 1737207
#! The paper investigates a generic method of time series classification that is invariant to transformations of time axis. The state-of-art methods widely use Dynamic Time Warping (DTW) with One-Nearest-Neighbor (1NN). We use DTW to transform time axis of each signal in order to decrease the Euclidean distance between signals from the same class. The predictive accuracy of an algorithm that learns from a heterogeneous set of features extracted from signals is analyzed. Feature selection is used to filter out irrelevant predictors and a serial ensemble of decision trees is used for classification. We simulate a dataset for providing a better insight into the algorithm. We also compare our method to DTW+1NN on several publicly available datasets.

#index 1100164
#* A Dynamic Clustering Algorithm for Mobile Objects
#@ Dominique Fournier;Gaële Simon;Bruno Mermet
#t 2007
#c 21
#% 103446
#% 210173
#% 345859
#% 594012
#% 727930
#% 769946
#% 881514
#! In this paper, a multiagent algorithm for dynamic clustering is presented. This kind of clustering is intended to manage mobile data and so, to be able to continuously adapt the built clusters. First of all, potential applications of this algorithm are presented. Then the specific constraints for this kind of clustering are studied. A multiagent architecture satisfying these constraints is described. It combines an ants algorithm with a cluster agents layer which are executed simultaneously. Finally, the first experimental results of our work are presented.

#index 1100165
#* A Method for Multi-relational Classification Using Single and Multi-feature Aggregation Functions
#@ Richard Frank;Flavia Moser;Martin Ester
#t 2007
#c 21
#% 458257
#% 478762
#% 729926
#% 729982
#% 731604
#% 745491
#% 998577
#% 1289267
#! This paper presents a novel method for multi-relational classification via an aggregation-based Inductive Logic Programming (ILP) approach. We extend the classical ILP representation by aggregation of multiple-features which aid the classification process by allowing for the analysis of relationships and dependencies between different features. In order to efficiently learn rules of this rich format, we present a novel algorithm capable of performing aggregation with the use of virtual joins of the data. By using more expressive aggregation predicates than the existential quantifier used in standard ILP methods, we improve the accuracy of multi-relational classification. This claim is supported by experimental evaluation on three different real world datasets.

#index 1100166
#* MINI: Mining Informative Non-redundant Itemsets
#@ Arianna Gallo;Tijl Bie;Nello Cristianini
#t 2007
#c 21
#% 152934
#% 279120
#% 342610
#% 431033
#% 478770
#% 785339
#% 823356
#% 867057
#% 1663672
#! Frequent itemset mining assists the data mining practitioner in searching for strongly associated items (and transactions) in large transaction databases. Since the number of frequent itemsets is usually extremely large and unmanageable for a human user, recent works have sought to define condensed representations of them, e.g. closedor maximalfrequent itemsets. We argue that not only these methods often still fall short in sufficiently reducing of the output size, but they also output many redundant itemsets. In this paper we propose a philosophically new approach that resolves both these issues in a computationally tractable way. We present and empirically validate a statistically founded approach called MINI, to compress the set of frequent itemsets down to a list of informative and non-redundant itemsets.

#index 1100167
#* Stream-Based Electricity Load Forecast
#@ João Gama;Pedro Pereira Rodrigues
#t 2007
#c 21
#% 1860210
#! Sensors distributed all around electrical-power distribution networks produce streams of data at high-speed. From a data mining perspective, this sensor network problem is characterized by a large number of variables (sensors), producing a continuous flow of data, in a dynamic non-stationary environment. Companies make decisions to buy or sell energy based on load profiles and forecast. We propose an architecture based on an online clustering algorithm where each cluster (group of sensors with high correlation) contains a neural-network based predictive model. The goal is to maintain in real-time a clustering model and a predictive model able to incorporate new information at the speed data arrives, detecting changes and adapting the decision models to the most recent information. We present results illustrating the advantages of the proposed architecture, on several temporal horizons, and its competitiveness with another predictive strategy.

#index 1100168
#* Automatic Hidden Web Database Classification
#@ Zhiguo Gong;Jingbai Zhang;Qian Liu
#t 2007
#c 21
#% 165111
#% 190581
#% 333932
#% 447946
#% 480479
#% 660365
#% 732669
#% 1499571
#! In this paper, a method for automatic classification of Hidden-Web databases is addressed. In our approach, the classification tree for Hidden Web databases is constructed by tailoring the well accepted classification tree of DMOZ Directory. Then the feature for each class is extracted from randomly selected Web documents in the corresponding category. For each Web database, query terms are selected from the class features based on their weights. A hidden-web database is then probed by analyzing the results of the class-specific query. To raise the performance further, we also use Web pages which have links pointing to the hidden-web database (HW-DB) as another important source to represent the database. We combine link-based evaluation and query-based probing as our final classification solution. The experiment shows that the combined method can produce much better performance for classification of hidden Web Databases.

#index 1100169
#* Pruning Relations for Substructure Discovery of Multi-relational Databases
#@ Hongyu Guo;Herna L. Viktor;Eric Paquet
#t 2007
#c 21
#% 36160
#% 136350
#% 243728
#% 745491
#% 844406
#% 881516
#% 1290272
#% 1897232
#! Multirelational data mining methods discover patterns across multiple interlinked tables (relations) in a relational database. In many large organizations, such a multi-relational database spans numerous departments and/or subdivisions, which are involved in different aspects of the enterprise such as customer profiling, fraud detection, inventory management, financial management, and so on. When considering multirelational classification, it follows that these subdivisions will express different interests in the data, leading to the need to explore various subsets of relevant relations with high utility with respect to the target class. The paper presents a novel approach for pruning the uninteresting relations of a relational database where relations come from such different parties and spans many classification tasks. We aim to create a pruned structure and thus minimize predictive performance loss on the final classification model. Our method identifies a set of strongly uncorrelated subgraphs to use for training and discards all others. The experiments performed demonstrate that our strategy is able to significantly reduce the size of the relational schema without sacrificing predictive accuracy.

#index 1100170
#* The Most Reliable Subgraph Problem
#@ Petteri Hintsanen
#t 2007
#c 21
#% 58608
#% 370988
#% 408396
#% 727932
#% 769887
#% 853532
#% 853538
#% 1692830
#! We introduce the problem of finding the most reliable subgraph: given a probabilistic graph Gsubject to random edge failures, a set of terminal vertices, and an integer Kfind a subgraph H茂戮驴 Ghaving Kfewer edges than G, such that the probability of connecting the terminals in His maximized. The solution has applications in link analysis and visualization. We begin by formally defining the problem in a general form, after which we focus on a two-terminal, undirected case. Although the problem is most likely computationally intractable, we give a polynomial-time algorithm for a special case where Gis seriesparallel. For the general case, we propose a computationally efficient greedy heuristic. Our experiments on simulated graphs illustrate the usefulness of the concept of most reliable subgraph, and suggest that the heuristic for the general case is quite competitive.

#index 1100171
#* Matching Partitions over Time to Reliably Capture Local Clusters in Noisy Domains
#@ Frank Höppner;Mirko Böttcher
#t 2007
#c 21
#% 210173
#% 273890
#% 546694
#% 594012
#% 774878
#% 1704309
#! When seeking for small clusters it is very intricate to distinguish between incidental agglomeration of noisy points and true local patterns. We present the PAMALOC algorithm that addresses this problem by exploiting temporal information which is contained in most business data sets. The algorithm enables the detection of local patterns in noisy data sets more reliable compared to the case when the temporal information is ignored. This is achieved by making use of the fact that noise does not reproduce its incidental structure but even small patterns do. In particular, we developed a method to track clusters over time based on an optimal match of data partitions between time periods.

#index 1100172
#* Searching for Better Randomized Response Schemes for Privacy-Preserving Data Mining
#@ Zhengli Huang;Wenliang Du;Zhouxuan Teng
#t 2007
#c 21
#% 300184
#% 333876
#% 577233
#% 727904
#% 729962
#% 800513
#% 810010
#% 810028
#% 993988
#! To preserve user privacy in Privacy-Preserving Data Mining (PPDM), the randomized response (RR) technique is widely used for categorical data. Although various RR schemes have been proposed, there is no study to systematically compare them in order to find optimal RR schemes. In the paper, we choose the R-U (Risk-Utility) confidentiality map to compare different randomization schemes. Using the R-U map as our metric, we present an optimal RR scheme for binary data, which helps us find an optimal class of RR matrices. From this optimal scheme, we have discovered several heuristic rules among the elements in the optimal class. We generalize these rules to find optimal class of RR matrices for categorical data. Based on these rules, we propose an RR scheme to find a class of RR matrices for categorical data. Our experimental results have shown that our scheme has much better performance than the existing RR schemes.

#index 1100173
#* Pre-processing Large Spatial Data Sets with Bayesian Methods
#@ Saara Hyvönen;Esa Junttila;Marko Salmenkivi
#t 2007
#c 21
#% 844325
#% 889100
#% 1927565
#! Binary data appears in many spatial applications such as dialectology and ecology. We demonstrate that a simple Bayesian modeling approach can be used in pre-processing large spatial data sets with missing or uncertain data. Our experiments on real and synthetic data show that conducting the pre-processing phase before applying conventional data mining methods, such as PCA, clustering or NMF, improves the results significantly.

#index 1100174
#* Tag Recommendations in Folksonomies
#@ Robert Jäschke;Leandro Marinho;Andreas Hotho;Lars Schmidt-Thieme;Gerd Stumme
#t 2007
#c 21
#% 290830
#% 330687
#% 734590
#% 734594
#% 869482
#% 869608
#% 1655418
#% 1667787
#! Collaborative tagging systems allow users to assign keywords--so called "tags"--to resources. Tags are used for navigation, finding resources and serendipitous browsing and thus provide an immediate benefit for users. These systems usually include tag recommendation mechanisms easing the process of finding good tags for a resource, but also consolidating the tag vocabulary across users. In practice, however, only very basic recommendation strategies are applied.In this paper we evaluate and compare two recommendation algorithms on large-scale real life datasets: an adaptation of user-based collaborative filtering and a graph-based recommender built on top of FolkRank. We show that both provide better results than non-personalized baseline methods. Especially the graph-based recommender outperforms existing methods considerably.

#index 1100175
#* Providing Naïve Bayesian Classifier-Based Private Recommendations on Partitioned Data
#@ Cihan Kaleli;Huseyin Polat
#t 2007
#c 21
#% 528156
#% 577289
#% 729930
#% 772829
#% 832368
#% 1650569
#% 1673616
#! Data collected for collaborative filtering (CF) purposes might be split between various parties. Integrating such data is helpful for both e-companies and customers due to mutual advantageous. However, due to privacy reasons, data owners do not want to disclose their data. We hypothesize that if privacy measures are provided, data holders might decide to integrate their data to perform richer CF services. In this paper, we investigate how to achieve naïve Bayesian classifier (NBC)-based CF tasks on partitioned data with privacy. We perform experiments on real data, analyze our outcomes, and provide some suggestions.

#index 1100176
#* Multi-party, Privacy-Preserving Distributed Data Mining Using a Game Theoretic Framework
#@ Hillol Kargupta;Kamalika Das;Kun Liu
#t 2007
#c 21
#% 575969
#% 729930
#% 878243
#% 972313
#% 1688260
#! Analysis of privacy-sensitive data in a multi-party environment often assumes that the parties are well-behaved and they abide by the protocols. Parties compute whatever is needed, communicate correctly following the rules, and do not collude with other parties for exposing third party's sensitive data. This paper argues that most of these assumptions fall apart in real-life applications of privacy-preserving distributed data mining (PPDM). This paper offers a more realistic formulation of the PPDM problem as a multi-party game where each party tries to maximize its own objectives. It develops a game-theoretic framework to analyze the behavior of each party in such games and presents detailed analysis of the well known secure sum computation as an example.

#index 1100177
#* Multilevel Conditional Fuzzy C-Means Clustering of XML Documents
#@ Michal Kozielski
#t 2007
#c 21
#% 207948
#% 296738
#% 729627
#% 785560
#% 789009
#% 972339
#% 1035793
#% 1788359
#! XML documents are the special kind of data having hierarchical structure. Typical clustering algorithms do not meet requirements which may be stated for analysis of such data. A novel, dedicated for XML documents clustering method called Multilevel clustering of XML documents(ML) is presented in the paper. The method clusters feature vectors encoding XML documents on the different structure levels. Application of Conditional Fuzzy C-Meansalgorithm to MLmethod is proposed in the paper and the advantage of this fuzzy method over hard approach to MLalgorithm is discussed and proved. An application of MLmethod to accelerating query execution on XML documents is discussed in the paper. The experimental results performed on two data sets having different characteristics show that the proposed method of multilevel conditional fuzzy clustering of XML documents outperforms hard multilevel clustering.

#index 1100178
#* Uncovering Fraud in Direct Marketing Data with a Fraud Auditing Case Builder
#@ Fletcher Lu
#t 2007
#c 21
#% 384911
#% 449561
#! This paper illustrates an automated system that replicates the investigative operation of human fraud auditors. Human fraud auditors often utilize fraud detection methods that exploit structure in database tables to uncover outliers that may be part of a fraud case. From the uncovered outliers, an auditor will build a case of fraud by searching data related to the outlier possibly across many different databases and tables within these different databases. This paper illustrates an industrial implementation of an adaptive fraud case building system that uses machine learning to conduct the search and decision-making process with an automated outlier detection component. This system was successfully applied to uncover fraud cases in real marketing data.

#index 1100179
#* Real Time GPU-Based Fuzzy ART Skin Recognition
#@ Mario Martínez-Zarzuela;Francisco Javier Díaz Pernas;David González Ortega;José Fernando Díez Higuera;Míriam Antón Rodríguez
#t 2007
#c 21
#% 111415
#% 296697
#% 593560
#% 717264
#% 806985
#% 1396321
#% 1676049
#! Graphics Processing Units (GPUs) have evolved into powerful programmable processors, becoming increasingly used in many research fields such as computer vision. For non-intrusive human body parts detection and tracking, skin filtering is a powerful tool. In this paper we propose the use of a GPU-designed implementation of a Fuzzy ART Neural Network for robust real-time skin recognition. Both learning and testing processes are done on the GPU using chrominance components in TSL color space. Within the GPU, classification of several pixels can be made simultaneously, allowing skin recognition at high frame rates. System performance depends both on video resolution and number of neural network committed categories. Our application can process 296 fps or 79 fps at video resolutions of 320x240 and 640x480 pixels respectively.

#index 1100180
#* A Cooperative Game Theoretic Approach to Prototype Selection
#@ Narayanan Rama Suri;V. Santosh Srinivas;M. Narasimha Murty
#t 2007
#c 21
#% 307100
#% 486045
#% 776586
#% 1704837
#! In this paper we consider the task of prototype selection whose primary goal is to reduce the storage and computational requirements of the Nearest Neighbor classifier while achieving better classification accuracies. We propose a solution to the prototype selection problem using techniques from cooperative game theory and show its efficacy experimentally.

#index 1100181
#* Dynamic Bayesian Networks for Real-Time Classification of Seismic Signals
#@ Carsten Riggelsen;Matthias Ohrnberger;Frank Scherbaum
#t 2007
#c 21
#% 44876
#% 146300
#% 185079
#% 266086
#% 1092478
#! We present a novel method for automatic classification of seismological data streams, focusing on the detection of earthquake signals. We consider the approach as being a first step towards a generic method that provides for classifying a broad range of seismic patterns by modeling the interrelationships between essential features of seismograms in a graphical model. Through a continuous Wavelet transform the features are extracted, yielding a time-frequency-amplitude decomposition. The extracted features obey certain Markov properties, which allows us to form a joint distribution in terms of a Dynamic Bayesian Network. We performed experiments using real seismic data recorded at different stations in the European Broadband Network, for which we achieve an average classification accuracy of 95%.

#index 1100182
#* Robust Visual Mining of Data with Error Information
#@ Jianyong Sun;Ata Kabán;Somak Raychaudhury
#t 2007
#c 21
#% 257039
#% 303620
#% 424831
#% 875949
#% 983910
#! Recent results on robust density-based clustering have indicated that the uncertainty associated with the actual measurements can be exploited to locate objects that are atypical for a reason unrelated to measurement errors. In this paper, we develop a constrainedrobust mixture model, which, in addition, is able to nonlinearly map such data for visual exploration. Our robust visual mining approach aims to combine statistically sound density-based analysis with visual presentation of the density structure, and to provide visual support for the identification and exploration of `genuine' peculiar objects of interest that are not due to the measurement errors. In this model, an exact inference is not possible despite the latent space being discretised, and we resort to employing a structured variational EM. We present results on synthetic data as well as a real application, for visualising peculiar quasars from an astrophysical survey, given photometric measurements with errors.

#index 1100183
#* An Effective Approach to Enhance Centroid Classifier for Text Categorization
#@ Songbo Tan;Xueqi Cheng
#t 2007
#c 21
#% 344447
#% 413589
#% 458379
#% 577232
#% 838502
#! Centroid Classifier has been shown to be a simple and yet effective method for text categorization. However, it is often plagued with model misfit (or inductive bias) incurred by its assumption. To address this issue, a novel Model Adjustment algorithm was proposed. The basic idea is to make use of some criteria to adjust Centroid Classifier model. In this work, the criteria include training-set errors as well as training-set margins. The empirical assessment indicates that proposed method performs slightly better than SVM classifier in prediction accuracy, as well as beats it in running time.

#index 1100184
#* Automatic Categorization of Human-Coded and Evolved CoreWar Warriors
#@ Nenad Tomašev;Doni Pracner;Miloš Radovanović;Mirjana Ivanović
#t 2007
#c 21
#% 246832
#% 269218
#% 926881
#% 1099024
#! CoreWar is a computer simulation devised in the 1980s where programs loaded into a virtual memory array compete for control over the virtual machine. These programs are written in a special-purpose assembly language called Redcodeand referred to as warriors. A great variety of environments and battle strategies have emerged over the years, leading to formation of different warrior types. This paper deals with the problem of automatic warrior categorization, presenting results of classification based on several approaches to warrior representation, and offering insight into ambiguities concerning the identification of strategic classes. Over 600 human-coded warriors were annotated, forming a training set for classification. Several major classifiers were used, SVMs proving to be the most reliable, reaching accuracy of 84%. Classification of an evolved warrior set using the trained classifiers was also conducted. The obtained results proved helpful in outlining the issues with both automatic and manual Redcode program categorization.

#index 1100185
#* Utility-Based Regression
#@ Luis Torgo;Rita Ribeiro
#t 2007
#c 21
#% 280437
#% 466268
#% 466760
#% 823406
#% 829981
#% 829988
#% 829989
#% 1289281
#! Cost-sensitive learning is a key technique for addressing many real world data mining applications. Most existing research has been focused on classification problems. In this paper we propose a framework for evaluating regression models in applications with non-uniform costs and benefits across the domain of the continuous target variable. Namely, we describe two metrics for asserting the costs and benefits of the predictions of any model given a set of test cases. We illustrate the use of our metrics in the context of a specific type of applications where non-uniform costs are required: the prediction of rare extreme values of a continuous target variable. Our experiments provide clear evidence of the utility of the proposed framework for evaluating the merits of any model in this class of regression domains.

#index 1100186
#* Multi-label Lazy Associative Classification
#@ Adriano Veloso;Wagner Meira, Jr.;Marcos Gonçalves;Mohammed Zaki
#t 2007
#c 21
#% 311034
#% 850525
#% 950571
#% 1273395
#% 1388992
#! Most current work on classification has been focused on learning from a set of instances that are associated with a single label (i.e., single-label classification). However, many applications, such as gene functional prediction and text categorization, may allow the instances to be associated with multiple labels simultaneously. Multi-label classification is a generalization of single-label classification, and its generality makes it much more difficult to solve.Despite its importance, research on multi-label classification is still lacking. Common approaches simply learn independent binary classifiers for each label, and do not exploit dependencies among labels. Also, several small disjuncts may appear due to the possibly large number of label combinations, and neglecting these small disjuncts may degrade classification accuracy. In this paper we propose a multi-label lazy associative classifier, which progressively exploits dependencies among labels. Further, since in our lazy strategy the classification model is induced on an instance-based fashion, the proposed approach can provide a better coverage of small disjuncts. Gains of up to 24% are observed when the proposed approach is compared against the state-of-the-art multi-label classifiers.

#index 1100187
#* Visual Exploration of Genomic Data
#@ Michail Vlachos;Bahar Taneri;Eamonn Keogh;Philip S. Yu
#t 2007
#c 21
#% 607875
#% 729931
#% 753026
#% 1010961
#% 1740869
#! In this study, we present methods for comparative visualization of DNA sequences in two dimensions. First, we illustrate a transformation of gene sequences into numerical trajectories. The trajectory visually captures the nucleotide content of each sequence, allowing for fast and easy visualization of long DNA sequences. Then, we project the relative placement of the trajectories on the 2D plane using a spanning-tree arrangement method, which allows the efficient comparison of multiple sequences. We demonstrate with various examples the applicability of our technique in evolutionary biology and specifically in capturing and visualizing the molecular phylogeny between species.

#index 1100188
#* Association Mining in Large Databases: A Re-examination of Its Measures
#@ Tianyi Wu;Yuguo Chen;Jiawei Han
#t 2007
#c 21
#% 227917
#% 227919
#% 392618
#% 452846
#% 464822
#% 577214
#% 632028
#% 727869
#% 769890
#% 769909
#! In the literature of data mining and statistics, numerous interestingness measures have been proposed to disclose succinct object relationships of association patterns. However, it is still not clear when a measure is truly effective in large data sets. Recent studies have identified a critical property, null-(transaction)invariance, for measuring event associations in large data sets, but many existing measures do not have this property. We thus re-examine the null-invariant measures and find interestingly that they can be expressed as a generalized mathematical mean, and there exists a total ordering of them. This ordering provides insights into the underlying philosophy of the measures and helps us understand and select the proper measure for different applications.

#index 1100189
#* Semantic Text Classification of Emergent Disease Reports
#@ Yi Zhang;Bing Liu
#t 2007
#c 21
#% 280817
#% 344447
#% 741891
#% 743629
#% 939568
#% 939718
#! Traditional text classification studied in the information retrieval and machine learning literature is mainly based on topics. That is, each class represents a particular topic, e.g., sports and politics. However, many real-world problems require more refined classification based on some semantic perspectives. For example, in a set of sentences about a disease, some may report outbreaks of the disease, some may describe how to cure the disease, and yet some may discuss how to prevent the disease. To classify sentences at this semantic level, the traditional bag-of-words model is no longer sufficient. In this paper, we study semantic sentence classification of disease reporting. We show that both keywords and sentence semantic features are useful. Our results demonstrated that this integrated approach is highly effective.

#index 1663612
#* Proceedings of the 10th European conference on Principle and Practice of Knowledge Discovery in Databases
#@ Johannes Fürnkranz;Tobias Scheffer;Myra Spiliopoulou
#t 2006
#c 21

#index 1663613
#* On temporal evolution in data streams
#@ Charu C. Aggarwal
#t 2006
#c 21
#! In recent years, the progress in hardware technology has made it possible for organizations to store and record large streams of transactional data. This results in databases which grow without limit at a rapid rate. This data can often show important changes in trends over time. In such cases, it is useful to understand, visualize, and diagnose the evolution of these trends. In this talk, we discuss a method to diagnose the changes in the underlying data stream and other related methods for change detection in streams. We also discuss the problem of data stream evolution in the context of mining algorithms such as clustering and classification. In many cases, mining algorithms may not function as effectively because of the change in the underlying data. We discuss the effects of evolution on mining and synopsis construction algorithms and a number of opportunities which may be available for further research on the topic.

#index 1663614
#* The future of citeseer: citeseerx
#@ C. Lee Giles
#t 2006
#c 21
#! CiteSeer, a public online computer and information science search engine and digital library, was introduced in 1997 and was a radical departure from the traditional methods of academic and scientific document access and analysis. Computer and information scientists quickly became used to and expected immediate access to their literature and CiteSeer provided a popular partial solution. CiteSeer was based on these features: actively acquiring new documents, automatic citation indexing, and automatic linking of citations and documents. CiteSeer, now hosted at the Pennsylvania State University with several mirrors, has over 750,000 documents. The current CiteSeer model is to a limited extent portable and was recently extended to academic business documents (SMEALSearch). Why has CiteSeer been so popular and how should it progress? What is its role with regards to other similar systems such as the Google Scholar and DBLP? What role should CiteSeer play in the open access movement? We discuss this and the Next Generation CiteSeer project, CiteSeerx, which will emphasize CiteSeer as a research tool, research web service, and researcher facilitator and testbed. In contrast to the current tightly integrated CiteSeer architecture, CiteSeerx will be modular, scalable and self managed. We will discuss how new intelligent data mining and information extraction algorithms will provide improved and new indexes, enhanced document access, expanded and automatic document gathering, collaboratories, new data and metadata resources, active mirroring, and web services. As an example of new features, we point out our new API based acknowledgement index and search. This new feature not only provides insight into the impact of acknowledged individuals, funding agencies and others, but also presents an architectural model for integration and expansion of our legacy system.

#index 1663615
#* Learning to have fun
#@ Jonathan Schaeffer
#t 2006
#c 21
#! Games have played a major role in the history of artificial intelligence research. The goal of this research largely has been to build programs capable of defeating strong human players. Most of the literature has been devoted to two-player, perfect information games—games where the research results have little wide-spread applicability. However, over the past few years the need for improved AI techniques have become apparent in commercial computer games, a $25 billion industry. Laird and van Lent call the new generation of commercial games “AI's killer application”. The buying public wants to see realistic artificial intelligence in these products. Here the the metric is a “fun” experience, not winning. Hence, the outcomes from research using these applications will be of much wider applicability. This talk will discuss the challenges of using machine learning in commercial computer games to create “fun”.

#index 1663616
#* Challenges of urban sensing
#@ Henry Tirri
#t 2006
#c 21
#! Wireless sensor networks are emerging as a critical information technology, and they are continuing the trend originating in mainframe computing currently at the stage of mobile computing. This trend shows several aspects consistent in the evolution of computing including the increasing hardware miniaturization of the computing units and an increasing emphasis of the role of communication between the computing units – “networking”. In addition from the software side there is an increasing need to software solutions that are robust, exhibit distributed control, collaborative interfaces resulting in adaptive capabilities also at the system level. Like the present Internet, wireless sensor networks are large-scale distributed systems, but composed of smart sensors and actuators. They will eventually infuse the physical world and provide “grounding” for the Internet thus creating the Internet of Things. Research on wireless sensor networks has been taking place at several levels, from the lowest physical level to the highest information level – the latter is much less developed than the research at the physical levels. In addition, much of the research in wireless sensor networks has been focusing on military or science applications. However, wireless sensor networks can also play an important role in the realization of ubiquitous computing for everyday life – creating what we call “Urban sensing environment”. In urban sensing many natural gateways exist to collect and process the sensor information – static ones such as media devices, or mobile devices such as smart phones that can collect sensor information when entering the communication range of an active sensor. Some of the applications of wireless sensor network technology at home include, in addition to the surveillance functions, adding “intelligence” to utility consumption, electronic tagging, contamination control and disaster monitoring. Similarly at the community level “traffic monitoring” including people allows a development of totally unseen services from micro weather forecasts to new ways for “sensing the environment” for entertainment. In this talk we will outline some of the research challenges for urban sensing, and the role of learning and data analysis techniques for solving those challenges.

#index 1663617
#* SD-map: a fast algorithm for exhaustive subgroup discovery
#@ Martin Atzmueller;Frank Puppe
#t 2006
#c 21
#% 232126
#% 300120
#% 424759
#% 459864
#% 477497
#% 481290
#% 722920
#% 763701
#% 1289454
#! In this paper we present the novel SD-Map algorithm for exhaustive but efficient subgroup discovery. SD-Map guarantees to identify all interesting subgroup patterns contained in a data set, in contrast to heuristic or sampling-based methods. The SD-Map algorithm utilizes the well-known FP-growth method for mining association rules with adaptations for the subgroup discovery task. We show how SD-Map can handle missing values, and provide an experimental evaluation of the performance of the algorithm using synthetic data.

#index 1663618
#* Decision trees for hierarchical multilabel classification: a case study in functional genomics
#@ Hendrik Blockeel;Leander Schietgat;Jan Struyf;Sašo Džeroski;Amanda Clare
#t 2006
#c 21
#% 136350
#% 290482
#% 466073
#% 478470
#% 840928
#% 906025
#% 1272000
#% 1676856
#! Hierarchical multilabel classification (HMC) is a variant of classification where instances may belong to multiple classes organized in a hierarchy. The task is relevant for several application domains. This paper presents an empirical study of decision tree approaches to HMC in the area of functional genomics. We compare learning a single HMC tree (which makes predictions for all classes together) to learning a set of regular classification trees (one for each class). Interestingly, on all 12 datasets we use, the HMC tree wins on all fronts: it is faster to learn and to apply, easier to interpret, and has similar or better predictive performance than the set of regular trees. It turns out that HMC tree learning is more robust to overfitting than regular tree learning.

#index 1663619
#* Clustering scientific literature using sparse citation graph analysis
#@ Levent Bolelli;Seyda Ertekin;C. Lee Giles
#t 2006
#c 21
#% 248790
#% 249143
#% 268079
#% 290830
#% 300971
#% 342620
#% 438103
#% 464304
#% 571729
#% 578775
#% 607793
#% 615723
#% 643008
#% 665639
#% 722914
#% 766433
#% 1835183
#! It is well known that connectivity analysis of linked documents provides significant information about the structure of the document space for unsupervised learning tasks. However, the ability to identify distinct clusters of documents based on link graph analysis is proportional to the density of the graph and depends on the availability of the linking and/or linked documents in the collection. In this paper, we present an information theoretic approach towards measuring the significance of individual words based on the underlying link structure of the document collection. This enables us to generate a non-uniform weight distribution of the feature space which is used to augment the original corpus-based document similarities. The experimental results on the collection of scientific literature show that our method achieves better separation of distinct groups of documents, yielding improved clustering solutions.

#index 1663620
#* VOGUE: a novel variable order-gap state machine for modeling sequences
#@ Bouchra Bouqata;Christopher D. Carothers;Boleslaw K. Szymanski;Mohammed J. Zaki
#t 2006
#c 21
#% 292004
#% 316552
#% 329537
#% 721139
#% 832572
#% 963898
#% 1389009
#! We present VOGUE, a new state machine that combines two separate techniques for modeling long range dependencies in sequential data: data mining and data modeling. VOGUE relies on a novel Variable-Gap Sequence mining method (VGS), to mine frequent patterns with different lengths and gaps between elements. It then uses these mined sequences to build the state machine. We applied VOGUE to the task of protein sequence classification on real data from the PROSITE protein families. We show that VOGUE yields significantly better scores than higher-order Hidden Markov Models. Moreover, we show that VOGUE's classification sensitivity outperforms that of HMMER, a state-of-the-art method for protein classification.

#index 1663621
#* Don't be afraid of simpler patterns
#@ Björn Bringmann;Albrecht Zimmermann;Luc De Raedt;Siegfried Nijssen
#t 2006
#c 21
#% 136350
#% 299985
#% 342604
#% 481290
#% 577218
#% 629708
#% 769891
#% 769951
#% 832870
#! This paper investigates the trade-off between the expressiveness of the pattern language and the performance of the pattern miner in structured data mining. This trade-off is investigated in the context of correlated pattern mining, which is concerned with finding the k-best patterns according to a convex criterion, for the pattern languages of itemsets, multi-itemsets, sequences, trees and graphs. The criteria used in our investigation are the typical ones in data mining: computational cost and predictive accuracy and the domain is that of mining molecular graph databases. More specifically, we provide empirical answers to the following questions: how does the expressive power of the language affect the computational cost? and what is the trade-off between expressiveness of the pattern language and the predictive accuracy of the learned model? While answering the first question, we also introduce a novel stepwise approach to correlated pattern mining in which the results of mining a simpler pattern language are employed as a starting point for mining in a more complex one. This stepwise approach typically leads to significant speed-ups (up to a factor 1000) for mining graphs.

#index 1663622
#* An adaptive prequential learning framework for bayesian network classifiers
#@ Gladys Castillo;João Gama
#t 2006
#c 21
#% 166244
#% 204531
#% 246832
#% 570155
#% 744024
#% 1718518
#! We introduce an adaptive prequential learning framework for Bayesian Network Classifiers which attempts to handle the cost-performance trade-off and cope with concept drift. Our strategy for incorporating new data is based on bias management and gradual adaptation. Starting with the simple Naïve Bayes, we scale up the complexity by gradually increasing the maximum number of allowable attribute dependencies, and then by searching for new dependences in the extended search space. Since updating the structure is a costly task, we use new data to primarily adapt the parameters and only if this is really necessary, do we adapt the structure. The method for handling concept drift is based on the Shewhart P-Chart. We evaluated our adaptive algorithms on artificial domains and benchmark problems and show its advantages and future applicability in real-world on-line learning systems.

#index 1663623
#* Adaptive active classification of cell assay images
#@ Nicolas Cebron;Michael R. Berthold
#t 2006
#c 21
#% 111306
#% 170649
#% 361966
#% 374537
#% 466419
#% 770771
#% 829013
#% 840425
#% 844323
#% 1562583
#% 1780699
#! Classifying large datasets without any a-priori information poses a problem in many tasks. Especially in the field of bioinformatics, often huge unlabeled datasets have to be explored mostly manually by a biology expert. In this work we consider an application that is motivated by the development of high-throughput microscope screening cameras. These devices are able to produce hundreds of thousands of images per day. We propose a new adaptive active classification scheme which establishes ties between the two opposing concepts of unsupervised clustering of the underlying data and the supervised task of classification. Based on Fuzzy c-means clustering and Learning Vector Quantization, the scheme allows for an initial clustering of large datasets and subsequently for the adjustment of the classification based on a small number of carefully chosen examples. Motivated by the concept of active learning, the learner tries to query the most informative examples in the learning process and therefore keeps the costs for supervision at a low level. We compare our approach to Learning Vector Quantization with random selection and Support Vector Machines with Active Learning on several datasets.

#index 1663624
#* Learning parameters in entity relationship graphs from ranking preferences
#@ Soumen Chakrabarti;Alekh Agarwal
#t 2006
#c 21
#% 111303
#% 268079
#% 290830
#% 309104
#% 348173
#% 466891
#% 577224
#% 577329
#% 577338
#% 654442
#% 660011
#% 805896
#% 1016176
#% 1289460
#! Semi-structured entity-relation (ER) data graphs have diverse node and edge types representing entities (paper, person, company) and relations (wrote, works for). In addition, nodes contain text snippets. Extending from vector-space information retrieval, we wish to automatically learn ranking function for searching such typed graphs. User input is in the form of a partial preference order between pairs of nodes, associated with a query. We present a unified model for ranking in ER graphs, and propose an algorithm to learn the parameters of the model. Experiments with carefully-controlled synthetic data as well as real data (garnered using CiteSeer, DBLP and Google Scholar) show that our algorithm can satisfy training preferences and generalize to test preferences, and estimate meaningful model parameters that represent the relative importance of ER types.

#index 1663625
#* Detecting fraudulent personalities in networks of online auctioneers
#@ Duen Horng Chau;Shashank Pandit;Christos Faloutsos
#t 2006
#c 21
#% 268079
#% 290830
#% 316798
#% 580307
#% 784344
#% 823370
#% 1016177
#! Online auctions have gained immense popularity by creating an accessible environment for exchanging goods at reasonable prices. Not surprisingly, malevolent auction users try to abuse them by cheating others. In this paper we propose a novel method, 2-Level Fraud Spotting (2LFS), to model the techniques that fraudsters typically use to carry out fraudulent activities, and to detect fraudsters preemptively. Our key contributions are: (a) we mine user level features (e.g., number of transactions, average price of goods exchanged, etc.) to get an initial belief for spotting fraudsters, (b) we introduce network level features which capture the interactions between different users, and (c) we show how to combine both these features using a Belief Propagation algorithm over a Markov Random Field, and use it to detect suspicious patterns (e.g., unnaturally close-nit groups of people that trade mainly among themselves). Our algorithm scales linearly with the number of graph edges. Moreover, we illustrate the effectiveness of our algorithm on a real dataset collected from a large online auction site.

#index 1663626
#* Measuring constraint-set utility for partitional clustering algorithms
#@ Ian Davidson;Kiri L. Wagstaff;Sugato Basu
#t 2006
#c 21
#% 376266
#% 464291
#% 464608
#% 715529
#% 769881
#% 829025
#! Clustering with constraints is an active area of machine learning and data mining research. Previous empirical work has convincingly shown that adding constraints to clustering improves performance, with respect to the true data labels. However, in most of these experiments, results are averaged over different randomly chosen constraint sets, thereby masking interesting properties of individual sets. We demonstrate that constraint sets vary significantly in how useful they are for constrained clustering; some constraint sets can actually decrease algorithm performance. We create two quantitative measures, informativeness and coherence, that can be used to identify useful constraint sets. We show that these measures can also help explain differences in performance for four particular constrained clustering algorithms.

#index 1663627
#* Discovery of interesting regions in spatial data sets using supervised clustering
#@ Christoph F. Eick;Banafsheh Vaezian;Dan Jiang;Jing Wang
#t 2006
#c 21
#% 478613
#% 501512
#% 527021
#% 527188
#% 566128
#% 785580
#% 1707733
#! The discovery of interesting regions in spatial datasets is an important data mining task. In particular, we are interested in identifying disjoint, contiguous regions that are unusual with respect to the distribution of a given class; i.e. a region that contains an unusually low or high number of instances of a particular class. This paper centers on the discussion of techniques, methodologies, and algorithms to discover such regions. A measure of interestingness and a supervised clustering framework are introduced for this purpose. Moreover, three supervised clustering algorithms are proposed in the paper: an agglomerative hierarchical supervised clustering named SCAH, an agglomerative, grid-based clustering method named SCHG, and lastly an algorithm named SCMRG which searches a multi-resolution grid structure top down for interesting regions. Finally, experimental results of applying the proposed framework and algorithms to the problem of identifying hotspots in spatial datasets are discussed.

#index 1663628
#* Optimal string mining under frequency constraints
#@ Johannes Fischer;Volker Heun;Stefan Kramer
#t 2006
#c 21
#% 115467
#% 137808
#% 143306
#% 235941
#% 280409
#% 544049
#% 545956
#% 587757
#% 629643
#% 751623
#% 770226
#% 779214
#% 844365
#% 906547
#% 1386508
#% 1656273
#% 1672945
#! We propose a new algorithmic framework that solves frequency-related data mining queries on databases of strings in optimal time, i.e., in time linear in the input and the output size. The additional space is linear in the input size. Our framework can be used to mine frequent strings, emerging strings and strings that pass other statistical tests, e.g., the χ2-test. In contrast to the presented result for strings, no optimal algorithms are known for other pattern domains such as itemsets. The key to our approach are several recent results on index structures for strings, among them suffix- and lcp-arrays, and a new preprocessing scheme for range minimum queries. The advantages of array-based data structures (compared with dynamic data structures such as trees) are good locality behavior and extensibility to secondary memory. We test our algorithm on real-world data from computational biology and demonstrate that the approach also works well in practice.

#index 1663629
#* k-Anonymous Decision Tree Induction
#@ Arik Friedman;Assaf Schuster;Ran Wolff
#t 2006
#c 21
#% 136350
#% 300184
#% 449588
#% 512307
#% 576762
#% 577239
#% 635215
#% 769943
#% 800514
#% 800515
#% 801690
#% 810011
#% 864406
#% 864412
#% 926881
#% 1673554
#% 1706194
#! In this paper we explore an approach to privacy preserving data mining that relies on the k-anonymity model. The k-anonymity model guarantees that no private information in a table can be linked to a group of less than k individuals. We suggest extended definitions of k-anonymity that allow the k-anonymity of a data mining model to be determined. Using these definitions, we present decision tree induction algorithms that are guaranteed to maintain k-anonymity of the learning examples. Experiments show that embedding anonymization within the decision tree induction process provides better accuracy than anonymizing the data first and inducing the tree later.

#index 1663630
#* Closed sets for labeled data
#@ Gemma C. Garriga;Petra Kralj;Nada Lavrač
#t 2006
#c 21
#% 280409
#% 420126
#% 449566
#% 459864
#% 763701
#% 765529
#% 772329
#% 785435
#% 791179
#% 926881
#% 1272357
#! Closed sets are being successfully applied in the context of compacted data representation for association rule learning. However, their use is mainly descriptive. This paper shows that, when considering labeled data, closed sets can be adapted for prediction and discrimination purposes by conveniently contrasting covering properties on positive and negative examples. We formally justify that these sets characterize the space of relevant combinations of features for discriminating the target class. In practice, identifying relevant/irrelevant combinations of features through closed sets is useful in many applications. Here we apply it to compacting emerging patterns and essential rules and to learn descriptions for subgroup discovery.

#index 1663631
#* Finding trees from unordered 0–1 data
#@ Hannes Heikinheimo;Heikki Mannila;Jouni K. Seppänen
#t 2006
#c 21
#% 172386
#% 232136
#% 248791
#% 280433
#% 316709
#% 342610
#% 461909
#% 502132
#% 577218
#% 577252
#% 727828
#% 729922
#% 765125
#% 769957
#% 944956
#! Tree structures are a natural way of describing occurrence relationships between attributes in a dataset. We define a new class of tree patterns for unordered 0–1 data and consider the problem of discovering frequently occurring members of this pattern class. Intuitively, a tree T occurs in a row u of the data, if the attributes of T that occur in u form a subtree of T containing the root. We show that this definition has advantageous properties: only shallow trees have a significant probability of occurring in random data, and the definition allows a simple levelwise algorithm for mining all frequently occurring trees. We demonstrate with empirical results that the method is feasible and that it discovers interesting trees in real data.

#index 1663632
#* Web communities identification from random walks
#@ Jiayuan Huang;Tingshao Zhu;Dale Schuurmans
#t 2006
#c 21
#% 249110
#% 290830
#% 309779
#% 310514
#% 313959
#% 433902
#% 438553
#% 457710
#% 805906
#% 840965
#! We propose a technique for identifying latent Web communities based solely on the hyperlink structure of the WWW, via random walks. Although the topology of the Directed Web Graph encodes important information about the content of individual Web pages, it also reveals useful meta-level information about user communities. Random walk models are capable of propagating local link information throughout the Web Graph, which can be used to reveal hidden global relationships between different regions of the graph. Variations of these random walk models are shown to be effective at identifying latent Web communities and revealing link topology. To efficiently extract these communities from the stationary distribution defined by a random walk, we exploit a computationally efficient form of directed spectral clustering. The performance of our approach is evaluated in real Web applications, where the method is shown to effectively identify latent Web communities based on link topology only.

#index 1663633
#* Information marginalization on subgraphs
#@ Jiayuan Huang;Tingshao Zhu;Russell Greiner;Dengyong Zhou;Dale Schuurmans
#t 2006
#c 21
#% 290830
#% 342621
#% 342659
#% 458652
#% 729918
#% 823328
#% 840840
#% 840965
#! Real-world data often involves objects that exhibit multiple relationships; for example, ‘papers' and ‘authors' exhibit both paper-author interactions and paper-paper citation relationships. A typical learning problem requires one to make inferences about a subclass of objects (e.g. ‘papers'), while using the remaining objects and relations to provide relevant information. We present a simple, unified mechanism for incorporating information from multiple object types and relations when learning on a targeted subset. In this scheme, all sources of relevant information are marginalized onto the target subclass via random walks. We show that marginalized random walks can be used as a general technique for combining multiple sources of information in relational data. With this approach, we formulate new algorithms for transduction and ranking in relational data, and quantify the performance of new schemes on real world data—achieving good results in many problems.

#index 1663634
#* Why does subsequence time-series clustering produce sine waves?
#@ Tsuyoshi Idé
#t 2006
#c 21
#% 727900
#% 729437
#% 769935
#% 770830
#% 844296
#% 844377
#! The data mining and machine learning communities were surprised when Keogh et al. (2003) pointed out that the k-means cluster centers in subsequence time-series clustering become sinusoidal pseudo-patterns for almost all kinds of input time-series data. Understanding this mechanism is an important open problem in data mining. Our new theoretical approach (based on spectral clustering and translational symmetry) explains why the cluster centers of k-means naturally tend to form sinusoidal patterns.

#index 1663635
#* Transductive learning for text classification using explicit knowledge models
#@ Georgiana Ifrim;Gerhard Weikum
#t 2006
#c 21
#% 269225
#% 311027
#% 329569
#% 451536
#% 458379
#% 466101
#% 466263
#% 565545
#% 785375
#! We present a generative model based approach for transductive learning for text classification. Our approach combines three methodological ingredients: learning from background corpora, latent variable models for decomposing the topic-word space into topic-concept and concept-word spaces, and explicit knowledge models (light-weight ontologies, thesauri, e.g. WordNet) with named concepts for populating latent variables. The combination has synergies that can boost the combined performance. This paper presents the theoretical model and extensive experimental results on three data collections. Our experiments show improved classification results over state-of-the-art classification techniques such as the Spectral Graph Transducer and Transductive Support Vector Machines, particularly for the case of sparse training.

#index 1663636
#* Exploring multiple communities with kernel-based link analysis
#@ Takahiko Ito;Masashi Shimbo;Daichi Mochihashi;Yuji Matsumoto
#t 2006
#c 21
#% 262061
#% 280819
#% 290830
#% 304917
#% 823388
#! We discuss issues raised by applying von Neumann kernels to graphs with multiple communities. Depending on the parameter setting, Kandola et al.'s von Neumann kernels can identify not only nodes related to a given node but also the most important nodes in a graph. However, when von Neumann kernels are biased towards importance, top-ranked nodes are the important nodes in the dominant community of the graph irrespective of the communities where the target node belongs. To solve this “topic-drift” problem, we apply von Neumann kernels to the weighted graphs (community graph), which are derived from a generative model of links.

#index 1663637
#* Distribution rules with numeric attributes of interest
#@ Alípio M. Jorge;Paulo J. Azevedo;Fernando Pereira
#t 2006
#c 21
#% 176024
#% 210160
#% 210162
#% 227917
#% 232126
#% 280433
#% 342640
#% 451441
#% 481290
#% 631970
#% 769913
#% 840849
#! In this paper we introduce distribution rules, a kind of association rules with a distribution on the consequent. Distribution rules are related to quantitative association rules but can be seen as a more fundamental concept, useful for learning distributions. We formalize the main concepts and indicate applications to tasks such as frequent pattern discovery, sub group discovery and forecasting. An efficient algorithm for the generation of distribution rules is described. We also provide interest measures, visualization techniques and evaluation.

#index 1663638
#* Tractable models for information diffusion in social networks
#@ Masahiro Kimura;Kazumi Saito
#t 2006
#c 21
#% 36698
#% 268079
#% 342596
#% 577217
#% 729923
#% 754107
#% 1289272
#% 1289476
#% 1669913
#! When we consider the problem of finding influential nodes for information diffusion in a large-scale social network based on the Independent Cascade Model (ICM), we need to compute the expected number of nodes influenced by a given set of nodes. However, a good estimate of this quantity needs a large amount of computation in the ICM. In this paper, we propose two natural special cases of the ICM such that a good estimate of this quantity can be efficiently computed. Using real large-scale social networks, we experimentally demonstrate that for extracting influential nodes, the proposed models can provide novel ranking methods that are different from the ICM, typical methods of social network analysis, and “PageRank” method. Moreover, we experimentally demonstrate that when the propagation probabilities through links are small, they can give good approximations to the ICM for finding sets of influential nodes.

#index 1663639
#* Efficient spatial classification using decoupled conditional random fields
#@ Chi-Hoon Lee;Russell Greiner;Osmar Zaïane
#t 2006
#c 21
#% 269218
#% 277396
#% 338741
#% 420077
#% 464434
#% 743284
#% 770866
#% 1673563
#! We present a discriminative method to classify data that have interdependencies in 2-D lattice. Although both Markov Random Fields (MRFs) and Conditional Random Fields (CRFs) are well-known methods for modeling such dependencies, they are often ineffective and inefficient, respectively. This is because many of the simplifying assumptions that underlie the MRF's efficiency compromise its accuracy. As CRFs are discriminative, they are typically more accurate than the generative MRFs. This also means their learning process is more expensive. This paper addresses this situation by defining and using “Decoupled Conditional Random Fields (DCRFs)”, a variant of CRFs whose learning process is more efficient as it decouples the tasks of learning potentials. Although our model is only guaranteed to approximate a CRF, our empirical results on synthetic/real datasets show that DCRF is essentially as accurate as other CRF variants, but is many times faster to train.

#index 1663640
#* Group SAX: extending the notion of contrast sets to time series and multimedia data
#@ Jessica Lin;Eamonn Keogh
#t 2006
#c 21
#% 152934
#% 248791
#% 280477
#% 282232
#% 310551
#% 577221
#% 662750
#% 727624
#% 729935
#% 789009
#! In this work, we take the traditional notation of contrast sets and extend them to other data types, in particular time series and by extension, images. In the traditional sense, contrast-set mining identifies attributes, values and instances that differ significantly across groups, and helps user understand the differences between groups of data. We reformulate the notion of contrast-sets for time series data, and define it to be the key pattern(s) that are maximally different from the other set of data. We propose a fast and exact algorithm to find the contrast sets, and demonstrate its utility in several diverse domains, ranging from industrial to anthropology. We show that our algorithm achieves 3 orders of magnitude speedup from the brute-force algorithm, while producing exact solutions.

#index 1663641
#* An attacker's view of distance preserving maps for privacy preserving data mining
#@ Kun Liu;Chris Giannella;Hillol Kargupta
#t 2006
#c 21
#% 67453
#% 300184
#% 576111
#% 576761
#% 740764
#% 805092
#% 810010
#% 843878
#% 844360
#% 993988
#% 1016189
#! We examine the effectiveness of distance preserving transformations in privacy preserving data mining. These techniques are potentially very useful in that some important data mining algorithms can be efficiently applied to the transformed data and produce exactly the same results as if applied to the original data e.g. distance-based clustering, k-nearest neighbor classification. However, the issue of how well the original data is hidden has, to our knowledge, not been carefully studied. We take a step in this direction by assuming the role of an attacker armed with two types of prior information regarding the original data. We examine how well the attacker can recover the original data from the transformed data and prior information. Our results offer insight into the vulnerabilities of distance preserving transformations.

#index 1663642
#* A scalable distributed stream mining system for highway traffic data
#@ Ying Liu;Alok Choudhary;Jianhong Zhou;Ashfaq Khokhar
#t 2006
#c 21
#% 340291
#% 345861
#% 397252
#% 460862
#% 481779
#% 594012
#% 727926
#% 769927
#% 843834
#% 993960
#% 1015261
#! To achieve the concept of smart roads, intelligent sensors are being placed on the roadways to collect real-time traffic streams. Traditional method is not a real-time response, and incurs high communication and storage costs. Existing distributed stream mining algorithms do not consider the resource limitation on the lightweight devices such as sensors. In this paper, we propose a distributed traffic stream mining system. The central server performs various data mining tasks only in the training and updating stage and sends the interesting patterns to the sensors. The sensors monitor and predict the coming traffic or raise alarms independently by comparing with the patterns observed in the historical streams. The sensors provide real-time response with less wireless communication and small resource requirement, and the computation burden on the central server is reduced. We evaluate our system on the real highway traffic streams in the GCM Transportation Corridor in Chicagoland.

#index 1663643
#* K-Landmarks: distributed dimensionality reduction for clustering quality maintenance
#@ Panagis Magdalinos;Christos Doulkeridis;Michalis Vazirgiannis
#t 2006
#c 21
#% 201893
#% 379340
#% 451536
#% 480132
#! Due to the vast amount and pace of high-dimensional data production and their distribution among network nodes, the fields of Distributed Knowledge Discovery (DKD) and Distributed Dimensionality Reduction (DDR) have emerged as a necessity in many application areas. While a wealth of centralized dimensionality reduction (DR) algorithms is available, only few have been proposed for distributed environments, most of them adaptations of centralized ones. In this paper, we introduce K-Landmarks, a new DDR algorithm, and we evaluate its comparative performance against a set of well known distributed and centralized DR algorithms. We primarily focus on each algorithm's performance in maintaining clustering quality throughout the projection, while retaining low stress values. Our algorithm outperforms most other algorithms, showing its suitability for highly distributed environments.

#index 1663644
#* The discrete basis problem
#@ Pauli Miettinen;Taneli Mielikäinen;Aristides Gionis;Gautam Das;Heikki Mannila
#t 2006
#c 21
#% 152934
#% 280819
#% 408396
#% 458673
#% 722904
#% 769928
#% 796209
#% 799752
#% 1742003
#! Matrix decomposition methods represent a data matrix as a product of two smaller matrices: one containing basis vectors that represent meaningful concepts in the data, and another describing how the observed data can be expressed as combinations of the basis vectors. Decomposition methods have been studied extensively, but many methods return real-valued matrices. If the original data is binary, the interpretation of the basis vectors is hard. We describe a matrix decomposition formulation, the Discrete Basis Problem. The problem seeks for a Boolean decomposition of a binary matrix, thus allowing the user to easily interpret the basis vectors. We show that the problem is computationally difficult and give a simple greedy algorithm for solving it. We present experimental results for the algorithm. The method gives intuitively appealing basis vectors. On the other hand, the continuous decomposition methods often give better reconstruction accuracies. We discuss the reasons for this behavior.

#index 1663645
#* Evaluation of summarization schemes for learning in streams
#@ Alec Pawling;Nitesh V. Chawla;Amitabh Chaudhary
#t 2006
#c 21
#% 273900
#% 310500
#% 342600
#% 342639
#% 378388
#% 453493
#% 847115
#! Traditional discretization techniques for machine learning, from examples with continuous feature spaces, are not efficient when the data is in the form of a stream from an unknown, possibly changing, distribution. We present a time-and-memory-efficient discretization technique based on computing ε-approximate exponential frequency quantiles, and prove bounds on the worst-case error introduced in computing information entropy in data streams compared to an offline algorithm that has no efficiency constraints. We compare the empirical performance of the technique, using it for feature selection, with (streaming adaptations of) two popular methods of discretization, equal width binning and equal frequency binning, under a variety of streaming scenarios for real and artificial datasets. Our experiments show that ε-approximate exponential frequency quantiles are remarkably consistent in their performance, in contrast to the simple and efficient equal width binning that perform quite well when the streams are from stationary distributions, and quite poorly otherwise.

#index 1663646
#* Efficient mining of correlation patterns in spatial point data
#@ Marko Salmenkivi
#t 2006
#c 21
#% 527188
#% 728302
#% 769914
#% 784509
#% 785420
#! We address the problem of analyzing spatial correlation between event types in large point data sets. Collocation rules are unsatisfactory, when confidence is not a sufficiently accurate interestingness measure, and Monte Carlo testing is infeasible, when the number of event types is large. We introduce an algorithm for mining correlation patterns, based on a non-parametric bootstrap test that, however, avoids the actual resampling by scanning each point and its distances to the events in the neighbourhood. As a real data set we analyze a large place name data set, the set of event types consisting of different linguistic features that appear in the place names. Experimental results show that the algorithm can be applied to large data sets with hundreds of event types.

#index 1663647
#* Improving functional modularity in protein-protein interactions graphs using hub-induced subgraphs
#@ Duygu Ucar;Sitaram Asur;Umit Catalyurek;Srinivasan Parthasarathy
#t 2006
#c 21
#% 833596
#% 842806
#% 1504829
#! Dense subgraphs of Protein-Protein Interaction (PPI) graphs are believed to be potential functional modules and play an important role in inferring the functional behavior of proteins. PPI graphs are known to exhibit the scale-free property in which a few nodes (hubs) are highly connected. This scale-free topology of PPI graphs makes it hard to isolate dense subgraphs effectively. In this paper, we propose a novel refinement method based on neighborhoods and the biological importance of hub proteins. We show that this refinement improves the functional modularity of the PPI graph and leads to effective clustering into dense components. A detailed comparison of these dense components with the ones obtained from the original PPI graph reveal three major benefits of the refinement: i) Enhancement of existing functional groupings; ii) Isolation of new functional groupings; and iii) Soft clustering of multifunctional hub proteins to multiple functional groupings.

#index 1663648
#* Refining aggregate conditions in relational learning
#@ Celine Vens;Jan Ramon;Hendrik Blockeel
#t 2006
#c 21
#% 136350
#% 248785
#% 478596
#% 478762
#% 550574
#% 550714
#% 550740
#% 729926
#% 729982
#% 883329
#% 1271968
#% 1290272
#% 1718470
#! In relational learning, predictions for an individual are based not only on its own properties but also on the properties of a set of related individuals. Many systems use aggregates to summarize this set. Features thus introduced compare the result of an aggregate function to a threshold. We consider the case where the set to be aggregated is generated by a complex query and present a framework for refining such complex aggregate conditions along three dimensions: the aggregate function, the query used to generate the set, and the threshold value. The proposed aggregate refinement operator allows a more efficient search through the hypothesis space and thus can be beneficial for many relational learners that use aggregates. As an example application, we have implemented the refinement operator in a relational decision tree induction system. Experimental results show a significant efficiency gain in comparison with the use of a less advanced refinement operator.

#index 1663649
#* Measuring to fit: virtual tailoring through cluster analysis and classification
#@ Herna L. Viktor;Eric Paquet;Hongyu Guo
#t 2006
#c 21
#% 136350
#% 252011
#% 290482
#% 392781
#% 393812
#% 465922
#% 612505
#% 830277
#! Clothes should be designed to tailor well, fit the body elegantly and hide obvious body flaws. To attain this goal, it is crucial to know the interrelationships between different body measurements, such as the interplay between e.g. shoulder width, neck circumference and waist. This paper discusses a study to better understand the typical consumer, from a virtual tailor's perspective. Cluster analysis was used to group the population into five clothing sizes. Next, multi-relational classification was applied to analyze the interplay between each group's anthropometric body measurements. Throughout this study, three- dimensional (3-D) body scans were used to verify the validity of our findings. Our results indicate that different sets of body measurements are used to characterize each clothing size. This information, together with the demographic profiles of the typical consumer, provides us with new insight into our evolving population.

#index 1663650
#* RIVA: indexing and visualization of high-dimensional data via dimension reorderings
#@ Michail Vlachos;Spiros Papadimitriou;Zografoula Vagena;Philip S. Yu
#t 2006
#c 21
#% 201893
#% 346696
#% 397376
#% 397382
#% 480146
#% 726032
#% 778215
#% 1016130
#! We propose a new representation for high-dimensional data that can prove very effective for visualization, nearest neighbor (NN) and range searches. It has been unequivocally demonstrated that existing index structures cannot facilitate efficient search in high-dimensional spaces. We show that a transformation from points to sequences can potentially diminish the negative effects of the dimensionality curse, permitting an efficient NN-search. The transformed sequences are optimally reordered, segmented and stored in a low-dimensional index. The experimental results validate that the proposed representation can be a useful tool for the fast analysis and visualization of high-dimensional databases.

#index 1663651
#* Distributed subgroup mining
#@ Michael Wurst;Martin Scholz
#t 2006
#c 21
#% 232126
#% 333987
#% 340291
#% 414609
#% 434348
#% 443091
#% 477497
#% 481290
#% 550575
#% 722920
#% 768667
#% 799042
#% 823351
#% 844403
#% 1289454
#% 1781524
#! Subgroup discovery is a popular form of supervised rule learning, applicable to descriptive and predictive tasks. In this work we study two natural extensions of classical subgroup discovery to distributed settings. In the first variant the goal is to efficiently identify global subgroups, i.e. the rules an analysis would yield after collecting all the data at a single central database. In contrast, the second considered variant takes the locality of data explicitly into account. The aim is to find patterns that point out major differences between individual databases with respect to a specific property of interest (target attribute). We point out substantial differences between these novel learning problems and other kinds of distributed data mining tasks. These differences motivate new search and communication strategies, aiming at a minimization of computation time and communication costs. We present and empirically evaluate new algorithms for both considered variants.

#index 1663652
#* Network flow for collaborative ranking
#@ Ziming Zhuang;Silviu Cucerzan;C. Lee Giles
#t 2006
#c 21
#% 53085
#% 255179
#% 268073
#% 268079
#% 268186
#% 288780
#% 290830
#% 309095
#% 309749
#% 310514
#% 310567
#% 330617
#% 411762
#% 458410
#% 458686
#% 476462
#% 735079
#% 769569
#% 783554
#% 805839
#% 818221
#% 1264955
#% 1289575
#! In query based Web search, a significant percentage of user queries are underspecified, most likely by naive users. Collaborative ranking helps the naive user by exploiting the collective expertise. We present a novel algorithmic model inspired by the network flow theory, which constructs a search network based on search engine logs to describe the relationship between the relevant entities in search: queries, documents, and users. This formal model permits the theoretical investigation of the nature of collaborative ranking in more concrete terms, and the learning of the dependence relations among the different entities. FlowRank, an algorithm derived from this model through an analysis of empirical usage patterns, is implemented and evaluated. We empirically show its potential in experiments involving real-world user relevance ratings and a random sample of 1,334 documents and 100 queries from a popular document search engine. Definite improvements over two baseline ranking algorithms for approximately 47% of the queries are reported.

#index 1663653
#* Finding hierarchies of subspace clusters
#@ Elke Achtert;Christian Böhm;Hans-Peter Kriegel;Peer Kröger;Ina Müller-Gorman;Arthur Zimek
#t 2006
#c 21
#% 248792
#% 273890
#% 273891
#% 280417
#% 397384
#% 785335
#% 844313
#! Many clustering algorithms are not applicable to high-dimensional feature spaces, because the clusters often exist only in specific subspaces of the original feature space. Those clusters are also called subspace clusters. In this paper, we propose the algorithm HiSC (Hierarchical Subspace Clustering) that can detect hierarchies of nested subspace clusters, i.e. the relationships of lower-dimensional subspace clusters that are embedded within higher-dimensional subspace clusters. Several comparative experiments using synthetic and real data sets show the performance and the effectivity of HiSC.

#index 1663654
#* Integrating pattern mining in relational databases
#@ Toon Calders;Bart Goethals;Adriana Prado
#t 2006
#c 21
#% 216508
#% 333243
#% 376266
#% 384978
#% 387508
#% 420076
#% 420101
#% 481290
#% 487671
#! Almost a decade ago, Imielinski and Mannila introduced the notion of Inductive Databases to manage KDD applications just as DBMSs successfully manage business applications. The goal is to follow one of the key DBMS paradigms: building optimizing compilers for ad hoc queries. During the past decade, several researchers proposed extensions to the popular relational query language, SQL, in order to express such mining queries. In this paper, we propose a completely different and new approach, which extends the DBMS itself, not the query language, and integrates the mining algorithms into the database query optimizer. To this end, we introduce virtual mining views, which can be queried as if they were traditional relational tables (or views). Every time the database system accesses one of these virtual mining views, a mining algorithm is triggered to materialize all tuples needed to answer the query. We show how this can be done effectively for the popular association rule and frequent set mining problems.

#index 1663655
#* Discovering patterns in real-valued time series
#@ Joe Catalano;Tom Armstrong;Tim Oates
#t 2006
#c 21
#% 240182
#% 280482
#% 477968
#% 529189
#% 662750
#% 729960
#! This paper describes an algorithm for discovering variable length patterns in real-valued time series. In contrast to most existing pattern discovery algorithms, ours does not first discretize the data, runs in linear time, and requires constant memory. These properties are obtained by sampling the data stream rather than processing all of the data. Empirical results show that the algorithm performs well on both synthetic and real data when compared to an exhaustive algorithm.

#index 1663656
#* Classification of dementia types from cognitive profiles data
#@ Giorgio Corani;Chris Edgar;Isabelle Marshall;Keith Wesnes;Marco Zaffalon
#t 2006
#c 21
#% 129980
#% 926881
#% 1786752
#! The Cognitive Drug Research (CDR) system is specifically validated for dementia assessment; it consists of a series of computerized tests, which assess the cognitive faculties of the patient to derive a cognitive profile. We use six different classification algorithms to classify clinically diagnosed diseases from their cognitive profiles. Good accuracy was obtained in separating patients affected by Parkinson's disease from demented patients, and in discriminating between Alzheimer's disease and Vascular Dementia. However, in discriminating between Parkinson disease with dementia (PDD) and dementia with Lewy bodies (DLB), the accuracy was only slightly superior to chance; the existence of a significant difference in the cognitive profiles of DLB and PDD is indeed questioned in the medical literature.

#index 1663657
#* When efficient model averaging out-performs boosting and bagging
#@ Ian Davidson;Wei Fan
#t 2006
#c 21
#% 312727
#% 376266
#% 727888
#% 770847
#% 844364
#% 1250171
#! The Bayes optimal classifier (BOC) is an ensemble technique used extensively in the statistics literature. However, compared to other ensemble techniques such as bagging and boosting, BOC is less known and rarely used in data mining. This is partly due to BOC being perceived as being inefficient and because bagging and boosting consistently outperforms a single model, which raises the question: “Do we even need BOC in datamining?”. We show that the answer to this question is “yes” by illustrating several recent efficient model averaging approximations to BOC can significantly outperform bagging and boosting in realistic situations such as extensive class label noise, sample selection bias and many-class problems. That model averaging techniques outperform bagging and boosting in these situations has not been published in the machine learning, mining or statistical communities to our knowledge.

#index 1663658
#* Peak-Jumping frequent itemset mining algorithms
#@ Nele Dexters;Paul W. Purdom;Dirk Van Gucht
#t 2006
#c 21
#% 152934
#% 248791
#% 300120
#% 443350
#% 465003
#% 481290
#% 841959
#% 874155
#! We analyze algorithms that, under the right circumstances, permit efficient mining for frequent itemsets in data with tall peaks (large frequent itemsets). We develop a family of level-by-level peak-jumping algorithms, and study them using a simple probability model. The analysis clarifies why the jumping idea sometimes works well, and which properties the data needs to have for this to be the case. The link with Max-Miner arises in a natural way and the analysis makes clear the role and importance of each major idea used in this algorithm.

#index 1663659
#* Autonomous visualization
#@ Khalid El-Arini;Andrew W. Moore;Ting Liu
#t 2006
#c 21
#% 89776
#% 156186
#% 248792
#% 290482
#% 321455
#% 333543
#% 451038
#% 466921
#% 823341
#% 1012144
#% 1786334
#! Many classification algorithms suffer from a lack of human interpretability. Using such classifiers to solve real world problems often requires blind faith in the given model. In this paper we present a novel approach to classification that takes into account interpretability and visualization of the results. We attempt to efficiently discover the most relevant snapshot of the data, in the form of a two-dimensional scatter plot with easily understandable axes. We then use this plot as the basis for a classification algorithm. Furthermore, we investigate the trade-off between classification accuracy and interpretability by comparing the performance of our classifier on real data with that of several traditional classifiers. Upon evaluating our algorithm on a wide range of canonical data sets we find that, in most cases, it is possible to obtain additional interpretability with little or no loss in classification accuracy.

#index 1663660
#* Naive bayes for text classification with unbalanced classes
#@ Eibe Frank;Remco R. Bouckaert
#t 2006
#c 21
#% 478128
#% 580511
#% 1712903
#! Multinomial naive Bayes (MNB) is a popular method for document classification due to its computational efficiency and relatively good predictive performance. It has recently been established that predictive performance can be improved further by appropriate data transformations [1,2]. In this paper we present another transformation that is designed to combat a potential problem with the application of MNB to unbalanced datasets. We propose an appropriate correction by adjusting attribute priors. This correction can be implemented as another data normalization step, and we show that it can significantly improve the area under the ROC curve. We also show that the modified version of MNB is very closely related to the simple centroid-based classifier and compare the two methods empirically.

#index 1663661
#* Knowledge-Conscious data clustering
#@ Amol Ghoting;Srinivasan Parthasarathy
#t 2006
#c 21
#% 280454
#% 280463
#% 414606
#% 1015261
#! We consider the problem of efficiently executing data clustering queries in a client-server setting. Extant solutions to this problem suffer from (a) a significant amount of remote I/O and (b) minimal re-use of computation between both iterations of a kMeans query, and executions of different kMeans queries. We propose to facilitate interactive kMeans clustering by employing a client-side knowledge-cache. This knowledge-cache is succinct and significantly reduces the amount of remote I/O needed during execution. Furthermore, it permits the re-use of computation, both within and between executions of the kMeans queries.

#index 1663662
#* On the lower bound of reconstruction error for spectral filtering based privacy preserving data mining
#@ Songtao Guo;Xintao Wu;Yingjiu Li
#t 2006
#c 21
#% 300184
#% 333876
#% 727904
#% 810010
#% 874169
#! Additive Randomization has been a primary tool to hide sensitive private information during privacy preserving data mining. The previous work based on Spectral Filtering empirically showed that individual data can be separated from the perturbed one and as a result privacy can be seriously compromised. Our previous work initiated the theoretical study on how the estimation error varies with the noise and gave an upper bound for the Frobenius norm of reconstruction error using matrix perturbation theory. In this paper, we propose one Singular Value Decomposition (SVD) based reconstruction method and derive a lower bound for the reconstruction error. We then prove the equivalence between the Spectral Filtering based approach and the proposed SVD approach and as a result the achieved lower bound can also be considered as the lower bound of the Spectral Filtering based approach.

#index 1663663
#* Frequent pattern discovery without binarization: mining attribute profiles
#@ Attila Gyenesei;Ralph Schlapbach;Etzard Stolte;Ulrich Wagner
#t 2006
#c 21
#% 210160
#% 227917
#% 248791
#% 300120
#% 320944
#% 420062
#% 443350
#% 481290
#% 832921
#% 905832
#% 1707758
#! Frequent pattern discovery has become a popular solution to many scientific and industrial problems in a range of different datasets. Traditional algorithms, developed for binary (or Boolean) attributes, can be applied to such data with a prerequisite of transforming non-binary (continuous or categorical) attribute domains into binary ones. As a consequence of this binarization, the discovered patterns no longer reflect the associations between attributes but the relations between their binned independent values, and thus, interactions between the original attributes may be lost. In this paper we propose to overcome this limitation by introducing the concept of mining frequent attribute profiles that describes the relationships between the original attributes. By this concept, previously hidden interactions can be discovered and redundant patterns that are identified by traditional methods are eliminated. A novel algorithm, called MAP, has been developed for mining attribute profiles that can be potentially applied to diverse data domains. The effectiveness of the proposed method is shown by using gene expression or microarray data.

#index 1663664
#* Efficient name disambiguation for large-scale databases
#@ Jian Huang;Seyda Ertekin;C. Lee Giles
#t 2006
#c 21
#% 190581
#% 273890
#% 310516
#% 466419
#% 614036
#% 760866
#% 788107
#% 809459
#% 819552
#% 855094
#% 870896
#% 916781
#! Name disambiguation can occur when one is seeking a list of publications of an author who has used different name variations and when there are multiple other authors with the same name. We present an efficient integrative framework for solving the name disambiguation problem: a blocking method retrieves candidate classes of authors with similar names and a clustering method, DBSCAN, clusters papers by author. The distance metric between papers used in DBSCAN is calculated by an online active selection support vector machine algorithm (LASVM), yielding a simpler model, lower test errors and faster prediction time than a standard SVM. We prove that by recasting transitivity as density reachability in DBSCAN, transitivity is guaranteed for core points. For evaluation, we manually annotated 3,355 papers yielding 490 authors and achieved 90.6% pairwise-F1. For scalability, authors in the entire CiteSeer dataset, over 700,000 papers, were readily disambiguated.

#index 1663665
#* Adaptive segmentation-based symbolic representations of time series for better modeling and lower bounding distance measures
#@ Bernard Hugueney
#t 2006
#c 21
#% 43464
#% 333941
#% 662750
#! Time series data-mining algorithms usually scale poorly with regard to dimensionality. Symbolic representations have proven to be a very effective way to reduce the dimensionality of time series even using simple aggregations over episodes of the same length and a fixed set of symbols. However, computing adaptive symbolic representations would enable more accurate representations of the dataset without compromising the dimensionality reduction. Therefore we propose a new generic framework to compute adaptive Segmentation Based Symbolic Representations (SBSR) of time series. SBSR can be applied to any model but we focus on piecewise constant models (SBSRL0) which are the most commonly used. SBSR are built by computing both the episode boundaries and the symbolic alphabet in order to minimize information loss of the resulting symbolic representation. We also propose a new distance measure for SBSRL0 tightly lower bounding the euclidean distance measure.

#index 1663666
#* A feature generation algorithm for sequences with application to splice-site prediction
#@ Rezarta Islamaj;Lise Getoor;W. John Wilbur
#t 2006
#c 21
#% 243727
#% 420507
#% 451154
#% 465754
#% 833462
#! In this paper we present a new approach to feature selection for sequence data. We identify general feature categories and give construction algorithms for each of them. We show how they can be integrated in a system that tightly couples feature construction and feature selection. This integrated process, which we refer to as feature generation, allows us to systematically search a large space of potential features. We demonstrate the effectiveness of our approach for an important component of the gene finding problem, splice-site prediction. We show that predictive models built using our feature generation algorithm achieve a significant improvement in accuracy over existing, state-of-the-art approaches.

#index 1663667
#* Discovering image-text associations for cross-media web information fusion
#@ Tao Jiang;Ah-Hwee Tan
#t 2006
#c 21
#% 218989
#% 853799
#! The diverse and distributed nature of the information published on the World Wide Web has made it difficult to collate and track information related to specific topics. Whereas most existing work on web information fusion has focused on multiple document summarization, this paper presents a novel approach for discovering associations between images and text segments, which subsequently can be used to support cross-media web content summarization. Specifically, we employ a similarity-based multilingual retrieval model and adopt a vague transformation technique for measuring the information similarity between visual features and textual features. The experimental results on a terrorist domain document set suggest that combining visual and textual features provides a promising approach to image and text fusion.

#index 1663668
#* Mining sequences of temporal intervals
#@ Steffen Kempe;Jochen Hipp
#t 2006
#c 21
#% 319244
#% 420063
#% 463903
#% 481290
#% 844326
#! Recently a new type of data source came into the focus of knowledge discovery from temporal data: interval sequences. In contrast to event sequences, interval sequences contain labeled events with a temporal extension. However, existing algorithms for mining patterns from interval sequences proved to be far from satisfying our needs. In brief, we missed an approach that at the same time: defines support as the number of pattern instances, allows input data that consists of more than one sequence, implements time constraints on a pattern instance, and counts multiple instances of a pattern within one interval sequence. In this paper we propose a new support definition which incorporates these properties. We also describe an algorithm that employs the new support definition and demonstrate its performance on field data from the automotive business.

#index 1663669
#* Pattern teams
#@ Arno J. Knobbe;Eric K. Y. Ho
#t 2006
#c 21
#% 458307
#% 722920
#% 722929
#% 799042
#% 823356
#% 881479
#! Pattern discovery algorithms typically produce many interesting patterns. In most cases, patterns are reported based on their individual merits, and little attention is given to the interestingness of a pattern in the context of other patterns reported. In this paper, we propose filtering the returned set of patterns based on a number of quality measures for pattern sets. We refer to a small subset of patterns that optimises such a measure as a pattern team. A number of quality measures, both supervised and unsupervised, is proposed. We analyse to what extent each of the measures captures a number of ‘intuitions' users may have concerning effective and informative pattern teams. Such intuitions involve qualities such as independence of patterns, low overlap, and combined predictiveness.

#index 1663670
#* Compression picks item sets that matter
#@ Matthijs van Leeuwen;Jilles Vreeken;Arno Siebes
#t 2006
#c 21
#% 136350
#% 152934
#% 248791
#% 280439
#% 458257
#% 496966
#% 926881
#! Finding a comprehensive set of patterns that truly captures the characteristics of a database is a complicated matter. Frequent item set mining attempts this, but low support levels often result in exorbitant amounts of item sets. Recently we showed that by using MDL we are able to select a small number of item sets that compress the data well [11]. Here we show that this small set is a good approximation of the underlying data distribution. Using the small set in a MDL-based classifier leads to performance on par with well-known rule-induction and association-rule based methods. Advantages are that no parameters need to be set manually and only very few item sets are used. The classification scores indicate that selecting item sets through compression is an elegant way of mining interesting patterns that can subsequently find use in many applications.

#index 1663671
#* Discovering overlapping communities of named entities
#@ Xin Li;Bing Liu;Philip S. Yu
#t 2006
#c 21
#% 268079
#% 282905
#% 343768
#% 438553
#% 504443
#% 578775
#% 756821
#% 811281
#% 938705
#% 1272053
#! Although community discovery based on social network analysis has been studied extensively in the Web hyperlink environment, limited research has been done in the case of named entities in text documents. The co-occurrence of entities in documents usually implies some connections among them. Investigating such connections can reveal important patterns. In this paper, we mine communities among named entities in Web documents and text corpus. Most existing works on community discovery generate a partition of the entity network, assuming each entity belongs to one community. However, in the scenario of named entities, an entity may participate in several communities. For example, a person is in the communities of his/her family, colleagues, and friends. In this paper, we propose a novel technique to mine overlapping communities of named entities. This technique is based on triangle formation, expansion, and clustering with content similarity. Our experimental results show that the proposed technique is highly effective.

#index 1663672
#* Closed non-derivable itemsets
#@ Juho Muhonen;Hannu Toivonen
#t 2006
#c 21
#% 152934
#% 464873
#% 478770
#% 1742005
#! Itemset mining typically results in large amounts of redundant itemsets. Several approaches such as closed itemsets, non-derivable itemsets and generators have been suggested for losslessly reducing the amount of itemsets. We propose a new pruning method based on combining techniques for closed and non-derivable itemsets that allows further reductions of itemsets. This reduction is done without loss of information, that is, the complete collection of frequent itemsets can still be derived from the collection of closed non-derivable itemsets. The number of closed non-derivable itemsets is bound both by the number of closed and the number of non-derivable itemsets, and never exceeds the smaller of these. Our experiments show that the reduction is significant in some datasets.

#index 1663673
#* Learning a distance metric for object identification without human supervision
#@ Satoshi Oyama;Katsumi Tanaka
#t 2006
#c 21
#% 36672
#% 209961
#% 269217
#% 302390
#% 387427
#% 393059
#% 729913
#% 770798
#% 855094
#! A method is described for learning a distance metric for use in object identification that does not require human supervision. It is based on two assumptions. One is that pairs of different names refer to different objects. The other is that names are arbitrary. These two assumptions justify using pairs of data items for objects with different names as “cannot-be-linked” example pairs for learning a distance metric for use in clustering ambiguous names. The metric learning is formulated using only dissimilar example pairs as a convex quadratic programming problem that can be solved much faster than a semi-definite programming problem, which generally must be solved to learn a distance metric matrix. Experiments on author identification using a bibliographic database showed that the learned metric improves identification F-measure.

#index 1663674
#* Towards association rules with hidden variables
#@ Ricardo Silva;Richard Scheines
#t 2006
#c 21
#% 420110
#% 788043
#% 859292
#% 961141
#! The mining of association rules can provide relevant and novel information to the data analyst. However, current techniques do not take into account that the observed associations may arise from variables that are unrecorded in the database. For instance, the pattern of answers in a large marketing survey might be better explained by a few latent traits of the population than by direct association among measured items. Techniques for mining association rules with hidden variables are still largely unexplored. This paper provides a sound methodology for finding association rules of the type H →A1, ..., Ak, where H is a hidden variable inferred to exist by making suitable assumptions and A1, ..., Ak are discrete binary or ordinal variables in the database.

#index 1663675
#* A data mining approach to the joint evaluation of field and manufacturing data in automotive industry
#@ Christian Manuel Strobel;Tomas Hrycej
#t 2006
#c 21
#% 227917
#% 316709
#% 462238
#% 481290
#% 858649
#! The manufacturing quality can be evaluated only by considering the failure behavior of the product in the field. When relating manufacturing events to failure events, the main challenge is to master the huge number of combinations of both event types, of which each is only covered by a small number of occurrences. Additionally, this leads to the problem of selection of interesting findings – the appropriateness of the selection criterion for consequent decision making is a critical point. Another challenge is the necessity of mapping the process of manufacturing tests to a vector of variables characterizing the manufacturing process. The solution presented, focuses on correct rule generation and selection in the case of combinations with low coverage. Therefore statistical and decision theory approaches were used. The multiple hypothesis aspect of the rule set has also been considered. The application field was quality control of electronic units in automotive assembly, with thousands of variables observed.

#index 1663676
#* Incremental aspect models for mining document streams
#@ Arun C. Surendran;Suvrit Sra
#t 2006
#c 21
#% 290830
#% 329569
#% 340147
#% 340910
#% 342621
#% 448195
#% 763708
#% 769897
#% 823344
#! In this paper we introduce a novel approach for incrementally building aspect models, and use it to dynamically discover underlying themes from document streams. Using the new approach we present an application which we call “query-line tracking” i.e., we automatically discover and summarize different themes or stories that appear over time, and that relate to a particular query. We present evaluation on news corpora to demonstrate the strength of our method for both query-line tracking, online indexing and clustering.

#index 1663677
#* Learning approximate MRFs from large transaction data
#@ Chao Wang;Srinivasan Parthasarathy
#t 2006
#c 21
#% 451
#% 252472
#% 258598
#% 303620
#% 333946
#% 333986
#% 481290
#% 727667
#% 770828
#% 1650569
#! In this paper we consider the problem of learning approximate Markov Random Fields (MRFs) from large transaction data. We rely on frequent itemsets to learn MRFs on the data. Since learning exact large MRFs is generally intractable, we resort to learning approximate MRFs. Our proposed modeling approach first employs graph partitioning to cluster variables into balanced disjoint partitions, and then augments important interactions across partitions to capture interdependencies across them. A novel treewidth based augmentation scheme is proposed to boost performance. We learn an exact local MRF for each partition and then combine all the local MRFs together to derive a global model of the data. A greedy approximate inference scheme is developed on this global model. We demonstrate the use of the learned MRFs on the selectivity estimation problem. Empirical evaluation on real datasets demonstrates the advantage of our approach over extant solutions.

#index 1663678
#* Similarity search for multi-dimensional NMR-Spectra of natural products
#@ Karina Wolfram;Andrea Porzel;Alexander Hinneburg
#t 2006
#c 21
#% 280819
#% 722904
#! Searching and mining nuclear magnetic resonance (NMR)-spectra of naturally occurring products is an important task to investigate new potentially useful chemical compounds. We develop a set-based similarity function, which, however, does not sufficiently capture more abstract aspects of similarity. NMR-spectra are like documents, but consists of continuous multi-dimensional points instead of words. Probabilistic semantic indexing (PLSI) is an retrieval method, which learns hidden topics. We develop several mappings from continuous NMR-spectra to discrete text-like data. The new mappings include redundancies into the discrete data, which proofs helpful for the PLSI-model used afterwards. Our experiments show that PLSI, which is designed for text data created by humans, can effectively handle the mapped NMR-data originating from natural products. Additionally, PLSI combined with the new mappings is able to find meaningful ”topics” in the NMR-data.

#index 1673547
#* Proceedings of the 9th European conference on Principles and Practice of Knowledge Discovery in Databases
#@ Alípio Mário Jorge;Luís Torgo;Pavel Brazdil;Rui Camacho;João Gama
#t 2005
#c 21

#index 1673548
#* Data analysis in the life sciences — sparking ideas —
#@ Michael R. Berthold
#t 2005
#c 21
#% 998549
#% 1346862
#! Data from various areas of Life Sciences have increasingly caught the attention of data mining and machine learning researchers. Not only is the amount of data available mind-boggling but the diverse and heterogenous nature of the information is far beyond any other data analysis problem so far. In sharp contrast to classical data analysis scenarios, the life science area poses challenges of a rather different nature for mainly two reasons. Firstly, the available data stems from heterogenous information sources of varying degrees of reliability and quality and is, without the interactive, constant interpretation of a domain expert, not useful. Furthermore, predictive models are of only marginal interest to those users – instead they hope for new insights into a complex, biological system that is only partially represented within that data anyway. In this scenario, the data serves mainly to create new insights and generate new ideas that can be tested. Secondly, the notion of feature space and the accompanying measures of similarity cannot be taken for granted. Similarity measures become context dependent and it is often the case that within one analysis task several different ways of describing the objects of interest or measuring similarity between them matter. Some more recently published work in the data analysis area has started to address some of these issues. For example, data analysis in parallel universes[1], that is, the detection of patterns of interest in various different descriptor spaces at the same time, and mining of frequent, discriminative fragments in large, molecular data bases[2]. In both cases, sheer numerical performance is not the focus; it is rather the discovery of interpretable pieces of evidence that lights up new ideas in the users mind. Future work in data analysis in the life sciences needs to keep this in mind: the goal is to trigger new ideas and stimulate interesting associations.

#index 1673549
#* Machine learning for natural language processing (and vice versa?)
#@ Claire Cardie
#t 2005
#c 21
#! Over the past 10-15 years, the influence of methods from machine learning has transformed the way that research is done in the field of natural language processing. This talk will begin by covering the history of this transformation. In particular, learning methods have proved successful in producing stand-alone text-processing components to handle a number of linguistic tasks. Moreover, these components can be combined to produce systems that exhibit shallow text-understanding capabilities: they can, for example, extract key facts from unrestricted documents in limited domains or find answers to general-purpose questions from open-domain document collections. I will briefly describe the state of the art for these practical text-processing applications, focusing on the important role that machine learning methods have played in their development. The second part of the talk will explore the role that natural language processing might play in machine learning research. Here, I will explain the kinds of text-based features that are relatively easy to incorporate into machine learning data sets. In addition, I’ll outline some problems from natural language processing that require, or could at least benefit from, new machine learning algorithms.

#index 1673550
#* Statistical relational learning: an inductive logic programming perspective
#@ Luc De Raedt
#t 2005
#c 21
#% 147677
#% 243701
#% 456659
#% 496116
#% 550743
#% 550745
#% 577225
#% 676365
#% 731606
#% 1269477
#% 1269484
#% 1272388
#% 1650280
#! In the past few years there has been a lot of work lying at the intersection of probability theory, logic programming and machine learning [14,18,13,9,6,1,11]. This work is known under the names of statistical relational learning [7,5], probabilistic logic learning [4], or probabilistic inductive logic programming. Whereas most of the existing works have started from a probabilistic learning perspective and extended probabilistic formalisms with relational aspects, I shall take a different perspective, in which I shall start from inductive logic programming and study how inductive logic programming formalisms, settings and techniques can be extended to deal with probabilistic issues. This tradition has already contributed a rich variety of valuable formalisms and techniques, including probabilistic Horn abduction by David Poole, PRISMs by Sato, stochastic logic programs by Muggleton[13] and Cussens[2], Bayesian logic programs[10,8] by Kersting and De Raedt, and Logical Hidden Markov Models[11]. The main contribution of this talk is the introduction of three probabilistic inductive logic programming settings which are derived from the learning from entailment, from interpretations and from proofs settings of the field of inductive logic programming [3]. Each of these settings contributes different notions of probabilistic logic representations, examples and probability distributions. The first setting, probabilistic learning from entailment, is incorporated in the wellknown PRISM system [19] and Cussens’s Failure Adjusted Maximisation approach to parameter estimation in stochastic logic programs [2]. A novel system that was recently developed and that .ts this paradigm is the nFOIL system [12]. It combines key principles of the well-known inductive logic programming system FOIL [15] with the naïve Bayes’ appraoch. In probabilistic learning from entailment, examples are ground facts that should be probabilistically entailed by the target logic program. The second setting, probabilistic learning from interpretations, is incorporated in Bayesian logic programs [10,8], which integrate Bayesian networks with logic programs. This setting is also adopted by [6]. Examples in this setting are Herbrand interpretations that should be a probabilistic model for the target theory. The third setting, learning from proofs [17], is novel. It is motivated by the learning of stochastic context free grammars from tree banks. In this setting, examples are proof trees that should be probabilistically provable from the unknown stochastic logic programs. The sketched settings (and their instances presented) are by no means the only possible settings for probabilisticinductive logic programming, but still – I hope – provide useful insights into the state-of-the-art of this exciting field. For a full survey of statistical relational learning or probabilistic inductive logic programming, the author would like to refer to [4], and for more details on the probabilistic inductive logic programming settings to [16], where a longer and earlier version of this contribution can be found.

#index 1673551
#* Recent advances in mining time series data
#@ Eamonn Keogh
#t 2005
#c 21
#% 577221
#% 727900
#% 769896
#% 993965
#! Much of the world’s supply of data is in the form of time series. Furthermore, as we shall see, many types of data can be meaningfully converted into ”time series”, including text, DNA, video, images etc. The last decade has seen an explosion of interest in mining time series data from the academic community. There has been significant work on algorithms to classify, cluster, segment, index, discover rules, visualize, and detect anomalies/novelties in time series. In this talk I will summarize the latest advances in mining time series data, including: – New representations of time series data. – New algorithms/definitions. – The migration from static problems to online problems. – New areas and applications of time series data mining. I will end the talk with a discussion of “what’s left to do” in time series data mining.

#index 1673552
#* Focus the mining beacon: lessons and challenges from the world of e-commerce
#@ Ron Kohavi
#t 2005
#c 21
#! Electronic Commerce is now entering its second decade, with Amazon.com and eBay now in existence for ten years. With massive amounts of data, an actionable domain, and measurable ROI, multiple companies use data mining and knowledge discovery to understand their customers and improve interactions. We present important lessons and challenges using e-commerce examples across two dimensions: (i) business-level to technical, and (ii) the mining lifecycle from data collection, data warehouse construction, to discovery and deployment. Many of the lessons and challenges are applicable to domains outside e-commerce.

#index 1673553
#* Data streams and data synopses for massive data sets
#@ Yossi Matias
#t 2005
#c 21
#% 278835
#% 282942
#% 341100
#% 378388
#! With the proliferation of data intensive applications, it has become necessary to develop new techniques to handle massive data sets. Traditional algorithmic techniques and data structures are not always suitable to handle the amount of data that is required and the fact that the data often streams by and cannot be accessed again. A field of research established over the past decade is that of handling massive data sets using data synopses, and developing algorithmic techniques for data stream models. We will discuss some of the research work that has been done in the field, and provide a decades’ perspective to data synopses and data streams.

#index 1673554
#* k-anonymous patterns
#@ Maurizio Atzori;Francesco Bonchi;Fosca Giannotti;Dino Pedreschi
#t 2005
#c 21
#% 152934
#% 300184
#% 333876
#% 341700
#% 464873
#% 478770
#% 481290
#% 576761
#% 576762
#% 729933
#% 742048
#% 747134
#% 769943
#! It is generally believed that data mining results do not violate the anonymity of the individuals recorded in the source database. In fact, data mining models and patterns, in order to ensure a required statistical significance, represent a large number of individuals and thus conceal individual identities: this is the case of the minimum support threshold in association rule mining. In this paper we show that this belief is ill-founded. By shifting the concept of k-anonymity from data to patterns, we formally characterize the notion of a threat to anonymity in the context of pattern discovery, and provide a methodology to efficiently and effectively identify all possible such threats that might arise from the disclosure of a set of extracted patterns.

#index 1673555
#* Interestingness is not a dichotomy: introducing softness in constrained pattern mining
#@ Stefano Bistarelli;Francesco Bonchi
#t 2005
#c 21
#% 126386
#% 230551
#% 248785
#% 273899
#% 280485
#% 310558
#% 342604
#% 392618
#% 438134
#% 447607
#% 481290
#% 577214
#% 577215
#% 629611
#% 727876
#% 757932
#% 785336
#% 1707794
#! The paradigm of pattern discovery based on constraints was introduced with the aim of providing to the user a tool to drive the discovery process towards potentially interesting patterns, with the positive side effect of achieving a more efficient computation. So far the research on this paradigm has mainly focussed on the latter aspect: the development of efficient algorithms for the evaluation of constraint-based mining queries. Due to the lack of research on methodological issues, the constraint-based pattern mining framework still suffers from many problems which limit its practical relevance. As a solution, in this paper we introduce the new paradigm of pattern discovery based on Soft Constraints. Albeit simple, the proposed paradigm overcomes all the major methodological drawbacks of the classical constraint-based paradigm, representing an important step further towards practical pattern discovery.

#index 1673556
#* Generating dynamic higher-order markov models in web usage mining
#@ José Borges;Mark Levene
#t 2005
#c 21
#% 268184
#% 309777
#% 312874
#% 349430
#% 410855
#% 452396
#% 552186
#% 571605
#% 739634
#% 755395
#% 963898
#! Markov models have been widely used for modelling users’ web navigation behaviour. In previous work we have presented a dynamic clustering-based Markov model that accurately represents second-order transition probabilities given by a collection of navigation sessions. Herein, we propose a generalisation of the method that takes into account higher-order conditional probabilities. The method makes use of the state cloning concept together with a clustering technique to separate the navigation paths that reveal differences in the conditional probabilities. We report on experiments conducted with three real world data sets. The results show that some pages require a long history to understand the users choice of link, while others require only a short history. We also show that the number of additional states induced by the method can be controlled through a probability threshold parameter.

#index 1673557
#* Tree2: decision trees for tree structured data
#@ Björn Bringmann;Albrecht Zimmermann
#t 2005
#c 21
#% 43862
#% 136350
#% 299985
#% 342604
#% 449508
#% 449588
#% 729941
#% 771944
#% 832870
#% 925102
#% 1712907
#! We present Tree2, a new approach to structural classification. This integrated approach induces decision trees that test for pattern occurrence in the inner nodes. It combines state-of-the-art tree mining with sophisticated pruning techniques to find the most discriminative pattern in each node. In contrast to existing methods, Tree2 uses no heuristics and only a single, statistically well founded parameter has to be chosen by the user. The experiments show that Tree2 classifiers achieve good accuracies while the induced models are smaller than those of existing approaches, facilitating better comprehensibility.

#index 1673558
#* Agglomerative hierarchical clustering with constraints: theoretical and empirical results
#@ Ian Davidson;S. S. Ravi
#t 2005
#c 21
#% 408396
#% 464608
#% 464631
#% 466890
#% 502122
#% 600496
#% 664823
#% 806594
#% 1707824
#! We explore the use of instance and cluster-level constraints with agglomerative hierarchical clustering. Though previous work has illustrated the benefits of using constraints for non-hierarchical clustering, their application to hierarchical clustering is not straight-forward for two primary reasons. First, some constraint combinations make the feasibility problem (Does there exist a single feasible solution?) NP-complete. Second, some constraint combinations when used with traditional agglomerative algorithms can cause the dendrogram to stop prematurely in a dead-end solution even though there exist other feasible solutions with a significantly smaller number of clusters. When constraints lead to efficiently solvable feasibility problems and standard agglomerative algorithms do not give rise to dead-end solutions, we empirically illustrate the benefits of using constraints to improve cluster purity and average distortion. Furthermore, we introduce the new γ constraint and use it in conjunction with the triangle inequality to considerably improve the efficiency of agglomerative clustering.

#index 1673559
#* Cluster aggregate inequality and multi-level hierarchical clustering
#@ Chris Ding;Xiaofeng He
#t 2005
#c 21
#% 18713
#% 36672
#% 210173
#% 296738
#% 313959
#% 438137
#% 466640
#% 729437
#% 729940
#! We show that (1) in hierarchical clustering, many linkage functions satisfy a cluster aggregate inequality, which allows an exact O(N2) multi-level (using mutual nearest neighbor) implementation of the standard O(N3) agglomerative hierarchical clustering algorithm. (2) a desirable close friends cohesion of clusters can be translated into kNN consistency which is guaranteed by the multi-level algorithm; (3) For similarity-based linkage functions, the multi-level algorithm is naturally implemented as graph contraction. The effectiveness of our algorithms is demonstrated on a number of real life applications.

#index 1673560
#* Ensembles of balanced nested dichotomies for multi-class problems
#@ Lin Dong;Eibe Frank;Stefan Kramer
#t 2005
#c 21
#% 136350
#% 290482
#% 312727
#% 580511
#% 722807
#% 770785
#% 1272365
#! A system of nested dichotomies is a hierarchical decomposition of a multi-class problem with c classes into c–1 two-class problems and can be represented as a tree structure. Ensembles of randomly-generated nested dichotomies have proven to be an effective approach to multi-class learning problems [1]. However, sampling trees by giving each tree equal probability means that the depth of a tree is limited only by the number of classes, and very unbalanced trees can negatively affect runtime. In this paper we investigate two approaches to building balanced nested dichotomies—class-balanced nested dichotomies and data-balanced nested dichotomies—and evaluate them in the same ensemble setting. Using C4.5 decision trees as the base models, we show that both approaches can reduce runtime with little or no effect on accuracy, especially on problems with many classes. We also investigate the effect of caching models when building ensembles of nested dichotomies.

#index 1673561
#* Protein sequence pattern mining with constraints
#@ Pedro Gabriel Ferreira;Paulo J. Azevedo
#t 2005
#c 21
#% 316552
#% 329537
#% 459006
#% 464996
#% 577256
#! Considering the characteristics of biological sequence databases, which typically have a small alphabet, a very long length and a relative small size (several hundreds of sequences), we propose a new sequence mining algorithm (gIL). gIL was developed for linear sequence pattern mining and results from the combination of some of the most efficient techniques used in sequence and itemset mining. The algorithm exhibits a high adaptability, yielding a smooth and direct introduction of various types of features into the mining process, namely the extraction of rigid and arbitrary gap patterns. Both breadth or a depth first traversal are possible. The experimental evaluation, in synthetic and real life protein databases, has shown that our algorithm has superior performance to state-of-the art algorithms. The use of constraints has also proved to be a very useful tool to specify user interesting patterns.

#index 1673562
#* An adaptive nearest neighbor classification algorithm for data streams
#@ Yan-Nei Law;Carlo Zaniolo
#t 2005
#c 21
#% 234756
#% 248792
#% 249321
#% 303021
#% 310500
#% 316709
#% 321455
#% 342600
#% 342639
#% 378388
#% 415033
#% 444007
#% 479799
#% 566128
#% 578560
#% 729932
#! In this paper, we propose an incremental classification algorithm which uses a multi-resolution data representation to find adaptive nearest neighbors of a test point. The algorithm achieves excellent performance by using small classifier ensembles where approximation error bounds are guaranteed for each ensemble size. The very low update cost of our incremental classifier makes it highly suitable for data stream applications. Tests performed on both synthetic and real-life data indicate that our new classifier outperforms existing algorithms for data streams in terms of accuracy and computational costs.

#index 1673563
#* Support vector random fields for spatial classification
#@ Chi-Hoon Lee;Russell Greiner;Mark Schmidt
#t 2005
#c 21
#% 33917
#% 269217
#% 338741
#% 464434
#% 567560
#% 724344
#% 732265
#% 743284
#! In this paper we propose Support Vector Random Fields (SVRFs), an extension of Support Vector Machines (SVMs) that explicitly models spatial correlations in multi-dimensional data. SVRFs are derived as Conditional Random Fields that take advantage of the generalization properties of SVMs. We also propose improvements to computing posterior probability distributions from SVMs, and present a local-consistency potential measure that encourages spatial continuity. SVRFs can be efficiently trained, converge quickly during inference, and can be trivially augmented with kernel functions. SVRFs are more robust to class imbalance than Discriminative Random Fields (DRFs), and are more accurate near edges. Our results on synthetic data and a real-world tumor detection task show the superiority of SVRFs over both SVMs and DRFs.

#index 1673564
#* Realistic, mathematically tractable graph generation and evolution, using kronecker multiplication
#@ Jurij Leskovec;Deepayan Chakrabarti;Jon Kleinberg;Christos Faloutsos
#t 2005
#c 21
#% 283833
#% 309749
#% 323925
#% 342592
#% 479969
#% 577219
#% 771380
#% 823342
#% 1394202
#! How can we generate realistic graphs? In addition, how can we do so with a mathematically tractable model that makes it feasible to analyze their properties rigorously? Real graphs obey a long list of surprising properties: Heavy tails for the in- and out-degree distribution; heavy tails for the eigenvalues and eigenvectors; small diameters; and the recently discovered “Densification Power Law” (DPL). All published graph generators either fail to match several of the above properties, are very complicated to analyze mathematically, or both. Here we propose a graph generator that is mathematically tractable and matches this collection of properties. The main idea is to use a non-standard matrix operation, the Kronecker product, to generate graphs that we refer to as “Kronecker graphs”. We show that Kronecker graphs naturally obey all the above properties; in fact, we can rigorously prove that they do so. We also provide empirical evidence showing that they can mimic very well several real graphs.

#index 1673565
#* A correspondence between maximal complete bipartite subgraphs and closed patterns
#@ Jinyan Li;Haiquan Li;Donny Soh;Limsoon Wong
#t 2005
#c 21
#% 152934
#% 171557
#% 281214
#% 309749
#% 464873
#% 536291
#% 729933
#% 731608
#% 779960
#% 833028
#! For an undirected graph G without self-loop, we prove: (i) that the number of closed patterns in the adjacency matrix of G is even; (ii) that the number of the closed patterns is precisely double the number of maximal complete bipartite subgraphs of G; (iii) that for every maximal complete bipartite subgraph, there always exists a unique pair of closed patterns that matches the two vertex sets of the subgraph. Therefore, we can enumerate all maximal complete bipartite subgraphs by using efficient algorithms for mining closed patterns which have been extensively studied in the data mining field.

#index 1673566
#* Improving generalization by data categorization
#@ Ling Li;Amrit Pratap;Hsuan-Tien Lin;Yaser S. Abu-Mostafa
#t 2005
#c 21
#% 190581
#% 232118
#% 715988
#% 781774
#! In most of the learning algorithms, examples in the training set are treated equally. Some examples, however, carry more reliable or critical information about the target than the others, and some may carry wrong information. According to their intrinsic margin, examples can be grouped into three categories: typical, critical, and noisy. We propose three methods, namely the selection cost, SVM confidence margin, and AdaBoost data weight, to automatically group training examples into these three categories. Experimental results on artificial datasets show that, although the three methods have quite different nature, they give similar and reasonable categorization. Results with real-world datasets further demonstrate that treating the three data categories differently in learning can improve generalization.

#index 1673567
#* Mining model trees from spatial data
#@ Donato Malerba;Michelangelo Ceci;Annalisa Appice
#t 2005
#c 21
#% 68089
#% 392781
#% 410601
#% 478596
#% 478613
#% 712001
#% 744795
#% 998577
#% 1775152
#! Mining regression models from spatial data is a fundamental task in Spatial Data Mining. We propose a method, namely Mrs-SMOTI, that takes advantage from a tight-integration with spatial databases and mines regression models in form of trees in order to partition the sample space. The method is characterized by three aspects. First, it is able to capture both spatially global and local effects of explanatory attributes. Second, explanatory attributes that influence the response attribute do not necessarily come from a single layer. Third, the consideration that geometrical representation and relative positioning of spatial objects with respect to a reference system implicitly define both spatial relationships and properties. An application to real-world spatial data is reported.

#index 1673568
#* Word sense disambiguation for exploiting hierarchical thesauri in text classification
#@ Dimitrios Mavroeidis;George Tsatsaronis;Michalis Vazirgiannis;Martin Theobald;Gerhard Weikum
#t 2005
#c 21
#% 152968
#% 228088
#% 279755
#% 465914
#% 466101
#% 466408
#% 482925
#% 633682
#% 719299
#% 756938
#% 1275285
#% 1279327
#% 1674714
#! The introduction of hierarchical thesauri (HT) that contain significant semantic information, has led researchers to investigate their potential for improving performance of the text classification task, extending the traditional “bag of words” representation, incorporating syntactic and semantic relationships among words. In this paper we address this problem by proposing a Word Sense Disambiguation (WSD) approach based on the intuition that word proximity in the document implies proximity also in the HT graph. We argue that the high precision exhibited by our WSD algorithm in various humanly-disambiguated benchmark datasets, is appropriate for the classification task. Moreover, we define a semantic kernel, based on the general concept of GVSM kernels, that captures the semantic relations contained in the hierarchical thesaurus. Finally, we conduct experiments using various corpora achieving a systematic improvement in classification accuracy using the SVM algorithm, especially when the training set is small.

#index 1673569
#* Mining paraphrases from self-anchored web sentence fragments
#@ Marius Paşca
#t 2005
#c 21
#% 198058
#% 309127
#% 458630
#% 708948
#% 742092
#% 746866
#% 783484
#% 815799
#% 816156
#% 817605
#% 854933
#% 939699
#% 939725
#% 963669
#% 995474
#! Near-synonyms or paraphrases are beneficial in a variety of natural language and information retrieval applications, but so far their acquisition has been confined to clean, trustworthy collections of documents with explicit external attributes. When such attributes are available, such as similar time stamps associated to a pair of news articles, previous approaches rely on them as signals of potentially high content overlap between the articles, often embodied in sentences that are only slight, paraphrase-based variations of each other. This paper introduces a new unsupervised method for extracting paraphrases from an information source of completely different nature and scale, namely unstructured text across arbitrary Web textual documents. In this case, no useful external attributes are consistently available for all documents. Instead, the paper introduces linguistically-motivated text anchors, which are identified automatically within the documents. The anchors are instrumental in the derivation of paraphrases through lightweight pairwise alignment of Web sentence fragments. A large set of categorized names, acquired separately from Web documents, serves as a filtering mechanism for improving the quality of the paraphrases. A set of paraphrases extracted from about a billion Web documents is evaluated both manually and through its impact on a natural-language Web search application.

#index 1673570
#* M2SP: mining sequential patterns among several dimensions
#@ M. Plantevit;Y. W. Choong;A. Laurent;D. Laurent;M. Teisseire
#t 2005
#c 21
#% 1267
#% 36683
#% 273916
#% 342666
#% 459006
#% 463903
#% 477791
#% 789007
#! Mining sequential patterns aims at discovering correlations between events through time. However, even if many works have dealt with sequential pattern mining, none of them considers frequent sequential patterns involving several dimensions in the general case. In this paper, we propose a novel approach, called M2SP, to mine multidimensional sequential patterns. The main originality of our proposition is that we obtain not only intra-pattern sequences but also inter-pattern sequences. Moreover, we consider generalized multidimensional sequential patterns, called jokerized patterns, in which some of the dimension values may not be instanciated. Experiments on synthetic data are reported and show the scalability of our approach.

#index 1673571
#* A systematic comparison of feature-rich probabilistic classifiers for NER tasks
#@ Benjamin Rosenfeld;Moshe Fresko;Ronen Feldman
#t 2005
#c 21
#% 211044
#% 278107
#% 464434
#% 466892
#% 709765
#% 783553
#% 815178
#% 815860
#% 855112
#% 855114
#% 855119
#% 855123
#% 1414746
#! In the CoNLL 2003 NER shared task, more than two thirds of the submitted systems used the feature-rich representation of the task. Most of them used maximum entropy to combine the features together. Others used linear classifiers, such as SVM and RRM. Among all systems presented there, one of the MEMM-based classifiers took the second place, losing only to a committee of four different classifiers, one of which was ME-based and another RRM-based. The lone RRM was fourth, and CRF came in the middle of the pack. In this paper we shall demonstrate, by running the three algorithms upon the same tasks under exactly the same conditions that this ranking is due to feature selection and other causes and not due to the inherent qualities of the algorithms, which should be ranked otherwise.

#index 1673572
#* Knowledge discovery from user preferences in conversational recommendation
#@ Maria Salamó;James Reilly;Lorraine McGinty;Barry Smyth
#t 2005
#c 21
#% 418152
#% 428436
#% 428440
#% 445152
#% 490786
#% 1269443
#% 1279228
#% 1279229
#% 1289352
#% 1499534
#! Knowledge discovery for personalizing the product recommendation task is a major focus of research in the area of conversational recommender systems to increase efficiency and effectiveness. Conversational recommender systems guide users through a product space, alternatively making product suggestions and eliciting user feedback. Critiquing is a common and powerful form of feedback, where a user can express her feature preferences by applying a series of directional critiques over recommendations, instead of providing specific value preferences. For example, a user might ask for a ‘less expensive’ vacation in a travel recommender; thus ‘less expensive’ is a critique over the price feature. The expectation is that on each cycle, the system discovers more about the user’s soft product preferences from minimal information input. In this paper we describe three different strategies for knowledge discovery from user preferences that improve recommendation efficiency in a conversational system using critiquing. Moreover, we will demonstrate that while the strategies work well separately, their combined effort has the potential to considerably increase recommendation efficiency even further.

#index 1673573
#* Unsupervised discretization using tree-based density estimation
#@ Gabi Schmidberger;Eibe Frank
#t 2005
#c 21
#% 136350
#% 290482
#% 424809
#% 466234
#% 565247
#% 580511
#! This paper presents an unsupervised discretization method that performs density estimation for univariate data. The subintervals that the discretization produces can be used as the bins of a histogram. Histograms are a very simple and broadly understood means for displaying data, and our method automatically adapts bin widths to the data. It uses the log-likelihood as the scoring function to select cut points and the cross-validated log-likelihood to select the number of intervals. We compare this method with equal-width discretization where we also select the number of bins using the cross-validated log-likelihood and with equal-frequency discretization.

#index 1673574
#* Weighted average pointwise mutual information for feature selection in text categorization
#@ Karl-Michael Schneider
#t 2005
#c 21
#% 78171
#% 115608
#% 169719
#% 312861
#% 321635
#% 420054
#% 465754
#% 722934
#% 722935
#! Mutual information is a common feature score in feature selection for text categorization. Mutual information suffers from two theoretical problems: It assumes independent word variables, and longer documents are given higher weights in the estimation of the feature scores, which is in contrast to common evaluation measures that do not distinguish between long and short documents. We propose a variant of mutual information, called Weighted Average Pointwise Mutual Information (WAPMI) that avoids both problems. We provide theoretical as well as extensive empirical evidence in favor of WAPMI. Furthermore, we show that WAPMI has a nice property that other feature metrics lack, namely it allows to select the best feature set size automatically by maximizing an objective function, which can be done using a simple heuristic without resorting to costly methods like EM and model selection.

#index 1673575
#* Non-stationary environment compensation using sequential EM algorithm for robust speech recognition
#@ Haifeng Shen;Jun Guo;Gang Liu;Qunxia Li
#t 2005
#c 21
#% 968635
#% 1579411
#% 1710111
#! The paper presents a non-stationary environment compensation using sequential EM estimation for tracking the complicated environment. All of the noisy features used in the recognition system are effectively compensated. The speech corruption in the log domain such as the 24 log-filterbank coefficients and the log-energy feature can be modeled as a nonlinear model. For efficient estimating noise parameter using the subsequent sequential Expectation-Maximization (EM) algorithm, the nonlinear environment model is linearized by the truncated first-order vector Taylor series (VTS) approximation. Due to the cepstral features are nearly independence, we train the clean speech using cepstral features and the log-energy feature, and then obtain a diagonal Gaussian mixture model in the log domain by taking inverse discrete cosine transform (IDCT). The experiments are conducted on the large vocabulary continuous speech recognition (LVCSR) system. Results demonstrate that it achieves attractive improvements when compared with CMN (cepstral mean normalization) and the batch-EM based compensation approach.

#index 1673576
#* Hybrid cost-sensitive decision tree
#@ Shengli Sheng;Charles X. Ling
#t 2005
#c 21
#% 92554
#% 136350
#% 160852
#% 280437
#% 464639
#% 477640
#% 765519
#% 770791
#% 785338
#% 1272369
#% 1289281
#! Cost-sensitive decision tree and cost-sensitive naïve Bayes are both new cost-sensitive learning models proposed recently to minimize the total cost of test and misclassifications. Each of them has its advantages and disadvantages. In this paper, we propose a novel cost-sensitive learning model, a hybrid cost-sensitive decision tree, called DTNB, to reduce the minimum total cost, which integrates the advantages of cost-sensitive decision tree and of the cost-sensitive naïve Bayes together. We empirically evaluate it over various test strategies, and our experiments show that our DTNB outperforms cost-sensitive decision and the cost-sensitive naïve Bayes significantly in minimizing the total cost of tests and misclassification based on the same sequential test strategies, and single batch strategies.

#index 1673577
#* Characterization of novel HIV drug resistance mutations using clustering, multidimensional scaling and SVM-Based feature ranking
#@ Tobias Sing;Valentina Svicher;Niko Beerenwinkel;Francesca Ceccherini-Silberstein;Martin Däumer;Rolf Kaiser;Hauke Walter;Klaus Korn;Daniel Hoffmann;Mark Oette;Jürgen K. Rockstroh;Gert Fätkenheuer;Carlo-Federico Perno;Thomas Lengauer
#t 2005
#c 21
#% 425048
#% 1011582
#! We present a case study on the discovery of clinically relevant domain knowledge in the field of HIV drug resistance. Novel mutations in the HIV genome associated with treatment failure were identified by mining a relational clinical database. Hierarchical cluster analysis suggests that two of these mutations form a novel mutational complex, while all others are involved in known resistance-conferring evolutionary pathways. The clustering is shown to be highly stable in a bootstrap procedure. Multidimensional scaling in mutation space indicates that certain mutations can occur within multiple pathways. Feature ranking based on support vector machines and matched genotype-phenotype pairs comprehensively reproduces current domain knowledge. Moreover, it indicates a prominent role of novel mutations in determining phenotypic resistance and in resensitization effects. These effects may be exploited deliberately to reopen lost treatment options. Together, these findings provide valuable insight into the interpretation of genotypic resistance tests.

#index 1673578
#* Object identification with attribute-mediated dependences
#@ Parag Singla;Pedro Domingos
#t 2005
#c 21
#% 201889
#% 310516
#% 310533
#% 406493
#% 464434
#% 577238
#% 577247
#% 577263
#% 729913
#% 766199
#% 854636
#% 1650403
#! Object identification is the problem of determining whether different observations correspond to the same object. It occurs in a wide variety of fields, including vision, natural language, citation matching, and information integration. Traditionally, the problem is solved separately for each pair of observations, followed by transitive closure. We propose solving it collectively, performing simultaneous inference for all candidate match pairs, and allowing information to propagate from one candidate match to another via the attributes they have in common. Our formulation is based on conditional random fields, and allows an optimal solution to be found in polynomial time using a graph cut algorithm. Parameters are learned using a voted perceptron algorithm. Experiments on real and synthetic datasets show that this approach outperforms the standard one.

#index 1673579
#* Weka4WS: a WSRF-enabled weka toolkit for distributed data mining on grids
#@ Domenico Talia;Paolo Trunfio;Oreste Verta
#t 2005
#c 21
#% 290482
#% 427307
#% 577292
#% 721313
#% 821342
#% 843819
#% 1707958
#! This paper presents Weka4WS, a framework that extends the Weka toolkit for supporting distributed data mining on Grid environments. Weka4WS adopts the emerging Web Services Resource Framework (WSRF) for accessing remote data mining algorithms and managing distributed computations. The Weka4WS user interface is a modified Weka Explorer environment that supports the execution of both local and remote data mining tasks. On every computing node, a WSRF-compliant Web Service is used to expose all the data mining algorithms provided by the Weka library. The paper describes the design and the implementation of Weka4WS using a first release of the WSRF library. To evaluate the efficiency of the proposed system, a performance analysis of Weka4WS for executing distributed data mining tasks in different network scenarios is presented.

#index 1673580
#* Using inductive logic programming for predicting protein-protein interactions from multiple genomic data
#@ Tuan Nam Tran;Kenji Satou;Tu Bao Ho
#t 2005
#c 21
#% 290729
#! Protein-protein interactions play an important role in many fundamental biological processes. Computational approaches for predicting protein-protein interactions are essential to infer the functions of unknown proteins, and to validate the results obtained of experimental methods on protein-protein interactions. We have developed an approach using Inductive Logic Programming (ILP) for protein-protein interaction prediction by exploiting multiple genomic data including protein-protein interaction data, SWISS-PROT database, cell cycle expression data, Gene Ontology, and InterPro database. The proposed approach demonstrates a promising result in terms of obtaining high sensitivity/specificity and comprehensible rules that are useful for predicting novel protein-protein interactions. We have also applied our method to a number of protein-protein interaction data, demonstrating an improvement on the expression profile reliability (EPR) index.

#index 1673581
#* ISOLLE: locally linear embedding with geodesic distance
#@ Claudio Varini;Andreas Degenhard;Tim Nattkemper
#t 2005
#c 21
#% 577290
#% 578407
#% 723241
#% 823623
#% 1389005
#! Locally Linear Embedding (LLE) has recently been proposed as a method for dimensional reduction of high-dimensional nonlinear data sets. In LLE each data point is reconstructed from a linear combination of its n nearest neighbors, which are typically found using the Euclidean Distance. We propose an extension of LLE which consists in performing the search for the neighbors with respect to the geodesic distance (ISOLLE). In this study we show that the usage of this metric can lead to a more accurate preservation of the data structure. The proposed approach is validated on both real-world and synthetic data.

#index 1673582
#* Active sampling for knowledge discovery from biomedical data
#@ Sriharsha Veeramachaneni;Francesca Demichelis;Emanuele Olivetti;Paolo Avesani
#t 2005
#c 21
#% 116165
#% 132697
#% 466887
#% 629616
#% 1289273
#% 1673023
#% 1778796
#! We describe work aimed at cost-constrained knowledge discovery in the biomedical domain. To improve the diagnostic/prognostic models of cancer, new biomarkers are studied by researchers that might provide predictive information. Biological samples from monitored patients are selected and analyzed for determining the predictive power of the biomarker. During the process of biomarker evaluation, portions of the samples are consumed, limiting the number of measurements that can be performed. The biological samples obtained from carefully monitored patients, that are well annotated with pathological information, are a valuable resource that must be conserved. We present an active sampling algorithm derived from statistical first principles to incrementally choose the samples that are most informative in estimating the efficacy of the candidate biomarker. We provide empirical evidence on real biomedical data that our active sampling algorithm requires significantly fewer samples than random sampling to ascertain the efficacy of the new biomarker.

#index 1673583
#* A multi-metric index for euclidean and periodic matching
#@ Michail Vlachos;Zografoula Vagena;Vittorio Castelli;Philip S. Yu
#t 2005
#c 21
#% 480146
#% 571043
#% 577221
#% 729931
#% 765412
#% 769896
#! In many classification and data-mining applications the user does not know a priori which distance measure is the most appropriate for the task at hand without examining the produced results. Also, in several cases, different distance functions can provide diverse but equally intuitive results (according to the specific focus of each measure). In order to address the above issues, we elaborate on the construction of a hybrid index structure that supports query-by-example on shape and structural distance measures, therefore lending enhanced exploratory power to the system user. The shape distance measure that the index supports is the ubiquitous Euclidean distance, while the structural distance measure that we utilize is based on important periodic features extracted from a sequence. This new measure is phase-invariant and can provide flexible sequence characterizations, loosely resembling the Dynamic Time Warping, requiring only a fraction of the computational cost of the latter. Exploiting the relationship between the Euclidean and periodic measure, the new hybrid index allows for powerful query processing, enabling the efficient answering of kNN queries on both measures in a single index scan. We envision that our system can provide a basis for fast tracking of correlated time-delayed events, with applications in data visualization, financial market analysis, machine monitoring/diagnostics and gene expression data analysis.

#index 1673584
#* Fast burst correlation of financial data
#@ Michail Vlachos;Kun-Lung Wu;Shyh-Kwei Chen;Philip S. Yu
#t 2005
#c 21
#% 149237
#% 206915
#% 427199
#% 577220
#% 729943
#% 765412
#% 783479
#% 808522
#% 998570
#! We examine the problem of monitoring and identification of correlated burst patterns in multi-stream time series databases. Our methodology is comprised of two steps: a burst detection part, followed by a burst indexing step. The burst detection scheme imposes a variable threshold on the examined data and takes advantage of the skewed distribution that is typically encountered in many applications. The indexing step utilizes a memory-based interval index for effectively identifying the overlapping burst regions. While the focus of this work is on financial data, the proposed methods and data-structures can find applications for anomaly or novelty detection in telecommunications and network traffic, as well as in medical data. Finally, we manifest the real-time response of our burst indexing technique, and demonstrate the usefulness of the approach for correlating surprising volume trading events at the NY stock exchange.

#index 1673585
#* A propositional approach to textual case indexing
#@ Nirmalie Wiratunga;Rob Lothian;Sutanu Chakraborti;Ivan Koychev
#t 2005
#c 21
#% 126892
#% 232136
#% 248857
#% 275837
#% 342670
#% 344447
#% 453325
#% 465754
#% 466912
#% 490461
#% 492203
#% 799751
#% 1289282
#! Problem solving with experiences that are recorded in text form requires a mapping from text to structured cases, so that case comparison can provide informed feedback for reasoning. One of the challenges is to acquire an indexing vocabulary to describe cases. We explore the use of machine learning and statistical techniques to automate aspects of this acquisition task. A propositional semantic indexing tool, Psi, which forms its indexing vocabulary from new features extracted as logical combinations of existing keywords, is presented. We propose that such logical combinations correspond more closely to natural concepts and are more transparent than linear combinations. Experiments show Psi-derived case representations to have superior retrieval performance to the original keyword-based representations. Psi also has comparable performance to Latent Semantic Indexing, a popular dimensionality reduction technique for text, which unlike Psi generates linear combinations of the original features.

#index 1673586
#* A quantitative comparison of the subgraph miners mofa, gspan, FFSM, and gaston
#@ Marc Wörlein;Thorsten Meinl;Ingrid Fischer;Michael Philippsen
#t 2005
#c 21
#% 152934
#% 466644
#% 478274
#% 629603
#% 629708
#% 727845
#% 729938
#% 731608
#% 769951
#% 998549
#% 1268739
#% 1273674
#! Several new miners for frequent subgraphs have been published recently. Whereas new approaches are presented in detail, the quantitative evaluations are often of limited value: only the performance on a small set of graph databases is discussed and the new algorithm is often only compared to a single competitor based on an executable. It remains unclear, how the algorithms work on bigger/other graph databases and which of their distinctive features is best suited for which database. We have re-implemented the subgraph miners MoFa, gSpan, FFSM, and Gaston within a common code base and with the same level of programming expertise and optimization effort. This paper presents the results of a comparative benchmarking that ran the algorithms on a comprehensive set of graph databases.

#index 1673587
#* Efficient classification from multiple heterogeneous databases
#@ Xiaoxin Yin;Jiawei Han
#t 2005
#c 21
#% 91872
#% 397369
#% 443085
#% 458178
#% 458257
#% 512307
#% 572314
#% 577289
#% 729930
#% 745491
#% 765433
#% 772829
#% 1290272
#! With the fast expansion of computer networks, it is inevitable to study data mining on heterogeneous databases. In this paper we propose MDBM, an accurate and efficient approach for classification on multiple heterogeneous databases. We propose a regression-based method for predicting the usefulness of inter-database links that serve as bridges for information transfer, because such links are automatically detected and may or may not be useful or even valid. Because of the high cost of inter-database communication, MDBM employs a new strategy for cross-database classification, which finds and performs actions with high benefit-to-cost ratios. The experiments show that MDBM achieves high accuracy in cross-database classification, with much higher efficiency than previous approaches.

#index 1673588
#* A probabilistic clustering-projection model for discrete data
#@ Shipeng Yu;Kai Yu;Volker Tresp;Hans-Peter Kriegel
#t 2005
#c 21
#% 280819
#% 303620
#% 342621
#% 361100
#% 629648
#% 643008
#% 668807
#% 722904
#% 766434
#! For discrete co-occurrence data like documents and words, calculating optimal projections and clustering are two different but related tasks. The goal of projection is to find a low-dimensional latent space for words, and clustering aims at grouping documents based on their feature representations. In general projection and clustering are studied independently, but they both represent the intrinsic structure of data and should reinforce each other. In this paper we introduce a probabilistic clustering-projection (PCP) model for discrete data, where they are both represented in a unified framework. Clustering is seen to be performed in the projected space, and projection explicitly considers clustering structure. Iterating the two operations turns out to be exactly the variational EM algorithm under Bayesian model inference, and thus is guaranteed to improve the data likelihood. The model is evaluated on two text data sets, both showing very encouraging results.

#index 1673589
#* Collaborative filtering on data streams
#@ Jorge Mario Barajas;Xue Li
#t 2005
#c 21
#% 124010
#% 220706
#% 266281
#% 310500
#% 330687
#% 447948
#% 465906
#% 643007
#% 737417
#% 1650569
#% 1707764
#! Collaborate Filtering is one of the most popular recommendation algorithms. Most Collaborative Filtering algorithms work with a static set of data. This paper introduces a novel approach to providing recommendations using Collaborative Filtering when user rating is received over an incoming data stream. In an incoming stream there are massive amounts of data arriving rapidly making it impossible to save all the records for later analysis. By dynamically building a decision tree for every item as data arrive, the incoming data stream is used effectively although an inevitable trade off between accuracy and amount of memory used is introduced. By adding a simple personalization step using a hierarchy of the items, it is possible to improve the predicted ratings made by each decision tree and generate recommendations in real-time. Empirical studies with the dynamically built decision trees show that the personalization step improves the overall predicted accuracy.

#index 1673590
#* The relation of closed itemset mining, complete pruning strategies and item ordering in apriori-based FIM algorithms
#@ Ferenc Bodon;Lars Schmidt-Thieme
#t 2005
#c 21
#% 300120
#% 481290
#% 1130630
#! In this paper we investigate the relationship between closed itemset mining, the complete pruning technique and item ordering in the Apriori algorithm. We claim, that when proper item order is used, complete pruning does not necessarily speed up Apriori, and in databases with certain characteristics, pruning increases run time significantly. We also show that if complete pruning is applied, then an intersection-based technique not only results in a faster algorithm, but we get free closed-itemset selection concerning both memory consumption and run-time.

#index 1673591
#* Community mining from multi-relational networks
#@ Deng Cai;Zheng Shao;Xiaofei He;Xifeng Yan;Jiawei Han
#t 2005
#c 21
#% 146494
#% 342596
#% 1499466
#! Social network analysis has attracted much attention in recent years. Community mining is one of the major directions in social network analysis. Most of the existing methods on community mining assume that there is only one kind of relation in the network, and moreover, the mining results are independent of the users’ needs or preferences. However, in reality, there exist multiple, heterogeneous social networks, each representing a particular kind of relationship, and each kind of relationship may play a distinct role in a particular task. In this paper, we systematically analyze the problem of mining hidden communities on heterogeneous social networks. Based on the observation that different relations have different importance with respect to a certain query, we propose a new method for learning an optimal linear combination of these relations which can best meet the user’s expectation. With the obtained relation, better performance can be achieved for community mining.

#index 1673592
#* Evaluating the correlation between objective rule interestingness measures and real human interest
#@ Deborah R Carvalho;Alex A. Freitas;Nelson Ebecken
#t 2005
#c 21
#% 136350
#% 389460
#% 392618
#% 478139
#% 501674
#% 577214
#% 799768
#% 803397
#! In the last few years, the data mining community has proposed a number of objective rule interestingness measures to select the most interesting rules, out of a large set of discovered rules. However, it should be recalled that objective measures are just an estimate of the true degree of interestingness of a rule to the user, the so-called real human interest. The latter is inherently subjective. Hence, it is not clear how effective, in practice, objective measures are. More precisely, the central question investigated in this paper is: “how effective objective rule interestingness measures are, in the sense of being a good estimate of the true, subjective degree of interestingness of a rule to the user?” This question is investigated by extensive experiments with 11 objective rule interestingness measures across eight real-world data sets.

#index 1673593
#* A kernel based method for discovering market segments in beef meat
#@ Jorge Díez;Juan José del Coz;Carlos Sañudo;Pere Albertí;Antonio Bahamonde
#t 2005
#c 21
#% 269217
#% 413456
#% 577224
#% 770800
#! In this paper we propose a method for learning the reasons why groups of consumers prefer some food products instead of others. We emphasize the role of groups given that, from a practical point of view, they may represent market segments that demand different products. Our method starts representing people’s preferences in a metric space; there we are able to define a kernel based similarity function that allows a clustering algorithm to discover significant groups of consumers with homogeneous tastes. Finally in each cluster, we learn, with a SVM, a function that explains the tastes of the consumers grouped in the cluster. To illustrate our method, a real case of consumers of beef meat was studied. The panel was formed by 171 people who rated 303 samples of meat from 101 animals with 3 different aging periods.

#index 1673594
#* Corpus-based neural network method for explaining unknown words by wordnet senses
#@ Bálint Gábor;Viktor Gyenes;András Lőrincz
#t 2005
#c 21
#% 356892
#% 458630
#% 669201
#! This paper introduces an unsupervised algorithm that collects senses contained in WordNet to explain words, whose meaning is unknown, but plenty of documents are available that contain the word in that unknown sense. Based on the widely accepted idea that the meaning of a word is characterized by its context, a neural network architecture was designed to reconstruct the meaning of the unknown word. The connections of the network were derived from word co-occurrences and word-sense statistics. The method was tested on 80 TOEFL synonym questions, from which 63 questions were answered correctly. This is comparable to other methods tested on the same questions, but using a larger corpus or richer lexical database. The approach was found robust against details of the architecture.

#index 1673595
#* Segment and combine approach for non-parametric time-series classification
#@ Pierre Geurts;Louis Wehenkel
#t 2005
#c 21
#% 302383
#% 466260
#% 478460
#% 715296
#% 799392
#% 799394
#% 812305
#! This paper presents a novel, generic, scalable, autonomous, and flexible supervised learning algorithm for the classification of multi-variate and variable length time series. The essential ingredients of the algorithm are randomization, segmentation of time-series, decision tree ensemble based learning of subseries classifiers, combination of subseries classification by voting, and cross-validation based temporal resolution adaptation. Experiments are carried out with this method on 10 synthetic and real-world datasets. They highlight the good behavior of the algorithm on a large diversity of problems. Our results are also highly competitive with existing approaches from the literature.

#index 1673596
#* Producing accurate interpretable clusters from high-dimensional data
#@ Derek Greene;Pádraig Cunningham
#t 2005
#c 21
#% 329562
#% 342621
#% 643008
#% 722902
#% 783511
#! The primary goal of cluster analysis is to produce clusters that accurately reflect the natural groupings in the data. A second objective is to identify features that are descriptive of the clusters. In addition to these requirements, we often wish to allow objects to be associated with more than one cluster. In this paper we present a technique, based on the spectral co-clustering model, that is effective in meeting these objectives. Our evaluation on a range of text clustering problems shows that the proposed method yields accuracy superior to that afforded by existing techniques, while producing cluster descriptions that are amenable to human interpretation.

#index 1673597
#* Stress-testing hoeffding trees
#@ Geoffrey Holmes;Richard Kirkby;Bernhard Pfahringer
#t 2005
#c 21
#% 310500
#% 729965
#% 737348
#! Hoeffding trees are state-of-the-art in classification for data streams. They perform prediction by choosing the majority class at each leaf. Their predictive accuracy can be increased by adding Naive Bayes models at the leaves of the trees. By stress-testing these two prediction methods using noise and more complex concepts and an order of magnitude more instances than in previous studies, we discover situations where the Naive Bayes method outperforms the standard Hoeffding tree initially but is eventually overtaken. The reason for this crossover is determined and a hybrid adaptive method is proposed that generally outperforms the two original prediction methods for both simple and complex concepts as well as under noise.

#index 1673598
#* Rank measures for ordering
#@ Jin Huang;Charles X. Ling
#t 2005
#c 21
#% 349550
#% 464606
#% 566871
#% 580510
#% 1279288
#% 1378224
#! Many data mining applications require a ranking, rather than a mere classification, of cases. Examples of these applications are widespread, including Internet search engines (ranking of pages returned) and customer relationship management (ranking of profitable customers). However, little theoretical foundation and practical guideline have been established to assess the merits of different rank measures for ordering. In this paper, we first review several general criteria to judge the merits of different single-number measures. Then we propose a novel rank measure, and compare the commonly used rank measures and our new one according to the criteria. This leads to a preference order for these rank measures. We conduct experiments on real-world datasets to confirm the preference order. The results of the paper will be very useful in evaluating and comparing rank algorithms.

#index 1673599
#* Dynamic ensemble re-construction for better ranking
#@ Jin Huang;Charles X. Ling
#t 2005
#c 21
#% 5182
#% 209021
#% 290482
#% 349550
#% 424997
#% 734915
#% 1378224
#% 1499573
#! Ensemble learning has been shown to be very successful in data mining. However most work on ensemble learning concerns the task of classification. Little work has been done to construct ensembles that aim to improve ranking. In this paper, we propose an approach to re-construct new ensembles based on a given ensemble with the purpose to improve the ranking performance, which is crucial in many data mining tasks. The experiments with real-world data sets show that our new approach achieves significant improvements in ranking over the original Bagging and Adaboost ensembles.

#index 1673600
#* Frequency-based separation of climate signals
#@ Alexander Ilin;Harri Valpola
#t 2005
#c 21
#% 803573
#% 855605
#! The paper presents an example of exploratory data analysis of climate measurements using a recently developed denoising source separation (DSS) framework. We analysed a combined dataset containing daily measurements of three variables: surface temperature, sea level pressure and precipitation around the globe. Components exhibiting slow temporal behaviour were extracted using DSS with linear denoising. These slow components were further rotated using DSS with nonlinear denoising which implemented a frequency-based separation criterion. The rotated sources give a meaningful representation of the slow climate variability as a combination of trends, interannual oscillations, the annual cycle and slowly changing seasonal variations.

#index 1673601
#* Efficient processing of ranked queries with sweeping selection
#@ Wen Jin;Martin Ester;Jiawei Han
#t 2005
#c 21
#% 86950
#% 201876
#% 210173
#% 248010
#% 248796
#% 300180
#% 333854
#% 333951
#% 410276
#% 427199
#% 464195
#% 465167
#% 479816
#% 591565
#% 654480
#% 733373
#% 799759
#% 1016182
#! Existing methods for top-k ranked query employ techniques including sorting, updating thresholds and materializing views. In this paper, we propose two novel index-based techniques for top-k ranked query: (1) indexing the layered skyline, and (2) indexing microclusters of objects into a grid structure. We also develop efficient algorithms for ranked query by locating the answer points during the sweeping of the line/hyperplane of the score function over the indexed objects. Both methods can be easily plugged into typical multi-dimensional database indexes. The comprehensive experiments not only demonstrate that our methods outperform the existing ones, but also illustrate that the application of data mining technique (microclustering) is a useful and effective solution for database query processing.

#index 1673602
#* Feature extraction from mass spectra for classification of pathological states
#@ Alexandros Kalousis;Julien Prados;Elton Rexhepaj;Melanie Hilario
#t 2005
#c 21
#% 290482
#% 477825
#% 833722
#! Mass spectrometry is becoming an important tool in proteomics. The representation of mass spectra is characterized by very high dimensionality and a high level of redundancy. Here we present a feature extraction method for mass spectra that directly models for domain knowledge, reduces the dimensionality and redundancy of the initial representation and controls for the level of granularity of feature extraction by seeking to optimize classification accuracy. A number of experiments are performed which show that the feature extraction preserves the initial discriminatory content of the learning examples.

#index 1673603
#* Numbers in multi-relational data mining
#@ Arno J. Knobbe;Eric K. Y. Ho
#t 2005
#c 21
#% 217072
#% 224755
#% 497964
#! Numeric data has traditionally received little attention in the field of Multi-Relational Data Mining (MRDM). It is often assumed that numeric data can simply be turned into symbolic data by means of discretisation. However, very few guidelines for successfully applying discretisation in MRDM exist. Furthermore, it is unclear whether the loss of information involved is negligible. In this paper, we consider different alternatives for dealing with numeric data in MRDM. Specifically, we analyse the adequacy of discretisation by performing a number of experiments with different existing discretisation approaches, and comparing the results with a procedure that handles numeric data dynamically. The discretisation procedures considered include an algorithm that is insensitive to the multi-relational structure of the data, and two algorithms that do involve this structure. With the empirical results thus obtained, we shed some light on the applicability of both dynamic and static procedures (discretisation), and give recommendations for when and how they can best be applied.

#index 1673604
#* Testing theories in particle physics using maximum likelihood and adaptive bin allocation
#@ Bruce Knuteson;Ricardo Vilalta
#t 2005
#c 21
#% 546537
#% 729437
#! We describe a methodology to assist scientists in quantifying the degree of evidence in favor of a new proposed theory compared to a standard baseline theory. The figure of merit is the log-likelihood ratio of the data given each theory. The novelty of the proposed mechanism lies in the likelihood estimations; the central idea is to adaptively allocate histogram bins that emphasize regions in the variable space where there is a clear difference in the predictions made by the two theories. We describe a software system that computes this figure of merit in the context of particle physics, and describe two examples conducted at the Tevatron Ring at the Fermi National Accelerator Laboratory. Results show how two proposed theories compare to the Standard Model and how the likelihood ratio varies as a function of a physical parameter (e.g., by varying the particle mass).

#index 1673605
#* Improved naive bayes for extremely skewed misclassification costs
#@ Aleksander Kołcz;Abdur Chowdhury
#t 2005
#c 21
#% 219052
#% 246831
#% 458369
#% 486328
#% 729956
#% 1786755
#! Naive Bayes has been an effective and important classifier in the text categorization domain despite violations of its underlying assumptions. Although quite accurate, it tends to provide poor estimates of the posterior class probabilities, which hampers its application in the cost-sensitive context. The apparent high confidence with which certain errors are made is particularly problematic when misclassification costs are highly skewed, since conservative setting of the decision threshold may greatly decrease the classifier utility. We propose an extension of the Naive Bayes algorithm aiming to discount the confidence with which errors are made. The approach is based on measuring the amount of change to feature distribution necessary to reverse the initial classifier decision and can be implemented efficiently without over-complicating the process of Naive Bayes induction. In experiments with three benchmark document collections, the decision-reversal Naive Bayes is demonstrated to substantially improve over the popular multinomial version of the Naive Bayes algorithm, in some cases performing more than 40% better.

#index 1673606
#* Clustering and prediction of mobile user routes from cellular data
#@ Kari Laasonen
#t 2005
#c 21
#% 235941
#% 419385
#% 487495
#% 723186
#% 737508
#% 778502
#% 813847
#! Location-awareness and prediction of future locations is an important problem in pervasive and mobile computing. In cellular systems (e.g., GSM) the serving cell is easily available as an indication of the user location, without any additional hardware or network services. With this location data and other context variables we can determine places that are important to the user, such as work and home. We devise online algorithms that learn routes between important locations and predict the next location when the user is moving. We incrementally build clusters of cell sequences to represent physical routes. Predictions are based on destination probabilities derived from these clusters. Other context variables such as the current time can be integrated into the model. We evaluate the model with real location data, and show that it achieves good prediction accuracy with relatively little memory, making the algorithms suitable for online use in mobile environments.

#index 1673607
#* Elastic partial matching of time series
#@ L. J. Latecki;V. Megalooikonomou;Q. Wang;R. Lakaemper;C. A. Ratanamahatana;E. Keogh
#t 2005
#c 21
#% 462231
#% 477479
#% 478455
#% 631920
#% 659971
#% 729931
#% 729960
#% 769896
#% 800574
#! We consider a problem of elastic matching of time series. We propose an algorithm that automatically determines a subsequence b′ of a target time series b that best matches a query series a. In the proposed algorithm we map the problem of the best matching subsequence to the problem of a cheapest path in a DAG (directed acyclic graph). Our experimental results demonstrate that the proposed algorithm outperforms the commonly used Dynamic Time Warping in retrieval accuracy.

#index 1673608
#* An entropy-based approach for generating multi-dimensional sequential patterns
#@ Chang-Hwan Lee
#t 2005
#c 21
#% 310559
#% 329537
#% 463903
#% 479971
#% 660658
#% 727913
#! This paper proposes a new method for generating multi-dimensional sequential patterns. While the current sequential pattern methods are generating patterns within a single attribute, the proposed method is able to detect them among different attributes. We employ an information theoretic method for generating multi-dimensional sequential patterns with the use of Hellinger entropy measure. A number of theorems are proposed to reduce the computational complexity of the sequential pattern systems. The proposed method is tested on some synthesized transaction databases.

#index 1673609
#* Visual terrain analysis of high-dimensional datasets
#@ Wenyuan Li;Kok-Leong Ong;Wee-Keong Ng
#t 2005
#c 21
#% 83976
#% 469422
#% 727882
#% 731279
#! Most real-world datasets are, to a certain degree, skewed. When considered that they are also large, they become the pinnacle challenge in data analysis. More importantly, we cannot ignore such datasets as they arise frequently in a wide variety of applications. Regardless of the analytic, it is often that the effectiveness of analysis can be improved if the characteristic of the dataset is known in advance. In this paper, we propose a novel technique to preprocess such datasets to obtain this insight. Our work is inspired by the resonance phenomenon, where similar objects resonate to a given response function. The key analytic result of our work is the data terrain, which shows properties of the dataset to enable effective and efficient analysis. We demonstrated our work in the context of various real-world problems. In doing so, we establish it as the tool for preprocessing data before applying computationally expensive algorithms.

#index 1673610
#* An auto-stopped hierarchical clustering algorithm for analyzing 3d model database
#@ Tian-yang Lv;Yu-hui Xing;Shao-bing Huang;Zheng-xuan Wang;Wan-li Zuo
#t 2005
#c 21
#% 248790
#% 416060
#% 479986
#% 719276
#! In the research of shape-based 3D model retrieval, the analysis and classification of 3D model database is an important topic for improving the retrieval performance. However, it encounters difficulties due to lack of valuable prior knowledge and the semantic gaps exist in 3D model retrieval. The paper proposes a new auto-stopped hierarchical clustering algorithm overcome these problems, which combines outlier detection with clustering. The Princeton Shape Benchmark along with 2 data sets from UCI is employed to evaluate the performance of the algorithm. And the new algorithm outperforms other auto-stopped algorithms and obtains better classification of 3D model database.

#index 1673611
#* A comparison between block CEM and two-way CEM algorithms to cluster a contingency table
#@ Mohamed Nadif;Gérard Govaert
#t 2005
#c 21
#% 131258
#% 342621
#% 375388
#% 469422
#% 796243
#! When the data consists of a set of objects described by a set of variables, we have recently proposed a new mixture model which takes into account the block clustering problem on the both sets and have developed the block CEM algorithm. In this paper, we embed the block clustering problem of contingency table in the mixture approach. In using a Poisson model and adopting the classification maximum likelihood principle we perform an adapted version of block CEM. We evaluate its performance and compare it to a simple use of CEM applied on the both sets separately. We present detailed experimental results on simulated data and we show the interest of this new algorithm.

#index 1673612
#* An imbalanced data rule learner
#@ Canh Hao Nguyen;Tu Bao Ho
#t 2005
#c 21
#% 260149
#% 280437
#% 331909
#% 464606
#% 577241
#% 1271973
#% 1289281
#! Imbalanced data learning has recently begun to receive much attention from research and industrial communities as traditional machine learners no longer give satisfactory results. Solutions to the problem generally attempt to adapt standard learners to the imbalanced data setting. Basically, higher weights are assigned to small class examples to avoid their being overshadowed by the large class ones. The difficulty determining a reasonable weight for each example remains. In this work, we propose a scheme to weight examples of the small class based solely on local data distributions. The approach is for categorical data, and a rule learning algorithm is constructed taking the weighting scheme into account. Empirical evaluations prove the advantages of this approach.

#index 1673613
#* Improvements in the data partitioning approach for frequent itemsets mining
#@ Son N. Nguyen;Maria E. Orlowska
#t 2005
#c 21
#% 152934
#% 201075
#% 227917
#% 338609
#% 443350
#% 462219
#% 481290
#% 481754
#% 729418
#! Frequent Itemsets mining is well explored for various data types, and its computational complexity is well understood. There are methods to deal effectively with computational problems. This paper shows another approach to further performance enhancements of frequent items sets computation. We have made a series of observations that led us to inventing data pre-processing methods such that the final step of the Partition algorithm, where a combination of all local candidate sets must be processed, is executed on substantially smaller input data. The paper shows results from several experiments that confirmed our general and formally presented observations.

#index 1673614
#* On-line adaptive filtering of web pages
#@ Richard Nock;Babak Esfandiari
#t 2005
#c 21
#% 165663
#% 166352
#% 238621
#% 534116
#! We present a browser extension to dynamically learn to filter unwanted Uniform Resource Locators (such as advertisements or flashy images) based on minimal user feedback. Our extension builds upon one of the top ten of Mozilla firefox plug-ins which filters URLs without learning capabilities. We apply a weighted majority-type learning algorithm working on regular expressions. Experimental results confirm that the accuracy of the predictions converges quickly to very high levels, with other key parameters: recall, specificity and precision.

#index 1673615
#* A bi-clustering framework for categorical data
#@ Ruggero G. Pensa;Céline Robardet;Jean-François Boulicaut
#t 2005
#c 21
#% 36672
#% 451052
#% 546527
#% 729918
#% 778215
#% 953950
#! Bi-clustering is a promising conceptual clustering approach. Within categorical data, it provides a collection of (possibly overlapping) bi-clusters, i.e., linked clusters for both objects and attribute-value pairs. We propose a generic framework for bi-clustering which enables to compute a bi-partition from collections of local patterns which capture locally strong associations between objects and properties. To validate this framework, we have studied in details the instance CDK-Means. It is a K-Means-like clustering on collections of formal concepts, i.e., connected closed sets on both dimensions. It enables to build bi-partitions with a user control on overlapping between bi-clusters. We provide an experimental validation on many benchmark datasets and discuss the interestingness of the computed bi-partitions.

#index 1673616
#* Privacy-preserving collaborative filtering on vertically partitioned data
#@ Huseyin Polat;Wenliang Du
#t 2005
#c 21
#% 280852
#% 280883
#% 397153
#% 577289
#% 616944
#% 727866
#% 729930
#% 810583
#% 1386180
#! Collaborative filtering (CF) systems are widely used by E-commerce sites to provide predictions using existing databases comprised of ratings recorded from groups of people evaluating various items, sometimes, however, such systems’ ratings are split among different parties. To provide better filtering services, such parties may wish to share their data. However, due to privacy concerns, data owners do not want to disclose data. This paper presents a privacy-preserving protocol for CF grounded on vertically partitioned data. We conducted various experiments to evaluate the overall performance of our scheme.

#index 1673617
#* Indexed bit map (IBM) for mining frequent sequences
#@ Lionel Savary;Karine Zeitouni
#t 2005
#c 21
#% 259993
#% 334041
#% 459006
#% 463903
#% 464996
#% 481290
#! Sequential pattern mining has been an emerging problem in data mining. In this paper, we propose a new algorithm for mining frequent sequences. It processes only one scan of the database thanks to an indexed structure associated to a bit map representation. Thus, it allows a fast data access and a compact storage in main memory. The experimental results show the efficiency of our method compared to existing algorithms. It has been tested on synthetic data and on real data containing sequences of activities of a urban population time-use survey.

#index 1673618
#* STochFS: a framework for combining feature selection outcomes through a stochastic process
#@ Jerffeson Teixeira de Souza;Nathalie Japkowicz;Stan Matwin
#t 2005
#c 21
#% 126894
#% 209021
#% 464444
#% 466410
#% 466912
#% 637486
#% 1022842
#% 1477332
#! The Feature Selection problem involves discovering a subset of features such that a classifier built only with this subset would have better predictive accuracy than a classifier built from the entire set of features. Ensemble methods, such as Bagging and Boosting, have been shown to increase the performance of classifiers to remarkable levels but surprisingly have not been tried in other parts of the classification process. In this paper, we apply the ensemble approach to feature selection by proposing a systematic way of combining various outcomes of a feature selection algorithm. The proposed framework, named STochFS, have been shown empirically to improve the performance of well-known feature selection algorithms.

#index 1673619
#* Speeding up logistic model tree induction
#@ Marc Sumner;Eibe Frank;Mark Hall
#t 2005
#c 21
#% 136350
#% 290482
#% 810935
#! Logistic Model Trees have been shown to be very accurate and compact classifiers [8]. Their greatest disadvantage is the computational complexity of inducing the logistic regression models in the tree. We address this issue by using the AIC criterion [1] instead of cross-validation to prevent overfitting these models. In addition, a weight trimming heuristic is used which produces a significant speedup. We compare the training time and accuracy of the new induction process with the original one on various datasets and show that the training time often decreases while the classification accuracy diminishes only slightly.

#index 1673620
#* A random method for quantifying changing distributions in data streams
#@ Haixun Wang;Jian Pei
#t 2005
#c 21
#% 115608
#% 342600
#% 400847
#% 424997
#% 443616
#% 481460
#% 654489
#% 729932
#% 729980
#! In applications such as fraud and intrusion detection, it is of great interest to measure the evolving trends in the data. We consider the problem of quantifying changes between two datasets with class labels. Traditionally, changes are often measured by first estimating the probability distributions of the given data, and then computing the distance, for instance, the K-L divergence, between the estimated distributions. However, this approach is computationally infeasible for large, high dimensional datasets. The problem becomes more challenging in the streaming data environment, as the high speed makes it difficult for the learning process to keep up with the concept drifts in the data. To tackle this problem, we propose a method to quantify concept drifts using a universal model that incurs minimal learning cost. In addition, our model also provides the ability of performing classification.

#index 1673621
#* Deriving class association rules based on levelwise subspace clustering
#@ Takashi Washio;Koutarou Nakanishi;Hiroshi Motoda
#t 2005
#c 21
#% 210160
#% 248792
#% 397384
#% 466483
#% 481290
#% 546047
#! Most approaches of Class Association Rule (CAR) based classification have not intensively addressed the classification of instances including numeric attributes. In this paper, a levelwise subspace clustering method deriving hyper-rectangular clusters is proposed to efficiently provide quantitative, interpretative and accurate CARs.

#index 1673622
#* An incremental algorithm for mining generators representation
#@ Lijun Xu;Kanglin Xie
#t 2005
#c 21
#% 280467
#% 464204
#% 466664
#% 481290
#% 481779
#% 511333
#% 546698
#% 785339
#! This paper presents an efficient algorithm for maintaining the generator representation in dynamic datasets. The generators representation is a kind of lossless, concise representation of the set of frequent itemsets. Furthermore, the algorithm utilizes a novel optimization based on generators borders for the first time in the literature. Generators borders are the borderline between frequent generators and other itemsets. New frequent generators can be generated through monitoring them. Experiments show that our algorithm is more efficient than previous solutions.

#index 1673623
#* Hybrid technique for artificial neural network architecture and weight optimization
#@ Cleber Zanchettin;Teresa Bernarda Ludermir
#t 2005
#c 21
#% 11720
#% 36408
#% 369236
#% 386199
#% 388154
#% 465882
#% 1777043
#! This work presents a technique that integrates the heuristics tabu search, simulated annealing, genetic algorithms and backpropagation. This approach obtained promising results in the simultaneous optimization of the artificial neural network architecture and weights.

