#index 1108816
#* Proceedings of the 2008 European Conference on Machine Learning and Knowledge Discovery in Databases - Part I
#@ Walter Daelemans;Bart Goethals;Katharina Morik
#t 2008
#c 22

#index 1108817
#* Industrializing Data Mining, Challenges and Perspectives
#@ Françoise Fogelman-Soulié
#t 2008
#c 22
#! Business Intelligence is a very active sector in all industrial domains. Classical techniques (reporting and Olap), mainly concerned with presenting data, are already widely deployed. Meanwhile, Data Mining has long been used in companies as a nichetechnique, reserved for experts only and for very specific problems (credit scoring, fraud detection for example). But with the increasing availability of large data volumes (in particular, but not only, from theWeb), companies are more and more turning to data mining to provide them with high added-value predictive analytics. However producing models in large numbers, making use of large data volumes in an industrial context can only happen if solutions to challenges, both theoretic and operational, are found: we need algorithms which can be used to produce models when datasets have thousands of variables and millions of observations; we need to learn how to run and control the correct execution of hundreds of models; we need ways to automate the data mining process.I will present these constraints in industrial contexts and show how KXEN has exploited theoretical results (coming from Vladimir Vapnik's work) to provide answers to the above-mentioned challenges. I will give a few examples of real-life applications and will conclude with some remarks on the future of data mining in the industrial domain.

#index 1108818
#* From Microscopy Images to Models of Cellular Processes
#@ Yoav Freund
#t 2008
#c 22
#! The advance of fluorescent tagging and of confocal microscopy is allowing biologists to image biochemical processes at a level of detail that was unimaginable just a few years ago. However, as the analysis of these images is done mostly by hand, there is a severe bottleneck in transforming these images into useful quantitative data that can be used to evaluate mathematical models.One of the inherent challenges involved in automating this transformation is that image data is highly variable. This requires a recalibration of the image processing algorithms for each experiment. We use machine learning methods to enable the experimentalist to calibrate the image processing methods without having any knowledge of how these methods work. This, we believe, will allow the rapid integration of computer vision methods with confocal microscopy and open the way to the development of quantitative spatial models of cellular processes.For more information, see http://seed.ucsd.edu/ yfreund/NewHomePage/ Applications/Biomedical Imaging.html

#index 1108819
#* Data Clustering: 50 Years Beyond K-means
#@ Anil K. Jain
#t 2008
#c 22
#! The practice of classifying objects according to perceived similarities is the basis for much of science. Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms in to taxonomic ranks: domain, kingdom, phylum, class, etc.). Cluster analysis is the formal study of algorithms and methods for grouping objects according to measured or perceived intrinsic characteristics. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes cluster analysis (unsupervised learning) from discriminant analysis (supervised learning). The objective of cluster analysis is to simply find a convenient and valid organization of the data, not to establish rules for separating future data into categories.

#index 1108820
#* Learning Language from Its Perceptual Context
#@ Raymond J. Mooney
#t 2008
#c 22
#! Current systems that learn to process natural language require laboriously constructed human-annotated training data. Ideally, a computer would be able to acquire language like a child by being exposed to linguistic input in the context of a relevant but ambiguous perceptual environment. As a step in this direction, we present a system that learns to sportscast simulated robot soccer games by example. The training data consists of textual human commentaries on Robocup simulation games. A set of possible alternative meanings for each comment is automatically constructed from game event traces. Our previously developed systems for learning to parse and generate natural language (KRISP and WASP) were augmented to learn from this data and then commentate novel games. The system is evaluated based on its ability to parse sentences into correct meanings and generate accurate descriptions of game events. Human evaluation was also conducted on the overall quality of the generated sportscasts and compared to human-generated commentaries.

#index 1108821
#* The Role of Hierarchies in Exploratory Data Mining
#@ Raghu Ramakrishnan
#t 2008
#c 22
#! In a broad range of data mining tasks, the fundamental challenge is to efficiently explore a very large space of alternatives. The difficulty is two-fold: first, the size of the space raises computational challenges, and second, it can introduce data sparsity issues even in the presence of very large datasets. In this talk, well consider how the use of hierarchies (e.g., taxonomies, or the OLAP multidimensional model) can help mitigate the problem.

#index 1108822
#* Rollout Sampling Approximate Policy Iteration
#@ Christos Dimitrakakis;Michail G. Lagoudakis
#t 2008
#c 22
#% 1077631
#! Several researchers [2,3] have recently investigated the connection between reinforcement learning and classification. Our work builds on [2], which suggests an approximate policy iteration algorithm for learning a good policy represented as a classifier, without explicit value function representation. At each iteration, a new policy is produced using training data obtained through rollouts of the previous policy on a simulator. These rollouts aim at identifying better action choices over a subset of states in order to form a set of data for training the classifier representing the improved policy. Even though [2,3] examine how to distribute training states over the state space, their major limitation remains the large amount of sampling employed at each training state.We suggest methods to reduce the number of samples needed to obtain a high-quality training set. This is done by viewing the setting as akin to a bandit problem over the states from which rollouts are performed. Our contribution is two-fold: (a) we suitably adapt existing bandit techniques for rollout management, and (b) we suggest a more appropriate statistical test for identifying states with dominating actions early and with high confidence. Experiments on two classical domains (inverted pendulum, mountain car) demonstrate an improvement in sample complexity that substantially increases the applicability of rollout-based algorithms. In future work, we aim to obtain algorithms specifically tuned to this task with even lower sample complexity and to address the question of the choice of sampling distribution.

#index 1108823
#* New Closed-Form Bounds on the Partition Function
#@ Krishnamurthy Dvijotham;Soumen Chakrabarti;Subhasis Chaudhuri
#t 2008
#c 22
#% 1077632
#! Estimating the partition function is a key computation in graphical models that is required for important tasks like parameter estimation, model selection and structure learning. However, this computation is intractable in general. Thus, developing efficient and accurate approximations is of considerable interest. Variational methods express the computation of the partition function as an optimization problem (solving which intractable in general) and then relax the optimization problem in various ways to obtain approximations to the partition function. Two popular algorithms belonging to this framework are loopy belief propagation (LBP) and tree-reweighted belief propagation (TRW-BP). Both these algorithms are so-called message passingalgorithms that work by updating local beliefs about probabilities at graph nodes by passing messages between the nodes in the graph until convergence is achieved. TRW-BP is guaranteed to give an upper bound on the partition function. However, neither algorithm is guaranteed to converge in general. Although convergent alternatives to TRW-BP have been proposed, they have no guarantees on the number of iterations required for convergence. Thus, these algorithms could be prohibitively expensive for applications requiring repeated inference on large graphs (like training large CRFs). In order to overcome this problem, Sutton et al. propose the piecewise approximation(PW) to the partition function. PW tends to be loose, but can be computed very fast, because it has a closed-form expression. Sutton et al. apply it successfully to common NLP tasks. In this paper, for a special class of potentials (that contain associative potentials), we prove that both LBP and TRW-BP converge in a single iteration. Using this fact, we obtain closed-form expressions for the TRW and LBP approximations to the partition function. In recent work, Wainwright et al. prove that LBP gives a lower bound on the partition function for binary attractive MRFs. We thus also get closed-form lower bounds for attractive associative MRFs. This enables us to obtain bounds on the error between the true partition function and these approximations for attractive associative MRFs. We also construct examples which show that TRW and LBP can give arbitrarily bad approximations to the marginal probabilities. Using the closed-form bounds for these special cases, we also develop novel closed-form upper bounds for arbitrary MRFs and closed-form lower bounds for associative binary MRFs. We also present experimental results showing that the new upper bounds are almost always tighter than the piecewise bound. The experiments also show that the novel lover bounds beat popular existing bounds like the mean-field bound on densely connected graphs.

#index 1108824
#* Large Margin vs. Large Volume in Transductive Learning
#@ Ran El-Yaniv;Dmitry Pechyony;Vladimir Vapnik
#t 2008
#c 22
#% 1077629
#! We focus on distribution-free transductive learning. In this setting the learning algorithm is given a `full sample' of unlabeled points. Then, a training sample is selected uniformly at random from the full sample and the labels of the training points are revealed. The goal is to predict the labels of the remaining unlabeled points as accurately as possible. The full sample partitions the transductive hypothesis space into a finite number of equivalence classes. All hypotheses in the same equivalence class, generate the same dichotomy of the full sample. We consider a large volumeprinciple, whereby the priority of each equivalence class is proportional to its "volume" in the hypothesis space.

#index 1108825
#* Incremental Exemplar Learning Schemes for Classification on Embedded Devices
#@ Ankur Jain;Daniel Nikovski
#t 2008
#c 22
#% 92533
#% 307100
#% 1077626
#! In this paper, we focus on the data classification problem when the classifier operates on an embedded device (e.g., fault detection in device condition-monitoring data streams). Memory-based classifiers are an excellent choice in such cases, however, an embedded device is unlikely to be able to hold a large training dataset in memory (which could potentially keep increasing in size as new training data with new concepts arrive). A viable option then is to employ exemplar learning (EL) techniques to find a training subset comprising a few carefully selected exemplarsof high functional value that fit in memory and effectively delineate the class boundaries. We propose two novel incremental EL schemes that unlike traditional EL approaches [3] are, (1) incremental (they naturally incorporate new training data streams), (2) offer ordered removal of instances (they can be customized to obtain exemplar sets of any user-defined size) and (3) robust (such that the exemplar sets generalize for other classifiers as well). Our proposed methods are as follows:EBEL(Entropy Based EL) --- This method removes instances from the training set based on their information content. Instead of using an adhoc ranking scheme, it removes a training instance whose removal causes the least amount of drop in the conditional entropy of the class indicator variable insuring minimum loss of information.ABEL(AUC Based EL) --- This method prunes data based on AUC (Area under ROC curve) performance. ABELuses a validation setand prunes an instance if its removal offers the least drop in the AUC computed for this validation set.We show that our schemes efficiently incorporate new training datasets while maintaining high-quality exemplar sets of any user-defined size. We present a comprehensive experimental analysis showing excellent classification-accuracy versus memory-usage tradeoffs of our proposed methods.

#index 1108826
#* A Collaborative Filtering Framework Based on Both Local User Similarity and Global User Similarity
#@ Heng Luo;Changyong Niu;Ruimin Shen;Carsten Ullrich
#t 2008
#c 22
#% 1077630
#! Collaborative filtering as a classical method of information retrieval is widely used in helping people to deal with information overload. In this paper, we introduce the concept of local user similarity and global user similarity, based on surprisal-based vector similarity and the application of the concept of maximin distance in graph theory. Surprisal-based vector similarity expresses the relationship between any two users based on the quantities of information (called surprisal) contained in their ratings, which is based on the intuition that less common ratings for a specific item tend to provide more discriminative information than the most common ratings. Furthermore, traditional methods of computing user similarity can not work if two users have not rated any identical item. To solve this problem, the global user similarity is introduced to define two users being similar if they can be connected through their locally similar neighbors. A weighted user graph is first constructed by using local similarity of any two users as the weight of the edge connecting them. Then the global similarity can be calculated as the maximin distance of any two nodes in the graph. Based on both of Local User Similarity and Global User Similarity, we develop a collaborative filtering framework called LS&GS. An empirical study using the MovieLens dataset shows that the proposed framework outperforms other state-of-the-art collaborative filtering algorithms.

#index 1108827
#* A Critical Analysis of Variants of the AUC
#@ Stijn Vanderlooy;Eyke Hüllermeier
#t 2008
#c 22
#% 1077628
#! The area under the ROC curve, or AUC, has been widely used to assess the ranking performance of binary scoring classifiers. Given a sample of labeled instances, the metric considers the number of correctly ordered pairs of instances with different class label. Thus, its value only depends on the ordering of the scores but not on the "margin" between them. Consequently, it can happen that a small change in scores leads to a considerable change in AUC value. Such an effect is especially apparent when the number of instances used to calculate the AUC is small. On the other hand, two classifiers can have the same AUC value, even though one of them is a "better separator" in the sense that it increases the difference between scores of positive and negative instances, respectively. It has been argued that this insensitivity toward score differences is disadvantageous for model evaluation and selection. For this reason, three variants of the AUC metric that take the score differences into account have recently been proposed, along with first experimental results.We present a unifying framework in which the conventional AUC and its variants can be modeled as special cases of a generalized AUC metric. Within this framework, we provide a formal analysis showing that the AUC variants produce estimates of the true AUC with a non-constant, model-specific bias, while the variance can decrease as well as increase. All things considered, the net effect on the quality of the estimations is thus not clear and, hereby, there is no solid theoretical foundation for the variants. Our analysis leads us to conjecture that actually none of the variants should be able to perform better in model selection than conventional AUC. This conjecture is corroborated by extensive experiments with synthetic data as well as real benchmark data, showing that the conventional AUC cannot be outperformed systematically by any variant, not in an ideal setting according to the theoretical analysis, and not in real model selection scenarios. Finally, our contribution also sheds light on recent research dealing with the construction of classifiers that (approximately) optimize the AUC directly, rather than accuracy or another performance metric.

#index 1108828
#* Improving Maximum Margin Matrix Factorization
#@ Markus Weimer;Alexandros Karatzoglou;Alex Smola
#t 2008
#c 22
#% 770816
#% 1077627
#! Maximum Margin Matrix Factorization (MMMF) has been proposed as a learning approach to the task of collaborative filtering with promising results. In our recent paper [2], we proposed to extend the general MMMF framework to allow for structured (ranking) losses in addition to the squared error loss.In this paper, we introduce a novel algorithm to compute the ordinal regression ranking loss which is significantly faster than the state of the art. In addition, we propose severals extensions to the MMMF model: We introduce offset terms to cater for user and item biases. Users exhibit vastly different rating frequencies ranging from only one rating per user to thousands of them. Similarly, some items get thousands of ratings while others get rated only once. We introduce an adaptive regularizer to allow for more complex models for those items and users with many ratings. Finally, we show equivalence between a recent extension introduced in and a graph kernel approach described in [3]. Both aim at providing meaningful predictions for users with very little training data by virtue of the recommender graph.We performed an evaluation of these extensions on two standard data sets: Eachmovie and Movielens. These experiments show that the introduced extensions do improve the predictive performance over the original MMMF formulation, even though we did not formally optimize the parameters.

#index 1108829
#* Finding Reliable Subgraphs from Large Probabilistic Graphs
#@ Petteri Hintsanen;Hannu Toivonen
#t 2008
#c 22
#% 1083509
#! Consider information search or discovery in a large graph of concepts and their weighted relationships. The user initiates a query by specifying some concepts ("search terms"), and wishes to obtain other concepts and relationships that connect the search concepts. An application example is in analysis of biological information, conveniently represented as a graph of biological concepts and their relations. A search engine we envision would allow a life scientist to query for connections between a gene and a phenotype, for instance, to find information supporting a hypothesis, or to help discover new hypothesis.

#index 1108830
#* A Space Efficient Solution to the Frequent String Mining Problem for Many Databases
#@ Adrian Kügel;Enno Ohlebusch
#t 2008
#c 22
#% 1083511
#% 1663628
#! In the frequent string mining problem, one is given mdatabases ${\cal D}_1,...,{\cal D}_m$ of strings and searches for strings that fulfill certain frequency constraints. The constraints consist of mpairs of thresholds $(\mathit{minf}_1,\mathit{maxf}_1),$ $...,(\mathit{minf}_m,\mathit{maxf}_m)$ and one wants to find all strings 茂戮驴that satisfy $\mathit{minf}_i \le \mathit{freq}(\phi, {\cal D}_i) \le \mathit{maxf}_i$ for all iwith 1 ≤ i≤ m, where $\mathit{freq}(\phi,\mathcal{D}_i) = |\{ \psi \in \mathcal{D}_i : \phi \mbox{ is a substring of } \psi \}|$.Fischer et al. [2] presented an algorithm that solves the frequent string mining problem in linear time under the assumption that the number of databases is treated as a constant. The space consumption of this algorithm, however, is proportional to the total size of all databases. We improve this algorithm in such a way that its space consumption is proportional to the size of the largest database, and it takes linear time regardless of the number of databases. Also, our algorithm is more flexible in the sense that one of several databases can be replaced without having to recalculate everything, that is, intermediate data can be stored on file and be reused.

#index 1108831
#* The Boolean Column and Column-Row Matrix Decompositions
#@ Pauli Miettinen
#t 2008
#c 22
#% 1083510
#! Matrix decompositions are used for many data mining purposes. One of these purposes is to find a concise but interpretable representation of a given data matrix. Different decomposition formulations have been proposed for this task, many of which assume a certain property of the input data (e.g., nonnegativity) and aim at preserving that property in the decomposition.

#index 1108832
#* SkyGraph: An Algorithm for Important Subgraph Discovery in Relational Graphs
#@ Apostolos N. Papadopoulos;Apostolos Lyritsis;Yannis Manolopoulos
#t 2008
#c 22
#% 1083508
#! Graph mining is gaining importance due to the numerous applications that rely on graph-based data. Some example applications are: (i) analysis of microarray data in bioinformatics, (ii) pattern discovery in social networks, (iii) analysis of transportation networks, (iv) community discovery in Web data. Existing pattern discovery approaches operate by using simple constraints on the mined patterns. For example, given a database of graphs, a typical graph mining task is to report all subgraphs that appear in at least s graphs, where s is the frequency support threshold. In other cases, we are interested in the discovery of dense or highly-connected subgraphs. In such a case, a threshold is defined for the density or the connectivity of the returned patterns. Other constraints may be defined as well, towards restricting the number of mined patterns. There are three important limitations with this approach: (i) there is an on-off decision regarding the eligibility of patterns, i.e., a pattern either satisfies the constraints or not, (ii) in the case where the constraints are very strict we risk an empty answer or an answer with only a few patterns, and (iii) in the case where the constraints are too weak the number of patterns may be huge.

#index 1108833
#* Mining Conjunctive Sequential Patterns
#@ Chedy Raïssi;Toon Calders;Pascal Poncelet
#t 2008
#c 22
#% 1083507
#! In this paper we study the discovery of frequent sequences and we aim at extending the non-derivable condensed representation in frequent itemset mining to sequential pattern mining. We start by showing a negative example: in the context of frequent sequences, the notion of non-derivability is meaningless.This negative result motivated us to look at a slightly different problem: the mining of conjunctionsof sequential patterns. This extended class of patterns turns out to have much nicer mathematical properties. For example, for this class of patterns we are able to extend the notion of non-derivable itemsets in a non-trivial way, based on a new unexploited theoretical definition of equivalence classes for sequential patterns. As a side-effect of considering conjunctions of sequences as the pattern type, we can easily form association rules between sequences. We believe that building a theoretical framework and an efficient approach for sequence association rules extraction problem is the first step toward the generalization of association rules to all complex and ordered patterns.

#index 1108834
#* Adequate Condensed Representations of Patterns
#@ Arnaud Soulet;Bruno Crémilleux
#t 2008
#c 22
#% 1083506
#! Patterns are at the core of the discovery of a lot of knowledge from data but their uses are limited due to their huge number and their mining cost. During the last decade, many works addressed the concept of condensed representation w.r.t. frequency queries. Such representations are several orders of magnitude smaller than the size of the whole collections of patterns, and also enable us to regenerate the frequency information of any pattern. Equivalence classes, based on the Galois closure, are at the core of the pattern condensed representations. However, in real-world applications, interestingness of patterns is evaluated by various many other user-defined measures (e.g., confidence, lift, minimum). To the best of our knowledge, these measures have received very little attention. The Galois closure is appropriate to frequency based measures but unfortunately not to other measures.

#index 1108835
#* Two Heads Better Than One: Pattern Discovery in Time-Evolving Multi-aspect Data
#@ Jimeng Sun;Charalampos E. Tsourakakis;Evan Hoke;Christos Faloutsos;Tina Eliassi-Rad
#t 2008
#c 22
#% 881493
#% 915297
#% 1083505
#! Data stream values are often associated with multiple aspects. For example, each value observed at a given time-stamp from environmental sensors may have an associated type (e.g., temperature, humidity, etc) as well as location. Time-stamp, type and location are the three aspects, which can be modeled using a tensor (high-order array). However, the time aspect is special, with a natural ordering, and with successive time-ticks having usually correlated values. Standard multiway analysis ignores this structure. To capture it, we propose 2 Heads Tensor Analysis(2-heads), which provides a qualitatively different treatment on time. Unlike most existing approaches that use a PCA-like summarization scheme for all aspects, 2-heads treats the time aspect carefully. 2-heads combines the power of classic multilinear analysis (PARAFAC [1], Tucker [5], DTA/STA [3], WTA [2]) with wavelets, leading to a powerful mining tool. Furthermore, 2-heads has several other advantages as well: (a) it can be computed incrementally in a streaming fashion, (b) it has a provable error guarantee and, (c) it achieves significant compression ratio against competitors. Finally, we show experiments on real datasets, and we illustrate how 2-heads reveals interesting trends in the data.This is an extended abstract of an article published in the Data Mining and Knowledge Discovery journal [4].

#index 1108836
#* TOPTMH: Topology Predictor for Transmembrane α-Helices
#@ Rezwan Ahmed;Huzefa Rangwala;George Karypis
#t 2008
#c 22
#% 269217
#% 471736
#% 950264
#! Alpha-helical transmembrane proteins mediate many key biological processes and represent 20%---30% of all genes in many organisms. Due to the difficulties in experimentally determining their high-resolution 3D structure, computational methods to predict the location and orientation of transmembrane helix segments using sequence information are essential. We present, TOPTMHa new transmembrane helix topology prediction method that combines support vector machines, hidden Markov models, and a widely-used rule-based scheme. The contribution of this work is the development of a prediction approach that first uses a binary SVM classifier to predict the helix residues and then it employs a pair of HMM models that incorporate the SVM predictions and hydropathy-based features to identify the entire transmembrane helix segments by capturing the structural characteristics of these proteins. TOPTMHoutperforms state-of-the-art prediction methods and achieves the best performance on an independent static benchmark.

#index 1108837
#* Learning to Predict One or More Ranks in Ordinal Regression Tasks
#@ Jaime Alonso;Juan José Coz;Jorge Díez;Oscar Luaces;Antonio Bahamonde
#t 2008
#c 22
#% 421460
#% 770800
#% 771846
#% 823317
#% 829028
#% 840853
#% 876081
#% 881477
#% 1014653
#% 1074350
#% 1673593
#! We present nondeterministic hypotheses learned from an ordinal regression task. They try to predict the true rank for an entry, but when the classification is uncertain the hypotheses predict a set of consecutive ranks (an interval). The aim is to keep the set of ranks as small as possible, while still containing the true rank. The justification for learning such a hypothesis is based on a real world problem arisen in breeding beef cattle. After defining a family of loss functions inspired in Information Retrieval, we derive an algorithm for minimizing them. The algorithm is based on posterior probabilities of ranks given an entry. A couple of implementations are compared: one based on a multiclass SVMand other based on Gaussian processes designed to minimize the linear loss in ordinal regression tasks.

#index 1108838
#* Cascade RSVM in Peer-to-Peer Networks
#@ Hock Hee Ang;Vivekanand Gopalkrishnan;Steven C. Hoi;Wee Keong Ng
#t 2008
#c 22
#% 190581
#% 414609
#% 424996
#% 466722
#% 552042
#% 738972
#% 875997
#% 881474
#% 888878
#% 915500
#% 926881
#% 945579
#% 989669
#% 1558464
#% 1742091
#% 1861262
#! The goal of distributed learning in P2P networks is to achieve results as close as possible to those from centralized approaches. Learning models of classification in a P2P network faces several challenges like scalability, peer dynamism, asynchronism and data privacy preservation. In this paper, we study the feasibility of building SVM classifiers in a P2P network. We show how cascading SVM can be mapped to a P2P network of data propagation. Our proposed P2P SVM provides a method for constructing classifiers in P2P networks with classification accuracy comparable to centralized classifiers and better than other distributed classifiers. The proposed algorithm also satisfies the characteristics of P2P computing and has an upper bound on the communication overhead. Extensive experimental results confirm the feasibility and attractiveness of this approach.

#index 1108839
#* An Algorithm for Transfer Learning in a Heterogeneous Environment
#@ Andreas Argyriou;Andreas Maurer;Massimiliano Pontil
#t 2008
#c 22
#% 236497
#% 723239
#% 829014
#% 916788
#% 961138
#% 961246
#% 983931
#% 1128929
#% 1271814
#! We consider the problem of learning in an environment of classification tasks. Tasks sampled from the environment are used to improve classification performance on future tasks. We consider situations in which the tasks can be divided into groups. Tasks within each group are related by sharing a low dimensional representation, which differs across the groups. We present an algorithm which divides the sampled tasks into groups and computes a common representation for each group. We report experiments on a synthetic and two image data sets, which show the advantage of the approach over single-task learning and a previous transfer learning method.

#index 1108840
#* Minimum-Size Bases of Association Rules
#@ José L. Balcázar
#t 2008
#c 22
#% 152934
#% 216972
#% 232136
#% 234797
#% 280433
#% 310520
#% 320946
#% 420062
#% 443427
#% 477636
#% 478770
#% 501193
#% 577216
#% 579314
#% 629704
#% 772329
#% 794935
#% 867053
#% 867057
#% 1663672
#! We focus on confidence-bounded association rules; we model a rather practical situation in which the confidence threshold is fixed by the user, as usually happens in applications. Within this model, we study notions of redundancy among association rules from a fundamental perspective: we discuss several existing alternative definitions and provide new characterizations and relationships between them. We show that these alternatives correspond actually to just two variants, which differ in the special treatment of full-confidence implications. For each of these two notions of redundancy, we show how to construct complete bases of absolutely minimum size.

#index 1108841
#* Combining Classifiers through Triplet-Based Belief Functions
#@ Yaxin Bi;Shengli Wu;Xuhui Shen;Pan Xiong
#t 2008
#c 22
#% 26348
#% 251145
#% 283145
#% 451221
#% 464782
#% 466572
#% 551721
#% 551723
#% 738972
#% 877399
#% 926881
#% 1075762
#% 1099526
#% 1250558
#% 1272353
#% 1273928
#% 1279286
#% 1289491
#! Classifier outputs in the form of continuous values have often been combined using linear sum or stacking, but little is generally known about evidential reasoning methods for combining truncated lists of ordered decisions. In this paper we introduce a novel class-indifferent method for combining such a kind of classifier decisions. Specifically we model each output given by classifiers on new instances as a list of ranked decisions that is divided into 2 subsets of decisions, which are represented by triplet-based belief functionsand then are combined using Dempster's rule of combination. We present a formalism for triplet-based belief functions and establish a range of general formulae for combining these beliefs in order to arrive at a consensus decision. In addition we carry out a comparative analysis with an alternative representation dichotomous belief functionson the UCI benchmark data. We also compare our combination method with the popular methods of stacking, boosting, linear sum and majority voting over the same benchmark data to demonstrate the advantage of our approach.

#index 1108842
#* An Improved Multi-task Learning Approach with Applications in Medical Diagnosis
#@ Jinbo Bi;Tao Xiong;Shipeng Yu;Murat Dundar;R. Bharat Rao
#t 2008
#c 22
#% 236497
#% 466750
#% 529216
#% 735256
#% 769886
#% 770848
#% 840962
#% 916788
#% 989679
#! We propose a family of multi-task learning algorithms for collaborative computer aided diagnosis which aims to diagnose multiple clinically-related abnormal structures from medical images. Our formulations eliminate features irrelevant to all tasks, and identify discriminative features for each of the tasks. A probabilistic model is derived to justify the proposed learning formulations. By equivalence proof, some existing regularization-based methods can also be interpreted by our probabilistic model as imposing a Wishart hyperprior. Convergence analysis highlights the conditions under which the formulations achieve convexity and global convergence. Two real-world medical problems: lung cancer prognosis and heart wall motion analysis, are used to validate the proposed algorithms.

#index 1108843
#* Semi-supervised Laplacian Regularization of Kernel Canonical Correlation Analysis
#@ Matthew B. Blaschko;Christoph H. Lampert;Arthur Gretton
#t 2008
#c 22
#% 375017
#% 722887
#% 855563
#% 893386
#% 916797
#% 961215
#% 961218
#% 961258
#% 983591
#% 1667643
#! Kernel canonical correlation analysis (KCCA) is a fundamental technique for dimensionality reduction for paired data. By finding directions that maximize correlation in the space implied by the kernel, KCCA is able to learn representations that are more closely tied to the underlying semantics of the data rather than high variance directions, which are found by PCA but may be the result of noise. However, meaningful directions are not only those that have high correlation to another modality, but also those that capture the manifold structure of the data. We propose a method that is able to simultaneously find highly correlated directions that are also located on high variance directions along the data manifold. This is achieved by the use of semi-supervised Laplacian regularization in the formulation of KCCA, which has the additional benefit of being able to use additional data for which correspondence between the modalities is not known to more robustly estimate the structure of the data manifold. We show experimentally on datasets of images and text that Laplacian regularized training improves the class separation over KCCA with only Tikhonov regularization, while causing no degradation in the correlation between modalities. We propose a model selection criterion based on the Hilbert-Schmidt norm of the semi-supervised Laplacian regularized cross-covariance operator, which can be computed in closed form. Kernel canonical correlation analysis (KCCA) is a dimensionality reduction technique for paired data. By finding directions that maximize correlation, KCCA learns representations that are more closely tied to the underlying semantics of the data rather than noise. However, meaningful directions are not only those that have high correlation to another modality, but also those that capture the manifold structure of the data. We propose a method that is simultaneously able to find highly correlated directions that are also located on high variance directions along the data manifold. This is achieved by the use of semi-supervised Laplacian regularization of KCCA. We show experimentally that Laplacian regularized training improves class separation over KCCA with only Tikhonov regularization, while causing no degradation in the correlation between modalities. We propose a model selection criterion based on the Hilbert-Schmidt norm of the semi-supervised Laplacian regularized cross-covariance operator, which we compute in closed form.

#index 1108844
#* Sequence Labelling SVMs Trained in One Pass
#@ Antoine Bordes;Nicolas Usunier;Léon Bottou
#t 2008
#c 22
#% 216079
#% 722822
#% 816181
#% 816186
#% 829043
#% 840856
#% 853701
#% 854636
#% 916781
#% 961152
#% 983815
#% 1000328
#% 1815223
#! This paper proposes an online solver of the dual formulation of support vector machines for structured output spaces. We apply it to sequence labelling using the exact and greedy inference schemes. In both cases, the per-sequence training time is the same as a perceptron based on the same inference procedure, up to a small multiplicative constant. Comparing the two inference schemes, the greedy version is much faster. It is also amenable to higher order Markov assumptions and performs similarly on test. In comparison to existing algorithms, both versions match the accuracies of batch solvers that use exact inference after a single pass over the training examples.

#index 1108845
#* Semi-supervised Classification from Discriminative Random Walks
#@ Jérôme Callut;Kevin Françoisse;Marco Saerens;Pierre Dupont
#t 2008
#c 22
#% 137711
#% 833012
#% 840965
#% 961278
#% 1682572
#! This paper describes a novel technique, called $\mathcal{D}$-walks, to tackle semi-supervised classification problems in large graphs. We introduce here a betweenness measure based on passage times during random walks of bounded lengths. Such walks are further constrained to start and end in nodes within the same class, defining a distinct betweenness for each class. Unlabeled nodes are classified according to the class showing the highest betweenness. Forward and backward recurrences are derived to efficiently compute the passage times. $\mathcal{D}$-walks can deal with directed or undirected graphs with a linear time complexity with respect to the number of edges, the maximum walk length considered and the number of classes. Experiments on various real-life databases show that $\mathcal{D}$-walks outperforms NetKit [5], the approach of Zhou and Schölkopf [15] and the regularized laplacian kernel [2]. The benefit of $\mathcal{D}$-walks is particularly noticeable when few labeled nodes are available. The computation time of $\mathcal{D}$-walks is also substantially lower in all cases.

#index 1108846
#* Learning Bidirectional Similarity for Collaborative Filtering
#@ Bin Cao;Jian-Tao Sun;Jianmin Wu;Qiang Yang;Zheng Chen
#t 2008
#c 22
#% 132779
#% 173879
#% 213101
#% 274193
#% 280852
#% 330687
#% 397153
#% 420539
#% 652436
#% 734592
#% 734594
#% 766432
#% 766449
#% 813966
#% 818216
#% 836266
#% 879627
#% 957360
#% 987197
#% 1650569
#! Memory-based collaborative filtering aims at predicting the utility of a certain item for a particular user based on the previous ratings from similar users and similar items. Previous studies in finding similar users and items are based on user-defined similarity metrics such as Pearson Correlation Coefficient or Vector Space Similarity which are not adaptive and optimized for different applications and datasets. Moreover, previous studies have treated the similarity function calculation between users and items separately. In this paper, we propose a novel adaptive bidirectional similarity metricfor collaborative filtering. We automatically learn similarities between users and items simultaneously through matrix factorization. We show that our model naturally extends the memory based approaches. Theoretical analysis shows our model to be a novel generalization of the SVD model. We evaluate our method using three benchmark datasets, including MovieLens, EachMovie and Netflix, through which we show that our methods outperform many previous baselines.

#index 1108847
#* Bootstrapping Information Extraction from Semi-structured Web Pages
#@ Andrew Carlson;Charles Schafer
#t 2008
#c 22
#% 271065
#% 278109
#% 330784
#% 342703
#% 346637
#% 465919
#% 577319
#% 729978
#% 786511
#% 788941
#% 800497
#% 805846
#% 1272397
#! We consider the problem of extracting structured records from semi-structured web pages with no human supervision required for each target web site. Previous work on this problem has either required significant human effort for each target site or used brittle heuristics to identify semantic data types. Our method only requires annotation for a few pages from a few sites in the target domain. Thus, after a tiny investment of human effort, our method allows automatic extraction from potentially thousands of other sites within the same domain. Our approach extends previous methods for detecting data fields in semi-structured web pages by matching those fields to domain schema columns using robust models of data values and contexts. Annotating 2---5 pages for 4---6 web sites yields an extraction accuracy of 83.8% on job offer sites and 91.1% on vacation rental sites. These results significantly outperform a baseline approach.

#index 1108848
#* Online Multiagent Learning against Memory Bounded Adversaries
#@ Doran Chakraborty;Peter Stone
#t 2008
#c 22
#% 266286
#% 464281
#% 528018
#% 557575
#% 722895
#% 823853
#% 890316
#% 890325
#% 1289288
#% 1289481
#! The traditional agenda in Multiagent Learning (MAL) has been to develop learners that guarantee convergence to an equilibrium in self-play or that converge to playing the best response against an opponent using one of a fixed setof known targeted strategies. This paper introduces an algorithm called Learn or Exploit for Adversary Induced Markov Decision Process (LoE-AIM) that targets optimality against any learning opponent that can be treated as a memory bounded adversary. LoE-AIMmakes no prior assumptions about the opponent and is tailored to optimally exploit any adversary which induces a Markov decision process in the state space of joint histories. LoE-AIMeither explores and gathers new information about the opponent or converges to the best response to the partially learned opponent strategy in repeated play. We further extend LoE-AIMto account for online repeated interactions against the same adversary with plays against other adversaries interleaved in between. LoE-AIM-repeatedstores learned knowledge about an adversary, identifies the adversary in case of repeated interaction, and reuses the stored knowledge about the behavior of the adversary to enhance learning in the current epoch of play. LoE-AIM and LoE-AIM-repeated are fully implemented, with results demonstrating their superiority over other existing MAL algorithms.

#index 1108849
#* Scalable Feature Selection for Multi-class Problems
#@ Boris Chidlovskii;Loïc Lecerf
#t 2008
#c 22
#% 169659
#% 243728
#% 464444
#% 466410
#% 466912
#% 501651
#% 793239
#% 796212
#% 818938
#% 876051
#% 928386
#% 987243
#% 1274940
#! Scalable feature selection algorithms should remove irrelevant and redundant features and scale well on very large datasets. We identify that the currently best state-of-art methods perform well on binary classification tasks but often underperform on multi-class tasks. We suggest that they suffer from the so-called accumulative effect which becomes more visible with the growing number of classes and results in removing relevant and unredundant features. To remedy the problem, we propose two new feature filtering methods which are both scalable and well adapted for the multi-class cases. We report the evaluation results on 17 different datasets which include both binary and multi-class cases.

#index 1108850
#* Learning Decision Trees for Unbalanced Data
#@ David A. Cieslak;Nitesh V. Chawla
#t 2008
#c 22
#% 260149
#% 272995
#% 449588
#% 464280
#% 466758
#% 466760
#% 580510
#% 765521
#% 793059
#% 961134
#% 983921
#% 1085130
#% 1271973
#% 1289281
#% 1558464
#! Learning from unbalanced datasets presents a convoluted problem in which traditional learning algorithms may perform poorly. The objective functions used for learning the classifiers typically tend to favor the larger, less important classes in such problems. This paper compares the performance of several popular decision tree splitting criteria --- information gain, Gini measure, and DKM --- and identifies a new skew insensitive measure in Hellinger distance. We outline the strengths of Hellinger distance in class imbalance, proposes its application in forming decision trees, and performs a comprehensive comparative analysis between each decision tree construction method. In addition, we consider the performance of each tree within a powerful sampling wrapper framework to capture the interaction of the splitting metric and sampling. We evaluate over this wide range of datasets and determine which operate best under class imbalance.

#index 1108851
#* Credal Model Averaging: An Extension of Bayesian Model Averaging to Imprecise Probabilities
#@ Giorgio Corani;Marco Zaffalon
#t 2008
#c 22
#% 464610
#% 1014661
#% 1074358
#! We deal with the arbitrariness in the choice of the prior over the models in Bayesian model averaging(BMA), by modelling prior knowledge by a set of priors (i.e., a prior credal set). We consider Dash and Cooper's BMA applied to naive Bayesian networks, replacing the single prior over the naive models by a credal set; this models a condition close to prior ignorance about the models, which leads to credal model averaging(CMA). CMA returns an indeterminateclassification, i.e., multiple classes, on the instances for which the learning set is not informative enough to smooth the effect of the choice of the prior. We give an algorithm to compute exact credal model averaging for naive networks. Extensive experiments show that indeterminate classifications preserve the reliability of CMA on the instances which are classified in a prior-dependent way by BMA.

#index 1108852
#* A Fast Method for Training Linear SVM in the Primal
#@ Trinh-Minh-Tri Do;Thierry Artières
#t 2008
#c 22
#% 269217
#% 592108
#% 722758
#% 770754
#% 770763
#% 803575
#% 881477
#% 916781
#% 959454
#% 983905
#% 989644
#! We propose a new algorithm for training a linear Support Vector Machine in the primal. The algorithm mixes ideas from non smooth optimization, subgradient methods, and cutting planes methods. This yields a fast algorithm that compares well to state of the art algorithms. It is proved to require O(1/茂戮驴茂戮驴) iterations to converge to a solution with accuracy 茂戮驴. Additionally we provide an exact shrinking method in the primal that allows reducing the complexity of an iteration to much less than O(N) where Nis the number of training samples.

#index 1108853
#* On the Equivalence of the SMO and MDM Algorithms for SVM Training
#@ Jorge López;Álvaro Barbero;José R. Dorronsoro
#t 2008
#c 22
#% 190581
#% 269217
#% 269218
#% 393059
#% 431295
#% 466589
#% 855583
#% 856251
#% 916790
#% 1002500
#% 1026322
#% 1676296
#% 1810960
#% 1860609
#! SVM training is usually discussed under two different algorithmic points of view. The first one is provided by decomposition methods such as SMO and SVMLight while the second one encompasses geometric methods that try to solve a Nearest Point Problem (NPP), the Gilbert---Schlesinger---Kozinec (GSK) and Mitchell---Demyanov---Malozemov (MDM) algorithms being the most representative ones. In this work we will show that, indeed, both approaches are essentially coincident. More precisely, we will show that a slight modification of SMO in which at each iteration both updating multipliers correspond to patterns in the same class solves NPP and, moreover, that this modification coincides with an extended MDM algorithm. Besides this, we also propose a new way to apply the MDM algorithm for NPP problems over reduced convex hulls.

#index 1108854
#* Nearest Neighbour Classification with Monotonicity Constraints
#@ Wouter Duivesteijn;Ad Feelders
#t 2008
#c 22
#% 59121
#% 99896
#% 182684
#% 252020
#% 272541
#% 349150
#% 408396
#% 998782
#% 1650644
#! In many application areas of machine learning, prior knowledge concerning the monotonicity of relations between the response variable and predictor variables is readily available. Monotonicity may also be an important model requirement with a view toward explaining and justifying decisions, such as acceptance/rejection decisions. We propose a modified nearest neighbour algorithm for the construction of monotone classifiers from data. We start by making the training data monotone with as few label changes as possible. The relabeled data set can be viewed as a monotone classifier that has the lowest possible error-rate on the training data. The relabeled data is subsequently used as the training sample by a modified nearest neighbour algorithm. This modified nearest neighbour rule produces predictions that are guaranteed to satisfy the monotonicity constraints. Hence, it is much more likely to be accepted by the intended users. Our experiments show that monotone kNN often outperforms standard kNN in problems where the monotonicity constraints are applicable.

#index 1108855
#* Modeling Transfer Relationships Between Learning Tasks for Improved Inductive Transfer
#@ Eric Eaton;Marie Desjardins;Terran Lane
#t 2008
#c 22
#% 169358
#% 174255
#% 290482
#% 723239
#% 732552
#% 876002
#% 916799
#! In this paper, we propose a novel graph-based method for knowledge transfer. We model the transfer relationships between source tasks by embedding the set of learned source models in a graph using transferability as the metric. Transfer to a new problem proceeds by mapping the problem into the graph, then learning a function on this graph that automatically determines the parameters to transfer to the new learning task. This method is analogous to inductive transfer along a manifold that captures the transfer relationships between the tasks. We demonstrate improved transfer performance using this method against existing approaches in several real-world domains.

#index 1108856
#* Mining Edge-Weighted Call Graphs to Localise Software Bugs
#@ Frank Eichinger;Klemens Böhm;Matthias Huber
#t 2008
#c 22
#% 48756
#% 136350
#% 136544
#% 210160
#% 231941
#% 581051
#% 629603
#% 629708
#% 641172
#% 729938
#% 769951
#% 800607
#% 868145
#% 871465
#% 889503
#% 911720
#% 926881
#% 985041
#! An important problem in software engineering is the automated discovery of noncrashing occasional bugs. In this work we address this problem and show that mining of weighted call graphs of program executions is a promising technique. We mine weighted graphs with a combination of structural and numerical techniques. More specifically, we propose a novel reduction technique for call graphs which introduces edge weights. Then we present an analysis technique for such weighted call graphs based on graph mining and on traditional feature selection schemes. The technique generalises previous graph mining approaches as it allows for an analysis of weights. Our evaluation shows that our approach finds bugs which previous approaches cannot detect so far. Our technique also doubles the precision of finding bugs which existing techniques can already localise in principle.

#index 1108857
#* Hierarchical Distance-Based Conceptual Clustering
#@ Ana Maria Funes;Cesar Ferri;Jose Hernández-Orallo;Maria Jose Ramírez-Quintana
#t 2008
#c 22
#% 131422
#% 296738
#% 324276
#% 451052
#% 466073
#% 550396
#% 1290272
#! In this work we analyse the relation between hierarchical distance-based clustering and the concepts that can be obtained from the hierarchy by generalisation. Many inconsistencies may arise, because the distance and the conceptual generalisation operator are usually incompatible. To overcome this, we propose an algorithm which integrates distance-based and conceptual clustering. The new dendrograms can show when an element has been integrated to the cluster because it is near in the metric space or because it is covered by the concept. In this way, the new clustering can differ from the original one but the metric traceability is clear. We introduce three different levels of agreement between the clustering hierarchy obtained from the linkage distance and the new hierarchy, and we define properties these generalisation operators should satisfy in order to produce distance-consistent dendrograms.

#index 1108858
#* Mining Frequent Connected Subgraphs Reducing the Number of Candidates
#@ Andrés Gago Alonso;José Eladio Medina Pagola;Jesús Ariel Carrasco-Ochoa;José Fco. Martínez-Trinidad
#t 2008
#c 22
#% 466644
#% 478274
#% 481290
#% 629603
#% 629708
#% 727845
#% 769951
#% 985041
#% 1273674
#% 1673586
#! In this paper, a new algorithm for mining frequent connected subgraphs called gRed (graph Candidate Reduction Miner) is presented. This algorithm is based on the gSpan algorithm proposed by Yan and Jan. In this method, the mining process is optimized introducing new heuristics to reduce the number of candidates. The performance of gRed is compared against two of the most popular and efficient algorithms available in the literature (gSpan and Gaston). The experimentation on real world databases shows the performance of our proposal overcoming gSpan, and achieving better performance than Gaston for low minimal support when databases are large.

#index 1108859
#* Unsupervised Riemannian Clustering of Probability Density Functions
#@ Alvina Goh;René Vidal
#t 2008
#c 22
#% 3084
#% 723241
#% 782625
#% 796237
#% 845568
#% 938920
#% 1719881
#! We present an algorithm for grouping families of probability density functions (pdfs). We exploit the fact that under the square-root re-parametrization, the space of pdfs forms a Riemannian manifold, namely the unit Hilbert sphere. An immediate consequence of this re-parametrization is that different families of pdfs form different submanifolds of the unit Hilbert sphere. Therefore, the problem of clustering pdfs reduces to the problem of clustering multiple submanifolds on the unit Hilbert sphere. We solve this problem by first learning a low-dimensional representation of the pdfs using generalizations of local nonlinear dimensionality reduction algorithms from Euclidean to Riemannian spaces. Then, by assuming that the pdfs from different groups are separated, we show that the null space of a matrix built from the local representation gives the segmentation of the pdfs. We also apply of our approach to the texture segmentation problem in computer vision.

#index 1108860
#* Online Manifold Regularization: A New Learning Setting and Empirical Study
#@ Andrew B. Goldberg;Ming Li;Xiaojin Zhu
#t 2008
#c 22
#% 252011
#% 425062
#% 466263
#% 771841
#% 803575
#% 840938
#% 875962
#% 961195
#% 961218
#% 1699580
#% 1759695
#% 1815223
#! We consider a novel "online semi-supervised learning" setting where (mostly unlabeled) data arrives sequentially in large volume, and it is impractical to store it all before learning. We propose an online manifold regularization algorithm. It differs from standard online learning in that it learns even when the input point is unlabeled. Our algorithm is based on convex programming in kernel space with stochastic gradient descent, and inherits the theoretical guarantees of standard online algorithms. However, naïve implementation of our algorithm does not scale well. This paper focuses on efficient, practical approximations; we discuss two sparse approximations using buffering and online random projection trees. Experiments show our algorithm achieves risk and generalization accuracy comparable to standard batch manifold regularization, while each step runs quickly. Our online semi-supervised learning setting is an interesting direction for further theoretical development, paving the way for semi-supervised learning to work on real-world life-long learning tasks.

#index 1108861
#* A Fast Algorithm to Find Overlapping Communities in Networks
#@ Steve Gregory
#t 2008
#c 22
#% 905901
#% 956685
#% 989654
#% 1100134
#% 1396208
#% 1684518
#% 1719412
#! Many networks possess a community structure, such that vertices form densely connected groups which are more sparsely linked to other groups. In some cases these groups overlap, with some vertices shared between two or more communities. Discovering communities in networks is a computationally challenging task, especially if they overlap. In previous work we proposed an algorithm, CONGA, that could detect overlapping communities using the new concept of split betweenness. Here we present an improved algorithm based on a localform of betweenness, which yields good results but is much faster. It is especially effective in discovering small-diameter communities in large networks, and has a time complexity of only O(nlog n) for sparse networks.

#index 1108862
#* A Case Study in Sequential Pattern Mining for IT-Operational Risk
#@ Valerio Grossi;Andrea Romei;Salvatore Ruggieri
#t 2008
#c 22
#% 342666
#% 459006
#% 1054313
#! IT-operational risk management consists of identifying, assessing, monitoring and mitigating the adverse risks of loss resulting from hardware and software system failures. We present a case study in IT-operational risk measurement in the context of a network of Private Branch eXchanges (PBXs). The approach relies on preprocessing and data mining tasks for the extraction of sequential patterns and their exploitation in the definition of a measure called expected risk.

#index 1108863
#* Tight Optimistic Estimates for Fast Subgroup Discovery
#@ Henrik Grosskreutz;Stefan Rüping;Stefan Wrobel
#t 2008
#c 22
#% 208180
#% 232126
#% 300120
#% 310554
#% 477497
#% 478613
#% 729418
#% 757953
#% 763701
#% 768667
#% 878169
#% 1272179
#% 1393191
#% 1663617
#! Subgroup discovery is the task of finding subgroups of a population which exhibit both distributional unusualness and high generality. Due to the non monotonicity of the corresponding evaluation functions, standard pruning techniques cannot be used for subgroup discovery, requiring the use of optimistic estimate techniques instead. So far, however, optimistic estimate pruning has only been considered for the extremely simple case of a binary target attribute and up to now no attempt was made to move beyond suboptimal heuristic optimistic estimates. In this paper, we show that optimistic estimate pruning can be developed into a sound and highly effective pruning approach for subgroup discovery. Based on a precise definition of optimality we show that previous estimates have been tight only in special cases. Thereafter, we present tight optimistic estimates for the most popular binary and multi-class quality functions, and present a family of increasingly efficient approximations to these optimal functions. As we show in empirical experiments, the use of our newly proposed optimistic estimates can lead to a speed up of an order of magnitude compared to previous approaches.

#index 1108864
#* Watch, Listen & Learn: Co-training on Captioned Images and Videos
#@ Sonal Gupta;Joohyun Kim;Kristen Grauman;Raymond Mooney
#t 2008
#c 22
#% 252011
#% 304876
#% 311027
#% 316509
#% 387427
#% 457912
#% 466263
#% 581658
#% 658871
#% 722927
#% 724184
#% 724289
#% 755467
#% 775269
#% 784995
#% 792603
#% 812418
#% 826289
#% 836851
#% 839912
#% 840066
#% 905395
#% 926881
#% 940447
#% 996170
#% 1265076
#% 1410100
#! Recognizing visual scenes and activities is challenging: often visual cues alone are ambiguous, and it is expensive to obtain manually labeled examples from which to learn. To cope with these constraints, we propose to leverage the text that often accompanies visual data to learn robust models of scenes and actions from partially labeled collections. Our approach uses co-training, a semi-supervised learning method that accommodates multi-modal views of data. To classify images, our method learns from captioned images of natural scenes; and to recognize human actions, it learns from videos of athletic events with commentary. We show that by exploiting both multi-modal representations and unlabeled data our approach learns more accurate image and video classifiers than standard baseline algorithms.

#index 1108865
#* Parameter Learning in Probabilistic Databases: A Least Squares Approach
#@ Bernd Gutmann;Angelika Kimmig;Kristian Kersting;Luc Raedt
#t 2008
#c 22
#% 3873
#% 33376
#% 171477
#% 342705
#% 376266
#% 379345
#% 496116
#% 731606
#% 893168
#% 1016201
#% 1026554
#% 1100058
#% 1269477
#% 1272279
#% 1272388
#% 1275150
#% 1415855
#% 1416204
#% 1476274
#% 1692830
#! We introduce the problem of learning the parameters of the probabilistic database ProbLog. Given the observed success probabilities of a set of queries, we compute the probabilities attached to facts that have a low approximation error on the training examples as well as on unseen examples. Assuming Gaussian error terms on the observed success probabilities, this naturally leads to a least squares optimization problem. Our approach, called LeProbLog, is able to learn both from queries and from proofs and even from both simultaneously. This makes it flexible and allows faster training in domains where the proofs are available. Experiments on real world data show the usefulness and effectiveness of this least squares calibration of probabilistic databases.

#index 1108866
#* Improving k-Nearest Neighbour Classification with Distance Functions Based on Receiver Operating Characteristics
#@ Md. Rafiul Hassan;M. Maruf Hossain;James Bailey;Kotagiri Ramamohanarao
#t 2008
#c 22
#% 126894
#% 136350
#% 169659
#% 209623
#% 464606
#% 464608
#% 499537
#% 501975
#% 515972
#% 769917
#% 940381
#% 1378224
#% 1669879
#% 1861531
#! The k-nearest neighbour (k-NN) technique, due to its interpretable nature, is a simple and very intuitively appealing method to address classification problems. However, choosing an appropriate distance function for k-NN can be challenging and an inferior choice can make the classifier highly vulnerable to noise in the data. In this paper, we propose a new method for determining a good distance function for k-NN. Our method is based on consideration of the area under the Receiver Operating Characteristics (ROC) curve, which is a well known method to measure the quality of binary classifiers. It computes weights for the distance function, based on ROC properties within an appropriate neighbourhood for the instances whose distance is being computed. We experimentally compare the effect of our scheme with a number of other well-known k-NN distance metrics, as well as with a range of different classifiers. Experiments show that our method can substantially boost the classification performance of the k-NN algorithm. Furthermore, in a number of cases our technique is even able to deliver better accuracy than state-of-the-art non k-NN classifiers, such as support vector machines.

#index 1108867
#* One-Class Classification by Combining Density and Class Probability Estimation
#@ Kathryn Hempstalk;Eibe Frank;Ian H. Witten
#t 2008
#c 22
#% 302812
#% 527928
#% 551874
#% 580510
#% 825887
#% 853599
#% 881506
#% 1558464
#! One-class classification has important applications such as outlier and novelty detection. It is commonly tackled using density estimation techniques or by adapting a standard classification algorithm to the problem of carving out a decision boundary that describes the location of the target data. In this paper we investigate a simple method for one-class classification that combines the application of a density estimator, used to form a reference distribution, with the induction of a standard model for class probability estimation. In this method, the reference distribution is used to generate artificial data that is employed to form a second, artificial class. In conjunction with the target class, this artificial class is the basis for a standard two-class learning problem. We explain how the density function of the reference distribution can be combined with the class probability estimates obtained in this way to form an adjusted estimate of the density function of the target class. Using UCI datasets, and data from a typist recognition problem, we show that the combined model, consisting of both a density estimator and a class probability estimator, can improve on using either component technique alone when used for one-class classification. We also compare the method to one-class classification using support vector machines.

#index 1108868
#* Efficient Frequent Connected Subgraph Mining in Graphs of Bounded Treewidth
#@ Tamás Horváth;Jan Ramon
#t 2008
#c 22
#% 39702
#% 56706
#% 129187
#% 212285
#% 219474
#% 263371
#% 408396
#% 813990
#% 881475
#% 944956
#% 955663
#% 1096512
#! The frequent connected subgraph mining problem, i.e., the problem of listing all connected graphs that are subgraph isomorphic to at least a certain number of transaction graphs of a database, cannot be solved in output polynomial time in the general case. If, however, the transaction graphs are restricted to forests then the problem becomes tractable. In this paper we generalize the positive result on forests to graphs of bounded treewidth. In particular, we show that for this class of transaction graphs, frequent connected subgraphs can be listed in incremental polynomial time. Since subgraph isomorphism remains NP-complete for bounded treewidth graphs, the positive complexity result of this paper shows that efficient frequent pattern mining is possible even for computationally hard pattern matching operators.

#index 1108869
#* Proper Model Selection with Significance Test
#@ Jin Huang;Charles X. Ling;Harry Zhang;Stan Matwin
#t 2008
#c 22
#% 90661
#% 229806
#% 349550
#% 769882
#% 770822
#% 837668
#% 1100069
#% 1100083
#% 1279288
#! Model selection is an important and ubiquitous task in machine learning. To select models with the best future classification performance measured by a goal metric, an evaluation metricis often used to select the best classification model among the competing ones. A common practice is to use the same goal and evaluation metric. However, in several recent studies, it is claimed that using an evaluation metric (such as AUC) other than the goal metric (such as accuracy) results in better selection of the correct models. In this paper, we point out a flaw in the experimental design of those studies, and propose an improved method to test the claim. Our extensive experiments show convincingly that only the goal metric itself can most reliably select the correct classification models.

#index 1108870
#* A Projection-Based Framework for Classifier Performance Evaluation
#@ Nathalie Japkowicz;Pritika Sanghi;Peter Tischer
#t 2008
#c 22
#% 296375
#% 743674
#% 893461
#% 1010961
#! In this paper, we propose approaching the problem of classifier evaluation in terms of a projection from a high-dimensional space to a visualizable two-dimensional one. Rather than collapsing confusion matrices into a single measure the way traditional evaluation methods do, we consider the vector composed of the entries of the confusion matrix (or the confusion matrices in case several domains are considered simultaneously) as the performance evaluation vector, and project it into a two dimensional space using a recently proposed distance-preserving projection method. This approach is shown to be particularly useful in the case of comparison of several classifiers on many domains as well as in the case of multiclass classification. Furthermore, by providing simultaneous multiple views of the same evaluation data, it allows for a quick and accurate assessment of classifier performance.

#index 1108871
#* Distortion-Free Nonlinear Dimensionality Reduction
#@ Yangqing Jia;Zheng Wang;Changshui Zhang
#t 2008
#c 22
#% 143194
#% 313959
#% 593047
#% 790049
#% 871628
#% 989597
#% 1705533
#! Nonlinear Dimensionality Reduction is an important issue in many machine learning areas where essentially low-dimensional data is nonlinearly embedded in some high-dimensional space. In this paper, we show that the existing Laplacian Eigenmaps method suffers from the distortion problem, and propose a new distortion-free dimensionality reduction method by adopting a local linear model to encode the local information. We introduce a new loss function that can be seen as a different way to construct the Laplacian matrix, and a new way to impose scaling constraints under the local linear model. Better low-dimensional embeddings are obtained via constrained concave convex procedure. Empirical studies and real-world applications have shown the effectiveness of our method.

#index 1108872
#* Learning with Lq
#@ Ata Kabán;Robert J. Durrant
#t 2008
#c 22
#% 277467
#% 387653
#% 466084
#% 722760
#% 722806
#% 722943
#% 770857
#% 803771
#% 982755
#! We study the use of fractional norms for regularisation in supervised learning from high dimensional data, in conditions of a large number of irrelevant features, focusing on logistic regression. We develop a variational method for parameter estimation, and show an equivalence between two approximations recently proposed in the statistics literature. Building on previous work by A.Ng, we show the fractional norm regularised logistic regression enjoys a sample complexity that grows logarithmically with the data dimensions and polynomially with the number of relevant dimensions. In addition, extensive empirical testing indicates that fractional-norm regularisation is more suitable than L1 in cases when the number of relevant features is very small, and works very well despite a large number of irrelevant features.

#index 1108873
#* Catenary Support Vector Machines
#@ Kin Fai Kan;Christian R. Shelton
#t 2008
#c 22
#% 416553
#% 722909
#% 812485
#% 840959
#% 875970
#% 881563
#! Many problems require making sequential decisions. For these problems, the benefit of acquiring further information must be weighed against the costs. In this paper, we describe the catenary support vector machine(catSVM), a margin-based method to solve sequential stopping problems. We provide theoretical guarantees for catSVM on future testing examples. We evaluated the performance of catSVM on UCI benchmark data and also applied it to the task of face detection. The experimental results show that catSVM can achieve a better cost tradeoff than single-stage SVM and chained boosting.

#index 1108874
#* Exact and Approximate Inference for Annotating Graphs with Structural SVMs
#@ Thoralf Klein;Ulf Brefeld;Tobias Scheffer
#t 2008
#c 22
#% 44876
#% 722816
#% 770759
#% 829043
#% 840882
#% 1196821
#% 1650318
#% 1650403
#! Training processes of structured prediction models such as structural SVMs involve frequent computations of the maximum-a-posteriori(MAP) prediction given a parameterized model. For specific output structures such as sequences or trees, MAP estimates can be computed efficiently by dynamic programming algorithms such as the Viterbi algorithm and the CKY parser. However, when the output structures can be arbitrary graphs, exact calculation of the MAP estimate is an NP-complete problem. In this paper, we compare exact inference and approximate inference for labeling graphs. We study the exact junction tree and the approximate loopy belief propagation and sampling algorithms in terms of performance and ressource requirements.

#index 1108875
#* Extracting Semantic Networks from Text Via Relational Clustering
#@ Stanley Kok;Pedro Domingos
#t 2008
#c 22
#% 26722
#% 44876
#% 266215
#% 310516
#% 727814
#% 729918
#% 850430
#% 938705
#% 939602
#% 940029
#% 983858
#% 1002100
#% 1250397
#% 1250567
#% 1275182
#! Extracting knowledge from text has long been a goal of AI. Initial approaches were purely logical and brittle. More recently, the availability of large quantities of text on the Web has led to the development of machine learning approaches. However, to date these have mainly extracted ground facts, as opposed to general knowledge. Other learning approaches can extract logical forms, but require supervision and do not scale. In this paper we present an unsupervised approach to extracting semantic networks from large volumes of text. We use the TextRunner system [1] to extract tuples from text, and then induce general concepts and relations from them by jointly clustering the objects and relational strings in the tuples. Our approach is defined in Markov logic using four simple rules. Experiments on a dataset of two million tuples show that it outperforms three other relational clustering approaches, and extracts meaningful semantic networks.

#index 1108876
#* Ranking the Uniformity of Interval Pairs
#@ Jussi Kujala;Tapio Elomaa
#t 2008
#c 22
#% 115608
#% 246831
#% 278833
#% 420054
#% 458174
#% 464618
#% 529493
#% 593043
#% 741335
#% 934581
#% 1100142
#% 1290032
#% 1712966
#! We study the problem of finding the most uniform partition of the class label distribution on an interval. This problem occurs, e.g., in supervised discretization of continuous features, where evaluation heuristics need to find the location of the best place to split the current feature. The weighted average of empirical entropies of the interval label distributions is often used in this task. We observe that this rule is suboptimal, because it prefers short intervals too much. Therefore, we proceed to study alternative approaches. A solution that is based on compression turns out to be the best in our empirical experiments. We also study how these alternative methods affect the performance of classification algorithms.

#index 1108877
#* Multiagent Reinforcement Learning for Urban Traffic Control Using Coordination Graphs
#@ Lior Kuyer;Shimon Whiteson;Bram Bakker;Nikos Vlassis
#t 2008
#c 22
#% 160859
#% 466726
#% 565550
#% 580307
#% 961198
#% 1196891
#% 1272302
#% 1672996
#% 1810385
#! Since traffic jams are ubiquitous in the modern world, optimizing the behavior of traffic lights for efficient traffic flow is a critically important goal. Though most current traffic lights use simple heuristic protocols, more efficient controllers can be discovered automatically via multiagent reinforcement learning, where each agent controls a single traffic light. However, in previous work on this approach, agents select only locally optimal actions without coordinating their behavior. This paper extends this approach to include explicit coordination between neighboring traffic lights. Coordination is achieved using the max-plus algorithm, which estimates the optimal joint action by sending locally optimized messages among connected agents. This paper presents the first application of max-plus to a large-scale problem and thus verifies its efficacy in realistic settings. It also provides empirical evidence that max-plus performs well on cyclic graphs, though it has been proven to converge only for tree-structured graphs. Furthermore, it provides a new understanding of the properties a traffic network must have for such coordination to be beneficial and shows that max-plus outperforms previous methods on networks that possess those properties.

#index 1108878
#* StreamKrimp: Detecting Change in Data Streams
#@ Matthijs Leeuwen;Arno Siebes
#t 2008
#c 22
#% 204531
#% 654489
#% 777933
#% 918001
#% 989648
#% 1016144
#% 1030788
#% 1117002
#% 1117081
#! Data streams are ubiquitous. Examples range from sensor networks to financial transactions and website logs. In fact, even market basket data can be seen as a stream of sales. Detecting changes in the distribution a stream is sampled from is one of the most challenging problems in stream mining, as only limited storage can be used. In this paper we analyse this problem for streams of transaction data from an MDL perspective. Based on this analysis we introduce the StreamKrimpalgorithm, whichuses the Krimpalgorithm to characterise probability distributions with code tables. With these code tables, StreamKrimppartitions the stream into a sequence of substreams. Each switch of code table indicates a change in the underlying distribution. Experiments on both real and artificial streams show that StreamKrimpdetects the changes while using only a very limited amount of data storage.

#index 1108879
#* Proceedings of the European conference on Machine Learning and Knowledge Discovery in Databases - Part II
#@ Walter Daelemans;Bart Goethals;Katharina Morik
#t 2008
#c 22

#index 1108880
#* Exceptional Model Mining
#@ Dennis Leman;Ad Feelders;Arno Knobbe
#t 2008
#c 22
#% 197387
#% 424759
#% 458307
#% 579526
#% 983935
#% 1663669
#! In most databases, it is possible to identify small partitions of the data where the observed distribution is notably different from that of the database as a whole. In classical subgroup discovery, one considers the distribution of a single nominal attribute, and exceptional subgroups show a surprising increase in the occurrence of one of its values. In this paper, we introduce Exceptional Model Mining(EMM), a framework that allows for more complicated target concepts. Rather than finding subgroups based on the distribution of a single target attribute, EMM finds subgroups where a model fitted to that subgroup is somehow exceptional. We discuss regression as well as classification models, and define quality measures that determine how exceptional a given model on a subgroup is. Our framework is general enough to be applied to many types of models, even from other paradigms such as association analysis and graphical modeling.

#index 1108881
#* A Joint Topic and Perspective Model for Ideological Discourse
#@ Wei-Hao Lin;Eric Xing;Alexander Hauptmann
#t 2008
#c 22
#% 279755
#% 280819
#% 303620
#% 722904
#% 788094
#% 1249457
#% 1673048
#! Polarizing discussions on political and social issues are common in mass and user-generated media. However, computer-based understanding of ideological discourse has been considered too difficult to undertake. In this paper we propose a statistical model for ideology discourse. By ideology we mean "a set of general beliefs socially shared by a group of people." For example, Democratic and Republican are two major political ideologies in the United States. The proposed model captures lexical variations due to an ideological text's topic and due to an author or speaker's ideological perspective. To cope with the non-conjugacy of the logistic-normal prior we derive a variational inference algorithm for the model. We evaluate the proposed model on synthetic data as well as a written and a spoken political discourse. Experimental results strongly support that ideological perspectives are reflected in lexical variations.

#index 1108882
#* Effective Pruning Techniques for Mining Quasi-Cliques
#@ Guimei Liu;Limsoon Wong
#t 2008
#c 22
#% 248791
#% 268040
#% 322619
#% 324431
#% 498852
#% 823347
#% 823357
#% 824711
#% 833120
#% 864460
#% 881553
#% 937814
#% 956459
#% 1663647
#! Many real-world datasets, such as biological networks and social networks, can be modeled as graphs. It is interesting to discover densely connected subgraphs from these graphs, as such subgraphs represent groups of objects sharing some common properties. Several algorithms have been proposed to mine quasi-cliques from undirected graphs, but they have not fully utilized the minimum degree constraint for pruning. In this paper, we propose an efficient algorithm called Quickto find maximal quasi-cliques from undirected graphs. The Quickalgorithm uses several effective pruning techniques based on the degree of the vertices to prune unqualified vertices as early as possible, and these pruning techniques can be integrated into existing algorithms to improve their performance as well. Our experiment results show that Quickis orders of magnitude faster than previous work on mining quasi-cliques.

#index 1108883
#* Efficient Pairwise Multilabel Classification for Large-Scale Problems in the Legal Domain
#@ Eneldo Loza Mencía;Johannes Fürnkranz
#t 2008
#c 22
#% 302390
#% 344447
#% 361100
#% 722807
#% 722924
#% 763708
#% 961152
#% 961252
#% 1095861
#% 1100104
#% 1223287
#% 1705518
#% 1860941
#! In this paper we applied multilabel classification algorithms to the EUR-Lex database of legal documents of the European Union. On this document collection, we studied three different multilabel classification problems, the largest being the categorization into the EUROVOC concept hierarchy with almost 4000 classes. We evaluated three algorithms: (i) the binary relevance approach which independently trains one classifier per label; (ii) the multiclass multilabel perceptron algorithm, which respects dependencies between the base classifiers; and (iii) the multilabel pairwise perceptron algorithm, which trains one classifier for each pair of labels. All algorithms use the simple but very efficient perceptron algorithm as the underlying classifier, which makes them very suitable for large-scale multilabel classification problems. The main challenge we had to face was that the almost 8,000,000 perceptrons that had to be trained in the pairwise setting could no longer be stored in memory. We solve this problem by resorting to the dual representation of the perceptron, which makes the pairwise approach feasible for problems of this size. The results on the EUR-Lex database confirm the good predictive performance of the pairwise approach and demonstrates the feasibility of this approach for large-scale tasks.

#index 1108884
#* Fitted Natural Actor-Critic: A New Algorithm for Continuous State-Action MDPs
#@ Francisco S. Melo;Manuel Lopes
#t 2008
#c 22
#% 169359
#% 203602
#% 258937
#% 363744
#% 393786
#% 425072
#% 520528
#% 720778
#% 829011
#% 1046338
#% 1074365
#% 1699598
#% 1699601
#! In this paper we address reinforcement learning problems with continuous state-action spaces. We propose a new algorithm, fitted natural actor-critic(FNAC), that extends the work in [1] to allow for general function approximation and data reuse. We combine the natural actor-critic architecture [1] with a variant of fitted value iteration using importance sampling. The method thus obtained combines the appealing features of both approaches while overcoming their main weaknesses: the use of a gradient-based actor readily overcomes the difficulties found in regression methods with policy optimization in continuous action-spaces; in turn, the use of a regression-based critic allows for efficient use of data and avoids convergence problems that TD-based critics often exhibit. We establish the convergence of our algorithm and illustrate its application in a simple continuous space, continuous action problem.

#index 1108885
#* A New Natural Policy Gradient by Stationary Distribution Metric
#@ Tetsuro Morimura;Eiji Uchibe;Junichiro Yoshimoto;Kenji Doya
#t 2008
#c 22
#% 124687
#% 258937
#% 309939
#% 361729
#% 384911
#% 465759
#% 857088
#% 1272385
#% 1279357
#% 1699598
#! The parameter space of a statistical learning machine has a Riemannian metric structure in terms of its objective function. [1] Amari proposed the concept of "natural gradient" that takes the Riemannian metric of the parameter space into account. Kakade [2] applied it to policy gradient reinforcement learning, called a natural policy gradient (NPG). Although NPGs evidently depend on the underlying Riemannian metrics, careful attention was not paid to the alternative choice of the metric in previous studies. In this paper, we propose a Riemannian metric for the joint distribution of the state-action, which is directly linked with the average reward, and derive a new NPG named "Natural State-action Gradient"(NSG). Then, we prove that NSG can be computed by fitting a certain linear model into the immediate reward function. In numerical experiments, we verify that the NSG learning can handle MDPs with a large number of states, for which the performances of the existing (N)PG methods degrade.

#index 1108886
#* Towards Machine Learning of Grammars and Compilers of Programming Languages
#@ Keita Imada;Katsuhiko Nakamura
#t 2008
#c 22
#% 9693
#% 238555
#% 349564
#% 382569
#% 408675
#% 485967
#% 550712
#% 581046
#% 853711
#% 1096510
#% 1378364
#% 1728744
#% 1728754
#% 1728755
#% 1728756
#! This paper discusses machine learning of grammars and compilers of programming languages from samples of translation from source programs into object codes. This work is an application of incremental learning of definite clause grammars (DCGs) and syntax directed translation schema (SDTS), which is implemented in the Synapse system. The main experimental result is that Synapse synthesized a set of SDTS rules for translating extended arithmetic expressions with function calls and assignment operators into object codes from positive and negative samples of the translation. The object language is a simple intermediate language based on inverse Polish notation. These rules contain an unambiguous context free grammar for the extended arithmetic expressions, which specifies the precedence and associativity of the operators. This approach can be used for designing and implementing a new programming language by giving the syntax and semantics in the form of the samples of the translation.

#index 1108887
#* Improving Classification with Pairwise Constraints: A Margin-Based Approach
#@ Nam Nguyen;Rich Caruana
#t 2008
#c 22
#% 464291
#% 464608
#% 464631
#% 722816
#% 770782
#% 770798
#% 812372
#% 852097
#% 983830
#% 983905
#% 983943
#! In this paper, we address the semi-supervised learning problem when there is a small amount of labeled data augmented with pairwise constraints indicating whether a pair of examples belongs to a same class or different classes. We introduce a discriminative learning approach that incorporates pairwise constraints into the conventional margin-based learning framework. We also present an efficient algorithm, PCSVM, to solve the pairwise constraint learning problem. Experiments with 15 data sets show that pairwise constraint information significantly increases the performance of classification.

#index 1108888
#* Metric Learning: A Support Vector Approach
#@ Nam Nguyen;Yunsong Guo
#t 2008
#c 22
#% 266426
#% 269217
#% 269218
#% 457926
#% 722816
#% 770798
#% 812372
#% 983830
#% 983905
#% 1861531
#! In this paper, we address the metric learning problem utilizing a margin-based approach. Our metric learning problem is formulated as a quadratic semi-definite programming problem (QSDP) with local neighborhood constraints, which is based on the Support Vector Machine (SVM) framework. The local neighborhood constraints ensure that examples of the same class are separated from examples of different classes by a margin. In addition to providing an efficient algorithm to solve the metric learning problem, extensive experiments on various data sets show that our algorithm is able to produce a new distance metric to improve the performance of the classical K-nearest neighbor (KNN) algorithm on the classification task. Our performance is always competitive and often significantly better than other state-of-the-art metric learning algorithms.

#index 1108889
#* Support Vector Machines, Data Reduction, and Approximate Kernel Matrices
#@ Xuanlong Nguyen;Ling Huang;Anthony D. Joseph
#t 2008
#c 22
#% 197394
#% 269217
#% 466597
#% 722815
#% 722909
#% 743284
#% 874994
#% 1022272
#% 1761305
#% 1815395
#! The computational and/or communication constraints associated with processing large-scale data sets using support vector machines (SVM) in contexts such as distributed networking systems are often prohibitively high, resulting in practitioners of SVM learning algorithms having to apply the algorithm on approximate versions of the kernel matrix induced by a certain degree of data reduction. In this paper, we study the tradeoffs between data reduction and the loss in an algorithm's classification performance. We introduce and analyze a consistent estimator of the SVM's achieved classification error, and then derive approximate upper bounds on the perturbation on our estimator. The bound is shown to be empirically tight in a wide range of domains, making it practical for the practitioner to determine the amount of data reduction given a permissible loss in the classification performance.

#index 1108890
#* Mixed Bregman Clustering with Approximation Guarantees
#@ Richard Nock;Panu Luosto;Jyrki Kivinen
#t 2008
#c 22
#% 425021
#% 725437
#% 898281
#% 916785
#% 991199
#% 991230
#% 1039665
#% 1699634
#% 1815617
#! Two recent breakthroughs have dramatically improved the scope and performance of k-means clustering: squared Euclidean seeding for the initialization step, and Bregman clustering for the iterative step. In this paper, we first unite the two frameworks by generalizing the former improvement to Bregman seeding-- a biased randomized seeding technique using Bregman divergences -- while generalizing its important theoretical approximation guarantees as well. We end up with a complete Bregman hard clustering algorithm integrating the distortion at hand in both the initialization and iterative steps. Our second contribution is to further generalize this algorithm to handle mixed Bregman distortions, which smooth out the asymetricity of Bregman divergences. In contrast to some other symmetrization approaches, our approach keeps the algorithm simple and allows us to generalize theoretical guarantees from regular Bregman clustering. Preliminary experiments show that using the proposed seeding with a suitable Bregman divergence can help us discover the underlying structure of the data.

#index 1108891
#* Hierarchical, Parameter-Free Community Discovery
#@ Spiros Papadimitriou;Jimeng Sun;Christos Faloutsos;Philip S. Yu
#t 2008
#c 22
#% 115608
#% 210173
#% 248790
#% 258598
#% 283833
#% 438137
#% 469422
#% 729918
#% 769883
#% 769896
#% 769947
#% 778215
#% 823347
#% 840840
#% 844325
#% 853537
#% 881493
#% 881496
#% 910794
#% 910865
#% 989640
#% 1016200
#% 1307659
#% 1672753
#! Given a large bipartite graph (like document-term, or userproduct graph), how can we find meaningful communities, quickly, and automatically? We propose to look for community hierarchies, with communities- within-communities. Our proposed method, the Context-specific Cluster Tree (CCT)finds such communities at multiple levels, with no user intervention, based on information theoretic principles (MDL). More specifically, it partitions the graph into progressively more refined subgraphs, allowing users to quickly navigate from the global, coarse structure of a graph to more focused and local patterns. As a fringe benefit, and also as an additional indication of its quality, it also achieves better compression than typical, non-hierarchical methods. We demonstrate its scalability and effectiveness on real, large graphs.

#index 1108892
#* A Genetic Algorithm for Text Classification Rule Induction
#@ Adriana Pietramala;Veronica L. Policicchio;Pasquale Rullo;Inderbir Sidhu
#t 2008
#c 22
#% 165110
#% 169777
#% 207252
#% 275837
#% 344447
#% 369236
#% 458379
#% 465754
#% 579575
#% 722935
#% 926881
#% 957734
#% 1274561
#! This paper presents a Genetic Algorithm, called Olex-GA, for the induction of rule-based text classifiers of the form "classify document dunder category cif t1ï戮驴 dor ... or tnï戮驴 dand not (tn+ 1ï戮驴 dor ... or tn+ mï戮驴 d) holds", where each tiis a term. Olex-GA relies on an efficient several-rules-per-individualbinary representation and uses the F-measure as the fitness function. The proposed approach is tested over the standard test sets Reuters-21578and Ohsumedand compared against several classification algorithms (namely, Naive Bayes, Ripper, C4.5, SVM). Experimental results demonstrate that it achieves very good performance on both data collections, showing to be competitive with (and indeed outperforming in some cases) the evaluated classifiers.

#index 1108893
#* Nonstationary Gaussian Process Regression Using Point Estimates of Local Smoothness
#@ Christian Plagemann;Kristian Kersting;Wolfram Burgard
#t 2008
#c 22
#% 138308
#% 305018
#% 840962
#% 891549
#% 983853
#% 1275105
#! Gaussian processes using nonstationary covariance functions are a powerful tool for Bayesian regression with input-dependent smoothness. A common approach is to model the local smoothness by a latent process that is integrated over using Markov chain Monte Carlo approaches. In this paper, we demonstrate that an approximation that uses the estimated mean of the local smoothness yields good results and allows one to employ efficient gradient-based optimization techniques for jointly learning the parameters of the latent and the observed processes. Extensive experiments on both synthetic and real-world data, including challenging problems in robotics, show the relevance and feasibility of our approach.

#index 1108894
#* Kernel-Based Inductive Transfer
#@ Ulrich Rückert;Stefan Kramer
#t 2008
#c 22
#% 236497
#% 466722
#% 763697
#% 766438
#% 829014
#% 829029
#% 829031
#% 840865
#% 840962
#% 875995
#% 961190
#% 961246
#% 1100098
#% 1271814
#! Methods for inductive transfer take advantage of knowledge from previous learning tasks to solve a newly given task. In the context of supervised learning, the task is to find a suitable bias for a new dataset, given a set of known datasets. In this paper, we take a kernel-based approach to inductive transfer, that is, we aim at finding a suitable kernel for the new data. In our setup, the kernel is taken from the linear span of a set of predefined kernels. To find such a kernel, we apply convex optimization on two levels. On the base level, we propose an iterative procedure to generate kernels that generalize well on the known datasets. On the meta level, we combine those kernels in a minimization criterion to predict a suitable kernel for the new data. The criterion is based on a meta kernel capturing the similarity of two datasets. In experiments on small molecule and text data, kernel-based inductive transfer showed a statistically significant improvement over the best individual kernel in almost all cases.

#index 1108895
#* State-Dependent Exploration for Policy Gradient Methods
#@ Thomas Rückstieß;Martin Felder;Jürgen Schmidhuber
#t 2008
#c 22
#% 124687
#% 124691
#% 384911
#% 527859
#% 565539
#% 1272286
#% 1403361
#% 1699598
#% 1860830
#! Policy Gradient methods are model-free reinforcement learning algorithms which in recent years have been successfully applied to many real-world problems. Typically, Likelihood Ratio (LR) methods are used to estimate the gradient, but they suffer from high variance due to random exploration at every time step of each training episode. Our solution to this problem is to introduce a state-dependent exploration function (SDE) which during an episode returns the same action for any given state. This results in less variance per episode and faster convergence. SDE also finds solutions overlooked by other methods, and even improves upon state-of-the-art gradient estimators such as Natural Actor-Critic. We systematically derive SDE and apply it to several illustrative toy problems and a challenging robotics simulation task, where SDE greatly outperforms random exploration.

#index 1108896
#* Client-Friendly Classification over Random Hyperplane Hashes
#@ Shyamsundar Rajaram;Martin Scholz
#t 2008
#c 22
#% 205305
#% 249321
#% 321635
#% 333881
#% 342617
#% 347225
#% 593928
#% 722935
#% 729964
#% 762054
#% 881575
#% 898309
#% 939408
#% 1083648
#! In this work, we introduce a powerful and general feature representation based on a locality sensitive hash scheme called random hyperplane hashing. We are addressing the problem of centrally learning (linear) classification models from data that is distributed on a number of clients, and subsequently deploying these models on the same clients. Our main goal is to balance the accuracy of individual classifiers and different kinds of costs related to their deployment, including communication costs and computational complexity. We hence systematically study how well schemes for sparse high-dimensional data adapt to the much denser representations gained by random hyperplane hashing, how much data has to be transmitted to preserve enough of the semantics of each document, and how the representations affect the overall computational complexity. This paper provides theoretical results in the form of error bounds and margin based bounds to analyze the performance of classifiers learnt over the hash-based representation. We also present empirical evidence to illustrate the attractive properties of random hyperplane hashing over the conventional baseline representation of bag of words with and without feature selection.

#index 1108897
#* Large-Scale Clustering through Functional Embedding
#@ Frédéric Ratle;Jason Weston;Matthew L. Miller
#t 2008
#c 22
#% 266426
#% 313959
#% 361100
#% 466263
#% 593047
#% 722810
#% 770830
#% 791402
#% 855573
#% 884076
#% 893725
#% 961195
#% 961218
#% 983944
#% 1073928
#% 1214804
#! We present a new framework for large-scale data clustering. The main idea is to modify functional dimensionality reduction techniques to directly optimize over discrete labels using stochastic gradient descent. Compared to methods like spectral clustering our approach solves a single optimization problem, rather than an ad-hoc two-stage optimization approach, does not require a matrix inversion, can easily encode prior knowledge in the set of implementable functions, and does not have an "out-of-sample" problem. Experimental results on both artificial and real-world datasets show the usefulness of our approach.

#index 1108898
#* Clustering Distributed Sensor Data Streams
#@ Pedro Pereira Rodrigues;João Gama;Luís Lopes
#t 2008
#c 22
#% 210173
#% 248790
#% 248792
#% 466908
#% 492912
#% 548479
#% 566128
#% 576119
#% 659972
#% 799146
#% 874178
#% 888878
#% 893104
#% 894257
#% 993960
#% 1015261
#% 1100167
#% 1700144
#% 1831268
#! Nowadays applications produce infinite streams of data distributed across wide sensor networks. In this work we study the problem of continuously maintain a cluster structure over the data points generated by the entire network. Usual techniques operate by forwarding and concentrating the entire data in a central server, processing it as a multivariate stream. In this paper, we propose DGClust, a new distributed algorithm which reduces both the dimensionality and the communication burdens, by allowing each local sensor to keep an online discretization of its data stream, which operates with constant update time and (almost) fixed space. Each new data point triggers a cell in this univariate grid, reflecting the current state of the data stream at the local site. Whenever a local site changes its state, it notifies the central server about the new state it is in. This way, at each point in time, the central site has the global multivariate state of the entire network. To avoid monitoring all possible states, which is exponential in the number of sensors, the central site keeps a small list of counters of the most frequent global states. Finally, a simple adaptive partitional clustering algorithm is applied to the frequent states central points in order to provide an anytime definition of the clusters centers. The approach is evaluated in the context of distributed sensor networks, presenting both empirical and theoretical evidence of its advantages.

#index 1108899
#* A Novel Scalable and Data Efficient Feature Subset Selection Algorithm
#@ Sergio Rodrigues De Morais;Alex Aussem
#t 2008
#c 22
#% 345862
#% 722929
#% 844415
#% 893460
#% 919561
#% 961265
#% 977231
#% 1099365
#% 1672997
#% 1732735
#! In this paper, we aim to identify the minimal subset of discrete random variables that is relevant for probabilistic classification in data sets with many variables but few instances. A principled solution to this problem is to determine the Markov boundaryof the class variable. Also, we present a novel scalable, data efficient and correct Markov boundary learning algorithm under the so-called faithfulnesscondition. We report extensive empiric experiments on synthetic and real data sets scaling up to 139,351 variables.

#index 1108900
#* Robust Feature Selection Using Ensemble Feature Selection Techniques
#@ Yvan Saeys;Thomas Abeel;Yves Peer
#t 2008
#c 22
#% 169659
#% 209021
#% 243728
#% 375017
#% 400847
#% 425048
#% 551723
#% 722929
#% 977991
#% 999695
#% 1041316
#% 1398542
#! Robustness or stability of feature selection techniques is a topic of recent interest, and is an important issue when selected feature subsets are subsequently analysed by domain experts to gain more insight into the problem modelled. In this work, we investigate the use of ensemble feature selection techniques, where multiple feature selection methods are combined to yield more robust results. We show that these techniques show great promise for high-dimensional domains with small sample sizes, and provide more robust feature subsets than a single feature selection technique. In addition, we also investigate the effect of ensemble feature selection techniques on classification performance, giving rise to a new model selection strategy.

#index 1108901
#* Effective Visualization of Information Diffusion Process over Complex Networks
#@ Kazumi Saito;Masahiro Kimura;Hiroshi Motoda
#t 2008
#c 22
#% 55700
#% 729923
#% 754107
#% 832271
#% 856289
#% 995208
#% 1269888
#! Effective visualization is vital for understanding a complex network, in particular its dynamical aspect such as information diffusion process. Existing node embedding methods are all based solely on the network topology and sometimes produce counter-intuitive visualization. A new node embedding method based on conditional probability is proposed that explicitly addresses diffusion process using either the IC or LT models as a cross-entropy minimization problem, together with two label assignment strategies that can be simultaneously adopted. Numerical experiments were performed on two large real networks, one represented by a directed graph and the other by an undirected graph. The results clearly demonstrate the advantage of the proposed methods over conventional spring model and topology-based cross-entropy methods, especially for the case of directed networks.

#index 1108902
#* Actively Transfer Domain Knowledge
#@ Xiaoxiao Shi;Wei Fan;Jiangtao Ren
#t 2008
#c 22
#% 116165
#% 169717
#% 236729
#% 464268
#% 961246
#% 983814
#% 983828
#% 1100145
#% 1100153
#% 1272110
#% 1387560
#% 1665187
#! When labeled examples are not readily available, active learning and transfer learning are separate efforts to obtain labeled examples for inductive learning. Active learning asks domain experts to label a small set of examples, but there is a cost incurred for each answer. While transfer learning could borrow labeled examples from a different domain without incurring any labeling cost, there is no guarantee that the transferred examples will actually help improve the learning accuracy. To solve both problems, we propose a framework to actively transfer the knowledge across domains, and the key intuition is to use the knowledge transferred from other domain as often as possible to help learn the current domain, and query experts only when necessary. To do so, labeled examples from the other domain (out-of-domain) are examined on the basis of their likelihood to correctly label the examples of the current domain (in-domain). When this likelihood is low, these out-of-domain examples will not be used to label the in-domain example, but domain experts are consulted to provide class label. We derive a sampling error bound and a querying bound to demonstrate that the proposed method can effectively mitigate risk of domain difference by transferring domain knowledge only when they are useful, and query domain experts only when necessary. Experimental studies have employed synthetic datasets and two types of real world datasets, including remote sensing and text classification problems. The proposed method is compared with previously proposed transfer learning and active learning methods. Across all comparisons, the proposed approach can evidently outperform the transfer learning model in classification accuracy given different out-of-domain datasets. For example, upon the remote sensing dataset, the proposed approach achieves an accuracy around 94.5%, while the comparable transfer learning model drops to less than 89% in most cases. The software and datasets are available from the authors.

#index 1108903
#* A Unified View of Matrix Factorization Models
#@ Ajit P. Singh;Geoffrey J. Gordon
#t 2008
#c 22
#% 224113
#% 280819
#% 375388
#% 382854
#% 425021
#% 562954
#% 712704
#% 722904
#% 757953
#% 812400
#% 818234
#% 840924
#% 876018
#% 876031
#% 881487
#% 881502
#% 916785
#% 983875
#% 987253
#% 989618
#% 1025356
#% 1073976
#% 1083696
#% 1100067
#% 1250561
#% 1699620
#% 1742154
#! We present a unified view of matrix factorization that frames the differences among popular methods, such as NMF, Weighted SVD, E-PCA, MMMF, pLSI, pLSI-pHITS, Bregman co-clustering, and many others, in terms of a small number of modeling choices. Many of these approaches can be viewed as minimizing a generalized Bregman divergence, and we show that (i) a straightforward alternating projection algorithm can be applied to almost any model in our unified view; (ii) the Hessian for each projection has special structure that makes a Newton projection feasible, even when there are equality constraints on the factors, which allows for matrix co-clustering; and (iii) alternating projections can be generalized to simultaneously factor a set of matrices that share dimensions. These observations immediately yield new optimization algorithms for the above factorization methods, and suggest novel generalizations of these methods such as incorporating row and column biases, and adding or relaxing clustering constraints.

#index 1108904
#* Parallel Spectral Clustering
#@ Yangqiu Song;Wen-Yen Chen;Hongjie Bai;Chih-Jen Lin;Edward Y. Chang
#t 2008
#c 22
#% 286878
#% 313959
#% 329562
#% 385633
#% 399255
#% 466675
#% 552172
#% 722902
#% 724227
#% 732552
#% 763708
#% 779621
#% 829307
#% 855799
#% 995140
#% 1013696
#! Spectral clustering algorithm has been shown to be more effective in finding clusters than most traditional algorithms. However, spectral clustering suffers from a scalability problem in both memory use and computational time when a dataset size is large. To perform clustering on large datasets, we propose to parallelize both memory use and computation on distributed computers. Through an empirical study on a large document dataset of 193,844 data instances and a large photo dataset of 637,137, we demonstrate that our parallel algorithm can effectively alleviate the scalability problem.

#index 1108905
#* Classification of Multi-labeled Data: A Generative Approach
#@ Andreas P. Streich;Joachim M. Buhmann
#t 2008
#c 22
#% 95730
#% 236497
#% 458379
#% 478470
#% 818236
#% 1272365
#! Multi-label classification assigns a data item to one or several classes. This problem of multiple labels arises in fields like acoustic and visual scene analysis, news reports and medical diagnosis. In a generative framework, data with multiple labels can be interpreted as additive mixtures of emissions of the individual sources. We propose a deconvolution approach to estimate the individual contributions of each source to a given data item. Similarly, the distributions of multi-label data are computed based on the source distributions. In experiments with synthetic data, the novel approach is compared to existing models and yields more accurate parameter estimates, higher classification accuracy and ameliorated generalization to previously unseen label sets. These improvements are most pronounced on small training data sets. Also on real world acoustic data, the algorithm outperforms other generative models, in particular on small training data sets.

#index 1108906
#* Pool-Based Agnostic Experiment Design in Linear Regression
#@ Masashi Sugiyama;Shinichi Nakajima
#t 2008
#c 22
#% 565531
#% 961139
#% 983814
#% 1272282
#% 1860599
#! We address the problem of batch active learning (or experiment design) in regression scenarios, where the best input points to label is chosen from a `pool' of unlabeled input samples. Existing active learning methods often assume that the model is correctly specified, i.e., the unknown learning target function is included in the model at hand. However, this assumption may not be fulfilled in practice (i.e., agnostic) and then the existing methods do not work well. In this paper, we propose a new active learning method that is robust against model misspecification. Simulations with various benchmark datasets as well as a real application to wafer alignment in semiconductor exposure apparatus illustrate the usefulness of the proposed method.

#index 1108907
#* Distribution-Free Learning of Bayesian Network Structure
#@ Xiaohai Sun
#t 2008
#c 22
#% 44876
#% 46437
#% 68244
#% 88134
#% 297171
#% 528170
#% 722815
#% 793242
#% 983911
#% 1269489
#% 1673681
#! We present an independence-based method for learning Bayesian network (BN) structure without making any assumptions on the probability distribution of the domain. This is mainly useful for continuous domains. Even mixed continuous-categorical domains and structures containing vectorial variables can be handled. We address the problem by developing a non-parametric conditional independence test based on the so-called kernel dependence measure, which can be readily used by any existing independence-based BN structure learning algorithm. We demonstrate the structure learning of graphical models in continuous and mixed domains from real-world data without distributional assumptions. We also experimentally show that our test is a good alternative, in particular in case of small sample sizes, compared to existing tests, which can only be used in purely categorical or continuous domains.

#index 1108908
#* Assessing Nonlinear Granger Causality from Multivariate Time Series
#@ Xiaohai Sun
#t 2008
#c 22
#% 722798
#% 722815
#% 853591
#% 1781199
#! A straightforward nonlinear extension of Granger's concept of causality in the kernel framework is suggested. The kernel-based approach to assessing nonlinear Granger causality in multivariate time series enables us to determine, in a model-free way, whether the causal relation between two time series is present or not and whether it is direct or mediated by other processes. The trace norm of the so-called covariance operator in feature space is used to measure the prediction error. Relying on this measure, we test the improvement of predictability between time series by subsampling-based multiple testing. The distributional properties of the resulting p-values reveal the direction of Granger causality. Experiments with simulated and real-world data show that our method provides encouraging results.

#index 1108909
#* Clustering Via Local Regression
#@ Jun Sun;Zhiyong Shen;Hui Li;Yidong Shen
#t 2008
#c 22
#% 36672
#% 143194
#% 313959
#% 466675
#% 722902
#% 724227
#% 734917
#% 755463
#% 757953
#% 891559
#% 983934
#% 987204
#% 989642
#% 1269774
#% 1269778
#% 1856351
#! This paper deals with the local learning approach for clustering, which is based on the idea that in a good clustering, the cluster label of each data point can be well predicted based on its neighbors and their cluster labels. We propose a novel local learning based clustering algorithm using kernel regression as the local label predictor. Although sum of absolute error is used instead of sum of squared error, we still obtain an algorithm that clusters the data by exploiting the eigen-structure of a sparse matrix. Experimental results on many data sets demonstrate the effectiveness and potential of the proposed method.

#index 1108910
#* Decomposable Families of Itemsets
#@ Nikolaj Tatti;Hannes Heikinheimo
#t 2008
#c 22
#% 152934
#% 185077
#% 232136
#% 248791
#% 338580
#% 388024
#% 464873
#% 478770
#% 528180
#% 785568
#% 823356
#% 934581
#% 984507
#% 985041
#% 1116995
#% 1348648
#% 1808676
#! The problem of selecting a small, yet high quality subset of patterns from a larger collection of itemsets has recently attracted a lot of research. Here we discuss an approach to this problem using the notion of decomposable families of itemsets. Such itemset families define a probabilistic model for the data from which the original collection of itemsets was derived. Furthermore, they induce a special tree structure, called a junction tree, familiar from the theory of Markov Random Fields. The method has several advantages. The junction trees provide an intuitive representation of the mining results. From the computational point of view, the model provides leverage for problems that could be intractable using the entire collection of itemsets. We provide an efficient algorithm to build decomposable itemset families, and give an application example with frequency bound querying using the model. An empirical study show that our algorithm yields high quality results.

#index 1108911
#* Transferring Instances for Model-Based Reinforcement Learning
#@ Matthew E. Taylor;Nicholas K. Jong;Peter Stone
#t 2008
#c 22
#% 160859
#% 169359
#% 203602
#% 204531
#% 236497
#% 363744
#% 377895
#% 384911
#% 527859
#% 722895
#% 983931
#% 1014676
#% 1073940
#% 1084045
#% 1250215
#% 1398250
#% 1650283
#% 1699609
#! Reinforcement learningagents typically require a significant amount of data before performing well on complex tasks. Transfer learningmethods have made progress reducing sample complexity, but they have primarily been applied to model-free learning methods, not more data-efficient model-based learning methods. This paper introduces timbrel, a novel method capable of transferring information effectively into a model-based reinforcement learning algorithm. We demonstrate that timbrelcan significantly improve the sample efficiency and asymptotic performance of a model-based algorithm when learning in a continuous state space. Additionally, we conduct experiments to test the limits of timbrel's effectiveness.

#index 1108912
#* A Simple Model for Sequences of Relational State Descriptions
#@ Ingo Thon;Niels Landwehr;Luc Raedt
#t 2008
#c 22
#% 3873
#% 147928
#% 194894
#% 363744
#% 368178
#% 541077
#% 567946
#% 850430
#% 1269503
#% 1275150
#% 1289462
#% 1416198
#% 1664551
#! Artificial intelligence aims at developing agents that learn and act in complex environments. Realistic environments typically feature a variable number of objects, relations amongst them, and non-deterministic transition behavior. Standard probabilistic sequence models provide efficient inference and learning techniques, but typically cannot fully capture the relational complexity. On the other hand, statistical relational learning techniques are often too inefficient. In this paper, we present a simple model that occupies an intermediate position in this expressiveness/efficiency trade-off. It is based on CP-logic, an expressive probabilistic logic for modeling causality. However, by specializing CP-logic to represent a probability distribution over sequences of relational state descriptions, and employing a Markov assumption, inference and learning become more tractable and effective. We show that the resulting model is able to handle probabilistic relational domains with a substantial number of objects and relations.

#index 1108913
#* Semi-Supervised Boosting for Multi-Class Classification
#@ Hamed Valizadegan;Rong Jin;Anil K. Jain
#t 2008
#c 22
#% 304876
#% 313959
#% 393059
#% 466263
#% 565545
#% 577240
#% 577298
#% 829005
#% 876016
#% 954289
#% 1269502
#% 1272365
#! Most semi-supervised learning algorithms have been designed for binary classification, and are extended to multi-class classification by approaches such as one-against-the-rest. The main shortcoming of these approaches is that they are unable to exploit the fact that each example is only assigned to one class. Additional problems with extending semi-supervised binary classifiers to multi-class problems include imbalanced classification and different output scales of different binary classifiers. We propose a semi-supervised boosting framework, termed Multi-Class Semi-Supervised Boosting (MCSSB), that directly solves the semi-supervised multi-class learning problem. Compared to the existing semi-supervised boosting methods, the proposed framework is advantageous in that it exploits both classification confidence and similarities among examples when deciding the pseudo-labels for unlabeled examples. Empirical study with a number of UCI datasets shows that the proposed MCSSB algorithm performs better than the state-of-the-art boosting algorithms for semi-supervised learning.

#index 1108914
#* A Joint Segmenting and Labeling Approach for Chinese Lexical Analysis
#@ Xinhao Wang;Jiazhong Nie;Dingsheng Luo;Xihong Wu
#t 2008
#c 22
#% 3134
#% 44862
#% 216017
#% 292340
#% 741066
#% 742230
#% 742527
#% 748591
#% 751697
#% 757423
#% 770844
#% 855193
#% 855290
#% 858035
#% 939353
#% 939947
#% 1215378
#% 1275029
#% 1277965
#% 1344885
#% 1344888
#! This paper introduces an approach which jointly performs a cascade of segmentation and labeling subtasks for Chinese lexical analysis, including word segmentation, named entity recognition and part-of-speech tagging. Unlike the traditional pipeline manner, the cascaded subtasks are conducted in a single step simultaneously, therefore error propagation could be avoided and the information could be shared among multi-level subtasks. In this approach, Weighted Finite State Transducers (WFSTs) are adopted. Within the unified framework of WFSTs, the models for each subtask are represented and then combined into a single one. Thereby, through one-pass decoding the joint optimal outputs for multi-level processes will be reached. The experimental results show the effectiveness of the presented joint processing approach, which significantly outperforms the traditional method in pipeline style.

#index 1108915
#* Transferred Dimensionality Reduction
#@ Zheng Wang;Yangqiu Song;Changshui Zhang
#t 2008
#c 22
#% 80995
#% 235342
#% 236497
#% 267027
#% 336073
#% 563100
#% 726730
#% 791402
#% 857439
#% 875975
#% 913838
#% 983828
#% 983869
#% 983899
#% 1290055
#% 1455666
#! Dimensionality reduction is one of the widely used techniques for data analysis. However, it is often hard to get a demanded low-dimensional representation with only the unlabeled data, especially for the discriminative task. In this paper, we put forward a novel problem of Transferred Dimensionality Reduction, which is to do unsupervised discriminative dimensionality reduction with the help of related prior knowledge from other classes in the same type of concept. We propose an algorithm named Transferred Discriminative Analysis to tackle this problem. It uses clustering to generate class labels for the target unlabeled data, and use dimensionality reduction for them joint with prior labeled data to do subspace selection. This two steps run adaptively to find a better discriminative subspace, and get better clustering results simultaneously. The experimental results on both constrained and unconstrained face recognition demonstrate significant improvements of our algorithm over the state-of-the-art methods.

#index 1108916
#* Multiple Manifolds Learning Framework Based on Hierarchical Mixture Density Model
#@ Xiaoxia Wang;Peter Tiňo;Mark A. Fardal
#t 2008
#c 22
#% 251155
#% 251418
#% 257039
#% 349210
#% 593047
#% 723241
#% 1289478
#! Several manifold learning techniques have been developed to learn, given a data, a single lower dimensional manifold providing a compact representation of the original data. However, for complex data sets containing multiple manifolds of possibly of different dimensionalities, it is unlikely that the existing manifold learning approaches can discover all the interesting lower-dimensional structures. We therefore introduce a hierarchical manifolds learning framework to discover a variety of the underlying low dimensional structures. The framework is based on hierarchical mixture latent variable model, in which each submodel is a latent variable model capturing a single manifold. We propose a novel multiple manifold approximation strategy used for the initialization of our hierarchical model. The technique is first verified on artificial data with mixed 1 ï戮驴, 2 ï戮驴 and 3 ï戮驴dimensional structures. It is then used to automatically detect lower-dimensional structures in disrupted satellite galaxies.

#index 1108917
#* Estimating Sales Opportunity Using Similarity-Based Methods
#@ Sholom M. Weiss;Nitin Indurkhya
#t 2008
#c 22
#% 23968
#% 168280
#% 464888
#% 729910
#% 734590
#% 813966
#% 823407
#% 875957
#% 881530
#% 900433
#% 1207139
#% 1289496
#! We describe an application of predicting sales opportunityusing similarity-based methods. Sales representatives interface with customers based on their potential for product sales. Estimates of this potential are made under optimistic conditions and referred to as the opportunity: How much can be sold if a sale were to be made? Since this can never be verified exactly, the direct use of predictive models is difficult. In building systems for estimating sales opportunity, the key issues are: (a) predictions for targets that cannot be verified, (b) explanatory capabilities (c) capability to incorporate external knowledge (d) parallel computation of multiple targets and other efficiencies (e) capability to calibrate optimism in the predictions. (f) method stability and ease of maintenance for incorporating new examples. Empirical experiments demonstrate excellent predictive accuracy while also meeting these objectives. The methods have been embedded in a widely-used similarity-based system for IBM's worldwide sales force.

#index 1108918
#* Learning MDP Action Models Via Discrete Mixture Trees
#@ Michael Wynkoop;Thomas Dietterich
#t 2008
#c 22
#% 136350
#% 214233
#% 314843
#% 465897
#% 600184
#% 755460
#% 961214
#% 1271827
#% 1290041
#% 1499586
#% 1650705
#! This paper addresses the problem of learning dynamic Bayesian network (DBN) models to support reinforcement learning. It focuses on learning regression tree (context-specific dependence) models of the conditional probability distributions of the DBNs. Existing algorithms rely on standard regression tree learning methods (both propositional and relational). However, such methods presume that the stochasticity in the domain can be modeled as a deterministic function with additive noise. This is inappropriate for many RL domains, where the stochasticity takes the form of stochastic choice over deterministic functions. This paper introduces a regression tree algorithm in which each leaf node is modeled as a finite mixture of deterministic functions. This mixture is approximated via a greedy set cover. Experiments on three challenging RL domains show that this approach finds trees that are more accurate and that are more likely to correctly identify the conditional dependencies in the DBNs based on small samples.

#index 1108919
#* Continuous Time Bayesian Networks for Host Level Network Intrusion Detection
#@ Jing Xu;Christian R. Shelton
#t 2008
#c 22
#% 75936
#% 442588
#% 729644
#% 763996
#% 789084
#% 808506
#% 821929
#% 821933
#% 821934
#% 831805
#% 841886
#% 963522
#% 1043869
#% 1050863
#% 1269514
#% 1289566
#% 1650390
#! We consider the problem of detecting host-level attacks in network traffic using unsupervised learning. We model the normal behavior of a host's traffic from its signature logs, and flag suspicious traces differing from this norm. In particular, we use continuous time Bayesian networks learned from historic non-attack data and flag future event sequences whose likelihood under this normal model is below a threshold. Our method differs from previous approaches in explicitly modeling temporal dependencies in the network traffic. Our model is therefore more sensitive to subtle variations in the sequences of network events. We present two simple extensions that allow for instantaneous events that do not result in state changes, and simultaneous transitions of two variables. Our approach does not require expensive labeling or prior exposure to the attack type. We illustrate the power of our method in detecting attacks with comparisons to other methods on real network traces.

#index 1108920
#* Data Streaming with Affinity Propagation
#@ Xiangliang Zhang;Cyril Furtlehner;Michèle Sebag
#t 2008
#c 22
#% 578388
#% 594012
#% 654443
#% 729965
#% 801696
#% 844426
#% 894646
#% 1015261
#% 1015301
#% 1021187
#% 1041340
#% 1085175
#! This paper proposed StrAP(Streaming AP), extending Affinity Propagation (AP) to data steaming. AP, a new clustering algorithm, extracts the data items, or exemplars, that best represent the dataset using a message passing method. Several steps are made to build StrAP. The first one (Weighted AP) extends AP to weighted items with no loss of generality. The second one (Hierarchical WAP) is concerned with reducing the quadratic AP complexity, by applying AP on data subsets and further applying Weighted AP on the exemplars extracted from all subsets. Finally StrAPextends Hierarchical WAP to deal with changes in the data distribution. Experiments on artificial datasets, on the Intrusion Detection benchmark (KDD99) and on a real-world problem, clustering the stream of jobs submitted to the EGEE grid system, provide a comparative validation of the approach.

#index 1108921
#* Semi-supervised Discriminant Analysis Via CCCP
#@ Yu Zhang;Dit-Yan Yeung
#t 2008
#c 22
#% 80995
#% 235342
#% 252011
#% 304876
#% 466263
#% 576520
#% 732522
#% 757953
#% 784525
#% 803769
#% 857439
#% 876003
#% 961176
#% 961218
#% 983940
#% 983941
#% 1502471
#! Linear discriminant analysis (LDA) is commonly used for dimensionality reduction. In real-world applications where labeled data are scarce, LDA does not work very well. However, unlabeled data are often available in large quantities. We propose a novel semi-supervised discriminant analysis algorithm called SSDA$_{\mathit{CCCP}}$. We utilize unlabeled data to maximize an optimality criterion of LDA and use the constrained concave-convex procedure to solve the optimization problem. The optimization procedure leads to estimation of the class labels for the unlabeled data. We propose a novel confidence measure for selecting those unlabeled data points with high confidence. The selected unlabeled data can then be used to augment the original labeled data set for performing LDA. We also propose a variant of SSDA$_{\mathit{CCCP}}$, called M-SSDA$_{\mathit{CCCP}}$, which adopts the manifold assumption to utilize the unlabeled data. Extensive experiments on many benchmark data sets demonstrate the effectiveness of our proposed methods.

#index 1108922
#* A Visualization-Based Exploratory Technique for Classifier Comparison with Respect to Multiple Metrics and Multiple Domains
#@ Rocío Alaiz-Rodríguez;Nathalie Japkowicz;Peter Tischer
#t 2008
#c 22
#% 290482
#% 769882
#% 1108870
#! Classifier performance evaluation typically gives rise to a multitude of results that are difficult to interpret. On the one hand, a variety of different performance metrics can be applied, each adding a little bit more information about the classifiers than the others; and on the other hand, evaluation must be conducted on multiple domains to get a clear view of the classifier's general behaviour.

#index 1108923
#* Pleiades: Subspace Clustering and Evaluation
#@ Ira Assent;Emmanuel Müller;Ralph Krieger;Timm Jansen;Thomas Seidl
#t 2008
#c 22
#% 248792
#% 273891
#% 464888
#% 765518
#% 785335
#% 785355
#% 915305
#% 926881
#% 1116995
#% 1117035
#! Subspace clustering mines the clusters present in locally relevant subsets of the attributes. In the literature, several approaches have been suggested along with different measures for quality assessment.Pleiadesprovides the means for easy comparison and evaluation of different subspace clustering approaches, along with several quality measures specific for subspace clustering as well as extensibility to further application areas and algorithms. It extends the popular WEKA mining tools, allowing for contrasting results with existing algorithms and data sets.

#index 1108924
#* SEDiL: Software for Edit Distance Learning
#@ Laurent Boyer;Yann Esposito;Amaury Habrard;Jose Oncina;Marc Sebban
#t 2008
#c 22
#% 251405
#% 288885
#% 826007
#% 940343
#% 1055501
#% 1100048
#% 1665128
#! In this paper, we present SEDiL, a Software forEditDistanceLearning. SEDiLis an innovative prototype implementation grouping together most of the state of the art methods [1,2,3,4] that aim to automatically learn the parameters of string and tree edit distances.

#index 1108925
#* Monitoring Patterns through an Integrated Management and Mining Tool
#@ Evangelos E. Kotsifakos;Irene Ntoutsi;Yannis Vrahoritis;Yannis Theodoridis
#t 2008
#c 22
#% 799779
#% 881538
#% 915244
#% 957155
#! Patterns upon the data of many real applications are affected by changes in these data. We employ Pattern-Minertool to detect changes of clusterings extracted from dynamic data and thus, to provide insight on the dataset and to support strategic decisions. Pattern-Miner, is an integrated environment for pattern (data mining model) management and mining that deals with the whole lifecycle of patterns, from their generation (using data mining techniques) to their storage and querying, putting also emphasis on the comparison between patterns and meta-mining operations over the extracted patterns. In the current version, Pattern-Minerintegrates also an algorithm and technique for monitoring patterns (currently clusters) over time.

#index 1108926
#* A Knowledge-Based Digital Dashboard for Higher Learning Institutions
#@ Wan Maseri Mohd;Abdullah Embong;Jasni Mohd Zain
#t 2008
#c 22
#! We propose a novel approach of knowledge discovery method by adopting dashboard concept and incorporating elements of data clustering, visualization and knowledge codification. The dashboard was designed to help the higher institution to explore the insight of student performance by analyzing significant patterns and tacit knowledge of the experts in order to improve decision making process. The system has been developed using system development life cycle (SDLC) methodology and coded in web-based and open source environment. The dashboard architecture and software are presented in this paper.

#index 1108927
#* SINDBAD and SiQL: An Inductive Database and Query Language in the Relational Model
#@ Jörg Wicker;Lothar Richter;Kristina Kessler;Stefan Kramer
#t 2008
#c 22
#% 2008
#% 342604
#% 347711
#% 420076
#% 420101
#% 449508
#% 787823
#% 1026556
#% 1044504
#% 1206794
#% 1742007
#! In this demonstration, we will present the concepts and an implementation of an inductive database--- as proposed by Imielinski and Mannila --- in the relational model. The goal is to support all steps of the knowledge discovery process on the basis of queries to a database system. The query language SiQL (structured inductive query language), an SQL extension, offers query primitives for feature selection, discretization, pattern mining, clustering, instance-based learning and rule induction. A prototype system processing such queries was implemented as part of the SINDBAD (structured inductive database development) project. To support the analysis of multi-relational data, we incorporated multi-relational distance measures based on set distances and recursive descent. The inclusion of rule-based classification models made it necessary to extend the data model and software architecture significantly. The prototype is applied to three different data sets: gene expression analysis, gene regulation prediction and structure-activity relationships (SARs) of small molecules.

#index 1267754
#* Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II
#@ Wray Buntine;Marko Grobelnik;Dunja Mladenić;John Shawe-Taylor
#t 2009
#c 22

#index 1267755
#* Decomposition Algorithms for Training Large-Scale Semiparametric Support Vector Machines
#@ Sangkyun Lee;Stephen J. Wright
#t 2009
#c 22
#% 116149
#% 269217
#% 269218
#% 304942
#% 393059
#% 425045
#% 894263
#% 1558464
#% 1699590
#! We describe a method for solving large-scale semiparametric support vector machines (SVMs) for regression problems. Most of the approaches proposed to date for large-scale SVMs cannot accommodate the multiple equality constraints that appear in semiparametric problems. Our approach uses a decomposition framework, with a primal-dual algorithm to find an approximate saddle point for the min-max formulation of each subproblem. We compare our method with algorithms previously proposed for semiparametric SVMs, and show that it scales well as the number of training examples grows.

#index 1267756
#* A Convex Method for Locating Regions of Interest with Multi-instance Learning
#@ Yu-Feng Li;James T. Kwok;Ivor W. Tsang;Zhi-Hua Zhou
#t 2009
#c 22
#% 224755
#% 272527
#% 464633
#% 465916
#% 565537
#% 763697
#% 770846
#% 771844
#% 803575
#% 812449
#% 840922
#% 875969
#% 881477
#% 916790
#% 961190
#% 983901
#% 983950
#% 1073923
#% 1074014
#% 1211847
#% 1298987
#% 1674145
#! In content-based image retrieval (CBIR) and image screening, it is often desirable to locate the regions of interest (ROI) in the images automatically. This can be accomplished with multi-instance learning techniques by treating each image as a bag of instances (regions). Many SVM-based methods are successful in predicting the bag labels, however, few of them can locate the ROIs. Moreover, they are often based on either local search or an EM-style strategy, and may get stuck in local minima easily. In this paper, we propose two convex optimization methods which maximize the margin of concepts via key instance generation at the instance-level and bag-level, respectively. Our formulation can be solved efficiently with a cutting plane algorithm. Experiments show that the proposed methods can effectively locate ROIs, and they also achieve performances competitive with state-of-the-art algorithms on benchmark data sets.

#index 1267757
#* Active Learning for Reward Estimation in Inverse Reinforcement Learning
#@ Manuel Lopes;Francisco Melo;Luis Montesano
#t 2009
#c 22
#% 466230
#% 466418
#% 770852
#% 1074001
#% 1270316
#% 1275169
#% 1302825
#! Inverse reinforcement learning addresses the general problem of recovering a reward function from samples of a policy provided by an expert/demonstrator. In this paper, we introduce active learning for inverse reinforcement learning. We propose an algorithm that allows the agent to query the demonstrator for samples at specific states, instead of relying only on samples provided at "arbitrary" states. The purpose of our algorithm is to estimate the reward function with similar accuracy as other methods from the literature while reducing the amount of policy samples required from the expert. We also discuss the use of our algorithm in higher dimensional problems, using both Monte Carlo and gradient methods. We present illustrative results of our algorithm in several simulated examples of different complexities.

#index 1267758
#* Simulated Iterative Classification A New Learning Procedure for Graph Labeling
#@ Francis Maes;Stéphane Peters;Ludovic Denoyer;Patrick Gallinari
#t 2009
#c 22
#% 28293
#% 211044
#% 769942
#% 840947
#% 875948
#% 881557
#% 961218
#% 961278
#% 987245
#% 1052576
#% 1289458
#% 1676331
#% 1848687
#! Collective classification refers to the classification of interlinked and relational objects described as nodes in a graph. The Iterative Classification Algorithm (ICA) is a simple, efficient and widely used method to solve this problem. It is representative of a family of methods for which inference proceeds as an iterative process: at each step, nodes of the graph are classified according to the current predicted labels of their neighbors. We show that learning in this class of models suffers from a training bias. We propose a new family of methods, called Simulated ICA, which helps reducing this training bias by simulating inference during learning. Several variants of the method are introduced. They are both simple, efficient and scale well. Experiments performed on a series of 7 datasets show that the proposed methods outperform representative state-of-the-art algorithms while keeping a low complexity.

#index 1267759
#* Graph-Based Discrete Differential Geometry for Critical Instance Filtering
#@ Elena Marchiori
#t 2009
#c 22
#% 116149
#% 197394
#% 242776
#% 307100
#% 331916
#% 420138
#% 444007
#% 464440
#% 465760
#% 477947
#% 722921
#% 840838
#% 840965
#% 875957
#% 940369
#% 959871
#% 983948
#% 995140
#% 1013603
#% 1074372
#% 1100079
#% 1232015
#% 1676331
#% 1861531
#! Graph theory has been shown to provide a powerful tool for representing and tackling machine learning problems, such as clustering, semi-supervised learning, and feature ranking. This paper proposes a graph-based discrete differential operator for detecting and eliminating competence-critical instances and class label noise from a training set in order to improve classification performance. Results of extensive experiments on artificial and real-life classification problems substantiate the effectiveness of the proposed approach.

#index 1267760
#* Integrating Novel Class Detection with Classification for Concept-Drifting Data Streams
#@ Mohammad M. Masud;Jing Gao;Latifur Khan;Jiawei Han;Bhavani Thuraisingham
#t 2009
#c 22
#% 342600
#% 577297
#% 729932
#% 731721
#% 823408
#% 840891
#% 957742
#% 1176894
#% 1206700
#! In a typical data stream classification task, it is assumed that the total number of classes are fixed. This assumption may not be valid in a real streaming environment, where new classes may evolve. Traditional data stream classification techniques are not capable of recognizing novel class instances until the appearance of the novel class is manually identified, and labeled instances of that class are presented to the learning algorithm for training. The problem becomes more challenging in the presence of concept-drift, when the underlying data distribution changes over time. We propose a novel and efficient technique that can automatically detect the emergence of a novel class in the presence of concept-drift by quantifying cohesion among unlabeled test instances, and separation of the test instances from training instances. Our approach is non-parametric, meaning, it does not assume any underlying distributions of data. Comparison with the state-of-the-art stream classification techniques prove the superiority of our approach.

#index 1267761
#* Neural Networks for State Evaluation in General Game Playing
#@ Daniel Michulke;Michael Thielscher
#t 2009
#c 22
#% 147065
#% 183499
#% 409507
#% 426646
#% 1250387
#% 1269851
#% 1269860
#% 1270060
#! Unlike traditional game playing, General Game Playing is concerned with agents capable of playing classes of games. Given the rules of an unknown game, the agent is supposed to play well without human intervention. For this purpose, agent systems that use deterministic game tree search need to automatically construct a state value function to guide search. Successful systems of this type use evaluation functions derived solely from the game rules, thus neglecting further improvements by experience. In addition, these functions are fixed in their form and do not necessarily capture the game's real state value function. In this work we present an approach for obtaining evaluation functions on the basis of neural networks that overcomes the aforementioned problems. A network initialization extracted from the game rules ensures reasonable behavior without the need for prior training. Later training, however, can lead to significant improvements in evaluation quality, as our results indicate.

#index 1267762
#* Learning to Disambiguate Search Queries from Short Sessions
#@ Lilyana Mihalkova;Raymond Mooney
#t 2009
#c 22
#% 280852
#% 528182
#% 576214
#% 577224
#% 578684
#% 754099
#% 754126
#% 805877
#% 818259
#% 823348
#% 848639
#% 850430
#% 879618
#% 915340
#% 956552
#% 987203
#% 988019
#% 1000502
#% 1055735
#% 1074025
#% 1074113
#% 1077150
#% 1100143
#% 1250579
#% 1269815
#% 1270275
#% 1348355
#! Web searches tend to be short and ambiguous. It is therefore not surprising that Web query disambiguation is an actively researched topic. To provide a personalized experience for a user, most existing work relies on search engine log data in which the search activities of that particular user , as well as other users, are recorded over long periods of time. Such approaches may raise privacy concerns and may be difficult to implement for pragmatic reasons. We present an approach to Web query disambiguation that bases its predictions only on a short glimpse of user search activity, captured in a brief session of 4---6 previous searches on average. Our method exploits the relations of the current search session to previous similarly short sessions of other users in order to predict the user's intentions and is based on Markov logic, a statistical relational learning model that has been successfully applied to challenging language problems in the past. We present empirical results that demonstrate the effectiveness of our proposed approach on data collected from a commercial general-purpose search engine.

#index 1267763
#* Dynamic Factor Graphs for Time Series Modeling
#@ Piotr Mirowski;Yann Lecun
#t 2009
#c 22
#% 182142
#% 269219
#% 269220
#% 304898
#% 476873
#% 811777
#% 1810385
#% 1861346
#! This article presents a method for training Dynamic Factor Graphs (DFG) with continuous latent state variables. A DFG includes factors modeling joint probabilities between hidden and observed variables, and factors modeling dynamical constraints on hidden variables. The DFG assigns a scalar energy to each configuration of hidden and observed variables. A gradient-based inference procedure finds the minimum-energy state sequence for a given observation sequence. Because the factors are designed to ensure a constant partition function, they can be trained by minimizing the expected energy over training sequences with respect to the factors' parameters. These alternated inference and parameter updates can be seen as a deterministic EM-like procedure. Using smoothing regularizers, DFGs are shown to reconstruct chaotic attractors and to separate a mixture of independent oscillatory sources perfectly. DFGs outperform the best known algorithm on the CATS competition benchmark for time series prediction. DFGs also successfully reconstruct missing motion capture data.

#index 1267764
#* On Feature Selection, Bias-Variance, and Bagging
#@ M. Arthur Munson;Rich Caruana
#t 2009
#c 22
#% 132583
#% 156181
#% 209021
#% 218961
#% 243728
#% 256615
#% 283145
#% 424997
#% 465912
#% 466401
#% 551723
#% 722929
#% 722933
#% 722939
#% 768669
#% 1108900
#% 1154325
#! We examine the mechanism by which feature selection improves the accuracy of supervised learning. An empirical bias/variance analysis as feature selection progresses indicates that the most accurate feature set corresponds to the best bias-variance trade-off point for the learning algorithm. Often, this is not the point separating relevant from irrelevant features, but where increasing variance outweighs the gains from adding more (weakly) relevant features. In other words, feature selection can be viewed as a variance reduction method that trades off the benefits of decreased variance (from the reduction in dimensionality) with the harm of increased bias (from eliminating some of the relevant features). If a variance reduction method like bagging is used, more (weakly) relevant features can be exploited and the most accurate feature set is usually larger. In many cases, the best performance is obtained by using all available features.

#index 1267765
#* Efficient Pruning Schemes for Distance-Based Outlier Detection
#@ Nguyen Hoang Vu;Vivekanand Gopalkrishnan
#t 2009
#c 22
#% 300136
#% 300183
#% 333934
#% 478297
#% 479791
#% 578388
#% 729912
#% 789012
#% 803123
#% 881495
#% 1107135
#! Outlier detection finds many applications, especially in domains that have scope for abnormal behavior. In this paper, we present a new technique for detecting distance-based outliers, aimed at reducing execution time associated with the detection process. Our approach operates in two phases and employs three pruning rules. In the first phase, we partition the data into clusters, and make an early estimate on the lower bound of outlier scores. Based on this lower bound, the second phase then processes relevant clusters using the traditional block nested-loop algorithm. Here two efficient pruning rules are utilized to quickly discard more non-outliers and reduce the search space. Detailed analysis of our approach shows that the additional overhead of the first phase is offset by the reduction in cost of the second phase. We also demonstrate the superiority of our approach over existing distance-based outlier detection methods by extensive empirical studies on real datasets.

#index 1267766
#* The Sensitivity of Latent Dirichlet Allocation for Information Retrieval
#@ Laurence A. Park;Kotagiri Ramamohanarao
#t 2009
#c 22
#% 280819
#% 324192
#% 643056
#% 722904
#% 785354
#% 879587
#% 1134174
#% 1153113
#% 1201876
#% 1393154
#! It has been shown that the use of topic models for Information retrieval provides an increase in precision when used in the appropriate form. Latent Dirichlet Allocation (LDA) is a generative topic model that allows us to model documents using a Dirichlet prior. Using this topic model, we are able to obtain a fitted Dirichlet parameter that provides the maximum likelihood for the document set. In this article, we examine the sensitivity of LDA with respect to the Dirichlet parameter when used for Information retrieval. We compare the topic model computation times, storage requirements and retrieval precision of fitted LDA to LDA with a uniform Dirichlet prior. The results show there there is no significant benefit of using fitted LDA over the LDA with a constant Dirichlet parameter, hence showing that LDA is insensitive with respect to the Dirichlet parameter when used for Information retrieval.

#index 1267767
#* Efficient Decoding of Ternary Error-Correcting Output Codes for Multiclass Classification
#@ Sang-Hyeun Park;Johannes Fürnkranz
#t 2009
#c 22
#% 425052
#% 722756
#% 722807
#% 771846
#% 926881
#% 1014653
#% 1093383
#% 1100104
#% 1272365
#% 1663331
#! We present an adaptive decoding algorithm for ternary ECOC matrices which reduces the number of needed classifier evaluations for multiclass classification. The resulting predictions are guaranteed to be equivalent with the original decoding strategy except for ambiguous final predictions. The technique works for Hamming Decoding and several commonly used alternative decoding strategies. We show its effectiveness in an extensive empirical evaluation considering various code design types: Nearly in all cases, a considerable reduction is possible. We also show that the performance gain depends on the sparsity and the dimension of the ECOC coding matrix.

#index 1267768
#* The Model of Most Informative Patterns and Its Application to Knowledge Extraction from Graph Databases
#@ Frédéric Pennerath;Amedeo Napoli
#t 2009
#c 22
#% 152934
#% 279120
#% 280456
#% 431033
#% 443350
#% 629603
#% 729418
#% 769951
#% 823356
#% 1083506
#% 1083646
#% 1100166
#% 1117006
#% 1130837
#% 1168770
#% 1268739
#! This article introduces the class of Most Informative Patterns (MIPs) for characterizing a given dataset. MIPs form a reduced subset of non redundant closed patterns that are extracted from data thanks to a scoring function depending on domain knowledge. Accordingly, MIPs are designed for providing experts good insights on the content of datasets during data analysis. The article presents the model of MIPs and their formal properties wrt other kinds of patterns. Then, two algorithms for extracting MIPs are detailed: the first directly searches for MIPs in a dataset while the second screens MIPs from frequent patterns. The efficiencies of both algorithms are compared when applied to reference datasets. Finally the application of MIPs to labelled graphs, here molecular graphs, is discussed.

#index 1267769
#* On Discriminative Parameter Learning of Bayesian Network Classifiers
#@ Franz Pernkopf;Michael Wohlmayr
#t 2009
#c 22
#% 44876
#% 115608
#% 246832
#% 361100
#% 715701
#% 810947
#% 810949
#% 840917
#% 840929
#% 891559
#! We introduce three discriminative parameter learning algorithms for Bayesian network classifiers based on optimizing either the conditional likelihood (CL) or a lower-bound surrogate of the CL. One training procedure is based on the extended Baum-Welch (EBW) algorithm. Similarly, the remaining two approaches iteratively optimize the parameters (initialized to ML) with a 2-step algorithm. In the first step, either the class posterior probabilities or class assignments are determined based on current parameter estimates. Based on these posteriors (class assignment, respectively), the parameters are updated in the second step. We show that one of these algorithms is strongly related to EBW. Additionally, we compare all algorithms to conjugate gradient conditional likelihood (CGCL) parameter optimization [1]. We present classification results for frame- and segment-based phonetic classification and handwritten digit recognition. Discriminative parameter learning shows a significant improvement over generative ML estimation for naive Bayes (NB) and tree augmented naive Bayes (TAN) structures on all data sets. In general, the performance improvement of discriminative parameter learning is large for simple Bayesian network structures which are not optimized for classification.

#index 1267770
#* Mining Spatial Co-location Patterns with Dynamic Neighborhood Constraint
#@ Feng Qian;Qinming He;Jiangfeng He
#t 2009
#c 22
#% 479797
#% 481290
#% 727910
#% 784296
#% 784509
#% 785420
#% 889100
#% 911122
#% 989613
#% 1030824
#% 1135161
#% 1422710
#! Spatial co-location pattern mining is an interesting and important issue in spatial data mining area which discovers the subsets of features whose events are frequently located together in geographic space. However, previous research literatures for mining co-location patterns assume a static neighborhood constraint that apparently introduces many drawbacks. In this paper, we conclude the preferences that algorithms rely on when making decisions for mining co-location patterns with dynamic neighborhood constraint. Based on this, we define the mining task as an optimization problem and propose a greedy algorithm for mining co-location patterns with dynamic neighborhood constraint. The experimental evaluation on a real world data set shows that our algorithm has a better capability than the previous approach on finding co-location patterns together with the consideration of the distribution of data set.

#index 1267771
#* Classifier Chains for Multi-label Classification
#@ Jesse Read;Bernhard Pfahringer;Geoff Holmes;Eibe Frank
#t 2009
#c 22
#% 302391
#% 311034
#% 580511
#% 914738
#% 926881
#% 989655
#% 1083666
#% 1083698
#% 1095861
#% 1095862
#% 1100077
#% 1108883
#% 1176915
#! The widely known binary relevance method for multi-label classification, which considers each label as an independent binary problem, has been sidelined in the literature due to the perceived inadequacy of its label-independence assumption. Instead, most current methods invest considerable complexity to model interdependencies between labels. This paper shows that binary relevance-based methods have much to offer, especially in terms of scalability to large datasets. We exemplify this with a novel chaining method that can model label correlations while maintaining acceptable computational complexity. Empirical evaluation over a broad range of multi-label datasets with a variety of evaluation metrics demonstrates the competitiveness of our chaining method against related and state-of-the-art methods, both in terms of predictive performance and time complexity.

#index 1267772
#* Dependency Tree Kernels for Relation Extraction from Natural Language Text
#@ Frank Reichartz;Hannes Korte;Gerhard Paass
#t 2009
#c 22
#% 269217
#% 318412
#% 458379
#% 722803
#% 722926
#% 743284
#% 756964
#% 817472
#% 938706
#% 938713
#% 939944
#% 1289520
#% 1310476
#% 1499981
#% 1665151
#! The automatic extraction of relations from unstructured natural text is challenging but offers practical solutions for many problems like automatic text understanding and semantic retrieval. Relation extraction can be formulated as a classification problem using support vector machines and kernels for structured data that may include parse trees to account for syntactic structure. In this paper we present new tree kernels over dependency parse trees automatically generated from natural language text. Experiments on a public benchmark data set show that our kernels with richer structural features significantly outperform all published approaches for kernel-based relation extraction from dependency trees. In addition we optimize kernel computations to improve the actual runtime compared to previous solutions.

#index 1267773
#* Statistical Relational Learning with Formal Ontologies
#@ Achim Rettinger;Matthias Nickles;Volker Tresp
#t 2009
#c 22
#% 731606
#% 850430
#% 948091
#% 1000502
#% 1250567
#% 1374382
#% 1410971
#% 1413159
#! We propose a learning approach for integrating formal knowledge into statistical inference by exploiting ontologies as a semantically rich and fully formal representation of prior knowledge. The logical constraints deduced from ontologies can be utilized to enhance and control the learning task by enforcing description logic satisfiability in a latent multi-relational graphical model. To demonstrate the feasibility of our approach we provide experiments using real world social network data in form of a $\mathcal{SHOIN}(D)$ ontology. The results illustrate two main practical advancements: First, entities and entity relationships can be analyzed via the latent model structure. Second, enforcing the ontological constraints guarantees that the learned model does not predict inconsistent relations. In our experiments, this leads to an improved predictive performance.

#index 1267774
#* Boosting Active Learning to Optimality: A Tractable Monte-Carlo, Billiard-Based Algorithm
#@ Philippe Rolet;Michèle Sebag;Olivier Teytaud
#t 2009
#c 22
#% 116165
#% 132676
#% 156184
#% 170407
#% 170649
#% 203304
#% 232214
#% 236729
#% 252034
#% 359194
#% 384911
#% 464268
#% 466419
#% 644560
#% 722761
#% 722906
#% 735357
#% 875997
#% 983838
#% 983848
#% 1269501
#% 1272282
#% 1396658
#% 1404135
#% 1665148
#% 1705517
#! This paper focuses on Active Learning with a limited number of queries; in application domains such as Numerical Engineering, the size of the training set might be limited to a few dozen or hundred examples due to computational constraints. Active Learning under bounded resources is formalized as a finite horizon Reinforcement Learning problem, where the sampling strategy aims at minimizing the expectation of the generalization error. A tractable approximation of the optimal (intractable) policy is presented, the Bandit-based Active Learner (BAAL ) algorithm. Viewing Active Learning as a single-player game, BAAL combines UCT, the tree structured multi-armed bandit algorithm proposed by Kocsis and Szepesvári (2006), and billiard algorithms. A proof of principle of the approach demonstrates its good empirical convergence toward an optimal policy and its ability to incorporate prior AL criteria. Its hybridization with the Query-by-Committee approach is found to improve on both stand-alone BAAL and stand-alone QbC.

#index 1267775
#* Capacity Control for Partially Ordered Feature Sets
#@ Ulrich Rückert
#t 2009
#c 22
#% 629708
#% 722909
#% 727896
#% 1047781
#% 1100111
#% 1663621
#! Partially ordered feature sets appear naturally in many classification settings with structured input instances, for example, when the data instances are graphs and a feature tests whether a specific substructure occurs in the instance. Since such features are partially ordered according to an "is substructure of" relation, the information in those datasets is stored in an intrinsically redundant form. We investigate how this redundancy affects the capacity control behavior of linear classification methods. From a theoretical perspective, it can be shown that the capacity of this hypothesis class does not decrease for worst case distributions. However, if the data generating distribution assigns lower probabilities to instances in the lower levels of the hierarchy induced by the partial order, the capacity of the hypothesis class can be bounded by a smaller term. For itemset, subsequence and subtree features in particular, the capacity is finite even when an infinite number of features is present. We validate these results empirically on three graph datasets and show that the limited capacity of linear classifiers on such data makes underfitting rather than overfitting the more prominent capacity control problem. To avoid underfitting, we propose using more general substructure classes with "elastic edges" and we demonstrate how such broad feature classes can be used with large datasets.

#index 1267776
#* Reconstructing Data Perturbed by Random Projections When the Mixing Matrix Is Known
#@ Yingpeng Sang;Hong Shen;Hui Tian
#t 2009
#c 22
#% 1868
#% 67453
#% 300184
#% 313975
#% 416518
#% 428404
#% 482071
#% 512307
#% 576111
#% 576761
#% 586838
#% 727904
#% 740764
#% 743280
#% 772829
#% 800513
#% 810010
#% 843878
#% 856216
#% 864412
#% 993988
#% 1074831
#% 1102985
#% 1393141
#% 1663641
#% 1721181
#% 1757799
#! Random Projection ($\mathcal{RP}$) has drawn great interest from the research of privacy-preserving data mining due to its high efficiency and security. It was proposed in [27] where the original data set composed of m attributes, is multiplied with a mixing matrix of dimensions k ×m (m k ) which is random and orthogonal on expectation, and then the k series of perturbed data are released for mining purposes. To our knowledge little work has been done from the view of the attacker, to reconstruct the original data to get some sensitive information, given the data perturbed by $\mathcal{RP}$ and some priori knowledge, e.g. the mixing matrix, the means and variances of the original data. In the case that the attributes of the original data are mutually independent and sparse, the reconstruction can be treated as a problem of Underdetermined Independent Component Analysis (UICA), but UICA has some permutation and scaling ambiguities. In this paper we propose a reconstruction framework based on UICA and also some techniques to reduce the ambiguities. The cases that the attributes of the original data are correlated and not sparse are also common in data mining. We also propose a reconstruction method for the typical case of Multivariate Gaussian Distribution, based on the method of Maximum A Posterior (MAP). Our experiments show that our reconstructions can achieve high recovery rates, and outperform the reconstructions based on Principle Component Analysis (PCA).

#index 1267777
#* Identifying the Original Contribution of a Document via Language Modeling
#@ Benyah Shaparenko;Thorsten Joachims
#t 2009
#c 22
#% 262043
#% 279755
#% 722904
#% 766431
#% 769906
#% 874462
#% 875959
#% 876017
#% 879575
#% 881498
#% 956510
#% 983833
#% 989633
#% 1289476
#% 1650298
#! One major goal of text mining is to provide automatic methods to help humans grasp the key ideas in ever-increasing text corpora. To this effect, we propose a statistically well-founded method for identifying the original ideas that a document contributes to a corpus, focusing on self-referential diachronic corpora such as research publications, blogs, email, and news articles. Our statistical model of passage impact defines (interesting) original content through a combination of impact and novelty, and the model is used to identify each document's most original passages. Unlike heuristic approaches, the statistical model is extensible and open to analysis. We evaluate the approach both on synthetic data and on real data in the domains of research publications and news, showing that the passage impact model outperforms a heuristic baseline method.

#index 1267778
#* Relaxed Transfer of Different Classes via Spectral Partition
#@ Xiaoxiao Shi;Wei Fan;Qiang Yang;Jiangtao Ren
#t 2009
#c 22
#% 236497
#% 313959
#% 413610
#% 464291
#% 466675
#% 593972
#% 770804
#% 770858
#% 876034
#% 879615
#% 989592
#% 1073879
#% 1083655
#% 1083678
#% 1108855
#% 1108902
#! Most existing transfer learning techniques are limited to problems of knowledge transfer across tasks sharing the same set of class labels. In this paper, however, we relax this constraint and propose a spectral-based solution that aims at unveiling the intrinsic structure of the data and generating a partition of the target data, by transferring the eigenspace that well separates the source data. Furthermore, a clustering-based KL divergence is proposed to automatically adjust how much to transfer. We evaluate the proposed model on text and image datasets where class categories of the source and target data are explicitly different, e.g., 3-classes transfer to 2-classes, and show that the proposed approach improves other baselines by an average of 10% in accuracy. The source code and datasets are available from the authors.

#index 1267779
#* Mining Databases to Mine Queries Faster
#@ Arno Siebes;Diyah Puspitaningrum
#t 2009
#c 22
#% 216508
#% 232136
#% 322880
#% 501536
#% 575973
#% 769893
#% 878207
#% 985037
#% 1117081
#% 1349571
#% 1663670
#! Inductive databases are databases in which models and patterns are first class citizens. Having models and patterns in the database raises the question: do the models and patterns that are stored help in computing new models and patterns? For example, let C be a classifier on database DB and let Q be a query. Does knowing C speed up the induction of a new classifier on the result of Q ? In this paper we answer this problem positively for the code tables induced by our Krimp algorithm. More in particular, assume we have the code tables for all tables in the database. Then we can approximate the code table induced by Krimp on the result of a query, using only these global code tables as candidates. That is, we do not have to mine for frequent item sets on the query result.

#index 1267780
#* MACs: Multi-Attribute Co-clusters with High Correlation Information
#@ Kelvin Sim;Vivekanand Gopalkrishnan;Hon Nian Chua;See-Kiong Ng
#t 2009
#c 22
#% 729918
#% 765439
#% 765518
#% 778215
#% 810066
#% 881478
#% 915227
#% 926881
#% 1050100
#! In many real-world applications that analyze correlations between two groups of diverse entities, each group of entities can be characterized by multiple attributes. As such, there is a need to co-cluster multiple attributes' values into pairs of highly correlated clusters. We denote this co-clustering problem as the multi-attribute co-clustering problem. In this paper, we introduce a generalization of the mutual information between two attributes into mutual information between two attribute sets. The generalized formula enables us to use correlation information to discover multi-attribute co-clusters (MACs) . We develop a novel algorithm MACminer to mine MACs with high correlation information from datasets. We demonstrate the mining efficiency of MACminer in datasets with multiple attributes, and show that MACs with high correlation information have higher classification and predictive power, as compared to MACs generated by alternative high-dimensional data clustering and pattern mining techniques.

#index 1267781
#* Bi-directional Joint Inference for Entity Resolution and Segmentation Using Imperatively-Defined Factor Graphs
#@ Sameer Singh;Karl Schultz;Andrew Mccallum
#t 2009
#c 22
#% 452991
#% 729913
#% 742230
#% 788107
#% 850430
#% 915340
#% 1250579
#% 1261597
#% 1269815
#% 1270258
#% 1270685
#% 1273824
#% 1344885
#% 1810385
#! There has been growing interest in using joint inference across multiple subtasks as a mechanism for avoiding the cascading accumulation of errors in traditional pipelines. Several recent papers demonstrate joint inference between the segmentation of entity mentions and their de-duplication, however, they have various weaknesses: inference information flows only in one direction, the number of uncertain hypotheses is severely limited, or the subtasks are only loosely coupled. This paper presents a highly-coupled, bi-directional approach to joint inference based on efficient Markov chain Monte Carlo sampling in a relational conditional random field. The model is specified with our new probabilistic programming language that leverages imperative constructs to define factor graph structure and operation. Experimental results show that our approach provides a dramatic reduction in error while also running faster than the previous state-of-the-art system.

#index 1267782
#* Latent Dirichlet Allocation for Automatic Document Categorization
#@ István Bíró;Jácint Szabó
#t 2009
#c 22
#% 329569
#% 344447
#% 722904
#% 722935
#% 812535
#% 836717
#% 879587
#% 926881
#% 988151
#% 1125904
#% 1650387
#! In this paper we introduce and evaluate a technique for applying latent Dirichlet allocation to supervised semantic categorization of documents. In our setup, for every category an own collection of topics is assigned, and for a labeled training document only topics from its category are sampled. Thus, compared to the classical LDA that processes the entire corpus in one, we essentially build separate LDA models for each category with the category-specific topics, and then these topic collections are put together to form a unified LDA model. For an unseen document the inferred topic distribution gives an estimation how much the document fits into the category. We use this method for Web document classification. Our key results are 46% decrease in 1-AUC value in classification accuracy over tf.idf with SVM and 43% over the plain LDA baseline with SVM. Using a careful vocabulary selection method and a heuristic which handles the effect that similar topics may arise in distinct categories the improvement is 83% over tf.idf with SVM and 82% over LDA with SVM in 1-AUC.

#index 1267783
#* New Regularized Algorithms for Transductive Learning
#@ Partha Pratim Talukdar;Koby Crammer
#t 2009
#c 22
#% 57485
#% 466263
#% 616105
#% 961218
#% 1055761
#% 1074015
#% 1264778
#% 1264831
#! We propose a new graph-based label propagation algorithm for transductive learning. Each example is associated with a vertex in an undirected graph and a weighted edge between two vertices represents similarity between the two corresponding example. We build on Adsorption, a recently proposed algorithm and analyze its properties. We then state our learning algorithm as a convex optimization problem over multi-label assignments and derive an efficient algorithm to solve this problem. We state the conditions under which our algorithm is guaranteed to converge. We provide experimental evidence on various real-world datasets demonstrating the effectiveness of our algorithm over other algorithms for such problems. We also show that our algorithm can be extended to incorporate additional prior information, and demonstrate it with classifying data where the labels are not mutually exclusive.

#index 1267784
#* Enhancing the Performance of Centroid Classifier by ECOC and Model Refinement
#@ Songbo Tan;Gaowei Wu;Xueqi Cheng
#t 2009
#c 22
#% 219052
#% 280817
#% 311034
#% 375017
#% 397135
#% 458379
#% 464777
#% 465754
#% 466762
#% 478128
#% 577232
#% 577269
#% 838502
#% 1345708
#% 1345827
#! With the aim of improving the performance of centroid text classifier, we attempt to make use of the advantages of Error-Correcting Output Codes (ECOC) strategy. The framework is to decompose one multi-class problem into multiple binary problems and then learn the individual binary classification problems by centroid classifier. However, this kind of decomposition incurs considerable bias for centroid classifier, which results in noticeable degradation of performance for centroid classifier. In order to address this issue, we use Model-Refinement strategy to adjust this so-called bias. The basic idea is to take advantage of misclassified examples in the training data to iteratively refine and adjust the centroids of text data. The experimental results reveal that Model-Refinement strategy can dramatically decrease the bias introduced by ECOC, and the combined classifier is comparable to or even better than SVM classifier in performance.

#index 1267785
#* Optimal Online Learning Procedures for Model-Free Policy Evaluation
#@ Tsuyoshi Ueno;Shin-Ichi Maeda;Motoaki Kawanabe;Shin Ishii
#t 2009
#c 22
#% 3084
#% 203596
#% 258937
#% 384911
#% 393786
#% 425076
#% 431472
#% 770824
#% 818171
#% 1014677
#% 1074006
#! In this study, we extend the framework of semiparametric statistical inference introduced recently to reinforcement learning [1] to online learning procedures for policy evaluation. This generalization enables us to investigate statistical properties of value function estimators both by batch and online procedures in a unified way in terms of estimating functions. Furthermore, we propose a novel online learning algorithm with optimal estimating functions which achieve the minimum estimation error. Our theoretical developments are confirmed using a simple chain walk problem.

#index 1267786
#* Kernels for Periodic Time Series Arising in Astronomy
#@ Gabriel Wachman;Roni Khardon;Pavlos Protopapas;Charles R. Alcock
#t 2009
#c 22
#% 116149
#% 310502
#% 464633
#% 528164
#% 770865
#% 838404
#% 840863
#% 893161
#% 961137
#% 961190
#% 983922
#% 1066716
#% 1073950
#% 1073990
#% 1858193
#! We present a method for applying machine learning algorithms to the automatic classification of astronomy star surveys using time series of star brightness. Currently such classification requires a large amount of domain expert time. We show that a combination of phase invariant similarity and explicit features extracted from the time series provide domain expert level classification. To facilitate this application, we investigate the cross-correlation as a general phase invariant similarity function for time series. We establish several theoretical properties of cross-correlation showing that it is intuitively appealing and algorithmically tractable, but not positive semidefinite, and therefore not generally applicable with kernel methods. As a solution we introduce a positive semidefinite similarity function with the same intuitive appeal as cross-correlation. An experimental evaluation in the astronomy domain as well as several other data sets demonstrates the performance of the kernel and related similarity functions.

#index 1267787
#* K-Subspace Clustering
#@ Dingding Wang;Chris Ding;Tao Li
#t 2009
#c 22
#% 248792
#% 273891
#% 280417
#% 300131
#% 316481
#% 397384
#% 643008
#% 722902
#% 724227
#% 729918
#% 765518
#% 766434
#% 769935
#% 881468
#% 891559
#% 983869
#% 1117088
#% 1562582
#! The widely used K-means clustering deals with ball-shaped (spherical Gaussian) clusters. In this paper, we extend the K-means clustering to accommodate extended clusters in subspaces, such as line-shaped clusters, plane-shaped clusters, and ball-shaped clusters. The algorithm retains much of the K-means clustering flavors: easy to implement and fast to converge. A model selection procedure is incorporated to determine the cluster shape. As a result, our algorithm can recognize a wide range of subspace clusters studied in various literatures, and also the global ball-shaped clusters (living in all dimensions). We carry extensive experiments on both synthetic and real-world datasets, and the results demonstrate the effectiveness of our algorithm.

#index 1267788
#* Latent Dirichlet Bayesian Co-Clustering
#@ Pu Wang;Carlotta Domeniconi;Kathryn Blackmond Laskey
#t 2009
#c 22
#% 722904
#% 729918
#% 915330
#% 1176960
#! Co-clustering has emerged as an important technique for mining contingency data matrices. However, almost all existing co-clustering algorithms are hard partitioning, assigning each row and column of the data matrix to one cluster. Recently a Bayesian co-clustering approach has been proposed which allows a probability distribution membership in row and column clusters. The approach uses variational inference for parameter estimation. In this work, we modify the Bayesian co-clustering model, and use collapsed Gibbs sampling and collapsed variational inference for parameter estimation. Our empirical evaluation on real data sets shows that both collapsed Gibbs sampling and collapsed variational inference are able to find more accurate likelihood estimates than the standard variational Bayesian co-clustering approach.

#index 1267789
#* Variational Graph Embedding for Globally and Locally Consistent Feature Extraction
#@ Shuang-Hong Yang;Hongyuan Zha;S. Kevin Zhou;Bao-Gang Hu
#t 2009
#c 22
#% 80995
#% 593043
#% 722929
#% 722942
#% 770767
#% 814023
#% 889150
#% 913838
#% 937308
#% 961279
#% 983948
#% 1034713
#! Existing feature extraction methods explore either global statistical or local geometric information underlying the data. In this paper, we propose a general framework to learn features that account for both types of information based on variational optimization of nonparametric learning criteria. Using mutual information and Bayes error rate as example criteria, we show that high-quality features can be learned from a variational graph embedding procedure, which is solved through an iterative EM-style algorithm where the E-Step learns a variational affinity graph and the M-Step in turn embeds this graph by spectral analysis. The resulting feature learner has several appealing properties such as maximum discrimination , maximum-relevance- minimum-redundancy and locality-preserving . Experiments on benchmark face recognition data sets confirm the effectiveness of our proposed algorithms.

#index 1267790
#* Protein Identification from Tandem Mass Spectra with Probabilistic Language Modeling
#@ Yiming Yang;Abhay Harpale;Subramaniam Ganapathy
#t 2009
#c 22
#% 340948
#% 832642
#% 1424275
#! This paper presents an interdisciplinary investigation of statistical information retrieval (IR) techniques for protein identification from tandem mass spectra, a challenging problem in proteomic data analysis. We formulate the task as an IR problem, by constructing a "query vector" whose elements are system-predicted peptides with confidence scores based on spectrum analysis of the input sample, and by defining the vector space of "documents" with protein profiles, each of which is constructed based on the theoretical spectrum of a protein. This formulation establishes a new connection from the protein identification problem to a probabilistic language modeling approach as well as the vector space models in IR, and enables us to compare fundamental differences in the IR models and common approaches in protein identification. Our experiments on benchmark spectrometry query sets and large protein databases demonstrate that the IR models significantly outperform well-established methods in protein identification, by enhancing precision in high-recall regions in particular, where the conventional approaches are weak.

#index 1267791
#* Causality Discovery with Additive Disturbances: An Information-Theoretical Perspective
#@ Kun Zhang;Aapo Hyvärinen
#t 2009
#c 22
#% 115608
#% 297171
#% 645407
#% 891549
#% 961205
#% 1073925
#% 1117673
#% 1194417
#% 1269489
#% 1860500
#! We consider causally sufficient acyclic causal models in which the relationship among the variables is nonlinear while disturbances have linear effects, and show that three principles, namely, the causal Markov condition (together with the independence between each disturbance and the corresponding parents), minimum disturbance entropy, and mutual independence of the disturbances, are equivalent. This motivates new and more efficient methods for some causal discovery problems. In particular, we propose to use multichannel blind deconvolution, an extension of independent component analysis, to do Granger causality analysis with instantaneous effects. This approach gives more accurate estimates of the parameters and can easily incorporate sparsity constraints. For additive disturbance-based nonlinear causal discovery, we first make use of the conditional independence relationships to obtain the equivalence class; undetermined causal directions are then found by nonlinear regression and pairwise independence tests. This avoids the brute-force search and greatly reduces the computational load.

#index 1267792
#* Subspace Regularization: A New Semi-supervised Learning Method
#@ Yan-Ming Zhang;Xinwen Hou;Shiming Xiang;Cheng-Lin Liu
#t 2009
#c 22
#% 190581
#% 311027
#% 466263
#% 765552
#% 961218
#% 983878
#! Most existing semi-supervised learning methods are based on the smoothness assumption that data points in the same high density region should have the same label. This assumption, though works well in many cases, has some limitations. To overcome this problems, we introduce into semi-supervised learning the classic low-dimensionality embedding assumption, stating that most geometric information of high dimensional data is embedded in a low dimensional manifold. Based on this, we formulate the problem of semi-supervised learning as a task of finding a subspace and a decision function on the subspace such that the projected data are well separated and the original geometric information is preserved as much as possible. Under this framework, the optimal subspace and decision function are iteratively found via a projection pursuit procedure. The low computational complexity of the proposed method lends it to applications on large scale data sets. Experimental comparison with some previous semi-supervised learning methods demonstrates the effectiveness of our method.

#index 1267793
#* Heteroscedastic Probabilistic Linear Discriminant Analysis with Semi-supervised Extension
#@ Yu Zhang;Dit-Yan Yeung
#t 2009
#c 22
#% 80995
#% 235342
#% 275107
#% 278040
#% 293279
#% 304876
#% 360691
#% 466263
#% 732522
#% 753300
#% 784525
#% 791402
#% 803769
#% 881502
#% 891559
#% 916787
#% 961218
#% 1022958
#% 1108921
#% 1502471
#% 1667684
#% 1667701
#! Linear discriminant analysis (LDA) is a commonly used method for dimensionality reduction. Despite its successes, it has limitations under some situations, including the small sample size problem, the homoscedasticity assumption that different classes have the same Gaussian distribution, and its inability to produce probabilistic output and handle missing data. In this paper, we propose a semi-supervised and heteroscedastic extension of probabilistic LDA, called S2HPLDA, which aims at overcoming all these limitations under a common principled framework. Moreover, we apply automatic relevance determination to determine the required dimensionality of the low-dimensional space for dimensionality reduction. We empirically compare our method with several related probabilistic subspace methods on some face and object databases. Very promising results are obtained from the experiments showing the effectiveness of our proposed method.

#index 1267794
#* Semi-Supervised Multi-Task Regression
#@ Yu Zhang;Dit-Yan Yeung
#t 2009
#c 22
#% 236495
#% 236497
#% 252011
#% 304876
#% 466080
#% 466263
#% 466750
#% 723239
#% 769886
#% 770782
#% 770804
#% 840852
#% 840938
#% 840962
#% 855330
#% 891549
#% 891559
#% 916788
#% 961218
#% 961246
#% 983942
#% 1128929
#% 1269778
#% 1274924
#% 1665150
#! Labeled data are needed for many machine learning applications but the amount available in some applications is scarce. Semi-supervised learning and multi-task learning are two of the approaches that have been proposed to alleviate this problem. In this paper, we seek to integrate these two approaches for regression applications. We first propose a new supervised multi-task regression method called SMTR, which is based on Gaussian processes (GP) with the assumption that the kernel parameters for all tasks share a common prior. We then incorporate unlabeled data into SMTR by changing the kernel function of the GP prior to a data-dependent kernel function, resulting in a semi-supervised extension of SMTR, called SSMTR. Moreover, we incorporate pairwise information into SSMTR to further boost the learning performance for applications in which such information is available. Experiments conducted on two commonly used data sets for multi-task regression demonstrate the effectiveness of our methods.

#index 1267795
#* A Flexible and Efficient Algorithm for Regularized Fisher Discriminant Analysis
#@ Zhihua Zhang;Guang Dai;Michael I. Jordan
#t 2009
#c 22
#% 3084
#% 124470
#% 581716
#% 729437
#% 743284
#% 769912
#% 819917
#% 841687
#% 857439
#% 983940
#% 1828410
#! Fisher linear discriminant analysis (LDA) and its kernel extension--kernel discriminant analysis (KDA)--are well known methods that consider dimensionality reduction and classification jointly. While widely deployed in practical problems, there are still unresolved issues surrounding their efficient implementation and their relationship with least mean squared error procedures. In this paper we address these issues within the framework of regularized estimation. Our approach leads to a flexible and efficient implementation of LDA as well as KDA. We also uncover a general relationship between regularized discriminant analysis and ridge regression. This relationship yields variations on conventional LDA based on the pseudoinverse and a direct equivalence to an ordinary least squares estimator. Experimental results on a collection of benchmark data sets demonstrate the effectiveness of our approach.

#index 1267796
#* Debt Detection in Social Security by Sequence Classification Using Both Positive and Negative Patterns
#@ Yanchang Zhao;Huaifeng Zhang;Shanshan Wu;Jian Pei;Longbing Cao;Chengqi Zhang;Hans Bohlscheid
#t 2009
#c 22
#% 280441
#% 280488
#% 280515
#% 310559
#% 329537
#% 459006
#% 463903
#% 464996
#% 466483
#% 471264
#% 577249
#% 577256
#% 844035
#% 844344
#% 844814
#% 1040761
#% 1081949
#% 1117080
#% 1155719
#% 1196009
#% 1390144
#! Debt detection is important for improving payment accuracy in social security. Since debt detection from customer transactional data can be generally modelled as a fraud detection problem, a straightforward solution is to extract features from transaction sequences and build a sequence classifier for debts. The existing sequence classification methods based on sequential patterns consider only positive patterns. However, according to our experience in a large social security application, negative patterns are very useful in accurate debt detection. In this paper, we present a successful case study of debt detection in a large social security application. The central technique is building sequence classification using both positive and negative sequential patterns.

#index 1267797
#* Learning the Difference between Partially Observable Dynamical Systems
#@ Sami Zhioua;Doina Precup;François Laviolette;Josée Desharnais
#t 2009
#c 22
#% 104387
#% 115608
#% 384911
#% 425074
#% 780271
#% 788097
#% 1290265
#% 1666378
#% 1734009
#! We propose a new approach for estimating the difference between two partially observable dynamical systems. We assume that one can interact with the systems by performing actions and receiving observations. The key idea is to define a Markov Decision Process (MDP) based on the systems to be compared, in such a way that the optimal value of the MDP initial state can be interpreted as a divergence (or dissimilarity) between the systems. This dissimilarity can then be estimated by reinforcement learning methods. Moreover, the optimal policy will contain information about the actions which most distinguish the systems. Empirical results show that this approach is useful in detecting both big and small differences, as well as in comparing systems with different internal structure.

#index 1267798
#* Universal Learning over Related Distributions and Adaptive Graph Transduction
#@ Erheng Zhong;Wei Fan;Jing Peng;Olivier Verscheure;Jiangtao Ren
#t 2009
#c 22
#% 842682
#% 926881
#% 1074015
#% 1083678
#% 1270196
#! The basis assumption that "training and test data drawn from the same distribution" is often violated in reality. In this paper, we propose one common solution to cover various scenarios of learning under "different but related distributions" in a single framework. Explicit examples include (a) sample selection bias between training and testing data, (b) transfer learning or no labeled data in target domain, and (c) noisy or uncertain training data. The main motivation is that one could ideally solve as many problems as possible with a single approach. The proposed solution extends graph transduction using the maximum margin principle over unlabeled data. The error of the proposed method is bounded under reasonable assumptions even when the training and testing distributions are different. Experiment results demonstrate that the proposed method improves the traditional graph transduction by as much as 15% in accuracy and AUC in all common situations of distribution difference. Most importantly, it outperforms, by up to 10% in accuracy, several state-of-art approaches proposed to solve specific category of distribution difference, i.e, BRSD [1] for sample selection bias, CDSC [2] for transfer learning, etc. The main claim is that the adaptive graph transduction is a general and competitive method to solve distribution differences implicitly without knowing and worrying about the exact type. These at least include sample selection bias, transfer learning, uncertainty mining, as well as those alike that are still not studied yet. The source code and datasets are available from the authors.

#index 1267799
#* The Feature Importance Ranking Measure
#@ Alexander Zien;Nicole Krämer;Sören Sonnenburg;Gunnar Rätsch
#t 2009
#c 22
#% 763697
#% 833124
#% 853741
#% 961190
#% 1717571
#! Most accurate predictions are typically obtained by learning machines with complex feature spaces (as e.g. induced by kernels). Unfortunately, such decision rules are hardly accessible to humans and cannot easily be used to gain insights about the application domain. Therefore, one often resorts to linear models in combination with variable selection, thereby sacrificing some predictive power for presumptive interpretability. Here, we introduce the Feature Importance Ranking Measure (FIRM), which by retrospective analysis of arbitrary learning machines allows to achieve both excellent predictive performance and superior interpretation. In contrast to standard raw feature weighting, FIRM takes the underlying correlation structure of the features into account. Thereby, it is able to discover the most relevant features, even if their appearance in the training data is entirely prevented by noise. The desirable properties of FIRM are investigated analytically and illustrated in simulations.

#index 1267800
#* OTTHO: On the Tip of My THOught
#@ Pierpaolo Basile;Marco Gemmis;Pasquale Lops;Giovanni Semeraro
#t 2009
#c 22
#% 252328
#% 1269584
#% 1305537
#% 1413165
#! This paper describes OTTHO (On the Tip of my THOught), a system designed for solving a language game called Guillotine . The rule of the game is simple: the player observes five words, generally unrelated to each other, and in one minute she has to provide a sixth word, semantically connected to the others. The system exploits several knowledge sources, such as a dictionary, a set of proverbs, and Wikipedia to realize a knowledge infusion process. The main motivation for designing an artificial player for Guillotine is the challenge of providing the machine with the cultural and linguistic background knowledge which makes it similar to a human being, with the ability of interpreting natural language documents and reasoning on their content. Our feeling is that the approach presented in this work has a great potential for other more practical applications besides solving a language game.

#index 1267801
#* Protecting Sensitive Topics in Text Documents with PROTEXTOR
#@ Chad Cumby
#t 2009
#c 22
#% 458389
#% 466078
#% 576762
#% 864412
#% 1083723
#! This is a demonstration of a system for protecting sensitive topics present in text documents. Our system works in a privacy framework where the topic is characterized as a multiclass classification problem in a generative setting. We show how our system helps a user redact a document in a business setting to obscure what company the text pertains to, and show some experimental results on redacting the topic for a standard text classification data set.

#index 1267802
#* Enhanced Web Page Content Visualization with Firefox
#@ Lorand Dali;Delia Rusu;Dunja Mladenić
#t 2009
#c 22
#! This paper aims at presenting how natural language processing and machine learning techniques can help the internet surfer to get a better overview of the pages he is reading. The proposed demo is a Firefox extension which can show a semantic graph of the text in the page that is currently loaded in the browser. The user can also get a summary of the web page she is looking at by choosing to display only the more important nodes in the semantic graph representation of the document, where importance of the nodes is obtained by machine learning techniques.

#index 1267803
#* ClusTR: Exploring Multivariate Cluster Correlations and Topic Trends
#@ Luigi Caro;Alejandro Jaimes
#t 2009
#c 22
#% 137473
#% 358412
#% 477817
#% 789224
#% 881050
#% 956494
#! We present a demonstration of ClusTR, a highly interactive system for exploring relationships between different clusterings of a dataset and for viewing the evolution in time of topics (e.g., tags associated with objects in the dataset) within and across such clusters. In particular, ClusTR allows exploration of generic multi-dimensional, text labeled and time sensitive data.

#index 1267804
#* Visual OntoBridge: Semi-automatic Semantic Annotation Software
#@ Miha Grcar;Dunja Mladenic
#t 2009
#c 22
#! Machine learning methods have been successfully used for data labeling, also referred to as data annotation, either in semi-automatic or fully automatic way. We present a system for semi-automatic annotation of Web service schemas and other resources with the motivation to support efficient browse and search through those resources and to enable efficient composition and execution of Web services. The presented system, Visual OntoBridge (VOB), provides a graphical user interface and employs a set of machine learning algorithms to support the user in the annotation task.

#index 1267805
#* Semi-automatic Categorization of Videos on VideoLectures.net
#@ Miha Grcar;Dunja Mladenic;Peter Kese
#t 2009
#c 22
#% 422115
#% 464615
#% 465747
#! Automatic or semi-automatic categorization of items (e.g. documents) into a taxonomy is an important and challenging machine-learning task. In this paper, we present a module for semi-automatic categorization of video-recorded lectures. Properly categorized lectures provide the user with a better browsing experience which makes her more efficient in accessing the desired content. Our categorizer combines information found in texts associated with lectures and information extracted from various links between lectures in a unified machine-learning framework. By taking not only texts but also the links into account, the classification accuracy is increased by 12---20%.

#index 1267806
#* Discovering Patterns in Flows: A Privacy Preserving Approach with the ACSM Prototype
#@ Stéphanie Jacquemont;François Jacquenet;Marc Sebban
#t 2009
#c 22
#% 907564
#% 1015813
#% 1074831
#% 1183445
#% 1215868
#% 1440242
#! In this demonstration, we aim to present the ACSM prototype that deals with the discovery of frequent patterns in the context of flow management problems. One important issue while working on such problems is to ensure the preservation of private data collected from the users. The approach presented here is based on the representation of flows in the form of probabilistic automata. Resorting to efficient algebraic techniques, the ACSM prototype is able to discover from those automata sequential patterns under constraints. Contrary to standard sequential pattern techniques that may be applied in such contexts, our prototype makes no use of individuals data.

#index 1267807
#* Using Temporal Language Models for Document Dating
#@ Nattiya Kanhabua;Kjetil Nørvåg
#t 2009
#c 22
#% 262096
#% 730070
#% 755899
#% 810921
#% 1107069
#! In order to increase precision in searching for web pages or web documents, taking the temporal dimension into account is gaining increased interest. A particular problem for web documents found on the Internet is that in general, no trustworthy timestamp is available. This is due to its decentralized nature and the lack of standards for time and date. In previous work we have presented techniques for solving this problem. In this paper, we present a tool for determining the timestamp of a non-timestamped document (using file, URL or text as input) using temporal language models. We also outline how this tool will be demonstrated.

#index 1267808
#* Omiotis: A Thesaurus-Based Measure of Text Relatedness
#@ George Tsatsaronis;Iraklis Varlamis;Michalis Vazirgiannis;Kjetil Nørvåg
#t 2009
#c 22
#% 814007
#% 896031
#% 1110198
#% 1250629
#% 1260784
#% 1269643
#! In this paper we present a new approach for measuring the relatedness between text segments, based on implicit semantic links between their words, as offered by a word thesaurus, namely WordNet. The approach does not require any type of training, since it exploits only WordNet to devise the implicit semantic links between text words. The paper presents a prototype on-line demo of the measure, that can provide word-to-word relatedness values, even for words of different part of speech. In addition the demo allows for the computation of relatedness between text segments.

#index 1267809
#* Found in Translation
#@ Marco Turchi;Ilias Flaounas;Omar Ali;Tijl Bie;Tristan Snowsill;Nello Cristianini
#t 2009
#c 22
#% 740915
#% 816170
#% 910797
#% 995468
#% 1215368
#! We present a complete working system that gathers multilingual news items from the Web, translates them into English, categorises them by topic and geographic location and presents them to the final user in a uniform way. Currently, the system crawls 560 news outlets, in 22 different languages, from the 27 European Union countries. Data gathering is based on RSS crawlers, machine translation on Moses and the text categorisation on SVMs. The system also presents on a European map statistical information about the amount of attention devoted to the various topics in each of the 27 EU countries. The integration of Support Vector Machines, Statistical Machine Translation, Web Technologies and Computer Graphics delivers a complete system where modern Statistical Machine Learning is used at multiple levels and is a crucial enabling part of the resulting functionality.

#index 1267810
#* A Community-Based Platform for Machine Learning Experimentation
#@ Joaquin Vanschoren;Hendrik Blockeel
#t 2009
#c 22
#% 478772
#% 926881
#% 1100127
#% 1164309
#% 1742004
#! We demonstrate the practical uses of a community-based platform for the sharing and in-depth investigation of the thousands of machine learning experiments executed every day. It is aimed at researchers and practitioners of data mining techniques, and is publicly available at http://expdb.cs.kuleuven.be . The system offers standards and API's for sharing experimental results, extensive querying capabilities of the gathered results and allows easy integration in existing data mining toolboxes. We believe such a system may speed up scientific discovery and enhance the scientific rigor of machine learning research.

#index 1267811
#* TeleComVis: Exploring Temporal Communities in Telecom Networks
#@ Qi Ye;Bin Wu;Lijun Suo;Tian Zhu;Chao Han;Bai Wang
#t 2009
#c 22
#% 844513
#! By the structure of call graphs derived from huge amounts of Call Detail Records, we can find out the social communities in the call graphs and make different market strategies for these social communities in real telecom applications. However, traditional telecom business intelligence methods are short of ways to understand the social interactions. To fill this gap, we propose a Tele com Com munity Vis ual Analysis prototype tool, called TeleComVis , to analyze the call graphs derived from Call Detail Records. In the demo, we will show (1) the functions of TeleComVis ; (2) the critical techniques of finding statistically significant communities in real-world telecom applications. Using TeleComVis , users can both analyze the statistical properties of massive call graphs and explore the statistically significant communities and the temporal links interactively.

#index 1268015
#* Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part I
#@ Wray Buntine;Marko Grobelnik;Dunja Mladenić;John Shawe-Taylor
#t 2009
#c 22

#index 1268016
#* Theory-Practice Interplay in Machine Learning --- Emerging Theoretical Challenges
#@ Shai Ben-David
#t 2009
#c 22
#! Theoretical analysis has played a major role in some of the most prominent practical successes of statistical machine learning. However, mainstream machine learning theory assumes some strong simplifying assumptions which are often unrealistic. In the past decade, the practice of machine learning has led to the development of various heuristic paradigms that answer the needs of a vastly growing range of applications. Many useful such paradigms fall beyond the scope of the currently available analysis. Will theory play a similar pivotal role in the newly emerging sub areas of machine learning? In this talk, I will survey some such application-motivated theoretical challenges. In particular, I will discuss recent developments in the theoretical analysis of semi-supervised learning, multi-task learning, "learning to learn", privacy-preserving learning and more.

#index 1268017
#* Are We There Yet?
#@ Nello Cristianini
#t 2009
#c 22
#! Statistical approaches to Artificial Intelligence are behind most success stories of the field in the past decade. The idea of generating non-trivial behaviour by analysing vast amounts of data has enabled recommendation systems, search engines, spam filters, optical character recognition, machine translation and speech recognition. As we celebrate the spectacular achievements of this line of research, we need to assess its full potential, its limitations and its position within the larger scheme of things. What are the next steps to take towards machine intelligence?

#index 1268018
#* The Growing Semantic Web
#@ Mark Greaves
#t 2009
#c 22
#! From its beginnings in 2004, the data available on the web in Semantic Web formats has typically been both eclectic and relatively small, and closely linked the interests of particular researchers. In the past year, however, the quantity and scope of data published on the public semantic web has exploded, and the size of the semantic web is now measured in the billions of assertions. It is a significant and growing resource for applications which depend on web-based resources for some or all of their knowledge. With this massive increase in quantity and scope come many opportunities, as well as the usual issues of scale on the web: inconsistency, mapping problems, incompleteness and data variability. This talk will cover the history and current state of the Semantic Web and the Linked Data Cloud, describe some of the uses to which web-based semantic data is currently put, and discuss prospects for the ECML/PKDD community to leverage this growing web of data.

#index 1268019
#* Privacy in Web Search Query Log Mining
#@ Rosie Jones
#t 2009
#c 22
#! Web search engines have changed our lives - enabling instant access to information about subjects that are both deeply important to us, as well as passing whims. The search engines that provide answers to our search queries also log those queries, in order to improve their algorithms. Academic research on search queries has shown that they can provide valuable information on diverse topics including word and phrase similarity, topical seasonality and may even have potential for sociology, as well as providing a barometer of the popularity of many subjects. At the same time, individuals are rightly concerned about what the consequences of accidental leaking or deliberate sharing of this information may mean for their privacy. In this talk I will cover the applications which have benefited from mining query logs, the risks that privacy can be breached by sharing query logs, and current algorithms for mining logs in a way to prevent privacy breaches.

#index 1268020
#* Highly Multilingual News Analysis Applications
#@ Ralf Steinberger
#t 2009
#c 22
#! The publicly accessible Europe Media Monitor (EMM) family of applications (http://press.jrc.it/overview.html) gather and analyse an average of 80,000 to 100,000 online news articles per day in up to 43 languages. Through the extraction of meta-information in these articles, they provide an aggregated view of the news; they allow to monitor trends and to navigate the news over time and even across languages. EMM-NewsExplorer additionally collects historical information about persons and organisations from the multilingual news, generates co-occurrence and quotation-based social networks, and more. All EMM applications were entirely developed at, and are being maintained by, the European Commission's Joint Research Centre (JRC) in Ispra, Italy. The applications make combined use of a variety of text analysis tools, including clustering, multi-label document classification, named entity recognition, name variant matching across languages and writing systems, topic detection and tracking, event scenario template filling, and more. Due to the high number of languages covered, linguistics-poor methods were used for the development of these text mining components. See the site http://langtech.jrc.it/ for technical details and a list of publications. The speaker will give an overview of the various applications and will then explain the workings of selected text analysis components.

#index 1268021
#* Combining Instance-Based Learning and Logistic Regression for Multilabel Classification
#@ Weiwei Cheng;Eyke Hüllermeier
#t 2009
#c 22
#% 1264044
#! Multilabel classification is an extension of conventional classification in which a single instance can be associated with multiple labels. Recent research has shown that, just like for conventional classification, instance-based learning algorithms relying on the nearest neighbor estimation principle can be used quite successfully in this context. However, since hitherto existing algorithms do not take correlations and interdependencies between labels into account, their potential has not yet been fully exploited. In this paper, we propose a new approach to multilabel classification, which is based on a framework that unifies instance-based learning and logistic regression, comprising both methods as special cases. This approach allows one to capture interdependencies between labels and, moreover, to combine model-based and similarity-based inference for multilabel classification. As will be shown by experimental studies, our approach is able to improve predictive accuracy in terms of several evaluation criteria for multilabel prediction.

#index 1268022
#* On Structured Output Training: Hard Cases and an Efficient Alternative
#@ Thomas Gärtner;Shankar Vembu
#t 2009
#c 22
#% 1264049
#! State-of-the-art structured prediction algorithms can be applied using off-the-shelf tools by implementing a joint kernel for inputs and outputs, and an algorithm for inference. The kernel is used for mapping the data to an appropriate feature space, while the inference algorithm is used for successively adding violated constraints to the optimisation problem. While this approach leads to efficient learning algorithms for many important real world problems, there are also many cases in which successively adding violated constraints is infeasible. As a simple yet relevant problem, we consider the prediction of routes (cyclic permutations) over a given set of points of interest. Solving this problem has many potential applications. For car drivers, prediction of individual routes can be used for intelligent car sharing applications or help optimise a hybrid vehicle's charge/discharge schedule. We show that state-of-the-art structured prediction algorithms cannot guarantee polynomial runtime for this output set of cyclic permutations.

#index 1268023
#* Sparse Kernel SVMs via Cutting-Plane Training
#@ Thorsten Joachims;Chun-Nam John Yu
#t 2009
#c 22
#% 734919
#% 961154
#% 1264050
#! While Support Vector Machines (SVMs) with kernels offer great flexibility and prediction performance on many application problems, their practical use is often hindered by the following two problems. Both problems can be traced back to the number of Support Vectors (SVs), which is known to generally grow linearly with the data set size [1]. First, training is slower than other methods and linear SVMs, where recent advances in training algorithms vastly improved training time. $h(x)={\rm sign} \left[\sum^{\#SV}_{i=1} \alpha_iK(x_i, x)\right]$ it is too expensive to evaluate in many applications when the number of SVs is large.

#index 1268024
#* Hybrid Least-Squares Algorithms for Approximate Policy Evaluation
#@ Jeff Johns;Marek Petrik;Sridhar Mahadevan
#t 2009
#c 22
#% 1264046
#! The goal of approximate policy evaluation is to "best" represent a target value function according to a specific criterion. Different algorithms offer different choices of the optimization criterion. Two popular least-squares algorithms for performing this task are the Bellman residual method, which minimizes the Bellman residual, and the fixed point method, which minimizes the projection of the Bellman residual. When used within policy iteration, the fixed point algorithm tends to ultimately find better performing policies whereas the Bellman residual algorithm exhibits more stable behavior between rounds of policy iteration. We propose two hybrid least-squares algorithms to try to combine the advantages of these algorithms. We provide an analytical and geometric interpretation of hybrid algorithms and demonstrate their utility on a simple problem. Experimental results on both small and large domains suggest hybrid algorithms may find solutions that lead to better policies when performing policy iteration.

#index 1268025
#* A Self-training Approach to Cost Sensitive Uncertainty Sampling
#@ Alexander Liu;Goo Jun;Joydeep Ghosh
#t 2009
#c 22
#% 1264047
#! Uncertainty sampling is an effective method for performing active learning that is computationally efficient compared to other active learning methods such as loss-reduction methods. However, unlike loss-reduction methods, uncertainty sampling cannot minimize total misclassification costs when errors incur different costs. This paper introduces a method for performing cost-sensitive uncertainty sampling that makes use of self-training. We show that, even when misclassification costs are equal, this self-training approach results in faster reduction of loss as a function of number of points labeled and more reliable posterior probability estimates as compared to standard uncertainty sampling. We also show why other more naive methods of modifying uncertainty sampling to minimize total misclassification costs will not always work well.

#index 1268026
#* Learning Multi-linear Representations of Distributions for Efficient Inference
#@ Dan Roth;Rajhans Samdani
#t 2009
#c 22
#% 1264048
#! We examine the class of multi-linear polynomial representations (MLR) for expressing probability distributions over discrete variables. Recently, MLR have been considered as intermediate representations that facilitate inference in distributions represented as graphical models. We show that MLR is an expressive representation of discrete distributions and can be used to concisely represent classes of distributions which have exponential size in other commonly used representations, while supporting probabilistic inference in time linear in the size of the representation. Our key contribution is presenting techniques for learning bounded-size distributions represented using MLR, which support efficient probabilistic inference. We propose algorithms for exact and approximate learning for MLR and, through a comparison with Bayes Net representations, demonstrate experimentally that MLR representations provide faster inference without sacrificing inference accuracy.

#index 1268027
#* Cost-Sensitive Learning Based on Bregman Divergences
#@ Raúl Santos-Rodríguez;Alicia Guerrero-Curieses;Rocío Alaiz-Rodríguez;Jesús Cid-Sueiro
#t 2009
#c 22
#% 1264045
#! This paper analyzes the application of a particular class of Bregman divergences to design cost-sensitive classifiers for multiclass problems. We show that these divergence measures can be used to estimate posterior probabilities with maximal accuracy for the probability values that are close to the decision boundaries. Asymptotically, the proposed divergence measures provide classifiers minimizing the sum of decision costs in non-separable problems, and maximizing a margin in separable MAP problems.

#index 1268028
#* RTG: A Recursive Realistic Graph Generator Using Random Typing
#@ Leman Akoglu;Christos Faloutsos
#t 2009
#c 22
#% 146494
#% 209895
#% 250199
#% 283833
#% 438553
#% 623261
#% 653861
#% 659965
#% 823342
#% 867050
#% 991194
#% 1082672
#% 1083682
#% 1176970
#% 1176979
#% 1394202
#% 1404187
#% 1673564
#% 1815166
#! We propose a new, recursive model to generate realistic graphs, evolving over time. Our model has the following properties: it is (a) flexible, capable of generating the cross product of weighted/ unweighted, directed/undirected, uni/bipartite graphs; (b) realistic, giving graphs that obey eleven static and dynamic laws that real graphs follow (we formally prove that for several of the (power) laws and we estimate their exponents as a function of the model parameters); (c) parsimonious, requiring only four parameters. (d) fast, being linear on the number of edges; (e) simple, intuitively leading to the generation of macroscopic patterns. We empirically show that our model mimics two real-world graphs very well: Blognet (unipartite, undirected, unweighted) with 27K nodes and 125K edges; and Committee-to-Candidate campaign donations (bipartite, directed, weighted) with 23K nodes and 880K edges. We also show how to handle time so that edge/weight additions are bursty and self-similar.

#index 1268029
#* Taxonomy-Driven Lumping for Sequence Mining
#@ Francesco Bonchi;Carlos Castillo;Debora Donato;Aristides Gionis
#t 2009
#c 22
#% 1263960
#! In many application domains, events are naturally organized in a hierarchy. Whether events describe human activities, system failures, coordinates in a trajectory, or biomedical phenomena, there is often a taxonomy that should be taken into consideration. A taxonomy allow us to represent the information at a more general description level, if we choose carefully the most suitable level of granularity. Given a taxonomy of events and a dataset of sequences of these events, we study the problem of finding efficient and effective ways to produce a compact representation of the sequences. This can be valuable by itself, or can be used to help solving other problems, such as clustering.

#index 1268030
#* On Subgroup Discovery in Numerical Domains
#@ Henrik Grosskreutz;Stefan Rüping
#t 2009
#c 22
#% 1263962
#! Subgroup discovery is a Knowledge Discovery task that aims at finding subgroups of a population with high generality and distributional unusualness. While several subgroup discovery algorithms have been presented in the past, they focus on databases with nominal attributes or make use of discretization to get rid of the numerical attributes. In this paper, we illustrate why the replacement of numerical attributes by nominal attributes can result in suboptimal results. Thereafter, we present a new subgroup discovery algorithm that prunes large parts of the search space by exploiting bounds between related numerical subgroup descriptions. The same algorithm can also be applied to ordinal attributes. In an experimental section, we show that the use of our new pruning scheme results in a huge performance gain when more that just a few split-points are considered for the numerical attributes.

#index 1268031
#* Harnessing the Strengths of Anytime Algorithms for Constant Data Streams
#@ Philipp Kranen;Thomas Seidl
#t 2009
#c 22
#% 1263955
#! Anytime algorithms have been proposed for many different applications e.g. in data mining. Their strengths are the ability to first provide a result after a very short initialization and second to improve their result with additional time. Therefore, anytime algorithms have so far been used when the available processing time varies, e.g. on varying data streams. In this paper we propose to employ anytime algorithms on constant data streams, i.e. for tasks with constant time allowance. We introduce two approaches that harness the strengths of anytime algorithms on constant data streams and thereby improve the over all quality of the result with respect to the corresponding budget algorithm. We derive formulas for the expected performance gain and demonstrate the effectiveness of our novel approaches using existing anytime algorithms on benchmark data sets. The goal that was set and reached in this paper is to improve the quality of the result over that of traditional budget approaches, which are used in an abundance of stream mining applications. Using anytime classification as an example application we show for SVM, Bayes and nearest neighbor classifiers that both our novel approaches improve the classification accuracy for slow and fast data streams. The results confirm our general theoretic models and show the effectiveness of our approaches. The simple yet effective idea can be employed for any anytime algorithm along with a quality measure and motivates further research in e.g. classification confidence measures or anytime algorithms.

#index 1268032
#* Identifying the Components
#@ Matthijs Leeuwen;Jilles Vreeken;Arno Siebes
#t 2009
#c 22
#% 1263961
#! Most, if not all, databases are mixtures of samples from different distributions. In many cases, however, nothing is known about the source components of these mixtures. Therefore, many methods that induce models regard a database as sampled from a single data distribution. Models that do take into account that databases actually are sampled from mixtures of distributions are often superior to those that do not, independent of whether this is modelled explicitly or implicitly.

#index 1268033
#* Two-Way Analysis of High-Dimensional Collinear Data
#@ Ilkka Huopaniemi;Tommi Suvitaival;Janne Nikkilä;Matej Orešič;Samuel Kaski
#t 2009
#c 22
#% 1263956
#! We present a Bayesian model for two-way ANOVA-type analysis of high-dimensional, small sample-size datasets with highly correlated groups of variables. Modern cellular measurement methods are a main application area; typically the task is differential analysis between diseased and healthy samples, complicated by additional covariates requiring a multi-way analysis. The main complication is the combination of high dimensionality and low sample size, which renders classical multivariate techniques useless. We introduce a hierarchical model which does dimensionality reduction by assuming that the input variables come in similarly-behaving groups, and performs an ANOVA-type decomposition for the set of reduced-dimensional latent variables. We apply the methods to study lipidomic profiles of a recent large-cohort human diabetes study.

#index 1268034
#* A Fast Ensemble Pruning Algorithm Based on Pattern Mining Process
#@ Qiang-Li Zhao;Yan-Huang Jiang;Ming Xu
#t 2009
#c 22
#% 1263958
#! Ensemble pruning deals with the reduction of base classifiers prior to combination in order to improve generalization and prediction efficiency. Existing ensemble pruning algorithms require much pruning time. This paper presents a fast pruning approach: PMEP (Pattern Mining based Ensemble Pruning). In this algorithm, the prediction results of all base classifiers are organized as a transaction database, and FP-Tree structure is used to compact the prediction results. Then a greedy pattern mining method is explored to find the ensemble of size k . After obtaining the ensembles of all possible sizes, the one with the best accuracy is outputted. Compared with Bagging, GASEN, and Forward Selection, experimental results show that PMEP achieves the best prediction accuracy and keeps the size of the final ensemble small, more importantly, its pruning time is much less than other ensemble pruning algorithms.

#index 1268035
#* Evaluation Measures for Multi-class Subgroup Discovery
#@ Tarek Abudawood;Peter Flach
#t 2009
#c 22
#% 99396
#% 232126
#% 424759
#% 449566
#% 521043
#% 550575
#% 579525
#% 763701
#% 793250
#% 799042
#% 926881
#% 961134
#% 1290052
#% 1669865
#% 1860941
#! Subgroup discovery aims at finding subsets of a population whose class distribution is significantly different from the overall distribution. It has previously predominantly been investigated in a two-class context. This paper investigates multi-class subgroup discovery methods. We consider six evaluation measures for multi-class subgroups, four of them new, and study their theoretical properties. We extend the two-class subgroup discovery algorithm CN2-SD to incorporate the new evaluation measures and a new weighting scheme inspired by AdaBoost. We demonstrate the usefulness of multi-class subgroup discovery experimentally, using discovered subgroups as features for a decision tree learner. Not only is the number of leaves of the decision tree reduced with a factor between 8 and 16 on average, but significant improvements in accuracy and AUC are achieved with particular evaluation measures and settings. Similar performance improvements can be observed when using naive Bayes.

#index 1268036
#* Empirical Study of Relational Learning Algorithms in the Phase Transition Framework
#@ Erick Alphonse;Aomar Osmani
#t 2009
#c 22
#% 26115
#% 167643
#% 175378
#% 180945
#% 229811
#% 283229
#% 341489
#% 449515
#% 458672
#% 543917
#% 550415
#% 604688
#% 723256
#% 723257
#% 731610
#% 835098
#% 872870
#% 977568
#% 1096499
#% 1108075
#% 1272314
#% 1279714
#% 1289361
#! Relational Learning (RL) has aroused interest to fill the gap between efficient attribute-value learners and growing applications stored in multi-relational databases. However, current systems use general- purpose problem solvers that do not scale-up well. This is in contrast with the past decade of success in combinatorics communities where studies of random problems, in the phase transition framework, allowed to evaluate and develop better specialised algorithms able to solve real-world applications up to millions of variables. A number of studies have been proposed in RL, like the analysis of the phase transition of a NP-complete sub-problem, the subsumption test, but none has directly studied the phase transition of RL. As RL, in general, is ${\it \Sigma}_2-hard$, we propose a first random problem generator, which exhibits the phase transition of its decision version, beyond NP. We study the learning cost of several learners on inherently easy and hard instances, and conclude on expected benefits of this new benchmarking tool for RL.

#index 1268037
#* Topic Significance Ranking of LDA Generative Models
#@ Loulwah Alsumait;Daniel Barbará;James Gentle;Carlotta Domeniconi
#t 2009
#c 22
#% 340903
#% 722904
#% 835018
#% 881498
#% 891559
#% 1176853
#! Topic models, like Latent Dirichlet Allocation (LDA), have been recently used to automatically generate text corpora topics, and to subdivide the corpus words among those topics. However, not all the estimated topics are of equal importance or correspond to genuine themes of the domain. Some of the topics can be a collection of irrelevant words, or represent insignificant themes. Current approaches to topic modeling perform manual examination to find meaningful topics. This paper presents the first automated unsupervised analysis of LDA models to identify junk topics from legitimate ones, and to rank the topic significance. Basically, the distance between a topic distribution and three definitions of "junk distribution" is computed using a variety of measures, from which an expressive figure of the topic significance is implemented using 4-phase Weighted Combination approach. Our experiments on synthetic and benchmark datasets show the effectiveness of the proposed approach in ranking the topic significance.

#index 1268038
#* Communication-Efficient Classification in P2P Networks
#@ Hock Hee Ang;Vivekanand Gopalkrishnan;Wee Keong Ng;Steven Hoi
#t 2009
#c 22
#% 340175
#% 424996
#% 429749
#% 840003
#% 888878
#% 915500
#% 989669
#% 1108838
#% 1742091
#% 1861262
#! Distributed classification aims to learn with accuracy comparable to that of centralized approaches but at far lesser communication and computation costs. By nature, P2P networks provide an excellent environment for performing a distributed classification task due to the high availability of shared resources, such as bandwidth, storage space, and rich computational power. However, learning in P2P networks is faced with many challenging issues; viz., scalability, peer dynamism, asynchronism and fault-tolerance. In this paper, we address these challenges by presenting CEMPaR--a communication-efficient framework based on cascading SVMs that exploits the characteristics of DHT-based lookup protocols. CEMPaR is designed to be robust to parameters such as the number of peers in the network, imbalanced data sizes and class distribution while incurring extremely low communication cost yet maintaining accuracy comparable to the best-in-the-class approaches. Feasibility and effectiveness of our approach are demonstrated with extensive experimental studies on real and synthetic datasets.

#index 1268039
#* A Generalization of Forward-Backward Algorithm
#@ Ai Azuma;Yuji Matsumoto
#t 2009
#c 22
#% 464434
#% 464644
#% 770759
#% 788036
#% 876066
#% 939527
#% 939940
#! Structured prediction has become very important in recent years. A simple but notable class of structured prediction is one for sequences, so-called sequential labeling. For sequential labeling, it is often required to take a summation over all the possible output sequences, when estimating the parameters of a probabilistic model for instance. We cannot make the direct calculation of such a summation from its definition in practice. Although the ordinary forward-backward algorithm provides an efficient way to do it, it is applicable to limited types of summations. In this paper, we propose a generalization of the forward-backward algorithm, by which we can calculate much broader types of summations than the existing forward-backward algorithms. We show that this generalization subsumes some existing calculations required in past studies, and we also discuss further possibilities of this generalization.

#index 1268040
#* Mining Graph Evolution Rules
#@ Michele Berlingerio;Francesco Bonchi;Björn Bringmann;Aristides Gionis
#t 2009
#c 22
#% 466644
#% 629708
#% 823342
#% 841960
#% 881460
#% 881493
#% 893371
#% 915366
#% 989640
#% 989643
#% 1030877
#% 1083675
#% 1176866
#% 1176892
#% 1176913
#% 1206603
#% 1393168
#% 1411112
#% 1674705
#! In this paper we introduce graph-evolution rules , a novel type of frequency-based pattern that describe the evolution of large networks over time, at a local level. Given a sequence of snapshots of an evolving graph, we aim at discovering rules describing the local changes occurring in it. Adopting a definition of support based on minimum image we study the problem of extracting patterns whose frequency is larger than a minimum support threshold. Then, similar to the classical association rules framework, we derive graph-evolution rules from frequent patterns that satisfy a given minimum confidence constraint. We discuss merits and limits of alternative definitions of support and confidence, justifying the chosen framework. To evaluate our approach we devise GERM (Graph Evolution Rule Miner), an algorithm to mine all graph-evolution rules whose support and confidence are greater than given thresholds. The algorithm is applied to analyze four large real-world networks (i.e., two social networks, and two co-authorship networks from bibliographic data), using different time granularities. Our extensive experimentation confirms the feasibility and utility of the presented approach. It further shows that different kinds of networks exhibit different evolution rules, suggesting the usage of these local patterns to globally discriminate different kind of networks.

#index 1268041
#* Parallel Subspace Sampling for Particle Filtering in Dynamic Bayesian Networks
#@ Eva Besada-Portas;Sergey M. Plis;Jesus M. Cruz;Terran Lane
#t 2009
#c 22
#% 320663
#% 458100
#% 528169
#% 1270310
#% 1650389
#! Monitoring the variables of real world dynamic systems is a difficult task due to their inherent complexity and uncertainty. Particle Filters (PF) perform that task, yielding probability distribution over the unobserved variables. However, they suffer from the curse of dimensionality problem: the number of particles grows exponentially with the dimensionality of the hidden state space. The problem is aggravated when the initial distribution of the variables is not well known, as happens in global localization problems. We present a new parallel PF for systems whose variable dependencies can be factored into a Dynamic Bayesian Network. The new algorithms significantly reduce the number of particles, while independently exploring different subspaces of hidden variables to build particles consistent with past history and measurements. We demonstrate this new PF approach on some complex dynamical system estimation problems, showing that our method successfully localizes and tracks hidden states in cases where traditional PFs fail.

#index 1268042
#* Adaptive XML Tree Classification on Evolving Data Streams
#@ Albert Bifet;Ricard Gavaldà
#t 2009
#c 22
#% 414993
#% 464640
#% 552188
#% 577218
#% 729938
#% 729941
#% 815896
#% 1035127
#% 1074357
#% 1083627
#% 1214635
#% 1250571
#% 1312802
#% 1408820
#% 1718448
#! We propose a new method to classify patterns, using closed and maximal frequent patterns as features. Generally, classification requires a previous mapping from the patterns to classify to vectors of features, and frequent patterns have been used as features in the past. Closed patterns maintain the same information as frequent patterns using less space and maximal patterns maintain approximate information. We use them to reduce the number of classification features. We present a new framework for XML tree stream classification. For the first component of our classification framework, we use closed tree mining algorithms for evolving data streams. For the second component, we use state of the art classification methods for data streams. To the best of our knowledge this is the first work on tree classification in streaming data varying with time. We give a first experimental evaluation of the proposed classification method.

#index 1268043
#* A Condensed Representation of Itemsets for Analyzing Their Evolution over Time
#@ Mirko Boettcher;Martin Spott;Rudolf Kruse
#t 2009
#c 22
#% 279120
#% 338594
#% 342632
#% 466658
#% 478770
#% 479785
#% 796210
#% 894300
#% 1126845
#% 1200861
#! Driven by the need to understand change within domains there is emerging research on methods which aim at analyzing how patterns and in particular itemsets evolve over time. In practice, however, these methods suffer from the problem that many of the observed changes in itemsets are temporally redundant in the sense that they are the side-effect of changes in other itemsets, hence making the identification of the fundamental changes difficult. As a solution we propose temporally closed itemsets, a novel approach for a condensed representation of itemsets which is based on removing temporal redundancies. We investigate how our approach relates to the well-known concept of closed itemsets if the latter would be directly generalized to account for the temporal dimension. Our experiments support the theoretical results by showing that the set of temporally closed itemsets is significantly smaller than the set of closed itemsets.

#index 1268044
#* Non-redundant Subgroup Discovery Using a Closure System
#@ Mario Boley;Henrik Grosskreutz
#t 2009
#c 22
#% 232126
#% 240262
#% 256685
#% 279120
#% 300120
#% 384416
#% 477497
#% 763701
#% 1074357
#% 1108863
#% 1663617
#% 1710149
#% 1738875
#! Subgroup discovery is a local pattern discovery task, in which descriptions of subpopulations of a database are evaluated against some quality function. As standard quality functions are functions of the described subpopulation, we propose to search for equivalence classes of descriptions with respect to their extension in the database rather than individual descriptions. These equivalence classes have unique maximal representatives forming a closure system. We show that minimum cardinality representatives of each equivalence class can be found during the enumeration process of that closure system without additional cost, while finding a minimum representative of a single equivalence class is NP-hard. With several real-world datasets we demonstrate that search space and output are significantly reduced by considering equivalence classes instead of individual descriptions and that the minimum representatives constitute a family of subgroup descriptions that is of same or better expressive power than those generated by traditional methods.

#index 1268045
#* PLSI: The True Fisher Kernel and beyond
#@ Jean-Cédric Chappelier;Emmanuel Eckard
#t 2009
#c 22
#% 262096
#% 280819
#% 304917
#% 329569
#% 340899
#% 430758
#% 457933
#% 528182
#% 722904
#% 769895
#% 769906
#% 780756
#% 836784
#% 844225
#% 875987
#% 881529
#% 1013668
#% 1117050
#% 1166534
#% 1665192
#% 1667700
#! The Probabilistic Latent Semantic Indexing model, introduced by T. Hofmann (1999), has engendered applications in numerous fields, notably document classification and information retrieval. In this context, the Fisher kernel was found to be an appropriate document similarity measure. However, the kernels published so far contain unjustified features, some of which hinder their performances. Furthermore, PLSI is not generative for unknown documents, a shortcoming usually remedied by "folding them in" the PLSI parameter space. This paper contributes on both points by (1) introducing a new, rigorous development of the Fisher kernel for PLSI, addressing the role of the Fisher Information Matrix, and uncovering its relation to the kernels proposed so far; and (2) proposing a novel and theoretically sound document similarity, which avoids the problem of "folding in" unknown documents. For both aspects, experimental results are provided on several information retrieval evaluation sets.

#index 1268046
#* Semi-supervised Document Clustering with Simultaneous Text Representation and Categorization
#@ Yanhua Chen;Lijun Wang;Ming Dong
#t 2009
#c 22
#% 46809
#% 342621
#% 397147
#% 466675
#% 478128
#% 643008
#% 729918
#% 821874
#% 823396
#% 840892
#% 876018
#% 879615
#% 881468
#% 915227
#% 915329
#% 997114
#% 1055703
#% 1117004
#% 1143800
#! In order to derive high quality information from text, the field of text mining has advanced swiftly from simple document clustering to co-clustering with words and categories. However, document co-clustering without any prior knowledge or background information is a challenging problem. In this paper, we propose a Semi-Supervised Non-negative Matrix Factorization (SS-NMF) framework for document co-clustering. Our method computes new word-document and document-category matrices by incorporating user provided constraints through simultaneous distance metric learning and modality selection. Using an iterative algorithm, we perform tri-factorization of the new matrices to infer the document, category and word clusters. Theoretically, we show the convergence and correctness of SS-NMF co-clustering and the advantages of SS-NMF co-clustering over existing approaches. Through extensive experiments conducted on publicly available data sets, we demonstrate the superior performance of SS-NMF for document co-clustering.

#index 1268047
#* One Graph Is Worth a Thousand Logs: Uncovering Hidden Structures in Massive System Event Logs
#@ Michal Aharon;Gilad Barash;Ira Cohen;Eli Mordechai
#t 2009
#c 22
#% 722904
#% 823418
#% 823422
#% 835188
#% 963675
#% 989678
#% 1050866
#% 1053709
#% 1077150
#% 1301803
#% 1306057
#% 1468578
#% 1759275
#% 1856288
#! In this paper we describe our work on pattern discovery in system event logs. For discovering the patterns we developed two novel algorithms. The first is a sequential and efficient text clustering algorithm which automatically discovers the templates generating the messages. The second, the PARIS algorithm (Principle Atom Recognition In Sets), is a novel algorithm which discovers patterns of messages that represent processes occurring in the system. We demonstrate the usefulness of our analysis, on real world logs from various systems, for debugging of complex systems, efficient search and visualization of logs and characterization of system behavior.

#index 1268048
#* Conference Mining via Generalized Topic Modeling
#@ Ali Daud;Juanzi Li;Lizhu Zhou;Faqir Muhammad
#t 2009
#c 22
#% 74120
#% 220709
#% 310516
#% 503213
#% 584932
#% 643024
#% 722904
#% 734594
#% 736155
#% 788094
#% 875959
#% 881498
#% 973077
#% 1040839
#% 1083734
#% 1121274
#% 1393162
#% 1650298
#% 1650569
#! Conference Mining has been an important problem discussed these days for the purpose of academic recommendation. Previous approaches mined conferences by using network connectivity or by using semantics-based intrinsic structure of the words present between documents (modeling from document level (DL)), while ignored semantics-based intrinsic structure of the words present between conferences. In this paper, we address this problem by considering semantics-based intrinsic structure of the words present in conferences (richer semantics) by modeling from conference level (CL). We propose a generalized topic modeling approach based on Latent Dirichlet Allocation (LDA) named as Conference Mining (ConMin). By using it we can discover topically related conferences, conferences correlations and conferences temporal topic trends. Experimental results show that proposed approach significantly outperformed baseline approach in discovering topically related conferences and finding conferences correlations because of its ability to produce less sparse topics.

#index 1268049
#* Within-Network Classification Using Local Structure Similarity
#@ Christian Desrosiers;George Karypis
#t 2009
#c 22
#% 92286
#% 248810
#% 464434
#% 833065
#% 961278
#% 1027765
#% 1083652
#% 1108845
#% 1650403
#% 1815596
#! Within-network classification, where the goal is to classify the nodes of a partly labeled network, is a semi-supervised learning problem that has applications in several important domains like image processing, the classification of documents, and the detection of malicious activities. While most methods for this problem infer the missing labels collectively based on the hypothesis that linked or nearby nodes are likely to have the same labels, there are many types of networks for which this assumption fails, e.g., molecular graphs, trading networks, etc. In this paper, we present a collective classification method, based on relaxation labeling, that classifies entities of a network using their local structure. This method uses a marginalized similarity kernel that compares the local structure of two nodes with random walks in the network. Through experimentation on different datasets, we show our method to be more accurate than several state-of-the-art approaches for this problem.

#index 1268050
#* Multi-task Feature Selection Using the Multiple Inclusion Criterion (MIC)
#@ Paramveer S. Dhillon;Brian Tomasik;Dean Foster;Lyle Ungar
#t 2009
#c 22
#% 187651
#% 236497
#% 770848
#% 876034
#% 916788
#% 961200
#% 983865
#% 1128929
#% 1128930
#% 1379069
#! We address the problem of joint feature selection in multiple related classification or regression tasks. When doing feature selection with multiple tasks, usually one can "borrow strength" across these tasks to get a more sensitive criterion for deciding which features to select. We propose a novel method, the Multiple Inclusion Criterion (MIC), which modifies stepwise feature selection to more easily select features that are helpful across multiple tasks. Our approach allows each feature to be added to none, some, or all of the tasks. MIC is most beneficial for selecting a small set of predictive features from a large pool of potential features, as is common in genomic and biological datasets. Experimental results on such datasets show that MIC usually outperforms other competing multi-task learning methods not only in terms of accuracy but also by building simpler and more interpretable models.

#index 1268051
#* Kernel Polytope Faces Pursuit
#@ Tom Diethe;Zakria Hussain
#t 2009
#c 22
#% 137603
#% 201259
#% 274586
#% 387653
#% 425062
#% 466597
#% 562940
#% 743284
#% 873583
#% 1688148
#! Polytope Faces Pursuit (PFP) is a greedy algorithm that approximates the sparse solutions recovered by ***1 regularised least-squares (Lasso) [4,10] in a similar vein to (Orthogonal) Matching Pursuit (OMP) [16]. The algorithm is based on the geometry of the polar polytope where at each step a basis function is chosen by finding the maximal vertex using a path-following method. The algorithmic complexity is of a similar order to OMP whilst being able to solve problems known to be hard for (O)MP. Matching Pursuit was extended to build kernel-based solutions to machine learning problems, resulting in the sparse regression algorithm, Kernel Matching Pursuit (KMP) [17]. We develop a new algorithm to build sparse kernel-based solutions using PFP, which we call Kernel Polytope Faces Pursuit (KPFP). We show the usefulness of this algorithm by providing a generalisation error bound [7] that takes into account a natural regression loss and experimental results on several benchmark datasets.

#index 1268052
#* Soft Margin Trees
#@ Jorge Díez;Juan José Coz;Antonio Bahamonde;Oscar Luaces
#t 2009
#c 22
#% 116149
#% 234978
#% 269221
#% 309208
#% 477964
#% 577959
#% 722816
#% 770849
#% 771846
#% 961134
#% 961267
#% 1702628
#! From a multi-class learning task, in addition to a classifier, it is possible to infer some useful knowledge about the relationship between the classes involved. In this paper we propose a method to learn a hierarchical clustering of the set of classes. The usefulness of such clusterings has been exploited in bio-medical applications to find out relations between diseases or populations of animals. The method proposed here defines a distance between classes based on the margin maximization principle, and then builds the hierarchy using a linkage procedure. Moreover, to quantify the goodness of the hierarchies we define a measure. Finally, we present a set of experiments comparing the scores achieved by our approach with other methods.

#index 1268053
#* Feature Weighting Using Margin and Radius Based Error Bound Optimization in SVMs
#@ Huyen Do;Alexandros Kalousis;Melanie Hilario
#t 2009
#c 22
#% 263850
#% 309208
#% 425040
#% 425048
#% 722938
#% 743284
#% 757953
#% 875970
#% 977991
#! The Support Vector Machine error bound is a function of the margin and radius. Standard SVM algorithms maximize the margin within a given feature space, therefore the radius is fixed and thus ignored in the optimization. We propose an extension of the standard SVM optimization in which we also account for the radius in order to produce an even tighter error bound than what we get by controlling only for the margin. We use a second set of parameters, μ , that control the radius introducing like that an explicit feature weighting mechanism in the SVM algorithm. We impose an l 1 constraint on μ which results in a sparse vector, thus performing feature selection. Our original formulation is not convex, we give a convex approximation and show how to solve it. We experiment with real world datasets and report very good predictive performance compared to standard SVM.

#index 1268054
#* Margin and Radius Based Multiple Kernel Learning
#@ Huyen Do;Alexandros Kalousis;Adam Woznica;Melanie Hilario
#t 2009
#c 22
#% 263850
#% 309208
#% 393059
#% 425040
#% 743284
#% 757953
#% 763697
#% 770846
#% 829029
#% 832903
#% 875970
#% 961190
#% 977991
#! A serious drawback of kernel methods, and Support Vector Machines (SVM) in particular, is the difficulty in choosing a suitable kernel function for a given dataset. One of the approaches proposed to address this problem is Multiple Kernel Learning (MKL) in which several kernels are combined adaptively for a given dataset. Many of the existing MKL methods use the SVM objective function and try to find a linear combination of basic kernels such that the separating margin between the classes is maximized. However, these methods ignore the fact that the theoretical error bound depends not only on the margin, but also on the radius of the smallest sphere that contains all the training instances. We present a novel MKL algorithm that optimizes the error bound taking account of both the margin and the radius. The empirical results show that the proposed method compares favorably with other state-of-the-art MKL methods.

#index 1268055
#* Inference and Validation of Networks
#@ Ilias N. Flaounas;Marco Turchi;Tijl Bie;Nello Cristianini
#t 2009
#c 22
#% 284562
#% 335005
#% 816170
#% 857451
#% 936239
#% 1215368
#% 1267809
#! We develop a statistical methodology to validate the result of network inference algorithms, based on principles of statistical testing and machine learning. The comparison of results with reference networks, by means of similarity measures and null models, allows us to measure the significance of results, as well as their predictive power. The use of Generalised Linear Models allows us to explain the results in terms of available ground truth which we expect to be partially relevant. We present these methods for the case of inferring a network of News Outlets based on their preference of stories to cover. We compare three simple network inference methods and show how our technique can be used to choose between them. All the methods presented here can be directly applied to other domains where network inference is used.

#index 1268056
#* Binary Decomposition Methods for Multipartite Ranking
#@ Johannes Fürnkranz;Eyke Hüllermeier;Stijn Vanderlooy
#t 2009
#c 22
#% 349550
#% 458623
#% 577224
#% 722756
#% 722807
#% 840853
#% 881477
#% 889273
#% 961134
#% 998581
#% 1014653
#% 1015908
#% 1093383
#! Bipartite ranking refers to the problem of learning a ranking function from a training set of positively and negatively labeled examples. Applied to a set of unlabeled instances, a ranking function is expected to establish a total order in which positive instances precede negative ones. The performance of a ranking function is typically measured in terms of the AUC. In this paper, we study the problem of multipartite ranking, an extension of bipartite ranking to the multi-class case. In this regard, we discuss extensions of the AUC metric which are suitable as evaluation criteria for multipartite rankings. Moreover, to learn multipartite ranking functions, we propose methods on the basis of binary decomposition techniques that have previously been used for multi-class and ordinal classification. We compare these methods both analytically and experimentally, not only against each other but also to existing methods applicable to the same problem.

#index 1268057
#* Leveraging Higher Order Dependencies between Features for Text Classification
#@ Murat C. Ganiz;Nikita I. Lytkin;William M. Pottenger
#t 2009
#c 22
#% 241238
#% 248810
#% 269221
#% 329435
#% 393059
#% 402289
#% 741083
#% 746929
#% 785353
#% 829974
#% 853532
#% 915219
#% 1289267
#% 1348343
#! Traditional machine learning methods only consider relationships between feature values within individual data instances while disregarding the dependencies that link features across instances. In this work, we develop a general approach to supervised learning by leveraging higher-order dependencies between features. We introduce a novel Bayesian framework for classification named Higher Order Naive Bayes (HONB). Unlike approaches that assume data instances are independent, HONB leverages co-occurrence relations between feature values across different instances. Additionally, we generalize our framework by developing a novel data-driven space transformation that allows any classifier operating in vector spaces to take advantage of these higher-order co-occurrence relations. Results obtained on several benchmark text corpora demonstrate that higher-order approaches achieve significant improvements in classification accuracy over the baseline (first-order) methods.

#index 1268058
#* Syntactic Structural Kernels for Natural Language Interfaces to Databases
#@ Alessandra Giordani;Alessandro Moschitti
#t 2009
#c 22
#% 227765
#% 375503
#% 428249
#% 458641
#% 722925
#% 742218
#% 743284
#% 815896
#% 817422
#% 855277
#% 938706
#% 939355
#% 939615
#% 939617
#% 939871
#% 940027
#% 940046
#% 983885
#% 1084592
#% 1102262
#% 1130832
#% 1215257
#% 1215283
#% 1249451
#% 1261669
#% 1344851
#% 1665151
#% 1735380
#! A core problem in data mining is to retrieve data in a easy and human friendly way. Automatically translating natural language questions into SQL queries would allow for the design of effective and useful database systems from a user viewpoint. Interesting previous work has been focused on the use of machine learning algorithms for automatically mapping natural language (NL) questions to SQL queries. In this paper, we present many structural kernels and their combinations for inducing the relational semantics between pairs of NL questions and SQL queries. We measure the effectiveness of such kernels by using them in Support Vector Machines to select the queries that correctly answer to NL questions. Experimental results on two different datasets show that our approach is viable and that syntactic information under the form of pairs of syntactic tree fragments (from queries and questions) plays a major role in deriving the relational semantics between the two languages.

#index 1268059
#* Active and Semi-supervised Data Domain Description
#@ Nico Görnitz;Marius Kloft;Ulf Brefeld
#t 2009
#c 22
#% 269218
#% 340031
#% 479791
#% 577250
#% 633259
#% 664547
#% 727871
#% 732387
#% 760805
#% 766959
#% 883972
#% 900175
#% 978434
#% 983952
#% 1670211
#% 1708339
#% 1728891
#% 1756868
#! Data domain description techniques aim at deriving concise descriptions of objects belonging to a category of interest. For instance, the support vector domain description (SVDD) learns a hypersphere enclosing the bulk of provided unlabeled data such that points lying outside of the ball are considered anomalous. However, relevant information such as expert and background knowledge remain unused in the unsupervised setting. In this paper, we rephrase data domain description as a semi-supervised learning task, that is, we propose a semi-supervised generalization of data domain description (SSSVDD) to process unlabeled and labeled examples. The corresponding optimization problem is non-convex. We translate it into an unconstraint, continuous problem that can be optimized accurately by gradient-based techniques. Furthermore, we devise an effective active learning strategy to query low-confidence observations. Our empirical evaluation on network intrusion detection and object recognition tasks shows that our SSSVDDs consistently outperform baseline methods in relevant learning settings.

#index 1268060
#* A Matrix Factorization Approach for Integrating Multiple Data Views
#@ Derek Greene;Pádraig Cunningham
#t 2009
#c 22
#% 252011
#% 274612
#% 722902
#% 769935
#% 785334
#% 1021506
#% 1673596
#! In many domains there will exist different representations or "views" describing the same set of objects. Taken alone, these views will often be deficient or incomplete. Therefore a key problem for exploratory data analysis is the integration of multiple views to discover the underlying structures in a domain. This problem is made more difficult when disagreement exists between views. We introduce a new unsupervised algorithm for combining information from related views, using a late integration strategy. Combination is performed by applying an approach based on matrix factorization to group related clusters produced on individual views. This yields a projection of the original clusters in the form of a new set of "meta-clusters" covering the entire domain. We also provide a novel model selection strategy for identifying the correct number of meta-clusters. Evaluations performed on a number of multi-view text clustering problems demonstrate the effectiveness of the algorithm.

#index 1268061
#* Transductive Classification via Dual Regularization
#@ Quanquan Gu;Jie Zhou
#t 2009
#c 22
#% 342621
#% 593047
#% 729918
#% 757953
#% 876068
#% 881468
#% 961218
#% 1074074
#% 1176920
#% 1214657
#% 1270204
#% 1305456
#% 1327693
#! Semi-supervised learning has witnessed increasing interest in the past decade. One common assumption behind semi-supervised learning is that the data labels should be sufficiently smooth with respect to the intrinsic data manifold. Recent research has shown that the features also lie on a manifold. Moreover, there is a duality between data points and features, that is, data points can be classified based on their distribution on features, while features can be classified based on their distribution on the data points. However, existing semi-supervised learning methods neglect these points. Based on the above observations, in this paper, we present a dual regularization, which consists of two graph regularizers and a co-clustering type regularizer. In detail, the two graph regularizers consider the geometric structure of the data points and the features respectively, while the co-clustering type regularizer takes into account the duality between data points and features. Furthermore, we propose a novel transductive classification framework based on dual regularization, which can be solved by alternating minimization algorithm and its convergence is theoretically guaranteed. Experiments on benchmark semi-supervised learning data sets demonstrate that the proposed methods outperform many state of the art transductive classification methods.

#index 1268062
#* Stable and Accurate Feature Selection
#@ Gokhan Gulgezen;Zehra Cataltepe;Lei Yu
#t 2009
#c 22
#% 717417
#% 787639
#% 793239
#% 796212
#% 977991
#% 1083713
#% 1108900
#% 1767420
#! In addition to accuracy, stability is also a measure of success for a feature selection algorithm. Stability could especially be a concern when the number of samples in a data set is small and the dimensionality is high. In this study, we introduce a stability measure, and perform both accuracy and stability measurements of MRMR (Minimum Redundancy Maximum Relevance) feature selection algorithm on different data sets. The two feature evaluation criteria used by MRMR, MID (Mutual Information Difference) and MIQ (Mutual Information Quotient), result in similar accuracies, but MID is more stable. We also introduce a new feature selection criterion, MID *** , where redundancy and relevance of selected features are controlled by parameter *** .

#index 1268063
#* Efficient Sample Reuse in EM-Based Policy Search
#@ Hirotaka Hachiya;Jan Peters;Masashi Sugiyama
#t 2009
#c 22
#% 124687
#% 225838
#% 384911
#% 464609
#% 466751
#% 528322
#% 983897
#% 1074038
#% 1270303
#% 1699598
#! Direct policy search is a promising reinforcement learning framework in particular for controlling in continuous, high-dimensional systems such as anthropomorphic robots. Policy search often requires a large number of samples for obtaining a stable policy update estimator due to its high flexibility. However, this is prohibitive when the sampling cost is expensive. In this paper, we extend an EM-based policy search method so that previously collected samples can be efficiently reused. The usefulness of the proposed method, called Reward-weighted Regression with sample Reuse (R3), is demonstrated through a robot learning experiment.

#index 1268064
#* Applying Electromagnetic Field Theory Concepts to Clustering with Constraints
#@ Huseyin Hakkoymaz;Georgios Chatzimilioudis;Dimitrios Gunopulos;Heikki Mannila
#t 2009
#c 22
#% 274612
#% 464291
#% 464608
#% 479649
#% 769881
#% 770782
#% 823395
#% 840892
#% 881480
#% 915344
#% 989654
#% 1083652
#% 1665168
#! This work shows how concepts from the electromagnetic field theory can be efficiently used in clustering with constraints. The proposed framework transforms vector data into a fully connected graph, or just works straight on the given graph data. User constraints are represented by electromagnetic fields that affect the weight of the graph's edges. A clustering algorithm is then applied on the adjusted graph, using k -distinct shortest paths as the distance measure. Our framework provides better accuracy compared to MPCK-Means, SS-Kernel-KMeans and Kmeans+Diagonal Metric even when very few constraints are used, significantly improves clustering performance on some datasets that other methods fail to partition successfully, and can cluster both vector and graph datasets. All these advantages are demonstrated through thorough experimental evaluation.

#index 1268065
#* An l 1 Regularization Framework for Optimal Rule Combination
#@ Yanjun Han;Jue Wang
#t 2009
#c 22
#% 63423
#% 217072
#% 235377
#% 398839
#% 449508
#% 674190
#% 770846
#% 771944
#% 961223
#% 961262
#% 983922
#% 1250568
#% 1396692
#! In this paper l 1 regularization is introduced into relational learning to produce sparse rule combination. In other words, as few as possible rules are contained in the final rule set. Furthermore, we design a rule complexity penalty to encourage rules with fewer literals. The resulted optimization problem has to be formulated in an infinite dimensional space of horn clauses R m associated with their corresponding complexity $\mathcal{C}_m$. It is proved that if a locally optimal rule is generated at each iteration, the final obtained rule set will be globally optimal. The proposed meta-algorithm is applicable to any single rule generator. We bring forward two algorithms, namely, l 1 FOIL and l 1 Progol. Empirical analysis is carried on ten real world tasks from bioinformatics and cheminformatics. The results demonstrate that our approach offers competitive prediction accuracy while the interpretability is straightforward.

#index 1268066
#* A Generic Approach to Topic Models
#@ Gregor Heinrich
#t 2009
#c 22
#% 424830
#% 722904
#% 722927
#% 769906
#% 770861
#% 798509
#% 876017
#% 915330
#% 983883
#% 1083687
#% 1207759
#% 1650387
#! This article contributes a generic model of topic models. To define the problem space, general characteristics for this class of models are derived, which give rise to a representation of topic models as "mixture networks", a domain-specific compact alternative to Bayesian networks. Besides illustrating the interconnection of mixtures in topic models, the benefit of this representation is its straight-forward mapping to inference equations and algorithms, which is shown with the derivation and implementation of a generic Gibbs sampling algorithm.

#index 1268067
#* Feature Selection by Transfer Learning with Linear Regularized Models
#@ Thibault Helleputte;Pierre Dupont
#t 2009
#c 22
#% 425040
#% 425048
#% 580511
#% 722929
#% 722943
#% 769886
#% 770804
#% 833552
#% 840898
#% 999695
#% 1041316
#% 1073897
#% 1108915
#% 1128927
#% 1211741
#% 1261539
#% 1272110
#% 1699633
#! This paper presents a novel feature selection method for classification of high dimensional data, such as those produced by microarrays. It includes a partial supervision to smoothly favor the selection of some dimensions (genes) on a new dataset to be classified. The dimensions to be favored are previously selected from similar datasets in large microarray databases, hence performing inductive transfer learning at the feature level. This technique relies on a feature selection method embedded within a regularized linear model estimation. A practical approximation of this technique reduces to linear SVM learning with iterative input rescaling. The scaling factors depend on the selected dimensions from the related datasets. The final selection may depart from those whenever necessary to optimize the classification objective. Experiments on several microarray datasets show that the proposed method both improves the selected gene lists stability, with respect to sampling variation, as well as the classification performances.

#index 1268068
#* Integrating Logical Reasoning and Probabilistic Chain Graphs
#@ Arjen Hommersom;Nivea Ferreira;Peter J. Lucas
#t 2009
#c 22
#% 44876
#% 147677
#% 233132
#% 503662
#% 550745
#% 676365
#% 850430
#! Probabilistic logics have attracted a great deal of attention during the past few years. While logical languages have taken a central position in research on knowledge representation and automated reasoning, probabilistic graphical models with their probabilistic basis have taken up a similar position when it comes to reasoning with uncertainty. The formalism of chain graphs is increasingly seen as a natural probabilistic graphical formalism as it generalises both Bayesian networks and Markov networks, and has a semantics which allows any Bayesian network to have a unique graphical representation. At the same time, chain graphs do not support modelling and learning of relational aspects of a domain. In this paper, a new probabilistic logic, chain logic, is developed along the lines of probabilistic Horn logic. The chain logic leads to relational models of domains in which associational and causal knowledge are relevant and where probabilistic parameters can be learned from data.

#index 1268069
#* Max-Margin Weight Learning for Markov Logic Networks
#@ Tuyen N. Huynh;Raymond J. Mooney
#t 2009
#c 22
#% 309208
#% 446360
#% 450888
#% 464434
#% 575676
#% 812487
#% 829043
#% 840882
#% 850430
#% 854636
#% 872235
#% 872852
#% 961193
#% 1026555
#% 1073910
#% 1073924
#% 1100143
#% 1108078
#% 1117688
#% 1149156
#% 1250579
#% 1264133
#% 1269496
#% 1269815
#% 1270261
#% 1416201
#% 1650403
#! Markov logic networks (MLNs) are an expressive representation for statistical relational learning that generalizes both first-order logic and graphical models. Existing discriminative weight learning methods for MLNs all try to learn weights that optimize the Conditional Log Likelihood (CLL) of the training examples. In this work, we present a new discriminative weight learning method for MLNs based on a max-margin framework. This results in a new model, Max-Margin Markov Logic Networks (M3LNs), that combines the expressiveness of MLNs with the predictive accuracy of structural Support Vector Machines (SVMs). To train the proposed model, we design a new approximation algorithm for loss-augmented inference in MLNs based on Linear Programming (LP). The experimental result shows that the proposed approach generally achieves higher F 1 scores than the current best discriminative weight learner for MLNs.

#index 1268070
#* Parameter-Free Hierarchical Co-clustering by n-Ary Splits
#@ Dino Ienco;Ruggero G. Pensa;Rosa Meo
#t 2009
#c 22
#% 309128
#% 316709
#% 546527
#% 565973
#% 722902
#% 722935
#% 729918
#% 1014670
#% 1052665
#% 1063729
#% 1407020
#! Clustering high-dimensional data is challenging. Classic metrics fail in identifying real similarities between objects. Moreover, the huge number of features makes the cluster interpretation hard. To tackle these problems, several co-clustering approaches have been proposed which try to compute a partition of objects and a partition of features simultaneously. Unfortunately, these approaches identify only a predefined number of flat co-clusters. Instead, it is useful if the clusters are arranged in a hierarchical fashion because the hierarchy provides insides on the clusters. In this paper we propose a novel hierarchical co-clustering, which builds two coupled hierarchies, one on the objects and one on features thus providing insights on both them. Our approach does not require a pre-specified number of clusters, and produces compact hierarchies because it makes n ***ary splits, where n is automatically determined. We validate our approach on several high-dimensional datasets with state of the art competitors.

#index 1268071
#* Mining Peculiar Compositions of Frequent Substrings from Sparse Text Data Using Background Texts
#@ Daisuke Ikeda;Einoshin Suzuki
#t 2009
#c 22
#% 232106
#% 235941
#% 273705
#% 289010
#% 310496
#% 459025
#% 479986
#% 496757
#% 501666
#% 546037
#% 566760
#% 577275
#% 729933
#% 844306
#% 1143770
#% 1196862
#! We consider mining unusual patterns from text T . Unlike existing methods which assume probabilistic models and use simple estimation methods, we employ a set B of background text in addition to T and composition s w = xy of x and y as patterns. A string w is peculiar if there exist x and y such that w = xy , each of x and y is more frequent in B than in T , and conversely w = xy is more frequent in T . The frequency of xy in T is very small since x and y are infrequent in T , but xy is relatively abundant in T compared to xy in B . Despite these complex conditions for peculiar compositions, we develop a fast algorithm to find peculiar compositions using the suffix tree. Experiments using DNA sequences show scalability of our algorithm due to our pruning techniques and the superiority of the concept of the peculiar composition.

#index 1268072
#* Minimum Free Energy Principle for Constraint-Based Learning Bayesian Networks
#@ Takashi Isozaki;Maomi Ueno
#t 2009
#c 22
#% 44876
#% 130153
#% 197387
#% 246832
#% 297171
#% 748465
#% 878207
#% 893460
#% 919561
#% 1145176
#% 1650298
#% 1650673
#% 1672997
#! Constraint-based search methods, which are a major approach to learning Bayesian networks, are expected to be effective in causal discovery tasks. However, such methods often suffer from impracticality of classical hypothesis testing for conditional independence when the sample size is insufficiently large. We propose a new conditional independence (CI) testing method that is effective for small samples. Our method uses the minimum free energy principle, which originates from thermodynamics, with the "Data Temperature" assumption recently proposed for relating probabilistic fluctuation to virtual thermal fluctuation. We define free energy using Kullback---Leibler divergence in a manner corresponding to an information-geometric perspective. This CI method incorporates the maximum entropy principle and converges to classical hypothesis tests in asymptotic regions. We provide a simulation study, the results of which show that our method improves the learning performance of the well known PC algorithm in some respects.

#index 1268073
#* Kernel-Based Copula Processes
#@ Sebastian Jaimungal;Eddie K. Ng
#t 2009
#c 22
#% 891549
#% 925382
#! Kernel-based Copula Processes (KCPs), a new versatile tool for analyzing multiple time-series, are proposed here as a unifying framework to model the interdependency across multiple time-series and the long-range dependency within an individual time-series. KCPs build on the celebrated theory of copula which allows for the modeling of complex interdependence structure, while leveraging the power of kernel methods for efficient learning and parsimonious model specification. Specifically, KCPs can be viewed as a generalization of the Gaussian processes enabling non-Gaussian predictions to be made. Such non-Gaussian features are extremely important in a variety of application areas. As one application, we consider temperature series from weather stations across the US. Not only are KCPs found to have modeled the heteroskedasticity of the individual temperature changes well, the KCPs also successfully discovered the interdependencies among different stations. Such results are beneficial for weather derivatives trading and risk management, for example.

#index 1268074
#* Compositional Models for Reinforcement Learning
#@ Nicholas K. Jong;Peter Stone
#t 2009
#c 22
#% 160859
#% 286423
#% 363744
#% 425072
#% 431471
#% 466075
#% 722895
#% 734920
#% 875957
#% 1073926
#% 1271827
#% 1279356
#% 1398250
#% 1699601
#! Innovations such as optimistic exploration, function approximation, and hierarchical decomposition have helped scale reinforcement learning to more complex environments, but these three ideas have rarely been studied together. This paper develops a unified framework that formalizes these algorithmic contributions as operators on learned models of the environment. Our formalism reveals some synergies among these innovations, and it suggests a straightforward way to compose them. The resulting algorithm, Fitted R-MAXQ, is the first to combine the function approximation of fitted algorithms, the efficient model-based exploration of R-MAX, and the hierarchical decompostion of MAXQ.

#index 1268075
#* Feature Selection for Value Function Approximation Using Bayesian Model Selection
#@ Tobias Jung;Peter Stone
#t 2009
#c 22
#% 349178
#% 384911
#% 450245
#% 722815
#% 722887
#% 840839
#% 840860
#% 876001
#% 891549
#% 983896
#% 1014677
#% 1073974
#% 1078833
#% 1182603
#! Feature selection in reinforcement learning (RL), i.e. choosing basis functions such that useful approximations of the unkown value function can be obtained, is one of the main challenges in scaling RL to real-world applications. Here we consider the Gaussian process based framework GPTD for approximate policy evaluation, and propose feature selection through marginal likelihood optimization of the associated hyperparameters. Our approach has two appealing benefits: (1) given just sample transitions, we can solve the policy evaluation problem fully automatically (without looking at the learning task, and, in theory, independent of the dimensionality of the state space), and (2) model selection allows us to consider more sophisticated kernels, which in turn enable us to identify relevant subspaces and eliminate irrelevant state variables such that we can achieve substantial computational savings and improved prediction performance.

#index 1268076
#* Learning Preferences with Hidden Common Cause Relations
#@ Kristian Kersting;Zhao Xu
#t 2009
#c 22
#% 169777
#% 577224
#% 715096
#% 734915
#% 829028
#% 840846
#% 840852
#% 875948
#% 891549
#% 902508
#% 989628
#% 1016175
#% 1055712
#% 1074083
#% 1074346
#% 1093383
#% 1305499
#! Gaussian processes have successfully been used to learn preferences among entities as they provide nonparametric Bayesian approaches for model selection and probabilistic inference. For many entities encountered in real-world applications, however, there are complex relations between them. In this paper, we present a preference model which incorporates information on relations among entities. Specifically, we propose a probabilistic relational kernel model for preference learning based on Silva et al.'s mixed graph Gaussian processes: a new prior distribution, enhanced with relational graph kernels, is proposed to capture the correlations between preferences. Empirical analysis on the LETOR datasets demonstrates that relational information can improve the performance of preference learning.

#index 1268077
#* Feature Selection for Density Level-Sets
#@ Marius Kloft;Shinichi Nakajima;Ulf Brefeld
#t 2009
#c 22
#% 269217
#% 340031
#% 577250
#% 727871
#% 743284
#% 757953
#% 763697
#% 770846
#% 812418
#% 855602
#% 945194
#% 961190
#% 983901
#% 983953
#% 1103984
#% 1118196
#% 1670211
#% 1728891
#! A frequent problem in density level-set estimation is the choice of the right features that give rise to compact and concise representations of the observed data. We present an efficient feature selection method for density level-set estimation where optimal kernel mixing coefficients and model parameters are determined simultaneously. Our approach generalizes one-class support vector machines and can be equivalently expressed as a semi-infinite linear program that can be solved with interleaved cutting plane algorithms. The experimental evaluation of the new method on network intrusion detection and object recognition tasks demonstrate that our approach not only attains competitive performance but also spares practitioners from a priori decisions on feature sets to be used.

#index 1268078
#* Efficient Multi-start Strategies for Local Search Algorithms
#@ Levente Kocsis;András György
#t 2009
#c 22
#% 155827
#% 156278
#% 425053
#% 429833
#% 578756
#% 926881
#% 945273
#% 1250126
#% 1250528
#% 1269575
#% 1274880
#% 1353289
#% 1664996
#! Local search algorithms for global optimization often suffer from getting trapped in a local optimum. The common solution for this problem is to restart the algorithm when no progress is observed. Alternatively, one can start multiple instances of a local search algorithm, and allocate computational resources (in particular, processing time) to the instances depending on their behavior. Hence, a multi-start strategy has to decide (dynamically) when to allocate additional resources to a particular instance and when to start new instances. In this paper we propose a consistent multi-start strategy that assumes a convergence rate of the local search algorithm up to an unknown constant, and in every phase gives preference to those instances that could converge to the best value for a particular range of the constant. Combined with the local search algorithm SPSA (Simultaneous Perturbation Stochastic Approximation), the strategy performs remarkably well in practice, both on synthetic tasks and on tuning the parameters of learning algorithms.

#index 1268079
#* Considering Unseen States as Impossible in Factored Reinforcement Learning
#@ Olga Kozlova;Olivier Sigaud;Pierre-Henri Wuillemin;Christophe Meyer
#t 2009
#c 22
#% 75936
#% 314843
#% 384911
#% 430959
#% 449529
#% 875977
#% 977024
#% 1074003
#% 1229359
#% 1272002
#% 1290041
#% 1650297
#% 1650699
#! The Factored Markov Decision Process (fmdp ) framework is a standard representation for sequential decision problems under uncertainty where the state is represented as a collection of random variables. Factored Reinforcement Learning (frl ) is an Model-based Reinforcement Learning approach to fmdps where the transition and reward functions of the problem are learned. In this paper, we show how to model in a theoretically well-founded way the problems where some combinations of state variable values may not occur, giving rise to impossible states. Furthermore, we propose a new heuristics that considers as impossible the states that have not been seen so far. We derive an algorithm whose improvement in performance with respect to the standard approach is illustrated through benchmark experiments.

#index 1268080
#* Relevance Grounding for Planning in Relational Domains
#@ Tobias Lang;Marc Toussaint
#t 2009
#c 22
#% 333786
#% 770823
#% 876063
#% 883334
#% 1211763
#% 1269827
#% 1272161
#% 1274869
#% 1289241
#% 1402658
#! Probabilistic relational models are an efficient way to learn and represent the dynamics in realistic environments consisting of many objects. Autonomous intelligent agents that ground this representation for all objects need to plan in exponentially large state spaces and large sets of stochastic actions. A key insight for computational efficiency is that successful planning typically involves only a small subset of relevant objects. In this paper, we introduce a probabilistic model to represent planning with subsets of objects and provide a definition of object relevance. Our definition is sufficient to prove consistency between repeated planning in partially grounded models restricted to relevant objects and planning in the fully grounded model. We propose an algorithm that exploits object relevance to plan efficiently in complex domains. Empirical results in a simulated 3D blocksworld with an articulated manipulator and realistic physics prove the effectiveness of our approach.

#index 1410703
#* Proceedings of the 3rd ECML/PKDD international conference on Mining complex data
#@ Zbigniew W. Raś;Shusaku Tsumoto;Djamel Zighed
#t 2007
#c 22

#index 1410704
#* Using text mining and link analysis for software mining
#@ Miha Grcar;Marko Grobelnik;Dunja Mladenic
#t 2007
#c 22
#% 55700
#% 104736
#% 717133
#% 748022
#% 758132
#% 1704311
#! Many data mining techniques are these days in use for ontology learning - text mining, Web mining, graph mining, link analysis, relational data mining, and so on. In the current state-of-the-art bundle there is a lack of "software mining" techniques. This term denotes the process of extracting knowledge out of source code. In this paper we approach the software mining task with a combination of text mining and link analysis techniques. We discuss how each instance (i.e. a programming construct such as a class or a method) can be converted into a feature vector that combines the information about how the instance is interlinked with other instances, and the information about its (textual) content. The so-obtained feature vectors serve as the basis for the construction of the domain ontology with OntoGen, an existing system for semi-automatic data-driven ontology construction.

#index 1410705
#* Generalization-based similarity for conceptual clustering
#@ S. Ferilli;T. M. A. Basile;N. Di Mauro;M. Biba;F. Esposito
#t 2007
#c 22
#% 65440
#% 90214
#% 117706
#% 131422
#% 296738
#% 451052
#% 465914
#% 466073
#% 550409
#% 550570
#% 939452
#! Knowledge extraction represents an important issue that concerns the ability to identify valid, potentially useful and understandable patterns from large data collections. Such a task becomes more difficult if the domain of application cannot be represented by means of an attribute-value representation. Thus, a more powerful representation language, such as First-Order Logic, is necessary. Due to the complexity of handling First-Order Logic formulæ, where the presence of relations causes various portions of one description to be possibly mapped in different ways onto another description, few works presenting techniques for comparing descriptions are available in the literature for this kind of representations. Nevertheless, the ability to assess similarity between first-order descriptions has many applications, ranging from description selection to flexible matching, from instance-based learning to clustering. This paper tackles the case of Conceptual Clustering, where a new approach to similarity evaluation, based on both syntactic and semantic features, is exploited to support the task of grouping together similar items according to their relational description. After presenting a framework for Horn Clauses (including criteria, a function and composition techniques for similarity assessment), classical clustering algorithms are exploited to carry out the grouping task. Experimental results on realworld datasets prove the effectiveness of the proposal.

#index 1410706
#* Trajectory analysis of laboratory tests as medical complex data mining
#@ Shoji Hirano;Shusaku Tsumoto
#t 2007
#c 22
#% 71149
#% 1200254
#! Finding temporally covariant variables is very important for clinical practice because we are able to obtain the measurements of some examinations very easily, while it takes a long time for us to measure other ones. Also, unexpected covariant patterns give us new knowledge for temporal evolution of chronic diseases. This paper focuses on clustering of trajectories of temporal sequences of two laboratory examinations. First, we map a set of time series containing different types of laboratory tests into directed trajectories representing temporal change in patients' status. Then the trajectories for individual patients are compared in multiscale and grouped into similar cases by using clustering methods. Experimental results on the chronic hepatitis data demonstrated that the method could find the groups of trajectories which reflects temporal covariance of platelet, albumin and choline esterase.

#index 1410707
#* Conceptual clustering applied to ontologies: a distance-based evolutionary approach
#@ Floriana Esposito;Nicola Fanizzi;Claudia D'Amato
#t 2007
#c 22
#% 3033
#% 170418
#% 296738
#% 366687
#% 481281
#% 550409
#% 550570
#% 857113
#% 935898
#% 948155
#% 1248914
#% 1274840
#% 1415869
#% 1777086
#% 1780757
#! A clustering method is presented which can be applied to semantically annotated resources in the context of ontological knowledge bases. This method can be used to discover emerging groupings of resources expressed in the standard ontology languages. The method exploits a language-independent semidistance measure over the space of resources, that is based on their semantics w.r.t. a number of dimensions corresponding to a committee of discriminating features represented by concept descriptions. A maximally discriminating group of features can be constructed through a feature construction method based on genetic programming. The evolutionary clustering algorithm proposed is based on the notion of medoids applied to relational representations. It is able to induce a set of clusters by means of a fitness function based on a discernibility criterion. An experimentation with some ontologies proves the feasibility of our method.

#index 1410708
#* Feature selection: near set approach
#@ James F. Peters;Sheela Ramanna
#t 2007
#c 22
#% 139193
#% 229401
#% 425109
#% 739899
#% 929722
#% 947942
#% 1054473
#% 1055266
#% 1395713
#% 1399929
#% 1729778
#% 1730019
#% 1776738
#% 1894113
#! The problem considered in this paper is how to select features that are useful in classifying perceptual objects that are qualitatively but not necessarily spatially near each other. The term qualitatively near is used here to mean closeness of descriptions or distinctive characteristics of objects. The solution to this problem is inspired by the work of Zdzisław Pawlak during the early 1980s on the classification of objects. In working toward a solution of the problem of the classification of perceptual objects, this article introduces a near set approach to feature selection. Consideration of the nearness of objects has recently led to the introduction of what are known as near sets, an optimist's view of the approximation of sets of objects that are more or less near each other. Near set theory started with the introduction of collections of partitions (families of neighbourhoods) that provide a basis for a feature selection method based on the information content of the partitions of a set of sample objects. A byproduct of the proposed approach is a feature filtering method that eliminates features that are less useful in the classification of objects. This contribution of this article is the introduction of a near set approach to feature selection.

#index 1410709
#* Evaluating accuracies of a trading rule mining method based on temporal pattern extraction
#@ Hidenao Abe;Satoru Hirabayashi;Miho Ohsaki;Takahira Yamaguchi
#t 2007
#c 22
#% 136350
#% 232106
#% 290482
#% 385564
#% 465922
#% 629650
#% 799768
#% 893374
#% 1499573
#! In this paper, we present an evaluation of accuracies of temporal rules obtained from the integrated temporal data mining environment using trading dataset from the Japanese stock market. Temporal data mining is one of key issues to get useful knowledge from databases. However, users often face on difficulties during such temporal data mining process for data pre-processing method selection/construction, mining algorithm selection, and post-processing to refine the data mining process. To get rules that are more valuable for domain experts from a temporal data mining process, we have designed an environment, which integrates temporal pattern extraction methods, rule induction methods and rule evaluation methods with visual human-system interface. Then, we have done a case study to mine temporal rules from a Japanese stock market database for trading. The result shows the availability to find out useful trading rules based on temporal pattern extraction.

#index 1410710
#* Discovering word meanings based on frequent termsets
#@ Henryk Rybinski;Marzena Kryszkiewicz;Grzegorz Protaziuk;Aleksandra Kontkiewicz;Katarzyna Marcinkowska;Alexandre Delteil
#t 2007
#c 22
#% 18571
#% 199781
#% 466664
#% 481290
#% 577285
#% 741080
#% 747738
#% 811281
#% 817576
#% 818059
#% 981597
#! Word meaning ambiguity has always been an important problem in information retrieval and extraction, as well as, text mining (documents clustering and classification). Knowledge discovery tasks such as automatic ontology building and maintenance would also profit from simple and efficient methods for discovering word meanings. The paper presents a novel text mining approach to discovering word meanings. The offered measures of their context are expressed by means of frequent termsets. The presented methods have been implemented with efficient data mining techniques. The approach is domain- and language-independent, although it requires applying part of speech tagger. The paper includes sample results obtained with the presented methods.

#index 1410711
#* Quality of musical instrument sound identification for various levels of accompanying sounds
#@ Alicja Wieczorkowska;Elżbieta Kolczyńska
#t 2007
#c 22
#% 551205
#% 574398
#% 855806
#% 974577
#% 991007
#% 1663428
#! Research on automatic identification of musical instrument sounds has already been performed through last years, but mainly for monophonic singular sounds. In this paper we work on identification of musical instrument in polyphonic environment, with added accompanying orchestral sounds for the training purposes, and using mixes of two instrument sounds for testing. Four instruments of definite pitch has been used. For training purposes, these sounds were mixed with orchestral recordings of various levels, diminished with respect to the original recording level. The level of sounds added for testing purposes was also diminished with respect to the original recording level, in order to assure that the investigated instrument actually produced the sound dominating in the recording. The experiments have been performed using WEKA classification software.

#index 1410712
#* Discriminant feature analysis for music timbre recognition and automatic indexing
#@ Xin Zhang;Zbigniew W. Raś;Agnieszka Dardzińska
#t 2007
#c 22
#% 434753
#% 445170
#% 624464
#% 866315
#% 974577
#% 974712
#% 974728
#% 977113
#% 995372
#% 1054443
#% 1688192
#% 1767421
#! The high volume of digital music recordings in the internet repositories has brought a tremendous need for a cooperative recommendation system to help users to find their favorite music pieces. Music instrument identification is one of the important subtasks of a content-based automatic indexing, for which authors developed novel new temporal features and built a multi-hierarchical decision system S with all the low-level MPEG7 descriptors as well as other popular descriptors for describing music sound objects. The decision attributes in S are hierarchical and they include Hornbostel-Sachs classification and generalization by articulation. The information richness hidden in these descriptors has strong implication on the confidence of classifiers built from S. Rule-based classifiers give us approximate definitions of values of decision attributes and they are used as a tool by content-based Automatic Indexing Systems (AIS). Hierarchical decision attributes allow us to have the indexing done on different granularity levels of classes of music instruments. We can identify not only the instruments playing in a given music piece but also classes of instruments if the instrument level identification fails. The quality of AIS can be verified using precision and recall based on two interpretations: user and system-based [16]. AIS engine follows system-based interpretation.

#index 1410713
#* Contextual adaptive clustering of web and text documents with personalization
#@ Krzysztof Ciesielski;Mieczysław A. Kłopotek;Sławomir T. Wierzchoń
#t 2007
#c 22
#% 46803
#% 248790
#% 329562
#% 391311
#% 1399049
#% 1663689
#% 1664597
#! We present a new method of modeling of cluster structure of a document collection and outline an approach to integrate additional knowledge we have about the document collection like prior categorization of some documents or user defined / deduced preferences in the process of personalized document map creation.

#index 1410714
#* Improving boosting by exploiting former assumptions
#@ Emna Bahri;Nicolas Nicoloyannis;Mondher Maddouri
#t 2007
#c 22
#% 73372
#% 165663
#% 209021
#% 266257
#% 302391
#% 307100
#% 331916
#% 458695
#% 562952
#% 562956
#% 1290045
#% 1393004
#% 1499584
#! The error reduction in generalization is one of the principal motivations of research in machine learning. Thus, a great number of work is carried out on the classifiers aggregation methods in order to improve generally, by voting techniques, the performance of a single classifier. Among these methods of aggregation, we find the Boosting which is most practical thanks to the adaptive update of the distribution of the examples aiming at increasing in an exponential way the weight of the badly classified examples. However, this method is blamed because of overfitting, and the convergence speed especially with noise. In this study, we propose a new approach and modifications carried out on the algorithm of AdaBoost. We will demonstrate that it is possible to improve the performance of the Boosting, by exploiting assumptions generated with the former iterations to correct the weights of the examples. An experimental study shows the interest of this new approach, called hybrid approach.

#index 1410715
#* Discovery of frequent graph patterns that consist of the vertices with the complex structures
#@ Tsubasa Yamamoto;Tomonobu Ozaki;Takenao Ohkawa
#t 2007
#c 22
#% 431105
#% 464996
#% 466644
#% 629603
#% 629708
#% 727845
#% 729938
#% 731608
#% 769951
#% 833025
#% 920863
#% 957735
#% 1393215
#! In some real world applications, the data can be represented naturally in a special kind of graphs in which each vertex consists of a set of (structured) data such as item sets, sequences and so on. One of the typical examples is metabolic pathways in bioinformatics. Metabolic pathway is represented in a graph structured data in which each vertex corresponds to an enzyme described by a set of various kinds of properties such as amino acid sequence, enzyme number and so on. We call this kind of complex graphs multi-structured graphs. In this paper, we propose an algorithm named FMG for mining frequent patterns in multistructured graphs. In FMG, while the external structure will be expanded by the same mechanism of conventional graph miners, the internal structure will be enumerated by the algorithms suitable for its structure. In addition, FMG employs novel pruning techniques to exclude uninteresting patterns. The preliminary experimental results with real datasets show the effectiveness of the proposed algorithm.

#index 1410716
#* Finding composite episodes
#@ Ronnie Bathoorn;Arno Siebes
#t 2007
#c 22
#% 300120
#% 420063
#% 867876
#% 881542
#% 915358
#% 972338
#% 1663670
#! Mining frequent patterns is a major topic in data mining research, resulting in many seminal papers and algorithms on item set and episode discovery. The combination of these, called composite episodes, has attracted far less attention in literature, however. The main reason is that the well-known frequent pattern explosion is far worse for composite episodes than it is for item sets or episodes. Yet, there are many applications where composite episodes are required, e.g., in developmental biology were sequences containing gene activity sets over time are analyzed. This paper introduces an effective algorithm for the discovery of a small, descriptive set of composite episodes. It builds on our earlier work employing MDL for finding such sets for item sets and episodes. This combination yields an optimization problem. For the best results the components descriptive power has to be balanced. Again, this problem is solved using MDL.

#index 1410717
#* Ordinal classification with decision rules
#@ Krzysztof Dembczyński;Wojciech Kotłowski;Roman Słowiński
#t 2007
#c 22
#% 235377
#% 283138
#% 466744
#% 734915
#% 840853
#% 926881
#% 1661944
#% 1696093
#! We consider the problem of ordinal classification, in which a value set of the decision attribute (output, dependent variable) is finite and ordered. This problem shares some characteristics of multi-class classification and regression, however, in contrast to the former, the order between class labels cannot be neglected, and, in the contrast to the latter, the scale of the decision attribute is not cardinal. In the paper, following the theoretical framework for ordinal classification, we introduce two algorithms based on gradient descent approach for learning ensemble of base classifiers being decision rules. The learning is performed by greedy minimization of so-called threshold loss, using a forward stagewise additive modeling. Experimental results are given that demonstrate the usefulness of the approach.

#index 1410718
#* Data mining of multi-categorized data
#@ Akinori Abe;Norihiro Hagita;Michiko Furutani;Yoshiyuki Furutani;Rumiko Matsuoka
#t 2007
#c 22
#% 136350
#% 152934
#% 392781
#% 486474
#% 719422
#% 771641
#% 1704021
#! At the International Research and Educational Institute for Integrated Medical Sciences (IREIIMS) project, we are collecting complete medical data sets to determine relationships between medical data and health status. Since the data include many items which will be categorized differently, it is not easy to generate useful rule sets. Sometimes rare rule combinations are ignored and thus we cannot determine the health status correctly. In this paper, we analyze the features of such complex data, point out the merit of categorized data mining and propose categorized rule generation and health status determination by using combined rule sets.

#index 1410719
#* ARAS: action rules discovery based on agglomerative strategy
#@ Zbigniew W. Raś;Elżbieta Wyrzykowska;Hanna Wasyluk
#t 2007
#c 22
#% 236752
#% 392618
#% 549459
#% 808913
#% 1663453
#% 1663457
#! Action rules can be seen as logical terms describing knowledge about possible actions associated with objects which is hidden in a decision system. Classical strategy for discovering them from a database requires prior extraction of classification rules which next are evaluated pair by pair with a goal to build a strategy of action based on condition features in order to get a desired effect on a decision feature. An actionable strategy is represented as a term r = [(ω) Λ (α → β)] ⇒ [φ → ψ], where ω, α, β, φ, and ψ are descriptions of objects or events. The term r states that when the fixed condition ω is satisfied and the changeable behavior (α → β) occurs in objects represented as tuples from a database so does the expectation (φ → ψ). This paper proposes a new strategy, called ARAS, for constructing action rules with the main module resembling LERS [6]. ARAS system is more simple than DEAR and its time complexity is also lower.

#index 1410720
#* Learning to order: a relational approach
#@ Donato Malerba;Michelangelo Ceci
#t 2007
#c 22
#% 33376
#% 185232
#% 310515
#% 330769
#% 376266
#% 382569
#% 392781
#% 396021
#% 543959
#% 629710
#% 718607
#% 718609
#% 729922
#% 818092
#% 844833
#% 940494
#% 1006708
#% 1272396
#! In some applications it is necessary to sort a set of elements according to an order relationship which is not known a priori. In these cases, a training set of ordered elements is often available, from which the order relationship can be automatically learned. In this work, it is assumed that the correct succession of elements in a training sequence (or chain) is given, so that it is possible to induce the definition of two predicates, first/1 and succ/2, which are then used to establish an ordering relationship. A peculiarity of this work is the relational representation of training data which allows various relationships between ordered elements to be expressed in addition to the ordering relationship. Therefore, an ILP learning algorithm is applied to induce the definitions of the two predicates. Two methods are reported for the identification of either single chains or multiple chains on new objects. They have been applied to the problem of learning the reading order of layout components extracted from document images. Experimental results show the effectiveness of the proposed solution.

#index 1410721
#* Using semantic distance in a content-based heterogeneous information retrieval system
#@ Ahmad El Sayed;Hakim Hacid;Djamel Zighed
#t 2007
#c 22
#% 183353
#% 198058
#% 279755
#% 457912
#% 465914
#% 465916
#% 642989
#% 721163
#% 730166
#% 741085
#% 744029
#% 748499
#% 748600
#% 748691
#% 1657431
#! This paper brings two contributions in relation with the semantic heterogeneous (documents composed of texts and images) information retrieval: (1) A new context-based semantic distance measure for textual data, and (2) an IR system providing a conceptual and an automatic indexing of documents by considering their heterogeneous content using a domain specific ontology. The proposed semantic distance measure is used in order to automatically fuzzify our domain ontology. The two proposals are evaluated and very interesting results were obtained. Using our semantic distance measure, we obtained a correlation ratio of 0.89 with human judgments on a set of words pairs which led our measure to outperform all the other measures. Preliminary combination results obtained on a specialized corpus of web pages are also reported.

#index 1410722
#* Using secondary knowledge to support decision tree classification of retrospective clinical data
#@ Dympna O'Sullivan;William Elazmeh;Szymon Wilk;Ken Farion;Stan Matwin;Wojtek Michalowski;Morvarid Sehatkar
#t 2007
#c 22
#% 533632
#% 926881
#% 1786786
#! Retrospective clinical data presents many challenges for data mining and machine learning. The transcription of patient records from paper charts and subsequent manipulation of data often results in high volumes of noise as well as a loss of other important information. In addition, such datasets often fail to represent expert medical knowledge and reasoning in any explicit manner. In this research we describe applying data mining methods to retrospective clinical data to build a prediction model for asthma exacerbation severity for pediatric patients in the emergency department. Difficulties in building such a model forced us to investigate alternative strategies for analyzing and processing retrospective data. This paper describes this process together with an approach to mining retrospective clinical data by incorporating formalized external expert knowledge (secondary knowledge sources) into the classification task. This knowledge is used to partition the data into a number of coherent sets, where each set is explicitly described in terms of the secondary knowledge source. Instances from each set are then classified in a manner appropriate for the characteristics of the particular set. We present our methodology and outline a set of experiential results that demonstrate some advantages and some limitations of our approach.

#index 1410723
#* POM centric multi-aspect data analysis for investigating human problem solving function
#@ Shinichi Motomura;Akinori Hara;Ning Zhong;Shengfu Lu
#t 2007
#c 22
#% 641961
#% 726219
#% 768668
#% 793347
#% 793961
#% 835098
#% 1704367
#% 1837376
#! In the paper, we propose an approach of POM (peculiarity oriented mining) centric multi-aspect data analysis for investigating human problem solving related functions, in which computation tasks are used as an example. The proposed approach is based on Brain Informatics (BI) methodology, which supports studies of human information processing mechanism systematically from both macro and micro points of view by combining experimental cognitive neuroscience with advanced information technology. We describe how to design systematically cognitive experiments to obtain multi-ERP data and analyze spatiotemporal peculiarity of such data. Preliminary results show the usefulness of our approach.

#index 1417545
#* Data Mining: Data Mining. Data dredging, Data-snooping bias, Data, ECML PKDD, Data warehouse, Information Awareness Office, Affinity analysis, Geographic ... Surveillance, National Security Agency
#@ John McBrewster;Frederic P. Miller;Agnes F. Vandome
#t 2009
#c 22
#! Data Mining. Data dredging, Data-snooping bias, Data, ECML PKDD, Data warehouse, Information Awareness Office, Affinity analysis, Geographic information system, Surveillance, National Security Agency, Quantitative structure-activity relationship, Customer analytics, Police-enforced ANPR in the UK, Association rule learning, Cluster analysis, Data scraping , Data analysis, Predictive analytics, Knowledge discover, Information extraction, Named entity recognition, Profiling practices, Predictive Model Markup Language.

#index 1495537
#* Proceedings of the 2010 European conference on Machine learning and knowledge discovery in databases: Part I
#@ José Luis Balcázar;Francesco Bonchi;Aristides Gionis;Michèle Sebag
#t 2010
#c 22

#index 1495538
#* Mining billion-node graphs: patterns, generators and tools
#@ Christos Faloutsos
#t 2010
#c 22

#index 1495539
#* Structure is informative: on mining structured information networks
#@ Jiawei Han
#t 2010
#c 22

#index 1495540
#* Intelligent interaction with the real world
#@ Leslie Pack Kaelbling
#t 2010
#c 22

#index 1495541
#* Mining experimental data for dynamical invariants - from cognitive robotics to computational biology
#@ Hod Lipson
#t 2010
#c 22

#index 1495542
#* Hierarchical learning machines and neuroscience of visual cortex
#@ Tomaso Poggio
#t 2010
#c 22

#index 1495543
#* Formal theory of fun and creativity
#@ Jürgen Schmidhuber
#t 2010
#c 22

#index 1495544
#* Porting decision tree algorithms to multicore using fastflow
#@ Marco Aldinucci;Salvatore Ruggieri;Massimo Torquati
#t 2010
#c 22
#% 136350
#% 217134
#% 314784
#% 420109
#% 429420
#% 443494
#% 470693
#% 481945
#% 535933
#% 575959
#% 631969
#% 660537
#% 765723
#% 785506
#% 789002
#% 824699
#% 954462
#% 1056814
#% 1219782
#% 1380871
#% 1421029
#! The whole computer hardware industry embraced multicores. For these machines, the extreme optimisation of sequential algorithms is no longer sufficient to squeeze the real machine power, which can be only exploited via thread-level parallelism. Decision tree algorithms exhibit natural concurrency that makes them suitable to be parallelised. This paper presents an approach for easy-yet-efficient porting of an implementation of the C4.5 algorithm on multicores. The parallel porting requires minimal changes to the original sequential code, and it is able to exploit up to 7× speedup on an Intel dual-quad core machine.

#index 1495545
#* On classifying drifting concepts in P2P networks
#@ Hock Hee Ang;Vivekanand Gopalkrishnan;Wee Keong Ng;Steven Hoi
#t 2010
#c 22
#% 137365
#% 280498
#% 342600
#% 342639
#% 458245
#% 466345
#% 729932
#% 888878
#% 893723
#% 907499
#% 989669
#% 1001525
#% 1072520
#% 1073923
#% 1074047
#% 1130875
#% 1202948
#% 1268038
#! Concept drift is a common challenge for many real-world data mining and knowledge discovery applications. Most of the existing studies for concept drift are based on centralized settings, and are often hard to adapt in a distributed computing environment. In this paper, we investigate a new research problem, P2P concept drift detection, which aims to effectively classify drifting concepts in P2P networks. We propose a novel P2P learning framework for concept drift classification, which includes both reactive and proactive approaches to classify the drifting concepts in a distributed manner. Our empirical study shows that the proposed technique is able to effectively detect the drifting concepts and improve the classification performance.

#index 1495546
#* A unified approach to active dual supervision for labeling features and examples
#@ Josh Attenberg;Prem Melville;Foster Provost
#t 2010
#c 22
#% 170649
#% 252011
#% 464268
#% 464465
#% 769908
#% 770807
#% 799753
#% 844399
#% 854646
#% 879626
#% 961194
#% 987202
#% 1074125
#% 1176920
#% 1197791
#% 1211770
#% 1211809
#% 1214749
#% 1220999
#% 1250186
#% 1264721
#% 1338536
#% 1673023
#! When faced with the task of building accurate classifiers, active learning is often a beneficial tool for minimizing the requisite costs of human annotation. Traditional active learning schemes query a human for labels on intelligently chosen examples. However, human effort can also be expended in collecting alternative forms of annotation. For example, one may attempt to learn a text classifier by labeling words associated with a class, instead of, or in addition to, documents. Learning from two different kinds of supervision adds a challenging dimension to the problem of active learning. In this paper, we present a unified approach to such active dual supervision: determining which feature or example a classifier is most likely to benefit from having labeled. Empirical results confirm that appropriately querying for both example and feature labels significantly reduces overall human effort--beyond what is possible through traditional one-dimensional active learning.

#index 1495547
#* Vector field learning via spectral filtering
#@ Luca Baldassarre;Lorenzo Rosasco;Annalisa Barla;Alessandro Verri
#t 2010
#c 22
#% 163348
#% 236497
#% 722798
#% 722805
#% 829014
#% 829023
#% 855495
#% 944004
#% 961228
#% 996512
#% 1084546
#% 1108839
#! In this paper we present and study a new class of regularized kernel methods for learning vector fields, which are based on filtering the spectrum of the kernel matrix. These methods include Tikhonov regularization as a special case, as well as interesting alternatives such as vector valued extensions of L2-Boosting. Our theoretical and experimental analysis shows that spectral filters that yield iterative algorithms, such as L2-Boosting, are much faster than Tikhonov regularization and attain the same prediction performances. Finite sample bounds for the different filters can be derived in a common framework and highlight different theoretical properties of the methods. The theory of vector valued reproducing kernel Hilbert space is a key tool in our study.

#index 1495548
#* Weighted symbols-based edit distance for string-structured image classification
#@ Cécile Barat;Christophe Ducottet;Elisa Fromont;Anne-Claire Legrand;Marc Sebban
#t 2010
#c 22
#% 23998
#% 232645
#% 251405
#% 288885
#% 317819
#% 321635
#% 522573
#% 724204
#% 755467
#% 760805
#% 836746
#% 940343
#% 996168
#% 1036617
#% 1036903
#% 1043038
#% 1108924
#% 1378528
#% 1432315
#% 1667698
#% 1855132
#% 1860548
#! As an alternative to vector representations, a recent trend in image classification suggests to integrate additional structural information in the description of images in order to enhance classification accuracy. Rather than being represented in a p-dimensional space, images can typically be encoded in the form of strings, trees or graphs and are usually compared either by computing suited metrics such as the (string or tree)-edit distance, or by testing subgraph isomorphism. In this paper, we propose a new way for representing images in the form of strings whose symbols are weighted according to a TF-IDF-based weighting scheme, inspired from information retrieval. To be able to handle such real-valued weights, we first introduce a new weighted string edit distance that keeps the properties of a distance. In particular, we prove that the triangle inequality is preserved which allows the computation of the edit distance in quadratic time by dynamic programming. We show on an image classification task that our new weighted edit distance not only significantly outperforms the standard edit distance but also seems very competitive in comparison with standard histogram distances-based approaches.

#index 1495549
#* A concise representation of association rules using minimal predictive rules
#@ Iyad Batal;Milos Hauskrecht
#t 2010
#c 22
#% 152934
#% 227919
#% 248785
#% 280433
#% 329537
#% 420126
#% 459020
#% 466483
#% 466644
#% 501817
#% 536291
#% 549439
#% 631970
#% 632029
#% 823356
#% 867057
#% 1083642
#% 1083649
#% 1127267
#! Association rule mining is an important branch of data mining research that aims to extract important relations from data. In this paper, we develop a new framework for mining association rules based on minimal predictive rules (MPR). Our objective is to minimize the number of rules in order to reduce the information overhead, while preserving and concisely describing the important underlying patterns. We develop an algorithm to efficiently mine these MPRs. Our experiments on several synthetic and UCI datasets demonstrate the advantage of our framework by returning smaller and more concise rule sets than the other existing association rule mining methods.

#index 1495550
#* Euclidean distances, soft and spectral clustering on weighted graphs
#@ François Bavaud
#t 2010
#c 22
#% 115608
#% 313959
#% 425035
#% 464615
#% 593047
#% 724227
#% 840907
#% 850013
#% 889151
#% 975021
#% 992320
#% 995140
#% 1092543
#% 1788040
#! We define a class of Euclidean distances on weighted graphs, enabling to perform thermodynamic soft graph clustering. The class can be constructed form the "raw coordinates" encountered in spectral clustering, and can be extended by means of higher-dimensional embeddings (Schoenberg transformations). Geographical flow data, properly conditioned, illustrate the procedure as well as visualization aspects.

#index 1495551
#* Adaptive parallel/serial sampling mechanisms for particle filtering in dynamic Bayesian networks
#@ Eva Besada-Portas;Sergey M. Plis;Jesus M. de la Cruz;Terran Lane
#t 2010
#c 22
#% 320663
#% 337494
#% 424819
#% 458100
#% 528169
#% 1007572
#% 1268041
#% 1270310
#% 1289572
#! Monitoring the variables of real world dynamical systems is a difficult task due to their inherent complexity and uncertainty. Particle Filters (PF) perform that task, yielding probability distribution over the unobserved variables. However, they suffer from the curse of dimensionality problem: the necessary number of particles grows exponentially with the dimensionality of the hidden state space. The problem is aggravated when the initial distribution of the variables is not well known, as happens in global localization problems. In this paper we present two new adaptive sampling mechanisms for PFs for systems whose variable dependencies can be factored into a Dynamic Bayesian Network. The novel PFs, developed over the proposed sampling mechanisms, exploit the strengths of other existing PFs. Their adaptive mechanisms 1) modify or establish probabilistic links among the subspaces of hidden variables that are independently explored to build particles consistent with the current measurements and past history, and 2) tune the performance of the new PFs toward the behaviors of several existing PFs. We demonstrate their performance on some complex dynamical system estimation problems, showing that our methods successfully localize and track hidden states, and outperform some of the existing PFs.

#index 1495552
#* Leveraging bagging for evolving data streams
#@ Albert Bifet;Geoff Holmes;Bernhard Pfahringer
#t 2010
#c 22
#% 209021
#% 310500
#% 342600
#% 342636
#% 342639
#% 400847
#% 420054
#% 465751
#% 729965
#% 755461
#% 763700
#% 961134
#% 1008315
#% 1214635
#% 1272365
#% 1472282
#% 1673597
#% 1710583
#! Bagging, boosting and Random Forests are classical ensemble methods used to improve the performance of single classifiers. They obtain superior performance by increasing the accuracy and diversity of the single classifiers. Attempts have been made to reproduce these methods in the more challenging context of evolving data streams. In this paper, we propose a new variant of bagging, called leveraging bagging. This method combines the simplicity of bagging with adding more randomization to the input, and output of the classifiers. We test our method by performing an evaluation study on synthetic and real-world datasets comprising up to ten million examples.

#index 1495553
#* ITCH: information-theoretic cluster hierarchies
#@ Christian Böhm;Frank Fiedler;Annahita Oswald;Claudia Plant;Bianca Wackersreuther;Peter Wackersreuther
#t 2010
#c 22
#% 36672
#% 273890
#% 304947
#% 309128
#% 369349
#% 466425
#% 635727
#% 769881
#% 770782
#% 855557
#% 881462
#% 1078626
#% 1815525
#! Hierarchical clustering methods are widely used in various scientific domains such as molecular biology, medicine, economy, etc. Despite the maturity of the research field of hierarchical clustering, we have identified the following four goals which are not yet fully satisfied by previous methods: First, to guide the hierarchical clustering algorithm to identify only meaningful and valid clusters. Second, to represent each cluster in the hierarchy by an intuitive description with e.g. a probability density function. Third, to consistently handle outliers. And finally, to avoid difficult parameter settings.With ITCH, we propose a novel clustering method that is built on a hierarchical variant of the information-theoretic principle of Minimum Description Length (MDL), referred to as hMDL. Interpreting the hierarchical cluster structure as a statistical model of the data set, it can be used for effective data compression by Huffman coding. Thus, the achievable compression rate induces a natural objective function for clustering, which automatically satisfies all four above mentioned goals.

#index 1495554
#* Coniunge et impera: multiple-graph mining for query-log analysis
#@ Ilaria Bordino;Debora Donato;Ricardo Baeza-Yates
#t 2010
#c 22
#% 194299
#% 310567
#% 330617
#% 728105
#% 754117
#% 823348
#% 956632
#% 963669
#% 987283
#% 989578
#% 1035578
#% 1063500
#% 1096052
#% 1125901
#% 1130868
#% 1130878
#% 1190101
#% 1245882
#% 1280748
#% 1348333
#% 1712595
#! Query logs of search engines record a huge amount of data about the actions of the users who search for information on the Web. Hence, they contain a wealth of valuable knowledge about the users' interests and preferences, as well as the implicit feedback that Web searchers provide when they click on the results obtained for their queries. In this paper we propose a general and completely unsupervised methodology for query-log analysis, which consists of aggregating multiple graph representations of a query log, tailored to capturing different semantic information. The combination is carried out by applying simple but efficient graph-mining techniques. We show that our approach achieves very good performance for two different applications, which are classifying query transitions and recognizing spam queries.

#index 1495555
#* Process mining meets abstract interpretation
#@ J. Carmona;J. Cortadella
#t 2010
#c 22
#% 68187
#% 348994
#% 349117
#% 535061
#% 622418
#% 772836
#% 981211
#% 992856
#% 1015843
#% 1102733
#% 1230301
#% 1365028
#% 1415596
#% 1711199
#! The discovery of process models out of system traces is a problem that has received significant attention in the last years. In this work, a theory for the derivation of a Petri net from a set of traces is presented. The method is based on the theory of abstract interpretation, which has been applied successfully in other areas. The principal application of this theory is Process Mining, an area that tries to incorporate the use of formal models both in the design and use of information systems.

#index 1495556
#* Smarter sampling in model-based Bayesian reinforcement learning
#@ Pablo Samuel Castro;Doina Precup
#t 2010
#c 22
#% 246887
#% 384911
#% 466731
#% 574044
#% 593976
#% 788055
#% 840955
#% 876032
#% 1211754
#% 1279315
#% 1417054
#% 1650283
#! Bayesian reinforcement learning (RL) is aimed at making more efficient use of data samples, but typically uses significantly more computation. For discrete Markov Decision Processes, a typical approach to Bayesian RL is to sample a set of models from an underlying distribution, and compute value functions for each, e.g. using dynamic programming. This makes the computation cost per sampled model very high. Furthermore, the number of model samples to take at each step has mainly been chosen in an ad-hoc fashion. We propose a principled method for determining the number of models to sample, based on the parameters of the posterior distribution over models. Our sampling method is local, in that we may choose a different number of samples for each state-action pair. We establish bounds on the error in the value function between a random model sample and the mean model from the posterior distribution. We compare our algorithm against state-of-the-art methods and demonstrate that our method provides a better trade-off between performance and running time.

#index 1495557
#* Predicting partial orders: ranking with abstention
#@ Weiwei Cheng;Michaël Rademaker;Bernard De Baets;Eyke Hüllermeier
#t 2010
#c 22
#% 327432
#% 728195
#% 889273
#% 1000452
#% 1077150
#% 1093383
#% 1117689
#% 1268056
#% 1272396
#% 1541778
#! The prediction of structured outputs in general and rankings in particular has attracted considerable attention in machine learning in recent years, and different types of ranking problems have already been studied. In this paper, we propose a generalization or, say, relaxation of the standard setting, allowing a model to make predictions in the form of partial instead of total orders. We interpret such kind of prediction as a ranking with partial abstention: If the model is not sufficiently certain regarding the relative order of two alternatives and, therefore, cannot reliably decide whether the former should precede the latter or the other way around, it may abstain from this decision and instead declare these alternatives as being incomparable. We propose a general approach to ranking with partial abstention as well as evaluation metrics for measuring the correctness and completeness of predictions. For two types of ranking problems, we show experimentally that this approach is able to achieve a reasonable trade-off between these two criteria.

#index 1495558
#* Predictive distribution matching SVM for multi-domain learning
#@ Chun-Wei Seah;Ivor W. Tsang;Yew-Soon Ong;Kee-Khoon Lee
#t 2010
#c 22
#% 466263
#% 629620
#% 770858
#% 961218
#% 1019099
#% 1117687
#% 1130817
#% 1211726
#% 1261539
#% 1271973
#% 1305479
#% 1380992
#% 1385982
#% 1400008
#! Domain adaptation (DA) using labeled data from related source domains comes in handy when the labeled patterns of a target domain are scarce. Nevertheless, it is worth noting that when the predictive distribution P(y|x) of the domains differs, which establishes Negative Transfer [19], DA approaches generally fail to perform well. Taking this cue, the Predictive Distribution Matching SVM (PDM-SVM) is proposed to learn a robust classifier in the target domain (referred to as the target classifier) by leveraging the labeled data from only the relevant regions of multiple sources. In particular, a k-nearest neighbor graph is iteratively constructed to identify the regions of relevant source labeled data where the predictive distribution maximally aligns with that of the target data. Predictive distribution matching regularization is then introduced to leverage these relevant source labeled data for training the target classifier. In addition, progressive transduction is adopted to infer the label of target unlabeled data for estimating the predictive distribution of the target domain. Finally, extensive experiments are conducted to illustrate the impact of Negative Transfer on several existing state-of-the-art DA methods, and demonstrate the improved performance efficacy of our proposed PDM-SVM on the commonly used multi-domain Sentiment and Reuters datasets.

#index 1495559
#* Kantorovich distances between rankings with applications to rank aggregation
#@ Stéphan Clémençon;Jérémie Jakubowicz
#t 2010
#c 22
#% 3084
#% 340936
#% 411762
#% 952823
#% 1093383
#% 1150355
#% 1312124
#! The goal of this paper is threefold. It first describes a novel way of measuring disagreement between rankings of a finite set χ of n ≥ 1 elements, that can be viewed as a (mass transportation) Kantorovich metric, once the collection rankings of χ is embedded in the set κn of n× n doubly-stochastic matrices. It also shows that such an embedding makes it possible to define a natural notion of median, that can be interpreted in a probabilistic fashion. In addition, from a computational perspective, the convexification induced by this approach makes median computation more tractable, in contrast to the standard metric-based method that generally yields NP-hard optimization problems. As an illustration, this novel methodology is applied to the issue of ranking aggregation, and is shown to compete with state of the art techniques.

#index 1495560
#* Characteristic kernels on structured domains excel in robotics and human action recognition
#@ Somayeh Danafar;Arthur Gretton;Jürgen Schmidhuber
#t 2010
#c 22
#% 763698
#% 775269
#% 891549
#% 1066707
#% 1100645
#% 1402457
#! Embedding probability distributions into a sufficiently rich (characteristic) reproducing kernel Hilbert space enables us to take higher order statistics into account. Characterization also retains effective statistical relation between inputs and outputs in regression and classification. Recent works established conditions for characteristic kernels on groups and semigroups. Here we study characteristic kernels on periodic domains, rotation matrices, and histograms. Such structured domains are relevant for homogeneity testing, forward kinematics, forward dynamics, inverse dynamics, etc. Our kernel-based methods with tailored characteristic kernels outperform previous methods on robotics problems and also on a widely used benchmark for recognition of human actions in videos.

#index 1495561
#* Regret analysis for performance metrics in multi-label classification: the case of hamming and subset zero-one loss
#@ Krzysztof Dembczyński;Willem Waegeman;Weiwei Cheng;Eyke Hüllermeier
#t 2010
#c 22
#% 236497
#% 739899
#% 838412
#% 925382
#% 926881
#% 1073900
#% 1100077
#% 1264044
#! In multi-label classification (MLC), each instance is associated with a subset of labels instead of a single class, as in conventional classification, and this generalization enables the definition of a multitude of loss functions. Indeed, a large number of losses has already been proposed and is commonly applied as performance metrics in experimental studies. However, even though these loss functions are of a quite different nature, a concrete connection between the type of multi-label classifier used and the loss to be minimized is rarely established, implicitly giving the misleading impression that the same method can be optimal for different loss functions. In this paper, we elaborate on risk minimization and the connection between loss functions in MLC, both theoretically and empirically. In particular, we compare two important loss functions, namely the Hamming loss and the subset 0/1 loss. We perform a regret analysis, showing how poor a classifier intended to minimize the subset 0/1 loss can become in terms of Hamming loss and vice versa. The theoretical results are corroborated by experimental studies, and their implications for MLC methods are discussed in a broader context.

#index 1495562
#* Clustering vessel trajectories with alignment kernels under trajectory compression
#@ Gerben de Vries;Maarten van Someren
#t 2010
#c 22
#% 280416
#% 659971
#% 722810
#% 743284
#% 907184
#% 960283
#% 1013696
#% 1016195
#% 1038326
#% 1224923
#% 1298890
#% 1318678
#% 1378458
#% 1674458
#! In this paper we apply a selection of alignment measures, such as dynamic time warping and edit distance, to the problem of clustering vessel trajectories. Vessel trajectories are an example of moving object trajectories, which have recently become an important research topic. The alignment measures are defined as kernels and are used in the kernel k-means clustering algorithm. We investigate the performance of these alignment kernels in combination with a trajectory compression method. Experiments on a gold standard dataset indicate that compression has a positive effect on clustering performance for a number of alignment measures. Also, soft-max kernels, based on summing all alignments, perform worse than classic kernels, based on taking the score of the best alignment.

#index 1495563
#* Adaptive bases for reinforcement learning
#@ Dotan Di Castro;Shie Mannor
#t 2010
#c 22
#% 203596
#% 226878
#% 299643
#% 384911
#% 393786
#% 1078833
#% 1154191
#% 1211814
#% 1782095
#! We consider the problem of reinforcement learning using function approximation, where the approximating basis can change dynamically while interacting with the environment. A motivation for such an approach is maximizing the value function fitness to the problem faced. Three errors are considered: approximation square error, Bellman residual, and projected Bellman residual. Algorithms under the actorcritic framework are presented, and shown to converge. The advantage of such an adaptive basis is demonstrated in simulations.

#index 1495564
#* Constructing nonlinear discriminants from multiple data views
#@ Tom Diethe;David Roi Hardoon;John Shawe-Taylor
#t 2010
#c 22
#% 635689
#% 722901
#% 742990
#% 743284
#% 770846
#% 840865
#% 855563
#% 876003
#% 961149
#! There are many situations in which we have more than one view of a single data source, or in which we have multiple sources of data that are aligned. We would like to be able to build classifiers which incorporate these to enhance classification performance. Kernel Fisher Discriminant Analysis (KFDA) can be formulated as a convex optimisation problem, which we extend to the Multiview setting (MFDA) and introduce a sparse version (SMFDA). We show that our formulations are justified from both probabilistic and learning theory perspectives. We then extend the optimisation problem to account for directions unique to each view (PMFDA). We show experimental validation on a toy dataset, and then give experimental results on a brain imaging dataset and part of the PASCAL 2007 VOC challenge dataset.

#index 1495565
#* Learning algorithms for link prediction based on chance constraints
#@ Janardhan Rao Doppa;Jun Yu;Prasad Tadepalli;Lise Getoor
#t 2010
#c 22
#% 464304
#% 464612
#% 466589
#% 722914
#% 730089
#% 778078
#% 790910
#% 793246
#% 853536
#% 881533
#% 915292
#% 961180
#% 1030874
#% 1117026
#% 1491563
#! In this paper, we consider the link prediction problem, where we are given a partial snapshot of a network at some time and the goal is to predict the additional links formed at a later time. The accuracy of current prediction methods is quite low due to the extreme class skew and the large number of potential links. Here, we describe learning algorithms based on chance constrained programs and show that they exhibit all the properties needed for a good link predictor, namely, they allow preferential bias to positive or negative class; handle skewness in the data; and scale to large networks. Our experimental results on three real-world domains--co-authorship networks, biological networks and citation networks--show significant performance improvement over baseline algorithms. We conclude by briefly describing some promising future directions based on this work.

#index 1495566
#* Sparse unsupervised dimensionality reduction algorithms
#@ Wenjun Dou;Guang Dai;Congfu Xu;Zhihua Zhang
#t 2010
#c 22
#% 224113
#% 983908
#% 1058131
#% 1300083
#! Principal component analysis (PCA) and its dual--principal coordinate analysis (PCO)--are widely applied to unsupervised dimensionality reduction. In this paper, we show that PCAand PCOcan be carried out under regression frameworks. Thus, it is convenient to incorporate sparse techniques into the regression frameworks. In particular, we propose a sparse PCA model and a sparse PCO model. The former is to find sparse principal components, while the latter directly calculates sparse principal coordinates in a low-dimensional space. Our models can be solved by simple and efficient iterative procedures. Finally, we discuss the relationship of our models with other existing sparse PCA methods and illustrate empirical comparisons for these sparse unsupervised dimensionality reduction methods. The experimental results are encouraging.

#index 1495567
#* Asking generalized queries to ambiguous oracle
#@ Jun Du;Charles X. Ling
#t 2010
#c 22
#% 116165
#% 170649
#% 224755
#% 272527
#% 450951
#% 451056
#% 464268
#% 464621
#% 534303
#% 565537
#% 722797
#% 735357
#% 735358
#% 763705
#% 840922
#% 1083677
#% 1272282
#% 1289639
#% 1318613
#% 1424132
#! Asking generalized queries (by regarding some features as don't-care) in active learning has been proposed and studied recently. As each generalized query is equivalent to a set of specific ones, the answers from the oracle can usually provide more information thus speeding up the learning effectively. However, as the answers to the generalized queries might be uncertain, previous studies often assume that the oracle is capable of providing (accurate) probabilistic answers. This assumption, however, is often too stringent in real-world situations. In this paper, we make a more realistic assumption that the oracle can only provide (non-probabilistic) ambiguous answers, similar to the setting in multiple-instance learning. That is, the generalized query is labeled positive if at least one of the corresponding specific queries is positive, and is labeled negative otherwise. We therefore propose an algorithm to construct the generalized queries and improve the learning model with such ambiguous answers in active learning. Empirical study shows that, the proposed algorithm can significantly speed up the learning process, and outperform active learning with either specific queries or inaccurately answered generalized queries.

#index 1495568
#* Analysis of large multi-modal social networks: patterns and a generator
#@ Nan Du;Hao Wang;Christos Faloutsos
#t 2010
#c 22
#% 283833
#% 287267
#% 342592
#% 713033
#% 823342
#% 847046
#% 867050
#% 989519
#% 1083628
#% 1083682
#% 1176979
#% 1206639
#% 1214648
#% 1268028
#% 1281832
#% 1384246
#% 1673564
#! On-line social networking sites often involve multiple relations simultaneously. While people can build an explicit social network by adding each other as friends, they can also form several implicit social networks through their daily interactions like commenting on people's posts, or tagging people's photos. So given a real social networking system which changes over time, what can we say about people's social behaviors ? Do their daily interactions follow any pattern ? The majority of earlier work mainly mimics the patterns and properties of a single type of network. Here, we model the formation and co-evolution of multi-modal networks emerging from different social relations such as "who-adds-whom-as-friend" and "who-comments-on-whose-post" simultaneously. The contributions are the following : (a) we propose a new approach called EigenNetwork Analysis for analyzing time-evolving networks, and use it to discover temporal patterns with people's social interactions; (b) we report inherent correlation between friendship and co-occurrence in on-line settings; (c) we design the first multimodal graph generator xSocial 1 that is capable of producing multiple weighted time-evolving networks, which match most of the observed patterns so far. Our study was performed on two real datasets (Nokia FriendView and Flickr) with 100,000 and 50,000,000 records respectively, each of which corresponds to a different social service, and spans up to two years of activity.

#index 1495569
#* A cluster-level semi-supervision model for interactive clustering
#@ Avinava Dubey;Indrajit Bhattacharya;Shantanu Godbole
#t 2010
#c 22
#% 170649
#% 272521
#% 464291
#% 464608
#% 464631
#% 466890
#% 729918
#% 785341
#% 893725
#% 936961
#% 983829
#% 1085668
#% 1250560
#% 1272282
#! Semi-supervised clustering models, that incorporate user provided constraints to yield meaningful clusters, have recently become a popular area of research. In this paper, we propose a cluster-level semi-supervision model for inter-active clustering. Prototype based clustering algorithms typically alternate between updating cluster descriptions and assignment of data items to clusters. In our model, the user provides semi-supervision directly for these two steps. Assignment feedback re-assigns data items among existing clusters, while cluster description feedback helps to position existing cluster centers more meaningfully. We argue that providing such supervision is more natural for exploratory data mining, where the user discovers and interprets clusters as the algorithm progresses, in comparison to the pair-wise instance level supervision model, particularly for high dimensional data such as document collection. We show how such feedback can be interpreted as constraints and incorporated within the kmeans clustering framework. Using experimental results on multiple real-world datasets, we show that this framework improves clustering performance significantly beyond traditional k-means. Interestingly, when given the same number of feedbacks from the user, the proposed framework significantly outperforms the pair-wise supervision model.

#index 1495570
#* Software-defect localisation by mining dataflow-enabled call graphs
#@ Frank Eichinger;Klaus Krogmann;Roland Klug;Klemens Böhm
#t 2010
#c 22
#% 136350
#% 231941
#% 411114
#% 488392
#% 581051
#% 729938
#% 733623
#% 823217
#% 840516
#% 868145
#% 911720
#% 926881
#% 1019254
#% 1063502
#% 1108856
#% 1114473
#% 1227871
#% 1354633
#% 1433444
#% 1493505
#% 1523286
#! Defect localisation is essential in software engineering and is an important task in domain-specific data mining. Existing techniques building on call-graph mining can localise different kinds of defects. However, these techniques focus on defects that affect the controlflow and are agnostic regarding the dataflow. In this paper, we introduce dataflowenabled call graphs that incorporate abstractions of the dataflow. Building on these graphs, we present an approach for defect localisation. The creation of the graphs and the defect localisation are essentially data mining problems, making use of discretisation, frequent subgraph mining and feature selection. We demonstrate the defect-localisation qualities of our approach with a study on defects introduced into Weka. As a result, defect localisation now works much better, and a developer has to investigate on average only 1.5 out of 30 methods to fix a defect.

#index 1495571
#* Induction of concepts in web ontologies through terminological decision trees
#@ Nicola Fanizzi;Claudia d'Amato;Floriana Esposito
#t 2010
#c 22
#% 449588
#% 550723
#% 570301
#% 935898
#% 948155
#% 1108081
#% 1152445
#% 1290052
#% 1290272
#% 1312805
#% 1413146
#! A new framework for the induction of logical decision trees is presented. Differently from the original setting, tests at the tree nodes are expressed with Description Logic concepts. This has a number of advantages: expressive terminological languages are endowed with full negation, thus allowing for a more natural division of the individuals at each test node; these logics support the standard ontology languages for representing knowledge bases in the Semantic Web. A top-down method for inducing terminological decision trees is proposed as an adaptation of well-known tree-induction methods. This offers an alternative way for learning in Description logics as concept descriptions can be associated to the terminological trees. A new version of the System TermiTIS, implementing the methods, is experimentally evaluated on ontologies from popular repositories.

#index 1495572
#* Classification with sums of separable functions
#@ Jochen Garcke
#t 2010
#c 22
#% 398278
#% 822771
#% 875985
#% 891559
#% 959454
#% 1133993
#% 1192874
#% 1294079
#% 1299720
#% 1300087
#! We present a novel approach for classification using a discretised function representation which is independent of the data locations. We construct the classifier as a sum of separable functions, extending the paradigm of separated representations. Such a representation can also be viewed as a low rank tensor product approximation. The central learning algorithm is linear in both the number of data points and the number of variables, and thus is suitable for large data sets in high dimensions. We show that our method achieves competitive results on several benchmark data sets which gives evidence for the utility of these representations.

#index 1495573
#* Feature selection for reinforcement learning: evaluating implicit state-reward dependency via conditional mutual information
#@ Hirotaka Hachiya;Masashi Sugiyama
#t 2010
#c 22
#% 124687
#% 225838
#% 384911
#% 722929
#% 734920
#% 739899
#% 876001
#% 983896
#% 983907
#% 1073966
#% 1362510
#% 1385955
#! Model-free reinforcement learning (RL) is a machine learning approach to decision making in unknown environments. However, realworld RL tasks often involve high-dimensional state spaces, and then standard RL methods do not perform well. In this paper, we propose a new feature selection framework for coping with high dimensionality. Our proposed framework adopts conditional mutual information between return and state-feature sequences as a feature selection criterion, allowing the evaluation of implicit state-reward dependency. The conditional mutual information is approximated by a least-squares method, which results in a computationally efficient feature selection procedure. The usefulness of the proposed method is demonstrated on grid-world navigation problems.

#index 1495574
#* Bagging for biclustering: application to microarray data
#@ Blaise Hanczar;Mohamed Nadif
#t 2010
#c 22
#% 209021
#% 469422
#% 551723
#% 579652
#% 722902
#% 753142
#% 778215
#% 906512
#% 1036692
#% 1039156
#% 1478814
#! One of the major tools of transcriptomics is the biclustering that simultaneously constructs a partition of both examples and genes. Several methods have been proposed for microarray data analysis that enables to identify groups of genes with similar expression pro?les only under a subset of examples. We propose to improve the quality of these biclustering methods by adapting the approach of bagging to biclustering problems. The principle consists in generating a set of biclusters and aggregating the results. Our method has been tested with success on artificial and real datasets.

#index 1495575
#* Hub gene selection methods for the reconstruction of transcription networks
#@ José Miguel Hernández-Lobato;Tjeerd M. H. Dijkstra
#t 2010
#c 22
#% 722760
#% 814023
#% 875974
#% 891559
#! Transcription control networks have a scale-free topological structure: While most genes are involved in a reduced number of links, a few hubs or key regulators are connected to a significantly large number of nodes. Several methods have been developed for the reconstruction of these networks from gene expression data, e.g. ARACNE. However, few of them take into account the scale-free structure of transcription networks. In this paper, we focus on the hubs that commonly appear in scale-free networks. First, three feature selection methods are proposed for the identification of those genes that are likely to be hubs and second, we introduce an improvement in ARACNE so that this technique can take into account the list of hub genes generated by the feature selection methods. Experiments with synthetic gene expression data validate the accuracy of the feature selection methods in the task of identifying hub genes. When ARACNE is combined with the output of these methods, we achieve up to a 62% improvement in performance over the original reconstruction algorithm. Finally, the best method for identifying hub genes is validated on a set of expression profiles from yeast.

#index 1495576
#* Expectation propagation for Bayesian multi-task feature selection
#@ Daniel Hernández-Lobato;José Miguel Hernández-Lobato;Thibault Helleputte;Pierre Dupont
#t 2010
#c 22
#% 715096
#% 722760
#% 769886
#% 891559
#% 961134
#% 999695
#% 1155296
#% 1268067
#% 1379069
#% 1650387
#! In this paper we propose a Bayesian model for multitask feature selection. This model is based on a generalized spike and slab sparse prior distribution that enforces the selection of a common subset of features across several tasks. Since exact Bayesian inference in this model is intractable, approximate inference is performed through expectation propagation (EP). EP approximates the posterior distribution of the model using a parametric probability distribution. This posterior approximation is particularly useful to identify relevant features for prediction. We focus on problems for which the number of features d is significantly larger than the number of instances for each task. We propose an efficient parametrization of the EP algorithm that offers a computational complexity linear in d. Experiments on several multitask datasets show that the proposed model outperforms baseline approaches for single-task learning or data pooling across all tasks, as well as two state-of-the-art multi-task learning approaches. Additional experiments confirm the stability of the proposed feature selection with respect to various sub-samplings of the training data.

#index 1495577
#* Graphical multi-way models
#@ Ilkka Huopaniemi;Tommi Suvitaival;Matej Orešič;Samuel Kaski
#t 2010
#c 22
#% 304879
#% 983857
#% 1214488
#% 1214514
#% 1237828
#% 1263956
#% 1447006
#! Multivariate multi-way ANOVA-type models are the default tools for analyzing experimental data with multiple independent covariates. However, formulating standard multi-way models is not possible when the data comes from different sources or in cases where some covariates have (partly) unknown structure, such as time with unknown alignment. The "small n, large p", large dimensionality p with small number of samples n, settings bring further problems to the standard multivariate methods. We extend our recent graphical multi-way model to three general setups, with timely applications in biomedicine: (i) multiview learning with paired samples, (ii) one covariate is time with unknown alignment, and (iii) multi-view learning without paired samples.

#index 1495578
#* Exploration-exploitation of eye movement enriched multiple feature spaces for content-based image retrieval
#@ Zakria Hussain;Alex P. Leung;Kitsuchart Pasupa;David R. Hardoon;Peter Auer;John Shawe-Taylor
#t 2010
#c 22
#% 341269
#% 425053
#% 722906
#% 743284
#% 763697
#% 770846
#% 1040539
#% 1376020
#% 1377380
#% 1705523
#! In content-based image retrieval (CBIR) with relevance feedback we would like to retrieve relevant images based on their content features and the feedback given by users. In this paper we view CBIR as an Exploration-Exploitation problem and apply a kernel version of the LinRel algorithm to solve it. By using multiple feature extraction methods and utilising the feedback given by users, we adopt a strategy of multiple kernel learning to find a relevant feature space for the kernel LinRel algorithm. We call this algorithm LinRelMKL. Furthermore, when we have access to eye movement data of users viewing images we can enrich our (multiple) feature spaces by using a tensor kernel SVM. When learning in this enriched space we show that we can significantly improve the search results over the LinRel and LinRelMKL algorithms. Our results suggest that the use of exploration-exploitation with multiple feature spaces is an efficient way of constructing CBIR systems, and that when eye movement features are available, they should be used to help improve CBIR.

#index 1495579
#* Graph regularized transductive classification on heterogeneous information networks
#@ Ming Ji;Yizhou Sun;Marina Danilevsky;Jiawei Han;Jing Gao
#t 2010
#c 22
#% 248810
#% 727834
#% 729982
#% 840840
#% 876018
#% 881557
#% 961218
#% 961268
#% 961278
#% 1214701
#% 1214717
#% 1273915
#% 1289267
#% 1650403
#! A heterogeneous information network is a network composed of multiple types of objects and links. Recently, it has been recognized that strongly-typed heterogeneous information networks are prevalent in the real world. Sometimes, label information is available for some objects. Learning from such labeled and unlabeled data via transductive classification can lead to good knowledge extraction of the hidden network structure. However, although classification on homogeneous networks has been studied for decades, classification on heterogeneous networks has not been explored until recently. In this paper, we consider the transductive classification problem on heterogeneous networked data which share a common topic. Only some objects in the given network are labeled, and we aim to predict labels for all types of the remaining objects. A novel graph-based regularization framework, GNetMine, is proposed to model the link structure in information networks with arbitrary network schema and arbitrary number of object/link types. Specifically, we explicitly respect the type differences by preserving consistency over each relation graph corresponding to each type of links separately. Efficient computational schemes are then introduced to solve the corresponding optimization problem. Experiments on the DBLP data set show that our algorithm significantly improves the classification accuracy over existing state-of-the-art methods.

#index 1495580
#* Temporal maximum margin Markov network
#@ Xiaoqian Jiang;Bing Dong;Latanya Sweeney
#t 2010
#c 22
#% 464434
#% 827631
#% 829043
#% 900235
#% 1073983
#% 1211796
#% 1650318
#! Typical structured learning models consist of a regression component of the explanatory variables (observations) and another regression component that accounts for the neighboring states. Such models, including Conditional Random Fields (CRFs) and Maximum Margin Markov Network (M3N), are essentially Markov random fields with the pairwise spatial dependence. They are effective tools for modeling spatial correlated responses; however, ignoring the temporal correlation often limits their performance to model the more complex scenarios. In this paper, we introduce a novel Temporal Maximum Margin Markov Network (TM3N) model to learn the spatial-temporal correlated hidden states, simultaneously. For learning, we estimate the model's parameters by leveraging on loopy belief propagation (LBP); for predicting, we forecast hidden states use linear integer programming (LIP); for evaluation, we apply TM3N to the simulated datasets and the real world challenge for occupancy estimation. The results are compared with other state-of the art models and demonstrate superior performance.

#index 1495581
#* Gaussian processes for sample efficient reinforcement learning with RMAX-like exploration
#@ Tobias Jung;Peter Stone
#t 2010
#c 22
#% 384911
#% 425080
#% 722895
#% 734920
#% 829011
#% 891549
#% 1182603
#% 1215601
#% 1398250
#% 1483632
#! We present an implementation of model-based online reinforcement learning (RL) for continuous domains with deterministic transitions that is specifically designed to achieve low sample complexity. To achieve low sample complexity, since the environment is unknown, an agent must intelligently balance exploration and exploitation, and must be able to rapidly generalize from observations. While in the past a number of related sample efficient RL algorithms have been proposed, to allow theoretical analysis, mainly model-learners with weak generalization capabilities were considered. Here, we separate function approximation in the model learner (which does require samples) from the interpolation in the planner (which does not require samples). For model-learning we apply Gaussian processes regression (GP) which is able to automatically adjust itself to the complexity of the problem (via Bayesian hyperparameter selection) and, in practice, often able to learn a highly accurate model from very little data. In addition, a GP provides a natural way to determine the uncertainty of its predictions, which allows us to implement the "optimism in the face of uncertainty" principle used to efficiently control exploration. Our method is evaluated on four common benchmark domains.

#index 1495582
#* Proceedings of the 2010 European conference on Machine learning and knowledge discovery in databases: Part II
#@ José Luis Balcázar;Francesco Bonchi;Aristides Gionis;Michèle Sebag
#t 2010
#c 22

#index 1495583
#* Bayesian knowledge corroboration with logical rules and user feedback
#@ Gjergji Kasneci;Jurgen Van Gael;Ralf Herbrich;Thore Graepel
#t 2010
#c 22
#% 44876
#% 272514
#% 496116
#% 669288
#% 715096
#% 731615
#% 850430
#% 893189
#% 935898
#% 956564
#% 1019061
#% 1190118
#% 1200291
#% 1206702
#% 1206817
#% 1270261
#% 1270363
#% 1279353
#% 1291123
#% 1292670
#% 1355029
#% 1374370
#% 1409954
#% 1426535
#% 1472273
#% 1668093
#% 1718473
#! Current knowledge bases suffer from either low coverage or low accuracy. The underlying hypothesis of this work is that user feedback can greatly improve the quality of automatically extracted knowledge bases. The feedback could help quantify the uncertainty associated with the stored statements and would enable mechanisms for searching, ranking and reasoning at entity-relationship level. Most importantly, a principled model for exploiting user feedback to learn the truth values of statements in the knowledge base would be a major step forward in addressing the issue of knowledge base curation. We present a family of probabilistic graphical models that builds on user feedback and logical inference rules derived from the popular Semantic-Web formalism of RDFS [1]. Through internal inference and belief propagation, these models can learn both, the truth values of the statements in the knowledge base and the reliabilities of the users who give feedback. We demonstrate the viability of our approach in extensive experiments on real-world datasets, with feedback collected from Amazon Mechanical Turk.

#index 1495584
#* Learning an affine transformation for non-linear dimensionality reduction
#@ Pooyan Khajehpour Tadavani;Ali Ghodsi
#t 2010
#c 22
#% 272544
#% 304931
#% 770839
#% 1211807
#% 1502529
#! The foremost nonlinear dimensionality reduction algorithms provide an embedding only for the given training data, with no straightforward extension for test points. This shortcoming makes them unsuitable for problems such as classification and regression. We propose a novel dimensionality reduction algorithm which learns a parametric mapping between the high-dimensional space and the embedded space. The key observation is that when the dimensionality of the data exceeds its quantity, it is always possible to find a linear transformation that preserves a given subset of distances, while changing the distances of another subset. Our method first maps the points into a high-dimensional feature space, and then explicitly searches for an affine transformation that preserves local distances while pulling non-neighbor points as far apart as possible. This search is formulated as an instance of semidefinite programming, and the resulting transformation can be used to map out-of-sample points into the embedded space.

#index 1495585
#* NDPMine: efficiently mining discriminative numerical features for pattern-based classification
#@ Hyungsul Kim;Sangkyum Kim;Tim Weninger;Jiawei Han;Tarek Abdelzaher
#t 2010
#c 22
#% 235377
#% 345823
#% 425033
#% 466483
#% 483552
#% 729941
#% 789011
#% 1083649
#% 1083688
#% 1183448
#% 1206650
#% 1214677
#% 1214716
#% 1558464
#! Pattern-based classification has demonstrated its power in recent studies, but because the cost of mining discriminative patterns as features in classification is very expensive, several efficient algorithms have been proposed to rectify this problem. These algorithms assume that feature values of the mined patterns are binary, i.e., a pattern either exists or not. In some problems, however, the number of times a pattern appears is more informative than whether a pattern appears or not. To resolve these deficiencies, we propose a mathematical programming method that directly mines discriminative patterns as numerical features for classification. We also propose a novel search space shrinking technique which addresses the inefficiencies in iterative pattern mining algorithms. Finally, we show that our method is an order of magnitude faster, significantly more memory efficient and more accurate than current approaches.

#index 1495586
#* Hidden conditional ordinal random fields for sequence classification
#@ Minyoung Kim;Vladimir Pavlovic
#t 2010
#c 22
#% 464434
#% 722816
#% 736300
#% 784899
#% 829028
#% 840853
#% 866463
#% 876066
#% 884049
#% 1055702
#% 1149161
#! Conditional Random Fields and Hidden Conditional Random Fields are a staple of many sequence tagging and classification frameworks. An underlying assumption in those models is that the state sequences (tags), observed or latent, take their values from a set of nominal categories. These nominal categories typically indicate tag classes (e.g., part-of-speech tags) or clusters of similar measurements. However, in some sequence modeling settings it is more reasonable to assume that the tags indicate ordinal categories or ranks. Dynamic envelopes of sequences such as emotions or movements often exhibit intensities growing from neutral, through raising, to peak values. In this work we propose a new model family, Hidden Conditional Ordinal Random Fields (HCORFs), that explicitly models sequence dynamics as the dynamics of ordinal categories. We formulate those models as generalizations of ordinal regressions to structured (here sequence) settings. We show how classification of entire sequences can be formulated as an instance of learning and inference in H-CORFs. In modeling the ordinal-scale latent variables, we incorporate recent binning-based strategy used for static ranking approaches, which leads to a log-nonlinear model that can be optimized by efficient quasi-Newton or stochastic gradient type searches. We demonstrate improved prediction performance achieved by the proposed models in real video classification problems.

#index 1495587
#* A unifying view of multiple kernel learning
#@ Marius Kloft;Ulrich Rückert;Peter L. Bartlett
#t 2010
#c 22
#% 251365
#% 266426
#% 722909
#% 763697
#% 770846
#% 906288
#% 959454
#% 961190
#% 961261
#% 1214467
#% 1551234
#% 1860761
#! Recent research on multiple kernel learning has lead to a number of approaches for combining kernels in regularized risk minimization. The proposed approaches include different formulations of objectives and varying regularization strategies. In this paper we present a unifying optimization criterion for multiple kernel learning and show how existing formulations are subsumed as special cases. We also derive the criterion's dual representation, which is suitable for general smooth optimization algorithms. Finally, we evaluate multiple kernel learning in this framework analytically using a Rademacher complexity bound on the generalization error and empirically in a set of experiments.

#index 1495588
#* Evolutionary dynamics of regret minimization
#@ Tomas Klos;Gerrit Jan Van Ahee;Karl Tuyls
#t 2010
#c 22
#% 56461
#% 124691
#% 266286
#% 384911
#% 465913
#% 466738
#% 643166
#% 830736
#% 850069
#% 951945
#% 960813
#% 960818
#% 1215608
#% 1272286
#! Learning in multi-agent systems (MAS) is a complex task. Current learning theory for single-agent systems does not extend to multi-agent problems. In a MAS the reinforcement an agent receives may depend on the actions taken by the other agents present in the system. Hence, the Markov property no longer holds and convergence guarantees are lost. Currently there does not exist a general formal theory describing and elucidating the conditions under which algorithms for multi-agent learning (MAL) are successful. Therefore it is important to fully understand the dynamics of multi-agent reinforcement learning, and to be able to analyze learning behavior in terms of stability and resilience of equilibria. Recent work has considered the replicator dynamics of evolutionary game theory for this purpose. In this paper we contribute to this framework. More precisely, we formally derive the evolutionary dynamics of the Regret Minimization polynomial weights learning algorithm, which will be described by a system of differential equations. Using these equations we can easily investigate parameter settings and analyze the dynamics of multiple concurrently learning agents using regret minimization. In this way it is clear why certain attractors are stable and potentially preferred over others, and what the basins of attraction look like. Furthermore, we experimentally show that the dynamics predict the real learning behavior and we test the dynamics also in nonself play, comparing the polynomial weights algorithm against the previously derived dynamics of Q-learning and various Linear Reward algorithms in a set of benchmark normal form games.

#index 1495589
#* Recognition of instrument timbres in real polytimbral audio recordings
#@ Elżbieta Kubera;Alicja Wieczorkowska;Zbigniew Raś;Magdalena Skrzypiec
#t 2010
#c 22
#% 400847
#% 741122
#% 741169
#% 855806
#% 974712
#% 1094314
#% 1267684
#% 1400859
#% 1455417
#% 1486440
#% 1663447
#! Automatic recognition of multiple musical instruments in polyphonic and polytimbral music is a difficult task, but often attempted to perform by MIR researchers recently. In papers published so far, the proposed systems were validated mainly on audio data obtained through mixing of isolated sounds of musical instruments. This paper tests recognition of instruments in real recordings, using a recognition system which has multilabel and hierarchical structure. Random forest classifiers were applied to build the system. Evaluation of our model was performed on audio recordings of classical music. The obtained results are shown and discussed in the paper.

#index 1495590
#* Finding critical nodes for inhibiting diffusion of complex contagions in social networks
#@ Chris J. Kuhlman;V. S. Anil Kumar;Madhav V. Marathe;S. S. Ravi;Daniel J. Rosenkrantz
#t 2010
#c 22
#% 342596
#% 408396
#% 577217
#% 729923
#% 754098
#% 754107
#% 866351
#% 939108
#% 949164
#% 989613
#% 989643
#% 991977
#% 1080076
#% 1083672
#% 1150085
#% 1182734
#% 1399997
#% 1491561
#% 1676017
#! We study the problem of inhibiting diffusion of complex contagions such as rumors, undesirable fads and mob behavior in social networks by removing a small number of nodes (called critical nodes) from the network. We show that, in general, for any ρ ≥ 1, even obtaining a ρ-approximate solution to these problems is NP-hard. We develop efficient heuristics for these problems and carry out an empirical study of their performance on three well known social networks, namely epinions, wikipedia and slashdot. Our results show that the heuristics perform well on the three social networks.

#index 1495591
#* Semi-supervised abstraction-augmented string kernel for multi-level bio-relation extraction
#@ Pavel Kuksa;Yanjun Qi;Bing Bai;Ronan Collobert;Jason Weston;Vladimir Pavlovic;Xia Ning
#t 2010
#c 22
#% 114667
#% 311027
#% 406493
#% 722925
#% 793247
#% 829038
#% 833913
#% 916788
#% 929717
#% 938706
#% 939917
#% 1042263
#% 1073892
#% 1267772
#% 1338540
#! Bio-relation extraction (bRE), an important goal in bio-text mining, involves subtasks identifying relationships between bio-entities in text at multiple levels, e.g., at the article, sentence or relation level. A key limitation of current bRE systems is that they are restricted by the availability of annotated corpora. In this work we introduce a semisupervised approach that can tackle multi-level bRE via string comparisons with mismatches in the string kernel framework. Our string kernel implements an abstraction step, which groups similar words to generate more abstract entities, which can be learnt with unlabeled data. Specifically, two unsupervised models are proposed to capture contextual (local or global) semantic similarities between words from a large unannotated corpus. This Abstraction-augmented String Kernel (ASK) allows for better generalization of patterns learned from annotated data and provides a unified framework for solving bRE with multiple degrees of detail. ASK shows effective improvements over classic string kernels on four datasets and achieves state-of-the-art bRE performance without the need for complex linguistic features.

#index 1495592
#* Online knowledge-based support vector machines
#@ Gautam Kunapuli;Kristin P. Bennett;Amina Shabbeer;Richard Maclin;Jude Shavlik
#t 2010
#c 22
#% 175368
#% 190581
#% 272538
#% 302390
#% 393059
#% 425046
#% 961152
#% 1044110
#% 1232034
#! Prior knowledge, in the form of simple advice rules, can greatly speed up convergence in learning algorithms. Online learning methods predict the label of the current point and then receive the correct label (and learn from that information). The goal of this work is to update the hypothesis taking into account not just the label feedback, but also the prior knowledge, in the form of soft polyhedral advice, so as to make increasingly accurate predictions on subsequent examples. Advice helps speed up and bias learning so that generalization can be obtained with less data. Our passive-aggressive approach updates the hypothesis using a hybrid loss that takes into account the margins of both the hypothesis and the advice on the current point. Encouraging computational results and loss bounds are provided.

#index 1495593
#* Learning with randomized majority votes
#@ Alexandre Lacasse;François Laviolette;Mario Marchand;Francis Turgeon-Boutin
#t 2010
#c 22
#% 235377
#% 276522
#% 431293
#% 464279
#% 722896
#% 803574
#% 1211734
#! We propose algorithms for producing weighted majority votes that learn by probing the empirical risk of a randomized (uniformly weighted) majority vote--instead of probing the zero-one loss, at some margin level, of the deterministic weighted majority vote as it is often proposed. The learning algorithms minimize a risk bound which is convex in the weights. Our numerical results indicate that learners producing a weighted majority vote based on the empirical risk of the randomized majority vote at some finite margin have no significant advantage over learners that achieve this same task based on the empirical risk at zero margin. We also find that it is sufficient for learners to minimize only the empirical risk of the randomized majority vote at a fixed number of voters without considering explicitly the entropy of the distribution of voters. Finally, our extensive numerical results indicate that the proposed learning algorithms are producing weighted majority votes that generally compare favorably to those produced by AdaBoost.

#index 1495594
#* Exploration in relational worlds
#@ Tobias Lang;Marc Toussaint;Kristian Kersting
#t 2010
#c 22
#% 333786
#% 425075
#% 464778
#% 722895
#% 771946
#% 876032
#% 883334
#% 1000502
#% 1073929
#% 1100109
#% 1178635
#% 1211695
#% 1211763
#% 1268080
#% 1272161
#% 1272282
#% 1273836
#% 1274869
#% 1289241
#% 1402658
#% 1629486
#! One of the key problems in model-based reinforcement learning is balancing exploration and exploitation. Another is learning and acting in large relational domains, in which there is a varying number of objects and relations between them. We provide one of the first solutions to exploring large relational Markov decision processes by developing relational extensions of the concepts of the Explicit Explore or Exploit (E3) algorithm. A key insight is that the inherent generalization of learnt knowledge in the relational representation has profound implications also on the exploration strategy: what in a propositional setting would be considered a novel situation and worth exploration may in the relational setting be an instance of a well-known context in which exploitation is promising. Our experimental evaluation shows the effectiveness and benefit of relational exploration over several propositional benchmark approaches on noisy 3D simulated robot manipulation problems.

#index 1495595
#* Efficient confident search in large review corpora
#@ Theodoros Lappas;Dimitrios Gunopulos
#t 2010
#c 22
#% 468209
#% 479649
#% 577355
#% 769892
#% 806212
#% 815915
#% 854646
#% 878935
#% 907489
#% 907490
#% 939346
#% 939896
#% 989576
#% 1035590
#% 1250237
#% 1261574
#% 1261576
#! Given an extensive corpus of reviews on an item, a potential customer goes through the expressed opinions and collects information, in order to form an educated opinion and, ultimately, make a purchase decision. This task is often hindered by false reviews, that fail to capture the true quality of the item's attributes. These reviews may be based on insufficient information or may even be fraudulent, submitted to manipulate the item's reputation. In this paper, we formalize the Confident Search paradigm for review corpora. We then present a complete search framework which, given a set of item attributes, is able to efficiently search through a large corpus and select a compact set of high-quality reviews that accurately captures the overall consensus of the reviewers on the specified attributes. We also introduce CREST (Confident REview Search Tool), a user-friendly implementation of our framework and a valuable tool for any person dealing with large review corpora. The efficacy of our framework is demonstrated through a rigorous experimental evaluation.

#index 1495596
#* Learning to tag from open vocabulary labels
#@ Edith Law;Burr Settles;Tom Mitchell
#t 2010
#c 22
#% 643010
#% 722904
#% 751818
#% 1183199
#% 1214715
#% 1767359
#! Most approaches to classifying media content assume a fixed, closed vocabulary of labels. In contrast, we advocate machine learning approaches which take advantage of the millions of free-form tags obtainable via online crowd-sourcing platforms and social tagging websites. The use of such open vocabularies presents learning challenges due to typographical errors, synonymy, and a potentially unbounded set of tag labels. In this work, we present a new approach that organizes these noisy tags into well-behaved semantic classes using topic modeling, and learn to predict tags accurately using a mixture of topic classes. This method can utilize an arbitrary open vocabulary of tags, reduces training time by 94% compared to learning from these tags directly, and achieves comparable performance for classification and superior performance for retrieval. We also demonstrate that on open vocabulary tasks, human evaluations are essential for measuring the true performance of tag classifiers, which traditional evaluation methods will consistently underestimate. We focus on the domain of tagging music clips, and demonstrate our results using data collected with a human computation game called TagATune.

#index 1495597
#* A robustness measure of association rules
#@ Yannick Le Bras;Patrick Meyer;Philippe Lenca;Stéphane Lallich
#t 2010
#c 22
#% 152934
#% 481290
#% 867057
#% 1099013
#% 1196015
#! We propose a formal definition of the robustness of association rules for interestingness measures. It is a central concept in the evaluation of the rules and has only been studied unsatisfactorily up to now. It is crucial because a good rule (according to a given quality measure) might turn out as a very fragile rule with respect to small variations in the data. The robustness measure that we propose here is based on a model we proposed in a previous work. It depends on the selected quality measure, the value taken by the rule and the minimal acceptance threshold chosen by the user. We present a few properties of this robustness, detail its use in practice and show the outcomes of various experiments. Furthermore, we compare our results to classical tools of statistical analysis of association rules. All in all, we present a new perspective on the evaluation of association rules.

#index 1495598
#* Automatic model adaptation for complex structured domains
#@ Geoffrey Levine;Gerald DeJong;Li-Lun Wang;Rajhans Samdani;Shankar Vembu;Dan Roth
#t 2010
#c 22
#% 450456
#% 722900
#% 793242
#% 934581
#% 1650785
#! Traditional model selection techniques involve training all candidate models in order to select the one that best balances training performance and expected generalization to new cases. When the number of candidate models is very large, though, training all of them is prohibitive. We present a method to automatically explore a large space of models of varying complexities, organized based on the structure of the example space. In our approach, one model is trained by minimizing a minimum description length objective function, and then derivatives of the objective with respect to model parameters over distinct classes of the training data are analyzed in order to suggest what model specifications and generalizations are likely to improve performance. This directs a search through the space of candidates, capable of finding a high performance model despite evaluating a small fraction of the total number of models.We apply our approach in a complex fantasy (American) football prediction domain and demonstrate that it finds high quality model structures, tailored to the amount of training data available.

#index 1495599
#* Collective traffic forecasting
#@ Marco Lippi;Matteo Bertini;Paolo Frasconi
#t 2010
#c 22
#% 394984
#% 1089647
#% 1264359
#% 1296275
#% 1301233
#% 1416201
#% 1774742
#% 1774805
#! Traffic forecasting has recently become a crucial task in the area of intelligent transportation systems, and in particular in the development of traffic management and control. We focus on the simultaneous prediction of the congestion state at multiple lead times and at multiple nodes of a transport network, given historical and recent information. This is a highly relational task along the spatial and the temporal dimensions and we advocate the application of statistical relational learning techniques. We formulate the task in the supervised learning from interpretations setting and use Markov logic networks with groundings-pecific weights to perform collective classification. Experimental results on data obtained from the California Freeway Performance Measurement System (PeMS) show the advantages of the proposed solution, with respect to propositional classifiers. In particular, we obtained significant performance improvement at larger time leads.

#index 1495600
#* On detecting clustered anomalies using SCiForest
#@ Fei Tony Liu;Kai Ming Ting;Zhi-Hua Zhou
#t 2010
#c 22
#% 300136
#% 300183
#% 310552
#% 333929
#% 408466
#% 420064
#% 479791
#% 578689
#% 716544
#% 729912
#% 789012
#% 823340
#% 855602
#% 866326
#% 913197
#% 1165483
#% 1176944
#% 1202160
#% 1272358
#! Detecting local clustered anomalies is an intricate problem for many existing anomaly detection methods. Distance-based and density-based methods are inherently restricted by their basic assumptions--anomalies are either far from normal points or being sparse. Clustered anomalies are able to avoid detection since they defy these assumptions by being dense and, in many cases, in close proximity to normal instances. In this paper, without using any density or distance measure, we propose a new method called SCiForest to detect clustered anomalies. SCiForest separates clustered anomalies from normal points effectively even when clustered anomalies are very close to normal points. It maintains the ability of existing methods to detect scattered anomalies, and it has superior time and space complexities against existing distance-based and density-based methods.

#index 1495601
#* Constrained parameter estimation for semi-supervised learning: the case of the nearest mean classifier
#@ Marco Loog
#t 2010
#c 22
#% 192878
#% 266292
#% 458699
#% 464631
#% 748550
#% 784540
#% 843654
#% 905689
#% 1073995
#% 1354495
#% 1455666
#! A rather simple semi-supervised version of the equally simple nearest mean classifier is presented. However simple, the proposed approach is of practical interest as the nearest mean classifier remains a relevant tool in biomedical applications or other areas dealing with relatively high-dimensional feature spaces or small sample sizes. More importantly, the performance of our semi-supervised nearest mean classifier is typically expected to improve over that of its standard supervised counterpart and typically does not deteriorate with increasing numbers of unlabeled data. This behavior is achieved by constraining the parameters that are estimated to comply with relevant information in the unlabeled data, which leads, in expectation, to a more rapid convergence to the large-sample solution because the variance of the estimate is reduced. In a sense, our proposal demonstrates that it may be possible to properly train a known classification scheme such that it can benefit from unlabeled data, while avoiding the additional assumptions typically made in semi-supervised learning.

#index 1495602
#* Online learning in adversarial Lipschitz environments
#@ Odalric-Ambrym Maillard;Rémi Munos
#t 2010
#c 22
#% 165663
#% 232319
#% 416988
#% 562944
#% 593734
#% 722906
#% 813744
#% 871302
#% 891559
#% 1053729
#% 1061652
#% 1073927
#% 1674795
#! We consider the problem of online learning in an adversarial environment when the reward functions chosen by the adversary are assumed to be Lipschitz. This setting extends previous works on linear and convex online learning. We provide a class of algorithms with cumulative regret upper bounded by Õ(√dt ln(λ)) where d is the dimension of the search space, T the time horizon, and λ the Lipschitz constant. Efficient numerical implementations using particle methods are discussed. Applications include online supervised learning problems for both full and partial (bandit) information settings, for a large class of non-linear regressors/classifiers, such as neural networks.

#index 1495603
#* Summarising data by clustering items
#@ Michael Mampaey;Jilles Vreeken
#t 2010
#c 22
#% 464873
#% 478770
#% 785362
#% 823356
#% 844294
#% 878207
#% 881479
#% 934581
#% 985041
#% 989606
#% 1001365
#% 1083656
#% 1116995
#% 1117081
#% 1214659
#% 1673615
#! For a book, the title and abstract provide a good first impression of what to expect from it. For a database, getting a first impression is not so straightforward. While low-order statistics only provide limited insight, mining the data quickly provides too much detail. In this paper we propose a middle ground, and introduce a parameter-free method for constructing high-quality summaries for binary data. Our method builds a summary by grouping items that strongly correlate, and uses the Minimum Description Length principle to identify the best grouping --without requiring a distance measure between items. Besides offering a practical overview of which attributes interact most strongly, these summaries are also easily-queried surrogates for the data. Experiments show that our method discovers high-quality results: correlated attributes are correctly grouped and the supports of frequent itemsets are closely approximated.

#index 1495604
#* Classification and novel class detection of data streams in a dynamic feature space
#@ Mohammad M. Masud;Qing Chen;Jing Gao;Latifur Khan;Jiawei Han;Bhavani Thuraisingham
#t 2010
#c 22
#% 342600
#% 729932
#% 769888
#% 823408
#% 840891
#% 915314
#% 1052684
#% 1176894
#% 1206700
#% 1267760
#! Data stream classification poses many challenges, most of which are not addressed by the state-of-the-art. We present DXMiner, which addresses four major challenges to data stream classification, namely, infinite length, concept-drift, concept-evolution, and feature-evolution. Data streams are assumed to be infinite in length, which necessitates single-pass incremental learning techniques. Concept-drift occurs in a data stream when the underlying concept changes over time. Most existing data stream classification techniques address only the infinite length and concept-drift problems. However, concept-evolution and feature- evolution are also major challenges, and these are ignored by most of the existing approaches. Concept-evolution occurs in the stream when novel classes arrive, and feature-evolution occurs when new features emerge in the stream. Our previous work addresses the concept-evolution problem in addition to addressing the infinite length and concept-drift problems. Most of the existing data stream classification techniques, including our previous work, assume that the feature space of the data points in the stream is static. This assumption may be impractical for some type of data, for example text data. DXMiner considers the dynamic nature of the feature space and provides an elegant solution for classification and novel class detection when the feature space is dynamic. We show that our approach outperforms state-of-the-art stream classification techniques in classifying and detecting novel classes in real data streams.

#index 1495605
#* Latent structure pattern mining
#@ Andreas Maunz;Christoph Helma;Tobias Cramer;Stefan Kramer
#t 2010
#c 22
#% 80995
#% 769951
#% 785396
#% 944956
#% 998549
#% 1063502
#% 1100111
#% 1214683
#% 1214727
#! Pattern mining methods for graph data have largely been restricted to ground features, such as frequent or correlated subgraphs. Kazius et al. have demonstrated the use of elaborate patterns in the biochemical domain, summarizing several ground features at once. Such patterns bear the potential to reveal latent information not present in any individual ground feature. However, those patterns were handcrafted by chemical experts. In this paper, we present a data-driven bottom-up method for pattern generation that takes advantage of the embedding relationships among individual ground features. The method works fully automatically and does not require data preprocessing (e.g., to introduce abstract node or edge labels). Controlling the process of generating ground features, it is possible to align them canonically and merge (stack) them, yielding a weighted edge graph. In a subsequent step, the subgraph features can further be reduced by singular value decomposition (SVD). Our experiments show that the resulting features enable substantial performance improvements on chemical datasets that have been problematic so far for graph mining approaches.

#index 1495606
#* First-order Bayes-ball
#@ Wannes Meert;Nima Taghipour;Hendrik Blockeel
#t 2010
#c 22
#% 1000502
#% 1165102
#% 1270256
#% 1270261
#% 1279353
#% 1289560
#% 1305597
#% 1417086
#% 1650620
#! Efficient probabilistic inference is key to the success of statistical relational learning. One issue that increases the cost of inference is the presence of irrelevant random variables. The Bayes-ball algorithm can identify the requisite variables in a propositional Bayesian network and thus ignore irrelevant variables. This paper presents a lifted version of Bayes-ball, which works directly on the first-order level, and shows how this algorithm applies to (lifted) inference in directed first-order probabilistic models.

#index 1495607
#* Learning from demonstration using MDP induced metrics
#@ Francisco S. Melo;Manuel Lopes
#t 2010
#c 22
#% 393059
#% 466418
#% 655325
#% 770852
#% 788055
#% 840894
#% 856877
#% 876036
#% 1042788
#% 1074001
#% 1187663
#% 1227205
#% 1255929
#% 1270316
#% 1272095
#% 1272256
#% 1275169
#% 1309356
#! In this paper we address the problem of learning a policy from demonstration. Assuming that the policy to be learned is the optimal policy for an underlying MDP, we propose a novel way of leveraging the underlying MDP structure in a kernel-based approach. Our proposed approach rests on the insight that the MDP structure can be encapsulated into an adequate state-space metric. In particular we show that, using MDP metrics, we are able to cast the problem of learning from demonstration as a classification problem and attain similar generalization performance as methods based on inverse reinforcement learning at a much lower online computational cost. Our method is also able to attain superior generalization than other supervised learning methods that fail to consider the MDP structure.

#index 1495608
#* Demand-driven tag recommendation
#@ Guilherme Vale Menezes;Jussara M. Almeida;Fabiano Belém;Marcos André Gonçalves;Anísio Lacerda;Edleno Silva De Moura;Gisele L. Pappa;Adriano Veloso;Nivio Ziviani
#t 2010
#c 22
#% 152934
#% 1055704
#% 1055739
#% 1074115
#% 1074116
#% 1074117
#% 1127458
#% 1127482
#% 1130816
#% 1130827
#% 1130829
#% 1131843
#% 1166510
#% 1190090
#% 1190091
#% 1190122
#% 1190133
#% 1227592
#% 1227601
#% 1227626
#% 1287227
#% 1292545
#% 1292558
#% 1292643
#! Collaborative tagging allows users to assign arbitrary keywords (or tags) describing the content of objects, which facilitates navigation and improves searching without dependence on pre-configured categories. In large-scale tag-based systems, tag recommendation services can assist a user in the assignment of tags to objects and help consolidate the vocabulary of tags across users. A promising approach for tag recommendation is to exploit the co-occurrence of tags. However, these methods are challenged by the huge size of the tag vocabulary, either because (1) the computational complexity may increase exponentially with the number of tags or (2) the score associated with each tag may become distorted since different tags may operate in different scales and the scores are not directly comparable. In this paper we propose a novel method that recommends tags on a demand-driven basis according to an initial set of tags applied to an object. It reduces the space of possible solutions, so that its complexity increases polynomially with the size of the tag vocabulary. Further, the score of each tag is calibrated using an entropy minimization approach which corrects possible distortions and provides more precise recommendations. We conducted a systematic evaluation of the proposed method using three types of media: audio, bookmarks and video. The experimental results show that the proposed method is fast and boosts recommendation quality on different experimental scenarios. For instance, in the case of a popular audio site it provides improvements in precision (p@5) ranging from 6.4% to 46.7% (depending on the number of tags given as input), outperforming a recently proposed co-occurrence based tag recommendation method.

#index 1495609
#* Solving structured sparsity regularization with proximal methods
#@ Sofia Mosci;Lorenzo Rosasco;Matteo Santoro;Alessandro Verri;Silvia Villa
#t 2010
#c 22
#% 770846
#% 803567
#% 829031
#% 875950
#% 916788
#% 948114
#% 1298976
#% 1302829
#% 1302843
#% 1302853
#% 1386006
#! Proximal methods have recently been shown to provide effective optimization procedures to solve the variational problems defining the l1 regularization algorithms. The goal of the paper is twofold. First we discuss how proximal methods can be applied to solve a large class of machine learning algorithms which can be seen as extensions of l1 regularization, namely structured sparsity regularization. For all these algorithms, it is possible to derive an optimization procedure which corresponds to an iterative projection algorithm. Second, we discuss the effect of a preconditioning of the optimization procedure achieved by adding a strictly convex functional to the objective function. Structured sparsity algorithms are usually based on minimizing a convex (not strictly convex) objective function and this might lead to undesired unstable behavior. We show that by perturbing the objective function by a small strictly convex term we often reduce substantially the number of required computations without affecting the prediction performance of the obtained solution.

#index 1495610
#* Exploiting causal independence in Markov logic networks: combining undirected and directed models
#@ Sriraam Natarajan;Tushar Khot;Daniel Lowd;Prasad Tadepalli;Kristian Kersting;Jude Shavlik
#t 2010
#c 22
#% 464304
#% 850428
#% 983850
#% 1000502
#% 1225216
#% 1271905
#% 1272302
#% 1416210
#% 1467732
#% 1650727
#% 1718455
#! A new method is proposed for compiling causal independencies into Markov logic networks (MLNs). An MLN can be viewed as compactly representing a factorization of a joint probability into the product of a set of factors guided by logical formulas. We present a notion of causal independence that enables one to further factorize the factors into a combination of even smaller factors and consequently obtain a finer-grain factorization of the joint probability. The causal independence lets us specify the factor in terms of weighted, directed clauses and operators, such as "or", "sum" or "max", on the contribution of the variables involved in the factors, hence combining both undirected and directed knowledge. Our experimental evaluations shows that making use of the finer-grain factorization provided by causal independence can improve quality of parameter learning in MLNs.

#index 1495611
#* Improved MinMax cut graph clustering with nonnegative relaxation
#@ Feiping Nie;Chris Ding;Dijun Luo;Heng Huang
#t 2010
#c 22
#% 313959
#% 336073
#% 466675
#% 915294
#% 983944
#% 1202938
#% 1269492
#% 1305478
#% 1481247
#! In graph clustering methods, MinMax Cut tends to provide more balanced clusters as compared to Ratio Cut and Normalized Cut. The traditional approach used spectral relaxation to solve the graph cut problem. The main disadvantage of this approach is that the obtained spectral solution has mixed signs, which could severely deviate from the true solution and have to resort to other clustering methods, such as K-means, to obtain final clusters. In this paper, we propose to apply additional nonnegative constraint into MinMax Cut graph clustering and introduce novel algorithms to optimize the new objective. With the explicit nonnegative constraint, our solutions are very close to the ideal class indicator matrix and can directly assign clusters to data points. We present efficient algorithms to solve the new problem with the non-negative constraint rigorously. Experimental results show that our new algorithm always converges and significantly outperforms the traditional spectral relaxation approach on ratio cut and normalized cut.

#index 1495612
#* Integrating constraint programming and itemset mining
#@ Siegfried Nijssen;Tias Guns
#t 2010
#c 22
#% 232136
#% 300120
#% 420067
#% 438134
#% 580588
#% 765529
#% 832571
#% 867881
#% 928731
#% 1083646
#% 1100159
#% 1125934
#% 1131306
#% 1214686
#! Over the years many pattern mining tasks and algorithms have been proposed. Traditionally, the focus of these studies was on the efficiency of the computation and the scalability towards very large databases. Little research has however been done on a general framework that encompasses several of these problems. In earlier work we showed how constraint programming (CP) can offer such a general framework; unfortunately, however, we also found that out-of-the-box CP solvers lack the efficiency and scalability achieved by specialized itemset mining systems, which could discourage their use. Here we study the question whether a framework can be built that inherits the generality of CP systems and the efficiency of specialized algorithms. We propose a CP-based framework for pattern mining that avoids the redundant representations and propagations found in existing CP systems. We show experimentally that an implementation of this framework performs comparable to specialized itemset mining systems; furthermore, under certain conditions it lists itemsets with polynomial delay, which demonstrates that it also is a promising approach for analyzing pattern mining tasks from more theoretical perspectives. This is illustrated on a graph mining problem.

#index 1495613
#* Topic modeling for personalized recommendation of volatile items
#@ Maks Ovsjanikov;Ye Chen
#t 2010
#c 22
#% 643056
#% 722904
#% 766422
#% 812535
#% 813966
#% 884117
#% 956521
#% 989580
#% 1083671
#% 1172630
#% 1214642
#% 1338620
#% 1355025
#% 1396090
#% 1650298
#! One of the major strengths of probabilistic topic modeling is the ability to reveal hidden relations via the analysis of co-occurrence patterns on dyadic observations, such as document-term pairs. However, in many practical settings, the extreme sparsity and volatility of co-occurrence patterns within the data, when the majority of terms appear in a single document, limits the applicability of topic models. In this paper, we propose an efficient topic modeling framework in the presence of volatile dyadic observations when direct topic modeling is infeasible. We show both theoretically and empirically that often-available unstructured and semantically-rich meta-data can serve as a link between dyadic sets, and can allow accurate and efficient inference. Our approach is general and can work with most latent variable models, which rely on stable dyadic data, such as pLSI, LDA, and GaP. Using transactional data from a major e-commerce site, we demonstrate the effectiveness as well as the applicability of our method in a personalized recommendation system for volatile items. Our experiments show that the proposed learning method outperforms the traditional LDA by capturing more persistent relations between dyadic sets of wide and practical significance.

#index 1495614
#* Conditional ranking on relational data
#@ Tapio Pahikkala;Willem Waegeman;Antti Airola;Tapio Salakoski;Bernard De Baets
#t 2010
#c 22
#% 117590
#% 393059
#% 577224
#% 734915
#% 833016
#% 833088
#% 840846
#% 875948
#% 881477
#% 1137422
#% 1166508
#% 1183446
#% 1268056
#% 1417104
#! In domains like bioinformatics, information retrieval and social network analysis, one can find learning tasks where the goal consists of inferring a ranking of objects, conditioned on a particular target object. We present a general kernel framework for learning conditional rankings from various types of relational data, where rankings can be conditioned on unseen data objects. Conditional ranking from symmetric or reciprocal relations can in this framework be treated as two important special cases. Furthermore, we propose an efficient algorithm for conditional ranking by optimizing a squared ranking loss function. Experiments on synthetic and real-world data illustrate that such an approach delivers state-of-the-art performance in terms of predictive power and computational complexity. Moreover, we also show empirically that incorporating domain knowledge in the model about the underlying relations can improve the generalization performance.

#index 1495615
#* Proceedings of the 2010 European conference on Machine learning and knowledge discovery in databases: Part III
#@ 
#t 2010
#c 22

#index 1496770
#* Proceedings of the 2010 European conference on Machine learning and knowledge discovery in databases: Part III
#@ José Luis Balcázar;Francesco Bonchi;Aristides Gionis;Michèle Sebag
#t 2010
#c 22

#index 1496771
#* Efficient planning in large POMDPs through policy graph based factorized approximations
#@ Joni Pajarinen;Jaakko Peltonen;Ari Hottinen;Mikko A. Uusitalo
#t 2010
#c 22
#% 528340
#% 823963
#% 842579
#% 983871
#% 1272075
#% 1289556
#% 1476294
#% 1650312
#% 1650568
#% 1650702
#% 1850965
#% 1851733
#! Partially observable Markov decision processes (POMDPs) are widely used for planning under uncertainty. In many applications, the huge size of the POMDP state space makes straightforward optimization of plans (policies) computationally intractable. To solve this, we introduce an efficient POMDP planning algorithm. Many current methods store the policy partly through a set of "value vectors" which is updated at each iteration by planning one step further; the size of such vectors follows the size of the state space, making computation intractable for large POMDPs. We store the policy as a graph only, which allows tractable approximations in each policy update step: for a state space described by several variables, we approximate beliefs over future states with factorized forms, minimizing Kullback-Leibler divergence to the nonfactorized distributions. Our other speedup approximations include bounding potential rewards. We demonstrate the advantage of our method in several reinforcement learning problems, compared to four previous methods.

#index 1496772
#* Unsupervised trajectory sampling
#@ Nikos Pelekis;Ioannis Kopanakis;Costas Panagiotakis;Yannis Theodoridis
#t 2010
#c 22
#% 280416
#% 300132
#% 527166
#% 721137
#% 769946
#% 873885
#% 881459
#% 907184
#% 960283
#% 976715
#% 976716
#% 989604
#% 1038326
#% 1046207
#% 1136692
#% 1206639
#% 1230847
#% 1267730
#% 1318678
#% 1720762
#! A novel methodology for efficiently sampling Trajectory Databases (TD) for mobility data mining purposes is presented. In particular, a three-step unsupervised trajectory sampling methodology is proposed, that initially adopts a symbolic vector representation of a trajectory which, using a similarity-based voting technique, is transformed to a continuous function that describes the representativeness of the trajectory in the TD. This vector representation is then relaxed by a merging algorithm, which identifies the maximal representative portions of each trajectory, at the same time preserving the space-time mobility pattern of the trajectory. Finally, a novel sampling algorithm operating on the previous representation is proposed, allowing us to select a subset of a TD in an unsupervised way encapsulating the behavior (in terms of mobility patterns) of the original TD. An experimental evaluation over synthetic and real TD demonstrates the efficiency and effectiveness of our approach.

#index 1496773
#* Fast extraction of locally optimal patterns based on consistent pattern function variations
#@ Frédéric Pennerath
#t 2010
#c 22
#% 152934
#% 279120
#% 280409
#% 431033
#% 729418
#% 800181
#% 1168770
#% 1267768
#% 1663669
#! This article introduces the problem of searching locally optimal patterns within a set of patterns constrained by some anti-monotonic predicate: given some pattern scoring function, a locally optimal pattern has a maximal (or minimal) score locally among neighboring patterns. Some instances of this problem have produced patterns of interest in the framework of knowledge discovery since locally optimal patterns extracted from datasets are very few, informative and nonredundant compared to other pattern families derived from frequent patterns. This article then introduces the concept of variation consistency to characterize pattern functions and uses this notion to propose GALLOP, an algorithm that outperforms existing algorithms to extract locally optimal itemsets. Finally it shows how GALLOP can generically be applied to two classes of scoring functions useful in binary classification or clustering pattern mining problems.

#index 1496774
#* Large margin learning of Bayesian classifiers based on Gaussian mixture models
#@ Franz Pernkopf;Michael Wohlmayr
#t 2010
#c 22
#% 333852
#% 393059
#% 722816
#% 810949
#% 814035
#% 875970
#% 891559
#% 898772
#% 1073920
#% 1138217
#! We present a discriminative learning framework for Gaussian mixture models (GMMs) used for classification based on the extended Baum-Welch (EBW) algorithm [1]. We suggest two criteria for discriminative optimization, namely the class conditional likelihood (CL) and the maximization of the margin (MM). In the experiments, we present results for synthetic data, broad phonetic classification, and a remote sensing application. The experiments show that CL-optimized GMMs (CL-GMMs) achieve a lower performance compared to MM-optimized GMMs (MM-GMMs), whereas both discriminative GMMs (DGMMs) perform significantly better than generatively learned GMMs. We also show that the generative discriminatively parameterized GMM classifiers still allow to marginalize over missing features, a case where generative classifiers have an advantage over purely discriminative classifiers such as support vector machines or neural networks.

#index 1496775
#* Learning with ensembles of randomized trees: new insights
#@ Vincent Pisetta;Pierre-Emmanuel Jouve;Djamel A. Zighed
#t 2010
#c 22
#% 129979
#% 132938
#% 190581
#% 209021
#% 310868
#% 312727
#% 331916
#% 400847
#% 412479
#% 425033
#% 451221
#% 771845
#% 866298
#% 1074347
#% 1117696
#% 1272222
#! Ensembles of randomized trees such as Random Forests are among the most popular tools used in machine learning and data mining. Such algorithms work by introducing randomness in the induction of several decision trees before employing a voting scheme to give a prediction for unseen instances. In this paper, randomized trees ensembles are studied in the point of view of the basis functions they induce. We point out a connection with kernel target alignment, a measure of kernel quality, which suggests that randomization is a way to obtain a high alignment, leading to possibly low generalization error. The connection also suggests to post-process ensembles with sophisticated linear separators such as Support Vector Machines (SVM). Interestingly, post-processing gives experimentally better performances than a classical majority voting. We finish by comparing those results to an approximate infinite ensemble classifier very similar to the one introduced by Lin and Li. This methodology also shows strong learning abilities, comparable to ensemble post-processing.

#index 1496776
#* Entropy and margin maximization for structured output learning
#@ Patrick Pletscher;Cheng Soon Ong;Joachim M. Buhmann
#t 2010
#c 22
#% 420507
#% 464434
#% 722816
#% 770763
#% 840922
#% 961272
#% 1000452
#% 1013670
#% 1117688
#% 1166535
#% 1211836
#% 1377736
#% 1470674
#! We consider the problem of training discriminative structured output predictors, such as conditional random fields (CRFs) and structured support vector machines (SSVMs). A generalized loss function is introduced, which jointly maximizes the entropy and the margin of the solution. The CRF and SSVM emerge as special cases of our framework. The probabilistic interpretation of large margin methods reveals insights about margin and slack rescaling. Furthermore, we derive the corresponding extensions for latent variable models, in which training operates on partially observed outputs. Experimental results for multiclass, linear-chain models and multiple instance learning demonstrate that the generalized loss can improve accuracy of the resulting classifiers.

#index 1496777
#* Virus propagation on time-varying networks: theory and immunization algorithms
#@ B. Aditya Prakash;Hanghang Tong;Nicholas Valler;Michalis Faloutsos;Christos Faloutsos
#t 2010
#c 22
#% 281214
#% 283833
#% 315967
#% 324817
#% 342596
#% 433981
#% 577217
#% 577360
#% 664489
#% 725348
#% 729923
#% 754107
#% 823342
#% 991977
#% 1092783
#! Given a contact network that changes over time (say, day vs night connectivity), and the SIS (susceptible/infected/susceptible, flu like) virus propagation model, what can we say about its epidemic threshold? That is, can we determine when a small infection will "take-off" and create an epidemic? Consequently then, which nodes should we immunize to prevent an epidemic? This is a very real problem, since, e.g. people have different connections during the day at work, and during the night at home. Static graphs have been studied for a long time, with numerous analytical results. Time-evolving networks are so hard to analyze, that most existing works are simulation studies [5]. Specifically, our contributions in this paper are: (a) we formulate the problem by approximating it by a Non-linear Dynamical system (NLDS), (b) we derive the first closed formula for the epidemic threshold of time-varying graphs under the SIS model, and finally (c) we show the usefulness of our threshold by presenting efficient heuristics and evaluate the effectiveness of our methods on synthetic and real data like the MIT reality mining graphs.

#index 1496778
#* Adapting decision DAGs for multipartite ranking
#@ José Ramón Quevedo;Elena Montañés;Oscar Luaces;Juan José Del Coz
#t 2010
#c 22
#% 223891
#% 349550
#% 458623
#% 566791
#% 722807
#% 771846
#% 840853
#% 840882
#% 889273
#% 959434
#% 961134
#% 1014653
#% 1015908
#% 1074360
#% 1093383
#% 1174584
#% 1268056
#% 1320409
#% 1664437
#% 1665172
#% 1707815
#! Multipartite ranking is a special kind of ranking for problems in which classes exhibit an order. Many applications require its use, for instance, granting loans in a bank, reviewing papers in a conference or just grading exercises in an education environment. Several methods have been proposed for this purpose. The simplest ones resort to regression schemes with a pre- and post-process of the classes, what makes them barely useful. Other alternatives make use of class order information or they perform a pairwise classification together with an aggregation function. In this paper we present and discuss two methods based on building a Decision Directed Acyclic Graph (DDAG). Their performance is evaluated over a set of ordinal benchmark data sets according to the C-Index measure. Both yield competitive results with regard to state-of-the-art methods, specially the one based on a probabilistic approach, called PR-DDAG.

#index 1496779
#* Fast and scalable algorithms for semi-supervised link prediction on static and dynamic graphs
#@ Rudy Raymond;Hisashi Kashima
#t 2010
#c 22
#% 730089
#% 770816
#% 806956
#% 809424
#% 828046
#% 833069
#% 833088
#% 833805
#% 853532
#% 853534
#% 891559
#% 1055685
#% 1083700
#% 1137069
#% 1195985
#% 1396216
#! Recent years have witnessed a widespread interest on methods using both link structure and node information for link prediction on graphs. One of the state-of-the-art methods is Link Propagation which is a new semi-supervised learning algorithm for link prediction on graphs based on the popularly-studied label propagation by exploiting information on similarities of links and nodes. Despite its efficiency and effectiveness compared to other methods, its applications were still limited due to the computational time and space constraints. In this paper, we propose fast and scalable algorithms for the Link Propagation by introducing efficient procedures to solve large linear equations that appear in the method. In particular, we show how to obtain a compact representation of the solution to the linear equations by using a non-trivial combination of techniques in linear algebra to construct algorithms that are also effective for link prediction on dynamic graphs. These enable us to apply the Link Propagation to large networks with more than 400,000 nodes. Experiments demonstrate that our approximation methods are scalable, fast, and their prediction qualities are comparably competitive.

#index 1496780
#* Modeling relations and their mentions without labeled text
#@ Sebastian Riedel;Limin Yao;Andrew McCallum
#t 2010
#c 22
#% 74846
#% 191986
#% 224755
#% 464434
#% 471758
#% 722926
#% 799686
#% 838435
#% 854636
#% 939375
#% 939376
#% 1019061
#% 1063570
#% 1267781
#% 1270341
#% 1270682
#% 1305487
#% 1330550
#% 1338541
#% 1470673
#! Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision. Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation. Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with. We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB. We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base. When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.

#index 1496781
#* An efficient and scalable algorithm for local Bayesian network structure discovery
#@ Sérgio Rodrigues De Morais;Alex Aussem
#t 2010
#c 22
#% 44876
#% 297171
#% 345862
#% 722804
#% 893460
#% 919561
#% 977231
#% 1099365
#% 1108899
#% 1270262
#% 1373045
#% 1411079
#% 1415214
#% 1650289
#! We present an efficient and scalable constraint-based algorithm, called Hybrid Parents and Children (HPC), to learn the parents and children of a target variable in a Bayesian network. Finding those variables is an important first step in many applications including Bayesian network structure learning, dimensionality reduction and feature selection. The algorithm combines ideas from incremental and divide-and-conquer methods in a principled and effective way, while still being sound in the sample limit. Extensive empirical experiments are provided on public synthetic and real-world data sets of various sample sizes. The most noteworthy feature of HPC is its ability to handle large neighborhoods contrary to current CB algorithm proposals. The number of calls to the statistical test, en hence the run-time, is empirically on the order O(n1.09), where n is the number of variables, on the five benchmarks that we considered, and O(n1.21) on a real drug design characterized by 138,351 features.

#index 1496782
#* Selecting information diffusion models over social networks for behavioral analysis
#@ Kazumi Saito;Masahiro Kimura;Kouzou Ohara;Hiroshi Motoda
#t 2010
#c 22
#% 729923
#% 794513
#% 832271
#% 868469
#% 1179993
#% 1222654
#% 1269888
#% 1333069
#% 1355040
#! We investigate how well different information diffusion models can explain observation data by learning their parameters and discuss which model is better suited to which topic. We use two models (AsIC, AsLT), each of which is an extension of the well known Independent Cascade (IC) and Linear Threshold (LT) models and incorporates asynchronous time delay. The model parameters are learned by maximizing the likelihood of observation, and the model selection is performed by choosing the one with better predictive accuracy. We first show by using four real networks that the proposed learning algorithm correctly learns the model parameters both accurately and stably, and the proposed selection method identifies the correct diffusion model from which the data are generated. We next apply these methods to behavioral analysis of topic propagation using the real blog propagation data, and show that although the relative propagation speed of topics that are derived from the learned parameter values is rather insensitive to the model selected, there is a clear indication as to which topic better follows which model. The correspondence between the topic and the model selected is well interpretable.

#index 1496783
#* Learning sparse Gaussian Markov networks using a greedy coordinate ascent approach
#@ Katya Scheinberg;Irina Rish
#t 2010
#c 22
#% 768668
#% 1074353
#% 1211778
#% 1299304
#! In this paper, we introduce a simple but efficient greedy algorithm, called SINCO, for the Sparse INverse COvariance selection problem, which is equivalent to learning a sparse Gaussian Markov Network, and empirically investigate the structure-recovery properties of the algorithm. Our approach is based on a coordinate ascent method which naturally preserves the sparsity of the network structure. We show that SINCO is often comparable to, and, in various cases, outperforms commonly used approaches such as glasso [7] and COVSEL [1], in terms of both structure-reconstruction error (particularly, false positive error) and computational time. Moreover, our method has the advantage of being easily parallelizable. Finally, we show that SINCO's greedy nature allows reproduction of the regularization path behavior by applying the method to one (sufficiently small) instance of the regularization parameter λ only; thus, SINCO can obtain a desired number of network links directly, without having to tune the λ parameter. We evaluate our method empirically on various simulated networks and real-life data from biological and neuroimaging applications.

#index 1496784
#* Online structural graph clustering using frequent subgraph mining
#@ Madeleine Seeland;Tobias Girschick;Fabian Buchwald;Stefan Kramer
#t 2010
#c 22
#% 234978
#% 478274
#% 479554
#% 570442
#% 629708
#% 745515
#% 876064
#% 989575
#% 1685011
#! The goal of graph clustering is to partition objects in a graph database into different clusters based on various criteria such as vertex connectivity, neighborhood similarity or the size of the maximum common subgraph. This can serve to structure the graph space and to improve the understanding of the data. In this paper, we present a novel method for structural graph clustering, i.e. graph clustering without generating features or decomposing graphs into parts. In contrast to many related approaches, the method does not rely on computationally expensive maximum common subgraph (MCS) operations or variants thereof, but on frequent subgraph mining. More specifically, our problem formulation takes advantage of the frequent subgraph miner gSpan (that performs well on many practical problems) without effectively generating thousands of subgraphs in the process. In the proposed clustering approach, clusters encompass all graphs that share a sufficiently large common subgraph. The size of the common subgraph of a graph in a cluster has to take at least a user-specified fraction of its overall size. The new algorithm works in an online mode (processing one structure after the other) and produces overlapping (non-disjoint) and nonexhaustive clusters. In a series of experiments, we evaluated the effectiveness and efficiency of the structural clustering algorithm on various real world data sets of molecular graphs.

#index 1496785
#* Large-scale support vector learning with structural kernels
#@ Aliaksei Severyn;Alessandro Moschitti
#t 2010
#c 22
#% 269217
#% 577218
#% 722815
#% 740916
#% 742218
#% 815896
#% 817422
#% 823311
#% 830744
#% 855091
#% 858036
#% 881477
#% 905498
#% 940027
#% 961188
#% 983885
#% 983905
#% 1073912
#% 1083712
#% 1084592
#% 1130832
#% 1249528
#% 1264050
#% 1344869
#% 1386114
#! In this paper, we present an extensive study of the cutting-plane algorithm (CPA) applied to structural kernels for advanced text classification on large datasets. In particular, we carry out a comprehensive experimentation on two interesting natural language tasks, e.g. predicate argument extraction and question answering. Our results show that (i) CPA applied to train a non-linear model with different tree kernels fully matches the accuracy of the conventional SVM algorithm while being ten times faster; (ii) by using smaller sampling sizes to approximate subgradients in CPA we can trade off accuracy for speed, yet the optimal parameters and kernels found remain optimal for the exact SVM. These results open numerous research perspectives, e.g. in natural language processing, as they show that complex structural kernels can be efficiently used in real-world applications. For example, for the first time, we could carry out extensive tests of several tree kernels on millions of training instances. As a direct benefit, we could experiment with a variant of the partial tree kernel, which we also propose in this paper.

#index 1496786
#* Synchronization based outlier detection
#@ Junming Shao;Christian Böhm;Qinli Yang;Claudia Plant
#t 2010
#c 22
#% 34077
#% 300136
#% 300183
#% 310552
#% 342641
#% 479791
#% 479986
#% 501988
#% 1214636
#% 1451198
#! The study of extraordinary observations is of great interest in a large variety of applications, such as criminal activities detection, athlete performance analysis, and rare events or exceptions identification. The question is: how can we naturally flag these outliers in a real complex data set? In this paper, we study outlier detection based on a novel powerful concept: synchronization. The basic idea is to regard each data object as a phase oscillator and simulate its dynamical behavior over time according to an extensive Kuramoto model. During the process towards synchronization, regular objects and outliers exhibit different interaction patterns. Outlier objects are naturally detected by local synchronization factor (LSF). An extensive experimental evaluation on synthetic and real world data demonstrates the benefits of our method.

#index 1496787
#* Laplacian spectrum learning
#@ Pannagadatta K. Shivaswamy;Tony Jebara
#t 2010
#c 22
#% 266426
#% 464615
#% 757953
#% 770846
#% 1386123
#! The eigenspectrum of a graph Laplacian encodes smoothness information over the graph. A natural approach to learning involves transforming the spectrum of a graph Laplacian to obtain a kernel. While manual exploration of the spectrum is conceivable, non-parametric learning methods that adjust the Laplacian's spectrum promise better performance. For instance, adjusting the graph Laplacian using kernel target alignment (KTA) yields better performance when an SVM is trained on the resulting kernel. KTA relies on a simple surrogate criterion to choose the kernel; the obtained kernel is then fed to a large margin classification algorithm. In this paper, we propose novel formulations that jointly optimize relative margin and the spectrum of a kernel defined via Laplacian eigenmaps. The large relative margin case is in fact a strict generalization of the large margin case. The proposed methods show significant empirical advantage over numerous other competing methods.

#index 1496788
#* k-version-space multi-class classification based on k-consistency tests
#@ Evgueni Smirnov;Georgi Nalbantov;Nikolay Nikolaev
#t 2010
#c 22
#% 302855
#% 376266
#% 529925
#% 688946
#% 741331
#% 771604
#% 1074350
#% 1210539
#% 1210649
#% 1223389
#% 1399027
#! k-Version spaces were introduced in [6] to handle noisy data. They were defined as sets of k-consistent hypotheses; i.e., hypotheses consistent with all but k instances. Although k-version spaces were applied, their implementation was intractable due to the boundary-set representation. This paper argues that to classify with k-version spaces we do not need an explicit representation. Instead we need to solve a general k-consistency problem and a general k0-consistency problem. The general k-consistency problem is to test the hypothesis space for classifier that is k-consistent with the data. The general k0-consistency problem is to test the hypothesis space for classifier that is k-consistent with the data and 0-consistent with a labeled test instance. Hence, our main result is that the k-version-space classification can be (tractably) implemented if we have (tractable) k-consistency-test algorithms and (tractable) k0-consistency-test algorithms. We show how to design these algorithms for any learning algorithm in multi-class classification setting.

#index 1496789
#* Complexity bounds for batch active learning in classification
#@ Philippe Rolet;Olivier Teytaud
#t 2010
#c 22
#% 116165
#% 156184
#% 170649
#% 190581
#% 236729
#% 310503
#% 359194
#% 450951
#% 451056
#% 464268
#% 466419
#% 735357
#% 875997
#% 1129587
#% 1174739
#% 1272282
#% 1396658
#% 1705517
#! Active learning [1] is a branch of Machine Learning in which the learning algorithm, instead of being directly provided with pairs of problem instances and their solutions (their labels), is allowed to choose, from a set of unlabeled data, which instances to query. It is suited to settings where labeling instances is costly. This paper analyzes the speed-up of batch (parallel) active learning compared to sequential active learning (where instances are chosen 1 by 1): how faster can an algorithm become if it can query λ instances at once?. There are two main contributions: proving lower and upper bounds on the possible gain, and illustrating them by experimenting on usual active learning algorithms. Roughly speaking, the speed-up is asymptotically logarithmic in the batch size λ (i.e. when λ → ∞). However, for some classes of functions with finite VC-dimension V, a linear speed-up can be achieved until a batch size of V. Practically speaking, this means that parallelizing computations on an expensive-to-label problem which is suited to active learning is very beneficial until V simultaneous queries, and less interesting (yet still bringing improvement) afterwards.

#index 1496790
#* Semi-supervised projection clustering with transferred centroid regularization
#@ Bin Tong;Hao Shao;Bin-Hui Chou;Einoshin Suzuki
#t 2010
#c 22
#% 92146
#% 309128
#% 466890
#% 757953
#% 765518
#% 829025
#% 840892
#% 961218
#% 989642
#% 1073897
#% 1083678
#% 1209696
#% 1214639
#% 1261539
#% 1270196
#% 1305479
#% 1318599
#% 1318623
#% 1327693
#% 1464068
#! We propose a novel method, called Semi-supervised Projection Clustering in Transfer Learning (SPCTL), where multiple source domains and one target domain are assumed. Traditional semi-supervised projection clustering methods hold the assumption that the data and pairwise constraints are all drawn from the same domain. However, many related data sets with different distributions are available in real applications. The traditional methods thus can not be directly extended to such a scenario. One major challenging issue is how to exploit constraint knowledge from multiple source domains and transfer it to the target domain where all the data are unlabeled. To handle this difficulty, we are motivated to construct a common subspace where the difference in distributions among domains can be reduced. We also invent a transferred centroid regularization, which acts as a bridge to transfer the constraint knowledge to the target domain, to formulate this geometric structure formed by the centroids from different domains. Extensive experiments on both synthetic and practical data sets show the effectiveness of our method.

#index 1496791
#* Permutation testing improves Bayesian network learning
#@ Ioannis Tsamardinos;Giorgos Borboudakis
#t 2010
#c 22
#% 150990
#% 466068
#% 729982
#% 893460
#% 917962
#% 1041545
#% 1211820
#% 1270262
#% 1386105
#! We are taking a peek "under the hood" of constraint-based learning of graphical models such as Bayesian Networks. This mainstream approach to learning is founded on performing statistical tests of conditional independence. In all prior work however, the tests employed for categorical data are only asymptotically-correct, i.e., they converge to the exact p-value in the sample limit. In this paper we present, evaluate, and compare exact tests, based on standard, adjustable, and semi-parametric Monte-Carlo permutation testing procedures appropriate for small sample sizes. It is demonstrated that (a) permutation testing is calibrated, i.e, the actual Type I error matches the significance level α set by the user; this is not the case with asymptotic tests, (b) permutation testing leads to more robust structural learning, and (c) permutation testing allows learning networks from multiple datasets sharing a common underlying structure but different distribution functions (e.g. continuous vs. discrete); we name this problem the Bayesian Network Meta-Analysis problem. In contrast, asymptotic tests may lead to erratic learning behavior in this task (error increasing with total sample-size). The semi-parametric permutation procedure we propose is a reasonable approximation of the basic procedure using 5000 permutations, while being only 10-20 times slower than the asymptotic tests for small sample sizes. Thus, this test should be practical in most graphical learning problems and could substitute asymptotic tests. The conclusions of our studies have ramifications for learning not only Bayesian Networks but other graphical models too and for related causal-based variable selection algorithms, such as HITON. The code is available at mensxmachina.org.

#index 1496792
#* Example-dependent basis vector selection for kernel-based classifiers
#@ Antti Ukkonen;Marta Arias
#t 2010
#c 22
#% 190581
#% 269222
#% 302390
#% 400847
#% 722760
#% 722817
#% 722918
#% 755460
#% 815896
#% 916781
#% 961154
#% 961252
#% 1042610
#% 1073962
#% 1264050
#% 1385999
#% 1730146
#% 1759695
#% 1781403
#! We study methods for speeding up classification time of kernel-based classifiers. Existing solutions are based on explicitly seeking sparse classifiers during training, or by using budgeted versions of the classifier where one directly limits the number of basis vectors allowed. Here, we propose a more flexible alternative: instead of using the same basis vectors over the whole feature space, our solution uses different basis vectors in different parts of the feature space. At the core of our solution lies an optimization procedure that, given a set of basis vectors, finds a good partition of the feature space and good subsets of the existing basis vectors. Using this procedure repeatedly, we build trees whose internal nodes specify feature space partitions and whose leaves implement simple kernel classifiers. Experiments suggest that our method reduces classification time significantly while maintaining performance. In addition, we propose several heuristics that also perform well.

#index 1496793
#* Surprising patterns for the call duration distribution of mobile phone users
#@ Pedro O. S. Vaz De Melo;Leman Akoglu;Christos Faloutsos;Antonio A. F. Loureiro
#t 2010
#c 22
#% 461484
#% 549441
#% 907530
#% 1083690
#% 1214648
#% 1233318
#% 1300556
#! How long are the phone calls of mobile users? What are the chances of a call to end, given its current duration? Here we answer these questions by studying the call duration distributions (CDDs) of individual users in large mobile networks. We analyzed a large, real network of 3.1 million users and more than one billion phone call records from a private mobile phone company of a large city, spanning 0.1TB. Our first contribution is the TLAC distribution to fit the CDD of each user; TLAC is the truncated version of so-called log-logistic distribution, a skewed, power-law-like distribution. We show that the TLAC is an excellent fit for the overwhelming majority of our users (more than 96% of them), much better than exponential or lognormal. Our second contribution is the MetaDist to model the collective behavior of the users given their CDDs. We show that the MetaDist distribution accurately and succinctly describes the calls duration behavior of users in large mobile networks. All of our methods are fast, and scale linearly with the number of customers.

#index 1496794
#* Variational Bayesian mixture of robust CCA models
#@ Jaakko Viinikanoja;Arto Klami;Samuel Kaski
#t 2010
#c 22
#% 360691
#% 855563
#% 875949
#% 942062
#% 983857
#% 1026330
#% 1194401
#% 1758790
#% 1861949
#! We study the problem of extracting statistical dependencies between multivariate signals, to be used for exploratory analysis of complicated natural phenomena. In particular, we develop generative models for extracting the dependencies, made possible by the probabilistic interpretation of canonical correlation analysis (CCA). We introduce a mixture of robust canonical correlation analyzers, using t-distribution to make the model robust to outliers and variational Bayesian inference for learning from noisy data. We demonstrate the improvements of the new model on artificial data, and further apply it for analyzing dependencies between MEG and measurements of autonomic nervous system to illustrate potential use scenarios.

#index 1496795
#* Adverse drug reaction mining in pharmacovigilance data using formal concept analysis
#@ Jean Villerd;Yannick Toussaint;Agnès Lillo-Le Louët
#t 2010
#c 22
#% 299985
#% 384416
#% 420126
#% 809268
#% 823417
#% 992699
#% 1174585
#% 1268044
#% 1368909
#% 1778785
#! In this paper we discuss the problem of extracting and evaluating associations between drugs and adverse effects in pharma-covigilance data. Approaches proposed by the medical informatics community for mining one drug - one effect pairs perform an exhaustive search strategy that precludes from mining high-order associations. Some specificities of pharmacovigilance data prevent from applying pattern mining approaches proposed by the data mining community for similar problems dealing with epidemiological studies. We argue that Formal Concept Analysis (FCA) and concept lattices constitute a suitable framework for both identifying relevant associations, and assisting experts in their evaluation task. Demographic attributes are handled so that the disproportionality of an association is computed w.r.t. the relevant population stratum to prevent confounding. We put the focus on the understandability of the results and provide evaluation facilities for experts. A real case study on a subset of the French spontaneous reporting system shows that the method identifies known adverse drug reactions and some unknown associations that has to be further investigated.

#index 1496796
#* Topic models conditioned on relations
#@ Mirwaes Wahabzada;Zhao Xu;Kristian Kersting
#t 2010
#c 22
#% 280819
#% 722904
#% 788043
#% 788094
#% 812535
#% 875959
#% 891549
#% 983833
#% 989621
#% 1055681
#% 1083696
#% 1117695
#% 1250567
#% 1289476
#% 1305499
#% 1318675
#! Latent Dirichlet allocation is a fully generative statistical language model that has been proven to be successful in capturing both the content and the topics of a corpus of documents. Recently, it was even shown that relations among documents such as hyper-links or citations allow one to share information between documents and in turn to improve topic generation. Although fully generative, in many situations we are actually not interested in predicting relations among documents. In this paper, we therefore present a Dirichlet-multinomial nonparametric regression topic model that includes a Gaussian process prior on joint document and topic distributions that is a function of document relations. On networks of scientific abstracts and of Wikipedia documents we show that this approach meets or exceeds the performance of several baseline topic models.

#index 1496797
#* Shift-invariant grouped multi-task learning for Gaussian processes
#@ Yuyang Wang;Roni Khardon;Pavlos Protopapas
#t 2010
#c 22
#% 280416
#% 729917
#% 829014
#% 840962
#% 891549
#% 961166
#% 961246
#% 1073879
#% 1073950
#% 1108842
#% 1127609
#% 1173744
#% 1267786
#% 1327706
#% 1450140
#! Multi-task learning leverages shared information among data sets to improve the learning performance of individual tasks. The paper applies this framework for data where each task is a phase-shifted periodic time series. In particular, we develop a novel Bayesian nonparametric model capturing a mixture of Gaussian processes where each task is a sum of a group-specific function and a component capturing individual variation, in addition to each task being phase shifted. We develop an efficient em algorithm to learn the parameters of the model. As a special case we obtain the Gaussian mixture model and EM algorithm for phased-shifted periodic time series. Experiments in regression, classification and class discovery demonstrate the performance of the proposed model using both synthetic data and real-world time series data from astrophysics. Our methods are particularly useful when the time series are sparsely and non-synchronously sampled.

#index 1496798
#* Nonparametric Bayesian clustering ensembles
#@ Pu Wang;Carlotta Domeniconi;Kathryn Blackmond Laskey
#t 2010
#c 22
#% 274612
#% 633220
#% 722902
#% 722904
#% 727903
#% 762808
#% 766828
#% 823331
#% 837616
#% 902497
#% 1147715
#% 1275202
#% 1393017
#! Forming consensus clusters from multiple input clusterings can improve accuracy and robustness. Current clustering ensemble methods require specifying the number of consensus clusters. A poor choice can lead to under or over fitting. This paper proposes a nonparametric Bayesian clustering ensemble (NBCE) method, which can discover the number of clusters in the consensus clustering. Three inference methods are considered: collapsed Gibbs sampling, variational Bayesian inference, and collapsed variational Bayesian inference. Comparison of NBCE with several other algorithms demonstrates its versatility and superior stability.

#index 1496799
#* Directed graph learning via high-order co-linkage analysis
#@ Hua Wang;Chris Ding;Heng Huang
#t 2010
#c 22
#% 249143
#% 268079
#% 397169
#% 464267
#% 577287
#% 763708
#% 818234
#% 840965
#% 905168
#% 987253
#% 989597
#% 1125906
#% 1130818
#% 1187181
#% 1269492
#% 1528859
#% 1665158
#! Many real world applications can be naturally formulated as a directed graph learning problem. How to extract the directed link structures of a graph and use labeled vertices are the key issues to infer labels of the remaining unlabeled vertices. However, directed graph learning is not well studied in data mining and machine learning areas. In this paper, we propose a novel Co-linkage Analysis (CA) method to process directed graphs in an undirected way with the directional information preserved. On the induced undirected graph, we use a Green's function approach to solve the semi-supervised learning problem. We present a new zero-mode free Laplacian which is invertible. This leads to an Improved Green's Function (IGF) method to solve the classification problem, which is also extended to deal with multi-label classification problems. Promising results in extensive experimental evaluations on real data sets have demonstrated the effectiveness of our approach.

#index 1496800
#* Incorporating domain models into Bayesian optimization for RL
#@ Aaron Wilson;Alan Fern;Prasad Tadepalli
#t 2010
#c 22
#% 156278
#% 384911
#% 466731
#% 734920
#% 840860
#% 891549
#% 1272386
#% 1274905
#% 1275935
#% 1650283
#! In many Reinforcement Learning (RL) domains there is a high cost for generating experience in order to evaluate an agent's performance. An appealing approach to reducing the number of expensive evaluations is Bayesian Optimization (BO), which is a framework for global optimization of noisy and costly to evaluate functions. Prior work in a number of RL domains has demonstrated the effectiveness of BO for optimizing parametric policies. However, those approaches completely ignore the state-transition sequence of policy executions and only consider the total reward achieved. In this paper, we study how to more effectively incorporate all of the information observed during policy executions into the BO framework. In particular, our approach uses the observed data to learn approximate transitions models that allow for Monte-Carlo predictions of policy returns. The models are then incorporated into the BO framework as a type of prior on policy returns, which can better inform the BO process. The resulting algorithm provides a new approach for leveraging learned models in RL even when there is no planner available for exploiting those models. We demonstrate the effectiveness of our algorithm in four benchmark domains, which have dynamics of variable complexity. Results indicate that our algorithm effectively combines model based predictions to improve the data efficiency of model free BO methods, and is robust to modeling errors when parts of the domain cannot be modeled successfully.

#index 1496801
#* Efficient and numerically stable sparse learning
#@ Sihong Xie;Wei Fan;Olivier Verscheure;Jiangtao Ren
#t 2010
#c 22
#% 276493
#% 302390
#% 961223
#% 1211727
#% 1211732
#% 1211806
#% 1232034
#! We consider the problem of numerical stability and model density growth when training a sparse linear model from massive data. We focus on scalable algorithms that optimize certain loss function using gradient descent, with either l0 or l1 regularization. We observed numerical stability problems in several existing methods, leading to divergence and low accuracy. In addition, these methods typically have weak controls over sparsity, such that model density grows faster than necessary. We propose a framework to address the above problems. First, the update rule is numerically stable with convergence guarantee and results in more reasonable models. Second, besides l1 regularization, it exploits the sparsity of data distribution and achieves a higher degree of sparsity with a PAC generalization error bound. Lastly, it is parallelizable and suitable for training large margin classifiers on huge datasets. Experiments show that the proposed method converges consistently and outperforms other baselines using 10% of features by as much as 6% reduction in error rate on average. Datasets and software are available from the authors.

#index 1496802
#* Fast active exploration for link-based preference learning using Gaussian processes
#@ Zhao Xu;Kristian Kersting;Thorsten Joachims
#t 2010
#c 22
#% 715096
#% 734915
#% 735358
#% 770753
#% 823360
#% 840846
#% 840852
#% 891549
#% 946521
#% 989628
#% 1000502
#% 1016175
#% 1055712
#% 1074083
#% 1077150
#% 1093383
#% 1195836
#% 1211840
#% 1268076
#% 1456843
#! In preference learning, the algorithm observes pairwise relative judgments (preference) between items as training data for learning an ordering of all items. This is an important learning problem for applications where absolute feedback is difficult to elicit, but pairwise judgments are readily available (e.g., via implicit feedback [13]). While it was already shown that active learning can effectively reduce the number of training pairs needed, the most successful existing algorithms cannot generalize over items or queries. Considering web search as an example, they would need to learn a separate relevance score for each document-query pair from scratch. To overcome this inefficiency, we propose a link-based active preference learning method based on Gaussian Processes (GPs) that incorporates dependency information from both feature-vector representations as well as relations. Specifically, to meet the requirement on computational efficiency of active exploration, we introduce a novel incremental update method that scales as well as the nongeneralizing models. The proposed algorithm is evaluated on datasets for information retrieval, showing that it learns substantially faster than algorithms that cannot model dependencies.

#index 1496803
#* Many-to-many graph matching: a continuous relaxation approach
#@ Mikhail Zaslavskiy;Francis Bach;Jean-Philippe Vert
#t 2010
#c 22
#% 45753
#% 443663
#% 443975
#% 737997
#% 836862
#% 1286835
#% 1387591
#% 1562612
#% 1664003
#! Graphs provide an efficient tool for object representation in various machine learning applications. Once graph-based representations are constructed, an important question is how to compare graphs. This problem is often formulated as a graph matching problem where one seeks a mapping between vertices of two graphs which optimally aligns their structure. In the classical formulation of graph matching, only one-to-one correspondences between vertices are considered. However, in many applications, graphs cannot be matched perfectly and it is more interesting to consider many-to-many correspondences where clusters of vertices in one graph are matched to clusters of vertices in the other graph. In this paper, we formulate the many-to-many graph matching problem as a discrete optimization problem and propose two approximate algorithms based on alternative continuous relaxations of the combinatorial problem. We compare new methods with other existing methods on several benchmark datasets.

#index 1496804
#* Competitive online generalized linear regression under square loss
#@ Fedor Zhdanov;Vladimir Vovk
#t 2010
#c 22
#% 266792
#% 284718
#% 350337
#% 548925
#% 891559
#% 1000325
#% 1047786
#! We apply the Aggregating Algorithm to the problem of online regression under the square loss function. We develop an algorithm competitive with the benchmark class of generalized linear models (our "experts"), which are used in a wide range of practical tasks. This problem does not appear to be analytically tractable. Therefore, we develop a prediction algorithm using the Markov chain Monte Carlo method, which is shown to be fast and reliable in many cases. We prove upper bounds on the cumulative square loss of the algorithm. We also perform experiments with our algorithm on a toy data set and two real world ozone level data sets and give suggestions about choosing its parameters.

#index 1496805
#* Cross validation framework to choose amongst models and datasets for transfer learning
#@ Erheng Zhong;Wei Fan;Qiang Yang;Olivier Verscheure;Jiangtao Ren
#t 2010
#c 22
#% 763708
#% 881470
#% 983828
#% 1074038
#% 1083655
#% 1190064
#% 1290045
#% 1440460
#! One solution to the lack of label problem is to exploit transfer learning, whereby one acquires knowledge from source-domains to improve the learning performance in the target-domain. The main challenge is that the source and target domains may have different distributions. An open problem is how to select the available models (including algorithms and parameters) and importantly, abundance of source-domain data, through statistically reliable methods, thus making transfer learning practical and easy-to-use for real-world applications. To address this challenge, one needs to take into account the difference in both marginal and conditional distributions in the same time, but not just one of them. In this paper, we formulate a new criterion to overcome "double" distribution shift and present a practical approach "Transfer Cross Validation" (TrCV) to select both models and data in a cross validation framework, optimized for transfer learning. The idea is to use density ratio weighting to overcome the difference in marginal distributions and propose a "reverse validation" procedure to quantify how well a model approximates the true conditional distribution of target-domain. The usefulness of TrCV is demonstrated on different cross-domain tasks, including wine quality evaluation, web-user ranking and text categorization. The experiment results show that the proposed method outperforms both traditional cross-validation and one state-of-the-art method which only considers marginal distribution shift. The software and datasets are available from the authors.

#index 1496806
#* Fast, effective molecular feature mining by local optimization
#@ Albrecht Zimmermann;Björn Bringmann;Ulrich Rückert
#t 2010
#c 22
#% 269217
#% 299985
#% 420062
#% 729941
#% 833126
#% 1083649
#% 1100111
#% 1117006
#% 1168770
#% 1267775
#% 1663621
#% 1663669
#% 1673557
#! In structure-activity-relationships (SAR) one aims at finding classifiers that predict the biological or chemical activity of a compound from its molecular graph. Many approaches to SAR use sets of binary substructure features, which test for the occurrence of certain substructures in the molecular graph. As an alternative to enumerating very large sets of frequent patterns, numerous pattern set mining and pattern set selection techniques have been proposed. Existing approaches can be broadly classified into those that focus on minimizing correspondences, that is, the number of pairs of training instances from different classes with identical encodings and those that focus on maximizing the number of equivalence classes, that is, unique encodings in the training data. In this paper we evaluate a number of techniques to investigate which criterion is a better indicator of predictive accuracy. We find that minimizing correspondences is a necessary but not sufficient condition for good predictive accuracy, that equivalence classes are a better indicator of success and that it is important to have a good match between training set and pattern set size. Based on these results we propose a new, improved algorithm which performs local minimization of correspondences, yet evaluates the effect of patterns on equivalence classes globally. Empirical experiments demonstrate its efficacy and its superior run time behavior.

#index 1496807
#* AnswerArt: contextualized question answering
#@ Lorand Dali;Delia Rusu;Blaž Fortuna;Dunja Mladenić;Marko Grobelnik
#t 2010
#c 22
#% 198055
#% 977142
#% 1243228
#! The focus of this paper is a question answering system, where the answers are retrieved from a collection of textual documents. The system also includes automatic document summarization and document visualization by means of a semantic graph. The information extracted from the documents is stored as subject-predicate-object triplets, and the indexed terms are expanded using Cyc, a large common sense ontology.

#index 1496808
#* Real-time news recommender system
#@ Blaž Fortuna;Carolina Fortuna;Dunja Mladenić
#t 2010
#c 22
#% 813966
#% 956521
#% 1356185
#! In this demo we present a robust system for delivering real-time news recommendation to the user based on the user's history of the past visits to the site, current user's context and popularity of stories. Our system is running live providing real-time recommendations of news articles. The system handles overspecializing as we recommend categories as opposed to items, it implicitly uses collaboration by taking into account user context and popular items and, it can handle new users by using context information. A unique characteristic of our system is that it prefers freshness over relevance, which is important for recommending news articles in real-world setting as addressed here. We experimentally compare the proposed approach as implemented in our system against several state-of-the-art alternatives and show that it significantly outperforms them.

#index 1496809
#* CET: a tool for creative exploration of graphs
#@ Stefan Haun;Andreas Nürnberger;Tobias Kötter;Kilian Thiel;Michael R. Berthold
#t 2010
#c 22
#% 1173185
#! We present a tool for interactive exploration of graphs that integrates advanced graph mining methods in an interactive visualization framework. The tool enables efficient exploration and analysis of complex graph structures. For flexible integration of state-of-the-art graph mining methods, the viewer makes use of the open source data mining platform KNIME. In contrast to existing graph visualization interfaces, all parts of the interface can be dynamically changed to specific visualization requirements, including the use of node type dependent icons, methods for a marking if nodes or edges and highlighting and a fluent graph that allows for iterative growing, shrinking and abstraction of (sub)graphs.

#index 1496810
#* NewsGist: a multilingual statistical news summarizer
#@ Mijail Kabadjov;Martin Atkinson;Josef Steinberger;Ralf Steinberger;Erik Van Der Goot
#t 2010
#c 22
#% 1190211
#% 1280537
#! In this paper we present NewsGist, a multilingual, multidocument news summarization system underpinned by the Singular Value Decomposition (SVD) paradigm for document summarization and purpose-built for the Europe Media Monitor (EMM). The summarization method employed yielded state-ofthe-art performance for English at the Update Summarization task of the last Text Analysis Conference (TAC) 2009 and integrated with EMM represents the first online summarization system able to produce summaries for so many languages. We discuss the context and motivation for developing the system and provide an overview of its architecture. The paper is intended to serve as accompaniment of a live demo of the system, which can be of interest to researchers and engineers working on multilingual open-source news analysis and mining.

#index 1496811
#* QUEST: query expansion using synonyms over time
#@ Nattiya Kanhabua;Kjetil Nørvåg
#t 2010
#c 22
#% 755899
#% 987257
#% 1434129
#% 1443174
#% 1495112
#! A particular problem of searching news archives with named entities is that they are very dynamic in appearance compared to other vocabulary terms, and synonym relationships between terms change with time. In previous work, we proposed an approach to extracting time-based synonyms of named entities from the whole history of Wikipedia. In this paper, we present QUEST (Query Expansion using Synonyms over Time), a system that exploits time-based synonyms in searching news archives. The system takes as input a named entity query, and automatically determines time-based synonyms for a given query wrt. time criteria. Query expansion using the determined synonyms can be employed in order to improve the retrieval effectiveness.

#index 1496812
#* Flu detector: tracking epidemics on twitter
#@ Vasileios Lampos;Tijl De Bie;Nello Cristianini
#t 2010
#c 22
#% 1073876
#! We present an automated tool with a web interface for tracking the prevalence of Influenza-like Illness (ILI) in several regions of the United Kingdom using the contents of Twitter's microblogging service. Our data is comprised by a daily average of approximately 200,000 geolocated tweets collected by targeting 49 urban centres in the UK for a time period of 40 weeks. Official ILI rates from the Health Protection Agency (HPA) form our ground truth. Bolasso, the bootstrapped version of LASSO, is applied in order to extract a consistent set of features, which are then used for learning a regression model.

#index 1496813
#* X-SDR: an extensible experimentation suite for dimensionality reduction
#@ Panagis Magdalinos;Anastasios Kapernekas;Alexandros Mpiratsis;Michalis Vazirgiannis
#t 2010
#c 22
#% 464888
#% 650248
#% 1663643
#! Due to the vast amount and pace of high-dimensional data production, dimensionality reduction emerges as an important requirement in many application areas. In this paper, we introduce X-SDR, a prototype designed specifically for the deployment and assessment of dimensionality reduction techniques. X-SDR is an integrated environment for dimensionality reduction and knowledge discovery that can be effectively used in the data mining process. In the current version, it supports communication with different database management systems and integrates a wealth of dimensionality reduction algorithms both distributed and centralized. Additionally, it interacts with Weka thus enabling the exploitation of the data mining algorithms therein. Finally, X-SDR provides an API that enables the integration and evaluation of any dimensionality reduction algorithm.

#index 1496814
#* SOREX: subspace outlier ranking exploration toolkit
#@ Emmanuel Müller;Matthias Schiffer;Patrick Gerwert;Matthias Hannen;Timm Jansen;Thomas Seidl
#t 2010
#c 22
#% 300136
#% 333929
#% 823340
#% 1038322
#% 1083673
#% 1083750
#% 1196030
#% 1207241
#% 1328215
#! Outlier mining is an important data analysis task to distinguish exceptional outliers from regular objects. In recent research novel outlier ranking methods propose to focus on outliers hidden in subspace projections of the data. However, focusing only on the detection of outliers these approaches miss to provide reasons why an object should be considered as an outlier. In this work, we propose a novel toolkit for exploration of subspace outlier rankings. To enable exploration of subspace outliers and to complete knowledge extraction we provide further descriptive information in addition to the pure detection of outliers. As wittinesses for the outlierness of an object, we provide information about the relevant projections describing the reasons for outlier properties. We provided SOREX as open source framework on our website it is easily extensible and suitable for research and educational purposes in this emerging research area.

#index 1496815
#* KDTA: automated knowledge-driven text annotation
#@ Katerina Papantoniou;George Tsatsaronis;Georgios Paliouras
#t 2010
#c 22
#% 805872
#% 957913
#% 1473931
#% 1714969
#! In this paper we demonstrate a system that automatically annotates text documents with a given domain ontology's concepts. The annotation process utilizes lexical and Web resources to analyze the semantic similarity of text components with any of the ontology concepts, and outputs a list with the proposed annotations, accompanied with appropriate confidence values. The demonstrated system is available online and free to use, and it constitutes one of the main components of the KDTA (Knowledge-Driven Text Analysis) module of the CASAM European research project.

#index 1496816
#* Detecting events in a million New York times articles
#@ Tristan Snowsill;Ilias Flaounas;Tijl De Bie;Nello Cristianini
#t 2010
#c 22
#! We present a demonstration of a newly developed text stream event detection method on over a million articles from the New York Times corpus. The event detection is designed to operate in a predominantly on-line fashion, reporting new events within a specified timeframe. The event detection is achieved by detecting significant changes in the statistical properties of the text where those properties are efficiently stored and updated in a suffix tree. This particular demonstration shows how our method is effective at discovering both short- and long-term events (which are often denoted topics), and how it automatically copes with topic drift on a corpus of 1 035 263 articles.

#index 1496817
#* Experience STORIES: a visual news search and summarization system
#@ Ilija Subaýić;Bettina Berendt
#t 2010
#c 22
#% 1433963
#% 1473300
#! Using data collections available on the Internet has for many people become the main medium for staying informed about the world. Many of these collections are dynamic by nature, evolving as the subjects they describe change. We present the STORIES system for (a) learning an abstracted story representation from a collection of time-indexed documents; (b) visualizing it in a way that encourages users to interact and explore in order to discover temporal "story stages" depending on their interests; and (c) supporting the search for documents and facts that pertain to the user-constructed story stages.

#index 1496818
#* Exploring real mobility data with M-atlas
#@ R. Trasarti;S. Rinzivillo;F. Pinelli;M. Nanni;A. Monreale;C. Renso;D. Pedreschi;F. Giannotti
#t 2010
#c 22
#% 989604
#% 1046207
#% 1084745
#% 1214685
#% 1230847
#% 1953174

#index 1587735
#* Proceedings of the international ECML/PKDD conference on Privacy and security issues in data mining and machine learning
#@ Christos Dimitrakakis;Aris Gkoulalas-Divanis;Aikaterini Mitrokotsa;S. Vassilios Verykios;Yücel Saygin
#t 2010
#c 22

#index 1587736
#* Edit constraints on microaggregation and additive noise
#@ Isaac Cano;Vicenç Torra
#t 2010
#c 22
#% 443478
#% 466455
#% 641954
#% 835075
#% 835077
#% 1019457
#% 1026188
#% 1074831
#% 1214170
#% 1440523
#! Privacy preserving data mining and statistical disclosure control propose several perturbative methods to protect the privacy of the respondents. Such perturbation can introduce inconsistencies to the sensitive data. Due to this, data editing techniques are used in order to ensure the correctness of the collected data before and after the anonymization. In this paper we propose a methodology to protect microdata based on noise addition that takes data edits into account. Informally, when adding noise causes a constraint to fail, we apply a process of noise swapping to preserve the edit constraint. We check its suitability against the constrained microaggregation, a method for microaggregation that avoids the introduction of such inconsistencies.

#index 1587737
#* Preserving privacy in data mining via importance weighting
#@ Charles Elkan
#t 2010
#c 22
#% 264164
#% 464280
#% 770847
#% 809245
#% 989637
#% 1061644
#% 1110366
#% 1414540
#! This paper presents a fundamentally new approach to allowing learning algorithms to be applied to a dataset, while still keeping the records in the dataset confidential. Let D be the set of records to be kept private, and let E be a fixed set of records from a similar domain that is already public. The idea is to compute and publish a weight w(x) for each record x in E that measures how representative it is of the records in D. Data mining on E using these importance weights is then approximately equivalent to data mining directly on D. The dataset D is used by its owner to compute the weights, but not revealed in any other way.

#index 1587738
#* Quadratic error minimization in a distributed environment with privacy preserving
#@ Gérald Gavin;Julien Velcin
#t 2010
#c 22
#% 17872
#% 23638
#% 136350
#% 465746
#% 512307
#% 520520
#% 523804
#% 554524
#% 656761
#% 948086
#% 1089783
#% 1356612
#% 1386180
#% 1389877
#% 1424137
#% 1669943
#% 1707130
#% 1726523
#% 1732710
#% 1815581
#! In this paper, we address the issue of privacy preserving datamining. Specifically, we consider a scenario where each member j of T parties has its own private database. The party j builds a private classifier hj for predicting a binary class variable y. The aim of this paper consists in aggregating these classifiers hj in order to improve the individual predictions. Precisely, the parties wish to compute an efficient linear combinations over their classifier in a secure manner.

#index 1587739
#* Secure top-k subgroup discovery
#@ Henrik Grosskreutz;Benedikt Lemmen;Stefan Rüping
#t 2010
#c 22
#% 227919
#% 232126
#% 340291
#% 420126
#% 477497
#% 512307
#% 575967
#% 575969
#% 763701
#% 772829
#% 799042
#% 844403
#% 881499
#% 972316
#% 1068533
#% 1068712
#% 1108863
#% 1176891
#% 1214686
#% 1232020
#% 1663651
#! Supervised descriptive rule discovery techniques like subgroup discovery are quite popular in applications like fraud detection or clinical studies. Compared with other descriptive techniques, like classical support/confidence association rules, subgroup discovery has the advantage that it comes up with only the top-k patterns, and that it makes use of a quality function that avoids patterns uncorrelated with the target. If these techniques are to be applied in privacy-sensitive scenarios involving distributed data, precise guarantees are needed regarding the amount of information leaked during the execution of the data mining. Unfortunately, the adaptation of secure multi-party protocols for classical support/confidence association rule mining to the task of subgroup discovery is impossible for fundamental reasons. The source is the different quality function and the restriction to a fixed number of patterns - i.e. exactly the desired features of subgroup discovery. In this paper, we present a new protocol which allows distributed subgroup discovery while avoiding the disclosure of the individual databases. We analyze the properties of the protocol, describe a prototypical implementation and present experiments that demonstrate the feasibility of the approach.

#index 1587740
#* ASAP: automatic semantics-aware analysis of network payloads
#@ Tammo Krueger;Nicole Krämer;Konrad Rieck
#t 2010
#c 22
#% 266426
#% 302479
#% 315637
#% 449102
#% 646234
#% 770890
#% 790040
#% 793248
#% 821987
#% 844728
#% 904987
#% 967005
#% 1051909
#% 1074089
#% 1074340
#% 1105709
#% 1109792
#% 1133255
#% 1259850
#% 1292122
#% 1401413
#% 1401435
#% 1670211
#% 1728888
#% 1728889
#! Automatic inspection of network payloads is a prerequisite for effective analysis of network communication. Security research has largely focused on network analysis using protocol specifications, for example for intrusion detection, fuzz testing and forensic analysis. The specification of a protocol alone, however, is often not sufficient for accurate analysis of communication, as it fails to reflect individual semantics of network applications. We propose a framework for semantics-aware analysis of network payloads which automatically extracts semanticsaware components from recorded network traffic. Our method proceeds by mapping network payloads to a vector space and identifying communication templates corresponding to base directions in the vector space. We demonstrate the efficacy of semantics-aware analysis in different security applications: automatic discovery of patterns in honeypot data, analysis of malware communication and network intrusion detection.

#index 1587741
#* Temporal defenses for robust recommendations
#@ Neal Lathia;Stephen Hailes;Licia Capra
#t 2010
#c 22
#% 754097
#% 813966
#% 889651
#% 987671
#% 1001280
#% 1073273
#% 1192405
#% 1227740
#% 1259861
#% 1287241
#% 1293162
#! Recommender systems are vulnerable to attack: malicious users may deploy a set of sybils (pseudonymous, automated entities) to inject ratings in order to damage or modify the output of Collaborative Filtering (CF) algorithms. To protect against these attacks, previous work focuses on designing sybil profile classification algorithms, whose aim is to find and isolate sybils. These methods, however, assume that the full sybil profiles have already been input to the system. Deployed recommender systems, on the other hand, operate over time, and recommendations may be damaged while sybils are still injecting their profiles, rather than only after all malicious ratings have been input. Furthermore, system administrators do not know when their system is under attack, and thus when to run these classification techniques, thus risking to leave their recommender system vulnerable to attacks. In this work, we address the problem of temporal sybil attacks, and propose and evaluate methods for monitoring global, user and item behaviour over time, in order to detect rating anomalies that reflect an ongoing attack.

#index 1587742
#* SBAD: sequence based attack detection via sequence comparison
#@ Ching-Hao Mao;Hsing-Kuo Pao;Christos Faloutsos;Hahn-Ming Lee
#t 2010
#c 22
#% 201893
#% 234979
#% 260152
#% 378173
#% 431296
#% 452821
#% 761289
#% 769896
#% 844306
#% 931200
#% 1206864
#! Given a stream of time-stamped events, like alerts in a network monitoring setting, how can we isolate a sequence of alerts that form a network attack? We propose a Sequence Based Attack Detection (SBAD) method, which makes the following contributions: (a) it automatically identifies groups of alerts that are frequent; (b) it summarizes them into a suspicious sequence of activity, representing them with graph structures; and (c) it suggests a novel graph-based dissimilarity measure. As a whole, SBAD is able to group suspicious alerts, visualize them, and spot anomalies at the sequence level. The evaluations from three datasets--two benchmark datasets (DARPA 1999, PKDD 2007) and a private dataset Acer 2007 gathered from a Security Operation Center in Taiwan--support our approach. The method performs well even without the help of the IP and payload information. No need for privacy information as the input makes the method easy to plug into existing system such as an intrusion detector. To talk about efficiency, the proposed method can deal with large-scale problems, such as processing 300K alerts within 20 mins on a regular PC.

#index 1587743
#* Classifier evasion: models and open problems
#@ Blaine Nelson;Benjamin I. P. Rubinstein;Ling Huang;Anthony D. Joseph;J. D. Tygar
#t 2010
#c 22
#% 766225
#% 769885
#% 823397
#% 871302
#% 1472972
#% 1736152
#! As a growing number of software developers apply machine learning to make key decisions in their systems, adversaries are adapting and launching ever more sophisticated attacks against these systems. The near-optimal evasion problem considers an adversary that searches for a low-cost negative instance by submitting a minimal number of queries to a classifier, in order to effectively evade the classifier. In this position paper, we posit several open problems and alternative variants to the near-optimal evasion problem. Solutions to these problems would significantly advance the state-of-the-art in secure machine learning.

#index 1587744
#* Large margin multiclass gaussian classification with differential privacy
#@ Manas A. Pathak;Bhiksha Raj
#t 2010
#c 22
#% 209961
#% 576110
#% 809245
#% 959454
#% 977011
#% 1141473
#% 1318812
#% 1606359
#% 1670071
#% 1740518
#! As increasing amounts of sensitive personal information is aggregated into data repositories, it has become important to develop mechanisms for processing the data without revealing information about individual data instances. The differential privacy model provides a framework for the development and theoretical analysis of such mechanisms. In this paper, we propose an algorithm for learning a discriminatively trained multiclass Gaussian classifier that satisfies differential privacy using a large margin loss function with a perturbed regularization term. We present a theoretical upper bound on the excess risk of the classifier introduced by the perturbation.

#index 1587745
#* Privacy preserving protocols for eigenvector computation
#@ Manas Pathak;Bhiksha Raj
#t 2010
#c 22
#% 420515
#% 575971
#% 616944
#% 1206988
#% 1386180
#! In this paper, we present a protocol for computing the principal eigenvector of a collection of data matrices belonging to multiple semi-honest parties with privacy constraints. Our proposed protocol is based on secure multi-party computation with a semi-honest arbitrator who deals with data encrypted by the other parties using an additive homomorphic cryptosystem. We augment the protocol with randomization and oblivious transfer to make it difficult for any party to estimate properties of the data belonging to other parties from the intermediate steps. The previous approaches towards this problem were based on expensive QR decomposition of correlation matrices, we present an efficient algorithm using the power iteration method. We present an analysis of the correctness, security, and efficiency of protocol.

#index 1587746
#* Content-based filtering in on-line social networks
#@ Marco Vanetti;Elisabetta Binaghi;Barbara Carminati;Moreno Carullo;Elena Ferrari
#t 2010
#c 22
#% 46803
#% 115462
#% 298856
#% 309122
#% 344447
#% 424028
#% 728123
#% 763708
#% 803668
#% 804422
#% 842605
#% 989161
#% 1018909
#% 1042868
#% 1077150
#% 1080081
#% 1211283
#% 1261446
#% 1399968
#% 1431611
#! This paper proposes a system enforcing content-based message filtering for On-line Social Networks (OSNs). The system allows OSN users to have a direct control on the messages posted on their walls. This is achieved through a flexible rule-based system, that allows a user to customize the filtering criteria to be applied to their walls, and a Machine Learning based soft classifier automatically labelling messages in support of content-based filtering.

#index 1617246
#* Proceedings of the 2011 European conference on Machine learning and knowledge discovery in databases - Volume Part I
#@ Dimitrios Gunopulos;Thomas Hofmann;Donato Malerba;Michalis Vazirgiannis
#t 2011
#c 22

#index 1617247
#* Enriching education through data mining
#@ Rakesh Agrawal
#t 2011
#c 22
#% 1528118
#% 1560308
#! Education is acknowledged to be the primary vehicle for improving the economic well-being of people [1,6]. Textbooks have a direct bearing on the quality of education imparted to the students as they are the primary conduits for delivering content knowledge [9]. They are also indispensable for fostering teacher learning and constitute a key component of the ongoing professional development of the teachers [5,8]. Many textbooks, particularly from emerging countries, lack clear and adequate coverage of important concepts [7]. In this talk, we present our early explorations into developing a data mining based approach for enhancing the quality of textbooks. We discuss techniques for algorithmically augmenting different sections of a book with links to selective content mined from the Web. For finding authoritative articles, we first identify the set of key concept phrases contained in a section. Using these phrases, we find web (Wikipedia) articles that represent the central concepts presented in the section and augment the section with links to them [4]. We also describe a framework for finding images that are most relevant to a section of the textbook, while respectingglobal relevancy to the entire chapter to which the section belongs. We pose this problem of matching images to sections in a textbook chapter as an optimization problem and present an efficient algorithm for solving it [2].

#index 1617248
#* Human dynamics: from human mobility to predictability
#@ Albert-László Barabási
#t 2011
#c 22
#! A range of applications, from predicting the spread of human and electronic viruses to city planning and resource management in mobile communications, depend on our ability to understand human activity patterns. I will discuss recent effort to explore human activity patterns, using the mobility of individuals as a proxy. As an application, I will show that by measuring the entropy of each individuals trajectory, we find can explore the underlying predictability of human mobility, raising fundamental questions on how predictable we really are. I will also discuss the interplay between human mobilty, social links, and the predictive power of data mining.

#index 1617249
#* Embracing uncertainty: applied machine learning comes of age
#@ Christopher Bishop
#t 2011
#c 22
#! Over the last decade the number of deployed applications of machine learning has grown rapidly, with examples in domains ranging from recommendation systems and web search, to spam filters and voice recognition. Most recently, the Kinect 3D full-body motion sensor, which relies crucially on machine learning, has become the fastest-selling consumer electronics device in history. Developments such as the advent of widespread internet connectivity, with its centralisation of data storage, as well as new algorithms for computationally efficient probabilistic inference, will create many new opportunities for machine learning over the coming years. The talk will be illustrated with tutorial examples, live demonstrations, and real-world case studies.

#index 1617250
#* Highly dimensional problems in computational advertising
#@ Andrei Broder
#t 2011
#c 22
#! The central problem of Computational Advertising is to find the "best match" between a given user in a given context and a suitable advertisement. The context could be a user entering a query in a search engine ("sponsored search"), a user reading a web page ("content match" and "display ads"), a user interacting with a portable device, and so on. The information about the user can vary from scarily detailed to practically nil. The number of potential advertisements might be in the billions. The number of contexts is unbound. Thus, depending on the definition of "best match" this problem leads to a variety of massive optimization and search problems, with complicated constraints. The solution to these problems provides the scientific and technical underpinnings of the online advertising industry, an industry estimated to surpass 28 billion dollars in US alone in 2011. An essential aspect of this problem is predicting the impact of an ad on users' behavior, whether immediate and easily quantifiable (e.g. clicking on ad or buying a product on line) or delayed and harder to measure (e.g. off-line buying or changes in brand perception). To this end, the three components of the problem - users, contexts, and ads - are represented as high dimensional objects and terabytes of data documenting the interactions among them are collected every day. Nevertheless, considering the representation difficulty, the dimensionality of the problem and the rarity of the events of interest, the prediction problem remains a huge challenge. The goal of this talk is twofold: to present a short introduction to Computational Adverting and survey several high dimensional problems at the core of this emerging scientific discipline.

#index 1617251
#* Learning from constraints
#@ Marco Gori
#t 2011
#c 22
#! In this talk, I propose a functional framework to understand the emergence of intelligence in agents exposed to examples and knowledge granules. The theory is based on the abstract notion of constraint, which provides a representation of knowledge granules gained from the interaction with the environment. I give a picture of the "agent body" in terms of representation theorems by extending the classic framework of kernel machines in such a way to incorporate logic formalisms, like first-order logic. This is made possible by the unification of continuous and discrete computational mechanisms in the same functional framework, so as any stimulus, like supervised examples and logic predicates, is translated into a constraint. The learning, which is based on constrained variational calculus, is either guided by a parsimonious match of the constraints or by unsupervised mechanisms expressed in terms of the minimization of the entropy. I show some experiments with different kinds of symbolic and subsymbolic constraints, and then I give insights on the adoption of the proposed framework in computer vision. It is shown that in most interesting tasks the learning from constraints naturally leads to "deep architectures", that emerge when following the developmental principle of focusing attention on "easy constraints", at each stage. Interestingly, this suggests that stage-based learning, as discussed in developmental psychology, might not be primarily the outcome of biology, but it could be instead the consequence of optimization principles and complexity issues that hold regardless of the "body."

#index 1617252
#* Permutation structure in 0-1 data
#@ Heikki Mannila
#t 2011
#c 22
#! Multidimensional 0-1 data occurs in many domains. Typically one assumes that the order of rows and columns has no importance. However, in some applications, e.g., in ecology, there is structure in the data that becomes visible only when the rows and columns are permuted in a certain way. Examples of such structure are different forms of nestedness and bandedness. I review some of the applications, intuitions, results, and open problems in this area.

#index 1617253
#* Reading customers needs and expectations with analytics
#@ Vasilis Aggelis
#t 2011
#c 22
#! Customers are the greatest asset for every bank. Do we know them in whole? Are we ready to fulfill their needs and expectations? Use of analytics is one of the keys in order to make better our relation with customers. In advance, analytics can bring gains both for customers and banks. Customer segmentation, targeted cross- and up-sell campaigns, data mining utilization are tools that drive in great results and contribute to customer centric turn.

#index 1617254
#* Algorithms and challenges on the GeoWeb
#@ Radu Jurca
#t 2011
#c 22
#! A substantial number of queries addressed nowadays to online search engines have a geographical dimension. People look up addresses on a map, but are also interested in events happening nearby, or inquire information about products, shops or attractions in a particular area. It is no longer enough to index and display geographical information; one should instead geographically organize the world's information. This is the mission of Google's GeoWeb, and several teams inside Google focus on solving this problem. This talk gives an overview of the main challenges characterizing this endeavor, and offers a glimpse into some of the solutions we built.

#index 1617255
#* Data science and machine learning at scale
#@ Neel Sundaresan
#t 2011
#c 22
#! Large Social Commerce Network sites like eBay have to constantly grapple with building scalable machine learning algorithms for search ranking, recommender systems, classification, and others. Large data availability is both a boon and curse. While it offers a lot more diverse observation, the same diversity with sparsity and lack of reliable labeled data at scale introduces new challenges. Also, availability of large data helps take advantage of correlational factors while requiring creativity in discarding irrelevant data. In this talk we will discuss all of this and more from the context of eBays large data problems.

#index 1617256
#* Smart cities: how data mining and optimization can shape future cities
#@ Olivier Verscheure
#t 2011
#c 22
#! By 2050, an estimated 70% of the worlds population will live in cities up from 13% in 1900. Already, cities consume an estimated 75% of the worlds energy, emit more than 80% of greenhouse gases, and lose as much as 20% of their water supply due to infrastructure leaks. As their urban populations continue to grow and these metrics increase, civic leaders face an unprecedented series of challenges to scale and optimize their infrastructures.

#index 1617257
#* Preference-based policy learning
#@ Riad Akrour;Marc Schoenauer;Michele Sebag
#t 2011
#c 22
#% 224755
#% 374560
#% 384911
#% 466418
#% 540908
#% 770852
#% 824262
#% 840882
#% 876055
#% 881477
#% 1034798
#% 1042610
#% 1065689
#% 1504351
#% 1781811
#! Many machine learning approaches in robotics, based on reinforcement learning, inverse optimal control or direct policy learning, critically rely on robot simulators. This paper investigates a simulatorfree direct policy learning, called Preference-based Policy Learning (PPL). PPL iterates a four-step process: the robot demonstrates a candidate policy; the expert ranks this policy comparatively to other ones according to her preferences; these preferences are used to learn a policy return estimate; the robot uses the policy return estimate to build new candidate policies, and the process is iterated until the desired behavior is obtained. PPL requires a good representation of the policy search space be available, enabling one to learn accurate policy return estimates and limiting the human ranking effort needed to yield a good policy. Furthermore, this representation cannot use informed features (e.g., how far the robot is from any target) due to the simulator-free setting. As a second contribution, this paper proposes a representation based on the agnostic exploitation of the robotic log. The convergence of PPL is analytically studied and its experimental validation on two problems, involving a single robot in a maze and two interacting robots, is presented.

#index 1617258
#* Constraint selection for semi-supervised topological clustering
#@ Kais Allab;Khalid Benabdeslem
#t 2011
#c 22
#% 252011
#% 391311
#% 464608
#% 466890
#% 679322
#% 770782
#% 829025
#% 840892
#% 948091
#% 959474
#% 989595
#% 1085668
#% 1455666
#% 1663626
#% 1673558
#% 1860652
#% 1914467
#! In this paper, we propose to adapt the batch version of selforganizing map (SOM) to background information in clustering task. It deals with constrained clustering with SOM in a deterministic paradigm. In this context we adapt the appropriate topological clustering to pairwise instance level constraints with the study of their informativeness and coherence properties for measuring their utility for the semi-supervised learning process. These measures will provide guidance in selecting the most useful constraint sets for the proposed algorithm. Experiments will be given over several databases for validating our approach in comparison with another constrained clustering ones.

#index 1617259
#* Is there a best quality metric for graph clusters?
#@ Hélio Almeida;Dorgival Guedes;Wagner Meira;Mohammed J. Zaki
#t 2011
#c 22
#% 281214
#% 313959
#% 577214
#% 755402
#% 835018
#% 944938
#% 1013696
#% 1055741
#% 1085750
#% 1328169
#% 1399996
#% 1835483
#! Graph clustering, the process of discovering groups of similar vertices in a graph, is a very interesting area of study, with applications in many different scenarios. One of the most important aspects of graph clustering is the evaluation of cluster quality, which is important not only to measure the effectiveness of clustering algorithms, but also to give insights on the dynamics of relationships in a given network. Many quality evaluation metrics for graph clustering have been proposed in the literature, but there is no consensus on how do they compare to each other and how well they perform on different kinds of graphs. In this work we study five major graph clustering quality metrics in terms of their formal biases and their behavior when applied to clusters found by four implementations of classic graph clustering algorithms on five large, real world graphs. Our results show that those popular quality metrics have strong biases toward incorrectly awarding good scores to some kinds of clusters, especially seen in larger networks. They also indicate that currently used clustering algorithms and quality metrics do not behave as expected when cluster structures are different from the more traditional, clique-like ones.

#index 1617260
#* Adaptive boosting for transfer learning using dynamic updates
#@ Samir Al-Stouhi;Chandan K. Reddy
#t 2011
#c 22
#% 520224
#% 770858
#% 906248
#% 983828
#% 989592
#% 990437
#% 1080960
#% 1270196
#% 1305479
#% 1318754
#% 1351051
#% 1464068
#% 1702201
#! Instance-based transfer learning methods utilize labeled examples from one domain to improve learning performance in another domain via knowledge transfer. Boosting-based transfer learning algorithms are a subset of such methods and have been applied successfully within the transfer learning community. In this paper, we address some of the weaknesses of such algorithms and extend the most popular transfer boosting algorithm, TrAdaBoost. We incorporate a dynamic factor into TrAdaBoost to make it meet its intended design of incorporating the advantages of both AdaBoost and the "Weighted Majority Algorithm". We theoretically and empirically analyze the effect of this important factor on the boosting performance of TrAdaBoost and we apply it as a "correction factor" that significantly improves the classification performance. Our experimental results on several real-world datasets demonstrate the effectiveness of our framework in obtaining better classification results.

#index 1617261
#* Peer and authority pressure in information-propagation models
#@ Aris Anagnostopoulos;George Brova;Evimaria Terzi
#t 2011
#c 22
#% 729923
#% 1083624
#% 1214671
#% 1227643
#% 1535333
#% 1560425
#% 1661308
#! Existing models of information diffusion assume that peer influence is the main reason for the observed propagation patterns. In this paper, we examine the role of authority pressure on the observed information cascades. We model this intuition by characterizing some nodes in the network as "authority" nodes. These are nodes that can influence large number of peers, while themselves cannot be influenced by peers. We propose a model that associates with every item two parameters that quantify the impact of the peer and the authority pressure on the item's propagation. Given a network and the observed diffusion patterns of the item, we learn these parameters from the data and characterize the item as peer- or authority-propagated. We also develop a randomization test that evaluates the statistical significance of our findings and makes our item characterization robust to noise. Our experiments with real data from online media and scientific-collaboration networks indicate that there is a strong signal of authority pressure in these networks.

#index 1617262
#* Constrained logistic regression for discriminative pattern mining
#@ Rajul Anand;Chandan K. Reddy
#t 2011
#c 22
#% 236497
#% 280409
#% 420126
#% 452821
#% 487680
#% 648469
#% 729935
#% 763701
#% 907183
#% 983828
#% 1085668
#% 1232020
#% 1272357
#% 1315574
#% 1464068
#% 1467522
#% 1673620
#% 1692331
#! Analyzing differences in multivariate datasets is a challenging problem. This topic was earlier studied by finding changes in the distribution differences either in the form of patterns representing conjunction of attribute value pairs or univariate statistical analysis for each attribute in order to highlight the differences. All such methods focus only on change in attributes in some form and do not implicitly consider the class labels associated with the data. In this paper, we pose the difference in distribution in a supervised scenario where the change in the data distribution is measured in terms of the change in the corresponding classification boundary. We propose a new constrained logistic regression model to measure such a difference between multivariate data distributions based on the predictive models induced on them. Using our constrained models, we measure the difference in the data distributions using the changes in the classification boundary of these models. We demonstrate the advantages of the proposed work over other methods available in the literature using both synthetic and real-world datasets.

#index 1617263
#* α-clusterable sets
#@ Gerasimos S. Antzoulatos;Michael N. Vrahatis
#t 2011
#c 22
#% 2115
#% 36672
#% 160980
#% 296738
#% 329349
#% 374537
#% 393792
#% 443531
#% 448457
#% 637742
#% 818916
#% 898281
#% 925120
#% 1215049
#% 1294184
#% 1301387
#% 1455533
#% 1785063
#! In spite of the increasing interest into clustering research within the last decades, a unified clustering theory that is independent of a particular algorithm, or underlying the data structure and even the objective function has not be formulated so far. In the paper at hand, we take the first steps towards a theoretical foundation of clustering, by proposing a new notion of "clusterability" of data sets based on the density of the data within a specific region. Specifically, we give a formal definition of what we call "α-clusterable" set and we utilize this notion to prove that the principles proposed in Kleinberg's impossibility theorem for clustering [25], are consistent. We further propose an unsupervised clustering algorithm which is based on the notion of α-clusterable set. The proposed algorithm exploits the ability of the well known and widely used particle swarm optimization [31] to maximize the recently proposed window density function [38]. The obtained clustering quality is compared favorably to the corresponding clustering quality of various other well-known clustering algorithms.

#index 1617264
#* Privacy preserving semi-supervised learning for labeled graphs
#@ Hiromi Arai;Jun Sakuma
#t 2011
#c 22
#% 264249
#% 466263
#% 523792
#% 554524
#% 743280
#% 833913
#% 839729
#% 963800
#% 1068712
#% 1073980
#% 1227606
#! We propose a novel privacy preserving learning algorithm that achieves semi-supervised learning in graphs. In real world networks, such as disease infection over individuals, links (contact) and labels (infection) are often highly sensitive information. Although traditional semisupervised learning methods play an important role in network data analysis, they fail to protect such sensitive information. Our solutions enable to predict labels of partially labeled graphs without disclosure of labels and links, by incorporating cryptographic techniques into the label propagation algorithm. Even when labels included in the graph are kept private, the accuracy of our PPLP is equivalent to that of label propagation which is allowed to observe all labels in the graph. Empirical analysis showed that our solution is scalable compared with existing privacy preserving methods. The results with human contact networks showed that our protocol takes only about 10 seconds for computation and no sensitive information is disclosed through the protocol execution.

#index 1617265
#* Novel fusion methods for pattern recognition
#@ Muhammad Awais;Fei Yan;Krystian Mikolajczyk;Josef Kittler
#t 2011
#c 22
#% 132938
#% 251145
#% 501539
#% 520224
#% 738972
#% 763697
#% 763699
#% 770846
#% 824956
#% 852098
#% 883972
#% 884039
#% 961190
#% 983953
#% 1160039
#% 1267771
#% 1378799
#! Over the last few years, several approaches have been proposed for information fusion including different variants of classifier level fusion (ensemble methods), stacking and multiple kernel learning (MKL). MKL has become a preferred choice for information fusion in object recognition. However, in the case of highly discriminative and complementary feature channels, it does not significantly improve upon its trivial baseline which averages the kernels. Alternative ways are stacking and classifier level fusion (CLF) which rely on a two phase approach. There is a significant amount of work on linear programming formulations of ensemble methods particularly in the case of binary classification. In this paper we propose a multiclass extension of binary v-LPBoost, which learns the contribution of each class in each feature channel. The existing approaches of classifier fusion promote sparse features combinations, due to regularization based on l1-norm, and lead to a selection of a subset of feature channels, which is not good in the case of informative channels. Therefore, we generalize existing classifier fusion formulations to arbitrary lp-norm for binary and multiclass problems which results in more effective use of complementary information. We also extended stacking for both binary and multiclass datasets. We present an extensive evaluation of the fusion methods on four datasets involving kernels that are all informative and achieve state-of-the-art results on all of them.

#index 1617266
#* A spectral learning algorithm for finite state transducers
#@ Borja Balle;Ariadna Quattoni;Xavier Carreras
#t 2011
#c 22
#% 203295
#% 252472
#% 464424
#% 741114
#% 748738
#% 805763
#% 815863
#% 857087
#% 1211694
#% 1338694
#% 1373402
#% 1564904
#% 1728757
#% 1757567
#! Finite-State Transducers (FSTs) are a popular tool for modeling paired input-output sequences, and have numerous applications in real-world problems. Most training algorithms for learning FSTs rely on gradient-based or EM optimizations which can be computationally expensive and suffer from local optima issues. Recently, Hsu et al. [13] proposed a spectral method for learning Hidden Markov Models (HMMs) which is based on an Observable Operator Model (OOM) view of HMMs. Following this line of work we present a spectral algorithm to learn FSTs with strong PAC-style guarantees. To the best of our knowledge, ours is the first result of this type for FST learning. At its core, the algorithm is simple, and scalable to large data sets. We present experiments that validate the effectiveness of the algorithm on synthetic and real data.

#index 1617267
#* An analysis of probabilistic methods for top-N recommendation in collaborative filtering
#@ Nicola Barbieri;Giuseppe Manco
#t 2011
#c 22
#% 124010
#% 330687
#% 643007
#% 722904
#% 734592
#% 823392
#% 860672
#% 1073982
#% 1139334
#% 1190066
#% 1273828
#% 1355025
#% 1396094
#% 1476448
#% 1476483
#% 1535449
#! In this work we perform an analysis of probabilistic approaches to recommendation upon a different validation perspective, which focuses on accuracy metrics such as recall and precision of the recommendation list. Traditionally, state-of-art approches to recommendations consider the recommendation process from a "missing value prediction" perspective. This approach simplifies the model validation phase that is based on the minimization of standard error metrics such as RMSE. However, recent studies have pointed several limitations of this approach, showing that a lower RMSE does not necessarily imply improvements in terms of specific recommendations. We demonstrate that the underlying probabilistic framework offers several advantages over traditional methods, in terms of flexibility in the generation of the recommendation list and consequently in the accuracy of recommendation.

#index 1617268
#* Learning good edit similarities with generalization guarantees
#@ Aurélien Bellet;Amaury Habrard;Marc Sebban
#t 2011
#c 22
#% 251405
#% 722805
#% 729913
#% 875954
#% 940343
#% 983830
#% 983928
#% 1055501
#% 1232015
#% 1283435
#! Similarity and distance functions are essential to many learning algorithms, thus training them has attracted a lot of interest. When it comes to dealing with structured data (e.g., strings or trees), edit similarities are widely used, and there exists a few methods for learning them. However, these methods offer no theoretical guarantee as to the generalization performance and discriminative power of the resulting similarities. Recently, a theory of learning with (ε, γ, τ)-good similarity functions was proposed. This new theory bridges the gap between the properties of a similarity function and its performance in classification. In this paper, we propose a novel edit similarity learning approach (GESL) driven by the idea of (ε, γ, τ)-goodness, which allows us to derive generalization guarantees using the notion of uniform stability. We experimentally show that edit similarities learned with our method induce classification models that are both more accurate and sparser than those induced by the edit distance or edit similarities learned with a state-of-the-art method.

#index 1617269
#* Constrained laplacian score for semi-supervised feature selection
#@ Khalid Benabdeslem;Mohammed Hindawi
#t 2011
#c 22
#% 227486
#% 243728
#% 361100
#% 391311
#% 720010
#% 722929
#% 729437
#% 771842
#% 829025
#% 983948
#% 1035242
#% 1085668
#% 1378513
#% 1411129
#% 1455666
#% 1542360
#! In this paper, we address the problem of semi-supervised feature selection from high-dimensional data. It aims to select the most discriminative and informative features for data analysis. This is a recent addressed challenge in feature selection research when dealing with small labeled data sampled with large unlabeled data in the same set. We present a filter based approach by constraining the known Laplacian score. We evaluate the relevance of a feature according to its locality preserving and constraints preserving ability. The problem is then presented in the spectral graph theory framework with a study of the complexity of the proposed algorithm. Finally, experimental results will be provided for validating our proposal in comparison with other known feature selection methods.

#index 1617270
#* COSNet: a cost sensitive neural network for semi-supervised learning in graphs
#@ Alberto Bertoni;Marco Frasca;Giorgio Valentini
#t 2011
#c 22
#% 833125
#% 905823
#% 983810
#% 992948
#% 1041440
#% 1042822
#% 1055741
#% 1377463
#% 1447814
#! The semi-supervised problem of learning node labels in graphs consists, given a partial graph labeling, in inferring the unknown labels of the unlabeled vertices. Several machine learning algorithms have been proposed for solving this problem, including Hopfield networks and label propagation methods; however, some issues have been only partially considered, e.g. the preservation of the prior knowledge and the unbalance between positive and negative labels. To address these items, we propose a Hopfield-based cost sensitive neural network algorithm (COSNet). The method factorizes the solution of the problem in two parts: 1) the subnetwork composed by the labelled vertices is considered, and the network parameters are estimated through a supervised algorithm; 2) the estimated parameters are extended to the subnetwork composed of the unlabeled vertices, and the attractor reached by the dynamics of this subnetwork allows to predict the labeling of the unlabeled vertices. The proposed method embeds in the neural algorithm the "a priori" knowledge coded in the labelled part of the graph, and separates node labels and neuron states, allowing to differentially weight positive and negative node labels. Moreover, COSNet introduces an efficient costsensitive strategy which allows to learn the near-optimal parameters of the network in order to take into account the unbalance between positive and negative node labels. Finally, the dynamics of the network is restricted to its unlabeled part, preserving the minimization of the overall objective function and significantly reducing the time complexity of the learning algorithm. COSNet has been applied to the genome-wide prediction of gene function in a model organism. The results, compared with those obtained by other semi-supervised label propagation algorithms and supervised machine learning methods, show the effectiveness of the proposed approach.

#index 1617271
#* Regularized sparse Kernel slow feature analysis
#@ Wendelin Böhmer;Steffen Grünewälder;Hannes Nickisch;Klaus Obermayer
#t 2011
#c 22
#% 97424
#% 266426
#% 450245
#% 450248
#% 466597
#% 635689
#% 722466
#% 724303
#% 743284
#% 818132
#% 855606
#% 961258
#! This paper develops a kernelized slow feature analysis (SFA) algorithm. SFA is an unsupervised learning method to extract features which encode latent variables from time series. Generative relationships are usually complex, and current algorithms are either not powerful enough or tend to over-fit. We make use of the kernel trick in combination with sparsification to provide a powerful function class for large data sets. Sparsity is achieved by a novel matching pursuit approach that can be applied to other tasks as well. For small but complex data sets, however, the kernel SFA approach leads to over-fitting and numerical instabilities. To enforce a stable solution, we introduce regularization to the SFA objective. Versatility and performance of our method are demonstrated on audio and video data sets.

#index 1617272
#* A selecting-the-best method for budgeted model selection
#@ Gianluca Bontempi;Olivier Caelen
#t 2011
#c 22
#% 229959
#% 314413
#% 383830
#% 425053
#% 788079
#% 1172002
#% 1593534
#! The paper focuses on budgeted model selection, that is the selection between a set of alternative models when the ratio between the number of model assessments and the number of alternatives, though bigger than one, is low. We propose an approach based on the notion of probability of correct selection, a notion borrowed from the domain of Monte Carlo stochastic approximation. The idea is to estimate from data the probability that a greedy selection returns the best alternative and to define a sampling rule which maximises such quantity. Analytical results in the case of two alternatives are extended to a larger number of alternatives by using the Clark's approximation of the maximum of a set of random variables. Preliminary results on synthetic and real model selection tasks show that the technique is competititive with state-of-the-art algorithms, like the bandit UCB.

#index 1617273
#* A robust ranking methodology based on diverse calibration of AdaBoost
#@ Róbert Busa-Fekete;Balázs Kégl;Tamás Éltetö;György Szarvas
#t 2011
#c 22
#% 235377
#% 302391
#% 734915
#% 871302
#% 983820
#% 987241
#% 1074344
#% 1211752
#% 1292528
#% 1343447
#% 1442575
#% 1442577
#% 1817412
#! In subset ranking, the goal is to learn a ranking function that approximates a gold standard partial ordering of a set of objects (in our case, relevance labels of a set of documents retrieved for the same query). In this paper we introduce a learning to rank approach to subset ranking based on multi-class classification. Our technique can be summarized in three major steps. First, a multi-class classification model (AdaBoost.MH) is trained to predict the relevance label of each object. Second, the trained model is calibrated using various calibration techniques to obtain diverse class probability estimates. Finally, the Bayes-scoring function (which optimizes the popular Information Retrieval performance measure NDCG), is approximated through mixing these estimates into an ultimate scoring function. An important novelty of our approach is that many different methods are applied to estimate the same probability distribution, and all these hypotheses are combined into an improved model. It is well known that mixing different conditional distributions according to a prior is usually more efficient than selecting one "optimal" distribution. Accordingly, using all the calibration techniques, our approach does not require the estimation of the best suited calibration method and is therefore less prone to overfitting. In an experimental study, our method outperformed many standard ranking algorithms on the LETOR benchmark datasets, most of which are based on significantly more complex learning to rank algorithms than ours.

#index 1617274
#* Active learning of model parameters for influence maximization
#@ Tianyu Cao;Xindong Wu;Tony Xiaohua Hu;Song Wang
#t 2011
#c 22
#% 342596
#% 577217
#% 729923
#% 1107420
#% 1214641
#% 1269888
#% 1355040
#% 1401271
#% 1451242
#% 1451243
#% 1451244
#% 1496782
#% 1535380
#! Previous research efforts on the influence maximization problem assume that the network model parameters are known beforehand. However, this is rarely true in real world networks. This paper deals with the situation when the network information diffusion parameters are unknown. To this end, we firstly examine the parameter sensitivity of a popular diffusion model in influence maximization, i.e., the linear threshold model, to motivate the necessity of learning the unknown model parameters. Experiments show that the influence maximization problem is sensitive to the model parameters under the linear threshold model. In the sequel, we formally define the problem of finding the model parameters for influence maximization as an active learning problem under the linear threshold model. We then propose a weighted sampling algorithm to solve this active learning problem. Extensive experimental evaluations on five popular network datasets demonstrate that the proposed weighted sampling algorithm outperforms pure random sampling in terms of both model accuracy and the proposed objective function.

#index 1617275
#* Sampling table configurations for the hierarchical poisson-dirichlet process
#@ Changyou Chen;Lan Du;Wray Buntine
#t 2011
#c 22
#% 722904
#% 939624
#% 1211828
#% 1211831
#% 1310058
#% 1310469
#% 1333050
#% 1424114
#% 1457042
#% 1535392
#% 1742154
#! Hierarchical modeling and reasoning are fundamental in machine intelligence, and for this the two-parameter Poisson-Dirichlet Process (PDP) plays an important role. The most popular MCMC sampling algorithm for the hierarchical PDP and hierarchical Dirichlet Process is to conduct an incremental sampling based on the Chinese restaurant metaphor, which originates from the Chinese restaurant process (CRP). In this paper, with the same metaphor, we propose a new table representation for the hierarchical PDPs by introducing an auxiliary latent variable, called table indicator, to record which customer takes responsibility for starting a new table. In this way, the new representation allows full exchangeability that is an essential condition for a correct Gibbs sampling algorithm. Based on this representation, we develop a block Gibbs sampling algorithm, which can jointly sample the data item and its table contribution. We test this out on the hierarchical Dirichlet process variant of latent Dirichlet allocation (HDP-LDA) developed by Teh, Jordan, Beal and Blei. Experiment results show that the proposed algorithm outperforms their "posterior sampling by direct assignment" algorithm in both out-of-sample perplexity and convergence speed. The representation can be used with many other hierarchical PDP models.

#index 1617276
#* Preference-based policy iteration: leveraging preference learning for reinforcement learning
#@ Weiwei Cheng;Johannes Fürnkranz;Eyke Hüllermeier;Sang-Hyeun Park
#t 2011
#c 22
#% 124687
#% 124691
#% 449561
#% 720778
#% 1073929
#% 1077631
#% 1093383
#% 1272095
#% 1280268
#% 1301004
#% 1541778
#! This paper makes a first step toward the integration of two subfields of machine learning, namely preference learning and reinforcement learning (RL). An important motivation for a "preference-based" approach to reinforcement learning is a possible extension of the type of feedback an agent may learn from. In particular, while conventional RL methods are essentially confined to deal with numerical rewards, there are many applications in which this type of information is not naturally available, and in which only qualitative reward signals are provided instead. Therefore, building on novel methods for preference learning, our general goal is to equip the RL agent with qualitative policy models, such as ranking functions that allow for sorting its available actions from most to least promising, as well as algorithms for learning such models from qualitative feedback. Concretely, in this paper, we build on an existing method for approximate policy iteration based on roll-outs. While this approach is based on the use of classification methods for generalization and policy learning, we make use of a specific type of preference learning method called label ranking. Advantages of our preference-based policy iteration method are illustrated by means of two case studies.

#index 1617277
#* Learning recommendations in social media systems by weighting multiple relations
#@ Boris Chidlovskii
#t 2011
#c 22
#% 156693
#% 769942
#% 770864
#% 799636
#% 840846
#% 983820
#% 1055704
#% 1055761
#% 1127458
#% 1166511
#% 1190090
#% 1459771
#% 1459772
#% 1490608
#% 1506188
#% 1536568
#% 1663624
#! We address the problem of item recommendation in social media sharing systems. We adopt a multi-relational framework capable to integrate different entity types available in the social media system and relations between the entities. We then model different recommendation tasks as weighted random walks in the relational graph. The main contribution of the paper is a novel method for learning the optimal contribution of each relation to a given recommendation task, by minimizing a loss function on the training dataset. We report results of the relation weight learning for two common tasks on the Flickr dataset, tag recommendation for images and contact recommendation for users.

#index 1617278
#* Clustering rankings in the fourier domain
#@ Stéphan Clémençon;Romaric Gaudel;Jérémie Jakubowicz
#t 2011
#c 22
#% 56600
#% 734915
#% 875979
#% 1093383
#% 1152378
#% 1232043
#% 1312124
#% 1495559
#! It is the purpose of this paper to introduce a novel approach to clustering rank data on a set of possibly large cardinality n ∈ N*, relying upon Fourier representation of functions defined on the symmetric group Sn. In the present setup, covering a wide variety of practical situations, rank data are viewed as distributions on Sn. Cluster analysis aims at segmenting data into homogeneous subgroups, hopefully very dissimilar in a certain sense. Whereas considering dissimilarity measures/distances between distributions on the non commutative group Sn, in a coordinate manner by viewing it as embedded in the set [0, 1]n! for instance, hardly yields interpretable results and leads to face obvious computational issues, evaluating the closeness of groups of permutations in the Fourier domain may be much easier in contrast. Indeed, in a wide variety of situations, a few well-chosen Fourier (matrix) coefficients may permit to approximate efficiently two distributions on Sn as well as their degree of dissimilarity, while describing global properties in an interpretable fashion. Following in the footsteps of recent advances in automatic feature selection in the context of unsupervised learning, we propose to cast the task of clustering rankings in terms of optimization of a criterion that can be expressed in the Fourier domain in a simple manner. The effectiveness of the method proposed is illustrated by numerical experiments based on artificial and real data.

#index 1617279
#* PERTURBO: a new classification algorithm based on the spectrum perturbations of the Laplace-Beltrami operator
#@ Nicolas Courty;Thomas Burger;Johann Laurent
#t 2011
#c 22
#% 266426
#% 270134
#% 307247
#% 593047
#% 729437
#% 770839
#% 889151
#% 990123
#% 995140
#% 1164929
#% 1214804
#% 1252774
#% 1295500
#% 1484119
#% 1777043
#! PerTurbo, an original, non-parametric and efficient classification method is presented here. In our framework, the manifold of each class is characterized by its Laplace-Beltrami operator, which is evaluated with classical methods involving the graph Laplacian. The classification criterion is established thanks to a measure of the magnitude of the spectrum perturbation of this operator. The first experiments show good performances against classical algorithms of the state-of-the-art. Moreover, from this measure is derived an efficient policy to design sampling queries in a context of active learning. Performances collected over toy examples and real world datasets assess the qualities of this strategy.

#index 1617280
#* Datum-wise classification: a sequential approach to sparsity
#@ Gabriel Dulac-Arnold;Ludovic Denoyer;Philippe Preux;Patrick Gallinari
#t 2011
#c 22
#% 363744
#% 384911
#% 543918
#% 722929
#% 942925
#% 1040316
#% 1117691
#% 1211793
#% 1415237
#% 1587374
#! We propose a novel classification technique whose aim is to select an appropriate representation for each datapoint, in contrast to the usual approach of selecting a representation encompassing the whole dataset. This datum-wise representation is found by using a sparsity inducing empirical risk, which is a relaxation of the standard L0 regularized risk. The classification problem is modeled as a sequential decision process that sequentially chooses, for each datapoint, which features to use before classifying. Datum-Wise Classification extends naturally to multi-class tasks, and we describe a specific case where our inference has equivalent complexity to a traditional linear classifier, while still using a variable number of features. We compare our classifier to classical L1 regularized linear models (L1-SVM and LARS) on a set of common binary and multi-class datasets and show that for an equal average number of features used we can get improved performance using our method.

#index 1617281
#* Manifold coarse graining for online semi-supervised learning
#@ Mehrdad Farajtabar;Amirreza Shaban;Hamid Reza Rabiee;Mohammad Hossein Rohban
#t 2011
#c 22
#% 780687
#% 784995
#% 889151
#% 961218
#% 1085164
#% 1108860
#% 1148459
#% 1238053
#% 1412624
#% 1455666
#! When the number of labeled data is not sufficient, Semi-Supervised Learning (SSL) methods utilize unlabeled data to enhance classification. Recently, many SSL methods have been developed based on the manifold assumption in a batch mode. However, when data arrive sequentially and in large quantities, both computation and storage limitations become a bottleneck. In this paper, we present a new semisupervised coarse graining (CG) algorithm to reduce the required number of data points for preserving the manifold structure. First, an equivalent formulation of Label Propagation (LP) is derived. Then a novel spectral view of the Harmonic Solution (HS) is proposed. Finally an algorithm to reduce the number of data points while preserving the manifold structure is provided and a theoretical analysis on preservation of the LP properties is presented. Experimental results on real world datasets show that the proposed method outperforms the state of the art coarse graining algorithm in different settings.

#index 1617282
#* Learning from partially annotated sequences
#@ Eraldo R. Fernandes;Ulf Brefeld
#t 2011
#c 22
#% 124183
#% 305016
#% 311027
#% 464434
#% 466263
#% 466736
#% 466892
#% 479726
#% 549447
#% 770759
#% 815924
#% 829043
#% 854819
#% 855108
#% 876077
#% 983952
#% 1123966
#% 1164348
#% 1211723
#% 1211836
#% 1260733
#% 1455666
#! We study sequential prediction models in cases where only fragments of the sequences are annotated with the ground-truth. The task does not match the standard semi-supervised setting and is highly relevant in areas such as natural language processing, where completely labeled instances are expensive and require editorial data. We propose to generalize the semi-supervised setting and devise a simple transductive loss-augmented perceptron to learn from inexpensive partially annotated sequences that could for instance be provided by laymen, the wisdom of the crowd, or even automatically. Experiments on mono- and crosslingual named entity recognition tasks with automatically generated partially annotated sentences from Wikipedia demonstrate the effectiveness of the proposed approach. Our results show that learning from partially labeled data is never worse than standard supervised and semi-supervised approaches trained on data with the same ratio of labeled and unlabeled tokens.

#index 1617283
#* The minimum transfer cost principle for model-order selection
#@ Mario Frank;Morteza Haghir Chehreghani;Joachim M. Buhmann
#t 2011
#c 22
#% 577514
#% 763861
#% 765548
#% 1091267
#% 1211811
#% 1428771
#% 1428772
#% 1605918
#% 1856288
#! The goal of model-order selection is to select a model variant that generalizes best from training data to unseen test data. In unsupervised learning without any labels, the computation of the generalization error of a solution poses a conceptual problem which we address in this paper. We formulate the principle of "minimum transfer costs" for model-order selection. This principle renders the concept of cross-validation applicable to unsupervised learning problems. As a substitute for labels, we introduce a mapping between objects of the training set to objects of the test set enabling the transfer of training solutions. Our method is explained and investigated by applying it to well-known problems such as singular-value decomposition, correlation clustering, Gaussian mixturemodels, and k-means clustering. Our principle finds the optimal model complexity in controlled experiments and in real-world problems such as image denoising, role mining and detection of misconfigurations in access-control data.

#index 1617284
#* A geometric approach to find nondominated policies to imprecise reward MDPs
#@ Valdinei Freire da Silva;Anna Helena Reali Costa
#t 2011
#c 22
#% 22348
#% 212297
#% 425080
#% 529348
#% 1269381
#% 1272002
#% 1290265
#% 1291488
#% 1417103
#! Markov Decision Processes (MDPs) provide a mathematical framework for modelling decision-making of agents acting in stochastic environments, in which transitions probabilities model the environment dynamics and a reward function evaluates the agent's behaviour. Lately, however, special attention has been brought to the difficulty of modelling precisely the reward function, which has motivated research on MDP with imprecisely specified reward. Some of these works exploit the use of nondominated policies, which are optimal policies for some instantiation of the imprecise reward function. An algorithm that calculates nondominated policies is π Witness, and nondominated policies are used to take decision under the minimax regret evaluation. An interesting matter would be defining a small subset of nondominated policies so that the minimax regret can be calculated faster, but accurately. We modified π Witness to do so. We also present the π Hull algorithm to calculate nondominated policies adopting a geometric approach. Under the assumption that reward functions are linearly defined on a set of features, we show empirically that pHull can be faster than our modified version of π Witness.

#index 1617285
#* Label noise-tolerant hidden Markov models for segmentation: application to ECGs
#@ Benoît Frénay;Gaël de Lannoy;Michel Verleysen
#t 2011
#c 22
#% 232118
#% 464287
#% 482034
#% 891559
#% 933994
#% 990448
#% 1220043
#! The performance of traditional classification models can adversely be impacted by the presence of label noise in training observations. The pioneer work of Lawrence and Schölkopf tackled this issue in datasets with independent observations by incorporating a statistical noise model within the inference algorithm. In this paper, the specific case of label noise in non-independent observations is rather considered. For this purpose, a label noise-tolerant expectation-maximisation algorithm is proposed in the frame of hidden Markov models. Experiments are carried on both healthy and pathological electrocardiogram signals with distinct types of additional artificial label noise. Results show that the proposed label noise-tolerant inference algorithm can improve the segmentation performances in the presence of label noise.

#index 1617286
#* Building sparse support vector machines for multi-instance classification
#@ Zhouyu Fu;Guojun Lu;Kai Ming Ting;Dengsheng Zhang
#t 2011
#c 22
#% 224755
#% 263850
#% 393059
#% 464633
#% 466597
#% 735256
#% 875969
#% 902511
#% 961154
#% 961188
#% 983950
#% 1267756
#! We propose a direct approach to learning sparse Support Vector Machine (SVM) prediction models for Multi-Instance (MI) classification. The proposed sparse SVM is based on a "label-mean" formulation of MI classification which takes the average of predictions of individual instances for bag-level prediction. This leads to a convex optimization problem, which is essential for the tractability of the optimization problem arising from the sparse SVM formulation we derived subsequently, as well as the validity of the optimization strategy we employed to solve it. Based on the "label-mean" formulation, we can build sparse SVM models for MI classification and explicitly control their sparsities by enforcing the maximum number of expansions allowed in the prediction function. An effective optimization strategy is adopted to solve the formulated sparse learning problem which involves the learning of both the classifier and the expansion vectors. Experimental results on benchmark data sets have demonstrated that the proposed approach is effective in building very sparse SVM models while achieving comparable performance to the state-of-the-art MI classifiers.

#index 1617287
#* Lagrange dual decomposition for finite horizon Markov decision processes
#@ Thomas Furmston;David Barber
#t 2011
#c 22
#% 46437
#% 124687
#% 266287
#% 352664
#% 384911
#% 757953
#% 1765219
#! Solving finite-horizon Markov Decision Processes with stationary policies is a computationally difficult problem. Our dynamic dual decomposition approach uses Lagrange duality to decouple this hard problem into a sequence of tractable sub-problems. The resulting procedure is a straightforward modification of standard non-stationary Markov Decision Process solvers and gives an upper-bound on the total expected reward. The empirical performance of the method suggests that not only is it a rapidly convergent algorithm, but that it also performs favourably compared to standard planning algorithms such as policy gradients and lower-bound procedures such as Expectation Maximisation.

#index 1617288
#* Unsupervised modeling of partially observable environments
#@ Vincent Graziano;Jan Koutník;Jürgen Schmidhuber
#t 2011
#c 22
#% 391311
#% 577966
#% 1034803
#% 1045755
#% 1106592
#% 1616251
#% 1766043
#! We present an architecture based on self-organizing maps for learning a sensory layer in a learning system. The architecture, temporal network for transitions (TNT), enjoys the freedoms of unsupervised learning, works on-line, in non-episodic environments, is computationally light, and scales well. TNT generates a predictive model of its internal representation of the world, making planning methods available for both the exploitation and exploration of the environment. Experiments demonstrate that TNT learns nice representations of classical reinforcement learning mazes of varying size (up to 20 × 20) under conditions of high-noise and stochastic actions.

#index 1617289
#* Tracking concept change with incremental boosting by minimization of the evolving exponential loss
#@ Mihajlo Grbovic;Slobodan Vucetic
#t 2011
#c 22
#% 302391
#% 342636
#% 342639
#% 727880
#% 729932
#% 1214635
#% 1704316
#% 1736165
#! Methods involving ensembles of classifiers, such as bagging and boosting, are popular due to the strong theoretical guarantees for their performance and their superior results. Ensemble methods are typically designed by assuming the training data set is static and completely available at training time. As such, they are not suitable for online and incremental learning. In this paper we propose IBoost, an extension of AdaBoost for incremental learning via optimization of an exponential cost function which changes over time as the training data changes. The resulting algorithm is flexible and allows a user to customize it based on the computational constraints of the particular application. The new algorithm was evaluated on stream learning in presence of concept change. Experimental results showed that IBoost achieves better performance than the original AdaBoost trained from scratch each time the data set changes, and that it also outperforms previously proposed Online Coordinate Boost, Online Boost and its non-stationary modifications, Fast and Light Boosting, ADWIN Online Bagging and DWM algorithms.

#index 1617290
#* Fast and memory-efficient discovery of the top-k relevant subgroups in a reduced candidate space
#@ Henrik Grosskreutz;Daniel Paurat
#t 2011
#c 22
#% 232126
#% 279120
#% 299985
#% 300120
#% 477497
#% 576214
#% 763701
#% 1074357
#% 1108863
#% 1116995
#% 1214686
#% 1267660
#% 1268044
#% 1710157
#! We consider a modified version of the top-k subgroup discovery task, where subgroups dominated by other subgroups are discarded. The advantage of this modified task, known as relevant subgroup discovery, is that it avoids redundancy in the outcome. Although it has been applied in many applications, so far no efficient exact algorithm for this task has been proposed. Most existing solutions do not guarantee the exact solution (as a result of the use of non-admissible heuristics), while the only exact solution relies on the explicit storage of the whole search space, which results in prohibitively large memory requirements. In this paper, we present a new top-k relevant subgroup discovery algorithm which overcomes these shortcomings. Our solution is based on the fact that if an iterative deepening approach is applied, the relevance check - which is the root of the problems of all other approaches - can be realized based solely on the best k subgroups visited so far. The approach also allows for the integration of admissible pruning techniques like optimistic estimate pruning. The result is a fast, memory-efficient algorithm which clearly outperforms existing top-k relevant subgroup discovery approaches. Moreover, we analytically and empirically show that it is competitive with simpler approaches which do not consider the relevance criterion.

#index 1617291
#* Linear discriminant dimensionality reduction
#@ Quanquan Gu;Zhenhui Li;Jiawei Han
#t 2011
#c 22
#% 80995
#% 224113
#% 235342
#% 722929
#% 729437
#% 757953
#% 803567
#% 829010
#% 836827
#% 876025
#% 876058
#% 913838
#% 983907
#% 983940
#% 1117001
#% 1128929
#% 1211747
#% 1270195
#% 1379069
#% 1417091
#% 1535440
#! Fisher criterion has achieved great success in dimensionality reduction. Two representative methods based on Fisher criterion are Fisher Score and Linear Discriminant Analysis (LDA). The former is developed for feature selection while the latter is designed for subspace learning. In the past decade, these two approaches are often studied independently. In this paper, based on the observation that Fisher score and LDA are complementary, we propose to integrate Fisher score and LDA in a unified framework, namely Linear Discriminant Dimensionality Reduction (LDDR). We aim at finding a subset of features, based on which the learnt linear transformation via LDA maximizes the Fisher criterion. LDDR inherits the advantages of Fisher score and LDA and is able to do feature selection and subspace learning simultaneously. Both Fisher score and LDA can be seen as the special cases of the proposed method. The resultant optimization problem is a mixed integer programming, which is difficult to solve. It is relaxed into a L2,1-norm constrained least square problem and solved by accelerated proximal gradient descent algorithm. Experiments on benchmark face recognition data sets illustrate that the proposed method outperforms the state of the art methods arguably.

#index 1617292
#* DB-CSC: a density-based approach for subspace clustering in graphs with feature vectors
#@ Stephan Günnemann;Brigitte Boden;Thomas Seidl
#t 2011
#c 22
#% 248792
#% 464888
#% 727851
#% 823347
#% 914059
#% 1040833
#% 1130918
#% 1165480
#% 1328169
#% 1372657
#% 1535346
#% 1535395
#! Data sources representing attribute information in combination with network information are widely available in today's applications. To realize the full potential for knowledge extraction, mining techniques like clustering should consider both information types simultaneously. Recent clustering approaches combine subspace clustering with dense subgraph mining to identify groups of objects that are similar in subsets of their attributes as well as densely connected within the network. While those approaches successfully circumvent the problem of full-space clustering, their limited cluster definitions are restricted to clusters of certain shapes. In this work, we introduce a density-based cluster definition taking the attribute similarity in subspaces and the graph density into account. This novel cluster model enables us to detect clusters of arbitrary shape and size. We avoid redundancy in the result by selecting only the most interesting non-redundant clusters. Based on this model, we introduce the clustering algorithm DB-CSC. In thorough experiments we demonstrate the strength of DB-CSC in comparison to related approaches.

#index 1617293
#* Learning the parameters of probabilistic logic programs from interpretations
#@ Bernd Gutmann;Ingo Thon;Luc De Raedt
#t 2011
#c 22
#% 3873
#% 333797
#% 379345
#% 850430
#% 923861
#% 1000502
#% 1108865
#% 1108912
#% 1165102
#% 1272388
#% 1275150
#% 1416197
#% 1416205
#% 1467732
#% 1664551
#! ProbLog is a recently introduced probabilistic extension of the logic programming language Prolog, in which facts can be annotated with the probability that they hold. The advantage of this probabilistic language is that it naturally expresses a generative process over interpretations using a declarative model. Interpretations are relational descriptions or possible worlds. This paper introduces a novel parameter estimation algorithm LFI-ProbLog for learning ProbLog programs from partial interpretations. The algorithm is essentially a Soft-EM algorithm. It constructs a propositional logic formula for each interpretation that is used to estimate the marginals of the probabilistic parameters. The LFI-ProbLog algorithm has been experimentally evaluated on a number of data sets that justifies the approach and shows its effectiveness

#index 1617294
#* Feature selection stability assessment based on the Jensen-Shannon divergence
#@ Roberto Guzmán-Martínez;Rocío Alaiz-Rodríguez
#t 2011
#c 22
#% 290482
#% 722929
#% 729437
#% 844279
#% 844309
#% 929722
#% 977991
#% 999695
#% 1041496
#% 1108900
#% 1214678
#% 1374741
#% 1392447
#% 1513075
#! Feature selection and ranking techniques play an important role in the analysis of high-dimensional data. In particular, their stability becomes crucial when the feature importance is later studied in order to better understand the underlying process. The fact that a small change in the dataset may affect the outcome of the feature selection/ranking algorithm has been long overlooked in the literature. We propose an information-theoretic approach, using the Jensen-Shannon divergence to assess this stability (or robustness). Unlike other measures, this new metric is suitable for different algorithm outcomes: full ranked lists, partial sublists (top-k lists) as well as the least studied partial ranked lists. This generalized metric attempts to measure the disagreement among a whole set of lists with the same size, following a probabilistic approach and being able to give more importance to the differences that appear at the top of the list. We illustrate and compare it with popular metrics like the Spearman rank correlation and the Kuncheva's index on feature selection/ ranking outcomes artificially generated and on an spectral fat dataset with different filter-based feature selectors.

#index 1617295
#* Mining actionable partial orders in collections of sequences
#@ Robert Gwadera;Gianluca Antonini;Abderrahim Labbi
#t 2011
#c 22
#% 159016
#% 310515
#% 413624
#% 463903
#% 727902
#% 778732
#% 785333
#% 902449
#% 985041
#% 1737787
#! Mining frequent partial orders from a collection of sequences was introduced as an alternative to mining frequent sequential patterns in order to provide a more compact/understandable representation. The motivation was that a single partial order can represent the same ordering information between items in the collection as a set of sequential patterns (set of totally ordered sets of items). However, in practice, a discovered set of frequent partial orders is still too large for an effective usage. We address this problem by proposing a method for ranking partial orders with respect to significance that extends our previous work on ranking sequential patterns. In experiments, conducted on a collection of visits to a website of a multinational technology and consulting firm we show the applicability of our framework to discover partial orders of frequently visited webpages that can be actionable in optimizing effectiveness of web-based marketing.

#index 1617296
#* A game theoretic framework for data privacy preservation in recommender systems
#@ Maria Halkidi;Iordanis Koutsopoulos
#t 2011
#c 22
#% 173879
#% 220709
#% 301259
#% 330687
#% 452563
#% 567950
#% 578684
#% 616944
#% 727866
#% 767656
#% 1000451
#% 1001277
#% 1001278
#% 1287239
#% 1358747
#! We address the fundamental tradeoff between privacy preservation and high-quality recommendation stemming from a third party. Multiple users submit their ratings to a third party about items they have viewed. The third party aggregates the ratings and generates personalized recommendations for each user. The quality of recommendations for each user depends on submitted rating profiles from all users, including the user to which the recommendation is destined. Each user would like to declare a rating profile so as to preserve data privacy as much as possible, while not causing deterioration in the quality of the recommendation he would get, compared to the one he would get if he revealed his true private profile. We employ game theory to model and study the interaction of users and we derive conditions and expressions for the Nash Equilibrium Point (NEP). This consists of the rating strategy of each user, such that no user can benefit in terms of improving its privacy by unilaterally deviating from that point. User strategies converge to the NEP after an iterative best-response strategy update. For a hybrid recommendation system, we find that the NEP strategy for each user in terms of privacy preservation is to declare false rating only for one item, the one that is highly ranked in his private profile and less correlated with items for which he anticipates recommendation. We also present various modes of cooperation by which users can mutually benefit.

#index 1617297
#* Proceedings of the 2011 European conference on Machine learning and knowledge discovery in databases - Volume Part II
#@ Dimitrios Gunopulos;Thomas Hofmann;Donato Malerba;Michalis Vazirgiannis
#t 2011
#c 22

#index 1617298
#* Common substructure learning of multiple graphical Gaussian models
#@ Satoshi Hara;Takashi Washio
#t 2011
#c 22
#% 236497
#% 397854
#% 1074353
#% 1074378
#% 1184963
#! Learning underlying mechanisms of data generation is of great interest in the scientific and engineering fields amongst others. Finding dependency structures among variables in the data is one possible approach for the purpose, and is an important task in data mining. In this paper, we focus on learning dependency substructures shared by multiple datasets. In many scenarios, the nature of data varies due to a change in the surrounding conditions or non-stationary mechanisms over the multiple datasets. However, we can also assume that the change occurs only partially and some relations between variables remain unchanged. Moreover, we can expect that such commonness over the multiple datasets is closely related to the invariance of the underlying mechanism. For example, errors in engineering systems are usually caused by faults in the sub-systems with the other parts remaining healthy. In such situations, though anomalies are observed in sensor values, the underlying invariance of the healthy sub-systems is still captured by some steady dependency structures before and after the onset of the error. We propose a structure learning algorithm to find such invariances in the case of Graphical Gaussian Models (GGM). The proposed method is based on a block coordinate descent optimization, where subproblems can be solved efficiently by existing algorithms for Lasso and the continuous quadratic knapsack problem. We confirm the validity of our approach through numerical simulations and also in applications with real world datasets extracted from the analysis of city-cycle fuel consumption and anomaly detection in car sensors.

#index 1617299
#* Mining research topic-related influence between academia and industry
#@ Dan He
#t 2011
#c 22
#% 342596
#% 729923
#% 789957
#% 989613
#% 1034723
#% 1107420
#% 1214641
#% 1214702
#% 1355040
#% 1810385
#! Recently the problem of mining social influence has attracted lots of attention. Given a social network, researchers are interested in problems such as how influence, ideas, information propagate in the network. Similar problems have been proposed on co-authorship networks where the goal is to differentiate the social influences on research topic level and quantify the strength of the influence. In this work, we are interested in the problem of mining topic-specific influence between academia and industry. More specifically, given a coauthorship network, we want to identify which academia researcher is most influential to a given company on specific research topics. Given pairwise influences between researchers, we propose three models (simple additive model, weighted additive model and clustering-based additive model) to evaluate how influential a researcher is to a company. Finally, we illustrate the effectiveness of these three models on real large data set as well as on simulated data set.

#index 1617300
#* Typology of mixed-membership models: towards a design method
#@ Gregor Heinrich
#t 2011
#c 22
#% 722904
#% 722927
#% 788094
#% 876017
#% 881534
#% 915330
#% 983883
#% 1055682
#% 1166510
#% 1268066
#% 1270334
#% 1432490
#! Presents an analysis of the structure of mixed-membership models into elementary blocks and their numerical properties. By associating such model structures with structures known or assumed in the data, we propose how models can be constructed in a controlled way, using the numerical properties of data likelihood and Gibbs full conditionals as predictors of model behavior. To illustrate this "bottom-up" design method, example models are constructed that may be used for expertise finding from labeled data.

#index 1617301
#* ShiftTree: an interpretable model-based approach for time series classification
#@ Balázs Hidasi;Csaba Gáspár-Papanek
#t 2011
#c 22
#% 172949
#% 235377
#% 394543
#% 659971
#% 795273
#% 810049
#% 835927
#% 1016195
#% 1023803
#% 1127609
#! Efficient algorithms of time series data mining have the common denominator of utilizing the special time structure of the attributes of time series. To accommodate the information of time dimension into the process, we propose a novel instance-level cursor based indexing technique, which is combined with a decision tree algorithm. This is beneficial for several reasons: (a) it is insensitive to the time level noise (for example rendering, time shifting), (b) its working method can be interpreted, making the explanation of the classification process more understandable, and (c) it can manage time series of different length. The implemented algorithm named ShiftTree is compared to the well-known instance-based time series classifier 1-NN using different distance metrics, used over all 20 datasets of a public benchmark time series database and two more public time series datasets. On these benchmark datasets, our experiments show that the new model-based algorithm has an average accuracy slightly better than the most efficient instance-based methods, and there are multiple datasets where our model-based classifier exceeds the accuracy of instance-based methods. We also evaluated our algorithm via blind testing on the 20 datasets of the SIGKDD 2007 Time Series Classification Challenge. To improve the model accuracy and to avoid model overfitting, we provide forest methods as well.

#index 1617302
#* Image classification for age-related macular degeneration screening using hierarchical image decompositions and graph mining
#@ Mohd Hanafi Ahmad Hijazi;Chuntao Jiang;Frans Coenen;Yalin Zheng
#t 2011
#c 22
#% 197394
#% 318051
#% 629708
#% 926881
#% 1055417
#% 1073923
#% 1117691
#% 1338864
#% 1350625
#% 1395502
#% 1489127
#% 1558464
#! Age-related Macular Degeneration (AMD) is the most common cause of adult blindness in the developed world. This paper describes a new image mining technique to perform automated detection of AMD from colour fundus photographs. The technique comprises a novel hierarchical image decomposition mechanism founded on a circular and angular partitioning. The resulting decomposition is then stored in a tree structure to which a weighted frequent sub-tree mining algorithm is applied. The identified sub-graphs are then incorporated into a feature vector representation (one vector per image) to which classification techniques can be applied. The results show that the proposed approach performs both efficiently and accurately.

#index 1617303
#* Online structure learning for Markov logic networks
#@ Tuyen N. Huynh;Raymond J. Mooney
#t 2011
#c 22
#% 26722
#% 226495
#% 271128
#% 464434
#% 568786
#% 770763
#% 840890
#% 850430
#% 939377
#% 983882
#% 1000502
#% 1108078
#% 1108080
#% 1211753
#% 1249506
#% 1267762
#% 1268069
#% 1269766
#% 1269815
#% 1344869
#% 1451169
#% 1467732
#% 1478466
#% 1673026
#% 1699637
#! Most existing learning methods for Markov Logic Networks (MLNs) use batch training, which becomes computationally expensive and eventually infeasible for large datasets with thousands of training examples which may not even all fit in main memory. To address this issue, previous work has used online learning to train MLNs. However, they all assume that the model's structure (set of logical clauses) is given, and only learn the model's parameters. However, the input structure is usually incomplete, so it should also be updated. In this work, we present OSL--the first algorithm that performs both online structure and parameter learning for MLNs. Experimental results on two realworld datasets for natural-language field segmentation show that OSL outperforms systems that cannot revise structure.

#index 1617304
#* Fourier-information duality in the identity management problem
#@ Xiaoye Jiang;Jonathan Huang;Leonidas Guibas
#t 2011
#c 22
#% 338460
#% 342659
#% 729918
#% 879237
#% 1039652
#% 1171563
#% 1232043
#% 1394376
#! We compare two recently proposed approaches for representing probability distributions over the space of permutations in the context of multi-target tracking. We show that these two representations, the Fourier approximation and the information form approximation can both be viewed as low dimensional projections of a true distribution, but with respect to different metrics. We identify the strengths and weaknesses of each approximation, and propose an algorithm for converting between the two forms, allowing for a hybrid approach that draws on the strengths of both representations. We show experimental evidence that there are situations where hybrid algorithms are favorable.

#index 1617305
#* Eigenvector sensitive feature selection for spectral clustering
#@ Yi Jiang;Jiangtao Ren
#t 2011
#c 22
#% 51749
#% 310561
#% 313959
#% 318390
#% 341596
#% 345824
#% 452881
#% 466414
#% 580509
#% 771842
#% 772864
#% 793239
#% 800188
#% 983948
#% 989586
#% 995140
#% 1002473
#% 1036909
#% 1073891
#% 1083630
#% 1211700
#% 1214712
#% 1249141
#% 1270195
#% 1451172
#% 1451196
#! Spectral clustering is one of the most popular methods for data clustering, and its performance is determined by the quality of the eigenvectors of the related graph Laplacian. Generally, graph Laplacian is constructed using the full features, which will degrade the quality of the related eigenvectors when there are a large number of noisy or irrelevant features in datasets. To solve this problem, we propose a novel unsupervised feature selection method inspired by perturbation analysis theory, which discusses the relationship between the perturbation of the eigenvectors of a matrix and its elements' perturbation. We evaluate the importance of each feature based on the average L1 norm of the perturbation of the first k eigenvectors of graph Laplacian corresponding to the k smallest positive eigenvalues, with respect to the feature's perturbation. Extensive experiments on several high-dimensional multi-class datasets demonstrate the good performance of our method compared with some state-of-the-art unsupervised feature selection methods.

#index 1617306
#* Restricted deep belief networks for multi-view learning
#@ Yoonseop Kang;Seungjin Choi
#t 2011
#c 22
#% 92145
#% 252011
#% 450888
#% 891060
#% 1071116
#% 1270086
#% 1302905
#% 1502411
#! Deep belief network (DBN) is a probabilistic generative model with multiple layers of hidden nodes and a layer of visible nodes, where parameterizations between layers obey harmonium or restricted Boltzmann machines (RBMs). In this paper we present restricted deep belief network (RDBN) for multi-view learning, where each layer of hidden nodes is composed of view-specific and shared hidden nodes, in order to learn individual and shared hidden spaces from multiple views of data. View-specific hidden nodes are connected to corresponding view-specific hidden nodes in the lower-layer or visible nodes involving a specific view, whereas shared hidden nodes follow inter-layer connections without restrictions as in standard DBNs. RDBN is trained using layer-wise contrastive divergence learning. Numerical experiments on synthetic and real-world datasets demonstrate the useful behavior of the RDBN, compared to the multi-wing harmonium (MWH) which is a two-layer undirected model.

#index 1617307
#* Motion segmentation by model-based clustering of incomplete trajectories
#@ Vasileios Karavasilis;Konstantinos Blekas;Christophoros Nikou
#t 2011
#c 22
#% 206584
#% 266616
#% 578409
#% 722760
#% 760805
#% 775138
#% 777219
#% 784984
#% 853308
#% 1096723
#% 1165532
#% 1169839
#% 1209707
#% 1272808
#% 1327711
#% 1482800
#% 1501190
#% 1505015
#% 1557580
#% 1562549
#% 1667668
#% 1735572
#% 1781990
#! In this paper, we present a framework for visual object tracking based on clustering trajectories of image key points extracted from a video. The main contribution of our method is that the trajectories are automatically extracted from the video sequence and they are provided directly to a model-based clustering approach. In most other methodologies, the latter constitutes a difficult part since the resulting feature trajectories have a short duration, as the key points disappear and reappear due to occlusion, illumination, viewpoint changes and noise. We present here a sparse, translation invariant regression mixture model for clustering trajectories of variable length. The overall scheme is converted into a Maximum A Posteriori approach, where the Expectation-Maximization (EM) algorithm is used for estimating the model parameters. The proposed method detects the different objects in the input image sequence by assigning each trajectory to a cluster, and simultaneously provides the motion of all objects. Numerical results demonstrate the ability of the proposed method to offer more accurate and robust solution in comparison with the mean shift tracker, especially in cases of occlusions.

#index 1617308
#* PTMSearch: a greedy tree traversal algorithm for finding protein post-translational modifications in tandem mass spectra
#@ Attila Kertész-Farkas;Beáta Reiz;Michael P. Myers;Sándor Pongor
#t 2011
#c 22
#% 252608
#% 832642
#! Peptide identification by tandem mass spectrometry (MS/MS) and database searching is becoming the standard high-throughput technology in many areas of the life sciences. The analysis of post-translational modifications (PTMs) is a major source of complications in this area, which calls for efficient computational approaches. In this paper we describe PTMSearch, a novel algorithm in which the PTM search space is represented by a tree structure, and a greedy traversal algorithm is used to identify a path within the tree that corresponds to the PTMs that best fit the input data. Tests on simulated and real (experimental) PTMs show that the algorithm performs well in terms of speed and accuracy. Estimates are given for the error caused by the greedy heuristics, for the size of the search space and a scheme is presented for the calculation of statistical significance.

#index 1617309
#* Efficient mining of top correlated patterns based on null-invariant measures
#@ Sangkyum Kim;Marina Barsky;Jiawei Han
#t 2011
#c 22
#% 152934
#% 227919
#% 452846
#% 481758
#% 577214
#% 727869
#% 818916
#% 824710
#% 835018
#% 1318601
#% 1318691
#% 1465175
#% 1503467
#! Mining strong correlations from transactional databases often leads to more meaningful results than mining association rules. In such mining, null (transaction)-invariance is an important property of the correlation measures. Unfortunately, some useful null-invariant measures such as Kulczynski and Cosine, which can discover correlations even for the very unbalanced cases, lack the (anti)-monotonicity property. Thus, they could only be applied to frequent itemsets as the post-evaluation step. For large datasets and for low supports, this approach is computationally prohibitive. This paper presents new properties for all known null-invariant measures. Based on these properties, we develop efficient pruning techniques and design the Apriori-like algorithm NICOMINER for mining strongly correlated patterns directly. We develop both the threshold-bounded and the top-k variations of the algorithm, where top-k is used when the optimal correlation threshold is not known in advance and to give user control over the output size. We test NICOMINER on real-life datasets from different application domains, using Cosine as an example of the null-invariant correlation measure. We show that NICOMINER outperforms support-based approach more than an order of magnitude, and that it is very useful for discovering top correlations in itemsets with low support.

#index 1617310
#* Smooth receiver operating characteristics (smROC) curves
#@ William Klement;Peter Flach;Nathalie Japkowicz;Stan Matwin
#t 2011
#c 22
#% 580510
#% 642988
#% 770761
#% 810947
#% 889276
#% 976824
#% 1077628
#% 1100083
#% 1389694
#% 1699624
#! Supervised learning algorithms perform common tasks including classification, ranking, scoring, and probability estimation. We investigate how scoring information, often produced by these models, is utilized by an evaluation measure. The ROC curve represents a visualization of the ranking performance of classifiers. However, they ignore the scores which can be quite informative. While this ignored information is less precise than that given by probabilities, it is much more detailed than that conveyed by ranking. This paper presents a novel method to weight the ROC curve by these scores. We call it the Smooth ROC (smROC) curve, and we demonstrate how it can be used to visualize the performance of learning models. We report experimental results to show that the smROC is appropriate for measuring performance similarities and differences between learning models, and is more sensitive to performance characteristics than the standard ROC curve.

#index 1617311
#* A boosting approach to multiview classification with cooperation
#@ Sokol Koço;Cécile Capponi
#t 2011
#c 22
#% 252011
#% 451221
#% 763697
#% 839912
#% 840066
#% 1073994
#% 1100932
#% 1182512
#% 1211734
#% 1230115
#% 1312908
#% 1431728
#% 1442436
#% 1528860
#! In many fields, such as bioinformatics or multimedia, data may be described using different sets of features (or views) which carry either global or local information. Some learning tasks make use of these several views in order to improve overall predictive power of classifiers through fusion-based methods. Usually, these approaches rely on a weighted combination of classifiers (or selected descriptions), where classifiers are learned independently. One drawback of these methods is that the classifier learned on one view does not communicate its failures within the other views. This paper deals with a novel approach to integrate multiview information. The proposed algorithm, named Mumbo, is based on boosting. Within the boosting scheme, Mumbo maintains one distribution of examples on each view, and at each round, it learns one weak classifier on each view. Within a view, the distribution of examples evolves both with the ability of the dedicated classifier to deal with examples of the corresponding features space, and with the ability of classifiers in other views to process the same examples within their own description spaces. Hence, the principle is to slightly remove the hard examples from the learning space of one view, while their weights get higher in the other views. This way, we expect that examples are urged to be processed by the most appropriate views, when possible. At the end of the iterative learning process, a final classifier is computed by a weighted combination of selected weak classifiers. This paper provides the Mumbo algorithm in a multiclass and multiview setting, based on recent theoretical advances in boosting. The boosting properties of Mumbo are proved, as well as some results on its generalization capabilities. Several experimental results are reported which point out that complementary views may actually cooperate under some assumptions.

#index 1617312
#* ARTEMIS: assessing the similarity of event-interval sequences
#@ Orestis Kostakis;Panagiotis Papapetrou;Jaakko Hollmén
#t 2011
#c 22
#% 300474
#% 313891
#% 319244
#% 421117
#% 477952
#% 478455
#% 487661
#% 536183
#% 549584
#% 728289
#% 749040
#% 844326
#% 878302
#% 972352
#% 975048
#% 980988
#% 998859
#% 1063499
#% 1112745
#% 1310498
#% 1477781
#% 1708558
#! In several application domains, such as sign language, medicine, and sensor networks, events are not necessarily instantaneous but they can have a time duration. Sequences of interval-based events may contain useful domain knowledge; thus, searching, indexing, and mining such sequences is crucial. We introduce two distance measures for comparing sequences of interval-based events which can be used for several data mining tasks such as classification and clustering. The first measure maps each sequence of interval-based events to a set of vectors that hold information about all concurrent events. These sets are then compared using an existing dynamic programming method. The second method, called Artemis, finds correspondence between intervals by mapping the two sequences into a bipartite graph. Similarity is inferred by employing the Hungarian algorithm. In addition, we present a linear-time lowerbound for Artemis. The performance of both measures is tested on data from three domains: sign language, medicine, and sensor networks. Experiments show the superiority of Artemis in terms of robustness to high levels of artificially introduced noise.

#index 1617313
#* Unifying guilt-by-association approaches: theorems and fast algorithms
#@ Danai Koutra;Tai-You Ke;U. Kang;Duen Horng Chau;Hsing-Kuo Kenneth Pao;Christos Faloutsos
#t 2011
#c 22
#% 268079
#% 580307
#% 641979
#% 784963
#% 857454
#% 871631
#% 881480
#% 915344
#% 956513
#% 961206
#% 1040831
#% 1214748
#% 1318636
#% 1495579
#% 1594624
#% 1673564
#% 1810385
#% 1815596
#! If several friends of Smith have committed petty thefts, what would you say about Smith? Most people would not be surprised if Smith is a hardened criminal. Guilt-by-association methods combine weak signals to derive stronger ones, and have been extensively used for anomaly detection and classification in numerous settings (e.g., accounting fraud, cyber-security, calling-card fraud). The focus of this paper is to compare and contrast several very successful, guilt-by-association methods: Random Walk with Restarts, Semi-Supervised Learning, and Belief Propagation (BP). Our main contributions are two-fold: (a) theoretically, we prove that all the methods result in a similar matrix inversion problem; (b) for practical applications, we developed FaBP, a fast algorithm that yields 2× speedup, equal or higher accuracy than BP, and is guaranteed to converge. We demonstrate these benefits using synthetic and real datasets, including YahooWeb, one of the largest graphs ever studied with BP.

#index 1617314
#* Online clustering of high-dimensional trajectories under concept drift
#@ Georg Krempl;Zaigham Faraz Siddiqui;Myra Spiliopoulou
#t 2011
#c 22
#% 280416
#% 310512
#% 677787
#% 729917
#% 775138
#% 874860
#% 1077150
#% 1268274
#! Historical transaction data are collected in many applications, e.g., patient histories recorded by physicians and customer transactions collected by companies. An important question is the learning of models upon the primary objects (patients, customers) rather than the transactions, especially when these models are subjected to drift. We address this problem by combining advances of online clustering on multivariate data with the trajectory mining paradigm. We model the measurements of each individual primary object (e.g. its transactions), taken at irregular time intervals, as a trajectory in a high-dimensional feature space. Then, we cluster individuals with similar trajectories to identify sub-populations that evolve similarly, e.g. groups of customers that evolve similarly or groups of employees that have similar careers. We assume that the multivariate trajectories are generated by drifting Gaussian Mixture Models. We study (i) an EM-based approach that clusters these trajectories incrementally as a reference method that has access to all the data for learning, and propose (ii) an online algorithm based on a Kalman filter that efficiently tracks the trajectories of Gaussian clusters. We show that while both methods approximate the reference well, the algorithm based on a Kalman filter is faster by one order of magnitude compared to the EM-based approach.

#index 1617315
#* Gaussian logic for predictive classification
#@ Ondřej Kuželka;Andrea Szabóová;Matěj Holec;Filip Železný
#t 2011
#c 22
#% 993437
#% 1153358
#% 1199639
#% 1211744
#% 1270263
#% 1416201
#% 1565708
#! We describe a statistical relational learning framework called Gaussian Logic capable to work efficiently with combinations of relational and numerical data. The framework assumes that, for a fixed relational structure, the numerical data can be modelled by a multivariate normal distribution. We demonstrate how the Gaussian Logic framework can be applied to predictive classification problems. In experiments, we first show an application of the framework for the prediction of DNAbinding propensity of proteins. Next, we show how the Gaussian Logic framework can be used to find motifs describing highly correlated gene groups in gene-expression data which are then used in a set-level-based classification method.

#index 1617316
#* Toward a fair review-management system
#@ Theodoros Lappas;Evimaria Terzi
#t 2011
#c 22
#% 152934
#% 190611
#% 197754
#% 727835
#% 769892
#% 878935
#% 907489
#% 907490
#% 939896
#% 1035590
#% 1054889
#% 1074124
#% 1250237
#% 1261574
#% 1261576
#% 1400002
#% 1495595
#% 1605931
#! Item reviews are a valuable source of information for potential buyers, who are looking for information on a product's attributes before making a purchase decision. This search of information is often hindered by overwhelming numbers of available reviews, as well as low-quality and noisy content. While a significant amount of research has been devoted to filtering and organizing review corpora toward the benefit of the buyers, a crucial part of the reviewing process has been overlooked: reviewer satisfaction. As in every content-based system, the content-generators, in this case the reviewers, serve as the driving force. Therefore, keeping the reviewers satisfied and motivated to continue submitting high-quality content is essential. In this paper, we propose a system that helps potential buyers by focusing on high-quality and informative reviews, while keeping reviewers content and motivated.

#index 1617317
#* Focused multi-task learning using gaussian processes
#@ Gayle Leen;Jaakko Peltonen;Samuel Kaski
#t 2011
#c 22
#% 236497
#% 528330
#% 770858
#% 916788
#% 961246
#% 1073879
#% 1464068
#! Given a learning task for a data set, learning it together with related tasks (data sets) can improve performance. Gaussian process models have been applied to such multi-task learning scenarios, based on joint priors for functions underlying the tasks. In previous Gaussian process approaches, all tasks have been assumed to be of equal importance, whereas in transfer learning the goal is asymmetric: to enhance performance on a target task given all other tasks. In both settings, transfer learning and joint modelling, negative transfer is a key problem: performance may actually decrease if the tasks are not related closely enough. In this paper, we propose aGaussian processmodel for the asymmetric setting, which learns to "explain away" non-related variation in the additional tasks, in order to focus on improving performance on the target task. In experiments, our model improves performance compared to single-task learning, symmetric multi-task learning using hierarchical Dirichlet processes, and transfer learning based on predictive structure learning.

#index 1617318
#* Reinforcement learning through global stochastic search in N-MDPs
#@ Matteo Leonetti;Luca Iocchi;Subramanian Ramamoorthy
#t 2011
#c 22
#% 171032
#% 203602
#% 384911
#% 465926
#% 466069
#% 564257
#% 576218
#% 578686
#% 810929
#% 1024713
#% 1215603
#% 1272385
#% 1453139
#% 1730056
#! Reinforcement Learning (RL) in either fully or partially observable domains usually poses a requirement on the knowledge representation in order to be sound: the underlying stochastic process must be Markovian. In many applications, including those involving interactions between multiple agents (e.g., humans and robots), sources of uncertainty affect rewards and transition dynamics in such a way that a Markovian representation would be computationally very expensive. An alternative formulation of the decision problem involves partially specified behaviors with choice points. While this reduces the complexity of the policy space that must be explored - something that is crucial for realistic autonomous agents that must bound search time - it does render the domain Non-Markovian. In this paper, we present a novel algorithm for reinforcement learning in Non-Markovian domains. Our algorithm, Stochastic Search Monte Carlo, performs a global stochastic search in policy space, shaping the distribution from which the next policy is selected by estimating an upper bound on the value of each action. We experimentally show how, in challenging domains for RL, high-level decisions in Non-Markovian processes can lead to a behavior that is at least as good as the one learned by traditional algorithms, and can be achieved with significantly fewer samples.

#index 1617319
#* Analyzing word frequencies in large text corpora using inter-arrival times and bootstrapping
#@ Jefrey Lijffijt;Panagiotis Papapetrou;Kai Puolamäki;Heikki Mannila
#t 2011
#c 22
#% 169781
#% 283833
#% 387427
#% 643520
#% 740900
#% 765412
#% 797693
#% 824666
#% 937549
#% 987218
#% 1117049
#% 1214669
#% 1256692
#! Comparing frequency counts over texts or corpora is an important task in many applications and scientific disciplines. Given a text corpus, we want to test a hypothesis, such as "word X is frequent", "word X has become more frequent over time", or "word X is more frequent in male than in female speech". For this purpose we need a null model of word frequencies. The commonly used bag-of-words model, which corresponds to a Bernoulli process with fixed parameter, does not account for any structure present in natural languages. Using this model for word frequencies results in large numbers of words being reported as unexpectedly frequent. We address how to take into account the inherent occurrence patterns of words in significance testing of word frequencies. Based on studies of words in two large corpora, we propose two methods for modeling word frequencies that both take into account the occurrence patterns of words and go beyond the bag-of-words assumption. The first method models word frequencies based on the spatial distribution of individual words in the language. The second method is based on bootstrapping and takes into account only word frequency at the text level. The proposed methods are compared to the current gold standard in a series of experiments on both corpora. We find that words obey different spatial patterns in the language, ranging from bursty to non-bursty/uniform, independent of their frequency, showing that the traditional approach leads to many false positives.

#index 1617320
#* Discovering temporal bisociations for linking concepts over time
#@ Corrado Loglisci;Michelangelo Ceci
#t 2011
#c 22
#% 406493
#% 723403
#% 1117013
#% 1182818
#% 1200861
#% 1254264
#% 1328556
#% 1411031
#% 1726656
#! Bisociations represent interesting relationships between seemingly unconnected concepts from two or more contexts. Most of the existing approaches that permit the discovery of bisociations from data rely on the assumption that contexts are static or considered as unchangeable domains. Actually, several real-world domains are intrinsically dynamic and can change over time. The same domain can change and can become completely different from what/how it was before: a dynamic domain observed at different time-points can present different representations and can be reasonably assimilated to a series of distinct static domains. In this work, we investigate the task of linking concepts from a dynamic domain through the discovery of bisociations which link concepts over time. This provides us with a means to unearth linkages which have not been discovered when observing the domain as static, but which may have developed over time, when considering the dynamic nature. We propose a computational solution which, assuming a time interval-based discretization of the domain, explores the spaces of association rules mined in the intervals and chains the rules on the basis of the concept generalization and information theory criteria. The application to the literature-based discovery shows how the method can rediscover known connections in biomedical terminology. Experiments and comparisons using alternative techniques highlight the additional peculiarities of this work.

#index 1617321
#* Minimum neighbor distance estimators of intrinsic dimension
#@ Gabriele Lombardi;Alessandro Rozza;Claudio Ceruti;Elena Casiraghi;Paola Campadelli
#t 2011
#c 22
#% 181240
#% 444020
#% 840871
#% 983837
#% 1010658
#% 1386110
#% 1759699
#! Most of the machine learning techniques suffer the "curse of dimensionality" effect when applied to high dimensional data. To face this limitation, a common preprocessing step consists in employing a dimensionality reduction technique. In literature, a great deal of research work has been devoted to the development of algorithms performing this task. Often, these techniques require as parameter the number of dimensions to be retained; to this aim, they need to estimate the "intrinsic dimensionality" of the given dataset, which refers to the minimum number of degrees of freedom needed to capture all the information carried by the data. Although many estimation techniques have been proposed, most of them fail in case of noisy data or when the intrinsic dimensionality is too high. In this paper we present a family of estimators based on the probability density function of the normalized nearest neighbor distance. We evaluate the proposed techniques on both synthetic and real datasets comparing their performances with those obtained by state of the art algorithms; the achieved results prove that the proposed methods are promising.

#index 1617322
#* Graph evolution via social diffusion processes
#@ Dijun Luo;Chris Ding;Heng Huang
#t 2011
#c 22
#% 148149
#% 303620
#% 342626
#% 592143
#% 593047
#% 1038867
#% 1310058
#! We present a new stochastic process, called as Social Diffusion Process (SDP), to address the graph modeling. Based on this model, we derive a graph evolution algorithm and a series of graphbased approaches to solve machine learning problems, including clustering and semi-supervised learning. SDP can be viewed as a special case of Matthew effect, which is a general phenomenon in nature and societies. We use social event as a metaphor of the intrinsic stochastic process for broad range of data. We evaluate our approaches in a large number of frequently used datasets and compare our approaches to other state-of-the-art techniques. Results show that our algorithm outperforms the existing methods in most cases. We also applying our algorithm into the functionality analysis of microRNA and discover biologically interesting cliques. Due to the broad availability of graph-based data, our new model and algorithm potentially have applications in wide range.

#index 1617323
#* Multi-subspace representation and discovery
#@ Dijun Luo;Feiping Nie;Chris Ding;Heng Huang
#t 2011
#c 22
#% 313959
#% 840839
#% 981513
#% 1164188
#% 1305478
#% 1535440
#! This paper presents the multi-subspace discovery problem and provides a theoretical solution which is guaranteed to recover the number of subspaces, the dimensions of each subspace, and the members of data points of each subspace simultaneously. We further propose a data representation model to handle noisy real world data. We develop a novel optimization approach to learn the presented model which is guaranteed to converge to global optimizers. As applications of our models, we first apply our solutions as preprocessing in a series of machine learning problems, including clustering, classification, and semisupervised learning. We found that our method automatically obtains robust data presentation which preserves the affine subspace structures of high dimensional data and generate more accurate results in the learning tasks. We also establish a robust standalone classifier which directly utilizes our sparse and low rank representation model. Experimental results indicate our methods improve the quality of data by preprocessing and the standalone classifier outperforms some state-of-the-art learning approaches.

#index 1617324
#* A novel stability based feature selection framework for k-means clustering
#@ Dimitrios Mavroeidis;Elena Marchiori
#t 2011
#c 22
#% 342621
#% 770830
#% 916789
#% 977991
#% 983826
#% 1083713
#% 1100062
#% 1108900
#% 1214678
#% 1267764
#% 1451172
#% 1535409
#! Stability of a learning algorithm with respect to small input perturbations is an important property, as it implies the derived models to be robust with respect to the presence of noisy features and/or data sample fluctuations. In this paper we explore the effect of stability optimization in the standard feature selection process for the continuous (PCA-based) k-means clustering problem. Interestingly, we derive that stability maximization naturally introduces a tradeoff between cluster separation and variance, leading to the selection of features that have a high cluster separation index that is not artificially inflated by the feature's variance. The proposed algorithmic setup is based on a Sparse PCA approach, that selects the features that maximize stability in a greedy fashion. In our study, we also analyze several properties of Sparse PCA relevant to stability that promote Sparse PCA as a viable feature selection mechanism for clustering. The practical relevance of the proposed method is demonstrated in the context of cancer research, where we consider the problem of detecting potential tumor biomarkers using microarray gene expression data. The application of our method to a leukemia dataset shows that the tradeoff between cluster separation and variance leads to the selection of features corresponding to important biomarker genes. Some of them have relative low variance and are not detected without the direct optimization of stability in Sparse PCA based k-means.

#index 1617325
#* Link prediction via matrix factorization
#@ Aditya Krishna Menon;Charles Elkan
#t 2011
#c 22
#% 304908
#% 397155
#% 577224
#% 765519
#% 809424
#% 833012
#% 833069
#% 987253
#% 1117026
#% 1190124
#% 1214623
#% 1260273
#% 1417104
#% 1451163
#% 1495565
#% 1496779
#% 1524266
#% 1535399
#% 1535441
#% 1560408
#! We propose to solve the link prediction problem in graphs using a supervised matrix factorization approach. The model learns latent features from the topological structure of a (possibly directed) graph, and is shown to make better predictions than popular unsupervised scores. We show how these latent features may be combined with optional explicit features for nodes or edges, which yields better performance than using either type of feature exclusively. Finally, we propose a novel approach to address the class imbalance problem which is common in link prediction by directly optimizing for a ranking loss. Our model is optimized with stochastic gradient descent and scales to large graphs. Results on several datasets show the efficacy of our approach.

#index 1617326
#* On oblique random forests
#@ Bjoern H. Menze;B. Michael Kelm;Daniel N. Splitthoff;Ullrich Koethe;Fred A. Hamprecht
#t 2011
#c 22
#% 209021
#% 256615
#% 312727
#% 400847
#% 520224
#% 833906
#% 836876
#% 866298
#% 889165
#% 1015775
#% 1108900
#% 1117696
#% 1164190
#% 1232011
#% 1272358
#% 1385952
#% 1464115
#% 1496775
#% 1656971
#% 1712965
#% 1750372
#! In his original paper on random forests, Breiman proposed two different decision tree ensembles: one generated from "orthogonal" trees with thresholds on individual features in every split, and one from "oblique" trees separating the feature space by randomly oriented hyperplanes. In spite of a rising interest in the random forest framework, however, ensembles built from orthogonal trees (RF) have gained most, if not all, attention so far. In the present work we propose to employ "oblique" random forests (oRF) built from multivariate trees which explicitly learn optimal split directions at internal nodes using linear discriminative models, rather than using random coefficients as the original oRF. This oRF outperforms RF, as well as other classifiers, on nearly all data sets but those with discrete factorial features. Learned node models perform distinctively better than random splits. An oRF feature importance score shows to be preferable over standard RF feature importance scores such as Gini or permutation importance. The topology of the oRF decision space appears to be smoother and better adapted to the data, resulting in improved generalization performance. Overall, the oRF propose here may be preferred over standard RF on most learning tasks involving numerical and spectral data.

#index 1617327
#* An alternating direction method for dual MAP LP relaxation
#@ Ofer Meshi;Amir Globerson
#t 2011
#c 22
#% 137448
#% 803567
#% 889176
#% 961201
#% 975169
#% 1073906
#% 1073972
#% 1148309
#% 1166535
#% 1276038
#% 1470674
#% 1481259
#% 1481536
#% 1524578
#% 1537110
#! Maximum a-posteriori (MAP) estimation is an important task in many applications of probabilistic graphical models. Although finding an exact solution is generally intractable, approximations based on linear programming (LP) relaxation often provide good approximate solutions. In this paper we present an algorithm for solving the LP relaxation optimization problem. In order to overcome the lack of strict convexity, we apply an augmented Lagrangian method to the dual LP. The algorithm, based on the alternating direction method of multipliers (ADMM), is guaranteed to converge to the global optimum of the LP relaxation objective. Our experimental results show that this algorithm is competitive with other state-of-the-art algorithms for approximate MAP estimation.

#index 1617328
#* Aggregating independent and dependent models to learn multi-label classifiers
#@ Elena Montañés;José Ramón Quevedo;Juan José del Coz
#t 2011
#c 22
#% 132938
#% 311034
#% 478470
#% 838412
#% 889101
#% 950571
#% 961134
#% 997067
#% 1074360
#% 1095861
#% 1100077
#% 1176915
#% 1264044
#% 1267771
#% 1495561
#! The aim of multi-label classification is to automatically obtain models able to tag objects with the labels that better describe them. Despite it could seem like any other classification task, it is widely known that exploiting the presence of certain correlations between labels helps to improve the classification performance. In other words, object descriptions are usually not enough to induce good models, also label information must be taken into account. This paper presents an aggregated approach that combines two groups of classifiers, one assuming independence between labels, and the other considering fully conditional dependence among them. The framework proposed here can be applied not only for multi-label classification, but also in multi-label ranking tasks. Experiments carried out over several datasets endorse the superiority of our approach with regard to other methods in terms of some evaluation measures, keeping competitiveness in terms of others.

#index 1617329
#* Tensor factorization using auxiliary information
#@ Atsuhiro Narita;Kohei Hayashi;Ryota Tomioka;Hisashi Kashima
#t 2011
#c 22
#% 828046
#% 840934
#% 1176933
#% 1211838
#% 1287221
#% 1300087
#% 1305469
#% 1355024
#% 1524266
#% 1535402
#% 1595860
#! Most of the existing analysis methods for tensors (or multiway arrays) only assume that tensors to be completed are of low rank. However, for example, when they are applied to tensor completion problems, their prediction accuracy tends to be significantly worse when only limited entries are observed. In this paper, we propose to use relationships among data as auxiliary information in addition to the low-rank assumption to improve the quality of tensor decomposition. We introduce two regularization approaches using graph Laplacians induced from the relationships, and design iterative algorithms for approximate solutions. Numerical experiments on tensor completion using synthetic and benchmark datasets show that the use of auxiliary information improves completion accuracy over the existing methods based only on the low-rank assumption, especially when observations are sparse.

#index 1617330
#* Kernels for link prediction with latent feature models
#@ Canh Hao Nguyen;Hiroshi Mamitsuka
#t 2011
#c 22
#% 397640
#% 464615
#% 730089
#% 833088
#% 833805
#% 881468
#% 1000502
#% 1038969
#% 1117695
#% 1183447
#% 1211760
#% 1250567
#! Predicting new links in a network is a problem of interest in many application domains. Most of the prediction methods utilize information on the network's entities such as nodes to build a model of links. Network structures are usually not used except for the networks with similarity or relatedness semantics. In this work, we use network structures for link prediction with a more general network type with latent feature models. The problem is the difficulty to train these models directly for large data. We propose a method to solve this problem using kernels and cast the link prediction problem into a binary classification problem. The key idea is not to infer latent features explicitly, but to represent these features implicitly in the kernels, making the method scalable to large networks. In contrast to the other methods for latent feature models, our method inherits all the advantages of kernel framework: optimality, efficiency and nonlinearity. We apply our method to real data of protein-protein interactions to show the merits of our method.

#index 1617331
#* Frequency-aware truncated methods for sparse online learning
#@ Hidekazu Oiwa;Shin Matsushima;Hiroshi Nakagawa
#t 2011
#c 22
#% 46803
#% 961152
#% 1073905
#% 1193366
#% 1232034
#% 1328357
#% 1386006
#! Online supervised learning with L1-regularization has gained attention recently because it generally requires less computational time and a smaller space of complexity than batch-type learning methods. However, a simple L1-regularization method used in an online setting has the side effect that rare features tend to be truncated more than necessary. In fact, feature frequency is highly skewed in many applications. We developed a new family of L1-regularization methods based on the previous updates for loss minimization in linear online learning settings. Our methods can identify and retain low-frequency occurrence but informative features at the same computational cost and convergence rate as previous works. Moreover, we combined our methods with a cumulative penalty model to derive more robust models over noisy data. We applied our methods to several datasets and empirically evaluated the performance of our algorithms. Experimental results showed that our frequency-aware truncated models improved the prediction accuracy.

#index 1617332
#* A shapley value approach for influence attribution
#@ Panagiotis Papapetrou;Aristides Gionis;Heikki Mannila
#t 2011
#c 22
#% 290830
#% 342596
#% 729923
#% 1540202
#! Finding who and what is "important" is an ever-occurring question. Many methods that aim at characterizing important items or influential individuals have been developed in areas such as, bibliometrics, social-network analysis, link analysis, and web search. In this paper we study the problem of attributing influence scores to individuals who accomplish tasks in a collaborative manner. We assume that individuals build small teams, in different and diverse ways, in order to accomplish atomic tasks. For each task we are given an assessment of success or importance score, and the goal is to attribute those team-wise scores to the individuals. The challenge we face is that individuals in strong coalitions are favored against individuals in weaker coalitions, so the objective is to find fair attributions that account for such biasing. We propose an iterative algorithm for solving this problem that is based on the concept of Shapley value. The proposed method is applicable to a variety of scenarios, for example, attributing influence scores to scientists who collaborate in published articles, or employees of a company who participate in projects. Our method is evaluated on two real datasets: ISI Web of Science publication data and the Internet Movie Database.

#index 1617333
#* Fast approximate text document clustering using compressive sampling
#@ Laurence A. F. Park
#t 2011
#c 22
#% 342617
#% 479973
#% 1815826
#! Document clustering involves repetitive scanning of a document set, therefore as the size of the set increases, the time required for the clustering task increases and may even become impossible due to computational constraints. Compressive sampling is a feature sampling technique that allows us to perfectly reconstruct a vector from a small number of samples, provided that the vector is sparse in some known domain. In this article, we apply the theory behind compressive sampling to the document clustering problem using k-means clustering. We provide a method of computing high accuracy clusters in a fraction of the time it would have taken by directly clustering the documents. This is performed by using the Discrete Fourier Transform and the Discrete Cosine Transform. We provide empirical results showing that compressive sampling provides a 14 times increase in speed with little reduction in accuracy on 7,095 documents, and we also provide a very accurate clustering of a 231,219 document set, providing 20 times increase in speed when compared to performing k-means clustering on the document set. This shows that compressive clustering is a very useful tool that can be used to quickly compute approximate clusters.

#index 1617334
#* Ancestor relations in the presence of unobserved variables
#@ Pekka Parviainen;Mikko Koivisto
#t 2011
#c 22
#% 129987
#% 197387
#% 297171
#% 465762
#% 528306
#% 763715
#% 794859
#% 1058706
#% 1417114
#% 1650684
#! Bayesian networks (BNs) are an appealing model for causal and noncausal dependencies among a set of variables. Learning BNs from observational data is challenging due to the nonidentifiability of the network structure and model misspecification in the presence of unobserved (latent) variables. Here, we investigate the prospects of Bayesian learning of ancestor relations, including arcs, in the presence and absence of unobserved variables. An exact dynamic programming algorithm to compute the respective posterior probabilities is developed, under the complete data assumption. Our experimental results show that ancestor relations between observed variables, arcs in particular, can be learned with good power even when a majority of the involved variables are unobserved. For comparison, deduction of ancestor relations from single maximum a posteriori network structures or their Markov equivalence class appears somewhat inferior to Bayesian averaging. We also discuss some shortcomings of applying existing conditional independence test based methods for learning ancestor relations.

#index 1617335
#* ShareBoost: boosting for multi-view learning with performance guarantees
#@ Jing Peng;Costin Barbu;Guna Seetharaman;Wei Fan;Xian Wu;Kannappan Palaniappan
#t 2011
#c 22
#% 132938
#% 235377
#% 252011
#% 302391
#% 416988
#% 425053
#% 832574
#% 871302
#% 976824
#% 1074016
#% 1183868
#% 1211781
#% 1270208
#% 1329960
#! Algorithms combining multi-view information are known to exponentially quicken classification, and have been applied to many fields. However, they lack the ability to mine most discriminant information sources (or data types) for making predictions. In this paper, we propose an algorithm based on boosting to address these problems. The proposed algorithm builds base classifiers independently from each data type (view) that provides a partial view about an object of interest. Different from AdaBoost, where each view has its own re-sampling weight, our algorithm uses a single re-sampling distribution for all views at each boosting round. This distribution is determined by the view whose training error is minimal. This shared sampling mechanism restricts noise to individual views, thereby reducing sensitivity to noise. Furthermore, in order to establish performance guarantees, we introduce a randomized version of the algorithm, where a winning view is chosen probabilistically. As a result, it can be cast within a multi-armed bandit framework, which allows us to show that with high probability the algorithm seeks out most discriminant views of data for making predictions. We provide experimental results that show its performance against noise and competing techniques.

#index 1617336
#* Analyzing and escaping local optima in planning as inference for partially observable domains
#@ Pascal Poupart;Tobias Lang;Marc Toussaint
#t 2011
#c 22
#% 272652
#% 706380
#% 827696
#% 842579
#% 876063
#% 1211825
#% 1250227
#% 1275142
#% 1417078
#% 1650313
#! Planning as inference recently emerged as a versatile approach to decision-theoretic planning and reinforcement learning for single and multi-agent systems in fully and partially observable domains with discrete and continuous variables. Since planning as inference essentially tackles a non-convex optimization problem when the states are partially observable, there is a need to develop techniques that can robustly escape local optima. We investigate the local optima of finite state controllers in single agent partially observable Markov decision processes (POMDPs) that are optimized by expectation maximization (EM). We show that EM converges to controllers that are optimal with respect to a one-step lookahead. To escape local optima, we propose two algorithms: the first one adds nodes to the controller to ensure optimality with respect to a multi-step lookahead, while the second one splits nodes in a greedy fashion to improve reward likelihood. The approaches are demonstrated empirically on benchmark problems.

#index 1617337
#* Abductive plan recognition by extending Bayesian logic programs
#@ Sindhu Raghavan;Raymond J. Mooney
#t 2011
#c 22
#% 25471
#% 44876
#% 147677
#% 424793
#% 550745
#% 850430
#% 1000502
#% 1089646
#% 1100058
#% 1272019
#% 1273438
#% 1274292
#% 1279398
#% 1393864
#% 1416204
#% 1417383
#% 1477122
#% 1477272
#% 1592100
#% 1704250
#! Plan recognition is the task of predicting an agent's top-level plans based on its observed actions. It is an abductive reasoning task that involves inferring cause from effect. Most existing approaches to plan recognition use either first-order logic or probabilistic graphical models. While the former cannot handle uncertainty, the latter cannot handle structured representations. In order to overcome these limitations, we develop an approach to plan recognition using Bayesian Logic Programs (BLPs), which combine first-order logic and Bayesian networks. Since BLPs employ logical deduction to construct the networks, they cannot be used effectively for plan recognition. Therefore, we extend BLPs to use logical abduction to construct Bayesian networks and call the resulting model Bayesian Abductive Logic Programs (BALPs). We learn the parameters in BALPs using the Expectation Maximization algorithm adapted for BLPs. Finally, we present an experimental evaluation of BALPs on three benchmark data sets and compare its performance with the state-of-the-art for plan recognition.

#index 1617338
#* Higher order contractive auto-encoder
#@ Salah Rifai;Grégoire Mesnil;Pascal Vincent;Xavier Muller;Yoshua Bengio;Yann Dauphin;Xavier Glorot
#t 2011
#c 22
#% 891060
#% 983863
#% 1074009
#% 1074018
#% 1302905
#% 1455666
#% 1551209
#! We propose a novel regularizer when training an autoencoder for unsupervised feature extraction. We explicitly encourage the latent representation to contract the input space by regularizing the norm of the Jacobian (analytically) and the Hessian (stochastically) of the encoder's output with respect to its input, at the training points. While the penalty on the Jacobian's norm ensures robustness to tiny corruption of samples in the input space, constraining the norm of the Hessian extends this robustness when moving further away from the sample. From a manifold learning perspective, balancing this regularization with the auto-encoder's reconstruction objective yields a representation that varies most when moving along the data manifold in input space, and is most insensitive in directions orthogonal to the manifold. The second order regularization, using the Hessian, penalizes curvature, and thus favors smooth manifold. We show that our proposed technique, while remaining computationally efficient, yields representations that are significantly better suited for initializing deep architectures than previously proposed approaches, beating state-of-the-art performance on a number of datasets.

#index 1617339
#* The VC-dimension of SQL queries and selectivity estimation through sampling
#@ Matteo Riondato;Mert Akdere;Uǧur Çetintemel;Stanley B. Zdonik;Eli Upfal
#t 2011
#c 22
#% 82346
#% 102786
#% 116084
#% 137885
#% 164361
#% 190330
#% 201921
#% 210188
#% 210190
#% 210353
#% 248812
#% 248821
#% 248822
#% 273908
#% 273909
#% 277347
#% 333947
#% 333983
#% 333986
#% 335411
#% 345611
#% 393907
#% 410958
#% 461918
#% 462623
#% 464062
#% 479648
#% 480471
#% 482092
#% 511349
#% 654486
#% 732905
#% 741348
#% 765427
#% 809254
#% 850732
#% 864393
#% 864405
#% 864408
#% 864426
#% 893137
#% 903014
#% 956455
#% 960248
#% 1206653
#% 1426448
#% 1563255
#! We develop a novel method, based on the statistical concept of VC-dimension, for evaluating the selectivity (output cardinality) of SQL queries - a crucial step in optimizing the execution of large scale database and data-mining operations. The major theoretical contribution of this work, which is of independent interest, is an explicit bound on the VC-dimension of a range space defined by all possible outcomes of a collection (class) of queries. We prove that the VC-dimension is a function of the maximum number of Boolean operations in the selection predicate, and of the maximum number of select and join operations in any individual query in the collection, but it is neither a function of the number of queries in the collection nor of the size of the database. We develop a method based on this result: given a class of queries, it constructs a concise random sample of a database, such that with high probability the execution of any query in the class on the sample provides an accurate estimate for the selectivity of the query on the original large database. The error probability holds simultaneously for the selectivity estimates of all queries in the collection, thus the same sample can be used to evaluate the selectivity of multiple queries, and the sample needs to be refreshed only following major changes in the database. The sample representation computed by our method is typically sufficiently small to be stored in main memory. We present extensive experimental results, validating our theoretical analysis and demonstrating the advantage of our technique when compared to complex selectivity estimation techniques used in PostgreSQL and the Microsoft SQL Server.

#index 1617340
#* Proceedings of the 2011 European conference on Machine learning and knowledge discovery in databases - Volume Part III
#@ Dimitrios Gunopulos;Thomas Hofmann;Donato Malerba;Michalis Vazirgiannis
#t 2011
#c 22

#index 1617341
#* Sparse Kernel-SARSA(λ) with an eligibility trace
#@ Matthew Robards;Peter Sunehag;Scott Sanner;Bhaskara Marthi
#t 2011
#c 22
#% 363744
#% 384911
#% 393059
#% 425072
#% 458685
#% 743284
#% 840860
#% 891559
#% 1073962
#% 1211817
#% 1495581
#% 1665215
#% 1861993
#! We introduce the first online kernelized version of SARSA(λ) to permit sparsification for arbitrary λ for 0 ≤ λ ≤ 1; this is possible via a novel kernelization of the eligibility trace that is maintained separately from the kernelized value function. This separation is crucial for preserving the functional structure of the eligibility trace when using sparse kernel projection techniques that are essential for memory efficiency and capacity control. The result is a simple and practical Kernel-SARSA(λ) algorithm for general 0 ≤ λ ≤ 1 that is memory-efficient in comparison to standard SARSA(λ) (using various basis functions) on a range of domains including a real robotics task running on a Willow Garage PR2 robot.

#index 1617342
#* Influence and passivity in social media
#@ Daniel M. Romero;Wojciech Galuba;Sitaram Asur;Bernardo A. Huberman
#t 2011
#c 22
#% 268079
#% 290830
#% 342596
#% 868469
#% 1035589
#% 1301020
#% 1355040
#% 1355042
#% 1475157
#! The ever-increasing amount of information flowing through Social Media forces the members of these networks to compete for attention and influence by relying on other people to spread their message. A large study of information propagation within Twitter reveals that the majority of users act as passive information consumers and do not forward the content to the network. Therefore, in order for individuals to become influential they must not only obtain attention and thus be popular, but also overcome user passivity. We propose an algorithm that determines the influence and passivity of users based on their information forwarding activity. An evaluation performed with a 2.5 million user dataset shows that our influence measure is a good predictor of URL clicks, outperforming several other measures that do not explicitly take user passivity into account. We demonstrate that high popularity does not necessarily imply high influence and vice-versa.

#index 1617343
#* Preference elicitation and inverse reinforcement learning
#@ Constantin A. Rothkopf;Christos Dimitrakakis
#t 2011
#c 22
#% 466418
#% 578692
#% 715337
#% 770852
#% 840852
#% 876032
#% 1250411
#% 1275169
#% 1275830
#! We state the problem of inverse reinforcement learning in terms of preference elicitation, resulting in a principled (Bayesian) statistical formulation. This generalises previous work on Bayesian inverse reinforcement learning and allows us to obtain a posterior distribution on the agent's preferences, policy and optionally, the obtained reward sequence, from observations. We examine the relation of the resulting approach to other statistical methods for inverse reinforcement learning via analysis and experimental results. We show that preferences can be determined accurately, even if the observed agent's policy is sub-optimal with respect to its own preferences. In that case, significantly improved policies with respect to the agent's preferences are obtained, compared to both other methods and to the performance of the demonstrated policy.

#index 1617344
#* A novel framework for locating software faults using latent divergences
#@ Shounak Roychowdhury;Sarfraz Khurshid
#t 2011
#c 22
#% 82316
#% 231941
#% 722929
#% 757953
#% 809099
#% 823217
#% 840516
#% 918579
#% 1019220
#% 1278869
#% 1314584
#! Fault localization, i.e., identifying erroneous lines of code in a buggy program, is a tedious process, which often requires considerable manual effort and is costly. Recent years have seen much progress in techniques for automated fault localization, specifically using program spectra - executions of failed and passed test runs provide a basis for isolating the faults. Despite the progress, fault localization in large programs remains a challenging problem, because even inspecting a small fraction of the lines of code in a large problem can require substantial manual effort. This paper presents a novel framework for fault localization based on latent divergences - an effective method for feature selection in machine learning. Our insight is that the problem of fault localization can be reduced to the problem of feature selection, where lines of code correspond to features. We also present an experimental evaluation of our framework using the Siemens suite of subject programs, which are a standard benchmark for studying fault localization techniques in software engineering. The results show that our framework enables more accurate fault localization than existing techniques.

#index 1617345
#* Transfer learning with adaptive regularizers
#@ Ulrich Rückert;Marius Kloft
#t 2011
#c 22
#% 197394
#% 236497
#% 722909
#% 722929
#% 766438
#% 769886
#% 876034
#% 916788
#% 961138
#% 1108894
#% 1128929
#% 1214724
#% 1267798
#% 1271814
#% 1464068
#! The success of regularized risk minimization approaches to classification with linear models depends crucially on the selection of a regularization term that matches with the learning task at hand. If the necessary domain expertise is rare or hard to formalize, it may be difficult to find a good regularizer. On the other hand, if plenty of related or similar data is available, it is a natural approach to adjust the regularizer for the new learning problem based on the characteristics of the related data. In this paper, we study the problem of obtaining good parameter values for a l2-style regularizer with feature weights. We analytically investigate a moment-based method to obtain good values and give uniform convergence bounds for the prediction error on the target learning task. An empirical study shows that the approach can improve predictive accuracy considerably in the application domain of text classification.

#index 1617346
#* Multimodal nonlinear filtering using Gauss-Hermite quadrature
#@ Hannes P. Saal;Nicolas M. O. Heess;Sethu Vijayakumar
#t 2011
#c 22
#% 97428
#% 277470
#% 722942
#% 724154
#% 837639
#% 1211697
#% 1211718
#! In many filtering problems the exact posterior state distribution is not tractable and is therefore approximated using simpler parametric forms, such as single Gaussian distributions. In nonlinear filtering problems the posterior state distribution can, however, take complex shapes and even become multimodal so that single Gaussians are no longer sufficient. A standard solution to this problem is to use a bank of independent filters that individually represent the posterior with a single Gaussian and jointly form a mixture of Gaussians representation. Unfortunately, since the filters are optimized separately and interactions between the components consequently not taken into account, the resulting representation is typically poor. As an alternative we therefore propose to directly optimize the full approximating mixture distribution by minimizing the KL divergence to the true state posterior. For this purpose we describe a deterministic sampling approach that allows us to perform the intractable minimization approximately and at reasonable computational cost. We find that the proposed method models multimodal posterior distributions noticeably better than banks of independent filters even when the latter are allowed many more mixture components. We demonstrate the importance of accurately representing the posterior with a tractable number of components in an active learning scenario where we report faster convergence, both in terms of number of observations processed and in terms of computation time, and more reliable convergence on up to ten-dimensional problems.

#index 1617347
#* Active supervised domain adaptation
#@ Avishek Saha;Piyush Rai;Hal Daumé;Suresh Venkatasubramanian;Scott L. DuVall
#t 2011
#c 22
#% 961177
#% 961194
#% 961246
#% 1108902
#% 1232017
#% 1261539
#% 1338536
#! In this paper, we harness the synergy between two important learning paradigms, namely, active learning and domain adaptation. We show how active learning in a target domain can leverage information from a different but related source domain. Our proposed framework, Active Learning Domain Adapted (Alda), uses source domain knowledge to transfer information that facilitates active learning in the target domain. We propose two variants of Alda: a batch B-Alda and an online O-Alda. Empirical comparisons with numerous baselines on real-world datasets establish the efficacy of the proposed methods.

#index 1617348
#* Efficiently approximating Markov tree bagging for high-dimensional density estimation
#@ Franćois Schnitzler;Sourour Ammar;Philippe Leray;Pierre Geurts;Louis Wehenkel
#t 2011
#c 22
#% 1451
#% 44876
#% 68244
#% 317178
#% 528151
#% 722753
#% 983856
#% 1228580
#% 1386105
#% 1417383
#% 1473246
#% 1606355
#% 1650288
#% 1650289
#% 1650349
#! We consider algorithms for generating Mixtures of Bagged Markov Trees, for density estimation. In problems defined over many variables and when few observations are available, those mixtures generally outperform a single Markov tree maximizing the data likelihood, but are far more expensive to compute. In this paper, we describe new algorithms for approximating such models, with the aim of speeding up learning without sacrificing accuracy. More specifically, we propose to use a filtering step obtained as a by-product from computing a first Markov tree, so as to avoid considering poor candidate edges in the subsequently generated trees. We compare these algorithms (on synthetic data sets) to Mixtures of Bagged Markov Trees, as well as to a single Markov tree derived by the classical Chow-Liu algorithm and to a recently proposed randomized scheme used for building tree mixtures.

#index 1617349
#* Resource-aware on-line RFID localization using proximity data
#@ Christoph Scholz;Stephan Doerfel;Martin Atzmueller;Andreas Hotho;Gerd Stumme
#t 2011
#c 22
#% 197394
#% 269217
#% 309430
#% 376266
#% 393113
#% 400847
#% 644230
#% 787175
#% 920157
#% 1017767
#% 1772311
#! This paper focuses on resource-aware and cost-effective indoor-localization at room-level using RFID technology. In addition to the tracking information of people wearing active RFID tags, we also include information about their proximity contacts. We present an evaluation using real-world data collected during a conference: We complement state-of-the-art machine learning approaches with strategies utilizing the proximity data in order to improve a core localization technique further.

#index 1617350
#* On the stratification of multi-label data
#@ Konstantinos Sechidis;Grigorios Tsoumakas;Ioannis Vlahavas
#t 2011
#c 22
#% 400847
#% 449563
#% 457912
#% 765519
#% 889101
#% 905168
#% 961134
#% 1095861
#% 1095862
#% 1176915
#% 1246173
#% 1264044
#% 1267771
#% 1290045
#% 1375778
#% 1671162
#! Stratified sampling is a sampling method that takes into account the existence of disjoint groups within a population and produces samples where the proportion of these groups is maintained. In single-label classification tasks, groups are differentiated based on the value of the target variable. In multi-label learning tasks, however, where there are multiple target variables, it is not clear how stratified sampling could/should be performed. This paper investigates stratification in the multi-label data context. It considers two stratification methods for multi-label data and empirically compares them along with random sampling on a number of datasets and based on a number of evaluation criteria. The results reveal some interesting conclusions with respect to the utility of each method for particular types of multi-label datasets.

#index 1617351
#* Learning first-order definite theories via object-based queries
#@ Joseph Selman;Alan Fern
#t 2011
#c 22
#% 697
#% 131685
#% 175383
#% 272886
#% 277616
#% 302388
#% 450951
#% 451056
#% 550561
#% 961264
#% 1183869
#! We study the problem of exact learning of first-order definite theories via queries, toward the goal of allowing humans to more efficiently teach first-order concepts to computers. Prior work has shown that first order Horn theories can be learned using a polynomial number of membership and equivalence queries [6]. However, these query types are sometimes unnatural for humans to answer and only capture a small fraction of the information that a human teacher might be able to easily communicate. In this work, we enrich the types of information that can be provided by a human teacher and study the associated learning problem from a theoretical perspective. First, we consider allowing queries that ask the teacher for the relevant objects in a training example. Second, we examine a new query type, called a pairing query, where the teacher provides mappings between objects in two different examples. We present algorithms that leverage these new query types as well as restrictions applied to equivalence queries to significantly reduce or eliminate the required number of membership queries, while preserving polynomial learnability. In addition, we give learnability results for certain cases of imperfect teachers. These results show, in theory, the potential for incorporating object-based queries into first-order learning algorithms in order to reduce human teaching effort.

#index 1617352
#* Fast support vector machines for structural Kernels
#@ Aliaksei Severyn;Alessandro Moschitti
#t 2011
#c 22
#% 269217
#% 722925
#% 727925
#% 734919
#% 742218
#% 815896
#% 817422
#% 829043
#% 855277
#% 858036
#% 881477
#% 916790
#% 939615
#% 1073912
#% 1083712
#% 1264050
#% 1385997
#% 1496785
#! In this paper, we propose three important enhancements of the approximate cutting plane algorithm (CPA) to train Support Vector Machines with structural kernels: (i) we exploit a compact yet exact representation of cutting plane models using directed acyclic graphs to speed up both training and classification, (ii) we provide a parallel implementation, which makes the training scale almost linearly with the number of CPUs, and (iii) we propose an alternative sampling strategy to handle class-imbalanced problem and show that theoretical convergence bounds are preserved. The experimental evaluations on three diverse datasets demonstrate the soundness of our approach and the possibility to carry out fast learning and classification with structural kernes.

#index 1617353
#* Generalized agreement statistics over fixed group of experts
#@ Mohak Shah
#t 2011
#c 22
#% 742990
#% 1264744
#% 1472273
#% 1561571
#! Generalizations of chance corrected statistics tomeasure interexpert agreement on class label assignments to the data instances have traditionally relied on the marginalization argument over a variable group of experts. Further, this argument has also resulted in agreement measures to evaluate the class predictions by an isolated classifier against the (multiple) labels assigned by the group of experts. We show that these measures are not necessarily suitable for application in the more typical fixed experts' group scenario. We also propose novel, moremeaningful, less variable generalizations for quantifying both the inter-expert agreement over the fixed group and assessing a classifier's output against it in a multiexpert multi-class scenario by taking into account expert-specific biases and correlations.

#index 1617354
#* Compact coding for hyperplane classifiers in heterogeneous environment
#@ Hao Shao;Bin Tong;Einoshin Suzuki
#t 2011
#c 22
#% 61792
#% 156181
#% 236497
#% 464268
#% 723239
#% 769896
#% 906248
#% 934581
#% 983828
#% 1108839
#% 1108894
#% 1108902
#% 1267778
#% 1310449
#% 1318689
#% 1464068
#% 1482214
#% 1558464
#% 1613637
#! Transfer learning techniques have witnessed a significant development in real applications where the knowledge from previous tasks are required to reduce the high cost of inquiring the labeled information for the target task. However, how to avoid negative transfer which happens due to different distributions of tasks in heterogeneous environment is still a open problem. In order to handle this kind of issue, we propose a Compact Coding method for Hyperplane Classifiers (CCHC) under a two-level framework in inductive transfer learning setting. Unlike traditional methods, we measure the similarities among tasks from the macro level perspective through minimum encoding. Particularly speaking, the degree of the similarity is represented by the relevant code length of the class boundary of each source task with respect to the target task. In addition, informative parts of the source tasks are adaptively selected in the micro level viewpoint to make the choice of the specific source task more accurate. Extensive experiments show the effectiveness of our algorithm in terms of the classification accuracy in both UCI and text data sets.

#index 1617355
#* Multi-label ensemble learning
#@ Chuan Shi;Xiangnan Kong;Philip S. Yu;Bai Wang
#t 2011
#c 22
#% 209021
#% 304515
#% 369236
#% 392343
#% 465692
#% 466379
#% 846508
#% 889101
#% 950571
#% 1095862
#% 1100077
#% 1176915
#% 1190536
#% 1214713
#% 1267771
#% 1451240
#% 1512994
#% 1673681
#% 1780902
#! Multi-label learning aims at predicting potentially multiple labels for a given instance. Conventional multi-label learning approaches focus on exploiting the label correlations to improve the accuracy of the learner by building an individual multi-label learner or a combined learner based upon a group of single-label learners. However, the generalization ability of such individual learner can be weak. It is well known that ensemble learning can effectively improve the generalization ability of learning systems by constructing multiple base learners and the performance of an ensemble is related to the both accuracy and diversity of base learners. In this paper, we study the problem of multilabel ensemble learning. Specifically, we aim at improving the generalization ability of multi-label learning systems by constructing a group of multilabel base learners which are both accurate and diverse. We propose a novel solution, called EnML, to effectively augment the accuracy as well as the diversity of multi-label base learners. In detail, we design two objective functions to evaluate the accuracy and diversity of multilabel base learners, respectively, and EnML simultaneously optimizes these two objectives with an evolutionary multi-objective optimization method. Experiments on real-world multi-label learning tasks validate the effectiveness of our approach against other well-established methods.

#index 1617356
#* Rule-based active sampling for learning to rank
#@ Rodrigo Silva;Marcos A. Gonçalves;Adriano Veloso
#t 2011
#c 22
#% 116165
#% 152934
#% 169717
#% 184490
#% 565531
#% 577224
#% 770771
#% 823360
#% 1073903
#% 1074084
#% 1100053
#% 1100072
#% 1195836
#% 1268491
#% 1450846
#% 1450862
#% 1456843
#% 1673573
#! Learning to rank (L2R) algorithms rely on a labeled training set to generate a ranking model that can be later used to rank new query results. Producing these labeled training sets is usually very costly as it requires human annotators to assess the relevance or order the elements in the training set. Recently, active learning alternatives have been proposed to reduce the labeling effort by selectively sampling an unlabeled set. In this paper we propose a novel rule-based active sampling method for Learning to Rank. Our method actively samples an unlabeled set, selecting new documents to be labeled based on how many relevance inference rules they generate given the previously selected and labeled examples. The smaller the number of generated rules, the more dissimilar and more "informative" is a document with regard to the current state of the labeled set. Differently from previous solutions, our algorithm does not rely on an initial training seed and can be directly applied to an unlabeled dataset. Also in contrast to previous work, we have a clear stop criterion and do not need to empirically discover the best configuration by running a number of iterations on the validation or test sets. These characteristics make our algorithm highly practical. We demonstrate the effectiveness of our active sampling method on several benchmarking datasets, showing that a significant reduction in training size is possible. Our method selects as little as 1.1% and at most 2.2% of the original training sets, while providing competitive results when compared to state-of-the-art supervised L2R algorithms that use the complete training sets.

#index 1617357
#* Parallel structural graph clustering
#@ Madeleine Seeland;Simon A. Berger;Alexandros Stamatakis;Stefan Kramer
#t 2011
#c 22
#% 629708
#% 876064
#% 905703
#% 989575
#% 1030880
#% 1041263
#% 1496784
#% 1685011
#! We address the problem of clustering large graph databases according to scaffolds (i.e., large structural overlaps) that are shared between cluster members. In previous work, an online algorithm was proposed for this task that produces overlapping (non-disjoint) and nonexhaustive clusterings. In this paper, we parallelize this algorithm to take advantage of high-performance parallel hardware and further improve the algorithm in three ways: a refined cluster membership test based on a set abstraction of graphs, sorting graphs according to size, to avoid cluster membership tests in the first place, and the definition of a cluster representative once the cluster scaffold is unique, to avoid cluster comparisons with all cluster members. In experiments on a large database of chemical structures, we show that running times can be reduced by a large factor for one parameter setting used in previous work. For harder parameter settings, it was possible to obtain results within reasonable time for 300,000 structures, compared to 10,000 structures in previous work. This shows that structural, scaffold-based clustering of smaller libraries for virtual screening is already feasible.

#index 1617358
#* Aspects of semi-supervised and active learning in conditional random fields
#@ Nataliya Sokolovska
#t 2011
#c 22
#% 464434
#% 812390
#% 855108
#% 875963
#% 883830
#% 939527
#% 983878
#% 1073995
#% 1251698
#% 1265094
#% 1318679
#% 1330554
#% 1338586
#% 1455666
#! Conditional random fields are among the state-of-the art approaches to structured output prediction, and the model has been adopted for various real-world problems. The supervised classification is expensive, since it is usually expensive to produce labelled data. Unlabeled data are relatively cheap, but how to use it? Unlabeled data can be used to estimate marginal probability of observations, and we exploit this idea in our work. Introduction of unlabeled data and of probability of observations into a purely discriminative model is a challenging task. We consider an extrapolation of a recently proposed semi-supervised criterion to the model of conditional random fields, and show its drawbacks. We discuss alternative usage of the marginal probability and propose a pool-based active learning approach based on quota sampling. We carry out experiments on synthetic as well as on standard natural language data sets, and we show that the proposed quota sampling active learning method is efficient.

#index 1617359
#* Comparing probabilistic models for melodic sequences
#@ Athina Spiliopoulou;Amos Storkey
#t 2011
#c 22
#% 450888
#% 492643
#% 730140
#% 891060
#% 1112718
#% 1211766
#% 1211818
#% 1211831
#! Modelling the real world complexity of music is a challenge for machine learning. We address the task of modeling melodic sequences fromthe same music genre. We perform a comparative analysis of two probabilistic models; a Dirichlet Variable Length Markov Model (Dirichlet-VMM) and a Time Convolutional Restricted Boltzmann Machine (TC-RBM). We show that the TC-RBM learns descriptive music features, such as underlying chords and typical melody transitions and dynamics. We assess the models for future prediction and compare their performance to a VMM, which is the current state of the art in melody generation. We show that both models perform significantly better than the VMM, with the Dirichlet-VMMmarginally outperforming the TC-RBM. Finally, we evaluate the short order statistics of the models, using the Kullback-Leibler divergence between test sequences and model samples, and show that our proposed methods match the statistics of the music genre significantly better than the VMM.

#index 1617360
#* Fast Projections onto l1,q-norm balls for grouped feature selection
#@ Suvrit Sra
#t 2011
#c 22
#% 6730
#% 416706
#% 769886
#% 799344
#% 829014
#% 873584
#% 1074378
#% 1211771
#% 1211772
#% 1211797
#% 1386006
#% 1818266
#! Joint sparsity is widely acknowledged as a powerful structural cue for performing feature selection in setups where variables are expected to demonstrate "grouped" behavior. Such grouped behavior is commonly modeled by Group-Lasso or Multitask Lasso-type problems, where feature selection is effected via l1,q -mixed-norms. Several particular formulations for modeling groupwise sparsity have received substantial attention in the literature; and in some cases, efficient algorithms are also available. Surprisingly, for constrained formulations of fundamental importance (e.g., regression with an l1,∞-norm constraint), highly scalable methods seem to be missing. We address this deficiency by presenting a method based on spectral projected-gradient (SPG) that can tackle l1,q -constrained convex regression problems. The most crucial component of our method is an algorithm for projecting onto l1,q-norm balls. We present several numerical results which show that our methods attain up to 30X speedups on large l1,∞-multitask lasso problems. Even more dramatic are the gains for just the l1,∞-projection subproblem: we observe almost three orders of magnitude speedups compared against the currently standard method.

#index 1617361
#* Generalized dictionary learning for symmetric positive definite matrices with application to nearest neighbor retrieval
#@ Suvrit Sra;Anoop Cherian
#t 2011
#c 22
#% 672
#% 73441
#% 232764
#% 249321
#% 249322
#% 264161
#% 270721
#% 315986
#% 416706
#% 479462
#% 479973
#% 593863
#% 744801
#% 883817
#% 883981
#% 1211776
#% 1355177
#% 1481330
#% 1495372
#% 1495429
#% 1526673
#% 1726434
#% 1856288
#% 1858898
#! We introduce Generalized Dictionary Learning (GDL), a simple but practical framework for learning dictionaries over the manifold of positive definite matrices. We illustrate GDL by applying it to Nearest Neighbor (NN) retrieval, a task of fundamental importance in disciplines such as machine learning and computer vision. GDL distinguishes itself from traditional dictionary learning approaches by explicitly taking into account the manifold structure of the data. In particular, GDL allows performing "sparse coding" of positive definite matrices, which enables better NN retrieval. Experiments on several covariance matrix datasets show that GDL achieves performance rivaling state-of-the-art techniques.

#index 1617362
#* Network regression with predictive clustering trees
#@ Daniela Stojanova;Michelangelo Ceci;Annalisa Appice;Sašo Džeroski
#t 2011
#c 22
#% 458708
#% 459008
#% 466073
#% 769942
#% 961268
#% 961278
#% 1083652
#% 1176980
#% 1269763
#% 1332124
#% 1403607
#! Regression inference in network data is a challenging task in machine learning and data mining. Network data describe entities represented by nodes, which may be connected with (related to) each other by edges. Many network datasets are characterized by a form of autocorrelation where the values of the response variable at a given node depend on the values of the variables (predictor and response) at the nodes connected to the given node. This phenomenon is a direct violation of the assumption of independent (i.i.d.) observations: At the same time, it offers a unique opportunity to improve the performance of predictive models on network data, as inferences about one entity can be used to improve inferences about related entities. In this paper, we propose a data mining method that explicitly considers autocorrelation when building regression models from network data. The method is based on the concept of predictive clustering trees (PCTs), which can be used both for clustering and predictive tasks: PCTs are decision trees viewed as hierarchies of clusters and provide symbolic descriptions of the clusters. In addition, PCTs can be used for multi-objective prediction problems, including multi-target regression and multi-target classification. Empirical results on real world problems of network regression show that the proposed extension of PCTs performs better than traditional decision tree induction when autocorrelation is present in the data.

#index 1617363
#* Learning from label proportions by optimizing cluster model selection
#@ Marco Stolpe;Katharina Morik
#t 2011
#c 22
#% 129212
#% 190581
#% 273891
#% 376266
#% 400847
#% 449588
#% 769935
#% 961134
#% 1117019
#% 1318743
#% 1385989
#% 1455666
#% 1567948
#% 1650665
#! In a supervised learning scenario, we learn a mapping from input to output values, based on labeled examples. Can we learn such a mapping also from groups of unlabeled observations, only knowing, for each group, the proportion of observations with a particular label? Solutions have real world applications. Here, we consider groups of steel sticks as samples in quality control. Since the steel sticks cannot be marked individually, for each group of sticks it is only known how many sticks of high (low) quality it contains. We want to predict the achieved quality for each stick before it reaches the final production station and quality control, in order to save resources. We define the problem of learning from label proportions and present a solution based on clustering. Our method empirically shows a better prediction performance than recent approaches based on probabilistic SVMs, Kernel k-Means or conditional exponential models.

#index 1617364
#* The minimum code length for clustering using the gray code
#@ Mahito Sugiyama;Akihiro Yamamoto
#t 2011
#c 22
#% 32926
#% 296738
#% 319176
#% 330327
#% 430746
#% 432446
#% 438137
#% 479799
#% 566128
#% 833928
#% 857228
#% 948089
#% 1310501
#% 1535473
#% 1815525
#! We propose new approaches to exploit compression algorithms for clustering numerical data. Our first contribution is to design a measure that can score the quality of a given clustering result under the light of a fixed encoding scheme. We call this measure the Minimum Code Length (MCL). Our second contribution is to propose a general strategy to translate any encoding method into a cluster algorithm, which we call COOL (COding-Oriented cLustering). COOL has a low computational cost since it scales linearly with the data set size. The clustering results of COOL is also shown to minimize MCL. To illustrate further this approach, we consider the Gray Code as the encoding scheme to present GCOOL. G-COOL can find clusters of arbitrary shapes and remove noise. Moreover, it is robust to change in the input parameters; it requires only two lower bounds for the number of clusters and the size of each cluster, whereas most algorithms for finding arbitrarily shaped clusters work well only if all parameters are tuned appropriately. G-COOL is theoretically shown to achieve internal cohesion and external isolation and is experimentally shown to work well for both synthetic and real data sets.

#index 1617365
#* Learning to infer social ties in large networks
#@ Wenbin Tang;Honglei Zhuang;Jie Tang
#t 2011
#c 22
#% 283136
#% 283833
#% 342596
#% 729923
#% 955712
#% 1000502
#% 1083734
#% 1194122
#% 1214702
#% 1269756
#% 1399997
#% 1400031
#% 1451159
#% 1451162
#% 1451245
#% 1536568
#% 1650318
#% 1673048
#! In online social networks, most relationships are lack of meaning labels (e.g., "colleague" and "intimate friends"), simply because users do not take the time to label them. An interesting question is: can we automatically infer the type of social relationships in a large network? what are the fundamental factors that imply the type of social relationships? In this work, we formalize the problem of social relationship learning into a semi-supervised framework, and propose a Partially-labeled Pairwise Factor Graph Model (PLP-FGM) for learning to infer the type of social ties. We tested the model on three different genres of data sets: Publication, Email and Mobile. Experimental results demonstrate that the proposed PLP-FGM model can accurately infer 92.7% of advisoradvisee relationships from the coauthor network (Publication), 88.0% of manager-subordinate relationships from the email network (Email), and 83.1% of the friendships from the mobile network (Mobile). Finally, we develop a distributed learning algorithm to scale up the model to real large networks.

#index 1617366
#* Comparing apples and oranges: measuring differences between data mining results
#@ Nikolaj Tatti;Jilles Vreeken
#t 2011
#c 22
#% 273891
#% 769902
#% 799752
#% 823361
#% 878207
#% 881542
#% 961249
#% 989648
#% 1086422
#% 1117701
#% 1214659
#% 1328215
#% 1348648
#% 1495603
#% 1565634
#% 1586974
#% 1605977
#% 1618915
#% 1673615
#! Deciding whether the results of two different mining algorithms provide significantly different information is an important open problem in exploratory data mining. Whether the goal is to select the most informative result for analysis, or decide which mining approach will likely provide the most novel insight, it is essential that we can tell how different the information is that two results provide. In this paper we take a first step towards comparing exploratory results on binary data. We propose to meaningfully convert results into sets of noisy tiles, and compare between these sets byMaximum Entropy modelling and Kullback-Leibler divergence. The measure we construct this way is flexible, and allows us to naturally include background knowledge, such that differences in results can be measured from the perspective of what a user already knows. Furthermore, adding to its interpretability, it coincides with Jaccard dissimilarity when we only consider exact tiles. Our approach provides a means to study and tell differences between results of different data mining methods. As an application, we show that it can also be used to identify which parts of results best redescribe other results. Experimental evaluation shows our measure gives meaningful results, correctly identifies methods that are similar in nature, and automatically provides sound redescriptions of results.

#index 1617367
#* Learning monotone nonlinear models using the choquet integral
#@ Ali Fallah Tehrani;Weiwei Cheng;Krzysztof Dembczynski;Eyke Hüllermeier
#t 2011
#c 22
#% 59121
#% 170745
#% 182684
#% 188062
#% 252233
#% 272541
#% 399790
#% 926298
#% 958632
#% 1090441
#% 1108854
#% 1166197
#% 1261473
#% 1301004
#% 1535384
#% 1537979
#% 1733100
#! The learning of predictive models that guarantee monotonicity in the input variables has received increasing attention in machine learning in recent years. While the incorporation of monotonicity constraints is rather simple for certain types of models, it may become a more intricate problem for others. By trend, the difficulty of ensuring monotonicity increases with the flexibility or, say, nonlinearity of a model. In this paper, we advocate the so-called Choquet integral as a tool for learning monotone nonlinear models. While being widely used as a flexible aggregation operator in different fields, such as multiple criteria decision making, the Choquet integral is much less known in machine learning so far. Apart from combining monotonicity and flexibility in a mathematically sound and elegant manner, the Choquet integral has additional features making it attractive from a machine learning point of view. Notably, it offers measures for quantifying the importance of individual predictor variables and the interaction between groups of variables. As a concrete application of the Choquet integral, we propose a generalization of logistic regression. The basic idea of our approach, referred to as choquistic regression, is to replace the linear function of predictor variables, which is commonly used in logistic regression to model the log odds of the positive class, by the Choquet integral.

#index 1617368
#* Feature selection for transfer learning
#@ Selen Uguroglu;Jaime Carbonell
#t 2011
#c 22
#% 209961
#% 722887
#% 906248
#% 1034531
#% 1195982
#% 1261539
#% 1270196
#% 1305479
#% 1305498
#% 1464068
#! Common assumption in most machine learning algorithms is that, labeled (source) data and unlabeled (target) data are sampled from the same distribution. However, many real world tasks violate this assumption: in temporal domains, feature distributions may vary over time, clinical studies may have sampling bias, or sometimes sufficient labeled data for the domain of interest does not exist, and labeled data from a related domain must be utilized. In such settings, knowing in which dimensions source and target data vary is extremely important to reduce the distance between domains and accurately transfer knowledge. In this paper, we present a novel method to identify variant and invariant features between two datasets. Our contribution is two fold: First, we present a novel transfer learning approach for domain adaptation, and second, we formalize the problem of finding differently distributed features as a convex optimization problem. Experimental studies on synthetic and benchmark real world datasets show that our approach outperform other transfer learning approaches, and it aids the prediction accuracy significantly.

#index 1617369
#* Multiview semi-supervised learning for ranking multilingual documents
#@ Nicolas Usunier;Massih-Reza Amini;Cyril Goutte
#t 2011
#c 22
#% 252011
#% 311027
#% 577224
#% 593047
#% 734915
#% 765552
#% 770846
#% 829008
#% 840882
#% 881477
#% 1074063
#% 1077150
#% 1270189
#% 1272396
#% 1396661
#% 1455666
#% 1705501
#! We address the problem of learning to rank documents in a multilingual context, when reference ranking information is only partially available. We propose a multiview learning approach to this semisupervised ranking task, where the translation of a document in a given language is considered as a view of the document. Although both multiview and semi-supervised learning of classifiers have been studied extensively in recent years, their application to the problem of ranking has received much less attention. We describe a semi-supervised multiview ranking algorithm that exploits a global agreement between viewspecific ranking functions on a set of unlabeled observations. We show that our proposed algorithm achieves significant improvements over both semi-supervised multiview classification and semi-supervised single-view rankers on a large multilingual collection of Reuters news covering 5 languages. Our experiments also suggest that our approach is most effective when few labeled documents are available and the classes are imbalanced.

#index 1617370
#* Non-redundant subgroup discovery in large and complex data
#@ Matthijs van Leeuwen;Arno Knobbe
#t 2011
#c 22
#% 232126
#% 464873
#% 477497
#% 763701
#% 814023
#% 934581
#% 1074357
#% 1108863
#% 1108880
#% 1116995
#% 1403611
#% 1456838
#% 1565634
#% 1663669
#! Large and complex data is challenging for most existing discovery algorithms, for several reasons. First of all, such data leads to enormous hypothesis spaces, making exhaustive search infeasible. Second, many variants of essentially the same pattern exist, due to (numeric) attributes of high cardinality, correlated attributes, and so on. This causes top-k mining algorithms to return highly redundant result sets, while ignoring many potentially interesting results. These problems are particularly apparent with Subgroup Discovery and its generalisation, Exceptional Model Mining. To address this, we introduce subgroup set mining: one should not consider individual subgroups, but sets of subgroups. We consider three degrees of redundancy, and propose corresponding heuristic selection strategies in order to eliminate redundancy. By incorporating these strategies in a beam search, the balance between exploration and exploitation is improved. Experiments clearly show that the proposed methods result in much more diverse subgroup sets than traditional Subgroup Discovery methods.

#index 1617371
#* Larger residuals, less work: active document scheduling for latent dirichlet allocation
#@ Mirwaes Wahabzada;Kristian Kersting
#t 2011
#c 22
#% 272521
#% 280819
#% 643056
#% 722904
#% 789800
#% 818291
#% 870226
#% 875987
#% 879661
#% 1038346
#% 1211835
#% 1214715
#% 1385969
#% 1523858
#% 1535323
#! Recently, there have been considerable advances in fast inference for latent Dirichlet allocation (LDA). In particular, stochastic optimization of the variational Bayes (VB) objective function with a natural gradient step was proved to converge and able to process massive document collections. To reduce noise in the gradient estimation, it considers multiple documents chosen uniformly at random. While it is widely recognized that the scheduling of documents in stochastic optimization may have significant consequences, this issue remains largely unexplored. In this work, we address this issue. Specifically, we propose residual LDA, a novel, easy-to-implement, LDA approach that schedules documents in an informed way. Intuitively, in each iteration, residual LDA actively selects documents that exert a disproportionately large influence on the current residual to compute the next update. On several real-world datasets, including 3M articles from Wikipedia, we demonstrate that residual LDA can handily analyze massive document collections and find topic models as good or better than those found with batch VB and randomly scheduled VB, and significantly faster.

#index 1617372
#* A community-based pseudolikelihood approach for relationship labeling in social networks
#@ Huaiyu Wan;Youfang Lin;Zhihao Wu;Houkuan Huang
#t 2011
#c 22
#% 44876
#% 464434
#% 844322
#% 1000502
#% 1176950
#% 1214703
#% 1451159
#% 1650318
#% 1650403
#! A social network consists of people (or other social entities) connected by a set of social relationships. Awareness of the relationship types is very helpful for us to understand the structure and the characteristics of the social network. Traditional classifiers are not accurate enough for relationship labeling since they assume that all the labels are independent and identically distributed. A relational probabilistic model, relational Markov networks (RMNs), is introduced to labeling relationships, but the inefficient parameter estimation makes it difficult to deploy in large-scale social networks. In this paper, we propose a communitybased pseudolikelihood (CBPL) approach for relationship labeling. The community structure of a social network is used to assist in constructing the conditional random field, and this makes our approach reasonable and accurate. In addition, the computational simplicity of pseudolikelihood effectively resolves the time complexity problem which RMNs are suffering. We apply our approach on two real-world social networks, one is a terrorist relation network and the other is a phone call network we collected from encrypted call detail records. In our experiments, for avoiding losing links while splitting a closely connected social network into separate training and test subsets, we split the datasets according to the links rather than the individuals. The experimental results show that our approach performs well in terms of accuracy and efficiency.

#index 1617373
#* Correcting bias in statistical tests for network classifier evaluation
#@ Tao Wang;Jennifer Neville;Brian Gallagher;Tina Eliassi-Rad
#t 2011
#c 22
#% 272995
#% 580511
#% 793234
#% 961278
#% 1715951
#! It is difficult to directly apply conventional significance tests to compare the performance of network classification models because network data instances are not independent and identically distributed. Recent work [6] has shown that paired t-tests applied to overlapping network samples will result in unacceptably high levels (e.g., up to 50%) of Type I error (i.e., the tests lead to incorrect conclusions that models are different, when they are not). Thus, we need new strategies to accurately evaluate network classifiers. In this paper, we analyze the sources of bias (e.g. dependencies among network data instances) theoretically and propose analytical corrections to standard significance tests to reduce the Type I error rate to more acceptable levels, while maintaining reasonable levels of statistical power to detect true performance differences. We validate the effectiveness of the proposed corrections empirically on both synthetic and real networks.

#index 1617374
#* Differentiating code from data in x86 binaries
#@ Richard Wartell;Yan Zhou;Kevin W. Hamlen;Murat Kantarcioglu;Bhavani Thuraisingham
#t 2011
#c 22
#% 38374
#% 393450
#% 740410
#% 961230
#% 979486
#% 1105280
#% 1150992
#% 1171913
#% 1704144
#! Robust, static disassembly is an important part of achieving high coverage for many binary code analyses, such as reverse engineering, malware analysis, reference monitor in-lining, and software fault isolation. However, one of the major difficulties current disassemblers face is differentiating code from data when they are interleaved. This paper presents a machine learning-based disassembly algorithm that segments an x86 binary into subsequences of bytes and then classifies each subsequence as code or data. The algorithm builds a language model from a set of pre-tagged binaries using a statistical data compression technique. It sequentially scans a new binary executable and sets a breaking point at each potential code-to-code and code-to-data/data-to-code transition. The classification of each segment as code or data is based on the minimum cross-entropy. Experimental results are presented to demonstrate the effectiveness of the algorithm.

#index 1617375
#* Bayesian matrix co-factorization: variational algorithm and Cramér-Rao bound
#@ Jiho Yoo;Seungjin Choi
#t 2011
#c 22
#% 135331
#% 818234
#% 840924
#% 987253
#% 1073982
#% 1083696
#% 1100108
#% 1232028
#% 1260273
#% 1333074
#% 1756613
#% 1826318
#! Matrix factorization is a popular method for collaborative prediction, where unknown ratings are predicted by user and item factor matrices which are determined to approximate a user-item matrix as their product. Bayesian matrix factorization is preferred over other methods for collaborative filtering, since Bayesian approach alleviates overfitting, integrating out all model parameters using variational inference or sampling methods. However, Bayesian matrix factorization still suffers from the cold-start problem where predictions of ratings for new items or of new users' preferences are required. In this paper we present Bayesian matrix co-factorization as an approach to exploiting side information such as content information and demographic user data, where multiple data matrices are jointly decomposed, i.e., each Bayesian decomposition is coupled by sharing some factor matrices. We derive variational inference algorithm for Bayesian matrix co-factorization. In addition, we compute Bayesian Cramér-Rao bound in the case of Gaussian likelihood, showing that Bayesian matrix co-factorization indeed improves the reconstruction over Bayesian factorization of single data matrix. Numerical experiments demonstrate the useful behavior of Bayesian matrix co-factorization in the case of cold-start problems.

#index 1617376
#* Learning from inconsistent and unreliable annotators by a Gaussian mixture model and Bayesian information criterion
#@ Ping Zhang;Zoran Obradovic
#t 2011
#c 22
#% 891559
#% 925099
#% 1083692
#% 1117687
#% 1130870
#% 1211801
#% 1214647
#% 1264744
#! Supervised learning from multiple annotators is an increasingly important problem in machine leaning and data mining. This paper develops a probabilistic approach to this problem when annotators are not only unreliable, but also have varying performance depending on the data. The proposed approach uses a Gaussian mixture model (GMM) and Bayesian information criterion (BIC) to find the fittest model to approximate the distribution of the instances. Then the maximum a posterior (MAP) estimation of the hidden true labels and the maximum-likelihood (ML) estimation of quality of multiple annotators are provided alternately. Experiments on emotional speech classification and CASP9 protein disorder prediction tasks show performance improvement of the proposed approach as compared to the majority voting baseline and a previous data-independent approach. Moreover, the approach also provides more accurate estimates of individual annotators performance for each Gaussian component, thus paving the way for understanding the behaviors of each annotator.

#index 1617377
#* iDVS: an interactive multi-document visual summarization system
#@ Yi Zhang;Dingding Wang;Tao Li
#t 2011
#c 22
#% 173424
#% 201992
#% 280835
#% 316539
#% 340884
#% 340971
#% 344430
#% 434614
#% 436509
#% 787502
#% 797556
#% 815920
#% 816173
#% 823086
#% 867378
#% 879448
#% 989597
#% 1019080
#% 1074087
#% 1074089
#% 1137815
#% 1147594
#% 1251709
#% 1275040
#% 1275213
#% 1292520
#% 1450891
#% 1455666
#% 1546444
#% 1705532
#% 1705533
#! Multi-document summarization is a fundamental tool for understanding documents. Given a collection of documents, most of existing multidocument summarization methods automatically generate a static summary for all the users using unsupervised learning techniques such as sentence ranking and clustering. However, these methods almost exclude human from the summarization process. They do not allow for user interaction and do not consider users' feedback which delivers valuable information and can be used as the guidance for summarization. Another limitation is that the generated summaries are displayed in textual format without visual representation. To address the above limitations, in this paper, we develop iDVS, a visualization-enabled multi-document summarization system with users' interaction, to improve the summarization performance using users' feedback and to assist users in document understanding using visualization techniques. In particular, iDVS uses a new semi-supervised document summarization method to dynamically select sentences based on users' interaction. To this regard, iDVS tightly integrates semi-supervised learning with interactive visualization for document summarization. Comprehensive experiments on multi-document summarization using benchmark datasets demonstrate the effectiveness of iDVS, and a user study is conducted to evaluate the users' satisfaction.

#index 1617378
#* Discriminative experimental design
#@ Yu Zhang;Dit-Yan Yeung
#t 2011
#c 22
#% 80995
#% 116165
#% 170649
#% 464268
#% 466419
#% 466576
#% 466887
#% 732385
#% 763708
#% 770771
#% 875997
#% 876080
#% 1073923
#% 1074130
#% 1211809
#% 1272282
#! Since labeling data is often both laborious and costly, the labeled data available in many applications is rather limited. Active learning is a learning approach which actively selects unlabeled data points to label as a way to alleviate the labeled data deficiency problem. In this paper, we extend a previous active learning method called transductive experimental design (TED) by proposing a new unlabeled data selection criterion. Our method, called discriminative experimental design (DED), incorporates both margin-based discriminative information and data distribution information and hence it can be seen as a discriminative extension of TED. We report experiments conducted on some benchmark data sets to demonstrate the effectiveness of DED.

#index 1617379
#* Active learning with evolving streaming data
#@ Indrė Žliobaitė;Albert Bifet;Bernhard Pfahringer;Geoff Holmes
#t 2011
#c 22
#% 169717
#% 170649
#% 240794
#% 266787
#% 763708
#% 796204
#% 961177
#% 1056031
#% 1116999
#% 1267711
#% 1318705
#% 1472282
#% 1545027
#% 1565633
#% 1710584
#! In learning to classify streaming data, obtaining the true labels may require major effort and may incur excessive cost. Active learning focuses on learning an accurate model with as few labels as possible. Streaming data poses additional challenges for active learning, since the data distribution may change over time (concept drift) and classifiers need to adapt. Conventional active learning strategies concentrate on querying the most uncertain instances, which are typically concentrated around the decision boundary. If changes do not occur close to the boundary, they will be missed and classifiers will fail to adapt. In this paper we develop two active learning strategies for streaming data that explicitly handle concept drift. They are based on uncertainty, dynamic allocation of labeling efforts over time and randomization of the search space. We empirically demonstrate that these strategies react well to changes that can occur anywhere in the instance space and unexpectedly.

#index 1617380
#* Celebrity watch: browsing news content by exploiting social intelligence
#@ Omar Ali;Ilias Flaounas;Tijl De Bie;Nello Cristianini
#t 2011
#c 22
#% 956521
#% 1133536
#% 1264288
#% 1581970
#! Celebrity Watch is an automatically-generated website that presents up-to-date entertainment news from around the world. It demonstrates the application of many pattern analysis methods that allow us to autonomously monitor millions of news articles and hundreds of millions of references to people mentioned in them. We apply statistical methods to merge references into people, track their association to various topics of news, and generate social networks of their co-occurrences in articles. From this sea of data we select the forty most-relevant people and display them on the website, offering users a highly condensed view of the latest in entertainment news. The site updates itself throughout the day and is the final step in a large, fully-autonomous system that monitors online news media.

#index 1617381
#* MOA: a real-time analytics open source framework
#@ Albert Bifet;Geoff Holmes;Bernhard Pfahringer;Jesse Read;Philipp Kranen;Hardy Kremer;Timm Jansen;Thomas Seidl
#t 2011
#c 22
#% 1214635
#% 1472282
#% 1605979
#% 1606025
#! Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA is designed to deal with the challenging problems of scaling up the implementation of state of the art algorithms to real world dataset sizes and of making algorithms comparable in benchmark streaming settings. It contains a collection of offline and online algorithms for classification, clustering and graph mining as well as tools for evaluation. For researchers the framework yields insights into advantages and disadvantages of different approaches and allows for the creation of benchmark streaming data sets through stored, shared and repeatable settings for the data feeds. Practitioners can use the framework to easily compare algorithms and apply them to real world data sets and settings. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis. Besides providing algorithms and measures for evaluation and comparison, MOA is easily extensible with new contributions and allows for the creation of benchmark scenarios.

#index 1617382
#* L-SME: a system for mining loosely structured motifs
#@ Fabio Fassetti;Gianluigi Greco;Giorgio Terracina
#t 2011
#c 22
#% 1119127
#! We present L-SME, a system to efficiently identify loosely structured motifs in genome-wide applications. L-SME is innovative in three aspects. Firstly, it handles wider classes of motifs than earlier motif discovery systems, by supporting boxes swaps and skips in the motifs structure as well as various kinds of similarity functions. Secondly, in addition to the standard exact search, it supports search via randomization in which guarantees on the quality of the results can be given a-priori based on user-definable resource (time and space) constraints. Finally, L-SME comes equipped with an intuitive graphical interface through which the structure for the motifs of interest can be defined, the discovery method can be selected, and results can be visualized. The tool is flexible and scalable, by allowing genome-wide searches for very complex motifs and is freely accessible at http://siloe.deis.unical.it/l-sme. A detailed description of the algorithms underlying L-SME is available in [1].

#index 1617383
#* The MASH project
#@ Franćois Fleuret;Philip Abbet;Charles Dubout;Leonidas Lefakis
#t 2011
#c 22
#! It has been demonstrated repeatedly that combiningmultiple types of image features improves the performance of learning-based classification and regression. However, no tools exist to facilitate the creation of large pools of feature extractors by extended teams of contributors. The MASH project aims at creating such tools. It is organized around the development of a collaborative web platform where participants can contribute feature extractors, browse a repository of existing ones, run image classification and goal-planning experiments, and participate in public large-scale experiments and contests. The tools provided on the platform facilitate the analysis of experimental results. In particular, they rank the feature extractors according to their efficiency, and help to identify the failure mode of the prediction system.

#index 1617384
#* Activity recognition with mobile phones
#@ Jordan Frank;Shie Mannor;Doina Precup
#t 2011
#c 22
#% 309208
#% 857125
#% 1668024
#! Our demonstration consists of a working activity and gait recognition system, implemented on a commercial smartphone. The activity recognition feature allows participants to train various activities, such as running, walking, or jumping, on the phone; the system can then identify when those activities are performed. The gait recognition feature learns particular characteristics of how participants walk, allowing the phone to identify the person carrying it.

#index 1617385
#* MIME: a framework for interactive visual pattern mining
#@ Bart Goethals;Sandy Moens;Jilles Vreeken
#t 2011
#c 22
#% 310517
#% 434613
#% 577214
#% 867057
#% 1083743
#% 1428404
#% 1428407
#% 1561599
#% 1705413
#! We present a framework for interactive visual pattern mining. Our system enables the user to browse through the data and patterns easily and intuitively, using a toolbox consisting of interestingness measures, mining algorithms and post-processing algorithms to assist in identifying interesting patterns. By mining interactively, we enable the user to combine their subjective interestingness measure and background knowledge with a wide variety of objective measures to easily and quickly mine the most important and interesting patterns. Basically, we enable the user to become an essential part of the mining algorithm. Our demo currently applies to mining interesting itemsets and association rules, and its extension to episodes and decision trees is ongoing research.

#index 1617386
#* InFeRno: an intelligent framework for recognizing pornographic web pages
#@ Sotiris Karavarsamis;Nikos Ntarmos;Konstantinos Blekas
#t 2011
#c 22
#% 457672
#% 975161
#% 1403925
#% 1798931
#! In this work we present InFeRno, an intelligent web pornography elimination system, classifying web pages based solely on their visual content. The main characteristics of our system include: (i) a powerful vector space with a small but sufficient number of features that manage to improve the discriminative ability of the SVM classifier; (ii) an extra class (bikini) that strengthens the performance of the classifier; (iii) an overall classification scheme that achieves high accuracy at considerably lower runtime costs compared to current state-of-the-art systems; and (iv) a full-fledged implementation of the proposed system capable of being integrated with ICAP-aware web proxy cache servers.

#index 1617387
#* Metadata retrieval: a software prototype for the annotation of maps with social metadata
#@ Rosa Meo;Elena Roglia;Enrico Ponassi
#t 2011
#c 22
#% 1147432
#% 1190117
#! MetaData Retrieval (MDR) is a software module for the enrichment of geo-referenced maps with metadata. Metadata are annotations on spatial locations that are taken from the Volunteered Graphical Information projects like OpenStreetMap and GeoNames. The MDR user acts with a user-friendly GUI, a Query By Example in which the user specifies in a multi-dimensional data model the spatial objects for which new information are searched for. The request is translated into SQL queries for the database and in web service requests for OpenStreetMap and GeoNames. Downloaded annotations are checked and compared with the history for duplicate elimination. Annotations are presented to the user in the context of an interactive, geo-referenced map and in a hierarchical, ontological structure, that is a facility for indexing and browsing. On demand, an annotation is stored in the system history. Finally, the user can filter the annotations that characterize a specified area by a statistical filter that compares the annotation frequency with the neighborhood.

#index 1617388
#* TRUMIT: a tool to support large-scale mining of text association rules
#@ Robert Neumayer;George Tsatsaronis;Kjetil Nørvåg
#t 2011
#c 22
#% 152934
#% 845266
#% 1192968
#% 1195875
#! Due to the nature of textual data the application of association rule mining in text corpora has attracted the focus of the research scientific community for years. In this paper we demonstrate a system that can efficiently mine association rules from text. The system annotates terms using several annotators, and extracts text association rules between terms or categories of terms. An additional contribution of this work is the inclusion of novel unsupervised evaluation measures for weighting and ranking the importance of the text rules. We demonstrate the functionalities of our system with two text collections, a set ofWikileaks documents, and one from TREC-7.

#index 1617389
#* Traffic jams detection using flock mining
#@ Rebecca Ong;Fabio Pinelli;Roberto Trasarti;Mirco Nanni;Chiara Renso;Salvatore Rinzivillo;Fosca Giannotti
#t 2011
#c 22
#% 907380
#% 985939
#% 1496818
#% 1953174

#index 1617390
#* Exploring city structure from georeferenced photos using graph centrality measures
#@ Katerina Vrotsou;Natalia Andrienko;Gennady Andrienko;Piotr Jankowski
#t 2011
#c 22
#% 1147435
#% 1190131
#% 1511765
#% 1523309
#% 1585843
#! We explore the potential of applying graph theory measures of centrality to the network of movements extracted from sequences of georeferenced photo captures in order to identify interesting places and explore city structure. We adopt a systematic procedure composed of a series of stages involving the combination of computational methods and interactive visual analytics techniques. The approach is demonstrated using a collection of Flickr photos from the Seattle metropolitan area.

#index 1700925
#* Machine Learning and Knowledge Discovery in Databases, Part III: European Conference, ECML PKDD 2010, Athens, Greece, September 5-9, 2011, ... / Lecture Notes in Artificial Intelligence)
#@ Dimitrios Gunopulos;Thomas Hofmann;Donato Malerba;Michalis Vazirgiannis
#t 2011
#c 22
#! This three-volume set LNAI 6911, LNAI 6912, and LNAI 6913 constitutes the refereed proceedings of the European conference on Machine Learning and Knowledge Discovery in Databases: ECML PKDD 2011, held in Athens, Greece, in September 2011. The 121 revised full papers presented together with 10 invited talks and 11 demos in the three volumes, were carefully reviewed and selected from about 600 paper submissions. The papers address all areas related to machine learning and knowledge discovery in databases as well as other innovative application domains such as supervised and unsupervised learning with some innovative contributions in fundamental issues; dimensionality reduction, distance and similarity learning, model learning and matrix/tensor analysis; graph mining, graphical models, hidden markov models, kernel methods, active and ensemble learning, semi-supervised and transductive learning, mining sparse representations, model learning, inductive logic programming, and statistical learning. a significant part of the papers covers novel and timely applications of data mining and machine learning in industrial domains.

#index 1925393
#* Proceedings of the 2012 European conference on Machine Learning and Knowledge Discovery in Databases - Volume Part I
#@ Peter A. Flach;Tijl Bie;Nello Cristianini
#t 2012
#c 22

#index 1925394
#* Machine learning for robotics
#@ Pieter Abbeel
#t 2012
#c 22
#! Robots are typically far less capable in autonomous mode than in tele-operated mode. The few exceptions tend to stem from long days (and more often weeks, or even years) of expert engineering for a specific robot and its operating environment. Current control methodology is quite slow and labor intensive. I believe advances in machine learning have the potential to revolutionize robotics. In this talk, I will present new machine learning techniques we have developed that are tailored to robotics. I will describe in depth "Apprenticeship learning", a new approach to high-performance robot control based on learning for control from ensembles of expert human demonstrations. Our initial work in apprenticeship learning has enabled the most advanced helicopter aerobatics to-date, including maneuvers such as chaos, tic-tocs, and auto-rotation landings which only exceptional expert human pilots can fly. Our most recent work in apprenticeship learning is providing traction on learning to perform challenging robotic manipulation tasks, such as knot-tying. I will also briefly highlight three other machine learning for robotics developments: Inverse reinforcement learning and its application to quadruped locomotion, Safe exploration in reinforcement learning which enables robots to learn on their own, and Learning for perception with application to robotic laundry.

#index 1925395
#* Declarative modeling for machine learning and data mining
#@ Luc De Raedt
#t 2012
#c 22
#! Despite the popularity of machine learning and data mining today, it remains challenging to develop applications and software that incorporates machine learning or data mining techniques. This is because machine learning and data mining have focussed on developing high-performance algorithms for solving particular tasks rather than on developing general principles and techniques. I propose to alleviate these problems by applying the constraint programming methodology to machine learning and data mining and to specify machine learning and data mining problems as constraint satisfaction and optimization problems. What is essential is that the user be provided with a way to declaratively specify what the machine learning or data mining problem is rather than having to outline how that solution needs to be computed. This corresponds to a model + solver-based approach to machine learning and data mining, in which the user specifies the problem in a high level modeling language and the system automatically transforms such models into a format that can be used by a solver to efficiently generate a solution. This should be much easier for the user than having to implement or adapt an algorithm that computes a particular solution to a specific problem. Throughout the talk, I shall use illustrations from our work on constraint programming for itemset mining and probabilistic programming.

#index 1925396
#* Machine learning methods for music discovery and recommendation
#@ Douglas Eck
#t 2012
#c 22
#! In this talk I will relate current work at Google in music recommendation to the challenge of automatic music annotation ("autotagging"). I will spend most of the talk looking at (a) signal processing and sparse coding strategies for pulling relevant structure from audio, and (b) training multi-class ranking models in order to build good music similarity spaces. Although I will describe some technical aspects of autotagging and ranking via embedding, the main goal of the talk is to foster a better understanding of the real-world challenges we face in helping users find music they'll love. To this end I will play a number of audio demos illustrating what we can (and cannot) hope to achieve by working with audio.

#index 1925397
#* Solving problems with visual analytics: challenges and applications
#@ Daniel Keim
#t 2012
#c 22
#! Never before in history data is generated and collected at such high volumes as it is today. As the volumes of data available to business people, scientists, and the public increase, their effective use becomes more challenging. Keeping up to date with the flood of data, using standard tools for data analysis and exploration, is fraught with difficulty. The field of visual analytics seeks to provide people with better and more effective ways to explore and understand large datasets, while also enabling them to act upon their findings immediately. Visual analytics integrates the analytic capabilities of the computer and the perceptual and intellectual abilities of the human analyst, allowing novel discoveries and empowering individuals to take control of the analytical process. Visual analytics enables unexpected insights, which may lead to beneficial and profitable innovation. The talk presents the challenges of visual analytics and exemplifies them with several application examples, which illustrate the exiting potential of current visual analysis techniques but also their limitations.

#index 1925398
#* Analyzing text and social network data with probabilistic models
#@ Padhraic Smyth
#t 2012
#c 22
#! Exploring and understanding large text and social network data sets is of increasing interest across multiple fields, in computer science, social science, history, medicine, and more. This talk will present an overview of recent work using probabilistic latent variable models to analyze such data. Latent variable models have a long tradition in data analysis and typically hypothesize the existence of simple unobserved phenomena to explain relatively complex observed data. In the past decade there has been substantial work on extending the scope of these approaches from relatively small simple data sets to much more complex text and network data. We will discuss the basic concepts behind these developments, reviewing key ideas, recent advances, and open issues. In addition we will highlight common ideas that lie beneath the surface of different approaches including links (for example) to work in matrix factorization. The concluding part of the talk will focus more specifically on recent work with temporal social networks, specifically data in the form of time-stamped events between nodes (such as emails exchanged among individuals over time).

#index 1925399
#* Discovering descriptive tile trees: by mining optimal geometric subtiles
#@ Nikolaj Tatti;Jilles Vreeken
#t 2012
#c 22
#% 144520
#% 481290
#% 799752
#% 878207
#% 934581
#% 985041
#% 1108910
#% 1116995
#% 1117002
#% 1117701
#% 1214659
#% 1565634
#% 1605977
#% 1618915
#% 1673615
#! When analysing binary data, the ease at which one can interpret results is very important. Many existing methods, however, discover either models that are difficult to read, or return so many results interpretation becomes impossible. Here, we study a fully automated approach for mining easily interpretable models for binary data. We model data hierarchically with noisy tiles--rectangles with significantly different density than their parent tile. To identify good trees, we employ the Minimum Description Length principle. We propose Stijl, a greedy any-time algorithm for mining good tile trees from binary data. Iteratively, it finds the locally optimal addition to the current tree, allowing overlap with tiles of the same parent. A major result of this paper is that we find the optimal tile in only Θ(NM min(N,M)) time. Stijl can either be employed as a top-k miner, or by MDL we can identify the tree that describes the data best. Experiments show we find succinct models that accurately summarise the data, and, by their hierarchical property are easily interpretable.

#index 1925400
#* Efficient discovery of association rules and frequent itemsets through sampling with tight performance guarantees
#@ Matteo Riondato;Eli Upfal
#t 2012
#c 22
#% 93790
#% 152934
#% 190581
#% 345611
#% 481290
#% 481779
#% 498445
#% 577261
#% 614619
#% 629652
#% 722920
#% 729915
#% 772831
#% 800181
#% 867053
#% 882736
#% 897769
#% 985041
#% 1072644
#% 1180019
#% 1200937
#% 1222773
#% 1405146
#% 1456834
#% 1488039
#% 1563255
#% 1585677
#% 1605977
#% 1670486
#% 1704584
#% 1707832
#% 1707838
#% 1712895
#! The tasks of extracting (top-K) Frequent Itemsets (FI's) and Association Rules (AR's) are fundamental primitives in data mining and database applications. Exact algorithms for these problems exist and are widely used, but their running time is hindered by the need of scanning the entire dataset, possibly multiple times. High quality approximations of FI's and AR's are sufficient for most practical uses, and a number of recent works explored the application of sampling for fast discovery of approximate solutions to the problems. However, these works do not provide satisfactory performance guarantees on the quality of the approximation, due to the difficulty of bounding the probability of under- or over-sampling any one of an unknown number of frequent itemsets. In this work we circumvent this issue by applying the statistical concept of Vapnik-Chervonenkis (VC) dimension to develop a novel technique for providing tight bounds on the sample size that guarantees approximation within user-specified parameters. Our technique applies both to absolute and to relative approximations of (top-K) FI's and AR's. The resulting sample size is linearly dependent on the VC-dimension of a range space associated with the dataset to be mined. The main theoretical contribution of this work is a characterization of the VC-dimension of this range space and a proof that it is upper bounded by an easy-to-compute characteristic quantity of the dataset which we call d-index, namely the maximum integer d such that the dataset contains at least d transactions of length at least d. We show that this bound is strict for a large class of datasets. The resulting sample size for an absolute (resp. relative) (ε, δ)-approximation of the collection of FI's is $O(\frac{1}{\varepsilon^2}(d+\log\frac{1}{\delta}))$ (resp. $O(\frac{2+\varepsilon}{\varepsilon^2(2-\varepsilon)\theta}(d\log\frac{2+\varepsilon}{(2-\varepsilon)\theta}+\log\frac{1}{\delta}))$) transactions, which is a significant improvement over previous known results. We present an extensive experimental evaluation of our technique on real and artificial datasets, demonstrating the practicality of our methods, and showing that they achieve even higher quality approximations than what is guaranteed by the analysis.

#index 1925401
#* Smoothing categorical data
#@ Arno Siebes;René Kersten
#t 2012
#c 22
#% 232136
#% 235377
#% 878207
#% 1176932
#% 1301004
#% 1663670
#! Global models of a dataset reflect not only the large scale structure of the data distribution, they also reflect small(er) scale structure. Hence, if one wants to see the large scale structure, one should somehow subtract this smaller scale structure from the model. While for some kinds of model --- such as boosted classifiers --- it is easy to see the "important" components, for many kind of models this is far harder, if at all possible. In such cases one might try an implicit approach: simplify the data distribution without changing the large scale structure. That is, one might first smooth the local structure out of the dataset. Then induce a new model from this smoothed dataset. This new model should now reflect the large scale structure of the original dataset. In this paper we propose such a smoothing for categorical data and for one particular type of models, viz., code tables. By experiments we show that our approach preserves the large scale structure of a dataset well. That is, the smoothed dataset is simpler while the original and smoothed datasets share the same large scale structure.

#index 1925402
#* An experimental comparison of hybrid algorithms for bayesian network structure learning
#@ Maxime Gasse;Alex Aussem;Haytham Elghazel
#t 2012
#c 22
#% 44876
#% 101213
#% 197387
#% 400980
#% 722900
#% 763715
#% 893460
#% 977231
#% 1270262
#% 1373045
#% 1386105
#% 1386107
#% 1415214
#% 1417383
#% 1496781
#% 1496791
#% 1650289
#% 1679235
#% 1765812
#! We present a novel hybrid algorithm for Bayesian network structure learning, called Hybrid HPC (H2PC). It first reconstructs the skeleton of a Bayesian network and then performs a Bayesian-scoring greedy hill-climbing search to orient the edges. It is based on a subroutine called HPC, that combines ideas from incremental and divide-and-conquer constraint-based methods to learn the parents and children of a target variable. We conduct an experimental comparison of H2PC against Max-Min Hill-Climbing (MMHC), which is currently the most powerful state-of-the-art algorithm for Bayesian network structure learning, on several benchmarks with various data sizes. Our extensive experiments show that H2PC outperforms MMHC both in terms of goodness of fit to new data and in terms of the quality of the network structure itself, which is closer to the true dependence structure of the data. The source code (in R) of H2PC as well as all data sets used for the empirical tests are publicly available.

#index 1925403
#* Bayesian network classifiers with reduced precision parameters
#@ Sebastian Tschiatschek;Peter Reinprecht;Manfred Mücke;Franz Pernkopf
#t 2012
#c 22
#% 44876
#% 246832
#% 334566
#% 356892
#% 788044
#% 810949
#% 810951
#% 891559
#% 1272350
#% 1417383
#% 1440783
#% 1472311
#% 1692359
#! Bayesian network classifiers (BNCs) are probabilistic classifiers showing good performance in many applications. They consist of a directed acyclic graph and a set of conditional probabilities associated with the nodes of the graph. These conditional probabilities are also referred to as parameters of the BNCs. According to common belief, these classifiers are insensitive to deviations of the conditional probabilities under certain conditions. The first condition is that these probabilities are not too extreme, i.e. not too close to 0 or 1. The second is that the posterior over the classes is significantly different. In this paper, we investigate the effect of precision reduction of the parameters on the classification performance of BNCs. The probabilities are either determined generatively or discriminatively. Discriminative probabilities are typically more extreme. However, our results indicate that BNCs with discriminatively optimized parameters are almost as robust to precision reduction as BNCs with generatively optimized parameters. Furthermore, even large precision reduction does not decrease classification performance significantly. Our results allow the implementation of BNCs with less computational complexity. This supports application in embedded systems using floating-point numbers with small bit-width. Reduced bit-widths further enable to represent BNCs in the integer domain while maintaining the classification performance.

#index 1925404
#* Combining subjective probabilities and data in training markov logic networks
#@ Tivadar Pápai;Shalini Ghosh;Henry Kautz
#t 2012
#c 22
#% 28292
#% 44876
#% 165793
#% 891559
#% 961183
#% 1074125
#% 1148262
#% 1211770
#% 1250579
#% 1264785
#% 1417383
#% 1467732
#% 1473382
#% 1610429
#% 1650582
#! Markov logic is a rich language that allows one to specify a knowledge base as a set of weighted first-order logic formulas, and to define a probability distribution over truth assignments to ground atoms using this knowledge base. Usually, the weight of a formula cannot be related to the probability of the formula without taking into account the weights of the other formulas. In general, this is not an issue, since the weights are learned from training data. However, in many domains (e.g. healthcare, dependable systems, etc.), only little or no training data may be available, but one has access to a domain expert whose knowledge is available in the form of subjective probabilities. Within the framework of Bayesian statistics, we present a formalism for using a domain expert's knowledge for weight learning. Our approach defines priors that are different from and more general than previously used Gaussian priors over weights. We show how one can learn weights in an MLN by combining subjective probabilities and training data, without requiring that the domain expert provides consistent knowledge. Additionally, we also provide a formalism for capturing conditional subjective probabilities, which are often easier to obtain and more reliable than non-conditional probabilities. We demonstrate the effectiveness of our approach by extensive experiments in a domain that models failure dependencies in a cyber-physical system. Moreover, we demonstrate the advantages of using our proposed prior over that of using non-zero mean Gaussian priors in a commonly cited social network MLN testbed.

#index 1925405
#* Score-Based bayesian skill learning
#@ Shengbo Guo;Scott Sanner;Thore Graepel;Wray Buntine
#t 2012
#c 22
#% 837639
#% 1100158
#% 1650536
#% 1810385
#! We extend the Bayesian skill rating system of TrueSkill to accommodate score-based match outcomes. TrueSkill has proven to be a very effective algorithm for matchmaking -- the process of pairing competitors based on similar skill-level -- in competitive online gaming. However, for the case of two teams/players, TrueSkill only learns from win, lose, or draw outcomes and cannot use additional match outcome information such as scores. To address this deficiency, we propose novel Bayesian graphical models as extensions of TrueSkill that (1) model player's offence and defence skills separately and (2) model how these offence and defence skills interact to generate score-based match outcomes. We derive efficient (approximate) Bayesian inference methods for inferring latent skills in these new models and evaluate them on three real data sets including Halo 2 XBox Live matches. Empirical evaluations demonstrate that the new score-based models (a) provide more accurate win/loss probability estimates than TrueSkill when training data is limited, (b) provide competitive and often better win/loss classification performance than TrueSkill, and (c) provide reasonable score outcome predictions with an appropriate choice of likelihood -- prediction for which TrueSkill was not designed, but which can be useful in many applications.

#index 1925406
#* A note on extending generalization bounds for binary large-margin classifiers to multiple classes
#@ Ürün Dogan;Tobias Glasmachers;Christian Igel
#t 2012
#c 22
#% 116149
#% 197394
#% 283859
#% 393059
#% 722816
#% 743284
#% 829043
#% 944007
#% 1074041
#% 1108844
#% 1260915
#! A generic way to extend generalization bounds for binary large-margin classifiers to large-margin multi-category classifiers is presented. The simple proceeding leads to surprisingly tight bounds showing the same $\tilde{O}(d^2)$ scaling in the number d of classes as state-of-the-art results. The approach is exemplified by extending a textbook bound based on Rademacher complexity, which leads to a multi-class bound depending on the sum of the margin violations of the classifier.

#index 1925407
#* Extension of the rocchio classification method to multi-modal categorization of documents in social media
#@ Amin Mantrach;Jean-Michel Renders
#t 2012
#c 22
#% 248810
#% 309142
#% 464267
#% 465895
#% 466896
#% 815908
#% 987226
#% 987241
#% 1077150
#% 1106226
#% 1536568
#% 1806010
#! Most of the approaches in multi-view categorization use early fusion, late fusion or co-training strategies. We propose here a novel classification method that is able to efficiently capture the interactions across the different modes. This method is a multi-modal extension of the Rocchio classification algorithm --- very popular in the Information Retrieval community. The extension consists of simultaneously maintaining different "centroid" representations for each class, in particular "cross-media" centroids that correspond to pairs of modes. To classify new data points, different scores are derived from similarity measures between the new data point and these different centroids; a global classification score is finally obtained by suitably aggregating the individual scores. This method outperforms the multi-view logistic regression approach (using either the early fusion or the late fusion strategies) on a social media corpus - namely the ENRON email collection - on two very different categorization tasks (folder classification and recipient prediction).

#index 1925408
#* Label-Noise robust logistic regression and its applications
#@ Jakramate Bootkrajang;Ata Kabán
#t 2012
#c 22
#% 72851
#% 124467
#% 443991
#% 464287
#% 482034
#% 494822
#% 635689
#% 906491
#% 906573
#% 961275
#% 1374646
#% 1472273
#% 1861282
#! The classical problem of learning a classifier relies on a set of labelled examples, without ever questioning the correctness of the provided label assignments. However, there is an increasing realisation that labelling errors are not uncommon in real situations. In this paper we consider a label-noise robust version of the logistic regression and multinomial logistic regression classifiers and develop the following contributions: (i) We derive efficient multiplicative updates to estimate the label flipping probabilities, and we give a proof of convergence for our algorithm. (ii) We develop a novel sparsity-promoting regularisation approach which allows us to tackle challenging high dimensional noisy settings. (iii) Finally, we throughly evaluate the performance of our approach in synthetic experiments and we demonstrate several real applications including gene expression analysis, class topology discovery and learning from crowdsourcing data.

#index 1925409
#* Sentiment classification with supervised sequence embedding
#@ Dmitriy Bespalov;Yanjun Qi;Bing Bai;Ali Shokoufandeh
#t 2012
#c 22
#% 280819
#% 311027
#% 466501
#% 501994
#% 722803
#% 722904
#% 722928
#% 763708
#% 818217
#% 818236
#% 833913
#% 1014683
#% 1073892
#% 1127964
#% 1155294
#% 1173693
#% 1254294
#% 1343447
#% 1434468
#% 1457039
#% 1471319
#% 1641958
#! In this paper, we introduce a novel approach for modeling n-grams in a latent space learned from supervised signals. The proposed procedure uses only unigram features to model short phrases (n-grams) in the latent space. The phrases are then combined to form document-level latent representation for a given text, where position of an n-gram in the document is used to compute corresponding combining weight. The resulting two-stage supervised embedding is then coupled with a classifier to form an end-to-end system that we apply to the large-scale sentiment classification task. The proposed model does not require feature selection to retain effective features during pre-processing, and its parameter space grows linearly with size of n-gram. We present comparative evaluations of this method using two large-scale datasets for sentiment classification in online reviews (Amazon and TripAdvisor). The proposed method outperforms standard baselines that rely on bag-of-words representation populated with n-gram features.

#index 1925410
#* The bitvector machine: a fast and robust machine learning algorithm for non-linear problems
#@ Stefan Edelkamp;Martin Stommel
#t 2012
#c 22
#% 309208
#% 321455
#% 402289
#% 464605
#% 464888
#% 465031
#% 635689
#% 916781
#% 940104
#% 983918
#% 1058303
#% 1058620
#% 1265149
#% 1373450
#% 1472278
#% 1765518
#! In this paper we present and evaluate a simple but effective machine learning algorithm that we call Bitvector Machine: Feature vectors are partitioned along component-wise quantiles and converted into bitvectors that are learned. It is shown that the method is efficient in both training and classification. The effectiveness of the method is analysed theoretically for best and worst-case scenarios. Experiments on high-dimensional synthetic and real world data show a huge speed boost compared to Support Vector Machines with RBF kernel. By tabulating kernel functions, computing medians in linear-time, and exploiting modern processor technology for advanced bitvector operations, we achieve a speed-up of 32 for classification and 48 for kernel evaluation compared to the popular LIBSVM. Although the method does not generally outperform a SVM with RBF kernel it achieves a high classification accuracy and has qualitative advantages over the linear classifier.

#index 1925411
#* Embedding monte carlo search of features in tree-based ensemble methods
#@ Francis Maes;Pierre Geurts;Louis Wehenkel
#t 2012
#c 22
#% 73374
#% 302391
#% 400847
#% 413955
#% 421188
#% 770857
#% 841926
#% 866298
#% 867107
#% 875965
#% 1211752
#% 1246315
#% 1248879
#% 1272358
#% 1280028
#% 1305362
#% 1401035
#% 1781536
#! Feature generation is the problem of automatically constructing good features for a given target learning problem. While most feature generation algorithms belong either to the filter or to the wrapper approach, this paper focuses on embedded feature generation. We propose a general scheme to embed feature generation in a wide range of tree-based learning algorithms, including single decision trees, random forests and tree boosting. It is based on the formalization of feature construction as a sequential decision making problem addressed by a tractable Monte Carlo search algorithm coupled with node splitting. This leads to fast algorithms that are applicable to large-scale problems. We empirically analyze the performances of these tree-based learners combined or not with the feature generation capability on several standard datasets.

#index 1925412
#* Hypergraph spectra for semi-supervised feature selection
#@ Zhihong Zhang;Edwin R. Hancock;Xiao Bai
#t 2012
#c 22
#% 213687
#% 265575
#% 266426
#% 592402
#% 720010
#% 729437
#% 812579
#% 814023
#% 836827
#% 875947
#% 983948
#% 1074364
#% 1128929
#% 1270195
#% 1300087
#% 1446972
#% 1451172
#% 1606587
#% 1667706
#% 1826317
#% 1862454
#! In many data analysis tasks, one is often confronted with the problem of selecting features from very high dimensional data. Most existing feature selection methods focus on ranking individual features based on a utility criterion, and select the optimal feature set in a greedy manner. However, the feature combinations found in this way do not give optimal classification performance, since they neglect the correlations among features. While the labeled data required by supervised feature selection can be scarce, there is usually no shortage of unlabeled data. In this paper, we propose a novel hypergraph based semi-supervised feature selection algorithm to select relevant features using both labeled and unlabeled data. There are two main contributions in this paper. The first is that by incorporating multidimensional interaction information (MII) for higher order similarities measure, we establish a novel hypergraph framework which is used for characterizing the multiple relationships within a set of samples. Thus, the structural information latent in the data can be more effectively modeled. Secondly, we derive a hypergraph subspace learning view of feature selection which casting the feature discriminant analysis into a regression framework that considers the correlations among features. As a result, we can evaluate joint feature combinations, rather than being confined to consider them individually. Experimental results demonstrate the effectiveness of our feature selection method on a number of standard face data-sets.

#index 1925413
#* Learning neighborhoods for metric learning
#@ Jun Wang;Adam Woznica;Alexandros Kalousis
#t 2012
#c 22
#% 13742
#% 529216
#% 977991
#% 983830
#% 995140
#% 1108888
#% 1211745
#% 1211774
#% 1232015
#% 1396466
#! Metric learning methods have been shown to perform well on different learning tasks. Many of them rely on target neighborhood relationships that are computed in the original feature space and remain fixed throughout learning. As a result, the learned metric reflects the original neighborhood relations. We propose a novel formulation of the metric learning problem in which, in addition to the metric, the target neighborhood relations are also learned in a two-step iterative approach. The new formulation can be seen as a generalization of many existing metric learning methods. The formulation includes a target neighbor assignment rule that assigns different numbers of neighbors to instances according to their quality; 'high quality' instances get more neighbors. We experiment with two of its instantiations that correspond to the metric learning algorithms LMNN and MCML and compare it to other metric learning methods on a number of datasets. The experimental results show state-of-the-art performance and provide evidence that learning the neighborhood relations does improve predictive performance.

#index 1925414
#* Massively parallel feature selection: an approach based on variance preservation
#@ Zheng Zhao;James Cox;David Duling;Warren Sarle
#t 2012
#c 22
#% 380564
#% 385564
#% 629628
#% 717417
#% 720010
#% 722929
#% 722943
#% 729437
#% 771842
#% 891084
#% 983907
#% 983940
#% 983948
#% 1228550
#% 1270195
#! Advances in computer technologies have enabled corporations to accumulate data at an unprecedented speed. Large-scale business data might contain billions of observations and thousands of features, which easily brings their scale to the level of terabytes. Most traditional feature selection algorithms are designed for a centralized computing architecture. Their usability significantly deteriorates when data size exceeds hundreds of gigabytes. High-performance distributed computing frameworks and protocols, such as the Message Passing Interface (MPI) and MapReduce, have been proposed to facilitate software development on grid infrastructures, enabling analysts to process large-scale problems efficiently. This paper presents a novel large-scale feature selection algorithm that is based on variance analysis. The algorithm selects features by evaluating their abilities to explain data variance. It supports both supervised and unsupervised feature selection and can be readily implemented in most distributed computing environments. The algorithm was developed as a SAS High-Performance Analytics procedure, which can read data in distributed form and perform parallel feature selection in both symmetric multiprocessing mode and massively parallel processing mode. Experimental results demonstrated the superior performance of the proposed method for large scale feature selection.

#index 1925415
#* PCA, eigenvector localization and clustering for side-channel attacks on cryptographic hardware devices
#@ Dimitrios Mavroeidis;Lejla Batina;Twan van Laarhoven;Elena Marchiori
#t 2012
#c 22
#% 512167
#% 514157
#% 514333
#% 560167
#% 560477
#% 770830
#% 929183
#% 995140
#% 1106317
#% 1109336
#% 1267991
#% 1677032
#% 1745120
#% 1746362
#% 1746384
#! Spectral methods, ranging from traditional Principal Components Analysis to modern Laplacian matrix factorization, have proven to be a valuable tool for a wide range of diverse data mining applications. Commonly these methods are stated as optimization problems and employ the extremal (maximal or minimal) eigenvectors of a certain input matrix for deriving the appropriate statistical inferences. Interestingly, recent studies have questioned this "modus operandi" and revealed that useful information may also be present within low-order eigenvectors whose mass is concentrated (localized) in a small part of their indexes. An application context where localized low-order eigenvectors have been successfully employed is "Differential Power Analysis" (DPA). DPA is a well studied side-channel attack on cryptographic hardware devices (such as smart cards) that employs statistical analysis of the device's power consumption in order to retrieve the secret key of the cryptographic algorithm. In this work we propose a data mining (clustering) formulation of the DPA process and also provide a theoretical model that justifies and explains the utility of low-order eigenvectors. In our data mining formulation, we consider that the key-relevant information is modelled as a "low-signal" pattern that is embedded in a "high-noise" dataset. In this respect our results generalize beyond DPA and are applicable to analogous low-signal, hidden pattern problems. The experimental results using power trace measurements from a programmable smart card, verify our approach empirically.

#index 1925416
#* Classifying stem cell differentiation images by information distance
#@ Xianglilan Zhang;Hongnan Wang;Tony J. Collins;Zhigang Luo;Ming Li
#t 2012
#c 22
#% 91028
#% 127154
#% 234979
#% 830880
#% 849867
#% 857308
#% 883475
#% 905998
#% 989659
#% 1246225
#% 1331884
#% 1542907
#% 1809406
#% 1815177
#! The ability of stem cells holds great potential for drug discovery and cell replacement therapy. To realize this potential, effective high content screening for drug candidates is required. Analysis of images from high content screening typically requires DNA staining to identify cell nuclei to do cell segmentation before feature extraction and classification. However, DNA staining has negative effects on cell growth, and segmentation algorithms err when compound treatments cause nuclear or cell swelling/shrinkage. In this paper, we introduced a novel Information Distance Classification (IDC) method, requiring no segmentation or feature extraction; hence no DNA staining is needed. In classifying 480 candidate compounds that may be used to stimulate stem cell differentiation, the proposed IDC method was demonstrated to achieve a 3% higher F1 score than conventional analysis. As far as we know, this is the first work to apply information distance in high content screening.

#index 1925417
#* Distance metric learning revisited
#@ Qiong Cao;Yiming Ying;Peng Li
#t 2012
#c 22
#% 209961
#% 443991
#% 812372
#% 829025
#% 983830
#% 1074017
#% 1415428
#% 1747258
#! The success of many machine learning algorithms (e.g. the nearest neighborhood classification and k-means clustering) depends on the representation of the data as elements in a metric space. Learning an appropriate distance metric from data is usually superior to the default Euclidean distance. In this paper, we revisit the original model proposed by Xing et al. [25] and propose a general formulation of learning a Mahalanobis distance from data. We prove that this novel formulation is equivalent to a convex optimization problem over the spectrahedron. Then, a gradient-based optimization algorithm is proposed to obtain the optimal solution which only needs the computation of the largest eigenvalue of a matrix per iteration. Finally, experiments on various UCI datasets and a benchmark face verification dataset called Labeled Faces in the Wild (LFW) demonstrate that the proposed method compares competitively to those state-of-the-art methods.

#index 1925418
#* Geodesic analysis on the gaussian RKHS hypersphere
#@ Nicolas Courty;Thomas Burger;Pierre-François Marteau
#t 2012
#c 22
#% 197394
#% 294964
#% 304931
#% 393059
#% 493731
#% 769935
#% 794860
#% 1189311
#% 1477689
#% 1495497
#% 1617279
#% 1750310
#% 1750633
#% 1861425
#! Using kernels to embed non linear data into high dimensional spaces where linear analysis is possible has become utterly classical. In the case of the Gaussian kernel however, data are distributed on a hypersphere in the corresponding Reproducing Kernel Hilbert Space (RKHS). Inspired by previous works in non-linear statistics, this article investigates the use of dedicated tools to take into account this particular geometry. Within this geometrical interpretation of the kernel theory, Riemannian distances are preferred over Euclidean distances. It is shown that this amounts to consider a new kernel and its corresponding RKHS. Experiments on real publicly available datasets show the possible benefits of the method on clustering tasks, notably through the definition of a new variant of kernel k-means on the hypersphere. Classification problems are also considered in a classwise setting. In both cases, the results show improvements over standard techniques.

#index 1925419
#* Boosting nearest neighbors for the efficient estimation of posteriors
#@ Roberto D'Ambrosio;Richard Nock;Wafa Bel Haj Ali;Frank Nielsen;Michel Barlaud
#t 2012
#c 22
#% 278833
#% 302391
#% 464440
#% 722921
#% 1286823
#% 1679593
#% 1811362
#% 1910898
#! It is an admitted fact that mainstream boosting algorithms like AdaBoost do not perform well to estimate class conditional probabilities. In this paper, we analyze, in the light of this problem, a recent algorithm, unn, which leverages nearest neighbors while minimizing a convex loss. Our contribution is threefold. First, we show that there exists a subclass of surrogate losses, elsewhere called balanced, whose minimization brings simple and statistically efficient estimators for Bayes posteriors. Second, we show explicit convergence rates towards these estimators for unn, for any such surrogate loss, under a Weak Learning Assumption which parallels that of classical boosting results. Third and last, we provide experiments and comparisons on synthetic and real datasets, including the challenging SUN computer vision database. Results clearly display that boosting nearest neighbors may provide highly accurate estimators, sometimes more than a hundred times more accurate than those of other contenders like support vector machines.

#index 1925420
#* Diversity regularized ensemble pruning
#@ Nan Li;Yang Yu;Zhi-Hua Zhou
#t 2012
#c 22
#% 697
#% 209021
#% 312727
#% 400985
#% 451221
#% 458196
#% 565528
#% 722806
#% 770854
#% 803770
#% 876021
#% 893457
#% 961134
#% 961181
#% 1164190
#% 1223456
#% 1229199
#% 1229259
#% 1246157
#% 1580952
#% 1736158
#% 1809314
#% 1826319
#% 1906161
#! Diversity among individual classifiers is recognized to play a key role in ensemble, however, few theoretical properties are known for classification. In this paper, by focusing on the popular ensemble pruning setting (i.e., combining classifier by voting and measuring diversity in pairwise manner), we present a theoretical study on the effect of diversity on the generalization performance of voting in the PAC-learning framework. It is disclosed that the diversity is closely-related to the hypothesis space complexity, and encouraging diversity can be regarded to apply regularization on ensemble methods. Guided by this analysis, we apply explicit diversity regularization to ensemble pruning, and propose the Diversity Regularized Ensemble Pruning (DREP) method. Experimental results show the effectiveness of DREP.

#index 1925421
#* Ensembles on random patches
#@ Gilles Louppe;Pierre Geurts
#t 2012
#c 22
#% 209021
#% 256615
#% 400847
#% 424996
#% 763710
#% 866298
#% 961134
#% 1399034
#% 1653970
#% 1688434
#! In this paper, we consider supervised learning under the assumption that the available memory is small compared to the dataset size. This general framework is relevant in the context of big data, distributed databases and embedded systems. We investigate a very simple, yet effective, ensemble framework that builds each individual model of the ensemble from a random patch of data obtained by drawing random subsets of both instances and features from the whole dataset. We carry out an extensive and systematic evaluation of this method on 29 datasets, using decision tree-based estimators. With respect to popular ensemble methods, these experiments show that the proposed method provides on par performance in terms of accuracy while simultaneously lowering the memory needs, and attains significantly better performance when memory is severely constrained.

#index 1925422
#* An efficiently computable support measure for frequent subgraph pattern mining
#@ Yuyi Wang;Jan Ramon
#t 2012
#c 22
#% 109538
#% 152934
#% 214222
#% 408396
#% 629646
#% 757953
#% 772884
#% 841960
#% 867050
#% 893371
#% 1268040
#% 1340065
#% 1411112
#% 1618916
#% 1654400
#% 1813351
#% 1925426
#! Graph support measures are functions measuring how frequently a given subgraph pattern occurs in a given database graph. An important class of support measures relies on overlap graphs. A major advantage of the overlap graph based approaches is that they combine anti-monotonicity with counting occurrences of a pattern which are independent according to certain criteria. However, existing overlap graph based support measures are expensive to compute. In this paper, we propose a new support measure which is based on a new notion of independence. We show that our measure is the solution to a linear program which is usually sparse, and using interior point methods can be computed efficiently. We show experimentally that for large networks, in contrast to earlier overlap graph based proposals, pattern mining based on our support measure is feasible.

#index 1925423
#* Efficient graph kernels by randomization
#@ Marion Neumann;Novi Patricia;Roman Garnett;Kristian Kersting
#t 2012
#c 22
#% 114667
#% 304917
#% 451933
#% 762054
#% 769891
#% 771841
#% 844291
#% 850430
#% 1183444
#% 1270261
#% 1318625
#% 1417084
#% 1472270
#% 1653962
#% 1826247
#! Learning from complex data is becoming increasingly important, and graph kernels have recently evolved into a rapidly developing branch of learning on structured data. However, previously proposed kernels rely on having discrete node label information. In this paper, we explore the power of continuous node-level features for propagation-based graph kernels. Specifically, propagation kernels exploit node label distributions from propagation schemes like label propagation, which naturally enables the construction of graph kernels for partially labeled graphs. In order to efficiently extract graph features from continuous node label distributions, and in general from continuous vector-valued node attributes, we utilize randomized techniques, which easily allow for deriving similarity measures based on propagated information. We show that propagation kernels utilizing locality-sensitive hashing reduce the runtime of existing graph kernels by several orders of magnitude. We evaluate the performance of various propagation kernels on real-world bioinformatics and image benchmark datasets.

#index 1925424
#* Graph mining for object tracking in videos
#@ Fabien Diot;Elisa Fromont;Baptiste Jeudy;Emmanuel Marilly;Olivier Martinot
#t 2012
#c 22
#% 349208
#% 629708
#% 748636
#% 823409
#% 903394
#% 915366
#% 1117699
#% 1268040
#% 1286833
#% 1470146
#% 1750448
#! This paper shows a concrete example of the use of graph mining for tracking objects in videos with moving cameras and without any contextual information on the objects to track. To make the mining algorithm efficient, we benefit from a video representation based on dynamic (evolving through time) planar graphs. We then define a number of constraints to efficiently find our so-called spatio-temporal graph patterns. Those patterns are linked through an occurrences graph to allow us to tackle occlusion or graph features instability problems in the video. Experiments on synthetic and real videos show that our method is effective and allows us to find relevant patterns for our tracking application.

#index 1925425
#* Hypergraph learning with hyperedge expansion
#@ Li Pu;Boi Faltings
#t 2012
#c 22
#% 239588
#% 722902
#% 840892
#% 840965
#% 875947
#% 983810
#% 995140
#% 1083698
#% 1383919
#% 1495453
#% 1506206
#% 1650754
#% 1667706
#% 1743967
#! We propose a new formulation called hyperedge expansion (HE) for hypergraph learning. The HE expansion transforms the hypergraph into a directed graph on the hyperedge level. Compared to the existing works (e.g. star expansion or normalized hypergraph cut), the learning results with HE expansion would be less sensitive to the vertex distribution among clusters, especially in the case that cluster sizes are unbalanced. Because of the special structure of the auxiliary directed graph, the linear eigenvalue problem of the Laplacian can be transformed into a quadratic eigenvalue problem, which has some special properties suitable for semi-supervised learning and clustering problems. We show in the experiments that the new algorithms based on the HE expansion achieves statistically significant gains in classification performance and good scalability for the co-occurrence data.

#index 1925426
#* Nearly exact mining of frequent trees in large networks
#@ Ashraf M. Kibriya;Jan Ramon
#t 2012
#c 22
#% 288990
#% 382569
#% 466644
#% 478274
#% 629603
#% 629708
#% 727845
#% 729938
#% 769940
#% 769951
#% 772884
#% 789011
#% 867873
#% 1083652
#% 1105380
#% 1232293
#% 1268040
#% 1328170
#% 1344280
#% 1449326
#% 1454139
#% 1605987
#% 1618916
#% 1673586
#% 1688444
#! Mining frequent patterns in a single network (graph) poses a number of challenges. Already only to match one path pattern to a network (upto subgraph isomorphism) is NP-complete. Matching algorithms that exist, become intractable even for reasonably small patterns, on networks which are large or have a high average degree. Based on recent advances in parameterized complexity theory, we propose a novel miner for rooted trees in networks. The miner, for a fixed parameter k (maximal pattern size), can mine all rooted trees with delay linear in the size of the network and only mildly exponential in the fixed parameter k (2k). This allows us to mine tractably, rooted trees, in large networks such as the WWW or social networks. We establish the practical applicability of our miner, by presenting an experimental evaluation on both synthetic and real-world data.

#index 1925427
#* Reachability analysis and modeling of dynamic event networks
#@ Kathy Macropol;Ambuj Singh
#t 2012
#c 22
#% 299941
#% 342592
#% 492784
#% 593994
#% 720278
#% 823342
#% 867050
#% 991977
#% 1082677
#% 1083675
#% 1083682
#% 1176970
#% 1176979
#% 1185580
#% 1246431
#% 1268028
#% 1369424
#% 1496777
#% 1523857
#% 1556619
#% 1635196
#% 1673564
#! A wealth of graph data, from email and telephone graphs to Twitter networks, falls into the category of dynamic "event" networks. Edges in these networks represent brief events, and their analysis leads to multiple interesting and important topics, such as the prediction of road traffic or modeling of communication flow. In this paper, we analyze a novel new dynamic event graph property, the "Dynamic Reachability Set" (DRS), which characterizes reachability within graphs across time. We discover that DRS histograms of multiple real world dynamic event networks follow novel distribution patterns. From these patterns, we introduce a new generative dynamic graph model, DRS-Gen. DRS-Gen captures the dynamic graph properties of connectivity and reachability, as well as generates time values for its edges. To the best of our knowledge, DRS-Gen is the first such model which produces exact time values on edges, allowing us to understand simultaneity across multiple information flows.

#index 1925428
#* CC-MR --- finding connected components in huge graphs with mapreduce
#@ Thomas Seidl;Brigitte Boden;Sergej Fries
#t 2012
#c 22
#% 53368
#% 162955
#% 319430
#% 319821
#% 554436
#% 963669
#% 1245882
#% 1318636
#% 1520914
#% 1581996
#! The detection of connected components in graphs is a well-known problem arising in a large number of applications including data mining, analysis of social networks, image analysis and a lot of other related problems. In spite of the existing very efficient serial algorithms, this problem remains a subject of research due to increasing data amounts produced by modern information systems which cannot be handled by single workstations. Only highly parallelized approaches on multi-core-servers or computer clusters are able to deal with these large-scale data sets. In this work we present a solution for this problem for distributed memory architectures, and provide an implementation for the well-known MapReduce framework developed by Google. Our algorithm CC-MR significantly outperforms the existing approaches for the MapReduce framework in terms of the number of necessary iterations, communication costs and execution runtime, as we show in our experimental evaluation on synthetic and real-world data. Furthermore, we present a technique for accelerating our implementation for datasets with very heterogeneous component sizes as they often appear in real data sets.

#index 1925429
#* Fast near neighbor search in high-dimensional binary data
#@ Anshumali Shrivastava;Ping Li
#t 2012
#c 22
#% 205305
#% 249321
#% 255137
#% 347225
#% 577370
#% 616528
#% 956507
#% 1012708
#% 1023422
#% 1215859
#% 1400000
#% 1674804
#% 1693954
#! Numerous applications in search, databases, machine learning, and computer vision, can benefit from efficient algorithms for near neighbor search. This paper proposes a simple framework for fast near neighbor search in high-dimensional binary data, which are common in practice (e.g., text). We develop a very simple and effective strategy for sub-linear time near neighbor search, by creating hash tables directly using the bits generated by b-bit minwise hashing. The advantages of our method are demonstrated through thorough comparisons with two strong baselines: spectral hashing and sign (1-bit) random projections.

#index 1925430
#* Fully sparse topic models
#@ Khoat Than;Tu Bao Ho
#t 2012
#c 22
#% 306700
#% 329569
#% 722904
#% 803567
#% 1117691
#% 1229386
#% 1385969
#% 1442064
#% 1523858
#% 1598402
#% 1661310
#% 1776934
#! In this paper, we propose Fully Sparse Topic Model (FSTM) for modeling large collections of documents. Three key properties of the model are: (1) the inference algorithm converges in linear time, (2) learning of topics is simply a multiplication of two sparse matrices, (3) it provides a principled way to directly trade off sparsity of solutions against inference quality and running time. These properties enable us to speedily learn sparse topics and to infer sparse latent representations of documents, and help significantly save memory for storage. We show that inference in FSTM is actually MAP inference with an implicit prior. Extensive experiments show that FSTM can perform substantially better than various existing topic models by different performance measures. Finally, our parallel implementation can handily learn thousands of topics from large corpora with millions of terms.

#index 1925431
#* Learning compact class codes for fast inference in large multi class classification
#@ M. Cissé;T. Artières;Patrick Gallinari
#t 2012
#c 22
#% 722756
#% 763699
#% 783478
#% 999048
#% 1074009
#% 1227578
#% 1270191
#% 1272365
#% 1417058
#% 1457107
#! We describe a new approach for classification with a very large number of classes where we assume some class similarity information is available, e.g. through a hierarchical organization. The proposed method learns a compact binary code using such an existing similarity information defined on classes. Binary classifiers are then trained using this code and decoding is performed using a simple nearest neighbor rule. This strategy, related to Error Correcting Output Codes methods, is shown to perform similarly or better than the standard and efficient one-vs-all approach, with much lower inference complexity.

#index 1925432
#* ParCube: sparse parallelizable tensor decompositions
#@ Evangelos E. Papalexakis;Christos Faloutsos;Nicholas D. Sidiropoulos
#t 2012
#c 22
#% 870226
#% 881488
#% 881493
#% 963493
#% 989585
#% 1038978
#% 1042588
#% 1218275
#% 1246431
#% 1298622
#% 1300087
#% 1635120
#% 1758232
#! How can we efficiently decompose a tensor into sparse factors, when the data does not fit in memory? Tensor decompositions have gained a steadily increasing popularity in data mining applications, however the current state-of-art decomposition algorithms operate on main memory and do not scale to truly large datasets. In this work, we propose ParCube, a new and highly parallelizable method for speeding up tensor decompositions that is well-suited to producing sparse approximations. Experiments with even moderately large data indicate over 90% sparser outputs and 14 times faster execution, with approximation error close to the current state of the art irrespective of computation and memory requirements. We provide theoretical guarantees for the algorithm's correctness and we experimentally validate our claims through extensive experiments, including four different real world datasets (Enron, Lbnl, Facebook and Nell), demonstrating its effectiveness for data mining practitioners. In particular, we are the first to analyze the very large Nell dataset using a sparse tensor decomposition, demonstrating that ParCube enables us to handle effectively and efficiently very large datasets.

#index 1925433
#* Stochastic coordinate descent methods for regularized smooth and nonsmooth losses
#@ Qing Tao;Kang Kong;Dejun Chu;Gaowei Wu
#t 2012
#c 22
#% 757953
#% 803567
#% 881477
#% 983905
#% 1014657
#% 1073906
#% 1073923
#% 1074360
#% 1077165
#% 1117675
#% 1193366
#% 1211772
#% 1211806
#% 1302843
#% 1302853
#% 1551187
#% 1551204
#% 1565315
#% 1860545
#% 1868023
#! Stochastic Coordinate Descent (SCD) methods are among the first optimization schemes suggested for efficiently solving large scale problems. However, until now, there exists a gap between the convergence rate analysis and practical SCD algorithms for general smooth losses and there is no primal SCD algorithm for nonsmooth losses. In this paper, we discuss these issues using the recently developed structural optimization techniques. In particular, we first present a principled and practical SCD algorithm for regularized smooth losses, in which the one-variable subproblem is solved using the proximal gradient method and the adaptive componentwise Lipschitz constant is obtained employing the line search strategy. When the loss is nonsmooth, we present a novel SCD algorithm, in which the one-variable subproblem is solved using the dual averaging method. We show that our algorithms exploit the regularization structure and achieve several optimal convergence rates that are standard in the literature. The experiments demonstrate the expected efficiency of our SCD algorithms in both smooth and nonsmooth cases.

#index 1925434
#* Sublinear algorithms for penalized logistic regression in massive datasets
#@ Haoruo Peng;Zhengyu Wang;Edward Y. Chang;Shuchang Zhou;Zhihua Zhang
#t 2012
#c 22
#% 471602
#% 770754
#% 771641
#% 1074348
#% 1290045
#% 1374688
#% 1386121
#% 1521612
#% 1551187
#! Penalized logistic regression (PLR) is a widely used supervised learning model. In this paper, we consider its applications in large-scale data problems and resort to a stochastic primal-dual approach for solving PLR. In particular, we employ a random sampling technique in the primal step and a multiplicative weights method in the dual step. This technique leads to an optimization method with sublinear dependency on both the volume and dimensionality of training data. We develop concrete algorithms for PLR with ℓ2-norm and ℓ1-norm penalties, respectively. Experimental results over several large-scale and high-dimensional datasets demonstrate both efficiency and accuracy of our algorithms.

#index 1925435
#* Author name disambiguation using a new categorical distribution similarity
#@ Shaohua Li;Gao Cong;Chunyan Miao
#t 2012
#c 22
#% 760866
#% 937552
#% 1083734
#% 1211086
#% 1213414
#% 1467901
#% 1688430
#% 1755323
#! Author name ambiguity has been a long-standing problem which impairs the accuracy of publication retrieval and bibliometric methods. Most of the existing disambiguation methods are built on similarity measures, e.g., "Jaccard Coefficient", between two sets of papers to be disambiguated, each set represented by a set of categorical features, e.g., coauthors and published venues. Such measures perform bad when the two sets are small, which is typical in Author Name Disambiguation. In this paper, we propose a novel categorical set similarity measure. We model an author's preference, e.g., to venues, using a categorical distribution, and derive a likelihood ratio to estimate the likelihood that the two sets are drawn from the same distribution. This likelihood ratio is used as the similarity measure to decide whether two sets belong to the same author. This measure is mathematically principled and verified to perform well even when the cardinalities of the two compared sets are small. Additionally, we propose a new method to estimate the number of distinct authors for a given name based on the name statistics extracted from a digital library. Experiment shows that our method significantly outperforms a baseline method, a widely used benchmark method, and a real system.

#index 1925436
#* Lifted online training of relational models with stochastic gradient methods
#@ Babak Ahmadi;Kristian Kersting;Sriraam Natarajan
#t 2012
#c 22
#% 138308
#% 258937
#% 450888
#% 550743
#% 722914
#% 850430
#% 876066
#% 983850
#% 1000502
#% 1211753
#% 1225216
#% 1269766
#% 1270261
#% 1272388
#% 1309354
#% 1416197
#% 1417084
#% 1478466
#% 1538538
#% 1617293
#% 1650409
#% 1688487
#% 1693530
#% 1826247
#! Lifted inference approaches have rendered large, previously intractable probabilistic inference problems quickly solvable by employing symmetries to handle whole sets of indistinguishable random variables. Still, in many if not most situations training relational models will not benefit from lifting: symmetries within models easily break since variables become correlated by virtue of depending asymmetrically on evidence. An appealing idea for such situations is to train and recombine local models. This breaks long-range dependencies and allows to exploit lifting within and across the local training tasks. Moreover, it naturally paves the way for online training for relational models. Specifically, we develop the first lifted stochastic gradient optimization method with gain vector adaptation, which processes each lifted piece one after the other. On several datasets, the resulting optimizer converges to the same quality solution over an order of magnitude faster, simply because unlike batch training it starts optimizing long before having seen the entire mega-example even once.

#index 1925437
#* Scalable relation prediction exploiting both intrarelational correlation and contextual information
#@ Xueyan Jiang;Volker Tresp;Yi Huang;Maximilian Nickel;Hans-Peter Kriegel
#t 2012
#c 22
#% 266230
#% 309095
#% 771944
#% 850430
#% 853532
#% 1121002
#% 1250567
#% 1250568
#% 1267773
#% 1305499
#% 1472270
#% 1607844
#% 1718525
#% 1746825
#% 1747267
#% 1876862
#% 1876864
#! We consider the problem of predicting instantiated binary relations in a multi-relational setting and exploit both intrarelational correlations and contextual information. For the modular combination we discuss simple heuristics, additive models and an approach that can be motivated from a hierarchical Bayesian perspective. In the concrete examples we consider models that exploit contextual information both from the database and from contextual unstructured information, e.g., information extracted from textual documents describing the involved entities. By using low-rank approximations in the context models, the models perform latent semantic analyses and can generalize across specific terms, i.e., the model might use similar latent representations for semantically related terms. All the approaches we are considering have unique solutions. They can exploit sparse matrix algebra and are thus highly scalable and can easily be generalized to new entities. We evaluate the effectiveness of nonlinear interaction terms and reduce the number of terms by applying feature selection. For the optimization of the context model we use an alternating least squares approach. We experimentally analyze scalability. We validate our approach using two synthetic data sets and using two data sets derived from the Linked Open Data (LOD) cloud.

#index 1925438
#* Relational differential prediction
#@ Houssam Nassif;Vítor Santos Costa;Elizabeth S. Burnside;David Page
#t 2012
#c 22
#% 92776
#% 246832
#% 575974
#% 793689
#% 850431
#% 875974
#% 923861
#% 961134
#% 1171750
#% 1289459
#% 1290272
#% 1491077
#% 1535455
#% 1715616
#! A typical classification problem involves building a model to correctly segregate instances of two or more classes. Such a model exhibits differential prediction with respect to given data subsets when its performance is significantly different over these subsets. Driven by a mammography application, we aim at learning rules that predict breast cancer stage while maximizing differential prediction over age-stratified data. In this work, we present the first multi-relational differential prediction (aka uplift modeling) system, and propose three different approaches to learn differential predictive rules within the Inductive Logic Programming framework. We first test and validate our methods on synthetic data, then apply them on a mammography dataset for breast cancer stage differential prediction rule discovery. We mine a novel rule linking calcification to in situ breast cancer in older women.

#index 1925439
#* Efficient training of graph-regularized multitask SVMs
#@ Christian Widmer;Marius Kloft;Nico Görnitz;Gunnar Rätsch
#t 2012
#c 22
#% 197394
#% 269217
#% 769886
#% 829014
#% 961246
#% 961261
#% 975142
#% 1073892
#% 1073923
#% 1117691
#% 1464068
#% 1472290
#% 1606356
#% 1616812
#% 1860761
#! We present an optimization framework for graph-regularized multi-task SVMs based on the primal formulation of the problem. Previous approaches employ a so-called multi-task kernel (MTK) and thus are inapplicable when the numbers of training examples n is large (typically nthree orders of magnitude over LibSVM and SVMLight for several standard benchmarks as well as challenging data sets from the application domain of computational biology. Combining our optimization methodology with the COFFIN large-scale learning framework [3], we are able to train a multi-task SVM using over 1,000,000 training points stemming from 4 different tasks. An efficient C++ implementation of our algorithm is being made publicly available as a part of the SHOGUN machine learning toolbox [4].

#index 1925440
#* Geometry preserving multi-task metric learning
#@ Peipei Yang;Kaizhu Huang;Cheng-Lin Liu
#t 2012
#c 22
#% 829014
#% 916785
#% 1042480
#% 1232015
#% 1451260
#% 1592775
#! Multi-task learning has been widely studied in machine learning due to its capability to improve the performance of multiple related learning problems. However, few researchers have applied it on the important metric learning problem. In this paper, we propose to couple multiple related metric learning tasks with von Neumann divergence. On one hand, the novel regularized approach extends previous methods from the vector regularization to a general matrix regularization framework; on the other hand and more importantly, by exploiting von Neumann divergence as the regularizer, the new multi-task metric learning has the capability to well preserve the data geometry. This leads to more appropriate propagation of side-information among tasks and provides potential for further improving the performance. We propose the concept of geometry preserving probability (PG) and show that our framework leads to a larger PG in theory. In addition, our formulation proves to be jointly convex and the global optimal solution can be guaranteed. A series of experiments across very different disciplines verify that our proposed algorithm can consistently outperform the current methods.

#index 1925441
#* Learning and inference in probabilistic classifier chains with beam search
#@ Abhishek Kumar;Shankar Vembu;Aditya Krishna Menon;Charles Elkan
#t 2012
#c 22
#% 576214
#% 577298
#% 1073910
#% 1606401
#% 1647889
#% 1826411
#% 1860543
#! Multilabel learning is an extension of binary classification that is both challenging and practically important. Recently, a method for multilabel learning called probabilistic classifier chains (PCCs) was proposed with numerous appealing properties, such as conceptual simplicity, flexibility, and theoretical justification. However, PCCs suffer from the computational issue of having inference that is exponential in the number of tags, and the practical issue of being sensitive to the suitable ordering of the tags while training. In this paper, we show how the classical technique of beam search may be used to solve both these problems. Specifically, we show how to use beam search to perform tractable test time inference, and how to integrate beam search with training to determine a suitable tag ordering. Experimental results on a range of multilabel datasets show that these proposed changes dramatically extend the practical viability of PCCs.

#index 1925442
#* Learning multiple tasks with boosted decision trees
#@ Jean Baptiste Faddoul;Boris Chidlovskii;Rémi Gilleron;Fabien Torre
#t 2012
#c 22
#% 136350
#% 235377
#% 236497
#% 302391
#% 769886
#% 829975
#% 961246
#% 983828
#% 1399977
#% 1451259
#% 1464068
#% 1473283
#% 1554506
#% 1586832
#% 1806059
#! We address the problem of multi-task learning with no label correspondence among tasks. Learning multiple related tasks simultaneously, by exploiting their shared knowledge can improve the predictive performance on every task. We develop the multi-task Adaboost environment with Multi-Task Decision Trees as weak classifiers. We first adapt the well known decision tree learning to the multi-task setting. We revise the information gain rule for learning decision trees in the multi-task setting. We use this feature to develop a novel criterion for learning Multi-Task Decision Trees. The criterion guides the tree construction by learning the decision rules from data of different tasks, and representing different degrees of task relatedness. We then modify MT-Adaboost to combine Multi-task Decision Trees as weak learners. We experimentally validate the advantage of the new technique; we report results of experiments conducted on several multi-task datasets, including the Enron email set and Spam Filtering collection.

#index 1925443
#* Multi-Task boosting by exploiting task relationships
#@ Yu Zhang;Dit-Yan Yeung
#t 2012
#c 22
#% 236495
#% 236497
#% 723239
#% 769886
#% 876039
#% 961246
#% 983828
#% 1128929
#% 1211727
#% 1451259
#! Multi-task learning aims at improving the performance of one learning task with the help of other related tasks. It is particularly useful when each task has very limited labeled data. A central issue in multi-task learning is to learn and exploit the relationships between tasks. In this paper, we generalize boosting to the multi-task learning setting and propose a method called multi-task boosting (MTBoost). Different tasks in MTBoost share the same base learners but with different weights which are related to the estimated task relationships in each iteration. In MTBoost, unlike ordinary boosting methods, the base learners, weights and task covariances are learned together in an integrated fashion using an alternating optimization procedure. We conduct theoretical analysis on the convergence of MTBoost and also empirical analysis comparing it with several related methods.

#index 1925444
#* Sparse gaussian processes for multi-task learning
#@ Yuyang Wang;Roni Khardon
#t 2012
#c 22
#% 840962
#% 891549
#% 916792
#% 1073950
#% 1151684
#% 1327706
#% 1496797
#% 1551199
#% 1606371
#! Multi-task learning models using Gaussian processes (GP) have been recently developed and successfully applied in various applications. The main difficulty with this approach is the computational cost of inference using the union of examples from all tasks. The paper investigates this problem for the grouped mixed-effect GP model where each individual response is given by a fixed-effect, taken from one of a set of unknown groups, plus a random individual effect function that captures variations among individuals. Such models have been widely used in previous work but no sparse solutions have been developed. The paper presents the first sparse solution for such problems, showing how the sparse approximation can be obtained by maximizing a variational lower bound on the marginal likelihood, generalizing ideas from single-task Gaussian processes to handle the mixed-effect model as well as grouping. Experiments using artificial and real data validate the approach showing that it can recover the performance of inference with the full sample, that it outperforms baseline methods, and that it outperforms state of the art sparse solutions for other multi-task GP formulations.

#index 1925445
#* Collective information extraction with context-specific consistencies
#@ Peter Kluegl;Martin Toepfer;Florian Lemmerich;Andreas Hotho;Frank Puppe
#t 2012
#c 22
#% 232126
#% 464434
#% 938708
#% 939376
#% 939641
#% 1190073
#% 1267781
#% 1269815
#% 1417057
#% 1523846
#! Conditional Random Fields (CRFs) have been widely used for information extraction from free texts as well as from semi-structured documents. Interesting entities in semi-structured domains are often consistently structured within a certain context or document. However, their actual compositions vary and are possibly inconsistent among different contexts. We present two collective information extraction approaches based on CRFs for exploiting these context-specific consistencies. The first approach extends linear-chain CRFs by additional factors specified by a classifier, which learns such consistencies during inference. In a second extended approach, we propose a variant of skip-chain CRFs, which enables the model to transfer long-range evidence about the consistency of the entities. The practical relevance of the presented work for real-world information extraction systems is highlighted in an empirical study. Both approaches achieve a considerable error reduction.

#index 1925446
#* Supervised learning of semantic relatedness
#@ Ran El-Yaniv;David Yanay
#t 2012
#c 22
#% 278099
#% 286069
#% 325502
#% 330705
#% 443305
#% 465914
#% 577373
#% 641963
#% 740329
#% 816185
#% 896031
#% 956570
#% 975019
#% 987262
#% 1019151
#% 1093383
#% 1250362
#% 1267808
#% 1270651
#% 1272185
#% 1272267
#% 1275285
#% 1279327
#% 1346151
#% 1355018
#% 1470575
#% 1473931
#% 1560388
#% 1598472
#! We propose and study a novel supervised approach to learning statistical semantic relatedness models from subjectively annotated training examples. The proposed semantic model consists of parameterized co-occurrence statistics associated with textual units of a large background knowledge corpus. We present an efficient algorithm for learning such semantic models from a training sample of relatedness preferences. Our method is corpus independent and can essentially rely on any sufficiently large (unstructured) collection of coherent texts. Moreover, the approach facilitates the fitting of semantic models for specific users or groups of users. We present the results of extensive range of experiments from small to large scale, indicating that the proposed method is effective and competitive with the state-of-the-art.

#index 1925447
#* Unsupervised bayesian part of speech inference with particle gibbs
#@ Gregory Dubbin;Phil Blunsom
#t 2012
#c 22
#% 939375
#% 939624
#% 1015777
#% 1249462
#% 1264753
#% 1270710
#% 1470644
#% 1592015
#! As linguistic models incorporate more subtle nuances of language and its structure, standard inference techniques can fall behind. These models are often tightly coupled such that they defy clever dynamic programming tricks. Here we demonstrate that Sequential Monte Carlo approaches, i.e. particle filters, are well suited to approximating such models. We implement two particle filters, which jointly sample either sentences or word types, and incorporate them into a Particle Gibbs sampler for Bayesian inference of syntactic part-of-speech categories. We analyze the behavior of the samplers and compare them to an exact block sentence sampler, a local sampler, and an existing heuristic word type sampler. We also explore the benefits of mixing Particle Gibbs and standard samplers.

#index 1925448
#* WikiSent: weakly supervised sentiment analysis through extractive summarization with wikipedia
#@ Subhabrata Mukherjee;Pushpak Bhattacharyya
#t 2012
#c 22
#% 287197
#% 288614
#% 313959
#% 340971
#% 769892
#% 815915
#% 854646
#% 855282
#% 891559
#% 938687
#% 938688
#% 1019105
#% 1055735
#% 1077150
#% 1083703
#% 1250362
#% 1306081
#% 1328330
#% 1338589
#% 1406896
#% 1432242
#% 1470682
#% 1481483
#% 1522121
#% 1590302
#% 1697484
#% 1711738
#! This paper describes a weakly supervised system for sentiment analysis in the movie review domain. The objective is to classify a movie review into a polarity class, positive or negative, based on those sentences bearing opinion on the movie alone, leaving out other irrelevant text. Wikipedia incorporates the world knowledge of movie-specific features in the system which is used to obtain an extractive summary of the review, consisting of the reviewer's opinions about the specific aspects of the movie. This filters out the concepts which are irrelevant or objective with respect to the given movie. The proposed system, WikiSent, does not require any labeled data for training. It achieves a better or comparable accuracy to the existing semi-supervised and unsupervised systems in the domain, on the same dataset. We also perform a general movie review trend analysis using WikiSent.

#index 1925449
#* Adaptive two-view online learning for math topic classification
#@ Tam T. Nguyen;Kuiyu Chang;Siu Cheung Hui
#t 2012
#c 22
#% 61792
#% 115608
#% 197394
#% 271060
#% 458369
#% 801566
#% 840938
#% 961152
#% 1073905
#% 1077150
#% 1338580
#% 1478493
#% 1728015
#% 1826291
#% 1874813
#! Text categorization has been a popular research topic for years and has become more or less a practical technology. However, there exists little research on math topic classification. Math documents contain both textual data and math expressions. The text and math can be considered as two related but different views of a math document. The goal of online math topic classification is to automatically categorize a math document containing both mathematical expressions and textual content into an appropriate topic without the need for periodically retraining the classifier. To achieve this, it is essential to have a two-view online classification algorithm, which deals with the textual data view and the math expression view at the same time. In this paper, we propose a novel adaptive two-view online math document classifier based on the Passive Aggressive (PA) algorithm. The proposed approach is evaluated on real world math questions and answers from the Math Overflow question answering system. Compared to the baseline PA algorithm, our method's overall F-measure is improved by up to 3%. The improvement of our algorithm over the plain math expression view is almost 6%.

#index 1925450
#* BDUOL: double updating online learning on a fixed budget
#@ Peilin Zhao;Steven C. H. Hoi
#t 2012
#c 22
#% 961152
#% 1000326
#% 1042610
#% 1385999
#% 1606374
#% 1759695
#! Kernel-based online learning often exhibits promising empirical performance for various applications according to previous studies. However, it often suffers a main shortcoming, that is, the unbounded number of support vectors, making it unsuitable for handling large-scale datasets. In this paper, we investigate the problem of budget kernel-based online learning that aims to constrain the number of support vectors by a predefined budget when learning the kernel-based prediction function in the online learning process. Unlike the existing studies, we present a new framework of budget kernel-based online learning based on a recently proposed online learning method called "Double Updating Online Learning" (DUOL), which has shown state-of-the-art performance as compared with the other traditional kernel-based online learning algorithms. We analyze the theoretical underpinning of the proposed Budget Double Updating Online Learning (BDUOL) framework, and then propose several BDUOL algorithms by designing different budget maintenance strategies. We evaluate the empirical performance of the proposed BDUOL algorithms by comparing them with several well-known budget kernel-based online learning algorithms, in which encouraging results validate the efficacy of the proposed technique.

#index 1925451
#* Handling time changing data with adaptive very fast decision rules
#@ Petr Kosina;João Gama
#t 2012
#c 22
#% 136350
#% 204531
#% 209023
#% 252533
#% 310500
#% 342600
#% 342639
#% 449559
#% 449566
#% 451036
#% 458178
#% 729932
#% 729965
#% 751439
#% 953970
#% 961134
#% 998561
#% 1192696
#% 1214635
#% 1214654
#% 1267740
#% 1301006
#% 1467766
#% 1472282
#% 1565633
#% 1796715
#% 1826263
#! Data streams are usually characterized by changes in the underlying distribution generating data. Therefore algorithms designed to work with data streams should be able to detect changes and quickly adapt the decision model. Rules are one of the most interpretable and flexible models for data mining prediction tasks. In this paper we present the Adaptive Very Fast Decision Rules (AVFDR), an on-line, any-time and one-pass algorithm for learning decision rules in the context of time changing data. AVFDR can learn ordered and unordered rule sets. It is able to adapt the decision model via incremental induction and specialization of rules. Detecting local drifts takes advantage of the modularity of rule sets. In AVFDR, each individual rule monitors the evolution of performance metrics to detect concept drift. AVFDR prunes rules that detect drift. This explicit change detection mechanism provides useful information about the dynamics of the process generating data, faster adaption to changes and generates compact rule sets. The experimental evaluation shows this method is able to learn fast and compact rule sets from evolving streams in comparison to alternative methods.

#index 1925452
#* Improved counter based algorithms for frequent pairs mining in transactional data streams
#@ Konstantin Kutzkov
#t 2012
#c 22
#% 338609
#% 443164
#% 481290
#% 519953
#% 548479
#% 569754
#% 729418
#% 751684
#% 816392
#% 844308
#% 857494
#% 874906
#% 894443
#% 937549
#% 993960
#% 1219788
#% 1318601
#% 1384246
#% 1399997
#% 1474891
#% 1494046
#% 1535200
#% 1689730
#% 1731170
#! A straightforward approach to frequent pairs mining in transactional streams is to generate all pairs occurring in transactions and apply a frequent items mining algorithm to the resulting stream. The well-known counter based algorithms Frequent and Space-Saving are known to achieve a very good approximation when the frequencies of the items in the stream adhere to a skewed distribution. Motivated by observations on real datasets, we present a general technique for applying Frequent and Space-Saving to transactional data streams for the case when the transactions considerably vary in their lengths. Despite of its simplicity, we show through extensive experiments that our approach is considerably more efficient and precise than the naïve application of Frequent and Space-Saving.

#index 1925453
#* Mirror descent for metric learning: a unified approach
#@ Gautam Kunapuli;Jude Shavlik
#t 2012
#c 22
#% 176853
#% 209623
#% 382854
#% 464291
#% 770798
#% 812372
#% 983830
#% 1232019
#% 1504249
#% 1556166
#% 1811362
#% 1845612
#! Most metric learning methods are characterized by diverse loss functions and projection methods, which naturally begs the question: is there a wider framework that can generalize many of these methods? In addition, ever persistent issues are those of scalability to large data sets and the question of kernelizability. We propose a unified approach to Mahalanobis metric learning: an online regularized metric learning algorithm based on the ideas of composite objective mirror descent (comid). The metric learning problem is formulated as a regularized positive semi-definite matrix learning problem, whose update rules can be derived using the comid framework. This approach aims to be scalable, kernelizable, and admissible to many different types of Bregman and loss functions, which allows for the tailoring of several different classes of algorithms. The most novel contribution is the use of the trace norm, which yields a sparse metric in its eigenspectrum, thus simultaneously performing feature selection along with metric learning.

#index 1925598
#* Proceedings of the 2012 European conference on Machine Learning and Knowledge Discovery in Databases - Volume Part II
#@ Peter A. Flach;Tijl Bie;Nello Cristianini
#t 2012
#c 22

#index 1925599
#* AUDIO: an integrity auditing framework of outlier-mining-as-a-service systems
#@ Ruilin Liu;Hui (Wendy) Wang;Anna Monreale;Dino Pedreschi;Fosca Giannotti;Wenge Guo
#t 2012
#c 22
#% 55337
#% 250530
#% 300183
#% 333929
#% 397367
#% 465152
#% 479791
#% 740850
#% 745406
#% 810042
#% 824701
#% 874980
#% 881074
#% 949148
#% 1022211
#% 1022267
#% 1127264
#% 1165483
#% 1299974
#% 1318619
#% 1328206
#% 1385890
#% 1442468
#% 1451187
#% 1587705
#% 1663641
#% 1692335
#! Spurred by developments such as cloud computing, there has been considerable recent interest in the data-mining-as-a-service paradigm. Users lacking in expertise or computational resources can outsource their data and mining needs to a third-party service provider (server). Outsourcing, however, raises issues about result integrity: how can the data owner verify that the mining results returned by the server are correct? In this paper, we present AUDIO, an integrity auditing framework for the specific task of distance-based outlier mining outsourcing. It provides efficient and practical verification approaches to check both completeness and correctness of the mining results. The key idea of our approach is to insert a small amount of artificial tuples into the outsourced data; the artificial tuples will produce artificial outliers and non-outliers that do not exist in the original dataset. The server's answer is verified by analyzing the presence of artificial outliers/non-outliers, obtaining a probabilistic guarantee of correctness and completeness of the mining result. Our empirical results show the effectiveness and efficiency of our method.

#index 1925600
#* Differentially private projected histograms: construction and use for prediction
#@ Staal A. Vinterbo
#t 2012
#c 22
#% 18658
#% 349550
#% 366687
#% 479648
#% 833751
#% 977011
#% 1029084
#% 1414540
#% 1484155
#% 1496267
#% 1523886
#% 1605968
#% 1606359
#% 1670071
#% 1740518
#% 1846817
#! Privacy concerns are among the major barriers to efficient secondary use of information and data on humans. Differential privacy is a relatively recent measure that has received much attention in machine learning as it quantifies individual risk using a strong cryptographically motivated notion of privacy. At the core of differential privacy lies the concept of information dissemination through a randomized process. One way of adding the needed randomness to any process is to pre-randomize the input. This can yield lower quality results than other more specialized approaches, but can be an attractive alternative when i. there does not exist a specialized differentially private alternative, or when ii. multiple processes applied in parallel can use the same pre-randomized input. A simple way to do input randomization is to compute perturbed histograms, which essentially are noisy multiset membership functions. Unfortunately, computation of perturbed histograms is only efficient when the data stems from a low-dimensional discrete space. The restriction to discrete spaces can be mitigated by discretization; Lei presented in 2011 an analysis of discretization in the context of M-estimators. Here we address the restriction regarding the dimensionality of the data. In particular we present a differentially private approximation algorithm for selecting features that preserve conditional frequency densities, and use this to project data prior to computing differentially private histograms. The resulting projected histograms can be used as machine learning input and include the necessary randomness for differential privacy. We empirically validate the use of differentially private projected histograms for learning binary and multinomial logistic regression models using four real world data sets.

#index 1925601
#* Fairness-Aware classifier with prejudice remover regularizer
#@ Toshihiro Kamishima;Shotaro Akaho;Hideki Asoh;Jun Sakuma
#t 2012
#c 22
#% 722902
#% 770847
#% 785341
#% 983828
#% 1074831
#% 1083686
#% 1289281
#% 1289741
#% 1426604
#% 1456835
#% 1535404
#% 1605969
#% 1605975
#% 1613005
#% 1688470
#% 1689697
#! With the spread of data mining technologies and the accumulation of social data, such technologies and data are being used for determinations that seriously affect individuals' lives. For example, credit scoring is frequently determined based on the records of past credit data together with statistical prediction techniques. Needless to say, such determinations must be nondiscriminatory and fair in sensitive features, such as race, gender, religion, and so on. Several researchers have recently begun to attempt the development of analysis techniques that are aware of social fairness or discrimination. They have shown that simply avoiding the use of sensitive features is insufficient for eliminating biases in determinations, due to the indirect influence of sensitive information. In this paper, we first discuss three causes of unfairness in machine learning. We then propose a regularization approach that is applicable to any prediction algorithm with probabilistic discriminative models. We further apply this approach to logistic regression and empirically show its effectiveness and efficiency.

#index 1925602
#* A live comparison of methods for personalized article recommendation at forbes.com
#@ Evan Kirshenbaum;George Forman;Michael Dugan
#t 2012
#c 22
#% 734590
#% 813966
#% 956521
#% 1047347
#% 1083671
#% 1127461
#% 1176959
#% 1356185
#% 1358747
#% 1384223
#% 1396102
#% 1399995
#% 1451209
#% 1476444
#% 1476448
#% 1476481
#% 1476483
#% 1543813
#% 1625359
#% 1625363
#% 1625364
#% 1625382
#! We present the results of a multi-phase study to optimize strategies for generating personalized article recommendations at the Forbes.com web site. In the first phase we compared the performance of a variety of recommendation methods on historical data. In the second phase we deployed a live system at Forbes.com for five months on a sample of 82,000 users, each randomly assigned to one of 20 methods. We analyze the live results both in terms of click-through rate (CTR) and user session lengths. The method with the best CTR was a hybrid of collaborative-filtering and a content-based method that leverages Wikipedia-based concept features, post-processed by a novel Bayesian remapping technique that we introduce. It both statistically significantly beat decayed popularity and increased CTR by 37%.

#index 1925603
#* Fast ALS-Based tensor factorization for context-aware recommendation from implicit feedback
#@ Balázs Hidasi;Domonkos Tikk
#t 2012
#c 22
#% 152934
#% 316143
#% 801785
#% 1038335
#% 1083671
#% 1116993
#% 1127499
#% 1176909
#% 1287231
#% 1287260
#% 1287300
#% 1399975
#% 1476452
#% 1476453
#% 1476492
#% 1480670
#% 1480681
#% 1480899
#% 1558821
#% 1598397
#% 1625385
#! Albeit the implicit feedback based recommendation problem--when only the user history is available but there are no ratings--is the most typical setting in real-world applications, it is much less researched than the explicit feedback case. State-of-the-art algorithms that are efficient on the explicit case cannot be straightforwardly transformed to the implicit case if scalability should be maintained. There are few implicit feedback benchmark datasets, therefore new ideas are usually experimented on explicit benchmarks. In this paper, we propose a generic context-aware implicit feedback recommender algorithm, coined iTALS. iTALS applies a fast, ALS-based tensor factorization learning method that scales linearly with the number of non-zero elements in the tensor. The method also allows us to incorporate various contextual information into the model while maintaining its computational efficiency. We present two context-aware implementation variants of iTALS. The first incorporates seasonality and enables to distinguish user behavior in different time intervals. The other views the user history as sequential information and has the ability to recognize usage pattern typical to certain group of items, e.g. to automatically tell apart product types that are typically purchased repetitively or once. Experiments performed on five implicit datasets (LastFM 1K, Grocery, VoD, and "implicitized" Netflix and MovieLens 10M) show that by integrating context-aware information with our factorization framework into the state-of-the-art implicit recommender algorithm the recommendation quality improves significantly.

#index 1925604
#* Probability estimation for multi-class classification based on label ranking
#@ Weiwei Cheng;Eyke Hüllermeier
#t 2012
#c 22
#% 246831
#% 342611
#% 470333
#% 577298
#% 722807
#% 763699
#% 771846
#% 840913
#% 1100041
#% 1211710
#% 1606372
#! We consider the problem of probability estimation in the setting of multi-class classification. While this problem has already been addressed in the literature, we tackle it from a novel perspective. Exploiting the close connection between probability estimation and ranking, our idea is to solve the former on the basis of the latter, taking advantage of recently developed methods for label ranking. More specifically, we argue that the Plackett-Luce ranking model is a very natural choice in this context, especially as it can be seen as a multinomial extension of the Bradley-Terry model. The latter provides the basis of pairwise coupling techniques, which arguably constitute the state-of-the-art in multi-class probability estimation. We explore the relationship between the pairwise and the ranking-based approach to probability estimation, both formally and empirically. Using synthetic and real-world data, we show that our method does not only enjoy nice theoretical properties, but is also competitive in terms of accuracy and efficiency.

#index 1925605
#* Adaptive planning for markov decision processes with uncertain transition models via incremental feature dependency discovery
#@ N. Kemal Ure;Alborz Geramifard;Girish Chowdhary;Jonathan P. How
#t 2012
#c 22
#% 160859
#% 221633
#% 363744
#% 384911
#% 576214
#% 722895
#% 810882
#% 891549
#% 959522
#% 1078833
#% 1291498
#% 1301331
#% 1358092
#% 1417054
#% 1468026
#% 1625621
#% 1760070
#% 1761265
#! Solving large scale sequential decision making problems without prior knowledge of the state transition model is a key problem in the planning literature. One approach to tackle this problem is to learn the state transition model online using limited observed measurements. We present an adaptive function approximator (incremental Feature Dependency Discovery (iFDD)) that grows the set of features online to approximately represent the transition model. The approach leverages existing feature-dependencies to build a sparse representation of the state transition model. Theoretical analysis and numerical simulations in domains with state space sizes varying from thousands to millions are used to illustrate the benefit of using iFDD for incrementally building transition models in a planning framework.

#index 1925606
#* APRIL: active preference learning-based reinforcement learning
#@ Riad Akrour;Marc Schoenauer;Michèle Sebag
#t 2012
#c 22
#% 197394
#% 384911
#% 422182
#% 466418
#% 722761
#% 734920
#% 770852
#% 829043
#% 840882
#% 846487
#% 881477
#% 1065689
#% 1073878
#% 1211740
#% 1442263
#% 1467774
#% 1495573
#% 1617257
#% 1617276
#% 1781811
#% 1943468
#! This paper focuses on reinforcement learning (RL) with limited prior knowledge. In the domain of swarm robotics for instance, the expert can hardly design a reward function or demonstrate the target behavior, forbidding the use of both standard RL and inverse reinforcement learning. Although with a limited expertise, the human expert is still often able to emit preferences and rank the agent demonstrations. Earlier work has presented an iterative preference-based RL framework: expert preferences are exploited to learn an approximate policy return, thus enabling the agent to achieve direct policy search. Iteratively, the agent selects a new candidate policy and demonstrates it; the expert ranks the new demonstration comparatively to the previous best one; the expert's ranking feedback enables the agent to refine the approximate policy return, and the process is iterated. In this paper, preference-based reinforcement learning is combined with active ranking in order to decrease the number of ranking queries to the expert needed to yield a satisfactory policy. Experiments on the mountain car and the cancer treatment testbeds witness that a couple of dozen rankings enable to learn a competent policy.

#index 1925607
#* Autonomous data-driven decision-making in smart electricity markets
#@ Markus Peters;Wolfgang Ketter;Maytal Saar-Tsechansky;John Collins
#t 2012
#c 22
#% 384911
#% 1343427
#% 1453467
#% 1467774
#% 1468026
#% 1478375
#% 1526171
#% 1826294
#! For the vision of a Smart Grid to materialize, substantial advances in intelligent decentralized control mechanisms are required. We propose a novel class of autonomous broker agents for retail electricity trading that can operate in a wide range of Smart Electricity Markets, and that are capable of deriving long-term, profit-maximizing policies. Our brokers use Reinforcement Learning with function approximation, they can accommodate arbitrary economic signals from their environments, and they learn efficiently over the large state spaces resulting from these signals. Our design is the first that can accommodate an offline training phase so as to automatically optimize the broker for particular market conditions. We demonstrate the performance of our design in a series of experiments using real-world energy market data, and find that it outperforms previous approaches by a significant margin.

#index 1925608
#* Bayesian nonparametric inverse reinforcement learning
#@ Bernard Michini;Jonathan P. How
#t 2012
#c 22
#% 286423
#% 384911
#% 393786
#% 466418
#% 770852
#% 876036
#% 980246
#% 1187663
#% 1267757
#% 1270316
#% 1275169
#% 1828477
#! Inverse reinforcement learning (IRL) is the task of learning the reward function of a Markov Decision Process (MDP) given the transition function and a set of observed demonstrations in the form of state-action pairs. Current IRL algorithms attempt to find a single reward function which explains the entire observation set. In practice, this leads to a computationally-costly search over a large (typically infinite) space of complex reward functions. This paper proposes the notion that if the observations can be partitioned into smaller groups, a class of much simpler reward functions can be used to explain each group. The proposed method uses a Bayesian nonparametric mixture model to automatically partition the data and find a set of simple reward functions corresponding to each partition. The simple rewards are interpreted intuitively as subgoals, which can be used to predict actions or analyze which states are important to the demonstrator. Experimental results are given for simple examples showing comparable performance to other IRL algorithms in nominal situations. Moreover, the proposed method handles cyclic tasks (where the agent begins and ends in the same state) that would break existing algorithms without modification. Finally, the new algorithm has a fundamentally different structure than previous methods, making it more computationally efficient in a real-world learning scenario where the state space is large but the demonstration set is small.

#index 1925609
#* Bootstrapping monte carlo tree search with an imperfect heuristic
#@ Truong-Huy Dinh Nguyen;Wee-Sun Lee;Tze-Yun Leong
#t 2012
#c 22
#% 425053
#% 425074
#% 983838
#% 1270060
#% 1305297
#% 1404135
#% 1665148
#% 1729162
#! We consider the problem of using a heuristic policy to improve the value approximation by the Upper Confidence Bound applied in Trees (UCT) algorithm in non-adversarial settings such as planning with large-state space Markov Decision Processes. Current improvements to UCT focus on either changing the action selection formula at the internal nodes or the rollout policy at the leaf nodes of the search tree. In this work, we propose to add an auxiliary arm to each of the internal nodes, and always use the heuristic policy to roll out simulations at the auxiliary arms. The method aims to get fast convergence to optimal values at states where the heuristic policy is optimal, while retaining similar approximation as the original UCT at other states. We show that bootstrapping with the proposed method in the new algorithm, UCT-Aux, performs better compared to the original UCT algorithm and its variants in two benchmark experiment settings. We also examine conditions under which UCT-Aux works well.

#index 1925610
#* Fast reinforcement learning with large action sets using error-correcting output codes for MDP factorization
#@ Gabriel Dulac-Arnold;Ludovic Denoyer;Philippe Preux;Patrick Gallinari
#t 2012
#c 22
#% 124689
#% 321455
#% 425052
#% 1077631
#% 1272365
#% 1604926
#% 1606376
#! The use of Reinforcement Learning in real-world scenarios is strongly limited by issues of scale. Most RL learning algorithms are unable to deal with problems composed of hundreds or sometimes even dozens of possible actions, and therefore cannot be applied to many real-world problems. We consider the RL problem in the supervised classification framework where the optimal policy is obtained through a multiclass classifier, the set of classes being the set of actions of the problem. We introduce error-correcting output codes (ECOCs) in this setting and propose two new methods for reducing complexity when using rollouts-based approaches. The first method consists in using an ECOC-based classifier as the multiclass classifier, reducing the learning complexity from $\mathcal{O}(A^2)$ to $\mathcal{O}(A \log(A))$. We then propose a novel method that profits from the ECOC's coding dictionary to split the initial MDP into $\mathcal{O}(\log(A))$ separate two-action MDPs. This second method reduces learning complexity even further, from $\mathcal{O}(A^2)$ to $\mathcal{O}(\log(A))$, thus rendering problems with large action sets tractable. We finish by experimentally demonstrating the advantages of our approach on a set of benchmark problems, both in speed and performance.

#index 1925611
#* Learning policies for battery usage optimization in electric vehicles
#@ Stefano Ermon;Yexiang Xue;Carla Gomes;Bart Selman
#t 2012
#c 22
#% 34659
#% 280088
#% 289949
#% 321455
#% 363744
#% 384911
#% 393786
#% 1021595
#% 1272286
#% 1275083
#% 1301004
#! The high cost, limited capacity, and long recharge time of batteries pose a number of obstacles for the widespread adoption of electric vehicles. Multi-battery systems that combine a standard battery with supercapacitors are currently one of the most promising ways to increase battery lifespan and reduce operating costs. However, their performance crucially depends on how they are designed and operated. In this paper, we formalize the problem of optimizing real-time energy management of multi-battery systems as a stochastic planning problem, and we propose a novel solution based on a combination of optimization, machine learning and data-mining techniques. We evaluate the performance of our intelligent energy management system on various large datasets of commuter trips crowdsourced in the United States. We show that our policy significantly outperforms the leading algorithms that were previously proposed as part of an open algorithmic challenge.

#index 1925612
#* Policy iteration based on a learned transition model
#@ Vivek Ramavajjala;Charles Elkan
#t 2012
#c 22
#% 103439
#% 384911
#% 466575
#% 734920
#% 829011
#% 1014677
#% 1024771
#% 1073966
#% 1108884
#% 1369700
#% 1369701
#% 1787847
#% 1874051
#! This paper investigates a reinforcement learning method that combines learning a model of the environment with least-squares policy iteration (LSPI). The LSPI algorithm learns a linear approximation of the optimal state-action value function; the idea studied here is to let this value function depend on a learned estimate of the expected next state instead of directly on the current state and action. This approach makes it easier to define useful basis functions, and hence to learn a useful linear approximation of the value function. Experiments show that the new algorithm, called NSPI for next-state policy iteration, performs well on two standard benchmarks, the well-known mountain car and inverted pendulum swing-up tasks. More importantly, the NSPI algorithm performs well, and better than a specialized recent method, on a resource management task known as the day-ahead wind commitment problem. This latter task has action and state spaces that are high-dimensional and continuous.

#index 1925613
#* Structured apprenticeship learning
#@ Abdeslam Boularias;Oliver Krömer;Jan Peters
#t 2012
#c 22
#% 344568
#% 466418
#% 563100
#% 770852
#% 770866
#% 812487
#% 827631
#% 876036
#% 1074001
#% 1270316
#% 1275169
#% 1342866
#% 1382556
#! We propose a graph-based algorithm for apprenticeship learning when the reward features are noisy. Previous apprenticeship learning techniques learn a reward function by using only local state features. This can be a limitation in practice, as often some features are misspecified or subject to measurement noise. Our graphical framework, inspired from the work on Markov Random Fields, allows to alleviate this problem by propagating information between states, and rewarding policies that choose similar actions in adjacent states. We demonstrate the advantage of the proposed approach on grid-world navigation problems, and on the problem of teaching a robot to grasp novel objects in simulation.

#index 1925614
#* A bayesian approach for classification rule mining in quantitative databases
#@ Dominique Gay;Marc Boullé
#t 2012
#c 22
#% 152934
#% 210160
#% 277919
#% 342640
#% 458257
#% 458298
#% 465922
#% 829042
#% 878207
#% 893465
#% 934581
#% 961134
#% 976826
#% 1014661
#% 1070887
#% 1148765
#% 1301004
#% 1411040
#% 1451168
#% 1663637
#% 1663670
#! We suggest a new framework for classification rule mining in quantitative data sets founded on Bayes theory --- without univariate preprocessing of attributes. We introduce a space of rule models and a prior distribution defined on this model space. As a result, we obtain the definition of a parameter-free criterion for classification rules. We show that the new criterion identifies interesting classification rules while being highly resilient to spurious patterns. We develop a new parameter-free algorithm to mine locally optimal classification rules efficiently. The mined rules are directly used as new features in a classification process based on a selective naive Bayes classifier. The resulting classifier demonstrates higher inductive performance than state-of-the-art rule-based classifiers.

#index 1925615
#* A bayesian scoring technique for mining predictive and non-spurious rules
#@ Iyad Batal;Gregory Cooper;Milos Hauskrecht
#t 2012
#c 22
#% 197387
#% 227919
#% 280409
#% 283138
#% 344447
#% 420126
#% 442814
#% 443350
#% 449566
#% 466483
#% 481290
#% 501817
#% 631970
#% 813990
#% 867057
#% 881500
#% 976826
#% 1081949
#% 1214686
#% 1232020
#% 1529066
#% 1710157
#! Rule mining is an important class of data mining methods for discovering interesting patterns in data. The success of a rule mining method heavily depends on the evaluation function that is used to assess the quality of the rules. In this work, we propose a new rule evaluation score - the Predictive and Non-Spurious Rules (PNSR) score. This score relies on Bayesian inference to evaluate the quality of the rules and considers the structure of the rules to filter out spurious rules. We present an efficient algorithm for finding rules with high PNSR scores. The experiments demonstrate that our method is able to cover and explain the data with a much smaller rule set than existing methods.

#index 1925616
#* Generic pattern trees for exhaustive exceptional model mining
#@ Florian Lemmerich;Martin Becker;Martin Atzmueller
#t 2012
#c 22
#% 232126
#% 300120
#% 458307
#% 477497
#% 1108880
#% 1232020
#% 1267660
#% 1456838
#% 1535398
#% 1599175
#% 1617370
#% 1663617
#% 1708743
#! Exceptional model mining has been proposed as a variant of subgroup discovery especially focusing on complex target concepts. Currently, efficient mining algorithms are limited to heuristic (non exhaustive) methods. In this paper, we propose a novel approach for fast exhaustive exceptional model mining: We introduce the concept of valuation bases as an intermediate condensed data representation, and present the general GP-growth algorithm based on FP-growth. Furthermore, we discuss the scope of the proposed approach by drawing an analogy to data stream mining and provide examples for several different model classes. Runtime experiments show improvements of more than an order of magnitude in comparison to a naive exhaustive depth-first search.

#index 1925617
#* Bidirectional semi-supervised learning with graphs
#@ Tomoharu Iwata;Kevin Duh
#t 2012
#c 22
#% 304876
#% 311027
#% 340897
#% 411762
#% 642990
#% 1034778
#% 1131844
#% 1132507
#% 1174086
#% 1250573
#% 1264831
#% 1272110
#% 1302068
#% 1338333
#% 1354495
#% 1473317
#% 1481560
#% 1482213
#% 1511384
#% 1633144
#% 1722664
#% 1872023
#! We present a machine learning task, which we call bidirectional semi-supervised learning, where label-only samples are given as well as labeled and unlabeled samples. A label-only sample contains the label information of the sample but not the feature information. Then, we propose a simple and effective graph-based method for bidirectional semi-supervised learning in multi-label classification. The proposed method assumes that correlated classes are likely to have the same labels among the similar samples. First, we construct a graph that represents similarities between samples using labeled and unlabeled samples in the same way with graph-based semi-supervised methods. Second, we construct another graph using labeled and label-only samples by connecting classes that are likely to co-occur, which represents correlations between classes. Then, we estimate labels of unlabeled samples by propagating labels over these two graphs. We can find a closed-form global solution for the label propagation by using matrix algebra. We demonstrate the effectiveness of the proposed method over supervised and semi-supervised learning methods with experiments using synthetic and multi-label text data sets.

#index 1925618
#* Coupled bayesian sets algorithm for semi-supervised learning and information extraction
#@ Saurabh Verma;Estevam R. Hruschka
#t 2012
#c 22
#% 252011
#% 278107
#% 283180
#% 301241
#% 504443
#% 1275182
#% 1291356
#% 1355026
#% 1471327
#% 1560247
#% 1586601
#% 1592272
#% 1604671
#% 1826065
#! Our inspiration comes from Nell (Never Ending Language Learning), a computer program running at Carnegie Mellon University to extract structured information from unstructured web pages. We consider the problem of semi-supervised learning approach to extract category instances (e.g. country(USA), city(New York)) from web pages, starting with a handful of labeled training examples of each category or relation, plus hundreds of millions of unlabeled web documents. Semi-supervised approaches using a small number of labeled examples together with many unlabeled examples are often unreliable as they frequently produce an internally consistent, but nevertheless, incorrect set of extractions. We believe that this problem can be overcome by simultaneously learning independent classifiers in a new approach named Coupled Bayesian Sets algorithm, based on Bayesian Sets, for many different categories and relations (in the presence of an ontology defining constraints that couple the training of these classifiers). Experimental results show that simultaneously learning a coupled collection of classifiers for random 11 categories resulted in much more accurate extractions than training classifiers through original Bayesian Sets algorithm, Naive Bayes, BaS-all and Coupled Pattern Learner (the category extractor used in NELL).

#index 1925619
#* Graph-Based transduction with confidence
#@ Matan Orbach;Koby Crammer
#t 2012
#c 22
#% 466263
#% 763708
#% 801566
#% 1055761
#% 1073905
#% 1264831
#% 1267783
#% 1338580
#% 1455666
#% 1471327
#% 1653987
#! We present a new multi-class graph-based transduction algorithm. Examples are associated with vertices in an undirected weighted graph and edge weights correspond to a similarity measure between examples. Typical algorithms in such a setting perform label propagation between neighbours, ignoring the quality, or estimated quality, in the labeling of various nodes. We introduce an additional quantity of confidence in label assignments, and learn them jointly with the weights, while using them to dynamically tune the influence of each vertex on its neighbours. We cast learning as a convex optimization problem, and derive an efficient iterative algorithm for solving it. Empirical evaluations on seven NLP data sets demonstrate our algorithm improves over other state-of-the-art graph-based transduction algorithms.

#index 1925620
#* Maximum consistency preferential random walks
#@ Deguang Kong;Chris Ding
#t 2012
#c 22
#% 252011
#% 438553
#% 881496
#% 915344
#% 987222
#% 989597
#% 1040831
#% 1083652
#% 1264031
#% 1455666
#% 1536568
#% 1617313
#% 1815596
#! Random walk plays a significant role in computer science. The popular PageRank algorithm uses random walk. Personalized random walks force random walk to "personalized views" of the graph according to users' preferences. In this paper, we show the close relations between different preferential random walks and label propagation methods used in semi-supervised learning. We further present a maximum consistency algorithm on these preferential random walk/label propagation methods to ensure maximum consistency from labeled data to unlabeled data. Extensive experimental results on 9 datasets provide performance comparisons of different preferential random walks/label propagation methods. They also indicate that the proposed maximum consistency algorithm clearly improves the classification accuracy over existing methods.

#index 1925621
#* Semi-supervised multi-label classification: a simultaneous large-margin, subspace learning approach
#@ Yuhong Guo;Dale Schuurmans
#t 2012
#c 22
#% 311034
#% 458379
#% 818234
#% 818236
#% 961191
#% 989655
#% 1073976
#% 1095861
#% 1128929
#% 1190076
#% 1250573
#% 1270338
#% 1305467
#% 1384971
#% 1535421
#% 1654170
#! Labeled data is often sparse in common learning scenarios, either because it is too time consuming or too expensive to obtain, while unlabeled data is almost always plentiful. This asymmetry is exacerbated in multi-label learning, where the labeling process is more complex than in the single label case. Although it is important to consider semi-supervised methods for multi-label learning, as it is in other learning scenarios, surprisingly, few proposals have been investigated for this particular problem. In this paper, we present a new semi-supervised multi-label learning method that combines large-margin multi-label classification with unsupervised subspace learning. We propose an algorithm that learns a subspace representation of the labeled and unlabeled inputs, while simultaneously training a supervised large-margin multi-label classifier on the labeled portion. Although joint training of these two interacting components might appear intractable, we exploit recent developments in induced matrix norm optimization to show that these two problems can be solved jointly, globally and efficiently. In particular, we develop an efficient training procedure based on subgradient search and a simple coordinate descent strategy. An experimental evaluation demonstrates that semi-supervised subspace learning can improve the performance of corresponding supervised multi-label learning methods.

#index 1925622
#* MDL-Based analysis of time series at multiple time-scales
#@ Ugo Vespier;Arno Knobbe;Siegfried Nijssen;Joaquin Vanschoren
#t 2012
#c 22
#% 71149
#% 176172
#% 466506
#% 800574
#% 875024
#% 934581
#% 1108878
#% 1273135
#% 1651711
#% 1688500
#% 1726647
#! The behavior of many complex physical systems is affected by a variety of phenomena occurring at different temporal scales. Time series data produced by measuring properties of such systems often mirrors this fact by appearing as a composition of signals across different time scales. When the final goal of the analysis is to model the individual phenomena affecting a system, it is crucial to be able to recognize the right temporal scales and to separate the individual components of the data. In this paper, we approach this challenge through a combination of the Minimum Description Length (MDL) principle, feature selection strategies, and convolution techniques from the signal processing field. As a result, our algorithm produces a good decomposition of a given time series and, as a side effect, builds a compact representation of its identified components. Experiments demonstrate that our method manages to identify correctly both the number and the temporal scale of the components for real-world as well as artificial data and show the usefulness of our method as an exploratory tool for analyzing time series data.

#index 1925623
#* Separable approximate optimization of support vector machines for distributed sensing
#@ Sangkyun Lee;Marco Stolpe;Katharina Morik
#t 2012
#c 22
#% 269217
#% 565549
#% 722815
#% 769930
#% 770846
#% 832903
#% 916799
#% 961190
#% 983901
#% 1264133
#% 1299294
#% 1495599
#% 1563305
#% 1606356
#% 1694288
#! Sensor measurements from diverse locations connected with possibly low bandwidth communication channels pose a challenge of resource-restricted distributed data analyses. In such settings it would be desirable to perform learning in each location as much as possible, without transferring all data to a central node. Applying the support vector machines (SVMs) with nonlinear kernels becomes nontrivial, however. In this paper, we present an efficient optimization scheme for training SVMs over such sensor networks. Our framework performs optimization independently in each node, using only the local features stored in the respective node. We make use of multiple local kernels and explicit approximations to the feature mappings induced by them. Together they allow us constructing a separable surrogate objective that provides an upper bound of the primal SVM objective. A central coordination is also designed to adjust the weights among local kernels for improved prediction, while minimizing communication cost.

#index 1925624
#* Unsupervised inference of auditory attention from biosensors
#@ Melih Kandemir;Arto Klami;Akos Vetek;Samuel Kaski
#t 2012
#c 22
#% 344556
#% 818220
#% 855563
#% 891549
#% 936365
#% 983857
#% 1147703
#% 1293608
#% 1496794
#% 1573944
#% 1727782
#! We study ways of automatically inferring the level of attention a user is paying to auditory content, with applications for example in automatic podcast highlighting and auto-pause, as well as in a selection mechanism in auditory interfaces. In particular, we demonstrate how the level of attention can be inferred in an unsupervised fashion, without requiring any labeled training data. The approach is based on measuring the (generalized) correlation or synchrony between the auditory content and physiological signals reflecting the state of the user. We hypothesize that the synchrony is higher when the user is paying attention to the content, and show empirically that the level of attention can indeed be inferred based on the correlation. In particular, we demonstrate that the novel method of time-varying Bayesian canonical correlation analysis gives unsupervised prediction accuracy comparable to having trained a supervised Gaussian process regression with labeled training data recorded from other users.

#index 1925625
#* A family of feed-forward models for protein sequence classification
#@ Sam Blasiak;Huzefa Rangwala;Kathryn B. Laskey
#t 2012
#c 22
#% 274189
#% 773682
#% 830744
#% 832727
#% 905796
#% 1021422
#% 1826253
#% 1860543
#! Advances in sequencing have greatly outpaced experimental methods for determining a protein's structure and function. As a result, biologists increasingly rely on computational techniques to infer these properties of proteins from sequence information alone. We present a sequence classification framework that differs from the common SVM/kernel-based approach. We introduce a type of artificial neural network which we term the Subsequence Network (SN) that incorporates structural models over sequences in its lowest layer. These structural models, which we call Sequence Scoring Models (SSM), are similar to Hidden Markov Models and act as a mechanism to extract relevant features from sequences. In contrast to SVM/kernel methods, which only allow learning of linear discrimination weights, our feed-forward structure allows linear weights to be learned in conjunction with sequence-level features using standard optimization techniques.

#index 1925626
#* General algorithms for mining closed flexible patterns under various equivalence relations
#@ I. Tomohiro;Yuki Enokuma;Hideo Bannai;Masayuki Takeda
#t 2012
#c 22
#% 24076
#% 302742
#% 329537
#% 420063
#% 459006
#% 463903
#% 464996
#% 577256
#% 745515
#% 783497
#% 982764
#% 1108833
#% 1206864
#% 1307272
#% 1412479
#% 1535472
#% 1549838
#% 1594610
#% 1737789
#! We address the closed pattern discovery problem in sequential databases for the class of flexible patterns. We propose two techniques of coarsening existing equivalence relations on the set of patterns to obtain new equivalence relations. Our new algorithm GenCloFlex is a generalization of MaxFlex proposed by Arimura and Uno (2007) that was designed for a particular equivalence relation. GenCloFlex can cope with existing, as well as new equivalence relations, and we investigate the computational complexities of the algorithm for respective equivalence relations. Then, we present an improved algorithm GenCloFlex+ based on new pruning techniques, which improve the delay time per output for some of the equivalence relations. By computational experiments on synthetic data, we show that most of the redundancies in the mined patterns are removed using the proposed equivalence relations.

#index 1925627
#* Size matters: finding the most informative set of window lengths
#@ Jefrey Lijffijt;Panagiotis Papapetrou;Kai Puolamäki
#t 2012
#c 22
#% 409857
#% 420063
#% 548479
#% 569754
#% 725366
#% 729960
#% 742513
#% 840903
#% 844308
#% 844315
#% 875024
#% 972352
#% 1022227
#% 1038477
#% 1084210
#% 1617319
#! Event sequences often contain continuous variability at different levels. In other words, their properties and characteristics change at different rates, concurrently. For example, the sales of a product may slowly become more frequent over a period of several weeks, but there may be interesting variation within a week at the same time. To provide an accurate and robust "view" of such multi-level structural behavior, one needs to determine the appropriate levels of granularity for analyzing the underlying sequence. We introduce the novel problem of finding the best set of window lengths for analyzing discrete event sequences. We define suitable criteria for choosing window lengths and propose an efficient method to solve the problem. We give examples of tasks that demonstrate the applicability of the problem and present extensive experiments on both synthetic data and real data from two domains: text and DNA. We find that the optimal sets of window lengths themselves can provide new insight into the data, e.g., the burstiness of events affects the optimal window lengths for measuring the event frequencies.

#index 1925628
#* Discovering links among social networks
#@ Francesco Buccafurri;Gianluca Lax;Antonino Nocera;Domenico Ursino
#t 2012
#c 22
#% 452859
#% 748619
#% 881917
#% 913783
#% 955712
#% 993980
#% 1080078
#% 1082200
#% 1131425
#% 1443431
#% 1606051
#% 1635129
#% 1737766
#% 1966777
#! Distinct social networks are interconnected via bridge users, who play thus a key role when crossing information is investigated in the context of Social Internetworking analysis. Unfortunately, not always users make their role of bridge explicit by specifying the so-called me edge (i.e., the edge connecting the accounts of the same user in two distinct social networks), missing thus a potentially very useful information. As a consequence, discovering missing me edges is an important problem to face in this context yet not so far investigated. In this paper, we propose a common-neighbors approach to detecting missing me edges, which returns good results in real life settings. Indeed, an experimental campaign shows both that the state-of-the-art common-neighbors approaches cannot be effectively applied to our problem and, conversely, that our approach returns precise and complete results.

#index 1925629
#* Efficient bi-objective team formation in social networks
#@ Mehdi Kargar;Aijun An;Morteza Zihayat
#t 2012
#c 22
#% 262112
#% 881460
#% 1075875
#% 1178476
#% 1214668
#% 1297295
#% 1482238
#% 1512399
#% 1546761
#% 1642027
#% 1746882
#! We tackle the problem of finding a team of experts from a social network to complete a project that requires a set of skills. The social network is modeled as a graph. A node in the graph represents an expert and has a weight representing the monetary cost for using the expert service. Two nodes in the graph can be connected and the weight on the edge represents the communication cost between the two corresponding experts. Given a project, our objective is to find a team of experts that covers all the required skills and also minimizes the communication cost as well as the personnel cost of the project. To minimize both of the objectives, we define a new combined cost function which is based on the linear combination of the objectives (i.e. communication and personnel costs). We show that the problem of minimizing the combined cost function is an NP-hard problem. Thus, one approximation algorithm is proposed to solve the problem. The proposed approximation algorithm is bounded and the approximation ratio of the algorithm is proved in the paper. Three heuristic algorithms based on different intuitions are also proposed for solving the problem. Extensive experiments on real datasets demonstrate the effectiveness and scalability of the proposed algorithms.

#index 1925630
#* Feature-Enhanced probabilistic models for diffusion network inference
#@ Liaoruo Wang;Stefano Ermon;John E. Hopcroft
#t 2012
#c 22
#% 251365
#% 577217
#% 729923
#% 832271
#% 1451242
#% 1451246
#% 1617325
#! Cascading processes, such as disease contagion, viral marketing, and information diffusion, are a pervasive phenomenon in many types of networks. The problem of devising intervention strategies to facilitate or inhibit such processes has recently received considerable attention. However, a major challenge is that the underlying network is often unknown. In this paper, we revisit the problem of inferring latent network structure given observations from a diffusion process, such as the spread of trending topics in social media. We define a family of novel probabilistic models that can explain recurrent cascading behavior, and take into account not only the time differences between events but also a richer set of additional features. We show that MAP inference is tractable and can therefore scale to very large real-world networks. Further, we demonstrate the effectiveness of our approach by inferring the underlying network structure of a subset of the popular Twitter following network by analyzing the topics of a large number of messages posted by users over a 10-month period. Experimental results show that our models accurately recover the links of the Twitter network, and significantly improve the performance over previous models based entirely on time.

#index 1925631
#* Influence spread in large-scale social networks --- a belief propagation approach
#@ Huy Nguyen;Rong Zheng
#t 2012
#c 22
#% 268079
#% 342596
#% 577217
#% 580307
#% 729923
#% 989613
#% 1214641
#% 1451243
#% 1472304
#% 1523718
#% 1535380
#% 1560169
#% 1650318
#% 1663638
#% 1848680
#! Influence maximization is the problem of finding a small set of seed nodes in a social network that maximizes the spread of influence under a certain diffusion model. The Greedy algorithm for influence maximization first proposed by Kempe, later improved by Leskovec suffers from two sources of computational deficiency: 1) the need to evaluate many candidate nodes before selecting a new seed in each round, and 2) the calculation of the influence spread of any seed set relies on Monte-Carlo simulations. In this work, we tackle both problems by devising efficient algorithms to compute influence spread and determine the best candidate for seed selection. The fundamental insight behind the proposed algorithms is the linkage between influence spread determination and belief propagation on a directed acyclic graph (DAG). Experiments using real-world social network graphs with scales ranging from thousands to millions of edges demonstrate the superior performance of the proposed algorithms with moderate computation costs.

#index 1925632
#* Location affiliation networks: bonding social and spatial information
#@ Konstantinos Pelechrinis;Prashant Krishnamurthy
#t 2012
#c 22
#% 1135166
#% 1281823
#% 1399017
#% 1476153
#% 1480830
#% 1573621
#% 1606045
#% 1606049
#% 1606051
#! Location-based social networks (LBSNs) have recently attracted a lot of attention due to the number of novel services they can offer. Prior work on analysis of LBSNs has mainly focused on the social part of these systems. Even though it is important to know how different the structure of the social graph of an LBSN is as compared to the friendship-based social networks (SNs), it raises the interesting question of what kinds of linkages exist between locations and friendships. The main problem we are investigating is to identify such connections between the social and the spatial planes of an LBSN. In particular, in this paper we focus on answering the following general question "What are the bonds between the social and spatial information in an LBSN and what are the metrics that can reveal them?" In order to tackle this problem, we employ the idea of affiliation networks. Analyzing a dataset from a specific LBSN (Gowalla), we make two main interesting observations; (i) the social network exhibits signs of homophily with regards to the "places/venues" visited by the users, and (ii) the "nature" of the visited venues that are common to users is powerful and informative in revealing the social/spatial linkages. We further show that the "entropy" (or diversity) of a venue can be used to better connect spatial information with the existing social relations. The entropy records the diversity of a venue and requires only location history of users (it does not need temporal history). Finally, we provide a simple application of our findings for predicting existing friendship relations based on users' historic spatial information. We show that even with simple unsupervised learning models we can achieve significant improvement in prediction when we consider features that capture the "nature" of the venue as compared to the case where only apparent properties of the location history are used (e.g., number of common visits).

#index 1925633
#* On approximation of real-world influence spread
#@ Yu Yang;Enhong Chen;Qi Liu;Biao Xiang;Tong Xu;Shafqat Ali Shad
#t 2012
#c 22
#% 342596
#% 729923
#% 881460
#% 949164
#% 1083624
#% 1451243
#% 1663638
#% 1746850
#! To find the most influential nodes for viral marketing, several models have been proposed to describe the influence propagation process. Among them, the Independent Cascade (IC) Model is most widely-studied. However, under IC model, computing influence spread (i.e., the expected number of nodes that will be influenced) for each given seed set has been proved to be #P-hard. To that end, in this paper, we propose GS algorithm for quick approximation of influence spread by solving a linear system, based on the fact that propagation probabilities in real-world social networks are usually quite small. Furthermore, for better approximation, we study the structural defect problem existing in networks, and correspondingly, propose enhanced algorithms, GSbyStep and SSSbyStep, by incorporating the Maximum Influence Path heuristic. Our algorithms are evaluated by extensive experiments on four social networks. Experimental results show that our algorithms can get better approximations to the IC model than the state-of-the-arts.

#index 1925634
#* Opinion formation by voter model with temporal decay dynamics
#@ Masahiro Kimura;Kazumi Saito;Kouzou Ohara;Hiroshi Motoda
#t 2012
#c 22
#% 729923
#% 794513
#% 949164
#% 989613
#% 1083641
#% 1171581
#% 1214641
#% 1214666
#% 1350272
#% 1407355
#% 1535380
#% 1630584
#! Social networks play an important role for spreading information and forming opinions. A variety of voter models have been defined that help analyze how people make decisions based on their neighbors' decisions. In these studies, common practice has been to use the latest decisions in opinion formation process. However, people may decide their opinions by taking account not only of their neighbors' latest opinions, but also of their neighbors' past opinions. To incorporate this effect, we enhance the original voter model and define the temporal decay voter (TDV) model incorporating a temporary decay function with parameters, and propose an efficient method of learning these parameters from the observed opinion diffusion data. We further propose an efficient method of selecting the most appropriate decay function from among the candidate functions each with the optimized parameter values. We adopt three functions as the typical candidates: the exponential decay, the power-law decay, and no decay, and evaluate the proposed method (parameter learning and model selection) through extensive experiments. We, first, experimentally demonstrate, by using synthetic data, the effectiveness of the proposed method, and then we analyze the real opinion diffusion data from a Japanese word-of-mouth communication site for cosmetics using three decay functions above, and show that most opinions conform to the TDV model of the power-law decay function.

#index 1925635
#* Viral marketing for product cross-sell through social networks
#@ Ramasuri Narayanam;Amit A. Nanavati
#t 2012
#c 22
#% 342596
#% 577217
#% 729923
#% 989613
#% 990216
#% 1081553
#% 1098282
#% 1214641
#% 1384246
#% 1407355
#% 1407359
#% 1425621
#% 1535389
#% 1540249
#% 1605972
#% 1663638
#! The well known influence maximization problem [1] (or viral marketing through social networks) deals with selecting a few influential initial seeds to maximize the awareness of product(s) over the social network. In this paper, we introduce a novel and generalized version of the influence maximization problem that considers simultaneously the following three practical aspects: (i) Often cross-sell among products is possible, (ii) Product specific costs (and benefits) for promoting the products have to be considered, and (iii) Since a company often has budget constraints, the initial seeds have to be chosen within a given budget. We refer to this generalized problem setting as Budgeted Influence Maximization with Cross-sell of Products (B-IMCP). To the best of our knowledge, we are not aware of any work in the literature that addresses the B-IMCP problem which is the subject matter of this paper. Given a fixed budget, one of the key issues associated with the B-IMCP problem is to choose the initial seeds within this budget not only for the individual products, but also for promoting cross-sell phenomenon among these products. In particular, the following are the specific contributions of this paper: (i) We propose an influence propagation model to capture both the cross-sell phenomenon and product specific costs and benefits; (ii) As the B-IMCP problem is NP-hard computationally, we present a simple greedy approximation algorithm and then derive the approximation guarantee of this greedy algorithm by drawing upon the results from the theory of matroids; (iii) We then outline two efficient heuristics based on well known concepts in the literature. Finally, we experimentally evaluate the proposed approach for the B-IMCP problem using a few well known social network data sets such as WikiVote data set, Epinions, and Telecom call detail records data.

#index 1925636
#* Which topic will you follow?
#@ Deqing Yang;Yanghua Xiao;Bo Xu;Hanghang Tong;Wei Wang;Sheng Huang
#t 2012
#c 22
#% 794513
#% 881460
#% 907511
#% 1026853
#% 1035580
#% 1083624
#% 1083641
#% 1214692
#% 1214702
#% 1292563
#% 1297063
#% 1399993
#% 1451162
#% 1451233
#% 1451242
#% 1535333
#% 1567974
#% 1689528
#% 1810385
#! Who are the most appropriate candidates to receive a call-for-paper or call-for-participation? What session topics should we propose for a conference of next year? To answer these questions, we need to precisely predict research topics of authors. In this paper, we build a MLR (Multiple Logistic Regression) model to predict the topic-following behavior of an author. By empirical studies, we find that social influence and homophily are two fundamental driving forces of topic diffusion in SCN (Scientific Collaboration Network). Hence, we build the model upon the explanatory variables representing above two driving forces. Extensive experimental results show that our model can consistently achieves good predicting performance. Such results are independent of the tested topics and significantly better than that of state-of-the-art competitor.

#index 1925637
#* Inferring geographic coincidence in ephemeral social networks
#@ Honglei Zhuang;Alvin Chin;Sen Wu;Wei Wang;Xia Wang;Jie Tang
#t 2012
#c 22
#% 464434
#% 787175
#% 813844
#% 1083734
#% 1089822
#% 1135166
#% 1214702
#% 1267770
#% 1425621
#% 1451232
#% 1451245
#% 1531162
#% 1535341
#% 1606049
#% 1617365
#% 1693935
#% 1886573
#! We study users' behavioral patterns in ephemeral social networks, which are temporarily built based on events such as conferences. From the data distribution and social theory perspectives, we found several interesting patterns. For example, the duration of two random persons staying at the same place and at the same time obeys a two-stage power-law distribution. We develop a framework to infer the likelihood of two users to meet together, and we apply the framework to two mobile social networks: UbiComp and Reality. The former is formed by researchers attending UbiComp 2011 and the latter is a network of students published by MIT. On both networks, we validate the proposed predictive framework, which significantly improve the accuracy for predicting geographic coincidence by comparing with two baseline methods.

#index 1925638
#* Pedestrian quantity estimation with trajectory patterns
#@ Thomas Liebig;Zhao Xu;Michael May;Stefan Wrobel
#t 2012
#c 22
#% 122797
#% 463903
#% 464615
#% 862540
#% 891549
#% 923861
#% 1000502
#% 1090160
#% 1135199
#% 1159171
#% 1159298
#% 1318675
#% 1318808
#% 1682572
#! In street-based mobility mining, traffic volume estimation receives increasing attention as it provides important applications such as emergency support systems, quality-of-service evaluation and billboard placement. In many real world scenarios, empirical measurements are usually sparse due to some constraints. On the other hand, pedestrians generally show some movement preferences, especially in closed environments, e.g., train stations. We propose a Gaussian process regression based method for traffic volume estimation, which incorporates topological information and prior knowledge on preferred trajectories with a trajectory pattern kernel. Our approach also enables effectively finding most informative sensor placements. We evaluate our method with synthetic German train station pedestrian data and real-world episodic movement data from the zoo of Duisburg. The empirical analysis demonstrates that incorporating trajectory patterns can largely improve the traffic prediction accuracy, especially when traffic networks are sparsely monitored.

#index 1925639
#* Socioscope: spatio-temporal signal recovery from social media
#@ Jun-Ming Xu;Aniruddha Bhargava;Robert Nowak;Xiaojin Zhu
#t 2012
#c 22
#% 262042
#% 350859
#% 722904
#% 869516
#% 1400018
#% 1432574
#% 1481659
#% 1560379
#% 1560410
#% 1711859
#% 1816821
#! Many real-world phenomena can be represented by a spatio-temporal signal: where, when, and how much. Social media is a tantalizing data source for those who wish to monitor such signals. Unlike most prior work, we assume that the target phenomenon is known and we are given a method to count its occurrences in social media. However, counting is plagued by sample bias, incomplete data, and, paradoxically, data scarcity --- issues inadequately addressed by prior work. We formulate signal recovery as a Poisson point process estimation problem. We explicitly incorporate human population bias, time delays and spatial distortions, and spatio-temporal regularization into the model to address the noisy count issues. We present an efficient optimization algorithm and discuss its theoretical properties. We show that our model is more accurate than commonly-used baselines. Finally, we present a case study on wildlife roadkill monitoring, where our model produces qualitatively convincing results.

#index 1925640
#* A framework for evaluating the smoothness of data-mining results
#@ Gaurav Misra;Behzad Golshan;Evimaria Terzi
#t 2012
#c 22
#% 338397
#% 360748
#% 729923
#% 832742
#% 881472
#% 937549
#% 963241
#% 1164933
#% 1219784
#% 1301156
#% 1379583
#% 1495595
#% 1535471
#% 1605931
#! The data-mining literature is rich in problems that are formalized as combinatorial-optimization problems. An indicative example is the entity-selection formulation that has been used to model the problem of selecting a subset of representative reviews from a review corpus [11,22]or important nodes in a social network [10]. Existing combinatorial algorithms for solving such entity-selection problems identify a set of entities (e.g., reviews or nodes) as important. Here, we consider the following question: how do small or large changes in the input dataset change the value or the structure of the such reported solutions? We answer this question by developing a general framework for evaluating the smoothness (i.e, consistency) of the data-mining results obtained for the input dataset X. We do so by comparing these results with the results obtained for datasets that are within a small or a large distance from X. The algorithms we design allow us to perform such comparisons effectively and thus, approximate the results' smoothness efficiently. Our experimental evaluation on real datasets demonstrates the efficacy and the practical utility of our framework in a wide range of applications.

#index 1925641
#* Active evaluation of ranking functions based on graded relevance
#@ Christoph Sawade;Steffen Bickel;Timo von Oertzen;Tobias Scheffer;Niels Landwehr
#t 2012
#c 22
#% 132583
#% 400847
#% 411762
#% 879598
#% 879632
#% 1019126
#% 1211696
#% 1227446
#% 1292528
#% 1817412
#! Evaluating the quality of ranking functions is a core task in web search and other information retrieval domains. Because query distributions and item relevance change over time, ranking models often cannot be evaluated accurately on held-out training data. Instead, considerable effort is spent on manually labeling the relevance of query results for test queries in order to track ranking performance. We address the problem of estimating ranking performance as accurately as possible on a fixed labeling budget. Estimates are based on a set of most informative test queries selected by an active sampling distribution. Query labeling costs depend on the number of result items as well as item-specific attributes such as document length. We derive cost-optimal sampling distributions for the commonly used performance measures Discounted Cumulative Gain (DCG) and Expected Reciprocal Rank (ERR). Experiments on web search engine data illustrate significant reductions in labeling costs.

#index 1925642
#* Community trend outlier detection using soft temporal pattern mining
#@ Manish Gupta;Jing Gao;Yizhou Sun;Jiawei Han
#t 2012
#c 22
#% 333929
#% 466425
#% 481290
#% 781774
#% 784297
#% 785389
#% 1019143
#% 1202160
#% 1206639
#% 1214633
#% 1446962
#% 1451221
#% 1482422
#% 1523860
#% 1562549
#% 1594652
#% 1607952
#% 1872334
#! Numerous applications, such as bank transactions, road traffic, and news feeds, generate temporal datasets, in which data evolves continuously. To understand the temporal behavior and characteristics of the dataset and its elements, we need effective tools that can capture evolution of the objects. In this paper, we propose a novel and important problem in evolution behavior discovery. Given a series of snapshots of a temporal dataset, each of which consists of evolving communities, our goal is to find objects which evolve in a dramatically different way compared with the other community members. We define such objects as community trend outliers. It is a challenging problem as evolutionary patterns are hidden deeply in noisy evolving datasets and thus it is difficult to distinguish anomalous objects from normal ones. We propose an effective two-step procedure to detect community trend outliers. We first model the normal evolutionary behavior of communities across time using soft patterns discovered from the dataset. In the second step, we propose effective measures to evaluate chances of an object deviating from the normal evolutionary patterns. Experimental results on both synthetic and real datasets show that the proposed approach is highly effective in discovering interesting community trend outliers.

#index 1925643
#* Data structures for detecting rare variations in time series
#@ Caio Valentim;Eduardo S. Laber;David Sotelo
#t 2012
#c 22
#% 186
#% 172949
#% 397381
#% 498538
#% 765403
#% 765537
#% 998465
#% 1503356
#% 1672945
#! In this paper we study, from both a theoretical and an experimental perspective, algorithms and data structures to process queries that help in the detection of rare variations over time intervals that occur in time series. Our research is strongly motivated by applications in financial domain.

#index 1925644
#* Invariant time-series classification
#@ Josif Grabocka;Alexandros Nanopoulos;Lars Schmidt-Thieme
#t 2012
#c 22
#% 232396
#% 310545
#% 425049
#% 478438
#% 493092
#% 640416
#% 737331
#% 788073
#% 795273
#% 857993
#% 874593
#% 876074
#% 1013664
#% 1127609
#% 1510746
#! Time-series classification is a field of machine learning that has attracted considerable focus during the recent decades. The large number of time-series application areas ranges from medical diagnosis up to financial econometrics. Support Vector Machines (SVMs) are reported to perform non-optimally in the domain of time series, because they suffer detecting similarities in the lack of abundant training instances. In this study we present a novel time-series transformation method which significantly improves the performance of SVMs. Our novel transformation method is used to enlarge the training set through creating new transformed instances from the support vector instances. The new transformed instances encapsulate the necessary intra-class variations required to redefine the maximum margin decision boundary. The proposed transformation method utilizes the variance distributions from the intra-class warping maps to build transformation fields, which are applied to series instances using the Moving Least Squares algorithm. Extensive experimentations on 35 time series datasets demonstrate the superiority of the proposed method compared to both the Dynamic Time Warping version of the Nearest Neighbor and the SVMs classifiers, outperforming them in the majority of the experiments.

#index 1925645
#* Learning bi-clustered vector autoregressive models
#@ Tzu-Kuo Huang;Jeff Schneider
#t 2012
#c 22
#% 434557
#% 832644
#% 840872
#% 1036692
#% 1214482
#% 1270334
#% 1417096
#% 1835483
#! Vector Auto-regressive (VAR) models are useful for analyzing temporal dependencies among multivariate time series, known as Granger causality. There exist methods for learning sparse VAR models, leading directly to causal networks among the variables of interest. Another useful type of analysis comes from clustering methods, which summarize multiple time series by putting them into groups. We develop a methodology that integrates both types of analyses, motivated by the intuition that Granger causal relations in real-world time series may exhibit some clustering structure, in which case the estimation of both should be carried out together. Our methodology combines sparse learning and a nonparametric bi-clustered prior over the VAR model, conducting full Bayesian inference via blocked Gibbs sampling. Experiments on simulated and real data demonstrate improvements in both model estimation and clustering quality over standard alternatives, and in particular biologically more meaningful clusters in a T-cell activation gene expression time series dataset than those by other methods.

#index 1925646
#* Discriminative factor alignment across heterogeneous feature space
#@ Fangwei Hu;Tianqi Chen;Nathan N. Liu;Qiang Yang;Yong Yu
#t 2012
#c 22
#% 457912
#% 642990
#% 722927
#% 760805
#% 812535
#% 839975
#% 975105
#% 983899
#% 1083696
#% 1148273
#% 1328303
#% 1417104
#% 1464068
#% 1484460
#% 1868272
#! Transfer learning as a new machine learning paradigm has gained increasing attention lately. In situations where the training data in a target domain are not sufficient to learn predictive models effectively, transfer learning leverages auxiliary source data from related domains for learning. While most of the existing works in this area are only focused on using the source data with the same representational structure as the target data, in this paper, we push this boundary further by extending transfer between text and images. We integrate documents , tags and images to build a heterogeneous transfer learning factor alignment model and apply it to improve the performance of tag recommendation. Many algorithms for tag recommendation have been proposed, but many of them have problem; the algorithm may not perform well under cold start conditions or for items from the long tail of the tag frequency distribution. However, with the help of documents, our algorithm handles these problems and generally outperforms other tag recommendation methods, especially the non-transfer factor alignment model.

#index 1925647
#* Learning to perceive two-dimensional displays using probabilistic grammars
#@ Nan Li;William W. Cohen;Kenneth R. Koedinger
#t 2012
#c 22
#% 20845
#% 262191
#% 480824
#% 654469
#% 1127393
#% 1710351
#% 1876999
#% 1877038
#! People learn to read and understand various displays (e.g., tables on webpages and software user interfaces) every day. How do humans learn to process such displays? Can computers be efficiently taught to understand and use such displays? In this paper, we use statistical learning to model how humans learn to perceive visual displays. We extend an existing probabilistic context-free grammar learner to support learning within a two-dimensional space by incorporating spatial and temporal information. Experimental results in both synthetic domains and real world domains show that the proposed learning algorithm is effective in acquiring user interface layout. Furthermore, we evaluate the effectiveness of the proposed algorithm within an intelligent tutoring agent, SimStudent, by integrating the learned display representation into the agent. Experimental results in learning complex problem solving skills in three domains show that the learned display representation is as good as one created by a human expert, in that skill learning using the learned representation is as effective as using a manually created representation.

#index 1925648
#* Transfer spectral clustering
#@ Wenhao Jiang;Fu-lai Chung
#t 2012
#c 22
#% 36672
#% 236497
#% 313959
#% 342621
#% 464291
#% 729918
#% 770847
#% 840862
#% 916785
#% 916788
#% 983899
#% 1073897
#% 1077150
#% 1211714
#% 1272110
#% 1464068
#% 1757632
#! Transferring knowledge from auxiliary datasets has been proved useful in machine learning tasks. Its adoption in clustering however is still limited. Despite of its superior performance, spectral clustering has not yet been incorporated with knowledge transfer or transfer learning. In this paper, we make such an attempt and propose a new algorithm called transfer spectral clustering (TSC). It involves not only the data manifold information of the clustering task but also the feature manifold information shared between related clustering tasks. Furthermore, it makes use of co-clustering to achieve and control the knowledge transfer among tasks. As demonstrated by the experimental results, TSC can greatly improve the clustering performance by effectively using auxiliary unlabeled data when compared with other state-of-the-art clustering algorithms.

#index 1925649
#* An aspect-lexicon creation and evaluation tool for sentiment analysis researchers
#@ Mus'ab Husaini;Ahmet Koçyiğit;Dilek Tapucu;Berrin Yanikoglu;Yücel Saygın
#t 2012
#c 22
#% 816186
#% 1127964
#% 1536539
#! In this demo paper, we present SARE, a modular and extendable semi-automatic system that 1) assists researchers in building gold-standard lexicons and evaluating their lexicon extraction algorithms; and 2) provides a general and extendable sentiment analysis environment to help researchers analyze the behavior and errors of a core sentiment analysis engine using a particular lexicon.

#index 1925650
#* Association rule mining following the web search paradigm
#@ Radek Škrabal;Milan Šimůnek;Stanislav Vojíř;Andrej Hazucha;Tomáš Marek;David Chudán;Tomáš Kliegr
#t 2012
#c 22
#% 1300485
#% 1434114
#% 1617385
#% 1619636
#% 1647913
#! I:ZI Miner (sewebar.vse.cz/izi-miner ) is an association rule mining system with a user interface resembling a search engine. It brings to the web the notion of interactive pattern mining introduced by the MIME framework at ECML'11 and KDD'11. In comparison with MIME, I:ZI Miner discovers multi-valued attributes, supports the full range of logical connectives and 19 interest measures. A relevance feedback module is used to filter the rules based on previous user interactions.

#index 1925651
#* ASV monitor: creating comparability of machine learning methods for content analysis
#@ Andreas Niekler;Patrick Jähnichen;Gerhard Heyer
#t 2012
#c 22
#% 575570
#% 577220
#% 722904
#! In this demonstration paper we present an application to compare and evaluate machine learning methods used for natural language processing within a content analysis framework. Our aim is to provide an example set of possible machine learning results for different inputs to increase the acceptance of using machine learning in settings that originally rely on manual treatment. We will demonstrate the possibility to compare machine learning algorithms regarding the outcome of the implemented approaches. The application allows the user to evaluate the benefit of using machine learning algorithms for content analysis by a visual comparison of their results.

#index 1925652
#* ClowdFlows: a cloud based scientific workflow platform
#@ Janez Kranjc;Vid Podpečan;Nada Lavrač
#t 2012
#c 22
#% 799792
#% 881575
#% 1567948
#% 1630585
#% 1706755
#! This paper presents an open cloud based platform for composition, execution, and sharing of interactive data mining workflows. It is based on the principles of service-oriented knowledge discovery, and features interactive scientific workflows. In contrast to comparable data mining platforms, our platform runs in all major Web browsers and platforms, including mobile devices. In terms of crowdsourcing, ClowdFlows provides researchers with an easy way to expose and share their work and results, as only an Internet connection and a Web browser are required to access the workflows from anywhere. Practitioners can use ClowdFlows to seamlessly integrate and join different implementations of algorithms, tools and Web services into a coherent workflow that can be executed in a cloud based application. ClowdFlows is also easily extensible during run-time by importing Web services and using them as new workflow components.

#index 1925653
#* Extracting trajectories through an efficient and unifying spatio-temporal pattern mining system
#@ Phan Nhat Hai;Dino Ienco;Pascal Poncelet;Maguelonne Teisseire
#t 2012
#c 22
#% 769899
#% 875505
#% 1127436
#% 1426623
#% 1523860
#% 1697319
#% 1720762
#! Recent improvements in positioning technology has led to a much wider availability of massive moving object data. A crucial task is to find the moving objects that travel together. Usually, these object sets are called spatio-temporal patterns. Analyzing such data has been applied in many real world applications, e.g., in ecological study, vehicle control, mobile communication management, etc. However, few tools are available for flexible and scalable analysis of massive scale moving objects. Additionally, there is no framework devoted to efficiently manage multiple kinds of patterns at the same time. Motivated by this issue, we propose a framework, named GeT_Move, which is designed to extract and manage different kinds of spatio-temporal patterns concurrently. A user-friendly interface is provided to facilitate interactive exploration of mining results. Since GeT_Move is tested on many kinds of real data sets, it will benefit users to carry out versatile analysis on these kinds of data by exhibiting different kinds of patterns efficiently.

#index 1925654
#* Knowledge discovery through symbolic regression with heuristiclab
#@ Gabriel Kronberger;Stefan Wagner;Michael Kommenda;Andreas Beham;Andreas Scheibenpflug;Michael Affenzeller
#t 2012
#c 22
#% 1261874
#% 1296110
#% 1723297
#! This contribution describes how symbolic regression can be used for knowledge discovery with the open-source software HeuristicLab. HeuristicLab includes a large set of algorithms and problems for combinatorial optimization and for regression and classification, including symbolic regression with genetic programming. It provides a rich GUI to analyze and compare algorithms and identified models. This contribution mainly focuses on specific aspects of symbolic regression that are unique to HeuristicLab, in particular, the identification of relevant variables and model simplification.

#index 1925655
#* OutRules: a framework for outlier descriptions in multiple context spaces
#@ Emmanuel Müller;Fabian Keller;Sebastian Blanc;Klemens Böhm
#t 2012
#c 22
#% 300136
#% 333929
#% 479986
#% 1174748
#% 1196030
#% 1202160
#% 1496814
#% 1594655
#% 1846695
#! Analyzing exceptional objects is an important mining task. It includes the identification of outliers but also the description of outlier properties in contrast to regular objects. However, existing detection approaches miss to provide important descriptions that allow human understanding of outlier reasons. In this work we present OutRules, a framework for outlier descriptions that enable an easy understanding of multiple outlier reasons in different contexts. We introduce outlier rules as a novel outlier description model. A rule illustrates the deviation of an outlier in contrast to its context that is considered to be normal. Our framework highlights the practical use of outlier rules and provides the basis for future development of outlier description models.

#index 1925656
#* Scientific workflow management with ADAMS
#@ Peter Reutemann;Joaquin Vanschoren
#t 2012
#c 22
#% 879809
#% 881575
#% 1174009
#% 1726647
#! We demonstrate the Advanced Data mining And Machine learning System (ADAMS), a novel workflow engine designed for rapid prototyping and maintenance of complex knowledge workflows. ADAMS does not require the user to manually connect inputs to outputs on a large canvas. It uses a compact workflow representation, control operators, and a simple interface between operators, allowing them to be auto-connected. It contains an extensive library of operators for various types of analysis, and a convenient plug-in architecture to easily add new ones.

#index 1925657
#* TopicExplorer: exploring document collections with topic models
#@ Alexander Hinneburg;Rico Preiss;René Schröder
#t 2012
#c 22
#% 347225
#% 722904
#% 1701756
#! The demo presents a prototype --- called TopicExplorer --- that combines topic modeling, key word search and visualization techniques to explore a large collection of Wikipedia documents. Topics derived by Latent Dirichlet Allocation are presented by top words. In addition, topics are accompanied by image thumbnails extracted from related Wikipedia documents to aid sense making of derived topics during browsing. Topics are shown in a linear order such that similar topics are close. Topics are mapped to color using that order. The auto-completion of search terms suggests words together with their color coded topics, which allows to explore the relation between search terms and topics. Retrieved documents are shown with color coded topics as well. Relevant documents and topics found during browsing can be put onto a shortlist. The tool can recommend further documents with respect to the average topic mixture of the shortlist.

#index 1925658
#* VIKAMINE: open-source subgroup discovery, pattern mining, and analytics
#@ Martin Atzmueller;Florian Lemmerich
#t 2012
#c 22
#% 763701
#% 1223574
#% 1267660
#! This paper presents an overview on the VIKAMINE system for subgroup discovery, pattern mining and analytics. As of VIKAMINE version 2, it is implemented as rich-client platform (RCP) application, based on the Eclipse framework. This provides for a highly-configurable environment, and allows modular extensions using plugins. We present the system, briefly discuss exemplary plugins, and provide a sketch of successful applications.

#index 1925659
#* Learning submodular functions
#@ Maria-Florina Balcan;Nicholas J. A. Harvey
#t 2012
#c 22
#% 593846
#% 866746
#% 1061588
#% 1071494
#% 1105337
#% 1164876
#% 1274911
#! Submodular functions are discrete functions that model laws of diminishing returns and enjoy numerous algorithmic applications that have been used in many areas, including combinatorial optimization, machine learning, and economics. In this work we use a learning theoretic angle for studying submodular functions. We provide algorithms for learning submodular functions, as well as lower bounds on their learnability. In doing so, we uncover several novel structural results revealing both extremal properties as well as regularities of submodular functions, of interest to many areas.

#index 1925660
#* Matrix factorization as search
#@ Kristian Kersting;Christian Bauckhage;Christian Thurau;Mirwaes Wahabzada
#t 2012
#c 22
#% 1119142
#% 1278910
#% 1482435
#% 1694292
#! Simplex Volume Maximization (SiVM) exploits distance geometry for efficiently factorizing gigantic matrices. It was proven successful in game, social media, and plant mining. Here, we review the distance geometry approach and argue that it generally suggests to factorize gigantic matrices using search-based instead of optimization techniques.

#index 1925661
#* Metal binding in proteins: machine learning complements x-ray absorption spectroscopy
#@ Marco Lippi;Andrea Passerini;Marco Punta;Paolo Frasconi
#t 2012
#c 22
#% 829043
#% 1126394
#% 1653817
#! We present an application of machine learning algorithms for the identification of metalloproteins and metal binding sites on a genome scale. An extensive evaluation conducted in combination with X-ray absorption spectroscopy shows the great potentiality of the approach.

#index 1925662
#* Modelling input varying correlations between multiple responses
#@ Andrew Gordon Wilson;Zoubin Ghahramani
#t 2012
#c 22
#% 891549
#! We introduced a generalised Wishart process (GWP) for modelling input dependent covariance matrices Σ(x), allowing one to model input varying correlations and uncertainties between multiple response variables. The GWP can naturally scale to thousands of response variables, as opposed to competing multivariate volatility models which are typically intractable for greater than 5 response variables. The GWP can also naturally capture a rich class of covariance dynamics --- periodicity, Brownian motion, smoothness, …--- through a covariance kernel.

#index 2054377
#* Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September 23-27, 2013
#@ Hendrik Blockeel;Kristian Kersting;Siegfried Nijssen;Filip Zelezn
#t 2013
#c 22
#! This three-volume set LNAI 8188, 8189 and 8190 constitutes the refereed proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2013, held in Prague, Czech Republic, in September 2013. The 111 revised research papers presented together with 5 invited talks were carefully reviewed and selected from 447 submissions. The papers are organized in topical sections on reinforcement learning; Markov decision processes; active learning and optimization; learning from sequences; time series and spatio-temporal data; data streams; graphs and networks; social network analysis; natural language processing and information extraction; ranking and recommender systems; matrix and tensor analysis; structured output prediction, multi-label and multi-task learning; transfer learning; bayesian learning; graphical models; nearest-neighbor methods; ensembles; statistical learning; semi-supervised learning; unsupervised learning; subgroup discovery, outlier detection and anomaly detection; privacy and security; evaluation; applications; and medical applications.

