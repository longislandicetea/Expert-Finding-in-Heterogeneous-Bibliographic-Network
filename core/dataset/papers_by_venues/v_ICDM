#index 412150
#* Proceedings: 2001 IEEE International Conference on Data Mining, 29 November - 2 December 2001, San Jose, California
#@ Nick Cercone;Tsau Y. Lin;Xindong Wu
#t 2001
#c 18

#index 454202
#* Proceedings of the 2001 IEEE International Conference on Data Mining
#@ Nick Cercone;Tsau Young Lin;Xindong Wu
#t 2001
#c 18

#index 466341
#* Using Rough Sets Theory and Database Operations to Construct a Good Ensemble of Classifiers for Data Mining Applications
#@ Xiaohua Hu
#t 2001
#c 18
#! In this paper we present a new approach to construct a good ensemble of classifiers using rough sets theory and database operations. Ensembles of classifiers is formulated precisely within the framework of rough sets theory and constructed very efficiently by using set-oriented database operations. Our method first computes a set of reductswhich include all the indispensable attributes required for the decision categories. For each reduct, a reduct table is generated by removing those attributes which are not in the reduct. Next, a novel rule induction algorithm is used to compute the maximal generalized rules for each reducttable and a set of reduct classifiers is formed based on thecorresponding reducts. The distinctive features of our method as compared to other methods of constructing ensembles of classifiers are:(1) present a theoretical model to explain the mechanism of constructing ensemble of classifiers, (2) each reduct is a minimum subset of attributes, has the same classification ability as the entire attributes,(3)ea h reduct classifier constructed from the corresponding reduct has a minimal set of classification rules, and is as accurate andcomplete as possible and at the same time as diverse as possible from the other classifiers, (4)the test indicates that the number of classifiers used to improve the accuracy is muchless than other methods

#index 466342
#* Closing the Loop: An Agenda- and Justification-Based Framework for Selecting the Next Discovery Task to Perform
#@ Gary Livingston;John M. Rosenberg;Bruce G. Buchanan
#t 2001
#c 18
#! We propose and evaluate an agenda-and justification-basedarchitecture for discovery systems that selects the next tasks to perform. This framework has manydesirable properties: (1) it facilitates the encoding of general discovery strategies using a variety of backgroundknowledge, (2) t reasons about the appropriateness of the tasks being considered, and (3) it tailors its behavior toward a user 's interests. A prototype discovery program called HAMB demonstrates that both reasons andestimates of interestingness contribute to performance in the domains of protein crystallization and patient rehabilitation.

#index 466343
#* Efficient Splitting Rules Based on the Probabilities of Pre-assigned Intervals
#@ June-Suh Cho;Nabil R. Adam
#t 2001
#c 18
#! This paper describes new methods for classification in orderto find an optimal tree. Unlike the current splitting rules that areprovided by searching all threshold values, this paper proposes thesplitting rules that are based on the probabilities of pre-assignedintervals.

#index 466344
#* Association Rules Enhanced Classification of Underwater Acoustic Signal
#@ Jie Chen;Haiying Li;Shiwei Tang
#t 2001
#c 18
#! Classification of underwater acoustic signal is one ofthe important fields of pattern recognition. Inspired bythe experience of training man experts in sonar, wepropose a two-phase training algorithm to exploit theassociation rules to reveal the understandable intrinsicrules contributing to correct classification in the knownmisclassification datasets in this paper. Preliminaryexperimental results demonstrate the potential ofclassification association rules to enhance the accuracyof classification of underwater acoustic signals.

#index 466345
#* Distributed Web Mining Using Bayesian Networks from Multiple Data Streams
#@ R. Chen;Krishnamoorthy Sivakumar;Hillol Kargupta
#t 2001
#c 18
#! We present a collective approach to mine Bayesian net-works from distributed heterogenous web-log data streams. In this approach we first learn a local Bayesian network at each site using the local data. Then each site identifies the observations that are most likely to be evidence of coupling between local and non-local variables and transmits asub-set of these observations to a central site. Another Bayesian network is learnt at the central site using the data transmittedfrom the local site. The local and central Bayesian networks are combined to obtain a collective Bayesian net-work, that models the entire data. We applied this techniqueto mine multiple data streams where data centralization is difficult because of large response time and scalability issues.Experimental results and theoretical justification that demonstrate the feasibility of our approach are presented.

#index 466346
#* Mining California Vital Statistics Data
#@ Du Zhang;Quoc Luan Ha;Meiliu Lu
#t 2001
#c 18
#! Vital statistics data offer a fertile ground for data mining.In this paper, we discuss the results of a data miningproject on the causes of death aspect of the vital statisticsdata in the state of California. A data mining tool calledCubist is used to build predictive models out of two millioncases over a nine-year period. The objective of our studyis to discover knowledge that can be used to gain insightinto various aspects of mortality in California, to predicthealth issues related to the causes of death, to offer an aidto decision-or policy-making process, and to provideuseful information services to the customers. The resultsobtained in our study contain valuable new information.

#index 466347
#* A Pattern Decomposition (PD) Algorithm for Finding All Frequent Patterns in Large Datasets
#@ Qinghua Zou;Wesley W. Chu;David Johnson;Henry Chiu
#t 2001
#c 18
#! Efficient algorithms to mine frequent patterns are crucial to many tasks in data mining. Since the Apriori algorithm was proposed in 1994, there have been several methods proposed to improve its performance. However, most still adopt its candidate set generation-and-testapproach. We propose a pattern decomposition (PD) algorithm that can significantly reduce the size of the dataset on each pass making it more efficient to mine frequent patterns in a large dataset. The proposed algorithm avoids the costly process of candidate set generation and saves time by reducing dataset. Our empirical evaluation shows that the algorithmoutperforms Apriori by one order of magnitude and is faster than FP-tree. Further, PD is more scalable than both Apriori and FP-tree.

#index 466348
#* Creating Ensembles of Classifiers
#@ Nitesh V. Chawla;Steven Eschrich;Lawrence O. Hall
#t 2001
#c 18
#! Ensembles of classifiers offer promise in increasing overall classification accuracy. The availability of extremely large datasets has opened avenues for application of distributed and/or parallel learning to efficiently learn models of them. In this paper, distributed learningis done by training classifiers on disjoint subsets of the data. We examine a random partitioning method to create disjoint subsets and propose a more intelligent way of partitioning into disjointsubsets using clustering. It was observed that the intelligent method of partitioning generally performs better than random partitioning for our datasets. In both methods a significant gain in accuracy may be obtained by applying bagging to each of the disjoint subsets, creating multiple diverse classifiers. The significance of our finding is that a partition strategy for even small/moderate sized datasets when combined with bagging can yield better performancethan applying a single learner using the entire dataset.

#index 466349
#* Functional Trees for Classification
#@ Joao Gama
#t 2001
#c 18
#! The design of algorithms that explore multiple representation languages and explore different search space has an intuitive appeal.In this context of classification problems, algorithmsthat generate multivariate trees are able to explore multiplerepresentation languages by using decision test based on acombination of attributes.The same applies to models threesalgorithms, in regression domains, but using linear models atleaf nodes.In this paper we study where to use combinations of attributes in decision tree learning.We present an algorithm for multivariate tree learning that combines a univariate decision tree with a discriminant function by means of constructiveinduction.This algorithm is able to use decision nodes with multivariate tests, and leaf nodes that predict a class using adiscrimnant. Multivariate decision nodes are built when growing the tree, while functional leaves are built when pruning the tree.Functional trees can be seen as a generalization of multivariate trees.Our algorithm was compared against to its components and two simplified versions using 30 benchmark datasets. The experimental evaluation shows that our algorithm has clear Advantages with respect to the generalization ability and model sizes at statistically significant.

#index 466350
#* AINE: An Immunological Approach to Data Mining
#@ Thomas Knight;Jon Timmis
#t 2001
#c 18
#! An investigation has been undertaken to repeat previous work on an artificial immune system for data analysis called AINE (Artificial Immune Network).The previous work was limited to testing the algorithm on relatively small data sets. The aim of this investigation is two fold,firstly to corroborate the results presented in previous work and secondly, to test the algorithm on a larger and more complex data set. A new re-implementation of AINE is then described and differences in behaviour are identified and explained. It is argued that the behaviourseen in the new implementation is more accurate than that seen in previous work and an in-depth analysis of the algorithm structure is undertaken in order to confirm theseobservations. The algorithm is also tested on new data and the results of this are presented. Comparisons are draw with other similar techniques for data mining and it is argued that AINE is an effective data-mining algorithm.

#index 466351
#* Metric Rule Generation with Septic Shock Patient Data
#@ Jürgen Paetz
#t 2001
#c 18
#! In this contribution we present an application of metric rule generation in the domain of medical research. We consider intensive car unit patients developing a septic shockduring their stay at the hospital. To analyse the patient data, rule generation is embedded in a medical data mining cycle. For rule generation, we improve an architecture basedon a growing trapezoidal basis function network.

#index 466352
#* An Experimental Comparison of Supervised and Unsupervised Approaches to Text Summarization
#@ Tadashi Nomoto;Yuji Matsumoto
#t 2001
#c 18
#! The paper presents a direct comparison of supervised and unsupervised approaches to text summarization. As a representative supervised method, we use the C4.5 decision tree algorithm, extended with the Minimum Description Length Principle (MDL), and compare it against several unsupervised methods. It is found that a particular un-supervised method based on an extension of the K-means clustering algorithm, performs equal to and in some cases superior to the decision tree based method.

#index 466353
#* The EQ Framework for Learning Equivalence Classes of Bayesian Networks
#@ Paul Munteanu;Mohamed Bendou
#t 2001
#c 18
#! This paper proposes a theoretical and an algorithmic framework for the analysis and the design of efficient learning algorithms which explore the space of equivalence classes of Bayesian network structures.This framework is composed of a generic learning model which uses essential graphs and more general partially directed graphs i order to represent the equivalence classes evaluated during search, operational characterizations of these graphs, processing procedures and formulas for directly calculating their score.The experimental results of the algorithms designed within this framework show that the space of equivalence classes may be explored efficiently and with better results than the classical search in the space of Bayesian network structures.

#index 466473
#* Comparisons of Classification Methods for Screening Potential Compounds
#@ Aijun An;Yuanyuan Wang
#t 2001
#c 18

#index 466474
#* Classification with Degree of Membership: A Fuzzy Approach
#@ Wai-Ho Au;Keith C. C. Chan
#t 2001
#c 18
#! algorithms adopt either a decision tree based approach or an approach that requires users to provide some user-specifiedthresholds to guide the search for interesting rules. In this paper, we propose a new approach based on the use of an objective interestingness measure todistinguish interesting rules from uninteresting ones. Using linguistic terms to represent the revealed regularities and exceptions, this approach s especially useful when the discovered rules are presented to human experts for examination because of the affinity with thehuman knowledge representation. The use of fuzzy technique allows the predict on of attribute values to be associated with degree of membership. Our approach s, therefore, able to deal with the cases that an object can belong to more than one class. For example, a person can suffer from cold and fever to certain extent at the same time. Furthermore, our approach is more resilient to noise and missing data values because of the use of fuzzy technique. To evaluate the performance of our approach, we tested it using several real-life databases. The experimental results show that it can be very effective at data mining tasks. In fact, when compared to popular data mining algorithms, our approach can be better ableto uncover useful rules hidden in databases.

#index 466475
#* Using Boosting to Simplify Classification Models
#@ Virginia Wheway
#t 2001
#c 18
#! Ensemble classification techniques such as bagging ,boosting and arcingalgorithms have been shown to lead to reduced classification error on unseencases and seem immune t the problem of overfitting. Several explanations forthe reduction in generalisation error have been presented, with authors morerecently defining and applying diagnostics such as edge and margin [4,9,10 ].These measures pr vide insight into the behaviour of ensemble classifiers but can they be exploited further?

#index 466476
#* Mining Mutually Dependent Patterns
#@ Sheng Ma;Joseph L. Hellerstein
#t 2001
#c 18
#! In some domains, such as isolating problems in computer net-worksand discovering stock market irregularities, there is more interest inpatterns consisting of infrequent, but highly correlated items rather thanpatterns that occur frequently (as defined by minsup, the minimum supportlevel). Herein, we describe the m-pattern, a new pattern that is definedin terms of minp, the minimum probability of mutual dependence of itemsin the pattern. We show that all infrequent m-pattern can be discovered byan efficient algorithm that makes use of: (a) a linear algorithm to qualifyan m-pattern; (b) an effective technique for candidate pruning based on anecessary condition for the presence of an m-pattern; and (c) a level-wisesearch for m-pattern discovery (which is possible because m-patterns aredownward closed). Further, we consider frequent m-patterns, which aredefined in terms of both minp and minsup. Using synthetic data, we studythe scalability of our algorithm. Then, we apply our algorithm to data froma production computer network both to show the m-patterns present andto contrast with frequent patterns. We show that when minp_0, our algorithmis equivalent to finding frequent patterns. However, with a larger minp, our algorithm yields a modest number of highly correlated items, which makes it possible to mine for infrequent but highly correlated item-sets. To date, many actionable m-patterns have been discovered in production systems.

#index 466477
#* Mining Coverage-Based Fuzzy Rules by Evolutional Computation
#@ Tzung-Pei Hong;Yeong-Chyi Lee
#t 2001
#c 18
#! In this paper, we propose a novel mining approach based on the genetic process and an evaluation mechanism to automatically construct an effective fuzzy rule base. The proposed approach consists of three phases: fuzzy-rule generating, fuzzy-rule encoding and fuzzy-ruleevolution. In the fuzzy-rule generating phase, a number of fuzzy rules are randomly generated. In the fuzzy-rule encoding phase, all the rules generated are translated into fixed-length bit strings to form an initial population. In the fuzzy-rule evolution phase, genetic operations andcredit assignment are applied at the rule level. The proposed mining approach chooses good individuals in the population for mating, gradually creating better offspring fuzzy rules. A concise and compact fuzzy rule base is thus constructed effectively without human expertintervention.

#index 466478
#* An Immune Neural Network Used for Classification
#@ Lei Wang;Licheng Jiao
#t 2001
#c 18
#! Based on analyzing the immune phenomena in nature and utilizing performances of ANN, a novel network model, i.e., an immune neural network (INN), is proposed which integrates the immune mechanism and the function of neural information processing. The learning algorithm of INN is mainly about the selection of an excitation function and an adaptive algorithm of the network.

#index 466479
#* SSDT: A Scalable Subspace-Splitting Classifier for Biased Data
#@ Haixun Wang;Philip S. Yu
#t 2001
#c 18
#! Decision trees are one of the most extensively used data mining models. Recently, a number of efficient, scalable algorithms for constructing decision trees on large disk-resident dataset have been introduced. In this paper, we study the problem of learning scalable decision trees from datasets with biased class distribution. Our objective is to build decision trees that are ore concise and oreinterpretable while maintaining the scalability of the model.To achieve this, our approach searches for subspace clusters of data cases of the biased class to enable multivariate splittings based on weighted distances to such clusters. In orderto build concise and interpretable models, other approaches including multivariate decision trees and association rules, often introduce scalability and performance issues. The SSDT algorithm we present achieves the objective without loss in efficiency, scalability, and accuracy.

#index 466480
#* A Comparison of Stacking with Meta Decision Trees to Bagging, Boosting, and Stacking with other Methods
#@ Bernard Zenko;Ljupco Todorovski;Saso Dzeroski
#t 2001
#c 18
#! Abstract. Meta decision trees (MTs) are a method for combining multiple classifiers. We present an integration of the algorithm MLC4.5 for learning MTs into the Weka data mining suite. We compare classifier ensembles combined with MDTs to bagged and boosted decision trees, and to classifier ensembles combined with other methods: voting and stacking with three different meta-level classifiers (ordinary decision trees, naive Bayes, and multi-response linear regression -MLR).

#index 466481
#* Clustering Validity Assessment: Finding the Optimal Partitioning of a Data Set
#@ Maria Halkidi;Michalis Vazirgiannis
#t 2001
#c 18
#! Clustering s a mostly unsupervised procedure and the majority of the clustering algorithms depend on certain assumptions in order to define the subgroups present in a data set. As a consequence, in most applications the resulting clustering scheme requires some sort ofevaluation as regards its validity. In this paper we present a clustering validity procedure,which evaluates the results of clustering algorithms on data sets. We define a validity index, S_Dbw, based on well-defined clustering criteria enabling the selection of the optimal input parameters' values for a clustering algorithm that result in the best partitioning of a data set.We evaluate the reliability of our index both theoretically and experimentally, considering three representative clustering algorithms ran on synthetic and real data sets. Also, we carried out an evaluation study to compare S_Dbw performance with other known validity indices.Our approach performed favorably in all cases, even in those that other indices failed to indicate the correct partitions in a data set.

#index 466482
#* Incremental Learning with Support Vector Machines
#@ Stefan Rüping
#t 2001
#c 18
#! Support Vector Machines (SVMs) have become a popular tool for machine learning with large amounts of high dimensional data. In this paper an approach for incremental learning with Support Vector Machines is presented, that improves the existing approach of [3 ]. Also, some insight into the interpretability of support vectors s given.

#index 466483
#* CMAR: Accurate and Efficient Classification Based on Multiple Class-Association Rules
#@ Wenmin Li;Jiawei Han;Jian Pei
#t 2001
#c 18
#! Previous studies propose that associative classification has high classification accuracy and strong flexibility at handling unstructured data. However, it still suffers from the huge set of mined rules and sometimes biased classification or overfitting since the classificationis based on only single high-confidence rule. In this study, we propose new associative classification method, CMAR, i.e., Classification based on Multiple Association Rules. The method extends an efficient frequent pattern mining method, FP-growth ,constructs classdistribution-associated FP-tree, and mines large database efficiently. Moreover, it applies CR-tree structure to store and retrieve mined association rulesefficiently, and prunes rules effectively based on confidence, correlation and database coverage. The classification is performed based on weighted X2 analysis using multiple strong association rules. Our extensive experiments on 26 databases from UCI machine learning database repository show that CMAR is consistent, highly effective at classificationof various kinds of databases and has better average classificationaccuracy in comparison with CBA and C4.5.Moreover,our performancestudy shows that the method is highly efficient and scalable in comparison with other reported associative classification methods.

#index 466484
#* Evolutionary Structure Learning Algorithm for Bayesian Network and Penalized Mutual Information Metric
#@ Gang Li;Fu Tong;Honghua Dai
#t 2001
#c 18
#! This paper formulates the problem of learning Bayesian network structures from data as determining the structure that best approximates the probability distribution indicated by the data. A new metric, Penalized Mutual Information metric, is proposed, and a evolutionary algorithm is designed to search for the best structure among alternatives. The experimental results show that this approach is reliable and promising.

#index 466485
#* Mining the Smallest Association Rule Set for Predictions
#@ Jiuyong Li;Hong Shen;Rodney W. Topor
#t 2001
#c 18
#! Mining transaction databases for association rules usually generates a large number of rules, most of which are unnecessary when used for subsequent prediction. In this paper we define a rule set for a given transaction database that is much smaller than the association rule set but makes the same predictions as the association rule set by the confidence priority. We call this subset the informative rule set. The informative rule set is not constrained to particular target items; and it is smaller than the non-redundant association rule set. We present an algorithm to directly generate the informative rule set, i.e., without generating all frequentitemsets first, and that accesses the database less often than other unconstrained direct methods. We show experimentally that the informative rule set is much smaller than boththe association rule set and the non-redundant association rule set, and that it can be generated more efficiently.

#index 466486
#* RPCL-Based Local PCA Algorithm
#@ Zhiyong Liu;Lei Xu
#t 2001
#c 18
#! Mining local structure is important in data analysis.Gaussian mixture is able to describe local structurethrough the covariance matrices, but when used on high dimensional data, fitly specifying such a large number of d(d + 1)=2 free elements in each covariance matrix is difficult. In this paper, by constraining the covariance matrixin decomposed orthonormal form, we propos a Local PCAalgorithm to tackle this problem in help of RPCL competitivelearning, which can automatically determine the number of local structure.

#index 466487
#* A Tight Upper Bound on the Number of Candidate Patterns
#@ Floris Geerts;Bart Goethals;Jan Van den Bussche
#t 2001
#c 18
#! In the context of mining for frequent patterns using the standard level wise algorithm, the following question arises: given the current level and the current set of frequentpatterns, what is the maximal number of candidate patterns that can be generated on the next level? We answer this question by providing a tight upper bound, derived from a combinatorial result from the sixties by Kruskal andKatona. Our result is useful to educe the number of databasescans.

#index 466488
#* Fuzzy Data Mining: Effect of Fuzzy Discretization
#@ Hisao Ishibuchi;Takashi Yamamoto;Tomoharu Nakashima
#t 2001
#c 18
#! When we generate association rules, continuous attributes have to be discretized into intervals while our knowledge representation is not always based on such discretiztion.Forexample, we usually use some linguistic terms (e.g., young, middle age, and old) for dividing our ages into somefuzzy categories.In this paper, we describe the extraction of linguistic association rules and examine the performanceof extracted rules.First we modify the definitions of the two basic measures (i.e., confidence and support) ofassociation rules for extracting linguistic association rules. The main difference between standard and linguistics association rules is the discretiztion of continuous attributes. We divide the domain interval of each attribute into some Fuzzy discretiztion with standard on-fuzzy discretiztion Through computer simulations on a pattern classificationproblem with many continuous attributes.The classification performance of extracted rules on unseen test patterns is examined under various conditions.Simulation results show that linguistic association rules with rule weights have highgeneralization ability even when the domain of each continuous attribute is homogeneously partitioned.

#index 466489
#* Anchor Text Mining for Translation of Web Queries
#@ Wen-Hsiang Lu;Lee-Feng Chien;Hsi-Jian Lee
#t 2001
#c 18
#! This paper presents an approach to automatically extracting translations of Web query terms through mining of Web anchor texts and link structures. One of the existing difficulties in cross-language information retrieval (CLIR)and Web search is the lack of the appropriate translations of new terminology and proper names. Such a difficult problem can be effectively alleviated by our proposed approach, and the resource of anchor texts in the Web is proven a valuable corpus for this kind of term translation.

#index 466490
#* H-Mine: Hyper-Structure Mining of Frequent Patterns in Large Databases
#@ Jian Pei;Jiawei Han;Hongjun Lu;Shojiro Nishio;Shiwei Tang;Dongqing Yang
#t 2001
#c 18
#! Methods for efficient mining of frequent patterns have been studied extensively by many researchers. However, the previously proposed methods still encounter someperformance bottlenecks when mining databases with different data characteristics, such as dense vs. sparse, long vs. short patterns, memory-based vs. disk-based, etc.In this study, we propose a simple and novel hyper-linkeddata structure, H-struct , and a new mining algorithm, H-mine ,which takes advantage of this data structure anddynamically adjusts links in the mining process. A distinct feature of this method is that it has very limitedand precisely predictable space overhead and runs really fast in memory-based setting. Moreover, it ca be scaled up to very large databases by database partitioning, and whenthe data set becomes dense,(conditional)FP-trees can be constructed dynamically as part of the mining process. Our study shows that H-mine has high performance in various kinds of data, outperforms the previously developedalgorithms in different settings, and is highly scalable in mining large databases. This study also proposes a new datamining methodology, space-preserving mining ,which mayhave strong impact in the future development of efficient and scalable data mining methods.

#index 466491
#* Concise Representation of Frequent Patterns Based on Disjunction-Free Generators
#@ Marzena Kryszkiewicz
#t 2001
#c 18
#! Many data mining problems require the discover of frequent patterns in order to be solved.Frequent Itemsets are useful in the discover of association rules, episode rules, sequential patterns and clusters. The number of frequent itemsets is usually huge. Therefore, it is important to work out concise representations of frequent itemsets. In the paper, we describe three basic loassless representations of frequent patters in a uniform wayand offer a new lossless representation of frequent patterns based on disjunction-free generators. The new representation is more concisethan two of the basic representations and more efficiently computablethan the third representation. We propose an algorithm for the determining the new representation.

#index 466492
#* Closing the Loop: Heuristics for Autonomous Discovery
#@ Gary Livingston;John M. Rosenberg;Bruce G. Buchanan
#t 2001
#c 18

#index 466493
#* Maintenance of Sequential Patterns for Record Deletion
#@ Ching-Yao Wang;Tzung-Pei Hong;Shian-Shyong Tseng
#t 2001
#c 18
#! In the past, we proposed an incremental mining algorithm for maintenance of sequential patterns based on the concept of pre-large sequences as new records were inserted. In this paper, we attempt to apply the concept of pre-large sequences to maintain sequentialpatterns as records are deleted. Pre-large sequences are defined by a lower support threshold and an upper support threshold. They act as buffers to avoid the movements of sequential patterns directly from large to small and vice-versa. Our proposed algorithm does notrequire rescanning original databases until the accumulative amount of deleted customer sequences exceeds a safety bound, which depends on database size. As databases grow larger, the numbers of deleted customer sequences allowed before database rescanningis required also grow. The proposed approach is thus efficient for a large database.

#index 466494
#* Significance Tests for Patterns in Continuous Data
#@ Richard J. Bolton;David J. Hand
#t 2001
#c 18
#! In this paper we consider the question of uncertainty of detected patterns in data mining. In particular, we develop statistical tests for patterns found in continuous data, indicating the significance of these patterns in terms of the probability that they have occurred by chance. We examine the performance of these tests on patterns detected in several large data sets, including a data set describing the locations of earthquakes in California and another describing flow cytometry measurements on phytoplankton.

#index 466495
#* An Efficient Fuzzy C-Means Clustering Algorithm
#@ Ming-Chuan Hung;Don-Lin Yang
#t 2001
#c 18
#! The Fuzzy C-Means (FCM) algorithm is commonly used for clustering.The performance of the FCM algorithm depends on the selection of the initial cluster center and/or the initial membership value.If a good initial cluster center that is close to the actual final clustercenter can be found, the FCM algorithm will converge very quickly and the processing time can be drastically.In this paper, we propose a novel algorithm for efficient clustering.This algorithm is a modified FCM called the psFCM algorithm, which significantly reduces the computation timerequired to partition a dataset into desired cluster.We find the actual cluster center by using a simplified set of the original complete dataset.It refines the initial value of the FCM algorithm to speed up the convergence time.Our Experiments show that the proposed psFCM algorithm isAlgorithm.We also demonstrate that the quality of the Proposed psFCM algorithm is the same as the FCM algorithm.

#index 466496
#* Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints
#@ Sherri K. Harms;Jitender S. Deogun;Jamil Saquer;Tsegaye Tadesse
#t 2001
#c 18
#! Discovering association rules from time-series data is an important data mining problem. The number of potential rules grows quickly as the number of items in the antecedent grows. It is therefore difficult for an expert to analyze the rules and identify the useful. An approach for generating representative association rules for transactions that uses only a subset of the set of frequent itemsets called frequent closed itemsets was presented in [6 ]. We employ formalconcept analysis to develop the notion of frequent closed episodes. The concept of representative association rules is formalized in the context of event sequences. Applying constraints to target highly significant rules further reduces the number of rules. Our approach results in a significant reduction of the number of rules generated, while maintaining the minimum set of relevant association rules and retaining the ability to generate the entire set of association rules with respect to the given constraints. We show how our method can be used to discover associations in a drought risk management decision support system and use multiple climatology datasets related to automated weather stations1

#index 466497
#* Ad Hoc Association Rule Mining as SQL3 Queries
#@ Hasan M. Jamil
#t 2001
#c 18
#! Although there have been several encouraging attempts at developing methods for data mining using SQL, simplicity and efficiency still remain significant impediments for furtherdevelopment. In this paper, we propose a significantly new approach and show that any object relational database can be mined for association rules without any restructuring orpreprocessing using only basic SQL3 constructs and functions, and hence no additional machineries are necessary. In particular, we show that the cost of computing associationrules for a given database does not depend on support and confidence thresholds. More precisely, the set of large items can be computed using one simple join query and anaggregation once the set of all possible meets (least fix point) of item set patterns in the input table is known. The principal focus of this paper is to demonstrate that several SQL3expressions exists for the mining of association rules.

#index 466498
#* Incremental Learning of Bayesian Networks with Hidden Variables
#@ Fengzhan Tian;Hongwei Zhong;Yuchang Lu;Chunyi Shi
#t 2001
#c 18
#! In this paper, an incremental method for learning Bayesian networks based on evolutionary computing, IEMA, is put forward. IEMA introduces the evolutionary algorithm and EM algorithm into the process of incremental learning, can not only avoid getting into local maxima, but also incrementally learn Bayesian networks with high accuracy in presence of missing values andhidden variables. In addition, we improved the incremental learning process by Friedman et al. The experimental results verified the validity of IEMA. In terms of storage cost, IEMA is comparable with the incremental learning method of Friedman et al, while it is ore accurate.

#index 466499
#* Bayesian Data Mining on the Web with B-Course
#@ Petri Myllymäki;Tomi Silander;Henry Tirri;Pekka Uronen
#t 2001
#c 18
#! B-Course is a free 1 web-based Bayesian data mining service. This service allows the users to analyze their own data for multivariate probabilistic dependencies represented as Bayesian network models. In addition to this, B-Course also offers facilities for inferring certain type of causal dependencies from the data. The software is especially suitable for educational purposes as the tutorial style user-friendly interface intertwines the steps in the data analysiswith support material that gives an informal introduction to the Bayesian approach adopted. Nevertheless, although the analysis methods, modeling assumptions and restrictionsare totally transparent to the user, this transparency is not achieved at the expense of analysis power: with the restrictions stated in the support material, B-Course is a powerful analysis tool exploiting several theoretically elaborate results developed recently in the fields of Bayesian and causal modeling.

#index 466500
#* FlExPat: Flexible Extraction of Sequential Patterns
#@ Pierre-Yves Rolland
#t 2001
#c 18
#! This paper addresses sequential data mining, a sub-area of data mining where the data to be analyzed is organized in sequences. In many problem domains a natural ordering exists over data. Examples of sequential databases (SDBs) include: (a)collections of temporal data sequences, such as chronologicalseries of daily stock indices or multimedia data (sound, music, video..); and (b) macromolecule banks, where aminoacid or proteic sequences are represented as strings.In a SDB it is often valuable to detect regularities through one or several sequences. In particular, finding exact or approximate repetitions of segments ca be utilized directly (e.g.for determining the biochemical activity of a protein region) or indirectly, e.g. for prediction in finance. To this end, we present concepts and an algorithm for automatically extracting sequential patterns from a sequential database. Such a patter is defined as a group of significantly similar segments from one or several sequences. Appropriate functions for measuringsimilarity between sequence segments are proposed, generalizing the edit distance framework. There is a trade off here between flexibility, particularly in sequence data representation and in associated similarity metrics, and computational efficiency. Wedesigned the FlExPat algorithm to satisfactorily cope with this trade-off. FlExPat's complexity is in practice lesser than quadratic in the total length of the SDB analyzed, while allowinghigh flexibility. Some experimental results obtained with FlExPat on music data are presented and commented.

#index 466501
#* Hierarchical Text Classification and Evaluation
#@ Aixin Sun;Ee-Peng Lim
#t 2001
#c 18
#! Hierarchical Classification refers to assigning of one or more suitable categories from a hierarchical category space to a document. While previous work in hierarchical classification focused on virtual category trees where documents are assigned only to the leaf categories, we propose atop-down level-based classification method that can classify documents to both leaf and internal categories. As the standard performance measures assume independence between categories, they have not considered the documents incorrectly classified into categories that are similar or not far from the correct ones in the category tree. We therefore propose the Category-Similarity Measures and Distance-Based Measures to consider the degree of misclassification in measuring the classification performance. An experiment has been carried out to measure the performance four proposed hierarchical classification method. The results showed that our method performs well for Reuters text collection when enough training documents are given andthe new measures have indeed considered the contributions of misclassified documents.

#index 466502
#* Knowledge Discovery from Diagrammatically Represented Data
#@ Michael Anderson
#t 2001
#c 18
#! Knowledge discover from diagrammatic data can be facilitated by a language that permits queries on such data.Such a language (diagrammatic SQL) is being developed to expedite the development of an autonomous artificially intelligent agent with a capacity to deal with diagrammatic information.This language is described and examples of how it can be used to facilitatediagrammatic data mining are detaled

#index 466503
#* Statistical Considerations in Learning from Data
#@ Henry E. Kyburg, Jr.
#t 2001
#c 18
#! In this paper we focus on statistics. Classical statistics and Bayesian statistics are both employed in data mining. Both have advantages but both also have severe limitations in this context. We point out some of these limitations as well as s me of the advantages. The fact that we may need to take account of evidence both internal and external to the data set presents a difficulty for classical statistics. The need to incorporate an objective measure of reliability creates a difficulty for Bayesian statistics.We outline an approach to uncertainty that promises to capture the best of both worlds by incorporating both background knowledge and objectivity.

#index 466504
#* Dependency Derivation in Industrial Process Data
#@ Daniel Gillblad;Anders Holst
#t 2001
#c 18
#! In many industrial processes, finding dependencies and the creation of dependency graphs can increase the understanding of the system significantly. This knowledge can then be used for further optimization and variable selection. Most of the measured attributes in these cases come in the form of time series. There are several ways of determining correlation between series, most of them suffering from specific problems when applied to real-world data. Here, awell performing measure based on the mutual information rate is derived and discussed with results from both synthetic and real data.

#index 466505
#* alpha-Surface and Its Application to Mining Protein Data
#@ Xiong Wang
#t 2001
#c 18
#! Given a finite set of points in three dimensional Euclidean space R3, the subset that forms its surface could bedifferent when observed in different levels of details. In thispaper, we introduce a notion called a-surface. We presentan algorithm that extracts the a-surface from a finite set ofpoints in R3. We apply the algorithm to extracting the a-surfaces of proteins and discover patterns from these surface structures, using the pattern discovery algorithm wedeveloped earlier. We then use these patterns to classify theproteins. Experimental results show the good performanceof the proposed approach.

#index 466506
#* An Online Algorithm for Segmenting Time Series
#@ Eamonn J. Keogh;Selina Chu;David Hart;Michael J. Pazzani
#t 2001
#c 18
#! In recent years, there has been an explosion of interest in mining time series databases. As with most computer science problems, representation of the data is the key to efficient and effective solutions. One of the most commonly used representations is piecewise linear approximation. This representation has been used by various researchers to support clustering, classification, indexing and association rule mining of t me series data. A variety of algorithms have been proposed to obtain this representation, with several algorithms having been independently rediscovered several times. In this paper, we undertake the first extensive review and empirical comparison of all proposed techniques. We show that allthese algorithms have fatal flaws from a data mining perspective. We introduce a novel algorithm that we empirically show to be super or to all others n the literature.

#index 466507
#* Distance Measures for Effective Clustering of ARIMA Time-Series
#@ Konstantinos Kalpakis;Dhiral Gada;Vasundhara Puttagunta
#t 2001
#c 18
#! Many environmental and socioeconomic time-series data can be adequately modeled using Auto-RegressiveIntegrated Moving Average (ARIMA) models. We call such Time-series ARIMA time-series. We consider the problem of clustering ARIMA time-series. We propose the use of the Linear Predictive Coding (LPC) cepstrum of time-series for clustering ARIMA time-series, by using the Euclideandistance between the LPC cepstra of two time-series as their dissimilarity measure. We demonstrate that LPC cepstral coefficients have the desire features for accurate clustering and efficient indexing of ARIMA time-series. For example, few LPC cepstral coefficients are sufficient in order todiscriminate between time-series that are modeled by different ARIMA models. In fact this approach requires fewer coefficients than traditional approaches, such as DFT and DWT. The proposed distance measure can be use for measuring the similarity between different ARIMA models as well.We cluster ARIMA time-series using the Partition Around Medoids method with various similarity measures. We present experimental results demonstrating that using the proposed measure we achieve significantly betterclusterings of ARIMA time-series data as compared to clusterings obtained by using other traditional similaritymeasures, such as DFT, DWT, PCA, etc. Experiments wereperformed both on simulated as well as real data.

#index 466508
#* An Efficient Data Mining Technique for Discovering Interesting Sequential Patterns
#@ Show-Jane Yen;Yue-Shi Lee
#t 2001
#c 18
#! Mining sequential patterns is to discover sequentialpurchasing behaviors of most customers from a largeamount of customer transactions. In this paper, a datamining language is presented. From the data mininglanguage, use s can specify the interested items and thecriteria of the sequential patterns to be discovered. Also,an efficient data mining technique is proposed to ext actthe sequential patterns according to the uses` requests.

#index 466509
#* Inexact Field Learning: An Approach to Induce High Quality Rules from Low Quality Data
#@ Honghua Dai;Xiaoshu Hang;Gang Li
#t 2001
#c 18
#! To avoid low quality problem caused by low quality data, this paper introduces an inexactfield learning approach which derives rules by working on the fields of attributes with respect to classes, rather than on individual point values of attributes. The experimental results show that field learning achieved a higher prediction accuracy rate on new unseen test cases which is particularly true when the learning is performed on large low qualitydata.

#index 466510
#* Incremental Support Vector Machine Construction
#@ Carlotta Domeniconi;Dimitrios Gunopulos
#t 2001
#c 18
#! SVMs suffer from the problem of large memory requirement and CPU time when trained in batch mode on large data sets. We overcome these limitations, and at the same time make SVMs suitable for learning with data streams, by constructing incremental learning algorithms.We first introduce and compare different incremental learning techniques, and show that they are capable of producing performance results similar to the batch algorithm, and in some cases superior condensation properties. We then consider the problem of training SVMs using stream data. Our objective is to maintain an updated representation of recent batches of data. We apply incremental schemes to the problem and show that their accuracy is comparable to the batch algorithm.

#index 466511
#* Learning Automatic Acquisition of Subcategorization Frames Using Bayesian Inference and Support Vector Machines
#@ Manolis Maragoudakis;K. Kermanidis;Nikos Fakotakis;George K. Kokkinakis
#t 2001
#c 18
#! Learning Bayesian Belief Network (BBN) from corpora and Support Vector Machines (SVM) have been applied to the automatic acquisition of verb subcategorization frames for Modern Greek.We are incorporating minimal linguistic resources, i.e. basic morphological tagging and phrase chunking, to demonstrate that verb subcategorization, which is of great significance for developing robust natural language human computer interaction systems, could be achieved using large corpora, without having any general-purpose syntactic parser at all.

#index 466512
#* A Clustering Method for Very Large Mixed Data Sets
#@ Guillermo Sánchez-Díaz;José Ruiz-Shulcloper
#t 2001
#c 18
#! In the developed countries, especially over the last decade, there has been an explosive growth in the capability to generate, collect and use very large data sets. The objects of these data sets could be simultaneously described by quantitative and qualitative attributes. At present, algorithms able to process either very large data sets (in metric spaces) or mixed(qualitative and quantitative) incomplete data (missing value) sets have been developed, but not for very large mixed incomplete data sets. In this paper we introduce a new clustering method named GLC+to process very large mixed incomplete data sets in order to obtain apartition in connected sets.

#index 466513
#* A Fast Algorithm to Cluster High Dimensional Basket Data
#@ Carlos Ordonez;Edward Omiecinski;Norberto Ezquerra
#t 2001
#c 18
#! Clustering is a data mining problem that has received significant attention by the database community. Data set size, dimensionality and sparsity have been identified as aspectsthat make clustering more difficult. This work introduces a fast algorithm to cluster large binary data sets where data points have high dimensionality and most o their coordinates are zero. This is the case with basket data transactions containing items, that can be represented as sparse binary vectors with very high dimensionality. An experimental section shows performance, advantages and limitations of the proposed approach.

#index 466514
#* Preprocessing Opportunities in Optimal Numerical Range Partitioning
#@ Tapio Elomaa;Juho Rousu
#t 2001
#c 18
#! We show that only the segment borders have to be taken into account as cut point candidates in searching for theoptimal multisplit of a numerical value range with respect to convex attribute evaluation functions. Segment borders can be found efficiently in a linear-time preprocessing step. With Training Set Error, which is not strictly convex, the data can be preprocessed into an even smaller number of cut point candidates, called alternations, when striving for the optimal partition. We show that no segment borders(resp. alternations) can be overlooked with strictly convex functions (resp. Training Set Error) without risking to lose optimality. Our experiments show that while in real-world domainssignificant reduction in the number of cut point candidates can be obtained for Training Set Error, the number of segment borders is usually not much lower than that of boundary points.

#index 466638
#* On Effective Conceptual Indexing and Similarity Search in Text Data
#@ Charu C. Aggarwal;Philip S. Yu
#t 2001
#c 18
#! Similarity search in text has proven to be an interesting problem from the qualitative perspective because of inherent redundancies and ambiguities in textual descriptions. The methods used in search engines in order to retrieve documents most similar to user-defined sets of keywords are not applicable to targets which are medium to large size documents, because of even greater noise effects stemming from the presence of a large number of words unrelated to the overall topic in the document. The inverted representation is the dominant method for indexing text, but it is not as suitable for document-to-document similarity search, as for short user-queries. One way of improving the quality of similarity search is Latent Semantic Indexing (LSI), which maps the documents from the original set of words to a concept space. U fortunately, LSI maps the data into a domain in which it is not possible to provide effectiveindexing techniques. In this paper, we investigate new ways of providing conceptual search among documents bycreating a representation in terms of conceptual word-chains. This technique also allows effective indexing techniques so that similarity queries ca be performed on large collectionsof documents by accessing a small amount of data. We demonstrate that our scheme outperforms standard textual similarity search o the inverted representation both in terms of quality a d search efficiency.

#index 466639
#* Using Rule Sets to Maximize ROC Performance
#@ Tom Fawcett
#t 2001
#c 18
#! Rules are commonly use for classification because they are modular, intelligible and easy to learn. Existing work in classification rule learning assumes the goal is to produce categorical classifications to maximize classification accuracy. Recent work in machine learning has pointed out the limitations of classification accuracy: when class distributions are skewed, or error costs are unequal, an accuracy maximizing rule set can perform poorly. Amore flexible use of a rule set is to produce instance scores indicating the likelihood that an instance belongs to a given class. With such an ability, we can apply rulesets effectively whendistributions are skewed or error costs are unequal. This paper empirically investigates different strategies for evaluating rule sets when the goal is to maximize the scoring (ROC)performance.

#index 466640
#* An Agglomerative Hierarchical Clustering Using Partial Maximum Array and Incremental Similarity Computation Method
#@ Sung Young Jung;Taek-Soo Kim
#t 2001
#c 18
#! As the tractable amount of data is growing in computer science area, fast clustering algorithm is being required because traditional clustering algorithms are not so feasible for very large and high dimensional data. Many studies have been reported for clustering of large database, but most of them circumvent this problem by using the approximation method to result in thedeterioration of accuracy. In this paper, we propose a new clustering algorithm by means of partial maximum array, which can realize the agglomerative hierarchical clustering with the same accuracy to the brute-force algorithm and has O(N 2 ) time complexity. And we alsopresent the incremental method of similarity computation which substitutes the scalar calculation for the time-consuming calculation of vector similarity. The experimental results show that clustering becomes significantly fast for large and high dimensional data.

#index 466641
#* Fast Parallel Association Rule Mining without Candidacy Generation
#@ Osmar R. Zaïane;Mohammad El-Hajj;Paul Lu
#t 2001
#c 18
#! In this paper we introduce a new parallel algorithm MLFPT (Multiple Local Frequent Pattern Tree) [11] for parallel mining of frequent patterns, based on FP-growth mining, that uses only two full I/O scans of the database, eliminating the need for generating the candidate items and distributing the work fairly among processors. We have devised partitioning strategies at different stages of the mining process to achieve near optimal balancing between processors.We have successfully tested our algorithm on datasets larger than 50 million transactions.

#index 466642
#* Applications of Data Mining in Hydrology
#@ Xu Liang;Yao Liang
#t 2001
#c 18
#! Long-term range streamflow forecast plays an invaluable role in water resources planning andmanagement. In this study, the potential applicability and limitations of the time series forecasting approach using neural network with the multiresolution learning paradigm (NNMLP) are investigated. The predictedlongterm range streamflows using the NNMLP are compared with the observations. The results show that the time series forecasting approach of NNMLP has good predicting skill. The NNMLP requires only historicalstreamflow information. The time series forecasting approach of NNMLP has great potential for being used alone in regions with limited available information, and for being combined with other approaches to improve long-term range streamflow forecasts.

#index 466643
#* Neural Analysis of Mobile Radio Access Network
#@ Kimmo Raivio;Olli Simula;Jaana Laiho
#t 2001
#c 18
#! The Self-Organizing Map (SOM) is an efficient tool for visualization and clustering of multidimensional data. It transforms the input vectors on two-dimensional grid of prototype vectors and orders them. The ordered prototype vectors are easier to visualize and explore than the original data. Mobile networks produce a huge amount of spatio-temporaldata. The data consists of parameters of base stations (BS)and quality information of calls. There are two alternatives in starting the data analysis. We can build either a general one-cell-model trained using state vectors from all cells, or a model of the network using state vectors with parameters from all mobile cells. In both methods,further analysis is needed to understand the reasons for various operational states of the entire network.

#index 466644
#* Frequent Subgraph Discovery
#@ Michihiro Kuramochi;George Karypis
#t 2001
#c 18
#! As data mining techniques are being increasingly applied to non-traditional domains, existing approaches for finding frequent itemsets cannot be used as they cannot model the requirement of these domains. An alternate way of modeling the objects in these data sets is to use graphs. Within that model, the problem of finding frequent patterns becomes that of discovering subgraphs that occur frequently over the entire set of graphs. In this paper we present a computationally efficient algorithm for finding all frequent subgraphs in large graph databases. We evaluated the performance of the algorithm by experiments with synthetic datasets as well as a chemical compound dataset. The empirical results show that our algorithm scales linearly with the number of input transactions and it is able to discover frequent subgraphs from a set of graph transactions reasonably fast, even though we have to deal with computationally hard problems such as canonical labeling of graphs and subgraph isomorphism which are not necessary for traditional frequent itemset discovery.

#index 466645
#* Web Cartography for Online State Promotion: An Algorithm for Clustering Web Resources
#@ François Velin;Pascale Kuntz;Henri Briand
#t 2001
#c 18
#! This paper presents an approach of Web cartography to be used in the context of online site promotion.The overall objective is to provide users with handy maps offering information about candidate sites for the creation of hyperlinks that enable a large flow of targeted visitors.Two main types of data must be considered; texts and hyperlinks.We propose to exploit the latter to construct a relevant corpus on which semantic as well as graph analysis can be applied.The stress is put on theclustering of Web resources based on the link network,which makes it possible to highlight groups of strongly connected sites which are of the utmost interest for our application.To tackle the site graph partitioning problem, we turn to a promising iterative approach initially developedin the context of computer-aided design.It uses spectral decomposition of the Laplacian matrix to embed theconsidered graph in a geometric space where efficientmethods can be applied.An algorithm that was adaptedfrom an existing one implements the method.Experimentswere conductedon a real application case concerning the promotion of a site dealing with Cognac.We present the obtained map as well as leads to exploit it.

#index 466646
#* Interestingness PreProcessing
#@ Sigal Sahar
#t 2001
#c 18
#! As the size of databases increases, the number of rules mined from them also increases, often to a extent that overwhelms users. To address this problem, an important part of the KDD process is dedicated to determining which of these patterns is interesting. In this paper we define the Interestingness PreProcessing Step, and introduce a new framework for interestingness analysis. In asimilar fashion to data-preprocessing, this preprocessing should always be applied prior to interestingness processing. A strictrequirement, and the biggest challenge, in defining Interestingness PreProcessing techniques is that the preprocessing will not eliminate any potentially interesting patterns. That is, the preprocessing methods must be domain-,task-and user-independent. This property differentiates the preprocessing methods from existing interestingness criteria, and, since they can be applied automatically, makes them very useful. This generic nature also makes them rare: PreProcessing methods are very challenging to define.We also define in this paper the first two preprocessing techniques, and present the empirical results of applying them to six databases. The results indicate that Interestingness PreProcessing Step is very powerful: in most cases, an average of half the rules mined were eliminated by the application of the two Interestingness PreProcessing techniques. These results are Particularly significant since no user-interaction is required to achieve them.

#index 466647
#* Data Analysis and Mining in Ordered Information Tables
#@ Ying Sai;Y. Y. Yao;Ning Zhong
#t 2001
#c 18
#! Many real world problems deal with ordering objects instead of classifying objects, although majority of research in machine learning and data mining has been focused on the latter. For modeling ordering problems, we generalize the notion of information tables to ordered information tables by adding order relations on attribute values. The problem of mining ordering rules is formulated as findingassociation between orderings of attribute values and the overall ordering of objects. An ordering rules ay state that "if the value of an object x on an attribute a is ordered ahead of the value of another object y on the same attribute, then x is ordered ahead of y" For mining ordering rules, we first transform an ordered information table into a binaryinformation, and then apply any standard machine learning and data mining algorithms. As an illustration, we analyze in detail MacLean's universities ranking for the year 2000.

#index 466648
#* A Hypergraph Based Clustering Algorithm for Spatial Data Sets
#@ Jong-Sheng Cherng;Mei-Jung Lo
#t 2001
#c 18
#! Clustering is a discovery process in data mining an can be used to group together the objects of a database into meaningful subclasses which serve as the foundation for other data analysis techniques.In this paper, we focus on dealing with a set of spatial data. For the spatial data, the clustering problem becomes that of finding the densely populate regions of the space and thus grouping these regions into clusters such that the intracluster similarity is maximized and theintercluster similarity is minimized. We develop a novel hierarchical clustering algorithm that uses a hypergraph to represent a set of spatial data. This hypergraph is initially constructed from the Delaunay triangulation graph of the data set and can correctly capture the relationships among sets of data points. Two phases are developed for the proposed clustering algorithm to find the clusters in the data set.We evaluate our hierarchical clustering algorithm with some spatial data sets in which contain clusters of different sizes, shapes, densities, and noise. Experimental results on these data sets are very encouraging.

#index 466649
#* FARM: A Framework for Exploring Mining Spaces with Multiple Attributes
#@ Chang-Shing Perng;Haixun Wang;Sheng Ma;Joseph L. Hellerstein
#t 2001
#c 18
#! Mining for frequent itemsets typically involves a preprocessing step in which data with multiple attributes are grouped into transactions, and item are defined based on attribute values. We have observed that such fixed attribute mining can severely constrain the pattern that are discovered. Herein, we introduce mining paces, a new framework for mining multi-attribute data that include the discovery of transaction and item definition (with the exploitation of taxonomies and functional dependenciesif they are available).We prove that special downward closure properties (or anti-monotonic property) hold for mining paces, aresult that allows us to construct efficient algorithms for mining pattern without the constraint of fixed attribute mining. We apply our algorithm to real world data collected from a production computer network. The result how that by exploiting the special kind of downward closure in mining paces, execution times for mining can be reduced by a factor of three to four.

#index 466650
#* On Mining General Temporal Association Rules in a Publication Database
#@ Chang-Hung Lee;Cheng-Ri Lin;Ming-Syan Chen
#t 2001
#c 18
#! In this paper, we explore a new problem of mining general temporal association rules in publication databases. In essence, a publication database is a set of transactions where each transaction T is a set of items of which each item contains an individual exhibition period. The current model of association rule mining is not able to handle the publication database due to the following fundamental problems, i.e., (1) lack of consideration of the exhibition period of each individual item; (2) lack of an equitable support counting basis for each item. To remedy this, we propose an innovative algorithm Progressive-Partition-Miner (abbreviatedly as PPM) to discover general temporal association rules in a publication database. The basic idea ofPPM is to first partition the publication database in light of exhibition periods of items and then progressively accumulate the occurrence count of each candidate 2-itemset based on the intrinsic partitioning characteristics. Algorithm PPM is also designed to employ a filtering threshold in each partition to early prune out those cumulatively infrequent 2-itemsets. Explicitly, the execution time of PPM is, in orders of magnitude, smaller than those required by the schemes which are directly extended from existing methods.

#index 466651
#* Preparations for Semantics-Based XML Mining
#@ Jung-Won Lee;Kiho Lee;Won Kim
#t 2001
#c 18
#! XML allows users to define elements using arbitrary words and organize them in a nested structure. These features of XML offer both challenges and opportunities in information retrieval, document management, and data mining. In this paper,we propose a new methodology for preparing XML documents for quantitative determination of similarity between XML documents by taking account of XML semantics (i.e.,meanings of the elements andnested structures of XML documents).Accurate quantitative determination of similarity between XML documents provides an important basis for a variety of applications of XML document mining and processing. Experiments with XML documents show that ourmethodology provides a 50-100%improvement in determining similarity, over the traditional vector-space model that considers only term-frequency and 100% accuracy in identifying the category of each document from an on-line bookstore.

#index 466652
#* Mining Image Features for Efficient Query Processing
#@ Beitao Li;Wei-Cheng Lai;Edward Y. Chang;Kwang-Ting Cheng
#t 2001
#c 18
#! The number of feature required to depict an image can be very large. Using all features simultaneously to measure image similarity and to learn image query-concepts can suffer from the problem of dimensionality curse ,which degrades both search accuracy and search peed. Regarding search accuracy, the presence of irrelevant features with respect to a query can contaminate similarity measurement, and hence decrease both the recall and precision of thatquery. To remedy this problem, we present a mining method that learns online user query concept and identities important features quickly. Regarding search speed, the presence of a large number of feature can low down query-concept learning and indexing performance. We propose a divide-and-conquer method that divides the concept-learning task into G subtasks to achieve speedup. We notice that a task must be divided carefully, or search accuracy maysuffer. We thus propose a genetic-based mining algorithm to discover good feature groupings. Through analysis and mining result, we observe that organizing image features in a multi-resolution manner, and minimizing intra-group feature correlation, can peed up query-concept learning substantially while maintaining high search accuracy.

#index 466653
#* LPMiner: An Algorithm for Finding Frequent Itemsets Using Length-Decreasing Support Constraint
#@ Masakazu Seno;George Karypis
#t 2001
#c 18
#! Over the years, a variety of algorithms or finding frequentitemsets in very large transaction databases have been developed. The key feature in most to these algorithms is that they use a constant support constraint to control the inherently exponential complexity of the problem. In general, itemsets that contain only a few items will tend to be interesting if they have a high support, whereas long itemsets can still be interesting even if their support is relatively small. Ideally, we desire to have an algorithm that finds all the frequent itemsets whose support decreases as a function of their length. In this paper we present an algorithm called LPMiner, that finds all itemsets that satisfy a length-decreasing support constraint. Our experimental evaluation shows that LPMiner is up to two orders of magnitude faster than the FP-growth algorithm or finding itemsets at a constant support constraint, and that its runtime increasesgradually as the average length of the transactions (and the discovered itemsets) increases.

#index 466654
#* Evaluating Boosting Algorithms to Classify Rare Classes: Comparison and Improvements
#@ Mahesh V. Joshi;Vipin Kumar;Ramesh C. Agarwal
#t 2001
#c 18
#! Classification of rare vents has many important data mining applications. Boosting is a promising meta-techniquethat improves the classification performance of any weak classifier. So far, no systematic study has been conducted to evaluate how boosting performs for the task of mining rare classes. In this paper, we evaluate three existing categories of boosting algorithms from the single viewpoint of how they update the example weights in eachiteration, and discuss their possible effect on recall andprecision of the rare class. We propose enhanced algorithms in two of the categories, and justify their choice of weightupdating parameters theoretically. Using some specially designed synthetic datasets, we compare the capability of all the algorithms from the rare class perspective. Theresults support our qualitative analysis, and also indicate that our enhancements bring an extra capability for achieving better balance between recall and precision in mining rareclasses.

#index 466655
#* Measuring Real-Time Predictive Models
#@ Sam Steingold;Richard Wherry;Gregory Piatetsky-Shapiro
#t 2001
#c 18
#! In this paper we examine the problem of comparing real-time predictive models and propose a number of measures for selecting the best model, based on a combination of accuracy, timeliness, and cost. We apply the measure to the real-time attrition problem.

#index 466656
#* Mining Decision Trees from Data Streams in a Mobile Environment
#@ Hillol Kargupta;Byung-Hoon Park
#t 2001
#c 18
#! This paper presents a novel Fourier analysis-based technique toaggregate, communicate, and visualize decision trees in a mobile environment. Fourier representation of a decision tree has several useful properties that are particularly useful for mining continuous data streams from small mobile computing devices. This paper presents algorithms to compute the Fourier spectrum of a decision tree and the vice versa. It offers a framework to aggregate decision trees in their Fourier representations. It a so describes atouch-pad/ticker-based approach to visualize decision trees using their Fourier spectrum and an implementation for PDAs..

#index 466657
#* Text Clustering Based on Good Aggregations
#@ Andreas Hotho;Alexander Maedche;Steffen Staab
#t 2001
#c 18

#index 466658
#* Analyzing the Interestingness of Association Rules from the Temporal Dimension
#@ Bing Liu;Yiming Ma;Ronnie Lee
#t 2001
#c 18
#! Rule discovery is one of the central tasks of data mining. Existing research has produced many algorithms for the purpose. These algorithms, however, often generate too manyrules. In the past few years, rule interestingness techniques were proposed to help the user find interesting rules. These techniques typically employ the dataset as a whole to mine rules, and then filter and/or rank the discovered rules in various ways. In this paper, we argue that this is insufficient. These techniques are unable to answer a question that is of criticalimportance to the application of rules, i.e., can the rules be trusted? In practice, the users are always concerned with the question. They want to know whether the rules indeed represent some true and stable (or reliable)underlying relationships in the domain. If a rule is not stable, does it show any systematic pattern such as a trend? Before any rule can be used, these questions must be answered. This paper proposes a technique to use statistical methods to analyze rules from the temporal dimension to answer these questions. Experimental results show that the proposed technique is very effective.

#index 466659
#* Visualizing Association Mining Results through Hierarchical Clusters
#@ Steven Noel;Vijay V. Raghavan;Chee-Hung Henry Chu
#t 2001
#c 18
#! We propose a new methodology for visualizing association mining results. Inter-item distances are computed from combinations of item set supports. The new distances retain a simple pairwise structure, and are consistent with important frequently occurring item sets. Thus standard tools of visualization, e.g. hierarchical clustering dendrograms can still be applied, while the distance information upon which they are based is richer. Our approach is applicable to general association mining applications, as well as applications involving information spaces modeled by directed graphs, e.g. the Web. In the context of collections of hypertext documents, the inter-document distances capture the information inherent in a collection's link structure, a for of link mining. We demonstrate our methodology with document sets extracted fro the Science Citation Index, applying a metric that measures consistency between clusters and frequent itemsets.

#index 466660
#* Mining Constrained Association Rules to Predict Heart Disease
#@ Carlos Ordonez;Edward Omiecinski;Levien de Braal;Cesar A. Santana;Norberto Ezquerra;Jose A. Taboada;David Cooke;Elizabeth Krawczynska;Ernest V. Garcia
#t 2001
#c 18
#! This work describes our experiences on discovering association rules in medical data to predict heart disease. We focus on two aspects in this work: mapping medical data toa transaction format suitable for mining association rules and identifying useful constraints. Based on these aspects we introduce an improved algorithm to discover constrainedassociation rules. We present an experimental sectionexplaining several interesting discovered rules.

#index 466661
#* Indiscernibility Degree of Objects for Evaluating Simplicity of Knowledge in the Clustering Procedure
#@ Shoji Hirano;Shusaku Tsumoto
#t 2001
#c 18
#! This paper presents a new, rough sets-based clusteringmethod that enables evaluation of simplicity of classification knowledge during the clustering procedure. The method iteratively refines equivalence relations so that they become more simple set of relations that give adequately coarse classification to the objects. At each step ofiteration, importance of the equivalence relation is evaluated on the basis of the newly introduced measure, indiscernibility degree. An indiscernibility degree is defined as a ratio of equivalence relations that classify the two objects into the same equivalence class. If an equivalence relation hasability to discern the two objects that have high indiscernibility degree, it is considered to perform too fine classification and then modified to regard them as indiscernible objects. The refinement is repeated decreasing the threshold level ofindiscernibility degree, and finally simple clusters can beobtained. Experimental results on the artificial data showed that iterative refinement of equivalence relation lead tosuccessful generation of coarse clusters that can be representedby simple knowledge.

#index 466662
#* Efficient Determination of Dynamic Split Points in a Decision Tree
#@ David Maxwell Chickering;Christopher Meek;Robert Rounthwaite
#t 2001
#c 18
#! We consider the problem of choosing split points forcontinuous predictor variables in a decision tree. Previousapproaches to this problem typically either (1) discretize the continuous predictor values prior to learning or (2) apply a dynamic method that considers all possible split points for each potential split. In this paper, we describe anumber of alternative approaches that generate a smallnumber of candidate split points dynamically with littleoverhead. We argue that these approaches are preferable to pre-discretization, and provide experimental evidence that they yield probabilistic decision trees with the same prediction accuracy as the traditional dynamic approach.Furthermore, because the time to grow a decision tree isproportional to the number of split points evaluated, our approach is significantly faster than the traditional dynamic approach.

#index 466663
#* Subject Classification in the Oxford English Dictionary
#@ Zarrin Langari;Frank Wm. Tompa
#t 2001
#c 18
#! The oxford English Dictionary is a valuable source of lexical information and a rich testing ground for mining highly structured text.Each entry is organized into a hierarchy of senses, which include definitions, labels and cited quotations.Subject labels distinguish the subject classification of a sense, for example they signal how a word may be used in Anthropology, Music or Computing.Unfortunately subject labeling in the dictionary is incomplete. To overcome thisincompleteness, we attempt to classify the senses (i.e., definitions) in the dictionary by their subjects, using thecitations as an information guide.We report on four different approaches: K Nearest Neighbors, a standard classification technique; Term Weighting, an information retrieval method dealing with text; Naïve Bayes, a probabilistic method; and Expectation Maximization, An iterative probabilistic method.Experimental performance of these Methods is compared based on standard classification metrics.

#index 466664
#* Efficiently Mining Maximal Frequent Itemsets
#@ Karam Gouda;Mohammed Javeed Zaki
#t 2001
#c 18
#! We present GenMax, a backtrack search based algorithm for mining maximal frequent itemsets. GenMax uses a number of optimizations to prune the search space.It usesa novel technique called progressive focusing to perform maximality checking, and diffset propagation to perform fast frequency computation. Systematic experimental comparison with previous work indicates that different methods have varying strengths and weaknesses based on dataset characteristics. We found GenMax to be a highly efficient method to mine the exact set of maximal patterns.

#index 466665
#* Discovery of Association Rules in Tabular Data
#@ Graeme Richards;Victor J. Rayward-Smith
#t 2001
#c 18
#! In this paper we address the problem of finding all association rules in tabular data. An Algorithm, ARA, for finding rules, that satisfy clearly specified constraints, in tabular data is presented. ARA is based on the Dense Miner algorithm but includes an additional constraintand an improved method of calculating support. ARA is tested and compared with our implementation of Dense Miner ;it is conclude that ARA is usually more efficient than Dense Miner and is often considerably more so.We also consider the potential for modifying the constraints used in ARA in order to find more generalrules.

#index 466666
#* The Representative Basis for Association Rules
#@ Viet Phan Luong
#t 2001
#c 18
#! We define the concept of the representative basic for interesting association rules, and an inference system which is purely qualitative. The representative basis is unique, and minimal with respect to (wrt) the inference system. On the representative basis, the inference system is correct and complete. Experimental results show that the number of rule in the representative basis is significantly reduced wrt the number of rules generated by other existing approaches.

#index 466667
#* A Synchronization Based Algorithm for Discovering Ellipsoidal Clusters in Large Datasets
#@ Hichem Frigui;Mohamed Ben Hadj Rhouma
#t 2001
#c 18
#! This paper introduces a new scalable approach to clusteringbased on synchronization of pulse-coupled oscillators. Eachdata point is represented by an integrate-and-fire oscillator, and the interaction between oscillators is defined according to the relative similarity between the points. The set of oscillators will self-organize into stable phase-locked subgroups. Our approach proceeds by loading only a subset of the data and allowing it to self-organize. Groups ofsynchronized oscillators are then summarized and purged from memory. We show that our method is robust, scales linearly, and can determine the number of clusters. The proposedapproach is empirically evaluated with several synthetic data sets and is used to segment large color images.

#index 466668
#* A Scalable Algorithm for Clustering Sequential Data
#@ Valerie Guralnik;George Karypis
#t 2001
#c 18
#! In recent years, we have seen an enormous growth in the amount of available commercial and scientific data. Data from domains such as protein sequences, retail transactions, intrusion detection, and web-logs have an inherent sequential nature. Clustering of such data sets is usefulfor various purposes. For example, clustering of sequences from commercialdata sets may help marketer identify different customer groups based upon their purchasing patterns. Grouping protein sequences that share similar structure helps in identifying sequences with similar functionality. Over the years, many methods have been developed for clustering objects according to their similarity. However these methods tend to have a computational complexity that is at least quadratic on the number of sequences. In this paperwe present an entirely different approach to sequence clustering that does not require an all-against-all analysis and uses a nearlinear complexity K-means based clustering algorithm. Our experiments using data sets derived from sequences of purchasing transactions and protein sequences show that this approach is scalable and leads to reasonably good clusters.

#index 466669
#* The Computational Complexity of High-Dimensional Correlation Search
#@ Chris Jermaine
#t 2001
#c 18
#! There is a growing awareness that the popular support metric (often used to guide search in market-basket analysis) is not appropriate for use in every association mining application. Support measures only the frequency of co-occurrence of a set of events when determining which pat-terns to report back to the user. It incorporates no rigorous statistical notion of surprise or interest, and many of the patterns deemed interesting by the support metric are uninteresting to the user.However, a positive aspect of support is that search using support is very efficient. The question we address in this paper is: can we retain this efficiency if we move beyond support, and to other, more rigorous metrics? We consider the computational implications of incorporating simple expectation into the data mining task. It turns out that many variations on the problem which incorporate more rigorous tests of dependence (or independence) result in NP-hard problem definitions.

#index 466670
#* Mining Generalized Association Rules for Sequential and Path Data
#@ Wolfgang Gaul;Lars Schmidt-Thieme
#t 2001
#c 18
#! While association rules for set data se and describe relations between parts of set valued objects completely, association rules for sequential data are restricted by specific interpretations of the subsequence relation: contiguous subsequences describe localfeatures of a sequence valued object, noncontiguous subsequences its global features. We model both types of features with generalized subsequences that describe local deviations by wildcards, and present a new algorithm of Apriori type for mining all generalized subsequences with prescribed minim m support from a given database of sequences. Furthermore we show that the givenalgorithm automatically takes into account an eventually underlying graph structure, i.e., is applicable to path data also.

#index 466671
#* Efficient Yet Accurate Clustering
#@ Manoranjan Dash;Kian-Lee Tan;Huan Liu
#t 2001
#c 18
#! In this paper we show that most hierarchical agglomerativeclustering (HAC)algorithms follow a 90-10 rule where roughly 90%iterations from the beginning merge cluster pairs with dissimilarity less than 10%of the maximumdissimilarity. We propose two algorithms - 2-phase andnested - based on partially overlapping partitioning (POP).To handle high-dimensional data efficiently, we propose a tree structure particularly suitable for POP. Extensive experimentsshow that the proposed algorithms reduce the time andmemory requirement of existing HAC algorithms significantly without compromising in accuracy.

#index 466672
#* The DIAsDEM Framework for Converting Domain-Specific Texts into XML Documents with Data Mining Techniques
#@ Henner Graubitz;Myra Spiliopoulou;Karsten Winkler
#t 2001
#c 18
#! Modern organizations are accumulating huge volumesof textual documents. To turn archives into valuable know-ledge sources, textual content must become explicit andqueryable. Semantic tagging with markup languages suchas XML satisfies both requirements. We thus introduce theDIAsDEM* framework for extra ting semantics from structural text units (e.g., sentences), assigning XML tags to them and deriving a flat XML DTD for the archive. DIAsDEM focuses on archives characterized by a peculiar terminologyand by an implicit structure such as court filings and company reports. In the knowledge discovery phase, text units are iteratively clustered by similarity of their content. Eachiteration outputs clusters satisfying a set of quality criteria.Text units contained in these clusters are tagged with semi-automatically determined luster labels and XML tags respectively. Additionally, extracted named entities (e.g.,per-sons) serve as attributes of XML tags. We apply the frame-work in a case study on the German Commercial Register.

#index 466673
#* Heuristic Optimization for Decentralized Frequent Itemset Counting
#@ Viviane Crestana-Jensen;Nandit Soparkar
#t 2001
#c 18
#! The choices for mining of decentralized data are numerous, and we have developed techniques to enumerate andoptimize decentralized frequent itemset counting. In thispaper, we introduce our heuristic approach to improve theperformance of such techniques developed in ways similarto query processing in database systems. We also describeempirical results that validate our heuristic techniques.

#index 466674
#* Using Artificial Anomalies to Detect Unknown and Known Network Intrusions
#@ Wei Fan;Matthew Miller;Salvatore J. Stolfo;Wenke Lee;Philip K. Chan
#t 2001
#c 18
#! Intrusion detection systems (IDSs) must be capable of detecting new and unknown attacks, or anomalies. We study the problem of building detection models for both pure anomaly detection and combined misuse and anomaly detection (i.e., detection of both known and unknown intrusions). We propose an algorithm to generate artificial anomalies to coerce the inductive learner into discovering an accurate boundary between known classes (normal connections and known intrusions) and anomalies.Empirical studies show that our pure anomaly detection model trained using nor al and artificial anomalies is capable of detecting ore than 77%of all unknown intrusion classes with more than 50%accuracy per intrusion class. The combined misuse and anomaly detection models are as accurate as a pure misuse detection model in detecting known intrusions and are capable of detecting at least 50%of unknown intrusion classes with accuracy measurements between 75% and 100%per class.

#index 466675
#* A Min-max Cut Algorithm for Graph Partitioning and Data Clustering
#@ Chris H. Q. Ding;Xiaofeng He;Hongyuan Zha;Ming Gu;Horst D. Simon
#t 2001
#c 18
#! An important application of graph partitioning is data clustering using a graph model - the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. Here we propose a new algorithm for graph partition with an objective function that follows the min-max clustering principle. The relaxed version of the optimization of the min-max cut objective function leads to the Fiedler vector in spectral graph partition. Theoretical analyses of min-max cut indicate that it leads to balanced partitions, and lower bonds are derived. The min-max cut algorithm is tested on news-group datasets and is found to outperform other current popular partitioning/clustering methods. The linkage-based refinements in the algorithm further improve the quality of clustering substantially. We also demonstrate that the linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effectivepartition method.

#index 466676
#* Integrating E-Commerce and Data Mining: Architecture and Challenges
#@ Suhail Ansari;Ron Kohavi;Llew Mason;Zijian Zheng
#t 2001
#c 18
#! We show that the e-commerce domain can provide all the right ingredients for successful data mining. We describe an integrate architecture for supporting this integration. Thearchitecture can dramatically reduce the pre-processing, cleaning, and data understanding effort often documented to take 80%of the time in knowledge discovery projects. We emphasize the need for data collection at the application server layer (not the web server)in order to support logging of data and metadata that is essential to the discovery process. We describe the datatransformation bridges require from the transaction processing systems an customer event streams (e.g.,clickstreams) to the data warehouse. We detail the mining workbench, which needs to provide multiple views of the data through reporting, data mining algorithms, visualization, and OLAP. We conclude with a set of challenges.

#index 466677
#* Provably Fast Training Algorithms for Support Vector Machines
#@ José L. Balcázar;Yang Dai;Osamu Watanabe
#t 2001
#c 18
#! Support Vector Machines are a family of data analysis algorithms, based on convex Quadratic Programming. We focus on their use for classification that case the SVM algorithms work by maximizing the margin of a classifying hyperplane in a feature space. The feature space is handled by means of kernels f the problems are formulated in dual form. Random Sampling techniques successfully used for similar problems are studied here. The main contribute onis a random zed algorithm for training SVMs for which we can formally prove an upper bound on the expected running time that is quasilinear on the number of data points. To ourknowledge, this is the first algorithm for training SVMs in dual formulation and with kernels for which such a quasi-linear time bound has been formally proved.

#index 466678
#* Mining Frequent Closed Itemsets with the Frequent Pattern List
#@ Fan-Chen Tseng;Ching-Chi Hsu;Henry Chen
#t 2001
#c 18
#! The mining of the complete set of frequent itemsets willlead to a huge number of itemsets. Fortunately, thisproblem can be reduced to the mining of frequent closeditemsets (FCIs), which results in a much smaller number ofitemsets. The approaches to mining frequent closeditemsets can be categorized into two groups: those withcandidate generation and those without. In this paper, wepropose an approach to mining frequent closed itemsetswithout candidate generation: with a data structure calledthe Frequent Pattern List (FPL). We designed thealgorithm FPLC -Mining to mine the frequent closeditemsets (FCIs). Experimental result shows that our methodis faster than the previously existing ones.

#index 466679
#* Classification through Maximizing Density
#@ Hui Wang;Ivo Düntsch;David A. Bell;Dayou Liu
#t 2001
#c 18
#! This paper presents a novel method for classification, which makes use of the models builtby the lattice machine (LM) [1,3 ]. The LM approximates data resulting in, as a model of data, a set of hyper tuples that are equilabelled, supported and maximal . The method presentedin this paper uses the LM model of data to classify new data with a view to maximising the density of the model. Experiments show that this method, when used with the LM, outperforms the C2 algorithm in [3 ] and it is comparable to the C5.0 classification algorithm.

#index 466805
#* Automatic Topic Identification Using Webpage Clustering
#@ Xiaofeng He;Chris H. Q. Ding;Hongyuan Zha;Horst D. Simon
#t 2001
#c 18
#! Grouping webpage into distinct topics is one way to organize the large amount of retrieved information on the web. In this paper, we report that based on similaritymetric which incorporates textual information, hyperlinkstructure and co-citation relations, an unsupervised clustering method can automatically and effectively identify relevant topics, a shown in experiments on several retrieved sets of webpages. The clustering method is a state-of-art spectral graph partitioning method based on normalized cutcriterion first developed for image segmentation.

#index 466806
#* Document Clustering and Cluster Topic Extraction in Multilingual Corpora
#@ Joaquim Ferreira da Silva;João Mexia;Carlos Agra Coelho;José Gabriel Pereira Lopes
#t 2001
#c 18
#! A statistics-based approach for clustering documents and for extracting cluster topics is described. Relevant (meaningful) Expressions (REs) automatically extracted from corpora are used as clustering base features. These features are transformed and its number is strongly reduced in order to obtain a small set of document classificationfeatures. This is achieved on the basis of PrincipalComponents Analysis. Model-Based Clustering Analysis finds thebest number of clusters. Then, the most important REs are extracted from each cluster and taken as document cluster topics.

#index 466807
#* Theory and Applications of Attribute Decomposition
#@ Lior Rokach;Oded Mainon
#t 2001
#c 18
#! This paper examines the Attribute Decomposition Approach with simple Bayesian combination for dealing with classi拢cation problems that contain high number ofattributes and moderate numbers of records. According to the attribute Decomposition approach, the set of input attributes is automatically decomposed into several subsets. classi拢cation model is built for each subset, then all the models are combined using simple Bayesian combination.This paper presents theoretical and practical foundation for the Attribute Decomposition approach. A greedyprocedure, called D-IFN, is developed to decompose the input attributes set into subsets and build a classi拢cation model for each subset separately. The results achieved in theempirical comparison testing with well-known classi拢cationmethods (like C4.5)indicate the superiority of the decomposition approach.

#index 466808
#* Better Rules, Few Features: A Semantic Approach to Selecting Features from Text
#@ Catherine Blake;Wanda Pratt
#t 2001
#c 18
#! The choice of features used to represent a domain has a profound effect on the quality of the model produced; yet, few researchers have investigated the relationship between the features used to represent text and the quality of the final model. We explored this relationship formedical texts by comparing association rules based on features with three different semantic levels: (1) words (2) manually assigned keywords and (3) automatically selected medical concepts. Our preliminary findings indicate that bi-directional association rules based onconcepts or keywords are more plausible and more useful than those based on word features. The concept and keyword representations also required 90% fewer features than the word representation. This drastic dimensionality reduction suggests that this approach is well suited to large textual corpus of medical text, such as parts of the Web.

#index 466809
#* Discovering Similar Patterns for Characterising Time Series in a Medical Domain
#@ Fernando Alonso;Juan Pedro Caraça-Valente;Loïc Martínez;César Montes
#t 2001
#c 18
#! In this article, we describe the process of discovering similar patterns in time series and creating reference models for population groups in a medical domain, and particularly in the field of physiotherapy, using data mining techniques on a set of isokinetic data.The discovered knowledge was evaluated against the expertise of a physician specialised in isokinetic techniques, and applied in the I4 (Intelligent Interpretation of Isokinetic Information) project developed in conjunction with the Spanish National Centre for Sports Research and Sciences and the School of Physiotherapy of the Spanish National Organisation for the Blind for muscular diagnosis and rehabilitation, injury prevention, training evaluation and planning, etc., of elite and blind athletes.

#index 466810
#* Mining the Web with Active Hidden Markov Models
#@ Tobias Scheffer;Christian Decomain;Stefan Wrobel
#t 2001
#c 18

#index 564281
#* Time Series Segmentation for Context Recognition in Mobile Devices
#@ Johan Himberg;Kalle Korpiaho;Heikki Mannila;Johanna Tikanmäki;Hannu Toivonen
#t 2001
#c 18
#! Recognizing the context of se is important in making mobile devices as simple to use as possible. Finding out what the user's situation is can help the device andunderlying service in providing an adaptive and personalized user interface. The device can infer parts of the context of the user from sensor data: the mobile device can includesensors for acceleration, noise level, luminosity, humidity, etc. In this paper we consider context recognition by unsupervisedsegmentation of time series produced by sensors.Dynamic programming can be used to find segments that minimize the intra-segment variances. While this method produces optimal solutions, it is too slow for long sequencesof data. We present and analyze randomized variations of the algorithm. One of them, Global Iterative Replacement or GIR, gives approximately optimal results in a fraction of the time required by dynamic programming. Wedemonstrate the se of time series segmentation in contextrecognition for mobile phone applications.

#index 564283
#* Combining Labeled and Unlabeled Data for Text Classification with a Large Number of Categories
#@ Rayid Ghani
#t 2001
#c 18
#! We develop a framework to incorporate unlabeled data in the Error-Correcting Output Coding (ECOC)setup by decomposing multiclass problems into multiple binary problems and then use Co-Training to learn the individual binary classification problems. We show that our method isespecially useful for classification tasks involving a large number of categories where Co-training doesn't perform very well by itself and when combined with ECOC, outperforms several other algorithms that combine labeled and unlabeled data for text classification in terms of accuracy, precision-recall tradeoff, and efficiency.

#index 565487
#* Meta-patterns: Revealing Hidden Periodic Patterns
#@ Wei Wang;Jiong Yang;Philip S. Yu
#t 2001
#c 18
#! Discovery of periodic patterns in time series data has become an active research area with many applications. These patterns can be hierarchical in nature, where higher level pattern may consist of repetitions of lower level patterns.Unfortunately, the presence of noise m y prevent these higher level patterns from being recognized in the sense that two portions (of data sequence) that support the same (high level) pattern may have different layouts of occurrences of basic symbols. There may not exist any common representation in terms of raw symbol combinations; and hence such (high level) pattern may not be expressed by any previous model (defined on raw symbols or symbol combinations) and would not be properly recognized by any existing method. In this paper, we propose novel model, namely meta-pattern, to capture these high level patterns. As more flexible model, the number of potential meta-patterns could be very large. A substantial difficulty lies on how to identify the proper pattern candidates. However, the well-known Apriori property is not able to provide sufficient pruning power. A new property, namely component location property, is identified and used to conduct the candidate generation so that an efficient computation-based mining algorithm can be developed. Last but not least, we apply our algorithm to some real and synthetic sequences and some interesting patterns are discovered.

#index 565488
#* Who Links to Whom: Mining Linkage between Web Sites
#@ Krishna Bharat;Bay-Wei Chang;Monika Rauch Henzinger;Matthias Ruhl
#t 2001
#c 18
#! Previous studies of the web graph structure have focused on the graph structure at the level of individual pages. In actuality the web is a hierarchically nested graph, with domains, hosts and web sites introducing intermediate levels of affiliation and administrativecontrol. To better understand the growth of the web we need to understand its macro-structure, in terms of the linkage between web sites. In this paper e approximate this by studying the graph of the linkage between hosts on the web. This as done based on snapshots of the web taken by Google in Oct 1999,Aug 2000 and Jun 2001.The connectivity between hosts is represented by a directed graph, with hosts as nodes and weighted edges representingthe count of hyperlinks between pages on the corresponding hosts. We demonstrate how such a "hostgraph" an be used to study connectivity properties of hosts and domains over time, anddiscuss a modified "copy model" too explain observed link eight distributions as a function of subgraph size. We discuss changes in the web over time in the size and connectivity of web sites and country domains. We also describe a data mining application of the hostgraph: a related host finding algorithm which achieves a precision of 0.65 at rank 3.

#index 565489
#* A Simple KNN Algorithm for Text Categorization
#@ Pascal Soucy;Guy W. Mineau
#t 2001
#c 18
#! Text categoriztion (also called text classification) is the process of identifying the class to which a text document belongs. This paper proposes to use a simple non-weighted feature KNN algorithm for text caegoriztion. We propose to use a feature selection method that finds the relevant features for the learning task at hand using feature interaction (based on word interdependencies).

#index 629291
#* Proceedings of the 2002 IEEE International Conference on Data Mining
#@ 
#t 2002
#c 18

#index 629601
#* Phrase-based Document Similarity Based on an Index Graph Model
#@ Khaled M. Hammouda;Mohamed S. Kamel
#t 2002
#c 18
#! Document clustering techniques mostly rely on singleterm analysis of the document data set, such as the VectorSpace Model. To better capture the structure of documents,the underlying data model should be able to represent thephrases in the document as well as single terms. We presenta novel data model, the Document Index Graph, which indexesweb documents based on phrases, rather than singleterms only. The semi-structured web documents helpin identifying potential phrases that when matched withother documents indicate strong similarity between the documents.The Document Index Graph captures this informa-tion,and finding significant matching phrases between documentsbecomes easy and efficient with such model. Thesimilarity between documents is based on both single termweights and matching phrases weights. The combined similaritiesare used with standard document clustering techniquesto test their effect on the clustering quality. Experimentalresults show that our phrase-based similarity, combinedwith single-term similarity measures, enhances webdocument clustering quality significantly.

#index 629602
#* Objective-Oriented Utility-Based Association Mining
#@ Yi-Dong Shen;Zhong Zhang;Qiang Yang
#t 2002
#c 18
#! The necessity to develop methods for discovering associationpatterns to increase business utility of an enterprisehas long been recognized in data mining community.This requires modeling specific association patterns thatare both statistically (based on support and confidence) andsemantically (based on objective utility) relating to a givenobjective that a user wants to achieve or is interested in.However, we notice that no such a general model has beenreported in the literature. Traditional association miningfocuses on deriving correlations among a set of items andtheir association rules like diaper 驴 beer only tell us thata pattern like fdiaperg is statistically related to an itemlike beer. In this paper, we present a new approach, calledObjective-Oriented utility-based Association (OOA)mining,to modeling such association patterns that are explicitlyrelating to a user's objective and its utility. Due to its focuson a user's objective and the use of objective utility as keysemantic information to measure the usefulness of associationpatterns, OOA mining differs significantly from existingapproaches such as the existing constraint-based associationmining. We formally define OOA mining and developan algorithm for mining OOA rules. The algorithm is anenhancement to Apriori with specific mechanisms for handlingobjective utility. We prove that the utility constraint isneither monotone nor anti-monotone nor succinct nor convertibleand present a novel pruning strategy based on theutility constraint to improve the efficiency of OOA mining.

#index 629603
#* Mining Molecular Fragments: Finding Relevant Substructures of Molecules
#@ Christian Borgelt;Michael R. Berthold
#t 2002
#c 18
#! We present an algorithm to find fragments in a setof molecules that help to discriminate between differentclasses of, for instance, activity in a drug discovery context.Instead of carrying out a brute-force search, our methodgenerates fragments by embedding them in all appropriatemolecules in parallel and prunes the search tree based ona local order of the atoms and bonds, which results in substantiallyfaster search by eliminating the need for frequent,computationally expensive reembeddings and by suppressingredundant search. We prove the usefulness of our algorithmby demonstrating the discovery of activity-relatedgroups of chemical compounds in the well-known NationalCancer Institute's HIV-screening dataset.

#index 629604
#* Mining Significant Associations in Large Scale Text Corpora
#@ Prabhakar Raghavan;Panayiotis Tsaparas
#t 2002
#c 18
#! Mining large-scale text corpora is an essential step in extractingthe key themes in a corpus. We motivate a quanti-tativemeasure for significant associations through the distributionsof pairs and triplets of co-occurring words. Weconsider the algorithmic problem of efficiently enumerat-ingsuch significant associations and present pruning algorithmsfor these problems, with theoretical as well as empiricalanalyses. Our algorithms make use of two novel miningmethods: (1) matrix mining, and (2) shortened documents.We present evidence from a diverse set of documents that ourmeasure does in fact elicit interesting co-occurrences.

#index 629605
#* A Self-Organizing Map with Expanding Force for Data Clustering and Visualization
#@ Wing-Ho Shum;Hui-Dong Jin;Kwong-Sak Leung;Man-Leung Wong
#t 2002
#c 18
#! The Self-Organizing Map (SOM) is a powerful tool in theexploratory phase of data mining. However, due to the dimensional conflict, the neighborhood preservation cannotalways lead to perfect topology preservation. In this paper, we establish an Expanding SOM (ESOM) to detect andpreserve better topology correspondence between the twospaces. Our experiment results demonstrate that the ESOMconstructs better mappings than the classic SOM in terms ofboth the topological and the quantization errors. Furthermore, clustering results generated by the ESOM are moreaccurate than those by the SOM.

#index 629606
#* On Computing Condensed Frequent Pattern Bases
#@ Jian Pei;Guozhu Dong;Wei Zou;Jiawei Han
#t 2002
#c 18
#! Frequent pattern mining has been studied extensively.However, the effectiveness and efficiency of this mining isoften limited, since the number of frequent patterns generatedis often too large. In many applications it is sufficientto generate and examine only frequent patterns with supportfrequency in close-enough approximation instead of in fullprecision. Such a compact but close-enough frequent patternbase is called a condensed frequent patterns-base.In this paper, we propose and examine several alternativesat the design, representation, and implementation ofsuch condensed frequent pattern-bases. A few algorithmsfor computing such pattern-bases are proposed. Their effectivenessat pattern compression and their efficient computationmethods are investigated. A systematic performancestudy is conducted on different kinds of databases,which demonstrates the effectiveness and efficiency of ourapproach at handling frequent pattern mining in largedatabases.

#index 629607
#* Mining Motifs in Massive Time Series Databases
#@ Pranav Patel;Eamonn Keogh;Jessica Lin;Stefano Lonardi
#t 2002
#c 18
#! The problem of efficiently locating previously knownpatterns in a time series database (i.e., query by content) hasreceived much attention and may now largely be regardedas a solved problem. However, from a knowledge discoveryviewpoint, a more interesting problem is the enumeration ofpreviously unknown, frequently occurring patterns. We callsuch patterns "motifs", because of their close analogy totheir discrete counterparts in computation biology. Anefficient motif discovery algorithm for time series would beuseful as a tool for summarizing and visualizing massivetime series databases. In addition it could be used as asubroutine in various other data mining tasks, including thediscovery of association rules, clustering and classification.In this work we carefully motivate, then introduce, a non-trivialdefinition of time series motifs. We propose anefficient algorithm to discover them, and we demonstrate theutility and efficiency of our approach on several real worlddatasets.

#index 629608
#* Employing Discrete Bayes Error rate for discretization and feature selection
#@ Ankush Mittal;Loong-Fah Cheong
#t 2002
#c 18
#! The tasks of discretization and feature selection are frequentlyused to improve classification accuracy. In this paper,we use discrete approximation of Bayes error rate toperform discretization on the features. The discretizationprocedure targets minimization of Bayes error rate withineach partition. A class-pair discriminatory measure can bedefined on discretized partitions which forms the basis offeature selection algorithm. Small value of this measure fora class-pair indicates that the class-pair in considerationis confusing and the features which distinguish them wellshould be chosen first. A video classification problem ona large database is considered for showing the comparisonof a classifier using our discretization and feature selectiontasks with SVM, Neural network classifier, decision treesand K-Nearest neighbor classifier

#index 629609
#* Empirical Comparison of Various Reinforcement Learning Strategies for Sequential Targeted Marketing
#@ Naoki Abe;Edwin Pednault;Haixun Wang;Bianca Zadrozny;Wei Fan;Chid Apte
#t 2002
#c 18
#! We empirically evaluate the performance of various re-inforcementlearning methods in applications to sequentialtargeted marketing. In particular, we propose and evaluatea progression of reinforcement learning methods, rangingfrom the "direct" or "batch" methods to "indirect" or"simulation based" methods, and those that we call "semi-direct"methods that fall between them. We conduct a num-berof controlled experiments to evaluate the performanceof these competing methods. Our results indicate that whilethe indirect methods can perform better in a situation inwhich nearly perfect modeling is possible, under the morerealistic situations in which the system's modeling parametershave restricted attention, the indirect methods' performancetend to degrade. We also show that semi-directmethods are effective in reducing the amount of computationnecessary to attain a given level of performance, andoften result in more profitable policies.

#index 629610
#* Heterogeneous Learner for Web Page Classification
#@ Hwanjo Yu;Kevin Chen-Chuan Chang;Jiawei Han
#t 2002
#c 18
#! Classification of an interesting class of Web pages (e.g.,personal homepages, resume pages) has been an interestingproblem. Typical machine learning algorithms for thisproblem require two classes of data for training: positiveand negative training examples. However, in applicationto Web page classification, gathering an unbiased sampleof negative examples appears to be difficult. We proposea heterogeneous learning framework for classifying Webpages, which (1) eliminates the need for negative trainingdata, and (2) increases classification accuracy by using twoheterogeneous learners. Our framework uses two heterogeneouslearners - a decision list and a linear separatorwhich complement each other - to eliminate the need fornegative training data in the training phase and to increasethe accuracy in the testing phase. Our results show that ourheterogeneous framework achieves high accuracy withoutrequiring negative training data; it enhances the accuracyof linear separators by reducing the errors on "low-margindata". That is, it classifies more accurately while requiringless human efforts in training.

#index 629611
#* Adaptive and Resource-Aware Mining of Frequent Sets
#@ S. Orlando;P. Palmerini;R. Perego;F. Silvestri
#t 2002
#c 18
#! The performance of an algorithm that mines frequent sets from transactional databases may severely depend on the specific features of the data being analyzed. Moreover, some architectural characteristics of the computational platform used - e.g. the available main memory - can dramatically change its runtime behavior. In this paper we present DCI (Direct Count & Intersect), an efficient algorithm for discovering frequent sets from large databases. Due to the multiple heuristics strategies adopted, DCI can adapt its behavior not only to the features of the specific computing platform, but also to the features of the datasetbeing mined, so that it results very effective in mining both short and long patterns from sparse and dense datasets. Finally we also discuss the parallelization strategies adopted in the design of ParDCI, a distributed and multi-threaded implementation of DCI.

#index 629612
#* From Path Tree To Frequent Patterns: A Framework for Mining Frequent Patterns
#@ Yabo Xu;Jeffrey Xu Yu;Guimei Liu;Hongjun Lu
#t 2002
#c 18
#! In this paper, we propose a new framework for miningfrequent patterns from large transactional databases. Thecore of the framework is of a novel coded prefix-path treewith two representations, namely, a memory-based prefix-pathtree and a disk-based prefix-path tree. The disk-basedprefix-path tree is simple in its data structure yet rich ininformation contained, and is small in size. The memory-basedprefix-path tree is simple and compact. Upon thememory-based prefix-path tree, a new depth-first frequentpattern discovery algorithm, called P P-Mine, is proposedin this paper that outperforms FP-growth significantly. Thememory-based prefix-path tree can be stored on disk usinga disk-based prefix-path tree with assistance of the new codingscheme. We present efficient loading algorithms to loadthe minimal required disk-based prefix-path tree into mainmemory. Our technique is to push constraints into the loadingprocess, which has not been well studied yet.

#index 629613
#* Mining Associations by Pattern Structure in Large Relational Tables
#@ Haixun Wang;Chang-Shing Perng;Sheng Ma;Philip S. Yu
#t 2002
#c 18
#! Association rule mining aims at discovering patternswhose support is beyond a given threshold. Mining patternscomposed of items described by an arbitrary subset ofattributes in a large relational table represents a new challengeand has various practical applications, including theevent management systems that motivated this work. Theattribute combinations that define the items in a pattern providethe structural information of the pattern. Current associationalgorithms do not make full use of the structuralinformation of the patterns: the information is either lostafter it is encoded with attribute values, or is constrainedby a given hierarchy or taxonomy. Pattern structures conveyimportant knowledge about the patterns. In this paper,we present a novel architecture that organizes the miningspace based on pattern structures. By exploiting the inter-relationshipsamong pattern structures, execution times formining can be reduced significantly. This advantage isdemonstrated by our experiments using both synthetic andreal-life datasets.

#index 629614
#* Mining Generalized Association Rules Using Pruning Techniques
#@ Yin-Fu Huang;Chiech-Ming Wu
#t 2002
#c 18
#! The goal of the paper is to mine generalizedassociation rules using pruning techniques. Given a largetransaction database and a hierarchical taxonomy tree ofthe items, we try to find the association rules between theitems at different levels in the taxonomy tree under theassumption that original frequent itemsets and associationrules have already been generated beforehand. In theproposed algorithm GMAR, we use join methods andpruning techniques to generate new generalizedassociation rules. Through several comprehensiveexperiments, we find that the GMAR algorithm is muchbetter than BASIC and Cumulate algorithms.

#index 629615
#* Mining Association Rules from Stars
#@ Eric Ka Ka Ng;Ada Wai-Chee Fu;Ke Wang
#t 2002
#c 18
#! Association rule mining is an important data mining problem.It is found to be useful for conventional relational data.However, previous work had mostly targeted on mining a single table.In real life, a database is typically made up of multiple table and one important case is where some of the tables form a star schema.That tables typically correspond to entity sets and joining the tables in a star schema gives relationship amoung entity sets which can be very interesting information.Hence mining on the join result is an important problem.Based on characteristics of the star schema we propose an efficient algorithm for mining association rules on the joinresult but without actually performing the join opertation.We show that this approach can significantly out-perform the join-then-mine approach even when the latter adopts a fastest known mining algorithm.

#index 629616
#* On Active Learning for Data Acquisition
#@ Zhiqiang Zheng;Balaji Padmanabhan
#t 2002
#c 18
#! Many applications are characterized by having naturallyincomplete data on customers - where data on only somefixed set of local variables is gathered. However, having amore complete picture can help build better models. Thenaïve solution to this problem - acquiring complete datafor all customers - is often impractical due to the costs ofdoing so. A possible alternative is to acquire completedata for "some" customers and to use this to improve themodels built. The data acquisition problem is determininghow many, and which, customers to acquire additionaldata from. In this paper we suggest using active learningbased approaches for the data acquisition problem. Inparticular, we present initial methods for data acquisitionand evaluate these methods experimentally on web usagedata and UCI datasets. Results show that the methodsperform well and indicate that active learning basedmethods for data acquisition can be a promising area fordata mining research.

#index 629617
#* Online Algorithms for Mining Semi-structured Data Stream
#@ Tatsuya Asai;Hiroki Arimura;Kenji Abe;Shinji Kawasoe;Setsuo Arikawa
#t 2002
#c 18
#! In this paper, we study an online data mining problemfrom streams of semi-structured data such as XML data.Modeling semi-structured data and patterns as labeled orderedtrees, we present an online algorithm StreamT thatreceives fragments of an unseen possibly infinite semi-structureddata in the document order through a datastream, and can return the current set of frequent patternsimmediately on request at any time. A crucial part of our algorithmis the incremental maintenance of the occurrencesof possibly frequent patterns using a tree sweeping technique.We give modifications of the algorithm to other on-linemining model. We present theoretical and empiricalanalyses to evaluate the performance of the algorithm.

#index 629618
#* A Lazy Approach to Pruning Classification Rules
#@ Elena Baralis;Paolo Garza
#t 2002
#c 18
#! Associative classification is a promising technique forthe generation of highly precise classifiers. Previous workspropose several clever techniques to prune the huge set ofgenerated rules, with the twofold aim of selecting a smallset of high quality rules, and reducing the chance of overfitting.In this paper, we argue that pruning should be reducedto a minimum and that the availability of a large rule basemay improve the precision of the classifier, without affectingits performance. In L3 (Live and Let Live), a new algorithmfor associative classification, a lazy pruning technique iterativelydiscards all rules that only yield wrong case classifications.Classification is performed in two steps. Initially, ruleswhich have already correctly classified at least one trainingcase, sorted by confidence, are considered. If the caseis still unclassified, the remaining rules (unused during thetraining phase) are considered, again sorted by confidence.Extensive experiments on 26 databases from the UCImachine learning database repository show that L3 improvesthe classification precision with respect to previousapproaches.

#index 629619
#* Feature Selection Algorithms: A Survey and Experimental Evaluation
#@ Luis Carlos Molina;Lluís Belanche;Àngela Nebot
#t 2002
#c 18
#! In view of the substantial number of existing feature selection algorithms, the need arises to count on criteria that enables to adequately decide which algorithm to us in certain situations.This work assess the performance of several fundamental algorithms found in the literature in a controlled scenario.A scoring measure ranks the algorithms by taking into account the amount of relevance, irrelevance and redundance on sample data sets.This measure computer the degree of matching between the output given by the algorithm and the know optimal solution.Sample size effects are also studied.

#index 629620
#* Learning with Progressive Transductive Support Vector Machine
#@ Yisong Chen;Guoping Wang;Shihai Dong
#t 2002
#c 18
#! Support Vector Machine (SVM) is a new learningmethod developed in recent years based on thefoundations of statistical learning theory. By taking atransductive approach instead of an inductive one insupport vector classifiers, the test set can be used as anadditional source of information about margins. Intuitively,we would expect transductive learning to yieldimprovements when the training sets are small or whenthere is a significant deviation between the training andworking set subsamples of the total population. In thispaper, a progressive transductive support vector machineis addressed to extend Joachims' Transductive SVM tohandle different class distributions. It solves the problemof having to estimate the ratio of positive/negativeexamples from the working set. The experimental resultsshow that the algorithm is very promising.

#index 629621
#* Discriminative Category Matching: Efficient Text Classification for Huge Discriminative Category Matching: Efficient Text Classification for Huge
#@ Gabriel Pui Cheong Fung;Jeffrey Xu Yu;Hongjun Lu
#t 2002
#c 18
#! With the rapid growth of textual information availableon the Internet, having a good model for classifying andmanaging documents automatically is undoubtly important.When more documents are archived, new terms, new conceptsand concept-drift will frequently appear. Without adoubt, updating the classification model frequently ratherthan using the old model for a very long period is absolutelyessential. Here, the challenges are: a) obtain a highaccuracy classification model; b) consume low computationaltime for both model training and operation; and c)occupy low storage space. However, none of the existingclassification approaches could achieve all of these requirements.In this paper, we propose a novel text classificationapproach, called Discriminative Category Matching, whichcould achieve all of the stated characteristics. Extensive experimentsusing two benchmarks and a large real-life collectionare conducted. The encouraging results indicatedthat our approach is hignhly feasible.

#index 629622
#* Convex Hull Ensemble Machine
#@ Yongdai Kim
#t 2002
#c 18
#! We propose a new ensemble algorithm called "ConvexHull Ensemble Machine (CHEM)." CHEM in Hilbert spaceis developed first and it is modified to regression and clas-sificationproblems. Empirical studies show that in classi-ficationproblems CHEM has similar prediction accuracyas AdaBoost, but CHEM is much more robust to outputnoise. In regression problems, CHEM works competitivelywith other ensemble methods such as Gradient Boost andBagging.

#index 629623
#* SLPMiner: An Algorithm for Finding Frequent Sequential Patterns Using Length-Decreasing Support Constraint
#@ Masakazu Seno;George Karypis
#t 2002
#c 18
#! Over the years, a variety of algorithms for finding frequentsequential patterns in very large sequential databaseshave been developed. The key feature in most of these algorithmsis that they use a constant support constraint tocontrol the inherently exponential complexity of the problem.In general, patterns that contain only a few items willtend to be interesting if they have a high support, whereaslong patterns can still be interesting even if their supportis relatively small. Ideally, we desire to have an algorithmthat finds all the frequent patterns whose support decreasesas a function of their length. In this paper we present an algorithmcalled SLPMiner, that finds all sequential patternsthat satisfy a length-decreasing support constraint. Our experimentalevaluation shows that SLPMiner achieves up totwo orders of magnitude of speedup by effectively exploitingthe length-decreasing support constraint, and that itsruntime increases gradually as the average length of the sequences(and the discovered frequent patterns) increases.

#index 629624
#* Unsupervised Clustering of Symbol Strings and Context Recognition
#@ John A. Flanagan;Jani Mäntyjarvi;Johan Himberg
#t 2002
#c 18
#! The representation of information based on symbolstrings has been applied to the recognition of context. Aframework for approaching the context recognition problemhas been described and interpreted in terms of symbolstring recognition. The Symbol String Clustering Map(SCM) is introduced as an efficient algorithm for the unsupervisedclustering and recognition of symbol string data.The SCM can be implemented in an on line manner usinga computationally simple similarity measure based ona weighted average. It is shown how measured sensor datacan be processed by the SCM algorithm to learn, representand distinguish different user contexts without any user input.

#index 629625
#* Progressive Modeling
#@ Wei Fan;Haixun Wang;Philip S. Yu;Shaw-hwa Lo;Salvatore Stolfo
#t 2002
#c 18
#! Presently, inductive learning is still performed in a frustratingbatch process. The user has little interaction withthe system and no control over the final accuracy and trainingtime. If the accuracy of the produced model is too low,all the computing resources are misspent. In this paper, wepropose a progressive modeling framework. In progressivemodeling, the learning algorithm estimates online both theaccuracy of the final model and remaining training time. Ifthe estimated accuracy is far below expectation, the usercan terminate training prior to completion without wastingfurther resources. If the user chooses to complete the learningprocess, progressive modeling will compute a modelwith expected accuracy in expected time. We describe oneimplementation of progressive modeling using ensemble ofclassifiers.

#index 629626
#* O-Cluster: Scalable Clustering of Large High Dimensional Data Sets
#@ Boriana L. Milenova;Marcos M. Campos
#t 2002
#c 18
#! Clustering large data sets of high dimensionality hasalways been a challenge for clustering algorithms. Manyrecently developed clustering algorithms have attemptedto address either handling data sets with a very largenumber of records and/or with a very high number ofdimensions. This paper provides a discussion of theadvantages and limitations of existing algorithms whenthey operate on very large multidimensional data sets. Tosimultaneously overcome both the "curse ofdimensionality" and the scalability problems associatedwith large amounts of data, we propose a new clusteringalgorithm called O-Cluster. O-Cluster combines a novelactive sampling technique with an axis-parallelpartitioning strategy to identify continuous areas of highdensity in the input space. The method operates on alimited memory buffer and requires at most a single scanthrough the data. We demonstrate the high quality of theobtained clustering solutions, their robustness to noise,and O-Cluster's excellent scalability.

#index 629627
#* Automatic Web Page Classification in a Dynamic and Hierarchical Way
#@ XIAOGANG PENG;BEN CHOI
#t 2002
#c 18
#! Automatic classification of web pages is an effectiveway to deal with the difficulty of retrieving informationfrom the Internet. Although there are many automaticclassification algorithms and systems that have beenproposed, most of them ignore the conflict between thefixed number of categories and the growing number ofweb pages going into the system. They also requiresearching through all existing categories to make anyclassification. We propose a dynamic and hierarchicalclassification system that is capable of adding newcategories as required, organizing the web pages into atree structure, and classifying web pages by searchingthrough only one path of the tree structure. Our testresults show that our proposed single-path searchtechnique reduces the search complexity and increasesthe accuracy by 6% comparing to related algorithms. Ourdynamic-category expansion technique also achievessatisfying results on adding new categories into oursystem as required.

#index 629628
#* Feature Selection for Clustering - A Filter Solution
#@ Manoranjan Dash;Kiseok Choi;Peter Scheuermann;Huan Liu
#t 2002
#c 18
#! Processing applications with a large number of dimensionshas been a challenge to the KDD community. Featureselection, an effective dimensionality reduction technique,is an essential pre-processing method to remove noisy features.In the literature there are only a few methods proposedfor feature selection for clustering. And, almost all ofthose methods are wrapper' techniques that require a clusteringalgorithm to evaluate the candidate feature subsets.The wrapper approach is largely unsuitable in real-worldapplications due to its heavy reliance on clustering algorithmsthat require parameters such as number of clusters,and due to lack of suitable clustering criteria to evaluateclustering in different subspaces. In this paper we proposea filter' method that is independent of any clustering algorithm.The proposed method is based on the observationthat data with clusters has very different point-to-point distancehistogram than that of data without clusters. Usingthis we propose an entropy measure that is low if data hasdistinct clusters and high otherwise. The entropy measure issuitable for selecting the most important subset of featuresbecause it is invariant with number of dimensions, and isaffected only by the quality of clustering. Extensive performanceevaluation over synthetic, benchmark, and realdatasets shows its effectiveness.

#index 629629
#* PERUSE: An Unsupervised Algorithm for Finding Recurrig Patterns in Time Series
#@ Tim Oates
#t 2002
#c 18
#! This paper describes PERUSE, an unsupervised algorithm for finding recurring patterns in time series.It was initially developed and tested with sensor data from a mobile robot, i.e. noisy, re-valued, multivariate time series with variable intervals between observations.The pattern discovery problem is decomposed into two sub-problems: (1) a supervised learning problem in which a teacher provised exemplars of patterns and labels time series according to whether they contain the patterns; (2)an un supervised learning problem in which the time series are used to generate an approximation to the teacher.Experimental results show that PERUSE can discover patterns in audio data corresponding to qualitatively distinct outcomes of taking actions.

#index 629630
#* Discovering Frequent Geometric Subgraphs
#@ Michihiro Kuramochi;George Karypis
#t 2002
#c 18
#! As data mining techniques are being increasingly appliedto non-traditional domains, existing approaches forfinding frequent itemsets cannot be used as they cannotmodel the requirement of these domains. An alternate wayof modeling the objects in these data sets, is to use a graphto model the database objects. Within that model, the problemof finding frequent patterns becomes that of discoveringsubgraphs that occur frequently over the entire set ofgraphs. In this paper we present a computationally efficientalgorithm for finding frequent geometric subgraphs ina large collection of geometric graphs. Our algorithm isable to discover geometric subgraphs that can be rotation,scaling and translation invariant, and it can accommodateinherent errors on the coordinates of the vertices. Our experimentalresults show that our algorithms requires relativelylittle time, can accommodate low support values, andscales linearly on the number of transactions.

#index 629631
#* Unsupervised Segmentation of Categorical Time Series into Episodes
#@ Paul Cohen;Brent Heeringa;Niall Adams
#t 2002
#c 18
#! This paper describes an unsupervised algorithm forsegmenting categorical time series into episodes. TheVOTING-EXPERTS algorithm first collects statistics aboutthe frequency and boundary entropy of ngrams, then passesa window over the series and has two "expert methods" decidewhere in the window boundaries should be drawn. Thealgorithm successfully segments text into words in four languages.The algorithm also segments time series of robotsensor data into subsequences that represent episodes inthe life of the robot. We claim that VOTING-EXPERTSfinds meaningful episodes in categorical time series becauseit exploits two statistical characteristics of meaningfulepisodes.

#index 629632
#* Modal-style operators in qualitative data analysis
#@ Ivo Düntsch;Günther Gediga
#t 2002
#c 18
#! We explore the usage of the modal possibility operator (andits dual necessity operator) in qualitative data analysis, andshow that it - quite literally - complements the derivationoperator of formal concept analysis; we also propose a newgeneralization of the rough set approximation operators. Asan example for the applicability of the concepts we investigatethe Morse data set which has been frequently studiedin multidimensional scaling procedures.

#index 629633
#* Evolutionary Time Series Segmentation for Stock Data Mining
#@ Fu-lai Chung;Tak-chung Fu;Robert Luk;Vincent Ng
#t 2002
#c 18
#! Stock data in the form of multiple time series aredifficult to process, analyze and mine. However, when theycan be transformed into meaningful symbols like technicalpatterns, it becomes an easier task. Most recent work ontime series queries only concentrates on how to identify agiven pattern from a time series. Researchers do notconsider the problem of identifying a suitable set of timepoints for segmenting the time series in accordance with agiven set of pattern templates (e.g., a set of technicalpatterns for stock analysis). On the other hand, using fixedlength segmentation is a primitive approach to thisproblem; hence, a dynamic approach (with highcontrollability) is preferred so that the time series can besegmented flexibly and effectively according to the needs ofthe users and the applications. In view of the facts that sucha segmentation problem is an optimization problem andevolutionary computation is an appropriate tool to solve it,we propose an evolutionary time series segmentationalgorithm. This approach allows a sizeable set of stockpatterns to be generated for mining or query. In addition,defining the similarity between time series (or time seriessegments) is of fundamental importance in fitnesscomputation. By identifying the perceptually importantpoints directly from the time domain, time series segmentsand templates of different lengths can be compared andintuitive pattern matching can be carried out in an effectiveand efficient manner. Encouraging experimental results arereported from tests that segment the time series of selectedHong Kong stocks.

#index 629634
#* Comparison of Lazy Bayesian Rule and Tree-Augmented Bayesian Learning
#@ Zhihai Wang;Geoffrey I. Webb
#t 2002
#c 18
#! The naive Bayes classifier is widely used in interactiveapplications due to its computational efficiency, direct theoreticalbase, and competitive accuracy. However, its attributeindependence assumption can result in sub-optimalaccuracy. A number of techniques have explored simple relaxationsof the attribute independence assumption in or-derto increase accuracy. Among these, the lazy Bayesianrule () and the tree-augmented naive Bayes ()have demonstrated strong prediction accuracy. However,their relative performance has never been evaluated. Thispaper compares and contrasts these two techniques, findingthat they have comparable accuracy and hence shouldbe selected according to computational profile. LBR is desirablewhen small numbers of objects are to be classifiedwhile TAN is desirable when large numbers of objects areto be classified.

#index 629635
#* Multivariate supervised discretization, a neighborhood graph approach
#@ Fabrice Muhlenbach;Ricco Rakotomalala
#t 2002
#c 18
#! We present a new discretization method in the contextof supervised learning. This method entitled HyperClusterFinder is characterized by its supervised and polytheticbehavior. The method is based on the notion of clustersand processes in two steps. First, a neighborhood graphconstruction from the learning database allows discoveringhomogenous clusters. Second, the minimal and maximalvalues of each cluster are transferred to each dimension inorder to define some boundaries to cut the continuous attributein a set of intervals. The discretization abilities ofthis method are illustrated by some examples, in particular,processing the XOR problem.

#index 629636
#* Adapting Information Extraction Knowledge For Unseen Web Sites
#@ Tak-Lam Wong;Wai Lam
#t 2002
#c 18
#! We propose a wrapper adaptation framework which aimsat adapting a learned wrapper to an unseen Web site. It significantlyreduces human effort in constructing wrappers.Our framework makes use of extraction rules previously discoveredfrom a particular site to seek potential training ex-amplecandidates for an unseen site. Rule generalizationand text categorization are employed for finding suitable examplecandidates. Another feature of our approach is thatit makes use of the previously discovered lexicon to classifygood training examples automatically for the new site. Weconducted extensive experiments to evaluate the quality ofthe extraction performance and the adaptability of our approach.

#index 629637
#* Efficient Discovery of Common Substructures in Macromolecules
#@ Srinivasan Parthasarathy;Matt Coatney
#t 2002
#c 18
#! Biological macromolecules play a fundamental role indisease; therefore, they are of great interest to fields such aspharmacology and chemical genomics. Yet due to macromolecules'complexity, development of effective techniquesfor elucidating structure-function macromolecular relationshipshas been ill explored. Previous techniques have eitherfocused on sequence analysis, which only approximatesstructure-function relationships, or on small coor-dinatedatasets, which does not scale to large datasets orhandle noise. We present a novel scalable approach toefficiently discover macromolecule substructures based onthree-dimensional coordinate data, without domain-specificknowledge. The approach combines structure-based frequentpattern discovery with search space reduction andcoordinate noise handling. We analyze computational performancecompared to traditional approaches, validate thatour approach can discover meaningful substructures innoisy macromolecule data by automated discovery of primaryand secondary protein structures, and show that ourtechnique is superior to sequence-based approaches at determiningstructural, and thus functional, similarity be-tweenproteins.

#index 629638
#* Using Category-Based Adherence to Cluster Market-Basket Data
#@ Ching-Huang Yun;Kun-Ta Chuang;Ming-Syan Chen
#t 2002
#c 18
#! In this paper, we devise an efficient algorithm for clusteringmarket-basket data. Different from those of the traditionaldata, the features of market-basket data are knownto be of high dimensionality, sparsity, and with massive out-liers.Without explicitly considering the presence of the tax-onomy,most prior efforts on clustering market-basket datacan be viewed as dealing with items in the leaf level of thetaxonomy tree. Clustering transactions across different levelsof the taxonomy is of great importance for marketingstrategies as well as for the result representation of the clusteringtechniques for market-basket data. In view of thefeatures of market-basket data, we devise in this paper anovel measurement, called the category-based adherence,and utilize this measurement to perform the clustering. Thedistance of an item to a given cluster is defined as the numberof links between this item and its nearest large node inthe taxonomy tree where a large node is an item (i.e., leaf)or a category (i.e., internal) node whose occurrence countexceeds a given threshold. The category-based adherenceof a transaction to a cluster is then defined as the averagedistance of the items in this transaction to that cluster.With this category-based adherence measurement, wedevelop an efficient clustering algorithm, called algorithmCBA (standing for Category-Based Adherence), for market-basketdata with the objective to minimize the category-basedadherence. A validation model based on InformationGain (IG) is also devised to assess the quality of clusteringfor market-basket data. As validated by both real and syntheticdatasets, it is shown by our experimental results, withthe taxonomy information, algorithm CBA devised in thispaper significantly outperforms the prior works in both theexecution efficiency and the clustering quality for market-basketdata.

#index 629639
#* Using functional PCA for cardiac motion exploration
#@ Denis Clot
#t 2002
#c 18
#! Principal component analysis (PCA) [14, 6] is a maintool in multivariate data analysis. Its paradigms are alsoused in the Karhunen-Loeve decomposition [5], a standardtool in image processing. Extensions of PCA to the frameworkof functional data have been proposed. The analy-sisprovided by the functional PCA seems to be a powerfultool to find principal sources of variability in curves or images,but it fails in providing us with easy interpretationsin the case of multifunctional data. Guide lines aiming atspot information from the outputs of PCA applied to functionalswith values in space of continuous functions upona bounded domain are proposed. An application to cardiacmotion analysis illustrates the complexity of the multi-functionalframework and the results provided by functionalPCA.

#index 629640
#* Predicting Rare Events In Temporal Domains
#@ Ricardo Vilalta;Sheng Ma
#t 2002
#c 18
#! Temporal data mining aims at finding patterns in historicaldata. Our work proposes an approach to extract temporalpatterns from data to predict the occurrence of targetevents, such as computer attacks on host networks, or fraudulenttransactions in financial institutions. Our problemformulation exhibits two major challenges: 1) we assumeevents being characterized by categorical features and displayinguneven inter-arrival times; such an assumption fallsoutside the scope of classical time-series analysis, 2) weassume target events are highly infrequent; predictive techniquesmust deal with the class-imbalance problem. We pro-posean efficient algorithm that tackles the challenges aboveby transforming the event prediction problem into a searchfor all frequent eventsets preceding target events. The classimbalance problem is overcome by a search for patterns onthe minority class exclusively; the discrimination power ofpatterns is then validated against other classes. Patternsare then combined into a rule-based model for prediction.Our experimental analysis indicates the types of event sequenceswhere target events can be accurately predicted.

#index 629641
#* A Hybrid Approach to Discover Bayesian Networks From Databases Using Evolutionary Programming
#@ Man Leung Wong;Shing Yan Lee;Kwong Sak Leung
#t 2002
#c 18
#! This paper describes a novel data mining approach thatemploys evolutionary programming to discover knowledgerepresented in Bayesian networks. There are two differentapproaches to the network learning problem. The first oneuses dependency analysis, while the second one searchesgood network structures according to a metric. Unfortu-nately,both approaches have their own drawbacks. Thus,we propose a novel hybrid algorithm of the two approaches,which consists of two phases, namely, the Conditional Inde-pendence(CI) test and the search phases. A new opera-toris introduced to further enhance the search efficiency.We conduct a number of experiments and compare the hy-bridalgorithm with our previous algorithm, MDLEP [18],which uses EP for network learning. The empirical resultsillustrate that the new approach has better performance.We apply the approach to a data sets of direct marketingand compare the performance of the evolved Bayesian net-worksobtained by the new algorithm with the models gen-eratedby other methods. In the comparison, the inducedBayesian networks produced by the new algorithm outper-formthe other models.

#index 629642
#* Text Document Categorization by Term Association
#@ Maria-Luiza Antonie;Osmar R. Zaïane
#t 2002
#c 18
#! A good text classifier is a classifier that efficiently categorizeslarge sets of text documents in a reasonable timeframe and with an acceptable accuracy, and that providesclassification rules that are human readable for possiblefine-tuning. If the training of the classifier is also quick,this could become in some application domains a good assetfor the classifier. Many techniques and algorithms forautomatic text categorization have been devised. Accordingto published literature, some are more accurate than others,and some provide more interpretable classification modelsthan others. However, none can combine all the beneficialproperties enumerated above. In this paper, we present anovel approach for automatic text categorization that borrowsfrom market basket analysis techniques using associationrule mining in the data-mining field. We focus on twomajor problems: (1) finding the best term association rulesin a textual database by generating and pruning; and (2)using the rules to build a text classifier. Our text categorizationmethod proves to be efficient and effective, and experimentson well-known collections show that the classifierperforms well. In addition, training as well as classificationare both fast and the generated rules are human readable.

#index 629643
#* A Theory of Inductive Query Answering
#@ Luc DE RAEDT;Manfred JAEGER;Sau Dan LEE;Heikki MANNILA
#t 2002
#c 18
#! We introduce the boolean inductive query evaluationproblem, which is concerned with answering inductivequeries that are arbitrary boolean expressions over monotonicand anti-monotonic predicates. Secondly, we developa decomposition theory for inductive query evaluation inwhich a boolean query Q is reformulated into k sub-queriesQ_i= Q_A\wedge Q_Mthat are the conjunction of a monotonicand an anti-monotonic predicate. The solution to each sub-querycan be represented using a version space. We investigatehow the number of version spaces k needed to answerthe query can be minimized. Thirdly, for the pattern domainof strings, we show how the version spaces can berepresented using a novel data structure, called the versionspace tree, and can be computed using a variant of the famousApriori algorithm. Finally, we present some experi-mentsthat validate the approach.

#index 629644
#* Mining Top.K Frequent Closed Patterns without Minimum Support
#@ Jiawei Han;Jianyong Wang;Ying Lu;Petre Tzvetkov
#t 2002
#c 18
#! In this paper, we propose a new mining task: mining top-kfrequent closed patterns of length no less than min_l, wherek is the desired number of frequent closed patterns to bemined, and min _l is the minimal length of each pattern.An efficient algorithm, called TFP, is developed for mining such patterns without minimum support. Two methods, closed_node_count and descendant_sum are proposedto effiectively raise support threshold and prune FP-tree bothduring and after the construction of FP-tree. During themining process, a novel top-down and bottom-up combinedFP-tree mining strategy is developed to speed-up support-raising and closed frequent pattern discovering. In addition,a fast hash-based closed pattern verification scheme has beenemployed to check efficiently if a potential closed pattern isreally closed.Our performance study shows that in most cases, TFPoutperforms CLOSET and CHARM, two efficient frequentclosed pattern mining algorithms, even when both are running with the best tuned min_support. Furthermore, themethod can be extended to generate association rules andto incorporate user-specified constraints. Thus we concludethat for frequent pattern mining, mining top-k frequent closedpatterns without min support is more preferable than thetraditional min_support-based mining.

#index 629645
#* Adapting classification rule induction to subgroup discovery
#@ Nada Lavrac;Peter Flach;Branko Kavsek;Ljupco Todorovski
#t 2002
#c 18
#! Rule learning is typically used for solving classificationand prediction tasks. However, learning of classificationrules can be adapted also to subgroup discovery. This papershows how this can be achieved by modifying the coveringalgorithm and the search heuristic, performing probabilisticclassification of instances, and using an appropriatemeasure for evaluating the results of subgroup discovery.Experimental evaluation of the CN2-SD subgroup discoveryalgorithm on 17 UCI data sets demonstrates substantialreduction of the number of induced rules, increased rulecoverage and rule significance, as well as slight improvementsin terms of the area under the ROC curve.

#index 629646
#* Computing Frequent Graph Patterns from Semistructured Data
#@ N. Vanetik;E. Gudes;S. E. Shimony
#t 2002
#c 18
#! Whereas data mining in structured data focuses on frequentdata values, in semi-structured and graph data theemphasis is on frequent labels and common topologies.Here, the structure of the data is just as important as its content.We study the problem of discovering typical patterns ofgraph data. The discovered patterns can be useful for manyapplications, including: compact representation of sourceinformation and a road-map for browsing and querying informationsources. Difficulties arise in the discovery taskfrom the complexity of some of the required sub-tasks, suchas sub-graph isomorphism. This paper proposes a new algorithmfor mining graph data, based on a novel definitionof support. Empirical evidence shows practical, as well astheoretical, advantages of our approach.

#index 629647
#* Investigative Profiling with Computer Forensic Log Data and Association Rules
#@ Tamas Abraham;Olivier de Vel
#t 2002
#c 18
#! Investigative profiling is an important activity in computerforensics that can narrow the search for one or morecomputer perpetrators. Data mining is a technique that hasproduced good results in providing insight into large volumesof data. This paper describes how the associationrule data mining technique may be employed to generateprofiles from log data and the methodology used for the interpretationof the resulting rule sets. The process relies onbackground knowledge in the form of concept hierarchiesand beliefs, commonly available from, or attainable by, thecomputer forensic investigative team. Results obtained withthe profiling system has identified irregularities in computerlogs.

#index 629648
#* Adaptive dimension reduction for clustering high dimensional data
#@ Chris Ding;Xiaofeng He;Hongyuan Zha;Horst D. Simon
#t 2002
#c 18
#! It is well-known that for high dimensional data clustering, standard algorithms such as EM and the K -meansare often trapped in local minimum. Many initializationmethods were proposed to tackle this problem, but withonly limited success. In this paper we propose newapproach to resolve this problem by repeated dimension reductions such that K-means or EM are performedonly in very low dimensions.Cluster membership is utilized as a bridge between the reduced dimensional sub-space and the original space, providing flexibility andease of implementation. Clustering analysis performedon highly overlapped Gaussians, DNA gene expressionprofiles and internet newsgroups demonstrate the effectiveness of the proposed algorithm.

#index 629649
#* Mining Case Bases for Action Recommendation
#@ Qiang Yang;Hong Cheng
#t 2002
#c 18
#! Corporations and institutions are often interested inderiving marketing strategies from corporate data andproviding informed advice for their customers oremployees. For example, a financial institution mayderive marketing strategies for turning their reluctantcustomers into active ones and a telecommunicationscompany may plan actions to stop their valuablecustomers from leaving. In data mining terms, theseadvice and action plans are aimed at convertingindividuals from an undesirable class to a desirable one,or to help devising a direct-marketing plan in order toincrease the profit for the institution. In this paper, wepresent an approach to use role models' for generatingsuch advice and plans. These role models are typicalcases that form a case base and can be used forcustomer advice generation. For each new customerseeking advice, a nearest-neighbor algorithm is used tofind a cost-effective and highly probable plan forswitching a customer to the most desirable role models.In this paper, we explore the tradeoff among time, spaceand quality of computation in this case-based reasoningframework. We demonstrate the effectiveness of themethods through empirical results.

#index 629650
#* Mining Similar Temporal Patterns in Long Time-Series Data and Its Application to Medicine
#@ Shoji Hirano;Shusaku Tsumoto
#t 2002
#c 18
#! Data mining in time-series medical databases has beenreceiving considerable attention since it provides a way ofrevealing useful information hidden in the database; forexample relationships between temporal course of examinationresults and onset time of diseases. This paperpresents a new method for finding similar patterns in temporalsequences. The method is a hybridization of phase-constraintmultiscale matching and rough clustering. Multiscalematching enables us cross-scale comparison of thesequences, namely, it enable us to compare temporal patternsby partially changing observation scales. Rough clusteringenable us to construct interpretable clusters of thesequences even if their similarities are given as relativesimilarities. We combine these methods and cluster the sequencesaccording to multiscale similarity of patterns. Experimentalresults on the chronic hepatitis dataset showedthat clusters demonstrating interesting temporal patternswere successfully discovered.

#index 629651
#* Using Text Mining to Infer Semantic Attributes for Retail Data Mining
#@ Rayid Ghani;Andrew E. Fano
#t 2002
#c 18
#! Current Data Mining techniques usually do not have amechanism to automatically infer semantic features inherentin the data being "mined". The semantics are eitherinjected in the initial stages (by feature construction) or byinterpreting the results produced by the algorithms. Bothof these techniques have proved effective but require a lotof human effort. In many domains, semantic informationis implicitly available and can be extracted automaticallyto improve data mining systems. In this paper, we present acase study of a system that is trained to extract semantic featuresfor apparel products and populate a knowledge basewith these products and features. We show that semanticfeatures of these items can be successfully extracted by applyingtext learning techniques to the descriptions obtainedfrom websites of retailers. We also describe several applicationsof such a knowledge base of product semantics that wehave built including recommender systems and competitiveintelligence tools and provide evidence that our approachcan successfully build a knowledge base with accurate factswhich can then be used to create profiles of individual customers,groups of customers, or entire retail stores.

#index 629652
#* Efficient Progressive Sampling for Association Rules
#@ Srinivasan Parthasarathy
#t 2002
#c 18
#! In data mining, sampling has often been suggested as aneffective tool to reduce the size of the dataset operated atsome cost to accuracy. However, this loss to accuracy isoften difficult to measure and characterize since the exactnature of the learning curve (accuracy vs. sample size) isparameter and data dependent, i.e., we do not know aprioriwhat sample size is needed to achieve a desired accuracyon a particular dataset for a particular set of parameters.In this article we propose the use of progressive sampling todetermine the required sample size for association rule mining.We first show that a naive application of progressivesampling is not very efficient for association rule mining.We then present a refinement based on equivalence classes,that seems to work extremely well in practice and is able toconverge to the desired sample size very quickly and veryaccurately. An additional novelty of our approach is thedefinition of a support-sensitive, interactive measure of accuracyacross progressive samples.

#index 629653
#* Cluster merging and splitting in hierarchical clustering algorithms
#@ Chris Ding;Xiaofeng He
#t 2002
#c 18
#! Hierarchical clustering constructs a hierarchy of clusterseither repeatedly mer in two smaller clusters into alarger one or splittin a larger cluster into smaller ones. The crucial step is how to best select the next cluster(s)to split or merge. Here we provide a comprehensiveanalysis of selection methods and propose several newmethods. We perform extensive clustering experimentsto test 8 selection methods, and ?nd that the averagesimilarity is the best method in divisive clustering andMinMax linkage is the best in agglomerativeCluster balance is a key factor to achieve goodperformance. We also introduce the concept of objective function saturation and clustering target distanceto effectively assess the quality of clustering.

#index 629654
#* User-directed Exploration of Mining Space with Multiple Attributes
#@ Chang-Shing Perng;Haixun Wang;Sheng Ma;Joseph L. Hellerstein
#t 2002
#c 18
#! There has been a growing interest in mining frequentitemsets in relational data with multiple attributes. A keystep in this approach is to select a set of attributes thatgroup data into transactions and a separate set of attributesthat labels data into items. Unsupervised and unrestrictedmining, however, is stymied by the combinatorial complexityand the quantity of patterns as the number of attributesgrows. In this paper, we focus on leveraging the semanticsof the underlying data for mining frequent itemsets. Forinstance, there are usually taxonomies in the data schemaand functional dependencies among the attributes. Domainknowledge and user preferences often have the potentialto significantly reduce the exponentially growing miningspace. These observations motivate the design of a user-directeddata mining framework that allows such domainknowledge to guide the mining process and control the miningstrategy. We show examples of tremendous reductionin computation by using domain knowledge in mining relationaldata with multiple attributes.

#index 629655
#* Speed-up Iterative Frequent Itemset Mining with Constraint Changes
#@ Gao Cong;Bing Liu
#t 2002
#c 18
#! Mining of frequent itemsets is a fundamental datamining task. Past research has proposed many efficientalgorithms for the purpose. Recent work also highlightedthe importance of using constraints to focus the miningprocess to mine only those relevant itemsets. In practice,data mining is often an interactive and iterative process.The user typically changes constraints and runs the miningalgorithm many times before satisfied with the finalresults. This interactive process is very time consuming.Existing mining algorithms are unable to take advantageof this iterative process to use previous mining results tospeed up the current mining process. This results inenormous waste in time and in computation. In this paper,we propose an efficient technique to utilize previousmining results to improve the efficiency of current miningwhen constraints are changed. We first introduce theconcept of tree boundary to summarize the usefulinformation available from previous mining. We then showthat the tree boundary provides an effective and efficientframework for the new mining. The proposed techniquehas been implemented in the contexts of two existingfrequent itemset mining algorithms, FP-tree and TreeProjection. Experiment results on both synthetic and real-lifedatasets show that the proposed approach achievesdramatic saving in computation.

#index 629656
#* TreeFinder: a First Step towards XML Data Mining
#@ Alexandre Termier;Marie-Christine Rousset;Michèl Sebag
#t 2002
#c 18
#! In this paper, we consider the problem of searching fre-quenttrees from a collection of tree-structured data model-ingXML data. The TreeF inder algorithm aims at findingtrees, such that their exact or perturbed copies are frequentin a collection of labelled trees.To cope with complexity issues, TreeF inder is correctbut not complete: it finds a subset of the actually frequenttrees. The default of completeness is experimentally inves-tigatedon artificial medium size datasets; it is shown thatTreeFinderreaches completeness or falls short to it for arange of experimental settings.

#index 629657
#* A Parameterless Method for Efficiently Discovering Clusters of Arbitrary Shape in Large Datasets
#@ Andrew Foss;Osmar R. Zaïane
#t 2002
#c 18
#! Clustering is the problem of grouping data based on similarityand consists of maximizing the intra-group similaritywhile minimizing the inter-group similarity. The problem ofclustering data sets is also known as unsupervised classification,since no class labels are given. However, all exist-ingclustering algorithms require some parameters to steerthe clustering process, such as the famous k for the numberof expected clusters, which constitutes a supervision ofa sort. We present in this paper a new, efficient, fast andscalable clustering algorithm that clusters over a range ofresolutions and finds a potential optimum clustering withoutrequiring any parameter input. Our experiments showthat our algorithm outperforms most existing clustering algorithmsin quality and speed for large data sets.

#index 629658
#* On the Mining of Substitution Rules for Statistically Dependent Items
#@ Wei-Guang Teng;Ming-Jyh Hsieh;Ming-Syan Chen
#t 2002
#c 18
#! In this paper, a new mining capability, called mining ofsubstitution rules, is explored. A substitution refers to thechoice made by a customer to replace the purchase of someitems with that of others. The process of mining substitutionrules can be decomposed into two procedures. The first procedureis to identify concrete itemsets among a large numberof frequent itemsets, where a concrete itemset is a frequentitemset whose items are statistically dependent. Thesecond procedure is then on the substitution rule generation.Two concrete itemsets X and Y form a substitutionrule, denoted by X \triangleright Y to mean that X is a substitute for Y,if and only if (1) X and Y are negatively correlated and (2)the negative association rule X \to \overline Y exists. In this paper,we derive theoretical properties for the model of substitutionrule mining. Then, in light of these properties, algorithmSRM (standing for substitution rule mining) is designedand implemented to discover the substitution rulesefficiently while attaining good statistical significance. Empiricalstudies are performed to evaluate the performance ofalgorithm SRM proposed. It is shown that algorithm SRMproduces substitution rules of very high quality.

#index 629659
#* Attribute (Feature) Completion - The Theory of Attributes from Data Mining Prospect
#@ Tsay Young ('T.  Y. ') Lin
#t 2002
#c 18
#! A "correct" selection of attributes (features) is vital indata mining. As a first step, this paper constructs all possibleattributes of a given relation. The results are basedon the observations that each relation is isomorphic to aunique abstract relation, called canonical model. The completeset of attributes of the canonical model is, then, constructed.Any attribute of a relation can be interpreted (viaisomorphism) from such a complete set.

#index 629660
#* A Comparison Study on Algorithms for Incremental Update of Frequent Sequences
#@ Minghua Zhang;Ben Kao;Chi-Lap Yip
#t 2002
#c 18
#! The problem of mining frequent sequences is to extractfrequently occurring subsequences in a sequence database.Algorithms on this mining problem include GSP, MFS, andSPADE. The problem of incremental update of frequent sequencesis to keep track of the set of frequent sequences asthe underlying database changes. Previous studies have extendedthe traditional algorithms to efficiently solve the up-dateproblem. These incremental algorithms include ISM,GSP+and MFS+. Each incremental algorithm has its owncharacteristics and they have been studied and evaluatedseparately under different scenarios. This paper presentsa comprehensive study on the relative performance of theincremental algorithms as well as their non-incrementalcounterparts. Our goal is to provide guidelines on thechoice of an algorithm for solving the incremental updateproblem given the various characteristics of a sequencedatabase.

#index 629661
#* Recognition of Common Areas in a Web Page Using Visual Information: a possible application in a page classification
#@ Milos Kovacevic;Michelangelo Diligenti;Marco Gori;Veljko Milutinovic
#t 2002
#c 18
#! Extracting and processing information from Webpages is an important task in many areas likeconstructing search engines, information retrieval, anddata mining from the Web. Common approach in theextraction process is to represent a page as a "bag ofwords" and then to perform additional processing onsuch a flat representation. In this paper we propose anew, hierarchical representation that includes browserscreen coordinates for every HTML object in a page.Using visual information one is able to define heuristicsfor the recognition of common page areas such asheader, left and right menu, footer and center of a page.We show in initial experiments that using our heuristicsdefined objects are recognized properly in 73% of cases.Finally, we show that a Naive Bayes classifier, takinginto account the proposed representation, clearlyoutperforms the same classifier using only informationabout the content of documents.

#index 629662
#* Mining General Temporal Association Rules for Items with Different Exhibition Periods
#@ Cheng-Yue Chang;Ming-Syan Chen;Chang-Hung Lee
#t 2002
#c 18
#! In this paper, we explore a new model of mining generaltemporal association rules from large databases wherethe exhibition periods of the items are allowed to be differentfrom one to another. Note that in this new model,the downward closure property which all prior Apriori-basedalgorithms relied upon to attain good efficiency isno longer valid. As a result, how to efficiently generatecandidate itemsets form large databases has become themajor challenge. To address this issue, we develop an efficientalgorithm, referred to as algorithm SPF (standingfor Segmented Progressive Filter) in this paper. The basicidea behind SPF is to first segment the database into sub-databasesin such a way that items in each sub-databasewill have either the common starting time or the commonending time. Then, for each sub-database, SPF progressivelyfilters candidate 2-itemsets with cumulative filteringthresholds either forward or backward in time. This featureallows SPF of adopting the scan reduction techniqueby generating all candidate k-itemsets (k 2) from candidate2-itemsets directly. The experimental results show thatalgorithm SPF significantly outperforms other schemeswhich are extended from prior methods in terms of the executiontime and scalability.

#index 629663
#* A new implementation technique for fast Spectral based document retrieval systems
#@ Laurence A.  F. Park;Marimuthu Palaniswami;Kotagiri Ramamohanarao
#t 2002
#c 18
#! The traditional methods of spectral text retrieval(FDS,CDS) create an index of spatial data and convert thedata to its spectral form at query time. We present a newmethod of implementing and querying an index containingspectral data which will conserve the high precision performanceof the spectral methods, reduce the time needed toresolve the query, and maintain an acceptable size for theindex. This is done by taking advantage of the propertiesof the discrete cosine transform and by applying ideas fromvector space document ranking methods.

#index 629664
#* On a Capacity Control Using Boolean Kernels for the Learning of Boolean Functions
#@ Ken Sadohara
#t 2002
#c 18
#! This paper concerns the classification task discrete attribute spaces, but consider the task in a more fundamental framework: the learning of Boolean functions.The purpose of this paper is to present a new learning algorithm for Boolean functions called Boolean Kernel Classifier (BKC) employing capacity control using Boolean kernels.BKC uses Support Vector Machines (SVMs) as learning engines and Boolean kernels are primarily used for running SVMs in feature spaces spanned by conjunctions of Boolean literals.However, another inportant role of Boolean kernels is to appropriately control the size of its hypothesis space to avoid overfitting.After applying a SVM to learn a classifier f in a feature space H induced by a Boolean kernel f k of f onto a subspace Hk of H spanned by conjunctions with length at most k, BKC can determine the smallest k such that f k is as accurate as f and learn another f' in Hk expected to have lower error for unseen data.By an empirical study on learning of randomly generated Boolean functions, it is shown that the capacity control is effective, and BKC outperforms C4.5 and naive Bayes classifiers.

#index 629665
#* High Performance Data Mining Using the Nearest Neighbor Join
#@ Christian Böhm;Florian Krebs
#t 2002
#c 18
#! The similarity join has become an important database primitiveto support similarity search and data mining. A similarity joincombines two sets of complex objects such that the result containsall pairs of similar objects. Well-known are two types of thesimilarity join, the distance range join where the user defines adistance threshold for the join, and the closest point query ork-distance join which retrieves the k most similar pairs. In thispaper, we investigate an important, third similarity join operationcalled k-nearest neighbor join which combines each point ofone point set with its k nearest neighbors in the other set. It hasbeen shown that many standard algorithms of Knowledge Discoveryin Databases (KDD) such as k-means and k-medoid clustering,nearest neighbor classification, data cleansing, postprocessingof sampling-based data mining etc. can be implementedon top of the k-nn join operation to achieve performance improvementswithout affecting the quality of the result of these algorithms.We propose a new algorithm to compute the k-nearestneighbor join using the multipage index (MuX), a specialized indexstructure for the similarity join. To reduce both CPU and I/Ocost, we develop optimal loading and processing strategies.

#index 629666
#* Iterative Clustering of High Dimensional Text Data Augmented by Local Search
#@ Inderjit S. Dhillon;Yuqiang Guan;J. Kogan
#t 2002
#c 18
#! The k-means algorithm with cosine similarity, alsoknown as the spherical k-means algorithm, is a popularmethod for clustering document collections. However,spherical k-means can often yield qualitatively poor results,especially when cluster sizes are small, say 25-30 documentsper cluster, where it tends to get stuck at a localmaximum far away from the optimal solution. In this paper,we present a local search procedure, which we call"first-variation" that refines a given clustering by incrementallymoving data points between clusters, thus achievinga higher objective function value. An enhancement offirst variation allows a chain of such moves in a Kernighan-Linfashion and leads to a better local maximum. Combiningthe enhanced first-variation with spherical k-meansyields a powerful "ping-pong" strategy that often qualitativelyimproves k-means clustering and is computationallyefficient. We present several experimental results to high-lightthe improvement achieved by our proposed algorithmin clustering high-dimensional and sparse text data.

#index 629667
#* A Formal Model for User Preference
#@ Sung Young Jung;Jeong-Hee Hong;Taek-Soo Kim
#t 2002
#c 18
#! Personalization and recommendation systems requireformalized model for user preference. This paper presentsthe formal model of preference including positivepreference and negative preference. For rare events, weapply the probability of random occurrence in order toreduce noise effects caused by data sparseness. Paretodistribution is adopted for the random occurrenceprobability. We also present the method for combininginformation of joint feature variables in different sizes bydynamic weighting using random occurrence probability.

#index 629668
#* Estimating the number of segments in time series data using permutation tests
#@ Kari T. Vasko;Hannu T. T. Toivonen
#t 2002
#c 18
#! Segmentation is a popular technique for discoveringstructure in time series data. We address the largely openproblem of estimating the number of segments that can bereliably discovered. We introduce a novel method for theproblem, called Pete. Pete is based on permutation testing.The problem is an instance of model (dimension) selection.The proposed method analyzes the possible overfitof a model to the available data rather than uses a termfor penalizing model complexity. In this respect the approachis more similar to cross-validation than regulariza-tionbased techniques (e.g., AIC, BIC, MDL, MML). Further,the method produces a p value for each increase in thenumber of segments. This gives the user an overview of thestatistical significance of the segmentations. We evaluatethe performance of the proposed method using both syntheticand real time series data. The experiments show thatpermutation testing gives realistic results about the numberof reliably identifiable segments and that it compares favorablywith the Monte Carlo cross-validation (MCCV) andcommonly used BIC criteria.

#index 629669
#* Adaptive Ripple Down Rules Method based on Minimum Description Length Principle
#@ Tetsuya Yoshida;Hiroshi Motoda;Takashi Washio;Takuya Wada
#t 2002
#c 18
#! When class distribution changes, some pieces of knowledgepreviously acquired become worthless, and the existenceof such knowledge may hinder acquisition of newknowledge. This paper proposes an adaptive Ripple DownRules (RDR) method based on the Minimum DescriptionLength Principle aiming at knowledge acquisition in a dynamicallychanging enviromnent. To cope with the changeof class distribution, knowledge deletion is carried out aswell as knowledge acquisition so that useless knowledge isproperly discarded. To cope with the change of the sourceof knowledge, RDR knowledge based systems can be constructedadaptively by acquiring knowledge from both domainexperts and data. By incorporating inductive learningmethods, knowledge acquision can be carried out evenwhen only either data or experts are available by switchingthe source of knowledge from domain experts to dataand vice versa at any time of knowledge acquisition. Sinceexperts need not be available all the time, it contributes toreducing the cost of personnel expenses. Experiments wereconducted by simulating the change of the source of knowledgeand the change of class distribution using the datasetsin UCI repository. The results are encouraging.

#index 629670
#* Linear Causal Model Discovery Using the MML criterion
#@ Gang Li;Honghua Dai;Yiqing Tu
#t 2002
#c 18
#! Determining the causal structure of a domain is a keytask in the area of Data Mining and Knowledge Discovery.The algorithm proposed by Wallace et al. [15] hasdemonstrated its strong ability in discovering Linear CausalModels from given data sets. However, some experimentsshowed that this algorithm experienced difficulty in discoveringlinear relations with small deviation, and it occasion-allygives a negative message length, which should not beallowed. In this paper, a more efficient and precise MML encodingscheme is proposed to describe the model structureand the nodes in a Linear Causal Model. The estimation ofdifferent parameters is also derived. Empirical results showthat the new algorithm outperformed the previous MML-basedalgorithm in terms of both speed and precision.

#index 629671
#* SmartMiner: A Depth First Algorithm Guided by Tail Information for Mining Maximal Frequent Itemsets
#@ Qinghua Zou;Wesley W. Chu;Baojing Lu
#t 2002
#c 18
#! Maximal frequent itemsets (MFI) are crucial to manytasks in data mining. Since the MaxMiner algorithm firstintroduced enumeration trees for mining MFI in 1998,several methods have been proposed to use depth firstsearch to improve performance. To further improve theperformance of mining MFI, we proposed a techniquethat takes advantage of the information gathered fromprevious steps to discover new MFI. More specifically,our algorithm called SmartMiner gathers and passes tailinformation and uses a heuristic select function whichuses the tail information to select the next node toexplore. Compared with Mafia and GenMax, SmartMinergenerates a smaller search tree, requires a smallernumber of support counting, and does not requiresuperset checking. Using the datasets Mushroom andConnect, our experimental study reveals that SmartMinergenerates the same MFI as Mafia and GenMax, but yieldsan order of magnitude improvement in speed.

#index 629672
#* Towards Automatic Generation of Query Taxonomy: A Hierarchical Query Clustering Approach
#@ Shui-Lung Chuang;Lee-Feng Chien
#t 2002
#c 18
#! Previous works on automatic query clustering most generatea flat, un-nested partition of query terms. In this work,we are pursuing to organize query terms into a hierarchicalstructure and construct a query taxonomy in an automaticway. The proposed approach is designed based on a hierarchicalagglomerative clustering algorithm to hierarchicallygroup similar queries and generate the cluster hierarchiesby a novel cluster partition technique. The search processesof real-world search engines are combined to obtain highlyranked Web documents as the feature source for each queryterm. Preliminary experiments show that the proposed approachis effective to obtain thesaurus information for queryterms, and is also feasible to construct a query taxonomywhich provides a basis for in-depth analysis of users' searchinterests and domain-specific vocabulary on a larger scale.

#index 629673
#* Mining A Set of Coregulated RNA Sequences
#@ Yuh-Jyh Hu
#t 2002
#c 18
#! Post-transcriptional regulation, though less studied, isan important research topic in bioinformatics. In a set ofpost-transcriptionally coregulated RNAs, the basepair interactionscan organize the molecules into domains andprovide a framework for functional interactions. Their consensusmotifs may represent the binding sites of RNA regulatoryproteins. Unlike DNA motifs, RNA motifs are moreconserved in structures than in sequences. Knowing thestructural motifs can help us better understand the regulationactivities. In this paper, we propose a novel data miningapproach to RNA secondary structure prediction. Todemonstrate the performance of our new approach, we firsttested it on the same data sets previously used and publishedin literature. Secondly, to show the flexibility of ournew approach, we also tested it on a data set that containspseudoknot motifs that most current systems cannot identify.

#index 629674
#* An Incremental Approach to Building a Cluster Hierarchy
#@ Dwi H. Widyantoro;Thomas R. Ioerger;John Yen
#t 2002
#c 18
#! In this paper we present a novel Incremental HierarchicalClustering (IHC) algorithm. Our approach aims to constructa hierarchy that satisfies the homogeneity and themonotonicity properties. Working in a bottom-up fashion,a new instance is placed in the hierarchy and a sequence ofhierarchy restructuring process is performed only in regionsthat have been affected by the presence of the new instance.The experimental results on a variety of domains demonstratethat our algorithm is not sensitive to input ordering,can produce a quality cluster hierarchy, and is efficient interms of its computational time.

#index 629675
#* Progressive and Interactive Analysis of Event Data Using Event Miner
#@ Sheng Ma;Joseph L. Hellerstein;Chang-shing Perng;Genady Grabarnik
#t 2002
#c 18
#! Exploring large data sets typically involves activities that iteratebetween data selection and data analysis, in which insights obtainedfrom analysis result in new data selection. Further, data analysis needs touse a combination of analysis techniques: data summarization, mining algorithmsand visualization. This interweaving of functions arises both fromthe semantics of what the analyst hopes to achieve and from scalability requirementsfor dealing with large data volumes. We refer to such a processas a progressive analysis. Herein is described a tool, Event Miner, that integratesdata selection, mining and visualization for progressive analysis oftemporal, categorical data. We discuss a data model and architecture. Weillustrate how our tool can be used for complex mining tasks such as findingpatterns not occurring on Monday. Further, we discuss the novel visualizationemployed, such as visualizing categorical data and the results of datamining. Also, we discuss the extension of the existing mining frameworkneeded to mine temporal events with multiple attributes. Throughout, weillustrate the capabilities of Event Miner by applying it to event data fromlarge computer networks.

#index 629676
#* Mining Genes in DNA Using GeneScout
#@ Michael M. Yin;Jason T.  L. Wang
#t 2002
#c 18
#! In this paper, we present a new system, calledGeneScout, for predicting gene structures in vertebrate genomicDNA. The system contains specially designed hiddenMarkov models (HMMs) for detecting functional sites includingprotein-translation start sites, mRNA splicing junctiondonor and acceptor sites, etc. Our main hypothesisis that, given a vertebrate genomic DNA sequence S, it isalways possible to construct a directed acyclic graph Gsuch that the path for the actual coding region of S is inthe set of all paths on G. Thus, the gene detection problemis reduced to that of analyzing the paths in the graphG. A dynamic programming algorithm is used to find theoptimal path in G. The proposed system is trained usingan expectation-maximization (EM) algorithm and its performanceon vertebrate gene prediction is evaluated usingthe 10-way cross-validation method. Experimental resultsshow the good performance of the proposed system and itscomplementarity to a widely used gene detection system.

#index 629677
#* InfoMiner+: Mining Partial Periodic Patterns with Gap Penalties
#@ Jiong Yang;Wei Wang;Philip S. Yu
#t 2002
#c 18
#! In this paper, we focus on mining periodic patterns allowing some degreeof imperfection in the form of random replacement from a perfectperiodic pattern. Information gain was proposed to identify patternswith events of vastly different occurrence frequencies and adjust forthe deviation from a pattern. However, it does not take any penaltyif there exists some gap between the pattern occurrences. In manyapplications, e.g., bio-informatics, it is important to identify subsequencesthat a pattern repeats perfectly (or near perfectly). As a solution,we extend the information gain measure to include a penaltyfor gaps between pattern occurrences. We call this measure as generalizedinformation gain. Furthermore, we want to find subsequenceS' such that for a pattern P , the generalized information gain of Pin S' is high. This is particularly useful in locating repeats in DNAsequences. In this paper, we developed an effective mining algorithm,InfoMiner+, to simultaneously mine significant patterns and the as-sociatedsubsequences.

#index 629678
#* Solving the Fragmentation Problem of Decision Trees by Discovering Boundary Emerging Patterns
#@ Jinyan Li;Limsoon Wong
#t 2002
#c 18
#! The single coverage constraint discourages a decisiontree to contain many significant rules. The loss of significantrules leads to a loss in accuracy. On the other hand, thefragmentation problem causes a decision tree to contain toomany minor rules. The presence of minor rules decreasesaccuracy. We propose to use emerging patterns to solvethese problems. In our approach, many globally significantrules can be discovered. Extensive experimental results ongene expression datasets show that our approach are moreaccurate than single C4.5 trees, and are also better thanbagged or boosted C4.5 trees.

#index 629679
#* An Algebraic Approach to Data Mining: Some Examples
#@ Robert L. Grossman;Richard G. Larson
#t 2002
#c 18
#! In this paper, we introduce an algebraic approach tothe foundations of data mining. Our approach is basedupon two algebras of functions defined over a commonstate space X and a pairing between them.One algebra is an algebra of state space observations, and the other is an algebra of labeled sets ofstates.We interpret H as the algebraic encoding of the dataand the pairing as the misclassification rate when theclassifer f is applied to the set of states X.In this paper, we give a realization theorem givingconditions on formal series of data sets built from Dthat imply there is a realization involving a state spaceX, a classifier f \in R and a set of labeled states x \in R_0that yield this series.

#index 629680
#* A Personalized Music Filtering System Based on Melody Style Classification
#@ Fang-Fei Kuo;Man-Kwan Shan
#t 2002
#c 18
#! With the growth of digital music, the personalized musicfiltering system is helpful for users. Melody style is one ofthe music features to represent user's music preference. Inthis paper, we present a personalized content-based musicfiltering system to support music recommendation based onuser's preference of melody style. We propose the multitypemelody style classification approach to recommend themusic objects. The system learns the user preference bymining the melody patterns from the music access behaviorof the user. A two-way melody preference classifier istherefore constructed for each user. Music recommendationis made through this melody preference classifier.Performance evaluation shows that the filtering effect of theproposed approach meets user's preference.

#index 629681
#* Association Analysis with One Scan of Databases
#@ Hao Huang;Xindong Wu;Richard Relue
#t 2002
#c 18
#! Mining frequent patterns with an FP-tree avoids costlycandidate generation and repeatedly occurrence frequencychecking against the support threshold. It thereforeachieves better performance and efficiency than Apriori-likealgorithms. However, the database still needs tobe scanned twice to get the FP-tree. This can be verytime-consuming when new data are added to an existingdatabase because two scans may be needed for not only thenew data but also the existing data. This paper presentsa new data structure P-tree, Pattern Tree, and a new technique,which can get the P-tree through only one scan of thedatabase and can obtain the corresponding FP-tree with aspecified support threshold. Updating a P-tree with newdata needs one scan of the new data only, and the existingdata do not need to be re-scanned.

#index 629682
#* Adaptive Parallel Sentences Mining from Web Bilingual News Collection
#@ Bing Zhao;Stephan Vogel
#t 2002
#c 18
#! In this paper a robust, adaptive approach for miningparallel sentences from a bilingual comparable newscollection is described. Sentence length models andlexicon-based models are combined under a maximumlikelihood criterion. Specific models are proposed to handleinsertions and deletions that are frequent in bilingualdata collected from the web. The proposed approach isadaptive, updating the translation lexicon iteratively usingthe mined parallel data to get better vocabulary coverageand translation probability parameter estimation.Experiments are carried out on 10 years of Xinhuabilingual news collection. Using the mined data, we getsignificant improvement in word-to-word alignment accuracyin machine translation modeling.

#index 629683
#* Evaluating the Utility of Statistical Phrases and Latent Semantic Indexing for Text Classification
#@ Huiwen Wu;Dimitrios Gunopulos
#t 2002
#c 18
#! The term-based vector space model is a prominenttechnique to retrieve textual information. In this paper weexamine the usefulness of phrases as terms in vector-baseddocument classification. We focus on statistical techniquesto extract both adjacent and window phrases fromdocuments. We discover that the positive effect of addingphrase terms is very limited, if we have already achievedgood performance using single-word terms, even whenSVD/LSI is used as dimensionality reduction method.

#index 629684
#* Maintenance of Sequential Patterns for Record Modification Using Pre-large Sequences
#@ Ching-Yao Wang;Tzung-Pei Hong;Shian-Shyong Tseng
#t 2002
#c 18
#! In the past, we proposed incremental miningalgorithms for maintenance of sequential patterns basedon the concept of pre-large sequences as records wereinserted or deleted. Although maintenance of sequentialpatterns for record modification can be performed byusage of the deletion procedure and then the insertionprocedure, twice computation time of a single procedureis needed. In this paper, we thus attempt to apply theconcept of pre-large sequences to maintain sequentialpatterns as records are modified. The proposed algorithmdoes not require rescanning original databases until theaccumulative amount of modified customer sequencesexceeds a safety bound derived by pre-large concept. Asdatabases grow larger, the numbers of modified customersequences allowed before database rescanning isrequired also grow.

#index 629685
#* A Comparative Study of RNN for Outlier Detection in Data Mining
#@ Graham Williams;Rohan Baxter;Hongxing He;Simon Hawkins;Lifang Gu
#t 2002
#c 18
#! We have proposed replicator neural networks (RNNs)for outlier detection [8]. Here we compare RNN for outlierdetection with three other methods using both publiclyavailable statistical datasets (generally small) and datamining datasets (generally much larger and generally realdata). The smaller datasets provide insights into the relativestrengths and weaknesses of RNNs. The larger datasetsparticularly test scalability and practicality of application.

#index 629686
#* Improving Medical/Biological Data Classification Performance by Wavelet Preprocessing
#@ Qi Li;Tao Li;Shenghuo Zhu;Chandra Kambhamettu
#t 2002
#c 18
#! Many real-world datasets contain noise and noisecould degrade the performances of learning algorithms.Motivated from the success of wavelet denoisingtechniques in image data, we explore a generalsolution to alleviate the effect of noisy databy wavelet preprocessing for medical/biological dataclassification. Our experiments are divided into twocategories: one is of different classification algorithmson a specific database (Ecoli [6]) and the other isof a specific classification algorithm (decision tree)on different databases. The experiment results showthat the wavelet denoising of noisy data is able to improvethe accuracies of those classification methods,if the localities of the attributes are strong enough.

#index 629687
#* Exploring the Parameter State Space of Stacking
#@ Alexander K. Seewald
#t 2002
#c 18
#! Ensemble learning schemes are a new field in data mining.While current research concentrates mainly on improvingthe performance of single learning algorithms, an alternativeis to combine learners with different biases. Stackingis the best-known such scheme which tries to combine learners'predictions or confidences via another learning algorithm.However, the adoption of Stacking into the data mining communityis hampered by its large parameter space, consistingmainly of other learning algorithms: (1) the set of learning algorithmsto combine, (2) the meta-learner responsible for thecombining and (3) the type of meta-data to use: confidencesor predictions. None of these parameters are obvious choices.Furthermore, little is known about the relation between parametersettings and performance of Stacking. By exploring all ofStacking's parameter settings and their interdependencies, weintend make Stacking a suitable choice for mainstream datamining applications.

#index 629688
#* On Evaluating Performance of Classifiers for Rare Classes
#@ Mahesh V. Joshi
#t 2002
#c 18
#! Predicting rare classes effectively is an important problem.The definition of effective classifier, embodied in theclassifier evaluation metric, is however very subjective, dependenton the application domain. In this paper, a widevariety of point-metrics are put into a common analyticalcontext defined by the recall and precision of the target rareclass. This enables us to compare various metrics in an objective,domain-independent manner. We judge their suitabilityfor the rare class problems along the dimensions oflearning difficulty and levels of rarity. This yields manyvaluable insights. In order to address the goal of achievingbetter recall and precision, we also propose a way ofcomparing classifiers directly based on the relationships betweenrecall and precision values. It resorts to a compositepoint-metric only when recall-precision based comparisonsyield conflicting results.

#index 629689
#* ESRS: A Case Selection Algorithm Using Extended Similarity-based Rough Sets
#@ Liqiang Geng;Howard J. Hamilton
#t 2002
#c 18
#! A case selection algorithm selects representative casesfrom a large data set for future case-based reasoningtasks. This paper proposes the ESRS algorithm, based onextended similarity-based rough set theory, which selectsa reasonable number of the representative cases whilemaintaining satisfactory classification accuracy. It alsocan handle noise and inconsistent data. Experimentalresults on synthetic and real sets of cases showed that itspredictive accuracy is similar to that of well-knownmachine learning systems on standard data sets, while ithas the advantage of being applicable to any data setwhere a similarity function can be defined.

#index 629690
#* Neighborgram Clustering Interactive Exploration of Cluster Neighborhoods
#@ Michael R. Berthold;Bernd Wiswedel;David E. Patterson
#t 2002
#c 18
#! We describe an interactive way to generate a set of clustersfor a given data set. The clustering is done by constructinglocal histograms, which can then be used to visualize,select, and fine-tune potential cluster candidates.The accompanying algorithmcan also generate clusters automatically,allowing for an automatic or semi-automaticclustering process where the user only occasionally interactswith the algorithm. We illustrate the ability to automaticallyidentify and visualize clusters using NCI's AIDSAntiviral Screen data set.

#index 629691
#* Toward XML-Based Knowledge Discovery Systems
#@ Rosa Meo;Giuseppe Psaila
#t 2002
#c 18
#! Inductive databases are intended to be general purposedatabases in which both source data and mined patterns canbe represented, retrieved and manipulated; however, theheterogeneity of models for mined patterns makes difficult torealize them. In this paper, we explore the feasibility of usingXML as the unifying framework for inductive databases,introducing a suitable data model called XDM (XML forData Mining). XDM is designed to describe source rawdata, heterogeneous mined patterns and data mining statements,so that they can be stored inside a unique XML-basedinductive database.

#index 629692
#* Concept Tree Based Clustering Visualization with Shaded Similarity Matrices
#@ Jun Wang;Bei Yu;Les Gasser
#t 2002
#c 18
#! One of the problems with existing clustering methods isthat the interpretation of clusters may be difficult. Two differentapproaches have been used to solve this problem:conceptual clustering in machine learning and clusteringvisualization in statistics and graphics. The purpose of thispaper is to investigate the benefits of combining clusteringvisualization and conceptual clustering to obtain bettercluster interpretations. In our research we have combinedconcept trees for conceptual clustering with shaded similaritymatrices for visualization. Experimentation shows thatthe two interpretation approaches can complement eachother to help us understand data better.

#index 629693
#* Clustering Spatial Data when Facing Physical Constraints
#@ Osmar R. Zaïane;Chi-Hoon Lee
#t 2002
#c 18
#! Clustering spatial data is a well-known problem that hasbeen extensively studied to find hidden patterns or meaningfulsub-groups and has many applications such as satelliteimagery, geographic information systems, medical imageanalysis, etc. Although many methods have been proposedin the literature, very few have considered constraintssuch that physical obstacles and bridges linking clustersmay have significant consequences on the effectiveness ofthe clustering. Taking into account these constraints duringthe clustering process is costly, and the effective modeling ofthe constraints is of paramount importance for good performance.In this paper, we define the clustering problem in thepresence of constraints - obstacles and crossings - and investigateits efficiency and effectiveness for large databases.In addition, we introduce a new approach to model theseconstraints to prune the search space and reduce the numberof polygons to test during clustering. The algorithmDBCluC we present detects clusters of arbitrary shape andis insensitive to noise and the input order. Its average runningcomplexity is O(NlogN) where N is the number of dataobjects.

#index 629694
#* \Delta B + Tree: Indexing 3D Point Sets for Pattern Discovery
#@ Xiong Wang
#t 2002
#c 18
#! Three-dimensional point sets can be used to representdata in different domains. Given a database of 3D pointsets, pattern discovery looks for similar subsets that occurin multiple point sets. Geometric hashing proved to be aneffective technique in discovering patterns in 3D point sets.However, there are also known shortcomings. We proposea new indexing technique called \Delta B+Trees. It is an extensionof B+-Trees that stores point triplet information. Itovercomes the shortcomings of the geometric hashing technique.We introduce four different ways of constructing thekey from a triplet. We give analytical comparison betweenthe new index structure and the geometric hashing technique.We also conduct experiments on both synthetic dataand real data to evaluate the performance.

#index 629695
#* Using Sequential and Non-Sequential Patterns in Predictive Web Usage Mining Tasks
#@ Bamshad Mobasher;Honghua Dai;Tao Luo;Miki Nakagawa
#t 2002
#c 18
#! We describe an efficient framework for Web personalizationbased on sequential and non-sequential pattern discov-eryfrom usage data. Our experimental results performedon real usage data indicate that more restrictive patterns,such as contiguous sequential patterns (e.g., frequent navigationalpaths) are more suitable for predictive tasks, suchas Web prefetching, which involve predicting which item isaccessed next by a user), while less constrained patterns,such as frequent itemsets or general sequential patterns aremore effective alternatives in the context of Web personalizationand recommender systems.

#index 629696
#* Intersection Based Generalization Rules for the Analysis of Symbolic Septic Shock Patient Data
#@ Jürgen Paetz
#t 2002
#c 18
#! In intensive care units much data is irregularly recorded.Here, we consider the analysis of symbolic septic shock patientdata. We show that it could be worth consideringthe generalization paradigm (individual cases generalizedto more general rules) instead of the association paradigm(combining single attributes) when considering very individualcases (e.g. patients) and when expecting longer rulesthan shorter ones. We present an algorithm for rule generationand classification based on heuristically generatedset-based intersections. We demonstrate the usefulness ofour algorithm by analysing our septic shock patient data.

#index 629697
#* FD_Mine: Discovering Functional Dependencies in a Database Using Equivalences
#@ Hong Yao;Howard J. Hamilton;Cory J. Butz
#t 2002
#c 18
#! The discovery of FDs from databases has recentlybecome a significant research problem. In this paper, wepropose a new algorithm, called FD_Mine. FD_Minetakes advantage of the rich theory of FDs to reduce boththe size of the dataset and the number of FDs to bechecked by using discovered equivalences. We show thatthe pruning does not lead to loss of information.Experiments on 15 UCI datasets show that FD_Mine canprune more candidates than previous methods.

#index 629698
#* Mining Surveillance Video for Independent Motion Detection
#@ Zhongfei (Mark) Zhang
#t 2002
#c 18
#! This paper addresses the special applications of datamining techniques in homeland defense. The problemtargeted, which is frequently encountered in military/intelligence surveillance, is to mine a massive surveillancevideo database automatically collected to retrieve theshots containing independently moving targets. A novelsolution to this problem is presented in this paper, whichoffers a completely qualitative approach to solving for theautomatic independent motion detection problem directlyfrom the compressed surveillance video in a faster thanrealtime mining performance. This approach is based onthe linear system consistency analysis, and consequentlyis called QLS. SincetheQLS approach only focuses onwhat exactly is necessary to compute a solution, it savesthe computation to a minimum and achieves the efficacy tothe maximum. Evaluations from real data show that QLSdelivers effective mining performance at the achieved efficiency.

#index 629699
#* Optimal Projections of High Dimensional Data
#@ Emilio Corchado;Colin Fyfe
#t 2002
#c 18
#! In this paper, we compare two artificial neuralnetwork algorithms for performing ExploratoryProjection Pursuit, a statistical technique forinvestigating data by projecting it onto lower dimensionalmanifolds. The neural networks are extensions of anetwork which performs Principal Component Analysis.We illustrate the technique on artificial data beforeapplying it to real data.

#index 629700
#* A New Algorithm for Learning Parameters of a Bayesian Network from Distributed Data
#@ R. Chen;K. Sivakumar
#t 2002
#c 18
#! We present a novel approach for learning parametersof a Bayesian network from distributed heterogeneousdataset. In this case, the whole dataset is distributedin several sites and each site contains observations fora different subset of features. The new method usesthe collective learning approach proposed in our earlierwork and substantially reduces the computational andtransmission overhead. Theoretical analysis is givenand experimental results are provided to illustrate theaccuracy and efficiency of our method.

#index 629701
#* Extraction Techniques for Mining Services from Web Sources
#@ Hasan Davulcu;Saikat Mukherjee;I. V. Ramakrishnan
#t 2002
#c 18
#! The Web has established itself as the dominantmedium for doing electronic commerce. Consequentlythe number of service providers, bothlarge and small, advertising their services on theweb continues to proliferate. In this paper we describenew extraction algorithms for mining servicedirectories from web pages. We develop anovel propagation technique for identifying andaccumulating all of the attributes related to a serviceentity in a web page. We provide experimentalresults of the effectiveness of our extractiontechniques by mining a database of veterinarianservice providers from web sources.

#index 629702
#* Implementation of a Least Fixpoint Operator for Fast Mining of Relational Databases
#@ Hasan M. Jamil
#t 2002
#c 18
#! Recent research has focused on computing large item sets for association rule mining using SQL3 least fixpoint computation, and by exploiting the monotonic nature of the SQL3 aggregate functions such as sum and create view recursive constructs.Such approaches allow us to view mining as an ad hoc querying exercise and treat the efficiency issue as an optimization problem.In this paper, we present a recursive implementation of a recently proposed least fixpoint operator for computing large item sets from object-relational databases.We present experimental evidence to show that our implementation compares well with several well-regarded and contemporary algorithms for large item set generation.

#index 629703
#* Considering Both Intra-Pattern and Inter-Pattern Anomalies for Intrusion Detection
#@ Ning Jiang;Kien A. Hua;Simon Sheu
#t 2002
#c 18
#! Various approaches have been proposed to discoverpatterns from system call trails of UNIX processes tobetter model application behavior. However, thesetechniques only consider relationship between systemcalls (or system audit events). In this paper, we firstrefine the definition of maximal patterns given in [8] andprovide a pattern extraction algorithm to identify suchmaximal patterns. We then add one additional dimensionto the problem domain by also taking into considerationthe overlap relationship between patterns. We argue thatan execution path of an application is usually not anarbitrary combination of various patterns; but rather,they overlap each other in some specific order. Suchoverlap relationship characterizes the normal behavior ofthe application. Finally, a novel pattern matchingmodule is proposed to detect intrusions based on bothintra-pattern and inter-pattern anomalies. We test thisidea using the data sets obtained from the University ofNew Mexico. The experimental results indicate that ourscheme detect significantly more anomalies than thescheme presented in [8] while maintaining a very lowfalse alarm rate.

#index 629704
#* Generating an informative cover for association rules
#@ Laurentiu Cristofor;Dan Simovici
#t 2002
#c 18
#! Mining association rules may generate a large numbersof rules making the results hard to analyze manually.Pasquier et al. have discussed the generation of Guigues-Duquenne-Luxenburger basis (GD-L basis). Using a similarapproach, we introduce a new rule of inference anddefine the notion of association rules cover as a minimalset of rules that are non-redundant with respect to this newrule of inference. Our experimental results (obtained usingboth synthetic and real data sets) show that our coversare smaller than the GD-L basis and they are computed intime that is comparable to the classic Apriori algorithm forgenerating rules.

#index 629705
#* Exploring Interestingness Through Clustering: A Framework
#@ Sigal Sahar
#t 2002
#c 18
#! Determining interestingness is a notoriously difficultproblem: it is subjective and elusive to capture. It is alsobecoming an increasingly more important problem in KDDas the number of mined patterns increases. In this work weintroduce and investigate a framework for association ruleclustering that enables automating much of the laboriousmanual effort normally involved in the exploration and understandingof interestingness. Clustering is ideally suitedfor this task; it is the unsupervised organization of patternsinto groups, so that patterns in the same group are moresimilar to each other than to patterns in other groups. Wealso define a data-driven inferred labeling of these clusters,the ancestor coverage, which provides an intuitive, conciserepresentation of the clusters.

#index 629706
#* Reviewing RELIEF and its Extensions: A new Approach for Estimating Attributes considering high-correlated Features
#@ Raquel Flórez-López
#t 2002
#c 18
#! RELIEF algorithm [4], [5] and its extensions [8], [9]are some of the most known filter methods for estimatingthe quality of attributes in classification problems dealingwith both dependent and independent features. Thesemethods attend to find all meaningful features for eachproblem (both weakly and strongly ones [6]) so they areusually employed like a first stage for detecting irrelevantattributes. Nevertheless, in this paper we checked thatRELIEF-family algorithms present some importantlimitations that could distort the selection of the finalfeatures' subset, specially in the presence of high-correlatedattributes. To overcome these difficulties, anew approach has been developed (WACSA algorithm),which performance and validity are verified on well-knowndata sets.

#index 629707
#* Mining Associated Implication Networks: Computational Intermarket Analysis
#@ Phil Tse;Jiming Liu
#t 2002
#c 18
#! Current attempts to analyze international financialmarkets include the use of financial technical analysis anddata mining techniques. In this paper, we propose a newapproach that incorporates implication networks andassociation rules to form an associated network structure.The proposed approach explicitly addresses the issue oflocal vs. global influences between financial markets.

#index 629708
#* gSpan: Graph-Based Substructure Pattern Mining
#@ Xifeng Yan;Jiawei Han
#t 2002
#c 18
#! We investigate new approaches for frequent graph-basedpattern mining in graph datasets and propose a novel algorithmcalled gSpan (graph-based Substructure pattern mining),which discovers frequent substructures without candidategeneration. gSpan builds a new lexicographic orderamong graphs, and maps each graph to a unique minimumDFS code as its canonical label. Based on this lexico-graphicorder, gSpan adopts the depth-first search strategyto mine frequent connected subgraphs efficiently. Our performancestudy shows that gSpan substantially outperformsprevious algorithms, sometimes by an order of magnitude.

#index 629709
#* Wavelet Based UXO Detection
#@ S. Hodgson;N. Dunstan;R. Murison
#t 2002
#c 18
#! The detection and classification of Unexploded Ordnance(UXO) is considered a multi-dimensional pattern recognitionproblem. Standard techniques in solving multi-dimensionaldetection and classification problems involveusing large sets of templates or libraries. This paper showsthat by using Wavelet Transformation a single library willallow a particular class of ordnance to be classified over arange of depths.

#index 629710
#* Learning from Order Examples
#@ Toshihiro Kamishima;Shotaro Akaho
#t 2002
#c 18
#! We advocate a new learning task that deals with ordersof items, and we call this the Learning from Order Examples(LOE) task. The aim of the task is to acquire the rule thatis used for estimating the proper order of a given unordereditem set. The rule is acquired from training examples thatare ordered item sets. We present several solution methodsfor this task, and evaluate the performance and the characteristicsof these methods based on the experimental resultsof tests using both artificial data and realistic data.

#index 629711
#* Mixtures of ARMA Models for Model-Based Time Series Clustering
#@ Yimin Xiong;Dit-Yan Yeung
#t 2002
#c 18
#! Clustering problems are central to many knowledge discoveryand data mining tasks. However, most existing clusteringmethods can only work with fixed-dimensional representationsof data patterns. In this paper, we study the clusteringof data patterns that are represented as sequencesor time series possibly of different lengths. We propose amodel-based approach to this problem using mixtures of autoregressivemoving average (ARMA) models. We derive anexpectation-maximization (EM) algorithm for learning themixing coefficients as well as the parameters of the componentmodels. Experiments were conducted on simulatedand real datasets. Results show that our method comparesfavorably with another method recently proposed by othersfor similar time series clustering problems.

#index 629712
#* On Incorporating Subjective Interestingness Into the Mining Process
#@ Sigal Sahar
#t 2002
#c 18
#! Subjective interestingness is at the heart of thesuccessful discovery of association rules. To determine what is subjectively interesting, users' domainknowledge must be applied. [7] introduced an approach that requires very little domain knowledgeand inter action to eliminate the majority of therules that are subjectively not interesting. In thispaper we investigate how this approach can be incorporated into the mining process, the benefits anddisadvantages of doing so, and examine the resultsof its application to real databases.

#index 629713
#* Ensemble Modeling Through Multiplicative Adjustment of Class Probability
#@ Se June Hong;Jonathan Hosking;Ramesh Natarajan
#t 2002
#c 18
#! We develop a new concept for aggregating items of evidencefor class probability estimation. In Naïve Bayes, eachfeature contributes an independent multiplicative factor tothe estimated class probability. We modify this model to includean exponent in each factor in order to introduce fea-tureimportance. These exponents are chosen to maximizethe accuracy of estimated class probabilities on the trainingdata. For Naïve Bayes, this modification accomplishes morethan what feature selection can. More generally, since theindividual features can be the outputs of separate probabilitymodels, this yields a new ensemble modeling approach,which we call APM (Adjusted Probability Model), alongwith a regularized version called APMR.

#index 629714
#* Message from the Conference Chairs and Program Chairs
#@ 
#t 2002
#c 18

#index 629715
#* Discovery of Interesting Association Rules from Livelink Web Log Data
#@ Xiangji Huang;Aijun An;Nick Cercone;Gary Promhouse
#t 2002
#c 18
#! We present our experience in mining web usage patternsfrom a large collection of Livelink log data. Livelink is aweb-based product of Open Text, which provides automaticmanagement and retrieval of different types of informationobjects over an intranet or extranet. We report our experiencein preprocessing raw log data and post-processing themining results for finding interesting rules. In particular,we compare and evaluate a number of rule interestingnessmeasures and find that two of the measures that have notbeen used in association rule learning work very well.

#index 629716
#* Experimentation and Self Learning in Continuous Database Marketing
#@ James E. Pearce;Geoffrey I. Webb;Robin N. Shaw;Brian Garner
#t 2002
#c 18
#! We present a method for continuous database marketingthat identifies target customers for a number of marketingoffers using predictive models. The algorithm thenselects the appropriate offer for the customer. Experimentaldesign principles are encapsulated to capturemore information that will be used to monitor and refinethe predictive models. The updated predictive models arethen used for the next round of marketing offers.

#index 629717
#* Mining Optimal Actions for Profitable CRM
#@ Charles X. Ling;Tielin Chen;Qiang Yang;Jie Cheng
#t 2002
#c 18
#! Data mining has been applied to CRM (Customer RelationshipManagement) in many industries witha limitedsuccess.Most data mining tools can only discover customer modelsor profiles (such as customers who are likely attritors andcustomers who are loyal), but not actions that would improvecustomer relationship (such as changing attritors toloyal customers). We describe a novel algorithm that suggestsactions to change customers from an undesired status(such as attritors) to a desired one (such as loyal). Our algorithmtakes into account the cost of actions, and further,it attempts to maximize the expected net profit. To our bestknowledge, no data mining algorithms or tools today can accomplishthis important task in CRM. The algorithm is implemented,with many advanced features, in a specializedand highly effective data mining software called ProactiveSolution.

#index 629718
#* Demand Forecasting by the Neural Network with Discrete Fourier Transform
#@ Mariko Yohda;Makiko Saito-Arita;Akira Okada;Ryota Suzuki;Yoshitsugu Kakemoto
#t 2002
#c 18
#! This paper proposes a new demand forecastingmethod using the Neural Network and Fourier Transform.In this method, time series data of sales resultsconsidered as a combination of frequency aretransformed into several frequency data. They areidentified from objective indexes that consist of productproperties or economic indicators and so forth. Thismethod is efficient for demand forecasting aimed at newproducts that have no historical data.

#index 629719
#* webSPADE: A Parallel Sequence Mining Algorithm to Analyze Web Log Data
#@ Ayhan Demiriz
#t 2002
#c 18
#! Enterprise-class web sites receive a large amountof traffic, from both registered and anonymous users.Data warehouses are built to store and help analyze the click streams within this traffic to providecompanies with valuable insights into the behaviorof their customers. This article proposes a parallelsequence mining algorithm, webSPADE, to analyzethe click streams found in site web logs. In this process, raw web logs are first cleaned and inserted intoa data warehouse. The click streams are then minedby webSPADE. An innovative web-based front-endis used to visualize and query the sequence miningresults. The webSPADE algorithm is currently usedby Verizon to analyze the daily traffic of the Verizon.com web site.

#index 629720
#* Mining Online Users' Access Records for Web Business Intelligence
#@ Simon Fong;Serena Chan
#t 2002
#c 18
#! This paper discusses about how business intelligence on awebsite could be obtained from users' access recordsinstead of web logs of "hits". Users' access records arecaptured by implementing an Access-Control (AC)architectural model on the website. This model requiresusers to register their profiles in an exchange of apassword; and thereafter they have to login before gainingaccess to certain resources on the website. The links tothe resources on the website have been modified such thata record of information about the access would berecorded in the database when clicked. This way, data-miningcan be performed on a relatively clean set ofaccess records about the users. Hence, a good deal ofbusiness intelligence about the users' behaviors,preferences and about the popularities of the resources(products) on the website can be gained. In this paper, wealso discussed how the business intelligence acquired, inturn, can be used to provide e-CRM for the users.

#index 629721
#* Visually Mining Web User Clickpaths
#@ Teresa Mah;Ying Li
#t 2002
#c 18
#! As powerful as clickpath mining methods can be, theyoften lead to huge incomprehensible and non-interestingresult sets. Our clickpath mining practice at MSN wasfaced with challenges of keeping analysts closer to thedata exploration process, revealing powerful insight fromclickpath mining that business owners can directly actupon. These challenges stressed the importance of aninteractive and visual representation of clickpath miningresults. Most products today that can perform clickpathvisualization do so by presenting massive cross-weavingweb graphs. We present a new type of clickpathvisualization which focuses only on clickpaths of interest,simplifying the visualization space while still retaining thesame degree of mineable knowledge in the data. We alsodescribe visualization techniques we have used toenhance the detection of interesting clickpath patternsfrom data, and provide a real-life case study that hasbenefited from the use of our implemented clickpathvisualizer PAVE.

#index 629722
#* Telecommunications Strategic Marketing - KDD and Economic Modeling
#@ Stefano Cazzella;Luigi Dragone;Stefano M. Trisolini
#t 2002
#c 18
#! The Italian deregulation process of telecommunications market in the last years has produced a largeeconomic impact since it has altered equilibriums thatwere established for a long time. In this framework, wenotice a strong need for adequate tools to analyze themarket and its trends and, at the same time, a lack ofspecific solutions within the scientific literature, due tothe new technical challenges issued by the problem.In particular, in the context of building a DecisionSupport System (DSS) for the strategic marketing unit ofTELECOM Italia (TI) we have devised a newmethodology to profitably combine most powerful toolsfrom KDD and Economic Sciences. We have tested ourapproach by analyzing the residential telecommunicationsmarket demand in Italy during the transition from amonopolistic structure to an oligopolistic one.In this paper, we first address the state of the art inDSS design, then we describe the proposed methodologyand its application in the case study.

#index 659507
#* Welcome from the Steering Committee Chair
#@ 
#t 2001
#c 18

#index 659508
#* Closing the Loop: Heuristics for Autonomous Discovery
#@ 
#t 2001
#c 18
#! Autonomous discovery systems will be able to peruse very large databases more thoroughly than people can. In a companion paper [1], we describe a general frame-work for autonomous systems. We present and evaluate heuristics for use in this framework. Although these heuristics were designed for a prototype system, we believe they provide good initial solutions to problems encountered when implementing fully autonomous discovery systems. As such, these heuristics may be used as the starting point for future research into fully autonomousdiscovery systems.

#index 659509
#* Interestingness, Peculiarity, and Multi-database Mining
#@ 
#t 2001
#c 18
#! In order to discover new, surprising, interesting patterns hidden in data, peculiarity oriented mining and multi-database mining are required. In the paper, we introduce peculiarity rules as new class of rules, which can be discovered from relatively low number of peculiar data by searching the relevance among the peculiar data. We give formal interpretation and comparison of three classes of rules: association rules, exception rules, and peculiarityrules, as well as describe how to mine more interesting peculiarity rules in multiple databases.

#index 659510
#* Comparisons of Classification Methods for Screening Potential Compounds
#@ 
#t 2001
#c 18
#! We compare a number of data mining and statistical methods on the drug design problem of modeling molecular structure-activity relationships. The relationships can be use to identify active compounds base on their chemical structures from a large inventory of chemical compounds. The data set of this application has a highly skewed class distribution, in which only 2%of the compounds are considered active. We apply a number of classification methodsto this extremely imbalance data set and propose to use different performance measures to evaluate these methods. We report our findings on the characteristics of theperformance measures, the effect of using pruning techniques in this application and a comparison of local learning methodswith global techniques. We also investigate whetherreducing the imbalance in the training data by up-sampling or down-sampling would improve the predictive performance.

#index 727701
#* Proceedings of the Third IEEE International Conference on Data Mining
#@ 
#t 2003
#c 18

#index 727805
#* Findings from a Practical Project Concerning Web Usage Mining
#@ Frank Dellmann;Holger Wulff;Stefan Schmitz
#t 2003
#c 18
#% 255208
#% 420120
#% 420132
#% 420133
#% 711323
#! In a practical project a statistical analysis of the Weblog files of the domain www.volkswagen.de was carriedout by using the CRISP-DM procedure. For the preprocessingphase, more profound findings could be gainedthan are usually described in many studies. Since the aimwas to deduce significant statements while measuring theeffect, tests of significance for e-metrics were used inaddition to the commonly described procedure.

#index 727806
#* Mining Production Data with Neural Network & CART
#@ Mingkun Li;Shuo Feng;Ishwar K. Sethi;Jason Luciow;Keith Wagner
#t 2003
#c 18
#% 190581
#% 310579
#% 376589
#% 729437
#% 818916
#% 1860593
#% 1860659
#! This paper presents the preliminary results of a datamining study of a production line involving hundreds ofvariables related to mechanical, chemical, electrical andmagnetic processes involved in manufacturing coatedglass. The study was performed using two nonlinear,nonparametric approaches, namely neural network andCART, to model the relationship between the qualities ofthe coating and machine readings. Furthermore, neuralnetwork sensitivity analysis and CART variable rankingswere used to gain insight into the coating process. Ourinitial results show the promise of data mining techniquesto improve the production.

#index 727807
#* Detecting Patterns of Change Using Enhanced Parallel Coordinates Visualization
#@ Kaidi Zhao;Bing Liu;Thomas M. Tirpak;Andreas Schaller
#t 2003
#c 18
#% 25351
#% 65341
#% 136350
#% 286721
#% 436116
#% 481290
#% 481611
#% 727807
#! Analyzing data to find trends, correlations, and stablepatterns is an important problem for many industrialapplications. In this paper, we propose a new techniquebased on parallel coordinates visualization. Previous workon parallel coordinates methods has shown that they areeffective only when variables that are correlated and/orshow similar patterns are displayed adjacently. Althoughcurrent parallel coordinates tools allow the user tomanually rearrange the order of variables, this process isvery time-consuming when the number of variables islarge. Automated assistance is needed. This paperproposes an edit-distance based technique to rearrangevariables so that interesting patterns can be easilydetected. Our system, V-Miner, includes both automatedmethods for visualizing common patterns and a query toolthat enables the user to describe specific target patterns tobe mined/displayed by the system. Following an overviewof the system, a case study is presented to explain howMotorola engineers have used V-Miner to identifysignificant patterns in their product test and design data.

#index 727808
#* Text Mining for a Clear Picture of Defect Reports: A Praxis Report
#@ Jutta Kreyss;Steve Selvaggio;Michael White;Zach Zakharian
#t 2003
#c 18
#% 1306053
#! We applied the text mining categorization technology,in the publicly available, IBM Enterprise InformationPortal V8.1 to more than 15,000 customer reported,product problem records. We used a proven softwarequality category set to categorize these problem recordsinto different areas of interest. Our intent was to developa clear picture of potential areas for quality improvementin each of the software products reviewed, and to providethis information to development's management.The paper presents the benefits that can be gained fromcategorizing problem records, as well as the limitations.

#index 727809
#* Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks
#@ Rajat Gupta;B. V. L. Narayana;P. Krishna Reddy;G. V.  Ranga Rao;C. L. L. Gowda;Y. V. R. Reddy;G. Rama Murthy
#t 2003
#c 18
#% 356892
#% 818916
#! Insect pests are a major cause of crop loss globally. Pestmanagement will be effective and efficient if we canpredict the occurrence of peak activities of a given pest.Research efforts are going on to understand the pestdynamics by applying analytical and other techniques onpest surveillance data sets. In this study we make an effortto understand pest population dynamics using NeuralNetworks by analyzing pest surveillance data set ofHelicoverpa armigera or Pod borer on chickpea (Cicerarietinum L.) crop. The results show that neural networkmethod successfully predicts the pest attack incidences forone week in advance.

#index 727810
#* Applying Noise Handling Techniques to Genomic Data: A Case Study
#@ Choh Man Teng
#t 2003
#c 18
#% 136350
#% 385564
#% 449566
#% 466236
#% 471279
#% 516149
#% 543272
#! Osteogenesis Imperfecta (OI) is a genetic collagenousdisease associated with mutations in one or both of thegenes COLIA1 and COLIA2. There are at least four knownphenotypes of OI, of which type II is the severest and oftenlethal. We identified three approaches to noise handling,namely, robust algorithms, filtering, and polishing,and evaluated their effectiveness when applied to the problemof classifying the disease OI based on a data set ofamino acid sequences and associated information of pointmutations of COLIA1. Preliminary results suggest that eachnoise handling mechanism can be useful under different circumstances.Filtering is stable across all cases. Pruningwith robust c4.5 increased the classification accuracy insome cases, and polishing gave rise to some additional improvementin classifying the lethal OI phenotype.

#index 727811
#* Regulatory Element Discovery Using Tree-structured Models
#@ Tu Minh Phuong;Doheon Lee;Kwang Hyung Lee
#t 2003
#c 18
#% 328323
#! Computational discovery of transcriptional regulatoryregions in DNA sequences provides an efficient way tobroaden our understanding of how cellular processes arecontrolled. In this paper, we formulate the regulatoryelement discovery problem in the regression frameworkwith regulatory regions treated as predictor variables andgene expression levels as responses. We use regressiontree models to identify structural relationships betweenpredictors and responses. The regression treemethodology is extended to handle multiple responsesfrom different experiments by modifying the split function.We apply this method to two data sets of the yeastSaccharomyces cerevisiae. The method successfullyidentifies most of regulatory motifs that are known tocontrol gene transcription under the given experimentalconditions. Our method also suggests several putativemotifs that can present novel regulatory motifs.

#index 727812
#* Inference of Protein-Protein Interactions by Unlikely Profile Pair
#@ Byung-Hoon Park;George Ostrouchov;Gong-Xin Yu;Al Geist;Andrey Gorin;Nagiza F. Samatova
#t 2003
#c 18
#! We note that a set of statistically "unusual" protein-profilepairs in experimentally determined database ofprotein-protein interactions can typify protein-proteininteractions, and propose a novel method calledPICUPP that sifts such protein-profile pairs using astatistical simulation. It is demonstrated that unusualPfam and InterPro profile pairs can be extracted fromthe DIP database using a bootstrapping approach. Weparticularly illustrate that such protein-profile pairs canbe used for predicting putative pairs of interactingproteins. Their prediction accuracies are around 86%and 90% when InterPro and Pfam profiles are used,respectively at 75% confidence level.

#index 727813
#* Predicting distribution of a new forest disease using one-class SVMs
#@ Qinghua Guo;Maggi Kelly;Catherine Graham
#t 2003
#c 18
#% 190581
#% 302406
#% 571111
#% 855602
#% 1558464
#! In California, a newly discovered virulent pathogen(Phytophthora ramorum) has killed thousands of nativeoak trees. Mapping the potential distribution of thepathogen is essential for decision makers to assess therisk of the pathogen and aid in preventing its furtherspread. Most methods used to map potential ranges ofspecies (e.g. multivariate or logistic regression) requireboth presence and absence data, the latter of which is notalways feasibly collected. In this study, we present theone-class Support Vector Machine (SVM) to predict thepotential distribution of Sudden Oak Death in California.The model was developed using presence data collectedthroughout the state, and tested for accuracy using a 5-fold cross-validation approach. The model performedwell, and provided 91% predicted accuracy. We believeone-class SVM when coupled with GeographicalInformation Systems (GIS) will become a very usefulmethod to deal with presence-only data in ecologicalanalysis over a range of scales.

#index 727814
#* Mining Semantic Networks for Knowledge Discovery
#@ K. Rajaraman;Ah-Hwee Tan
#t 2003
#c 18
#% 2298
#% 111415
#% 286069
#% 815922
#! This paper addresses the problem of mining a class ofsemantic networks, called Concept Frame Graphs (CFG's),for knowledge discovery from text. This new representationis motivated by the need to capture richer text content sothat non-trivial mining tasks can be performed. We firstdefine the CFG representation and then describe a rule-basedalgorithm for constructing a CFG from text documents.Treating the CFG as a networked knowledge base,we propose new methods for text mining. On a specific taskof discovering the top companies in an area, we observe thatour approach leads to simpler content mining algorithms,once the CFG has been constructed. Moreover, exploitingthe network structure of CFG results in significant improvementsin precision and recall.

#index 727815
#* Protecting Sensitive Knowledge By Data Sanitization
#@ Stanley R.  M. Oliveira;Osmar R. Zaïane
#t 2003
#c 18
#% 428404
#% 539744
#% 586838
#% 635220
#! In this paper, we address the problem of protecting somesensitive knowledge in transactional databases. The challengeis on protecting actionable knowledge for strategicdecisions, but at the same time not losing the great benefitof association rule mining. To accomplish that, we introducea new, efficient one-scan algorithm that meets privacyprotection and accuracy in association rule mining, withoutputting at risk the effectiveness of the data mining per se.

#index 727816
#* Mining the Web to Discover the Meanings of an Ambiguous Word
#@ Raz Tamir;Reinhard Rapp
#t 2003
#c 18
#% 279755
#% 577285
#% 748550
#! In information retrieval and text mining, informationon word senses is usually taken from dictionaries or lexicaldatabases that have been prepared by lexicographers.In this paper we propose an automatic method for wordsense induction, i.e. for the discovery of a set of sensedescriptors to a given ambiguous word. The approach isbased on the statistics of word co-occurrence as derivedfrom web pages. The underlying assumption is that thesenses of an ambiguous word are best described by termsthat, although bearing a strong association to this word,are mutually exclusive, i.e. whose association strengthwithin the retrieved web pages is as weak as possible.Measuring association strength is based upon a novelConfidence Gain approach that relates the observed co-occurrencefrequency for two sense descriptor candidatesto an average co-occurrence frequency for pairs of arbitrarywords. The proposed approach is fully unsupervisedand takes into account the contemporary meanings ofwords, as reflected in texts from the internet. Our resultsare evaluated using a list of ambiguous words commonlyreferred to in the literature.

#index 727817
#* A Feature Selection Framework for Text Filtering
#@ Zhaohui Zheng;Rohini Srihari;Sargur Srihari
#t 2003
#c 18
#% 232653
#% 318412
#% 344447
#% 375017
#% 465754
#% 507844
#! This paper presents a new framework for local featureselection in text filtering. In this framework, a feature setis constructed per category by first selecting a set of termshighly indicative of membership (positive set) and anotherset of terms highly indicative of non-membership (negativeset), and then combining these two sets. This feature selectionframework not only unifies several standard featureselection methods, but also facilitates the proposal of a newmethod that optimally combines the positive and negativesets. The experimental comparison between the proposedmethod and standard methods was conducted on six featureselection metrics: chi-square, correlation coefficient, oddsratio, GSS coefficient and two proposed variants of odds ratioand GSS coefficient: OR-square and GSS-square respectively.The results show that the proposed feature selectionmethod improves text filtering performance.

#index 727818
#* Effectiveness of Information Extraction, Multi-Relational, and Semi-Supervised Learning for Predicting Functional Properties of Genes
#@ Mark-A. Krogel;Tobias Scheffer
#t 2003
#c 18
#% 252011
#% 345862
#% 398847
#% 466263
#% 550740
#% 727818
#% 1378224
#! We focus on the problem of predicting functional propertiesof the proteins corresponding to genes in the yeastgenome. Our goal is to study the effectiveness of approachesthat utilize all data sources that are availablein this problem setting, including unlabeled and relationaldata, and abstracts of research papers. We study transductionand co-training for using unlabeled data. We investigatea propositionalization approach which uses relationalgene interaction data. We study the benefit of informationextraction for utilizing a collection of scientific abstracts.The studied tasks are KDD Cup tasks of 2001 and 2002.The solutions which we describe achieved the highest scorefor task 2 in 2001, the fourth rank for task 3 in 2001, thehighest score for one of the two subtasks and the third placefor the overall task 2 in 2002.

#index 727819
#* Bootstrapping Rule Induction
#@ Lemuel R. Waitman;Douglas H. Fisher;Paul H. King
#t 2003
#c 18
#% 179770
#% 209021
#% 259022
#% 260149
#! Most rule learning systems posit hard decision boundariesfor continuous attributes and point estimates of ruleaccuracy, with no measures of variance, which may seemarbitrary to a domain expert. These hard boundaries/pointschange with small perturbations to the training data. Moreover,rule induction typically produces a large number ofrules that must be filtered and interpreted by an analyst.This paper describes a method of combining rules over multiplebootstrap replications of rule induction so as to reducethe total number of rules presented to an analyst and to providemeasures of variance to continuous attribute decisionboundaries and accuracy-point estimates. The method isillustrated with perioperative data.

#index 727820
#* SVM Based Models for Predicting Foreign Currency Exchange Rates
#@ Joarder Kamruzzaman;Ruhul A. Sarker;Iftekhar Ahmad
#t 2003
#c 18
#% 139070
#% 215698
#% 1860820
#% 1860822
#% 1860826
#! Support vector machine (SVM) has appeared as a powerfultool for forecasting forex market and demonstrated betterperformance over other methods, e.g., neural network orARIMA based model. SVM-based forecasting modelnecessitates the selection of appropriate kernel function andvalues of free parameters: regularization parameter and \varepsilon-insensitive loss function. In this paper, we investigate the effectof different kernel functions, namely, linear, polynomial, radialbasis and spline on prediction error measured by several widelyused performance metrics. The effect of regularizationparameter is also studied. The prediction of six different foreigncurrency exchange rates against Australian dollar has beenperformed and analyzed. Some interesting results are presented.

#index 727821
#* Objective and Subjective Algorithms for Grouping Association Rules
#@ Aijun An;Shakil Khan;Xiangji Huang
#t 2003
#c 18
#% 280485
#% 420118
#% 461909
#% 629715
#! We propose two algorithms for grouping and summarizingassociation rules. The first algorithm recursively groupsrules according to the structure of the rules and generatesa tree of clusters as a result. The second algorithm groupsthe rules according to the semantic distance between therules by making use of an autometically tagged semantictree-structured network of items. We provide a case study inwhich the proposed algorithms are evaluated. The resultsshow that our grouping methods are effective and producegood grouping results.

#index 727822
#* Improving Home Automation by Discovering Regularly Occurring Device Usage Patterns
#@ Edwin O. Heierman, III;Diane J. Cook
#t 2003
#c 18
#% 266223
#% 463903
#% 1769665
#! The data stream captured by recording inhabitant-deviceinteractions in an environment can be mined todiscover significant patterns, which an intelligent agentcould use to automate device interactions. However, thisknowledge discovery problem is complicated by severalchallenges, such as excessive noise in the data, data thatdoes not naturally exist as transactions, a need tooperate in real time, and a domain where frequency maynot be the best discriminator. In this paper, we propose anovel data mining technique that addresses thesechallenges and discovers regularly-occurringinteractions with a smart home. We also discuss a casestudy that shows the data mining technique can improvethe accuracy of two prediction algorithms, thusdemonstrating multiple uses for a home automationsystem. Finally, we present an analysis of the algorithmand results obtained using inhabitant interactions.

#index 727823
#* K-D Decision Tree: An Accelerated and Memory Efficient Nearest Neighbor Classifier
#@ Tomoyuki Shibata;Takekazu Kato;Toshikazu Wada
#t 2003
#c 18
#% 92533
#% 190581
#% 235377
#% 264161
#% 321455
#% 1273392
#! Most nearest neighbor (NN) classifiers employ NN searchalgorithms for the acceleration. However, NNclassification does not always require the NN search.Based on this idea, we propose a novel algorithm namedk-d decision tree (KDDT). Since KDDT uses Voronoicondensed prototypes, it is less memory consuming thannaive NN classifiers. We have confirmed that KDDT ismuch faster than NN search based classifiers through thecomparative experiment (from 9 to 369 times faster).

#index 727824
#* Semantic Role Parsing: Adding Semantic Structure to Unstructured Text
#@ Sameer Pradhan;Kadri Hacioglu;Wayne Ward;James H. Martin;Daniel Jurafsky
#t 2003
#c 18
#% 190581
#% 278107
#% 420129
#% 452991
#% 668807
#% 747738
#% 747891
#% 815808
#% 815893
#% 816200
#% 817420
#% 855271
#% 855273
#! There is a ever-growing need to add structure in the formof semantic markup to the huge amounts of unstructured textdata now available. We present the technique of shallow semanticparsing, the process of assigning a simple WHO didWHAT to WHOM, etc., structure to sentences in text, as auseful tool in achieving this goal. We formulate the semanticparsing problem as a classification problem using SupportVector Machines. Using a hand-labeled training setand a set of features drawn from earlier work together withsome feature enhancements, we demonstrate a system thatperforms better than all other published results on shallowsemantic parsing.

#index 727825
#* Interpretations of Association Rules by Granular Computing
#@ Yuefeng Li;Ning Zhong
#t 2003
#c 18
#% 100324
#% 443393
#% 443466
#% 501323
#% 1408629
#! This paper presents interpretations for associationrules. It first introduces Pawlak's method, and thecorresponding algorithm of finding decision rules (a kindof association rules). It then uses extended random sets topresent a new algorithm of finding interesting rules. Itproves that the new algorithm is faster than Pawlak'salgorithm. The extended random sets are easily to includemore than one criterion for determining interesting rules.They also provide two measures for dealing withuncertainties in association rules.

#index 727826
#* Using Discriminant Analysis for Multi-class Classification
#@ Tao Li;Shenghuo Zhu;Mitsunori Ogihara
#t 2003
#c 18
#% 51647
#% 80995
#% 105622
#% 190581
#% 212689
#% 269217
#% 272518
#% 324288
#% 342307
#% 397140
#% 430887
#% 551902
#% 722756
#% 730050
#% 1272365
#! Discriminant analysis is known to learn discriminativefeature transformations. This paper studies its use in multi-classclassification problems. The performance is tested ona large collection of benchmark datasets.

#index 727827
#* Model Stability: A key factor in determining whether an algorithm produces an optimal model from a matching distribution
#@ Kai Ming Ting;Regina Jing Ying Quek
#t 2003
#c 18
#% 136350
#% 331909
#% 443509
#% 464472
#% 466760
#% 727827
#! This paper investigates the factors leading to producingsuboptimal models when training and test class distributions(or misclassification costs) are matched. Our resultshows that model stability plays a key role in determiningwhether the algorithm produces an optimal modelfrom a matching distribution (cost). The performance differencebetween a model trained from the matching distribution(cost) and the optimal model generally increases asthe degree of model stability decreases. The practical implicationof our result is that one should only follow theconventional wisdom of using a training class distribution(cost) that matches the test class distribution (cost) to traina classifier if the learning algorithm is known to be stable.

#index 727828
#* Indexing and Mining Free Trees
#@ Yun Chi;Yirong Yang;Richard R. Muntz
#t 2003
#c 18
#% 27604
#% 408638
#% 481290
#% 577218
#% 727828
#! Tree structures are used extensively in domains such ascomputational biology, pattern recognition, computer networks,and so on. In this paper, we present an indexing techniquefor free trees and apply this indexing technique to theproblem of mining frequent subtrees. We first define a novelrepresentation, the canonical form, for rooted trees and extendthe definition to free trees. We also introduce anotherconcept, the canonical string, as a simpler representationfor free trees in their canonical forms. We then apply ourtree indexing technique to the frequent subtree mining problemand present FreeTreeMiner, a computationally efficientalgorithm that discovers all frequently occurring subtreesin a database of free trees. We study the performance andthe scalability of our algorithms through extensive experimentsbased on both synthetic data and datasets from tworeal applications: a dataset of chemical compounds and adataset of Internet multicast trees.

#index 727829
#* General MC: Estimating Boundary of Positive Class from Small Positive Data
#@ Hwanjo Yu
#t 2003
#c 18
#% 464641
#% 577235
#% 729621
#% 1279295
#! Single-Class Classification (SCC) seeks to distinguishone class of data from the universal set of multiple classes.We propose a SCC method called General MC that estimatesan accurate classification boundary of positive classfrom small positive data using the distribution of unlabeleddata. Our theoretical and empirical analyses show that,as long as the distribution of unlabeled data is not highlyskewed in the feature space, General MC significantly outperformsother recent SCC methods when the positive dataset is highly under-sampled.

#index 727830
#* Class Decomposition via Clustering: A New Framework for Low-Variance Classifiers
#@ Ricardo Vilalta;Murali-Krishna Achari;Christoph F. Eick
#t 2003
#c 18
#% 132583
#% 209021
#! We propose a pre-processing step to classification thatapplies a clustering algorithm to the training set to discoverlocal patterns in the attribute or input space. Wedemonstrate how this knowledge can be exploited to enhancethe predictive accuracy of simple classifiers. Our focusis mainly on classifiers characterized by high bias butlow variance (e.g., linear classifiers); these classifiers experiencedifficulty in delineating class boundaries over theinput space when a class distributes in complex ways. Decomposingclasses into clusters makes the new class distributioneasier to approximate and provides a viable way toreduce bias while limiting the growth in variance. Experimentalresults on real-world domains show an advantagein predictive accuracy when clustering is used as a pre-processingstep to classification.

#index 727831
#* Active Sampling for Feature Selection
#@ Sriharsha Veeramachaneni;Paolo Avesani
#t 2003
#c 18
#% 170649
#% 243727
#% 280437
#% 464268
#% 466887
#% 629616
#% 722929
#% 1272369
#% 1289273
#! In knowledge discovery applications, where new featuresare to be added, an acquisition policy can help select thefeatures to be acquired based on their relevance and thecost of extraction. This can be posed as a feature selectionproblem where the feature values are not known in advance.We propose a technique to actively sample the featurevalues with the ultimate goal of choosing between alternativecandidate features with minimum sampling cost.Our heuristic algorithm is based on extracting candidatefeatures in a region of the instance space where the featurevalue is likely to alter our knowledge the most. An experimentalevaluation on a standard database shows that it ispossible outperform a random subsampling policy in termsof the accuracy in feature selection.

#index 727832
#* Facilitating Fuzzy Association Rules Mining by Using Multi-Objective Genetic Algorithms for Automated Clustering
#@ Mehmet Kaya;Reda Alhajj
#t 2003
#c 18
#% 114994
#% 210160
#% 227953
#% 240200
#% 330327
#% 461909
#% 481281
#% 563975
#% 589686
#% 637609
#% 1777103
#! In this paper, we propose an automated clustering methodbased on multi-objective genetic algorithms (GA); the aim ofthis method is to automatically cluster values of a givenquantitative attribute to obtain large number of largeitemsets in low duration (time). We compare the proposedmulti-objective GA-based approach with CURE-basedapproach. In addition to the autonomous specification offuzzy sets, experimental results showed that the proposedautomated clustering exhibits good performance overCURE-based approach in terms of runtime as well as thenumber of large itemsets and interesting association rules.

#index 727833
#* Ensembles of Cascading Trees
#@ Jinyan Li;Huiqing Liu
#t 2003
#c 18
#% 136350
#% 209021
#% 312727
#% 400847
#% 424997
#% 727833
#! We introduce a new method, called CS4, to constructcommittees of decision trees for classification. The methodconsiders different top-ranked features as the root nodes ofmember trees. This idea is particularly suitable for dealingwith high-dimensional bio-medical data as top-ranked featuresin this type of data usually possess similar merits forclassification. To make a decision, the committee combinesthe power of individual trees in a weighted manner. UnlikeBagging or Boosting which uses bootstrapped trainingdata, our method builds all the member trees of a committeeusing exactly the same set of training data. We have testedthese ideas on UCI data sets as well as recent bio-medicaldata sets of gene expression or proteomic profiles that areusually described by more than 10,000 features. All the experimentalresults show that our method is efficient and thatthe classification performance are superior to C4.5 familyalgorithms.

#index 727834
#* Simple Estimators for Relational Bayesian Classifiers
#@ Jennifer Neville;David Jensen;Brian Gallagher
#t 2003
#c 18
#% 246831
#% 464304
#% 529493
#% 1273824
#% 1289267
#% 1393860
#! In this paper we present the Relational BayesianClassifier (RBC), a modification of the Simple BayesianClassifier (SBC) for relational data. There exist severalBayesian classifiers that learn predictive models ofrelational data, but each uses a different estimationtechnique for modeling heterogeneous sets of attributevalues. The effects of data characteristics on estimationhave not been explored. We consider four simpleestimation techniques and evaluate them on three real-worlddata sets. The estimator that assumes each multisetvalue is independently drawn from the same distribution(INDEPVAL) achieves the best empirical results. Weexamine bias and variance tradeoffs over a range of datasets and show that INDEPVAL's ability to model moremultiset information results in lower bias estimates andcontributes to its superior performance.

#index 727835
#* A Fast Algorithm for Computing Hypergraph Transversals and its Application in Mining Emerging Patterns
#@ James Bailey;Thomas Manoukian;Kotagiri Ramamohanarao
#t 2003
#c 18
#% 21137
#% 197754
#% 221328
#% 237200
#% 280409
#% 420062
#% 501540
#% 504526
#% 528704
#! Computing the minimal transversals of a hypergraph isan important problem in computer science that has significantapplications in data mining. In this paper, we present anew algorithm for computing hypergraph transversals andhighlight their close connection to an important class ofpatterns known as emerging patterns. We evaluate our techniqueon a number of large datasets and show that it out-performsprevious approaches by a factor of 9-29 times.

#index 727836
#* Tree-structured Partitioning Based on Splitting Histograms of Distances
#@ Longin Jan Latecki;Rajagopal Venugopal;Marc Sobel;Steve Horvath
#t 2003
#c 18
#% 136350
#% 315996
#% 361966
#% 375388
#! We propose a novel clustering algorithm that is similar in spiritto classification trees. The data is recursively split using a criterionthat applies a discrete curve evolution method to the histogramof distances. The algorithm can be depicted throughtree diagrams with triple splits. Leaf nodes represent eitherclusters or sets of observations that can not yet be clearly assignedto a cluster. After constructing the tree, unclassified datapoints are mapped to their closest clusters. The algorithm hasseveral advantages. First, it deals effectively with observationsthat can not be unambiguously assigned to a cluster by allowinga "margin of error". Second, it automatically determinesthe number of clusters; apart from the margin of error the useronly needs to specify the minimal cluster size but not the numberof clusters. Third, it is linear with respect to the number ofdata points and thus suitable for very large data sets. Experimentsinvolving both simulated and real data from differentdomains show that the proposed method is effective and efficient.

#index 727837
#* A Hybrid Data-Mining Approach in Genomics and Text Structures
#@ Horia-Nicolai Teodorescu;Lucian Iulian Fira
#t 2003
#c 18
#% 218077
#! We introduce a genetic sequence identifier based on ahierarchical system using fuzzy and classic (crisp) neuralnetworks. The system is based on a set of predictors andon a decision network. The prediction of the structure ofthe genes is addressed using a new method and tools,involving the sequence of distances between bases andneuro-fuzzy predictors. The method and system have beensuccessful in predicting genomic sequences and textstructures.

#index 727838
#* Information Theoretic Clustering of Sparse Co-Occurrence Data
#@ Inderjit S. Dhillon;Yuqiang Guan
#t 2003
#c 18
#% 115608
#% 309128
#% 397139
#% 629666
#% 722934
#% 729437
#! A novel approach to clustering co-occurrence data posesit as an optimization problem in information theory whichminimizes the resulting loss in mutual information. A divisiveclustering algorithm that monotonically reduces thisloss function was recently proposed. In this paper we showthat sparse high-dimensional data presents special challengeswhich can result in the algorithm getting stuck atpoor local minima. We propose two solutions to this problem:(a) a "prior" to overcome infinite relative entropy valuesas in the supervised Naive Bayes algorithm, and (b)local search to escape local minima. Finally, we combinethese solutions to get a robust algorithm that is computationallyefficient. We present experimental results to showthat the proposed method is effective in clustering documentcollections and outperforms previous information-theoreticclustering approaches.

#index 727839
#* The Hybrid Poisson Aspect Model for Personalized Shopping Recommendation
#@ Chun-Nan Hsu;Hao-Hsiang Chung;Han-Shen Huang
#t 2003
#c 18
#% 124010
#% 173879
#% 342594
#% 420117
#% 465928
#% 481290
#% 528182
#% 768664
#% 1650298
#% 1650569
#! Predicting an individual customer's likelihood of purchasinga specific item forms the basis of many marketingactivities, such as personalized shopping recommendation.Collaborative filtering and association rule miningcan be applied to this problem, but in retail supermarkets,the problem becomes particularly challenging because ofthe sparsity and skewness of transaction data. This paperpresents HyPAM(Hybrid Poisson Aspect Model), a newprobabilistic graphical model that combines a Poisson mixturewith a latent aspect class model to model customers'shopping behavior. We empirically compare HyPAM withtwo well-known recommenders, GroupLens (a correlation-basedmethod), and IBM SmartPad (association rules andcosine similarity). Experimental results show that HyPAMoutperforms the other recommenders by a large margin fortwo real-world retail supermarkets, ranking most of actualpurchases in the top ten percent of the most likely purchaseditems. We also present a new visualization method, rankplot, to evaluate the quality of recommendations.

#index 727840
#* Towards Simple, Easy-to-Understand, yet Accurate Classifiers
#@ Doina Caragea;Dianne Cook;Vasant G. Honavar
#t 2003
#c 18
#% 1211
#% 190581
#% 209021
#% 342618
#% 551723
#! We design a method for weighting linear support vectormachine classifiers or random hyperplanes, to obtain classifierswhose accuracy is comparable to the accuracy of anon-linear support vector machine classifier, and whose resultscan be readily visualized. We conduct a simulationstudy to examine how our weighted linear classifiers behavein the presence of known structure. The results show thatthe weighted linear classifiers might perform well comparedto the non-linear support vector machine classifiers, whilethey are more readily interpretable than the non-linear classifiers.

#index 727841
#* Links Between Kleinberg's Hubs and Authorities, Correspondence Analysis, and Markov Chains
#@ Francois Fouss;Marco Saerens;Jean-Michel Renders
#t 2003
#c 18
#% 224113
#% 290830
#% 340147
#% 1289272
#! In this work, we show that Kleinberg's hubs and authoritiesmodel is closely related to both correspondence analysis,a well-known multivariate statistical technique, and aparticular Markov chain model of navigation through theweb. The only difference between correspondence analysisand Kleinberg's method is the use of the average value ofthe hubs (authorities) scores for computing the authorities(hubs) scores, instead of the sum for Kleinberg's method.We also show that correspondence analysis and our Markovmodel are related to SALSA, a variant of Kleinberg's model.

#index 727842
#* An Algorithm for the Exact Computation of the Centroid of Higher Dimensional Polyhedra and its Application to Kernel Machines
#@ Frederic Maire
#t 2003
#c 18
#% 232214
#% 722761
#% 1860761
#! The Support Vector Machine (SVM) solution correspondsto the centre of the largest sphere inscribed in versionspace. Alternative approaches like Bayesian PointMachines (BPM) and Analytic Centre Machines have suggestedthat the generalization performance can be furtherenhanced by considering other possible centres of versionspace like the centroid (centre of mass) or the analytic centre.We present an algorithm to compute exactly the centroidof higher dimensional polyhedra, then derive approximationalgorithms to build a new learning machine whoseperformance is comparable to BPM. We also show that forregular kernel matrices (Gaussian kernels for example), theSVM solution can be obtained by solving a linear system ofequalities.

#index 727843
#* Icon-based Visualization of Large High-Dimensional Datasets
#@ Ping Chen;Chenyi Hu;Wei Ding;Heloise Lynn;Yves Simon
#t 2003
#c 18
#% 240337
#% 259620
#% 434539
#% 726070
#! High dimensional data visualization is critical todata analysts since it gives a direct view of originaldata. We present a method to visualize large amount ofhigh dimensional data. We divide dimensions of datainto several groups. Then, we use one icon to represent each group, and associate visual properties of eachicon with dimensions in each group. A high dimensional data record will be represented by multiple different types of icons located in the same position. Furthermore, we use summary icons to display local detailsof viewer's interests and the whole data set at meantime. We show its effectiveness and efficiency through a case study on a real large data set.

#index 727844
#* PixelMaps: A New Visual Data Mining Approach for Analyzing Large Spatial Data Sets
#@ Daniel A. Keim;Christian Panse;Mike Sips;Stephen C. North
#t 2003
#c 18
#% 259631
#% 477101
#% 619484
#% 818916
#! PixelMaps are a new pixel-oriented visual data miningtechnique for large spatial datasets. They combine kernel-density-based clustering with pixel-oriented displays to emphasizeclusters while avoiding overlap in locally densepoint sets on maps. Because a full evaluation of densityfunctions is prohibitively expensive, we also propose an efficientapproximation, Fast-PixelMap, based on a synthesisof the quadtree and gridfile data structures.

#index 727845
#* Efficient Mining of Frequent Subgraphs in the Presence of Isomorphism
#@ Jun Huan;Wei Wang;Jan Prins
#t 2003
#c 18
#% 466644
#% 478274
#% 479465
#% 577218
#% 629603
#% 629646
#% 629708
#% 1273674
#! Frequent subgraph mining is an active research topic inthe data mining community. A graph is a general modelto represent data and has been used in many domains likecheminformatics and bioinformatics. Mining patterns fromgraph databases is challenging since graph related operations,such as subgraph testing, generally have higher timecomplexity than the corresponding operations on itemsets,sequences, and trees, which have been studied extensively.In this paper, we propose a novel frequent subgraph miningalgorithm: FFSM, which employs a vertical search schemewithin an algebraic graph framework we have developedto reduce the number of redundant candidates proposed.Our empirical study on synthetic and real datasets demonstratesthat FFSM achieves a substantial performance gainover the current start-of-the-art subgraph mining algorithmgSpan.

#index 727846
#* Mining Frequent Itemsets in Distributed and Dynamic Databases
#@ M. E. Otey;C. Wang;S. Parthasarathy;A. Veloso;W. Meira, Jr.
#t 2003
#c 18
#% 420067
#% 443091
#% 464204
#% 632036
#% 727846
#! Traditional methods for frequent itemset mining typicallyassume that data is centralized and static. Such methods imposeexcessive communication overhead when data is distributed,and they waste computational resources when datais dynamic. In this paper we present what we believe to bethe first unified approach that overcomes these assumptions.Our approach makes use of parallel and incremental techniquesto generate frequent itemsets in the presence of dataupdates without examining the entire database, and imposesminimal communication overhead when mining distributeddatabases. Further, our approach is able to generate bothlocal and global frequent itemsets. This ability permits ourapproach to identify high-contrast frequent itemsets, whichallows one to examine how the data is skewed over differentsites.

#index 727847
#* Algorithms for Spatial Outlier Detection
#@ Chang-Tien Lu;Dechang Chen;Yufeng Kou
#t 2003
#c 18
#% 51647
#% 230138
#% 342638
#% 479791
#% 574284
#% 998623
#! A spatial outlier is a spatially referenced object whosenon-spatial attribute values are significantly different fromthe values of its neighborhood. Identification of spatial outlierscan lead to the discovery of unexpected, interesting,and useful spatial patterns for further analysis. One drawbackof existing methods is that normal objects tend to befalsely detected as spatial outliers when their neighborhoodcontains true spatial outliers. In this paper, we proposea suite of spatial outlier detection algorithms to overcomethis disadvantage. We formulate the spatial outlier detectionproblem in a general way and design algorithms whichcan accurately detect spatial outliers. In addition, usinga real-world census data set, we demonstrate that our approachescan not only avoid detecting false spatial outliersbut also find true spatial outliers ignored by existing methods.

#index 727848
#* Enhancing Techniques for Efficient Topic Hierarchy Integration
#@ Jyh-Jong Tsay;Hsuan-Yu Chen;Chi-Feng Chang;Ching-Han Lin
#t 2003
#c 18
#% 219052
#% 232653
#% 252403
#% 309141
#% 311034
#% 318412
#% 330767
#% 376266
#% 458379
#% 466078
#% 479817
#% 571073
#! In this paper, we study the problem of integrating documentsfrom different sources into a comprehensive topic hierarchy.Our objective is to develop efficient techniques thatimprove the accuracy of traditional categorization methodsby incorporating categorization information providedby data sources into categorization process. Notice thatin the World-Wide Web, categorization information is oftenavailable from information sources. We present severalenhancing techniques that use categorization informationto enhance traditional methods such as naive Bayes andsupport vector machines. Experiment on collections fromOpenfind and Yam, and Google and Yahoo!, well-knownpopular web sites in Taiwan and USA, respectively, showsthat our techniques significantly improve the classificationaccuracy from, for example, 55% to 66% for Naive Bayes,and from 57% to 67% for SVM for the data set collectedfrom Yam and Openfind.

#index 727849
#* Validating and Refining Clusters via Visual Rendering
#@ Keke Chen;Ling Liu
#t 2003
#c 18
#% 36672
#% 248790
#% 273890
#% 296738
#% 310526
#% 316704
#% 342601
#% 397597
#% 436509
#% 479799
#% 728371
#! The automatic clustering algorithms are known towork well in dealing with clusters of regular shapes, e.g.compact spherical/elongated shapes, but may incur highererror rates when dealing with arbitrarily shaped clusters.Although some efforts have been devoted to addressingthe problem of skewed datasets, the problem of handlingclusters with irregular shapes is still in its infancy,especially in terms of dimensionality of the datasets andthe precision of the clustering results considered. Notsurprisingly, the statistical indices works ineffective invalidating clusters of irregular shapes, too. In this paper,we address the problem of clustering and validatingarbitrarily shaped clusters with a visual framework(VISTA). The main idea of the VISTA approach is tocapitalize on the power of visualization and interactivefeedbacks to encourage domain experts to participate inthe clustering revision and clustering validation process.

#index 727850
#* Structure Search and Stability Enhancement of Bayesian Networks
#@ Hanchuan Peng;Chris Ding
#t 2003
#c 18
#% 44876
#% 129987
#% 212700
#% 240222
#% 277480
#% 443025
#% 722754
#% 1650279
#% 1650440
#! Learning Bayesian network structure from large-scale datasets, without any expert-specified ordering of variables, remainsa difficult problem. We propose systematic improvements toautomatically learn Bayesian network structure from data. (1)We propose a linear parent search method to generate candidategraph. (2) We propose a comprehensive approach to eliminatecycles using minimal likelihood loss, a short cycle first heuristic,and a cut-edge repairing. (3) We propose structure perturbationto assess the stability of the network and a stability-improvementmethod to refine the network structure. The algorithms are easyto implement and efficient for large networks. Experimental resultson two data sets show that our new approach outperformsexisting methods.

#index 727851
#* Tractable Group Detection on Large Link Data Sets
#@ Jeremy Kubica;Andrew Moore;Jeff Schneider
#t 2003
#c 18
#% 311027
#% 314054
#% 578775
#% 722904
#% 959438
#! Discovering underlying structure from co-occurrencedata is an important task in a variety of fields, including:insurance, intelligence, criminal investigation, epidemiology,human resources, and marketing.Previously Kubicaet. al. presented the group detection algorithm (GDA) - analgorithm for finding underlying groupings of entities fromco-occurrence data.This algorithm is based on a probabilisticgenerative model and produces coherent groups thatare consistent with prior knowledge.Unfortunately, the optimizationused in GDA is slow, potentially making it infeasiblefor many large data sets.To this end, we present k-groups - an algorithm that uses an approach similar tothat of k-means to significantly acclerate the discovery ofgroups while retaining GDA's probabilistic model.We comparethe performance of GDA and k-groups on a variety ofdata, showing that k-groups' sacrifice in solution quality issignificantly offset by its increase in speed.

#index 727852
#* Postprocessing Decision Trees to Extract Actionable Knowledge
#@ Qiang Yang;Jie Yin;Charles X. Ling;Tielin Chen
#t 2003
#c 18
#% 216499
#% 238794
#% 443086
#% 443313
#% 481290
#! Most data mining algorithms and tools stop at discoveredcustomer models, producing distribution informationon customer profiles. Such techniques, when applied to industrialproblems such as customer relationship management(CRM), are useful in pointing out customers who arelikely attritors and customers who are loyal, but they requirehuman experts to postprocess the mined information manually.Most of the postprocessing techniques have been limitedto producing visualization results and interestingnessranking, but they do not directly suggest actions that wouldlead to an increase the objective function such as profit. Inthis paper, we present a novel algorithm that suggest actionsto change customers from an undesired status (suchas attritors) to a desired one (such as loyal) while maximizingobjective function: the expected net profit. We developthese algorithms under resource constraints that areabound in reality. The contribution of the work is in takingthe output from an existing mature technique (decisiontrees, for example), and producing novel, actionable knowledgethrough automatic postprocessing.

#index 727853
#* A K-NN Associated Fuzzy Evidential Reasoning Classifier with Adaptive Neighbor Selection
#@ Hongwei Zhu;Otman Basir
#t 2003
#c 18
#% 310313
#! The paper presents a fuzzy evidential reasoning algorithmin light of the Dempster-Shafer evidence theory andthe K-nearest neighbor algorithm for pattern classification.Given an input pattern to be classified, each of its K nearestneighbors is viewed as an evidence source, in terms ofa fuzzy evidence structure. The distance between the inputpattern and each of its K nearest neighbors is usedfor mass determination while the contextual information ofthe nearest neighbor in the training sample space is formulatedby a fuzzy set in determining a fuzzy focal element.Therefore, pooling evidence provided by neighbors is realizedby a fuzzy evidential reasoning, where feature selectionis further considered through ranking and adaptive combinationof neighbors. A fast implementation scheme of thefuzzy evidential reasoning is also developed. Experimentalresults of classifying multi-channel remote sensing imageshave shown that the proposed approach outperforms the K-nearestneighbor (K-NN) algorithm [1], the fuzzy K-nearestneighbor (F-KNN) algorithm [2], the evidence-theoretic K-nearestneighbor (E-KNN) algorithm [3], and the fuzzy ex-tendedversion of E-KNN (FE-KNN) [4], in terms of theclassification accuracy and insensitivity to the number Kof nearest neighbors.

#index 727854
#* Comparing Pure Parallel Ensemble Creation Techniques Against Bagging
#@ Lawrence O. Hall;Kevin W. Bowyer;Robert E. Banfield;Divya Bhadoria;W. Philip Kegelmeyer;Steven Eschrich
#t 2003
#c 18
#% 73372
#% 136350
#% 209021
#% 256615
#% 290482
#% 312727
#% 400847
#% 424997
#% 452017
#% 562963
#! We experimentally evaluate randomization-based approachesto creating an ensemble of decision-tree classifiers.Unlike methods related to boosting, all of the eightapproaches considered here create each classifier in an ensembleindependently of the other classifiers. Experimentswere performed on 28 publicly available datasets, usingC4.5 release 8 as the base classifier. While each of the otherseven approaches has some strengths, we find that none ofthem is consistently more accurate than standard baggingwhen tested for statistical significance.

#index 727855
#* Combining the web content and usage mining to understand the visitor behavior in a web site
#@ Juan Velásquez;Hiroshi Yasuda;Terumasa Aoki
#t 2003
#c 18
#% 387427
#% 488554
#% 519555
#! A web site is a semi structured collection of differentkinds of data, whose motivation is show relevant informationto visitor and by this way capture her/his attention.Understand the specifics preferences that define the visitorbehavior in a web site, is a complex task. An approximationis suppose that it depend the content, navigationsequence and time spent in each page visited. These variablescan be extracted from the web log files and the website itself, using web usage and content mining respectively.Combining the describe variables, a similarity measureamong visitor sessions is introduced and used in a clusteringalgorithm, which identifies groups of similar sessions,allowing the analysis of visitors behavior.In order to prove the methodology's effectiveness, it wasapplied in a certain web site, showing the benefits of thedescribed approach.

#index 727856
#* Analyzing High-Dimensional Data by Subspace Validity
#@ Amihood Amir;Reuven Kashi;Nathan S. Netanyahu;Daniel Keim;Markus Wawryniuk
#t 2003
#c 18
#% 248792
#% 273891
#% 280407
#% 300131
#% 397384
#% 434613
#% 436509
#% 480669
#! We are proposing a novel method that makes it possibleto analyze high dimensional data with arbitrary shapedprojected clusters and high noise levels. At the core of ourmethod lies the idea of subspace validity. We map the datain a way that allows us to test the quality of subspaces usingstatistical tests. Experimental results, both on synthetic andreal data sets, demonstrate the potential of our method.

#index 727857
#* Pattern Discovery based on Rule Induction and Taxonomy Generation
#@ Shusaku Tsumoto;Shoji Hirano
#t 2003
#c 18
#% 136350
#% 168559
#% 275064
#% 404362
#% 1200254
#! One of the most important problems with rule inductionmethods is that they cannot extract rules, which plausiblyrepresent experts' decision processes. In this paper,the characteristics of experts' rules are closely examinedand a new approach to extract plausible rules is introduced,which consists of the following three procedures. First, thecharacterization of decision attributes (given classes) is extractedfrom databases and the concept hierarchy for givenclasses is calculated. Second, based on the hierarchy, rulesfor each hierarchical level are induced from data. Then, foreach given class, rules for all the hierarchical levels are integratedinto one rule.

#index 727858
#* Dimensionality Reduction Using Kernel Pooled Local Discriminant Information
#@ Peng Zhang;Jing Peng;Carlotta Domeniconi
#t 2003
#c 18
#% 266426
#% 309208
#% 485689
#% 857439
#! We study the use of kernel subspace methods for learninglow-dimensional representations for classification. We proposea kernel pooled local discriminant subspace methodand compare it against several competing techniques: generalizedFisher discriminant analysis (GDA) and kernelprincipal components analysis (KPCA) in classificationproblems. We evaluate the classification performance ofthe nearest-neighbor rule with each subspace representation.The experimental results demonstrate the efficacy ofthe kernel pooled local subspace method and the potentialfor substantial improvements over competing methods suchas KPCA in some classification problems.

#index 727859
#* Comparing Naive Bayes, Decision Trees, and SVM with AUC and Accuracy
#@ Jin Huang;Jingjing Lu;Charles X. Ling
#t 2003
#c 18
#% 53944
#% 80995
#% 136350
#% 292664
#% 420142
#% 420146
#% 464606
#% 466086
#% 566871
#% 580510
#% 1279288
#% 1378224
#% 1558464
#! Predictive accuracy has often been used as the mainand often only evaluation criterion for the predictive performanceof classification or data mining algorithms. Inrecent years, the area under the ROC (Receiver OperatingCharacteristics) curve, or simply AUC, has been proposedas an alternative single-number measure for evaluating performanceof learning algorithms. In our previous work, weproved that AUC is, in general, a better measure (definedprecisely) than accuracy. Many popular data mining algorithmsshould then be re-evaluated in terms of AUC. Forexample, it is well accepted that Naive Bayes and decisiontrees are very similar in accuracy. How do they compare inAUC? Also, how does the recently developed SVM (SupportVector Machine) compare to traditional learning algorithmsin accuracy and AUC? We will answer these questions inthis paper. Our conclusions will provide important guide-linesin data mining applications on real-world datasets.

#index 727860
#* Integrating Fuzziness into OLAP for Multidimensional Fuzzy Association Rules Mining
#@ Reda Alhajj;Mehmet Kaya
#t 2003
#c 18
#% 240200
#% 273898
#% 443310
#% 443427
#% 461921
#% 563975
#% 566140
#% 637609
#! This paper contributes to the ongoing research onmultidimensional online association rules mining byproposing a general architecture that utilizes a fuzzy datacube for knowledge discovery. Three different methods areintroduced to mine fuzzy association rules in the constructedfuzzy data cube, namely single dimension, multidimensionaland hybrid association rules mining. Experimental resultsobtained for each of the three methods on the adult data ofthe United States census in 2000 show their effectiveness andapplicability.

#index 727861
#* Ontologies Improve Text Document Clustering
#@ Andreas Hotho;Steffen Staab;Gerd Stumme
#t 2003
#c 18
#% 198058
#% 741080
#% 757276
#! Text document clustering plays an important role in providingintuitive navigation and browsing mechanisms by organizinglarge sets of documents into a small number ofmeaningful clusters. The bag of words representation usedfor these clustering methods is often unsatisfactory as it ignoresrelationships between important terms that do not co-occurliterally. In order to deal with the problem, we integratecore ontologies as background knowledge into theprocess of clustering text documents. Our experimentalevaluations compare clustering techniques based on pre-categorizationsof texts from Reuters newsfeeds and on asmaller domain of an eLearning course about Java. In theexperiments, improvements of results by background knowledgecompared to a baseline without background knowledgecan be shown in many interesting combinations.

#index 727862
#* Mining Relevant Text from Unlabelled Documents
#@ Daniel Barbará;Carlotta Domeniconi;Ning Kang
#t 2003
#c 18
#% 252011
#% 425047
#% 458379
#! Automatic classification of documents is an importantarea of research with many applications in the fields of documentsearching, forensics and others. Methods to performclassification of text rely on the existence of a sample of documentswhose class labels are known. However, in manysituations, obtaining this sample may not be an easy (oreven possible) task. In this paper we focus on the classificationof unlabelled documents into two classes: relevant andirrelevant, given a topic of interest. By dividing the set ofdocuments into buckets (for instance, answers returned bydifferent search engines), and using association rule miningto find common sets of words among the buckets, we can efficientlyobtain a sample of documents that has a large percentageof relevant ones. This sample can be used to trainmodels to classify the entire set of documents. We prove, viaexperimentation, that our method is capable of filtering relevantdocuments even in adverse conditions where the percentageof irrelevant documents in the buckets is relativelyhigh.

#index 727863
#* Center-Based Indexing for Nearest Neighbors Search
#@ Arkadiusz Wojna
#t 2003
#c 18
#% 252304
#% 321455
#% 481460
#% 939983
#% 1011871
#% 1013994
#! The paper addresses the problem of indexing data forthe k nearest neighbors (k-nn) search. It presents a tree-basedtop-down indexing method that uses an iterative k-meansalgorithm for tree node splitting and combines threedifferent search pruning criteria from BST, GHT and GNATinto one. The experiments show that the presented indexingtree accelerates the k-nn searching up to several thousandstimes in case of large data sets.

#index 727864
#* Fast PNN-based Clustering Using K-nearest Neighbor Graph
#@ Pasi Fränti;Olli Virmajoki;Ville Hautamäki
#t 2003
#c 18
#% 1854970
#% 1855044
#! Search for nearest neighbor is the main source ofcomputation in most clustering algorithms. We proposethe use of nearest neighbor graph for reducing thenumber of candidates. The number of distancecalculations per search can be reduced from O(N) to O(k)where N is the number of clusters, and k is the number ofneighbors in the graph. We apply the proposed schemewithin agglomerative clustering algorithm known as thePNN algorithm.

#index 727865
#* A User-driven and Quality-oriented Visualization for Mining Association Rules
#@ Julien Blanchard;Fabrice Guillet;Henri Briand
#t 2003
#c 18
#% 176999
#% 216508
#% 232108
#% 232136
#% 310520
#% 420101
#% 477786
#% 478119
#% 577214
#% 581572
#% 641130
#! On account of the enormous amounts of rules that canbe produced by data mining algorithms, knowledgevalidation is one of the most problematic steps in anassociation rule discovery process.In order to findrelevant knowledge for decision-making, the user needs toreally rummage through the rules.Visualization can bevery beneficial to support him/her in this task byimproving the intelligibility of the large rule sets andenabling the user to navigate inside them.In this article,we propose to answer the association rule validationproblem by designing a human-centered visualizationmethod for the rule rummaging task.This new approachbased on a specific rummaging model relies on ruleinterestingness measures and on interactive rule subsetfocusing and mining.We have implemented ourrepresentation by developing a first experimentalprototype called ARVis.

#index 727866
#* Privacy-Preserving Collaborative Filtering Using Randomized Perturbation Techniques
#@ Huseyin Polat;Wenliang Du
#t 2003
#c 18
#% 173879
#% 220711
#% 261357
#% 280852
#% 300184
#% 397153
#% 616944
#% 1650569
#! Collaborative Filtering (CF) techniques are becomingincreasingly popular with the evolution of the Internet. Toconduct collaborative filtering, data from customers areneeded. However, collecting high quality data from customersis not an easy task because many customers areso concerned about their privacy that they might decide togive false information. We propose a randomized perturbation(RP) technique to protect users' privacy while stillproducing accurate recommendations.

#index 727867
#* Impact Studies and Sensitivity Analysis in Medical Data Mining with ROC-based Genetic Learning
#@ Michèle Sebag;Jérôme Azé;Noël Lucas
#t 2003
#c 18
#% 190581
#% 207195
#% 270633
#% 280437
#% 349550
#% 464606
#% 465746
#% 466086
#% 1378224
#% 1389694
#! ROC curves have been used for a fair comparison of machinelearning algorithms since the late 90's. Accordingly,the area under the ROC curve (AUC) is nowadays considereda relevant learning criterion, accommodating imbalanceddata, misclassification costs and noisy data.This paper shows how a genetic algorithm-based optimizationof the AUC criterion can be exploited for impactstudies and sensitivity analysis.The approach is illustrated on the Atherosclerosis Identificationproblem, PKDD 2002 Challenge.

#index 727868
#* Frequent-Pattern based Iterative Projected Clustering
#@ Man Lung Yiu;Nikos Mamoulis
#t 2003
#c 18
#% 201893
#% 248792
#% 273891
#% 300120
#% 300131
#% 314054
#% 397384
#% 464888
#% 481290
#! Irrelevant attributes add noise to high dimensional clustersand make traditional clustering techniques inappropriate.Projected clustering algorithms have been proposed to findthe clusters in hidden subspaces. We realize the analogy betweenmining frequent itemsets and discovering the relevantsubspace for a given cluster. We propose a methodology forfinding projected clusters by mining frequent itemsets andpresent heuristics that improve its quality. Our techniquesare evaluated with synthetic and real data; they are scalableand discover projected clusters accurately.

#index 727869
#* CoMine: Efficient Mining of Correlated Patterns
#@ Young-Koo Lee;Won-Young Kim;Y. Dora Cai;Jiawei Han
#t 2003
#c 18
#% 227919
#% 299985
#% 300120
#% 452846
#% 466476
#% 481290
#! Association rule mining often generates a huge numberof rules, but a majority of them either are redundantor don not reflect the tue correlation relationship amongdata objects.In this paper, we re-examine this problemand show that two interesting measures, all_confidence(denoted as \alpha) and coherence (denoted as \gamma), both disclosegenuine correlation relationships and can be computedefficiently.Moreover, we propose two interestingalgorithms, CoMine(\alpha) and CoMine(\gamma), based onextensions of a pattern-growth methodology.Our performancestudy shows that the CoMine algorithms havehigh performance in comparison with their Apriori-basedcounterpart algorithms.

#index 727870
#* Efficient Subsequence Matching in Time Series Databases Under Time and Amplitude Transformations
#@ Tassos Argyros;Charis Ermopoulos
#t 2003
#c 18
#% 172949
#% 273704
#% 333941
#% 460862
#% 462231
#% 477479
#% 477968
#% 501658
#% 504158
#% 632089
#% 661026
#% 993965
#% 1562026
#! Subsequence matching in large time series databases hasattracted a lot of interest and many methods have been proposedthat cope with this problem in an adequate extend.However, locating subsequence matches of arbitrary length,under time and amplitude transformations, has received farless attention and is still an open problem. In this paperwe present an efficient algorithm for variable-length subsequencematching under transformations that guaranteesno false dismissals. Further, this algorithm uses a novelsimilarity criterion for determining similarity under amplitudetransformations in a most efficient way. Finally, ouralgorithm has been tested in various experiments on realdata, resulting in a running time improvement of one orderof magnitude compared to the naive approach.

#index 727871
#* Learning Rules for Anomaly Detection of Hostile Network Traffic
#@ Matthew V. Mahoney;Philip K. Chan
#t 2003
#c 18
#% 149237
#% 188026
#% 321553
#% 479177
#% 481290
#% 727871
#% 790040
#% 978633
#! We introduce an algorithm called LERAD that learnsrules for finding rare events in nominal time-series datawith long range dependencies. We use LERAD to findanomalies in network packets and TCP sessions to detectnovel intrusions. We evaluated LERAD on the 1999DARPA/Lincoln Laboratory intrusion detection evaluationdata set and on traffic collected in a universitydepartmental server environment.

#index 727872
#* Clustering Item Data Sets with Association-Taxonomy Similarity
#@ Ching-Huang Yun;Kun-Ta Chuang;Ming-Syan Chen
#t 2003
#c 18
#% 287285
#% 420081
#% 481290
#% 629638
#% 631985
#! We explore in this paper the efficient clustering of itemdata. Different from those of the traditional data, the featuresof item data are known to be of high dimensionalityand sparsity. In view of the features of item data, we devisein this paper a novel measurement, called the association-taxonomysimilarity, and utilize this measurement to performthe clustering. With this association-taxonomy similaritymeasurement, we develop an efficient clustering algorithm,called algorithm AT (standing for Association-Taxonomy),for item data. Two validation indexes basedon association and taxonomy properties are also devised toassess the quality of clustering for item data. As validatedby the real dataset, it is shown by our experimental resultsthat algorithm AT devised in this paper significantly outperformsthe prior works in the clustering quality as measuredby the validation indexes, indicating the usefulness ofassociation-taxonomy similarity in item data clustering.

#index 727873
#* T-Trees, Vertical Partitioning and Distributed Association Rule Mining
#@ Frans Coenen;Paul Leng;Shakil Ahmed
#t 2003
#c 18
#% 387588
#% 443091
#% 481290
#% 729417
#! In this paper we consider a technique (DATA-VP) fordistributed (and parallel) Association Rule Mining thatmakes use of a vertical partitioning technique to distributethe input data amongst processors. The proposed verticalpartitioning is facilitated by a novel compressed set enumerationtree data structure (the T-tree), and an associatedmining algorithm (Apriori-T), that allows for computationallyeffective distributed/parallel ARM when compared withexisting approaches.

#index 727874
#* The Rough Set Approach to Association Rule Mining
#@ J. W. Guan;D. A. Bell;D. Y. Liu
#t 2003
#c 18
#% 247585
#% 262232
#% 366687
#% 477642
#! In transaction processing, an association is said to existbetween two sets of items when a transaction containingone set is likely to also contain the other. In informationretrieval, an association between two sets of keywords occurswhen they co-occur in a document. Similarly, in datamining, an association occurs when one attribute set occurstogether with another. As the number of such associationsmay be large, maximal association rules are sought, e.g.,Feldman et al (1997, 1998).Rough set theory is a successful tool for data mining. Byusing this theory, rules similar to maximal associations canbe found. However, we show that the rough set approach todiscovering knowledge is much simpler than the maximalassociation method.

#index 727875
#* A new optimization criterion for generalized discriminant analysis on undersampled problems
#@ Jieping Ye;Ravi Janardan;Cheong Hee Park;Haesun Park
#t 2003
#c 18
#% 36672
#% 80995
#% 200694
#% 329562
#% 581716
#% 729437
#! A new optimization criterion for discriminant analysis ispresented. The new criterion extends the optimization criteriaof the classical linear discriminant analysis (LDA) byintroducing the pseudo-inverse when the scatter matricesare singular. It is applicable regardless of the relative sizesof the data dimension and sample size, overcoming a limitationof the classical LDA. Recently, a new algorithm calledLDA/GSVD for structure-preserving dimension reductionhas been introduced, which extends the classical LDA tovery high-dimensional undersampled problems by using thegeneralized singular value decomposition (GSVD). The solutionfrom the LDA/GSVD algorithm is a special case of thesolution for our generalized criterion in this paper, which isalso based on GSVD.We also present an approximate solution for our GSVD-basedsolution, which reduces computational complexity byfinding sub-clusters of each cluster, and using their centroidsto capture the structure of each cluster. This reducedproblem yields much smaller matrices of which the GSVDcan be applied efficiently. Experiments on text data, withup to 7000 dimensions, show that the approximation algorithmproduces results that are close to those produced bythe exact algorithm.

#index 727876
#* ExAMiner: Optimized Level-wise Frequent Pattern Mining with Monotone Constraints
#@ Francesco Bonchi;Fosca Giannotti;Alessio Mazzanti;Dino Pedreschi
#t 2003
#c 18
#% 201894
#% 248785
#% 342643
#% 438134
#% 464989
#% 471235
#% 481290
#% 577215
#% 629611
#% 998627
#! The key point of this paper is that, in frequent patternmining, the most appropriate way of exploiting monotoneconstraints in conjunction with frequency is to use them inorder to reduce the problem input together with the searchspace. Following this intuition, we introduce ExAMiner, alevel-wise algorithm which exploits the real synergy of anti-monotoneand monotone constraints: the total benefit isgreater than the sum of the two individual benefits. ExAMinergeneralizes the basic idea of the preprocessing algorithmExAnte, embedding such ideas at all levels ofan Apriori-like computation. The resulting algorithm is thegeneralization of the Apriori algorithm when a conjunctionof monotone constraints is conjoined to the frequency anti-monotoneconstraint. Experimental results confirm that thisis, so far, the most efficient way of attacking the computationalproblem in analysis.

#index 727877
#* Sentiment Analyzer: Extracting Sentiments about a Given Topic using Natural Language Processing Techniques
#@ Jeonghee Yi;Tetsuya Nasukawa;Razvan Bunescu;Wayne Niblack
#t 2003
#c 18
#% 118040
#% 180254
#% 220707
#% 279755
#% 342650
#% 342707
#% 529193
#% 577246
#% 577355
#% 740900
#% 740916
#% 746885
#% 786515
#% 815915
#% 854646
#% 1788189
#! We present Sentiment Analyzer (SA) that extracts sentiment(or opinion) about a subject from online text documents.Instead of classifying the sentiment of an entire documentabout a subject, SA detects all references to the givensubject, and determines sentiment in each of the referencesusing natural language processing (NLP) techniques. Oursentiment analysis consists of 1) a topic specific featureterm extraction, 2) sentiment extraction, and 3) (subject,sentiment) association by relationship analysis. SA utilizestwo linguistic resources for the analysis: the sentiment lexiconand the sentiment pattern database. The performanceof the algorithms was verified on online product review articles("digital camera" and "music" reviews), and moregeneral documents including general webpages and newsarticles.

#index 727878
#* Regression Clustering
#@ Bin Zhang
#t 2003
#c 18
#% 280416
#% 372188
#% 431104
#% 918469
#% 1390148
#! Complex distribution in real-world data is oftenmodeled by a mixture of simpler distributions. Clusteringis one of the tools to reveal the structure of this mixture.The same is true to the datasets with chosen responsevariables that people run regression on. Withoutseparating the clusters with very different responseproperties, the residue error of the regression is large.Input variable selection could also be misguided to ahigher complexity by the mixture. In RegressionClustering (RC), K (1) regression functions are appliedto the dataset simultaneously which guide the clusteringof the dataset into K subsets each with a simplerdistribution matching its guiding function. Each functionis regressed on its own subset of data with a muchsmaller residue error. Both the regressions and theclustering optimize a common objective function. Wepresent a RC algorithm based on K-Harmonic Meansclustering algorithm and compare it with other existingRC algorithms based on K-Means and EM.

#index 727879
#* Efficient Multidimensional Quantitative Hypotheses Generation
#@ Amihood Amir;Reuven Kashi;Nathan S. Netanyahu
#t 2003
#c 18
#% 34077
#% 210190
#% 242366
#% 280436
#% 463742
#% 480669
#! Finding local interrelations (hypotheses) among attributeswithin very large databases of high dimensionalityis an acute problem for many databases and data miningapplications. These include, dependency modeling, clusteringlarge databases, correlation and link analysis.Traditional statistical methods are concerned with the corroborationof (a set of) hypotheses on a given body ofdata. Testing all of the hypotheses that can be generatedfrom a database with millions of records and dozens offields is clearly infeasible. Generating, on the other hand,a set of the most "promising" hypotheses (to be corroborated)requires much intuition and ingenuity.In this paper we present an efficient method for rankingthe multidimensional hypotheses using image processingof data visualization. In the heart of the method lies theuse of visualization techniques and image processing ideasto rank subsets of attributes according to the relation betweenthem in the databases. Some of the scalability issuesare solved by concise generalized histograms and by usingan efficient on-line computation of clustering around amedian with only five additional memory words. In additionto presenting our algorithmic methodology, we demonstrateits efficiency and performance by applying it to realcensus data sets, as well as synthetic data sets.

#index 727880
#* Dynamic Weighted Majority: A New Ensemble Method for Tracking Concept Drift
#@ Jeremy Z. Kolter;Marcus A. Maloof
#t 2003
#c 18
#% 136350
#% 165663
#% 204531
#% 209021
#% 226674
#% 246747
#% 280496
#% 310500
#% 312727
#% 321056
#% 342600
#% 342639
#% 424997
#% 451055
#% 498622
#% 720011
#% 751439
#% 1478814
#% 1650665
#! Algorithms for tracking concept drift are important formany applications. We present a general method basedon the Weighted Majority algorithm for using any on-linelearner for concept drift. Dynamic Weighted Majority(DWM) maintains an ensemble of base learners, predictsusing a weighted-majority vote of these "experts",and dynamically creates and deletes experts in response tochanges in performance. We empirically evaluated two experimentalsystems based on the method using incrementalnaive Bayes and Incremental Tree Inducer (ITI) as experts.For the sake of comparison, we also included Blum's implementationof Weighted Majority. On the STAGGER Conceptsand on the SEA Concepts, results suggest that the ensemblemethod learns drifting concepts almost as well as the basealgorithms learn each concept individually. Indeed, we reportthe best overall results for these problems to date.

#index 727881
#* Sequence Modeling with Mixtures of Conditional Maximum Entropy Distributions
#@ Dmitry Pavlov
#t 2003
#c 18
#% 211044
#% 226495
#% 252472
#% 280494
#% 310543
#% 342607
#% 727881
#% 727917
#% 815864
#% 1673026
#! We present a novel approach to modeling sequences usingmixtures of conditional maximum entropy (maxent) distributions.Our method generalizes the mixture of first-orderMarkov models by including the "long-term" dependenciesin model components.The "long-term" dependenciesare represented by the frequently used in the naturallanguage processing (NLP) domain probabilistic triggersor rules (suc as "A occured k positions back" \Longrightarrow"the current symbol is B" with probability P).The maxentframework is then used to create a coherent global probabilisticmodel from all selected triggers.In this paper, weenhance this formalism by using probabilistic mixtures withmaxent models as components, thus representing hidden orunobserved effects in the data.We demonstrate how ourmixture of conditional maxent models can be learned fromdata using the generalized EM algorithm that scales linearlyin the dimensions of the data and the number of mixturecomponents.We present empirical results on the simulatedand real-world data sets and demonstrate that theproposed approach enables us to create better quality modelsthan the mixtures of first-order Markov models and resistoverfitting and curse of dimensionality that would inevitablypresent themselves for the higher order Markov models.

#index 727882
#* OP-Cluster: Clustering by Tendency in High Dimensional Space
#@ Jinze Liu;Wei Wang
#t 2003
#c 18
#% 210173
#% 248792
#% 273891
#% 280417
#% 300131
#% 310507
#% 397382
#% 397383
#% 397632
#% 420067
#% 459006
#% 463903
#% 464888
#% 464996
#% 469422
#% 480124
#% 577256
#% 659967
#! Clustering is the process of grouping a set of objects intoclasses of similar objects. Because of unknownness of thehidden patterns in the data sets, the definition of similarityis very subtle. Until recently, similarity measures are typicallybased on distances, e.g Euclidean distance and cosinedistance. In this paper, we propose a flexible yet powerfulclustering model, namely OP-Cluster (Order PreservingCluster). Under this new model, two objects are similaron a subset of dimensions if the values of these twoobjects induce the same relative order of those dimensions.Such a cluster might arise when the expression levels of (co-regulated)genes can rise or fall synchronously in responseto a sequence of environment stimuli. Hence, discovery ofOP-Cluster is essential in revealing significant gene regulatorynetworks. A deterministic algorithm is designed andimplemented to discover all the significant OP-Clusters. Aset of extensive experiments has been done on several realbiological data sets to demonstrate its effectiveness and efficiencyin detecting co-regulated patterns.

#index 727883
#* Building Text Classifiers Using Positive and Unlabeled Examples
#@ Bing Liu;Yang Dai;Xiaoli Li;Wee Sun Lee;Philip S. Yu
#t 2003
#c 18
#% 169717
#% 169806
#% 190581
#% 252011
#% 269217
#% 280817
#% 304876
#% 311027
#% 406493
#% 458379
#% 458758
#% 464466
#% 464604
#% 464631
#% 464641
#% 464777
#% 464780
#% 466229
#% 466888
#% 476553
#% 564957
#% 577235
#% 669214
#% 722811
#% 891711
#% 1279298
#! This paper studies the problem of building text classifiersusing positive and unlabeled examples. The key feature ofthis problem is that there is no negative example forlearning. Recently, a few techniques for solving thisproblem were proposed in the literature. These techniquesare based on the same idea, which builds a classifier intwo steps. Each existing technique uses a different methodfor each step. In this paper, we first introduce some newmethods for the two steps, and perform a comprehensiveevaluation of all possible combinations of methods of thetwo steps. We then propose a more principled approachto solving the problem based on a biased formulation ofSVM, and show experimentally that it is more accuratethan the existing techniques.

#index 727884
#* Semantic Log Analysis Based on a User Query Behavior Model
#@ Kawamae Noriaki;Mukaigaito Takeya;Hanaki Miyoshi
#t 2003
#c 18
#% 186340
#% 279755
#% 284796
#% 330708
#% 536046
#% 590523
#% 748465
#% 756964
#% 814962
#! We propose a novel log analysis method to capture thesemantic relations among words appearing in Web searchlogs. Our method focuses on the reciprocal relations amonga user's intentions, stages of information need, and querybehavior in seeking information via a search engine. Theapproach works because it is based on the assumption that auser's intentions in each query can be derived as a model onthe basis of his stage of information need and query behavior,through multiple empirical observations of search logs.The user's intentions drive user to change the words in eachsuccessive queries and can thus be used to clarify the semanticrelations among words. As a result, this method hasthe advantage of capturing the semantic relations amongwords without requiring either manual or natural languageprocessing. Our experimental results indicate that semanticrelations could successfully be derived from search logs,confirming that an ontology and thesaurus could be constructedautomatically.

#index 727885
#* Learning Bayesian Networks from Incomplete Data Based on EMI Method
#@ Fengzhan Tian;Hongwei Zhang;Yuchang Lu
#t 2003
#c 18
#% 44876
#% 129987
#% 197387
#% 240222
#% 246834
#% 400980
#% 443025
#% 501829
#% 1650319
#% 1650579
#! Currently, there are few efficient methods in practice forlearning Bayesian networks from incomplete data, whichaffects their use in real world data mining applications.This paper presents a general-duty method that estimatesthe (Conditional) Mutual Information directly from incompletedatasets, EMI. EMI starts by computing the intervalestimates of a joint probability of a variable set, which areobtained from the possible completions of the incompletedataset. And then computes a point estimate via a convexcombination of the extreme points, with weights dependingon the assumed pattern of missing data. Finally, based onthese point estimates, EMI gets the estimated (conditional)Mutual Information. This paper also applies EMI to the dependencyanalysis based learning algorithm by J. Cheng soas to efficiently learn BNs with incomplete data. The experimentalresults on Asia and Alarm networks show that EMIbased algorithm is much more efficient than two search&scoring based algorithms, SEM and EM-EA algorithms. Interms of accuracy, EMI based algorithm is more accuratethan SEM algorithm, and comparable with EM-EA algorithm.

#index 727886
#* Segmenting Customer Transactions Using a Pattern-Based Clustering Approach
#@ Yinghui Yang;Balaji Padmanabhan
#t 2003
#c 18
#% 232136
#% 239588
#% 287285
#% 397382
#% 479659
#% 577257
#% 577296
#% 631985
#! Grouping customer transactions into categories helpsunderstand customers better. The marketing literaturehas concentrated on identifying important segmentationvariables (e.g. customer loyalty) and on using clusteringand mixture models for segmentation. The data miningliterature has provided various clustering algorithms forsegmentation. In this paper we investigate using"pattern-based" clustering approaches to groupingcustomer transactions. We argue that there are clustersin transaction data based on natural behavioral patterns,and present a new technique, YACA, that groupstransactions such that itemsets generated from eachcluster, while similar to each other, are different fromones generated from others. We present experimentalresults from user-centric Web usage data thatdemonstrates that YACA generates a highly effectiveclustering of transactions.

#index 727887
#* Integrating Customer Value Considerations into Predictive Modeling
#@ Saharon Rosset;Einat Neumann
#t 2003
#c 18
#% 342652
#% 420064
#% 477809
#% 577245
#! The success of prediction models for business purposesshould not be measured by their accuracy only. Theirevaluation should also take into account the higherimportance of precise prediction for "valuable"customers. We illustrate this idea through the example ofchurn modeling in telecommunications, where it isobviously much more important to identify potentialchurn among valuable customers. We discuss, boththeoretically and empirically, the optimal use of"customer value" data in the model training, modelevaluation and scoring stages. Our main conclusion isthat a non-trivial approach of using "decayed" value-weightsfor training is usually preferable to the twoobvious approaches of either using non-decayed customervalues as weights or ignoring them.

#index 727888
#* Is random model better? On its accuracy and efficiency
#@ Wei Fan;Haixun Wang;Philip S. Yu;Sheng Ma
#t 2003
#c 18
#% 136350
#% 209021
#% 214236
#% 235377
#% 236656
#% 272403
#% 273900
#% 342611
#% 458361
#% 459008
#% 481945
#% 703747
#! Inductive learning searches an optimal hypothesis thatminimizes a given loss function. It is usually assumed thatthe simplest hypothesis that fits the data is the best approximateto an optimal hypothesis. Since finding the simplesthypothesis is NP-hard for most representations, we generallyemploy various heuristics to search its closest match.Computing these heuristics incurs significant cost, makinglearning inefficient and unscalable for large dataset. In thesame time, it is still questionable if the simplest hypothesisis indeed the closest approximate to the optimal model.Recent success of combining multiple models, such as bagging,boosting and meta-learning, has greatly improved theaccuracy of the simplest hypothesis, providing a strong argumentagainst the optimality of the simplest hypothesis.However, computing these combined hypotheses incurs significantlyhigher cost. In this paper, we first advert that aslong as the error of a hypothesis on each example is withina range dictated by a given loss function, it can still be optimal.Contrary to common beliefs, we propose a completelyrandom decision tree algorithm that achieves much higheraccuracy than the single best hypothesis and is comparableto boosted or bagged multiple best hypotheses. The advantageof multiple random tree is its training efficiency aswell as minimal memory requirement.

#index 727889
#* Detecting Interesting Exceptions from Medical Test Data with Visual Summarization
#@ Einoshin Suzuki;Takeshi Watanabe;Hideto Yokoi;Katsuhiko Takabayashi
#t 2003
#c 18
#% 270633
#% 340739
#% 380342
#% 443092
#% 449566
#% 477948
#% 570886
#% 727889
#% 1273557
#% 1843661
#! In this paper, we propose a method which visualizes irregularmulti-dimensional time-series data as a sequence ofprobabilistic prototypes for detecting exceptions from medicaltest data. Conventional visualization methods often requireiterative analysis and considerable skill thus are nottotally supported by a wide range of medical experts. OurPrototypeLines displays summarized information based ona probabilistic mixture model by using hue only thus is consideredto exhibit novelty. The effectiveness of the summarizationis pursued mainly through use of a novel informationcriterion. We report our endeavor with chronic hepatitisdata, especially discoveries of interesting exceptions bya non-expert and an untrained expert.

#index 727890
#* Mining Plans for Customer-Class Transformation
#@ Qiang Yang;Hong Cheng
#t 2003
#c 18
#% 136350
#% 174161
#% 310559
#% 329537
#% 346389
#% 384911
#% 459006
#% 463903
#% 464996
#% 477791
#% 577237
#% 646959
#% 1272286
#! We consider the problem of mining high-utility plansfrom historical plan databases that can be used to transformcustomers from one class to other, more desirable classes.Traditional data mining algorithms are focused on findingfrequent sequences. But high frequency may not imply lowcosts and high benefits. Traditional Markov Decision Process(MDP) algorithms are designed to address this issueby bringing in the concept of utility, but these algorithmsare also known to be expensive to execute. In this paper,we present a novel algorithm AUPlan which automaticallygenerates sequential plans with high utility by combiningdata mining and AI planning. These high-utility plans couldbe used to convert groups of customers from less desirablestates to more desirable ones. Our algorithm adapts theApriori algorithm by considering the concepts of plans andutilities. We show through empirical studies that planningusing our integrated algorithm produces high-utility plansefficiently.

#index 727891
#* A High-Performance Distributed Algorithm for Mining Association Rules
#@ Assaf Schuster;Ran Wolff;Dan Trock
#t 2003
#c 18
#% 70050
#% 152934
#% 199538
#% 201894
#% 227917
#% 310558
#% 333987
#% 340291
#% 443091
#% 459020
#% 461818
#% 466641
#% 481290
#% 481754
#% 481758
#% 481779
#! We present a new distributed association rule mining(D-ARM) algorithm that demonstrates superlinear speedupwith the number of computing nodes. The algorithm isthe first D-ARM algorithm to perform a single scan overthe database. As such, its performance is unmatched byany previous algorithm. Scale-up experiments over standard synthetic benchmarks demonstrate stable run time regardless of the number of computers. Theoretical analysisreveals a tighter bound on error probability than the oneshown in the corresponding sequential algorithm.

#index 727892
#* Spatial Interest Pixels (SIPs): Useful Low-Level Features of Visual Media Data
#@ Qi Li;Jieping Ye;Chandra Kambhamettu
#t 2003
#c 18
#% 120270
#% 217292
#% 235342
#% 295919
#% 313140
#% 316148
#% 324288
#% 451617
#% 581716
#% 593030
#% 593636
#% 718445
#% 1022958
#% 1272808
#! Visual media data such as an image is the raw data representationfor many important applications. The biggestchallenge in using visual media data comes from the extremelyhigh dimensionality. We present a comparativestudy on spatial interest pixels (SIPs), including eight-way(a novel SIP miner), Harris, and Lucas-Kanade, whose extractionis considered as an important step in reducing thedimensionality of visual media data. With extensive casestudies, we have shown the usefulness of SIPs as the low-levelfeatures of visual media data. A class-preserving dimensionreduction algorithm (using GSVD) is applied tofurther reduce the dimension of feature vectors based onSIPs. The experiments showed its superiority over PCA.

#index 727893
#* Mining Significant Pairs of Patterns from Graph Structures with Class Labels
#@ Akihiro Inokuchi;Hisashi Kashima
#t 2003
#c 18
#% 280433
#% 299985
#% 342604
#% 431105
#% 464603
#% 464619
#% 466644
#% 477784
#% 478274
#% 478297
#% 565974
#% 577218
#% 629708
#% 1289265
#! In recent years, the problem of mining association rulesover frequent itemsets in transactional data has been frequentlystudied and yielded several algorithms that can findassociation rules within a limited amount of time. Alsomore complex patterns have been considered such as orderedtrees, unordered trees, or labeled graphs. Althoughsome approaches can efficiently derive all frequent subgraphsfrom a massive dataset of graphs, a subgraph orsubtree that is mathematically defined is not necessarily abetter knowledge representation. In this paper, we proposean efficient approach to discover significant rules to classifypositive and negative graph examples by estimating atight upper bound on the statistical metric. This approachabandons unimportant rules earlier in the computations,and thereby accelerates the overall performance. The performancehas been evaluated using real world datasets, andthe efficiency and effect of our approach has been confirmedwith respect to the amount of data and the computation time.

#index 727894
#* Mining High Utility Itemsets
#@ Raymond Chan;Qiang Yang;Yi-Dong Shen
#t 2003
#c 18
#% 152934
#% 248785
#% 300120
#% 310505
#% 310558
#% 443092
#% 445403
#% 464873
#% 477497
#% 481290
#% 565974
#% 629602
#% 629644
#% 631970
#! Traditional association rule mining algorithms onlygenerate a large number of highly frequent rules, butthese rules do not provide useful answers for what thehigh utility rules are. In this work, we develop a novelidea of top-K objective-directed data mining, which focuseson mining the top-K high utility closed patterns thatdirectly support a given business objective. To associationmining, we add the concept of utility to capture highly desirablestatistical patterns and present a level-wise item-setmining algorithm. With both positive and negativeutilities, the anti-monotone pruning strategy in Apriorialgorithm no longer holds. In response, we develop a newpruning strategy based on utilities that allow pruning oflow utility itemsets to be done by means of a weaker butanti-monotonic condition. Our experimental results showthat our algorithm does not require a user specifiedminimum utility and hence is effective in practice.

#index 727895
#* Parsing Without a Grammar: Making Sense of Unknown File Formats
#@ Levon Lloyd;Steven Skiena
#t 2003
#c 18
#% 36672
#% 235941
#% 251919
#% 337483
#% 395135
#% 453473
#! The thousands of specialized structured file formats inuse today present a substantial barrier to freely exchanginginformation between applications programs. We considerthe problem of deducing such basic features as thewhitespace characters, bracketing delimiter symbols, andself-delimiter characters of a given file format from one ormore example files. We demonstrate that for sufficientlylarge example files, we can typically identify the basic featuresof interest.

#index 727896
#* Frequent Sub-Structure-Based Approaches for Classifying Chemical Compounds
#@ Mukund Deshpande;Michihiro Kuramochi;George Karypis
#t 2003
#c 18
#% 136350
#% 190581
#% 269217
#% 331909
#% 342604
#% 376266
#% 413590
#% 420088
#% 445369
#% 466229
#% 466473
#% 466483
#% 466644
#% 478274
#% 629603
#% 629708
#% 772830
#% 1273674
#! In this paper we study the problem of classifying chemical compounddatasets. We present a sub-structure-based classificationalgorithm that decouples the sub-structure discovery processfrom the classification model construction and uses frequentsubgraph discovery algorithms to find all topological and geometricsub-structures present in the dataset. The advantage ofour approach is that during classification model construction, allrelevant sub-structures are available allowing the classifier tointelligently select the most discriminating ones. The computationalscalability is ensured by the use of highly efficient frequentsubgraph discovery algorithms coupled with aggressive featureselection. Our experimental evaluation on eight different classificationproblems shows that our approach is computationallyscalable and on the average, outperforms existing schemes by10% to 35%.

#index 727897
#* Mining Strong Affinity Association Patterns in Data Sets with Skewed Support Distribution
#@ Hui Xiong;Pang-Ning Tan;Vipin Kumar
#t 2003
#c 18
#% 36672
#% 152934
#% 227919
#% 248791
#% 342667
#% 375017
#% 443393
#% 452846
#% 465003
#% 481290
#% 577214
#! Existing association-rule mining algorithms often relyon the support-based pruning strategy to prune its combinatorialsearch space. This strategy is not quite effectivefor data sets with skewed support distributions because theytend to generate many spurious patterns involving itemsfrom different support levels or miss potentially interestinglow-support patterns. To overcome these problems, we proposethe concept of hyperclique pattern, which uses an objectivemeasure called h-confidence to identify strong affinitypatterns. We also introduce the novel concept of cross-supportproperty for eliminating patterns involving itemswith substantially different support levels. Our experimentalresults demonstrate the effectiveness of this method forfinding patterns in dense data sets even at very low supportthresholds, where most of the existing algorithms wouldbreak down. Finally, hyperclique patterns also show greatpromise for clustering items in high dimensional space.

#index 727898
#* An Algebra for Inductive Query Evaluation
#@ Sau Dan Lee;Luc De Raedt
#t 2003
#c 18
#% 178515
#% 342604
#% 420062
#% 481290
#% 487532
#% 511333
#% 575973
#% 577215
#% 629643
#% 1116726
#% 1280023
#% 1289265
#! Inductive queries are queries that generate pattern sets.This paper studies properties of boolean inductive queries,i.e. queries that are boolean expressions over monotonicand anti-monotonic constraints. More specifically, we introduceand study algebraic operations on the answer setsof such queries and show how these can be used for constructingand optimizing query plans. Special attention isdevoted to the dimension of the queries, i.e. the minimumnumber of version spaces needed to represent the answersets. The framework has been implemented for the patterndomain of strings and experimentally validated.

#index 727899
#* CBC: Clustering Based Text Classification Requiring Minimal Labeled Data
#@ Hua-Jun Zeng;Xuan-Hui Wang;Zheng Chen;Hongjun Lu;Wei-Ying Ma
#t 2003
#c 18
#% 118736
#% 165110
#% 165111
#% 190581
#% 232653
#% 252011
#% 280817
#% 311027
#% 316509
#% 458369
#% 458379
#% 464291
#% 464608
#% 466263
#% 577286
#! Semi-supervised learning methods construct classifiersusing both labeled and unlabeled training data samples.While unlabeled data samples can help to improve theaccuracy of trained models to certain extent, existingmethods still face difficulties when labeled data is notsufficient and biased against the underlying datadistribution. In this paper, we present a clustering basedclassification (CBC) approach. Using this approach,training data, including both the labeled and unlabeleddata, is first clustered with the guidance of the labeleddata. Some of unlabeled data samples are then labeledbased on the clusters obtained. Discriminative classifierscan subsequently be trained with the expanded labeleddataset. The effectiveness of the proposed method isjustified analytically. Our experimental resultsdemonstrated that CBC outperforms existing algorithmswhen the size of labeled dataset is very small.

#index 727900
#* Clustering of Time Series Subsequences is Meaningless: Implications for Previous and Future Research
#@ Eamonn Keogh;Jessica Lin;Wagner Truppel
#t 2003
#c 18
#% 152934
#% 260016
#% 280482
#% 310580
#% 397631
#% 430746
#% 430767
#% 443515
#% 463948
#% 464888
#% 465031
#% 466083
#% 492333
#% 494958
#% 498625
#% 501995
#% 528055
#% 546415
#% 577221
#% 594012
#% 630989
#% 993965
#! Time series data is perhaps the most frequently encountered typeof data examined by the data mining community. Clustering isperhaps the most frequently used data mining algorithm, beinguseful in it's own right as an exploratory technique, and also as asubroutine in more complex data mining algorithms such as rulediscovery, indexing, summarization, anomaly detection, andclassification. Given these two facts, it is hardly surprising thattime series clustering has attracted much attention. The data to beclustered can be in one of two formats: many individual timeseries, or a single time series, from which individual time seriesare extracted with a sliding window. Given the recent explosion ofinterest in streaming data and online algorithms, the latter casehas received much attention.In this work we make an amazing claim. Clustering of streamingtime series is completely meaningless. More concretely, clustersextracted from streaming time series are forced to obey a certainconstraint that is pathologically unlikely to be satisfied by anydataset, and because of this, the clusters extracted by anyclustering algorithm are essentially random. While this constraintcan be intuitively demonstrated with a simple illustration and issimple to prove, it has never appeared in the literature.We can justify calling our claim surprising, since it invalidatesthe contribution of dozens of previously published papers. We willjustify our claim with a theorem, illustrative examples, and acomprehensive set of experiments on reimplementations ofprevious work.

#index 727901
#* Probabilistic Noise Identification and Data Cleaning
#@ Jeremy Kubica;Andrew Moore
#t 2003
#c 18
#% 232117
#% 232118
#% 466236
#% 466249
#% 1499584
#! Real world data is never as perfect as we would like itto be and can often suffer from corruptions that may impactinterpretations of the data, models created from thedata, and decisions made based on the data.One approachto this problem is to identify and remove records that containcorruptions.Unfortunately, if only certain fields in arecord have been corrupted then usable, uncorrupted datawill be lost.In this paper we present LENS, an approach foridentifying corrupted fields and using the remaining non-corruptedfields for subsequent modeling and analysis.Ourapproach uses the data to learn a probabilistic model containingthree components: a generative model of the cleanrecords, a generative model of the noise values, and a probabilisticmodel of the corruption process.We provide an algorithmfor the unsupervised discovery of such models andempirically evaluate both its performance at detecting corruptedfields and, as one example application, the resultingimprovement this gives to a classifier.

#index 727902
#* Reliable Detection of Episodes in Event Sequences
#@ Robert Gwadera;Mikhail Atallah;Wojciech Szpankowski
#t 2003
#c 18
#% 120649
#% 179696
#% 205024
#% 229127
#% 273712
#% 352402
#% 401095
#% 420063
#% 492463
#% 546285
#% 548120
#% 1001648
#! Suppose one wants to detect "bad" or "suspicious" subsequencesin event sequences.Whether an observed patternof activity (in the form of a particular subsequence) is significantand should be a cause for alarm, depends on howlikely it is to occur fortuitously.A long enough sequenceof observed events will almost certainly contain any subsequence,and setting thresholds for alarm is an important issuein a monitoring system that seeks to avoid false alarms.Suppose a long sequence T of observed events contains asuspicious subsequence pattern S within it, where the suspicioussubsequence S consists of m events and spans a windowof size w within T.We address the fundamental problem:is a certain number of occurrences of a particular subsequenceunlikely to be fortuitous (i.e., indicative of suspiciousactivity)?If the probability of fortuitous occurrencesis high and an automated monitoring system flags it as suspiciousanyway, then such a system will suffer from generatingtoo many false alarms.This paper quantifies the probabilityof such an S occuring in T within a window of sizew, the number of distinct windows containing S as a subsequence,the expected number of such occurrences, its variance,and establishes its limiting distribution that allows toset up an alarm threshold so that the probability of falsealarms is very small.We report on experiments confirmingthe theory and showing that we can detect bad subsequenceswith low false alarm rate.

#index 727903
#* Combining Multiple Weak Clusterings
#@ Alexander Topchy;Anil K. Jain;William Punch
#t 2003
#c 18
#% 36672
#% 296738
#% 349552
#% 451052
#% 494396
#% 551737
#% 568869
#% 633220
#% 722902
#% 1499573
#! A data set can be clustered in many ways dependingon the clustering algorithm employed, parameter settingsused and other factors. Can multiple clusterings becombined so that the final partitioning of data providesbetter clustering? The answer depends on the quality ofclusterings to be combined as well as the properties of thefusion method. First, we introduce a unifiedrepresentation for multiple clusterings and formulate thecorresponding categorical clustering problem. As aresult, we show that the consensus function is related tothe classical intra-class variance criterion using thegeneralized mutual information definition. Second, weshow the efficacy of combining partitions generated byweak clustering algorithms that use data projections andrandom data splits. A simple explanatory model is offeredfor the behavior of combinations of such weak clusteringcomponents. We analyze the combination accuracy as afunction of parameters controlling the power andresolution of component partitions as well as the learningdynamics vs. the number of clusterings involved. Finally,some empirical studies compare the effectiveness ofseveral consensus functions.

#index 727904
#* On the Privacy Preserving Properties of Random Data Perturbation Techniques
#@ Hillol Kargupta;Souptik Datta;Qi Wang;Krishnamoorthy Sivakumar
#t 2003
#c 18
#% 300184
#% 333876
#% 340475
#% 478632
#% 487496
#% 575971
#% 576111
#% 577233
#% 577289
#% 993988
#! Privacy is becoming an increasingly important issue inmany data mining applications. This has triggered the developmentof many privacy-preserving data mining techniques.A large fraction of them use randomized data distortiontechniques to mask the data for preserving the privacyof sensitive data. This methodology attempts to hidethe sensitive data by randomly modifying the data values oftenusing additive noise. This paper questions the utility ofthe random value distortion technique in privacy preservation.The paper notes that random objects (particularly randommatrices) have "predictable" structures in the spectraldomain and it develops a random matrix-based spectral filteringtechnique to retrieve original data from the datasetdistorted by adding random values. The paper presents thetheoretical foundation of this filtering method and extensiveexperimental results to demonstrate that in many cases randomdata distortion preserve very little data privacy. Thepaper also points out possible avenues for the developmentof new privacy-preserving data mining techniques like exploitingmultiplicative and colored noise for preserving privacyin data mining applications.

#index 727905
#* Model-based Clustering with Soft Balancing
#@ Shi Zhong;Joydeep Ghosh
#t 2003
#c 18
#% 36672
#% 72560
#% 190581
#% 296738
#% 310512
#% 342621
#% 375388
#% 438137
#% 464890
#% 593960
#% 594009
#% 722902
#% 727905
#% 739636
#% 1860228
#! Balanced clustering algorithms can be useful in a varietyof applications and have recently attracted increasing researchinterest. Most recent work, however, addressed onlyhard balancing by constraining each cluster to have equalor a certain minimum number of data objects. This paperprovides a soft balancing strategy built upon a soft mixture-of-models clustering framework. This strategy constrains the sum of posterior probabilities of object membership foreach cluster to be equal and thus balances the expectednumber of data objects in each cluster. We first derive softmodel-based clustering from an information-theoretic viewpointand then show that the proposed balanced clusteringcan be parameterized by a temperature parameter that controlsthe softness of clustering as well as that of balancing.As the temperature decreases, the resulting partitioning becomesmore and more balanced. In the limit, when temperaturebecomes zero, the balancing becomes hard and theactual partitioning becomes perfectly balanced. The effectivenessof the proposed soft balanced clustering algorithmis demonstrated on both synthetic and real text data.

#index 727906
#* MPIS: Maximal-Profit Item Selection with Cross-Selling Considerations
#@ Raymond Chi-Wing Wong;Ada Wai-Chee Fu;Ke Wang
#t 2003
#c 18
#% 152934
#% 280456
#% 282905
#% 300120
#% 310548
#% 408396
#% 420082
#% 424328
#% 464712
#% 481290
#% 577291
#% 919225
#% 935262
#! In the literature of data mining, many different algorithmsfor association rule mining have been proposed. However,there is relatively little study on how association rules can aidin more specific targets. In this paper, one of the applicationsfor association rules - maximal-profit item selection with cross-selling effect (MPIS) problem - is investigated. The problemis about selecting a subset of items which can give the maximalprofit with the consideration of cross-selling. We provethat a simple version of this problem is NP-hard. We proposea new approach to the problem with the consideration of theloss rule - a kind of association rule to model the cross-sellingeffect. We show that the problem can be transformed to aquadratic programming problem. In case quadratic programmingis not applicable, we also propose a heuristic approach.Experiments are conducted to show that both of the proposedmethods are highly effective and efficient.

#index 727907
#* Identifying Markov Blankets with Decision Tree Induction
#@ Lewis Frey;Douglas Fisher;Ioannis Tsamardinos;Constantin F. Aliferis;Alexander Statnikov
#t 2003
#c 18
#% 44876
#% 67866
#% 243728
#% 246835
#% 400980
#% 449588
#% 729990
#% 1273439
#! The Markov Blanket of a target variable is theminimum conditioning set of variables that makes thetarget independent of all other variables. MarkovBlankets inform feature selection, aid in causal discoveryand serve as a basis for scalable methods of constructingBayesian networks. This paper applies decision treeinduction to the task of Markov Blanket identification.Notably, we compare (a) C5.0, a widely used algorithmfor decision rule induction, (b) C5C, which post-processesC5.0's rule set to retain the most frequentlyreferenced variables and (c) PC, a standard method forBayesian Network induction. C5C performs as well as orbetter than C5.0 and PC across a number of data sets.Our modest variation of an inexpensive, accurate, off-the-shelfinduction engine mitigates the need for specializedprocedures, and establishes baseline performance againstwhich specialized algorithms can be compared.

#index 727908
#* MaPle: A Fast Algorithm for Maximal Pattern-based Clustering
#@ Jian Pei;Xiaoling Zhang;Moonjung Cho;Haixun Wang;Philip S. Yu
#t 2003
#c 18
#% 152934
#% 248792
#% 273891
#% 280417
#% 300120
#% 300131
#% 397382
#% 464888
#% 469422
#% 480124
#% 481290
#! Pattern-based clustering is important in many applications,such as DNA micro-array data analysis, automaticrecommendation systems and target marketing systems.However, pattern-based clustering in large databasesis challenging. On the one hand, there can be a huge numberof clusters and many of them can be redundant and thusmake the pattern-based clustering ineffective. On the otherhand, the previous proposed methods may not be efficient orscalable in mining large databases.In this paper, we study the problem of maximal pattern-basedclustering. Redundant clusters are avoided completelyby mining only the maximal pattern-based clusters.MaPle, an efficient and scalable mining algorithm is developed.It conducts a depth-first, divide-and-conquer searchand prunes unnecessary branches smartly. Our extensiveperformance study on both synthetic data sets and real datasets shows that maximal pattern-based clustering is effective.It reduces the number of clusters substantially. Moreover,MaPle is more efficient and scalable than the previouslyproposed pattern-based clustering methods in mininglarge databases.

#index 727909
#* Efficient Data Mining for Maximal Frequent Subtrees
#@ Yongqiao Xiao;Jenq-Foung Yao;Zhigang Li;Margaret H. Dunham
#t 2003
#c 18
#% 300120
#% 378183
#% 378391
#% 443194
#% 463903
#% 466644
#% 478274
#% 481290
#% 577218
#% 629708
#! A new type of tree mining is defined in this paper,which uncovers maximal frequent induced subtrees from adatabase of unordered labeled trees. A novel algorithm,PathJoin, is proposed. The algorithm uses a compact datastructure, FST-Forest, which compresses the trees and stillkeeps the original tree structure. PathJoin generates candidatesubtrees by joining the frequent paths in FST-Forest.Such candidate subtree generation is localized and thussubstantially reduces the number of candidate subtrees. Experimentswith synthetic data sets show that the algorithmis effective and efficient.

#index 727910
#* Complex Spatial Relationships
#@ Robert Munro;Sanjay Chawla;Pei Sun
#t 2003
#c 18
#% 300120
#% 452863
#% 464603
#% 481290
#% 527021
#% 527188
#% 727910
#% 728302
#! This paper describes the need for mining complex relationshipsin spatial data. Complex relationships are definedas those involving two or more of: multi-feature colocation,self-colocation, one-to-many relationships, self-exclusionand multi-feature exclusion. We demonstrate that even inthe mining of simple relationships, knowledge of complexrelationships is necessary to accurately calculate the significanceof results. We implement a representation of spatialdata such that it contains known 'weak-monotonic' properties,which are exploited for the efficient mining of complexrelationships, and discuss the strengths and limitations ofthis representation.

#index 727911
#* Scalable Model-based Clustering by Working on Data Summaries
#@ Huidong Jin;Man-Leung Wong;Kwong-Sak Leung
#t 2003
#c 18
#% 232117
#% 274604
#% 280402
#% 280448
#% 300132
#% 304932
#% 310512
#% 329531
#% 342620
#% 350336
#% 420057
#% 481281
#% 716088
#% 818916
#! The scalability problem in data mining involves the developmentof methods for handling large databases withlimited computational resources. In this paper, we presenta two-phase scalable model-based clustering framework:First, a large data set is summed up into sub-clusters; Then,clusters are directly generated from the summary statisticsof sub-clusters by a specifically designed Expectation-Maximization(EM) algorithm. Taking example for Gaussianmixture models, we establish a provably convergentEM algorithm, EMADS, which embodies cardinality, mean,and covariance information of each sub-cluster explicitly.Combining with different data summarization procedures,EMADS is used to construct two clustering systems:gEMADS and bEMADS. The experimental results demonstratethat they run several orders of magnitude faster thanthe classic EM algorithm with little loss of accuracy. Theygenerate significantly better results than other model-basedclustering systems using similar computational resources.

#index 727912
#* Statistical Relational Learning for Document Mining
#@ Alexandrin Popescul;Lyle H. Ungar;Steve Lawrence;David M. Pennock
#t 2003
#c 18
#% 226438
#% 248810
#% 314784
#% 333797
#% 348178
#% 373774
#% 398839
#% 398842
#% 398846
#% 398847
#% 420087
#% 420088
#% 438103
#% 464304
#% 464449
#% 466077
#% 478596
#% 549285
#% 550745
#% 568785
#% 577225
#% 727912
#% 729926
#% 1289319
#% 1290272
#% 1650403
#! A major obstacle to fully integrated deployment of manydata mining algorithms is the assumption that data sitsin a single table, even though most real-world databaseshave complex relational structures. We propose an integratedapproach to statistical modeling from relationaldatabases. We structure the search space based on "refinementgraphs", which are widely used in inductive logic programmingfor learning logic descriptions. The use of statisticsallows us to extend the search space to include richerset of features, including many which are not boolean.Search and model selection are integrated into a single process,allowing information criteria native to the statisticalmodel, for example logistic regression, to make feature selectiondecisions in a step-wise manner. We present experimentalresults for the task of predicting where scientific paperswill be published based on relational data taken fromCiteSeer. Our approach results in classification accuraciessuperior to those achieved when using classical "flat" features.The resulting classifier can be used to recommendwhere to publish articles.

#index 727913
#* TSP: Mining Top-K Closed Sequential Patterns
#@ Petre Tzvetkov;Xifeng Yan;Jiawei Han
#t 2003
#c 18
#% 329537
#% 459006
#% 463903
#% 464996
#% 577256
#% 629644
#% 631985
#% 729938
#! Sequential pattern mining has been studied extensivelyin data mining community.Most previous studies requirethe specification of a minimum support threshold to performthe mining.However, it is difficult for users to providean appropriate threshold in practice.To overcomethis difficulty, we propose an alternative task: mining top-kfrequent closed sequential patterns of length no less thanmin_l, where k is the desired number of closed sequentialpatterns to be mined, and min_l is the minimum length ofeach pattern.We mine closed patterns since they are compactrepresentations of frequent patterns.We developed an efficient algorithm, called TSP, whichmakes use of the length constraint and the properties of top-kclosed sequential patterns to perform dynamic support-raisingand projected database-pruning.Our extensive performancestudy shows that TSP outperforms the closed sequentialpattern mining algorithm even when the latter isrunning with the best tuned minimum support threshold.

#index 727914
#* Interactive Visualization and Navigation in Large Data Collections using the Hyperbolic Space
#@ Jörg Walter;Jörg Ontrup;Daniel Wessling;Helge Ritter
#t 2003
#c 18
#% 173425
#% 202036
#% 287606
#% 322953
#% 325209
#% 361966
#% 577223
#% 641101
#% 751574
#% 1011582
#% 1835340
#% 1860651
#! We propose the combination of two recently introducedmethods for the interactive visual data mining of largecollections of data. Both, Hyperbolic Multi-DimensionalScaling (HMDS) and Hyperbolic Self-Organizing Maps(HSOM) employ the extraordinary advantages of the hyperbolicplane (H2): (i) the underlying space grows exponentiallywith its radius around each point - ideal for embeddinghigh-dimensional (or hierarchical) data; (ii) thePoincaré model of the IH2 exhibits a fish-eye perspectivewith a focus area and a context preserving surrounding; (iii)the mouse binding of focus-transfer allows intuitive interactivenavigation.The HMDS approach extends multi-dimensional scalingand generates a spatial embedding of the data representingtheir dissimilarity structure as faithfully as possible. Itis very suitable for interactive browsing of data object collections,but calls for batch precomputation for larger collectionsizes.The HSOM is an extension of Kohonen's Self-OrganizingMap and generates a partitioning of the data collection assignedto an IH2 tessellating grid. While the algorithm'scomplexity is linear in the collection size, the data browsingis rigidly bound to the underlying grid.By integrating the two approaches we gain the synergetic effectof adding advantages of both. And the hybrid architectureuses consistently the IH2 visualization and navigationconcept. We present the successfully application to a textmining example involving the Reuters-21578 text corpus.

#index 727915
#* Visualization of Rule's Similarity using Multidimensional Scaling
#@ Shusaku Tsumoto;Shoji Hirano
#t 2003
#c 18
#% 24538
#% 168559
#% 216500
#% 275064
#! One of the most important problems with rule inductionmethods is that it is very difficult for domain experts to checkmillions of rules generated from large datasets. The discoveryfrom these rules requires deep interpretation from domainknowledge. Although several solutions have been proposedin the studies on data mining and knowledge discovery,these studies are not focused on similarities betweenrules obtained. When one rule r1 has reasonable featuresand the other rule r2 with high similarity to r1 includes unexpectedfactors, the relations between these rules will becomea trigger to the discovery of knowledge. In this paper,we propose a visualization approach to show the similarrelations between rules based on multidimensional scaling,which assign a two-dimensional cartesian coordinateto each data point from the information about similiariesbetween this data and others data. We evaluated this methodon two medical data sets, whose experimental results showthat knowledge useful for domain experts could be found.

#index 727916
#* On Precision and Recall of Multi-Attribute Data Extraction from Semistructured Sources
#@ Guizhen Yang;Saikat Mukherjee;I. V. Ramakrishnan
#t 2003
#c 18
#% 145591
#% 188429
#% 227987
#% 229828
#% 244103
#% 248808
#% 259991
#% 271065
#% 273925
#% 275915
#% 278109
#% 289130
#% 348146
#% 480824
#% 654469
#% 730038
#! Machine learning techniques for data extraction fromsemistructured sources exhibit different precision and recallcharacteristics. However to date the formal relationship betweenlearning algorithms and their impact on these twometrics remains unexplored. This paper proposes a formalizationof precision and recall of extraction and investigatesthe complexity-theoretic aspects of learning algorithms formulti-attribute data extraction based on this formalism. Weshow that there is a tradeoff between precision/recall of extractionand computational efficiency and present experimentalresults to demonstrate the practical utility of theseconcepts in designing scalable data extraction algorithmsfor improving recall without compromising on precision.

#index 727917
#* Probabilistic User Behavior Models
#@ Eren Manavoglu;Dmitry Pavlov;C. Lee Giles
#t 2003
#c 18
#% 173879
#% 226495
#% 252472
#% 266283
#% 275360
#% 308769
#% 310543
#% 420055
#% 438103
#% 722754
#% 727881
#% 815864
#! We present a mixture model based approach for learningindividualized behavior models for the Web users. Weinvestigate the use of maximum entropy and Markov mixturemodels for generating probabilistic behavior models.We first build a global behavior model for the entire populationand then personalize this global model for the existingusers by assigning each user individual componentweights for the mixture model. We then use these individualweights to group the users into behavior model clusters.We show that the clusters generated in this manner areinterpretable and able to represent dominant behavior patterns.We conduct offline experiments on around two monthsworth of data from CiteSeer, an online digital library forcomputer science research papers currently storing morethan 470,000 documents. We show that both maximum entropyand Markov based personal user behavior modelsare strong predictive models. We also show that maximumentropy based mixture model outperforms Markov mixturemodels in recognizing complex user behavior patterns.

#index 727918
#* Exploiting Unlabeled Data for Improving Accuracy of Predictive Data Mining
#@ Kang Peng;Slobodan Vucetic;Bo Han;Hongbo Xie;Zoran Obradovic
#t 2003
#c 18
#% 46803
#% 190581
#% 252011
#% 311027
#% 464641
#% 577298
#% 658333
#% 722812
#! Predictive data mining typically relies on labeled datawithout exploiting a much larger amount of availableunlabeled data. The goal of this paper is to show thatusing unlabeled data can be beneficial in a range ofimportant prediction problems and therefore should be anintegral part of the learning process. Given an unlabeleddataset representative of the underlying distribution and aK-class labeled sample that might be biased, ourapproach is to learn K contrast classifiers each trained todiscriminate a certain class of labeled data from theunlabeled population. We illustrate that contrastclassifiers can be useful in one-class classification, outlierdetection, density estimation, and learning from biaseddata. The advantages of the proposed approach aredemonstrated by an extensive evaluation on synthetic datafollowed by real-life bioinformatics applications for (1)ranking PubMed articles by their relevance to proteindisorder and (2) cost-effective enlargement of adisordered protein database.

#index 727919
#* Introducing Uncertainty into Pattern Discovery in Temporal Event Sequences
#@ Xingzhi Sun;Maria E. Orlowska;Xue Li
#t 2003
#c 18
#% 310542
#% 310559
#% 342642
#% 397383
#% 420063
#% 459006
#% 463903
#% 464986
#% 464996
#% 481290
#% 1390144
#! Pattern discovery in temporal event sequences is of greatimportance in many application domains, such as telecommunicationnetwork fault analysis. In reality, not every typeof event has an accurate timestamp. Some of them, definedas inaccurate events in this paper, may only have an intervalas possible time of occurrence. The existence of inaccurateevents may cause uncertainty in event ordering. Thetraditional support model cannot deal with this uncertainty,which would cause some interesting patterns to be missing.In this paper, a new concept, precise support, is introducedto evaluate the probability of a pattern contained in a sequence.Based on this new metric, we define the uncertaintymodel and present an algorithm to discover interesting patternsin the sequence database that has one type of inaccurateevent. In our model, the number of types of inaccurateevents can be extended to k readily, however, at a cost ofincreasing computational complexity.

#index 727920
#* Efficient Nonlinear Dimension Reduction for Clustered Data Using Kernel Functions
#@ Cheong Hee Park;Haesun Park
#t 2003
#c 18
#% 80995
#% 266426
#% 309208
#% 420077
#% 430739
#% 727875
#% 729437
#% 857439
#% 1860543
#! In this paper, we propose a nonlinear feature extractionmethod which is based on centroids and kernel functions.The dimension reducing nonlinear transformation isobtained by implicitly mapping the input data into a featurespace using a kernel function, and then finding a linearmapping based on an orthonormal basis of centroids in thefeature space that maximally separates the between-classrelationship. The proposed method utilizes an efficient algorithmto compute an orthonormal basis of centroids in thefeature space transformed by a kernel function and achievesdramatic computational savings. The experimental resultsdemonstrate that our method is capable of extracting non-linearfeatures effectively so that competitive performanceof classification can be obtained in the reduced dimensionalspace.

#index 727921
#* Evolutionary Gabor Filter Optimization with Application to Vehicle Detection
#@ Zehang Sun;George Bebis;Ronald Miller
#t 2003
#c 18
#% 8512
#% 71162
#% 104477
#% 131532
#% 190581
#% 212690
#% 256613
#% 296738
#% 316998
#% 369236
#% 384905
#% 420077
#% 614478
#% 625788
#% 1857104
#! Despite the considerable amount of research work on the applicationof Gabor filters in pattern classification, their design and selectionhave been mostly done on a trial and error basis. Existing techniques areeither only suitable for a small number of filters or less problem-oriented.A systematic and general evolutionary Gabor filter optimization (EGFO)approach that yields a more optimal, problem-specific, set of filters is proposedin this study. The EGFO approach unifies filter design with filter selectionby integrating Genetic Algorithms (GAs) with an incremental clusteringapproach. Specifically, filter design is performed using GAs, a globaloptimization approach that encodes the parameters of the Gabor filters ina chromosome and uses genetic operators to optimize them. Filter selectionis performed by grouping together filters having similar characteristics(i.e., similar parameters) using incremental clustering in the parameterspace. Each group of filters is represented by a single filter whose parameterscorrespond to the average parameters of the filters in the group. Thisstep eliminates redundant filters, leading to a compact, optimized set of filters.The average filters are evaluated using an application-oriented fitnesscriterion based on Support Vector Machines (SVMs). To demonstrate theeffectiveness of the proposed framework, we have considered the challengingproblem of vehicle detection from gray-scale images. Our experimentalresults illustrate that the set of Gabor filters, specifically optimized for theproblem of vehicle detection, yield better performance than using traditionalfilter banks.

#index 727922
#* Direct Interesting Rule Generation
#@ Jiuyong Li;Yanchun Zhang
#t 2003
#c 18
#% 152934
#% 201894
#% 210162
#% 227917
#% 227919
#% 280436
#% 300120
#% 300124
#% 310494
#% 310505
#% 342643
#% 376266
#% 452822
#% 458178
#% 466485
#% 481290
#% 577214
#% 631970
#% 632029
#% 735876
#% 1272179
#! An association rule generation algorithm usually generatestoo many rules including a lot of uninteresting ones.Many interestingness criteria are proposed to prune thoseuninteresting rules. However, they work in post-pruningprocess and hence do not improve the rule generation ef拢ciency. In this paper, we discuss properties of informativerule set and conclude that the informative rule set includesall interesting rules measured by many commonly used interestingnesscriteria, and that rules excluded by the informativerule set are forwardly prunable, i.e. they can be removedin the rule generation process instead of post pruning.Based on these properties, we propose a Direct Interestingrule Generation algorithm, DIG, to directly generateinteresting rules de拢ned by any of 12 interestingness criteriadiscussed in this paper. We further show experimentallythat DIG is faster and uses less memory than Apriori.

#index 727923
#* Zigzag: a new algorithm for mining large inclusion dependencies in databases
#@ Fabien De Marchi;Jean-Marc Petit
#t 2003
#c 18
#% 16
#% 197754
#% 237200
#% 248791
#% 279120
#% 332166
#% 338594
#% 345872
#% 384978
#% 387089
#% 420062
#% 427873
#% 431033
#% 443343
#% 451552
#% 458275
#% 458869
#% 459020
#% 462214
#% 463853
#% 466664
#% 478770
#% 479814
#% 480250
#% 481290
#! In the relational model, inclusion dependencies (INDs)convey many information on data semantics. They generalizeforeign keys, which are very popular constraints inpractice. However, one seldom knows the set of satisfiedINDs in a database. The IND discovery problem in existingdatabases can be formulated as a data-mining problem.We underline in this article that the exploration of IND expressionsfrom most general (smallest) INDs to most specific(largest) INDs does not succeed whenever large INDshave to be discovered. To cope with this problem, we introducea new algorithm, called Zigzag , which combinesthe strength of levelwise algorithms (to find out some smallestINDs) with an optimistic criteria to jump more or lessto largest INDs. Preliminary tests, on synthetic databases,are presented and commented on. It is worth noting that themain result of this paper is general enough to be appliedto other data-mining problems, such as maximal frequentitemsets mining.

#index 727924
#* Localized Prediction of Continuous Target Variables Using Hierarchical Clustering
#@ Aleksandar Lazarevic;Ramdev Kanapady;Chandrika Kamath;Vipin Kumar;Kumar Tamma
#t 2003
#c 18
#% 169358
#% 236497
#% 267036
#% 727924
#! In this paper, we propose a novel technique for the efficientprediction of multiple continuous target variablesfrom high-dimensional and heterogeneous data sets usinga hierarchical clustering approach. The proposed approachconsists of three phases applied recursively:partitioning, localization and prediction. In thepartitioning step, similar target variables are groupedtogether by a clustering algorithm. In the localizationstep, a classification model is used to predict which groupof target variables is of particular interest. If theidentified group of target variables still contains a largenumber of target variables, the partitioning andlocalization steps are repeated recursively and theidentified group is further split into subgroups with moresimilar target variables. When the number of targetvariables per identified subgroup is sufficiently small, thethird step predicts target variables using localized predictionmodels built from only those data records thatcorrespond to the particular subgroup. Experimentsperformed on the problem of damage prediction incomplex mechanical structures indicate that ourproposed hierarchical approach is computationally moreefficient and more accurate than straightforward methodsof predicting each target variable individually orsimultaneously using global prediction models.

#index 727925
#* Cost-Sensitive Learning by Cost-Proportionate Example Weighting
#@ Bianca Zadrozny;John Langford;Naoki Abe
#t 2003
#c 18
#% 697
#% 61800
#% 136350
#% 178511
#% 235377
#% 264164
#% 269217
#% 280437
#% 342611
#% 458681
#% 466268
#% 466759
#% 466760
#% 1289281
#% 1499573
#! We propose and evaluate a family of methods for convertingclassifier learning algorithms and classification theoryinto cost-sensitive algorithms and theory. The proposedconversion is based on cost-proportionate weighting of thetraining examples, which can be realized either by feedingthe weights to the classification algorithm (as often done inboosting), or by careful subsampling. We give some theoreticalperformance guarantees on the proposed methods,as well as empirical evidence that they are practical alternativesto existing approaches. In particular, we proposecosting, a method based on cost-proportionate rejectionsampling and ensemble aggregation, which achievesexcellent predictive performance on two publicly availabledatasets, while drastically reducing the computation requiredby other methods.

#index 727926
#* Association Rule Mining in Peer-to-Peer Systems
#@ Ran Wolff;Assaf Schuster
#t 2003
#c 18
#% 152934
#% 227917
#% 333987
#% 340291
#% 420067
#% 443091
#% 443348
#% 461811
#% 462219
#% 481290
#% 993960
#! We extend the problem of association rule mining -a key data mining problem - to systems in which thedatabase is partitioned among a very large number ofcomputers that are dispersed over a wide area. Such computing systems include GRID computing platforms, federated database systems, and peer-to-peer computing environments. The scale of these systems poses several difficulties, such as the impracticality of global communications and global synchronization, dynamic topology changes ofthe network, on-the-fly data updates, the need to share resources with other applications, and the frequent failureand recovery of resources.We present an algorithm by which every node in thesystem can reach the exact solution, as if it were giventhe combined database. The algorithm is entirely asynchronous, imposes very little communication overhead,transparently tolerates network topology changes andnode failures, and quickly adjusts to changes in the dataas they occur. Simulation of up to 10,000 nodes show thatthe algorithm is local: all rules, except for those whoseconfidence is about equal to the confidence threshold, arediscovered using information gathered from a very smallvicinity, whose size is independent of the size of the system.

#index 727927
#* Change Profiles
#@ Taneli Mielikäinen
#t 2003
#c 18
#% 54221
#% 232136
#% 272284
#% 300120
#% 320944
#% 333877
#% 338594
#% 388196
#% 399789
#% 416497
#% 416500
#% 420062
#% 420063
#% 420141
#% 431033
#% 431097
#% 443350
#% 443502
#% 464873
#% 466487
#% 466491
#% 478770
#% 492767
#% 501536
#% 546694
#% 563249
#% 577218
#% 580670
#% 629606
#% 629630
#% 873840
#! In this paper we introduce a generalization of associationrules: change profiles. We analyze their properties, describetheir relationship to other structures in pattern discoveryand sketch their possible applications. We studyhow the frequent patterns can be clustered based on theirchange profiles and propose methods for approximating thefrequencies of the patterns from the approximate changeprofiles and bounding the intervals where the frequencies ofthe patterns are guaranteed to be. We evaluate empiricallythe methods for estimating the frequencies and the stabilityof their frequency estimates under different kinds of noise.

#index 727928
#* Optimized Disjunctive Association Rules via Sampling
#@ J. Elble;C. Heeren;L. Pitt
#t 2003
#c 18
#% 1331
#% 66937
#% 152934
#% 210162
#% 213977
#% 320944
#% 397480
#% 420080
#% 443466
#% 477982
#% 481779
#% 614619
#! The problem of finding optimized support associationrules for a single numerical attribute, where the optimizedregion is a union of k disjoint intervals from the range ofthe attribute, is investigated. The first polynomial timealgorithm for the problem of finding such a region maximizingsupport and meeting a minimum cumulative confidencethreshold is given. Because the algorithm is notpractical, an ostensibly easier, more constrained versionof the problem is considered. Experiments demonstratethat the best extant algorithm for the constrained versionhas significant performance degradation on both a syntheticmodel of patterned data and on real world data sets.Running the algorithm on a small random sample is proposedas a means of obtaining near optimal results withhigh probability. Theoretical bounds on sufficient samplesize to achieve a given performance level are proved, andrapid convergence on synthetic and real-world data is validatedexperimentally.

#index 727929
#* Privacy-preserving Distributed Clustering using Generative Models
#@ Srujana Merugu;Joydeep Ghosh
#t 2003
#c 18
#% 115608
#% 209021
#% 270531
#% 300184
#% 311027
#% 333876
#% 424995
#% 425021
#% 512307
#% 552172
#% 568869
#% 577233
#% 722902
#! We present a framework for clustering distributed datain unsupervised and semi-supervised scenarios, taking intoaccount privacy requirements and communication costs.Rather than sharing parts of the original or perturbed data,we instead transmit the parameters of suitable generativemodels built at each local data site to a central location.We mathematically show that the best representative of allthe data is a certain "mean" model, and empirically showthat this model can be approximated quite well by generatingartificial samples from the underlying distributions usingMarkov Chain Monte Carlo techniques, and then fittinga combined global model with a chosen parametric form tothese samples. We also propose a new measure that quantifiesprivacy based on information theoretic concepts, andshow that decreasing privacy leads to a higher quality of thecombined model and vice versa. We provide empirical resultson different data types to highlight the generality of ourframework. The results show that high quality distributedclustering can be achieved with little privacy loss and lowcommunication cost.

#index 727930
#* TECNO-STREAMS: Tracking Evolving Clusters in Noisy Data Streams with a Scalable Immune System Learning Model
#@ Olfa Nasraoui;Cesar Cardona Uribe;Carlos Rojas Coronel;Fabio Gonzalez
#t 2003
#c 18
#% 210173
#% 345859
#% 428155
#% 594012
#% 993958
#! Artificial Immune System (AIS) models hold many promises inthe field of unsupervised learning. However, existing models arenot scalable, which makes them of limited use in data mining. Wepropose a new AIS based clustering approach (TECNO-STREAMS)that addresses the weaknesses of current AIS models. Comparedto existing AIS based techniques, our approach exhibits superiorlearning abilities, while at the same time, requiring low memoryand computational costs. Like the natural immune system, thestrongest advantage of immune based learning compared to otherapproaches is expected to be its ease of adaptation to the dynamicenvironment that characterizes several applications, particularlyin mining data streams. We illustrate the ability of the proposedapproach in detecting clusters in noisy data sets, and in miningevolving user profiles from Web clickstream data in a single pass.TECNO-STREAMS adheres to all the requirements of clusteringdata streams: compactness of representation, fast incremental processingof new data points, and clear and fast identification of outliers.

#index 727931
#* A Dynamic Adaptive Self-Organising Hybrid Model for Text Clustering
#@ Chihli Hung;Stefan Wermter
#t 2003
#c 18
#% 46803
#% 60576
#% 67565
#% 176705
#% 391311
#% 494241
#% 577966
#% 630983
#% 815240
#% 1860651
#% 1860653
#% 1861031
#! Clustering by document concepts is a powerful way ofretrieving information from a large number of documents.This task in general does not make any assumption on thedata distribution. In this paper, for this task we propose anew competitive Self-Organising (SOM) model, namelythe Dynamic Adaptive Self-Organising Hybrid model(DASH). The features of DASH are a dynamic structure,hierarchical clustering, non-stationary data learning andparameter self-adjustment. All features are data-oriented:DASH adjusts its behaviour not only by modifying itsparameters but also by an adaptive structure. Thehierarchical growing architecture is a useful facility forsuch a competitive neural model which is designed fortext clustering. In this paper, we have presented a newtype of self-organising dynamic growing neural networkwhich can deal with the non-uniform data distributionand the non-stationary data sets and represent the innerdata structure by a hierarchical view.

#index 727932
#* Unsupervised Link Discovery in Multi-relational Data via Rarity Analysis
#@ Shou-de Lin;Hans Chalupsky
#t 2003
#c 18
#% 211348
#% 216500
#% 268079
#% 300183
#% 333929
#% 342638
#% 428982
#% 445369
#% 477821
#% 479791
#% 1290247
#! A significant portion of knowledge discovery and datamining research focuses on finding patterns of interest indata. Once a pattern is found, it can be used to recognizesatisfying instances. The new area of link discoveryrequires a complementary approach, since patterns ofinterest might not yet be known or might have too fewexamples to be learnable. This paper presents anunsupervised link discovery method aimed at discoveringunusual, interestingly linked entities in multi-relationaldatasets. Various notions of rarity are introduced tomeasure the "interestingness" of sets of paths andentities. These measurements have been implemented andapplied to a real-world bibliographic dataset where theygive very promising results.

#index 727933
#* Welcome to ICDM 2003
#@ 
#t 2003
#c 18

#index 784596
#* Proceedings of the Fourth IEEE International Conference on Data Mining
#@ 
#t 2004
#c 18

#index 785331
#* Welcome to ICDM 2004
#@ 
#t 2004
#c 18

#index 785332
#* Subspace Selection for Clustering High-Dimensional Data
#@ Christian Baumgartner;Claudia Plant;Karin Kailing;Hans-Peter Kriegel;Peer Kroger
#t 2004
#c 18
#! In high-dimensional feature spaces traditional clustering algorithms tend to break down in terms of efficiency and quality. Nevertheless, the data sets often contain clusters which are hidden in various subspaces of the original feature space. In this paper, we present a feature selection technique called SURFING (SUbspaces Relevant For clusterING) that finds all subspaces interesting for clustering and sorts them by relevance. The sorting is based on a quality criterion for the interestingness of a subspace using the k-nearest neighbor distances of the objects. As our method is more or less parameterless, it addresses the unsupervised notion of the data mining task "clustering" in a best possible way. A broad evaluation based on synthetic and real-world data sets demonstrates that SURFING is suitable to find all relevant subspaces in high dimensional, sparse data sets and produces better results than comparative methods.

#index 785333
#* Detection of Significant Sets of Episodes in Event Sequences
#@ Mikhail Atallah;Robert Gwadera;Wojciech Szpankowski
#t 2004
#c 18
#! We present a method for a reliable detection of "unusual" sets of episodes in the form of many pattern sequences, scanned simultaneously for an occurrence as a subsequence in a large event stream within a window of size w. We also investigate the important special case of all permutations of the same sequence, which models the situation where the order of events in an episode does not matter, e.g., when events correspond to purchased market basket items. In order to build a reliable monitoring system we compare obtained measurements to a reference model which in our case is a probabilistic model (Bernoulli or Markov). We first present a precise analysis that leads to a construction of a threshold. The difficulties of carrying out a probabilistic analysis for an arbitrary set of patterns, stems from the possible simultaneous occurrence of many members of the set as subsequences in the same window, the fact that the different patterns typically do have common symbols or common subsequences or possibly common prefixes, and that they may have different lengths. We also report on extensive experimental results, carried out on the Wal-Mart transactions database, that show a remarkable agreement with our theoretical analysis. This paper is an extension of our previous work in [Reliable detection of episodes in event sequences] where we laid out foundation for the problem of the reliable detection of an "unusual" episodes, but did not consider more than one episode scanned simultaneously for an occurrence.

#index 785334
#* Multi-View Clustering
#@ Steffen Bickel;Tobias Scheffer
#t 2004
#c 18
#! We consider clustering problems in which the available attributes can be split into two independent subsets, such that either subset suffices for learning. Example applications of this multi-view setting include clustering of web pages which have an intrinsic view (the pages themselves) and an extrinsic view (e.g., anchor texts of inbound hyperlinks); multi-view learning has so far been studied in the context of classification. We develop and study partitioning and agglomerative, hierarchical multi-view clustering algorithms for text data. We find empirically that the multi-view versions of k-Means and EM greatly improve on their single-view counterparts. By contrast, we obtain negative results for agglomerative hierarchical multi-view clustering. Our analysis explains this surprising phenomenon.

#index 785335
#* Density Connected Clustering with Local Subspace Preferences
#@ Christian Bohm;Karin Kailing;Hans-Peter Kriegel;Peer Kroger
#t 2004
#c 18
#! Many clustering algorithms tend to break down in high-dimensional feature spaces, because the clusters often exist only in specific subspaces (attribute subsets) of the original feature space. Therefore, the task of projected clustering (or subspace clustering) has been defined recently. As a novel solution to tackle this problem, we propose the concept of local subspace preferences, which captures the main directions of high point density. Using this concept we adopt density-based clustering to cope with high-dimensional data. In particular, we achieve the following advantages over existing approaches: Our proposed method has a determinate result, does not depend on the order of processing, is robust against noise, performs only one single scan over the database, and is linear in the number of dimensions. A broad experimental evaluation shows that our approach yields results of significantly better quality than recent work on clustering high-dimensional data.

#index 785336
#* On Closed Constrained Frequent Pattern Mining
#@ Francesco Bonchi;Claudio Lucchese
#t 2004
#c 18
#! Constrained frequent patterns and closed frequent patterns are two paradigms aimed at reducing the set of extracted patterns to a smaller, more interesting, subset. Although a lot of work has been done with both these paradigms, there is still confusion around the mining problem obtained by joining closed and constrained frequent patterns in a unique framework. In this paper we shed light on this problem by providing a formal definition and a thorough characterization. Wealso study computational issues and show how to combine the most recent results in both paradigms, providing a very efficient algorithm which exploits the two requirements (satisfying constraints and being closed) together at mining time in order to reduce the computation as much as possible.

#index 785337
#* Efficient Density-Based Clustering of Complex Objects
#@ Stefan Brecheisen;Hans-Peter Kriegel;Martin Pfeifle
#t 2004
#c 18
#! Nowadays data mining in large databases of complex objects from scientific, engineering or multimedia applications is getting more and more important. In many different application domains complex object representations along with complex distance functions are used for measuring the similarity between objects. Often not only these complex distance measures are available but also simpler distance functions which can be computed much more efficiently. Traditionally, the well known concept of multi-step query processing which is based on exact and lower-bounding approximative distance functions is used independently of data mining algorithms. In this paper, we will demonstrate how the paradigm of multi-step query processing can be integrated into the two density-based clustering algorithms DBSCAN and OPTICS resulting in a considerable efficiency boost. Our approach tries to confine itself to 驴-range queries on the simple distance functions and carries out complex distance computations only at that stage of the clustering algorithm where they are compulsory to compute the correct clustering result. In a broad experimental evaluation based on real-world test data sets, we demonstrate that our approach accelerates the generation of flat and hierarchical density-based clusterings by more than one order of magnitude.

#index 785338
#* Test-Cost Sensitive Naive Bayes Classification
#@ Xiaoyong Chai;Lin Deng;Qiang Yang;Charles X. Ling
#t 2004
#c 18
#! Inductive learning techniques such as the naive Bayes and decision tree algorithms have been extended in the past to handle different types of costs mainly by distinguishing different costs of classification errors. However, it is an equally important issue to consider how to handle the test costs associated with querying the missing values in a test case. When the value of an attribute is missing in a test case, it may or may not be worthwhile to take the effort to obtain its missing value, depending on how much the value will result in a potential gain in the classification accuracy. In this paper, we show how to obtain a test-cost sensitive naive Bayes classifier (csNB) by including a test strategy which determines how unknown attributes are selected to perform test on in order to minimize the sum of the mis-classification costs and test costs. We propose and evaluate several potential test strategies including one that allows several tests to be done at once. We empirically evaluate the csNB method, and show that it compares favorably with its decision tree counterpart.

#index 785339
#* Moment: Maintaining Closed Frequent Itemsets over a Stream Sliding Window
#@ Yun Chi;Haixun Wang;Philip S. Yu;Richard R. Muntz
#t 2004
#c 18
#! This paper considers the problem of mining closed frequent itemsets over a sliding window using limited memory space. We design a synopsis data structure to monitor transactions in the sliding window so that we can output the current closed frequent itemsets at any time. Due to time and memory constraints, the synopsis data structure cannot monitor all possible itemsets. However, monitoring only frequent itemsets will make it impossible to detect new itemsets when they become frequent. In this paper, we introduce a compact data structure, the closed enumeration tree (CET), to maintain a dynamically selected set of itemsets over a sliding-window. The selected itemsets consist of a boundary between closed frequent itemsets and the rest of the itemsets. Concept drifts in a data stream are reflected by boundary movements in the CET. In other words, a status change of any itemset (e.g., from non-frequent to frequent) must occur through the boundary. Because the boundary is relatively stable, the cost of mining closed frequent itemsets over a sliding window is dramatically reduced to that of mining transactions that can possibly cause boundary movements in the CET. Our experiments show that our algorithm performs much better than previous approaches.

#index 785340
#* Communication Efficient Construction of Decision Trees Over Heterogeneously Distributed Data
#@ Chris Giannella;Kun Liu;Todd Olsen;Hillol Kargupta
#t 2004
#c 18
#! We present an algorithm designed to efficiently construct a decision tree over heterogeneously distributed data without centralizing. We compare our algorithm against a standard centralized decision tree implementation in terms of accuracy as well as the communication complexity. Our experimental results show that by using only 20% of the communication cost necessary to centralize the data we can achieve trees with accuracy at least 80% of the trees produced by the centralized version.

#index 785341
#* Non-Redundant Data Clustering
#@ David Gondek;Thomas Hofmann
#t 2004
#c 18
#! Data clustering is a popular approach for automatically finding classes, concepts, or groups of patterns. In practice this discovery process should avoid redundancies with existing knowledge about class structures or groupings, and reveal novel, previously unknown aspects of the data. In order to deal with this problem, we present an extension of the information bottleneck framework, called coordinated conditional information bottleneck, which takes negative relevance information into account by maximizing a conditional mutual information score subject to constraints. Algorithmically, one can apply an alternating optimization scheme that can be used in conjunction with different types of numeric and non-numeric attributes. We present experimental results for applications in text mining and computer vision.

#index 785342
#* Fast and Exact Out-of-Core K-Means Clustering
#@ Anjan Goswami;Ruoming Jin;Gagan Agrawal
#t 2004
#c 18
#! Clustering has been one of the most widely studied topics in data mining and k-means clustering has been one of the popular clustering algorithms. K-means requires several passes on the entire dataset, which can make it very expensive for large disk-resident datasets. In view of this, a lot of work has been done on various approximate versions of k-means, which require only one or a small number of passes on the entire dataset. In this paper, we present a new algorithm which typically requires only one or a small numberof passes on the entire dataset, and provably produces the same cluster centers as reported by the original k-means algorithm. The algorithm uses sampling to create initial cluster centers, and then takes one or more passes over the entire dataset to adjust these cluster centers. We provide theoretical analysis to show that the cluster centers thus reported are the same as the ones computed by the original k-means algorithm. Experimental results from a number of real and synthetic datasets show speedup between a factor of 2 and 4.5, as compared to k-means.

#index 785343
#* Mining Frequent Itemsets from Secondary Memory
#@ Gosta Grahne;Jianfei Zhu
#t 2004
#c 18
#! Mining frequent itemsets is at the core of mining association rules, and is by now quite well understood algorithmically for main memory databases. In this paper, we investigate approaches to mining frequent itemsets when the database or the data structures used in the mining are too large to fit in main memory. Experimental results show that our techniques reduce the required disk accesses by orders of magnitude, and enable truly scalable data mining.

#index 785344
#* A Bayesian Framework for Regularized SVM Parameter Estimation
#@ Jens Gregor;Zhenqiu Liu
#t 2004
#c 18
#! The support vector machine (SVM) is considered here in the context of pattern classification. The emphasis is on the soft margin classifier which uses regularization to handle non-separable learning samples. We present an SVM parameter estimation algorithm that first identifies a subset of the learning samples that we call the support set and then determines not only the weights of the classifier but also the hyperparameter that controls the influence of the regularizing penalty term on basis thereof. We provide numerical results using several data sets from the public domain.

#index 785345
#* Unimodal Segmentation of Sequences
#@ Niina Haiminen;Aristides Gionis
#t 2004
#c 18
#! We study the problem of segmenting a sequence into k pieces so that the resulting segmentation satisfies monotonicity or unimodality constraints. Unimodal functions can be used to model phenomena in which a measured variable first increases to a certain level and then decreases. We combine a well-known unimodal regression algorithm with a simple dynamic-programming approach to obtain an optimal quadratic-time algorithm for the problem of unimodal k-segmentation. In addition, we describe a more efficient greedy-merging heuristic that is experimentally shown to give solutions very close to the optimal. As a concrete application of our algorithms, we describe two methods for testing if a sequence behaves unimodally or not. Our experimental evaluation shows that our algorithms and the proposed unimodality tests give very intuitive results.

#index 785346
#* Dependencies between Transcription Factor Binding Sites: Comparison between ICA, NMF, PLSA and Frequent Sets
#@ Heli Hiisila;Ella Bingham
#t 2004
#c 18
#! Gene expression of eucaryotes is regulated through transcription factors, which are molecules able to attach to the binding sites in the DNA sequence. These binding sites are small pieces of DNA usually found upstream from the gene they regulate. As the binding sites play an important role in the gene expression, it is of interest to find out their characteristics. In this paper we look for dependencies and independencies between these binding sites using independent component analysis (ICA), non-negative matrix factorization (NMF), probabilistic latent semantic analysis (PLSA) and the method of frequent sets. The data used are human gene upstream regions and possible binding sites listed in a biological database. Also, results on the baker's yeast (S.Cerevisiae) upstream regions are briefly discussed for comparison. ICA, NMF and PLSA are latent variable methods that decompose the observed data into smaller components. Of these, ICA and NMF were originally aimed for continuous data. We show that these methods can be successfully used on discrete DNA data as well. PLSA and the method of frequent sets were created for discrete data sets. The above methods reveal partially overlapping sets of possible binding sites such that the binding sites within a set are dependent of each other. The methods of frequent sets and NMF give a good overview of the most common data structures, whereas using ICA and PLSA we find large sets that are surprisingly frequent. That is, sets of very frequently occurring possible binding sites can be found near hundreds or thousands of genes; also interesting but less frequent ones co-occur surprisingly often.

#index 785347
#* Mass Spectrum Labeling: Theory and Practice
#@ Z. Huang;L. Chen;J-Y. Cai;D. Gross;D. Musicant;R. Ramakrishnan;J. Schauer;S. J. Wright
#t 2004
#c 18
#! We introduce the problem of labeling a particle's mass spectrum with the substances it contains, and develop several formal representations of the problem, taking into account practical complications such as unknown compounds and noise. This task is currently a bottle-neck in analyzing data from a new generation of instruments for real-time environmental monitoring.

#index 785348
#* Generation of Attribute Value Taxonomies from Data for Data-Driven Construction of Accurate and Compact Classifiers
#@ Dae-Ki Kang;Adrian Silvescu;Jun Zhang;Vasant Honavar
#t 2004
#c 18
#! Attribute Value Taxonomies (AVT) have been shown to be useful in constructing compact, robust, and comprehensible classifiers. However, in many application domains, human-designed AVTs are unavailable. We introduce AVT-Learner, an algorithm for automated construction of attribute value taxonomies from data. AVT-Learner uses Hierarchical Agglomerative Clustering (HAC) to cluster attribute values based on the distribution of classes that co-occur with the values. We describe experiments on UCI data sets that compare the performance of AVT-NBL (an AVT-guided Naive Bayes Learner) with that of the standard Naive Bayes Learner (NBL) applied to the original data set. Our results show that the AVTs generated by AVT-Learner are competitive with human-generated AVTs (in cases where such AVTs are available). AVT-NBL using AVTs generated by AVT-Learner achieves classification accuracies that are comparable to or higher than those obtained by NBL; and the resulting classifiers are significantly more compact than those generated by NBL.

#index 785349
#* Semi-Supervised Mixture-of-Experts Classification
#@ Grigoris Karakoulas;Ruslan Salakhutdinov
#t 2004
#c 18
#! We introduce a mixture-of-experts technique that is a generalization of mixture modeling techniques previously suggested for semi-supervised learning. We apply the bias-variance decomposition to semi-supervised classification and use the decomposition to study the effects from adding unlabeled data when learning a mixture model. Our empirical results indicate that the biggest gain from adding unlabeled data comes from the reduction of the model variance, whereas the behavior of the bias error term heavily depends on the correctness of the underlying model assumptions.

#index 785350
#* Transduction and Typicalness for Quality Assessment of Individual Classifications in Machine Learning and Data Mining
#@ Matjaz Kukar
#t 2004
#c 18
#! In the past machine learning algorithms have been successfully used in many problems, and are emerging as valuable data analysis tools. However, their serious practical use is affected by the fact, that more often than not, they cannot produce reliable and unbiased assessments of their predictions' quality. In last years, several approaches for estimating reliability or confidence of individual classifiers have emerged, many of them building upon the algorithmic theory of randomness, such as (historically ordered) transduction-based confidence estimation, typicalness-based confidence estimation, and transductive reliability estimation. Unfortunately, they all have weaknesses: either they are tightly bound with particular learning algorithms, or the interpretation of reliability estimations is not always consistent with statistical confidence levels. In the paper we propose a joint approach that compensates the mentioned weaknesses by integrating typicalness-based confidence estimation and transductive reliability estimation into joint confidence machine. The resulting confidence machine produces confidence values in the statistical sense (e.g., a confidence level of 95% means that in 95% the predicted class is also a true class), as well as provides us with a general principle that is independent of to the particular underlying classifier We perform a series of tests with several different machine learning algorithms in several problem domains. We compare our results with that of a proprietary TCM-NN method as well as with kernel density estimation. We show that the proposed method significantly outperforms density estimation methods, and how it may be used to improve their performance.

#index 785351
#* Mining Associations by Linear Inequalities
#@ Tsay Young Lin
#t 2004
#c 18
#! The main theorem is: Generalized associations of a relational table can be found by a finite set of linear inequalities within polynomial time. It is derived from the following three results, which were established in ICDM0'02 and are re-developed here. They are (1) Isomorphic Theorem: Isomorphic relations have isomorphic patterns. Such an isomorphism classifies relational tables into isomorphic classes. (2) A variant of the classical bitmaps indexes uniquely exists in each isomorphic class. We take it as the canonical model of the class. (3) All possible attributes/features can be generated by a generalized procedure of the classical AOG (attribute oriented generalization). Then, (4) the main theorem for canonical model is established. By isomorphism theorem, we had the final result (5).

#index 785352
#* Improving Text Classification using Local Latent Semantic Indexing
#@ Tao Liu;Zheng Chen;Benyu Zhang;Wei-ying Ma;Gongyi Wu
#t 2004
#c 18
#! Latent Semantic Indexing (LSI) has been shown to be extremely useful in information retrieval, but it is not an optimal representation for text classification. It always drops the text classification performance when being applied to the whole training set (global LSI) because this completely unsupervised method ignores class discrimination while only concentrating on representation. Some local LSI methods have been proposed to improve the classification by utilizing class discrimination information. However, their performance improvements over original term vectors are still very limited. In this paper, we propose a new local LSI method called "Local Relevancy Weighted LSI" to improve text classification by performing a separate Single Value Decomposition (SVD) on the transformed local region of each class. Experimental results show that our method is much better than global LSI and traditional local LSI methods on classification within a much smaller LSI dimension.

#index 785353
#* Dependency Networks for Relational Data
#@ Jennifer Neville;David Jensen
#t 2004
#c 18
#! Instance independence is a critical assumption of traditional machine learning methods contradicted by many relational datasets. For example, in scientific literature datasets there are dependencies among the references of a paper. Recent work on graphical models for relational data has demonstrated significant performance gains for models that exploit the dependencies among instances. In this paper, we present relational dependency networks (RDNs), a new form of graphical model capable of reasoning with such dependencies in a relational setting. We describe the details of RDN models and outline their strengths, most notably the ability to learn and reason with cyclic relational dependencies. We present RDN models learned on a number of real-world datasets, and evaluate the models in a classification context, showing significant performance improvements. In addition, we use synthetic data to evaluate the quality of model learning and inference procedures.

#index 785354
#* Hybrid Pre-Query Term Expansion using Latent Semantic Analysis
#@ Laurence A.  F. Park;Kotagiri Ramamohanarao
#t 2004
#c 18
#! Latent semantic retrieval methods (unlike vector space methods) take the document and query vectors and map them into a topic space to cluster related terms and documents. This produces a more precise retrieval but also a long query time. We present a new method of document retrieval which allows us to process the latent semantic information into a hybrid Latent Semantic-Vector Space query mapping. This mapping automatically expands the users query based on the latent semantic information in the document set. This expanded query is processed using a fast vector space method. Since we have the latent semantic data in a mapping, we are able to store and retrieve vector information in the same fast manner that the vector space method offers. Multiple mappings are combined to produce hybrid latent semantic retrieval which provide precision results 5% greater than the vector space method and fast query times.

#index 785355
#* SCHISM: A New Approach for Interesting Subspace Mining
#@ Karlton Sequeira;Mohammed Zaki
#t 2004
#c 18
#! High-dimensional data pose challenges to traditional clustering algorithms due to their inherent sparsity and data tend to cluster in different and possibly overlapping subspaces of the entire feature space. Finding such subspaces is called subspace mining. We present SCHISM, a new algorithm for mining interesting subspaces, using the notions of support and Chernoff-Hoeffding bounds. We use a vertical representation of the dataset, and use a depth-first search with backtracking to find maximal interesting subspaces. We test our algorithm on a number of high-dimensional synthetic and real datasets to test its effectiveness.

#index 785356
#* A Transaction-Based Neighbourhood-Driven Approach to Quantifying Interestingness of Association Rules
#@ B. Shekar;Rajesh Natarajan
#t 2004
#c 18
#! In this paper, we present a data-driven approach for ranking association rules (ARs) based on interestingness. The occurrence of unrelated or weakly related item-pairs in an AR is interesting. In the retail market-basket context, items may be related through various relationships arising due to mutual interaction, 'substitutability' and 'complementarity.' Item-relatedness is a composite of these relationships. We introduce three relatedness measures for capturing relatedness between item-pairs. These measures use the concept of function embedding to appropriately weigh the relatedness contributions due tocomplementarity and substitutability between items. We propose an interestingness coefficient by combining the three relatedness measures. We compare this with two objective measures of interestingness and show the intuitiveness of the proposed interestingness coefficient.

#index 785357
#* Probabilistic Principal Surfaces for Yeast Gene Microarray Data Mining
#@ Antonino Staiano;Lara De Vinco;Angelo Ciaramella;Giancarlo Raiconi;Roberto Tagliaferri;Roberto Amato;Giuseppe Longo;Ciro Donalek;Gennaro Miele;Diego Di Bernardo
#t 2004
#c 18
#! The recent technological advances are producing huge data sets in almost all fields of scientific research, from astronomy to genetics. Although each research field often requires ad-hoc, fine tuned, procedures to properly exploit all the available information inherently present in the data, there is an urgent need for a new generation of general computational theories and tools capable to boost most human activities of data analysis. Here we propose Probabilistic Principal Surfaces (PPS) as an effective high-D data visualization and clustering tool for data mining applications, emphasizing its flexibility and generality of use in data-rich field. In order to better illustrate the potentialities of the method, we also provide a real world case-study by discussing the use of PPS for the analysis of yeast gene expression levels from microarray chips.

#index 785358
#* On Local Spatial Outliers
#@ Pei Sun;Sanjay Chawla
#t 2004
#c 18
#! We propose a measure, Spatial Local Outlier Measure (SLOM) which captures the local behaviour of datum in their spatial neighborhood. With the help of SLOM we are able to discern local spatial outliers which are usually missed by global techniques like "three standard deviations away from the mean". Furthermore the measure takes into account the local stability around a data point and supresses the reporting of outliers in highly unstable areas, where data is too heterogeneous and the notion of outliers is not meaningful. We prove several properties of SLOM and report experiments on synthetic and real data sets which show that our approach is novel and scalable to large data sets.

#index 785359
#* MMAC: A New Multi-Class, Multi-Label Associative Classification Approach
#@ Fadi A. Thabtah;Peter Cowling;Yonghong Peng
#t 2004
#c 18
#! Building fast and accurate classifiers for large-scale databases is an important task in data mining. There is growing evidence that integrating classification and association rule mining together can produce more efficient and accurate classifiers than traditional classification techniques. In this paper, the problem of producing rules with multiple labels is investigated. We propose a new associative classification approach called multi-class, multi-label associative classification (MMAC). This paper also presents three measures for evaluating the accuracy of data mining classification approaches to a wide range of traditional and multi-label classification problems. Results for 28 different datasets show that the MMAC approach is an accurate and effective classification technique, highly competitive and scalable in comparison with other classification approaches.

#index 785360
#* Analysis of Consensus Partition in Cluster Ensemble
#@ Alexander P. Topchy;Martin H.  C. Law;Anil K. Jain;Ana L. Fred
#t 2004
#c 18
#! In combination of multiple partitions, one is usually interested in deriving a consensus solution with a quality better than that of given partitions. Several recent studies have empirically demonstrated improved accuracy of clustering ensembles on a number of artificial and real-world data sets. Unlike certain multiple supervised classifier systems, convergence properties of unsupervised clustering ensembles remain unknown for conventional combination schemes. In this paper we present formal arguments on the effectiveness of cluster ensemble from two perspectives. The first is based on a stochastic partition generation model related to re-labeling and consensus function with plurality voting. The second is to study the property of the "mean" partition of an ensemble with respect to a metric on the space of all possible partitions. In both the cases, the consensus solution can be shown to converge to a true underlying clustering solution as the number of partitions in the ensemble increases. This paper provides a rigorous justification for the use of cluster ensemble.

#index 785361
#* Privacy-Preserving Outlier Detection
#@ Jaideep Vaidya;Chris Clifton
#t 2004
#c 18
#! Outlier detection can lead to the discovery of truly unexpected knowledge in many areas such as electronic commerce, credit card fraud and especially national security. We look at the problem of finding outliers in large distributed databases where privacy/security concerns restrict the sharing of data. Both homogeneous and heterogeneous distribution of data is considered. We propose techniques to detect outliers in such scenarios while giving formal guarantees on the amount of information disclosed.

#index 785362
#* SUMMARY: Efficiently Summarizing Transactions for Clustering
#@ Jianyong Wang;George Karypis
#t 2004
#c 18
#! Frequent itemset mining was initially proposed and has been studied extensively in the context of association rule mining. In recent years, several studies have also extended its applicationto the transaction (or document) classification and clustering. However, most of the frequent-itemset based clustering algorithms need to first mine a large intermediate set of frequent itemsets in order to identify a subset of the most promising ones that can be used for clustering. In this paper, we study how to directly find a subset of high quality frequent itemsets that can be used as a concise summary of the transaction database and to clusterthe categorical data. By exploring some properties of the subset of itemsets that we are interested in, we proposed several search space pruning methods and designed an efficient algorithm called SUMMARY. Our empirical results have shown that SUMMARY runs very fast even when the minimum support is extremely low and scales very well with respect to the database size, and surprisingly, as a pure frequent itemset mining algorithm it is very effectivein clustering the categorical data and smmarizing the dense transaction databases.

#index 785363
#* Bottom-Up Generalization: A Data Mining Solution to Privacy Protection
#@ Ke Wang;Philip S. Yu;Sourav Chakraborty
#t 2004
#c 18
#! The well-known privacy-preserved data mining modifies existing data mining techniques to randomized data. In this paper, we investigate data mining as a technique for masking data, therefore, termed data mining based privacy protection. This approach incorporates partially the requirement of a targeted data mining task into the process of masking data so that essential structure is preserved in the masked data. The idea is simple but novel: we explore the data generalization concept from data mining as a way to hide detailed information, rather than discover trends and patterns. Once the data is masked, standard data mining techniques can be applied without modification. Our work demonstrated another positive use of data mining technology: not only can it discover useful patterns, but also mask private information. We consider the following privacy problem: a data holder wants to release a version of datafor building classification models, but wants to protect against linking the released data to an external source for inferring sensitive information. We adapt an iterative bottom-up generalization from data mining to generalize the data. The generalized data remains useful to classification but becomes difficult to link to other sources. The generalization space is specified by a hierarchical structure of generalizations. A key is identifying the best generalization to climb up the hierarchy at each iteration. Enumerating all candidate generalizations is impractical. We present a scalable solution that examines at most one generalization in each iteration for each attribute involved in the linking.

#index 785364
#* Aligning Boundary in Kernel Space for Learning Imbalanced Dataset
#@ Gang Wu;Edward Y. Chang
#t 2004
#c 18
#! An imbalanced training dataset poses serious problem for many real-world supervised learning tasks. In this paper, we propose a kernel-boundary-alignment algorithm, which considers training-data imbalance as prior information to augment SVMs to improve class-prediction accuracy. Using a simple example, we first show that SVMs can suffer from high incidences of false negatives when the training instances of the target class are heavily outnumbered by the training instances of a non-target class. The remedy we propose is to adjust the class boundary by modifying the kernel matrix, according to the imbalanced data distribution. Through theoretical analysis backed by empirical study, we show that our kernel-boundary-alignment algorithm works effectively on several datasets.

#index 785365
#* A Probabilistic Approach for Adapting Information Extraction Wrappers and Discovering New Attributes
#@ Tak-Lam Wong;Wai Lam
#t 2004
#c 18
#! We develop a probabilistic framework for adapting information extraction wrappers with new attribute discovery. Wrapper adaptation aims at automatically adapting a previously learned wrapper from the source Web site to a new unseen site for information extraction. One unique characteristic of our framework is that it can discover new or previously unseen attributes as well as headers from the new site. It is based on a generative model for the generation of text fragments related to attribute items and formatting data in a Web page. To solve the wrapper adaptation problem, we consider two kinds of information from the source Web site. The first kind of information is the extraction knowledge contained in the previously learned wrapper from the source Web site. The second kind of information is the previously extracted or collected items. We employ a Bayesian learning approach to automatically select a set of training examples for adapting a wrapper for the new unseen site. To solve the new attribute discovery problem, we develop a model which analyzes the surrounding text fragments of the attributes in the new unseen site. A Bayesian learning method is developed to discover the new attributes and their headers. EM technique is employed in both Bayesian learning models. We conducted extensive experiments from a number of real-world Web sites to demonstrate the effectiveness of our framework.

#index 785366
#* IRC: An Iterative Reinforcement Categorization Algorithm for Interrelated Web Objects
#@ Gui-Rong Xue;Dou Shen;Qiang Yang;Hua-Jun Zeng;Zheng Chen;Yong Yu;WenSi Xi;Wei-Ying Ma
#t 2004
#c 18
#! Most existing categorization algorithms deal with homogeneous Web data objects, and consider interrelated objects as additional features when taking the interrelationships withother types of objects into account. However, focusing on any single aspects of these interrelationships and objects will not fully reveal their true categories. In this paper, wepropose a novel categorization algorithm, the Iterative Reinforcement Categorization algorithm (IRC), to exploit the full interrelationships between the heterogeneous objects on the Web.IRC attempts to classify the interrelated Web objects by iterative reinforcement between individual classification results of different types via the interrelationships. Experiments on a clickthrough log dataset from MSN search engine show that, with the F1 measures, IRC achieves a 26.4% improvement over a pure content-based classification method, a 21% improvement over a query metadata-based method, and a 16.4% improvement over a virtual document-based method. Furthermore, our experiments show that IRC converges rapidly.

#index 785367
#* A Polygonal Line Algorithm based Nonlinear Feature Extraction Method
#@ Feng Zhang
#t 2004
#c 18
#! We propose a polygonal line based principal curve algorithm for nonlinear feature extraction, in which the nonlinearities among the multivariable data can be described by a set of local linear models. The proposed algorithm integrates the linear PCA approach with the polygonal line algorithm to represent complicated nonlinear data structure. Statistical redundancy elimination for high dimensional data is also discussed for describing the underlying principal curves without much loss of information among the original data sets. The polygonal line algorithm can produce robust and accurate nonlinear curve estimation for different multivariate data types, and it is helpful in reducing the computation complexity for existing principal curve approaches when the sample size is large.

#index 785368
#* AVT-NBL: An Algorithm for Learning Compact and Accurate Naïve Bayes Classifiers from Attribute Value Taxonomies and Data
#@ Jun Zhang;Vasant Honavar
#t 2004
#c 18
#! In many application domains, there is a need for learning algorithms that can effectively exploit attribute value taxonomies (AVT) - hierarchical groupings of attribute values - to learn compact, comprehensible, and accurate classifiers from data - including data that are partially specified. This paper describes AVT-NBL, a natural generalization of the Naïve Bayes learner (NBL), for learning classifiers from AVT and data. Our experimental results show that AVT-NBL is able to generate classifiers that are substantially more compact and more accurate than those produced by NBL on a broad range of data sets with different percentages of partiallyspecified values. We also show that AVT-NBL is more efficient in its use of training data: AVT-NBL produces classifiers that outperform those produced by NBL using substantially fewer training examples.

#index 785369
#* Cost-Guided Class Noise Handling for Effective Cost-Sensitive Learning
#@ Xingquan Zhu;Xindong Wu
#t 2004
#c 18
#! Recent research in machine learning, data mining and related areas has produced a wide variety of algorithms for cost-sensitive (CS) classification, where instead of maximizing the classification accuracy, minimizing the misclassification cost becomes the objective. However, these methods assume that training sets do not contain significant noise, which is rarely the case in real-world environments. In this paper, we systematically study the impacts of class noise on CS learning, and propose a cost-guided class noise handling algorithm to identify noise for effective CS learning. We call it Cost-guided Iterative Classification Filter (CICF), because it seamlessly integrates costs and an existing Classification Filter for noise identification. Instead of putting equal weights to handle noise in all classes in existing efforts, CICF puts more emphasis on expensive classes, which makes it especially successful in dealing with datasets with a large cost-ratio. Experimental results and comparative studies from real-world datasets indicate that the existence of noise may seriously corrupt the performance of CS classifiers, and by adopting the proposed CICF algorithm, we can significantly reduce the misclassification cost of a CS classifier in noisy environments.

#index 785370
#* Using Emerging Patterns and Decision Trees in Rare-Class Classification
#@ Hamad Alhammady;Kotagiri Ramamohanarao
#t 2004
#c 18
#! The problem of classifying rarely occurring cases is faced in many real life applications. The scarcity of the rare cases makes it difficult to classify them correctly using traditional classifiers. In this paper, we propose a new approach to use emerging patterns (EPs) and decision trees (DTs) in rare-class classification (EPDT). EPs are those itemsets whose supports in one class are significantly higher than their supports in the other classes. EPDT employs the power of EPs to improve the quality of rare-case classification. To achieve this aim, we first introduce the idea of generating new non-existing rare-class instances, and then we over-sample the most important rare-class instances. Our experiments show that EPDT outperforms many classification methods.

#index 785371
#* Dynamic Classifier Selection for Effective Mining from Noisy Data Streams
#@ Xingquan Zhu;Xindong Wu;Ying Yang
#t 2004
#c 18
#! Recently, mining from data streams has become an important and challenging task for many real-world applications such as credit card fraud protection and sensor networking. One popular solution is to separate stream data into chunks, learn a base classifier from each chunk, and then integrate all base classifiers for effective classification. In this paper, we propose a new dynamic classifier selection (DCS) mechanism to integrate base classifiers for effective mining from data streams. The proposed algorithm dynamically selects a single "best" classifier to classify each test instance at run time. Our scheme uses statistical information from attribute values, and uses each attribute to partition the evaluation set into disjoint subsets, followed by a procedure that evaluates the classification accuracy of each base classifier on these subsets. Given a test instance, its attribute values determine the subsets that the similar instances in the evaluation set have constructed, and the classifier with the highest classification accuracy on those subsets is selected to classify the test instance. Experimental results and comparative studies demonstrate the efficiency and efficacy of our method. Such a DCS scheme appears to be promising in mining data streams with dramatic concept drifting or with a significant amount of noise, where the base classifiers are likely conflictive or have low confidence.

#index 785372
#* Discovery of Functional Relationships in Multi-Relational Data using Inductive Logic Programming
#@ Alexessander Alves;Rui Camacho;Eugenio Oliveira
#t 2004
#c 18
#! ILP systems have been largely applied to datamining classification tasks with a considerable success. The use of ILP systems in regression tasks has been far less successful. Current systems have very limited numerical reasoning capabilities, which limits the application of ILP to discovery of functional relationships of numeric nature. This paper proposes improvements in numerical reasoning capabilities of ILP systems for dealing with regression tasks. It proposes the use of statistical-based techniques like Model Validation and Model Selection to improve noise handling and it introduces a new search stopping criterium based on the PAC method to evaluate learning performance. We have found these extensions essential to improve on results over machine learning and statistical-based algorithms used in the empirical evaluation study.

#index 785373
#* Attribute Measurement Policies for Time and Cost Sensitive Classification
#@ Andrew Arnt;Shlomo Zilberstein
#t 2004
#c 18
#! Attribute measurement is an important component of classification algorithms, which could limit their applicability in realtime settings. The time taken to assign a value to an unknown attribute may reduce the overall utility of the final result. We identify three different costs that must be considered, including a time sensitive utility function. We model this attribute measurement problem as a Markov decision process (MDP), and build a policy to control this process using AO* heuristic search. The results offer a cost-effective approach to attribute measurement and classification for a variety of realtime applications.

#index 785374
#* Detecting Patterns of Appliances from Total Load Data Using a Dynamic Programming Approach
#@ Michael Baranski;Jurgen Voss
#t 2004
#c 18
#! Nonintrusive Appliance Load Monitoring (NIALM) systems require sufficient accurate total load data to separate the load into its major appliances. The most available solutions separate the whole electric energy consumption based on the measurement of all three voltages and currents. Aside from the cost for special measuring devices, the intrusion into the local installation is the main problem for reaching a high market distribution. The use of standard digital electricity meters could avoid this problem but the loss of information of the measured data has to be compensated by more intelligent algorithms and implemented rules to disaggregate the total load trace of only the active power measurements. The paper presents a new NIALM approach to analyse data, collected form a standard digital electricity meter. To disaggregate the consumption of the entire active power into its major electrical end uses, an algorithm consisting of clustering methods, a genetic algorithm and a dynamic programming approach is presented. The genetic algorithm is used to combine frequently occuring events to create hypothetical finite state machines to model detectable appliances. The time series of each finite state machine is optimized using a dynamic programming method similar to the viterbi algorithm.

#index 785375
#* Text Classification by Boosting Weak Learners based on Terms and Concepts
#@ Stephan Bloehdorn;Andreas Hotho
#t 2004
#c 18
#! Document representations for text classification are typically based on the classical Bag-Of-Words paradigm. This approach comes with deficiencies that motivate the integration of features on a higher semantic level than single words. In this paper we propose an enhancement of the classical document representation through concepts extracted from background knowledge. Boosting is used for actual classification. Experimental evaluations on two well known text corpora support our approach through consistent improvement of the results.

#index 785376
#* Matching in Frequent Tree Discovery
#@ Bjorn Bringmann
#t 2004
#c 18
#! Various definitions and frameworks for discovering frequent trees in forests have been developed recently. At the heart of these frameworks lies the notion of matching, which determines when a pattern tree matches a tree in a data set. We introduce a novel notion of tree matching for use in frequent tree mining and we show that it generalizes the framework of Zaki while still being more specific than that of Termier et al. Furthermore, we show how Zaki's TreeMinerV algorithm can be adapted towards our notion of tree matching. Experiments show the promise of the approach.

#index 785377
#* A Biobjective Model to Select Features with Good Classification Quality and Low Cost
#@ Emilio Carrizosa;Belen Martin-Barragan;Dolores Romero Morales
#t 2004
#c 18
#! In this paper we address a multi-group classification problem in which we want to take into account, together with the generalization ability, cots associated with the features. This cost is not limited to an economical payment, but can also refer to risk, computational effort, space requirements, etc. In order to get a good generalization ability, we use Support Vector Machines (SVM) as the basic mechanism by considering the maximization of the margin. We formulate the problem as a biobjective mixed integer problem, for which Pareto optimal solutions can be obtained.

#index 785378
#* Incremental Mining of Frequent XML Query Patterns
#@ Yi Chen;Liang Huai Yang;Yu Guo Wang
#t 2004
#c 18
#! Recently, the discovering of frequent XML query patterns gains its focus due to its many applications in XML data management, and several algorithms have been proposed to discover frequent query patterns using the frequent structure mining techniques. In this paper we consider the problem of incremental mining of frequent XML query patterns. We propose a novel method to minimize the I/O and computation requirements for handling incremental updates.

#index 785379
#* Spam Filtering using a Markov Random Field Model with Variable Weighting Schemas
#@ Shalendra Chhabra;William S. Yerazunis;Christian Siefkes
#t 2004
#c 18
#! In this paper we present a Markov Random Field model based approach to filter spam. Our approach examines the importance of the neighborhood relationship (MRF cliques) among words in an email message for the purpose of spam classification. We propose and test several different theoretical bases for weighting schemes among corresponding neighborhood windows. Our results demonstrate that unexpected side effects depending on the neighborhood window size may have larger accuracy impact than the neighborhood relationship effects of the Markov Random Field.

#index 785380
#* An Adaptive Learning Approach for Noisy Data Streams
#@ Fang Chu;Yizhou Wang;Carlo Zaniolo
#t 2004
#c 18
#! Two critical challenges typically associated with mining data streams are concept drift and data contamination. To address these challenges, we seek learning techniques and models that are robust to noise and can adapt to changes in timely fashion. We approach the stream-mining problem using a statistical estimation framework, and propose a fast and robust discriminative model for learning noisy data streams. We build an ensemble of classifiers to achieve timely adaptation by weighting classifiers in a way that maximizes the likelihood of the data. We further employ robust statistical techniques to alleviate the problem of noise sensitivity. Experimental results on both synthetic and real-life data sets demonstrate the effectiveness of this new model learning approach.

#index 785381
#* Scalable Multi-Relational Association Mining
#@ Amanda Clare;Hugh E. Williams;Nicholas Lester
#t 2004
#c 18
#! We propose the new RADAR technique for multi-relational data mining. This permits the mining of very large collections and provides a new technique for discovering multi-relational associations. Results show that RADAR is reliable and scalable for mining a large yeast homology collection, and that it does not have the main-memory scalability constraints of the Farmer and Warmr tools.

#index 785382
#* An Evaluation of Approaches to Classification Rule Selection
#@ Frans Coenen;Paul Leng
#t 2004
#c 18
#! In this paper a number of Classification Rule evaluation measures are considered. In particular the authors review the use of a variety of selection techniques used to order classification rules contained in a classifier, and a number of mechanisms used to classify unseen data. The authors demonstrate that rule ordering founded on the size of antecedent works well given certain conditions.

#index 785383
#* Mining Frequent Closed Patterns in Microarray Data
#@ Gao Cong;Kian-Lee Tan;Anthony K.  H. Tung;Feng Pan
#t 2004
#c 18
#! Microarray data typically contains a large number of columns and a small number of rows, which poses a great challenge for existing frequent (closed) pattern mining algorithms that discover patterns in item enumeration space. In this paper, we propose two new algorithms that explore the row enumeration space to mine frequent closed patterns. Several experiments on real-life gene expression data show that the new algorithms are faster than existing algorithms, including CLOSET, CHARM, CLOSET+ and CARPENTER.

#index 785384
#* Clustering on Demand for Multiple Data Streams
#@ Bi-Ru Dai;Jen-Wei Huang;Mi-Yen Yeh;Ming-Syan Chen
#t 2004
#c 18
#! In the data stream environment, the patterns generated by the mining techniques are usually distinct at different time because of the evolution of data. In order to deal with various types of multiple data streams and to support flexible mining requirements, we devise in this paper a Clustering on Demand framework, abbreviated as COD framework, to dynamically cluster multiple data streams. While providing a general framework of clustering on multiple data streams, the COD framework has two major features, namely one data scan for online statistics collection and compact multi-resolution approximations, which are designed to address, respectively, the time and the space constraints in a data stream environment. Furthermore, with the multi-resolution approximations of data streams, flexible clustering demands can be supported.

#index 785385
#* Extensible Markov Model
#@ Margaret H. Dunham;Yu Meng;Jie Huang
#t 2004
#c 18
#! A Markov Chain is a popular data modeling tool. This paper presents a variation of Markov Chain, namely Extensible Markov Model (EMM). By providing a dynamically adjustable structure, EMM overcomes the problems caused by the static nature of the traditional Markov Chain. Therefore, EMMs are particularly well suited to model spatiotemporal data such as network traffic, environmental data, weather data, and automobile traffic. Performance studies using EMMs for spatiotemporal prediction problems show the advantages of this approach.

#index 785386
#* Using Representative-Based Clustering for Nearest Neighbor Dataset Editing
#@ Christoph F. Eick;Nidal Zeidat;Ricardo Vilalta
#t 2004
#c 18
#! The goal of dataset editing in instance-based learning is to remove objects from a training set in order to increase the accuracy of a classifier. For example, Wilson editing removes training examples that are misclassified by a nearest neighbor classifier so as to smooth the shape of the resulting decision boundaries. This paper revolves around the use of representative-based clustering algorithms for nearest neighbor dataset editing. We term this approach supervised clustering editing. The main idea is to replace a dataset by a set of cluster prototypes. A novel clustering approach called supervised clustering is introduced for this purpose. Our empirical evaluation using eight UCI datasets shows that both Wilson and supervised clustering editing improve accuracy on more than 50% of the datasets tested. However, supervised clustering editing achieves four times higher compression rates than Wilson editing.

#index 785387
#* Decision Tree Evolution Using Limited Number of Labeled Data Items from Drifting Data Streams
#@ Wei Fan;Yi-an Huang;Philip S. Yu
#t 2004
#c 18
#! Most previously proposed mining methods on data streams make an unrealistic assumption that "labelled" data stream is readily available and can be mined at anytime. However, in most real-world problems, labelled data streams are rarely immediately available. Due to this reason, models are reconstructed only when labelled data become available periodically. This passive stream mining model has several drawbacks. We propose a new concept of demand-driven active data mining. In active mining, the loss of the model is either continuously guessed without using any true class labels or estimated, whenever necessary, from a small number of instances whose actual class labels are verified by paying an affordable cost. When the estimated loss is more than a tolerable threshold, the model evolves by using a small number of instances with verified true class labels. Previous work on active mining concentrates on error guess and estimation. In this paper, we discuss several approaches on decision tree evolution.

#index 785388
#* A Machine Learning Approach to Improve Congestion Control over Wireless Computer Networks
#@ Pierre Geurts;Ibtissam El Khayat;Guy Leduc
#t 2004
#c 18
#! In this paper, we present the application of machine learning techniques to the improvement of the congestion control of TCP in wired/wireless networks. TCP is sub-optimal in hybrid wired/wireless networks because it reacts in the same way to losses due to congestion and losses due to link errors. We thus propose to use machine learning techniques to build automatically a loss classifier from a database obtained by simulations of random network topologies. Several machine learning algorithms are compared for this task and the best method for this application turns out to be decision tree boosting. It outperforms ad hoc classifiers proposed in the networking literature.

#index 785389
#* LOADED: Link-Based Outlier and Anomaly Detection in Evolving Data Sets
#@ Amol Ghoting;Matthew Eric Otey;Srinivasan Parthasarathy
#t 2004
#c 18
#! In this paper, we present LOADED, an algorithm for outlier detection in evolving data sets containing both continuous and categorical attributes. LOADED is a tunable algorithm, wherein one can trade off computation for accuracy so that domain-specific response times are achieved. Experimental results show that LOADED provides very good detection and false positive rates, which are several times better than those of existing distance-based schemes.

#index 785390
#* SVD based Term Suggestion and Ranking System
#@ David Gleich;Leonid Zhukov
#t 2004
#c 18
#! In this paper, we consider the application of the singular value decomposition (SVD) to a search term suggestion system in a pay-for-performance search market. We propose a novel positive and negative refinement method based on orthogonal subspace projections. We demonstrate that SVD subspace-based methods: 1) expand coverage by reordering the results, and 2) enhance the clustered structure of the data. The numerical experiments reported in this paper were performed on Overture's pay-per-performance search market data.

#index 785391
#* The Anatomy of a Hierarchical Clustering Engine for Web-page, News and Book Snippets
#@ Paolo Ferragina;Antonio Gulli
#t 2004
#c 18
#! In this paper, we investigate the web snippet hierarchical clustering problem in its full extent by devising an algorithmic solution, and a software prototype called SnakeT (accessible at http://roquefort.di.unipi.it/), that: (1) draws the snippets from 16 Web search engines, the Amazon collection of books a9.com, the news of Google News and the blogs of Blogline; (2) builds the clusters on-the-fly (ephemeral clustering) in response to a user query without adopting any pre-defined organization in categories; (3) labels the clusters with sentences of variable length, drawn from the snippets and possibly missing some terms, provided they are not too many;

#index 785392
#* Query-Driven Support Pattern Discovery for Classification Learning
#@ Yiqiu Han;Wai Lam
#t 2004
#c 18
#! We propose a novel query-driven lazy learning algorithm which attempts to discover useful local patterns, called support patterns, for classifying a given query. The learning is customized to the query to avoid the horizon effect. We show that this query-driven learning algorithm can guarantee to discover all support patterns with perfect expected accuracy in polynomial time. The experimental results on benchmark data sets also demonstrate that our learning algorithm really has prominent learning performance.

#index 785393
#* Evolutionary Algorithms for Clustering Gene-Expression Data
#@ Eduardo R. Hruschka;Leandro N.  de Castro;Ricardo J.  G.  B. Campello
#t 2004
#c 18
#! This work deals with the problem of automatically finding optimal partitions in bioinformatics datasets. We propose incremental improvements for a Clustering Genetic Algorithm (CGA), culminating in the Evolutionary Algorithm for Clustering (EAC). The CGA and its modified versions are evaluated in five gene-expression datasets, showing that the proposed EAC is a promising tool for clustering gene-expression data.

#index 785394
#* Mining Ratio Rules Via Principal Sparse Non-Negative Matrix Factorization
#@ Chenyong Hu;Benyu Zhang;Shuicheng Yan;Qiang Yang;Jun Yan;Zheng Chen;Wei-Ying Ma
#t 2004
#c 18
#! Association rules are traditionally designed to capture statistical relationship among itemsets in a given database. To additionally capture the quantitative association knowledge, F.Korn et al recently proposed a paradigm named Ratio Rules for quantifiable data mining. However, their approach is mainly based on Principle Component Analysis (PCA) and as a result, it cannot guarantee that the ratio coefficient is non-negative. This may lead to serious problems in the rules' application. In this paper, we propose a new method, called Principal Sparse Non-Negative Matrix Factorization (PSNMF), for learning the associations between itemsets in the form of Ratio Rules. In addition, we provide a support measurement to weigh the importance of each rule for the entire dataset.

#index 785395
#* Feature Selection via Supervised Model Construction
#@ Y. Huang;P. J. McCullagh;N. D. Black
#t 2004
#c 18
#! ReliefF is a feature mining technique, which has been successfully used in data mining applications.However, ReliefF is sensitive to the definition of relevance that is used in its implementation and when handling a large data set, it is computationally expensive.This paper presents an optimisation (Feature Selection via Supervised Model Construction) for data transformation and starter selection, and evaluates its effectiveness with C4.5.Experiments indicate that the proposed method gave improvement of computation efficiency whilst maintaining classification accuracy of trial data sets.

#index 785396
#* Mining Generalized Substructures from a Set of Labeled Graphs
#@ Akihiro Inokuchi
#t 2004
#c 18
#! The problem of mining frequent itemsets in transactional data has been studied frequently and has yielded several algorithms that can find the itemsets within a limited amount of time. Some of them can derive "generalized" frequent itemsets consisting of items at any level of a taxonomy. Recently, several approaches have been proposed to mine frequent substructures (patterns) from a set of labeled graphs. The graph mining approaches are easily extended to mine generalized patterns where some vertices and/or edges have labels at any level of a taxonomy of the labels by extending the definition of "subgraph". However, the extended method outputs a massive set of the patterns most of which are over-generalized, which causes computation explosion. In this paper, an efficient and novel method is proposed to discover all frequent patterns which are not over-generalized from labeled graphs, when taxonomies on vertex and edge labels are available.

#index 785397
#* Divide and Prosper: Comparing Models of Customer Behavior From Populations to Individuals
#@ Tianyi Jiang;Alexander Tuzhilin
#t 2004
#c 18
#! This paper compares customer segmentation, 1-to-1, and aggregate marketing approaches across a broad range of experimental settings, including multiple segmentation levels, marketing datasets, dependent variables, and different types of classifiers, segmentation techniques, and predictive measures. Our experimental results show that, overall, 1-to-1 modeling significantly outperforms the aggregate approach among high-volume customers and is never worse than aggregate approach among low-volume customers. Moreover, the best segmentation techniques tend to outperform 1-to-1 modeling among low-volume customers.

#index 785398
#* Filling-in Missing Objects in Orders
#@ Toshihiro Kamishima;Shotaro Akaho
#t 2004
#c 18
#! Filling-in techniques are important, since missing values frequently appear in real data. Such techniques have been established for categorical or numerical values. Though lists of ordered objects are widely used as representational forms (e.g., Web search results, best-seller lists), filling-in techniques for orders have received little attention. We therefore propose a simple but effective technique to fill-in missing objects in orders. We built this technique into our collaborative filtering system.

#index 785399
#* Orthogonal Decision Trees
#@ Hillol Kargupta;Haimonti Dutta
#t 2004
#c 18
#! This paper introduces orthogonal decision trees that offer an effective way to construct a redundancy-free, accurate, and meaningful representation of large decision-tree-ensembles often created by popular techniques such as Bagging, Boosting, Random Forests and many distributed and data stream mining algorithms. Orthogonal decision trees are functionally orthogonal to each other and they correspond to the principal components of the underlying function space. This paper offers a technique to construct such trees based on eigen-analysis of the ensemble and offers experimental results to document the performance of orthogonal trees on grounds of accuracy and model complexity.

#index 785400
#* Integrating Multi-Objective Genetic Algorithms into Clustering for Fuzzy Association Rules Mining
#@ Mehmet Kaya;Reda Alhajj
#t 2004
#c 18
#! In this paper, we propose an automated method to decide on the number of fuzzy sets and for the autonomous mining of both fuzzy sets and fuzzy association rules. We compare the proposed multi-objective GA based approach with: 1) CURE based approach; 2) Chien et al clustering approach. Experimental results on 100K transactions extracted from the adult data of United States census in year 2000 show that the proposed method exhibits good performance over the other two approaches in terms of runtime, number of large itemsets and number of association rules.

#index 785401
#* Feature-Based Prediction of Unknown Preferences for Nearest-Neighbor Collaborative Filtering
#@ Hyungil Kim;Juntae Kim;Jonathan Herlocker
#t 2004
#c 18
#! Recommendation systems analyze user preferences and recommend items to a user by predicting the user's preference for those items.Among various kinds of recommendation methods, collaborative filtering (CF) has been widely used and successfully applied to practical applications.However, collaborative filtering has two inherent problems: data sparseness and the cold-start problems.In this paper, we propose a method of integrating additional feature information of users and items into CF to overcome the difficulties caused by sparseness and improve the accuracy of recommendation. Several experimental results that show the effectiveness of the proposed method are also presented.

#index 785402
#* GREW-A Scalable Frequent Subgraph Discovery Algorithm
#@ Michihiro Kuramochi;George Karypis
#t 2004
#c 18
#! Existing algorithms that mine graph datasets to discover patterns corresponding to frequently occurring subgraphs can operate efficiently on graphs that are sparse, contain a large number of relatively small connected components, have vertices with low and bounded degrees, and contain well-labeled vertices and edges. However, for graphs that do not share these characteristics, these algorithms become highly unscalable. In this paper we present a heuristic algorithm called GREW to overcome the limitations of existing complete or heuristic frequent subgraph discovery algorithms. GREW is designed to operate on a large graph and to find patterns corresponding to connected subgraphs that have a large number of vertex-disjoint embeddings. Our experimental evaluation shows that GREW is efficient, can scale to very large graphs, and find non-trivial patterns.

#index 785403
#* Predicting Density-Based Spatial Clusters Over Time
#@ Chih Lai;Nga T. Nguyen
#t 2004
#c 18
#! Most of existing clustering algorithms are designed to discover snapshot clusters that reflect only the current status of a database. Snapshot clusters do not reveal the fact that clusters may either persist over a period of time, or slowly fade away as other clusters may gradually develop. Predicting dynamic cluster evolutions and their occurring periods are important because this information can guide users to prepare appropriate actions toward the right areas during the right time for the most effective results. In this paper we developed a simple but effective approach in predicting the future distance among object pairs. Objects that will be close in distance over different periods of time are then processed to discover density-based clusters that may occur or change over time.

#index 785404
#* Dynamic Daily-Living Patterns and Association Analyses in Tele-Care Systems
#@ B.-S. Lee;T. P. Martin;N. P. Clarke;B. Majeed;D. Nauck
#t 2004
#c 18
#! Tele-care systems aim to carry out intelligent analyses of a person's wellbeing using data about their daily activities. This is a very challenging task because the massive dataset is likely to be erroneous, possibly with misleading sections due to noise or missing values. Furthermore, the interpretation of the data is highly sensitive to the lifestyle of the monitored person and the environment in which they interact. In our tele-care project, sensor-network domain knowledge is used to overcome the difficulties of monitoring long-term wellbeing with an imperfect data source. In addition, a fuzzy association analysis is leveraged to implement a dynamic and flexible analysis over individual- and environment-dependent data.

#index 785405
#* Mining Temporal Patterns Without Predefined Time Windows
#@ Tao Li;Sheng Ma
#t 2004
#c 18
#! This paper proposes algorithms for discovering temporal patterns without predefined time windows.The problem of discovering temporal patterns is divided into two sub-tasks: (1) using "cheap statistics" for dependence testing and candidates removal (2) identifying the temporal relationships between dependent event types.The dependence problem is formulated as the problem of comparing two probability distributions and is solved using a technique reminiscent of the distance methods used in spatial point process, while the latter problem is solved using an approach based on Chi-Squared tests.Experiments are conducted to evalaute the effectiveness and scalability of the proposed methods.

#index 785406
#* Classifying Biomedical Citations without Labeled Training Examples
#@ Xiaoli Li;Rohit Joshi;Sreeram Ramachandaran;Tze-Yun Leong
#t 2004
#c 18
#! In this paper we introduce a novel technique for classifying text citations without labeled training examples. We first utilize the search results of a general search engine as original training data. We then proposed a mutually reinforcing learning algorithm (MRL) to mine the classification knowledge and to "clean" the training data. With the help of a set of established domain-specific ontological terms or keywords, the MRL mining step derives the relevant classification knowledge. The MRL cleaning step then builds a Naive Bayes classifier based on the mined classification knowledge and tries to clean the training set. The MRL algorithm is iteratively applied until a clean training set is obtained. We show the effectiveness of the proposed technique in the classification of biomedical citations from a large medical literature database.

#index 785407
#* Improving the Reliability of Decision Tree and Naive Bayes Learners
#@ David Lindsay;Sian Cox
#t 2004
#c 18
#! The C4.5 Decision Tree and Naive Bayes learners are known to produce unreliable probability forecasts. We have used simple Binning and Laplace Transform techniques to improve the reliability of these learners and compare their effectiveness with that of the newly developed Venn Probability Machine (VPM) meta-learner. We assess improvements in reliability using loss functions, Receiver Operator Characteristic (ROC) curves and Empirical Reliability Curves (ERC). The VPM outperforms the simple techniques to improve reliability, although at the cost of increased computational intensity and slight increase in error rate. These trade-offs are discussed.

#index 785408
#* Revealing True Subspace Clusters in High Dimensions
#@ Jinze Liu;Karl Strohmaier;Wei Wang
#t 2004
#c 18
#! Subspace clustering is one of the best approaches for discovering meaningful clusters in high dimensional space. One cluster in high dimensional space may be transcribed into multiple distinct maximal clusters by projecting onto different subspaces. A direct consequence of clustering independently in each subspace is an overwhelmingly large set of overlapping clusters which may be significantly similar. To reveal the true underlying clusters, we propose a similarity measurement of the overlapping clusters. We adopt the model of Gaussian tailed hyper-rectangles to capture the distribution of any subspace cluster. A set of experiments on a synthetic dataset demonstrates the effectiveness of our approach. Application to real gene expression data also reveals impressive meta-clusters expected by biologists.

#index 785409
#* An Adaptive Density-Based Clustering Algorithm for Spatial Database with Noise
#@ Daoying Ma;Aidong Zhang
#t 2004
#c 18
#! Clustering spatial data has various applications. Several clustering algorithms have been proposed to cluster objects in spatial databases. Spatial object distribution has significant effect on the results of clustering. Few of current algorithms consider the distribution of objects while processing clusters. In this paper, we propose an adaptive density-based clustering algorithm, ADBC, which uses a novel adaptive strategy for neighbor selection based on spatial object distribution to improve clustering accuracy. We perform a series of experiments on simulated data sets and real data sets. A comparison with DBSCAN and OPTICS shows the superiority of our new approach.

#index 785410
#* Finding Constrained Frequent Episodes Using Minimal Occurrences
#@ Xi Ma;HweeHwa Pang;Kian-Lee Tan
#t 2004
#c 18
#! Recurrent combinations of events within an event sequence, known as episodes, oftenreveal useful information. Most of the proposed episode mining algorithms adopt an apriori-like approach that generates candidates and then calculates their support levels. Obviously, such an approach is computationally expensive. Moreover, those algorithms are capable ofhandling only a limited range of constraints. In this paper, we introduce two miningalgorithms - Episode Prefix Tree (EPT) and Position Pairs Set (PPS) - based on a prefix-growth approach to overcome the above limitations. Both algorithms push constraints systematically into the mining process. Performance study shows that the proposed algorithms run considerably faster than MINEPI.

#index 785411
#* Estimation of False Negatives in Classification
#@ Sandeep Mane;Jaideep Srivastava;San-Yih Hwang;Jamshid Vayghan
#t 2004
#c 18
#! In many classification problems such as spam detection and network intrusion, a large number of unlabeled test instances are predicted negative by the classifier. However, the high costsas well as time constraints on an expert's time prevent further analysis of the "predicted false" class instances in order to segregate the false negatives from the true negatives. A systematic method is thus required to obtain an estimate of the number of false negatives. A capture-recapture based method can be used to obtain an ML-estimate of false negatives when two or more independent classifiers are available. In the case for which independence does not hold, we can apply log-linear models to obtain an estimate of false negatives. However, as shown in this paper, lesser the dependencies among the classifiers, better is the estimate obtained for false negatives. Thus, ideally independent classifiers should be used to estimate the false negatives in an unlabeled dataset. Experimental results on the spam dataset from the UCI Machine Learning Repository are presented.

#index 785412
#* Correlation Preserving Discretization
#@ Sameep Mehta;Srinivasan Parthasarathy;Hui Yang
#t 2004
#c 18
#! Discretization is a crucial preprocessing primitive for a variety of data warehousing and mining tasks. In this article we present a novel PCA-based unsupervised algorithm for the discretization of continuous attributes in multivariate datasets. The algorithm leverages the underlying correlation structure in the dataset to obtain the discrete intervals, and ensures that the inherent correlations are preserved. The approach also extends easily to datasets containing missing values. We demonstrate the efficacy of the approach on real datasets and as a preprocessing step for both classification and frequent itemset mining tasks. We also show that the intervals are meaningful and can uncover hidden patterns in data.

#index 785413
#* Active Feature-Value Acquisition for Classifier Induction
#@ Prem Melville;Maytal Saar-Tsechansky;Foster Provost;Raymond Mooney
#t 2004
#c 18
#! Many induction problems include missing data that can be acquired at a cost. For building accurate predictive models, acquiring complete information for all instances is often expensive or unnecessary, while acquiring information for a random subset of instances may not be most effective. Active feature-value acquisition tries to reduce the cost of achieving a desired model accuracy by identifying instances for which obtaining complete information is most informative. We present an approach in which instances are selected for acquisition based on the current model's accuracy and its confidence in the prediction. Experimental results demonstrate that our approach can induce accurate models using substantially fewer feature-value acquisitions as compared to alternative policies.

#index 785414
#* Privacy-Sensitive Bayesian Network Parameter Learning
#@ D. Meng;K. Sivakumar;H. Kargupta
#t 2004
#c 18
#! This paper considers the problem of learning the parameters of a Bayesian Network, assuming the structure of the network is given, from a privacy-sensitive dataset that is distributed between multiple parties. For a binary-valued dataset, we show that the count information required to estimate the conditional probabilities in a Bayesian network can be obtained as a solution to a set of linear equations involving some inner product between the relevantdifferent feature vectors. We consider a random projection-based method that was proposed elsewhere to securely compute the inner product (with a modified implementation of that method).

#index 785415
#* MMSS: Multi-Modal Story-Oriented Video Summarization
#@ Jia-Yu Pan;Hyungjeong Yang;Christos Faloutsos
#t 2004
#c 18
#! We propose multi-modal story-oriented video summarization (MMSS) which, unlike previous works that use fine-tuned, domain-specific heuristics, provides a domain-independent, graph-based framework. MMSS uncovers correlation between information of different modalities which gives meaningful story-oriented news video summaries. MMSS can also be applied for video retrieval, giving performance that matches the best traditional retrieval techniques (OKAPI and LSI), with no fine-tuned heuristics such as tf/idf.

#index 785416
#* A Comparative Study of Linear and Nonlinear Feature Extraction Methods
#@ Cheong Hee Park;Haesun Park;Panos Pardalos
#t 2004
#c 18
#! This paper presents theoretical relationships among several generalized LDA algorithms and proposes computationally efficient approaches for them utilizing the relationships. Generalized LDA algorithms are extended nonlinearly by kernel methods resulting in nonlinear discriminant analysis. Performances and computational complexities of these linear and nonlinear discriminant analysis algorithms are compared.

#index 785417
#* SVM and Graphical Algorithms: A Cooperative Approach
#@ Francois Poulet
#t 2004
#c 18
#! We present a cooperative approach using both Support Vector Machine (SVM) algorithms and visualization methods. SVM are widely used today and often give high quality results, but they are used as "black-box" (it is very difficult to explain the obtained results) and cannot treat easily very large datasets. We have developed graphical methods to help the user to evaluate and explain the SVM results. The first method is a graphical representation of the separating frontier quality, it is then linked with other visualization tools to help the user explaining SVM results. The information provided by these graphical methods is also used for SVM parameter tuning, they are then used together with automatic algorithms to deal with very large datasets on standard computers. We present an evaluation of our approach with the UCI and the Kent Ridge Bio-medical data sets.

#index 785418
#* RDF: A Density-Based Outlier Detection Method using Vertical Data Representation
#@ Dongmei Ren;Baoying Wang;William Perrizo
#t 2004
#c 18
#! Outlier detection can lead to discovering unexpected and interesting knowledge, which is critical important to some areas such as monitoring of criminal activities in electronic commerce, credit card fraud, etc. In this paper, we developed an efficient density-based outlier detection method for large datasets. Our contributions are: a) We introduce a relative density factor (RDF); b) Based on RDF, we propose an RDF-based outlier detection method which can efficiently prune the data points which are deep in clusters, and detect outliers only within the remaining small subset of the data; c) The performance of our method is further improved by means of a vertical data representation, P-trees. We tested our method with NHL and NBA data. Our method shows an order of magnitude speed improvement compared to the contemporary approaches.

#index 785419
#* Quantitative Association Rules Based on Half-Spaces: An Optimization Approach
#@ Ulrich Ruckert;Lothar Richter;Stefan Kramer
#t 2004
#c 18
#! We tackle the problem of finding association rules for quantitative data. Whereas most of the previous approaches operate on hyperrectangles, we propose a representation based on half-spaces. Consequently, the left-hand side and right-hand side of an association rule does not contain a conjunction of items or intervals, but a weighted sum of variables tested against a threshold. Since the downward closure property does not hold for such rules, we propose an optimization setting for finding locally optimal rules. A simple gradient descent algorithm optimizes a parameterized score function, where iterations optimizing the first separating hyperplane alternate with iterations optimizing the second. Experiments with two real-world data sets show that the approach finds non-random patterns and scales up well. We therefore propose quantitative association rules based on half-spaces as an interesting new class of patterns with a high potential for applications.

#index 785420
#* Evaluating Attraction in Spatial Point Patterns with an Application in the Field of Cultural History
#@ Marko Salmenkivi
#t 2004
#c 18
#! Spatial collocation rules are often useful for describing dependencies between spatial features. Still, the commonly used criteria for the interestingness of the rules and the selected neighbourhood constraints for spatial objects may be too rough for capturing the essentials of such dependencies. We demonstrate the difficulties with concrete examples on a large place-name data set. We propose a technique based on simple density estimation for assessing the interestingness with different neighbouring constraints.

#index 785421
#* Spatial Collocation Rules are Often Useful for Describing
#@ Dawit Yimam Seid;Sharad Mehrotra
#t 2004
#c 18
#! Multi-relational data mining(MRDM) is concerned with data that contains heterogeneous and semantically rich relationships among various entity types. In this paper, we introduce multi-relational iceberg-cubes (MRI-Cubes) as a scalable approach to efficiently compute data cubes (aggregations) over multiple database relations and, in particular, as mechanisms to compute frequent multi-relational patterns ("itemsets"). We also present a summary of performance results of our algorithm.

#index 785422
#* Cluster Cores-Based Clustering for High Dimensional Data
#@ Yi-Dong Shen;Zhi-Yong Shen;Shi-Ming Zhang;Qiang Yang
#t 2004
#c 18
#! We propose a new approach to clustering high dimensional data based on a novel notion of cluster cores, instead of on nearest neighbors. A cluster core is a fairly dense group with a maximal number of pairwise similar objects. It represents the core of a cluster, as all objects in a cluster are with a great degree attracted to it. As a result, building clusters from cluster cores achieves high accuracy. Other major characteristics of the approach include: (1) It uses a semantics-based similarity measure. (2) It does not incur the curse of dimensionality and is scalable linearly with the dimensionality of data. (3) It outperforms the well-known clustering algorithm, ROCK, with both lower time complexity and higher accuracy.

#index 785423
#* Metric Incremental Clustering of Nominal Data
#@ Dan Simovici;Namita Singla;Michael Kuperberg
#t 2004
#c 18
#! We present an algorithm for clustering nominal data that is based on a metric on the set of partitions of a finite set of objects; this metric is defined starting from a lower valuation of the lattice of partitions. The proposed algorithm seeks to determine a clustering partition such that the total distance between this partition and the partitions determined by the attributes of the objects has a local minimum. The resulting clustering is quite stable relative to the ordering of the objects.

#index 785424
#* On Ranking Refinements in the Step-by-Step Searching through a Product Catalogue
#@ Nenad Stojanovic
#t 2004
#c 18
#! In our previous work we have developed a logic-based approach for the refinement of ontology-based queries that enables a user to search through a repository in a step-by-step fashion. Since the set of refinements in a step can be large, they should be ranked according to their relevance for fulfilling a user's need. In this paper we present such a ranking model, which takes into account the information content (informativeness) of a refinement as well as the preferences of the user.

#index 785425
#* Learning Conditional Independence Tree for Ranking
#@ Jiang Su;Harry Zhang
#t 2004
#c 18
#! Accurate ranking is desired in many real-world data mining applications. Traditional learning algorithms, however, aim only at high classification accuracy. It has been observed that both traditional decision trees and naive Bayes produce good classification accuracy but poor probability estimates. In this paper, we use a new model, conditional independence tree (CITree), which is a combination of decision tree and naive Bayes and more suitable for ranking and more learnable in practice. We propose a novel algorithm for learning CITree for ranking, and the experiments show that the CITree algorithm outperforms the state-of-the-art decision tree learning algorithm C4.4 and naive Bayes significantly in yielding accurate rankings. Our work provides an effective data mining algorithm for applications in which an accurate ranking is required.

#index 785426
#* Supervised Latent Semantic Indexing for Document Categorization
#@ Jian-Tao Sun;Zheng Chen;Hua-Jun Zeng;Yu-Chang Lu;Chun-Yi Shi;Wei-Ying Ma
#t 2004
#c 18
#! Latent Semantic Indexing (LSI) is a successful technology in information retrieval (IR) which attempts to explore the latent semantics implied by a query or a document through representing them in a dimension-reduced space. However, LSI is not optimal for document categorization tasks because it aims to find the most representative features for document representation rather than the most discriminative ones. In this paper, we propose Supervised LSI (SLSI) which selects the most discriminative basis vectors using the training data iteratively. The extracted vectors are then used to project the documents into a reduced dimensional space for better classification. Experimental evaluations show that the SLSI approach leads to dramatic dimension reduction while achieving good classification results.

#index 785427
#* Sparse Kernel Least Squares Classifier
#@ Ping Sun
#t 2004
#c 18
#! In this paper, we propose a new learning algorithm for constructing kernel least squares classifier. The new algorithm adopts a recursive learning way and a novel two-step sparsification procedure is incorporated into learning phase. These two most importantfeatures not only provide a feasible approach for large-scale problems as it is not necessary to store the entire kernel matrix, but also produce a very sparse model with fast training and testing time. Experimental results on a number of data classification problems are presented to demonstrate the competitiveness of new proposed algorithm.

#index 785428
#* DRYADE: A New Approach for Discovering Closed Frequent Trees in Heterogeneous Tree Databases
#@ Alexandre Termier;Marie-Christine Rousset;Michele Sebag
#t 2004
#c 18
#! In this paper we present a novel algorithm for discovering tree patterns in a tree database. This algorithm uses a relaxed tree inclusion definition, making the problem more complex (checking tree inclusion is NP-complete), but allowing to mine highly heterogeneous databases. To obtain good performances, our DRYADE algorithm discovers only closed frequent tree patterns.

#index 785429
#* A Greedy Algorithm for Selecting Models in Ensembles
#@ Andrei L. Turinsky;Robert L. Grossman
#t 2004
#c 18
#! We are interested in ensembles of models built over k data sets. Common approaches are either to combine models by vote averaging, or to build a meta-model on the outputs of the local models. In this paper, we consider the model assignment approach, in which a meta-model selects one of the local statistical models for scoring. We introduce an algorithm called Greedy Data Labeling (GDL) that improves the initial data partition by reallocating some data, so that when each model is built on its local data subset, the resulting hierarchical system has minimal error. We present evidence that model assignment may in certain situations be more natural than traditional ensemble learning, and if enhanced by GDL, it often outperforms traditional ensembles.

#index 785430
#* Mining Web Data to Create Online Navigation Recommendations
#@ Juan D. Velasquez;Alejandro Bassi;Hiroshi Yasuda;Terumasa Aoki
#t 2004
#c 18
#! A system to provide online navigation recommendation for web visitors is introduced. We call visitor the anonymous user, i.e., when only data about her/his browsing behavior (web logs) are available. We first apply clustering techniques over a large sample of web data. Next, from thesignificant patterns that are discovered, a set of rules about how to use them is created. Finally, comparing the current web visitor session with the patterns, online navigation recommendations are proposed using the mentioned rules. The system was tested using data from a real web site, showing its effectiveness.

#index 785431
#* Alpha Galois Lattices
#@ Veronique Ventos;Henry Soldano;Thibaut Lamadon
#t 2004
#c 18
#! In many applications there is a need to represent a large number of data by clustering them in a hierarchy of classes. Our basic representation is a Galois lattice, a structure that exhaustively represents the whole set of concepts that are distinguishable given the instance set and the representation language. What we propose here is a method to reduce the size of the lattice, and thus simplify our view of the data, while conserving its formal structure and exhaustivity. For that purpose we use a preliminary partition of the instance set, representing the association of a "type" to each instance. By redefining the notion of extent of a term in order to cope, to a certain degree (denoted as 驴), with this partition, we define a particular family of Galois lattices denoted as Alpha Galois lattices. We also discuss the related implication rules defined as inclusion of such 驴-extents.

#index 785432
#* AGILE: A General Approach to Detect Transitions in Evolving Data Streams
#@ Jiong Yang;Wei Wang
#t 2004
#c 18
#! In many applications such as e-commerce, system diagnosis and telecommunication services, data arrives in streams at a high speed. It is common that the underlying process generating the stream may change over time, either as a result of the fundamental evolution or in response to some external stimulus. Detecting these changes is a very challenging problem of great practical importance. The overall volume of the stream usually far exceeds the available main memory and access to the data stream is typically performed via a linear scan in ascending order of the indices of the records. In this paper, we propose a novel approach, AGILE, to monitor streaming data and to detect distinguishable transitions of the underlying processes. AGILE has many advantages over the traditional Hidden Markov Model, e.g., AGILE only requires one scan of the data.

#index 785433
#* Scalable Construction of Topic Directory with Nonparametric Closed Termset Mining
#@ Hwanjo Yu;Duane Searsmith;Xiaolei Li;Jiawei Han
#t 2004
#c 18
#! A topic directory, e.g., Yahoo directory, provides a view of a document set at different levelsof abstraction and is ideal for the interactive exploration and visualization of the document set. We present a method that dynamically generates a topic directory from a document set usinga frequent closed termset mining algorithm. Our method shows experimental results of equal quality to recent document clustering methods and has additional benefits such as automatic generation of topic labels and determination of a clustering parameter.

#index 785434
#* Learning Weighted Naive Bayes with Accurate Ranking
#@ Harry Zhang;Shengli Sheng
#t 2004
#c 18
#! Naive Bayes is one of most effective classification algorithms. In many applications, however, a ranking of examples are more desirable than just classification. How to extend naive Bayes to improve its ranking performance is an interesting and useful question in practice. Weighted naive Bayes is an extension of naive Bayes, in which attributes have different weights. This paper investigates how to learn a weighted naive Bayes with accurate ranking from data, or more precisely, how to learn the weights of a weighted naive Bayes to produce accurate ranking. We explore various methods: the gain ratio method, the hill climbing method, and the Markov Chain Monte Carlo method, the hill climbing method combined with the gain ratio method, and the Markov Chain Monte Carlo method combined with the gain ratio method. Our experiments show that a weighted naive Bayes trained to produce accurate ranking outperforms naive Bayes.

#index 785435
#* Learning Rules from Highly Unbalanced Data Sets
#@ Jianping Zhang;Eric Bloedorn;Lowell Rosen;Daniel Venese
#t 2004
#c 18
#! This paper presents a simple and effective rule learning algorithm for highly unbalanced data sets. By using the small size of the minority class to its advantage this algorithm can conduct an almost exhaustive search for patterns within the known fraudulent cases. This algorithm was designed for and successfully applied to a law enforcement problem, which involves discovering common patterns of fraudulent transactions.

#index 785436
#* Relational Peculiarity Oriented Data Mining
#@ Ning Zhong;Chunnian Liu;Y. Y. Yao;Muneaki Ohshima;Mingxin Huang;Jiajin Huang
#t 2004
#c 18
#! Peculiarity rules are a new type of interesting rules which can be discovered by searching the relevance among peculiar data. A main task of mining peculiarity rules is the identification of peculiarity. Traditional methods of finding peculiar data are attribute-based approaches. This paper extends peculiarity oriented mining to relational peculiarity oriented mining. Peculiar data are identified on record level, and peculiar rules are mined and explained in a relational mining framework. The results from preliminary experiments show that relational peculiarity oriented mining is very effective.

#index 844279
#* Stability of Feature Selection Algorithms
#@ Alexandros Kalousis;Julien Prados;Melanie Hilario
#t 2005
#c 18
#% 1252
#% 132583
#% 183376
#% 197057
#% 290482
#% 312913
#% 319257
#% 389116
#% 389790
#% 413273
#% 413291
#% 425048
#% 445878
#% 452394
#% 466401
#% 535939
#% 569719
#% 578322
#% 580552
#% 720010
#% 725893
#% 741985
#% 741994
#% 742005
#% 753308
#% 763251
#% 778833
#% 884946
#% 1673602
#% 1719352
#! With the proliferation of extremely high-dimensional data, feature selection algorithms have become indispensable components of the learning process. Strangely, despite extensive work on the stability of learning algorithms, the stability of feature selection algorithms has been relatively neglected. This study is an attempt to fill that gap by quantifying the sensitivity of feature selection algorithms to variations in the training set. We assess the stability of feature selection algorithms based on the stability of the feature preferences that they express in the form of weights-scores, ranks, or a selected feature subset. We examine a number of measures to quantify the stability of feature preferences and propose an empirical way to estimate them. We perform a series of experiments with several feature selection algorithms on a set of proteomics datasets. The experiments allow us to explore the merits of each stability measure and create stability profiles of the feature selection algorithms. Finally we show how stability profiles can support the choice of a feature selection algorithm.

#index 844284
#* Proceedings of the Fifth IEEE International Conference on Data Mining
#@ 
#t 2005
#c 18

#index 844287
#* Improving Automatic Query Classification via Semi-Supervised Learning
#@ Steven M. Beitzel;Eric C. Jensen;Ophir Frieder;David D. Lewis;Abdur Chowdhury;Aleksander Kolcz
#t 2005
#c 18
#% 115608
#% 194284
#% 279755
#% 306468
#% 321635
#% 330617
#% 341006
#% 342961
#% 375017
#% 376266
#% 642982
#% 730051
#% 766447
#% 818281
#% 843735
#! Accurate topical classification of user queries allows for increased effectiveness and efficiency in general-purpose web search systems. Such classification becomes critical if the system is to return results not just from a general web collection but from topic-specific back-end databases as well. Maintaining sufficient classification recall is very difficult as web queries are typically short, yielding few features per query. This feature sparseness coupled with the high query volumes typical for a large-scale search service makes manual and supervised learning approaches alone insufficient. We use an application of computational linguistics to develop an approach for mining the vast amount of unlabeled data in web query logs to improve automatic topical web query classification. We show that our approach in combination with manual matching and supervised learning allows us to classify a substantially larger proportion of queries than any single technique. We examine the performance of each approach on a real web query stream and show that our combined method accurately classifies 46% of queries, outperforming the recall of best single approach by nearly 20%, with a 7% improvement in overall effectiveness.

#index 844288
#* ViVo: Visual Vocabulary Construction for Mining Biomedical Images
#@ Arnab Bhattacharya;Vebjorn Ljosa;Jia-Yu Pan;Mark R. Verardo;Hyungjeong Yang;Christos Faloutsos;Ambuj K. Singh
#t 2005
#c 18
#% 275779
#% 420077
#% 457912
#% 522279
#% 718478
#% 724320
#% 726464
#% 768039
#% 1022958
#% 1854913
#! Given a large collection of medical images of several conditions and treatments, how can we succinctly describe the characteristics of each setting? For example, given a large collection of retinal images from several different experimental conditions (normal, detached, reattached, etc.), how can data mining help biologists focus on important regions in the images or on the differences between different experimental conditions? If the images were text documents, we could find the main terms and concepts for each condition by existing IR methods (e.g., tf/idf and LSI). We propose something analogous, but for the much more challenging case of an image collection: We propose to automatically develop a visual vocabulary by breaking images into n 脳 n tiles and deriving key tiles ("ViVos") for each image and condition. We experiment with numerous domain-independent ways of extracting features from tiles (color histograms, textures, etc.), and several ways of choosing characteristic tiles (PCA, ICA). We perform experiments on two disparate biomedical datasets. The quantitative measure of success is classification accuracy: Our "ViVos" achieve high classification accuracy (up to 83% for a nine-class problem on feline retinal images). More importantly, qualitatively, our "ViVos" do an excellent job as "visual vocabulary terms": they have biological meaning, as corroborated by domain experts; they help spot characteristic regions of images, exactly like text vocabulary terms do for documents; and they highlight the differences between pairs of images.

#index 844289
#* Adaptive Product Normalization: Using Online Learning for Record Linkage in Comparison Shopping
#@ Mikhail Bilenko;Sugato Basu;Mehran Sahami
#t 2005
#c 18
#% 189880
#% 201889
#% 235941
#% 240955
#% 271128
#% 279755
#% 296738
#% 302390
#% 310516
#% 310533
#% 387427
#% 577238
#% 577247
#% 577263
#% 577522
#% 654467
#% 729913
#% 763697
#% 766199
#% 770798
#% 854636
#% 1673578
#! The problem of record linkage focuses on determining whether two object descriptions refer to the same underlying entity. Addressing this problem effectively has many practical applications, e.g., elimination of duplicate records in databases and citation matching for scholarly articles. In this paper, we consider a new domain where the record linkage problem is manifested: Internet comparison shopping. We address the resulting linkage setting that requires learning a similarity function between record pairs from streaming data. The learned similarity function is subsequently used in clustering to determine which records are co-referent and should be linked. We present an online machine learning method for addressing this problem, where a composite similarity function based on a linear combination of basis functions is learned incrementally. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site, and show that our method is able to effectively learn various distance functions for product data with differing characteristics. We also provide experimental results that show the importance of considering multiple performance measures in record linkage evaluation.

#index 844290
#* Using Information-Theoretic Measures to Assess Association Rule Interestingness
#@ Julien Blanchard;Fabrice Guillet;Regis Gras;Henri Briand
#t 2005
#c 18
#% 4086
#% 136350
#% 227917
#% 227919
#% 232136
#% 280436
#% 304319
#% 442814
#% 445403
#% 449566
#% 478594
#% 751575
#% 772329
#! Assessing rules with interestingness measures is the cornerstone of successful applications of association rule discovery. However, there exists no information-theoretic measure which is adapted to the semantics of association rules. In this article, we present the Directed Information Ratio (DIR), a new rule interestingness measure which is based on information theory. DIR is specially designed for association rules, and in particular it differentiates two opposite rules a → b and a → \mathop b\limits^ - . Moreover, to our knowledge, DIR is the only rule interestingness measure which rejects both independence and (what we call) equilibrium, i.e. it discards both the rules whose antecedent and consequent are negatively correlated, and the rules which have more counter-examples than examples. Experimental studies show that DIR is a very filtering measure, which is useful for association rule post-processing.

#index 844291
#* Shortest-Path Kernels on Graphs
#@ Karsten M. Borgwardt;Hans-Peter Kriegel
#t 2005
#c 18
#% 24077
#% 190581
#% 269226
#% 288232
#% 327432
#% 464615
#% 769891
#% 770868
#% 833065
#! Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classificationaccuracy than walk-based kernels.

#index 844292
#* Mining Frequent Spatio-Temporal Sequential Patterns
#@ Huiping Cao;Nikos Mamoulis;David W. Cheung
#t 2005
#c 18
#% 397383
#% 420063
#% 463903
#% 466506
#% 527319
#% 577275
#% 629644
#% 662757
#% 769899
#! Many applications track the movement of mobile objects, which can be represented as sequences of timestamped locations. Given such a spatio-temporal series, we study the problem of discovering sequential patterns, which are routes frequently followed by the object. Sequential pattern mining algorithms for transaction data are not directly applicable for this setting. The challenges to address are (i) the fuzziness of locations in patterns, and (ii) the identification of non-explicit pattern instances. In this paper, we define pattern elements as spatial regions around frequent line segments. Our method first transforms the original sequence into a list of sequence segments, and detects frequent regions in a heuristic way. Then, we propose algorithms to find patterns by employing a newly proposed substring tree structure and improving Apriori technique. A performance evaluation demonstrates the effectiveness and efficiency of our approach.

#index 844293
#* Modeling Multiple Time Series for Anomaly Detection
#@ Philip K. Chan;Matthew V. Mahoney
#t 2005
#c 18
#% 458857
#% 729931
#% 769896
#% 843676
#% 1113099
#! Our goal is to generate comprehensible and accurate models from multiple time series for anomaly detection. The models need to produce anomaly scores in an online manner for real-life monitoring tasks. We introduce three algorithms that work in a constructed feature space and evaluate them with a real data set from the NASA shuttle program. Our offline and online evaluations indicate that our algorithms can be more accurate than two existing algorithms.

#index 844294
#* Summarization — Compressing Data into an Informative Representation
#@ Varun Chandola;Vipin Kumar
#t 2005
#c 18
#% 36672
#% 152934
#% 300136
#% 310520
#% 316709
#% 387791
#% 428400
#% 428401
#% 464873
#% 478770
#% 577250
#% 629606
#% 629644
#% 769876
#% 769892
#% 835018
#! In this paper, we formulate the problem of summarization of a dataset of transactions with categorical attributes as an optimization problem involving two objective functions - compaction gain and information loss. We propose metrics to characterize the output of any summarization algorithm. We investigate two approaches to address this problem. The first approach is an adaptation of clustering and the second approach makes use of frequent itemsets from the association analysis domain. We illustrate one application of summarization in the field of network data where we show how our technique can be effectively used to summarize network traffic into a compact but meaningful representation. Specifically, we evaluate our proposed algorithms on the 1998 DARPA Off-line Intrusion Detection Evaluation data and network data generated by SKAION Corp for the ARDA information assurance program.

#index 844295
#* Labeling Unclustered Categorical Data into Clusters Based on the Important Attribute Values
#@ Hung-Leng Chen;Kun-Ta Chuang;Ming-Syan Chen
#t 2005
#c 18
#% 36672
#% 248790
#% 280419
#% 296738
#% 325357
#% 387427
#% 393844
#% 420081
#% 443531
#% 631985
#! Sampling has been recognized as an important technique to improve the efficiency of clustering. However, with sampling applied, those points which are not sampled will not have their labels. Although there is a straightforward approach in the numerical domain, the problem of how to allocate those unlabeled data points into proper clusters remains as a challenging issue in the categorical domain. In this paper, a mechanism named MAximal Resemblance Data Labeling (abbreviated as MARDL) is proposed to allocate each unlabeled data point into the corresponding appropriate cluster based on the novel categorical clustering representative, namely, Node Importance Representative(abbreviated as NIR), which represents clusters by the importance of attribute values. MARDL has two advantages: (1) MARDL exhibits high execution efficiency; (2) after each unlabeled data is allocated into the proper cluster, MARDL preserves clustering characteristics, i.e., high intra-cluster similarity and low inter-cluster similarity. MARDL is empirically validated via real and synthetic data sets, and is shown to be not only more efficient than prior methods but also attaining results of better quality.

#index 844296
#* Making Subsequence Time Series Clustering Meaningful
#@ Jason R. Chen
#t 2005
#c 18
#% 260645
#% 280482
#% 443515
#% 576113
#% 594012
#% 727900
#% 800177
#! Recently, the startling claim was made that sequential time series clustering is meaningless. This has important consequences for a significant amount of work in the literature, since such a claim invalidates this work's contribution. In this paper, we show that sequential time series clustering is not meaningless, and that the problem highlighted in these works stem from their use of the Euclidean distance metric as the distance measure in the subsequence vector space. As a solution, we consider quite a general class of time series, and propose a regime based on two types of similarity that can exist between subsequence vectors, which give rise naturally to an alternative distance measure to Euclidean distance in the subsequence vector space. We show that, using this alternative distance measure, sequential time series clustering can indeed be meaningful. We repeat a key experiment in the work on which the "meaningless" claim was based, and show that our method leads to a successful clustering outcome.

#index 844297
#* Kernel-Density-Based Clustering of Time Series Subsequences Using a Continuous Random-Walk Noise Model
#@ Anne Denton
#t 2005
#c 18
#% 232122
#% 243728
#% 310580
#% 321455
#% 349208
#% 443894
#% 534183
#% 629607
#% 659971
#% 727900
#! Noise levels in time series subsequence data are typically very high, and properties of the noise differ from those of white noise. The proposed algorithm incorporates a continuous random-walk noise model into kernel-density-based clustering. Evaluation is done by testing to what extent the resulting clusters are predictive of the process that generated the time series. It is shown that the new algorithm not only outperforms partitioning techniques that lead to trivial and unsatisfactory results under the given quality measure, but also improves upon other density-based algorithms. The results suggest that the noise elimination properties of kernel-density-based clustering algorithms can be of significant value for the use of clustering in preprocessing of data.

#index 844298
#* Usage-Based PageRank for Web Personalization
#@ Magdalini Eirinaki;Michalis Vazirgiannis
#t 2005
#c 18
#% 190611
#% 268079
#% 309777
#% 310512
#% 310543
#% 312874
#% 348173
#% 453320
#% 552184
#% 552186
#% 727326
#% 727917
#% 729919
#% 765423
#% 779871
#% 783708
#% 799787
#% 993970
#! Recommendation algorithms aim at proposing "next" pages to a user based on her current visit and the past users' navigational patterns. In the vast majority of related algorithms, only the usage data are used to produce recommendations, whereas the structural properties of the Web graph are ignored. We claim that taking also into account the web structure and using link analysis algorithms ameliorates the quality of recommendations. In this paper we present UPR, a novel personalization algorithm which combines usage data and link analysis techniques for ranking and recommending web pages to the end user. Using the web site's structure and its usage data we produce personalized navigational graph synopses (prNG) to be used for applying UPR and produce personalized recommendations. Experimental results show that the accuracy of the recommendations is superior to pure usage-based approaches.

#index 844299
#* WARP: Time Warping for Periodicity Detection
#@ Mohamed G. Elfeky;Walid G. Aref;Ahmed K. Elmagarmid
#t 2005
#c 18
#% 179696
#% 310545
#% 464986
#% 480156
#% 481609
#% 564263
#% 813978
#% 993965
#% 1015301
#! Periodicity mining is used for predicting trends in time series data. Periodicity detection is an essential process in periodicity mining to discover potential periodicity rates. Existing periodicity detection algorithms do not take into account the presence of noise, which is inevitable in almost every real-world time series data. In this paper, we tackle the problem of periodicity detection in the presence of noise. We propose a new periodicity detection algorithm that deals efficiently with all types of noise. Based on time warping, the proposed algorithm warps (extends or shrinks) the time axis at various locations to optimally remove the noise. Experimental results show that the proposed algorithm out-performs the existing periodicity detection algorithms in terms of noise resiliency.

#index 844300
#* Bifold Constraint-Based Mining by Simultaneous Monotone and Anti-Monotone Checking
#@ Mohammad El-Hajj;Osmar R. Zaiane;Paul Nalos
#t 2005
#c 18
#% 152934
#% 273899
#% 300120
#% 310558
#% 464989
#% 465003
#% 481290
#% 577215
#% 727876
#% 785336
#% 823411
#! Mining for frequent itemsets can generate an overwhelming number of patterns, often exceeding the size of the original transactional database. One way to deal with this issue is to set filters and interestingness measures. Others advocate the use of constraints to apply to the patterns, either on the form of the patterns or on descriptors of the items in the patterns. However, typically the filtering of patterns based on these constraints is done as a post-processing phase. Filtering the patterns post-mining adds a significant overhead, still suffers from the sheer size of the pattern set and loses the opportunity to exploit those constraints. In this paper we propose an approach that allows the efficientmining of frequent itemsets patterns, while pushing simultaneously both monotone and anti-monotone constraints during and at different strategic stages of the mining process. Our implementation shows a significant improvement when considering the constraints early and a better performance over Dualminer which also considers both types of constraints.

#index 844301
#* Effective Estimation of Posterior Probabilities: Explaining the Accuracy of Randomized Decision Tree Approaches
#@ Wei Fan;Ed Greengrass;Joe McCloskey;Philip S. Yu;Kevin Drummey
#t 2005
#c 18
#% 132583
#% 209021
#% 236656
#% 312727
#% 314785
#% 376266
#% 400847
#% 424997
#% 577298
#% 580510
#% 727888
#% 1250172
#% 1707849
#! There has been increasing number of independently proposed randomization methods in different stages of decision tree construction to build multiple trees. Randomized decision tree methods have been reported to be significantly more accurate than widely-accepted single decision trees, although the training procedure of some methods incorporates a surprisingly random factor and therefore opposes the generally accepted idea of employing gain functions to choose optimum features at each node and compute a single tree that fits the data. One important question that is not well understood yet is the reason behind the high accuracy. We provide an insight based on posterior probability estimations. We first establish the relationship between effective posterior probability estimation and effective loss reduction. We argue that randomized decision tree methods effectively approximate the true probability distribution using the decision tree hypothesis space. We conduct experiments using both synthetic and real-world datasets under both 0-1 and cost-sensitive loss functions.

#index 844302
#* A Thorough Experimental Study of Datasets for Frequent Itemsets
#@ Frederic Flouvat;Fabien De Marchi;Jean-Marc Petit
#t 2005
#c 18
#% 583
#% 152934
#% 279120
#% 300120
#% 333877
#% 338594
#% 420062
#% 431033
#% 465003
#% 466664
#% 481290
#% 502141
#% 576118
#% 727923
#% 737325
#% 800615
#% 1698990
#! The discovery of frequent patterns is a famous problem in data mining. While plenty of algorithms have been proposed during the last decade, only a few contributions have tried to understand the influence of datasets on the algorithms behavior. Being able to explain why certain algorithms are likely to perform very well or very poorly on some datasets is still an open question. In this setting, we describe a thorough experimental study of datasets with respect to frequent itemsets. We study the distribution of frequent itemsets with respect to itemsets size together with the distribution of three concise representations: frequent closed, frequent free and frequent essential itemsets. For each of them, we also study the distribution of their positive and negative borders whenever possible. From this analysis, we exhibit a new characterization of datasets and some invariants allowing to better predict the behavior of well known algorithms. The main perspective of this work is to devise adaptive algorithms with respect to dataset characteristics.

#index 844303
#* AMIOT: Induced Ordered Tree Mining in Tree-Structured Databases
#@ Shohei Hido;Hiroyuki Kawano
#t 2005
#c 18
#% 248791
#% 300120
#% 478274
#% 481290
#% 577218
#% 765125
#! Frequent subtree mining has become increasingly important in recent years. In this paper, we present AMIOT algorithm to discover all frequent ordered subtrees in a tree-structured database. In order to avoid the generation of infrequent candidate trees, we propose the techniques such as right-and-left tree join and serial tree extension. Proposed methods enumerate only the candidate trees with high probability of being frequent without any duplications. The experiments on synthetic dataset and XML database show that AMIOT reduces redundant candidate trees and outperforms FREQT algorithm by up to five times in execution time.

#index 844304
#* Hierarchy-Regularized Latent Semantic Indexing
#@ Yi Huang;Kai Yu;Matthias Schubert;Shipeng Yu;Volker Tresp;Hans-Peter Kriegel
#t 2005
#c 18
#% 269226
#% 280817
#% 290830
#% 309141
#% 420507
#% 458379
#% 465747
#% 465754
#% 466078
#% 592143
#% 642998
#% 770796
#% 783478
#! Organizing textual documents into a hierarchical taxonomy is a common practice in knowledge management. Beside textual features, the hierarchical structure of directories reflect additional and important knowledge annotated by experts. It is generally desired to incorporate this information into text mining processes. In this paper, we propose hierarchy-regularized latent semantic indexing, which encodes the hierarchy into a similarity graph of documents and then formulates an optimization problem mapping each document into a low dimensional vector space. The new feature space preserves the intrinsic structure of the original taxonomy and thus provides a meaningful basis for various learning tasks like visualization and classification. Our approach employs the information about class proximity and class specificity, and can naturally cope with multi-labeled documents. Our empirical studies show very encouraging results on two real-world data sets, the new Reuters (RCV1) benchmark and the Swissprot protein database.

#index 844305
#* Extracting Frequent Subsequences from a Single Long Data Sequence: A Novel Anti-Monotonic Measure and a Simple On-Line Algorithm
#@ Koji Iwanuma;Ryuichi Ishihara;Yo Takano;Hidetomo Nabeshima
#t 2005
#c 18
#% 259993
#% 310542
#% 414993
#% 463903
#% 464996
#% 569754
#% 815238
#% 993960
#! In this paper, we study frequent-subsequence extraction from a single very-long data-sequence. First we propose a novel frequency measure, called the total frequency, for counting multiple occurrences of a sequential pattern in a single data sequence. The total frequency is anti-monotonic, and makes it possible to count up pattern occurrences without duplication. Moreover the total frequency has a good property for implementation based on the dynamic programming strategy. Second we give a simple on-line algorithm for a specialized subsequence extraction problem, i.e., a problem with the infinite window-length. This specialized problem is considered to be a relaxation of the general-case problem, thus this fast on-line algorithm is important from the view of practical applications.

#index 844306
#* Mining Minimal Distinguishing Subsequence Patterns with Gap Constraints
#@ Xiaonan Ji;James Bailey;Guozhu Dong
#t 2005
#c 18
#% 280409
#% 316552
#% 329537
#% 379331
#% 420126
#% 445371
#% 570158
#% 577256
#% 587757
#% 729935
#% 729953
#% 745515
#% 778732
#% 799764
#! Discovering contrasts between collections of data is an important task in data mining. In this paper, we introduce a new type of contrast pattern, called a Minimal Distinguishing Subsequence (MDS). An MDS is a minimal subsequence that occurs frequently in one class of sequences and infrequently in sequences of another class. It is a natural way of representing strong and succinct contrast information between two sequential datasets and can be useful in applications such as protein comparison, document comparison and building sequential classification models. Mining MDS patterns is a challenging task and is significantly different from mining contrasts between relational/transactional data. One particularly important type of constraint that can be integrated into the mining process is the maximum gap constraint. We present an efficient algorithm called ConSGapMiner, to mine all MDSs according to a maximum gap constraint. It employs highly efficient bitset and boolean operations, for powerful gap based pruning within a prefix growth framework. A performance evaluation with both sparse and dense datasets, demonstrates the scalability of ConSGapMiner and shows its ability to mine patterns from high dimensional datasets at low supports.

#index 844307
#* Learning Instance Greedily Cloning Naive Bayes for Ranking
#@ Liangxiao Jiang;Harry Zhang
#t 2005
#c 18
#% 246243
#% 246831
#% 246832
#% 290482
#% 321059
#% 349550
#% 466086
#% 502131
#% 580510
#% 1378224
#% 1673007
#% 1713157
#! Naive Bayes (simply NB) [12] has been widely used in machine learning and data mining as a simple and effective classification algorithm. Since its conditional independence assumption is rarely true, researchers have made a substantial amount of effort to improve naive Bayes. The related research work can be broadly divided into two approaches: eager learning and lazy learning, depending on when the major computation occurs. Different from eager approach, the key idea for extending naive Bayes from the lazy approach is to learn a naive Bayes for each testing example. In recent years, some lazy extensions of naive Bayes have been proposed. For example, SNNB [18], LWNB [7], and LBR [19]. All are aiming at improving the classification accuracy of naive Bayes. In many real-world machine learning and data mining applications, however, an accurate ranking is more desirable than an accurate classification. Responding to this fact, we present a lazy learning algorithm called instance greedily cloning naive Bayes (simply IGCNB) in this paper. Our motivation is to improve naive Bayes' ranking performance measured by AUC [4, 14]. We experimentally tested our algorithm, using the whole 36 UCI datasets recommended by Weka [1], and compared it to C4.4 [16], NB [12], SNNB [18] and LWNB [7]. The experimental results show that our algorithm outperforms all the other algorithms used to compare significantly in yielding accurate ranking.

#index 844308
#* An Algorithm for In-Core Frequent Itemset Mining on Streaming Data
#@ Ruoming Jin;Gagan Agrawal
#t 2005
#c 18
#% 201894
#% 232136
#% 273898
#% 300120
#% 342643
#% 378388
#% 434348
#% 443348
#% 481290
#% 481754
#% 481779
#% 729920
#% 785339
#% 993960
#% 1016146
#! Frequent itemset mining is a core data mining operation and has been extensively studied over the last decade. This paper takes a new approach for this problem and makes two major contributions. First, we present a one pass algorithm for frequent itemset mining, which has deterministic bounds on the accuracy, and does not require any out-of-core summary structure. Second, because our one pass algorithm does not produce any false negatives, it can be easily extended to a two pass accurate algorithm. Our two pass algorithm is very memory efficient, and allows mining of datasets with large number of distinct items and/or very low support levels. Our detailed experimental evaluation on synthetic and real datasets shows the following. First, our one pass algorithm is very accurate in practice. Second, our algorithm requires significantly lower memory than Manku and Motwani's one pass algorithm and the multi-pass Apriori algorithm. Our two pass algorithm outperforms Apriori and FP-tree when the number of distinct items is large and/or support levels are very low. In other cases, it is quite competitive, with possible exception of cases where the average length of frequent itemsets is quite high.

#index 844309
#* Stability of Feature Selection Algorithms
#@ Alexandros Kalousis;Julien Prados;Melanie Hilario
#t 2005
#c 18
#% 132583
#% 197057
#% 290482
#% 425048
#% 466401
#% 720010
#% 1673602
#! With the proliferation of extremely high-dimensional data, feature selection algorithms have become indispensable components of the learning process. Strangely, despite extensive work on the stability of learning algorithms, the stability of feature selection algorithms has been relatively neglected. This study is an attempt to fill that gap by quantifying the sensitivity of feature selection algorithms to variations in the training set. We assess the stability of feature selection algorithms based on the stability of the feature preferences that they express in the form of weights-scores, ranks, or a selected feature subset. We examine a number of measures to quantify the stability of feature preferences and propose an empirical way to estimate them. We perform a series of experiments with several feature selection algorithms on a set of proteomics datasets. The experiments allow us to explore the merits of each stability measure and create stability profiles of the feature selection algorithms. Finally we show how stability profiles can support the choice of a feature selection algorithm.

#index 844310
#* HOT SAX: Efficiently Finding the Most Unusual Time Series Subsequence
#@ Eamonn Keogh;Jessica Lin;Ada Fu
#t 2005
#c 18
#% 70370
#% 282232
#% 497916
#% 570886
#% 577221
#% 662750
#% 720645
#% 729960
#% 769896
#% 769922
#! In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. As we will show, discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.

#index 844311
#* Orthogonal Neighborhood Preserving Projections
#@ E. Kokiopoulou;Y. Saad
#t 2005
#c 18
#% 593047
#% 723241
#% 791368
#! Orthogonal Neighborhood Preserving Projections (ONPP) is a linear dimensionality reduction technique which attempts to preserve both the intrinsic neighborhood geometry of the data samples and the global geometry. The proposed technique constructs a weighted data graph where the weights are constructed in a data-driven fashion, similarly to Locally Linear Embedding (LLE). A major difference with the standard LLE where the mapping between the input and the reduced spaces is implicit, is that ONPP employs an explicit linear mapping between the two. As a result, and in contrast with LLE, handling new data samples becomes straightforward, as this amounts to a simple linear transformation. ONPP shares some of the properties of Locality Preserving Projections (LPP). Both ONPP and LPP rely on a k-nearest neighbor graph in order to capture the data topology. However, our algorithm inherits the characteristics of LLE in preserving the structure of local neighborhoods, while LPP aims at preserving only locality without specifically aiming at preserving the geometric structure. This feature makes ONPP an effective method for data visualization. We provide ample experimental evidence to demonstrate the advantageous characteristics of ONPP, using well known synthetic test cases as well as real life data from computational biology and computer vision.

#index 844312
#* Higher-Order Web Link Analysis Using Multilinear Algebra
#@ Tamara G. Kolda;Brett W. Bader;Joseph P. Kenny
#t 2005
#c 18
#% 49501
#% 200694
#% 262061
#% 268073
#% 268079
#% 290830
#% 309868
#% 340147
#% 340932
#% 348172
#% 348173
#% 348174
#% 397169
#% 415697
#% 415767
#% 438136
#% 457831
#% 466574
#% 643069
#% 722914
#% 748024
#% 785390
#% 787098
#% 804808
#% 805877
#% 910167
#% 1289272
#% 1719430
#! Linear algebra is a powerful and proven tool in web search. Techniques, such as the PageRank algorithm of Brin and Page and the HITS algorithm of Kleinberg, score web pages based on the principal eigenvector (or singular vector) of a particular non-negative matrix that captures the hyperlink structure of the web graph. We propose and test a new methodology that uses multilinear algebra to elicit more information from a higher-order representation of the hyperlink graph. We start by labeling the edges in our graph with the anchor text of the hyperlinks so that the associated linear algebra representation is a sparse, three-way tensor. The first two dimensions of the tensor represent the web pages while the third dimension adds the anchor text. We then use the rank-1 factors of a multilinear PARAFAC tensor decomposition, which are akin to singular vectors of the SVD, to automatically identify topics in the collection along with the associated authoritative web pages.

#index 844313
#* A Generic Framework for Efficient Subspace Clustering of High-Dimensional Data
#@ Hans-Peter Kriegel;Peer Kroger;Matthias Renz;Sebastian Wurst
#t 2005
#c 18
#% 248792
#% 273891
#% 280417
#% 397384
#% 629628
#% 659967
#% 765518
#% 785332
#% 785335
#! Subspace clustering has been investigated extensively since traditional clustering algorithms often fail to detect meaningful clusters in high-dimensional data spaces. Many recently proposed subspace clustering methods suffer from two severe problems: First, the algorithms typically scale exponentially with the data dimensionality and/or the subspace dimensionality of the clusters. Second, for performance reasons, many algorithms use a global density threshold for clustering, which is quite questionable since clusters in subspaces of significantly different dimensionality will most likely exhibt significantly varying densities. In this paper, we propose a generic framework to overcome these limitations. Our framework is based on an efficient filter-refinement architecture that scales at most quadratic w.r.t. the data dimensionality and the dimensionality of the subspace clusters. It can be applied to any clustering notions including notions that are based on a local density threshold. A broad experimental evaluation on synthetic and real-world data empirically shows that our method achieves a significant gain of runtime and quality in comparison to state-of-the-art subspace clustering algorithms.

#index 844314
#* Effective and Efficient Distributed Model-Based Clustering
#@ Hans-Peter Kriegel;Peer Kroger;Alexey Pryakhin;Matthias Schubert
#t 2005
#c 18
#% 338588
#% 420097
#% 430746
#% 552172
#% 568869
#% 799757
#! In many companies data is distributed among several sites, i.e. each site generates its own data and manages its own data repository. Analyzing and mining these distributed sources requires distributed data mining techniques to find global patterns representing the complete information. The transmission of the entire local data set is often unacceptable because of performance considerations, privacy and security aspects, and bandwidth constraints. Traditional data mining algorithms, demanding access to complete data, are not appropriate for distributed applications. Thus, there is a need for distributed data mining algorithms in order to analyze and discover new knowledge in distributed environments. One of the most important data mining tasks is clustering which aims at detecting groups of similar data objects. In this paper, we propose a distributed model-based clustering algorithm that uses EM for detecting local models in terms of mixtures of Gaussian distributions. We propose an efficient and effective algorithm for deriving and merging these local Gaussian distributions to generate a meaningful global model. In a broad experimental evaluation we show that our framework is scalable in a highly distributed environment.

#index 844315
#* Finding Maximal Frequent Itemsets over Online Data Streams Adaptively
#@ Daesu Lee;Wonsuk Lee
#t 2005
#c 18
#% 227917
#% 310507
#% 342600
#% 342627
#% 481290
#% 487507
#% 660003
#% 729959
#% 993960
#! Due to the characteristics of a data stream, it is very important to confine the memory usage of a data mining process regardless of the amount of information generated in the data stream. For this purpose, this paper proposes a CP-tree (Compressed-prefix tree)that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream. Unlike a prefix tree, a node of a CP-tree can maintain the information of several itemsets together. Based on this characteristic, the size of a CP-tree can be flexibly controlled by merging or splitting nodes. In this paper, a mining method employing a CP-tree is proposed and an adaptive memory utilization scheme is also presented in order to maximize the mining accuracy of the proposed method for confined memory space at all times. Finally, the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics.

#index 844316
#* CanTree: A Tree Structure for Efficient Incremental Mining of Frequent Patterns
#@ Carson Kai-Sang Leung;Quamrul I. Khan;Tariqul Hoque
#t 2005
#c 18
#% 152934
#% 210162
#% 227919
#% 248784
#% 248785
#% 248791
#% 248813
#% 273898
#% 280467
#% 300120
#% 399794
#% 443164
#% 464204
#% 464989
#% 481290
#% 511333
#% 577215
#% 629681
#% 659977
#% 729418
#% 731405
#% 769889
#% 775838
#% 785336
#! Since its introduction, frequent-pattern mining has been the subject of numerous studies, including incremental updating. Many existing incremental mining algorithms are Apriori-based, which are not easily adoptable to FP-tree based frequent-pattern mining. In this paper, we propose a novel tree structure, called CanTree (Canonical-order Tree), that captures the content of the transaction database and orders tree nodes according to some canonical order. By exploiting its nice properties, the CanTree can be easily maintained when database transactions are inserted, deleted, and/or modified. For example, the CanTree does not require adjustment, merging, and/or splitting of tree nodes during maintenance. No rescan of the entire updated database or reconstruction of a new tree is needed for incremental updating. Experimental results show the effectiveness of our CanTree.

#index 844317
#* Combining Multiple Clusterings by Soft Correspondence
#@ Bo Long;Zhongfei (Mark) Zhang;Philip S. Yu
#t 2005
#c 18
#% 36672
#% 239588
#% 274612
#% 494396
#% 551737
#% 571905
#% 578670
#% 727903
#% 770836
#% 785360
#! Combining multiple clusterings arises in various important data mining scenarios. However, finding a consensus clustering from multiple clusterings is a challenging task because there is no explicit correspondence between the classes from different clusterings. We present a new framework based on soft correspondence to directly address the correspondence problem in combining multiple clusterings. Under this framework, we propose a novel algorithm that iteratively computes the consensus clustering and correspondence matrices using multiplicative updating rules. This algorithm provides a final consensus clustering as well as correspondence matrices that gives intuitive interpretation of the relations between the consensus clustering and each clustering from clustering ensembles. Extensive experimental evaluations also demonstrate the effectiveness and potential of this framework as well as the algorithm for discovering a consensus clustering from multiple clusterings.

#index 844318
#* A New Algorithm for Finding Minimal Sample Uniques for Use in Statistical Disclosure Assessment
#@ A. M. Manning;D. J. Haglin
#t 2005
#c 18
#% 152934
#% 465003
#% 487496
#% 576757
#! We present SUDA2, a recursive algorithm for finding Minimal Sample Uniques (MSUs). SUDA2 uses a novel method for representing the search space forMSUs and new observations about the properties ofMSUs to prune and traverse this space. Experimental comparisons with previous work demonstrate that SUDA2 is not only several orders of magnitude faster but is also capable of identifying the boundaries of the search space, enabling datasets of larger numbers of columns than before to be addressed.

#index 844319
#* Alternate Representation of Distance Matrices for Characterization of Protein Structure
#@ Keith Marsolo;Srinivasan Parthasarathy
#t 2005
#c 18
#% 116390
#% 136350
#% 451146
#% 565764
#% 762841
#% 842797
#! The most suitable method for the automated classification of protein structures remains an open problem in computational biology. In order to classify a protein structure with any accuracy, an effective representation must be chosen. Here we present two methods of representing protein structure. One involves representing the distances between the Cá atoms of a protein as a two-dimensional matrix and creating a model of the resulting surface with Zernike polynomials. The second uses a wavelet-based approach. We convert the distances between a protein's Cα atoms into a one-dimensional signal which is then decomposed using a discrete wavelet transformation. Using the Zernike co-efficients and the approximation coefficients of the wavelet decomposition as feature vectors, we test the effectiveness of our representation with two different classifiers on a dataset of more than 600 proteins taken from the 27 most-populated SCOP folds. We find that the wavelet decomposition greatly outperforms the Zernike model.With the wavelet representation, we achieve an accuracy of approximately 56%, roughly 12% higher than results reported on a similar, but less-challenging dataset. In addition, we can couple our structure-based feature vectors with several sequence-based properties to increase accuracy another 5-7%. Finally, we use a multi-stage classification strategy on the combined features to increase performance to 78%, an improvement in accuracy of more than 15-20% and 34% over the highest reported sequence-based and structure-based classification results, respectively.

#index 844320
#* Training Support Vector Machines Using Gilbert's Algorithm
#@ Shawn Martin
#t 2005
#c 18
#% 116149
#% 197394
#% 269217
#% 269218
#% 338577
#% 420077
#% 837668
#% 1860545
#% 1860609
#! Support Vector Machines are classifiers designed around the computation of an optimal separating hyperplane. This hyperplane is typically obtained by solving a constrained quadratic programming problem, but may also be located by solving a nearest point problem. Gilbert's Algorithm can be used to solve this nearest point problem but is unreasonably slow. In this paper we present a modified version of Gilbert's Algorithm for the fast computation of the Support Vector Machine hyperplane. We then compare our algorithm with the Nearest Point Algorithm and with Sequential Minimal Optimization.

#index 844321
#* A Heterogeneous Field Matching Method for Record Linkage
#@ Steven N. Minton;Claude Nanjo;Craig A. Knoblock;Martin Michalowski;Matthew Michelson
#t 2005
#c 18
#% 201889
#% 269217
#% 577238
#% 577247
#% 577263
#% 729913
#% 788090
#% 1271899
#! Record linkage is the process of determining that two records refer to the same entity. A key subprocess is evaluating how well the individual fields, or attributes, of the records match each other. One approach to matching fields is to use hand-written domain-specific rules. This "expert systems" approach may result in good performance for specific applications, but it is not scalable. This paper describes a new machine learning approach that creates expert-like rules for field matching. In our approach, the relationship between two field values is described by a set of heterogeneous transformations. Previous machine learning methods used simple models to evaluate the distance between two fields. However, our approach enables more sophisticated relationships to be modeled, which better capture the complex domain specific, common-sense phenomena that humans use to judge similarity. We compare our approach to methods that rely on simpler homogeneous models in several domains. By modeling more complex relationships we produce more accurate results.

#index 844322
#* Leveraging Relational Autocorrelation with Latent Group Models
#@ Jennifer Neville;David Jensen
#t 2005
#c 18
#% 248810
#% 266215
#% 282905
#% 313959
#% 464449
#% 466896
#% 578775
#% 722904
#% 727834
#% 729982
#% 769942
#% 769954
#% 785353
#% 1273824
#% 1289267
#% 1650403
#! The presence of autocorrelation provides a strong motivation for using relational learning and inference techniques. Autocorrelation is a statistical dependence between the values of the same variable on related entities and is a nearly ubiquitous characteristic of relational data sets. Recent research has explored the use of collective inference techniques to exploit this phenomenon. These techniques achieve significant performance gains by modeling observed correlations among class labels of related instances, but the models fail to capture a frequent cause of autocorrelation — the presence of underlying groups thatinfluence the attributes on a set of entities. We propose a latent group model (LGM) for relational data, which discovers and exploits the hidden structures responsible for the observed autocorrelation among class labels. Modeling the latent group structure improves model performance, increases inference efficiency, and enhances our understanding of the datasets. We evaluate performance on three relational classification tasks and show that LGM outperforms models that ignore latent group structure, particularly when there is little information with which to seed inference.

#index 844323
#* Balancing Exploration and Exploitation: A New Algorithm for Active Machine Learning
#@ Thomas Osugi;Deng Kun;Stephen Scott
#t 2005
#c 18
#% 116165
#% 236729
#% 310503
#% 464268
#% 466419
#% 466576
#% 722797
#% 735357
#% 737982
#% 763705
#% 765387
#% 770771
#% 772867
#% 810437
#% 829013
#! Active machine learning algorithms are used when large numbers of unlabeled examples are available and getting labels for them is costly (e.g. requiring consulting a human expert). Many conventional active learning algorithms focus on refining the decision boundary, at the expense of exploring new regions that the current hypothesis misclassifies.We propose a new active learning algorithm that balances such exploration with refining of the decision boundary by dynamically adjusting the probability to explore at each step. Our experimental results demonstrate improved performance on data sets that require extensive exploration while remaining competitive on data sets that do not. Our algorithm also shows significant tolerance of noise.

#index 844324
#* Finding Representative Set from Massive Data
#@ Feng Pan;Wei Wang;Anthony K.  H. Tung;Jiong Yang
#t 2005
#c 18
#% 115608
#% 309128
#% 594009
#% 722934
#% 769881
#% 769897
#% 785362
#! In the information age, data is pervasive. In some applications, data explosion is a significant phenomenon. The massive data volume poses challenges to both human users and computers. In this project, we propose a new model for identifying representative set from a large database. A representative set is a special subset of the original dataset, which has three main characteristics: It is significantly smaller in size compared to the original dataset. It captures the most information from the original dataset compared to other subsets of the same size. It has low redundancy among the representatives it contains. We use information-theoretic measures such as mutual information and relative entropy to measure the representativeness of the representative set. We first design a greedy algorithm and then present a heuristic algorithm that delivers much better performance. We run experiments on two real datasets and evaluate the effectiveness of our representative set in terms of coverage and accuracy. The experiments show that our representative set attains expected characteristics and captures information more efficiently.

#index 844325
#* Parameter-Free Spatial Data Mining Using MDL
#@ Spiros Papadimitriou;Aristides Gionis;Panayiotis Tsaparas;Risto A. Vaisanen;Heikki Mannila;Christos Faloutsos
#t 2005
#c 18
#% 115608
#% 210173
#% 248790
#% 316709
#% 329562
#% 346696
#% 413869
#% 438137
#% 466425
#% 481290
#% 481414
#% 665658
#% 728302
#% 729418
#% 729918
#% 769881
#% 769883
#% 769896
#% 769914
#% 785420
#% 1307659
#% 1502454
#! Consider spatial data consisting of a set of binary features taking values over a collection of spatial extents (grid cells). We propose a method that simultaneously finds spatial correlation and feature co-occurrence patterns, without any parameters. In particular, we employ the Minimum Description Length (MDL) principle coupled with a natural way of compressing regions. This defines what "good" means: a feature co-occurrence pattern is good, if it helps us better compress the set of locations for these features. Conversely, a spatial correlation is good, if it helps us better compress the set of features in the corresponding region. Our approach is scalable for large datasets (both number of locations and of features). We evaluate our method on both real and synthetic datasets.

#index 844326
#* Discovering Frequent Arrangements of Temporal Intervals
#@ Panagiotis Papapetrou;George Kollios;Stan Sclaroff;Dimitrios Gunopulos
#t 2005
#c 18
#% 248791
#% 300120
#% 310559
#% 329537
#% 413550
#% 463903
#% 464873
#% 464996
#% 465003
#% 477952
#% 479971
#% 481290
#% 527319
#% 536183
#% 577256
#% 629623
#% 678222
#% 729933
#% 745515
#% 1389014
#! In this paper we study a new problem in temporal pattern mining: discovering frequent arrangements of temporal intervals. We assume that the database consists of sequences of events, where an event occurs during a time-interval. The goal is to mine arrangements of event intervals that appear frequently in the database. There are many applications where these type of patterns can be useful, including data network, scientific, and financial applications. Efficient methods to find frequent arrangements of temporal intervals using both breadth first and depth first search techniques are described. The performance of the proposed algorithms is evaluated and compared with other approaches on real datasets (American Sign Language streams and network data) and large synthetic datasets.

#index 844327
#* Mining Patterns of Change in Remote Sensing Image Databases
#@ Marcelino Pereira S. Silva;Gilberto Camara;Ricardo Cartaxo M. Souza;Dalton M. Valeriano;Maria Isabel S. Escada
#t 2005
#c 18
#% 136350
#% 290482
#% 318785
#% 345848
#% 489429
#% 771844
#% 771918
#% 1296176
#! Remote sensing image databases are the fastest growing archives of spatial information. However, we still have a limited capacity for extracting information from large remote sensing image databases. There are currently very few techniques for image data mining and information extraction in large image data sets, and thus we are failing to exploit our large remote sensing data archives. This paper proposes a methodology to provide guidance for mining remote sensing image databases. The basic idea is to use domain concepts to build generic description of patterns in remote sensing images, and then use structural approaches to identify such patterns in images. We illustrate our proposal with a case study for detecting land use patterns in Amazonia from INPE's remote sensing image database.

#index 844328
#* Ranking-Based Evaluation of Regression Models
#@ Saharon Rosset;Claudia Perlich;Bianca Zadrozny
#t 2005
#c 18
#% 190581
#% 1378224
#! We suggest the use of ranking-based evaluation measures for regression models, as a complement to the commonly used residual-based evaluation. We argue that in some cases, such as the case study we present, ranking can be the main underlying goal in building a regression model, and ranking performance is the correct evaluation metric. However, even when ranking is not the contextually correct performance metric, the measures we explore still have significant advantages: They are robust against extreme outliers in the evaluation set; and they are interpretable. The two measures we consider correspond closely to non-parametric correlation coefficients commonly used in data analysis (Spearman's ρ and Kendall's τ); and they both have interesting graphical representations, which, similarly to ROC curves, offer useful "partial" model performance views, in addition to a one-number summary in the area under the curve. We illustrate our methods on a case study of evaluating IT Wallet size estimation models for IBM's customers.

#index 844329
#* Compound Classification Models for Recommender Systems
#@ Lars Schmidt-Thieme
#t 2005
#c 18
#% 109322
#% 124010
#% 173879
#% 202011
#% 220709
#% 414514
#% 464449
#% 465928
#% 501827
#% 578684
#% 730049
#% 734592
#% 734594
#% 1650569
#% 1860941
#! Recommender systems recommend products to customers based on ratings or past customer behavior. Without any information about attributes of the products or customers involved, the problem has been tackled most successfully by a nearest neighbor method called collaborative filtering in the context, while additional efforts invested in building classification models did not pay off and did not increase the quality. Therefore, classification methods have mainly been used in conjunction with product or customer attributes. Starting from a view on the plain recommendation task without attributes as a multi-class classification problem, we investigate two particularities, its autocorrelation structure as well as the absence of re-occurring items (repeat buying). We adapt the standard generic reductions 1-vs-rest and 1-vs-1 of multi-class problems to a set of binary classification problems to these particularities and thereby provide a generic compound classifier for recommender systems. We evaluate a particular specialization thereof using linear support vector machines as member classifiers on MovieLens data and show that it outperforms state-of-the-artmethods, i.e., item-based collaborative filtering.

#index 844330
#* Multi-Stage Classification
#@ Ted E. Senator
#t 2005
#c 18
#% 552040
#% 579593
#% 729947
#% 731613
#% 740265
#% 742990
#% 837722
#! While much research has focused on methods for evaluating and maximizing the accuracy of classifiers either individually or in ensembles, little effort has been devoted to analyzing how classifiers are typically deployed in practice. In many domains, classifiers are used as part of a multi-stage process that increases accuracy at the expense of more data collection and/or more processing resources as the likelihood of a positive class label increases. This paper systematically explores the tradeoffs inherent in constructing these multi-stage classifiers from a series of increasingly accurate and expensive individual classifiers, considering a variety of metrics such as accuracy, cost/benefit ratio, and lift. It suggests architectures appropriate for both independent instances and for highly linked data.

#index 844331
#* Learning Functional Dependency Networks Based on Genetic Programming
#@ Wing-Ho Shum;Kwong-Sak Leung;Man-Leung Wong
#t 2005
#c 18
#% 251147
#% 411390
#% 528005
#% 637644
#% 1022856
#% 1650319
#% 1777312
#! Bayesian Network (BN) is a powerful network model, which represents a set of variables in the domain and provides the probabilistic relationships among them. But BN can handle discrete values only; it cannot handle continuous, interval and ordinal ones, which must be converted to discrete values and the order information is lost. Thus, BN tends to have higher network complexity and lower understandability. In this paper, we present a novel dependency network which can handle discrete, continuous, interval and ordinal values through functions; it has lower network complexity and stronger expressive power; it can represent any kind of relationships; and it can incorporate a-priori knowledge though user-defined functions. We also propose a novel Genetic Programming (GP) to learn dependency networks. The novel GP does not use any knowledge-guided nor application-oriented operator, thus it is robust and easy to replicate. The experimental results demonstrate that the novel GP can successfully discover the target novel dependency networks, which have the highest accuracy and the lowest network complexity.

#index 844332
#* Generalizing the Notion of Confidence
#@ Michael Steinbach;Vipin Kumar
#t 2005
#c 18
#% 152934
#% 210160
#% 227919
#% 238376
#% 248785
#% 280458
#% 342610
#% 342640
#% 424759
#% 481290
#% 487824
#% 577214
#% 769958
#% 835018
#% 1395429
#! In this paper, we explore extending association analysis to non-traditional types of patterns and non-binary data by generalizing the notion of confidence. The key idea is to regard confidence as a measure of the extent to which the strength of one association pattern provides information about the strength of another. This approach provides a framework that encompasses the traditional concept of confidence as a special case and can be used as the basis for designing a variety of new confidence measures. Besides discussing such confidence measures, we provide examples that illustrate the potential usefulness of a generalized notion of confidence. In particular, we describe an approach to defining confidence for error tolerant itemsets that preserves the interpretation of confidence as a conditional probability and derive a confidence measure for continuous data that agrees with the standard confidence measure when applied to binary transaction data.

#index 844333
#* SVM Feature Selection for Classification of SPECT Images of Alzheimer's Disease Using Spatial Information
#@ Jonathan Stoeckel;Glenn Fung
#t 2005
#c 18
#% 190581
#% 390723
#% 466084
#% 517759
#% 519154
#% 936452
#! Alzheimer's disease is the most frequent type of dementia for elderly patients. Due to aging populations the occurrence of this disease will increase in the next years. Early diagnosis is crucial to be able to develop more powerful treatments. Brain perfusion changes can be a marker for Alzheimer's disease. In this article we study the use of SPECT perfusion imaging for the diagnosis of Alzheimer's disease differentiating between images from healthy subjects and images from Alzheimer's disease patients. Our classification approach is based on a linear programming formulation similar to the 1-norm support vector machines. In contrastwith other linear hyperplane-based methods that perform simultaneous feature selection and classification, our proposed formulation incorporates proximity information about the features and generates a classifier that does not just select the most relevant voxels but the most relevant "areas" for classification resulting in more robust classifiersthat are better suitable for interpretation. This approach is compared with the classical Fisher linear discriminant (FLD) classifier as well as with statistical parametric mapping (SPM). We tested our method on data from four European institutions. Our method achieved sensitivity of 84.4% at 90.9% specificity, this is considerable better the human experts. Our method also outperformed the FLD and SPM techniques. We conclude that our approach has the potential to be a useful help for clinicians.

#index 844334
#* Neighborhood Formation and Anomaly Detection in Bipartite Graphs
#@ Jimeng Sun;Huiming Qu;Deepayan Chakrabarti;Christos Faloutsos
#t 2005
#c 18
#% 202011
#% 258598
#% 268079
#% 333929
#% 348173
#% 577273
#% 594009
#% 729918
#% 729983
#% 769883
#% 769952
#% 799747
#% 1908546
#! Many real applications can be modeled using bipartite graphs, such as users vs. files in a P2P system, traders vs. stocks in a financial trading system, conferences vs. authors in a scientific publication network, and so on. We introduce two operations on bipartite graphs: 1) identifying similar nodes (Neighborhood formation), and 2) finding abnormal nodes (Anomaly detection). And we propose algorithms to compute the neighborhood for each node using random walk with restarts and graph partitioning; we also propose algorithms to identify abnormal nodes, using neighborhood information. We evaluate the quality of neighborhoods based on semantics of the datasets, and we also measure the performance of the anomaly detection algorithm with manually injected anomalies. Both effectiveness and efficiency of the methods are confirmed by experiments on several real datasets.

#index 844335
#* A Border-Based Approach for Hiding Sensitive Frequent Itemsets
#@ Xingzhi Sun;Philip S. Yu
#t 2005
#c 18
#% 420062
#% 428404
#% 481290
#% 539744
#% 586838
#% 635220
#% 727815
#% 740764
#% 742048
#! Sharing data among organizations often leads to mutual benefit. Recent technology in data mining has enabled efficientextraction of knowledge from large databases. This, however, increases risks of disclosing the sensitive knowledge when the database is released to other parties. To address this privacy issue, one may sanitize the original database so that the sensitive knowledge is hidden. The challenge is to minimize the side effect on the quality of the sanitized database so that non-sensitive knowledge can still be mined. In this paper, we study such a problem in the context of hiding sensitive frequent itemsets by judiciously modifying the transactions in the database. To preserve the non-sensitive frequent itemsets, we propose a border-based approach to efficiently evaluate the impact of any modification to the database during the hiding process. The quality of database can be well maintained by greedily selecting the modifications with minimal side effect. Experiments results are also reported to show the effectiveness of the proposed approach.

#index 844336
#* X-mHMM: An Efficient Algorithm for Training Mixtures of HMMs When the Number of Mixtures Is Unknown
#@ Zoltan Szamonek;Csaba Szepesvari
#t 2005
#c 18
#% 36672
#% 466416
#% 466425
#% 734917
#% 1378261
#! In this paper we consider sequence clustering problems and propose an algorithm for the estimation of the number of clusters based on the X-means algorithm. The sequences are modeled using mixtures of Hidden Markov Models. By means of experiments with synthetic data we analyze the proposed algorithm. This algorithm proved to be both computationally efficient and capable of providing accurate estimates of the number of clusters. Some results of experiments with real-world web-log data are also given.

#index 844337
#* Supervised Tensor Learning
#@ Dacheng Tao;Xuelong Li;Weiming Hu;Stephen Maybank;Xindong Wu
#t 2005
#c 18
#% 114739
#% 190581
#% 268121
#% 345848
#% 435061
#% 721163
#% 722901
#% 729437
#% 757953
#% 763697
#% 789025
#! This paper aims to take general tensors as inputs for supervised learning. A supervised tensor learning (STL) framework is established for convex optimization based learning techniques such as support vector machines (SVM) and minimax probability machines (MPM). Within the STL framework, many conventional learning machines can be generalized to take n^th-order tensors as inputs. We also study the applications of tensors to learning machine design and feature extraction by linear discriminant analysis (LDA). Our method for tensor based feature extraction is named the tenor rank-one discriminant analysis (TR1DA). These generalized algorithms have several advantages: 1) reduce the curse of dimension problem in machine learning and data mining; 2) avoid the failure to converge; and 3) achieve better separation between the different categories of samples. As an example, we generalize MPM to its STL version, which is named the tensor MPM (TMPM). TMPM learns a series of tensor projections iteratively. It is then evaluated against the original MPM. Our experiments on a binary classification problem show that TMPM significantly outperforms the original MPM.

#index 844338
#* A Random Walk through Human Associations
#@ Raz Tamir
#t 2005
#c 18
#% 268079
#% 282905
#% 315967
#% 340147
#% 341009
#% 422833
#% 467270
#% 592143
#% 727816
#% 878304
#! Letting one's thoughts wander is not simply an arbitrary or rambling process. It can better be described as "associative thinking", where a complex chain of associative thoughts and ideas are linked. It is our contention that this seemingly chaotic process can be modeled by a random walk in a weighted directed graph. Furthermore, is it possible to predict mathematically the "steady state" of such a process, to determine where such wandering is leading. The random walk process uses rules of association, defined by the Local Confidence Gain (LCG) interestingness measure. Extracted concepts are used as nodes of a directed graph. The associative "forces" between any two concepts (measured by LCG) are used to weigh the edges connecting the nodes that create a graph of associations. It is common, yet not trivial, for people to look for data about a subject without knowing its exact nomenclature (for example, finding the name of a disease just by knowing its symptoms). Random walk in association graphs can discover highly informative phrases that can be used for query expansion in a way that better expresses the user's initial search goals. A different usage is to create a user profile representing his current interests. We used a modified version of the Turing Test to show that the random walk process discovers association rules that conform to a human associations generating process. By constructing the user associations we were able to build a profile representing the user's "line of thoughts". The suggested algorithm can be used in any database and can implement the ranking measures of other association rules.

#index 844339
#* A Bernoulli Relational Model for Nonlinear Embedding
#@ Gang Wang;Hui Zhang;Zhihua Zhang;Frederick H. Lochovsky
#t 2005
#c 18
#% 266426
#% 388730
#% 1279292
#! The notion of relations is extremely important in mathematics. In this paper, we use relations to describe the embedding problem and propose a novel stochastic relational model for nonlinear embedding. Given some relation among points in a high-dimensional space, we start from preserving the same relation in a low embedded space and model the relation as probabilistic distributions over these two spaces, respectively. We illustrate that the stochastic neighbor embedding and the Gaussian process latent variable model can be derived from our relational model. Moreover we devise a new stochastic embedding model and refer to it as Bernoulli relational embedding (BRE). BRE's ability in nonlinear dimensionality reduction is illustrated on a set of synthetic data and collections of bitmaps of handwritten digits and face images.

#index 844340
#* Template-Based Privacy Preservation in Classification Problems
#@ Ke Wang;Benjamin C.  M. Fung;Philip S. Yu
#t 2005
#c 18
#% 136350
#% 152934
#% 329858
#% 488324
#% 488338
#% 575966
#% 575969
#% 576762
#% 577233
#% 577239
#% 740764
#% 769943
#% 785363
#% 800514
#% 800515
#! In this paper, we present a template-based privacy preservation to protect against the threats caused by data mining abilities. The problem has dual goals: preserve the information for a wanted classification analysis and limit the usefulness of unwanted sensitive inferences that may be derived from the data. Sensitive inferences are specified by a set of "privacy templates". Each template specifies the sensitive information to be protected, a set of identifying attributes, and the maximum association between the two. We show that suppressing the domain values is an effective way to eliminate sensitive inferences. For a large data set, finding an optimal suppression is hard, since it requires optimization over all suppressions. We present an approximate but scalable solution. We demonstrate the effectiveness of this approach on real life data sets.

#index 844341
#* On Reducing Classifier Granularity in Mining Concept-Drifting Data Streams
#@ Peng Wang;Haixun Wang;Xiaochen Wu;Wei Wang;Baile Shi
#t 2005
#c 18
#% 273900
#% 310500
#% 342600
#% 342639
#% 466483
#% 479787
#% 481945
#% 594012
#% 729932
#% 729959
#% 785339
#% 993958
#% 993960
#! Many applications use classification models on streaming data to detect actionable alerts. Due to concept drifts in the underlying data, how to maintain a model's up-to-dateness has become one of the most challenging tasks in mining data streams. State of the art approaches, including both the incrementally updated classifiers and the ensemble classifiers, have proved that model update is a very costly process. In this paper, we introduce the concept of model granularity. We show that reducing model granularity will reduce model update cost. Indeed, models of fine granularity enable us to efficiently pinpoint local components in the model that are affected by the concept drift. It also enables us to derive new components that can easily integrate with the model to reflect the current data distribution, thus avoiding expensive updates on a global scale. Experiments on real and synthetic data show that our approach is able to maintain good prediction accuracy at a fraction of model updating cost of state of the art approaches.

#index 844342
#* Approximate Inverse Frequent Itemset Mining: Privacy, Complexity, and Approximation
#@ Yongge Wang;Xintao Wu
#t 2005
#c 18
#% 42485
#% 73571
#% 152934
#% 342643
#% 576118
#% 801682
#! In order to generate synthetic basket datasets for better benchmark testing, it is important to integrate characteristics from real-life databases into the synthetic basket datasets. The characteristics that could be used for this purpose include the frequent itemsets and association rules. The problem of generating synthetic basket datasets from frequent itemsets is generally referred to as inverse frequent itemset mining. In this paper, we show that the problem of approximate inverse frequent itemset mining is NP-complete. Then we propose and analyze an approximate algorithm for approximate inverse frequent itemset mining, and discuss privacy issues related to the synthetic basket dataset. In particular, we propose an approximate algorithm to determine the privacy leakage in a synthetic basket dataset.

#index 844343
#* Atomic Wedgie: Efficient Query Filtering for Streaming Times Series
#@ Li Wei;Eamonn Keogh;Helga Van Herle;Agenor Mafra-Neto
#t 2005
#c 18
#% 397380
#% 577221
#% 731408
#% 765262
#% 1113090
#! In many applications it is desirable to monitor a streaming time series for predefined patterns. In domains as diverse as the monitoring of space telemetry, patient intensive care data, and insect populations, where data streams at a high rate and the number of predefined patterns is large, it may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false dismissals. Our approach is based on the widely used envelope-based lower bounding technique. Extensive experiments demonstrate that our approach achieves tremendous improvements in performance in the offline case, and significant improvements in the fastest possible arrival rate of the data stream that can be processed with guaranteed no false dismissal.

#index 844344
#* Discriminatively Trained Markov Model for Sequence Classification
#@ Oksana Yakhnenko;Adrian Silvescu;Vasant Honavar
#t 2005
#c 18
#% 190581
#% 260001
#% 276467
#% 341682
#% 388024
#% 410855
#% 735077
#% 770761
#% 810949
#% 833026
#% 1650403
#% 1673026
#! In this paper, we propose a discriminative counterpart of the directed Markov Models of order k - 1, or MM(k-1) for sequence classification. MM(k-1) models capture dependencies among neighboring elements of a sequence. The parameters of the classifiers are initialized to based on the maximum likelihood estimates for their generative counterparts. We derive gradient based update equations for the parameters of the sequence classifiers in order to maximize the conditional likelihood function. Results of our experiments with data sets drawn from biological sequence classification (specifically protein function and subcellular localization) and text classification applications show that the discriminatively trained sequence classifiers outperform their generative counterparts, confirming the benefits of discriminative training when the primary objective is classification.Our experiments also show that the discriminatively trained MM(k - 1) sequence classifiers are competitive with the computationally much more expensive Support Vector Machines trained using k-gram representations of sequences.

#index 844345
#* Integrating Hidden Markov Models and Spectral Analysis for Sensory Time Series Clustering
#@ Jie Yin;Qiang Yang
#t 2005
#c 18
#% 36672
#% 280404
#% 280416
#% 310512
#% 466416
#% 522017
#% 529189
#% 577221
#% 629711
#% 1279342
#% 1562549
#! We present a novel approach for clustering sequences of multi-dimensional trajectory data obtained from a sensor network. The sensory time-series data present new challenges to data mining, including uneven sequence lengths, multi-dimensionality and high levels of noise. We adopt a principled approach, by first transforming all the data into an equal-length vector form while keeping as much temporal information as we can, and then applying dimensionality and noise reduction techniques such as spectral clustering to the transformed data. Experimental evaluation on synthetic and real data shows that our proposed approach outperforms standard model-based clustering algorithms for time series data.

#index 844346
#* Discriminant Analysis: A Unified Approach
#@ Peng Zhang;Norbert Riedel
#t 2005
#c 18
#% 80995
#% 91872
#% 212689
#% 235342
#% 302906
#% 342598
#% 774854
#% 789030
#% 1861142
#! Linear discriminant analysis (LDA) as a dimension reduction method is widely used in data mining and machine learning. It however suffers from the small sample size (SSS) problem when data dimensionality is greater than the sample size. Many modified methods have been proposed to address some aspect of this difficulty from a particular viewpoint. A comprehensive framework that provides a complete solution to the SSS problem is still missing. In this paper, we provide a unified approach to LDA, and investigate the SSS problem in the framework of statistical learning theory. In such a unified approach, our analysis results in a deeper understanding of LDA. We demonstrate that LDA (and its nonlinear extension) belongs to the same framework where powerful classifiers such as support vector machines (SVMs) are formulated. In addition, this approach allows us to establish an error bound for LDA. Finally our experiments validate our theoretical analysis results.

#index 844347
#* Sharing Classifiers among Ensembles from Related Problem Domains
#@ Yi Zhang;W. Nick Street;Samuel Burer
#t 2005
#c 18
#% 132938
#% 136350
#% 205305
#% 209021
#% 236497
#% 280496
#% 342628
#% 342639
#% 400847
#% 424997
#% 443616
#% 445344
#% 565528
#% 770854
#% 1272000
#! A classification ensemble is a group of classifiers that all solve the same prediction problem in different ways. It is well-known that combining the predictions of classifiers within the same problem domain using techniques like bagging or boosting often improves the performance. This research shows that sharing classifiers among different but closely related problem domains can also be helpful. In addition, a semi-definite programming based ensemble pruning method is implemented in order to optimize the selection of a subset of classifiers for each problem domain. Computational results on a catalog dataset indicate that the ensembles resulting from sharing classifiers among different product categories generally have larger AUCs than those ensembles trained only on their own categories. The pruning algorithm not only prevents the occasional decrease of effectiveness caused by conflicting concepts among the problem domains, but also provides a better understanding of the problem domains and their relationships.

#index 844348
#* A Visual Data Mining Framework for Convenient Identification of Useful Knowledge
#@ Kaidi Zhao;Bing Liu;Thomas M. Tirpak;Weimin Xiao
#t 2005
#c 18
#% 136350
#% 280487
#% 310525
#% 310531
#% 342631
#% 434613
#% 443092
#% 481290
#% 577216
#% 641130
#% 769926
#% 838395
#! Data mining algorithms usually generate a large number of rules, which may not always be useful to human users. In this project, we propose a novel visual data-mining framework, called Opportunity Map, to identify useful and actionable knowledge quickly and easily from the discovered rules. The framework is inspired by the House of Quality from Quality Function Deployment (QFD) in Quality Engineering. It associates discovered rules, related summarized data and data distributions with the application objective using an interactive matrix. Combined with drill down visualization, integrated visualization of data distribution bars and rules, visualization of trend behaviors, and comparative analysis, the Opportunity Map allows users to analyze rules and data at different levels of detail and quickly identify the actionable knowledge and opportunities. The proposed framework represents a systematic and flexible approach to rule analysis. Applications of the system to large-scale data sets from our industrial partner have yielded promising results.

#index 844349
#* Efficient Text Classification by Weighted Proximal SVM
#@ Dong Zhuang;Benyu Zhang;Qiang Yang;Jun Yan;Zheng Chen;Ying Chen
#t 2005
#c 18
#% 269217
#% 269218
#% 317535
#% 340904
#% 342598
#% 387427
#% 420077
#% 763708
#! In this paper, we present an algorithm that can classify large-scale text data with high classification quality and fast training speed. Our method is based on a novel extension of the proximal SVM mode [3]. Previous studies on proximal SVM have focused on classification for low dimensional data and did not consider the unbalanced data cases. Such methods will meet difficulties when classifying unbalanced and high dimensional data sets such as text documents. In this work, we extend the original proximal SVM by learning a weight for each training error. We show that the classification algorithm based on this model is capable of handling high dimensional and unbalanced data. In the experiments, we compare our method with the original proximal SVM (as a special case of our algorithm) and the standard SVM (such as SVM light) on the recently published RCV1-v2 dataset. The results show that our proposed method had comparable classification quality with the standard SVM. At the same time, both the time and memory consumption of our method are less than that of the standard SVM.

#index 844350
#* A Rule Evaluation Support Method with Learning Models Based on Objective Rule Evaluation Indexes
#@ Hidenao Abe;Shusaku Tsumoto;Miho Ohsaki;Takahira Yamaguchi
#t 2005
#c 18
#% 136350
#% 156186
#% 269218
#% 290482
#% 292240
#% 392618
#% 465922
#% 501346
#% 501381
#% 577214
#% 641961
#% 799768
#! In this paper, we present a novel rule evaluation support method for post-processing of mined results with rule evaluation models based on objective indexes. Post-processing of mined results is one of the key issues to make a data mining process successfully. However, it is difficult for human experts to evaluate many thousands of rules from a large dataset with noises completely. To reduce the costs of rule evaluation procedures, we have developed the rule evaluation support method with rule evaluation models, which are obtained with objective rule evaluation indexes and evaluations of a human expert for each rule. Since the method is needed more accurate rule evaluation models, we have compared learning algorithms to construct rule evaluation models with the actual meningitis data mining result and actual rule sets from UCI datasets. Then we show the availability of our adaptive rule evaluation support method.

#index 844351
#* Mining Chains of Relations
#@ Foto Afrati;Gautam Das;Aristides Gionis;Heikki Mannila;Taneli Mielikainen;Panayiotis Tsaparas
#t 2005
#c 18
#% 249110
#% 301165
#% 420062
#% 466644
#% 550412
#% 577218
#% 600501
#% 765429
#% 785381
#% 809250
#! Traditional data mining applications consider the problem of mining a single relation between two attributes. For example, in a scientific bibliography database, authors are related to papers, and we may be interested in discovering association rules between authors. However, in real life, we often have multiple attributes related though chains of relations. For example, authors write papers, and papers concern one or more topics. Mining such relational chains poses additional challenges. In this paper we consider the following problem: given a chain of two relationsR₁(A, P) and R₂(P, T) we want to find selectors for the objects in T such that the projected relation between A and P satisfies a specific property. The motivation for our approach is that a given property might not hold on the whole dataset, but it might hold when projecting the data on a selector set. We discuss various algorithms and we examine the conditions under which the apriori technique can be used. We experimentally demonstrate the effectiveness of our methods.

#index 844352
#* A Preference Model for Structured Supervised Learning Tasks
#@ Fabio Aiolli
#t 2005
#c 18
#! The preference model introduced in this paper gives a natural framework and a principled solution for a broad class of supervised learning problems with structured predictions, such as predicting orders (label and instance ranking), and predicting rates (classification and ordinal regression). We show how all these problems can be cast as linear problems in an augmented space, and we propose an on-line method to efficiently solve them. Experiments on an ordinal regression task confirm the effectiveness of the approach.

#index 844353
#* Blocking Anonymity Threats Raised by Frequent Itemset Mining
#@ Maurizio Atzori;Francesco Bonchi;Fosca Giannotti;Dino Pedreschi
#t 2005
#c 18
#% 152934
#% 464873
#% 478770
#% 576761
#% 1673554
#! In this paper we study when the disclosure of datamining results represents, per se, a threat to the anonymity of the individuals recorded in the analyzed database. The novelty of our approach is that we focus on an objective definition of privacy compliance of patterns without any reference to a preconceived knowledge of what is sensitive and what is not, on the basis of the rather intuitive and realistic constraint that the anonymity of individuals should be guaranteed. In particular, the problem addressed here arises from the possibility of inferring from the output of frequent itemset mining (i.e., a set of itemsets with support larger than a threshold ó), the existence of patterns with very low support (smaller than an anonymity threshold k)[3]. In the following we develop a simple methodology to block such inference opportunities by introducing distortion on the dangerous patterns.

#index 844354
#* Adaptive Clustering: Obtaining Better Clusters Using Feedback and Past Experience
#@ Abraham Bagherjeiran;Christoph F. Eick;Chun-Sheng Chen;Ricardo Vilalta
#t 2005
#c 18
#% 124691
#% 160859
#% 363744
#% 576214
#% 1272286
#! Adaptive clustering uses external feedback to improve cluster quality; past experience serves to speed up execution time. An adaptive clustering environment is proposed that uses Q-learning to learn the reward values of successive data clusterings. Adaptive clustering supports the reuse of clusterings by memorizing what worked well in the past. It has the capability of exploring multiple paths in parallel when searching for good clusters. In a case study, we apply adaptive clustering to instance-based learning relying on a distance function modification approach. A distance function adaptation scheme that uses external feedback is proposed and compared with other distance function learning approaches. Experimental results indicate that the use of adaptive clustering leads to significant improvements of instance-based learning techniques, such as k-nearest neighbor classifiers. Moreover, as a by-product a new instance-based learning technique is introduced that classifies examples by solely using cluster representatives; this technique shows high promise in our experimental evaluation.

#index 844355
#* Semi-Supervised Mixture of Kernels via LPBoost Methods
#@ Jinbo Bi;Glenn Fung;Murat Dundar;Bharat Rao
#t 2005
#c 18
#% 425033
#% 577213
#% 763697
#% 769930
#! We propose an algorithmto construct classification models with a mixture of kernels from labeled and unlabeled data. The derived classifier is a mixture of models, each based on one kernel choice from a library of kernels. The sparse-favoring 1-norm regularization method is employed to restrict the complexity of mixture models and to achieve the sparsity of solutions. By modifying the column generation boosting algorithm LPBoost to a more general linear programming formulation, we are able to efficiently solve mixture-of-kernel problems and automatically select kernel basis functions centered at labeled data as well as unlabeled data. The effectiveness of the proposed approach is proved by experimental results on benchmark datasets.

#index 844356
#* A Levelwise Search Algorithm for Interesting Subspace Clusters
#@ Haiyun Bian;Raj Bhatnagar
#t 2005
#c 18
#% 152934
#% 248792
#% 280417
#% 463903
#% 1289265
#! We present a levelwise search algorithm for finding subspace clusters in high dimensional data satisfying various properties besides the commonly used minimum density property. A set of such properties are summarized and a user can choose any of these properties. A lattice is built with all the discovered clusters which enables further analysis and discovery of useful knowledge about the clusters and their inter-relationships.

#index 844357
#* Segment-Based Injection Attacks against Collaborative Filtering Recommender Systems
#@ Robin Burke;Bamshad Mobasher;Runa Bhaumik;Chad Williams
#t 2005
#c 18
#% 280852
#% 330687
#% 734590
#% 754097
#% 783438
#! Significant vulnerabilities have recently been identi- fied in collaborative filtering recommender systems. Researchers have shown that attackers can manipulate a system's recommendations by injecting biased profiles into it. In this paper, we examine attacks that concentrate on a targeted set of users with similar tastes, biasing the system's responses to these users. We show that such attacks are both pragmatically reasonable and also highly effective against both user-based and item-based algorithms. As a result, an attacker can mount such a "segmented" attack with little knowledge of the specific system being targeted and with strong likelihood of success.

#index 844358
#* On Feature Selection through Clustering
#@ Richard Butterworth;Gregory Piatetsky-Shapiro;Dan A. Simovici
#t 2005
#c 18
#% 243727
#% 243728
#% 290482
#% 722929
#% 748004
#% 785423
#% 929676
#% 937173
#! We study an algorithm for feature selection that clusters attributes using a special metric and then makes use of the dendrogram of the resulting cluster hierarchy to choose the most relevant attributes. The main interest of our technique resides in the improved understanding of the structure of the analyzed data and of the relative importance of the attributes for the selection process.

#index 844359
#* Sequential Pattern Mining in Multiple Streams
#@ Gong Chen;Xindong Wu;Xingquan Zhu
#t 2005
#c 18
#% 778732
#! In this paper, we deal with mining sequential patterns in multiple data streams. Building on a state-of-the-art sequential pattern mining algorithm PrefixSpan for mining transaction databases, we propose MILE鹿, an efficient algorithm to facilitate the mining process. MILE recursively utilizes the knowledge of existing patterns to avoid redundant data scanning, and can therefore effectively speed up the new patterns' discovery process. Another unique feature of MILE is that it can incorporate some prior knowledge of the data distribution in data streams into the mining process to further improve the performance. Extensive empirical results show thatMILE is significantly faster than PrefixSpan. As MILE consumes more memory than PrefixSpan, we also present a solution to balance the memory usage and time efficiency in memory constrained environments.

#index 844360
#* Privacy Preserving Data Classification with Rotation Perturbation
#@ Keke Chen;Ling Liu
#t 2005
#c 18
#% 300184
#% 333876
#% 576111
#% 727904
#% 810010
#! Data perturbation techniques are one of the most popular models for privacy preserving data mining [3, 1]. It is especially convenient for applications where the data owners need to export/publish the privacy-sensitive data. A data perturbation procedure can be simply described as follows. Before the data owner publishes the data, they randomly change the data in certain way to disguise the sensitive information while preserving the particular data property that is critical for building the data models. Several perturbation techniques have been proposed recently, among which the most typical ones are randomization approach [3] and condensation approach [1].

#index 844361
#* A Computational Framework for Taxonomic Research: Diagnosing Body Shape within Fish Species Complexes
#@ Yixin Chen;Henry L. Bart, Jr.;Shuqing Huang;Huimin Chen
#t 2005
#c 18
#% 722932
#! It is estimated that ninety percent of the world's species have yet to be discovered and described. The main reason for the slow pace of new species description is that the science of taxonomy, as traditionally practiced, can be very laborious. To formally describe a new species, taxonomists have to manually gather and analyze data from large numbers of specimens, often from broad geographic areas, and identify the smallest subset of external body characters that uniquely diagnoses the new species as distinct from all its known relatives. In this paper, we use an automated feature selection and classification approach to address the taxonomic impediment in new species discovery. The experiments on a taxonomic problem involving species of suckers in the genus Carpiodes demonstrate promising results.

#index 844362
#* Obtaining Best Parameter Values for Accurate Classification
#@ Frans Coenen;Paul Leng
#t 2005
#c 18
#% 466483
#% 1707806
#! In this paper we examine the effect that the choice of support and confidence thresholds has on the accuracy of classifiers obtained by Classification Association Rule Mining. We show that accuracy can almost always be improved by a suitable choice of threshold values, and we describe a method for finding the best values. We present results that demonstrate this approach can obtain higher accuracy without the need for coverage analysis of the training data. Keywords: Classification, Association Rule Mining.

#index 844363
#* Process Diagnosis via Electrical-Wafer-Sorting Maps Classification
#@ Federico Di Palma;Giuseppe De Nicolao;Guido Miraglia;Oliver M. Donzelli
#t 2005
#c 18
#% 841441
#! The commonality analysis is a proven tool for fault detection in semiconductor manufacturing. This methodology extracts subsets of production lots from all the available data. Then, data mining techniques are used only on the selected data. This approach loses part of the available information and does not discriminate among the lots. The new methodology performance the automatic classificationof the electrical wafer test maps in order to identify the classes of failure present in the production lots. Subsequently, the proposed procedure uses the process history of each wafer to create a list of the root cause candidates. This methodology is the core of the software tool ACID which is currently used for process diagnosis at the Agrate site of the ST Microelectronics. A real analysis is presented.

#index 844364
#* An Improved Categorization of Classifier's Sensitivity on Sample Selection Bias
#@ Wei Fan;Ian Davidson;Bianca Zadrozny;Philip S. Yu
#t 2005
#c 18
#% 770847
#! A recent paper categorizes classifier learning algorithms according to their sensitivity to a common type of sample selection bias where the chance of an example being selected into the training sample depends on its feature vector x but not (directly) on its class label y. A classifier learner is categorized as "local" if it is insensitive to this type of sample selection bias, otherwise, it is considered "global". In that paper, the true model is not clearly distinguished from the model that the algorithm outputs. In their discussion of Bayesian classifiers, logistic regression and hard-margin SVMs, the true model (or the model that generates the true class label for every example) is implicitly assumed to be contained in the model space of the learner, and the true class probabilities and model estimated class probabilities are assumed to asymptotically converge as the training data set size increases. However, in the discussion of naive Bayes, decision trees and soft-margin SVMs, the model space is assumed not to contain the true model, and these three algorithms are instead argued to be "global learners". We argue that most classifier learners may or may not be affected by sample selection bias; this depends on the dataset as well as the heuristics or inductive bias implied by the learning algorithm and their appropriateness to the particular dataset.

#index 844365
#* Fast Frequent String Mining Using Suffix Arrays
#@ Johannes Fischer;Volker Heun;Stefan Kramer
#t 2005
#c 18
#% 143306
#% 235941
#% 544049
#% 629643
#% 751623
#% 770226
#% 938016
#% 1656273
#! We present a method to mine strings that are frequent in one database and infrequent in another. The method uses suffix- and lcp-arrays that can be computed extremely fast and space efficiently, and further exhibit a good locality behavior. Experiments with several biologically relevant data sets show that our approach outperforms existing methods in terms of time and space.

#index 844366
#* Privacy-Preserving Frequent Pattern Mining across Private Databases
#@ Ada Wai-Chee Fu;Raymond Chi-Wing Wong;Ke Wang
#t 2005
#c 18
#% 264263
#% 289282
#% 577289
#% 629615
#% 654448
#% 769937
#! Privacy consideration has much significance in the application of data mining. It is very important that the privacy of individual parties will not be exposed when data mining techniques are applied to a large collection of data about the parties. In many scenarios such as data warehousing or data integration, data from the different parties form a many-to-many schema. This paper addresses the problem of privacy-preserving frequent pattern mining in such a schema across two dimension sites. We assume that sites are not trusted and they are semi-honest. Our method is based on the concept of semi-join and does not involve data encryption which is used in most previous work. Experiments are conducted to study the efficiency of the proposed models.

#index 844367
#* CoLe: A Cooperative Data Mining Approach and Its Application to Early Diabetes Detection
#@ Jie Gao;Jorg Denzinger;Robert C. James
#t 2005
#c 18
#% 443428
#% 463903
#% 465922
#% 1720566
#! We present CoLe, a cooperative data mining approach for discovering hybrid knowledge. It employs multiple different data mining algorithms, and combines results from them to enhance the mined knowledge. For our medical application area, we analyse several focusing strategies that allowed us to gain medically significant results.

#index 844368
#* Feature Selection for Building Cost-Effective Data Stream Classifiers
#@ Like Gao;X. Sean Wang
#t 2005
#c 18
#% 342639
#% 346511
#% 564259
#% 720010
#% 769927
#% 1272369
#! A stream classifier is a decision model that assigns a class label to a data stream, based on its arriving data. Various features of the stream can be used in the classifier, each of which may have different relevance to the classification task and different cost in obtaining its value. As time passes by, some less costly features may become more relevant, but the time needed for decision may be considered as a cost. A challenge is how to balance the different costs when building a cost-effective classifier. This paper proposes a new feature selection strategy that extends the traditional Relief algorithm in two aspects: (1) estimate the classification cost associated with each feature, and (2) order all the features with a score that combines both cost estimation and classification relevance. A classifier is then built with the selected features using a traditional classification method. Experimental results show that classifiers constructed with this strategy are indeed cost effective.

#index 844369
#* A Scalable Collaborative Filtering Framework Based on Co-Clustering
#@ Thomas George;Srujana Merugu
#t 2005
#c 18
#% 173879
#% 734590
#% 734592
#% 769928
#% 844369
#% 1650569
#! Collaborative filtering-based recommender systems have become extremely popular in recent years due to the increase in web-based activities such as e-commerce and online content distribution. Current collaborative filtering (CF) techniques such as correlation and SVD based methods provide good accuracy, but are computationally expensive and can be deployed only in static off-line settings. However, a number of practical scenarios require dynamic real-time collaborative filtering that can allow new users, items and ratings to enter the system at a rapid rate. In this paper, we consider a novel CF approach based on a recently proposed weighted co-clustering algorithm [1] that involves simultaneous clustering of users and items. We design incremental and parallel versions of the co-clustering algorithm and use it to build an efficient real-time CF framework. Empirical evaluation demonstrates that our approach provides an accuracy comparable to that of the correlation and matrix factorization based approaches at a much lower computational cost.

#index 844370
#* Text Classification with Evolving Label-Sets
#@ Shantanu Godbole;Ganesh Ramakrishnan;Sunita Sarawagi
#t 2005
#c 18
#% 262043
#% 316546
#% 458379
#% 466408
#% 577297
#% 754106
#% 763708
#% 799753
#% 840920
#! We introduce the evolving label-set problem encountered in building real-world text classification systems. This problem arises when a text classification system trained on a label-set encounters documents of unseen classes at deployment time. We design a Class-Detector module that monitors unlabeled data, detects new classes, and suggests them to the administrator for inclusion in the label-set. We propose abstractions that group together tokens under human understandable concepts and provide a mechanism of assigning importance to unseen terms. We present generative algorithms leveraging the notion of support of documents in a model for (1) selecting documents of proposed new classes, and (2) automatically triggering detection of new classes. Experiments on three real world taxonomies show that our methods select new class documents with high precision, and trigger emergence of new classes with low false-positive and false-negative rates.

#index 844371
#* CloseMiner: Discovering Frequent Closed Itemsets Using Frequent Closed Tidsets
#@ N. Gourakishwar Singh;S. Ranbir Singh;Anjana K. Mahanta
#t 2005
#c 18
#% 152934
#% 300120
#% 310494
#% 326731
#% 443350
#% 464873
#% 481754
#! Complete set of itemsets can be grouped into non-overlapping clusters identified by closed tidsets. Each cluster has only one closed itemset and is the superset of all itemsets with the same support. Number of closed itemsets is identical to the number of clusters. Therefore, the problem of discovering closed itemsets can be considered as the problem of clustering the complete set of itemsets by closed tidsets. In this paper, we present CloseMiner, a new algorithm for discovering all frequent closed itemsets by grouping the complete set of itemsets into non-overlapping clusters identified by closed tidsets. An extensive experimental evaluation on a number of real and synthetic databases shows that CloseMiner outperforms Apriori and CHARM.

#index 844372
#* A Framework for Semi-Supervised Learning Based on Subjective and Objective Clustering Criteria
#@ M. Halkidi;D. Gunopulos;N. Kumar;M. Vazirgiannis;C. Domeniconi
#t 2005
#c 18
#% 252011
#% 311027
#% 464291
#% 466481
#% 466895
#% 769881
#% 770782
#! In this paper, we propose a semi-supervised framework for learning a weighted Euclidean subspace, where the best clustering can be achieved. Our approach capitalizes on user-constraints and the quality of intermediate clustering results in terms of its structural properties. It uses the clustering algorithm and the validity measure as parameters.

#index 844373
#* Focused Community Discovery
#@ Kirsten Hildrum;Philip S. Yu
#t 2005
#c 18
#% 310514
#% 549441
#% 805906
#% 1715790
#! We present a new approach to community discovery. Community discovery usually partitions the graph into communities or clusters. Focused community discovery allows the searcher to specify start points of interest, and find the community of those points. Focused search allows for a much more scalable algorithm in which the time depends only on the size of the community, and not on the number of nodes in the graph, and so is scalable to arbitrarily large graphs. Furthermore, our algorithm is robust to imperfect data, such as extra or missing edges in the graph. We show the effectiveness of our algorithm using both synthetic graphs and on the real-life Livejournal friends graph, a publicly-available social network consisting of over two million users and 13 million edges.

#index 844374
#* Suppressing Data Sets to Prevent Discovery of Association Rules
#@ Ayca Azgın Hintoglu;Ali Inan;Yucel Saygın;Mehmet Keskinoz
#t 2005
#c 18
#% 428404
#% 727815
#% 740764
#! Enterprises have been collecting data for many reasons including better customer relationship management, and high-level decision making. Public safety was another motivation for large-scale data collection efforts initiated by government agencies. However, such widespread data collection efforts coupled with powerful data analysis tools raised concerns about privacy. This is due to the fact that collected data may contain confidential information. One method to ensure privacy is to selectively hide confidential information from the data sets to be disclosed. In this paper, we focus on hiding confidential correlations. We introduce a heuristic to reduce the information loss and propose a blocking method that prevents discovery of confidential correlations while preserving the usefulness of the data set.

#index 844375
#* Triple Jump Acceleration for the EM Algorithm
#@ Han-Shen Huang;Bou-Ho Yang;Chun-Nan Hsu
#t 2005
#c 18
#% 129987
#% 1650323
#% 1650696
#% 1673039
#! This paper presents the triple jump framework for accelerating the EM algorithm and other bound optimization methods. The idea is to extrapolate the third search point based on the previous two search points found by regular EM. As the convergence rate of regular EM becomes slower, the distance of the triple jump will be longer, and thus provide higher speedup for data sets where EM converges slowly. Experimental results show that the triple jump framework significantly outperforms EM and other acceleration methods of EM for a variety of probabilistic models, especially when the data set is sparse. The results also show that the triple jump framework is particularly effective for Cluster Models.

#index 844376
#* Partial Ensemble Classifiers Selection for Better Ranking
#@ Jin Huang;Charles X. Ling
#t 2005
#c 18
#% 5182
#% 209021
#% 290482
#% 349550
#% 564279
#% 1378224
#! Ranking is an important task in data mining and knowledge discovery. We propose a novel approach called PECS algorithm to improve the overall ranking performance of a given ensemble. We formally analyse the sufficient and necessary condition under whichPECS algorithm can effectively improve ensemble ranking performance. The experiments with real-world data sets show that this new approach achieves significant improvements in ranking over the original Bagging and Adaboost ensembles.

#index 844377
#* Pairwise Symmetry Decomposition Method for Generalized Covariance Analysis
#@ Tsuyoshi Ide
#t 2005
#c 18
#! We propose a new theoretical framework for generalizing the traditional notion of covariance. First, we discuss the role of pairwise cross-cumulants by introducing a cluster expansion technique for the cumulant generating function. Next, we introduce a novel concept of symmetry decomposition of probability density functions according to the C_4v group. By utilizing the irreducible representations, generalized covariances are explicitly defined, and their utility is demonstrated using an analytically solvable model.

#index 844378
#* FS3: A Random Walk Based Free-Form Spatial Scan Statistic for Anomalous Window Detection
#@ Vandana P. Janeja;Vijayalakshmi Atluri
#t 2005
#c 18
#% 103743
#% 342623
#% 810524
#% 1835101
#! Often, it is required to identify anomalous windows over a spatial region that reflect unusual rate of occurrence of a specific event of interest. A spatial scan statistic essentially considers a scan window, and identifies anomalous windows by moving the scan window in the region. While spatial scan statistic has been successful, earlier proposals suffer from two limitations: (i) They resrict the scan window to be of a regular shape (e.g., circle, rectangle, cylinder). However, the region of anomaly, in general, is not necessarily of a regular shape. (ii) They take into account autocorrelation among spatial data, but not spatial heterogeneity. As a result, they often result in inaccurate anomalous windows. To address these limitations, we propose a random walk based Free-Form Spatial Scan Statistic (FS鲁). Application of FS鲁 on real datasets has shown that it can identify more refined anomalous windows with better likelihood ratio of it being an anomaly, than those identified by earlier spatial scan statistic approaches.

#index 844379
#* Mining Ontological Knowledge from Domain-Specific Text Documents
#@ Xing Jiang;Ah-Hwee Tan
#t 2005
#c 18
#% 156337
#% 519561
#% 727814
#% 854720
#! Traditional text mining systems employ shallow parsing techniques and focus on concept extraction and taxonomic relation extraction. This paper presents a novel system called CRCTOL for mining rich semantic knowledge in the form of ontology from domain-specific text documents. By using a full text parsing technique and incorporating both statistical and lexico-syntactic methods, the knowledge extracted by our system is more concise and contains a richer semantics compared with alternative systems. We conduct a case study wherein CRCTOL extracts ontological knowledge, specifically key concepts and semantic relations, from a terrorism domain text collection. Quantitative evaluation, by comparing with a state-of-the-art ontology learning system known as Text-To-Onto, has shown that CRCTOL produces much better precision and recall for both concept and relation extraction, especially from sentences with complex structures.

#index 844380
#* Mining Patterns That Respond to Actions
#@ Yuelong Jiang;Ke Wang;Alexander Tuzhilin;Ada Wai-Chee Fu
#t 2005
#c 18
#% 136350
#% 408715
#% 420082
#% 458833
#% 727852
#! Data mining focuses on patterns that summarize the data. In this paper, we focus on mining patterns that could change the state by responding to opportunities of actions.

#index 844381
#* Supervised Ordering — An Empirical Survey
#@ Toshihiro Kamishima;Hideto Kazawa;Shotaro Akaho
#t 2005
#c 18
#% 577224
#% 629710
#% 734915
#% 805526
#% 1272396
#! Ordered lists of objects are widely used as representational forms. Such ordered objects include Web search results or bestseller lists. In spite of their importance, methods of processing orders have received little attention. However, research concerning orders has recently become common; in particular, researchers have developed various methods for the task of Supervised Ordering to acquire functions for object sorting from example orders. Here, we give a unified view of these methods and our new one, and empirically survey their merits and demerits.

#index 844382
#* Categorization and Keyword Identification of Unlabeled Documents
#@ Ning Kang;Carlotta Domeniconi;Daniel Barbara
#t 2005
#c 18
#% 248792
#% 260008
#% 273891
#% 333941
#% 397384
#% 480307
#! In this paper we first propose a global unsupervised feature selection approach for text, based on frequent itemset mining. As a result, each document is represented as a set of words that co-occur frequently in the given corpus of documents. We then introduce a locally adaptive clustering algorithm, designed to estimate (local) word relevance and, simultaneously, to group the documents. We present experimental results to demonstrate the feasibility of our approach. Furthermore, the analysis of the weights credited to terms provides evidence that the identified keywords can guide the process of label assignment to clusters. We take into consideration both spam email filtering and general classification datasets. Our analysis of the distribution of weights in the two cases provides insights on how the spam problem distinguishes from the general classification case.

#index 844383
#* Gradual Model Generator for Single-Pass Clustering
#@ Ismo Karkkainen;Pasi Franti
#t 2005
#c 18
#% 80995
#% 413619
#% 420057
#% 443243
#% 857390
#% 1378334
#! We present an algorithm for generating a mixture model from data set by performing a single pass over the data. The method is applicable when the entire data is not available at the same time in the main memory. We use Gaussian mixture model but the algorithm can be adapted to other types of models, too. We also outline a post processing method, which can iteratively reduce the size of the model obtained by the single-pass algorithm. This will result in a model with fewer components, but with approximately the same representation accuracy than the result of the original model from the single-pass algorithm.

#index 844384
#* Making Logistic Regression a Core Data Mining Tool with TR-IRLS
#@ Paul Komarek;Andrew W. Moore
#t 2005
#c 18
#% 374195
#% 647057
#! Binary classification is a core data mining task. For large datasets or real-time applications, desirable classifiersare accurate, fast, and need no parameter tuning. We present a simple implementation of logistic regression that meets these requirements. A combination of regularization, truncated Newton methods, and iteratively re-weighted least squares make it faster and more accurate than modern SVM implementations, and relatively insensitive to parameters. It is robust to linear dependencies and some scaling problems, making most data preprocessing unnecessary.

#index 844385
#* Hierarchical Density-Based Clustering of Uncertain Data
#@ Hans-Peter Kriegel;Martin Pfeifle
#t 2005
#c 18
#% 273890
#! The hierarchical density-based clustering algorithm OPTICS has proven to help the user to get an overview over large data sets. When using OPTICS for analyzing uncertain data which naturally occur in many emerging application areas, e.g. location based services, or sensor databases, the similarity between uncertain objects has to be expressed by one numerical distance value. Based on such single-valued distance functions OPTICS, like other standard data mining algorithms, can work without any changes. In this paper, we propose to express the similarity between two fuzzy objects by distance probability functions which assign a probability value to each possible distance value. Contrary to the traditional approach, we do not extract aggregated values from the fuzzy distance functions but enhance OPTICS so that it can exploit the full information provided by these functions. The resulting algorithm FOPTICS helps the user to get an overview over a large set of fuzzy objects.

#index 844386
#* Semi-Supervised Clustering with Metric Learning Using Relative Comparisons
#@ Nimit Kumar;Krishna Kummamuru;Deepa Paranjpe
#t 2005
#c 18
#% 309128
#% 769945
#% 770074
#% 770782
#! Semi-supervised clustering algorithms partition a given data set using limited supervision from the user. In this paper, we propose a clustering algorithmthat uses supervision in terms of relative comparisons, viz., is closer to than to . The success of a clustering algorithm also depends on the kind of dissimilarity measure. The proposed clustering algorithm learns the underlying dissimilarity measure while finding compact clusters in the given data set. Through our experimental studies on high-dimensional textual data sets, we demonstrate that the proposed algorithm achieves higher accuracy than the algorithms using pairwise constraints for supervision.

#index 844387
#* On Learning Asymmetric Dissimilarity Measures
#@ Krishna Kummamuru;Raghu Krishnapuram;Rakesh Agrawal
#t 2005
#c 18
#% 266215
#% 269217
#% 309128
#% 342739
#% 356892
#% 577224
#% 729910
#% 769945
#% 770074
#% 770782
#! Many practical applications require that distance measures to be asymmetric and context-sensitive. We introduce Context-sensitive Learnable Asymmetric Dissimilarity (CLAD) measures, which are defined to be a weighted sum of a fixed number of dissimilarity measures where the associated weights depend on the point from which the dissimilarity is measured. The parameters used in defining the measure capture the global relationships among the features. We provide an algorithm to learn the dissimilarity measure automatically from a set of user specified comparisons in the form "x is closer to y than to z," and study its performance. The experimental results show that the proposed algorithm outperforms other approaches due to the context sensitive nature of the CLAD measures.

#index 844388
#* Partial Elastic Matching of Time Series
#@ Longin Jan Latecki;Vasileios Megalooikonomou;Qiang Wang;Rolf Lakaemper;C. A. Ratanamahatana;E. Keogh
#t 2005
#c 18
#% 462231
#% 477479
#% 478455
#% 631920
#% 659971
#% 729931
#% 729960
#% 769896
#% 800574
#% 1673607
#! We consider the problem of elastic matching of time series. We propose an algorithm that determines a subsequence of a target time series that best matches a query series. In the proposed algorithm we map the problem of the best matching subsequence to the problem of a cheapest path in a DAG (directed acyclic graph). The proposed approach allows us to also compute the optimal scale and translation of time series values, which is a nontrivial problem in the case of subsequence matching.

#index 844389
#* CLUGO: A Clustering Algorithm for Automated Functional Annotations Based on Gene Ontology
#@ In-Yee Lee;Jan-Ming Ho;Ming-Syan Chen
#t 2005
#c 18
#% 721327
#% 830652
#% 832643
#% 833027
#% 842795
#! We address the issue of providing highly informative and comprehensive annotations using information revealed by the structured vocabularies of Gene Ontology (GO). For a target, a set of candidate terms for inferring target properties is collected and form a unique distribution on the GO directed acyclic graph (DAG). We propose a novel ontology-based clustering algorithm — CLUGO, which considers GO hierarchical characteristics and the clustering of term distributions. By identifying significant groups in the distributions, CLUGO assigns comprehensive and correct annotations for a target. According to the results of experiments with automated sequence functional annotations, CLUGO represents a considerable improvement over our previous work — GOMIT in terms of recall while maintaining a similar level of precision. We conclude that given a GO candidate term distribution, CLUGO is an efficient ontology-based clustering algorithm for selecting comprehensive and correct annotations.

#index 844390
#* An Optimal Linear Time Algorithm for Quasi-Monotonic Segmentation
#@ Daniel Lemire;Martin Brooks;Yuhong Yan
#t 2005
#c 18
#% 581675
#% 745513
#% 1289414
#! Monotonicity is a simple yet significant qualitative characteristic. We consider the problem of segmenting an array in up to K segments. We want segments to be as monotonic as possible and to alternate signs. We propose a quality metric for this problem, present an optimal linear time algorithm based on novel formalism, and compare experimentally its performance to a linear time top-down regression algorithm. We show that our algorithm is faster and more accurate. Applications include pattern recognition and qualitative modeling.

#index 844391
#* Average Number of Frequent (Closed) Patterns in Bernouilli and Markovian Databases
#@ Francois Rioult;Arnaud Soulet
#t 2005
#c 18
#% 210160
#% 232136
#% 237200
#% 310494
#% 464714
#% 466487
#% 481290
#% 481779
#! In data mining, enumerate the frequent or the closed patterns is often the first difficult task leading to the association rules discovery. The number of these patterns represents a great interest. The lower bound is known to be constant whereas the upper bound is exponential, but both situations correspond to pathological cases. For the first time, we give an average analysis of the number of frequent or closed patterns. Average analysis is often closer to real situations and gives more information about the role of the parameters. In this paper, two probabilistic models are studied: a BERNOULLI and a MARKOVIAN. In both models and for large databases, we prove that the number of frequent patterns, for a fixed frequency threshold , is exponential in the number of items and polynomial in the number of transactions. On the other hand, for a proportional frequency threshold , the number of frequent patterns is polynomial in the number of items and does not involve the number of transactions. Finally, we prove in the BERNOULLI model that the number of closed patterns, for a proportional frequency threshold, is polynomial in the number of items.

#index 844392
#* Predicting Software Escalations with Maximum ROI
#@ Charles X. Ling;Shengli Sheng;Tilmann Bruckhaus;Nazim H. Madhavji
#t 2005
#c 18
#% 136350
#% 209021
#% 232102
#% 290482
#% 333934
#% 374518
#% 393792
#% 438360
#% 449588
#% 534295
#% 727925
#% 770791
#% 1289281
#! Enterprise software venders often have to release software products before all reported defects are corrected, and a small number of these reported defects will be escalated by customers whose businesses are seriously impacted. Escalated defects must be quickly resolved at a high cost by the software vendors. The total costs can be even greater, including loss of reputation, satisfaction, loyalty, and repeat revenue. In this paper, we develop an Escalation Prediction (EP) system to mine historic defect report data and predict the escalation risk of current defect reports for maximum ROI (Return On Investment). More specifically, we first describe a simple and general framework to convert the maximum ROI problem to cost-sensitive learning. We then apply and compare several best-known cost-sensitive learning approaches for EP. The EP system has produced promising results, and has been deployed in the product group of an enterprise software vendor. Conclusions drawn from this study also provide guidelines for mining imbalanced datasets and cost-sensitive learning.

#index 844393
#* Text Representation: From Vector to Tensor
#@ Ning Liu;Benyu Zhang;Jun Yan;Zheng Chen;Wenyin Liu;Fengshan Bai;Leefeng Chien
#t 2005
#c 18
#% 316143
#% 387427
#% 648320
#% 719598
#! In this paper, we propose a text representation model, Tensor Space Model (TSM), which models the text by multilinear algebraic high-order tensor instead of the traditional vector. Supported by techniques of multilinear algebra, TSM offers a potent mathematical framework for analyzing the multifactor structures. TSM is further supported by certain introduced particular operations and presented tools, such as the High-Order Singular Value Decomposition (HOSVD) for dimension reduction and other applications. Experimental results on the 20 Newsgroups dataset show that TSM is constantly better than VSM for text classification.

#index 844394
#* Mining Approximate Frequent Itemsets from Noisy Data
#@ Jinze Liu;Susan Paulsen;Wei Wang;Andrew Nobel;Jan Prins
#t 2005
#c 18
#% 152934
#% 232136
#% 342610
#% 769905
#% 769957
#! Frequent itemset mining is a popular and important first step in analyzing data sets across a broad range of applications. The traditional, "exact" approach for finding frequent itemsets requires that every item in the itemset occurs in each supporting transaction. However, real data is typically subject to noise, and in the presence of such noise, traditional itemset mining may fail to detect relevant itemsets, particularly those large itemsets that are more vulnerable to noise. In this paper we propose approximate frequent itemsets (AFI), as a noise-tolerant itemset model. In addition to the usual requirement for sufficiently many supporting transactions, the AFI model places constraints on the fraction of errors permitted in each item column and the fraction of errors permitted in a supporting transaction. Taken together, these constraints winnow out the approximate itemsets that exhibit systematic errors. In the context of a simple noise model, we demonstrate that AFI is better at recovering underlying data patterns, while identifying fewer spurious patterns than either the exact frequent itemset approach or the existing error tolerant itemset approach of Yang et al. [11].

#index 844395
#* Parallel Algorithms for Distance-Based and Density-Based Outliers
#@ Elio Lozano;Edgar Acuna
#t 2005
#c 18
#% 223687
#% 300136
#% 300183
#% 430430
#% 434349
#% 479791
#% 481281
#% 570886
#% 729912
#% 781774
#! An outlier is an observation that deviates so much from other observations as to arouse suspicion that it was generated by a different mechanism. Outlier detection has many applications, such as data cleaning, fraud detection and network intrusion. The existence of outliers can indicate individuals or groups that exhibit a behavior that is very different from most of the individuals of the dataset. In this paper we design two parallel algorithms, the first one is for finding out distance-based outliers based on nested loops along with randomization and the use of a pruning rule. The second parallel algorithm is for detecting density-based local outliers. In both cases data parallelism is used. We show that both algorithms reach near linear speedup. Our algorithms are tested on four real-world datasets coming from the Machine Learning Database Repository at the UCI.

#index 844396
#* Bit Reduction Support Vector Machine
#@ Tong Luo;Lawrence O. Hall;Dmitry B. Goldgof;Andrew Remsen
#t 2005
#c 18
#% 191910
#% 269218
#% 310547
#% 331916
#% 410276
#% 431037
#% 775375
#% 1558464
#% 1781460
#% 1788314
#! Support vector machines are very accurate classifiers and have been widely used in many applications. However, the training and to a lesser extent prediction time of support vector machines on very large data sets can be very long. This paper presents a fast compression method to scale up support vector machines to large data sets. A simple bit reduction method is applied to reduce the cardinality of the data by weighting representative examples. We then develop support vector machines which may be trained on weighted data. Experiments indicate that the bit reduction support vector machine produces a significant reduction in the time required for both training and prediction with minimum loss in accuracy. It is also shown to be more accurate than random sampling, when the data is not over-compressed.

#index 844397
#* Spatial Clustering of Chimpanzee Locations for Neighborhood Identification
#@ Sandeep Mane;Carson Murray;Shashi Shekhar;Jaideep Srivastava;Anne Pusey
#t 2005
#c 18
#% 408159
#! Since 1960, the chimpanzees (Pan troglodytes) of Gombe National Park, Tanzania, have been studied by behavioral ecologists, including Jane Goodall. Data have been collected for more than 40 years and are being analyzed by researchers in order to increase our understanding of the social structure of chimpanzees. In this paper, we consider the following question of interest to behavioral ecologists — "Does clustering exist among female chimpanzees in terms of their spatial locations?" The analysis of this question will help behavioral ecologists to learn about the space use and the social interactions between female chimpanzees. The data collected for this analysis are marked spatial point patterns over the park. Current spatial clustering methods lack the ability to handle such marked point patterns directly. This paper presents a novel application of spatial point pattern analysis and data mining techniques to the ecological problem of clustering female chimpanzees. We found that Ripley's K-function provides a powerful statistical tool for evaluating clustering behavior among spatial point patterns. We then proposed two clustering approaches for marked point patterns using the K-function. Experimental results using the proposed clustering methods provide significant insight into the dynamics of female chimpanzee space use and into the overall social stucture of the species. In addition, the proposed methods can be extended to also include temporal information.

#index 844398
#* A Graph-Ranking Algorithm for Geo-Referencing Documents
#@ Bruno Martins;Mario J. Silva
#t 2005
#c 18
#% 480467
#% 766441
#% 1016176
#! This paper presents an application of PageRank for assigning documents with a corresponding geographical scope. We describe the technique in detail, together with its theoretical formulation. Experimental results are promising, comparing favorably with previous proposals.

#index 844399
#* An Expected Utility Approach to Active Feature-Value Acquisition
#@ Prem Melville;Maytal Saar-Tsechansky;Foster Provost;Raymond Mooney
#t 2005
#c 18
#% 17144
#% 170649
#% 290482
#% 464268
#% 629616
#% 785413
#% 829982
#% 1673023
#! In many classification tasks training data have missing feature values that can be acquired at a cost. For building accurate predictive models, acquiring all missing values is often prohibitively expensive or unnecessary, while acquiring a random subset of feature values may not be most effective. The goal of active feature-value acquisition is to incrementally select feature values that are most cost-effective for improving the model's accuracy. We present an approach that acquires feature values for inducing a classification model based on an estimation of the expected improvement in model accuracy per unit cost. Experimental results demonstrate that our approach consistently reduces the cost of producing a model of a desired accuracy compared to random feature acquisitions.

#index 844400
#* Automatically Mining Result Records from Search Engine Response Pages
#@ Dheerendranath Mundluru;Jayasimha Reddy Katukuri;Saygin Celebi
#t 2005
#c 18
#% 317975
#% 330784
#% 643073
#% 729978
#% 794508
#! Usually, Web applications such as deep Web crawlers, metasearch engines, and other Web mining systems need to extract information displayed in the form of result records on response pages returned by search engines in response to submitted queries. Extracting such records is challenging as search engines are heterogeneous in displaying their records. In addition, response pages returned by many search engines include other noisy content such as advertisements, suggestion links, etc., which make the extraction task even more complicated. In this paper, we propose a highly effective and efficient algorithm for automatically mining result records from search engine response pages.

#index 844401
#* Efficiently Mining Frequent Closed Partial Orders
#@ Jian Pei;Jian Liu;Haixun Wang;Ke Wang;Philip S. Yu;Jianyong Wang
#t 2005
#c 18
#% 310515
#% 397632
#% 420063
#% 463903
#% 464996
#% 729922
#! Mining ordering information from sequence data is an important data mining task. Sequential pattern mining [1] can be regarded as mining frequent segments of total orders from sequence data. However, sequential patterns are often insufficient to concisely capture the general ordering information.

#index 844402
#* CLUMP: A Scalable and Robust Framework for Structure Discovery
#@ Kunal Punera;Joydeep Ghosh
#t 2005
#c 18
#% 36672
#% 210173
#% 248790
#% 329562
#% 466083
#% 722902
#% 785549
#% 844402
#! We introduce a robust and efficient framework called CLUMP (CLustering Using Multiple Prototypes) for unsupervised discovery of structure in data. CLUMP relies on finding multiple prototypes that summarize the data. Clustering the prototypes enables our algorithm to scale up to extremely large and high-dimensional domains such as text data. Other desirable properties include robustness to noise and parameter choices. In this paper, we describe the approach in detail, characterize its performance on a variety of datasets, and compare it to some existing model selection approaches.

#index 844403
#* On the Tractability of Rule Discovery from Distributed Data
#@ Martin Scholz
#t 2005
#c 18
#% 232126
#% 414609
#% 481290
#% 501207
#% 722920
#% 799042
#! This paper analyses the tractability of rule selection for supervised learning in distributed scenarios. The selection of rules is usually guided by a utility measure such as predictive accuracy or weighted relative accuracy. A common strategy to tackle rule selection from distributed data is to evaluate rules locally on each dataset. While this works well for homogeneously distributed data, this work proves limitations of this strategy if distributions are allowed to deviate. The identification of those subsets for which local and global distributions deviate, poses a learning task of its own, which is shown to be at least as complex as discovering the globally best rules from local data.

#index 844404
#* Face Recognition Using Landmark-Based Bidimensional Regression
#@ Jiazheng Shi;Ashok Samal;David Marx
#t 2005
#c 18
#% 282190
#% 315986
#% 443716
#! This paper studies how biologically meaningful landmarks extracted from face images can be exploited for face recognition using the bidimensional regression. Incorporating the correlation statistics of landmarks, this paper also proposes a new approach called eigenvalue weighted bidimensional regression. Complex principal component analysis is used for computing eigenvalues and removing correlation among landmarks. We evaluate our approach using two standard face databases: the Purdue AR and the NIST FERET. Experimental results show that the bidimensional regression is an efficient method to exploit geometry information of face images.

#index 844405
#* Instability of Classifiers on Categorical Data
#@ Arno Siebes;Muhammad Subianto;Ad Feelders
#t 2005
#c 18
#% 425068
#% 729437
#! In this paper we study the local behaviour of arbitrary classifiers using the instability of that classifier in a data point. Moreover, we introduce two algorithms. The first to find highly unstable points, the second to find islands of stability.

#index 844406
#* Pruning Social Networks Using Structural Properties and Descriptive Attributes
#@ Lisa Singh;Lise Getoor;Louis Licamele
#t 2005
#c 18
#% 146494
#% 342596
#% 478596
#% 577356
#% 729923
#% 729926
#% 730089
#! Scale is often an issue with understanding and making sense of large social networks. Here we investigate methods for pruning social networks by determining the most relevant relationships. We measure importance in terms of predictive accuracy on a set of target attributes of the social network. Our goal is to create a pruned network that models only the most informative affiliations and relationships. We present methods for pruning networks based on both structural properties and descriptive attributes demonstrate it on a network of NASDAQ and NYSE businesses and on a bibliographic network.

#index 844407
#* Optimizing Constraint-Based Mining by Automatically Relaxing Constraints
#@ Arnaud Soulet;Bruno Cremilleux
#t 2005
#c 18
#% 216508
#% 420062
#% 464989
#% 479971
#% 481290
#% 576117
#% 577215
#% 785336
#% 1707855
#! In constraint-based mining, the monotone and anti-monotone properties are exploited to reduce the search space. Even if a constraint has not such suitable properties, existing algorithms can be re-used thanks to an approximation, called relaxation. In this paper, we automatically compute monotone relaxations of primitive-based constraints. First, we show that the latter are a superclass of combinations of both kinds of monotone constraints. Second, we add two operators to detect the properties of monotonicity of such constraints. Finally, we define relaxing operators to obtain monotone relaxations of them.

#index 844408
#* Bias Analysis in Text Classification for Highly Skewed Data
#@ Lei Tang;Huan Liu
#t 2005
#c 18
#% 465754
#% 466266
#% 722935
#% 765521
#% 1272000
#! Feature selection is often applied to high-dimensional data as a preprocessing step in text classification. When dealing with highly skewed data, we observe that typical feature selection metrics like information gain or chi-squared are biased toward selecting features for the minor class, and the metric of bi-normal separation can select features for both minor and major classes. In this work, we investigate how these feature selection metrics impact on the performance of frequently used classifiers such as Decision Trees, Na篓ýve Bayes, and Support Vector Machines via bias analysis for highly skewed data. Three types of biases are metric bias, class bias, and classifier bias. Extensive experiments are designed to understand how these biases can be employed in concert and efficiently to achieve good classificationperformance. We report our findings and present recommended approaches to text classification based on bias analysis and the empirical study.

#index 844409
#* Efficient Mining of High Branching Factor Attribute Trees
#@ Alexandre Termier;Marie-Christine Rousset;Michele Sebag;Kouzou Ohara;Takashi Washio;Hiroshi Motoda
#t 2005
#c 18
#% 481290
#% 577218
#% 785428
#% 944951
#% 1718448
#! In this paper, we present a new tree mining algorithm, DRYADEPARENT, based on the hooking principle first introduced in DRYADE [9]. In the experiments, we demonstrate that the branching factor and depth of the frequent patterns to find are key factor of complexity for tree mining algorithms. We show that DRYADEPARENT outperforms the current fastest algorithm, CMTreeMiner, by orders of magnitude on datasets where the frequent patterns have a high branching factor.

#index 844410
#* Anomaly Intrusion Detection Using Multi-Objective Genetic Fuzzy System and Agent-Based Evolutionary Computation Framework
#@ Chi-Ho Tsang;Sam Kwong;Hanli Wang
#t 2005
#c 18
#% 128968
#% 630993
#% 1346861
#% 1777209
#% 1788191
#! In this paper, we present a multi-objective genetic fuzzy system for anomaly intrusion detection. The proposed system extracts accurate and interpretable fuzzy rule-based knowledge from network data using an agent-based evolutionary computation framework. The experimental results on KDD-Cup99 intrusion detection benchmark data demonstrate that our system can achieve high detection rate for intrusion attacks and low false positive rate for normal network traffic.

#index 844411
#* Mining Quantitative Frequent Itemsets Using Adaptive Density-Based Subspace Clustering
#@ Takashi Washio;Yuki Mitsunaga;Hiroshi Motoda
#t 2005
#c 18
#% 210160
#% 248792
#% 273891
#% 280417
#% 316481
#% 397384
#% 443480
#% 785355
#% 796202
#! A novel approach to subspace clustering is proposed to exhaustively and efficiently mine quantitative frequent itemsets (QFIs) from massive transaction data鹿. For the computational tractability, our approach introduces adaptive density-based and Apriori-like algorithm. Its outstanding performance is shown through numerical experiments.

#index 844412
#* Hot Item Mining and Summarization from Multiple Auction Web Sites
#@ Tak-Lam Wong;Wai Lam
#t 2005
#c 18
#% 301241
#% 387791
#% 565545
#% 722926
#% 769892
#% 785365
#% 800608
#% 823366
#% 1428371
#! Online auction Web sites are fast changing, highly dynamic, and complex as they involve tremendous sellers and potential buyers, as well as a huge amount of items listed for bidding. We develop a two-phase framework which aims at mining and summarizing hot items from multiple auctionWeb sites to assist decision making. The objective of the first phase is to automatically extract the product features and product feature values of the items from the descriptions provided by the sellers. We design a HMM-based learning method to train an extended HMM model which can adapt to the unseen Web page from which the information is extracted. The goal of the second phase is to discover and summarize the hot items based on the extracted information. We formulate the hot item mining task as a semi-supervised learning problem and employ the graph mincuts algorithm to accomplish this task. The summary of the hot items is then generated by considering the frequency and the position of the product features being mentioned in the descriptions. We have conducted extensive experiments from several real-world auction Web sites to demonstrate the effectiveness of our framework.

#index 844413
#* Merging Interface Schemas on the Deep Web via Clustering Aggregation
#@ Wensheng Wu;AnHai Doan;Clement Yu
#t 2005
#c 18
#% 654459
#% 765409
#% 800530
#% 1015284
#! We consider the problem of integrating a large number of interface schemas over the Deep Web, The scale of the problem and the diversity of the sources present serious challenges to the conventional manual or rule-based approaches to schema integration. To address these challenges, we propose a novel formulation of schema integration as an optimization problem, with the objective of maximally satisfying the constraints given by individual schemas. Since the optimization problem can be shown to be NP-complete, we develop a novel approximation algorithm LMax, which builds the unified schema via recursive applications of clustering aggregation. We further extend LMax to handle the irregularities frequently occurring among the interface schemas. Extensive evaluation on real-world data sets shows the effectiveness of our approach.

#index 844414
#* On the Stationarity of Multivariate Time Series for Correlation-Based Data Analysis
#@ Kiyoung Yang;Cyrus Shahabi
#t 2005
#c 18
#% 115462
#% 294634
#% 780854
#% 784569
#% 788670
#% 821868
#% 1781033
#! Multivariate time series (MTS) data sets are common in various multimedia, medical and financial application domains. These applications perform several data-analysis operations on large number of MTS data sets such as similarity searches, feature-subset-selection, clustering and classifications. Correlation-based techniques, such as Principal Component Analysis (PCA), have proven to improve the efficiency of many of the above-mentioned data-analysis operations on MTS, which implies that the correlation coefficientsconcisely represent the original MTS data. However, if the statistical properties (e.g., variance) of MTS data change over time dimension, i.e., MTS data is non-stationary, the correlation coefficients are not stable. In this paper, we propose to utilize the stationarity of the MTS data sets, in order to represent the original MTS data more stably, as well as concisely with the correlation coefficients. That is, before performing any correlation-based data analysis, we first executes the stationarity test to decide whether the MTS data is stationary or not, i.e., whether the correlation is stable or not. Subsequently, for a non-stationary MTS data set, we difference it to render the data set stationary. Even though our approach is general, to focus the discussion we describe our approach within the context of our previously proposed technique for MTS similarity search. In order to show the validity of our approach, we performed several experiments on four real-world data sets. The results show that the performance of our similarity search technique have significantly improved in terms of precision/recall.

#index 844415
#* Speculative Markov Blanket Discovery for Optimal Feature Selection
#@ Sandeep Yaramakala;Dimitris Margaritis
#t 2005
#c 18
#% 44876
#! In this paper we address the problem of learning the Markov blanket of a quantity from data in an efficient manner. Markov blanket discovery can be used in the feature selection problem to find an optimal set of features for classificationtasks, and is a frequently-used preprocessing phase in data mining, especially for high-dimensional domains. Our contribution is a novel algorithm for the induction of Markov blankets from data, called Fast-IAMB, that employs a heuristic to quickly recover the Markov blanket. Empirical results show that Fast-IAMB performs in many cases faster and more reliably than existing algorithms without adversely affecting the accuracy of the recovered Markov blankets.

#index 844416
#* A Join-Less Approach for Co-Location Pattern Mining: A Summary of Results
#@ Jin Soung Yoo;Shashi Shekhar;Mete Celik
#t 2005
#c 18
#% 342635
#% 481290
#% 527021
#% 784296
#! Spatial co-location patterns represent the subsets of features whose instances are frequently located together in geographic space. Co-location pattern discovery presents challenges since the instances of spatial features are embedded in a continuous space and share a variety of spatial relationships. A large fraction of the computation time is devoted to identifying the instances of co-location patterns. We propose a novel join-less approach for co-location pattern mining, which materializes spatial neighbor relationships with no loss of co-location instances and reduces the computational cost of identifying the instances. The join-less co-location mining algorithm is efficient since it uses an instance-lookup scheme instead of an expensive spatial or instance join operation for identifying co-location instances. The experimental evaluations show the join-less algorithm performs more efficiently than a current join-based algorithm and is scalable in dense spatial datasets.

#index 844417
#* Learning through Changes: An Empirical Study of Dynamic Behaviors of Probability Estimation Trees
#@ Kun Zhang;Zujia Xu;Jing Peng;Bill Buckles
#t 2005
#c 18
#% 136350
#% 458361
#% 580510
#% 727888
#% 1250172
#% 1272000
#% 1707849
#! In practice, learning from data is often hampered by the limited training examples. In this paper, as the size of training data varies, we empirically investigate several probability estimation tree algorithms over eighteen binary classification problems. Nine metrics are used to evaluate their performances. Our aggregated results show that ensemble trees consistently outperform single trees. Confusion factor trees(CFT) register poor calibration even as training size increases, which shows that CFTs are potentially biased if data sets have small noise. We also provide analysis on the observed performance of the tree algorithms.

#index 844418
#* Visualizing Global Manifold Based on Distributed Local Data Abstractions
#@ Xiaofeng Zhang;William K. Cheung
#t 2005
#c 18
#% 257039
#% 727929
#% 1279283
#% 1289650
#! Mining distributed data for global knowledge is getting more attention recently. The problem is especially challenging when data sharing is prohibited due to local constraints like limited bandwidth and data privacy. In this paper, we investigate how to derive the embedded manifold (as a 2-D map)for a horizontally partitioned data set, where data cannot be shared among the partitions directly. We propose a model-based approach which computes hierarchical local data abstractions, aggregates the abstractions, and finally learns a global generative model — generative topographic mapping (GTM) based on the aggregated data abstraction. We applied the proposed method to two benchmarking data sets and demonstrated that the accuracy of the derived manifold can effectively be controlled by adjusting the data granularity level of the adopted local abstraction.

#index 844419
#* Bagging with Adaptive Costs
#@ Yi Zhang;W. Nick Street
#t 2005
#c 18
#% 132938
#% 190581
#% 209021
#% 400847
#% 424997
#% 551723
#! Ensemble methods have proved to be highly effective in improving the performance of base learners under most circumstances. In this paper, we propose a new algorithm that combines the merits of some existing techniques, namely bagging, arcing and stacking. The basic structure of the algorithm resembles bagging, using a linear support vector machine (SVM). However, the misclassification cost of each training point is repeatedly adjusted according to its observed out-of-bag vote margin. In this way, the method gains the advantage of arcing — building the classifier the ensemble needs — without fixating on potentially noisy points. Computational experiments show that this algorithm performs consistently better than bagging and arcing.

#index 844420
#* Example-Based Robust Outlier Detection in High Dimensional Datasets
#@ Cui Zhu;Hiroyuki Kitagawa;Christos Faloutsos
#t 2005
#c 18
#% 296738
#% 300136
#% 333929
#% 369236
#% 464888
#% 479791
#% 686757
#! Detecting outliers is an important problem. Most of its applications typically possess high dimensional datasets. In high dimensional space, the data becomes sparse which implies that every object can be regarded as an outlier from the point of view of similarity. Furthermore, a fundamental issue is that the notion of which objects are outliers typically varies between users, problem domains or, even, datasets. In this paper, we present a novel robust solution which detects high dimensional outliers based on user examples and tolerates incorrect inputs. It studies the behavior of projections of such a few examples, to discover further objects that are outstanding in the projection where many examples are outlying. Our experiments on both real and synthetic datasets demonstrate the ability of the proposed method to detect outliers corresponding to the user examples.

#index 844421
#* CTC — Correlating Tree Patterns for Classification
#@ Albrecht Zimmermann;Bjorn Bringmann
#t 2005
#c 18
#% 299985
#% 342604
#% 449508
#% 466483
#% 729941
#% 1712907
#! We present CTC, a new approach to structural classification. It uses the predictive power of tree patterns correlating with the class values, combining state-of-the-art tree mining with sophisticated pruning techniques to find the k most discriminative pattern in a dataset. In contrast to existing methods, CTC uses no heuristics and the only parameters to be chosen by the user are the maximum size of the rule set and a single, statistically well founded cut-off value. The experiments show that CTC classifiers achieve good accuracies while the induced models are smaller than those of existing approaches, facilitating comprehensibility.

#index 844422
#* Welcome to ICDM 2005
#@ 
#t 2005
#c 18

#index 844423
#* Handling Generalized Cost Functions in the Partitioning Optimization Problem through Sequential Binary Programming
#@ Alan S. Abrahams;Adrian Becker;Daniel Fleder;Ian C. MacMillan
#t 2005
#c 18
#% 136350
#% 160852
#% 280437
#% 458681
#% 464280
#% 520431
#% 564200
#% 635996
#% 727925
#% 746470
#% 770791
#% 1272369
#% 1289281
#! This paper proposes a framework for cost-sensitive classification under a generalized cost function. By combining decision trees with sequential binary programming, we can handle unequal misclassification costs, constrained classification, and complex objective functions that other methods cannot. Our approach has two main contributions. First, it provides a new method for cost-sensitive classification that outperforms a traditional, accuracy-based method and some current cost-sensitive approaches. Second, and more important, our approach can handle a generalized cost function, instead of the simpler misclassification cost matrix to which other approaches are limited.

#index 844424
#* Online Hierarchical Clustering in a Data Warehouse Environment
#@ Elke Achtert;Christian Bohm;Hans-Peter Kriegel;Peer Kroger
#t 2005
#c 18
#% 273890
#% 333933
#% 345857
#% 345859
#% 481956
#% 566870
#% 629674
#% 632080
#% 765440
#% 818916
#% 1015292
#% 1390149
#! Many important industrial applications rely on data mining methods to uncover patterns and trends in large data warehouse environments. Since a data warehouse is typically updated periodically in a batch mode, the mined patterns have to be updated as well. This requires not only accuracy from data mining methods but also fast availability of up-to-date knowledge, particularly in the presence of a heavy update load. To cope with this problem, we propose the use of online data mining algorithms which permanently store the discovered knowledge in suitable data structures and enable an efficient adaptation of these structures after insertions and deletions on the raw data. In this paper, we demonstrate how hierarchical clustering methods can be reformulated as online algorithms based on the hierarchical clustering method OPTICS, using a density estimator for data grouping. We also discuss how this algorithmic schema can be specialized for efficient online single-link clustering. A broad experimental evaluation demonstrates that the efficiency is superior with significant speed-up factors even for large bulk insertions and deletions.

#index 844425
#* eMailSift: Email Classification Based on Structure and Content
#@ Manu Aery;Sharma Chakravarthy
#t 2005
#c 18
#% 214751
#% 252755
#% 369349
#% 445369
#% 449566
#% 466644
#% 629708
#% 718611
#! In this paper we propose a novel approach that uses structure as well as the content of emails in a folder for email classification. Our approach is based on the premise that representative — common and recurring — structures/patterns can be extracted from a pre-classified email folder and the same can be used effectively for classifying incoming emails. A number of factors that influence representative structure extraction and the classification are analyzed conceptually and validated experimentally. In our approach, the notion of inexact graph match is leveraged for deriving structures that provide coverage for characterizing folder contents. Extensive experimentation validate the selection of parameters and the effectiveness of our approach for email classification.

#index 844426
#* An Empirical Bayes Approach to Detect Anomalies in Dynamic Multidimensional Arrays
#@ Deepak Agarwal
#t 2005
#c 18
#% 280402
#% 345857
#% 378388
#% 404849
#% 632090
#% 993961
#% 1016144
#! We consider the problem of detecting anomalies in data that arise as multidimensional arrays with each dimension corresponding to the levels of a categorical variable. In typical data mining applications, the number of cells in such arrays are usually large. Our primary focus is detecting anomalies by comparing information at the current time to historical data. Naive approaches advocated in the process control literature do not work well in this scenario due to the multiple testing problem - performing multiple statistical tests on the same data produce excessive number of false positives. We use an Empirical Bayes method which works by fitting a two component gaussian mixture to deviations at current time. The approach is scalable to problems that involve monitoring massive number of cells and fast enough to be potentially useful in many streaming scenarios. We show the superiority of the method relative to a naive "per component error rate" procedure through simulation. A novel feature of our technique is the ability to suppress deviations that are merely the consequence of sharp changes in the marginal distributions. This research was motivated by the need to extract critical application information and business intelligence from the daily logs that accompany large-scale spoken dialog systems deployed by AT&T. We illustrate our method on one such system.

#index 844427
#* Classifier Fusion Using Shared Sampling Distribution for Boosting
#@ Costin Barbu;Raja Iqbal;Jing Peng
#t 2005
#c 18
#% 209021
#% 231803
#% 235377
#% 251145
#% 302391
#% 341450
#% 344597
#% 465746
#% 482030
#% 783521
#% 791412
#! We present a new framework for classifier fusion that uses a shared sampling distribution for obtaining a weighted classifier ensemble. The weight update process is self regularizing as subsequent classifiers trained on the disjoint views rectify the bias introduced by any classifier in preceding iterations. We provide theoretical guarantees that our approach indeed provides results which are better than the case when boosting is performed separately on different views. The results are shown to outperform other classifier fusion strategies on a well known texture image database.

#index 915197
#* Proceedings of the Sixth International Conference on Data Mining
#@ 
#t 2006
#c 18

#index 915212
#* Welcome from Conference Chairs
#@ 
#t 2006
#c 18

#index 915213
#* Discovery of Collocation Episodes in Spatiotemporal Data
#@ Huiping Cao;Nikos Mamoulis;David W. Cheung
#t 2006
#c 18
#! Given a collection of trajectories of moving objects with different types (e.g., pumas, deers, vultures, etc.), we introduce the problem of discovering collocation episodes in them (e.g., if a puma is moving near a deer, then a vulture is also going to move close to the same deer with high probability within the next 3 minutes). Collocation episodes catch the inter-movement regularities among different types of objects. We formally define the problem of mining collocation episodes and propose two scaleable algorithms for its efficient solution. We empirically evaluate the performance of the proposed methods using synthetically generated data that emulate real-world object movements.

#index 915214
#* Getting the Most Out of Ensemble Selection
#@ Rich Caruana;Art Munson;Alexandru Niculescu-Mizil
#t 2006
#c 18
#! We investigate four previously unexplored aspects of ensemble selection, a procedure for building ensembles of classifiers. First we test whether adjusting model predictions to put them on a canonical scale makes the ensembles more effective. Second, we explore the performance of ensemble selection when different amounts of data are available for ensemble hillclimbing. Third, we quantify the benefit of ensemble selection's ability to optimize to arbitrary metrics. Fourth, we study the performance impact of pruning the number of models available for ensemble selection. Based on our results we present improved ensemble selection methods that double the benefit of the original method.

#index 915215
#* Diverse Topic Phrase Extraction through Latent Semantic Analysis
#@ Jilin Chen;Jun Yan;Benyu Zhang;Qiang Yang;Zheng Chen
#t 2006
#c 18
#! We propose a novel algorithm for extracting diverse topic phrases in order to provide summary for large corpora. Previous works often ignore the importance of diversity and thus extract phrases crowded on some hot topics while failing to cover other less obvious but important topics. We solve this problem through document re-weighting and phrase diversification by using latent semantic analysis (LSA). Experiments on various datasets show that our new algorithm can improve relevance as well as diversity over different topics for topic phrase extraction problems.

#index 915216
#* AC-Close: Efficiently Mining Approximate Closed Itemsets by Core Pattern Recovery
#@ Hong Cheng;Philip S. Yu;Jiawei Han
#t 2006
#c 18
#! Recent studies have proposed methods to discover approximate frequent itemsets in the presence of random noise. By relaxing the rigid requirement of exact frequent pattern mining, some interesting patterns, which would previously be fragmented by exact pattern mining methods due to the random noise or measurement error, are successfully recovered. Unfortunately, a large number of "uninteresting" candidates are explored as well during the mining process, as a result of the relaxed pattern mining methodology. This severely slows down the mining process. Even worse, it is hard for an end user to distinguish the recovered interesting patterns from these uninteresting ones. In this paper, we propose an efficient algorithm AC-Close to recover the approximate closed itemsets from "core patterns". By focusing on the so-called core patterns, integrated with a top-down mining and several effective pruning strategies, the algorithm narrows down the search space to those potentially interesting ones. Experimental results show that AC-Close substantially outperforms the previously proposed method in terms of efficiency, while delivers a similar set of interesting recovered patterns.

#index 915217
#* Belief Propagation in Large, Highly Connected Graphs for 3D Part-Based Object Recognition
#@ Frank DiMaio;Jude Shavlik
#t 2006
#c 18
#! We describe a part-based object-recognition framework, specialized to mining complex 3D objects from detailed 3D images. Objects are modeled as a collection of parts together with a pairwise potential function. An efficient inference algorithm -- based on belief propagation (BP) -- finds the optimal layout of parts, given some input image. We introduce AggBP, a message aggregation scheme for BP, in which groups of messages are approximated as a single message. For objects consisting of N parts, we reduce CPU time and memory requirements from O( N^2 ) to O(N). We apply AggBP on synthetic data as well as a real-world task identifying protein fragments in three-dimensional images. These experiments show that our improvements result in minimal loss in accuracy in significantly less time.

#index 915218
#* A Framework for Regional Association Rule Mining in Spatial Datasets
#@ Wei Ding;Christoph F. Eick;Jing Wang;Xiaojing Yuan
#t 2006
#c 18
#! The immense explosion of geographically referenced data calls for efficient discovery of spatial knowledge. One of the special challenges for spatial data mining is that information is usually not uniformly distributed in spatial datasets. Consequently, the discovery of regional knowledge is of fundamental importance for spatial data mining. This paper centers on discovering regional association rules in spatial datasets. In particular, we introduce a novel framework to mine regional association rules relying on a given class structure. A reward-based regional discovery methodology is introduced, and a divisive, grid-based supervised clustering algorithm is presented that identifies interesting subregions in spatial datasets. Then, an integrated approach is discussed to systematically mine regional rules. The proposed framework is evaluated in a real-world case study that identifies spatial risk patterns from arsenic in the Texas water supply.

#index 915219
#* Detection of Interdomain Routing Anomalies Based on Higher-Order Path Analysis
#@ Murat Can Ganiz;Sudhan Kanitkar;Mooi Choo Chuah;William M. Pottenger
#t 2006
#c 18
#! Anomalous interdomain Border Gateway Protocol (BGP) events including misconfigurations, attacks and large-scale power failures often affect the global routing infrastructure. Thus, the ability to detect and categorize such events is extremely useful. In this article we present a novel anomaly detection technique for BGP that distinguishes between different anomalies in BGP traffic. This technique is termed Higher Order Path Analysis (HOPA) and focuses on the discovery of patterns in higher order paths in supervised learning datasets. Our results demonstrate that not only worm events but also different types of worms as well as blackout events are cleanly separable and can be classified in real time based on our incremental approach. This novel approach to supervised learning has potential applications in cybersecurity/forensics and text/data mining in general.

#index 915220
#* Exploratory Mining in Cube Space
#@ Raghu Ramakrishnan
#t 2006
#c 18
#! Data Mining has evolved as a new discipline at the intersection of several existing areas, including Database Systems, Machine Learning, Optimization, and Statistics. An important question is whether the field has matured to the point where it has originated substantial new problems and techniques that distinguish it fromits parent disciplines. In this paper, we discuss a class of new problems and techniques that show great promise for exploratory mining, while synthesizing and generalizing ideas from the parent disciplines. While the class of problems we discuss is broad, there is a common underlying objective-to look beyond a single data mining step (e.g., data summarization or model construction) and address the combined process of data selection and transformation, parameter and algorithm selection, and model construction. The fundamental difficulty lies in the large space of alternative choices at each step, and good solutions must provide a natural framework for managing this complexity. We regard this as a grand challenge for DataMining, and see the ideas in this paper as promising initial steps towards a rigorous exploratory framework that supports the entire process.

#index 915221
#* Data Mining Methods for Modeling Gene Expression Regulation and Their Applications
#@ Weixiong Zhang
#t 2006
#c 18
#! Understanding gene expression regulation at both transcriptional and post-transcriptional levels is critical for elucidation of the mechanism of stress tolerance in plants and important for understanding and diagnosis of human diseases. With the advent of high throughput gene expression profiling techniques, a huge amount of gene expression data on various organisms has been collected. Such a wealth of biological data has provided excellent opportunities to elucidating transcriptional regulation mechanisms using machine learning and data mining approaches.

#index 915222
#* An Information Theoretic Approach to Detection of Minority Subsets in Database
#@ Shin Ando;Einoshin Suzuki
#t 2006
#c 18
#! Detection of rare and exceptional occurrences in large-scale databases have become an important practice in the field of knowledge discovery and information retrieval. Many databases include large amount of noise or irrelevant data, whose distribution often overlaps with the subsets of exceptional data containing useful knowledge. This paper addresses the problem of finding a small subset of "minority" data whose distribution overlaps with, but are exceptional to or inconsistent with that of the majority of the database. In such a case, conventional distance-based or density-based approaches in Outlier Detection are ineffective due to their dependence on the structure of the majority or the prerequisite of critical parameters. We formalize the task as an estimation of a model of the minority subset which provides a simple description of the subset and yet maintains divergence from that of the majority. This estimation is formalized as a minimization problem using an information theoretic framework of Rate Distortion theory. We further introduce conditions of the majority to derive an objective function which factorizes the property of the minority and dependence to the structure of the majority. The proposed method shows improvements from conventional approaches in artificial data and a promising result in document retrieval problem.

#index 915223
#* Bayesian State Space Modeling Approach for Measuring the Effectiveness of Marketing Activities and Baseline Sales from POS Data
#@ Tomohiro Ando
#t 2006
#c 18
#! Analysis of Point of Sales (POS) data is an important research area of marketing science and knowledge discovery, which may enable marketing managers to attain the effective marketing activities. To measure the effectiveness of marketing activities and baseline sales, we develop the multivariate time series modeling method in the framework of a general state space model. A multivariate Poisson model and a multivariate correlated auto-regressive model are used for a system model and an observation model. The Bayesian approach via Markov Chain Monte Carlo (MCMC) algorithm is employed for estimating model parameters. To evaluate the goodness of the estimated models, the Bayesian predictive information criterion is utilized. The proposed model is evaluated with its application to actual POS data.

#index 915224
#* Mining Generalized Graph Patterns Based on User Examples
#@ Pavel Dmitriev;Carl Lagoze
#t 2006
#c 18
#! There has been a lot of recent interest in mining patterns from graphs. Often, the exact structure of the patterns of interest is not known. This happens, for example, when molecular structures are mined to discover fragments useful as features in chemical compound classification task, or when web sites are mined to discover sets of web pages representing logical documents. Such patterns are often generated from a few small subgraphs (cores), according to certain generalization rules (GRs). We call such patterns "generalized patterns"(GPs). While being structurally different, GPs often perform the same function in the network. Previously proposed approaches to mining GPs either assumed that the cores and the GRs are given, or that all interesting GPs are frequent. These are strong assumptions, which often do not hold in practical applications. In this paper, we propose an approach to mining GPs that is free from the above assumptions. Given a small number of GPs selected by the user, our algorithm discovers all GPs similar to the user examples. First, a machine learning-style approach is used to find the cores. Second, generalizations of the cores in the graph are computed to identify GPs. Evaluation on synthetic data, generated using real cores and GRs from biological and web domains, demonstrates effectiveness of our approach.

#index 915225
#* An Experimental Investigation of Graph Kernels on a Collaborative Recommendation Task
#@ Francois Fouss;Luh Yen;Alain Pirotte;Marco Saerens
#t 2006
#c 18
#! This work presents a systematic comparison between seven kernels (or similarity matrices) on a graph, namely the exponential diffusion kernel, the Laplacian diffusion kernel, the von Neumann kernel, the regularized Laplacian kernel, the commute time kernel, and finally the Markov diffusion kernel and the cross-entropy diffusion matrix -- both introduced in this paper -- on a collaborative recommendation task involving a database. The database is viewed as a graph where elements are represented as nodes and relations as links between nodes. From this graph, seven kernels are computed, leading to a set of meaningful proximity measures between nodes, allowing to answer questions about the structure of the graph under investigation; in particular, recommend items to users. Crossvalidation results indicate that a simple nearest-neighbours rule based on the similarity measure provided by the regularized Laplacian, the Markov diffusion and the commute time kernels performs best. We therefore recommend the use of the commute time kernel for computing similarities between elements of a database, for two reasons: (1) it has a nice appealing interpretation in terms of random walks and (2) no parameter needs to be adjusted.

#index 915226
#* A Balanced Ensemble Approach to Weighting Classifiers for Text Classification
#@ Gabriel Pui Cheong Fung;Jeffrey Xu Yu;Haixun Wang;David W. Cheung;Huan Liu
#t 2006
#c 18
#! This paper studies the problem of constructing an effective heterogeneous ensemble classifier for text classification. One major challenge of this problem is to formulate a good combination function, which combines the decisions of the individual classifiers in the ensemble. We show that the classification performance is affected by three weight components and they should be included in deriving an effective combination function. They are: (1) Global effectiveness, which measures the effectiveness of a member classifier in classifying a set of unseen documents; (2) Local effectiveness, which measures the effectiveness of a member classifier in classifying the particular domain of an unseen document; and (3) Decision confidence, which describes how confident a classifier is when making a decision when classifying a specific unseen document. We propose a new balanced combination function, called Dynamic Classifier Weighting (DCW), that incorporates the afore-mentioned three components. The empirical study demonstrates that the new combination function is highly effective for text classification.

#index 915227
#* Star-Structured High-Order Heterogeneous Data Co-clustering Based on Consistent Information Theory
#@ Bin Gao;Tie-Yan Liu;Wei-Ying Ma
#t 2006
#c 18
#! Heterogeneous object co-clustering has become an important research topic in data mining. In early years of this research, people mainly worked on two types of heterogeneous data (denoted by pair-wise co-clustering); while recently more and more attention was paid to multiple types of heterogeneous data (denoted by highorder co-clustering). In this paper, we studied the highorder co-clustering of objects with star-structured interrelationship, i.e., there is a central type of objects that connects the other types of objects. Actually, this case could be a very good model for many real-world applications, such as the co-clustering of Web images, their low-level visual features, and the surrounding text. We used a tripartite graph to represent the interrelationships among different objects, and proposed a consistent information theory which generates an effective algorithm to obtain the co-clusters of different types of objects. Experiments on a Web image show that our proposed algorithm is a better choice compared with previous work on heterogeneous object co-clustering.

#index 915228
#* GraphRank: Statistical Modeling and Mining of Significant Subgraphs in the Feature Space
#@ Huahai He;Ambuj K. Singh
#t 2006
#c 18
#! We propose a technique for evaluating the statistical significance of frequent subgraphs in a database. A graph is represented by a feature vector that is a histogram over a set of basis elements. The set of basis elements is chosen based on domain knowledge and consists generally of vertices, edges, or small graphs. A given subgraph is transformed to a feature vector and the significance of the subgraph is computed by considering the significance of occurrence of the corresponding vector. The probability of occurrence of the vector in a random vector is computed based on the prior probability of the basis elements. This is then used to obtain a probability distribution on the support of the vector in a database of random vectors. The statistical significance of the vector/subgraph is then defined as the p-value of its observed support. We develop efficient methods for computing p-values and lower bounds. A simplified model is further proposed to improve the efficiency. We also address the problem of feature vector mining, a generalization of itemset mining where counts are associated with items and the goal is to find significant sub-vectors. We present an algorithm that explores closed frequent sub-vectors to find significant ones. Experimental results show that the proposed techniques are effective, efficient, and useful for ranking frequent subgraphs by their statistical significance.

#index 915229
#* Learning to Use a Learned Model: A Two-Stage Approach to Classification
#@ Maria-Luiza Antonie;Osmar R. Zaiane;Robert C. Holte
#t 2006
#c 18
#! Association rule-based classifiers have recently emerged as competitive classification systems. However, there are still deficiencies that hinder their performance. One defi- ciency is the use of rules in the classification stage. Current systems assign classes to new objects based on the best rule applied or on some predefined scoring of multiple rules. In this paper we propose a new technique where the system automatically learns how to use the rules. We achieve this by developing a two-stage classification model. First, we use association rule mining to discover classification rules. Second, we employ another learning algorithm to learn how to use these rules in the prediction process. Our two-stage approach outperforms C4.5 and RIPPER on the UCI datasets in our study, and outperforms other rule-learning methods on more than half the datasets. The versatility of our method is also demonstrated by applying it to text classification, where it equals the performance of the best known systems for this task, SVMs.

#index 915230
#* Hierarchical Classification by Expected Utility Maximization
#@ Korinna Bade;Eyke Hullermeier;Andreas Nurnberger
#t 2006
#c 18
#! Hierarchical classification refers to an extension of the standard classification problem, in which labels must be chosen from a class hierarchy. In this paper, we look at hierarchical classification from an information retrieval point of view. More specifically, we consider a scenario in which a user searches a document in a topic hierarchy. This scenario gives rise to the problem of predicting an optimal entry point, that is, a topic node in which the user starts searching. The usefulness of a corresponding prediction strongly depends on the search behavior of the user, which becomes relevant if the document is not immediately found in the predicted node. Typically, users tend to browse the hierarchy in a top-down manner, i.e., they look at a few more specific subcategories but usually refuse exploring completely different branches of the search tree. From a classification point of view, this means that a prediction should be evaluated, not solely on the basis of its correctness, but rather by judging its usefulness against the background of the user behavior. The idea of this paper is to formalize hierarchical classification within a decision-theoretic framework which allows for modeling this usefulness in terms of a user-specific utility function. The prediction problem thus becomes a problem of expected utility maximization. Apart from its theoretical appeal, we provide first empirical results showing that the approach performs well in practice.

#index 915231
#* COALA: A Novel Approach for the Extraction of an Alternate Clustering of High Quality and High Dissimilarity
#@ Eric Bae;James Bailey
#t 2006
#c 18
#! Cluster analysis has long been a fundamental task in data mining and machine learning. However, traditional clustering methods concentrate on producing a single solution, even though multiple alternative clusterings may exist. It is thus difficult for the user to validate whether the given solution is in fact appropriate, particularly for large and complex datasets. In this paper we explore the critical requirements for systematically finding a new clustering, given that an already known clustering is available and we also propose a novel algorithm, COALA, to discover this new clustering. Our approach is driven by two important factors; dissimilarity and quality. These are especially important for finding a new clustering which is highly informative about the underlying structure of data, but is at the same time distinctively different from the provided clustering. We undertake an experimental analysis and show that our method is able to outperform existing techniques, for both synthetic and real datasets.

#index 915232
#* Cluster Ranking with an Application to Mining Mailbox Networks
#@ Ziv Bar-Yossef;Ido Guy;Ronny Lempel;Yoelle S. Maarek;Vladimir Soroka
#t 2006
#c 18
#! We initiate the study of a new clustering framework, called cluster ranking. Rather than simply partitioning a network into clusters, a cluster ranking algorithm also orders the clusters by their strength. To this end, we introduce a novel strength measure for clusters--the integrated cohesion--which is applicable to arbitrary weighted networks. We then present C-Rank: a new cluster ranking algorithm. Given a network with arbitrary pairwise similarity weights, C-Rank creates a list of overlapping clusters and ranks them by their integrated cohesion. We provide extensive theoretical and empirical analysis of C-Rank and show that it is likely to have high precision and recall. Our experiments focus on mining mailbox networks. A mailbox network is an egocentric social network, consisting of contacts with whom an individual exchanges email. Ties among contacts are represented by the frequency of their co-occurrence on message headers. C-Rank is well suited to mine such networks, since they are abundant with overlapping communities of highly variable strengths. We demonstrate the effectiveness of C-Rank on the Enron data set, consisting of 130 mailbox networks.

#index 915233
#* Large Scale Detection of Irregularities in Accounting Data
#@ Stephen Bay;Krishna Kumaraswamy;Markus G. Anderle;Rohit Kumar;David M. Steier
#t 2006
#c 18
#! In recent years, there have been several large accounting frauds where a company's financial results have been intentionally misrepresented by billions of dollars. In response, regulatory bodies have mandated that auditors perform analytics on detailed financial data with the intent of discovering such misstatements. For a large auditing firm, this may mean analyzing millions of records from thousands of clients. This paper proposes techniques for automatic analysis of company general ledgers on such a large scale, identifying irregularities - which may indicate fraud or just honest errors - for additional review by auditors. These techniques have been implemented in a prototype system, called Sherlock, which combines aspects of both outlier detection and classification. In developing Sherlock, we faced three major challenges: developing an efficient process for obtaining data from many heterogeneous sources, training classifiers with only positive and unlabeled examples, and presenting information to auditors in an easily interpretable manner. In this paper, we describe how we addressed these challenges over the past two years and report on experiments evaluating Sherlock.

#index 915234
#* A Feature Selection and Evaluation Scheme for Computer Virus Detection
#@ Olivier Henchiri;Nathalie Japkowicz
#t 2006
#c 18
#! Anti-virus systems traditionally use signatures to detect malicious executables, but signatures are over-fitted features that are of little use in machine learning. Other more heuristic methods seek to utilize more general features, with some degree of success. In this paper, we present a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. We also evaluate the predictive power of a classifier by taking into account dependence relationships that exist between viruses, and we show that our classifier yields high detection rates and can be expected to perform as well in real-world conditions.

#index 915235
#* Cluster Analysis of Time-Series Medical Data Based on the Trajectory Representation and Multiscale Comparison Techniques
#@ Shoji Hirano;Shusaku Tsumoto
#t 2006
#c 18
#! This paper presents a cluster analysis method for multi-dimensional time-series data on clinical laboratory examinatios. Our method represents the time series of test results as trajectories in multidimensional space, and compares their structural similarity by using the multiscale comparison technique. It enables us to find the part-to-part correspondences between two trajectories, taking into account the relationships between different tests. The resultant dissimilarity can be further used with clustering algorithms for finding the groups of similar cases. The method was applied to the cluster analysis of Albumin-Platelet data in the chronic hepatitis dataset. The results denonstrated that it could form interesting groups of cases that have high correspondence to the fibrotic stages.

#index 915236
#* Constructing Ensembles for Better Ranking
#@ Jin Huang;Charles X. Ling
#t 2006
#c 18
#! We propose a novel algorithm, RankDE, to build an ensemble using an extra artificial dataset. RankDE aims at improving the overall ranking performance, which is crucial in many machine learning applications. This algorithm constructs artificial datasets that are diverse with the current training dataset in terms of ranking. We conduct experiments with real-world data sets to compare RankDE with some traditional and state-of-the-art ensembling algorithms of Bagging, Adaboost, DECORATE and Rankboost in terms of ranking. The experiments showthat RankDEoutperforms Bagging, DECORATE, Adaboost, and Rankboost when limited data is available. When enough training data is available, it is competitive with DECORATE and Adaboost

#index 915237
#* TRIAS--An Algorithm for Mining Iceberg Tri-Lattices
#@ Robert Jaschke;Andreas Hotho;Christoph Schmitz;Bernhard Ganter;Gerd Stumme
#t 2006
#c 18
#! In this paper, we present the foundations for mining frequent tri-concepts, which extend the notion of closed itemsets to three-dimensional data to allow for mining folk-sonomies. We provide a formal definition of the problem, and present an efficient algorithm for its solution as well as experimental results on a large real-world example.

#index 915238
#* Intelligent Icons: Integrating Lite-Weight Data Mining and Visualization into GUI Operating Systems
#@ Eamonn Keogh;Li Wei;Xiaopeng Xi;Stefano Lonardi;Jin Shieh;Scott Sirowy
#t 2006
#c 18
#! The vast majority of visualization tools introduced so far are specialized pieces of software that run explicitly on a particular dataset at a particular time for a particular purpose. In this work we introduce a novel framework for allowing visualization to take place in the background of normal day-to-day operation of any GUI based operation system. Our system works by replacing the standard file icons with automatically created icons that reflect the contents of the files in a principled way. We call such icons INTELLIGENT ICONS. The utility of Intelligent Icons is further enhanced by arranging them in a way that reflects their similarity/differences. We demonstrate the utility of our approach on diverse applications.

#index 915239
#* COSMIC: Conceptually Specified Multi-Instance Clusters
#@ Hans-Peter Kriegel;Alexey Pryakhin;Matthias Schubert;Arthur Zimek
#t 2006
#c 18
#! Recently, more and more applications represent data objects as sets of feature vectors or multi-instance objects. In this paper, we propose COSMIC, a method for deriving concept lattices from multi-instance data based on hierarchical density-based clustering. The found concepts correspond to groups or clusters of multi-instance objects having similar instances in common. We demonstrate that COSMIC outperforms compared methods with respect to efficiency and cluster quality and is capable to extract interesting patterns in multi-instance data sets.

#index 915240
#* Direct Marketing When There Are Voluntary Buyers
#@ Yi-Ting Lai;Ke Wang;Daymond Ling;Hua Shi;Jason Zhang
#t 2006
#c 18
#! In traditional direct marketing, the implicit assumption is that customers will only purchase the product if they are contacted. In real business environments, however, there are "voluntary buyers," who will still make the purchase in the absence of a contact. While no direct promotion is needed for voluntary buyers, the traditional response-driven paradigm tends to target such customers. This paper presents "influential marketing," targeting only those whose purchase decisions can be positively influenced, i.e. buyers who are non-voluntary. Our novel, practical solution to this problem gives promising results.

#index 915241
#* DSTree: A Tree Structure for the Mining of Frequent Sets from Data Streams
#@ Carson Kai-Sang Leung;Quamrul I. Khan
#t 2006
#c 18
#! With advances in technology, a flood of data can be produced in many applications such as sensor networks and Web click streams. This calls for efficient techniques for extracting useful information from streams of data. In this paper, we propose a novel tree structure, called DSTree (Data Stream Tree), that captures important data from the streams. By exploiting its nice properties, the DSTree can be easily maintained andmined for frequent itemsets as well as various other patterns like constrained itemsets.

#index 915242
#* Adaptive Blocking: Learning to Scale Up Record Linkage
#@ Mikhail Bilenko;Beena Kamath;Raymond J. Mooney
#t 2006
#c 18
#! Many data mining tasks require computing similarity between pairs of objects. Pairwise similarity computations are particularly important in record linkage systems, as well as in clustering and schema mapping algorithms. Because the number of object pairs grows quadratically with the size of the dataset, computing similarity between all pairs is impractical and becomes prohibitive for large datasets and complex similarity functions. Blocking methods alleviate this problem by efficiently selecting approximately similar object pairs for subsequent distance computations, leaving out the remaining pairs as dissimilar. Previously proposed blocking methods require manually constructing an index-based similarity function or selecting a set of predicates, followed by hand-tuning of parameters. In this paper, we introduce an adaptive framework for automatically learning blocking functions that are efficient and accurate. We describe two predicate-based formulations of learnable blocking functions and provide learning algorithms for training them. The effectiveness of the proposed techniques is demonstrated on real and simulated datasets, on which they prove to be more accurate than non-adaptive blocking methods.

#index 915243
#* Adaptive Parallel Graph Mining for CMP Architectures
#@ Gregory Buehrer;Srinivasan Parthasarathy;Yen-Kuang Chen
#t 2006
#c 18
#! Mining graph data is an increasingly popular challenge, which has practical applications in many areas, including molecular substructure discovery, web link analysis, fraud detection, and social network analysis. The problem statement is to enumerate all subgraphs occurring in at least \sigmagraphs of a database, where \sigmais a user specified parameter. Chip Multiprocessors (CMPs) provide true parallel processing, and are expected to become the de facto standard for commodity computing. In this work, building on the state-of-the-art, we propose an efficient approach to parallelize such algorithms for CMPs. We show that an algorithm which adapts its behavior based on the runtime state of the system can improve system utilization and lower execution times. Most notably, we incorporate dynamic state management to allow memory consumption to vary based on availability. We evaluate our techniques on current day shared memory systems (SMPs) and expect similar performance for CMPs. We demonstrate excellent speedup, 27- fold on 32 processors for several real world datasets. Additionally, we show our dynamic techniques afford this scalability while consuming up to 35% less memory than static techniques.

#index 915244
#* Meta Clustering
#@ Rich Caruana;Mohamed Elhawary;Nam Nguyen;Casey Smith
#t 2006
#c 18
#! Clustering is ill-defined. Unlike supervised learning where labels lead to crisp performance criteria such as accuracy and squared error, clustering quality depends on how the clusters will be used. Devising clustering criteria that capture what users need is difficult. Most clustering algorithms search for optimal clusterings based on a pre-specified clustering criterion. Our approach differs. We search for many alternate clusterings of the data, and then allow users to select the clustering(s) that best fit their needs. Meta clustering first finds a variety of clusterings and then clusters this diverse set of clusterings so that users must only examine a small number of qualitatively different clusterings. We present methods for automatically generating a diverse set of alternate clusterings, as well as methods for grouping clusterings into meta clusters. We evaluate meta clustering on four test problems and two case studies. Surprisingly, clusterings that would be of most interest to users often are not very compact clusterings.

#index 915245
#* Mixed-Drove Spatio-Temporal Co-occurence Pattern Mining: A Summary of Results
#@ Mete Celik;Shashi Shekhar;James P. Rogers;James A. Shine;Jin Soung Yoo
#t 2006
#c 18
#! Mixed-drove spatio-temporal co-occurrence patterns (MDCOPs) represent subsets of object-types that are located together in space and time. Discovering MDCOPs is an important problem with many applications such as identifying tactics in battlefields, games, and predator-prey interactions. However, mining MDCOPs is computationally very expensive because the interest measures are computationally complex, datasets are larger due to the archival history, and the set of candidate patterns is exponential in the number of object-types. We propose a monotonic composite interest measure for discovering MDCOPs and a novel MDCOP mining algorithm. Analytical and experimental results show that the proposed algorithm is correct and complete. Results also show the proposed method is computationally more efficient than naïve alternatives.

#index 915246
#* An Interactive Semantic Video Mining and Retrieval Platform--Application in Transportation Surveillance Video for Incident Detection
#@ Xin Chen;Chengcui Zhang
#t 2006
#c 18
#! Understanding and retrieving videos based on their semantic contents is an important research topic in multimedia data mining and has found various real-world applications. Most existing video analysis techniques focus on the low level visual features of video data. However, there is a "semantic gap" between the machine-readable features and the high level human concepts i.e. human understanding of the video content. In this paper, an interactive platform for semantic video mining and retrieval is proposed using Relevance Feedback (RF), a popular technique in the area of Content-based Image Retrieval (CBIR). By tracking semantic objects in a video and then modeling spatio-temporal events based on object trajectories and object interactions, the proposed interactive learning algorithm in the platform is able to mine the spatio-temporal data extracted from the video. An iterative learning process is involved in the proposed platform, which is guided by the user's response to the retrieved results. Although the proposed video retrieval platform is intended for general use and can be tailored to many applications, we focus on its application in traffic surveillance video database retrieval to demonstrate the design details. The effectiveness of the algorithm is demonstrated by our experiments on real-life traffic surveillance videos.

#index 915247
#* Searching for Pattern Rules
#@ Guichong Li;Howard J. Hamilton
#t 2006
#c 18
#! We address the problem of finding a set of pattern rules, from a transaction dataset given a statistical metric. A new data structure, called an incrementally counting suffix tree (ICST), is proposed for online computation of estimates of the support of any pattern or itemset. Using an ICST, our approach directly generates a set of pattern rules by a single scan of the whole dataset in partitions without the generation of frequent itemsets. Non-redundant rules can be found by removing redundancies from the pattern rules. The PPMCR algorithm first finds pattern rules and then non-redundant rules by generating valid candidates while traversing the ICST. Experimental results show that the PPMCR algorithm can be used for efficiently mining fewer non-redundant rules.

#index 915248
#* Adding Semantics to Email Clustering
#@ Hua Li;Dou Shen;Benyu Zhang;Zheng Chen;Qiang Yang
#t 2006
#c 18
#! This paper presents a novel algorithm to cluster emails according to their contents and the sentence styles of their subject lines. In our algorithm, natural language processing techniques and frequent itemset mining techniques are utilized to automatically generate meaningful generalized sentence patterns (GSPs) from subjects of emails. Then we put forward a novel unsupervised approach which treats GSPs as pseudo class labels and conduct email clustering in a supervised manner, although no human labeling is involved. Our proposed algorithm is not only expected to improve the clustering performance, it can also provide meaningful descriptions of the resulted clusters by the GSPs. Experimental results on open dataset (Enron email dataset) and a personal email dataset collected by ourselves demonstrate that the proposed algorithm outperforms the K-means algorithm in terms of the popular measurement F1. Furthermore, the cluster naming readability is improved by 68.5% on the personal email dataset.

#index 915249
#* Gradual Cube: Customize Profile on Mobile OLAP
#@ Jun Li;Haofeng Zhou;Wei Wang
#t 2006
#c 18
#! OLAP is supported by more and more environment as a powerful analysis tool. With the rapid development of mobile and wireless technologies, users wish to enjoy the OLAP service on these devices. However, there are many issues on mobile OLAP against the traditional ones, e.g. the transmission bottleneck, unstable network connection, etc. Moreover, the mobile device owners have raised increasing requirements to customize the service such as transmitting the data on demand or ASAP to support their activities. All these challenges provide new chances for OLAP. In this paper, a new mechanism Gradual Cube is proposed to face such challenges. It can reduce the transmission data size, provide customized transmission strategy and enable users to conduct off-line browsing. We assume the users' precision requirement follows some distribution so that three methods, namely random, optimal and heuristic, are developed to customize the transmission plan. The experiments show that such methods are both effective and efficient.

#index 915250
#* CoMiner: An Effective Algorithm for Mining Competitors from the Web
#@ Rui Li;Shenghua Bao;Jin Wang;Yong Yu;Yunbo Cao
#t 2006
#c 18
#! This paper attempts to accomplish a novel task of mining competitive information with respect to an entity (such as a company, product, person) from the web. An algorithm called "CoMiner" is proposed, which first extracts a set of comparative candidates of the input entity and then ranks them according to the comparability, and finally extracts the competitive fields. The experimental results show that the proposed algorithm drafts a complete picture of competitive relation of a given entity effectively.

#index 915251
#* Multi-Tier Granule Mining for Representations of Multidimensional Association Rules
#@ Yuefeng Li;Wanzhong Yang;Yue Xu
#t 2006
#c 18
#! It is a big challenge to promise the quality of multidimensional association mining. The essential issue is how to represent meaningful multidimensional association rules efficiently. Currently we have not found satisfactory approaches for solving this challenge because of the complicated correlation between attributes. Multi-tier granule mining is an initiative for solving this challenging issue. It divides attributes into some tiers and then compresses the large multidimensional database into granules at each tier. It also builds association mappings to illustrate the correlation between tiers. In this way, the meaningful association rules can be justified according to these association mappings.

#index 915252
#* Social Capital in Friendship-Event Networks
#@ Louis Licamele;Lise Getoor
#t 2006
#c 18
#! In this paper, we examine a particular form of social network which we call a friendship-event network. A friendship-event network captures both the friendship relationship among a set of actors, and also the organizer and participation relationships of actors in a series of events. Within these networks, we formulate the notion of social capital based on the actor-organizer friendship relationship and the notion of benefit, based on event participation. We investigate appropriate definitions for the social capital of both a single actor and a collection of actors. We ground these definitions in a real-world example of academic collaboration networks, where the actors are researchers, the friendships are collaborations, the events are conferences, the organizers are program committee members and the participants are conference authors. We show that our definitions of capital and benefit capture interesting qualitative properties of event series. In addition, we show that social capital is a better publication predictor than publication history.

#index 915253
#* Exploratory Under-Sampling for Class-Imbalance Learning
#@ Xu-Ying Liu;Jianxin Wu;Zhi-Hua Zhou
#t 2006
#c 18
#! Under-sampling is a class-imbalance learning method which uses only a subset of major class examples and thus is very efficient. The main deficiency is that many major class examples are ignored. We propose two algorithms to overcome the deficiency. EasyEnsemble samples several subsets from the major class, trains a learner using each of them, and combines the outputs of those learners. BalanceCascade is similar to EasyEnsemble except that it removes correctly classified major class examples of trained learners from further consideration. Experiments show that both of the proposed algorithms have better AUC scores than many existing class-imbalance learning methods. Moreover, they have approximately the same training time as that of under-sampling, which trains significantly faster than other methods.

#index 915254
#* \delta-Tolerance Closed Frequent Itemsets
#@ James Cheng;Yiping Ke;Wilfred Ng
#t 2006
#c 18
#! In this paper, we study an inherent problem of mining Frequent Itemsets (FIs): the number of FIs mined is often too large. The large number of FIs not only affects the mining performance, but also severely thwarts the application of FI mining. In the literature, Closed FIs (CFIs) and Maximal FIs (MFIs) are proposed as concise representations of FIs. However, the number of CFIs is still too large in many cases, while MFIs lose information about the frequency of the FIs. To address this problem, we relax the restrictive definition of CFIs and propose the \delta-Tolerance CFIs (\delta- TCFIs). Mining \delta-TCFIs recursively removes all subsets of a \delta-TCFI that fall within a frequency distance bounded by \delta. We propose two algorithms, CFI2TCFI and MineTCFI, to mine \delta-TCFIs. CFI2TCFI achieves very high accuracy on the estimated frequency of the recovered FIs but is less efficient when the number of CFIs is large, since it is based on CFI mining. MineTCFI is significantly faster and consumes less memory than the algorithms of the state-of-the-art concise representations of FIs, while the accuracy of MineTCFI is only slightly lower than that of CFI2TCFI.

#index 915255
#* Active Learning to Maximize Area Under the ROC Curve
#@ Matt Culver;Deng Kun;Stephen Scott
#t 2006
#c 18
#! In active learning, a machine learning algorithmis given an unlabeled set of examples U, and is allowed to request labels for a relatively small subset of U to use for training. The goal is then to judiciously choose which examples in U to have labeled in order to optimize some performance criterion, e.g. classification accuracy. We study how active learning affects AUC. We examine two existing algorithms from the literature and present our own active learning algorithms designed to maximize the AUC of the hypothesis. One of our algorithms was consistently the top performer, and Closest Sampling from the literature often came in second behind it. When good posterior probability estimates were available, our heuristics were by far the best.

#index 915256
#* Rapid Identification of Column Heterogeneity
#@ Bing Tian Dai;Nick Koudas;Beng Chin Ooi;Divesh Srivastava;Suresh Venkatasubramanian
#t 2006
#c 18
#! Data quality is a serious concern in every data management application, and a variety of quality measures have been proposed, e.g., accuracy, freshness and completeness, to capture common sources of data quality degradation. We identify and focus attention on a novel measure, column heterogeneity, that seeks to quantify the data quality problems that can arise when merging data from different sources. We identify desiderata that a column heterogeneity measure should intuitively satisfy, and describe our technique to quantify database column heterogeneity based on using a novel combination of cluster entropy and soft clustering. Finally, we present detailed experimental results, using diverse data sets of different types, to demonstrate that our approach provides a robust mechanism for identifying and quantifying database column heterogeneity.

#index 915257
#* Data Mining Approaches to Criminal Career Analysis
#@ Jeroen S.  de Bruin;Tim K. Cocx;Walter A. Kosters;Jeroen F.  J. Laros;Joost N. Kok
#t 2006
#c 18
#! Narrative reports and criminal records are stored digitally across individual police departments, enabling the collection of this data to compile a nation-wide database of criminals and the crimes they committed. The compilation of this data through the last years presents new possibilities of analyzing criminal activity through time. Augmenting the traditional, more socially oriented, approach of behavioral study of these criminals and traditional statistics, data mining methods like clustering and prediction enable police forces to get a clearer picture of criminal careers. This allows officers to recognize crucial spots in changing criminal behaviour and deploy resources to prevent these careers from unfolding. Four important factors play a role in the analysis of criminal careers: crime nature, frequency, duration and severity. We describe a tool that extracts these from the database and creates digital profiles for all offenders. It compares all individuals on these profiles by a new distance measure and clusters them accordingly. This method yields a visual clustering of these criminal careers and enables the identification of classes of criminals. The proposed method allows for several user-defined parameters.

#index 915258
#* Biclustering Protein Complex Interactions with a Biclique Finding Algorithm
#@ Chris Ding;Ya Zhang;Tao Li;Stephen R. Holbrook
#t 2006
#c 18
#! Biclustering has many applications in text mining, web clickstream mining, and bioinformatics. When data entries are binary, the tightest biclusters become bicliques. We propose a flexible and highly efficient algorithm to compute bicliques. We first generalize the Motzkin-Straus formalism for computing the maximal clique from L_1 constraint to L_p constraint, which enables us to provide a generalized Motzkin-Straus formalism for computing maximal-edge bicliques. By adjusting parameters, the algorithm can favor biclusters with more rows less columns, or vice verse, thus increasing the flexibility of the targeted biclusters. We then propose an algorithmto solve the generalized Motzkin- Straus optimization problem. The algorithm is provably convergent and has a computational complexity of O(|E|) where |E| is the number of edges. Using this algorithm, we bicluster the yeast protein complex interaction network. We find that biclustering protein complexes at the protein level does not clearly reflect the functional linkage among protein complexes in many cases, while biclustering at protein domain level can reveal many underlying linkages. We show several new biologically significant results.

#index 915259
#* Turning Clusters into Patterns: Rectangle-Based Discriminative Data Description
#@ Byron J. Gao;Martin Ester
#t 2006
#c 18
#! The ultimate goal of data mining is to extract knowledge from massive data. Knowledge is ideally represented as human-comprehensible patterns from which end-users can gain intuitions and insights. Yet not all data mining methods produce such readily understandable knowledge, e.g., most clustering algorithms output sets of points as clusters. In this paper, we perform a systematic study of cluster description that generates interpretable patterns from clusters. We introduce and analyze novel description formats leading to more expressive power, motivate and define novel description problems specifying different trade-offs between interpretability and accuracy. We also present effective heuristic algorithms together with their empirical evaluations.

#index 915260
#* The Influence of Class Imbalance on Cost-Sensitive Learning: An Empirical Study
#@ Xu-Ying Liu;Zhi-Hua Zhou
#t 2006
#c 18
#! In real-world applications the number of examples in one class may overwhelm the other class, but the primary interest is usually on the minor class. Cost-sensitive learning has been deeded as a good solution to these class-imbalanced tasks, yet it is not clear how does the class-imbalance affect cost-sensitive classifiers. This paper presents an empirical study using 38 data sets, which discloses that class-imbalance often affects the performance of cost-sensitive classifiers: When the misclassification costs are not seriously unequal, cost-sensitive classifiers generally favor natural class distribution although it might be imbalanced; while when misclassification costs are seriously unequal, a balanced class distribution is more favorable.

#index 915261
#* Similarity of Temporal Query Logs Based on ARIMA Model
#@ Ning Liu;Shuzhen Nong;Jun Yan;Benyu Zhang;Zheng Chen;Ying Li
#t 2006
#c 18
#! A challenging issue faced by modern information retrieval is that of determining and satisfying users' requirements relying only on very short text queries. In this paper, we propose an algorithm to find out related queries based on Auto-Regressive Integrated Moving Average (ARIMA) Model. First, we select and estimate ARIMA model of the temporal query logs. And then each query is denoted by a sequence of coefficients. We use the correlation of ARIMA coefficients as the similarity measurement. We call it as the ARIMA Temporal Similarity (ARIMA TS). This similarity describes how strongly two time series are linearly related. On the other hand, the ARIMA model could also be treated as a dimensionality reduction procedure. It can save storage space for a large database of the query logs. In addition, ARIMA model could be used as a tool to predict the trend of a query. The experimental results on two query logs of MSN search engine 1 demonstrate that the proposed approach can achieve better similarity measurement efficiently.

#index 915262
#* Probabilistic Segmentation and Analysis of Horizontal Cells
#@ Vebjorn Ljosa;Ambuj K. Singh
#t 2006
#c 18
#! Because images of neurons show interweaved processes from multiple cells, it is hard to determine which pixels belong to each cell, and consequently to analyze the images automatically. To manage these difficulties, we introduce probabilistic segmentation, in which each pixel is assigned a probability of belonging to each cell instead of being categorically assigned to one cell. We propose a randomized algorithm for probabilistic segmentation. The algorithm is based on repeated, intensity-weighted random walks on the image, and leads to improved segmentation quality. Analysis and mining techniques can utilize the more nuanced and complete information that the probabilistic segmentation yields about an image. Such techniques can then compute probabilistic values, which indicate the level of confidence that can be placed in them.

#index 915263
#* Mining Correlation between Motifs and Gene Expression
#@ Yi Lu;Shiyong Lu;Adrian E. Platts;Stephen A. Krawetz
#t 2006
#c 18
#! One of the major challenges in the post-genomic era is to determine all DNA-binding transcription factors (TFs) and their regulatory binding sites (motifs) within the genomes. To discover the relationship between the motifs and changes in gene expression, we propose a new algorithm, Co-Miner (Correlation Miner). Correlation rules are generated based on the expression profiles of genes with significant expression change through the time course of gene expression. Thus, we may consider the change in gene expression to be causatively associated with the transcription binding sites in the upstream sequences. In addition, we introduce partition and constraint pushing techniques to improve the performance and demonstrate their effectiveness by our experiments. By applying Co-Miner to a yeast dataset, the relationships between motifs and gene expression revealed by Co-Miner are confirmed in the literature.

#index 915264
#* High Quality, Efficient Hierarchical Document Clustering Using Closed Interesting Itemsets
#@ Hassan H. Malik;John R. Kender
#t 2006
#c 18
#! High dimensionality remains a significant challenge for document clustering. Recent approaches used frequent itemsets and closed frequent itemsets to reduce dimensionality, and to improve the efficiency of hierarchical document clustering. In this paper, we introduce the notion of "closed interesting" itemsets (i.e. closed itemsets with high interestingness). We provide heuristics such as "super item" to efficiently mine these itemsets and show that they provide significant dimensionality reduction over closed frequent itemsets. Using "closed interesting" itemsets, we propose a new, sub-linearly scalable, hierarchical document clustering method that outperforms state of the art agglomerative, partitioning and frequent-itemset based methods both in terms of clustering quality and runtime performance, without requiring dataset specific parameter tuning. We evaluate twenty interestingness measures and show that when used to generate "closed interesting" itemsets, and to select parent nodes, Mutual Information, Added Value, Yule's Q and Chi- Square offer best clustering performance.

#index 915265
#* On Trajectory Representation for Scientific Features
#@ Sameep Mehta;Srinivasan Parthasarathy;Raghu Machiraju
#t 2006
#c 18
#! In this article, we present trajectory representation algorithms for tangible features found in temporally varying scientific datasets. Rather than modeling the features as points, we take attributes like shape and extent of the feature into account. Our contention is that these attributes play an important role in understanding the temporal evolution and interactions among features. The proposed representation scheme is based on motion and shape parameters including linear velocity, angular velocity, etc. We use these parameters to segment the trajectory instead of relying on the geometry of the trajectory. We evaluate our algorithms on real datasets originating from different domains. We show the accuracy of the motion and shape parameter estimation by reconstructing the trajectories with high accuracy. Finally, we present performance and scalability results.

#index 915266
#* STAGGER: Periodicity Mining of Data Streams Using Expanding Sliding Windows
#@ Mohamed G. Elfeky;Walid G. Aref;Ahmed K. Elmagarmid
#t 2006
#c 18
#! Sensor devices are becoming ubiquitous, especially in measurement and monitoring applications. Because of the real-time, append-only and semi-infinite natures of the generated sensor data streams, an online incremental approach is a necessity for mining stream data types. In this paper, we propose STAGGER: a one-pass, online and incremental algorithm for mining periodic patterns in data streams. STAGGER does not require that the user pre-specify the periodicity rate of the data. Instead, STAGGER discovers the potential periodicity rates. STAGGER maintains multiple expanding sliding windows staggered over the stream, where computations are shared among the multiple overlapping windows. Small-length sliding windows are imperative for early and real-time output, yet are limited to discover short periodicity rates. As streamed data arrives continuously, the sliding windows expand in length in order to cover the whole stream. Larger-length sliding windows are able to discover longer periodicity rates. STAGGER incrementally maintains a tree-like data structure for the frequent periodic patterns of each discovered potential periodicity rate. In contrast to the Fourier/Wavelet-based approaches used for discovering periodicity rates, STAGGER not only discovers a wider, more accurate set of periodicities, but also discovers the periodic patterns themselves. In fact, experimental results with real and synthetic data sets show that STAGGER outperforms Fourier/Wavelet-based approaches by an order of magnitude in terms of the accuracy of the discovered periodicity rates. Moreover, realdata experiments demonstrate the practicality of the discovered periodic patterns.

#index 915267
#* Converting Output Scores from Outlier Detection Algorithms into Probability Estimates
#@ Jing Gao;Pang-Ning Tan
#t 2006
#c 18
#! Current outlier detection schemes typically output a numeric score representing the degree to which a given observation is an outlier. We argue that converting the scores into well-calibrated probability estimates is more favorable for several reasons. First, the probability estimates allow us to select the appropriate threshold for declaring outliers using a Bayesian risk model. Second, the probability estimates obtained from individual models can be aggregated to build an ensemble outlier detection framework. In this paper, we present two methods for transforming outlier scores into probabilities. The first approach assumes that the posterior probabilities follow a logistic sigmoid function and learns the parameters of the function from the distribution of outlier scores. The second approach models the score distributions as a mixture of exponential and Gaussian probability functions and calculates the posterior probabilites via the Bayes' rule. We evaluated the efficacy of both methods in the context of threshold selection and ensemble outlier detection. We also show that the calibration accuracy improves with the aid of some labeled examples.

#index 915268
#* Personalization in Context: Does Context Matter When Building Personalized Customer Models?
#@ M. Gorgoglione;C. Palmisano;A. Tuzhilin
#t 2006
#c 18
#! The idea that context is important when predicting customer behavior has been maintained by scholars in marketing and data mining. However, no systematic study measuring how much the contextual information really matters in building customer models in personalization applications have been done before. In this paper, we address this problem. To this aim, we collected data containing rich contextual information by developing a special-purpose browser to help users to navigate a well-known e-commerce retail portal and purchase products on its site. The experimental results show that context does matter for the case of modeling behavior of individual customers. The granularity of contextual information also matters, and the effect of contextual information gets diluted during the process of aggregating customers' data.

#index 915269
#* Bregman Bubble Clustering: A Robust, Scalable Framework for Locating Multiple, Dense Regions in Data
#@ Gunjan Gupta;Joydeep Ghosh
#t 2006
#c 18
#! In traditional clustering, every data point is assigned to at least one cluster. On the other extreme, One Class Clustering algorithms proposed recently identify a single dense cluster and consider the rest of the data as irrelevant. However, in many problems, the relevant data forms multiple natural clusters. In this paper, we introduce the notion of Bregman bubbles and propose Bregman Bubble Clustering (BBC) that seeks k dense Bregman bubbles in the data. We also present a corresponding generative model, Soft BBC, and show several connections with Bregman Clustering, and with a One Class Clustering algorithm. Empirical results on various datasets show the effectiveness of our method.

#index 915270
#* Optimal Segmentation Using Tree Models
#@ Robert Gwadera;Aristides Gionis;Heikki Mannila
#t 2006
#c 18
#! Sequence data are abundant in application areas such as computational biology, environmental sciences, and telecommunication. Many real-life sequences have a strong segmental structure, with segments of different complexities. In this paper we study the description of sequence segments using variable length Markov chains (VLMCs), also known as tree models. We discover the segment boundaries of a sequence and at the same time we obtain a VLMC for each segment. Such a context tree contains the probability distribution vectors that capture the essential features of the corresponding segment. We use the Bayesian Information Criterion (BIC) and the Krichevsky-Trofimov Probability (KT) to select the number of segments of a sequence. On DNA data the method selects segments that closely correspond to the annotated regions of the genes.

#index 915271
#* Mining for Tree-Query Associations in a Graph
#@ Eveline Hoekx;Jan Van den Bussche
#t 2006
#c 18
#! New applications of data mining, such as in biology, bioinformatics, or sociology, are faced with large datasets structured as graphs. We present an efficient algorithm for mining associations between tree queries in a large graph. Tree queries are powerful tree-shaped patterns featuring existential variables and data constants. Our algorithm applies the theory of conjunctive database queries to make the generation of association rules efficient. We propose a practical, database-oriented implementation in SQL, and show that the approach works in practice through experiments on data about food webs, protein interactions, and citation analysis.

#index 915272
#* NewsCATS: A News Categorization and Trading System
#@ Marc-Andre Mittermayer;Gerhard F. Knolmayer
#t 2006
#c 18
#! NewsCATS is an Automated Text Categorization (ATC) prototype using a hand-made thesaurus to forecast intraday stock price trends from information contained in press releases. Due to a unique labeling approach and by carefully selecting the appropriate training data News- CATS achieves a performance which is clearly superior to other ATC prototypes used for stock price trend forecasting. In this paper we describe the architecture, training, and testing of NewsCATS as well as the results of an extensive robustness analysis.

#index 915273
#* Improving Grouped-Entity Resolution Using Quasi-Cliques
#@ Byung-Won On;Ergin Elmacioglu;Dongwon Lee;Jaewoo Kang;Jian Pei
#t 2006
#c 18
#! The entity resolution (ER) problem, which identifies duplicate entities that refer to the same real world entity, is essential in many applications. In this paper, in particular, we focus on resolving entities that contain a group of related elements in them (e.g., an author entity with a list of citations, a singer entity with song list, or an intermediate result by GROUP BY SQL query). Such entities, named as grouped-entities, frequently occur in many applications. The previous approaches toward grouped-entity resolution often rely on textual similarity, and produce a large number of false positives. As a complementing technique, in this paper, we present our experience of applying a recently proposed graph mining technique, Quasi-Clique, atop conventional ER solutions. Our approach exploits contextual information mined from the group of elements per entity in addition to syntactic similarity. Extensive experiments verify that our proposal improves precision and recall up to 83% when used together with a variety of existing ER solutions, but never worsens them.

#index 915274
#* Fast Relevance Discovery in Time Series
#@ Chang-shing Perng;Haixun Wang;Sheng Ma
#t 2006
#c 18
#! In this paper, we propose to model time series from a new angle: state transition points. When fluctuation of values in a time series crosses a certain point, it may trigger state transition in the system, which may lead to abrupt changes in many other time series. The concept of state transition points is essential in understanding the behavior of the time series and the behavior of the system. The new measure is robust and is capable of discovering correlations that Pearson's coefficient cannot reveal. We propose efficient algorithms to identify state transition points and to compute correlation between two time series. We also introduce some triangular inequalities to efficiently find highly correlated time series among many time series.

#index 915275
#* Probabilistic Enhanced Mapping with the Generative Tabular Model
#@ Rodolphe Priam;Mohamed Nadif
#t 2006
#c 18
#! Visualization of the massive datasets needs new methods which are able to quickly and easily reveal their contents. The projection of the data cloud is an interesting paradigm in spite of its difficulty to be explored when data plots are too numerous. So we study a new way to show a bi-dimensional projection from a multidimensional data cloud: our generative model constructs a tabular view of the projected cloud. We are able to show the high densities areas by their non equidistributed discretization. This approach is an alternative to the self-organizing map when a projection does already exist. The resulting pixel views of a dataset are illustrated by projecting a data sample of real images: it becomes possible to observe how are laid out the class labels or the frequencies of a group of modalities without being lost because of a zoom enlarging change for instance. The conclusion gives perspectives to this original promising point of view to get a readable projection for a statistical data analysis of large data samples.

#index 915276
#* Object Identification with Constraints
#@ Steffen Rendle;Lars Schmidt-Thieme
#t 2006
#c 18
#! Object identification aims at identifying different representations of the same object based on noisy attributes such as descriptions of the same product in different online shops or references to the same paper in different publications. Numerous solutions have been proposed for solving this task, almost all of them based on similarity functions of a pair of objects. Although today the similarity functions are learned from a set of labeled training data, the structural information given by the labeled data is not used. By formulating a generic model for object identification we show how almost any proposed identification model can easily be extended for satisfying structural constraints. Therefore we propose a model that uses structural information given as pairwise constraints to guide collective decisions about object identification in addition to a learned similarity measure. We show with empirical experiments on public and on real-life data that combining both structural information and attribute-based similarity enormously increases the overall performance for object identification tasks.

#index 915277
#* High-Performance Unsupervised Relation Extraction from Large Corpora
#@ Binjamin Rozenfeld;Ronen Feldman
#t 2006
#c 18
#! We present URIES -- an Unsupervised Relation Identification and Extraction system. The system automatically identifies interesting binary relations between entities in the input corpus, and then proceeds to extract a large number of instances of these relations. The system discovers relations by clustering frequently co-occuring pairs of entities, based on the contexts in which they appear. Its complex pattern-based representation of the contexts allows the clustering step to achieve very high precision, sufficient for the clusters to perform as sets of seeds for bootstrapping a high-recall relation extraction process. In a series of experiments we demonstrate the successful performance of URIES and compare it to the two existing systems -- a weakly supervised high-recall Web relation extraction system called SRES, and an unsupervised relation identification system that uses a simpler bag-of-words representation of contexts. The experiments show that URIES performs comparably to SRES, but without any supervision, and that such performance is due to the power of its complex contexts representation and to its novel candidate selection method.

#index 915278
#* Global and Componentwise Extrapolation for Accelerating Data Mining from Large Incomplete Data Sets with the EM Algorithm
#@ Chun-Nan Hsu;Han-Shen Huang;Bo-Hou Yang
#t 2006
#c 18
#! The Expectation-Maximization (EM) algorithm is one of the most popular algorithms for data mining from incomplete data. However, when applied to large data sets with a large proportion of missing data, the EM algorithm may converge slowly. The triple jump extrapolation method can effectively accelerate the EM algorithm by substantially reducing the number of iterations required for EM to converge. There are two options for the triple jump method, global extrapolation (TJEM) and componentwise extrapolation (CTJEM). We tried these two methods for a variety of probabilistic models and found that in general, global extraplolation yields a better performance, but there are cases where componentwise extrapolation yields very high speedup. In this paper, we investigate when componentwise extrapolation should be preferred. We conclude that, when the Jacobian of the EM mapping is diagonal or block diagonal, CTJEM should be preferred. We show how to determine whether a Jacobian is diagonal or block diagonal and experimentally confirm our claim. In particular, we show that CTJEM is especially effective for the semi-supervised Bayesian classifier model given a highly sparse data set.

#index 915279
#* Keyphrase Extraction Using Semantic Networks Structure Analysis
#@ Chong Huang;Yonghong Tian;Zhi Zhou;Charles X. Ling;Tiejun Huang
#t 2006
#c 18
#! Keyphrases play a key role in text indexing, summarization and categorization. However, most of the existing keyphrase extraction approaches require human-labeled training sets. In this paper, we propose an automatic keyphrase extraction algorithm, which can be used in both supervised and unsupervised tasks. This algorithm treats each document as a semantic network. Structural dynamics of the network are used to extract keyphrases (key nodes) unsupervised. Experiments demonstrate the proposed algorithm averagely improves 50% in effectiveness and 30% in efficiency in unsupervised tasks and performs comparatively with supervised extractors. Moreover, by applying this algorithm to supervised tasks, we develop a classifier with an overall accuracy up to 80%.

#index 915280
#* Subjectivity Categorization of Weblog with Part-of-Speech Based Smoothing
#@ Shen Huang;Jian-Tao Sun;Xuanhui Wang;Hua-Jun Zeng;Zheng Chen
#t 2006
#c 18
#! Experts from different domains try to mine users' comments on weblogs for different reasons such as politics or commerce. All these needs necessitate automatically distinguishing subjective weblog contents from objective ones, namely subjectivity categorization. Since weblogs contain various topics from different domains, limited training data can hardly cover all the topics and "unseen words" becomes a serious problem for categorization tasks. In this paper, Part-Of-Speech (POS) based smoothing is proposed to alleviate the "unseen words" problem. In conjunction with a naïve Bayes model constructed from limited training data, the probability of an unseen word in a new domain can be well smoothed by the probability of its POS result. Empirical studies on five datasets show that our approach consistently outperforms the basic naïve Bayes with Laplace smoothing. In a cross-domain experiment, our approach achieves 22.0% improvement in Macro F1 and 24.4% in Micro F1 over basic naïve Bayes. These verify that POS based smoothing can indeed benefit subjectivity categorization, especially in the cases with a large number of unseen words.

#index 915281
#* Applying Data Mining to Pseudo-Relevance Feedback for High Performance Text Retrieval
#@ Xiangji Huang;Yan Rui Huang;Miao Wen;Aijun An;Yang Liu;Josiah Poon
#t 2006
#c 18
#! In this paper, we investigate the use of data mining, in particular the text classification and co-training techniques, to identify more relevant passages based on a small set of labeled passages obtained from the blind feedback of a retrieval system. The data mining results are used to expand query terms and to re-estimate some of the parameters used in a probabilistic weighting function. We evaluate the data mining based feedback method on the TREC HARD data set. The results show that data mining can be successfully applied to improve the text retrieval performance. We report our experimental findings in detail.

#index 915282
#* Improving Personalization Solutions through Optimal Segmentation of Customer Bases
#@ Tianyi Jiang;Alexander Tuzhilin
#t 2006
#c 18
#! On the Web, where the search costs are low and the competition is just a mouse click away, it is crucial to segment the customers intelligently in order to offer more targeted and personalized products and services to them. Traditionally, customer segmentation is achieved using statistics-based methods that compute a set of statistics from the customer data and group customers into segments by applying distance-based clustering algorithms in the space of these statistics. In this paper, we present a direct grouping based approach to computing customer segments that groups customers not based on computed statistics, but in terms of optimally combining transactional data of several customers to build a data mining model of customer behavior for each group. Then building customer segments becomes a combinatorial optimization problem of finding the best partitioning of the customer base into disjoint groups. The paper shows that finding an optimal customer partition is NP-hard, proposes a suboptimal direct grouping segmentation method and empirically compares it against traditional statistics-based segmentation and 1-to-1 methods across multiple experimental conditions. We show that the direct grouping method significantly dominates the statistics-based and 1-to-1 approaches across all the experimental conditions, while still being computationally tractable. We also show that there are very few size-one customer segments generated by the best direct grouping method and that micro-segmentation provides the best approach to personalization.

#index 915283
#* Dimension Reduction for Supervised Ordering
#@ Toshihiro Kamishima;Shotaro Akaho
#t 2006
#c 18
#! Ordered lists of objects are widely used as representational forms. Such ordered objects include Web search results and best-seller lists. Techniques for processing such ordinal data are being developed, particularly methods for a supervised ordering task: i.e., learning functions used to sort objects from sample orders. In this article, we propose two dimension reduction methods specifically designed to improve prediction performance in a supervised ordering task.

#index 915284
#* Cluster Based Core Vector Machine
#@ Asharaf S;M. Narasimha Murty;S. K. Shevade
#t 2006
#c 18
#! Core Vector Machine(CVM) is suitable for efficient large-scale pattern classification. In this paper, a method for improving the performance of CVM with Gaussian kernel function irrespective of the orderings of patterns belonging to different classes within the data set is proposed. This method employs a selective sampling based training of CVM using a novel kernel based scalable hierarchical clustering algorithm. Empirical studies made on synthetic and real world data sets show that the proposed strategy performs well on large data sets.

#index 915285
#* Enhancing Text Clustering Using Concept-based Mining Model
#@ Shady Shehata;Fakhri Karray;Mohamed Kamel
#t 2006
#c 18
#! Most of text mining techniques are based on word and/or phrase analysis of the text. The statistical analysis of a term (word or phrase) frequency captures the importance of the term within a document. However, to achieve a more accurate analysis, the underlying mining technique should indicate terms that capture the semantics of the text from which the importance of a term in a sentence and in the document can be derived. A new concept-based mining model that relies on the analysis of both the sentence and the document, rather than, the traditional analysis of the document dataset only is introduced. The proposed mining model consists of a concept-based analysis of terms and a concept-based similarity measure. The term which contributes to the sentence semantics is analyzed with respect to its importance at the sentence and document levels. The model can efficiently find significant matching terms, either words or phrases, of the documents according to the semantics of the text. The similarity between documents relies on a new concept-based similarity measure which is applied to the matching terms between documents. Experiments using the proposed concept-based term analysis and similarity measure in text clustering are conducted. Experimental results demonstrate that the newly developed concept-based mining model enhances the clustering quality of sets of documents substantially.

#index 915286
#* Detecting Link Spam Using Temporal Information
#@ Guoyang Shen;Bin Gao;Tie-Yan Liu;Guang Feng;Shiji Song;Hang Li
#t 2006
#c 18
#! How to effectively protect against spam on search ranking results is an important issue for contemporary web search engines. This paper addresses the problem of combating one major type of web spam: 'link spam.' Most of the previous work on anti link spam managed to make use of one snapshot of web data to detect spam, and thus it did not take advantage of the fact that link spam tends to result in drastic changes of links in a short time period. To overcome the shortcoming, this paper proposes using temporal information on links in detection of link spam, as well as other information. Specifically, it defines temporal features such as In-link Growth Rate (IGR) and In-link Death Rate (IDR) in a spam classification model (i.e., SVM). Experimental results on web domain graph data show that link spam can be successfully detected with the proposed method.

#index 915287
#* Minimum Enclosing Spheres Formulations for Support Vector Ordinal Regression
#@ S. K. Shevade;Wei Chu
#t 2006
#c 18
#! We present two new support vector approaches for ordinal regression. These approaches find the concentric spheres with minimum volume that contain most of the training samples. Both approaches guarantee that the radii of the spheres are properly ordered at the optimal solution. The size of the optimization problem is linear in the number of training samples. The popularSMO algorithm is adapted to solve the resulting optimization problem. Numerical experiments on some real-world data sets verify the usefulness of our approaches for data mining.

#index 915288
#* Mining Maximal Quasi-Bicliques to Co-Cluster Stocks and Financial Ratios for Value Investment
#@ Kelvin Sim;Jinyan Li;Vivekanand Gopalkrishnan;Guimei Liu
#t 2006
#c 18
#! We introduce an unsupervised process to co-cluster groups of stocks and financial ratios, so that investors can gain more insight on how they are correlated. Our idea for the co-clustering is based on a graph concept called maximal quasi-bicliques, which can tolerate erroneous or/and missing information that are common in the stock and financial ratio data. Compared to previous works, our maximal quasi-bicliques require the errors to be evenly distributed, which enable us to capture more meaningful co-clusters. We develop a new algorithm that can efficiently enumerate maximal quasi-bicliques from an undirected graph. The concept of maximal quasi-bicliques is domain-independent; it can be extended to perform co-clustering on any set of data that are modeled by graphs.

#index 915289
#* Boosting the Feature Space: Text Classification for Unstructured Data on the Web
#@ Yang Song;Ding Zhou;Jian Huang;Isaac G. Councill;Hongyuan Zha;C. Lee Giles
#t 2006
#c 18
#! The issue of seeking efficient and effective methods for classifying unstructured text in large document corpora has received much attention in recent years. Traditional document representation like bag-of-words encodes documents as feature vectors, which usually leads to sparse feature spaces with large dimensionality, thus making it hard to achieve high classification accuracies. This paper addresses the problem of classifying unstructured documents on the Web. A classification approach is proposed that utilizes traditional feature reduction techniques along with a collaborative filtering method for augmenting document feature spaces. The method produces feature spaces with an order of magnitude less features compared with a baseline bag-of-words feature selection method. Experiments on both real-world data and benchmark corpus indicate that our approach improves classification accuracy over the traditional methods for both Support Vector Machines and AdaBoost classifiers.

#index 915290
#* Plagiarism Detection in arXiv
#@ Daria Sorokina;Johannes Gehrke;Simeon Warner;Paul Ginsparg
#t 2006
#c 18
#! We describe a large-scale application of methods for finding plagiarism in research document collections. The methods are applied to a collection of 284,834 documents collected by arXiv.org over a 14 year period, covering a few different research disciplines. The methodology effi- ciently detects a variety of problematic author behaviors, and heuristics are developed to reduce the number of false positives. The methods are also efficient enough to imple- ment as a real-time submission screen for a collection many times larger.

#index 915291
#* Secure Distributed k-Anonymous Pattern Mining
#@ Wei Jiang;Maurizio Atzori
#t 2006
#c 18
#! Privacy-Preserving Data Mining is an important area that studies privacy issues of data mining. When the goal is to share data mining results, two privacy-related problems may arise. The first one is how to compute the data-mining results among several parties without sharing the data. Cryptography-based primitives are the basic tool used to develop ad-hoc secure multi-party computation protocols that share information as less as possible during the computation under different adversary models. The second one is how to produce data mining results that provably do not contain threats to the anonymity of individuals. The concept of k-anonymity has been used to discover anonymity-preserving frequent patterns, and centralized algorithms have been developed. In this paper and for the first time, we study how to produce anonymity-preserving data mining results in a distributed environment. We present two privacy-preserving strategies and show their feasibility through experimental analysis.

#index 915292
#* A Parameterized Probabilistic Model of Network Evolution for Supervised Link Prediction
#@ Hisashi Kashima;Naoki Abe
#t 2006
#c 18
#! We introduce a new approach to the problem of link prediction for network structured domains, such as the Web, social networks, and biological networks. Our approach is based on the topological features of network structures, not on the node features. We present a novel parameterized probabilistic model of network evolution and derive an efficient incremental learning algorithm for such models, which is then used to predict links among the nodes. We show some promising experimental results using biological network data sets.

#index 915293
#* Incremental Mining of Frequent Query Patterns from XML Queries for Caching
#@ Guoliang Li;Jianhua Feng;Jianyong Wang;Yong Zhang;Lizhu Zhou
#t 2006
#c 18
#! Existing studies for mining frequent XML query patterns mainly introduce a straightforward candidate generate-and-test strategy and compute frequencies of candidate query patterns from scratch periodically by checking the entire transaction database, which consists of XML query patterns transformed from user queries. However, it is nontrivial to maintain such discovered frequent patterns in real XML databases because there may incur frequent updates that may not only invalidate some existing frequent query patterns but also generate some new frequent ones. Accordingly, existing proposals are inefficient for the evolution of the transaction database. To address these problems, this paper presents an efficient algorithm IPS-FXQPMiner for mining frequent XML query patterns without candidate maintenance and costly tree-containment checking. We transform XML queries into sequences through a oneto- one mapping and then mine the frequent sequences to generate frequent XML query patterns. More importantly, based on IPS-FXQPMiner, an efficient incremental algorithm, Incre-FXQPMiner is proposed to incrementally mine frequent XML query patterns, which can minimize the I/O and computation requirements for handling incremental updates. Our experimental study on various real-life datasets demonstrates the efficiency and scalability of our algorithms over previous known alternatives.

#index 915294
#* The Relationships Among Various Nonnegative Matrix Factorization Methods for Clustering
#@ Tao Li;Chris Ding
#t 2006
#c 18
#! The nonnegative matrix factorization (NMF) has been shown recently to be useful for clustering and various extensions and variations of NMF have been proposed recently. Despite significant research progress in this area, few attempts have been made to establish the connections between various factorization methods while highlighting their differences. In this paper we aim to provide a comprehensive study on matrix factorization for clustering. In particular, we present an overview and summary on various matrix factorization algorithms and theoretically analyze the relationships among them. Experiments are also conducted to empirically evaluate and compare various factorization methods. In addition, our study also answers several previously unaddressed yet important questions for matrix factorizations including the interpretation and normalization of cluster posterior and the benefits and evaluation of simultaneous clustering. We expect our study would provide good insights on matrix factorization research for clustering.

#index 915295
#* Integrating Features from Different Sources for Music Information Retrieval
#@ Tao Li;Mitsunori Ogihara;Shenghuo Zhu
#t 2006
#c 18
#! Efficient and intelligent music information retrieval is a very important topic of the 21st century. With the ultimate goal of building personal music information retrieval systems, this paper studies the problem of identifying "similar" artists using both lyrics and acoustic data. In this paper, we present a clustering algorithm that integrates features from both sources to perform bimodal learning. The algorithm is tested on a data set consisting of 570 songs from 53 albums of 41 artists using artist similarity provided by All Music Guide. Experimental results show that the accuracy of artist similarity classifiers can be significantly improved and that artist similarity can be efficiently identified.

#index 915296
#* How Bayesians Debug
#@ Chao Liu;Zeng Lian;Jiawei Han
#t 2006
#c 18
#! Manual debugging is expensive. And the high cost has motivated extensive research on automated fault lo- calization in both software engineering and data mining communities. Fault localization aims at automatically locating likely fault locations, and hence assists manual debugging. A number of fault localization algorithms have been developed in recent years, which prove effec- tive when multiple failing and passing cases are avail- able. However, we notice what is more commonly en- countered in practice is the two-sample debugging prob- lem, where only one failing and one passing cases are available. This problem has been either overlooked or insufficiently tackled in previous studies. In this paper, we develop a new fault localization al- gorithm, named BayesDebug, which simulates some manual debugging principles through a Bayesian ap- proach. Different from existing approaches that base fault analysis on multiple passing and failing cases, BayesDebug only requires one passing and one failing cases. We reason about why BayesDebug fits the two- sample debugging problem and why other approaches do not. Finally, an experiment with a real-world program grep-2.2 is conducted, which exemplifies the effective- ness of BayesDebug.

#index 915297
#* Window-based Tensor Analysis on High-dimensional and Multi-aspect Streams
#@ Jimeng Sun;Spiros Papadimitriou;Philip S. Yu
#t 2006
#c 18
#! Data stream values are often associated with multiple aspects. For example, each value from environmental sensors may have an associated type (e.g., temperature, humidity, etc) as well as location. Aside from timestamp, type and location are the two additional aspects. How to model such streams? How to simultaneously find patterns within and across the multiple aspects? How to do it incrementally in a streaming fashion? In this paper, all these problems are addressed through a general data model, tensor streams, and an effective algorithmic framework, window-based tensor analysis (WTA). Two variations of WTA, independent-window tensor analysis (IW) and moving-window tensor analysis (MW), are presented and evaluated extensively on real datasets. Finally, we illustrate one important application, Multi-Aspect Correlation Analysis (MACA), which uses WTA and we demonstrate its effectiveness on an environmental monitoring application.

#index 915298
#* Automatic Single-Organ Segmentation in Computed Tomography Images
#@ Ruchaneewan Susomboon;Daniela Raicu;Jacob Furst;David Channin
#t 2006
#c 18
#! In this paper, we propose a hybrid approach for automatic single-organ segmentation in Computed Tomography (CT) data. The approach consists of three stages: first, a probability image of the organ of interest is obtained by applying a binary classification model obtained using pixel-based texture features; second, an adaptive split-and-merge segmentation algorithm is applied on the organ probability image to remove the noise introduced by the misclassified pixels; and third, the segmented organ's boundaries from the previous stage are iteratively refined using a region growing algorithm. While we applied our approach for liver segmentation in 2-D CT images, a challenging and important task in many medical applications, the proposed approach can be applied for the segmentation of any other organ in CT images. Moreover, the proposed approach can be extended to perform automatic multiple organ segmentation and to build context-sensitive reporting tools for computer-aided diagnosis applications.

#index 915299
#* Improving Nearest Neighbor Classifier Using Tabu Search and Ensemble Distance Metrics
#@ Muhammad Atif Tahir;James Smith
#t 2006
#c 18
#! The nearest-neighbor (NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In this paper, a new ensemble technique is proposed to improve the performance of NN classifier. The proposed approach combines multiple NN classifiers, where each classifier uses a different distance function and potentially a different set of features (feature vector). These feature vectors are determined for each distance metric using Simple Voting Scheme incorporated in Tabu Search (TS). The proposed ensemble classifier with different distance metrics and different feature vectors (TS-DF/NN) is evaluated using various benchmark data sets from UCI Machine Learning Repository. Results have indicated a significant increase in the performance when compared with various well-known classifiers. Furthermore, the proposed ensemble method is also compared with ensemble classifier using different distance metrics but with same feature vector (with or without Feature Selection (FS)).

#index 915300
#* Comparisons of K-Anonymization and Randomization Schemes under Linking Attacks
#@ Zhouxuan Teng;Wenliang Du
#t 2006
#c 18
#! Recently K-anonymity has gained popularity as a privacy quantification against linking attacks, in which attackers try to identify a record with values of some identifying attributes. If attacks succeed, the identity of the record will be revealed and potential confidential information contained in other attributes of the record will be disclosed. K-anonymity counters this attack by requiring that each record must be indistinguishable from at least K -1 other records with respect to the identifying attributes. Randomization can also be used for protection against linking attacks. In this paper, we compare the performance of K-anonymization and randomization schemes under linking attacks. We present a new privacy definition that can be applied to both k-anonymization and randomization. We compare these two schemes in terms of both utility and risks of privacy disclosure, and we promote to use R-U confidentiality map for such comparisons. We also compare various randomization schemes.

#index 915301
#* MARGIN: Maximal Frequent Subgraph Mining
#@ Lini T. Thomas;Satyanarayana R. Valluri;Kamalakar Karlapalem
#t 2006
#c 18
#! The exponential number of possible subgraphsmakes the problem of frequent subgraph mining a challenge. The set of maximal frequent subgraphs is much smaller to that of the set of frequent subgraphs, thus providing ample scope for pruning. MARGIN is a maximal subgraph mining algorithm that moves among promising nodes of the search space along the "border" of the infrequent and frequent subgraphs. This drastically reduces the number of candidate patterns considered in the search space. Experimental results validate the efficiency and utility of the technique proposed.

#index 915302
#* Resource Management for Networked Classifiers in Distributed Stream Mining Systems
#@ Deepak S. Turaga;Olivier Verscheure;Upendra V. Chaudhari;Lisa D. Amini
#t 2006
#c 18
#! Networks of classifiers are capturing the attention of system and algorithmic researchers because they offer improved accuracy over single model classifiers, can be distributed over a network of servers for improved scalability, and can be adapted to available system resources. This work provides a principled approach for the optimized allocation of system resources across a networked chain of classifiers. We begin with an illustrative example of how complex classification tasks can be decomposed into a network of binary classifiers. We formally define a global performance metric by recursively collapsing the chain of classifiers into one combined classifier. The performance metric trades off the end-to-end probabilities of detection and false alarm, both of which depend on the resources allocated to each individual classifier. We formulate the optimization problem and present optimal resource allocation results for both simulated and state-of-the-art classifier chains operating on telephony data.

#index 915303
#* On the Use of Structure and Sequence-Based Features for Protein Classification and Retrieval
#@ Keith Marsolo;Srinivasan Parthasarathy
#t 2006
#c 18
#! The need to retrieve or classify protein molecules using structure or sequence-based similarity measures underlies a wide range of biomedical applications. In drug discovery, researchers search for proteins that share specific chemical properties as possible sources for new treatment. With folding simulations, similar intermediate structures might be indicative of a common folding pathway. To derive any type of similarity, however, one must have an effective model of the protein that allows for easy comparison. In this work, we present two normalized, stand-alone representations of proteins that enable fast and efficient object retrieval based on sequence or structure. To create our sequence-based representation, we take the frequency and scoring matrices returned by the PSI-BLAST alignment algorithm and create a normalized summary using a discrete wavelet transform. Our structural descriptor is constructed using an algorithm we developed previously. First, we transform each 3D structure into a 2D distance matrix by calculating the pair-wise distance between the amino acids of a protein. We normalize this matrix and apply a 2D wavelet decomposition to generate a set of approximation coefficients, which serve as our feature vector. We also concatenate the sequence and structural descriptors together to create a hybrid solution. We evaluate the generality of our models by using them as database indices for nearest-neighbor and range-based retrieval experiments as well as feature vectors for classification using support vector machines. We find that our methods provide excellent performance when compared with the current state-of-the-art techniques of each task. Our results show that the sequence-based representation is on par with, or out-performs, the structure-based representation. Moreover, we find that in the classification context, the hybrid strategy affords a significant improvement over sequence or structure.

#index 915304
#* Accelerating Newton Optimization for Log-Linear Models through Feature Redundancy
#@ Arpit Mathur;Soumen Chakrabarti
#t 2006
#c 18
#! Log-linear models are widely used for labeling feature vectors and graphical models, typically to estimate robust conditional distributions in presence of a large number of potentially redundant features. Limited-memory quasi-Newton methods like LBFGS or BLMVM are optimization workhorses for such applications, and most of the training time is spent computing the objective and gradient for the optimizer. We propose a simple technique to speed up the training optimization by clustering features dynamically, and interleaving the standard optimizer with another, coarse-grained, faster optimizer that uses far fewer variables. Experiments with logistic regression training for text classification and conditional random field (CRF) training for information extraction show promising speed-ups between 2脳 and 9脳 without any systematic or significant degradation in the quality of the estimated models.

#index 915305
#* P3C: A Robust Projected Clustering Algorithm
#@ Gabriela Moise;Jorg Sander;Martin Ester
#t 2006
#c 18
#! Projected clustering has emerged as a possible solution to the challenges associated with clustering in high dimensional data. A projected cluster is a subset of points together with a subset of attributes, such that the cluster points project onto a small range of values in each of these attributes, and are uniformly distributed in the remaining attributes. Existing algorithms for projected clustering rely on parameters whose appropriate values are difficult to set by the user, or are unable to identify projected clusters with few relevant attributes. In this paper, we present a robust algorithm for projected clustering that can effectively discover projected clusters in the data while minimizing the number of parameters required as input. In contrast to all previous approaches, our algorithm can discover, under very general conditions, the true number of projected clusters. We show through an extensive experimental evaluation that our algorithm: (1) significantly outperforms existing algorithms for projected clustering in terms of accuracy; (2) is effective in detecting very low-dimensional projected clusters embedded in high dimensional spaces; (3) is effective in detecting clusters with varying orientation in their relevant subspaces; (4) is scalable with respect to large data sets and high number of dimensions.

#index 915306
#* Frequent Closed Itemset Mining Using Prefix Graphs with an Efficient Flow-Based Pruning Strategy
#@ H. D. K. Moonesinghe;Samah Fodeh;Pang-Ning Tan
#t 2006
#c 18
#! This paper presents PGMiner, a novel graph-based algorithm for mining frequent closed itemsets. Our approach consists of constructing a prefix graph structure and decomposing the database to variable length bit vectors, which are assigned to nodes of the graph. The main advantage of this representation is that the bit vectors at each node are relatively shorter than those produced by existing vertical mining methods. This facilitates fast frequency counting of itemsets via intersection operations. We also devise several internode and intra-node pruning strategies to substantially reduce the combinatorial search space. Unlike other existing approaches, we do not need to store in memory the entire set of closed itemsets that have been mined so far in order to check whether a candidate itemset is closed. This dramatically reduces the memory usage of our algorithm, especially for low support thresholds. Our experiments using synthetic and real-world data sets show that PGMiner outperforms existing mining algorithms by as much as an order of magnitude and is scalable to very large databases.

#index 915307
#* Efficient Clustering of Uncertain Data
#@ Wang Kay Ngai;Ben Kao;Chun Kit Chui;Reynold Cheng;Michael Chau;Kevin Y. Yip
#t 2006
#c 18
#! We study the problem of clustering data objects whose locations are uncertain. A data object is represented by an uncertainty region over which a probability density function (pdf) is defined. One method to cluster uncertain objects of this sort is to apply the UK-means algorithm, which is based on the traditional K-means algorithm. In UK-means, an object is assigned to the cluster whose representative has the smallest expected distance to the object. For arbitrary pdf, calculating the expected distance between an object and a cluster representative requires expensive integration computation. We study various pruning methods to avoid such expensive expected distance calculation.

#index 915308
#* A Simple Yet Effective Data Clustering Algorithm
#@ Soujanya Vadapalli;Satyanarayana R. Valluri;Kamalakar Karlapalem
#t 2006
#c 18
#! In this paper, we use a simple concept based on k-reverse nearest neighbor digraphs, to develop a framework RECORD for clustering and outlier detection. We developed three algorithms - (i) RECORD algorithm (requires one parameter), (ii) Agglomerative RECORD algorithm (no parameters required) and (iii) Stability-based RECORD algorithm( no parameters required). Our experimental results with published datasets, synthetic and real-life datasets show that RECORD not only handles noisy data, but also identifies the relevant clusters. Our results are as good as (if not better than) the results got from other algorithms.

#index 915309
#* Entropy-based Concept Shift Detection
#@ Peter Vorburger;Abraham Bernstein
#t 2006
#c 18
#! When monitoring sensory data (e.g., from a wearable device) the context oftentimes changes abruptly: people move from one situation (e.g., working quietly in their office) to another (e.g., being interrupted by one's manager). These context changes can be treated like concept shifts, since the underlying data generator (the concept) changes while moving from one context situation to another. We present an entropy based measure for data streams that is suitable to detect concept shifts in a reliable, noise-resistant, fast, and computationally efficient way. We assess the entropy measure under different concept shift conditions. To support our claims we illustrate the concept shift behavior of the stream entropy. We also present a simple algorithm control approach to show how useful and reliable the information obtained by the entropy measure is compared to a ensemble learner as well as an experimentally inferred upper limit. Our analysis is based on three large synthetic data sets representing real, virtual, and a combination of both concept drifts under different noise conditions (up to 50%). Last but not least, we demonstrate the usefulness of the entropy based measure context switch indication in a real world application in the context-awareness/wearable computing domain.

#index 915310
#* Recommendation on Item Graphs
#@ Fei Wang;Sheng Ma;Liuzhong Yang;Tao Li
#t 2006
#c 18
#! A novel scheme for item-based recommendation is proposed in this paper. In our framework, the items are described by an undirected weighted graph G = (V, E). V is the node set which is identical to the item set, and E is the edge set. Associate with each edge e_ij \inE is a weight w_ij \geqslant0, which represents similarity between items i and j. Without the loss of generality, we assume that any user's ratings to the items should be sufficiently smooth with respect to the intrinsic structure of the items, i.e., a user should give similar ratings to similar items. A simple algorithm is presented to achieve such a "smooth" solution. Encouraging experimental results are provided to show the effectiveness of our method.

#index 915311
#* Solution Path for Semi-Supervised Classification with Manifold Regularization
#@ Gang Wang;Tao Chen;Dit-Yan Yeung;Frederick H. Lochovsky
#t 2006
#c 18
#! With very low extra computational cost, the entire solution path can be computed for various learning algorithms like support vector classification (SVC) and support vector regression (SVR). In this paper, we extend this promising approach to semi-supervised learning algorithms. In particular, we consider finding the solution path for the Laplacian support vector machine (LapSVM) which is a semi-supervised classification model based on manifold regularization. One advantage of the this algorithm is that the coefficient path is piecewise linear with respect to the regularization parameter, hence its computational complexity is quadratic in the number of labeled examples.

#index 915312
#* Semi-Supervised Kernel Regression
#@ Meng Wang;Xian-Sheng Hua;Yan Song;Li-Rong Dai;Hong-Jiang Zhang
#t 2006
#c 18
#! Insufficiency of training data is a major obstacle in machine learning and data mining applications. Many different semi-supervised learning algorithms have been proposed to tackle this difficulty by leveraging a large amount of unlabeled data. However, most of them focus on semi-supervised classification. In this paper we propose a semi-supervised regression algorithm named Semi-Supervised Kernel Regression (SSKR). While classical kernel regression is only based on labeled examples, our approach extends it to all observed examples using a weighting factor to modulate the effect of unlabeled examples. Experimental results prove that SSKR significantly outperforms traditional kernel regression and graph-based semi-supervised regression methods.

#index 915313
#* Mining Complex Time-Series Data by Learning Markovian Models
#@ Yi Wang;Lizhu Zhou;Jianhua Feng;Jianyong Wang;Zhi-Qiang Liu
#t 2006
#c 18
#! In this paper, we propose a novel and general approach for time-series data mining. As an alternative to traditional ways of designing specific algorithm to mine certain kind of pattern directly from the data, our approach extracts the temporal structure of the time-series data by learning Markovian models, and then uses well established methods to efficiently mine a wide variety of patterns from the topology graph of the learned models. We consolidate the approach by explaining the use of some well-known Markovian models on mining several kinds of patterns. We then present a novel high-order hidden Markov model, the variable-length hidden Markov model (VLHMM), which combines the advantages of well-known Markovian models and has the superiority in both efficiency and accuracy. Therefore, it can mine a much wider variety of patterns than each of prior Markovian models. We demonstrate the power of VLHMM by mining four kinds of interesting patterns from 3D motion capture data, which is typical for the high-dimensionality and complex dynamics.

#index 915314
#* Temporal Data Mining in Dynamic Feature Spaces
#@ Brent Wenerstrom;Christophe Giraud-Carrier
#t 2006
#c 18
#! Many interesting real-world applications for temporal data mining are hindered by concept drift. One particular form of concept drift is characterized by changes to the underlying feature space. Seemingly little has been done in this area. This paper presents FAE, an incremental ensemble approach to mining data subject to such concept drift. Empirical results on large data streams demonstrate promise.

#index 915315
#* A Data Mining Approach for Capacity Building of Stakeholders in Integrated Flood Management
#@ Peter Owotoki;Natasa Manojlovic;Friedrich Mayer-Lindenberg;Erik Pasche
#t 2006
#c 18
#! New approaches to managing flood events are increasingly of more relevance due to recent widespread floods and the presumed changes in the climate. These approaches fall under the integrated flood management (IFM) banner and focus not only on flood prevention, but on flood resilience. This paper introduces an application (FLORETO) for IFM that utilizes the data mining approach, in a web based three tier system, devoted to the capacity building of stakeholders as a micro-scale resilience strategy of IFM. The intelligent models, which constitute the business logic in FLORETO, are used to match the input parameters or design criteria, describing properties prone to flooding, to technically justifiable flood mitigation measures. Datasets from the German city of Kellinghusen were collected and intelligent models were built. Satisfactory results have been obtained, which shows the promise of this data mining approach and opens the door for its application for IFM in other regions.

#index 915316
#* Local Correlation Tracking in Time Series
#@ Spiros Papadimitriou;Jimeng Sun;Philip S. Yu
#t 2006
#c 18
#! We address the problem of capturing and tracking local correlations among time evolving time series. Our approach is based on comparing the local auto-covariance matrices (via their spectral decompositions) of each series and generalizes the notion of linear cross-correlation. In this way, it is possible to concisely capture a wide variety of local patterns or trends. Our method produces a general similarity score, which evolves over time, and accurately reflects the changing relationships. Finally, it can also be estimated incrementally, in a streaming setting. We demonstrate its usefulness, robustness and efficiency on a wide range of real datasets.

#index 915317
#* Who Thinks Who Knows Who? Socio-cognitive Analysis of Email Networks
#@ Nishith Pathak;Sandeep Mane;Jaideep Srivastava
#t 2006
#c 18
#! Interpersonal interaction plays an important role in organizational dynamics, and understanding these interaction networks is a key issue for any organization, since these can be tapped to facilitate various organizational processes. However, the approaches of collecting data about them using surveys/interviews are fraught with problems of scalability, logistics and reporting biases, especially since such surveys may be perceived to be intrusive. Widespread use of computer networks for organizational communication provides a unique opportunity to overcome these difficulties and automatically map the organizational networks with a high degree of detail and accuracy. This paper describes an effective and scalable approach for modeling organizational networks by tapping into an organization's email communication. The approach models communication between actors as non-stationary Bernoulli trials and Bayesian inference is used for estimating model parameters over time. This approach is useful for sociocognitive analysis (who knows who knows who) of organizational communication networks. Using this approach, novel measures for analysis of (i) closeness between actors' perceptions about such organizational networks (agreement), (ii) divergence of an actor's perceptions about organizational network from reality (misperception) are explained. Using the Enron email data, we show that these techniques provide sociologists with a new tool to understand organizational networks.

#index 915318
#* An Efficient Reference-Based Approach to Outlier Detection in Large Datasets
#@ Yaling Pei;Osmar R. Zaiane;Yong Gao
#t 2006
#c 18
#! A bottleneck to detecting distance and density based outliers is that a nearest-neighbor search is required for each of the data points, resulting in a quadratic number of pairwise distance evaluations. In this paper, we propose a new method that uses the relative degree of density with respect to a fixed set of reference points to approximate the degree of density defined in terms of nearest neighbors of a data point. The running time of our algorithm based on this approximation is O(R_n log n) where n is the size of dataset and R is the number of reference points. Candidate outliers are ranked based on the outlier score assigned to each data point. Theoretical analysis and empirical studies show that our method is effective, efficient, and highly scalable to very large datasets.

#index 915319
#* Using an Ensemble of One-Class SVM Classifiers to Harden Payload-based Anomaly Detection Systems
#@ Roberto Perdisci;Guofei Gu;Wenke Lee
#t 2006
#c 18
#! Unsupervised or unlabeled learning approaches for network anomaly detection have been recently proposed. In particular, recent work on unlabeled anomaly detection focused on high speed classification based on simple payload statistics. For example, PAYL, an anomaly IDS, measures the occurrence frequency in the payload of n-grams. A simple model of normal traffic is then constructed according to this description of the packets' content. It has been demonstrated that anomaly detectors based on payload statistics can be "evaded" by mimicry attacks using byte substitution and padding techniques. In this paper we propose a new approach to construct high speed payload-based anomaly IDS intended to be accurate and hard to evade. We propose a new technique to extract the features from the payload. We use a feature clustering algorithm originally proposed for text classification problems to reduce the dimensionality of the feature space. Accuracy and hardness of evasion are obtained by constructing our anomaly-based IDS using an ensemble of one-class SVM classifiers that work on different feature spaces.

#index 915320
#* Relational Ensemble Classification
#@ Christine Preisach;Lars Schmidt-Thieme
#t 2006
#c 18
#! Relational classification aims at including relations among entities, for example taking relations between documents such as a common author or citations into account. However, considering more than one relation can further improve classification accuracy. In this paper we introduce a new approach to make use of several relations as well as both relations and attributes for classification using ensemble methods. To accomplish this, we present a generic relational ensemble model, that can use different relational and local classifiers as components. Furthermore, we discuss solutions for several problems concerning relational data such as heterogeneity, sparsity, and multiple relations. Finally, we provide empirical evidence, that our relational ensemble methods outperform existing relational classification methods, even rather complex models such as relational probability trees (RPTs), relational dependency networks (RDNs) and relational Bayesian classifiers (RBCs).

#index 915321
#* Discover Bayesian Networks from Incomplete Data Using a Hybrid Evolutionary Algorithm
#@ Man Leung Wong;Yuan Yuan Guo
#t 2006
#c 18
#! This paper proposes a novel hybrid approach for learning Bayesian networks from incomplete data in the presence of missing values, which combines an evolutionary algorithm with the traditional Expectation-Maximization (EM) algorithm. The new algorithm can overcome the problem of getting stuck in sub-optimal solutions which occurs in most existing learning algorithms. The experimental results on the data sets generated from several benchmark networks illustrate that the new algorithm has better performance than some state-of-the-art algorithms. We also apply the approach to a data set of direct marketing and compare the performance of the discovered Bayesian networks obtained by the new algorithm with the networks generated by other methods. In the comparison, the Bayesian networks learned by the new algorithm outperform other networks.

#index 915322
#* Distances and (Indefinite) Kernels for Sets of Objects
#@ Adam Woznica;Alexandros Kalousis;Melanie Hilario
#t 2006
#c 18
#! The main disadvantage of most existing set kernels is that they are based on averaging, which might be inappropriate for problems where only specific elements of the two sets should determine the overall similarity. In this paper we propose a class of kernels for sets of vectors directly exploiting set distance measures and, hence, incorporating various semantics into set kernels and lending the power of regularization to learning in structural domains where natural distance functions exist. These kernels belong to two groups: (i) kernels in the proximity space induced by set distances and (ii) set distance substitution kernels (non-PSD in general). We report experimental results which show that our kernels compare favorably with kernels based on averaging and achieve results similar to other state-of-the-art methods. At the same time our kernels systematically improve over the naive way of exploiting distances.

#index 915323
#* Deploying Approaches for Pattern Refinement in Text Mining
#@ Sheng-Tang Wu;Yuefeng Li;Yue Xu
#t 2006
#c 18
#! Text mining is the technique that helps users find useful information from a large amount of digital text documents on the Web or databases. Instead of the keyword-based approach which is typically used in this field, the pattern-based model containing frequent sequential patterns is employed to perform the same concept of tasks. However, how to effectively use these discovered patterns is still a big challenge. In this study, we propose two approaches based on the use of pattern deploying strategies. The performance of the pattern deploying algorithms for text mining is investigated on the Reuters dataset RCV1 and the results show that the effectiveness is improved by using our proposed pattern refinement approaches.

#index 915324
#* TOP-COP: Mining TOP-K Strongly Correlated Pairs in Large Databases
#@ Hui Xiong;Mark Brodie;Sheng Ma
#t 2006
#c 18
#! Recently, there has been considerable interest in computing strongly correlated pairs in large databases. Most previous studies require the specification of a minimum correlation threshold to perform the computation. However, it may be difficult for users to provide an appropriate threshold in practice, since different data sets typically have different characteristics. To this end, we propose an alternative task: mining the top-k strongly correlated pairs. In this paper, we identify a 2-D monotone property of an upper bound of Pearson's correlation coefficient and develop an efficient algorithm, called TOP-COP to exploit this property to effectively prune many pairs even without computing their correlation coefficients. Our experimental results show that the TOP-COP algorithm can be orders of magnitude faster than brute-force alternatives for mining the top-k strongly correlated pairs.

#index 915325
#* Manifold Clustering of Shapes
#@ Dragomir Yankov;Eamonn Keogh
#t 2006
#c 18
#! Shape clustering can significantly facilitate the automatic labeling of objects present in image collections. For example, it could outline the existing groups of pathological cells in a bank of cyto-images; the groups of species on photographs collected from certain aerials; or the groups of objects observed on surveillance scenes from an office building. Here we demonstrate that a nonlinear projection algorithm such as Isomap can attract together shapes of similar objects, suggesting the existence of isometry between the shape space and a low dimensional nonlinear embedding. Whenever there is a relatively small amount of noise in the data, the projection forms compact, convex clusters that can easily be learned by a subsequent partitioning scheme. We further propose a modification of the Isomap projection based on the concept of degree-bounded minimum spanning trees. The proposed approach is demonstrated to move apart bridged clusters and to alleviate the effect of noise in the data.

#index 915326
#* Linear and Non-Linear Dimensional Reduction via Class Representatives for Text Classification
#@ Dimitrios Zeimpekis;Efstratios Gallopoulos
#t 2006
#c 18
#! We address the problem of building fast and effective text classification tools. We describe a "representatives methodology" related to feature extraction and illustrate its performance using as vehicles a centroid based method and a method based on clustered LSI that were recently proposed as useful tools for low rank matrix approximation and cost effective alternatives to LSI. The methodology is very flexible, providing the means for accelerating existing algorithms. It is also combined with kernel techniques to enable the analysis of data for which linear techniques are insufficient. Numerous classification examples indicate that the proposed technique is effective and efficient with an overall performance superior than existing linear and nonlinear LSI-based approaches.

#index 915327
#* Discovering Partial Orders in Binary Data
#@ Deepak Rajan;Philip S. Yu
#t 2006
#c 18
#! We approach the problem of discovering interesting orders in data. In many applications, it is more important to find interesting partial orders since there is often no clear ordering between certain sets of elements. Furthermore, a partial order is more robust against partially erroneous data. We present the notion of fundamental partial orders (FPO), and argue that any partial order that satisfies this property is an interesting partial order. To mine such partial orders, we present a two-stage methodology that first finds an interesting total order, and then discovers a partial order satisfying FPO using this total order. To illustrate, we focus on {0, 1} data. This is an important problem with many applications, e.g., in paleontology, where we chronologically order fossil sites by minimizing Lazarus counts. We present the experimental results of our method on paleontological data, and show that it outperforms existing approaches. The techniques developed here are general and can be abstracted for mining partial orders in any setting.

#index 915328
#* Stability Region Based Expectation Maximization for Model-based Clustering
#@ Chandan K. Reddy;Hsiao-Dong Chiang;Bala Rajaratnam
#t 2006
#c 18
#! In spite of the initialization problem, the Expectation- Maximization (EM) algorithm is widely used for estimating the parameters in several data mining related tasks. Most popular model-based clustering techniques might yield poor clusters if the parameters are not initialized properly. To reduce the sensitivity of initial points, a novel algorithm for learning mixture models from multivariate data is introduced in this paper. The proposed algorithm takes advantage of TRUST-TECH (TRansformation Under STability-reTaining Equilibra CHaracterization) to compute neighborhood local maxima on likelihood surface using stability regions. Basically, our method coalesces the advantages of the traditional EM with that of the dynamic and geometric characteristics of the stability regions of the corresponding nonlinear dynamical system of the log-likelihood function. Two phases namely, the EM phase and the stability region phase, are repeated alternatively in the parameter space to achieve improvements in the maximum likelihood. Though applied to Gaussian mixtures in this paper, our technique can be easily generalized to any other parametric finite mixture model. The algorithm has been tested on both synthetic and real datasets and the improvements in the performance compared to other approaches are demonstrated. The robustness with respect to initialization is also illustrated experimentally.

#index 915329
#* Co-clustering Documents and Words Using Bipartite Isoperimetric Graph Partitioning
#@ Manjeet Rege;Ming Dong;Farshad Fotouhi
#t 2006
#c 18
#! In this paper, we present a novel graph theoretic approach to the problem of document-word co-clustering. In our approach, documents and words are modeled as the two vertices of a bipartite graph. We then propose Isoperimetric Co-clustering Algorithm (ICA) - a new method for partitioning the document-word bipartite graph. ICA requires a simple solution to a sparse system of linear equations instead of the eigenvalue or SVD problem in the popular spectral co-clustering approach. Our extensive experiments performed on publicly available datasets demonstrate the advantages of ICA over spectral approach in terms of the quality, efficiency and stability in partitioning the document-word bipartite graph.

#index 915330
#* Latent Dirichlet Co-Clustering
#@ M. Mahdi Shafiei;Evangelos E. Milios
#t 2006
#c 18
#! We present a generative model for simultaneously clustering documents and terms. Our model is a four-level hierarchical Bayesian model, in which each document is modeled as a random mixture of document topics , where each topic is a distribution over some segments of the text. Each of these segments in the document can be modeled as a mixture of word topics where each topic is a distribution over words. We present efficient approximate inference techniques based on Markov Chain Monte Carlo method and a Moment-Matching algorithm for empirical Bayes parameter estimation. We report results in document modeling, document and term clustering, comparing to other topic models, Clustering and Co-Clustering algorithms including Latent Dirichlet Allocation (LDA), Model-based Overlapping Clustering (MOC), Model-based Overlapping Co-Clustering (MOCC) and Information-Theoretic Co-Clustering (ITCC).

#index 915331
#* Latent Friend Mining from Blog Data
#@ Dou Shen;Jian-Tao Sun;Qiang Yang;Zheng Chen
#t 2006
#c 18
#! The rapid growth of blog (also known as "weblog") data provides a rich resource for social community mining. In this paper, we put forward a novel research problem of mining the latent friends of bloggers based on the contents of their blog entries. Latent friends are defined in this paper as people who share the similar topic distribution in their blogs. These people may not actually know each other, but they have the interest and potential to find each other out. Three approaches are designed for latent friend detection. The first one, called cosine similarity-based method, determines the similarity between bloggers by calculating the cosine similarity between the contents of the blogs. The second approach, known as topic-based method, is based on the discovery of latent topics using a latent topic model and then calculating the similarity at the topic level. The third one is two-level similarity-based, which is conducted in two stages. In the first stage, an existing topic hierarchy is exploited to build a topic distribution for a blogger. Then, in the second stage, a detailed similarity comparison is conducted for bloggers that are close in interest to each other which are discovered in the first stage. Our experimental results show that both the topic-based and two-level similarity-based methods work well, and the last approach performs much better than the first two. In this paper, we give a detailed analysis of the advantages and disadvantages of different approaches.

#index 915332
#* Adaptive Kernel Principal Component Analysis with Unsupervised Learning of Kernels
#@ Daoqiang Zhang;Zhi-Hua Zhou;Songcan Chen
#t 2006
#c 18
#! Choosing an appropriate kernel is one of the key problems in kernel-based methods. Most existing kernel selection methods require that the class labels of the training examples are known. In this paper, we propose an adaptive kernel selection method for kernel principal component analysis, which can effectively learn the kernels when the class labels of the training examples are not available. By iteratively optimizing a novel criterion, the proposed method can achieve nonlinear feature extraction and unsupervised kernel learning simultaneously. Moreover, a noniterative approximate algorithm is developed. The effectiveness of the proposed algorithms are validated on UCI datasets and the COIL-20 object recognition database.

#index 915333
#* Rule-Based Platform for Web User Profiling
#@ Jianping Zhang;Manu Shukla
#t 2006
#c 18
#! This paper discusses a research project: rule-based Web user profiling platform. In this platform, usage data are encoded as a sequence of events, each of which represents an action performed by a user on a Web service at a given time. An event template is proposed to define event models for different Web services. The platform is rule-based. Rules define profile metrics and determine how to compute profile metrics from usage events. A prototype of the platform was implemented and was applied to generate profiles from page view events. The major contribution of the work is the rule-based approach to user profiling. It is the rules and the event template that provide the flexibility to allow the platform to be configured for different Web services.

#index 915334
#* Opening the Black Box of Feature Extraction: Incorporating Visualization into High-Dimensional Data Mining Processes
#@ Jianting Zhang;Le Gruenwald
#t 2006
#c 18
#! Feature extraction techniques have been used to handle high-dimensional data and experimental studies often show improved classification accuracies. Unfortunately very few studies provide concrete evidences on the effectiveness of these feature extraction techniques and they largely remain to be black boxes. In this study, we design and implement a visualization prototype system that allows users to look into the classification processes, explore the links among the original and extracted features in different classifiers, examine why and how an instance is correctly or incorrectly classified. We demonstrate the prototype's capabilities by combining a feature extraction method based on hierarchical feature space clustering with J48 decision tree classifiers and perform experiments on a real hyperspectral remote sensing image dataset.

#index 915335
#* Semantic Smoothing for Model-based Document Clustering
#@ Xiaodan Zhang;Xiaohua Zhou;Xiaohua Hu
#t 2006
#c 18
#! A document is often full of class-independent "general" words and short of class-specific 'core" words, which leads to the difficulty of document clustering. We argue that both problems will be relieved after suitable smoothing of document models in agglomerative approaches and of cluster models in partitional approaches, and hence improve clustering quality. To the best of our knowledge, most model-based clustering approaches use Laplacian smoothing to prevent zero probability while most similarity-based approaches employ the heuristic TF*IDF scheme to discount the effect of "general" words. Inspired by a series of statistical translation language model for text retrieval, we propose in this paper a novel smoothing method referred to as context-sensitive semantic smoothing for document clustering purpose. The comparative experiment on three datasets shows that model-based clustering approaches with semantic smoothing is effective in improving cluster quality.

#index 915336
#* Corrective Classification: Classifier Ensembling with Corrective and Diverse Base Learners
#@ Yan Zhang;Xingquan Zhu;Xindong Wu
#t 2006
#c 18
#! Empirical studies on supervised learning have shown that ensembling methods lead to a model superior to the one built from a single learner under many circumstances [1], especially when learning from imperfect, such as biased or noise infected, information sources. In this paper, we provide a novel corrective classification (C2) design, which incorporates error detection, data cleansing and Bootstrap sampling to construct base learners that constitute the classifier ensemble. The essential goal is to reduce noise impacts and eventually enhance the learners built from noise corrupted data. We further analyze the importance of both the accuracy and diversity of base learners in ensembling, in order to shed some light on the mechanism under which C2 works. Experimental comparisons will demonstrate that C2 is not only superior to the learner built from the original noisy sources, but also more reliable than Bagging [2] or the Aggressive Classifier Ensemble (ACE) [3], which are two degenerate components/variants of C2.

#index 915337
#* Speedup Clustering with Hierarchical Ranking
#@ Jianjun Zhou;Joerg Sander
#t 2006
#c 18
#! Many clustering algorithms in particular hierarchical clustering algorithms do not scale-up well for large data-sets especially when using an expensive distance function. In this paper, we propose a novel approach to perform approximate clustering with high accuracy. We introduce the concept of a pairwise hierarchical ranking to efficiently determine close neighbors for every data object. Empirical results on synthetic and real-life data show a speedup of up to two orders of magnitude over OPTICS while maintaining a high accuracy and up to one order of magnitude over the previously proposed DATA BUBBLES method, which also tries to speedup OPTICS by trading accuracy for speed.

#index 915338
#* Query-Sensitive Similarity Measure for Content-Based Image Retrieval
#@ Zhi-Hua Zhou;Hong-Bin Dai
#t 2006
#c 18
#! Similarity measure is one of the keys of a high-performance content-based image retrieval (CBIR) system. Given a pair of images, existing similarity measures usually produce a static and constant similarity score. However, an image can usually be perceived with different meanings and therefore, the similarity between the same pair of images may change when the concept being queried changes. This paper proposes a query-sensitive similarity measure, Qsim, which takes the concept being queried into account in measuring image similarities, by exploiting the query image as well as the images labeled by user in the relevance feedback process. Experimental comparisons to state-of-the-art techniques show that Qsim has superior performance.

#index 915339
#* The PDD Framework for Detecting Categories of Peculiar Data
#@ Mahesh Shrestha;Howard J. Hamilton;Yiyu Yao;Ken Konkel;Liqiang Geng
#t 2006
#c 18
#! Peculiar data are objects that are relatively few in number and significantly different from the other objects in a data set. In this paper, we propose the PDD framework for detecting multiple categories of peculiar data. This framework provides an extensible set of perspectives for viewing data, currently including viewing data as a set of records, attributes, frequencies, intervals, sequences, or sequences of changes. By using these six views of the data, multiple categories of peculiar data can be detected to reveal different aspects of the data. For each view, the framework provides an extensible set of peculiarity measures to detect outliers and other kinds of peculiar data. The PDD framework has been implemented for Oracle and Access. Experiments are reported for data sets concerning Regina weather and NHL hockey.

#index 915340
#* Entity Resolution with Markov Logic
#@ Parag Singla;Pedro Domingos
#t 2006
#c 18
#! Entity resolution is the problem of determining which records in a database refer to the same entities, and is a crucial and expensive step in the data mining process. Interest in it has grown rapidly in recent years, and many approaches have been proposed. However, they tend to address only isolated aspects of the problem, and are often ad hoc. This paper proposes a well-founded, integrated solution to the entity resolution problem based on Markov logic. Markov logic combines first-order logic and probabilistic graphical models by attaching weights to first-order formulas, and viewing them as templates for features of Markov networks. We show how a number of previous approaches can be formulated and seamlessly combined in Markov logic, and how the resulting learning and inference problems can be solved efficiently. Experiments on two citation databases show the utility of this approach, and evaluate the contribution of the different components.

#index 915341
#* Boosting Kernel Models for Regression
#@ Ping Sun;Xin Yao
#t 2006
#c 18
#! This paper proposes a general boosting framework for combining multiple kernel models in the context of both classification and regression problems. Our main approach is built on the idea of gradient boosting together with a new regularization scheme and aims at reducing the cubic com- plexity of training kernel models. We focus mainly on using the proposed boosting framework to combine kernel ridge regression (KRR) models for regression tasks. Numerical experiments on four large-scale data sets have shown that boosting multiple small KRR models is superior to training a single large KRR model on both improving generalization performance and reducing computational requirements.

#index 915342
#* Boosting for Learning Multiple Classes with Imbalanced Class Distribution
#@ Yanmin Sun;Mohamed S. Kamel;Yang Wang
#t 2006
#c 18
#! Classification of data with imbalanced class distribution has posed a significant drawback of the performance attainable by most standard classifier learning algorithms, which assume a relatively balanced class distribution and equal misclassification costs. This learning difficulty attracts a lot of research interests. Most efforts concentrate on bi-class problems. However, bi-class is not the only scenario where the class imbalance problem prevails. Reported solutions for bi-class applications are not applicable to multi-class problems. In this paper, we develop a cost-sensitive boosting algorithm to improve the classification performance of imbalanced data involving multiple classes. One barrier of applying the cost-sensitive boosting algorithm to the imbalanced data is that the cost matrix is often unavailable for a problem domain. To solve this problem, we apply Genetic Algorithm to search the optimum cost setup of each class. Empirical tests show that the proposed cost-sensitive boosting algorithm improves the classification performances of imbalanced data sets significantly.

#index 915343
#* What is the Dimension of Your Binary Data?
#@ Nikolaj Tatti;Taneli Mielikainen;Aristides Gionis;Heikki Mannila
#t 2006
#c 18
#! Many 0/1 datasets have a very large number of variables; however, they are sparse and the dependency structure of the variables is simpler than the number of variables would suggest. Defining the effective dimensionality of such a dataset is a nontrivial problem. We consider the problem of defining a robust measure of dimension for 0/1 datasets, and show that the basic idea of fractal dimension can be adapted for binary data. However, as such the fractal dimension is difficult to interpret. Hence we introduce the concept of normalized fractal dimension. For a dataset D, its normalized fractal dimension counts the number of independent columns needed to achieve the unnormalized fractal dimension of D. The normalized fractal dimension measures the degree of dependency structure of the data. We study the properties of the normalized fractal dimension and discuss its computation. We give empirical results on the normalized fractal dimension, comparing it against PCA.

#index 915344
#* Fast Random Walk with Restart and Its Applications
#@ Hanghang Tong;Christos Faloutsos;Jia-Yu Pan
#t 2006
#c 18
#! How closely related are two nodes in a graph? How to compute this score quickly, on huge, disk-resident, real graphs? Random walk with restart (RWR) provides a good relevance score between two nodes in a weighted graph, and it has been successfully used in numerous settings, like automatic captioning of images, generalizations to the "connection subgraphs", personalized PageRank, and many more. However, the straightforward implementations of RWR do not scale for large graphs, requiring either quadratic space and cubic pre-computation time, or slow response time on queries. We propose fast solutions to this problem. The heart of our approach is to exploit two important properties shared by many real graphs: (a) linear correlations and (b) blockwise, community-like structure. We exploit the linearity by using low-rank matrix approximation, and the community structure by graph partitioning, followed by the Sherman- Morrison lemma for matrix inversion. Experimental results on the Corel image and the DBLP dabasets demonstrate that our proposed methods achieve significant savings over the straightforward implementations: they can save several orders of magnitude in pre-computation and storage cost, and they achieve up to 150x speed up with 90%+ quality preservation.

#index 915345
#* Anytime Classification Using the Nearest Neighbor Algorithm with Applications to Stream Mining
#@ Ken Ueno;Xiaopeng Xi;Eamonn Keogh;Dah-Jye Lee
#t 2006
#c 18
#! For many real world problems we must perform classification under widely varying amounts of computational resources. For example, if asked to classify an instance taken from a bursty stream, we may have from milliseconds to minutes to return a class prediction. For such problems an anytime algorithm may be especially useful. In this work we show how we can convert the ubiquitous nearest neighbor classifier into an anytime algorithm that can produce an instant classification, or if given the luxury of additional time, can utilize the extra time to increase classification accuracy. We demonstrate the utility of our approach with a comprehensive set of experiments on data from diverse domains.

#index 915346
#* Dirichlet Aspect Weighting: A Generalized EM Algorithm for Integrating External Data Fields with Semantically Structured Queries by Using Gradient Projection Method
#@ Atulya Velivelli;Thomas S. Huang
#t 2006
#c 18
#! In this paper we address the problem of document retrieval with semantically structured queries - queries where each term has a tagged field label. We introduce Dirichlet Aspect Weighting model which integrates terms from external databases into the query language model in a bayesian learning framework. For this model, the dirichlet prior distribution is governed by parameters which depend on the number of fields in the external databases. This model needs additional examples to be augmented to the semantically structured query. These examples are obtained using pseudo relevance feedback. We formulate a loglikelihood function for the Dirichlet Aspect Weighting model and maximize it using a novel Generalized EM algorithm. Comparison of the results of Dirichlet Aspect Weighting model on TREC 2005 Genomics Track dataset with baseline methods using pseudo relevance feedback, while incorporating terms from external databases shows an improvement.

#index 915347
#* Lazy Associative Classification
#@ Adriano Veloso;Wagner Meira Jr.;Mohammed J. Zaki
#t 2006
#c 18
#! Decision tree classifiers perform a greedy search for rules by heuristically selecting the most promising features. Such greedy (local) search may discard important rules. Associative classifiers, on the other hand, perform a global search for rules satisfying some quality constraints (i.e., minimum support). This global search, however, may generate a large number of rules. Further, many of these rules may be useless during classification, and worst, important rules may never be mined. Lazy (non-eager) associative classification overcomes this problem by focusing on the features of the given test instance, increasing the chance of generating more rules that are useful for classifying the test instance. In this paper we assess the performance of lazy associative classification. First we demonstrate that an associative classifier performs no worse than the corresponding decision tree classifier. Also we demonstrate that lazy classifiers outperform the corresponding eager ones. Our claims are empirically confirmed by an extensive set of experimental results. We show that our proposed lazy associative classifier is responsible for an error rate reduction of approximately 10% when compared against its eager counterpart, and for a reduction of 20% when compared against a decision tree classifier. A simple caching mechanism makes lazy associative classification fast, and thus improvements in the execution time are also observed.

#index 915348
#* Geometrically Inspired Itemset Mining
#@ Florian Verhein;Sanjay Chawla
#t 2006
#c 18
#! In our geometric view, an itemset is a vector (itemvector) in the space of transactions. Linear and potentially non-linear transformations can be applied to the itemvectors before mining patterns. Aggregation functions and interestingness measures can be applied to the transformed vectors and pushed inside the mining process. We show that interesting itemset mining can be carried out by instantiating four abstract functions: a transformation (g), an algebraic aggregation operator () and measures (f and F). For Frequent Itemset Mining (FIM), g and F are identity transformations,is intersection and f is the cardinality. Based on this geometric view we present a novel algorithm that uses space linear in the number of 1-itemsets to mine all interesting itemsets in a single pass over the data, with no candidate generation. It scales (roughly) linearly in running time with the number of interesting itemsets. FIM experiments show that it outperforms FPGrowth on realistic datasets above a small support threshold (0.29% and 1.2% in our experiments) .

#index 915349
#* Finding "Who Is Talking to Whom" in VoIP Networks via Progressive Stream Clustering
#@ Olivier Verscheure;Michail Vlachos;Aris Anagnostopoulos;Pascal Frossard;Eric Bouillet;Philip S. Yu
#t 2006
#c 18
#! Technologies that use the Internet network to deliver voice communications have the potential to reduce costs and improve access to communications services around the world. However, these new technologies pose several challenges in terms of confidentiality of the conversations and anonymity of the conversing parties. Call authentication and encryption techniques provide a way to protect confidentiality, while anonymity is typically preserved by an anonymizing service (anonymous call). This work studies the feasibility of revealing pairs of anonymous and encrypted conversing parties (caller/callee pair of streams) by exploiting the vulnerabilities inherent to VoIP systems. In particular, by exploiting the aperiodic inter-departure time of VoIP packets, we can trivialize each VoIP stream into a binary time-series. We first define a simple yet intuitive metric to gauge the correlation between two VoIP binary streams. Then we propose an effective technique that progressively pairs conversing parties with high accuracy and in a limited amount of time. Our metric and method are justified analytically and validated by experiments on a very large standard corpus of conversational speech. We obtain impressively high pairing accuracy that reaches 97% after 5 minutes of voice conversations.

#index 915350
#* Comparison of Descriptor Spaces for Chemical Compound Retrieval and Classification
#@ Nikil Wale;George Karypis
#t 2006
#c 18
#! In recent years the development of computational techniques that build models to correctly assign chemical compounds to various classes or to retrieve potential drug-like compounds has been an active area of research. Many of the best-performing techniques for these tasks utilize a descriptor-based representation of the compound that captures various aspects of the underlying molecular graph's topology. In this paper we compare different set of descriptors that are currently used for chemical compound classification. In this process, we also introduce four different descriptors derived from all connected fragments present in the molecular graphs. In addition, we introduce an extension to existing vector-based kernel functions to take into account the length of the fragments present in the descriptors. We experimentally evaluate the performance of the previously introduced and the new descriptors in the context of SVM-based classification and ranked-retrieval on 28 classification and retrieval problems derived from 18 datasets. Our experiments show that for both these tasks, the new descriptors consistently and statistically outperform previously developed schemes based on the widely used fingerprint- and Maccs keys-based descriptors, as well as recently introduced descriptors obtained by mining and analyzing the structure of the molecular graphs.

#index 915351
#* Regularized Least Absolute Deviations Regression and an Efficient Algorithm for Parameter Tuning
#@ Li Wang;Michael D. Gordon;Ji Zhu
#t 2006
#c 18
#! Linear regression is one of the most important and widely used techniques for data analysis. However, sometimes people are not satisfied with it because of the following two limitations: 1) its results are sensitive to outliers, so when the error terms are not normally distributed, especially when they have heavy-tailed distributions, linear regression often works badly; 2) its estimated coefficients tend to have high variance, although their bias is low. To reduce the influence of outliers, robust regression models were developed. Least absolute deviation (LAD) regression is one of them. LAD minimizes the mean absolute errors, instead of mean squared errors, so its results are more robust. To address the second limitation, shrinkage methods were proposed, which add a penalty on the size of the coefficients. The LASSO is one of these methods and it uses the L1-norm penalty, which not only reduces the prediction error and the variance of estimated coefficients, but also provides an automatic feature selection function. In this paper, we propose the regularized least absolute deviation (RLAD) regression model, which combines the nice features of the LAD and the LASSO together. The RLAD is a regularization method, whose objective function has the form of "loss + penalty." The "loss" is the sum of the absolute deviations and the "penalty" is the L1-norm of the coefficient vector. Furthermore, to facilitate parameter tuning, we develop an efficient algorithm which can solve the entire regularization path in one pass. Simulations with various settings are performed to demonstrate its performance. Finally, we apply the algorithm to solve the image reconstruction problem and find interesting results.

#index 915352
#* LOCI: Load Shedding through Class-Preserving Data Acquisition
#@ Peng Wang;Haixun Wang;Wei Wang;Baile Shi;Philip S. Yu
#t 2006
#c 18
#! An avalanche of data available in the stream form is overstretching our data analyzing ability. In this paper, we propose a novel load shedding method that enables fast and accurate stream data classification. We transform input data so that its class information concentrates on a few features, and we introduce a progressive classifier that makes prediction with partial input. We take advantage of stream data's temporal locality . for example, readings from a temperature sensor usually do not change dramatically over a short period of time . for load shedding. We first show that temporal locality of the original data is preserved by our transform, then we utilize positive and negative knowledge about the data (which is of much smaller size than the data itself) for classification. We employ both analytical and empirical analysis to demonstrate the advantage of our approach.

#index 915353
#* SAXually Explicit Images: Finding Unusual Shapes
#@ Li Wei;Eamonn Keogh;Xiaopeng Xi
#t 2006
#c 18
#! Over the past three decades, there has been a great deal of research on shape analysis, focusing mostly on shape indexing, clustering, and classification. In this work, we introduce the new problem of finding shape discords, the most unusual shapes in a collection. We motivate the problem by considering the utility of shape discords in diverse domains including zoology, anthropology, and medicine. While the brute force search algorithm has quadratic time complexity, we avoid this by using locality-sensitive hashing to estimate similarity between shapes which enables us to reorder the search more efficiently. An extensive experimental evaluation demonstrates that our approach can speed up computation by three to four orders of magnitude.

#index 915354
#* A Novel Scalable Algorithm for Supervised Subspace Learning
#@ Jun Yan;Ning Liu;Benyu Zhang;Qiang Yang;Shuicheng Yan;Zheng Chen
#t 2006
#c 18
#! Subspace learning approaches aim to discover important statistical distribution on lower dimensions for high dimensional data. Methods such as Principal Component Analysis (PCA) do not make use of the class information, and Linear Discriminant Analysis (LDA) could not be performed efficiently in a scalable way. In this paper, we propose a novel highly scalable supervised subspace learning algorithm called as Supervised Kampong Measure (SKM). It assigns data points as close as possible to their corresponding class mean, simultaneously assigns data points to be as far as possible from the other class means in the transformed lower dimensional subspace. Theoretical derivation shows that our algorithm is not limited by the number of classes or the singularity problem faced by LDA. Furthermore, our algorithm can be executed in an incremental manner in which learning is done in an online fashion as data streams are received. Experimental results on several datasets, including a very large text data set RCV1, show the outstanding performance of our proposed algorithm on classification problems as compared to PCA, LDA and a popular feature selection approach, Information Gain (IG).

#index 915355
#* A Novel Method for Detecting Outlying Subspaces in High-dimensional Databases Using Genetic Algorithm
#@ Ji Zhang;Qigang Gao;Hai Wang
#t 2006
#c 18
#! Detecting outlying subspaces is a relatively new research problem in outlier-ness analysis for high-dimensional data. An outlying subspace for a given data point p is the subspace in which p is an outlier. Outlying subspace detection can facilitate a better characterization process for the detected outliers. It can also enable outlier mining for highdimensional data to be performed more accurately and efficiently. In this paper, we proposed a new method using genetic algorithm paradigm for searching outlying subspaces efficiently. We developed a technique for efficiently computing the lower and upper bounds of the distance between a given point and its kth nearest neighbor in each possible subspace. These bounds are used to speed up the fitness evaluation of the designed genetic algorithm for outlying subspace detection. We also proposed a random sampling technique to further reduce the computation of the genetic algorithm. The optimal number of sampling data is specified to ensure the accuracy of the result. We show that the proposed method is efficient and effective in handling outlying subspace detection problem by a set of experiments conducted on both synthetic and real-life datasets.

#index 915356
#* Discovering Unrevealed Properties of Probability Estimation Trees: On Algorithm Selection and Performance Explanation
#@ Kun Zhang;Wei Fan;Bill Buckles;Xiaojing Yuan;Zujia Xu
#t 2006
#c 18
#! There has been increasing interest to design better probability estimation trees, or PETs, for ranking and probability estimation. Capable of generating class membership probabilities, PETs have been shown to be highly accurate and flexible for many difficult problems, such as cost-sensitive learning and matching skewed distributions. There are a large number of PET algorithms available, and about ten of them are well-known. This large number provides an advantage, but it also creates confusion in practice. One would ask "given a new dataset, which algorithm to choose and what performance to expect and not to expect? What are the reasons to explain either good or bad performance under different situations?" In this paper, we systematically, for the first time, answer these important questions by conducting a large-scale empirical comparison of five popular PETs by examining their AUC, MSE and error rate "learning curves" (instead of training-test split based cross-validation). Using the maximum AUC achieved by any of the evaluated probability estimation tree algorithms, we demonstrate that the preference of a probability estimation tree on different evaluation metrics can be accurately characterized by the "signal-noise separability" of the dataset, as well as some other observable statistics of the dataset explained further in the paper. Moreover, in order to understand their relative performance, many important and previously unrevealed properties of each PET's mechanism and heuristics are analyzed and evaluated. Importantly, a practical guide for choosing the most appropriate PET algorithm given a new data mining problem is provided.

#index 915357
#* Forecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions
#@ Kun Zhang;Wei Fan;Xiaojing Yuan;Ian Davidson;Xiangshang Li
#t 2006
#c 18
#! Much work on skewed, stochastic, high dimensional, and biased datasets usually implicitly solve each problem separately. Recently, we have been approached by Texas Commission on Environmental Quality (TCEQ) to help them build highly accurate ozone level alarm forecasting models for the Houston area, where these technical difficulties come together in one single problem. Key characteristics of this problem that are challenging and interesting include: 1) the dataset is sparse (72 features, and 2% or 5% positives depending on the criteria of "ozone days"), 2) evolving over time from year to year, 3) limited in collected data size (7 years or around 2500 data entries), 4) contains a large number of irrelevant features, 5) is biased in terms of "sample selection bias", and 6) the true model is stochastic as a function of measurable factors. Besides solving a difficult application problem, this dataset offers a unique opportunity to explore new and existing data mining techniques, and to provide experience and guidance for similar problems. Our main technical focus addresses on how to estimate reliable probability given both sample selection bias and a large number of irrelevant features, and how to choose the most reliable decision threshold to predict the unknown future with different distribution. On the application side, the prediction accuracy of our approach is 20% higher in recall (correctly detects 1 to 3 more ozone days, depending on the year) and 10% higher in precision (15 to 30 fewer false alarm days per year) than state-of-the-art methods used by air quality control scientists, and these results are significant for TCEQ.

#index 915358
#* Identifying Follow-Correlation Itemset-Pairs
#@ Shichao Zhang;Jilian Zhang;Xiaofeng Zhu;Zifang Huang
#t 2006
#c 18
#! An association rule A\to B is useful to predict that B will likely occur when A occurs. This is a classical association rule. In real world applications, such as bioinformatics and medical research, there are many follow correlations between itemsets A and B: B likely occurs n times after A occurred m times, wrote to \le A^m , B^n \ge. We refer to this follow-correlation as P3.1 itemset-pairs because \le A^3 , B^1\ge like that in Example 2 should be uninterested in association analysis. This paper designs an efficient algorithm for identifying P3.1 itemset-pairs in sequential data. We experimentally evaluate our approach, and demonstrate that the proposed approach is efficient and promising.

#index 915359
#* On the Lower Bound of Local Optimums in K-Means Algorithm
#@ Zhenjie Zhang;Bing Tian Dai;Anthony K. H. Tung
#t 2006
#c 18
#! The k-means algorithm is a popular clustering method used in many different fields of computer science, such as data mining, machine learning and information retrieval. However, the k-means algorithm is very likely to converge to some local optimum which is much worse than the desired global optimal solution. To overcome this problem, current k-means algorithm and its variants usually run many times with different initial centers to avoid being trapped in local optimums that are of unacceptable quality. In this paper, we propose an efficient method to compute a lower bound on the cost of the local optimum from the current center set. After every k-means iteration, k-means algorithm can halt the procedure if the lower bound of the cost at the future local optimum is worse than the best solution that has already been computed so far. Although such a lower bound computation incurs some extra time consumption in the iterations, extensive experiments on both synthetic and real data sets show that this method can greatly prune the unnecessary iterations and improve the efficiency of the algorithm in most of the data sets, especially with high dimensionality and large k.

#index 915360
#* Fast On-line Kernel Learning for Trees
#@ Fabio Aiolli;Giovanni Da San Martino;Alessandro Sperduti;Alessandro Moschitti
#t 2006
#c 18
#! Kernel methods have been shown to be very effective for applications requiring the modeling of structured objects. However kernels for structures usually are too computational demanding to be applied to complex learning algorithms, e.g. Support Vector Machines. Consequently, in order to apply kernels to large amount of structured data, we need fast on-line algorithms along with an efficiency optimization of kernel-based computations. In this paper, we optimize this computation by representing set of trees by minimal Direct Acyclic Graphs (DAGs) allowing us i) to reduce the storage requirements and ii) to speed up the evaluation on large number of trees as it can be done 'one-shot' by computing kernels over DAGs. The experiments on predicate argument subtrees from PropBank data show that substantial computational savings can be obtained for the perceptron algorithm.

#index 915361
#* bitSPADE: A Lattice-based Sequential Pattern Mining Algorithm Using Bitmap Representation
#@ Sujeevan Aseervatham;Aomar Osmani;Emmanuel Viennet
#t 2006
#c 18
#! Sequential pattern mining allows to discover temporal relationship between items within a database. The patterns can then be used to generate association rules. When the databases are very large, the execution speed and the memory usage of the mining algorithm become critical parameters. Previous research has focused on either one of the two parameters. In this paper, we present bitSPADE, a novel algorithm that combines the best features of SPAM, one of the fastest algorithm, and SPADE, one of the most memory efficient algorithm. Moreover, we introduce a new pruning strategy that enables bitSPADE to reach high performances. Experimental evaluations showed that bitSPADE ensures an efficient tradeoff between speed and memory usage by outperforming SPADE by both speed and memory usage factors more than 3.4 and SPAM by a memory consumption factor up to more than an order of magnitude.

#index 915362
#* Decision Trees for Functional Variables
#@ Suhrid Balakrishnan;David Madigan
#t 2006
#c 18
#! Classification problems with functionally structured in- put variables arise naturally in many applications. In a clinical domain, for example, input variables could include a time series of blood pressure measurements. In a financial setting, different time series of stock returns might serve as predictors. In an archaeological application, the 2-D pro- file of an artifact may serve as a key input variable. In such domains, accuracy of the classifier is not the only reason- able goal to strive for; classifiers that provide easily inter- pretable results are also of value. In this work, we present an intuitive scheme for extending decision trees to handle functional input variables. Our results show that such deci- sion trees are both accurate and readily interpretable.

#index 915363
#* Mining Latent Associations of Objects Using a Typed Mixture Model--A Case Study on Expert/Expertise Mining
#@ Shenghua Bao;Yunbo Cao;Bing Liu;Yong Yu;Hang Li
#t 2006
#c 18
#! This paper studies the problem of discovering latent associations among objects in text documents. Specifically, given two sets of objects and various types of co-occurrence data concerning the objects existing in texts, we aim to discover the hidden or latent associative relationships between the two sets of objects. Existing methods are not directly applicable as they are unable to consider all this information. For example, the probabilistic mixture model called Separable Mixture Model (SMM) proposed by Hofmann can use only one type of co-occurrences to mine latent associations. This paper proposes a more general probabilistic mixture model called the Typed Separable Mixture Model (TSMM), which is able to use all types of co-occurrences within a single framework. Experimental results based on the expert/expertise mining task show that TSMM outperforms SMM significantly.

#index 915364
#* Semantic Kernels for Text Classification Based on Topological Measures of Feature Similarity
#@ Stephan Bloehdorn;Roberto Basili;Marco Cammisa;Alessandro Moschitti
#t 2006
#c 18
#! In this paper we propose a new approach to the design of semantic smoothing kernels for text classification. These kernels implicitly encode a superconcept expansion in a semantic network using well-known measures of term similarity. The experimental evaluation on two different datasets indicates that our approach consistently improves performance in situations of little training data and data sparseness.

#index 915365
#* Mining Maximal Generalized Frequent Geographic Patterns with Knowledge Constraints
#@ Vania Bogorny;Joao Valiati;Sandro Camargo;Paulo Engel;Bart Kuijpers;Luis O. Alvares
#t 2006
#c 18
#! In frequent geographic pattern mining a large amount of patterns is well known a priori. This paper presents a novel approach for mining frequent geographic patterns without associations that are previously known as non-interesting. Geographic dependences are eliminated during the frequent set generation using prior knowledge. After the dependence elimination maximal generalized frequent sets are computed to remove redundant frequent sets. Experimental results show a significant reduction of both the number of frequent sets and the computational time for mining maximal frequent geographic patterns.

#index 915366
#* Pattern Mining in Frequent Dynamic Subgraphs
#@ Karsten M. Borgwardt;Hans-Peter Kriegel;Peter Wackersreuther
#t 2006
#c 18
#! Graph-structured data is becoming increasingly abundant in many application domains. Graph mining aims at finding interesting patterns within this data that represent novel knowledge. While current data mining deals with static graphs that do not change over time, coming years will see the advent of an increasing number of time series of graphs. In this article, we investigate how pattern mining on static graphs can be extended to time series of graphs. In particular, we are considering dynamic graphs with edge insertions and edge deletions over time. We define frequency in this setting and provide algorithmic solutions for finding frequent dynamic subgraph patterns. Existing subgraph mining algorithms can be easily integrated into our framework to make them handle dynamic graphs. Experimental results on real-world data confirm the practical feasibility of our approach.

#index 932095
#* Advances in Data Mining: Applications in Medicine, Web Mining, Marketing, Image and Signal Mining6th Industrial Conference on Data Mining, ICDM 2006, Leipzig, ... (Lecture Notes in Computer Science)
#@ Petra Perner
#t 2006
#c 18

#index 1103378
#* Proceedings of the 8th industrial conference on Advances in Data Mining: Medical Applications, E-Commerce, Marketing, and Theoretical Aspects
#@ Petra Perner
#t 2008
#c 18

#index 1103379
#* Prototypes for Medical Case-Based Applications
#@ Rainer Schmidt;Tina Waligora;Olga Vorobieva
#t 2008
#c 18
#% 2768
#% 373871
#% 485782
#% 490464
#% 494252
#% 1099653
#% 1273557
#% 1389760
#% 1727840
#! Already in the early stages of Case-Based Reasoning prototypes were considered as an interesting technique to structure the case base and to fill the knowledge gap between single cases and general knowledge. Unfortunately, later on prototypes never became a hot topic within the CBR community. However, for medical applications they have been used rather regularly, because they correspond to the reasoning of doctors in a natural way. In this paper, we illustrate the role of prototypes by application programs, which cover all typical medical tasks: diagnosis, therapy, and course analysis.

#index 1103380
#* Hopfield Networks in Relevance and Redundancy Feature Selection Applied to Classification of Biomedical High-Resolution Micro-CT Images
#@ Benjamin Auffarth;Maite López;Jesús Cerquides
#t 2008
#c 18
#% 5182
#% 197394
#% 420146
#% 464434
#% 564044
#% 717417
#% 769966
#% 814023
#% 950267
#% 961134
#% 999687
#% 1041316
#% 1558464
#! We study filter---based feature selection methods for classification of biomedical images. For feature selection, we use two filters -- a relevance filter which measures usefulness of individual features for target prediction, and a redundancy filter, which measures similarity between features. As selection method that combines relevance and redundancy we try out a Hopfield network. We experimentally compare selection methods, running unitary redundancy and relevance filters, against a greedy algorithm with redundancy thresholds [9], the min-redundancy max-relevance integration [8,23,36], and our Hopfield network selection. We conclude that on the whole, Hopfield selection was one of the most successful methods, outperforming min-redundancy max-relevance when more features are selected.

#index 1103381
#* Modelling Medical Time Series Using Grammar-Guided Genetic Programming
#@ Fernando Alonso;Loïc Martínez;Aurora Pérez;Agustín Santamaría;Juan Pedro Valente
#t 2008
#c 18
#% 124073
#% 389460
#% 477935
#% 490987
#% 662750
#% 686757
#% 723484
#% 777162
#% 979909
#% 1562029
#% 1657276
#% 1777132
#! The analysis of time series is extremely important in the field of medicine, because this is the format of many medical data types. Most of the approaches that address this problem are based on numerical algorithms that calculate distances, clusters, reference models, etc. However, a symbolic rather than numerical analysis is sometimes needed to search for the characteristics of time series. Symbolic information helps users to efficiently analyse and compare time series in the same or in a similar way as a domain expert would. This paper describes the definition of the symbolic domain, the process of converting numerical into symbolic time series and a distance for comparing symbolic temporal sequences. Then, the paper focuses on a method to create the symbolic reference model for a certain population using grammar-guided genetic programming. The work is applied to the isokinetics domain within an application called I4.

#index 1103382
#* Data Mining with Neural Networks for Wheat Yield Prediction
#@ Georg Ruß;Rudolf Kruse;Martin Schneider;Peter Wagner
#t 2008
#c 18
#% 91868
#% 132676
#% 177728
#% 356892
#! Precision agriculture (PA) and information technology (IT) are closely interwoven. The former usually refers to the application of nowadays' technology to agriculture. Due to the use of sensors and GPS technology, in today's agriculture many data are collected. Making use of those data via IT often leads to dramatic improvements in efficiency. For this purpose, the challenge is to change these raw data into useful information. In this paper we deal with neural networks and their usage in mining these data. Our particular focus is whether neural networks can be used for predicting wheat yield from cheaply-available in-season data. Once this prediction is possible, the industrial application is quite straightforward: use data mining with neural networks for, e.g., optimizing fertilizer usage, in economic or environmental terms.

#index 1103383
#* Experiences Using Clustering and Generalizations for Knowledge Discovery in Melanomas Domain
#@ A. Fornells;E. Armengol;E. Golobardes;S. Puig;J. Malvehy
#t 2008
#c 18
#% 328944
#% 356892
#% 391311
#% 549578
#% 926881
#% 1099622
#% 1223010
#% 1345404
#! One of the main goals in prevention of cutaneous melanoma is early diagnosis and surgical excision. Dermatologists work in order to define the different skin lesion types based on dermatoscopic features to improve early detection. We propose a method called SOMEX with the aim of helping experts to improve the characterization of dermatoscopic melanoma types. SOMEX combines clustering and generalization to perform knowledge discovery. First, SOMEX uses Self-Organizing Maps to identify groups of similar melanoma. Second, SOMEX builds general descriptions of clusters applying the anti-unification concept. These descriptions can be interpreted as explanations of groups of melanomas. Experiments prove that explanations are very useful for experts to reconsider the characterization of melanoma classes.

#index 1103384
#* Noisy Image Segmentation by a Robust Clustering Algorithm Based on DC Programming and DCA
#@ Le Thi Hoai An;Le Hoai Minh;Nguyen Trong Phuc;Pham Dinh Tao
#t 2008
#c 18
#% 374537
#% 416553
#% 720742
#% 770766
#% 875247
#% 875970
#% 1786775
#! We present a fast and robust algorithm for image segmentation problems via Fuzzy C-Means (FCM) clustering model. Our approach is based on DC (Difference of Convex functions) programming and DCA (DC Algorithms) that have been successfully applied in a lot of various fields of Applied Sciences, including Machine Learning. In an elegant way, the FCM model is reformulated as a DC program for which a very simple DCA scheme is investigated. For accelerating the DCA, an alternative FCM-DCA procedure is developed. Moreover, in the case of noisy images, we propose a new model that incorporates spatial information into the membership function for clustering. Experimental results on noisy images have illustrated the effectiveness of the proposed algorithm and its superiority with respect to the standard FCM algorithm in both running-time and quality of solutions.

#index 1103385
#* An Application for Electroencephalogram Mining for Epileptic Seizure Prediction
#@ Bruno Direito;António Dourado;Francisco Sales;Marco Vieira
#t 2008
#c 18
#% 1398311
#! A computational framework to support seizure predictions in epileptic patients is presented. It is based on mining and knowledge discovery in Electroencephalogram (EEG) signal. A set of features is extracted and classification techniques are then used to eventually derive an alarm signal predicting a coming seizure. The epileptic patient may then take steps in order to prevent accidents and social exposure.

#index 1103386
#* An Infrastructure for Mining Medical Multimedia Data
#@ Sara Colantonio;Ovidio Salvetti;Marco Tampucci
#t 2008
#c 18
#% 838668
#% 927966
#! Biomedical research processes related to disease diagnosis, prognosis and monitoring would great benefit from advanced tools able not exclusively to store and manage multimodal data but also to process and extract significant relations and then novel knowledge from them. Indeed, making a prediction on a disease outcome usually requires considering heterogeneous pieces of information obtained from several sources which should be compared and related. Mining medical multimedia objects is aimed at discovering and making available the hidden useful knowledge embedded in collections of data and is, then, of key importance for supporting clinical decision-making. In this paper, we report current results of a medical warehouse we are developing in an integrated environment for mining clinical data acquired by different media. In particular, focus is herein given to the infrastructure of the warehouse and its current functionalities not limited to storage and management but including intelligent representation and annotation of multimedia objects.

#index 1103387
#* Realizing Modularized Knowledge Models for Heterogeneous Application Domains
#@ Klaus-Dieter Althoff;Kerstin Bach;Meike Reichle
#t 2008
#c 18
#% 492194
#% 492375
#% 494597
#% 866963
#% 1705998
#! This paper addresses the realization of modularized knowledge models within a heterogeneous application domain using an existing knowledge management tool. The application domain we deal with is travel medicine, which combines medical aspects with geography, climate, holiday activities and associated traveling conditions. In this paper we present the application's requirements and show how knowledge models can be developed using an industrial strength application. Furthermore we present the challenges of a knowledge model based on multi-case bases whereas each case base represents its own area of expertise. Hence, we introduce our knowledge model for the travel medicine application and exemplify the implementation of typical data types and similarity measures.

#index 1103388
#* GEP-Induced Expression Trees as Weak Classifiers
#@ Joanna Jedrzejowicz;Piotr Jedrzejowicz
#t 2008
#c 18
#% 132938
#% 156421
#% 168855
#% 192731
#% 235377
#% 424997
#% 465908
#% 729437
#% 733620
#% 886785
#% 916867
#% 950502
#% 961149
#% 1037034
#% 1051514
#% 1693317
#% 1693386
#% 1777281
#! The paper proposes applying Gene Expression Programming (GEP) to induce expression trees used subsequently as weak classifiers. Two techniques of constructing ensemble classifiers from weak classifiers are investigated in the paper. The working hypothesis of the paper can be stated as follows: given a set of classifiers generated through applying gene expression programming method and using some variants of boosting technique, one can construct the ensemble producing effectively high quality classification results. A detailed description of the proposed GEP implementation generating classifiers in the form of expression trees is followed by the report on AdaBoost and boosting algorithms used to construct an ensemble classifier. To validate the approach computational experiment involving several benchmark datasets has been carried out. Experiment results show that using GEP-induced expression trees as weak classifiers allows for construction of a high quality ensemble classifier outperforming, in terms of classification accuracy, many other recently published solutions.

#index 1103389
#* Projection with Double Nonlinear Integrals for Classification
#@ Jinfeng Wang;Kwongsak Leung;Kinhong Lee;Zhenyuan Wang
#t 2008
#c 18
#% 160813
#% 170745
#% 207935
#% 281579
#% 396114
#% 787659
#% 1015675
#% 1788308
#! In this study, a new classification model based on projection with Double Nonlinear Integrals is proposed. There exist interactions among predictive attributes towards the decisive attribute. The contribution rate of each combination of predictive attributes, including each singleton, towards the decisive attribute can be re presented by a fuzzy measure. We use Double Nonlinear Integrals with respect to the signed fuzzy measure to project data to 2-Dimension space. Then classify the virtual value in the 2-D space projected by Nonlinear Integrals. In our experiments, we compare our classifier based on projection with Double Nonlinear Integrals with the classical method- Naïve Bayes. The results show that our classification model is better than Naïve Bayes.

#index 1103390
#* Local Modelling in Classification
#@ Gero Szepannek;Julia Schiffner;Julie Wilson;Claus Weihs
#t 2008
#c 18
#% 191910
#% 272995
#% 361966
#% 387941
#% 400847
#% 450303
#% 1727222
#% 1727240
#% 1860838
#! In classification tasks it may sometimes not be meaningful to build single rules on the whole data. This may especially be the case if the classes are composed of several subclasses. Several common as well as recent issues are presented to solve this problem. As it can e.g. be seen in Weihs et al. (2006) there may result strong benefit from such local modelling. All presented methods are evaluated and compared on four real-world classification problems in order to obtain some overall ranking of their performance following an idea of Hornik and Meyer (2007).

#index 1103391
#* Improving Imbalanced Multidimensional Dataset Learner Performance with Artificial Data Generation: Density-Based Class-Boost Algorithm
#@ Ladan Malazizi;Daniel Neagu;Qasim Chaudhry
#t 2008
#c 18
#% 290482
#% 349598
#% 765522
#% 1019070
#! Improving the learner performance over imbalanced and multidimensional datasets raises a challenging task for machine learning community. Although a salient characteristic in data modeling is the amount of data provided for the learner, the proportional distribution of that data in each class has also direct relationship with the classifier performance. In imbalanced datasets when data is distributed into different classes, various in size, understanding of data structure and characteristics plays an important role in improving the learner accuracy. In this paper we introduce a new approach that combines the information gained from traditional classification algorithms, confusion matrix parameters and density-based clustering to generate artificial data in order to increase the learner performance. First a classification algorithm is run on training data. Then the confusion matrix is studied and the True Positive (TP) rate of each class is measured. The class with the lowest TP rate is selected. Using density-based clustering we identify the centroid of the class and measure the samples distribution in multidimensional space in the next step. With the values gained from Probability Density Function estimations for clusters, extra samples are generated and added to the original dataset to rebalance the class proportion and the weight of different classes in the whole training set. Our method has been evaluated in terms of TP, F-Measure and also overall accuracy against a number of Demetra (toxicology) and UCI datasets. Our method provides an insight view of the data structure and characteristics in order to identify how much and where the data need to be added for increasing the classification accuracy of the learner.

#index 1103392
#* CPL Clustering with Feature Costs
#@ Leon Bobrowski
#t 2008
#c 18
#% 51647
#% 111349
#% 729437
#% 1048059
#! The convex and piecewise linear (CPL) criterion functions can be specified for the purposes of data clustering or unsupervised learning. The data set is in this case composed of feature vectors without additional knowledge in the form of vectors categories. The minimisation of the CPLcriterion functions allows for discovering linear dependence among feature vectors from a given data set. Introducing feature costs to the CPLcriterion functions allows to combine linear dependence examination with feature selection process.

#index 1103393
#* Proceedings of the 8th industrial conference on Advances in Data Mining: Medical Applications, E-Commerce, Marketing, and Theoretical Aspects
#@ Petra Perner
#t 2008
#c 18

#index 1103394
#* Relative Linkage Disequilibrium: A New Measure for Association Rules
#@ Ron Kenett;Silvia Salini
#t 2008
#c 18
#% 152934
#% 227917
#% 280433
#% 420112
#% 452846
#% 727897
#% 751575
#% 1727220
#! Association rules are one of the most popular unsupervised data mining methods. Once obtained, the list of association rules extractable from a given dataset is compared in order to evaluate their importance level. The measures commonly used to assess the strength of an association rule are the indexes of support, confidence, and the lift.Relative Linkage Disequilibrium (RLD) was originally proposed as an approach to analyse both quantitatively and graphically general two way contingency tables. RLD can be considered an adaptation of the lift measure with the advantage that it presents more effectively the deviation of the support of the whole rule from the support expected under independence given the supports of the LHS (A) and the RHS (B). RLD can be interpreted graphically using a simplex representation leading to powerful graphical display of association relationships. Moreover the statistical properties of RLD are known so that confirmatory statistical tests of significance or basic confidence intervals can be applied.This paper will present the properties of RLD in the context of association rules and provide several application examples to demonstrate it's practical advantages.

#index 1103395
#* Weighted Association Rule Mining from Binary and Fuzzy Data
#@ M. Sulaiman Khan;Maybin Muyeba;Frans Coenen
#t 2008
#c 18
#% 152934
#% 246002
#% 280456
#% 310541
#% 478433
#% 481290
#% 641014
#% 729988
#% 998745
#! A novel approach is presented for mining weighted association rules (ARs) from binary and fuzzy data. We address the issue of invalidation of downward closure property (DCP) in weighted association rule mining where each item is assigned a weight according to its significance w.r.t some user defined criteria. Most works on weighted association rule mining so far struggle with invalid downward closure property and some assumptions are made to validate the property. We generalize the weighted association rule mining problem for databases with binary and quantitative attributes with weighted settings. Our methodology follows an Apriori approach [9] and avoids pre and post processing as opposed to most weighted association rule mining algorithms, thus eliminating the extra steps during rules generation. The paper concludes with experimental results and discussion on evaluating the proposed approach.

#index 1103396
#* A Comparative Impact Study of Attribute Selection Techniques on Naïve Bayes Spam Filters
#@ J. R. Méndez;I. Cid;D. Glez-Peña;M. Rocha;F. Fdez-Riverola
#t 2008
#c 18
#% 226099
#% 227486
#% 465754
#% 811373
#% 942167
#% 1290045
#% 1650665
#! The main problem of Internet e-mail service is the massive spam message delivery. Everyday, millions of unwanted and unhelpful messages are received by Internet users annoying their mailboxes. Fortunately, nowadays there are different kinds of filters able to automatically identify and delete most of these messages. In order to reduce the bulk of information to deal with, only distinctive attributes are selected spam and legitimate e-mails. This work presents a comparative study about the performance of five well-known feature selection techniques when they are applied in conjunction with four different types of Naïve Bayes classifier. The results obtained from the experiments carried out show the relevance of choosing an appropriate feature selection technique in order to obtain the most accurate results.

#index 1103397
#* The Impact of Noise in Spam Filtering: A Case Study
#@ I. Cid;L. R. Janeiro;J. R. Méndez;D. Glez-Peña;F. Fdez-Riverola
#t 2008
#c 18
#% 226099
#% 375017
#% 722803
#% 793247
#% 1103396
#% 1290045
#! Unsolicited commercial e-mail (UCE), more commonly known as spam is a growing problem on the Internet. Every day people receive lots of unwanted advertising e-mails that flood their mailboxes. Fortunately, there are several approaches for spam filtering able to detect and automatically delete this kind of messages. However, spammers have adopted some techniques to reduce the effectiveness of these filters by introducing noise in their messages. This work presents a new pre-processing technique for noise identification and reduction, showing preliminary results when it is applied with a Flexible Bayes classifier. The experimental analysis confirms the advantages of using the proposed technique in order to improve spam filters accuracy.

#index 1103398
#* Designing Specific Weighted Similarity Measures to Improve Collaborative Filtering Systems
#@ Laurent Candillier;Frank Meyer;Françoise Fessant
#t 2008
#c 18
#% 173879
#% 202011
#% 330687
#% 342687
#% 452563
#% 734590
#% 734594
#% 813966
#% 860672
#% 989580
#% 1099014
#! The aim of collaborative filteringis to help usersto find itemsthat they should appreciate from huge catalogues. In that field, we can distinguish user-basedfrom item-basedapproaches. The former is based on the notion of user neighbourhoods while the latter uses item neighbourhoods.The definition of similaritybetween users and items is a key problem in both approaches. While traditional similarity measures can be used, we will see in this paper that bespoke ones, that are tailored to type of data that is typically available (i.e. very sparse), tend to lead to better results.Extensive experiments are conducted on two publicly available datasets, called MovieLensand Netflix. Many similarity measures are compared. And we will show that using weighted similarity measures significantly improves the results of both user- and item-based approaches.

#index 1103399
#* Browsing Assistance Service for Intranet Information Systems
#@ Peter Géczy;Noriaki Izumi;Shotaro Akaho;Kôiti Hasida
#t 2008
#c 18
#% 186340
#% 399426
#% 424013
#% 722477
#% 728935
#% 755395
#% 813966
#% 822123
#% 940058
#% 1046782
#% 1339916
#% 1785057
#! Improved usability and efficiency of organizational information systems brings economical benefits to the organization and time benefits to the users. We present a browsing assistance service suitable for the organizational intranet environments. It helps users to shorten their browsing interactions and achieve their goals faster. These benefits are accomplished by providing relevant suggestions on the potential navigation targets of interest to the users. The system design employs the analytics of user browsing behavior and its appropriate segmentation. It efficiently utilizes the initial and the terminal navigation points for providing recommendations. The performance of the system has been evaluated on the real world data of a large scale intranet portal.

#index 1103400
#* WebAngels Filter: A Violent Web Filtering Engine Using Textual and Structural Content-Based Analysis
#@ Radhouane Guermazi;Mohamed Hammami;Abdelmajid Ben Hamadou
#t 2008
#c 18
#% 116149
#% 136350
#% 216500
#% 376266
#% 445567
#% 449588
#% 468271
#% 731003
#% 763774
#% 845226
#% 878932
#% 928640
#% 937949
#% 961629
#% 975161
#% 1067709
#% 1097284
#% 1113343
#! The development of the Web has been paralleled by the proliferation of harmful Web pages content. Using Violent Web page as a case study, we review some existing solutions, then we propose a violent Web content detection and filtering system called "WebAngels filter" which uses textual and structural analysis. "WebAngels filter" has the advantage of combining several data mining algorithms for Web site classification. We present a comparative study of different data mining techniques to block violent contentWeb pages. Also, we discuss how the combination learning based methods can improve filtering performances. Our results show that it can detect and filter violent content effectively.

#index 1103401
#* Mining Unexpected Web Usage Behaviors
#@ Dong (Haoyuan) Li;Anne Laurent;Pascal Poncelet
#t 2008
#c 18
#% 275360
#% 453320
#% 463903
#% 477985
#% 479971
#% 552181
#% 629695
#% 630984
#% 842021
#% 845221
#% 1026524
#% 1113160
#% 1396087
#! Recently, the applications of Web usage mining are more and more concentrated on finding valuable user behaviors from Web navigation record data, where the sequential pattern model has been well adapted. However with the growth of the explored user behaviors, the decision makers will be more and more interested in unexpected behaviors, but not only in those already confirmed. In this paper, we present our approach USER, that finds unexpected sequences and implication rules from sequential data with user defined beliefs, for mining unexpected behaviors from Web access logs. Our experiments with the belief bases constructed from explored user behaviors show that our approach is useful to extract unexpected behaviors for improving the Web site structures and user experiences.

#index 1103402
#* Generalized Graph Matching for Data Mining and Information Retrieval
#@ Alexandra Brügger;Horst Bunke;Peter Dickinson;Kaspar Riesen
#t 2008
#c 18
#% 288990
#% 677512
#% 736538
#% 772884
#% 798044
#% 935148
#% 1705692
#! Graph based data representation offers a convenient possibility to represent entities, their attributes, and their relationships to other entities. Consequently, the use of graph based representation for data mining has become a promising approach to extracting novel and useful knowledge from relational data. In order to check whether a certain graph occurs, as a substructure, within a larger database graph, the widely studied concept of subgraph isomorphism can be used. However, this conventional approach is rather limited. In the present paper the concept of subgraph isomorphism is substantially extended such that it can cope with don't care symbols, variables, and constraints. Our novel approach leads to a powerful graph matching methodology which can be used for advanced graph based data mining.

#index 1103403
#* Contrast-Set Mining of Aircraft Accidents and Incidents
#@ Zohreh Nazeri;Daniel Barbara;Kenneth Jong;George Donohue;Lance Sherry
#t 2008
#c 18
#% 280477
#% 481290
#% 532736
#! Identifying patterns of factors associated with aircraft accidents is of high interest to the aviation safety community. However, accident data is not large enough to allow a significant discovery of repeating patterns of the factors. We applied the STUCCO algorithm to analyze aircraft accident datain contrast to the aircraft incident datain major aviation safety databases and identified factors that are significantly associated with the accidents. The data pertains to accidents and incidents involving commercial flights within the United States. The NTSB accident database was analyzed against four incident databases and the results were compared. We ranked the findings by the Factor Support Ratio, a measure introduced in this work.

#index 1103404
#* Using Data Mining to Build Integrated Discrete Event Simulations
#@ David A. Holland
#t 2008
#c 18
#% 385629
#% 867880
#! Building a system from disparate software requires analysis to establish commonality of code. The ability of a data mining tool to extract repeating functional structures is the first step to reduce exploration, save development time, and re-use software components. This case study looks specifically at the application of graph-based data mining algorithms to code re-factoring. After writing a module to obtain a graph representation of a discrete event model, we built a tool around the University of Washington's SUBDUE package to find recurring patterns of logic. This resulted in cleaner code and increased awareness of code re-use.

#index 1103405
#* Control Charts of Workflows
#@ Calin Ciufudean;Constantin Filote;Dumitru Amarandei
#t 2008
#c 18
#% 962952
#! This paper focuses on the control of the performance characteristics of workflows modeled with stochastic Petri nets (SPN's). This goal is achieved by focusing on a new model for Artificial Social Systems (ASS's) behaviors, and by introducing equivalent transfer functions for SPN's. ASS's exist in practically every multi-agent system, and play a major role in the performance and effectiveness of the agents. This is the reason why we introduce a more suggestive model for ASS's. To model these systems, a class of Petri nets is adopted, and briefly introduced in the paper. This class allows representing the flow of physical resources and control information data of the ASS's components. In the analysis of SPN we use simulations in respect to timing parameters in a generalized semi-Markov process (GSMP). By using existing results on perturbation (e.g., delays in supply with raw materials, derangements of equipments, etc.) analysis and by extending them to new physical interpretations we address unbiased sensitivity estimators correlated with practical solutions in order to attenuate the perturbations.

#index 1103406
#* Maximum Margin Active Learning for Sequence Labeling with Different Length
#@ Haibin Cheng;Ruofei Zhang;Yefei Peng;Jianchang Mao;Pang-Ning Tan
#t 2008
#c 18
#% 170649
#% 404719
#% 420077
#% 464268
#% 464434
#% 466887
#% 466892
#% 565531
#% 829043
#% 854819
#% 913170
#% 938727
#% 983889
#! Sequence labeling problem is commonly encountered in many natural language and query processing tasks. SVMstructis a supervised learning algorithm that provides a flexible and effective way to solve this problem. However, a large amount of training examples is often required to train SVMstruct, which can be costly for many applications that generate long and complex sequence data. This paper proposes an active learning technique to select the most informative subset of unlabeled sequences for annotation by choosing sequences that have largest uncertainty in their prediction. A unique aspect of active learning for sequence labeling is that it should take into consideration the effort spent on labeling sequences, which depends on the sequence length. A new active learning technique is proposed to use dynamic programming to identify the best subset of sequences to be annotated, taking into account both the uncertainty and labeling effort. Experiment results show that our SVMstructactive learning technique can significantly reduce the number of sequences to be labeled while outperforming other existing techniques.

#index 1103407
#* An Efficient Similarity Searching Algorithm Based on Clustering for Time Series
#@ Yucai Feng;Tao Jiang;Yingbiao Zhou;Junkui Li
#t 2008
#c 18
#% 172949
#% 227924
#% 333941
#% 460862
#% 462231
#% 464994
#% 480146
#% 564263
#% 659971
#% 915656
#% 993965
#% 1703172
#! Indexing large time series databases is crucial for efficient searching of time series queries. In the paper, we propose a novel indexing scheme RQI (Range Query based on Index) which includes three filtering methods: first-k filtering, indexing lower bounding and upper bounding as well as triangle inequality pruning. The basic idea is calculating wavelet coefficient whose first kcoefficients are used to form a MBR (minimal bounding rectangle) based on haar wavelet transform for each time series and then using point filteringmethod; At the same time, lower bounding and upper bounding feature of each time series is calculated, in advance, and stored into index structure. At last, triangle inequality pruning method is used by calculating the distance between time series beforehand. Then we introduce a novel lower bounding distance function SLBS (Symmetrical Lower Bounding based on Segment) and a novel clustering algorithm CSA (Clustering based on Segment Approximation) in order to further improve the search efficiency of point filteringmethod by keeping a good clustering trait of index structure. Extensive experiments over both synthetic and real datasets show that our technologies provide perfect pruning power and could obtain an order of magnitude performance improvement for time series queries over traditional naive evaluation techniques.

#index 1103408
#* Efficient String Mining under Constraints Via the Deferred Frequency Index
#@ David Weese;Marcel H. Schulz
#t 2008
#c 18
#% 200784
#% 280409
#% 287434
#% 300312
#% 393792
#% 501540
#% 587757
#% 629643
#% 751623
#% 844365
#% 874156
#% 906547
#% 951838
#% 985041
#% 1656273
#% 1663628
#% 1672945
#! We propose a general approach for frequency based string mining, which has many applications, e.g. in contrast data mining. Our contribution is a novel algorithm based on a deferred data structure. Despite its simplicity, our approach is up to 4 times faster and uses about half the memory compared to the best-known algorithm of Fischer et al. Applications in various string domains, e.g. natural language, DNA or protein sequences, demonstrate the improvement of our algorithm.

#index 1103409
#* Autonomous Forex Trading Agents
#@ Rui Pedro Barbosa;Orlando Belo
#t 2008
#c 18
#% 114621
#! In this paper we describe an infrastructure for implementing hybrid intelligent agents with the ability to trade in the Forex Marketwithout requiring human supervision. This infrastructure is composed of three modules. The "Intuition Module", implemented using an Ensemble Model, is responsible for performing pattern recognition and predicting the direction of the exchange rate. The "A Posteriori Knowledge Module", implemented using a Case-Based Reasoning System, enables the agents to learn from empirical experience and is responsible for suggesting how much to invest in each trade. The "A Priori Knowledge Module", implemented using a Rule-Based Expert System, enables the agents to incorporate non-experiential knowledge in their trading decisions. This infrastructure was used to develop an agent capable of trading the USD/JPY currency pair with a 6 hours timeframe. The agent's simulated and live trading results lead us to believe our infrastructure can be of practical interest to the traditional trading community.

#index 1103410
#* An Exploration into the Power of Formal Concept Analysis for Domestic Violence Analysis
#@ Jonas Poelmans;Paul Elzinga;Stijn Viaene;Guido Dedene
#t 2008
#c 18
#% 65948
#% 384416
#% 466177
#% 466328
#% 477661
#% 564111
#% 1303208
#% 1705153
#! The types of police inquiries performed are very diverse in nature and the current data processing architecture is not sufficiently tailored to cope with this diversity. Many information concerning cases is still stored in databases as unstructured text. Formal Concept Analysis is showcased as an exploratory data analysis technique for discovering new knowledge from police reports. It turns out that it provides a powerful framework for exploring the dataset, resulting in essential knowledge for improving current practices. It is shown that the domestic violence definition employed by the police organisation of the Netherlands is not always as clear as it should be, making it hard to use it effectively for classification purposes. In addition, newly discovered knowledge for automatically classifying certain cases as either domestic or non-domestic violence is presented. Moreover, essential techniques for detecting incorrect classifications, performed by police officers, are provided. Finally, some problems encountered because of the sometimes unstructured way of working of police officers are discussed. Both using Formal Concept Analysis for exploratory data analysis and its application on this area are novel enough to make this paper into a valuable contribution to the literature.

#index 1103411
#* Leatherbacks Matching by Automated Image Recognition
#@ Eric J. Pauwels;Paul M. Zeeuw;Danielle M. Bounantony
#t 2008
#c 18
#% 760805
#% 1398326
#! We describe a method that performs automated recognition of individual laetherback turtles within a large nesting population. With only minimal preprocessing required of the user, we prove able to produce unsupervised matching results. The matching is based on the Scale-Invariant Feature Transform by Lowe. A strict condition posed by biologists reads that matches should not be missed (no false negatives). A robust criterion is defined to meet this requirement. Results are reported for a considerable sample of leatherbacks.

#index 1116419
#* Proceedings of the 2007 Seventh IEEE International Conference on Data Mining
#@ 
#t 2007
#c 18

#index 1116991
#* Efficient Data Sampling in Heterogeneous Peer-to-Peer Networks
#@ Benjamin Arai;Song Lin;Dimitrios Gunopulos
#t 2007
#c 18
#! Performing data-mining tasks such as clustering, classification, and prediction on large datasets is an arduous task and, many times, it is an infeasible task given current hardware limitations. The distributed nature of peer-to-peer databases further complicates this issue by introducing an access overhead cost in addition to the cost of sending individual tuples over the network. We propose a two-level sampling approach focusing on peer-to-peer databases for maximizing sample quality given a user-defined communication budget. Given that individual peers may have varying cardinality we propose an algorithm for determining the optimal sample rate (the percentage of tuples to sample from a peer) for each peer. We do this by analyzing the variance of individual peers, ultimately minimizing the total variance of the entire sample. By performing local optimization of individual peer sample rates we maximize approximation accuracy of the samples. We also offer several techniques for sampling in peer-to-peer databases given various amounts of known and unknown information about the network and its peers.

#index 1116992
#* Temporal Analysis of Semantic Graphs Using ASALSAN
#@ Brett W. Bader;Richard A. Harshman;Tamara G. Kolda
#t 2007
#c 18
#! ASALSAN is a new algorithm for computing three-way DEDICOM, which is a linear algebra model for analyzing intrinsically asymmetric relationships, such as trade among nations or the exchange of emails among individuals, that incorporates a third mode of the data, such as time. ASALSAN is unique because it enables computing the three-way DEDICOM model on large, sparse data. A nonnegative version of ASALSAN is described as well. When we apply these techniques to adjacency arrays arising from directed graphs with edges labeled by time, we obtain a smaller graph on latent semantic dimensions and gain additional information about their changing relationships over time. We demonstrate these techniques on international trade data and the Enron email corpus to uncover latent components and their transient behavior. The mixture of roles assigned to individuals by ASALSAN showed strong correspondence with known job classifications and revealed the patterns of communication between these roles. Changes in the communication pattern over time, e.g., between top executives and the legal department, were also apparent in the solutions.

#index 1116993
#* Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights
#@ Robert M. Bell;Yehuda Koren
#t 2007
#c 18
#! Recommender systems based on collaborative filtering predict user preferences for products or services by learning past user-item relationships. A predominant approach to collaborative filtering is neighborhood based (" k-nearest neighbors"), where a user-item preference rating is interpolated from ratings of similar items and/or users. We enhance the neighborhood-based approach leading to substantial improvement of prediction accuracy, without a meaningful increase in running time. First, we remove certain so-called "global effects" from the data to make the ratings more comparable, thereby improving interpolation accuracy. Second, we show how to simultaneously derive interpolation weights for all nearest neighbors, unlike previous approaches where each weight is computed separately. By globally solving a suitable optimization problem, this simultaneous interpolation accounts for the many interactions between neighbors leading to improved accuracy. Our method is very fast in practice, generating a prediction in about 0.2 milliseconds. Importantly, it does not require training many parameters or a lengthy preprocessing, making it very practical for large scale applications. Finally, we show how to apply these methods to the perceivably much slower user-oriented approach. To this end, we suggest a novel scheme for low dimensional embedding of the users. We evaluate these methods on the Netflix dataset, where they deliver significantly better results than the commercial Netflix Cinematch recommender system.

#index 1116994
#* Rule Cubes for Causal Investigations
#@ Axel Blumenstock;Franz Schweiggert;Markus Muller
#t 2007
#c 18
#! With the complexity of modern vehicles tremendously increasing, quality engineers play a key role within today's automotive industry. Field data analysis supports corrective actions in development, production and after sales support. We decompose the requirements and show that association rules, being a popular approach to generating explanative models, still exhibit shortcomings. Recently proposed interactive rule cubes are a promising alternative. We extend this work by introducing a way of intuitively visualizing and meaningfully ranking them. Moreover, we present methods to interactively factorize a problem and validate hypotheses by ranking patterns based on expectations, and by browsing a cube-based network of related influences. All this is currently in use as an interactive tool for warranty data analysis in the automotive industry. A real-world case study shows how engineers successfully use it in identifying root causes of quality issues.

#index 1116995
#* The Chosen Few: On Identifying Valuable Patterns
#@ Bjorn Bringmann;Albrecht Zimmermann
#t 2007
#c 18
#! Constrained pattern mining extracts patterns based on their individual merit. Usually this results in far more patterns than a human expert or a machine learning technique could make use of. Often different patterns or combinations of patterns cover a similar subset of the examples, thus being redundant and not carrying any new information. To remove the redundant information contained in such pattern sets, we propose a general heuristic approach for selecting a small subset of patterns. We identify several selection techniques for use in this general algorithm and evaluate those on several data sets. The results show that the technique succeeds in severely reducing the number of patterns, while at the same time apparently retaining much of the original information. Additionally the experiments show that reducing the pattern set indeed improves the quality of classification results. Both results show that the approach is very well suited for the goals we aim at.

#index 1116996
#* Co-ranking Authors and Documents in a Heterogeneous Network
#@ Ding Zhou;Sergey A. Orshanskiy;Hongyuan Zha;C. Lee Giles
#t 2007
#c 18
#! Recent graph-theoretic approaches have demonstrated remarkable successes for ranking networked entities, but most of their applications are limited to homogeneous networks such as the network of citations between publications. This paper proposes a novel method for co-ranking authors and their publications using several networks: the social network connecting the authors, the citation network connecting the publications, as well as the authorship network that ties the previous two together. The new co-ranking framework is based on coupling two random walks, that separately rank authors and documents following the PageRank paradigm. As a result, improved rankings of documents and their authors depend on each other in a mutually reinforcing way, thus taking advantage of the additional information implicit in the heterogeneous network of authors and documents.

#index 1116997
#* Discovering Temporal Communities from Social Network Documents
#@ Ding Zhou;Isaac Councill;Hongyuan Zha;C. Lee Giles
#t 2007
#c 18
#! This paper studies the discovery of communities from social network documents produced over time, addressing the discovery of temporal trends in community memberships. We first formulate static community discovery at a single time period as a tripartite graph partitioning problem. Then we propose to discover the temporal communities by threading the statically derived communities in different time periods using a new constrained partitioning algorithm, which partitions graphs based on topology as well as prior information regarding vertex membership. We evaluate the proposed approach on synthetic datasets and a real-world dataset prepared from the CiteSeer.

#index 1116998
#* Efficient Discovery of Frequent Approximate Sequential Patterns
#@ Feida Zhu;Xifeng Yan;Jiawei Han;Philip S. Yu
#t 2007
#c 18
#! We propose an efficient algorithm for mining frequent approximate sequential patterns under the Hamming distance model. Our algorithm gains its efficiency by adopting a "break-down-and-build-up" methodology. The "breakdown" is based on the observation that all occurrences of a frequent pattern can be classified into groups, which we call strands. We developed efficient algorithms to quickly mine out all strands by iterative growth. In the "build-up" stage, these strands are grouped up to form the support sets from which all approximate patterns would be identified. A salient feature of our algorithm is its ability to grow the frequent patterns by iteratively assembling building blocks of significant sizes in a local search fashion. By avoiding incremental growth and global search, we achieve greater efficiency without losing the completeness of the mining result. Our experimental studies demonstrate that our algorithm is efficient in mining globally repeating approximate sequential patterns that would have been missed by existing methods.

#index 1116999
#* Active Learning from Data Streams
#@ Xingquan Zhu;Peng Zhang;Xiaodong Lin;Yong Shi
#t 2007
#c 18
#! In this paper, we address a new research problem on active learning from data streams where data volumes grow continuously and labeling all data is considered expensive and impractical. The objective is to label a small portion of stream data from which a model is derived to predict newly arrived instances as accurate as possible. In order to tackle the challenges raised by data streams' dynamic nature, we propose a classifier ensembling based active learning framework which selectively labels instances from data streams to build an accurate classifier. A Minimal Variance principle is introduced to guide instance labeling from data streams. In addition, a weight updating rule is derived to ensure that our instance labeling process can adaptively adjust to dynamic drifting concepts in the data. Experimental results on synthetic and real-world data demonstrate the performances of the proposed efforts in comparison with other simple approaches. *

#index 1117000
#* Lazy Bagging for Classifying Imbalanced Data
#@ Xingquan Zhu
#t 2007
#c 18
#! In this paper, we propose a Lazy Bagging (LB) design, which builds bootstrap replicate bags based on the characteristics of the test instances. Upon receiving a test instance Ik, LB will trim bootstrap bags by taking Ik's nearest neighbors in the training set into consideration. Our hypothesis is that an unlabeled instance's nearest neighbors provide valuable information for learners to refine their local decision boundaries for classifying this instance. By taking full advantage of Ik's nearest neighbors, the base learners are able to receive less bias and variance in classifying Ik. This strategy is beneficial for classifying imbalanced data because refining local decision boundaries can help a learner reduce its inherent bias towards the majority class and improve its performance on minority class examples. Our experimental results will confirm that LB outperforms C4.5 and TB in terms of reducing classification error, and most importantly this error reduction is largely contributed from LB's improvement on minority class examples.

#index 1117001
#* Spectral Regression: A Unified Approach for Sparse Subspace Learning
#@ Deng Cai;Xiaofei He;Jiawei Han
#t 2007
#c 18
#! Recently the problem of dimensionality reduction (or, subspace learning) has received a lot of interests in many fields of information processing, including data mining, information retrieval, and pattern recognition. Some popular methods include Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA) and Locality Preserving Projection (LPP). However, a disadvantage of all these approaches is that the learned projective functions are linear combinations of all the original features, thus it is often difficult to interpret the results. In this paper, we propose a novel dimensionality reduction framework, called Unified Sparse Subspace Learning (USSL), for learning sparse projections. USSL casts the problem of learning the projective functions into a regression framework, which facilitates the use of different kinds of regularizers. By using a L1-norm regularizer (lasso), the sparse projections can be efficiently computed. Experimental results on real world classification and clustering problems demonstrate the effectiveness of our method.

#index 1117002
#* Mining Frequent Itemsets in a Stream
#@ Toon Calders;Nele Dexters;Bart Goethals
#t 2007
#c 18
#! We study the problem of finding frequent itemsets in a continuous stream of transactions. The current frequency of an itemset in a stream is defined as its maximal frequency over all possible windows in the stream from any point in the past until the current state that satisfy a minimal length constraint. Properties of this new measure are studied and an incremental algorithm that allows, at any time, to immediately produce the current frequencies of all frequent itemsets is proposed. Experimental and theoretical analysis show that the space requirements for the algorithm are extremely small for many realistic data distributions.

#index 1117003
#* A Cascaded Approach to Biomedical Named Entity Recognition Using a Unified Model
#@ Shing-Kit Chan;Wai Lam;Xiaofeng Yu
#t 2007
#c 18
#! We propose a cascaded approach for extracting biomedical named entities from text documents using a unified model. Previous works often ignore the high computational cost incurred by a single-phase approach. We alleviate this problem by dividing the named entity extraction task into a segmentation task and a classification task, reducing the computational cost by an order of magnitude. A unified model, which we term "maximum-entropy margin-based" (MEMB), is used in both tasks. The MEMB model considers the error between a correct and an incorrect output during training and helps improve the performance of extracting sparse entity types that occur in biomedical literature. We report experimental evaluations on the GENIA corpus available from the BioNLP/NLPBA (2004) shared task, which demonstrate the state-of-the-art performance achieved by the proposed approach.

#index 1117004
#* Incorporating User Provided Constraints into Document Clustering
#@ Yanhua Chen;Manjeet Rege;Ming Dong;Jing Hua
#t 2007
#c 18
#! Document clustering without any prior knowledge or background information is a challenging problem. In this paper, we propose SS-NMF: a semi-supervised nonnegative matrix factorization framework for document clustering. In SS-NMF, users are able to provide supervision for document clustering in terms of pairwise constraints on a few documents specifying whether they "must" or "cannot" be clustered together. Through an iterative algorithm, we perform symmetric tri-factorization of the documentdocument similarity matrix to infer the document clusters. Theoretically, we show that SS-NMF provides a general framework for semi-supervised clustering and that existing approaches can be considered as special cases of SS-NMF. Through extensive experiments conducted on publicly available data sets, we demonstrate the superior performance of SS-NMF for clustering documents.

#index 1117005
#* Depth-Based Novelty Detection and Its Application to Taxonomic Research
#@ Yixin Chen;Henry L.  Bart Jr.;Xin Dang;Hanxiang Peng
#t 2007
#c 18
#! It is estimated that less than 10 percent of the world's species have been described, yet species are being lost daily due to human destruction of natural habitats. The job of describing the earth's remaining species is exacerbated by the shrinking number of practicing taxonomists and the very slow pace of traditional taxonomic research. In this article, we tackle, from a novelty detection perspective, one of the most important and challenging research objectives in taxonomy new species identification. We propose a unique and efficient novelty detection framework based on statistical depth functions. Statistical depth functions provide from the "deepest" point a "center-outward ordering" of multidimensional data. In this sense, they can detect observations that appear extreme relative to the rest of the observations, i.e., novelty. Of the various statistical depths, the spatial depth is especially appealing because of its computational efficiency and mathematical tractability. We propose a novel statistical depth, the kernelized spatial depth (KSD) that generalizes the spatial depth via positive definite kernels. By choosing a proper kernel, the KSD can capture the local structure of a data set while the spatial depth fails. Observations with depth values less than a threshold are declared as novel. The proposed algorithm is simple in structure: the threshold is the only one parameter for a given kernel. We give an upper bound on the false alarm probability of a depth-based detector, which can be used to determine the threshold. Experimental study demonstrates its excellent potential in new species discovery.

#index 1117006
#* ORIGAMI: Mining Representative Orthogonal Graph Patterns
#@ Mohammad Al Hasan;Vineet Chaoji;Saeed Salem;Jeremy Besson;Mohammed J. Zaki
#t 2007
#c 18
#! In this paper, we introduce the concept of -orthogonal patterns to mine a representative set of graph patterns. Intuitively, two graph patterns are -orthogonal if their similarity is bounded above by . Each -orthogonal pattern is also a representative for those patterns that are at least similar to it. Given user defined , [0, 1], the goal is to mine an -orthogonal, -representative set that minimizes the set of unrepresented patterns. We present ORIGAMI, an effective algorithm for mining the set of representative orthogonal patterns. ORIGAMI first uses a randomized algorithm to randomly traverse the pattern space, seeking previously unexplored regions, to return a set of maximal patterns. ORIGAMI then extracts an orthogonal, -representative set from the mined maximal patterns. We show the effectiveness of our algorithm on a number of real and synthetic datasets. In particular, we show that our method is able to extract high quality patterns even in cases where existing enumerative graph mining methods fail to do so.

#index 1117007
#* Detecting Fractures in Classifier Performance
#@ David A. Cieslak;Nitesh V. Chawla
#t 2007
#c 18
#! A fundamental tenet assumed by many classification algorithms is the presumption that both training and testing samples are drawn from the same distribution of data this is the stationary distribution assumption. This entails that the past is strongly indicative of the future. However, in real world applications, many factors may alter the One True Model responsible for generating the data distribution both significantly and subtly. In circumstances violating the stationary distribution assumption, traditional validation schemes such as ten-folds and hold-out become poor performance predictors and classifier rankers. Thus, it becomes critical to discover the fracture points in classifier performance by discovering the divergence between populations. In this paper, we implement a comprehensive evaluation framework to identify bias, enabling selection of a "correct" classifier given the sample bias. To thoroughly evaluate the performance of classifiers within biased distributions, we consider the following three scenarios: missing completely at random (akin to stationary); missing at random; and missing not at random. The latter reflects the canonical sample selection bias problem.

#index 1117008
#* Non-redundant Multi-view Clustering via Orthogonalization
#@ Ying Cui;Xiaoli Z. Fern;Jennifer G. Dy
#t 2007
#c 18
#! Typical clustering algorithms output a single clustering of the data. However, in real world applications, data can often be interpreted in many different ways; data can have different groupings that are reasonable and interesting from different perspectives. This is especially true for high-dimensional data, where different feature subspaces may reveal different structures of the data. Why commit to one clustering solution while all these alternative clustering views might be interesting to the user. In this paper, we propose a new clustering paradigm for explorative data analysis: find all non-redundant clustering views of the data, where data points of one cluster can belong to different clusters in other views. We present a framework to solve this problem and suggest two approaches within this framework: (1) orthogonal clustering, and (2) clustering in orthogonal subspaces. In essence, both approaches find alternative ways to partition the data by projecting it to a space that is orthogonal to our current solution. The first approach seeks orthogonality in the cluster space, while the second approach seeks orthogonality in the feature space. We test our framework on both synthetic and high-dimensional benchmark data sets, and the results show that indeed our approaches were able to discover varied solutions that are interesting and meaningful. keywords: multi-view clustering, non-redundant clustering, orthogonalization

#index 1117009
#* On Appropriate Assumptions to Mine Data Streams: Analysis and Practice
#@ Jing Gao;Wei Fan;Jiawei Han
#t 2007
#c 18
#! Recent years have witnessed an increasing number of studies in stream mining, which aim at building an accurate model for continuously arriving data. Somehow most existing work makes the implicit assumption that the training data and the yet-to-come testing data are always sampled from the "same distribution, and yet this "same distribution evolves over time. We demonstrate that this may not be true, and one actually may never know either "how or "when the distribution changes. Thus, a model that fits well on the observed distribution can have unsatisfactory accuracy on the incoming data. Practically, one can just assume the bare minimum that learning from observed data is better than both random guessing and always predicting exactly the same class label. Importantly, we formally and experimentally demonstrate the robustness of a model averaging and simple voting-based framework for data streams, particularly when incoming data "continuously follows significantly different distributions. On a real streaming data, this framework reduces the expected error of baseline models by 60%, and remains the most accurate compared to those baseline models.

#index 1117010
#* Efficient Algorithms for Mining Significant Substructures in Graphs with Quality Guarantees
#@ Huahai He;Ambuj K. Singh
#t 2007
#c 18
#! Graphs have become popular for modeling scientific data in recent years. As a result, techniques for mining graphs are extremely important for understanding inherent data and domain characteristics. One such exploratory mining paradigm is the k-MST (minimum spanning tree over k vertices) problem that can be used to discover significant local substructures. In this paper, we present an efficient approximation algorithm for the k-MST problem in large graphs. The algorithm has an O (k) approximation ratio and O (n log n + m log m log k + nk2 log k) running time, where n and m are the number of vertices and edges respectively. Experimental results on synthetic graphs and protein interaction networks show that the algorithm is scalable to large graphs and useful for discovering biological pathways. The highlight of the algorithm is that it offers both analytical guarantees and empirical evidence of good running time and quality.

#index 1117011
#* Dynamic Micro Targeting: Fitness-Based Approach to Predicting Individual Preferences
#@ Tianyi Jiang;Alexander Tuzhilin
#t 2007
#c 18
#! It is crucial to segment customers intelligently in order to offer more targeted and personalized products and services. Traditionally, customer segmentation is achieved using statistics-based methods that compute a set of statistics from the customer data and group customers into segments by applying clustering algorithms. Recent research proposed a direct grouping-based approach that combines customers into segments by optimally combining transactional data of several customers and building a data mining model of customer behavior for each group. This paper proposes a new micro targeting method that builds predictive models of customer behavior not on the segments of customers but rather on the customer-product groups. This micro-targeting method is more general than the previously considered direct grouping method. We empirically show that it significantly outperforms the direct grouping and statistics-based segmentation methods across multiple experimental conditions and that it generates predominately small-sized segments, thus providing additional support for the micro-targeting approach to personalization. Index Terms: Customer segmentation, marketing application, personalization, micro targeting, customer profiles

#index 1117012
#* Data Discretization Unification
#@ Ruoming Jin;Yuri Breitbart;Chibuike Muoh
#t 2007
#c 18
#! Data discretization is defined as a process of converting continuous data attribute values into a finite set of intervals with minimal loss of information. In this paper, we prove that discretization methods based on informational theoretical complexity and the methods based on statistical measures of data dependency are asymptotically equivalent. Furthermore, we define a notion of generalized entropy and prove that discretization methods based on MDLP, Gini Index, AIC, BIC, and Pearson's X2 and G2 statistics are all derivable from the generalized entropy function. We design a dynamic programming algorithm that guarantees the best discretization based on the generalized entropy notion. Furthermore, we conducted an extensive performance evaluation of our method for several publicly available data sets. Our results show that our method delivers on the average 31% less classification errors than many previously known discretization methods.

#index 1117013
#* Improving Knowledge Discovery in Document Collections through Combining Text Retrieval and Link Analysis Techniques
#@ Wei Jin;Rohini K. Srihari;Hung Hay Ho;Xin Wu
#t 2007
#c 18
#! In this paper, we present Concept Chain Queries (CCQ), a special case of text mining in document collections focusing on detecting links between two topics across text documents. We interpret such a query as finding the most meaningful evidence trails across documents that connect these two topics. We propose to use link-analysis techniques over the extracted features provided by Information Extraction Engine for finding new knowledge. A graphical text representation and mining model is proposed which combines information retrieval, association mining and link analysis techniques. We present experiments on different datasets that demonstrate the effectiveness of our algorithm. Specifically, the algorithm generates ranked concept chains and evidence trails where the key terms representing significant relationships between topics are ranked high1.

#index 1117014
#* Finding Cohesive Clusters for Analyzing Knowledge Communities
#@ Vasileios Kandylas;S. Phineas Upham;Lyle H. Ungar
#t 2007
#c 18
#! Documents and authors can be clustered into "knowledge communities" based on the overlap in the papers they cite. We introduce a new clustering algorithm, Streemer, which finds cohesive foreground clusters embedded in a diffuse background, and use it to identify knowledge communities as foreground clusters of papers which share common citations. To analyze the evolution of these communities over time, we build predictive models with features based on the citation structure, the vocabulary of the papers, and the affiliations and prestige of the authors. Findings include that scientific knowledge communities tend to grow more rapidly if their publications build on diverse information and if they use a narrow vocabulary.

#index 1117015
#* Succinct Matrix Approximation and Efficient k-NN Classification
#@ Rong Liu;Yong Shi
#t 2007
#c 18
#! This work reveals that instead of the polynomial bounds in previous literatures there exists a sharper bound of exponential form for the L2 norm of an arbitrary shaped random matrix. Based on the newly elaborated bound, a nonuniform sampling method is presented to succinctly approximate a matrix with a sparse binary one, and thus relieves the computation loads of k-NN classifier in both time and storage. The method is also pass-efficient because sampling and quantizing are combined together in a single step and the whole process can be completed within one pass over the input matrix. In the evaluations on compression ratio and reconstruction error, the sampling method exhibits impressive capability in providing succinct and tight approximations for the input matrices. The most significant finding in the classification experiment is that the k-NN classifier based on the approximation can even outperform the standard one. This provides another strong evidence for the claim that our method is especially capable in capturing intrinsic characteristics.

#index 1117016
#* A Pairwise Covariance-Preserving Projection Method for Dimension Reduction
#@ Xiaoming Liu;Zhaohui Wang;Zhilin Feng;Jinshan Tang
#t 2007
#c 18
#! Dimension reduction is critical in many areas of pattern classification and machine learning and many discriminant analysis algorithms have been proposed. In this paper, a Pairwise Covariance-preserving Projection Method (PCPM) is proposed for dimension reduction. PCPM maximizes the class discrimination and also preserves approximately the pairwise class covariances. The optimization involved in PCPM can be solved directly by eigenvalues decomposition. Our theoretical and empirical analysis reveals the relationship between PCPM and Linear Discriminant Analysis (LDA), Sliced Average Variance Estimator (SAVE), Heteroscedastic Discriminant Analysis (HDA) and Covariance preserving Projection Method (CPM). PCPM can utilize class mean and class covariance information at the same time. Furthermore, pairwise weight scheme can be incorporated naturally with the pairwise summarization form. The proposed methods are evaluated by both synthetic and real-world datasets.

#index 1117017
#* Community Learning by Graph Approximation
#@ Bo Long;Xiaoyun Xu;Zhongfei Zhang;Philip S. Yu
#t 2007
#c 18
#! Learning communities from a graph is an important problem in many domains. Different types of communities can be generalized as link-pattern based communities. In this paper, we propose a general model based on graph approximation to learn link-pattern based community structures from a graph. The model generalizes the traditional graph partitioning approaches and is applicable to learning various community structures. Under this model, we derive a family of algorithms which are flexible to learn various community structures and easy to incorporate the prior knowledge of the community structures. Experimental evaluation and theoretical analysis show the effectiveness and great potential of the proposed model and algorithms.

#index 1117018
#* Parallel Mining of Frequent Closed Patterns: Harnessing Modern Computer Architectures
#@ Claudio Lucchese;Salvatore Orlando;Raffaele Perego
#t 2007
#c 18
#! Inspired by emerging multi-core computer architectures, in this paper we present MT CLOSED, a multi-threaded algorithm for frequent closed itemset mining (FCIM). To the best of our knowledge, this is the first FCIM parallel algorithm proposed so far. We studied how different duplicate checking techniques, typical of FCIM algorithms, may affect this parallelization. We showed that only one of them allows to decompose the global FCIM problem into independent tasks that can be executed in any order, and thus in parallel. Finally we show how MT CLOSED efficiently harness modern CPUs. We designed and tested several parallelization paradigms by investigating static/dynamic decomposition and scheduling of tasks, thus showing its scalability w.r.t. to the number of CPUs. We analyzed the cache friendliness of the algorithm. Finally, we provided additional speed-up by introducing SIMD extensions.

#index 1117019
#* Supervised Learning by Training on Aggregate Outputs
#@ David R. Musicant;Janara M. Christensen;Jamie F. Olson
#t 2007
#c 18
#! Supervised learning is a classic data mining problem where one wishes to be be able to predict an output value associated with a particular input vector. We present a new twist on this classic problem where, instead of having the training set contain an individual output value for each input vector, the output values in the training set are only given in aggregate over a number of input vectors. This new problem arose from a particular need in learning on mass spectrometry data, but could easily apply to situations when data has been aggregated in order to maintain privacy. We provide a formal description of this new problem for both classification and regression. We then examine how k-nearest neighbor, neural networks, and support vector machines can be adapted for this problem.

#index 1117020
#* Sample Selection for Maximal Diversity
#@ Feng Pan;Adam Roberts;Leonard McMillan;David Threadgill;Wei Wang
#t 2007
#c 18
#! The problem of selecting a sample subset sufficient to preserve diversity arises in many applications. One example is in the design of recombinant inbred lines (RIL) for genetic association studies. In this context, genetic diversity is measured by how many alleles are retained in the resulting inbred strains. RIL panels that are derived from more than two parental strains, such as the Collaborative Cross [2, 14], present a particular challenge with regard to which of the many existing lab mouse strains should be included in the initial breeding funnel in order to maximize allele retention. A similar problem occurs in the study of customer reviews when selecting a subset of products with a maximal diversity in reviews. Diversity in this case implies the presence of a set of products having both positive and negative ranks for each customer. In this paper, we demonstrate that selecting an optimal diversity subset is an NP-complete problem via reduction to set cover. This reduction is sufficiently tight that greedy approximations to the set cover problem directly apply to maximizing diversity. We then suggest a slightly modified subset selection problem in which an initial greedy diversity solution is used to effectively prune an exhaustive search for all diversity subsets bounded from below by a specified coverage threshold. Extensive experiments on real datasets are performed to demonstrate the effectiveness and efficiency of our approach.

#index 1117021
#* Mining Statistical Information of Frequent Fault-Tolerant Patterns in Transactional Databases
#@ Ardian Kristanto Poernomo;Vivekanand Gopalkrishnan
#t 2007
#c 18
#! Constraints applied on classic frequent patterns are too strict and may cause interesting patterns to be missed. Hence, researchers have proposed to mine a more relaxed version of frequent patterns, where transactions are allowed to miss some items in the itemset they support. Patterns exhibiting such "faults" are called frequent fault-tolerant patterns (FFT-patterns) if they are significant in number. In this paper, the term "pattern" is distinguished from "itemset" as referring to a pair (tidset 脳 itemset). Unlike classical frequent patterns, the number of FFTpatterns grows exponentially not only with the number of items, but also with the number of transactions. Since the latter may reach millions, mining FFT-patterns by enumerating them becomes infeasible. Hence, the challenge is to represent FFT-patterns concisely without losing any useful information. To address this, we draw on the observation that, in transactional databases, the transactions themselves are not important from the data mining point-ofview; i.e. researchers are interested in finding itemsets contained in lots of transactions, rather than in the transactions per se. Therefore, we propose to mine only the frequent itemsets along with the statistical information of the supporting transaction sets, rather than enumerate entire FFTpatterns. Then we present our approach the BIAS framework, consisting of Backtracking algorithm, Integer Linear Programming (ILP) constraints, and aggregation statistics to solve this problem. Algorithms under this framework not only increase the efficiency of the FFT-patterns mining process by more than an order of magnitude, but also provide a more comprehensive analysis of FFT-Patterns.

#index 1117022
#* Lightweight Distributed Trust Propagation
#@ Daniele Quercia;Stephen Hailes;Licia Capra
#t 2007
#c 18
#! Using mobile devices, such as smart phones, people may create and distribute different types of digital content (e.g., photos, videos). One of the problems is that digital content, being easy to create and replicate, may likely swamp users rather than informing them. To avoid that, users may organize content producers that they know and trust in a web of trust. Users may then reason about this web of trust to form opinions about content producers with whom they have never interacted before. These opinions will then determine whether content is accepted. The process of forming opinions is called trust propagation. We design a mechanism for mobile devices that effectively propagates trust and that is lightweight and distributed (as opposed to previous work that focuses on centralized propagation). This mechanism uses a graph-based learning technique. We evaluate the effectiveness (predictive accuracy) of this mechanism against a large real-world data set. We also evaluate the computational cost of a J2ME implementation on a mobile phone.

#index 1117023
#* Social Network Extraction of Academic Researchers
#@ Jie Tang;Duo Zhang;Limin Yao
#t 2007
#c 18
#! This paper addresses the issue of extraction of an academic researcher social network. By researcher social network extraction, we are aimed at finding, extracting, and fusing the `semantic'-based profiling information of a researcher from the Web. Previously, social network extraction was often undertaken separately in an ad-hoc fashion. This paper first gives a formalization of the entire problem. Specifically, it identifies the `relevant documents' from the Web by a classifier. It then proposes a unified approach to perform the researcher profiling using Conditional Random Fields (CRF). It integrates publications from the existing bibliography datasets. In the integration, it proposes a constraints-based probabilistic model to name disambiguation. Experimental results on an online system show that the unified approach to researcher profiling significantly outperforms the baseline methods of using rule learning or classification. Experimental results also indicate that our method to name disambiguation performs better than the baseline method using unsupervised learning. The methods have been applied to expert finding. Experiments show that the accuracy of expert finding can be significantly improved by using the proposed methods.

#index 1117024
#* General Averaged Divergence Analysis
#@ Dacheng Tao;Xuelong Li;Xindong Wu;Stephen J. Maybank
#t 2007
#c 18
#! Subspace selection is a powerful tool in data mining. An important subspace method is the Fisher Rao linear discriminant analysis (LDA), which has been successfully applied in many fields such as biometrics, bioinformatics, and multimedia retrieval. However, LDA has a critical drawback: the projection to a subspace tends to merge those classes that are close together in the original feature space. If the separated classes are sampled from Gaussian distributions, all with identical covariance matrices, then LDA maximizes the mean value of the Kullback Leibler (KL) divergences between the different classes. We generalize this point of view to obtain a framework for choosing a subspace by 1) generalizing the KL divergence to the Bregman divergence and 2) generalizing the arithmetic mean to a general mean. The framework is named the general averaged divergence analysis (GADA). Under this GADA framework, a geometric mean divergence analysis (GMDA) method based on the geometric mean is studied. A large number of experiments based on synthetic data show that our method significantly outperforms LDA and several representative LDA extensions.

#index 1117025
#* Maximum Entropy Based Significance of Itemsets
#@ Nikolaj Tatti
#t 2007
#c 18
#! We consider the problem of defining the significance of an itemset. We say that the itemset is significant if we are surprised by its frequency when compared to the frequencies of its sub-itemsets. In other words, we estimate the frequency of the itemset from the frequencies of its sub-itemsets and compute the deviation between the real value and the estimate. For the estimation we use Maximum Entropy and for measuring the deviation we use Kullback-Leibler divergence. A major advantage compared to the previous methods is that we are able to use richer models whereas the previous approaches only measure the deviation from the independence model. We show that our measure of significance goes to zero for derivable itemsets and that we can use the rank as a statistical test. Our empirical results demonstrate that for our real datasets the independence assumption is too strong but applying more flexible models leads to good results.

#index 1117026
#* Local Probabilistic Models for Link Prediction
#@ Chao Wang;Venu Satuluri;Srinivasan Parthasarathy
#t 2007
#c 18
#! One of the core tasks in social network analysis is to predict the formation of links (i.e. various types of relationships) over time. Previous research has generally represented the social network in the form of a graph and has leveraged topological and semantic measures of similarity between two nodes to evaluate the probability of link formation. Here we introduce a novel local probabilistic graphical model method that can scale to large graphs to estimate the joint co-occurrence probability of two nodes. Such a probability measure captures information that is not captured by either topological measures or measures of semantic similarity, which are the dominant measures used for link prediction. We demonstrate the effectiveness of the co-occurrence probability feature by using it both in isolation and in combination with other topological and semantic features for predicting co-authorship collaborations on three real datasets.

#index 1117027
#* Improving Text Classification by Using Encyclopedia Knowledge
#@ Pu Wang;Jian Hu;Hua-Jun Zeng;Lijun Chen;Zheng Chen
#t 2007
#c 18
#! The exponential growth of text documents available on the Internet has created an urgent need for accurate, fast, and general purpose text classification algorithms. However, the "bag of words" representation used for these classification methods is often unsatisfactory as it ignores relationships between important terms that do not co-occur literally. In order to deal with this problem, we integrate background knowledge in our application: Wikipedia into the process of classifying text documents. The experimental evaluation on Reuters newsfeeds and several other corpus shows that our classification results with encyclopedia knowledge are much better than the baseline "bag of words" methods.

#index 1117028
#* Language-Independent Set Expansion of Named Entities Using the Web
#@ Richard C. Wang;William W. Cohen
#t 2007
#c 18
#! Set expansion refers to expanding a given partial set of objects into a more complete set. A well-known example system that does set expansion using the web is Google Sets. In this paper, we propose a novel method for expanding sets of named entities. The approach can be applied to semi-structured documents written in any markup language and in any human language. We present experimental results on 36 benchmark sets in three languages, showing that our system is superior to Google Sets in terms of mean average precision.

#index 1117029
#* Structure-Based Statistical Features and Multivariate Time Series Clustering
#@ Xiaozhe Wang;Anthony Wirth;Liang Wang
#t 2007
#c 18
#! We propose a new method for clustering multivariate time series. A univariate time series can be represented by a fixed-length vector whose components are statistical features of the time series, capturing the global structure. These descriptive vectors, one for each component of the multivariate time series, are concatenated, before being clustered using a standard fast clustering algorithm such as k-means or hierarchical clustering. Such statistical feature extraction also serves as a dimension-reduction procedure for multivariate time series. We demonstrate the effectiveness and simplicity of our proposed method by clustering human motion sequences: dynamic and high-dimensional multivariate time series. The proposed method based on univariate time series structure and statistical metrics provides a novel, yet simple and flexible way to cluster multivariate time series data efficiently with promising accuracy. The success of our method on the case study suggests that clustering may be a valuable addition to the tools available for human motion pattern recognition research.

#index 1117030
#* A Generalization of Proximity Functions for K-Means
#@ Junjie Wu;Hui Xiong;Jian Chen;Wenjun Zhou
#t 2007
#c 18
#! K-means is a widely used partitional clustering method. A large amount of effort has been made on finding better proximity (distance) functions for K-means. However, the common characteristics of proximity functions remain unknown. To this end, in this paper, we show that all proximity functions that fit K-means clustering can be generalized as K-means distance, which can be derived by a differentiable convex function. A general proof of sufficient and necessary conditions for K-means distance functions is also provided. In addition, we reveal that K-means has a general uniformization effect; that is, K-means tends to produce clusters with relatively balanced cluster sizes. This uniformization effect of K-means exists regardless of proximity functions. Finally, we have conducted extensive experiments on various real-world data sets, and the results show the evidence of the uniformization effect. Also, we observed that external clustering validation measures, such as Entropy and Variance of Information (VI), have difficulty in measuring clustering quality if data have skewed distributions on class sizes.

#index 1117031
#* Multilevel Belief Propagation for Fast Inference on Markov Random Fields
#@ Liang Xiong;Fei Wang;Changshui Zhang
#t 2007
#c 18
#! Graph-based inference plays an important role in many mining and learning tasks. Among all the solvers for this problem, belief propagation (BP) provides a general and efficient way to derive approximate solutions. However, for large scale graphs the computational cost of BP is still demanding. In this paper, we propose a multilevel algorithm to accelerate belief propagation on Markov Random Fields (MRF). First, we coarsen the original graph to get a smaller one. Then, BP is applied on the new graph to get a coarse result. Finally the coarse solution is efficiently refined back to derive the original solution. Unlike traditional multiresolution approaches, our method features adaptive coarsening and efficient refinement. The above process can be recursively applied to reduce the computational cost remarkably. We theoretically justify the feasibility of our method on Gaussian MRFs, and empirically show that it is also effectual on discrete MRFs. The effectiveness of our method is verified in experiments on various inference tasks.

#index 1117032
#* Disk Aware Discord Discovery: Finding Unusual Time Series in Terabyte Sized Datasets
#@ Dragomir Yankov;Eamonn Keogh;Umaa Rebbapragada
#t 2007
#c 18
#! The problem of finding unusual time series has recently attracted much attention, and several promising methods are now in the literature. However, virtually all proposed methods assume that the data reside in main memory. For many real-world problems this is not be the case. For example, in astronomy, multi-terabyte time series datasets are the norm. Most current algorithms faced with data which cannot fit in main memory resort to multiple scans of the disk/tape and are thus intractable. In this work we show how one particular definition of unusual time series, the time series discord, can be discovered with a disk aware algorithm. The proposed algorithm is exact and requires only two linear scans of the disk with a tiny buffer of main memory. Furthermore, it is very simple to implement. We use the algorithm to provide further evidence of the effectiveness of the discord definition in areas as diverse as astronomy, web query mining, video surveillance, etc., and show the efficiency of our method on datasets which are many orders of magnitude larger than anything else attempted in the literature.

#index 1117033
#* Binary Matrix Factorization with Applications
#@ Zhongyuan Zhang;Tao Li;Chris Ding;Xiangsun Zhang
#t 2007
#c 18
#! An interesting problem in Nonnegative Matrix Factorization (NMF) is to factorize the matrix X which is of some specific class, for example, binary matrix. In this paper, we extend the standard NMF to Binary Matrix Factorization (BMF for short): given a binary matrix X , we want to factorize X into two binary matrices W ,H (thus conserving the most important integer property of the objective matrix X ) satisfying X WH. Two algorithms are studied and compared. These methods rely on a fundamental boundedness property of NMF which we propose and prove. This new property also provides a natural normalization scheme that eliminates the bias of factor matrices. Experiments on both synthetic and real world datasets are conducted to show the competency and effectiveness of BMF.

#index 1117034
#* A Semantic Kernel for Semi-structured DocumentS
#@ Sujeevan Aseervatham;Emmanuel Viennet;Younès Bennani
#t 2007
#c 18
#! Natural Language Processing has emerged as an active field of research in the machine learning community. Several methods based on statistical information have been proposed. However, with the linguistic complexity of the texts, semantic-based approaches have been investigated. In this paper, we propose a Semantic Kernel for semistructured biomedical documents. The semantic meanings of words are extracted using the UMLS framework. The kernel, with a SVM classifier, has been applied to a text categorization task on a medical corpus of free text documents. The results have shown that the Semantic Kernel outperforms the Linear Kernel and the Naive Bayes classifier. Moreover, this kernel was ranked in the top ten of the best algorithms among 44 classification methods at the 2007 CMC Medical NLP International Challenge.

#index 1117035
#* DUSC: Dimensionality Unbiased Subspace Clustering
#@ Ira Assent;Ralph Krieger;Emmanuel Müller;Thomas Seidl
#t 2007
#c 18
#! To gain insight into today's large data resources, data mining provides automatic aggregation techniques. Clustering aims at grouping data such that objects within groups are similar while objects in different groups are dissimilar. In scenarios with many attributes or with noise, clusters are often hidden in subspaces of the data and do not show up in the full dimensional space. For these applications, subspace clustering methods aim at detecting clusters in any subspace. Existing subspace clustering approaches fall prey to an effect we call dimensionality bias. As dimensionality of subspaces varies, approaches which do not take this effect into account fail to separate clusters from noise. We give a formal definition of dimensionality bias and analyze consequences for subspace clustering. A dimensionality unbiased subspace clustering (DUSC) definition based on statistical foundations is proposed. In thorough experiments on synthetic and real world data, we show that our approach outperforms existing subspace clustering algorithms.

#index 1117036
#* Finding Predictive Runs with LAPS
#@ Suhrid Balakrishnan;David Madigan
#t 2007
#c 18
#! We present an extension to the Lasso [6] for binary classification problems with ordered attributes. Inspired by the Fused Lasso [5] and the Group Lasso [7, 3] models, we aim to both discover and model runs (contiguous subgroups of the variables) that are highly predictive. We call the extended model LAPS (the Lasso with Attribute Partition Search). Such problems commonly arise in financial and medical domains, where predictors are time series variables, for example. This paper outlines the formulation of the problem, an algorithm to obtain the model coefficients and experiments showing applicability to practical problems of this type.

#index 1117037
#* Latent Dirichlet Conditional Naive-Bayes Models
#@ Arindam Banerjee;Hanhuai Shan
#t 2007
#c 18
#! In spite of the popularity of probabilistic mixture models for latent structure discovery from data, mixture models do not have a natural mechanism for handling sparsity, where each data point only has a few non-zero observations. In this paper, we introduce conditional naive-Bayes (CNB) models, which generalize naive-Bayes mixture models to naturally handle sparsity by conditioning the model on observed features. Further, we present latent Dirichlet conditional naive-Bayes (LD-CNB) models, which constitute a family of powerful hierarchical Bayesian models for latent structure discovery from sparse data. The proposed family of models are quite general and can work with arbitrary regular exponential family conditional distributions. We present a variational inference based EM algorithm for learning along with special case analyses for Gaussian and discrete distributions. The efficacy of the proposed models are demonstrated by extensive experiments on a wide variety of different datasets.

#index 1117038
#* Efficient Kernel Discriminant Analysis via Spectral Regression
#@ Deng Cai;Xiaofei He;Jiawei Han
#t 2007
#c 18
#! Linear Discriminant Analysis (LDA) has been a popular method for extracting features which preserve class separability. The projection vectors are commonly obtained by maximizing the between class covariance and simultaneously minimizing the within class covariance. LDA can be performed either in the original input space or in the reproducing kernel Hilbert space (RKHS) into which data points are mapped, which leads to Kernel Discriminant Analysis (KDA). When the data are highly nonlinear distributed, KDA can achieve better performance than LDA. However, computing the projective functions in KDA involves eigen-decomposition of kernel matrix, which is very expensive when a large number of training samples exist. In this paper, we present a new algorithm for kernel discriminant analysis, called Spectral Regression Kernel Discriminant Analysis (SRKDA). By using spectral graph analysis, SRKDA casts discriminant analysis into a regression framework which facilitates both efficient computation and the use of regularization techniques. Specifically, SRKDA only needs to solve a set of regularized regression problems and there is no eigenvector computation involved, which is a huge save of computational cost. Our computational analysis shows that SRKDA is 27 times faster than the ordinary KDA. Moreover, the new formulation makes it very easy to develop incremental version of the algorithm which can fully utilize the computational results of the existing training samples. Experiments on face recognition demonstrate the effectiveness and efficiency of the proposed algorithm.

#index 1117039
#* Zonal Co-location Pattern Discovery with Dynamic Parameters
#@ Mete Celik;James M. Kang;Shashi Shekhar
#t 2007
#c 18
#! Zonal co-location patterns represent subsets of featuretypes that are frequently located in a subset of space (i.e., zone). Discovering zonal spatial co-location patterns is an important problem with many applications in areas such as ecology, public health, and homeland defense. However, discovering these patterns with dynamic parameters (i.e., repeated specification of zone and interest measure values according to user preferences) is computationally complex due to the repetitive mining process. Also, the set of candidate patterns is exponential in the number of feature types, and spatial datasets are huge. Previous studies have focused on discovering global spatial co-location patterns with a fixed interest measure threshold. In this paper, we propose an indexing structure for co-location patterns and propose algorithms (Zoloc-Miner) to discover zonal colocation patterns efficiently for dynamic parameters. Extensive experimental evaluation shows our proposed approaches are scalable, efficient, and outperform na篓ive alternatives.

#index 1117040
#* Predicting Blogging Behavior Using Temporal and Social Networks
#@ Bi Chen;Qiankun Zhao;Bingjun Sun;Prasenjit Mitra
#t 2007
#c 18
#! Modeling the behavior of bloggers is an important problem with various applications in recommender systems, targeted advertising, and event detection. In this paper, we propose three models by combining content, temporal, social dimensions: the general blogging-behavior model, the profile-based blogging-behavior model and the socialnetwork and profile-based blogging-behavior model. The models are based on two regression techniques: Extreme Learning Machine (ELM), and Modified General Regression Neural Network (MGRNN). We choose one of the largest blogs, a political blog, DailyKos 1, for our empirical evaluation. Experiments show that the social network and profile-based blogging behavior model with ELM regression techniques produce good results for the most active bloggers and can be used to predict blogging behavior.

#index 1117041
#* gApprox: Mining Frequent Approximate Patterns from a Massive Network
#@ Chen Chen;Xifeng Yan;Feida Zhu;Jiawei Han
#t 2007
#c 18
#! Recently, there arise a large number of graphs with massive sizes and complex structures in many new applications, such as biological networks, social networks, and the Web, demanding powerful data mining methods. Due to inherent noise or data diversity, it is crucial to address the issue of approximation, if one wants to mine patterns that are potentially interesting with tolerable variations. In this paper, we investigate the problem of mining frequent approximate patterns from a massive network and propose a method called gApprox. gApprox not only finds approximate network patterns, which is the key for many knowledge discovery applications on structural data, but also enriches the library of graph mining methodologies by introducing several novel techniques such as: (1) a complete and redundancy-free strategy to explore the new pattern space faced by gApprox; and (2) transform "frequent in an approximate sense" into an anti-monotonic constraint so that it can be pushed deep into the mining process. Systematic empirical studies on both real and synthetic data sets show that frequent approximate patterns mined from the worm protein-protein interaction network are biologically interesting and gApprox is both effective and efficient.

#index 1117042
#* Document Transformation for Multi-label Feature Selection in Text Categorization
#@ Weizhu Chen;Jun Yan;Benyu Zhang;Zheng Chen;Qiang Yang
#t 2007
#c 18
#! Feature selection on multi-label documents for automatic text categorization is an under-explored research area. This paper presents a systematic document transformation framework, whereby the multi-label documents are transformed into single-label documents before applying standard feature selection algorithms, to solve the multi-label feature selection problem. Under this framework, we undertake a comparative study on four intuitive document transformation approaches and propose a novel approach called Entropy-based Label Assignment (ELA), which assigns the labels weights to a multi-label document based on label entropy. Three standard feature selection algorithms are utilized for evaluating the document transformation approaches in order to verify its impact on multi-class text categorization problems. Using a SVM classifier and two multi-label evaluation benchmark text collections, we show that the choice of document transformation approaches can significantly influence the performance of multi-class categorization and that our proposed document transformation approach ELA can achieve better performance than all other approaches.

#index 1117043
#* Recommendation via Query Centered Random Walk on K-Partite Graph
#@ Haibin Cheng;Pang-Ning Tan;Jon Sticklen;William F. Punch
#t 2007
#c 18
#! This paper presents an algorithm for recommending items using a diverse set of features. The items are recommended by performing a random walk on the k-partite graph constructed from the heterogenous features. To support personalized recommendation, the random walk must be initiated separately for each user, which is computationally demanding given the massive size of the graph. To overcome this problem, we apply multi-way clustering to group together the highly correlated nodes. A recommendation is then made by traversing the subgraph induced by clusters associated with a user's interest. Our experimental results on real data sets demonstrate the efficacy of the proposed algorithm.

#index 1117044
#* Bandit-Based Algorithms for Budgeted Learning
#@ Kun Deng;Chris Bourke;Stephen Scott;Julie Sunderman;Yaling Zheng 
#t 2007
#c 18
#! We explore the problem of budgeted machine learning, in which the learning algorithm has free access to the training examples' labels but has to pay for each attribute that is specified. This learning model is appropriate in many areas, including medical applications. We present new algorithms for choosing which attributes to purchase of which examples in the budgeted learning model based on algorithms for the multi-armed bandit problem. All of our approaches outperformed the current state of the art. Furthermore, we present a new means for selecting an example to purchase after the attribute is selected, instead of selecting an example uniformly at random, which is typically done. Our new example selection method improved performance of all the algorithms we tested, both ours and those in the literature.

#index 1117045
#* Extracting Product Comparisons from Discussion Boards
#@ Ronen Feldman;Moshe Fresco;Jacob Goldenberg;Oded Netzer;Lyle Ungar
#t 2007
#c 18
#! In recent years, product discussion forums have become a rich environment in which consumers and potential adopters exchange views and information. Researchers and practitioners are starting to extract user sentiment about products from user product reviews. Users often compare different products, stating which they like better and why. Extracting information about product comparisons offers a number of challenges; recognizing and normalizing entities (products) in the informal language of blogs and discussion groups require different techniques than those used for entity extraction in the more formal text of newspapers and scientific articles. We present a case study in extracting information about comparisons between running shoes and between cars, describe an effective methodology, and show how it produces insight into how consumers view the running shoe and car markets.

#index 1117046
#* Mining Interpretable Human Strategies: A Case Study
#@ Xiaoli Z. Fern;Chaitanya Komireddy;Margaret Burnett
#t 2007
#c 18
#! This paper focuses on mining human strategies by observing their actions. Our application domain is an HCI study aimed at discovering general strategies used by software users and understanding how such strategies relate to gender and success. We cast this as a sequential pattern discovery problem, where user strategies are manifested as sequential patterns. Problematically, we found that the patterns discovered by standard algorithms were difficult to interpret and provided limited information about high-level strategies. To help interpret the patterns and extract general strategies, we examined multiple ways of clustering the patterns into meaningful groups, which collectively led to interesting findings about user behavior both in terms of gender differences and problem-solving success. As a real-world application of data mining techniques, our work led to the discovery of new strategic patterns that are linked to user success and had not been revealed in more than nine years of manual empirical work. As a case study, our work highlights important research directions for making data mining more accessible to non-experts.

#index 1117047
#* Cross-Mining Binary and Numerical Attributes
#@ Gemma C. Garriga;Hannes Heikinheimo;Jouni K. Seppanen
#t 2007
#c 18
#! We consider the problem of relating itemsets mined on binary attributes of a data set to numerical attributes of the same data. An example is biogeographical data, where the numerical attributes correspond to environmental variables and the binary attributes encode the presence or absence of species in different environments. From the viewpoint of itemset mining, the task is to select a small collection of interesting itemsets using the numerical attributes; from the viewpoint of the numerical attributes, the task is to constrain the search for local patterns (e.g. clusters) using the binary attributes. We give a formal definition of the problem, discuss it theoretically, give a simple constant-factor approximation algorithm, and show by experiments on biogeographical data that the algorithm can capture interesting patterns that would not have been found using either itemset mining or clustering alone.

#index 1117048
#* Prism: A Primal-Encoding Approach for Frequent Sequence Mining
#@ Karam Gouda;Mosab Hassaan;Mohammed J. Zaki
#t 2007
#c 18
#! Sequence mining is one of the fundamental data mining tasks. In this paper we present a novel approach called PRISM, for mining frequent sequences. PRISM utilizes a vertical approach for enumeration and support counting, based on the novel notion of prime block encoding, which in turn is based on prime factorization theory. Via an extensive evaluation on both synthetic and real datasets, we show that PRISM outperforms popular sequence mining methods like SPADE [10], PrefixSpan [6] and SPAM [2], by an order of magnitude or more.

#index 1117049
#* Using Burstiness to Improve Clustering of Topics in News Streams
#@ Qi He;Kuiyu Chang;Ee-Peng Lim
#t 2007
#c 18
#! Specialists who analyze online news have a hard time separating the wheat from the chaff. Moreover, automatic data-mining techniques like clustering of news streams into topical groups can fully recover the underlying true class labels of data if and only if all classes are well separated. In reality, especially for news streams, this is clearly not the case. The question to ask is thus this: if we cannot recover the full C classes by clustering, what is the largest K \le C clusters we can find that best resemble the K underlying classes? Using the intuition that bursty topics are more likely to correspond to important events that are of interest to analysts, we propose several new bursty vector space models (B-VSM) for representing a news document. B-VSM takes into account the burstiness (across the full corpus and whole duration) of each constituent word in a document at the time of publication. We benchmarked our B-VSM against the classical TFIDF-VSM on the task of clustering a collection of news stream articles with known topic labels. Experimental results show that B-VSM was able to find the burstiest clusters/topics. Further, it also significantly improved the recall and precision for the top K clusters/topics.

#index 1117050
#* Bayesian Folding-In with Dirichlet Kernels for PLSI
#@ Alexander Hinneburg;Hans-Henning Gabriel;Andrè Gohr
#t 2007
#c 18
#! Probabilistic latent semantic indexing (PLSI) represents documents of a collection as mixture proportions of latent topics, which are learned from the collection by an expectation maximization (EM) algorithm. New documents or queries need to be folded into the latent topic space by a simplified version of the EM-algorithm. During PLSIFolding-in of a new document, the topic mixtures of the known documents are ignored. This may lead to a suboptimal model of the extended collection. Our new approach incorporates the topic mixtures of the known documents in a Bayesian way during foldingin. That knowledge is modeled as prior distribution over the topic simplex using a kernel density estimate of Dirichlet kernels. We demonstrate the advantages of the new Bayesian folding-in using real text data.

#index 1117051
#* Confident Identification of Relevant Objects Based on Nonlinear Rescaling Method and Transductive Inference
#@ Shen-Shyang Ho;Roman Polyak
#t 2007
#c 18
#! We present a novel machine learning algorithm to identify relevant objects from a large amount of data. This approach is driven by linear discrimination based on Nonlinear Rescaling (NR) method and transductive inference. The NR algorithm for linear discrimination (NRLD) computes both the primal and the dual approximation at each step. The dual variables associated with the given labeled dataset provide important information about the objects in the data-set and play the key role in ordering these objects. A confidence score based on a transductive inference procedure using NRLD is used to rank and identify the relevant objects from a pool of unlabeled data. Experimental results on an unbalanced protein data-set for the drug target prioritization and identification problem are used to illustrate the feasibility of the proposed identification algorithm.

#index 1117052
#* Training Conditional Random Fields by Periodic Step Size Adaptation for Large-Scale Text Mining
#@ Han-Shen Huang;Yu-Ming Chang;Chun-Nan Hsu
#t 2007
#c 18
#! For applications with consecutive incoming training examples, on-line learning has the potential to achieve a likelihood as high as off-line learning without scanning all available training examples and usually has a much smaller memory footprint. To train CRFs on-line, this paper presents the Periodic Step size Adaptation (PSA) method to dynamically adjust the learning rates in stochastic gradient descent. We applied our method to three large scale text mining tasks. Experimental results show that PSA outperforms the best off-line algorithm, L-BFGS, by many hundred times, and outperforms the best on-line algorithm, SMD, by an order of magnitude in terms of the number of passes required to scan the training data set.

#index 1117053
#* Semi-supervised Document Clustering via Active Learning with Pairwise Constraints
#@ Ruizhang Huang;Wai Lam
#t 2007
#c 18
#! This paper investigates a framework that discovers pairwise constraints for semi-supervised text document clustering. An active learning approach is proposed to select informative document pairs for obtaining user feedbacks. A gain directed document pair selection method that measures how much we can learn by revealing the relationships between pairs of documents is designed. Three different models, namely, uncertainty model, generation error model, and objective function model are proposed. Language modeling is investigated for representing clusters in the semi-supervised document clustering approach.

#index 1117054
#* Computing Correlation Anomaly Scores Using Stochastic Nearest Neighbors
#@ Tsuyoshi Idé;Spiros Papadimitriou;Michail Vlachos
#t 2007
#c 18
#! This paper addresses the task of change analysis of correlated multi-sensor systems. The goal of change analysis is to compute the anomaly score of each sensor when we know that the system has some potential difference from a reference state. Examples include validating the proper performance of various car sensors in the automobile industry. We solve this problem based on a neighborhood preservation principle -If the system is working normally, the neighborhood graph of each sensor is almost invariant against the fluctuations of experimental conditions. Here a neighborhood graph is defined based on the correlation between sensor signals. With the notion of stochastic neighborhood, our method is capable of robustly computing the anomaly score of each sensor under conditions that are hard to be detected by other naive methods.

#index 1117055
#* On Meta-Learning Rule Learning Heuristics
#@ Frederik Janssen;Johannes Furnkranz
#t 2007
#c 18
#! The goal of this paper is to investigate to what extent a rule learning heuristic can be learned from experience. To that end, we let a rule learner learn a large number of rules and record their performance on the test set. Subsequently, we train regression algorithms on predicting the test set performance of a rule from its training set characteristics. We investigate several variations of this basic scenario, including the question whether it is better to predict the performance of the candidate rule itself or of the resulting final rule. Our experiments on a number of independent evaluation sets show that the learned heuristics outperform standard rule learning heuristics. We also analyze their behavior in coverage space.

#index 1117056
#* Web Site Recommendation Using HTTP Traffic
#@ Ming Jia;Shaozhi Ye;Xing Li;Julie Dickerson
#t 2007
#c 18
#! Collaborative Filtering (CF) is widely used in web recommender systems, while most existing CF applications focus on transactions or page views within a single site. In this paper, we build a recommender system prototype, which suggests web sites to users, by collecting browsing events at routers without neither user nor website effort. 100 million HTTP flows, involving 11, 327 websites, are converted to user-site ratings using access frequency as the implicit rating metric. With this rating dataset, we evaluate six CF algorithms including one proposed algorithm based on IP address locality. Our experiments show that the recommendation from K nearest neighbors (RkNN ) performs the best by 50% p@10 (precision of top 10) and 53% p@5 (precision of top 5). Although the precision is far from ideal, our preliminary results suggest the potential value of such a centralized web site recommender system.

#index 1117057
#* Trend Motif: A Graph Mining Approach for Analysis of Dynamic Complex Networks
#@ Ruoming Jin;Scott McCallen;Eivind Almaas
#t 2007
#c 18
#! Complex networks have been used successfully in scientific disciplines ranging from sociology to microbiology to describe systems of interacting units. Until recently, studies of complex networks have mainly focused on their network topology. However, in many real world applications, the edges and vertices have associated attributes that are frequently represented as vertex or edge weights. Furthermore, these weights are often not static, instead changing with time and forming a time series. Hence, to fully understand the dynamics of the complex network, we have to consider both network topology and related time series data. In this work, we propose a motif mining approach to identify trend motifs for such purposes. Simply stated, a trend motif describes a recurring subgraph where each of its vertices or edges displays similar dynamics over a userdefined period. Given this, each trend motif occurrence can help reveal significant events in a complex system; frequent trend motifs may aid in uncovering dynamic rules of change for the system, and the distribution of trend motifs may characterize the global dynamics of the system. Here, we have developed efficient mining algorithms to extract trend motifs. Our experimental validation using three disparate empirical datasets, ranging from the stock market, world trade, to a protein interaction network, has demonstrated the efficiency and effectiveness of our approach.

#index 1117058
#* Analyzing and Detecting Review Spam
#@ Nitin Jindal;Bing Liu
#t 2007
#c 18
#! Mining of opinions from product reviews, forum posts and blogs is an important research topic with many applications. However, existing research has been focused on extraction, classification and summarization of opinions from these sources. An important issue that has not been studied so far is the opinion spam or the trustworthiness of online opinions. In this paper, we study this issue in the context of product reviews. To our knowledge, there is still no published study on this topic, although Web page spam and email spam have been investigated extensively. We will see that review spam is quite different from Web page spam and email spam, and thus requires different detection techniques. Based on the analysis of 5.8 million reviews and 2.14 million reviewers from amazon.com, we show that review spam is widespread. In this paper, we first present a categorization of spam reviews and then propose several techniques to detect them.

#index 1117059
#* A Computational Approach to Style in American Poetry
#@ David M. Kaplan;David M. Blei
#t 2007
#c 18
#! We develop a quantitative method to assess the style of American poems and to visualize a collection of poems in relation to one another. Qualitative poetry criticism helped guide our development of metrics that analyze various orthographic, syntactic, and phonemic features. These features are used to discover comprehensive stylistic information from a poem's multi-layered latent structure, and to compute distances between poems in this space. Visualizations provide ready access to the analytical components. We demonstrate our method on several collections of poetry, showing that it better delineates poetry style than the traditional word-occurrence features that are used in typical text analysis algorithms. Our method has potential applications to academic research of texts, to research of the intuitive personal response to poetry, and to making recommendations to readers based on their favorite poems.

#index 1117060
#* Change-Point Detection in Time-Series Data Based on Subspace Identification
#@ Yoshinobu Kawahara;Takehisa Yairi;Kazuo Machida
#t 2007
#c 18
#! In this paper, we propose series of algorithms for detecting change points in time-series data based on subspace identification, meaning a geometric approach for estimating linear state-space models behind time-series data. Our algorithms are derived from the principle that the subspace spanned by the columns of an observability matrix and the one spanned by the subsequences of time-series data are approximately equivalent. In this paper, we derive an batchtype algorithm applicable to ordinary time-series data, i.e. consisting of only output series, and then introduce the online version of the algorithm and the extension to be available with input-output time-series data. We illustrate the effectiveness of our algorithms with comparative experiments using some artificial and real datasets.

#index 1117061
#* Optimal Subsequence Bijection
#@ Longin Jan Latecki;Qiang Wang;Suzan Koknar-Tezel;Vasileios Megalooikonomou
#t 2007
#c 18
#! We consider the problem of elastic matching of sequences of real numbers. Since both a query and a target sequence may be noisy, i.e., contain some outlier elements, it is desirable to exclude the outlier elements from matching in order to obtain a robust matching performance. Moreover, in many applications like shape alignment or stereo correspondence it is also desirable to have a one-to-one and onto correspondence (bijection) between the remaining elements. We propose an algorithm that determines the optimal subsequence bijection (OSB) of a query and target sequence. The OSB is efficiently computed since we map the problem's solution to a cheapest path in a DAG (directed acyclic graph). We obtained excellent results on standard benchmark time series datasets. We compared OSB to Dynamic Time Warping (DTW) with and without warping window. We do not claim that OSB is always superior to DTW. However, our results demonstrate that skipping outlier elements as done by OSB can significantly improve matching results for many real datasets. Moreover, OSB is particularly suitable for partial matching. We applied it to the object recognition problem when only parts of contours are given. We obtained sequences representing shapes by representing object contours as sequences of curvatures.

#index 1117062
#* Connections between Mining Frequent Itemsets and Learning Generative Models
#@ Srivatsan Laxman;Prasad Naldurg;Raja Sripada;Ramarathnam Venkatesan
#t 2007
#c 18
#! Frequent itemsets mining is a popular framework for pattern discovery. In this framework, given a database of customer transactions, the task is to unearth all patterns in the form of sets of items appearing in a sizable number of transactions. We present a class of models called Itemset Generating Models (or IGMs) that can be used to formally connect the process of frequent itemsets discovery with the learning of generative models. IGMs are specified using simple probability mass functions (over the space of transactions), peaked at specific sets of items and uniform everywhere else. Under such a connection, it is possible to rigorously associate higher frequency patterns with generative models that have greater data likelihoods. This enables a generative model-learning interpretation of frequent itemsets mining. More importantly, it facilitates a statistical significance test which prescribes the minimum frequency needed for a pattern to be considered interesting. We illustrate the effectiveness of our analysis through experiments on standard benchmark data sets.

#index 1117063
#* Solving Consensus and Semi-supervised Clustering Problems Using Nonnegative Matrix Factorization
#@ Tao Li;Chris Ding;Michael I. Jordan
#t 2007
#c 18
#! Consensus clustering and semi-supervised clustering are important extensions of the standard clustering paradigm. Consensus clustering (also known as aggregation of clustering) can improve clustering robustness, deal with distributed and heterogeneous data sources and make use of multiple clustering criteria. Semi-supervised clustering can integrate various forms of background knowledge into clustering. In this paper, we show how consensus and semi-supervised clustering can be formulated within the framework of nonnegative matrix factorization (NMF). We show that this framework yields NMF-based algorithms that are: (1) extremely simple to implement; (2) provably correct and provably convergent. We conduct a wide range of comparative experiments that demonstrate the effectiveness of this NMF-based approach.

#index 1117064
#* Failure Prediction in IBM BlueGene/L Event Logs
#@ Yinglung Liang;Yanyong Zhang;Hui Xiong;Ramendra Sahoo
#t 2007
#c 18
#! Frequent failures are becoming a serious concern to the community of high-end computing, especially when the applications and the underlying systems rapidly grow in size and complexity. In order to develop effective fault-tolerant strategies, there is a critical need to predict failure events. To this end, we have collected detailed event logs from IBM BlueGene/L, which has 128K processors, and is currently the fastest supercomputer in the world. In this study, we first show how the event records can be converted into a data set that is appropriate for running classification techniques. Then we apply classifiers on the data, including RIPPER (a rule-based classifier), Support Vector Machines (SVMs), a traditional Nearest Neighbor method, and a customized Nearest Neighbor method. We show that the customized nearest neighbor approach can outperform RIPPER and SVMs in terms of both coverage and precision. The results suggest that the customized nearest neighbor approach can be used to alleviate the impact of failures.

#index 1117065
#* A Text Classification Framework with a Local Feature Ranking for Learning Social Networks
#@ Masoud Makrehchi;Mohamed S. Kamel
#t 2007
#c 18
#! In this paper, a text classifier framework with a feature ranking scheme is proposed to extract social structures from text data. It is assumed that only a small subset of relations between the individuals in a community is known. With this assumption, the social network extraction is translated into a classification problem. The relations between two individuals are represented by merging their document vectors and the given relations are used as labels of training data. By this transformation, a text classifier such as Rocchio is used for learning the unknown relations. We show that there is a link between the intrinsic sparsity of social networks and class imbalance. Furthermore, we show that feature ranking methods usually fail in problem with unbalanced data. In order to deal with this deficiency and re-balance the unbalanced social data, a local feature ranking method, which is called reverse discrimination, is proposed.

#index 1117066
#* Optimizing Frequency Queries for Data Mining Applications
#@ Hassan H. Malik;John R. Kender
#t 2007
#c 18
#! Data mining algorithms use various Trie and bitmap-based representations to optimize the support (i.e., frequency) counting performance. In this paper, we compare the memory requirements and support counting performance of FP Tree, and Compressed Patricia Trie against several novel variants of vertical bit vectors. First, borrowing ideas from the VLDB domain, we compress vertical bit vectors using WAH encoding. Second, we evaluate the Gray code rankbased transaction reordering scheme, and show that in practice, simple lexicographic ordering, obtained by applying LSB Radix sort, outperforms this scheme. Led by these results, we propose HDO, a novel Hamming-distance-based greedy transaction reordering scheme, and aHDO, a linear-time approximation to HDO. We present results of experiments performed on 15 common datasets with varying degrees of sparseness, and show that HDOreordered, WAH encoded bit vectors can take as little as 5% of the uncompressed space, while aHDO achieves similar compression on sparse datasets. Finally, with results from over a billion database and data mining style frequency query executions, we show that bitmap-based approaches result in up to hundreds of times faster support counting, and HDO-WAH encoded bitmaps offer the best space-time tradeoff.

#index 1117067
#* Detecting Subdimensional Motifs: An Efficient Algorithm for Generalized Multivariate Pattern Discovery
#@ David Minnen;Charles Isbell;Irfan Essa;Thad Starner
#t 2007
#c 18
#! Discovering recurring patterns in time series data is a fundamental problem for temporal data mining. This paper addresses the problem of locating subdimensional motifs in real-valued, multivariate time series, which requires the simultaneous discovery of sets of recurring patterns along with the corresponding relevant dimensions. While many approaches to motif discovery have been developed, most are restricted to categorical data, univariate time series, or multivariate data in which the temporal patterns span all of the dimensions. In this paper, we present an expected linear-time algorithm that addresses a generalization of multivariate pattern discovery in which each motif may span only a subset of the dimensions. To validate our algorithm, we discuss its theoretical properties and empirically evaluate it using several data sets including synthetic data and motion capture data collected by an on-body inertial sensor.

#index 1117068
#* Consensus Clusterings
#@ Nam Nguyen;Rich Caruana
#t 2007
#c 18
#! In this paper we address the problem of combining multiple clusterings without access to the underlying features of the data. This process is known in the literature as clustering ensembles, clustering aggregation, or consensus clustering. Consensus clustering yields a stable and robust final clustering that is in agreement with multiple clusterings. We find that an iterative EM-like method is remarkably effective for this problem. We present an iterative algorithm and its variations for finding clustering consensus. An extensive empirical study compares our proposed algorithms with eleven other consensus clustering methods on four data sets using three different clustering performance metrics. The experimental results show that the new ensemble clustering methods produce clusterings that are as good as, and often better than, these other methods.

#index 1117069
#* High-Speed Function Approximation
#@ Biswanath Panda;Mirek Riedewald;Johannes Gehrke;Stephen B. Pope
#t 2007
#c 18
#! We address a new learning problem where the goal is to build a predictive model that minimizes prediction time (the time taken to make a prediction) subject to a constraint on model accuracy. Our solution is a generic framework that leverages existing data mining algorithms without requiring any modifications to these algorithms. We show a first application of our framework to a combustion simulation problem. Our experimental evaluation shows significant improvements over existing methods; prediction time typically is improved by a factor between 2 and 6.

#index 1117070
#* Weighted Additive Criterion for Linear Dimension Reduction
#@ Jing Peng;Stefan Robila
#t 2007
#c 18
#! Linear discriminant analysis (LDA) for dimension reduction has been applied to a wide variety of face recognition tasks. However, it has two major problems. First, it suffers from the small sample size problem when dimensionality is greater than the sample size. Second, it creates subspaces that favor well separated classes over those that are not. In this paper, we propose a simple weighted criterion for linear dimension reduction that addresses the above two problems associated with LDA. In addition, there are well established numerical procedures such as semi-definite programming for efficiently computing the proposed criterion. We demonstrate the efficacy of our proposal and compare it against other competing techniques using a number of examples.

#index 1117071
#* Local Word Bag Model for Text Categorization
#@ Wen Pu;Ning Liu;Shuicheng Yan;Jun Yan;Kunqing Xie;Zheng Chen
#t 2007
#c 18
#! Many text processing applications adopted the Bag of Words (BOW) model representation of documents, in which each document is represented as a vector of weighted terms or n-grams, and then cosine distance between two vectors is used as the similarity measurement. Although the great success in information retrieval and text categorization, the conventional BOW model ignores the detailed local text information, i.e. the co-occurrence pattern of words at sentence or paragraph level. In this paper, we propose a novel approach to represent a document as a set of local tf-idf vectors, or what we called local word bags (LWB). By encapsulating local information distributed around a document into multiple LWBs, we can measure the similarity of two documents via the partial match of their corresponding local bags. To perform the matching efficiently, we introduce the Local Word Bag kernel (LWB kernel), a variant of VGPyramid match kernel. The new kernel enables the discriminative machine learning methods like SVM to compute the partial matching between two sets of LWBs in linear time after an one time hierarchical clustering procedure over all local bags at the initialization stage. Experiments on real world datasets demonstrate the effectiveness of our new approach.

#index 1117072
#* Sampling for Sequential Pattern Mining: From Static Databases to Data Streams
#@ Chedy Raissi;Pascal Poncelet
#t 2007
#c 18
#! Sequential pattern mining is an active field in the domain of knowledge discovery. Recently, with the constant progress in hardware technologies, real-world databases tend to grow larger and the hypothesis that a database can be loaded into main-memory for sequential pattern mining purpose is no longer valid. Furthermore, the new model of data as a continuous and potentially infinite flow, known as data stream model, call for a pre-processing step to ease the mining operations. Since the database size is the most influential factor for mining algorithms we examine the use of sampling over static databases to get approximate mining results with an upper bound on the error rate. Moreover, we extend these sampling analysis and present an algorithm based on reservoir sampling to cope with sequential pattern mining over data streams. We demonstrate with empirical results that our sampling methods are efficient and that sequence mining remains accurate over static databases and data streams.

#index 1117073
#* Can the Content of Public News Be Used to Forecast Abnormal Stock Market Behaviour?
#@ Calum Robertson;Shlomo Geva;Rodney C. Wolff
#t 2007
#c 18
#! A popular theory of markets is that they are efficient: all available information is deemed to provide an accurate valuation of an asset at any time. In this paper, we consider how the content of marketrelated news articles contributes to such information. Specifically, we mine news articles for terms of interest, and quantify this degree of interest. We then incorporate this measure into traditional models for market index volatility with a view to forecasting whether the incidence of interesting news is correlated with a shock in the index, and thus if the information can be captured to value the underlying asset. We illustrate the methodology on stock market indices for the USA, the UK, and Australia.

#index 1117074
#* An Efficient Spectral Algorithm for Network Community Discovery and Its Applications to Biological and Social Networks
#@ Jianhua Ruan;Weixiong Zhang
#t 2007
#c 18
#! Automatic discovery of community structures in complex networks is a fundamental task in many disciplines, including social science, engineering, and biology. Recently, a quantitative measure called modularity (Q) has been proposed to effectively assess the quality of community structures. Several community discovery algorithms have since been developed based on the optimization of Q. However, this optimization problem is NP-hard, and the existing algorithms have a low accuracy or are computationally expensive. In this paper, we present an efficient spectral algorithm for modularity optimization. When tested on a large number of synthetic or real-world networks, and compared to the existing algorithms, our method is efficient and and has a high accuracy. In addition, we have successfully applied our algorithm to detect interesting and meaningful community structures from real-world networks in different domains, including biology, medicine and social science. Due to space limitation, results of these applications are presented in a complete version of the paper available on our website (http://cse.wustl.edu/~jruan/).

#index 1117075
#* Exploration of Link Structure and Community-Based Node Roles in Network Analysis
#@ Jerry Scripps;Pang-Ning Tan;Abdol-Hossein Esfahanian
#t 2007
#c 18
#! Communities are nodes in a network that are grouped together based on a common set of properties. While the communities and link structures are often thought to be in alignment, it may not be the case when the communities are defined using other external criterion. In this paper we provide a new way to measure the alignment. We also provide a new metric that can be used to estimate the number of communities to which a node is attached. This metric, along with degree, is used to assign a communitybased role to nodes. We demonstrate the usefulness of the community-based node roles by applying them to the influence maximization problem.

#index 1117076
#* A Support Vector Approach to Censored Targets
#@ Pannagadatta K. Shivaswamy;Wei Chu;Martin Jansche
#t 2007
#c 18
#! Censored targets, such as the time to events in survival analysis, can generally be represented by intervals on the real line. In this paper, we propose a novel support vector technique (named SVCR) for regression on censored targets. SVCR inherits the strengths of support vector methods, such as a globally optimal solution by convex programming, fast training speed and strong generalization capacity. In contrast to ranking approaches to survival analysis, our approach is able not only to achieve superior ordering performance, but also to predict the survival time very well. Experiments show a significant performance improvement when the majority of the training data is censored. Experimental results on several survival analysis datasets demonstrate that SVCR is very competitive against classical survival analysis models.

#index 1117077
#* Understanding Discrete Classifiers with a Case Study in Gene Prediction
#@ Muhammad Subianto;Arno Siebes
#t 2007
#c 18
#! The requirement that the models resulting from data mining should be understandable is an uncontroversial requirement. In the data mining literature, however, it plays hardly any role, if at all. In practice, though, understandability is often even more important than, e.g., accuracy. Understandability does not mean that models should be simple. It means that one should be able to understand the predictions of models. In this paper we introduce tools to understand arbitrary classifiers defined on discrete data. More in particular, we introduce Explanations that provide insight at a local level. They explain why a classifier classifies a data point as it does. For global insight, we introduce attribute weights. The higher the weight of an attribute, the more often it is decisive in the classification of a data point. To illustrate our tools, we describe a case study in the prediction of small genes. This is a notoriously hard problem in Bioinformatics.

#index 1117078
#* Statistical Learning Algorithm for Tree Similarity
#@ Atsuhiro Takasu;Daiji Fukagawa;Tatsuya Akutsu
#t 2007
#c 18
#! Tree edit distance is one of the most frequently used distance measures for comparing trees. When using the tree edit distance, we need to determine the cost of each operation, but this is a labor-intensive and highly skilled task. This paper proposes an algorithm for learning the costs of tree edit operations from training data consisting of pairs of similar trees. To formalize the cost learning problem, we define a probabilistic model for tree alignment that is a variant of tree edit distance. Then, the parameters of the model are estimated using the expectation maximization (EM) technique. In this paper, we develop an algorithm for parameter learning that is polynomial in time (O(mn2d6)) and space (O(n2d4)) where n, d, and m represent the size of the trees, the maximum degree of trees, and the number of training pairs of trees, respectively.

#index 1117079
#* A Novel Criterion for Onset Detection: Differential Information Redundancy with Application to Human Movement Initiation
#@ Gert Van Dijck;Marc M.  Van Hulle;Jo Van Vaerenbergh
#t 2007
#c 18
#! A new detection criterion based on the change in the marginal information redundancy is presented. By establishing a link with information theory we are able to give an intuitive interpretation of our criterion. The usefulness of the new criterion is demonstrated for a case study of human movement initiation detection from force and torque signals in activity of daily living tasks. Using the new criterion, we achieve a performance that is more in agreement with expert decisions compared with traditional thresholding techniques and the advanced wavelet-based detector and energy detectors.

#index 1117080
#* Using Significant, Positively Associated and Relatively Class Correlated Rules for Associative Classification of Imbalanced Datasets
#@ Florian Verhein;Sanjay Chawla
#t 2007
#c 18
#! The application of association rule mining to classification has led to a new family of classifiers which are often referred to as "Associative Classifiers (ACs)". An advantage of ACs is that they are rule-based and thus lend themselves to an easier interpretation. Rule-based classifiers can play a very important role in applications such as medical diagnosis and fraud detection where "imbalanced data sets" are the norm and not the exception. The focus of this paper is to extend and modify ACs for classification on imbalanced data sets using only statistical techniques. We combine the use of statistically significant rules with a new measure, the Class Correlation Ratio ( CCR), to build an AC which we call SPARCCC. Experiments show that in terms of classification quality, SPARCCC performs comparably on balanced datasets and outperforms other AC techniques on imbalanced data sets. It also has a significantly smaller rule base and is much more computationally efficient.

#index 1117081
#* Preserving Privacy through Data Generation
#@ Jilles Vreeken;Matthijs van Leeuwen;Arno Siebes
#t 2007
#c 18
#! Many databases will not or can not be disclosed without strong guarantees that no sensitive information can be extracted. To address this concern several data perturbation techniques have been proposed. However, it has been shown that either sensitive information can still be extracted from the perturbed data with little prior knowledge, or that many patterns are lost. In this paper we show that generating new data is an inherently safer alternative. We present a data generator based on the models obtained by the MDLbased KRIMP [12] algorithm. These are accurate representations of the data distributions and can thus be used to generate data with the same characteristics as the original data. Experimental results show a very large patternsimilarity between the generated and the original data, ensuring that viable conclusions can be drawn from the anonymised data. Furthermore, anonymity is guaranteed for suited databases and the quality privacy trade-off can be balanced explicitly.

#index 1117082
#* Transitional Patterns and Their Significant Milestones
#@ Qian Wan;Aijun An
#t 2007
#c 18
#! Mining frequent patterns in transaction databases has been studied extensively in data mining research. However, most of the existing frequent pattern mining algorithms do not consider the time stamps associated with the transactions. In this paper, we extend the existing frequent pattern mining framework to take into account the time stamp of each transaction and discover patterns whose frequency dramatically changes over time. We define a new type of patterns, called transitional patterns, to capture the dynamic behavior of frequent patterns in a transaction database. Transitional patterns include both positive and negative transitional patterns. Their frequencies increase/decrease dramatically at some time points of a transaction database. We introduce the concept of significant milestones for a transitional pattern, which are time points at which the frequency of the pattern changes most significantly. Moreover, we develop an algorithm to mine from a transaction database the set of transitional patterns along with their significant milestones. Our experimental studies on real-world databases illustrate that mining positive and negative transitional patterns is highly promising as a practical and useful approach to discovering novel and interesting knowledge from large databases.

#index 1117083
#* Topical N-Grams: Phrase and Topic Discovery, with an Application to Information Retrieval
#@ Xuerui Wang;Andrew McCallum;Xing Wei
#t 2007
#c 18
#! Most topic models, such as latent Dirichlet allocation, rely on the bag-of-words assumption. However, word order and phrases are often critical to capturing the meaning of text in many text mining tasks. This paper presents topical n-grams, a topic model that discovers topics as well as topical phrases. The probabilistic model generates words in their textual order by, for each word, first sampling a topic, then sampling its status as a unigram or bigram, and then sampling the word from a topic-specific unigram or bigram distribution. Thus our model can model "white house" as a special meaning phrase in the `politics' topic, but not in the `real estate' topic. Successive bigrams form longer phrases. We present experiments showing meaningful phrases and more interpretable topics from the NIPS data and improved information retrieval performance on a TREC collection.

#index 1117084
#* Mechanism Design for Clustering Aggregation by Selfish Systems
#@ Pinata Winoto;Yiu-ming Cheung;Jiming Liu
#t 2007
#c 18
#! We propose a market mechanism that can be implemented on clustering aggregation problem among selfish systems, which tend to lie about their correct clustering during aggregation process. Our study is the preliminary step toward the development of robust distributed data mining among selfish systems.

#index 1117085
#* estMax: Tracing Maximal Frequent Itemsets over Online Data Streams
#@ Ho Jin Woo;Won Suk Lee
#t 2007
#c 18
#! In general, the number of frequent itemsets in a data set is very large. In order to represent them in more compact notation, closed or maximal frequent itemsets (MFIs) are used. However, the characteristics of a data stream make such a task be more difficult. For this purpose, this paper proposes a method called estMax that can trace the set of MFIs over a data stream. The proposed method maintains the set of frequent itemsets by a prefix tree and extracts all of MFIs without any additional superset/subset checking mechanism. Upon processing a newly generated transaction, its longest matched frequent itemsets are marked in a prefix tree as candidates for MFIs. At the same time, if any subset of these newly marked itemsets has been already marked as a candidate MFI, it is cleared as well. By employing this additional step, it is possible to extract the set of MFIs at any moment. The performance of the proposed method is comparatively analyzed by a series of experiments to identify its various characteristics.

#index 1117086
#* Locally Constrained Support Vector Clustering
#@ Dragomir Yankov;Eamonn Keogh;Kin Fai Kan
#t 2007
#c 18
#! Support vector clustering transforms the data into a high dimensional feature space, where a decision function is computed. In the original space, the function outlines the boundaries of higher density regions, naturally splitting the data into individual clusters. The method, however, though theoretically sound, has certain drawbacks which make it not so appealing to the practitioner. Namely, it is unstable in the presence of outliers and it is hard to control the number of clusters that it identifies. Parametrizing the algorithm incorrectly in noisy settings, can either disguise some objectively present clusters in the data, or can identify a large number of small and nonintuitive clusters. Here, we explore the properties of the data in small regions building a mixture of factor analyzers. The obtained information is used to regularize the complexity of the outlined cluster boundaries, by assigning suitable weighting to each example. The approach is demonstrated to be less susceptible to noise and to outline better interpretable clusters than support vector clustering alone.

#index 1117087
#* Cocktail Ensemble for Regression
#@ Yang Yu;Zhi-Hua Zhou;Kai Ming Ting
#t 2007
#c 18
#! This paper is motivated to improve the performance of individual ensembles using a hybrid mechanism in the regression setting. Based on an error-ambiguity decomposition, we formally analyze the optimal linear combination of two base ensembles, which is then extended to multiple individual ensembles via pairwise combinations. The Cocktail ensemble approach is proposed based on this analysis. Experiments over a broad range of data sets show that the proposed approach outperforms the individual ensembles, two other methods of ensemble combination, and two stateof-the-art regression approaches.

#index 1117088
#* Incremental Subspace Clustering over Multiple Data Streams
#@ Qi Zhang;Jinze Liu;Wei Wang
#t 2007
#c 18
#! Data streams are often locally correlated, with a subset of streams exhibiting coherent patterns over a subset of time points. Subspace clustering can discover clusters of objects in different subspaces. However, traditional subspace clustering algorithms for static data sets are not readily used for incremental clustering, and is very expensive for frequent re-clustering over dynamically changing stream data. In this paper, we present an efficient incremental subspace clustering algorithm for multiple streams over sliding windows. Our algorithm detects all the -CC-Clusters, which capture the coherent changing patterns among a set of streams over a set of time points. -CC-Clusters are incrementally generated by traversing a directed acyclic graph pDAG. We propose efficient insertion and deletion operations to update the pDAG dynamically. In addition, effective pruning techniques are applied to reduce the search space. Experiments on real data sets demonstrate the performance of our algorithm.

#index 1117089
#* Noise Modeling with Associative Corruption Rules
#@ Yan Zhang;Xindong Wu
#t 2007
#c 18
#! This paper presents an active learning approach to the problem of systematic noise inference and noise elimination, specifically the inference of Associated Corruption (AC) rules. AC rules are defined to simulate a common noise formation process in real-world data, in which the occurrence of an error on one attribute is dependent on several other attribute values. Our approach consists of two algorithms, Associative Corruption Forward (ACF) and Associative Corruption Backward (ACB). Algorithm ACF is proposed for noise inference, and ACB is designed for noise elimination. The experimental results show that the ACF algorithm can infer the noise formation correctly, and ACB indeed enhances the data quality for supervised learning.

#index 1117090
#* Invited Speakers and Their Talk Descriptions
#@ 
#t 2007
#c 18

#index 1117091
#* Tutorials and Their Descriptions
#@ 
#t 2007
#c 18

#index 1117092
#* How Much Noise Is Too Much: A Study in Automatic Text Classification
#@ Sumeet Agarwal;Shantanu Godbole;Diwakar Punjani;Shourya Roy
#t 2007
#c 18
#! Noise is a stark reality in real life data. Especially in the domain of text analytics, it has a significant impact as data cleaning forms a very large part of the data processing cycle. Noisy unstructured text is common in informal settings such as on-line chat, SMS, email, newsgroups and blogs, automatically transcribed text from speech, and automatically recognized text from printed or handwritten material. Gigabytes of such data is being generated everyday on the Internet, in contact centers, and on mobile phones. Researchers have looked at various text mining issues such as pre-processing and cleaning noisy text, information extraction, rule learning, and classification for noisy text. This paper focuses on the issues faced by automatic text classifiers in analyzing noisy documents coming from various sources. The goal of this paper is to bring out and study the effect of different kinds of noise on automatic text classification. Does the nature of such text warrant moving beyond traditional text classification techniques? We present detailed experimental results with simulated noise on the Reuters21578 and 20-newsgroups benchmark datasets. We present interesting results on real-life noisy datasets from various CRM domains.

#index 1117093
#* Clustering Needles in a Haystack: An Information Theoretic Analysis of Minority and Outlier Detection
#@ Shin Ando
#t 2007
#c 18
#! Identifying atypical objects is one of the traditional topics in machine learning. Recently, novel approaches, e.g., Minority Detection and One-class clustering, have explored further to identify clusters of atypical objects which strongly contrast from the rest of the data in terms of their distribution or density. This paper analyzes such tasks from an information theoretic perspective. Based on Information Bottleneck formalization, these tasks interpret to increasing the averaged atypicalness of the clusters while reducing the complexity of the clustering. This formalization yields a unifying view of the new approaches as well as the classic outlier detection. We also present a scalable minimization algorithm which exploits the localized form of the cost function over individual clusters. The proposed algorithm is evaluated using simulated datasets and a text classification benchmark, in comparison with an existing method.

#index 1176150
#* Proceedings of the 2008 Eighth IEEE International Conference on Data Mining
#@ 
#t 2008
#c 18

#index 1176853
#* On-line LDA: Adaptive Topic Models for Mining Text Streams with Applications to Topic Detection and Tracking
#@ Loulwah AlSumait;Daniel Barbará;Carlotta Domeniconi
#t 2008
#c 18
#! This paper presents Online Topic Model (OLDA), a topic model that automatically captures the thematic patterns and identifies emerging topics of text streams and their changes over time. Our approach allows the topic modeling framework, specifically the Latent Dirichlet Allocation (LDA) model, to work in an online fashion such that it incrementally builds an up-to-date model (mixture of topics per document and mixture of words per topic) when a new document (or a set of documents) appears. A solution based on the Empirical Bayes method is proposed. The idea is to incrementally update the current model according to the information inferred from the new stream of data with no need to access previous data. The dynamics of the proposed approach also provide an efficient mean to track the topics over time and detect the emerging topics in real time. Our method is evaluated both qualitatively and quantitatively using benchmark datasets. In our experiments, the OLDA has discovered interesting patterns by just analyzing a fraction of data at a time. Our tests also prove the ability of OLDA to align the topics across the epochs with which the evolution of the topics over time is captured. The OLDA is also comparable to, and sometimes better than, the original LDA in predicting the likelihood of unseen documents.

#index 1176854
#* Unsupervised Cross-Domain Learning by Interaction Information Co-clustering
#@ Shin Ando;Einoshin Suzuki
#t 2008
#c 18
#! In real-world data mining applications, one often has access to multiple datasets that are relevant to the task at hand. However, learning from such datasets can be difficult as they are often drawn from different domains, i.e., not identically distributed or differ in class or feature sets. In this paper, we consider the problem of learning the class structures %, unique and shared, of related domains in an unsupervised manner. Its setting generalizes that of information filtering and novelty detection applications which addresses both known and unknown classes. We propose a co-clustering framework for estimating and adapting the class structures of two related domains, {enabling the analyses of shared and unique classes.} We define an objective function using interaction information to take account of the divergence between the corresponding clusters of respective domains. We present an iterative algorithm which alternates object and feature clustering and converges to a local minimum of the objective function. We present empirical results using text benchmarks, comparing the proposed algorithm and combinations of conventional approaches in problems of partitioning documents and detecting unknown topics.

#index 1176855
#* Paired Learners for Concept Drift
#@ Stephen H. Bach;Marcus A. Maloof
#t 2008
#c 18
#! To cope with concept drift, we paired a stable online learner with a reactive one. A stable learner predicts based on all of its experience, whereas are active learner predicts based on its experience over a short, recent window of time. The method of paired learning uses differences in accuracy between the two learners over this window to determine when to replace the current stable learner, since the stable learner performs worse than does there active learner when the target concept changes. While the method uses the reactive learner as an indicator of drift, it uses the stable learner to predict, since the stable learner performs better than does the reactive learner when acquiring target concept. Experimental results support these assertions. We evaluated the method by making direct comparisons to dynamic weighted majority, accuracy weighted ensemble, and streaming ensemble algorithm (SEA) using two synthetic problems, the Stagger concepts and the SEA concepts, and three real-world data sets: meeting scheduling, electricity prediction, and malware detection. Results suggest that, on these problems, paired learners outperformed or performed comparably to methods more costly in time and space.

#index 1176856
#* Predicting Future Decision Trees from Evolving Data
#@ Mirko Böttcher;Martin Spott;Rudolf Kruse
#t 2008
#c 18
#! Recognizing and analyzing change is an important human virtue because it enables us to anticipate future scenarios and thus allows us to act pro-actively. One approach to understand change within a domain is to analyze how modelsand patterns evolve. Knowing how a model changes over time is suggesting to ask: Can we use this knowledge to learn a model in anticipation, such that it better reflects the near-future characteristics of an evolving domain? In this paper we provide an answer to this question by presenting an algorithm which predicts future decision trees based ona model of change. In particular, this algorithm encompasses a novel approach to change mining which is based on analyzing the changes of the decisions made during model learning. The proposed approach can also be applied to other types of classifiers and thus provides a basis for future research. We present our first experimental results which show that anticipated decision trees have the potential to outperform trees learned on the most recent data.

#index 1176857
#* A Randomized Approach for Approximating the Number of Frequent Sets
#@ Mario Boley;Henrik Grosskreutz
#t 2008
#c 18
#! We investigate the problem of counting the number of frequent (item)sets---a problem known to be intractable in terms of an exact polynomial time computation. In this paper, we show that it is in general also hard to approximate. Subsequently, a randomized counting algorithm is developed using the Markov chain Monte Carlo method. While for general inputs an exponential running time is needed in order to guarantee a certain approximation bound, we empirically show that the algorithm still has the desired accuracy on real-world datasets when its running time is capped polynomially.

#index 1176858
#* Cost-Sensitive Parsimonious Linear Regression
#@ Robby Goetschalckx;Kurt Driessens;Scott Sanner
#t 2008
#c 18
#! We examine linear regression problems where some features may only be observable at a cost (e.g., in medical domains where features may correspond to diagnostic tests that take time and costs money). This can be important in the context of data mining, in order to obtain the best predictions from the data on a limited cost budget. We define a parsimonious linear regression objective criterion that jointly minimizes prediction error and feature cost. We modify least angle regression algorithms commonly used for sparse linear regression to produce the ParLiR algorithm, whichnot only provides an efficient and parsimonious solution as we demonstrate empirically, but it also provides formal guarantees that we prove theoretically.

#index 1176859
#* Text Mining in Radiology Reports
#@ Tianxia Gong;Chew Lim Tan;Tze Yun Leong;Cheng Kiang Lee;Boon Chuan Pang;C. C.  Tchoyoson Lim;Qi Tian;Suisheng Tang;Zhuo Zhang
#t 2008
#c 18
#! Medical text mining has gained increasing interest in recent years. Radiology reports contain rich information describing radiologist’s observations on the patient’s medical conditions in the associated medical images. However, as most reports are in free text format, the valuable information contained in those reports cannot be easily accessed and used, unless proper text mining has been applied. In this paper, we propose a text mining system to extract and use the information in radiology reports. The system consists of three main modules: a medical finding extractor, a report and image retriever, and a text-assisted image feature extractor. In evaluation, the overall precision and recall for medical finding extraction are 95.5% and 87.9% respectively, and for all modifiers of the medical findings 88.2% and 82.8% respectively. The overall result of report and image retrieval module and text-assisted image feature extraction module is satisfactory to radiologists.

#index 1176860
#* A Hierarchical Algorithm for Clustering Uncertain Data via an Information-Theoretic Approach
#@ Francesco Gullo;Giovanni Ponti;Andrea Tagarelli;Sergio Greco
#t 2008
#c 18
#! In recent years there has been a growing interest in clustering uncertain data. In contrast to traditional, "sharp" data representation models, uncertain data objects can be represented in terms of an uncertainty region over which a probability density function (pdf) is defined. In this context, the focus has been mainly on partitional and density-based approaches, whereas hierarchical clustering schemes have drawn less attention.We propose a centroid-linkage-based agglomerative hierarchical algorithm for clustering uncertain objects, named U-AHC. The cluster merging criterion is based on an information-theoretic measure to compute the distance between cluster prototypes. These prototypes are represented as mixture densities that summarize the pdfs of all the uncertain objects in the clusters. Experiments have shown that our method outperforms state-of-the-art clustering algorithms from an accuracy viewpoint while achieving reasonably good efficiency.

#index 1176861
#* Discovering Significant Patterns in Multi-stream Sequences
#@ Robert Gwadera;Fabio Crestani
#t 2008
#c 18
#! Discovering significant patterns in synchronized multi-stream sequences also known as multi-attribute event sequences (multi-sequences), is an important problem in many domains, including monitoring systems and information retrieval. In this paper we propose a new approach for assessing significance of multi-stream patterns in multi-attribute event sequences. In experiments on physiological multi-stream data we show applicability of our method.

#index 1176862
#* Graph-Based Rare Category Detection
#@ Jingrui He;Yan Liu;Richard Lawrence
#t 2008
#c 18
#! Rare category detection is the task of identifying examples from rare classes in an unlabeled data set. It is an open challenge in machine learning and plays key roles in real applications such as financial fraud detection, network intrusion detection, astronomy, spam image detection, etc. In this paper, we develop a new graph-based method for rare category detection named GRADE. It makes use of the global similarity matrix motivated by the manifold ranking algorithm, which results in more compact clusters for the minority classes; by selecting examples from the regions where probability density changes the most, it relaxes the assumption that the majority classes and the minority classes are separable. Furthermore, when detailed information about the data set is not available, we develop a modified version of GRADE named GRADE-LI, which only needs an upper bound on the proportion of each minority class as input. Besides working with data with structured features, both GRADE and GRADE-LI can also work with graph data, which can not be handled by existing rare category detection methods. Experimental results on both synthetic and real data sets demonstrate the effectiveness of the GRADE and GRADE-LI algorithms.

#index 1176863
#* Clustering Documents with Active Learning Using Wikipedia
#@ Anna Huang;David Milne;Eibe Frank;Ian H. Witten
#t 2008
#c 18
#! Wikipedia has been applied as a background knowledge base to various text mining problems, but very few attempts have been made to utilize it for document clustering. In this paper we propose to exploit the semantic knowledge in Wikipedia for clustering, enabling the automatic grouping of documents with similar themes. Although clustering is intrinsically unsupervised, recent research has shown that incorporating supervision improves clustering performance, even when limited supervision is provided. The approach presented in this paper applies supervision using active learning. We first utilize Wikipedia to create a concept-based representation of a text document, with each concept associated to a Wikipedia article. We then exploit the semantic relatedness between Wikipedia concepts to find pair-wise instance-level constraints for supervised clustering, guiding clustering towards the direction indicated by the constraints. We test our approach on three standard text document datasets. Empirical results show that our basic document representation strategy yields comparable performance to previous attempts; and adding constraints improves clustering performance further by up to 20%.

#index 1176864
#* A Non-parametric Semi-supervised Discretization Method
#@ A. Bondu;M. Boulle;V. Lemaire;S. Loiseau;B. Duval
#t 2008
#c 18
#! Semi-supervised classification methods aim to exploit labelled and unlabelled examples to train a predictive model. Most of these approaches make assumptions on the distribution of classes. This article first proposes a new semi-supervised discretization method which adopts very low informative prior on data. This method discretizes the numerical domain of a continuous input variable, while keeping the information relative to the prediction of classes. Then, an in-depth comparison of this semi-supervised method with the original supervised MODL approach is presented. We demonstrate that the semi-supervised approach is asymptotically equivalent to the supervised approach, improved with a post-optimizationof the intervals bounds location.

#index 1176865
#* Non-negative Matrix Factorization on Manifold
#@ Deng Cai;Xiaofei He;Xiaoyun Wu;Jiawei Han
#t 2008
#c 18
#! Recently Non-negative Matrix Factorization (NMF) has received a lot of attentions in information retrieval, computer vision and pattern recognition. NMF aims to find two non-negative matrices whose product can well approximate the original matrix. The sizes of these two matrices are usually smaller than the original matrix. This results in a compressed version of the original data matrix. The solution of NMF yields a natural parts-based representation for the data. When NMF is applied for data representation, a major disadvantage is that it fails to consider the geometric structure in the data. In this paper, we develop a graph based approach for parts-based data representation in order to overcome this limitation. We construct an affinity graph to encode the geometrical information and seek a matrix factorization which respects the graph structure. We demonstrate the success of this novel algorithm by applying it on real world problems.

#index 1176866
#* Anti-monotonic Overlap-Graph Support Measures
#@ Toon Calders;Jan Ramon;Dries Van Dyck
#t 2008
#c 18
#! In graph mining, a frequency measure is anti-monotonic if the frequency of a pattern never exceeds the frequency of a subpattern. The efficiency and correctness of most graph pattern miners relies critically on this property. We study the case where the dataset is a single graph. Vanetik, Gudes and Shimony already gave sufficient and necessary conditions for anti-monotonicity of measures depending only on the edge-overlaps between the intances of the pattern in a labeled graph. We extend these results to homomorphisms, isomorphisms and homeomorphisms on both labeled and unlabeled, directed and undirected graphs, for vertex and edge overlap. We show a set of reductions between the different morphisms that preserve overlap. We also prove that the popular maximum independent set measure assigns the minimal possible meaningful frequency, introduce a new measure based on the minimum clique partition that assigns the maximum possible meaningful frequency and introduce a new measure sandwiched between the former two based on the poly-time computable Lovasz theta-function.

#index 1176867
#* SeqStream: Mining Closed Sequential Patterns over Stream Sliding Windows
#@ Lei Chang;Tengjiao Wang;Dongqing Yang;Hua Luan
#t 2008
#c 18
#! Previous studies have shown mining closed patterns provides more benefits than mining the complete set of frequent patterns, since closed pattern mining leads to more compact results and more efficient algorithms. It is quite useful in a data stream environment where memory and computation power are major concerns. This paper studies the problem of mining closed sequential patterns over data stream sliding windows. A synopsis structure IST (Inverse Closed Sequence Tree) is designed to keep inverse closed sequential patterns in current window. An efficient algorithm SeqStream is developed to mine closed sequential patterns in stream windows incrementally, and various novel strategies are adopted in SeqStream to prune search space aggressively. Extensive experiments on both real and synthetic data sets show that SeqStream outperforms PrefixSpan, CloSpan and BIDE by a factor of about one to two orders of magnitude.

#index 1176868
#* SPARCL: Efficient and Effective Shape-Based Clustering
#@ Vineet Chaoji;Mohammad Al Hasan;Saeed Salem;Mohammed J. Zaki
#t 2008
#c 18
#! Clustering is one of the fundamental data mining tasks. Many different clustering paradigms have been developed over the years, which include partitional, hierarchical, mixture model based, density-based, spectral, subspace, and so on. The focus of this paper is on full-dimensional, arbitrary shaped clusters. Existing methods for this problem suffer either in terms of the memory or time complexity (quadratic or even cubic). This shortcoming has restricted these algorithms to datasets of moderate sizes. In this paper we propose SPARCL, a simple and scalable algorithm for finding clusters with arbitrary shapes and sizes, and it has linear space and time complexity. SPARCL consists of two stages -- the first stage runs a carefully initialized version of the Kmeans algorithm to generate many small seed clusters. The second stage iteratively merges the generated clusters to obtain the final shape-based clusters. Experiments were conducted on a variety of datasets to highlight the effectiveness, efficiency, and scalability of our approach. On the large datasets SPARCL is an order of magnitude faster than the best existing approaches.

#index 1176869
#* Mining Order-Preserving Submatrices from Data with Repeated Measurements
#@ Chun Kit Chui;Ben Kao;Kevin Y. Yip;Sau Dan Lee
#t 2008
#c 18
#! Order-preserving submatrices (OPSM's) have been shown useful in capturing concurrent patterns in data when the relative magnitudes of data items are more important than their absolute values. To cope with data noise, repeated experiments are often conducted to collect multiple measurements. We propose and study a more robust version of OPSM, where each data item is represented by a set of values obtained from replicated experiments. We call the new problem OPSM-RM (OPSM with repeated measurements). We define OPSM-RM based on a number of practical requirements. We discuss the computational challenges of OPSM-RM and propose a generic mining algorithm. We further propose a series of techniques to speed up two time-dominating components of the algorithm. We clearly show the effectiveness of our methods through a series of experiments conducted on real microarray data.

#index 1176870
#* Direct Zero-Norm Optimization for Feature Selection
#@ Kaizhu Huang;Irwin King;Michael R. Lyu
#t 2008
#c 18
#! Zero-norm, defined as the number of non-zero elements in a vector, is an ideal quantity for feature selection. However, minimization of zero-norm is generally regarded as a combinatorially difficult optimization problem. In contrast to previous methods that usually optimize a surrogate of zero-norm, we propose a direct optimizationmethod to achieve zero-norm for feature selection in this paper. Based on Expectation Maximization (EM), this method boils down to solving a sequence of Quadratic Programming problems and hence can be practically optimized in polynomial time. We show that the proposed optimization technique has a nice Bayesian interpretation and converges to the true zero norm asymptotically, provided that agood starting point is given. Following the scheme of our proposed zero-norm, we even show that an arbitrary-norm based Support Vector Machine can be achieved in polynomial time. A series of experiments demonstrate that our proposed EM based zero-norm outperforms other state-of-the-art methods for feature selection on biological microarray data and UCI data, in terms of both the accuracy and the learning efficiency.

#index 1176871
#* Discovering Flow Anomalies: A SWEET Approach
#@ James M. Kang;Shashi Shekhar;Christine Wennen;Paige Novak
#t 2008
#c 18
#! Given a percentage-threshold and readings from a pair of consecutive upstream and downstream sensors, flow anomaly discovery identifies dominant time intervals where the fraction of time instants of significantly mis-matched sensor readings exceed the given percentage-threshold. Discovering flow anomalies (FA) is an important problem in environmental flow monitoring networks and early warning detection systems for water quality problems. However, mining FAs is computationally expensive because of the large (potentially infinite) number of time instants of measurement and potentially long delays due to stagnant (e.g. lakes) or slow moving (e.g. wetland) water bodies between consecutive sensors. Traditional outlier detection methods (e.g. t-test) are suited for detecting transient FAs (i.e., time instants of significant mis-matches across consecutive sensors) and cannot detect persistent FAs (i.e., long variable time-windows with a high fraction of time instant transient FAs) due to a lack of a pre-defined window size. In contrast, we propose a Smart Window Enumeration and Evaluation of persistence-Thresholds (SWEET) method to efficiently explore the search space of all possible window lengths. Computation overhead is brought down significantly by restricting the start and end points of a window to coincide with transient FAs, using a smart counter and efficient pruning techniques. Experimental evaluation using a real dataset shows our proposed approach outperforms Naıve alternatives.

#index 1176872
#* Boosting Relational Sequence Alignments
#@ Andreas Karwath;Kristian Kersting;Niels Landwehr
#t 2008
#c 18
#! The task of aligning sequences arises in many applications. Classical dynamic programming approaches require the explicit state enumeration in the reward model. This is often impractical: the number of states grows very quickly with the number of domain objects and relations among these objects. Relational sequence alignment aims at exploiting symbolic structure to avoid the full enumeration. This comes at the expense of a more complex reward model selection problem: virtually infinitely many abstraction levels have to be explored. In this paper, we apply gradient-based boosting to leverage this problem. Specifically, we show how to reduce the learning problem to a series of relational regressions problems. The main benefit of this is that interactions between states variables are introduced only as needed, so that the potentially infinite search space is not explicitly considered. As our experimental results show, this boosting approach can significantly improve upon established results in challenging applications.

#index 1176873
#* Support Vector Regression for Censored Data (SVRc): A Novel Tool for Survival Analysis
#@ Faisal M. Khan;Valentina Bayer Zubek
#t 2008
#c 18
#! A crucial challenge in predictive modeling for survival analysis is managing censored observations in the data. The Cox proportional hazards model is the standard tool for the analysis of continuous censored survival data. We propose a novel machine learning algorithm, Support Vector Regression for Censored Data (SVRc) for improved analysis of medical survival data. SVRc leverages the high-dimensional capabilities of traditional SVR while adapting it for use with censored data through a modified asymmetric loss/penalty function which allows censored (left and right censored) data to be processed. We applied the new algorithm to predict the recurrence and disease progression of prostate cancer, breast cancer and lung cancer. Compared with the traditional Cox model, SVRc achieves significant improvement in overall accuracy as well as in the ability to identify high-risk and low-risk patient populations.

#index 1176874
#* Nearest Neighbour Classifiers for Streaming Data with Delayed Labelling
#@ Ludmila I. Kuncheva;J. Salvador Sánchez
#t 2008
#c 18
#! We study streaming data where the true labels come with a delay. The question is whether the online nearest neighbour classifier (IB2 and IB3 here) should employ the unlabelled data. Three strategies are examined: do-nothing, replace and forget. Experiments with 28 data sets show that IB2 benefits from unlabelled data, while IB3 does not.

#index 1176875
#* WiFIsViz: Effective Visualization of Frequent Itemsets
#@ Carson Kai-Sang Leung;Pourang P. Irani;Christopher L. Carmichael
#t 2008
#c 18
#! Frequent itemset mining plays an essential role in the mining of many different patterns. Most existing frequent itemset mining algorithms return the mined results--namely, frequent itemsets--in the form of textual lists. However, the use of visual representation can enhance the user understanding of the inherent relations in a collection of frequent itemsets. In this paper, we propose an effective visualizer, called WiFIsViz, to display the mined frequent itemsets. WiFIsViz provides users with an overview and details about the itemsets. Moreover, this visualizer is also equipped with several interactive features for effective visualization of the frequent itemsets mined from various real-life applications.

#index 1176876
#* Graph OLAP: Towards Online Analytical Processing on Graphs
#@ Chen Chen;Xifeng Yan;Feida Zhu;Jiawei Han;Philip S. Yu
#t 2008
#c 18
#! OLAP (On-Line Analytical Processing) is an important notion in data analysis. Recently, more and more graph or networked data sources come into being. There exists a similar need to deploy graph analysis from different perspectives and with multiple granularities. However, traditional OLAP technology cannot handle such demands because it does not consider the links among individual data tuples. In this paper, we develop a novel graph OLAP framework, which presents a multi-dimensional and multi-level view over graphs. The contributions of this work are two-fold. First, starting from basic definitions, i.e., what are dimensions and measures in the graph OLAP scenario, we develop a conceptual framework for data cubes on graphs. We also look into different semantics of OLAP operations, and classify the framework into two major subcases: informational OLAP and topological OLAP. Then, with more emphasis on informational OLAP (topological OLAP will be covered in a future study due to the lack of space), we show how a graph cube can be materialized by calculating a special kind of measure called aggregated graph and how to implement it efficiently. This includes both full materialization and partial materialization where constraints are enforced to obtain an iceberg cube. We can see that the aggregated graphs, which depend on the graph properties of underlying networks, are much harder to compute than their traditional OLAP counterparts, due to the increased structural complexity of data. Empirical studies show insightful results on real datasets and demonstrate the efficiency of our proposed optimizations.

#index 1176877
#* Exploiting Local and Global Invariants for the Management of Large Scale Information Systems
#@ Haifeng Chen;Haibin Cheng;Guofei Jiang;Kenji Yoshihira
#t 2008
#c 18
#! This paper presents a data oriented approach to modeling the complex computing systems, in which an ensemble of correlation models are discovered to represent the system status. If the discovered correlations can continually hold under different user scenarios and workloads, they are regarded as invariants of the information system. In our previous work, we have developed an algorithm to automatically search the invariants between any pair of system attributes, which we call local invariants. However that method is unable to deal with the high order dependency models due to the combinatorial explosion of search space. In this paper we use Bayesian regression technique to discover those high order correlation models, called global invariants. We treat each attribute as a response variable in turn and express its dependency with the other attributes in a regression model. By adding the prior constraint of Laplacian distribution to the regression coefficients, we can find the solution in which only the correlated attributes with respect to the response have nonzero regression coefficients. After that we further consider the temporal dependencies of those extracted attributes by incorporating their past observations. We also provide a confidence metric and a validation procedure to measure the reliability of learned models. If the model does not break down in the validation, it is regarded as a true invariant of the system. Experimental results on a real wireless networking system show that the discovered invariants can be used to effectively detect system failures as well as provide valuable information about the failure source.

#index 1176878
#* DECK: Detecting Events from Web Click-Through Data
#@ Ling Chen;Yiqun Hu;Wolfgang Nejdl
#t 2008
#c 18
#! In the past few years there has been increased research interest in detecting previously unidentified events from Web resources. Our focus in this paper is to detect events from the click-through data generated by Web search engines. Existing event detection algorithms, which mainly study the news archive data, cannot be employed directly because of the following two unique features of click-through data: 1) the information provided by click-through data is quite limited; 2) not every query issued to a Web search engine corresponds to an event in the real world. In this paper, we address this problem by proposing an effective algorithm which Detects Events from ClicK-through data DECK. We firstly transform click-through data to the 2D polar space by considering the semantic dimension and temporal dimension of queries. Robust subspace estimation is performed to detect subspaces such that each subspace consists of queries of similar semantics. Next, we prune uninteresting subspaces which do not contain queries corresponding to real events by simultaneously considering the respective distribution of queries along the semantic dimension and the temporal dimension in each subspace. Finally, events are detected from interesting subspaces using a nonparametric clustering technique. Compared with an existing approach, our experimental results based on real-life data have shown that the proposed approach is more accurate and effective in detecting real events from click-through data.

#index 1176879
#* Start Globally, Optimize Locally, Predict Globally: Improving Performance on Imbalanced Data
#@ David A. Cieslak;Nitesh V. Chawla
#t 2008
#c 18
#! Class imbalance is a ubiquitous problem in supervised learning and has gained wide-scale attention in the literature. Perhaps the most prevalent solution is to applysampling to training data in order improve classiﬁer performance. The typical approach will apply uniform levels of sampling globally. However, we believe that datais typically multi-modal, which suggests sampling shouldbe treated locally rather than globally. It is the purposeof this paper to propose a framework which ﬁrst identiﬁes meaningful regions of data and then proceeds to ﬁndoptimal sampling levels within each. This paper demonstrates that a global classiﬁer trained on data locally sampled produces superior rank-orderings on a wide range ofreal-world and artiﬁcial datasets as compared to contemporary global sampling methods.

#index 1176880
#* Fast and Memory Efficient Mining of High Utility Itemsets in Data Streams
#@ Hua-Fu Li;Hsin-Yun Huang;Yi-Cheng Chen;Yu-Jiun Liu;Suh-Yin Lee
#t 2008
#c 18
#! Efficient mining of high utility itemsets has become one of the most interesting data mining tasks with broad applications. In this paper, we proposed two efficient one-pass algorithms, MHUI-BIT and MHUI-TID, for mining high utility itemsets from data streams within a transaction-sensitive sliding window. Two effective representations of item information and an extended lexicographical tree-based summary data structure are developed to improve the efficiency of mining high utility itemsets. Experimental results show that the proposed algorithms outperform than the existing algorithms for mining high utility itemsets from data streams.

#index 1176881
#* HIREL: An Incremental Clustering Algorithm for Relational Datasets
#@ Tao Li;Sarabjot S. Anand
#t 2008
#c 18
#! Traditional clustering approaches usually analyze static datasets in which objects are kept unchanged after being processed, but many practical datasets are dynamically modified which means some previously learned patterns have to be updated accordingly. Re-clustering the whole dataset from scratch is not a good choice due to the frequent data modifications and the limited out-of-service time, so the development of incremental clustering approaches is highly desirable. Besides that, propositional clustering algorithms are not suitable for relational datasets because of their quadratic computational complexity. In this paper, we propose an incremental clustering algorithm that requires only one pass of the relational dataset. The utilization of the Representative Objects and the balanced Search Tree greatly accelerate the learning procedure. Experimental results prove the effectiveness of our algorithm.

#index 1176882
#* Time Sensitive Ranking with Application to Publication Search
#@ Xin Li;Bing Liu;Philip Yu
#t 2008
#c 18
#! Link-based ranking has contributed significantly to the success of Web search. PageRank and HITS are the best known link-based ranking algorithms. These algorithms do not consider an important dimension, the temporal dimension. They favor older pages because these pages have many in-links accumulated over time. Bringing new and quality pages to the users is important because most users want the latest information. Existing remedies to PageRank are mostly heuristic approaches. This paper investigates the temporal aspect of ranking with application to publication search, and proposes a principled method based on the stationary probability distribution of the Markov Chain. The proposed techniques are evaluated empirically using a large collection of high energy particle physics publication. The results show that the proposed methods are highly effective.

#index 1176883
#* Releasing the SVM Classifier with Privacy-Preservation
#@ Keng-Pei Lin;Ming-Syan Chen
#t 2008
#c 18
#! Support vector machine (SVM) is a widely used tool in classification problem. SVM solves a quadratic optimization problem to decide which instances of training dataset are support vectors, i.e., the necessarily informative instances to form the classifier. The support vectors are intact tuples taken from the training dataset. Releasing the SVM classifier to public use or shipping the SVM classifier to clients will disclose the private content of support vectors, violating the privacy-preservation requirement in some legal or commercial reasons. To the best of our knowledge, there has not been work extending the notion of privacy-preservation to releasing the SVM classifier. In this paper, we propose an approximation approach which post-processes the SVM classifier to protect the private content of support vectors. This approach is designed for the commonly used Gaussian radial basis function kernel. By applying this post-processor on the SVM classifier, the resulted privacy-preserving SVM classifier can be publicly released without exposing the private content of support vectors and is able to provide comparable classification accuracy to the original SVM classifier.

#index 1176884
#* Text Cube: Computing IR Measures for Multidimensional Text Database Analysis
#@ Cindy Xide Lin;Bolin Ding;Jiawei Han;Feida Zhu;Bo Zhao
#t 2008
#c 18
#! Since Jim Gray introduced the concept of ”data cube” in 1997, data cube, associated with online analytical processing (OLAP), has become a driving engine in data warehouse industry. Because the boom of Internet has given rise to an ever increasing amount of text data associated with other multidimensional information, it is natural to propose a data cube model that integrates the power of traditional OLAP and IR techniques for text. In this paper, we propose a Text-Cube model on multidimensional text database and study effective OLAP over such data. Two kinds of hierarchies are distinguishable inside: dimensional hierarchy and term hierarchy. By incorporating these hierarchies, we conduct systematic studies on efficient text-cube implementation, OLAP execution and query processing. Our performance study shows the high promise of our methods.

#index 1176885
#* Multi-Space-Mapped SVMs for Multi-class Classification
#@ Bo Liu;Longbing Cao;Philip S. Yu;Chengqi Zhang
#t 2008
#c 18
#! In SVMs-based multiple classification, it is not always possible to find an appropriate kernel function to map all the classes from different distribution functions into a feature space where they are linearly separable from each other. This is even worse if the number of classes is very large. As a result, the classification accuracy is not as good as expected. In order to improve the performance of SVMs-based multi-classifiers, this paper proposes a method, named multi-space-mapped SVMs, to map the classes into different feature spaces and then classify them. The proposed method reduces the requirements for the kernel function. Substantial experiments have been conducted on One-against-All, One-against-One, FSVM, DDAG algorithms and our algorithm using six UCI data sets. The statistical results show that the proposed method has a higher probability of finding appropriate kernel functions than traditional methods and outperforms others.

#index 1176886
#* Generalized Framework for Syntax-Based Relation Mining
#@ Bonaventura Coppola;Alessandro Moschitti;Daniele Pighin
#t 2008
#c 18
#! Supervised approaches to Data Mining are particularly appealing as they allow for the extraction of complex relations from data objects. In order to facilitate their application in different areas, ranging from protein to protein interaction in bioinformatics to text mining in computational linguistics research, a modular and general mining framework is needed. The major constraint to the generalization process concerns the feature design for the description of relational data. In this paper, we present a machine learning framework for the automatic mining of relations, where the target objects are structurally organized in a tree. Object types are generalized by means of the use of roles, whereas the relation properties are described by means of the underlying tree structure. The latter is encoded in the learning algorithm thanks to kernel methods for structured data, which represent structures in terms of their all possible subparts. This approach can be applied to any kind of data disregarding their very nature. Experiments with Support Vector Machines on two text mining datasets for relation extraction, i.e. the PropBank and FrameNet corpora, show both that our approach is general, and that it reaches state-of-the-art accuracy.

#index 1176887
#* Formal Models for Expert Finding on DBLP Bibliography Data
#@ Hongbo Deng;Irwin King;Michael R. Lyu
#t 2008
#c 18
#! Finding relevant experts in a specific field is often crucial for consulting, both in industry and in academia. The aim of this paper is to address the expert-finding task in a real world academic field. We present three models for expert finding based on the large-scale DBLP bibliography and Google Scholar for data supplementation. The first, a novel weighted language model, models an expert candidate based on the relevance and importance of associated documents by introducing a document prior probability, and achieves much better results than the basic language model. The second, a topic-based model, represents each candidate as a weighted sum of multiple topics, whilst the third, a hybrid model, combines the language model and the topic-based model. We evaluate our system using a benchmark dataset based on human relevance judgments of how well the expertise of proposed experts matches a query topic. Evaluation results show that our hybrid model outperforms other models in nearly all metrics.

#index 1176888
#* ReDSOM: Relative Density Visualization of Temporal Changes in Cluster Structures Using Self-Organizing Maps
#@  Denny;Graham J. Williams;Peter Christen
#t 2008
#c 18
#! We introduce a Self-Organizing Map (SOM) based visualization method that compares cluster structures in temporal datasets using Relative Density SOM (ReDSOM) visualization. Our method, combined with a distance matrix-based visualization, is capable of visually identifying emerging clusters, disappearing clusters, enlarging clusters, contracting clusters, the shifting of cluster centroids, and changes in cluster density. For example, when a region in a SOM becomes significantly more dense compared to an earlier SOM, and well separated from other regions, then the new region can be said to represent a new cluster. The capabilities of ReDSOM are demonstrated using synthetic datasets, as well as real-life datasets from the World Bank and the Australian Taxation Office. The results on the real-life datasets demonstrate that changes identified interactively can be related to actual changes. The identification of such cluster changes is important in many contexts, including the exploration of changes in population behavior in the context of compliance and fraud in taxation.

#index 1176889
#* Nonnegative Matrix Factorization for Combinatorial Optimization: Spectral Clustering, Graph Matching, and Clique Finding
#@ Chris Ding;Tao Li;Michael I. Jordan
#t 2008
#c 18
#! Nonnegative matrix factorization (NMF) is a versatile model for data clustering. In this paper, we propose several NMF inspired algorithms to solve different data mining problems. They include (1) multi-way normalized cut spectral clustering, (2) graph matching of both undirected and directed graphs, and (3) maximal clique finding on both graphs and bipartite graphs. Key features of these algorithms are (a) they are extremely simple to implement; and (b) they are provably convergent. We conduct experiments to demonstrate the effectiveness of these new algorithms. We also derive a new spectral bound for the size of maximal edge bicliques as a byproduct of our approach.

#index 1176890
#* Space Efficient String Mining under Frequency Constraints
#@ Johannes Fischer;Veli Mäkinen;Niki Välimäki
#t 2008
#c 18
#! Let $\db_1$ and $\db_2$ be two databases (i.e. multisets) of $d$ strings, over an alphabet $\Sigma$, with overall length $n$. We study the problem of mining discriminative patterns between $\db_1$ and $\db_2$ --- e.g., patterns that are frequent in one database but not in the other, emerging patterns, or patterns satisfying other frequency-related constraints. Using the algorithmic framework by Hui (CPM 1992), one can solve several variants of this problem in the optimal linear time with the aid of suffix trees or suffix arrays. This stands in high contrast to other pattern domains such as itemsets or subgraphs, where super-linear lower bounds are known. However, the space requirement of existing solutions is $O(n \log n)$ bits, which is not optimal for $|\Sigma

#index 1176891
#* Efficient Discovery of Statistically Significant Association Rules
#@ Wilhelmiina Hämäläinen;Matti Nykänen
#t 2008
#c 18
#! Searching statistically significant association rules is an important but neglected problem. Traditional association rules do not capture the idea of statistical dependence and the resulting rules can be spurious, while the most significant rules may be missing. This leads to erroneous models and predictions which often become expensive.The problem is computationally very difficult, because the significance is not a monotonic property. However, in this paper we prove several other properties, which can be used for pruning the search space. The properties are implemented in the StatApriori algorithm, which searches statistically significant, non-redundant association rules. Based on both theoretical and empirical observations, the resulting rules are very accurate compared to traditional association rules. In addition, StatApriori can work with extremely low frequencies, thus finding new interesting rules.

#index 1176892
#* Spotting Significant Changing Subgraphs in Evolving Graphs
#@ Zheng Liu;Jeffrey Xu Yu;Yiping Ke;Xuemin Lin;Lei Chen
#t 2008
#c 18
#! Graphs are popularly used to model structural relationships between objects. In many application domains such as social networks, sensor networks and telecommunication, graphs evolve over time. In this paper, we study a new problem of discovering the subgraphs that exhibit significant changes in evolving graphs. This problem is challenging since it is hard to define changing regions that are closely related to the actual changes (i.e., additions/deletions of edges/nodes) in graphs. We formalize the problem, and design an efficient algorithm that is able to identify the changing subgraphs incrementally. Our experimental results on real datasets show that our solution is very efficient and the resultant subgraphs are of high quality.

#index 1176893
#* Classifying High-Dimensional Text and Web Data Using Very Short Patterns
#@ Hassan H. Malik;John R. Kender
#t 2008
#c 18
#! In this paper, we propose the "Democratic Classifier", a simple pattern-based classification algorithm that uses very short patterns for classification, and does not rely on the minimum support threshold. Borrowing ideas from democracy, our training phase allows each training instance to vote for an equal number of candidate size-2 patterns. The training instances select patterns by effectively balancing between local, class, and global significance of patterns. The selected patterns are simultaneously added to the model for all applicable classes and a novel power law based weighing scheme adjusts their weights with respect of each class. Results of experiments performed on 121 common text and web datasets show that our algorithm almost always outperforms state of the art classification algorithms, without any parameter tuning. On 100 real-life web datasets, the average absolute classification accuracy improvement was as great as 9.4% over SVM, Harmony, C4.5 and KNN. Also, our algorithm ran about 3.5 times faster than the fastest existing pattern-based classification algorithm.

#index 1176894
#* A Practical Approach to Classify Evolving Data Streams: Training with Limited Amount of Labeled Data
#@ Mohammad M. Masud;Jing Gao;Latifur Khan;Jiawei Han;Bhavani Thuraisingham
#t 2008
#c 18
#! Recent approaches in classifying evolving data streams are based on supervised learning algorithms, which can be trained with labeled data only. Manual labeling of data is both costly and time consuming. Therefore, in a real streaming environment, where huge volumes of data appear at a high speed, labeled data may be very scarce. Thus, only a limited amount of training data may be available for building the classification models, leading to poorly trained classifiers. We apply a novel technique to overcome this problem by building a classification model from a training set having both unlabeled and a small amount of labeled instances. This model is built as micro-clusters using semisupervised clustering technique and classification is performed with κ-nearest neighbor algorithm. An ensemble of these models is used to classify the unlabeled data. Empirical evaluation on both synthetic data and real botnet traffic reveals that our approach, using only a small amount of labeled data for training, outperforms state-of-the-art stream classification algorithms that use twenty times more labeled data than our approach.

#index 1176895
#* Spatiotemporal Relational Probability Trees: An Introduction
#@ Amy McGovern;Nathan C. Hiers;Matthew Collier;David J. Gagne II;Rodger A. Brown
#t 2008
#c 18
#! We introduce spatiotemporal relational probability trees (SRPTs), probability estimation trees for relational data that can vary in both space and time. The SRPT algorithm addresses the exponential increase in search complexity through sampling. We validate the SRPT using a simulated data set and we empirically demonstrate the SRPT algorithm on two real-world data sets.

#index 1176896
#* Stream Sequential Pattern Mining with Precise Error Bounds
#@ Luiz F. Mendes;Bolin Ding;Jiawei Han
#t 2008
#c 18
#! Sequential pattern mining is an interesting data mining problem with many real-world applications. This problem has been studied extensively in static databases. However, in recent years, emerging applications have introduced a new form of data called data stream. In a data stream, new elements are generated continuously. This poses additional constraints on the methods used for mining such data: memory usage is restricted, the infinitely flowing original dataset cannot be scanned multiple times, and current results should be available on demand.This paper introduces two effective methods for mining sequential patterns from data streams: the SS-BE method and the SS-MB method. The proposed methods break the stream into batches and only process each batch once. The two methods use different pruning strategies that restrict the memory usage but can still guarantee that all true sequential patterns are output at the end of any batch. Both algorithms scale linearly in execution time as the number of sequences grows, making them effective methods for sequential pattern mining in data streams. The experimental results also show that our methods are very accurate in that only a small fraction of the patterns that are output are false positives. Even for these false positives, SS-BE guarantees that their true support is above a pre-defined threshold.

#index 1176897
#* Organic Pie Charts
#@ Fabian Moerchen
#t 2008
#c 18
#! We present a new visualization of the distance and cluster structure of high dimensional data. It is particularly well suited for analysis tasks of users unfamiliar with complex data analysis techniques as it builds on the well known concept of pie charts. The non-linear projection capabilities of Emergent Self-Organizing Maps (ESOM) are used to generate a topology-preserving ordering of the data points on a circle. The distance structure within the high dimensional space is visualized on the circle analogously to the U-Matrix method for two-dimensional SOM. The resulting display resembles pie charts but has an organic structure that naturally emerges from the data. Pie segments correspond to groups of similar data points. Boundaries between segments represent low density regions with larger distances among neighboring points in the high dimensional space. The representation of distances in the form of a periodic sequence of values makes time series segmentation applicable to automated clustering of the data that is in sync with the visualization. We discuss the usefulness of the method on a variety of data sets to demonstrate the applicability in applications such as document analysis or customer segmentation.

#index 1176898
#* Interpreting PET Scans by Structured Patient Data: A Data Mining Case Study in Dementia Research
#@ Andreas Hapfelmeier;Jana Schmidt;Marianne Mueller;Stefan Kramer;Robert Perneczky;Alexander Kurz;Alexander Drzezga
#t 2008
#c 18
#! One of the goals of medical research in the area of dementia is to correlate images of the brain with other variables, for instance, demographic information or outcomes of clinical tests. The usual approach is to select a subset of patients based on such variables and analyze the images associated with those patients. In this paper, we apply data mining techniques to take the opposite approach: We start with the images and explain the differences and commonalities in terms of the other variables. In the first step, we cluster PET scans of patients to form groups sharing similar features in brain metabolism. To the best of our knowledge, it is the first time ever that clustering is applied to whole PET scans. In the second step, we explain the clusters by relating them to non-image variables. To do so, we employ RSD, an algorithm for relational subgroup discovery, with the cluster membership of patients as target variable. Our results enable interesting interpretations of differences in brain metabolism in terms of demographic and clinical variables. The approach was implemented and tested on an exceptionally large pre-existing data collection of patients with different types of dementia. It comprises 10 GB of image data from 454 PET scans, and 42 variables from psychological and demographical data organized in 11 relations of a relational database. We believe that explaining medical images in terms of other variables (patient records, demographic information, etc.) is a challenging new and rewarding area for data mining research.

#index 1176899
#* Inlier-Based Outlier Detection via Direct Density Ratio Estimation
#@ Shohei Hido;Yuta Tsuboi;Hisashi Kashima;Masashi Sugiyama;Takafumi Kanamori
#t 2008
#c 18
#! We propose a new statistical approach to the problem of inlier-based outlier detection, i.e.,finding outliers in the test set based on the training set consisting only of inliers. Our key idea is to use the ratio of training and test data densities as an outlier score; we estimate the ratio directly in a semi-parametric fashion without going through density estimation. Thus our approach is expected to have better performance in high-dimensional problems. Furthermore, the applied algorithm for density ratio estimation is equipped with a natural cross-validation procedure, allowing us to objectively optimize the value of tuning parameters such as the regularization parameter and the kernel width. The algorithm offers a closed-form solution as well as a closed-form formula for the leave-one-out error. Thanks to this, the proposed outlier detection me thod is computationally very efficient and is scalable to massive datasets. Simulations with benchmark and real-world datasets illustrate the usefulness of the proposed approach.

#index 1176900
#* Supervised Inductive Learning with Lotka-Volterra Derived Models
#@ Karen Hovsepian;Peter Anselmo;Subhasish Mazumdar
#t 2008
#c 18
#! We present a classification algorithm built on our adaptation of the Generalized Lotka-Volterra model, well-known in mathematical ecology. The training algorithm itself consists only of computing several scalars, per each training vector, using a single global user parameter and then solving a linear system of equations. Construction of the system matrix is driven by our model and based on kernel functions. The model allows an interesting point of view of kernels' role in the inductive learning process. We describe the model through axiomatic postulates. Finally, we present the results of the preliminary validation experiments.

#index 1176901
#* A Novel Language-Model-Based Approach for Image Object Mining and Re-ranking
#@ Jen-Hao Hsiao;Chu-Song Chen;Ming-Syan Chen
#t 2008
#c 18
#! One leading framework for image object mining is the bag-of-words (BOW) approach. The idea is to encode an image as a collection of visual words of the quantized local patches. Objects in the image can then be retrieved through inferring the semantic topics associated with the set of visual words. However, the visual BOW mining framework is apt to suffer from the so-called term-mismatch problem (a.k.a. vocabulary problem). This is caused by the poverty of query information, and consequently becomes an obstacle to deal with synonymy (i.e., different visual words for describing the same object). In this paper, we propose a novel language-model-based approach with pseudo-relevance feedback for addressing the vocabulary problem in visual BOW mining. We employ the pseudo positive images produced in response to the original query as a set of “cues” to gradually refine the query language model. Unlike traditional approaches that only ruggedly append feedback information into the original query, the proposed approach reconstructs the query language model with finer granularities so that the query concepts can be captured more accurately. The proposed approach is experimentally evaluated using two different types of image object databases. Our algorithms are shown to bring significant improvement in the retrieval accuracy over a non-feedback baseline, and achieve better performance than conventional feedback approaches.

#index 1176902
#* Maximum Margin Clustering with Pairwise Constraints
#@ Yang Hu;Jingdong Wang;Nenghai Yu;Xian-Sheng Hua
#t 2008
#c 18
#! Maximum margin clustering (MMC), which extends the theory of support vector machine to unsupervised learning, has been attracting considerable attention recently. The existing approaches mainly focus on reducing the computational complexity of MMC. The accuracy of these methods, however, has not always been guaranteed. In this paper, we propose to incorporate additional side-information, which is in the form of pairwise constraints, into MMC to further improve its performance. A set of pairwise loss functions are introduced into the clustering objective function which effectively penalize the violation of the given constraints. We show that the resulting optimization problem can be easily solved via constrained concave-convex procedure (CCCP). Moreover, for constrained multi-class MMC, we present an efficient cutting-plane algorithm to solve the sub-problem in each iteration of CCCP. The experiments demonstrate that the pairwise constrained MMC algorithms considerably outperform the unconstrained MMC algorithms and two other clustering algorithms that exploit the same type of side-information.

#index 1176903
#* Frequent Subgraph Retrieval in Geometric Graph Databases
#@ Sebastian Nowozin;Koji Tsuda
#t 2008
#c 18
#! Discovery of knowledge from geometric graph databases is of particular importance in chemistry and biology, because chemical compounds and proteins are represented as graphs with 3D geometric coordinates. In such applications, scientists are not interested in the statistics of the whole database. Instead they need information about a novel drug candidate or protein at hand, represented as a query graph. We propose a polynomial-delay algorithm for geometric frequent subgraph retrieval. It enumerates all subgraphs of a single given query graph which are frequent geometric $\epsilon$-subgraphs under the entire class of rigid geometric transformations in a database. By using geometric$\epsilon$-subgraphs, we achieve tolerance against variations in geometry. We compare the proposed algorithm to gSpan on chemical compound data, and we show that for a given minimum support the total number of frequent patterns is substantially limited by requiring geometric matching. Although the computation time per pattern is larger than for non-geometric graph mining,the total time is within a reasonable level even for small minimum support.

#index 1176904
#* Alert Detection in System Logs
#@ Adam J. Oliner;Alex Aiken;Jon Stearley
#t 2008
#c 18
#! We present Nodeinfo, an unsupervised algorithm for anomaly detection in system logs. We demonstrate Nodeinfo's effectiveness on data from four of the world's most powerful supercomputers: using logs representing over 746 million processor-hours, in which anomalous events called alerts were manually tagged for scoring, we aim to automatically identify the regions of the log containing those alerts. We formalize the alert detection task in these terms, describe how Nodeinfo uses the information entropy of message terms to identify alerts, and present an online version of this algorithm, which is now in production use. This is the first work to investigate alert detection on (several) publicly-available supercomputer system logs, thereby providing a reproducible performance baseline.

#index 1176905
#* Variance Minimization Least Squares Support Vector Machines for Time Series Analysis
#@ Róbert Ormándi
#t 2008
#c 18
#! Here we propose a novel machine learning method for time series forecasting which is based on the widely-used Least Squares Support Vector Machine (LS-SVM) approach. The objective function of our method contains a weighted variance minimization part as well. This modification makes the method more efficient in time series forecasting, as this paper will show. The proposed method is a generalization of the well-known LS-SVM algorithm. It has similar advantages like the applicability of the kernel-trick, it has a linear and unique solution, and a short computational time, but can perform better in certain scenarios. The main purpose of this paper is to introduce the novel Variance Minimization Least Squares Support Vector Machine (VMLS-SVM) method and to show its superiority through experimental results using standard benchmark time series prediction datasets.

#index 1176906
#* Quantitative Association Analysis Using Tree Hierarchies
#@ Feng Pan;Lynda Yang;Leonard McMillan;Fernando Pardo Manuel de Villena;David Threadgill;Wei Wang
#t 2008
#c 18
#! Association analysis arises in many important applications such as bioinformatics and business intelligence. Given a large collection of measurements over a set of samples, association analysis aims to find dependencies of target variables to subsets of measurements. Most previous algorithms adopt a two-stage approach; they first group samples based on the similarity in the subset of measurements, and then they examine the association between these groups and the specified target variables without considering the inter-group similarities or alternative groupings. This can lead to cases where the strength of association depends significantly on arbitrary clustering choices. In this paper, we propose a tree-based method for quantitative association analysis. Tree hierarchies derived from sample similarities represent many possible sample groupings. They also provide a natural way to incorporate domain knowledge such as ontologies and to identify and remove outliers. Given a tree hierarchy, our association analysis evaluates all possible groupings and selects the one with strongest association to the target variable. We introduce an efficient algorithm, TreeQA, to systematically explore the search-space of all possible groupings in a set of input trees, with integrated permutation tests. Experimental results show that TreeQA is able to handlelarge-scale association analysis very efficiently and is more effective and robust in association analysis than previous methods.

#index 1176907
#* Sparse Maximum Margin Logistic Regression for Credit Scoring
#@ Sabyasachi Patra;Kripa Shanker;Debasis Kundu
#t 2008
#c 18
#! The objective of credit scoring model is to categorizethe applicants as either accepted or rejected debtors prior to granting credit. A modified logistic loss function is proposed which can approximate hinge loss and therefore the resulting model, maximum margin logistic regression (MMLR), has the classification capability of support vector machine (SVM) with low computational cost. Finally, to classify credit applicants, an efficient algorithm is also described for MMLR based on epsilon-boosting which can provide sparse estimation of coefficients for better stability and interpretability.

#index 1176908
#* Similarity Learning for Nearest Neighbor Classification
#@ Ali Mustafa Qamar;Eric Gaussier;Jean-Pierre Chevallet;Joo Hwee Lim
#t 2008
#c 18
#! In this paper, we propose an algorithm for learning a general class of similarity measures for kNN classification. This class encompasses, among others, the standard cosine measure, as well as the Dice and Jaccard coefficients. The algorithm we propose is an extension of the voted perceptron algorithm and allows one to learn different types of similarity functions (either based on diagonal, symmetric or asymmetric similarity matrices). The results we obtained show that learning similarity measures yields significant improvements on several collections, for two prediction rules: the standard kNN rule, which was our primary goal, and a symmetric version of it.

#index 1176909
#* Collaborative Filtering for Implicit Feedback Datasets
#@ Yifan Hu;Yehuda Koren;Chris Volinsky
#t 2008
#c 18
#! A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively researched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithm is used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model.

#index 1176910
#* Semi-supervised Learning from General Unlabeled Data
#@ Kaizhu Huang;Zenglin Xu;Irwin King;Michael R. Lyu
#t 2008
#c 18
#! We consider the problem of Semi-supervised Learning (SSL) from general unlabeled data, which may contain irrelevant samples. Within the binary setting, our model manages to better utilize the information from unlabeled data by formulating them as a three-class ($-1,+1, 0$) mixture, where class $0$ represents the irrelevant data. This distinguishes our work from the traditional SSL problem where unlabeled data are assumed to contain relevant samples only, either $+1$ or $-1$, which are forced to be the same as the given labeled samples. This work is also different from another family of popular models, universum learning (universum means "irrelevant" data), in that the universum need not to be specified beforehand. One significant contribution of our proposed framework is that such irrelevant samples can be automatically detected from the available unlabeled data, even though they are mixed with relevant data. This hence presents a general SSL framework that does not force "clean" unlabeled data.More importantly, we formulate this general learning framework as a Semi-definite Programming problem, making it solvable in polynomial time. A series of experiments demonstrate that the proposed framework can outperform the traditional SSL on both synthetic and real data.

#index 1176911
#* Metropolis Algorithms for Representative Subgraph Sampling
#@ Christian Hübler;Hans-Peter Kriegel;Karsten Borgwardt;Zoubin Ghahramani
#t 2008
#c 18
#! While data mining in chemoinformatics studied graph data with dozens of nodes, systems biology and the Internet are now generating graph data with thousands and millions of nodes. Hence data mining faces the algorithmic challenge of coping with this significant increase in graph size: Classic algorithms for data analysis are often too expensive and too slow on large graphs. While one strategy to overcome this problem is to design novel efficient algorithms, the other is to 'reduce' the size of the large graph by sampling. This is the scope of this paper: We will present novel Metropolis algorithms for sampling a 'representative' small subgraph from the original large graph, with 'representative' describing the requirement that the sample shall preserve crucial graph properties of the original graph. In our experiments, we improve over the pioneering work of Leskovec and Faloutsos (KDD 2006), by producing representative subgraph samples that are both smaller and of higher quality than those produced by other methods from the literature.

#index 1176912
#* Learning on Weighted Hypergraphs to Integrate Protein Interactions and Gene Expressions for Cancer Outcome Prediction
#@ TaeHyun Hwang;Ze Tian;Rui Kuangy;Jean-Pierre Kocher
#t 2008
#c 18
#! Building reliable predictive models from multiple complementary genomic data for cancer study is a crucial step towards successful cancer treatment and a full understanding of the underlying biological principles. To tackle this challenging data integration problem, we propose a hypergraph-based learning algorithm called HyperGene to integrate microarray gene expressions and protein-protein interactions for cancer outcome prediction and biomarker identification. HyperGene is a robust two-step iterative method that alternatively finds the optimal outcome prediction and the optimal weighting of the marker genes guided by a protein-protein interaction network. Under the hypothesis that cancer-related genes tend to interact with each other, the HyperGene algorithm uses a protein-protein interaction network as prior knowledge by imposing a consistent weighting of interacting genes. Our experimental results on two large-scale breast cancer gene expression datasets show that HyperGene utilizing a curated protein-protein interaction network achieves significantly improved cancer outcome prediction. Moreover, HyperGene can also retrieve many known cancer genes as highly weighted marker genes.

#index 1176913
#* A Fast Method to Mine Frequent Subsequences from Graph Sequence Data
#@ Akihiro Inokuchi;Takashi Washio
#t 2008
#c 18
#! In recent years, the mining of a complete set of frequent subgraphs from labeled graph data has been extensively studied.However, to our best knowledge, almost no methods have been proposed to find frequent subsequences of graphs from a set of graph sequences. In this paper, we define a novel class of graph subsequences by introducing axiomatic rules of graph transformation, their admissibility constraints and a union graph. Then we propose an efficient approach named "GTRACE'' to enumerate frequent transformation subsequences (FTSs) of graphs from a given set of graph sequences. Its fundamental performance has been evaluated by using artificial datasets, and its practicality has been confirmed through the experiments using real world datasets.

#index 1176914
#* RBNBC: Repeat Based Naive Bayes Classifier for Biological Sequences
#@ Pratibha Rani;Vikram Pudi
#t 2008
#c 18
#! In this paper, we present RBNBC, a Repeat Based Naive Bayes Classifier of bio-sequences that uses maximal frequent subsequences as features. RBNBC's design is based on generic ideas that can apply to other domains where the data is organized as collections of sequences. Specifically, RBNBC uses a novel formulation of Naive Bayes that incorporates repeated occurrences of subsequences within each sequence. Our extensive experiments on two collections of protein families show that it performs as well as existing state-of-the-art probabilistic classifiers for bio-sequences. This is surprising as it is a pure data mining based generic classifier that does not require domain-specific background knowledge. We note that domain-specific ideas could further increase its performance.

#index 1176915
#* Multi-label Classification Using Ensembles of Pruned Sets
#@ Jesse Read;Bernhard Pfahringer;Geoff Holmes
#t 2008
#c 18
#! This paper presents a Pruned Sets method (PS) for multi-label classification. It is centred on the concept of treating sets of labels as single labels. This allows the classification process to inherently take into account correlations between labels. By pruning these sets, PS focuses only on the most important correlations, which reduces complexity and improves accuracy. By combining pruned sets in an ensemble scheme (EPS), new label sets can be formed to adapt to irregular or complex data. The results from experimental evaluation on a variety of multi-label datasets show that [E]PS can achieve better performance and train much faster than other multi-label methods.

#index 1176916
#* Active Learning of Equivalence Relations by Minimizing the Expected Loss Using Constraint Inference
#@ Steffen Rendle;Lars Schmidt-Thieme
#t 2008
#c 18
#! Selecting promising queries is the key to effective active learning. In this paper, we investigate selection techniques for the task of learning an equivalence relation where the queries are about pairs of objects. As the target relation satisfies the axioms of transitivity, from one queried pair additional constraints can be inferred. We derive both the upper and lower bound on the number of queries needed to converge to the optimal solution. Besides restricting the set of possible solutions, constraints can be used as training data for learning a similarity measure. For selecting queries that result in a large number of meaningful constraints, we present an approximative optimal selection technique that greedily minimizes the expected loss in each round of active learning. This technique makes use of inference of expected constraints. Besides the theoretical results, an extensive evaluation for the application of record linkage shows empirically that the proposed selection method leads to both interesting and a high number of constraints.

#index 1176917
#* Iterative Subgraph Mining for Principal Component Analysis
#@ Hiroto Saigo;Koji Tsuda
#t 2008
#c 18
#! Graph mining methods enumerate frequent subgraphs efficiently, but they are not necessarily good features for machine learning due to high correlation among features. Thus it makes sense to perform principal component analysis to reducethe dimensionality and create decorrelated features. We present a novel iterative mining algorithm that captures informative patterns corresponding to major entries of top principal components. It repeatedly callsweighted substructure mining where example weights are updated in each iteration. The Lanczos algorithm, a standard algorithm of eigen decomposition, is employed to update the weights. In experiments, our patterns are shown to approximate the principal components obtained by frequent mining.

#index 1176918
#* Clustering Geospatial Objects via Hidden Markov Random Fields
#@ Makoto Sato;Shuuichiro Imahara
#t 2008
#c 18
#! This paper addresses the problem of clustering objects located and correlated geographically and containing multiple attributes. For the clustering problem, it is necessary to consider both the similarities of the attributes and the spatial dependencies of the objects. A new clustering framework using hidden Markov random fields (HMRFs) and Gaussian distributions and new potential models of HMRFs for irregularly located geospatial objects are proposed in this paper. Experimental results for systematic data and two real-world data showed the availability of the proposed algorithms.

#index 1176919
#* Robust Time-Referenced Segmentation of Moving Object Trajectories
#@ Hyunjin Yoon;Cyrus Shahabi
#t 2008
#c 18
#! Trajectory segmentation is the process of partitioning a given trajectory into a small number of homogeneous segments w.r.t. some criteria. Conventional segmentation techniques only focus on the spatial features of the movement and could lead to spatially homogeneous segments but with presumably dissimilar temporal structures. Furthermore, trajectories could be over-segmented in the presence of outliers. In this paper, we propose a family of three trajectory segmentation methods that takes into account both geospatial and temporal structures of movement for the segmentation and is also robust with respect to time-referenced spatial outliers. The effectiveness of our methods is empirically demonstrated over three real-world datasets.

#index 1176920
#* Document-Word Co-regularization for Semi-supervised Sentiment Analysis
#@ Vikas Sindhwani;Prem Melville
#t 2008
#c 18
#! The goal of sentiment prediction is to automatically identify whether a given piece of text expresses positive or negative opinion towards a topic of interest. One can pose sentiment prediction as a standard text categorization problem, but gathering labeled data turns out to be a bottleneck. Fortunately, background knowledge is often available in the form of prior information about the sentiment polarity of words in a lexicon. Moreover, in many applications abundant unlabeled data is also available. In this paper, we propose a novel semi-supervised sentiment prediction algorithm that utilizes lexical prior knowledge in conjunction with unlabeled examples. Our method is based on joint sentiment analysis of documents and words based on a bipartite graph representation of the data. We present an empirical study on a diverse collection of sentiment prediction problems which confirms that our semi-supervised lexical models significantly outperform purely supervised and competing semi-supervised techniques.

#index 1176921
#* Overlapping Matrix Pattern Visualization: A Hypergraph Approach
#@ Ruoming Jin;Yang Xiang;David Fuhry;Feodor F. Dragan
#t 2008
#c 18
#! In this work, we study a visual data mining problem: Given a set of discovered overlapping submatrices of interest, how can we order the rows and columns of the data matrix to best display these submatrices and their relationships? We find this problem can be converted to the hypergraph ordering problem, which generalizes the traditional minimal linear arrangement (or graph ordering) problem and then we are able to prove the NP-hardness of this problem. We propose a novel iterative algorithm which utilize the existing graph ordering algorithm to solve the optimal visualization problem. This algorithm can always converge to a local minimum. The detailed experimental evaluation using a set of publicly available transactional datasets demonstrates the effectiveness and efficiency of the proposed algorithm.

#index 1176922
#* A Robust Discriminative Term Weighting Based Linear Discriminant Method for Text Classification
#@ Khurum Nazir Junejo;Asim Karim
#t 2008
#c 18
#! Text classification is widely used in applications ranging from e-mail filtering to review classification. Many of these applications demand that the classification method be efficient and robust, yet produce accurate categorizations by using the terms in the documents only. We present a supervised text classification method based on discriminative term weighting, discrimination information pooling, and linear discrimination. Terms in the documents are assigned weights according to the discrimination information they provide for one category over the others. These weights also serve to partition the terms into two sets. A linear opinion pool is adopted for combining the discrimination information provided by each set of terms yielding a two-dimensional feature space. Subsequently, a linear discriminant function is learned to categorize the documents in the feature space. We provide intuitive and empirical evidence of the robustness of our method with three term weighting strategies. Experimental results are presented for data sets from three different application areas. The results show that our method's accuracy is higher than other popular methods, especially when there is a distribution shift from training to testing sets. Moreover, our method is simple yet robust to different application domains and small training set sizes.

#index 1176923
#* Clustering Uncertain Data Using Voronoi Diagrams
#@ Ben Kao;Sau Dan Lee;David W. Cheung;Wai-Shing Ho;K. F. Chan
#t 2008
#c 18
#! We study the problem of clustering uncertain objects whose locations are described by probability density functions (pdf). We show that the UK-means algorithm, which generalises the k-means algorithm to handle uncertain objects, is very inefficient. The inefficiency comes from the fact that UK-means computes expected distances (ED) between objects and cluster representatives. For arbitrary pdf's, expected distances are computed by numerical integrations, which are costly operations. We propose pruning techniques that are based on Voronoi diagrams to reduce the number of expected distance calculation. These techniques are analytically proven to be more effective than the basic bounding-box-based technique previous known in the literature. We conduct experiments to evaluate the effectiveness of our pruning techniques and to show that our techniques significantly outperform previous methods.

#index 1176924
#* SCS: A New Similarity Measure for Categorical Sequences
#@ Abdellali Kelil;Shengrui Wang
#t 2008
#c 18
#! Measuring the similarity between categorical sequences is a fundamental process in many data mining applications. A key issue is to extract and make use of significant features hidden behind the chronological and structural dependencies found in these sequences. Almost all existing algorithms designed to perform this task are based on the matching of patterns in chronological order, but such sequences often have similar structural features in chronologically different positions. In this paper we propose SCS, a novel method for measuring the similarity between categorical sequences, based on an original pattern matching scheme that makes it possible to capture chronological and non-chronological dependencies. SCS captures significant patterns that represent the natural structure of sequences, and reduces the influence of those representing noise. It constitutes an effective approach for measuring the similarity of data such as biological sequences, natural language texts and financial transactions. To show its effectiveness, we have tested SCS extensively on a range of datasets, and compared the results with those obtained by various mainstream algorithms.

#index 1176925
#* Toward Faster Nonnegative Matrix Factorization: A New Algorithm and Comparisons
#@ Jingu Kim;Haesun Park
#t 2008
#c 18
#! Nonnegative Matrix Factorization (NMF) is a dimension reduction method that has been widely used for various tasks including text mining, pattern analysis, clustering, and cancer class discovery. The mathematical formulation for NMF appears as a non-convex optimization problem, and various types of algorithms have been devised to solve the problem. The alternating nonnegative least squares (ANLS) framework is a block coordinate descent approach for solving NMF, which was recently shown to be theoretically sound and empirically efficient. In this paper, we present a novel algorithm for NMF based on the ANLS framework. Our new algorithm builds upon the block principal pivoting method for the nonnegativity constrained least squares problem that overcomes some limitations of active set methods. We introduce ideas to efficiently extend the block principal pivoting method within the context of NMF computation. Our algorithm inherits the convergence theory of the ANLS framework and can easily be extended to other constrained NMF formulations. Comparisons of algorithms using datasets that are from real life applications as well as those artificially generated show that the proposed new algorithm outperforms existing ones in computational speed.

#index 1176926
#* A Non-parametric Approach to Pair-Wise Dynamic Topic Correlation Detection
#@ Yang Song;Lu Zhang;C. Lee Giles
#t 2008
#c 18
#! We introduce dynamic correlated topic models (DCTM) for analyzing discrete data over time. This model is inspired by the hierarchical Gaussian process latent variable models (GP-LVM). DCTM is essentially a non-linear dimension reduction technique which is capable of (1) detecting topic evolution within a document corpus,(2) discovering topic correlations between document corpora, and (3) monitoring topic and correlation trends dynamically. Unlike generative aspect models such like LDA, DCTM demonstrates a much faster converging rate with better model fitting to the data. We empirically assess our approach using 268,231 scientific documents, from the year 1988 to 2005. Posterior inferences suggest that DCTM is useful for capturing topic and correlation dynamics, as well as predicting their trends.

#index 1176927
#* Block-Iterative Algorithms for Non-negative Matrix Approximation
#@ Suvrit Sra
#t 2008
#c 18
#! In this paper we present new algorithms for non-negative matrix approximation (NMA), commonly known as the NMF problem. Our methods improve upon the well-known methods of Lee \& Seung~\cite{lee00} for both the Frobenius norm as well the Kullback-Leibler divergence versions of the problem. For the latter problem, our results are especially interesting because it seems to have witnessed much lesser algorithmic progress as compared to the Frobenius norm NMA problem. Our algorithms are based on a particular \textbf {block-iterative} acceleration technique for EM, which preserves the multiplicative nature of the updates and also ensures monotonicity. Furthermore, our algorithms also naturally apply to the Bregman-divergence NMA algorithms of~\cite{suv.nips}. Experimentally, we show that our algorithms outperform the traditional Lee/Seung approach most of the time.

#index 1176928
#* A Novel Method of Combined Feature Extraction for Recognition
#@ Tingkai Sun;Songcan Chen;Jingyu Yang;Pengfei Shi
#t 2008
#c 18
#! Multimodal recognition is an emerging technique to overcome the non-robustness of the unimodal recognition in real applications. Canonical correlation analysis (CCA) has been employed as a powerful tool for feature fusion in the realization of such multimodal system. However, CCA is the unsupervised feature extraction and it does not utilize the class information of the samples, resulting in the constraint of the recognition performance. In this paper, the class information is incorporated into the framework of CCA for combined feature extraction, and a novel method of combined feature extraction for multimodal recognition, called discriminative canonical correlation analysis (DCCA), is proposed. The experiments show that DCCA outperforms some related methods of both unimodal recognition and multimodal recognition.

#index 1176929
#* Prediction of Skin Penetration Using Machine Learning Methods
#@ Yi Sun;Gary P. Moss;Maria Prapopoulou;Rod Adams;Marc B. Brown;Neil Davey
#t 2008
#c 18
#! Improving predictions of the skin permeability coefficient is a difficult problem. It is also an important issue with the increasing use of skin patches as a means of drug delivery. In this work, we apply K-nearest-neighbour regression, single layer networks, mixture of experts and Gaussian processes to predict the permeability coefficient. We obtain a considerable improvement over the quantitative structure-activity relationship (QSARs) predictors. We show that using five features, which are molecular weight, solubility parameter, lipophilicity, the number of hydrogen bonding acceptor and donor groups, can produce better predictions than the one using only lipophilicity and the molecular weight. The Gaussian process regression with five compound features gives the best performance in this work.

#index 1176930
#* A Topic Modeling Approach and Its Integration into the Random Walk Framework for Academic Search
#@ Jie Tang;Ruoming Jin;Jing Zhang
#t 2008
#c 18
#! In this paper, we propose a unified topic modeling approach and its integration into the random walk framework for academic search. Specifically, we present a topic model for simultaneously modeling papers, authors, and publication venues. We combine the proposed topic model into the random walk framework. Experimental results show that our proposed approach for academic search significantly outperforms the baseline methods of using BM25 and language model, and those of using the existing topic models (including pLSI, LDA, and the AT model).

#index 1176931
#* Sequence Mining Automata: A New Technique for Mining Frequent Sequences under Regular Expressions
#@ Roberto Trasarti;Francesco Bonchi;Bart Goethals
#t 2008
#c 18
#! In this paper we study the problem of mining frequent sequences satisfying a given regular expression. Previous approaches to solve this problem were focusing on its search space, pushing (in some way) the given regular expression to prune unpromising candidate patterns. On the contrary, we focus completely on the given input data and regular expression. We introduce Sequence Mining Automata ($SMA$), a specialized kind of Petri Net that while reading input sequences, it produces for each sequence all and only the patterns contained in the sequence and that satisfy the given regular expression. Based on this automaton, we develop a family of algorithms. Our thorough experimentation on different datasets and application domains confirms that in many cases our methods outperform the current state of the art of frequent sequence mining algorithms using regular expressions (in some cases of orders of magnitude).

#index 1176932
#* Filling in the Blanks - Krimp Minimisation for Missing Data
#@ Jilles Vreeken;Arno Siebes
#t 2008
#c 18
#! Many data sets are incomplete. For correct analysis of such data, one can either use algorithms that are designed to handle missing data or use imputation. Imputation has the benefit that it allows for any type of data analysis. Obviously, this can only lead to proper conclusions if the provided data completion is both highly accurate and maintains all statistics of the original data. In this paper, we present three data completion methods that are built on the MDL-based {\sc Krimp} algorithm. Here, we also follow the MDL principle, i.e. the completed database that can be compressed best, is the best completion because it adheres best to the patterns in the data. By using local patterns, as opposed to a global model, Krimp captures the structure of the data in detail. Experiments show that both in terms of accuracy and expected differences of any marginal, better data reconstructions are provided than the state of the art, Structural EM.

#index 1176933
#* Scalable Tensor Decompositions for Multi-aspect Data Mining
#@ Tamara G. Kolda;Jimeng Sun
#t 2008
#c 18
#! Modern applications such as Internet traffic, telecommunication records, and large-scale social networks generate massive amounts of data with multiple aspects and high dimensionalities. Tensors (i.e., multi-way arrays) provide a natural representation for such data. Consequently, tensor decompositions such as Tucker become important tools for summarization and analysis.One major challenge is how to deal with high-dimensional, sparse data. In other words, how do we compute decompositions of tensors where most of the entries of the tensor are zero. Specialized techniques are needed for computing the Tucker decompositions for sparse tensors because standard algorithms do not account for the sparsity of the data. As a result, a surprising phenomenon is observed by practitioners: Despite the fact that there is enough memory to store both the input tensors and the factorized output tensors, memory overflows occur during the tensor factorization process. To address this intermediate blowup problem, we propose Memory-Efficient Tucker (MET). Based on the available memory, MET adaptively selects the right execution strategy during the decomposition. We provide quantitative and qualitative evaluation of MET on real tensors. It achieves over 1000X space reduction without sacrificing speed; it also allows us to work with much larger tensors that were too big to handle before. Finally, we demonstrate a data mining case-study using MET.

#index 1176934
#* Mining Periodic Behavior in Dynamic Social Networks
#@ Mayank Lahiri;Tanya Y. Berger-Wolf
#t 2008
#c 18
#! Social interactions that occur regularly typically correspond to significant yet often infrequent and hard to detect interaction patterns. To identify such regular behavior, we propose a new mining problem of finding periodic or near periodic subgraphs in dynamic social networks. We analyze the computational complexity of theproblem, showing that, unlike any of the related subgraph mining problems, it is polynomial. We propose a practical, efficient and scalable algorithm to find such subgraphs that takes imperfect periodicity into account. We demonstrate the applicability of our approach on severalreal-world networks and extract meaningful and interesting periodic interaction patterns.

#index 1176935
#* Unsupervised Face Annotation by Mining the Web
#@ Duy-Dinh Le;Shin'ichi Satoh
#t 2008
#c 18
#! Searching for images of people is an essential task for image and video search engines. However, current search engines have limited capabilities for this task since they rely on text associated with images and video, and such text is likely to return many irrelevant results. We propose a method for retrieving relevant faces of one person by learning the visual consistency among results retrieved from text correlation-based search engines. The method consists of two steps. In the first step, each candidate face obtained from a text-based search engine is ranked with a score that measures the distribution of visual similarities among the faces. Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list, respectively. The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as ’person-X’ or ’non-person-X’; and the faces are re-ranked according to their relevant score inferred from the classifier’s probability output. To train this classifier, we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets. These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step. In this way, the accuracy of the ranked list increases after a number of iterations. Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration, with the final performance being higher than those of the existing algorithms.

#index 1176936
#* Border Sampling through Coupling Markov Chain Monte Carlo
#@ Guichong Li;Nathalie Japkowicz;Trevor J. Stocki;R. Kurt Ungar
#t 2008
#c 18
#! Recently, Progressive Border Sampling (PBS) was proposed for sample selection in supervised learning by progressively learning an augmented full border from small labeled datasets. However, this quadratic learning algorithm is inapplicable to large datasets. In this paper, we incorporate the PBS to a state of the art technique called Coupling Markov Chain Monte Carlo (CMCMC) in an attempt to scale the original algorithm up on large labeled datasets. The CMCMC can produce an exact sample while a naive strategy for Markov Chain Monte Carlo cannot guarantee the convergence to a stationary distribution. The resulting CMCMC-PBS algorithm is thus proposed for border sampling on large datasets. CMCMC-PBS exhibits several remarkable characteristics: linear time complexity, learner-independence, and a consistent convergence to an optimal sample from the original training sets by learning from their subsamples. Our experimental results on the 33 either small or large labeled datasets from the UCIKDD repository and a nuclear security application show that our new approach outperforms many previous sampling techniques for sample selection.

#index 1176937
#* Computationally Efficient Estimators for Dimension Reductions Using Stable Random Projections
#@ Ping Li
#t 2008
#c 18
#! The method of stable random projections is an efficient tool for computing the lα distances using low memory, where 0 1. We derive its theoretical error bound and establish the explicit (i.e., no hidden constants) sample complexity bound.

#index 1176938
#* Computational Discovery of Motifs Using Hierarchical Clustering Techniques
#@ Dianhui Wang;Nung Kion Lee
#t 2008
#c 18
#! Discovery of motifs plays a key role in understanding gene regulation in organisms. Existing tools for motif discovery demonstrate some weaknesses in dealing with reliability and scalability. Therefore, development of advanced algorithms for resolving this problem will be useful. This paper aims to develop data mining techniques for discovering motifs. A mismatch based hierarchical clustering algorithm is proposed in this paper, where three heuristic rules for classifying clusters and a post-processing for ranking and refining the clusters are employed in the algorithm. Our algorithm is evaluated using two sets of DNA sequences with comparisons. Results demonstrate that the proposed techniques in this paper outperform MEME, AlignACE and SOMBRERO for most of the testing datasets.

#index 1176939
#* Inference Analysis in Privacy-Preserving Data Re-publishing
#@ Guan Wang;Zutao Zhu;Wenliang Du;Zhouxuan Teng
#t 2008
#c 18
#! Privacy-Preserving Data Re-publishing (PPDR) deals with publishing microdata in dynamic scenarios. Due to privacy concerns, data must be disguised before being published. Research in privacy-preserving data publishing (PPDP) has proposed many such methods on static data. In PPDR, multiple appeared records can be used to infer private information of other records. Therefore, inference channels exist among different releases. To understand the privacy property of data re-publishing, we need to analyze the impact of these inference channels. Previous studies show such analysis when data are updated or disguised in special ways, however, no general method has been proposed. Using the Maximum Entropy Modeling method, we have developed a general solution. Our method can conduct inference analysis when data are arbitrarily updated or arbitrarily disguised using either generalization or bucketization, two most common data disguise methods in PPDR. Through analysis and experiments, we demonstrate the advantage and the effectiveness of our method.

#index 1176940
#* Using Wikipedia for Co-clustering Based Cross-Domain Text Classification
#@ Pu Wang;Carlotta Domeniconi;Jian Hu
#t 2008
#c 18
#! Traditional approaches to document classification requires labeled data in order to construct reliable and accurate classifiers. Unfortunately, labeled data are seldom available, and often too expensive to obtain. Given a learning task for which training data are not available, abundant labeled data may exist for a different but related domain. One would like to use the related labeled data as auxiliary information to accomplish the classification task in the target domain. Recently, the paradigm of transfer learning has been introduced to enable effective learning strategies when auxiliary data obey a different probability distribution. A co-clustering based classification algorithm has been previously proposed to tackle cross-domain text classification. In this work, we extend the idea underlying this approach by making the latent semantic relationship between the two domains explicit. This goal is achieved with the use of Wikipedia. As a result, the pathway that allows to propagate labels between the two domains not only captures common words, but also semantic concepts based on the content of documents. We empirically demonstrate the efficacy of our semantic-based approach to cross-domain classification using a variety of real data.

#index 1176941
#* Iterative Set Expansion of Named Entities Using the Web
#@ Richard C. Wang;William W. Cohen
#t 2008
#c 18
#! Set expansion refers to expanding a partial set of "seed" objects into a more complete set. One system that does set expansion is SEAL (Set Expander for Any Language), which expands entities automatically by utilizing resources from the Web in a language independent fashion. In a previous study, SEAL showed good set expansion performance using three seed entities; however, when given a larger set of seeds (e.g., ten), SEAL's expansion method performs poorly. In this paper, we present Iterative SEAL (iSEAL), which allows a user to provide many seeds. Briefly, iSEAL makes several calls to SEAL, each call using a small number of seeds. We also show that iSEAL can be used in a "bootstrapping" manner, where each call to SEAL uses a mixture of user-provided and self-generated seeds. We show that the bootstrapping version of iSEAL obtains better results than SEAL even when using fewer user-provided seeds. In addition, we compare the performance of various ranking algorithms used in iSEAL, and show that the choice of ranking method has a small effect on performance when all seeds are user-provided, but a large effect when iSEAL is bootstrapped. In particular, we show that Random Walk with Restart is nearly as good as Bayesian Sets with user-provided seeds, and performs best with bootstrapped seeds.

#index 1176942
#* Experimental Evaluation of the Value of Structure: How to Efficiently Exploit Interdependencies in Sequence Labeling
#@ Guillaume Wisniewski;Patrick Gallinari
#t 2008
#c 18
#! Many problems in natural language processing, information extraction or bioinformatics consist in predicting a label for each element of a sequence of observations. The sequence of labels generally presents multiple dependencies that restrict the possible labels the elements can take. Therefore, relations between labels intuitively provide information valuable for the prediction. Several approaches have been proposed to take advantage of this additional information. However, experimental results show that taking relations into account does not always improve prediction performances, while it significantly increases the computational cost of both learning and prediction. In this work, we aim at both explaining these surprising results and proposing a simple but computationnaly efficient approach for labeling sequences.

#index 1176943
#* Publishing Sensitive Transactions for Itemset Utility
#@ Yabo Xu;Benjamin C.  M. Fung;Ke Wang;Ada W.  C. Fu;Jian Pei
#t 2008
#c 18
#! We consider the problem of publishing sensitive transaction data with privacy preservation. High dimensionality of transaction data poses unique challenges on data privacy and data utility. On one hand, re-identification attacks tend to use a subset of items that infrequently occur in transactions, called moles. On the other hand, data mining applications typically depend on subsets of items that frequently occur in transactions, called nuggets. Thus the problem is how to eliminate all moles while retaining nuggets as much as possible. A challenge is that moles and nuggets are multi-dimensional with exponential growth and are tangled together by shared items. We present a novel and scalable solution to this problem. The novelty lies in a compact border data structure that eliminates the need of generating all moles and nuggets.

#index 1176944
#* Isolation Forest
#@ Fei Tony Liu;Kai Ming Ting;Zhi-Hua Zhou
#t 2008
#c 18
#! Most existing model-based approaches to anomaly detection construct a profile of normal instances, then identify instances that do not conform to the normal profile as anomalies. This paper proposes a fundamentally different model-based method that explicitly isolates anomalies instead of profiles normal points. To our best knowledge, the concept of isolation has not been explored in current literature. The use of isolation enables the proposed method, iForest, to exploit sub-sampling to an extent that is not feasible in existing methods, creating an algorithm which has a linear time complexity with a low constant and a low memory requirement. Our empirical evaluation shows that iForest performs favourably to ORCA, a near-linear time complexity distance-based method, LOF and Random Forests in terms of AUC and processing time, and especially in large data sets. iForest also works well in high dimensional problems which have a large number of irrelevant attributes, and in situations where training set does not contain any anomalies.

#index 1176945
#* TEFE: A Time-Efficient Approach to Feature Extraction
#@ Li-Ping Liu;Yang Yu;Yuan Jiang;Zhi-Hua Zhou
#t 2008
#c 18
#! With the rapid evolution of internet applications, people all over the world are sharing pictures, videos and audios online, and thus, content-based analysis is often demanded. Test efficiency is crucial to the success of online information processing. One obstacle to high-speed testing is the time cost of feature extraction for test objects, particularly for objects with complex representation such as images, videos and audios. In this paper, we study the problem of reducing test time cost by extracting cheap but sufficient features. We propose the TEFE (Time-Efficient Feature Extraction) approach, which balances between the test accuracy and test time cost by extracting a proper subset of features for each test object. In the implementation, TEFE trains a sequence of support vector machines and classifies each test object cascadingly. Empirical study shows that TEFE is time efficient while holding a classification accuracy close to that of using all features. It also shows that the test time is linearly adjustable in TEFE.

#index 1176946
#* Transductive Component Analysis
#@ Wei Liu;Dacheng Tao;Jianzhuang Liu
#t 2008
#c 18
#! In this paper, we study semi-supervised linear dimensionality reduction. Beyond conventional supervised methods which merely consider labeled instances, the semi-supervised scheme allows to leverage abundant and ample unlabeled instances into learning so as to achieve better generalization performance. Under semi-supervised settings, our objective is to learn a smooth as well as discriminative subspace and linear dimensionality reduction is thus achieved by mapping all samples into the subspace. Specifically, we present the Transductive Component Analysis (TCA) algorithm to generate such a subspace founded on a graph-theoretic framework.Considering TCA is non-orthogonal, we further present the Orthogonal Transductive Component Analysis (OTCA) algorithm to iteratively produce a series of orthogonal basis vectors. OTCA has better discriminating power than TCA. Experiments carried out on synthetic and real-world datasets by OTCA show a clear improvement over the results of representative dimensionality reduction algorithms.

#index 1176947
#* Modeling and Predicting the Helpfulness of Online Reviews
#@ Yang Liu;Xiangji Huang;Aijun An;Xiaohui Yu
#t 2008
#c 18
#! Online reviews provide a valuable resource for potential customers to make purchase decisions. However, the sheer volume of available reviews as well as the large variations in the review quality present a big impediment to the effective use of the reviews, as the most helpful reviews may be buried in the large amount of low quality reviews. The goal of this paper is to develop models and algorithms for predicting the helpfulness of reviews, which provides the basis for discovering the most helpful reviews for given products. We first show that the helpfulness of a review depends on three important factors: the reviewer’s expertise, the writing style of the review, and the timeliness of the review. Based on the analysis of those factors, we present a nonlinear regression model for helpfulness prediction. Our empirical study on the IMDB movie reviews dataset demonstrates that the proposed approach is highly effective.

#index 1176948
#* LBF: A Labeled-Based Forecasting Algorithm and Its Application to Electricity Price Time Series
#@ Francisco Martínez-Álvarez;Alicia Troncoso;José C. Riquelme;Jesús S. Aguilar-Ruiz
#t 2008
#c 18
#! A new approach is presented in this work with the aim of predicting time series behaviors. A previous labeling of the samples is obtained utilizing clustering techniques and the forecasting is applied using the information provided by the clustering. Thus, the whole data set is discretized with the labels assigned to each data point and the main novelty is that only these labels are used to predict the future behavior of the time series, avoiding using the real values of the time series until the process ends. The results returned by the algorithm, however, are not labels but the nominal value of the point that is required to be predicted. The algorithm based on labeled (LBF) has been tested in several energy-related time series and a notable improvement in the prediction has been achieved.

#index 1176949
#* Scaling up Classifiers to Cloud Computers
#@ Christopher Moretti;Karsten Steinhaeuser;Douglas Thain;Nitesh V. Chawla
#t 2008
#c 18
#! As the size of available datasets has grown from Megabytes to Gigabytes and now into Terabytes, machine learning algorithms and computing infrastructures have continuously evolved in an effort to keep pace. But at large scales, mining for useful patterns still presents challenges in terms of data management as well as computation. These issues can be addressed by dividing both data and computation to build ensembles of classifiers in a distributed fashion, but trade-offs in cost, performance, and accuracy must be considered when designing or selecting an appropriate architecture. In this paper, we present an abstraction for scalable data mining that allows us to explore these trade-offs. Data and computation are distributed to a computing cloud with minimal effort from the user, and multiple models for data management are available depending on the workload and system configuration. We demonstrate the performance and scalability characteristics of our ensembles using a wide variety of datasets and algorithms on a Condor-based pool with Chirp to handle the storage.

#index 1176950
#* Pseudolikelihood EM for Within-network Relational Learning
#@ Rongjing Xiang;Jennifer Neville
#t 2008
#c 18
#! In this work, we study the problem of \emph{within-network} relational learning and inference, where models are learned on a partially labeled relational dataset and then are applied to predict the classes of unlabeled instances in the same graph. We categorize recent work in statistical relational learning into three alternative approaches for this setting: disjoint learning with disjoint inference, disjoint learning with collective inference, and collective learning with collective inference. Models from each of these categories has been employed previously in different settings, but to our knowledge there has been no systematic comparison of models from all three categories. In this paper, we develop a novel pseudolikelihood EM method that facilitates more general \emph{collective learning} and \emph{collective inference} on partially labeled relational networks. We then compare this method to competing methods from the other categories on both synthetic and real-world data. We show that collective learning and inference with the pseudolikelihood EM approach achieves significantly higher accuracy than the other types of models when there are a moderate number of labeled examples in the data graph.

#index 1176951
#* Learning the Latent Semantic Space for Ranking in Text Retrieval
#@ Jun Yan;Shuicheng Yan;Ning Liu;Zheng Chen
#t 2008
#c 18
#! Subspace learning techniques for text analysis, such as Latent Semantic Indexing (LSI), have been widely studied in the past decade. However, to our best knowledge, no previous study has leveraged the rank information for subspace learning in ranking tasks. In this paper, we propose a novel algorithm, called Learning Latent Semantics for Ranking (LLSR), to seek the optimal Latent Semantic Space tailored to the ranking tasks. We first present a dual explanation for the classical Latent Semantic Indexing (LSI) algorithm, namely learning the so-called Latent Semantic Space (LSS) to encode the data information. Then, to handle the increasing amount of training data for the practical ranking tasks, we propose a novel objective function to derive the optimal LSS for ranking. Experimental results on two SMART sub-collections and a TREC dataset show that LLSR effectively improves the ranking performance compared with the classical LSI algorithm and ranking without subspace learning.

#index 1176952
#* Robust Time-Referenced Segmentation of Moving Object Trajectories
#@ Hyunjin Yoon;Cyrus Shahabi
#t 2008
#c 18
#! Trajectory segmentation is the process of partitioning a given trajectory into a small number of homogeneous segments w.r.t. some criteria. Conventional segmentation techniques only focus on the spatial features of the movement and could lead to spatially homogeneous segments but with presumably dissimilar temporal structures. Furthermore, trajectories could be over-segmented in the presence of outliers. In this paper, we propose a family of three trajectory segmentation methods that takes into account both geospatial and temporal structures of movement for the segmentation and is also robust with respect to time-referenced spatial outliers. The effectiveness of our methods is empirically demonstrated over three real-world datasets.

#index 1176953
#* Maximum Margin Embedding
#@ Bin Zhao;Fei Wang;Changshui Zhang
#t 2008
#c 18
#! We propose a new dimensionality reduction method called Maximum Margin Embedding (MME), which targets to projecting data samples into the most discriminative subspace, where clusters are most well-separated. Specifically, MME projects input patterns onto the normal of the maximum margin separating hyperplanes. As a result, MME only depends on the geometry of the optimal decision boundary and not on the distribution of those data points lying further away from this boundary. Technically, MME is formulated as an integer programming problem and we propose a cutting plane algorithm to solve it. Moreover, we prove theoretically that the computational time of MME scales linearly with the dataset size. Experimental results on both toy and real world datasets demonstrate the effectiveness of MME.

#index 1176954
#* Graph-Based Iterative Hybrid Feature Selection
#@ ErHeng Zhong;Sihong Xie;Wei Fan;Jiangtao Ren;Jing Peng;Kun Zhang
#t 2008
#c 18
#! When the number of labeled examples is limited, traditional supervised feature selection techniques often fail due to sample selection bias or unrepresentative sample problem. To solve this, semi-supervised feature selection techniques exploit the statistical information of both labeled and unlabeled examples in the same time. However, the results of semi-supervised feature selection can be at times unsatisfactory, and the culprit is on how to effectively use the unlabeled data. Quite different from both supervised and semi-supervised feature selection, we propose a “hybrid”framework based on graph models. We first apply supervised methods to select a small set of most critical features from the labeled data. Importantly, these initial features might otherwise be missed when selection is performed onthe labeled and unlabeled examples simultaneously. Next,this initial feature set is expanded and corrected with the use of unlabeled data. We formally analyze why the expected performance of the hybrid framework is better than both supervised and semi-supervised feature selection. Experimental results demonstrate that the proposed method outperforms both traditional supervised and state-of-the-art semisupervised feature selection algorithms by at least 10% inaccuracy on a number of text and biomedical problems with thousands of features to choose from. Software and dataset is available from the authors.

#index 1176955
#* Cleansing Noisy Data Streams
#@ Xingquan Zhu;Peng Zhang;Xindong Wu;Dan He;Chengqi Zhang;Yong Shi
#t 2008
#c 18
#! In this paper, we identify a new research problem on cleansing noisy data streams which contain incorrectly labeled training examples. The objective is to accurately identify and remove mislabeled data, such that the prediction models built from the cleansed streams can be more accurate than the ones trained from the raw noisy streams. For this purpose, we first use bias-variance decomposition to derive a maximum variance margin (MVM) principle for stream data cleansing. Following this principle, we further propose a local and global filtering (LgF) framework to combine the strength of local noise filtering (within one single data chunk) and global noise filtering (across a number of adjacent data chunks) to identify erroneous data. Experimental results on six data streams (including two real-world data streams) demonstrate that LgF significantly outperforms simple methods in identifying noisy examples.

#index 1176956
#* Enhancing the Stability of Spectral Ordering with Sparsification and Partial Supervision: Application to Paleontological Data
#@ Dimitrios Mavroeidis;Ella Bingham
#t 2008
#c 18
#! Recent studies have demonstrated the prospects of data mining algorithms for addressing the task of seriation in paleontological data (i.e. the age-based ordering of the sites of excavation). A prominent approach is spectral ordering that computes a similarity measure between the sites and orders them such that similar sites become adjacent and dissimilar sites are placed far apart. In the paleontological domain, the similarity measure is based on the mammal genera whose remains are retrieved at each site of excavation. Although spectral ordering achieves good performance in the seriation task, it ignores the background knowledge that is naturally present in the domain, as paleontologists can derive the ages of the sites of excavation within some accuracy. On the other hand, the age information is uncertain, so the best approach would be to combine the background knowledge with the information on mammal co-occurrences. Motivated by this kind of partial supervision we propose a novel semi-supervised spectral ordering algorithm. Our algorithm modifies the Laplacian matrix used in spectral ordering, such that domain knowledge of the ordering is taken into account. Also, it performs feature selection (sparsification) by discarding features that contribute most to the unwanted variability of the data in bootstrap sampling. The theoretical properties of the proposed algorithm are thoroughly analyzed and it is demonstrated that the proposed framework enhances the stability of the spectral ordering output and induces computational gains.

#index 1176957
#* What Sperner Family Concept Class is Easy to Be Enumerated?
#@ Atsuyoshi Nakamura;Mineichi Kudo
#t 2008
#c 18
#! We study the problem of enumerating concepts in a Sperner family concept class using subconcept queries, which is a general problem including maximal frequent itemset mining as its instance. Though even the theoretically best known algorithm needs quasi-polynomial time to solve this problem in the worst case, there exist practically fast algorithms for this problem. This is because many instances of this problem in real world have low complexity in some measures. In this paper, we characterize the complexity of Sperner family concept class by the VC dimension of its intersection closure and its characteristic dimension, and analyze the worst case time complexity on the enumeration problem of its concepts in terms of the VC dimension. We also showed that the VC dimension of real data used in data mining is actually small by calculating the VC dimension of some real datasets using a new algorithm closely related to the introduced two measures, which does not only solve the problem but also let us know the VC dimension of the intersection closure of the target concept class.

#index 1176958
#* Learning by Propagability
#@ Bingbing Ni;Shuicheng Yan;Ashraf Kassim;Loong Fah Cheong
#t 2008
#c 18
#! In this paper, we present a novel feature extraction framework, called learning by propagability. The whole learning process is driven by the philosophy that the data labels and optimal feature representation can constitute a harmonic system, namely, the data labels are invariant with respect to the propagation on the similarity-graph constructed by the optimal feature representation. Based on this philosophy, a unified formulation for learning by propagability is proposed for both supervised and semi-supervised configurations. Specifically, this formulation offers the semi-supervised learning two characteristics: 1) unlike conventional semi-supervised learning algorithms which mostly include at least two parameters, this formulation is parameter-free; and 2) the formulation unifies the label propagation and optimal representation pursuing, and thus the label propagation is enhanced by benefiting from the graph constructed with the derived optimal representation instead of the original representation. Extensive experiments on UCI toy data, handwritten digit recognition, and face recognition all validate the effectiveness of our proposed learning framework compared with the state-of-the-art methods for feature extraction and semi-supervised learning.

#index 1176959
#* One-Class Collaborative Filtering
#@ Rong Pan;Yunhong Zhou;Bin Cao;Nathan N. Liu;Rajan Lukose;Martin Scholz;Qiang Yang
#t 2008
#c 18
#! Many applications of collaborative filtering (CF), such as news item recommendation and bookmark recommendation, are most naturally thought of as one-class collaborative filtering (OCCF) problems. In these problems, the training data usually consist simply of binary data reflecting a user's action or inaction, such as page visitation in the case of news item recommendation or webpage bookmarking in the bookmarking scenario. Usually this kind of data are extremely sparse (a small fraction are positive examples), therefore ambiguity arises in the interpretation of the non-positive examples. Negative examples and unlabeled positive examples are mixed together and we are typically unable to distinguish them. For example, we cannot really attribute a user not bookmarking a page to a lack of interest or lack of awareness of the page. Previous research addressing this one-class problem only considered it as a classification task. In this paper, we consider the one-class problem under the CF setting. We propose two frameworks to tackle OCCF. One is based on weighted low rank approximation; the other is based on negative example sampling. The experimental results show that our approaches significantly outperform the baselines.

#index 1176960
#* Bayesian Co-clustering
#@ Hanhuai Shan;Arindam Banerjee
#t 2008
#c 18
#! In recent years, co-clustering has emerged as a powerful data mining tool that can analyze dyadic data connecting two entities. However, almost all existing co-clustering techniques are partitional, and allow individual rows and columns of a data matrix to belong to only one cluster. Several current applications, such as recommendation systems and market basket analysis, can substantially benefit from a mixed membership of rows and columns. In this paper, we present Bayesian co-clustering (BCC) models, that allow a mixed membership in row and column clusters. BCC maintains separate Dirichlet priors for rows and columns over the mixed membership and assumes each observation to be generated by an exponential family distribution corresponding to its row and column clusters. We propose a fast variational algorithm for inference and parameter estimation. The model is designed to naturally handle sparse matrices as the inference is done only based on the non-missing entries. In addition to finding a co-cluster structure in observations, the model outputs a low dimensional co-embedding, and accurately predicts missing values in the original matrix. We demonstrate the efficacy of the model through experiments on both simulated and real data.

#index 1176961
#* DisCo: Distributed Co-clustering with Map-Reduce: A Case Study towards Petabyte-Scale End-to-End Mining
#@ Spiros Papadimitriou;Jimeng Sun
#t 2008
#c 18
#! Huge datasets are becoming prevalent; even as researchers, we now routinely have to work with datasets that are up to a few terabytes in size. Interesting real-world applications produce huge volumes of messy data. The mining process involves several steps, starting from pre-processing the raw data to estimating the final models. As data become more abundant, scalable and easy-to-use tools for distributed processing are also emerging. Among those, Map-Reduce has been widely embraced by both academia and industry. In database terms, Map-Reduce is a simple yet powerful execution engine, which can be complemented with other data storage and management components, as necessary. In this paper we describe our experiences and findings in applying Map-Reduce, from raw data to final models, on an important mining task. In particular, we focus on co-clustering, which has been studied in many applications such as text mining, collaborative filtering, bio-informatics, graph mining. We propose the Distributed Co-clustering (DisCo) framework, which introduces practical approaches for distributed data pre-processing, and co-clustering. We develop DisCo using Hadoop, an open source Map-Reduce implementation. We show that DisCo can scale well and efficiently process and analyze extremely large datasets (up to several hundreds of gigabytes) on commodity hardware.

#index 1176962
#* Learning Bayesian Networks: A MAP Criterion for Joint Selection of Model Structure and Parameter
#@ Carsten Riggelsen
#t 2008
#c 18
#! For learning Bayesian Network (BN) structures, it has become common practice to use the Bayesian Dirichlet (BD) scoring criterion. In contrast to most other scoring metrics that functionally can be interpreted as regularized maximum likelihood criteria, the BD metric cannot be considered as such. The functional dissimilarity of the BD metric compared to other metrics is an obstacle from an analytical point of view; this is for instance becomes clear in the context of the Structural EM algorithm for learning BNs from incomplete data. Also, it is not easy to pin-point why exactly and to what extend regularization is taken care of by applying the BD metric. We introduce a Bayesian scoring criterion that is closely related to the BD metric, but solves the obvious disadvantages of the BD metric. We arrive at this result by using the same basic assumptions as for the BD metric, but in contrast to the BD metric, where focus is on learning the model structure only, we aim at learning the most probable BN pair jointly, i.e., model structure and the parameter are selected as a pair. This approach yields a scoring metric that has the functional form of a regularized maximum likelihood metric. We perform experiments, and show that this MAP BN metric also yields better results than the BIC and BD metrics on independent test data.

#index 1176963
#* Temporal-Relational Classifiers for Prediction in Evolving Domains
#@ Umang Sharan;Jennifer Neville
#t 2008
#c 18
#! Many relational domains contain temporal information and dynamics that are important to model (e.g., social networks, protein networks). However, past work in relational learning has focused primarily on modeling static "snapshots" of the data and has largely ignored the temporal dimension of these data. In this work, we extend relational techniques to temporally-evolving domains and outline a representational framework that is capable of modeling both temporal and relational dependencies in the data. We develop efficient learning and inference techniques within the framework by considering a restricted set of temporal-relational dependencies and using parameter-tying methods to generalize across relationships and entities. More specifically, we model dynamic relational data with a two-phase process, first summarizing the temporal-relational information with kernel smoothing, and then moderating attribute dependencies with the summarized relational information. We develop a number of novel temporal-relational models using the framework and then show that the current approaches to modeling static relational data are special cases within the framework. We compare the new models to the competing static relational methods on three real-world datasets and show that the temporal-relational models consistently outperform the relational models that ignore temporal information - achieving significant reductions in error ranging from 15% to 70%.

#index 1176964
#* xCrawl: A High-Recall Crawling Method for Web Mining
#@ Kostyantyn Shchekotykhin;Dietmar Jannach;Gerhard Friedrich
#t 2008
#c 18
#! Web Mining Systems exploit the redundancy of data published on the Web to automatically extract information from existing web documents. The first step in the Information Extraction process is thus to locate within a limited period of time as many web pages as possible that contain relevant information, a task which is commonly accomplished by applying focused crawling techniques. The performance of such a crawler can be measured by its "recall", i.e. the percentage of documents found and identified as relevant compared to the number of existing documents. A higher recall value implies that more redundant data is available, which in turn leads to better results in the subsequent fact extraction phase. In this paper, we propose xCrawl, a new focused crawling method which outperforms state-of-the-art approaches with respect to recall values achievable within a given period of time. This method is based on a new combination of ideas and techniques used to identify and exploit navigational structures of websites, such as hierarchies, lists or maps. In addition, automatic query generation is applied to rapidly collect web sources containing target documents. The proposed crawling technique was inspired by the requirements of a Web Mining System developed to extract product and service descriptions and was evaluated in different application scenarios. Comparisons with existing focused crawling techniques reveal that the new crawling method leads to a significant increase in recall whilst maintaining precision.

#index 1176965
#* Comparison of Cluster Representations from Partial Second- to Full Fourth-Order Cross Moments for Data Stream Clustering
#@ Mingzhou (Joe) Song;Lin Zhang
#t 2008
#c 18
#! Under seven external clustering evaluation measures, a comparison is made for cluster representations from the partial second order to the fourth order in data stream clustering. Two external clustering evaluation measures, purity and cross entropy, adopted for data stream clustering performance evaluation in the past, penalize the performance of an algorithm when each hypothesized cluster contains points in different target classes or true clusters, while ignoring the issue of points in a target class falling into different hypothesized clusters. The seven measures will address both sides of the clustering performance. The represented geometry by the partial second-order statistics of a cluster is non-oblique ellipsoidal and cannot describe the orientation, asymmetry, or peakedness of a cluster. The higher-order cluster representation presented in this paper introduces the third and fourth cross moments, enabling the cluster geometry to be beyond an ellipsoid. The higher-order statistics allow two clusters with different representations to merge into a multivariate normal cluster, using normality tests based on multivariate skewness and kurtosis. The clustering performance under the seven external clustering evaluation measures with a synthetic and two real data streams demonstrates the effectiveness of the higher-order cluster representations.

#index 1176966
#* Web Mining for Understanding Stories through Graph Visualisation
#@ Ilija Subaic;Bettina Berendt
#t 2008
#c 18
#! Rich information spaces (like the Web or scientific publications) are full of "stories": sets of statements that evolve over time, manifested as, for example, collections of newspaper articles reporting events relating to an evolving crime investigation, sets of news articles and blog posts accompanying the development of a political election campaign, or sequences of scientific papers on a topic. In this paper, we propose a method and a visualisation tool for mapping and interacting with such stories. In contrast to existing approaches, our method concentrates on relational information and on local patterns rather than on the occurrence of individual concepts and global models. In addition, we present an evaluation framework. A real-life case study is used to illustrate and evaluate the method and tool.

#index 1176967
#* Balancing Spectral Clustering for Segmenting Spatio-temporal Observations of Multi-agent Systems
#@ Bálint Takács;Yiannis Demiris
#t 2008
#c 18
#! We examine the application of spectral clustering for breaking up the behavior of a multi-agent system in space and time into smaller, independent elements. We cluster observations of individualentities in order to identify significant changes in the parameter space (like spatial position)and detect temporal alterations of behavior within the same framework. Data is also influenced byknowledge about important events. Clusters are pre-processed at each step of the iterative subdivision to make the algorithm invariant against spatial scaling, rotation, replay speed andvarying sampling frequency. A method is presented to balance spatial and temporal segmentation based on the expected group size. We demonstrate our results by analyzing the outcomes of acomputer game.

#index 1176968
#* Finding Good Itemsets by Packing Data
#@ Nikolaj Tatti;Jilles Vreeken
#t 2008
#c 18
#! The problem of selecting small groups of itemsets that represent the data well has recently gained a lot of attention. We approach the problem by searching for the itemsets that compress the data efficiently. As a compression technique we use decision trees combined with a refined version of MDL. More formally, assuming that the items are ordered, we create a decision tree for each item that may only depend on the previous items. Our approach allows us to find complex interactions between the attributes, not just co-occurrences of 1s. Further, we present a link between the itemsets and the decision trees and use this link to export the itemsets from the decision trees. In this paper we present two algorithms. The first one is a simple greedy approach that builds a family of itemsets directly from data. The second one, given a collection of candidate itemsets, selects a small subset of these itemsets. Our experiments show that these approaches result in compact and high quality descriptions of the data.

#index 1176969
#* Measuring Proximity on Graphs with Side Information
#@ Hanghang Tong;Huiming Qu;Hani Jamjoom
#t 2008
#c 18
#! This paper studies how to incorporate side information (such as users' feedback) in measuring node proximity on large graphs. Our method (ProSIN) is motivated by the well-studied random walk with restart (RWR). The basic idea behind ProSIN is to leverage side information to refine the graph structure so that the random walk is biased towards/away from some specific zones on the graph. Our case studies demonstrate that ProSIN is well-suited in a variety of applications, including neighborhood search, center-piece subgraphs, and image caption. Given the potential computational complexity of ProSIN, we also propose a fast algorithm (Fast-ProSIN) that exploits the smoothness of the graph structures with/without side information. Our experimental evaluation shows that Fast-ProSIN achieves significant speedups (up to 49x) over straightforward implementations.

#index 1176970
#* Fast Counting of Triangles in Large Real Networks without Counting: Algorithms and Laws
#@ Charalampos E. Tsourakakis
#t 2008
#c 18
#! Triangles are important for real world social networks, lying at the heart of the clustering coefficient and of the transitivity ratio. However, straight-forward and even approximate counting algorithms can be slow, trying to execute or approximate the equivalent of a 3-way database join. In this paper, we provide two algorithms, the Eigen Triangle for counting the total number of triangles in a graph, and the Eigen Triangle Local algorithm that gives the count of triangles that contain a desired node. Additional contributions include the following:(a) We show that both algorithms achieve excellent accuracy, with up to ~1000x faster execution time, on several, real graphs and (b) we discover two new power laws (Degree-Triangle and Triangle Participation laws) with surprising properties.

#index 1176971
#* Improving Collaborative Filtering Recommendations Using External Data
#@ Akhmed Umyarov;Alexander Tuzhilin
#t 2008
#c 18
#! This paper describes an approach for incorporating externally specified aggregate ratings information into certain types of collaborative filtering (CF) methods. For a statistical model-based CF approach, we formally showed that this additional aggregated information provides more accurate recommendations of individual items to individual users. Furthermore, theoretical insights gained from the analysis of this model-based method suggested a way to incorporate aggregate information into the heuristic item-based CF method. Both the model-based and the heuristic item-based CF methods were empirically tested on several datasets, and the experiments uniformly confirmed that the aggregate rating information indeed improves CF recommendations. These results also show the power of theory by demonstrating how the insights gained from theoretical developments can shed light on proper selection of good heuristic methods. We also showed the way to introduce scalability and parallelization into the estimation procedure and reported the running time for steps of the estimation procedure for large datasets.

#index 1176972
#* A Generative Probabilistic Model for Multi-label Classification
#@ Hongning Wang;Minlie Huang;Xiaoyan Zhu
#t 2008
#c 18
#! Traditional discriminative classification method makes little attempt to reveal the probabilistic structure and the correlation within both input and output spaces. In the scenario of multi-label classification, most of the classifiers simply assume the predefined classes are independently distributed, which would definitely hinder the classification performance when there are intrinsic correlations between the classes. In this article, we propose a generative probabilistic model, the Correlated Labeling Model (CoL Model), to formulate the correlation between different classes. The CoL model is presented to capture the correlation between classes and the underlying structures via the latent random variables in a supervised manner. We develop a variational procedure to approximate the posterior distribution and employ the EM algorithm for the empirical Bayes parameter estimation. In our evaluations, the proposed model achieved promising results on various data sets.

#index 1176973
#* SpecVAT: Enhanced Visual Cluster Analysis
#@ Liang Wang;Xin Geng;James Bezdek;Christopher Leckie;Ramamohanarao Kotagiri
#t 2008
#c 18
#! Given a pairwise dissimilarity matrix $\bm{D}$ of a set ofobjects, visual methods such as the VAT algorithm (for visual analysis of cluster tendency) represent $\bm{D}$ as an image $\mathrm{I}(\tilde{\bm{D}})$ where the objects are reordered to highlight cluster structure as dark blocks along the diagonal of the image. A major limitation of such visual methods is their inability to highlight cluster structure in $\mathrm{I}(\tilde{\bm{D}})$ when $\bm{D}$ contains clusters with highly complex structure. In this paper, we address this limitation by proposing a Spectral VAT (SpecVAT) algorithm, where $\bm{D}$ is mapped to $\bm{D'}$ in an embedding space by spectral decomposition of the Laplacian matrix, and then reordered to $\bm{\tilde{D'}}$ using the VAT algorithm. We also propose astrategy to automatically determine the number of clusters in $\mathrm{I}(\bm{\tilde{D'}})$, as well as a method for cluster formation from $\mathrm{I}(\bm{\tilde{D'}})$ based on the difference between diagonal blocks and off-diagonal blocks. We demonstrate the effectiveness of our algorithms on several synthetic and real-world data sets that are not amenable to analysis via traditional VAT.

#index 1176974
#* Dirichlet Process Based Evolutionary Clustering
#@ Tianbing Xu;Zhongfei (Mark) Zhang;Philip S. Yu;Bo Long
#t 2008
#c 18
#! Evolutionary Clustering has emerged as an important research topic in recent literature of data mining, and solutions to this problem have found a wide spectrum of applications, particularly in social network analysis. In this paper, based on the recent literature on Dirichlet processes, we have developed two different and specific models as solutions to this problem: DPChain and HDP-EVO. Both models substantially advance the literature on evolutionary clustering in the sense that not only they both perform better than the existing literature, but more importantly they are capable of automatically learning the cluster numbers and structures during the evolution. Extensive evaluations have demonstrated the effectiveness and promise of these models against the state-of-the-art literature.

#index 1176975
#* Evolutionary Clustering by Hierarchical Dirichlet Process with Hidden Markov State
#@ Tianbing Xu;Zhongfei (Mark) Zhang;Philip S. Yu;Bo Long
#t 2008
#c 18
#! This paper studies evolutionary clustering, which is a recently hot topic with many important applications, noticeably in social network analysis. In this paper, based on the recent literature on Hierarchical Dirichlet Process (HDP) and Hidden Markov Model (HMM), we have developed a statistical model HDP-HTM that combines HDP with a Hierarchical Transition Matrix (HTM) based on the proposed Infinite Hierarchical Hidden Markov State model (iH$^2$MS) as an effective solution to this problem. The HDP-HTM model substantially advances the literature on evolutionary clustering in the sense that not only it performs better than the existing literature, but more importantly it is capable of automatically learning the cluster numbers and structures and at the same time explicitly addresses the correspondence issue during the evolution. Extensive evaluations have demonstrated the effectiveness and promise of this solution against the state-of-the-art literature.

#index 1176976
#* TOFA: Trace Oriented Feature Analysis in Text Categorization
#@ Jun Yan;Ning Liu;Qiang Yang;Weiguo Fan;Zheng Chen
#t 2008
#c 18
#! Dimension reduction for large-scale text data is attracting much attention lately due to the rapid growth of World Wide Web. We can consider dimension reduction algorithms in two categories: feature extraction and feature selection. An important problem remains: it has been difficult to integrate these two algorithm categories into a single framework, making it difficult to reap the benefit of both. In this paper, we formulate the two algorithm categories through a unified optimization framework. Under this framework, we develop a novel feature selection algorithm called Trace Oriented Feature Analysis (TOFA). The novel objective function of TOFA is a unified framework that integrates many prominent feature extraction algorithms such as unsupervised Principal Component Analysis and supervised Maximum Margin Criterion are special cases of it. Thus TOFA can process not only supervised problem but also unsupervised and semi-supervised problems. Experimental results on real text datasets demonstrate the effectiveness and efficiency of TOFA.

#index 1176977
#* Clustering Distributed Time Series in Sensor Networks
#@ Jie Yin;Mohamed Medhat Gaber
#t 2008
#c 18
#! Event detection is a critical task in sensor networks, especially for environmental monitoring applications. Traditional solutions to event detection are based on analyzing one-shot data points, which might incur a high false alarm rate because sensor data is inherently unreliable and noisy. To address this issue, we proposea novel Distributed Single-pass Incremental Clustering (DSIC) technique to cluster the time series obtained at sensor nodes based on their underlying trends. In order to achieve scalability and energy-efficiency, our DSIC technique uses a hierarchical structure of sensor networks as the underlying infrastructure. The algorithm first compresses the time series produced at individual sensor nodes into a compact representation using Haar wavelettransform, and then, based on dynamic time warping distances, hierarchically groups the approximate time series into a global clustering model in an incremental manner. Experimental results on both real data and synthetic data demonstrate that our DSIC algorithm is accurate, energy-efficient and robust with respect tonetwork topology changes.

#index 1176978
#* M3MIML: A Maximum Margin Method for Multi-instance Multi-label Learning
#@ Min-Ling Zhang;Zhi-Hua Zhou
#t 2008
#c 18
#! Multi-instance multi-label learning (MIML) deals with the problem where each training example is associated with not only multiple instances but also multiple class labels. Previous MIML algorithms work by identifying its equivalence in degenerated versions of multi-instance multi-label learning. However, useful information encoded in training examples may get lost during the identification process. In this paper, a maximum margin method is proposed for MIML which directly exploits the connections between instances and labels. The learning task is formulated as a quadratic programming (QP) problem and implemented in its dual form. Applications to scene classification and text categorization show that the proposed approach achieves superior performance over existing MIML methods.

#index 1176979
#* RTM: Laws and a Recursive Generator for Weighted Time-Evolving Graphs
#@ Leman Akoglu;Mary McGlohon;Christos Faloutsos
#t 2008
#c 18
#! How do real, weighted graphs change over time? What patterns, if any, do they obey? Earlier studies focus on unweighted graphs, and, with few exceptions, they focus on static snapshots. Here, we report patterns we discover on several real, weighted, time-evolving graphs. The reported patterns can help in detecting anomalies in natural graphs, in making link prediction and in providing more criteria for evaluation of synthetic graph generators. We further propose an intuitive and easy way to construct weighted, time-evolving graphs. In fact, we prove that our generator will produce graphs which obey many patterns and laws observed to date. We also provide empirical evidence to support our claims.

#index 1176980
#* A Shrinkage Approach for Modeling Non-stationary Relational Autocorrelation
#@ Pelin Angin;Jennifer Neville
#t 2008
#c 18
#! Recent research has shown that collective classification in relational data often exhibit significant performance gains over conventional approaches that classify instances individually. This is primarily due to the presence of autocorrelation in relational datasets, meaning that the class labels of related entities are correlated and inferences about one instance can be used to improve inferences about linked instances. Statistical relational learning techniques exploit relational autocorrelation by modeling global autocorrelation dependencies under the assumption that the level of autocorrelation is stationary throughout the dataset. To date, there has been no work examining the appropriateness of this stationarity assumption. In this paper, we examine two real-world datasets and show that there is significant variance in the autocorrelation dependencies throughout the relational data graphs. We develop a shrinkage technique for modeling this non-stationary autocorrelation and show that it achieves significant accuracy gains over competing techniques that model either local or global autocorrelation dependencies in isolation.

#index 1176981
#* Latent Dirichlet Allocation and Singular Value Decomposition Based Multi-document Summarization
#@ Rachit Arora;Balaraman Ravindran
#t 2008
#c 18
#! Multi-Document Summarization deals with computing a summary for a set of related articles such that they give the user a general view about the events. One of the objectives is that the sentences should cover the different events in the documents with the information covered in as few sentences as possible. Latent Dirichlet Allocation can breakdown these documents into different topics or events. However to reduce the common information content the sentences of the summary need to be orthogonal to each other since orthogonal vectors have the lowest possible similarity and correlation between them. Singular Value Decompositions used to get the orthogonal representations of vectors and representing sentences as vectors, we can get the sentences that are orthogonal to each other in the LDA mixture model weighted term domain. Thus using LDA we find the different topics in the documents and using SVD we find the sentences that best represent these topics. Finally we present the evaluation of the algorithms on the DUC2002 Corpus multi-document summarization tasks using the ROUGE evaluator to evaluate the summaries. Compared to DUC 2002 winners, our algorithms gave significantly better ROUGE-1 recall measures.

#index 1176982
#* INSCY: Indexing Subspace Clusters with In-Process-Removal of Redundancy
#@ Ira Assent;Ralph Krieger;Emmanuel Müller;Thomas Seidl
#t 2008
#c 18
#! Subspace clustering aims at detecting clusters in any subspace projection of a high dimensional space. As the number of projections is exponential in the number of dimensions, efficiency is crucial. Moreover, the resulting subspace clusters are often highly redundant, i.e. many clusters are detected multiply in several projections. We propose a novel index for efficient subspace clustering in a novel depth-first processing with in-process-removal of redundant clusters for better pruning. Thorough experiments on real and synthetic data show that INSCY yields substantial efficiency and quality improvements.

#index 1176983
#* A Conservative Feature Subset Selection Algorithm with Missing Data
#@ Alex Aussem;Sergio Rodrigues de Morais
#t 2008
#c 18
#! This paper introduces a novel conservative feature subset selection method with incomplete data sets. The method is conservative in the sense that it selects the minimal subset of features that renders the rest of the features independent of the target (the class variable) without making any assumption about the missing data mechanism. This is achieved in the context of determining the Markov blanket of the target that reflects the worst-case assumption about the missing data mechanism, including the case when data is not missing at random. An application of the method on synthetic incomplete data is carried out to illustrate its practical relevance. The method is compared against state-of-the-art approaches such as the {expectation maximization} (EM) algorithm and the available case technique.

#index 1176984
#* Nonparametric Monotone Classification with MOCA
#@ Nicola Barile;Ad Feelders
#t 2008
#c 18
#! We describe a monotone classification algorithm called MOCA that attemptsto minimize the mean absolute prediction error for classification problems with ordered class labels.We first find a monotone classifier with minimum L1 loss on the training sample, and then use a simpleinterpolation scheme to predict the class labels for attribute vectors not present in the training data.We compare MOCA to the Ordinal Stochastic Dominance Learner (OSDL), on artificial as well asreal data sets. We show that MOCA often outperforms OSDL with respect to mean absolute prediction error.

#index 1176985
#* Mining Large Networks with Subgraph Counting
#@ Ilaria Bordino;Debora Donato;Aristides Gionis;Stefano Leonardi
#t 2008
#c 18
#! The problem of mining frequent patterns in networks has many applications, including analysis of complex networks, clustering of graphs, finding communities in social networks, and indexing of graphical and biological databases. Despite this wealth of applications, the current state of the art lacks algorithmic tools for counting the number of subgraphs contained in a large network. In this paper we develop data-stream algorithms that approximate the number of all subgraphs of three and four vertices in directed and undirected networks. We use the frequency of occurrence of all subgraphs to prove their significance in order to characterize different kinds of networks: we achieve very good precision in clustering networks with similar structure. The significance of our method is supported by the fact that such high precision cannot be achieved when performing clustering based on simpler topological properties, such as degree, assortativity, and eigenvector distributions. We have also tested our techniques using swap randomization.

#index 1176986
#* Comparative Evaluation of Anomaly Detection Techniques for Sequence Data
#@ Varun Chandola;Varun Mithal;Vipin Kumar
#t 2008
#c 18
#! We present a comparative evaluation of a large number of anomaly detection techniques on a variety of publicly available as well as artificially generated data sets. Many of these are existing techniques while some are slight variants and/or adaptations of traditional anomaly detection techniques to sequence data.

#index 1176987
#* On Locally Linear Classification by Pairwise Coupling
#@ Feng Chen;Chang-Tien Lu;Arnold P. Boedihardjo
#t 2008
#c 18
#! Locally linear classification by pairwise coupling addresses a nonlinear classification problem by three basic phases: decompose the classes of complex concepts into linearly separable subclasses, learn a linear classifier for each pair, and combine pairwise classifiers into a single classifier. A number of methods have been proposed in this framework. However, these methods have two major deficiencies: 1) lack of systematic evaluation of this framework; 2) naive application of clustering algorithms to generate subclasses. This paper proves the equivalence between three popular combination schemas under general settings, defines several global criterion functions for measuring the goodness of subclasses, and presents a supervised greedy clustering algorithm to optimize the proposed criterion functions. Extensive experiments were conducted to validate the effectiveness of the proposed techniques.

#index 1176988
#* A Probability Model for Projective Clustering on High Dimensional Data
#@ Lifei Chen;Qingshan Jiang;Shengrui Wang
#t 2008
#c 18
#! Clustering high dimensional data is a big challenge in data mining due to the curse of dimensionality. To solve this problem, projective clustering has been defined as an extension of traditional clustering that seeks to find projected clusters in subsets of dimensions of a data space. In this paper, the problem of modeling projected clusters is first discussed, and an extended Gaussian model is proposed. Second, a general objective criterion used with $k$-means type projective clustering is presented based on the model. Finally, the expressions to learn model parameters are derived and then used in a new algorithm named FPC to perform fuzzy clustering on high dimensional data. The experimental results on document clustering show the effectiveness of the proposed clustering model.

#index 1176989
#* Estimating Aggregates over Multiple Sets
#@ Edith Cohen;Haim Kaplan
#t 2008
#c 18
#! Many datasets, including market basket data, text or hypertext documents, and measurement data collected in different nodes or time periods, are modeled as a collection of sets over a ground set of (weighted) items. We consider the problem of estimating basic aggregates such as the weight or selectivity of a subpopulation of the items. We extend classic summarization techniques based on sampling to this scenario when we have multiple sets and selection predicates based on membership in particular sets.

#index 1176990
#* Welcome to ICDM 2008
#@ 
#t 2008
#c 18

#index 1176991
#* A Joint Matrix Factorization Approach to Unsupervised Action Categorization
#@ Peng Cui;Fei Wang;Li-Feng Sun;Shi-Qiang Yang
#t 2008
#c 18
#! In this paper, a novel unsupervised approach to mining categories from action video sequences is presented. This approach consists of two modules: action representation and learning model. Videos are regarded as spatially distributed dynamic pixel time series, which are quantized into pixel prototypes. After replacing the pixel time eries with their corresponding prototype labels, the video sequences are compressed into 2D action matrices. We put these matrices together to form an multi-action tensor, and propose the joint matrix factorization method to simultaneously cluster the pixel prototypes into pixel signatures, and matrices into action classes. The approach is tested on public and popular Weizmann data set, and promising results are achieved.

#index 1176992
#* Finding Alternative Clusterings Using Constraints
#@ Ian Davidson;Zijie Qi
#t 2008
#c 18
#! The aim of data mining is to find novel and actionable insights. However, most algorithms typically just find a single explanation of the data even though alternatives could exist. In this work, we explore a general purpose approach to find an alternative clustering of the data with the aid of must-link and cannot-link constraints. This problem has received little attention in the literature and since our approach can be incorporated into the many clustering algorithms that use a distance function, compares favorably with existing work.

#index 1176993
#* Efficient Feature Selection in the Presence of Multiple Feature Classes
#@ Paramveer S. Dhillon;Dean Foster;Lyle H. Ungar
#t 2008
#c 18
#! We present an information theoretic approach to feature selection when the data possesses feature classes. Feature classes are pervasive in real data. For example, in gene expression data, the genes which serve as features may be divided into classes based on their membership in gene families or pathways. When doing word sense disambiguation or named entity extraction, features fall into classes including adjacent words, their parts of speech, and the topic and venue of the document the word is in. When predictive features occur predominantly in a small number of feature classes, our information theoretic approach significantly improves feature selection. Experiments on real and synthetic data demonstrate substantial improvement in predictive accuracy over the standard $L_0$ penalty-based stepwise and stream wise feature selection methods as well as over Lasso and Elastic Nets, all of which are oblivious to the existence of feature classes.

#index 1176994
#* Why Stacked Models Perform Effective Collective Classification
#@ Andrew Fast;David Jensen
#t 2008
#c 18
#! Collective classification techniques jointly infer all class labels of a relational data set, using the inferences about one class label to influence inferences about related class labels. Kou and Cohen recently introduced an efficient relational model based on stacking that, despite its simplicity, has equivalent accuracy to more sophisticated joint inference approaches. Using experiments on both real and synthetic data, we show that the primary cause for the performance of the stacked model is the reduction in bias from learning the stacked model on inferred labels rather than true labels. The reduction in variance due to conditional inference also contributes to the effect but it is not as strong. In addition, we show that the performance of the joint inference and stacked learners can be attributed to an implicit weighting of local and relational features at learning time.

#index 1176995
#* Multiplicative Mixture Models for Overlapping Clustering
#@ Qiang Fu;Arindam Banerjee
#t 2008
#c 18
#! The problem of overlapping clustering, where a point is allowed to belong to multiple clusters, is becoming increasingly important in a variety of applications. In this paper, we present an overlapping clustering algorithm based on multiplicative mixture models. We analyze a general setting where each component of the multiplicative mixture is from an exponential family, and present an efficient alternating maximization algorithm to learn the model and infer overlapping clusters. We also show that when each component is assumed to be a Gaussian, we can apply the kernel trick leading to non-linear cluster separators and obtain better clustering quality. The efficacy of the proposed algorithms is demonstrated usingexperiments on both UCI benchmark datasets and a microarray gene expression dataset.

#index 1176996
#* Anomaly Detection Support Vector Machine and Its Application to Fault Diagnosis
#@ Ryohei Fujimaki
#t 2008
#c 18
#! We address the issue of classification problems in the following situation: test data include data belonging to unlearned classes. To address this issue, most previous works have taken two-stage strategies where unclear data are detected using an anomaly detection algorithm in the first stage while the rest of data are classified into learned classes using a classification algorithm in the second stage. In this study, we propose Anomaly Detection Support Vector Machine (ADSVM) which unifies classification and anomaly detection. ADSVM is unique in comparison with the previous work in that it addresses the two problems simultaneously. We also propose a multiclass extension of ADSVM that uses a pairwise voting strategy. We empirically present that ADSVM outperforms two-stage algorithms in application to an real automobile fault dataset, as well as to UCI benchmark datasets.

#index 1176997
#* A Recommendation System for Preconditioned Iterative Solvers
#@ Thomas George;Anshul Gupta;Vivek Sarin
#t 2008
#c 18
#! Preconditioned iterative methods are often used to solve very large sparse systems of linear systems that arise in many scientific and engineering applications. The performance and robustness of these solvers is extremely sensitive to the choice of multiple preconditioner and solver parameters. Users of iterative methods often encounter an overwhelming number of combinations of choices for solvers, matrix preprocessing steps, preconditioners, and their parameters. The lack of a unified theoretical analysis of preconditioners coupled with limited knowledge of their interaction with linear systems makes it highly challenging for practitioners to choose good solver configurations. In this paper, we propose a novel, multi-stage learning based methodology for determining the best solver configurations to optimize the desired performance behavior for any given linear system. Empirical results over real performance data for the Hypre iterative solver package demonstrate the efficacy and flexibility of the proposed approach.

#index 1252949
#* Proceedings of the 9th Industrial Conference on Advances in Data Mining. Applications and Theoretical Aspects
#@ Petra Perner
#t 2009
#c 18

#index 1252950
#* Distances in Classification
#@ Claus Weihs;Gero Szepannek
#t 2009
#c 18
#% 835018
#% 1103390
#% 1414233
#! The notion of distance is the most important basis for classification. This is especially true for unsupervised learning, i.e. clustering, since there is no validation mechanism by means of objects of known groups. But also for supervised learning standard distances often do not lead to appropriate results. For every individual problem the adequate distance is to be decided upon. This is demonstrated by means of three practical examples from very different application areas, namely social science, music science, and production economics. In social science, clustering is applied to spatial regions with very irregular borders. Then adequate spatial distances may have to be taken into account for clustering. In statistical musicology the main problem is often to find an adequate transformation of the input time series as an adequate basis for distance definition. Also, local modelling is proposed in order to account for different subpopulations, e.g. instruments. In production economics often many quality criteria have to be taken into account with very different scaling. In order to find a compromise optimum classification, this leads to a pre-transformation onto the same scale, called desirability.

#index 1252951
#* Electronic Nose Ovarian Carcinoma Diagnosis Based on Machine Learning Algorithms
#@ José Chilo;György Horvath;Thomas Lindblad;Roland Olsson
#t 2009
#c 18
#% 129212
#% 136350
#% 181337
#% 304935
#% 376266
#% 926881
#% 1066218
#! Ovarian carcinoma is one of the most deadly diseases, especially in the case of late diagnosis. This paper describes the result of a pilot study on an early detection method that could be inexpensive and simple based on data processing and machine learning algorithms in an electronic nose system. Experimental analysis using real ovarian carcinoma samples is presented in this study. The electronic nose used in this pilot test is very much the same as a nose used to detect and identify explosives. However, even if the apparatus used is the same, it is shown that the use of proper algorithms for analysis of the multi-sensor data from the electronic nose yielded surprisingly good results with more than 77% classification rate. These results are suggestive for further extensive experiments and development of the hardware as well as the software.

#index 1252952
#* Data Mining of Agricultural Yield Data: A Comparison of Regression Models
#@ Georg Ruß
#t 2009
#c 18
#% 91868
#% 116149
#% 136350
#% 356892
#% 376266
#% 449588
#% 722757
#% 1103382
#% 1106563
#% 1402657
#! Nowadays, precision agriculture refers to the application of state-of-the-art GPS technology in connection with small-scale, sensor-based treatment of the crop. This introduces large amounts of data which are collected and stored for later usage. Making appropriate use of these data often leads to considerable gains in efficiency and therefore economic advantages. However, the amount of data poses a data mining problem --- which should be solved using data mining techniques. One of the tasks that remains to be solved is yield prediction based on available data. From a data mining perspective, this can be formulated and treated as a multi-dimensional regression task. This paper deals with appropriate regression techniques and evaluates four different techniques on selected agriculture data. A recommendation for a certain technique is provided.

#index 1252953
#* Study of Principal Components on Classification of Problematic Wine Fermentations
#@ Alejandra Urtubia U.;J. Ricardo Pérez-Correa
#t 2009
#c 18
#% 492970
#% 850491
#% 1389713
#! Data mining techniques have already shown useful to classify wine fermentations as problematic. Then, these techniques are a good option for winemakers who currently lack the tools to identify early signs of undesirable fermentation behavior and, therefore, are unable to take possible mitigating actions. In this study we assessed how much the performance of a clustering K-means fermentation classification procedure is affected by the number of principal components (PCs), when principal component analysis (PCA) is previously applied to reduce the dimensionality of the available data. It was observed that three PCs were enough to preserve the overall information of a dataset containing reliable measurements only. In this case, a 40% detection ability of problematic fermentations was achieved. In turn, using a more complete dataset, but containing unreliable measurements, the number of PCs yielded different classifications. Here, 33%f the problematic fermentations were detected.

#index 1252954
#* A Data Mining Method for Finding Hidden Relationship in Blood and Urine Examination Items for Health Check
#@ Kazuhiko Shinozawa;Norihiro Hagita;Michiko Furutani;Rumiko Matsuoka
#t 2009
#c 18
#! Our periodic health examination often describes whether each examination item in blood and urine takes in the reference range of each examination item and a simple summary report on checks in everyday life and the possibility of suspicious diseases. However, it uses n variable items such as AST(GOT), ALT(GPT) which are less correlated, and often includes expensive tumor markers. Therefore, this paper proposes a data mining method for finding hidden relationships between these items in order to reduce the examination fee and giving a report depending on individuals. Since low correlation coefficients are shown in most pairs of items over all clients, a set of item's values in consecutive health examinations of each client is investigated for data mining. Four groups are formed according to the frequency taking outside the reference range in an item for three consecutive examinations, and average values of the other items included in each group are calculated in all pairs of items. The experiment results for three consecutive health examinations show that a lot of item pairs have positive or negative correlations between different frequencies with an item and the averages with the other item despite the fact that their correlation coefficients are small. The result shows both possible reducting of reducing the examination fee as inexpensive as possible and the possibility of a health-care report reflecting individuals.

#index 1252955
#* Application of Classification Association Rule Mining for Mammalian Mesenchymal Stem Cell Differentiation
#@ Weiqi Wang;Yanbo J. Wang;René Bañares-Alcántara;Zhanfeng Cui;Frans Coenen
#t 2009
#c 18
#% 4868
#% 116149
#% 136350
#% 152934
#% 210160
#% 246831
#% 300120
#% 466483
#% 629642
#% 785382
#% 840901
#% 942741
#% 1098999
#% 1676579
#% 1707806
#! In this paper, data mining is used to analyze the differentiation of mammalian Mesenchymal Stem Cells (MSCs). A database comprising the key parameters which, we believe, influence the destiny of mammalian MSCs has been constructed. This paper introduces Classification Association Rule Mining (CARM) as a data mining technique in the domain of tissue engineering and initiates a new promising research field. The experimental results show that the proposed approach performs well with respect to the accuracy of (classification) prediction. Moreover, it was found that some rules mined from the constructed MSC database are meaningful and useful.

#index 1252956
#* Computer-Aided Diagnosis in Brain Computed Tomography Screening
#@ Hugo Peixoto;Victor Alves
#t 2009
#c 18
#% 926881
#! Currently, interpretation of medical images is almost exclusively made by specialized physicians. Although, the next decades will most certainly be of change and computer-aided diagnosis systems will play an important role in the reading process. Assisted interpretation of medical images has become one of the major research subjects in medical imaging and diagnostic radiology. From a methodological point of view, the main attraction for the resolution of this kind of problem arises from the combination of the image reading made by the radiologists, with the results obtained from using Artificial Intelligence based applications that will contribute to the reduction and eventually the elimination of perception errors. This article describes how machine learning algorithms can help distinguish normal readings in brain Computed Tomography from all its variations. The goal is to have a system that is able to detect normal appearing structures, thus identifying normal studies, making the reading by the radiologist unnecessary for a large proportion of the brain Computed Tomography scans.

#index 1252957
#* Knowledge Representation in Difficult Medical Diagnosis
#@ Ana Aguilera;Alberto Subero
#t 2009
#c 18
#% 65653
#% 492342
#% 556969
#% 566459
#% 568159
#% 1403608
#! This article is based on medical knowledge produced thought collaborative problem solving by a group of experts, in the field of medical diagnosis. In this work, we propose a representation format for a medical case base into a traditional RDBMS representation, which is queryable using standard SQL. We are concerned in difficult medical cases which imply a solution in several steps with several expert solvers (medical specialists). Some queries on this case base are proposed. A case base was implemented and validated in real time with experts on the real scenarios.

#index 1252958
#* Forecasting Product Life Cycle Phase Transition Points with Modular Neural Networks Based System
#@ Serge Parshutin;Ludmila Aleksejeva;Arkady Borisov
#t 2009
#c 18
#% 95130
#% 269634
#% 341700
#% 391311
#% 393812
#% 818916
#% 835018
#% 962852
#! Management of the product life cycle and of the corresponding supply network largely depends on information in which specific phase of the life cycle one or another product currently is and when the phase will be changed. Finding a phase of the product life cycle can be interpreted as forecasting transition points between phases of life cycle of these products. This paper provides a formulation of the above mentioned task of forecasting the transition points and presents the structured data mining system for solving that task. The developed system is based on the analysis of historical demand for products and on information about transitions between phases in life cycles of those products. The experimental results with real data display information about the potential of the created system.

#index 1252959
#* Visualizing the Competitive Structure of Online Auctions
#@ Stephen France;Douglas Carroll
#t 2009
#c 18
#% 720580
#% 948875
#% 1099011
#! Visualizations of product competition are common in marketing research. Competitive product relationships can be modeled using data from a variety of sources, including questionnaires, surveys and brand switching data. Product competition applications based on brand switching data are usually restricted to high volume, frequent purchase products such as coffee and frozen foods. Analysis of competitive product structure requires data for multiple purchases from a single consumer, data that are not usually available for large value, rare purchase items such as cars and computers. We use bid information from online auctions as a source of competitive product structure information for these items. We develop a simple algorithm for creating a distance matrix representing market structure between brands and brand features from online auction data. We take data from eBay mobile phone auctions in the USA and based upon the auction data develop visualizations of product competition for brands and brand features.

#index 1252960
#* Credit Risk Handling in Telecommunication Sector
#@ Monika Szczerba;Andrzej Ciemski
#t 2009
#c 18
#! This article presents an application of data mining methods in telecommunication sector. This sector becomes a new area of research for particular problem solving e.g. churn prediction, cross-up selling marketing campaigns, fraud detection, customer segmentation and profiling, data classification, association rules discovery, data clustering, parameter importance analysis etc. Credit risk prediction became a new research domain in pattern recognition area aimed to find the most risky customers. This article is devoted to assessing credit risk from the moment of opening a customer account to the moment of closing an account due to non-payment. Algorithms are used to identify and insolvency of a debtor. Credit scoring is presented in a form of activation models, which are used to predict customers' debt as well as indicate clients with the highest, medium and smallest credit risk. Practical part of the article is based on the real customer database in a telecommunication company.

#index 1252961
#* Sales Intelligence Using Web Mining
#@ Viara Popova;Robert John;David Stockton
#t 2009
#c 18
#% 118736
#% 136350
#% 190581
#% 269218
#% 271082
#% 279755
#% 281251
#% 318412
#% 320930
#% 406493
#% 458379
#% 465757
#% 480309
#% 736953
#% 756951
#% 766444
#% 815240
#% 926881
#% 1663660
#% 1711526
#! This paper presents a knowledge extraction system for providing sales intelligence based on information downloaded from the WWW. The information is first located and downloaded from relevant companies' websites and then machine learning is used to find these web pages that contain useful information where useful is defined as containing news about orders for specific products. Several machine learning algorithms were tested from which k-nearest neighbour, support vector machines, multi-layer perceptron and C4.5 decision tree produced best results in one or both experiments however k-nearest neighbour and support vector machines proved to be most robust which is a highly desired characteristic in the particular application. K-nearest neighbour slightly outperformed the support vector machines in both experiments which contradicts the results reported previously in the literature.

#index 1252962
#* A Sales Forecast Model for the German Automobile Market Based on Time Series Analysis and Data Mining Methods
#@ Bernhard Brühl;Marco Hülsmann;Detlef Borscheid;Christoph M. Friedrich;Dirk Reith
#t 2009
#c 18
#% 190581
#% 243728
#% 309208
#% 404849
#% 633796
#% 928355
#! In this contribution, various sales forecast models for the German automobile market are developed and tested. Our most important criteria for the assessment of these models are the quality of the prediction as well as an easy explicability. Yearly, quarterly and monthly data for newly registered automobiles from 1992 to 2007 serve as the basis for the tests of these models. The time series model used consists of additive components: trend, seasonal, calendar and error component. The three latter components are estimated univariately while the trend component is estimated multivariately by Multiple Linear Regression as well as by a Support Vector Machine. Possible influences which are considered include macro-economic and market-specific factors. These influences are analysed by a feature selection. We found the non-linear model to be superior. Furthermore, the quarterly data provided the most accurate results.

#index 1252963
#* Screening Paper Runnability in a Web-Offset Pressroom by Data Mining
#@ A. Alzghoul;A. Verikas;M. Hållander;M. Bacauskiene;A. Gelzinis
#t 2009
#c 18
#% 257039
#% 366182
#% 743284
#% 957072
#% 978117
#% 1011582
#% 1165665
#% 1860135
#! This paper is concerned with data mining techniques for identifying the main parameters of the printing press, the printing process and paper affecting the occurrence of paper web breaks in a pressroom. Two approaches are explored. The first one treats the problem as a task of data classification into "break " and "non break " classes. The procedures of classifier design and selection of relevant input variables are integrated into one process based on genetic search. The search process results in a set of input variables providing the lowest average loss incurred in taking decisions. The second approach, also based on genetic search, combines procedures of input variable selection and data mapping into a low dimensional space. The tests have shown that the web tension parameters are amongst the most important ones. It was also found that, provided the basic off-line paper parameters are in an acceptable range, the paper related parameters recorded online contain more information for predicting the occurrence of web breaks than the off-line ones. Using the selected set of parameters, on average, 93.7% of the test set data were classified correctly. The average classification accuracy of the break cases was equal to 76.7%.

#index 1252964
#* Evaluation of Distraction in a Driver-Vehicle-Environment Framework: An Application of Different Data-Mining Techniques
#@ Fabio Tango;Marco Botta
#t 2009
#c 18
#% 238657
#% 356892
#% 1774872
#! Distraction during driving task is one of the most serious problems affecting traffic safety, being one of the main causes of accidents. Therefore, a method to diagnose and evaluate Distraction appears to be of paramount importance to study and implement efficient counter-measures. This research aims at illustrating our approach in diagnosis of Distraction status, comparing some of the widely used data-mining techniques; in particular, Fuzzy Logic (with Adaptive-Network-based Fuzzy Inference System) and Artificial Neural Networks. The results are compared to select which method gives the best performances.

#index 1252965
#* SO_MAD: SensOr Mining for Anomaly Detection in Railway Data
#@ Julien Rabatel;Sandra Bringay;Pascal Poncelet
#t 2009
#c 18
#% 152934
#% 459006
#% 463903
#% 477791
#% 564496
#% 613364
#% 1052683
#% 1136707
#! Today, many industrial companies must face problems raised by maintenance. In particular, the anomaly detection problem is probably one of the most challenging. In this paper we focus on the railway maintenance task and propose to automatically detect anomalies in order to predict in advance potential failures. We first address the problem of characterizing normal behavior. In order to extract interesting patterns, we have developed a method to take into account the contextual criteria associated to railway data (itinerary, weather conditions, etc.). We then measure the compliance of new data, according to extracted knowledge, and provide information about the seriousness and possible causes of a detected anomaly.

#index 1252966
#* Online Mass Flow Prediction in CFB Boilers
#@ Andriy Ivannikov;Mykola Pechenizkiy;Jorn Bakker;Timo Leino;Mikko Jegoroff;Tommi Kärkkäinen;Sami Äyrämö
#t 2009
#c 18
#% 15462
#% 36638
#% 204531
#% 729437
#% 1159253
#% 1693295
#! Fuel feeding and inhomogeneity of fuel typically cause process fluctuations in the circulating fluidized bed (CFB) process. If control systems fail to compensate for the fluctuations, the whole plant will suffer from fluctuations that are reinforced by the closed-loop controls. This phenomenon causes a reduction of efficiency and lifetime of process components. Therefore, domain experts are interested in developing tools and techniques for getting better understanding of underlying processes and their mutual dependencies in CFB boilers. In this paper we consider an application of data mining technology to the analysis of time series data from a pilot CFB reactor. Namely, we present a rather simple and intuitive approach for online mass flow prediction in CFB boilers. This approach is based on learning and switching regression models. Additionally, noise canceling, and windowing mechanisms are used for improving the robustness of online prediction. We validate our approach with a set of simulation experiments with real data collected from the pilot CFB boiler.

#index 1252967
#* Integrating Data Mining and Agent Based Modeling and Simulation
#@ Omar Baqueiro;Yanbo J. Wang;Peter Mcburney;Frans Coenen
#t 2009
#c 18
#% 4868
#% 116149
#% 136350
#% 152934
#% 232108
#% 241703
#% 246831
#% 252533
#% 269268
#% 280409
#% 306861
#% 316709
#% 392811
#% 393792
#% 630991
#% 719768
#% 798033
#% 798624
#% 818916
#% 883295
#% 927581
#% 1043199
#% 1562157
#% 1776343
#% 1776560
#! In this paper, we introduce an integration study which combines Data Mining (DM) and Agent Based Modeling and Simulation (ABMS). This study, as a new paradigm for DM/ABMS, is concerned with two approaches: (i) applying DM techniques in ABMS investigation, and inversely (ii) utilizing ABMS results in DM research. Detailed description of each approach is presented in this paper. A conclusion and the future work of this (integration) study are given at the end.

#index 1252968
#* Combining Multidimensional Scaling and Computational Intelligence for Industrial Monitoring
#@ António Dourado;Sara Silva;Lara Aires;João Araújo
#t 2009
#c 18
#% 1527
#% 92148
#% 224182
#% 593047
#% 818170
#% 1398311
#% 1781333
#% 1786334
#! Large industrial complexes with hundreds of variables must be tightly monitored for safety, quality and resources optimization. Multidimensional scaling and computational intelligence are proposed in this work as effective tools for building classifiers of the operating state of the industrial process into normal / abnormal working regions. The VisRed, Visualization by Data Reduction computational framework, is extended with techniques from computational intelligence, such as neural networks (several architectures), support vector machines and neuro-fuzzy systems (in an evolving adaptive implementation) to build such classifiers. The Visbreaker plant of an oil refinery is taken as case study and some scenarios show the potentiality of the combined approach.

#index 1252969
#* A Case of Using Formal Concept Analysis in Combination with Emergent Self Organizing Maps for Detecting Domestic Violence
#@ Jonas Poelmans;Paul Elzinga;Stijn Viaene;Guido Dedene
#t 2009
#c 18
#% 232108
#% 353972
#% 384416
#% 466328
#% 477661
#% 1103410
#% 1303208
#! In this paper, we propose a framework for iterative knowledge discovery from unstructured text using Formal Concept Analysis and Emergent Self Organizing Maps. We apply the framework to a real life case study using data from the Amsterdam-Amstelland police. The case zooms in on the problem of distilling concepts for domestic violence from the unstructured text in police reports. Our human-centered framework facilitates the exploration of the data and allows for an efficient incorporation of prior expert knowledge to steer the discovery process. This exploration resulted in the discovery of faulty case labellings, common classification errors made by police officers, confusing situations, missing values in police reports, etc. The framework was also used for iteratively expanding a domain-specific thesaurus. Furthermore, we showed how the presented method was used to develop a highly accurate and comprehensible classification model that automatically assigns a domestic or non-domestic violence label to police reports.

#index 1252970
#* Ordinal Evaluation: A New Perspective on Country Images
#@ Marko Robnik-Šikonja;Kris Brijs;Koen Vanhoof
#t 2009
#c 18
#% 720010
#% 948210
#! We present a novel use of ordinal evaluation (OrdEval) algorithm as a promising technique to study various marketing phenomena. OrdEval algorithm has originated in data mining and is a general tool to analyze data with ordinal attributes, including surveys. Its many favorable features, including context sensitivity, ability to exploit meaning of ordered features and ordered response, and robustness to noise and missing values in the data, offer marketing practitioners a perspective, not available with classical analytical toolbox. We present a case study applying OrdEval algorithm on country-of-origin (COO) information. We demonstrate some interesting advantages it has to offer and show how to extract and interpret new insights allowing marketing practitioners to further optimize the management of products abroad. Data for the empirical study was gathered by means of 1225 questionnaires. Results indicate that, contrary to the classical view on COO-effects, the processing of country-related cognitions, affects and conations is a non-linear and asymmetric phenomenon. The practical implications of this finding for marketers are discussed more in detail.

#index 1252971
#* Evaluation of Fusion for Similarity Searching in Online Handwritten Documents
#@ Sascha Schimke;Maik Schott;Claus Vielhauer;Jana Dittmann
#t 2009
#c 18
#% 109079
#% 317819
#% 375017
#% 718884
#% 829234
#% 1136738
#% 1306058
#! With the spread of TabletPCs handwriting raises in its significance and importance in the digital domain. Also there exist other devices with pen-based inputs like PDAs, digitizer tablets and pads specially prepared with sensors. The advantage of handwritten input methods is their possibility of an ad hoc creation of technical sketches and drawings alongside with text and that keyboards may be in some cases and environments bothersome. Therefore the amount of handwritten documents is likely to increase. But a great problem is a proper full text search on such documents. This paper discusses the effects of multi-sample and multi-algorithm fusion approaches, known from biometrics to increase the performance. The tests are done by using three different devices (Logitech ioPen, Pegasus PC NotesMaker, ACE CAD DigiMemo Digital) and five different feature extraction methods (square grid, triangular grid, slope, curvature and slant of writing) and show that fusion can improve the retrieval performance in terms of precision and recall from 0.903 and 0.935 without fusion to 0.958 and 0.943 with fusion, respectively.

#index 1252972
#* Self-training Strategies for Handwriting Word Recognition
#@ Volkmar Frinken;Horst Bunke
#t 2009
#c 18
#% 252011
#% 316509
#% 718515
#% 732533
#% 738473
#% 875991
#% 940333
#% 1006589
#% 1164192
#% 1189254
#% 1283393
#% 1455666
#! Handwriting recognition is an emerging subfield of human-computer interaction that has many potential industrial applications, e.g. in postal automation, bank check processing, and automatic form reading. Training a recognizer, however, requires a substantial amount of training examples together with their corresponding ground truth, which needs to be created by humans. A promising way to significantly reduce this effort, and hence cut system development costs, is offered by semi-supervised learning, in which both text with and text without transcription is used for training. However, until today there is no straightforward and established way of semi-supervised learning, particularly not for handwriting recognition. In the self-training approach, an initially trained recognition system creates a new training set from unlabeled data. Using this set, a new recognizer is created. The creation of the training set is done by selecting elements from the unlabeled set, according to their recognition confidence. The success of self-training depends crucially on the data selected. In this paper, we test and compare different rules used to select new training data for single word recognition with and without additional language information in the form of a dictionary. We demonstrate that it is possible to substantially increase the recognition accuracy for both systems.

#index 1252973
#* On a New Similarity Analysis in Frequency Domain for Mining Faces within a Complex Background
#@ D. A. Karras
#t 2009
#c 18
#% 71174
#% 247889
#% 356892
#% 424081
#% 592108
#% 726460
#! A novel similarity analysis is presented in this paper for dealing with the problem of mining faces in a complex image background. The proposed approach integrates a robust feature extraction technique based on a specific method of eigenanalysis in the frequency domain of the unique classes identified in the problem at hand, with neural network based classifiers. Such an eigenalysis aims at identifying principal characteristics in the frequency domain of the above mentioned uniquely identified classes. Each unknown image, in the testing phase, is then, analyzed through a sliding window raster scanning procedure to sliding windows identified, through a first stage neural classifier, as belonging to one of the unique classes previously mentioned. After such a sliding window labeling procedure it is reasonable for a second stage neural classifier to be applied to the testing image viewed as a sequence of such labeled sliding windows for obtaining a final decision about whether a face exists within the given test image or not. Although the proposed approach is a hierarchical procedure, its most critical stage is the similarity analysis performed through eigenanalysis in the frequency domain, since, if good identification/ labeling accuracy could be then obtained, it would facilitate final face mining.

#index 1252974
#* Clustering with Domain Value Dissimilarity for Categorical Data
#@ Jeonghoon Lee;Yoon-Joon Lee;Minho Park
#t 2009
#c 18
#% 36672
#% 140588
#% 280419
#% 314054
#% 413618
#% 835018
#% 917960
#% 940299
#! Clustering is a representative grouping process to find out hidden information and understand the characteristics of dataset to get a view of the further analysis. The concept of similarity and dissimilarity of objects is a fundamental decisive factor for clustering and the measure of them dominates the quality of results. When attributes of data are categorical, it is not simple to quantify the dissimilarity of data objects that have unimportant attributes or synonymous values. We suggest a new idea to quantify dissimilarity of objects by using distribution information of data correlated to each categorical value. Our method discovers intrinsic relationship of values and measures dissimilarity of objects effectively. Our approach does not couple with a clustering algorithm tightly and so can be applied various algorithms flexibly. Experiments on both synthetic and real datasets show propriety and effectiveness of this method. When our method is applied only to traditional clustering algorithms, the results are considerably improved than those of previous methods.

#index 1252975
#* The Normalized Compression Distance as a Distance Measure in Entity Identification
#@ Sebastian Klenk;Dennis Thom;Gunther Heidemann
#t 2009
#c 18
#% 289281
#% 310516
#% 333679
#% 387427
#% 420072
#% 577238
#% 729913
#% 799701
#% 911725
#% 913783
#% 922779
#% 967272
#% 984083
#% 1052997
#% 1064741
#% 1081944
#% 1815525
#% 1816654
#! The identification of identical entities accross heterogeneous data sources still involves a large amount of manual processing. This is mainly due to the fact that different sources use different data representations in varying semantic contexts. Up to now entity identification requires either the --- often manual --- unification of different representations, or alternatively the effort of programming tools with specialized interfaces for each representation type. However, for large and sparse databases, which are common e.g. for medical data, the manual approach becomes infeasible. We have developed a widely applicable compression based approach that does not rely on structural or semantical unity. The results we have obtained are promising both in recognition precision and performance.

#index 1252976
#* Attribute Constrained Rules for Partially Labeled Sequence Completion
#@ Chad A. Williams;Peter C. Nelson;Abolfazl (Kouros) Mohammadian
#t 2009
#c 18
#% 152934
#% 342655
#% 375017
#% 413550
#% 443502
#% 463903
#% 479971
#% 629695
#% 805873
#% 936239
#% 985041
#! Sequential pattern and rule mining have been the focus of much research, however predicting missing sets of elements within a sequence remains a challenge. Recent work in survey design suggests that if these missing elements can be inferred with a higher degree of certainty, it could greatly reduce the time burden on survey participants. To address this problem and the more general problem of missing sensor data, we introduce a new form of constrained sequential rules that use attribute presence to better capture rule confidence in sequences with missing data than previous constraint based techniques. Specifically we examine the problem of given a partially labeled sequence of sets, how well can the missing attributes be inferred. Our study shows this technique significantly improves prediction robustness when even large amounts of data are missing compared to traditional techniques.

#index 1252977
#* Mining Determining Sets for Partially Defined Functions
#@ Dan A. Simovici;Dan Pletea;Rosanne Vetro
#t 2009
#c 18
#% 152934
#% 796210
#% 1089244
#! This paper describes an algorithm that determines the minimal sets of variables that determine the values of a discrete partial function. The Apriori-like algorithm is based on the dual hereditary property of determining sets. Experimental results are provided that demonstrate the efficiency of the algorithm for functions with up to 24 variables. The dependency of the number of minimal determining sets on the size of the specification of the partial function is also examined.

#index 1252978
#* On the Integration of Neural Classifiers through Similarity Analysis of Higher Order Features
#@ D. A. Karras;B. G. Mertzios
#t 2009
#c 18
#% 18547
#% 24027
#% 68713
#% 165769
#% 551872
#% 551884
#% 551905
#% 1286533
#! A novel methodology is herein outlined for combining the classification decisions of different neural network classifiers. Instead of the usual approach for applying voting schemes on the decisions of their output layer neurons, the proposed methodology integrates higher order features extracted by their upper hidden layer units. More specifically, different instances (cases) of each such classifier, derived from the same training process but with different training parameters, are investigated in terms of their higher order features, through similarity analysis, in order to find out repeated and stable higher order features. Then, all such higher order features are integrated through a second stage neural network classifier having as inputs suitable similarity features of them. The herein suggested hierarchical neural system for pattern recognition shows improved classification performance in a computer vision task. The validity of this novel combination approach has been investigated when the first stage neural classifiers involved correspond to different Feature Extraction Methodologies (FEM) for shape classification. The experimental study illustrates that such an approach, integrating higher order features through similarity analysis of a committee of the same classifier instances (cases) and a second stage neural classifier, outperforms other combination methods, like voting combination schemes as well as single neural network classifiers having as inputs all FEMs derived features. In addition, it outperforms hierarchical combination methods non performing integration of cases through similarity analysis.

#index 1252979
#* On Cellular Network Channels Data Mining and Decision Making through Ant Colony Optimization and Multi Agent Systems Strategies
#@ P. M. Papazoglou;D. A. Karras;R. C. Papademetriou
#t 2009
#c 18
#% 114994
#% 159111
#% 194483
#% 198113
#% 250311
#% 276894
#% 296865
#% 300744
#% 369236
#% 387591
#% 393113
#% 459176
#% 643150
#% 757984
#% 925215
#% 933448
#% 1057420
#% 1152219
#% 1219410
#% 1219412
#% 1235662
#% 1291505
#% 1412106
#% 1769881
#% 1848751
#! Finding suitable channels to allocate in order to serve increasing user demands in a cellular network, which is a dynamical system, constitute the most important issue in terms of network performance since they define the bandwidth management methodology. In modern cellular networks these strategies become challenging issues especially when advanced services are applied. The effectiveness of decision making for channel allocation in a cellular network is strongly connected to current traffic and wireless environment conditions. Moreover, in large scale environments, network states change dynamically and the network performance prediction is a hard task. In the recent literature, the network adaptation to current real user needs seems it could be achieved through computational intelligence based channel allocation schemes mainly involving genetic algorithms. In this paper, a quite new approach for communication channels decision making, based on ant colony optimization, which is a special form of swarm intelligence, modelled through multi agent methodology is presented. The main novelty of this research lies on modelling this optimization scheme through multi agent systems. The simulation model architecture which includes network and ant agents are also presented as well as the performance results based on the above techniques. Finally, the current study, also, shows that there is a great field of research concerning intelligent techniques modelled through multi-agent methodologies focused on channels decision making and bandwidth management in wireless communication systems.

#index 1252980
#* Responsible Data Releases
#@ Sanguthevar Rajasekaran;Ofer Harel;Michael Zuba;Greg Matthews;Robert Aseltine
#t 2009
#c 18
#% 576761
#% 937550
#% 1022266
#% 1206678
#% 1221252
#! Data releases to the public should ensure the privacy of individuals involved in the data. Several privacy mechanisms have been proposed in the literature. One such technique is that of data anonymization. For example, synthetic data sets are generated and released. In this paper we analyze the privacy aspects of synthetic data sets. In particular, we introduce a natural notion of privacy and employ it for synthetic data sets.

#index 1316400
#* Proceedings of the 2009 Ninth IEEE International Conference on Data Mining
#@ 
#t 2009
#c 18

#index 1318580
#* Bayesian Overlapping Subspace Clustering
#@ Qiang Fu;Arindam Banerjee
#t 2009
#c 18
#! Given a data matrix, the problem of finding dense/uniform sub-blocks in the matrix is becoming important in several applications. The problem is inherently combinatorial since the uniform sub-blocks may involve arbitrary subsets of rows and columns and may even be overlapping. While there are a few existing methods based on co-clustering or subspace clustering, they typically rely on local search heuristics and in general do not have a systematic model for such data. We present a Bayesian Overlapping Subspace Clustering (BOSC) model which is a hierarchical generative model for matrices with potentially overlapping uniform sub-block structures. The BOSC model can also handle matrices with missing entries. We propose an EM-style algorithm based on approximate inference using Gibbs sampling and parameter estimation using coordinate descent for the BOSC model. Through experiments on both simulated and real datasets, we demonstrate that the proposed algorithm outperforms the state-of-the-art.

#index 1318581
#* Regression Learning Vector Quantization
#@ Mihajlo Grbovic;Slobodan Vucetic
#t 2009
#c 18
#! Learning Vector Quantization (LVQ) is a popular class of nearest prototype classifiers for multiclass classification. Learning algorithms from this family are widely used because of their intuitively clear learning process and ease of implementation. In this paper we propose an extension of the LVQ algorithm to regression. Just like the LVQ algorithm, the proposed modification uses a supervised learning procedure to learn the best prototype positions, but unlike LVQ algorithm for classification, it also learns the best prototype target values. This results in the effective partition of the feature space, similar to the one the K-means algorithm would make. Experimental results on benchmark datasets showed that the proposed Regression LVQ algorithm performs better than the nearest prototype competitors that choose prototypes randomly or through K-means clustering, classification LVQ on quantized target values, and similarly to the memory-based Parzen Window and Nearest Neighbor algorithms.

#index 1318582
#* RING: An Integrated Method for Frequent Representative Subgraph Mining
#@ Shijie Zhang;Jiong Yang;Shirong Li
#t 2009
#c 18
#! We propose a novel representative based subgraph mining model. A series of standards and methods are proposed to select invariants. Patterns are mapped into invariant vectors in a multidimensional space. To find qualified patterns, only a subset of frequent patterns is generated as representatives, such that every frequent pattern is close to one of the representative patterns while representative patterns are distant from each other. We devise the RING algorithm, integrating the representative selection into the pattern mining process. Meanwhile, we use R-trees to assist this mining process. Last but not least, a large number of real and synthetic datasets are employed for the empirical study, which show the benefits of the representative model and the efficiency of the RING algorithm.

#index 1318583
#* Argumentation Based Constraint Acquisition
#@ Kostyantyn Shchekotykhin;Gerhard Friedrich
#t 2009
#c 18
#! Efficient acquisition of constraint networks is a key factor for the applicability of constraint problem solving methods. Current techniques learn constraint networks from sets of training examples, where each example is classified as either a solution or non-solution of a target network. However, in addition to this classification, an expert can usually provide arguments as to why examples should be rejected or accepted. Generally speaking domain specialists have partial knowledge about the theory to be acquired which can be exploited for knowledge acquisition. Based on this observation, we discuss the various types of arguments an expert can formulate and develop a knowledge acquisition algorithm for processing these types of arguments which gives the expert the possibility to input arguments in addition to the learning examples. The result of this approach is a significant reduction in the number of examples which must be provided to the learner in order to learn the target constraint network.

#index 1318584
#* Fine-Grain Perturbation for Privacy Preserving Data Publishing
#@ Rhonda Chaytor;Ke Wang;Patricia Brantingham
#t 2009
#c 18
#! Recent work [12] shows that conventional privacy preserving publishing techniques based on anonymity-groups are susceptible to corruption attacks. In a corruption attack, if the sensitive information of any anonymity-group member is uncovered, then the remaining group members are at risk. In this study, we abandon anonymity-groups and hide sensitive information through perturbation on the sensitive attribute. With each record being perturbed independently, corruption attacks cannot be effectively carried out. Previous anti-corruption work did not minimize information loss. This paper proposes to address this issue by allowing fine-grain privacy specification. We demonstrate the power of our approach through experiments on real medical and synthetic datasets.

#index 1318585
#* Accelerated Gradient Method for Multi-task Sparse Learning Problem
#@ Xi Chen;Weike Pan;James T. Kwok;Jaime G. Carbonell
#t 2009
#c 18
#! Many real world learning problems can be recast as multi-task learning problems which utilize correlations among different tasks to obtain better generalization performance than learning each task individually. The feature selection problem in multi-task setting has many applications in fields of computer vision, text classification and bio-informatics. Generally, it can be realized by solving a L-1-infinity regularized optimization problem. And the solution automatically yields the joint sparsity among different tasks. However, due to the nonsmooth nature of the L-1-infinity norm, there lacks an efficient training algorithm for solving such problem with general convex loss functions. In this paper, we propose an accelerated gradient method based on an ``optimal'' first order black-box method named after Nesterov and provide the convergence rate for smooth convex loss functions. For nonsmooth convex loss functions, such as hinge loss, our method still has fast convergence rate empirically. Moreover, by exploiting the structure of the L-1-infinity ball, we solve the black-box oracle in Nesterov's method by a simple sorting scheme. Our method is suitable for large-scale multi-task learning problem since it only utilizes the first order information and is very easy to implement. Experimental results show that our method significantly outperforms the most state-of-the-art methods in both convergence speed and learning accuracy.

#index 1318586
#* CoFKM: A Centralized Method for Multiple-View Clustering
#@ Guillaume Cleuziou;Matthieu Exbrayat;Lionel Martin;Jacques-Henri Sublemontier
#t 2009
#c 18
#! This paper deals with clustering for multi-view data, i.e. objects described by several sets of variables or proximity matrices. Many important domains or applications such as Information Retrieval, biology, chemistry and marketing are concerned by this problematic. The aim of this data mining research field is to search for clustering patterns that perform a consensus between the patterns from different views. This requires to merge information from each view by performing a fusion process that identifies the agreement between the views and solves the conflicts. Various fusion strategies can be applied, occurring either before, after or during the clustering process. We draw our inspiration from the existing algorithms based on a centralized strategy. We propose a fuzzy clustering approach that generalizes the three fusion strategies and outperforms the main existing multi-view clustering algorithm both on synthetic and real datasets.

#index 1318587
#* Active Selection of Sensor Sites in Remote Sensing Applications
#@ Debasish Das;Zoran Obradovic;Slobodan Vucetic
#t 2009
#c 18
#! In a data-mining approach, a model for estimation of Aerosol Optical Depth (AOD) from satellite observations is learned using collocated satellite and ground-based observations. For accurate learning of such a spatio-temporal model, it is important to collect ground-based data from a large number of sites. The objective of this project is to determine appropriate locations for the next set of ground-based data collection sites to maximize accuracy of AOD estimation. Ideally, a new site should capture the most significant unseen aerosol patterns and should be the least correlated with the previously observed patterns. We propose achieving this aim by selecting the locations on which the existing prediction model is the most uncertain. Several criteria were considered for site selection, including uncertainty, spatial diversity, similarity in temporal pattern, and their combination. Extensive experiments on globally distributed data over 90 AERONET sites from the years 2005 and 2006 provide strong evidence that sites selected using the proposed algorithms improve the overall AOD prediction accuracy at a faster rate than those selected randomly or based on spatial diversity among sites.

#index 1318588
#* Large Scale Relation Acquisition Using Class Dependent Patterns
#@ Stijn De Saeger;Kentaro Torisawa;Jun'ichi Kazama;Kow Kuroda;Masaki Murata
#t 2009
#c 18
#! This paper proposes a minimally supervised method for acquiring high-level semantic relations such as causality and prevention from the Web. Our method learns linguistic patterns that express causality such as “x gave rise to y”, and uses them to extract causal noun pairs like (global warming, malaria epidemic) from sentences like “global warming gave rise to a new malaria epidemic”. The novelty of our method lies in the use of semantic word classes acquired by large scale clustering for learning class dependent patterns. We demonstrate the effectiveness of this class based approach on three large-scale relation mining tasks from 50 million Japanese Web pages. In two of these tasks we obtained more than 30,000 relation instances with over 80% precision, outperforming a state-of-the-art system by a large margin.

#index 1318589
#* ICDM 2009 Program
#@ 
#t 2009
#c 18

#index 1318590
#* Explore/Exploit Schemes for Web Content Optimization
#@ Deepak Agarwal;Bee-Chung Chen;Pradheep Elango
#t 2009
#c 18
#! We propose novel multi-armed bandit (explore/exploit) schemes to maximize total clicks on a content module published regularly on Yahoo! Intuitively, one can ``explore'' each candidate item by displaying it to a small fraction of user visits to estimate the item's click-through rate (CTR), and then ``exploit'' high CTR items in order to maximize clicks. While bandit methods that seek to find the optimal trade-off between explore and exploit have been studied for decades, existing solutions are not satisfactory for web content publishing applications where dynamic set of items with short lifetimes, delayed feedback and non-stationary reward (CTR) distributions are typical. In this paper, we develop a Bayesian solution and extend several existing schemes to our setting. Through extensive evaluation with nine bandit schemes, we show that our Bayesian solution is uniformly better in several scenarios. We also study the empirical characteristics of our schemes and provide useful insights on the strengths and weaknesses of each. Finally, we validate our results with a ``side-by-side'' comparison of schemes through live experiments conducted on a random sample of real user visits to Yahoo!

#index 1318591
#* Connecting Sparsely Distributed Similar Bloggers
#@ Nitin Agarwal;Huan Liu;Shankara Subramanya;John J. Salerno;Philip S. Yu
#t 2009
#c 18
#! The nature of the Blogosphere determines that the majority of bloggers are only connected with a small number of fellow bloggers, and similar bloggers can be largely disconnected from each other. Aggregating them allows for cost-effective personalized services, targeted marketing, and exploration of new business opportunities. As most bloggers have only a small number of adjacent bloggers, the problem of aggregating similar bloggers presents challenges that demand novel algorithms of connecting the non-adjacent due to the fragmented distributions of bloggers. In this work, we define the problem, delineate its challenges, and present an approach that uses innovative ways to employ contextual information and collective wisdom to aggregate similar bloggers. A real-world blog directory is used for experiments. We demonstrate the efficacy of our approach, report findings, and discuss related issues and future work.

#index 1318592
#* Rule Ensembles for Multi-target Regression
#@ Timo Aho;Bernard enko;Sao Deroski
#t 2009
#c 18
#! Methods for learning decision rules are being successfully applied to many problem domains, especially where understanding and interpretation of the learned model is necessary. In many real life problems, we would like to predict multiple related (nominal or numeric) target attributes simultaneously. Methods for learning rules that predict multiple targets at once already exist, but are unfortunately based on the covering algorithm, which is not very well suited for regression problems. A better solution for regression problems may be a rule ensemble approach that transcribes an ensemble of decision trees into a large collection of rules. An optimization procedure is then used for selecting the best (and much smaller) subset of these rules, and to determine their weights. Using the rule ensembles approach we have developed a new system for learning rule ensembles for multi-target regression problems. The newly developed method was extensively evaluated and the results show that the accuracy of multi-target regression rule ensembles is better than the accuracy of multi-target regression trees, but somewhat worse than the accuracy of multi-target random forests. The rules are significantly more concise than random forests, and it is also possible to create very small rule sets that are still comparable in accuracy to single regression trees.

#index 1318593
#* A Local Scalable Distributed Expectation Maximization Algorithm for Large Peer-to-Peer Networks
#@ Kanishka Bhaduri;Ashok N. Srivastava
#t 2009
#c 18
#! This paper describes a local and distributed expectation maximization algorithm for learning parameters of Gaussian mixture models (GMM) in large peer-to-peer (P2P) environments. The algorithm can be used for a variety of well-known data mining tasks in distributed environments such as clustering, anomaly detection, target tracking, and density estimation to name a few, necessary for many emerging P2P applications in bioinformatics, webmining and sensor networks. Centralizing all or some of the data to build global models is impractical in such P2P environments because of the large number of data sources, the asynchronous nature of the P2P networks, and dynamic nature of the data/network. The proposed algorithm takes a two-step approach. In the monitoring phase, the algorithm checks if the model ‘quality’ is acceptable by using an efficient local algorithm. This is then used as a feedback loop to sample data from the network and rebuild the GMM when it is outdated. We present thorough experimental results to verify our theoretical claims.

#index 1318594
#* Finding Maximal Fully-Correlated Itemsets in Large Databases
#@ Lian Duan;William Nick Street
#t 2009
#c 18
#! Finding the most interesting correlations among items is essential for problems in many commercial, medical, and scientific domains. Much previous research focuses on finding correlated pairs instead of correlated itemsets in which all items are correlated with each other. When designing gift sets, store shelf arrangements, or website product categories, we are more interested in correlated itemsets than correlated pairs. We solve this problem by finding maximal fully-correlated itemsets (MFCIs), in which all subsets are closely related to all other subsets. Putting the items in an MFCI together can promote sales within this itemset. Though some exsiting methods find high-correlation itemsets, they suffer from both efficiency and effectiveness problems in large datasets. In this paper, we explore high-dimensional correlation in two ways. First, we expand the set of desirable properties for correlation measures and study the advantages and disadvantages of various measures. Second, we propose an MFCI framework to decouple the correlation measure from the need for efficient search. By wrapping the best measure in our MFCI framework, we take advantage of likelihood ratio’s superiority in evaluating itemsets, make use of the properties of MFCI to eliminate itemsets with irrelevant items, and still achieve good computational performance.

#index 1318595
#* Unsupervised Relation Extraction by Massive Clustering
#@ Edgar Gonzàlez;Jordi Turmo
#t 2009
#c 18
#! The goal of Information Extraction is to automatically generate structured pieces of information from the relevant information contained in text documents. Machine Learning techniques have been applied to reduce the cost of Information Extraction system adaptation. However, elements of human supervision strongly bias the learning process. Unsupervised learning approaches can avoid these biases. In this paper, we propose an unsupervised approach to learning for Relation Detection, based on the use of massive clustering ensembles. The results obtained on the ACE Relation Mention Detection task outperform in terms of F1 score by 5 points the state of the art of unsupervised techniques for this evaluation framework, in addition to being simpler and more flexible.

#index 1318596
#* Projective Clustering Ensembles
#@ Francesco Gullo;Carlotta Domeniconi;Andrea Tagarelli
#t 2009
#c 18
#! Recent advances in data clustering concern clustering ensembles and projective clustering methods, each addressing different issues in clustering problems. In this paper, we consider for the first time the projective clustering ensemble (PCE) problem, whose main goal is to derive a proper projective consensus partition from an ensemble of projective clustering solutions. We formalize PCE as an optimization problem which does not rely on any particular clustering ensemble algorithm, and which has the ability to handle hard as well as soft data clustering, and different feature weightings. We provide two formulations for PCE, namely a two-objective and a single-objective problem, in which the object-based and feature-based representations of the ensemble solutions are taken into account differently. Experiments have demonstrated that the proposed methods for PCE show clear improvements in terms of accuracy of the output consensus partition.

#index 1318597
#* Knowledge Discovery from Citation Networks
#@ Zhen Guo;Zhongfei Zhang;Shenghuo Zhu;Yun Chi;Yihong Gong
#t 2009
#c 18
#! Knowledge discovery from scientific articles has received increasing attentions recently since huge repositories are made available by the development of the Internet and digital databases. In a corpus of scientific articles such as a digital library, documents are connected by citations and one document plays two different roles in the corpus: \emph{document itself} and \emph{a citation of other documents}. In the existing topic models, little effort is made to differentiate these two roles. We believe that the topic distributions of these two roles are different and related in a certain way. In this paper we propose a \emph{Bernoulli Process Topic}~(BPT) model which models the corpus at two levels: \emph{document level} and \emph{citation level}. In the BPT model, each document has two different representations in the latent topic space associated with its roles. Moreover, the multi-level hierarchical structure of the citation network is captured by a generative process involving a Bernoulli process. The distribution parameters of the BPT model are estimated by a variational approximation approach. In addition to conducting the experimental evaluations on the document modeling task, we also apply the BPT model to a well known scientific corpus to discover the latent topics. The comparisons against state-of-the-art methods demonstrate a very promising performance.

#index 1318598
#* A Bootstrap Approach to Eigenvalue Correction
#@ Anne Hendrikse;Luuk Spreeuwers;Raymond Veldhuis
#t 2009
#c 18
#! Eigenvalue analysis is an important aspect in many data modeling methods. Unfortunately, the eigenvalues of the sample covariance matrix (sample eigenvalues) are biased estimates of the eigenvalues of the covariance matrix of the data generating process (population eigenvalues). We present a new method based on bootstrapping to reduce the bias in the sample eigenvalues: the eigenvalue estimates are updated in several iterations, where in each iteration synthetic data is generated to determine how to update the population eigenvalue estimates. Comparison of the bootstrap eigenvalue correction with a state of the art correction method by Karoui shows that depending on the type of population eigenvalue distribution, sometimes the Karoui method performs better and sometimes our bootstrap method.

#index 1318599
#* Cross-Guided Clustering: Transfer of Relevant Supervision across Domains for Improved Clustering
#@ Indrajit Bhattacharya;Shantanu Godbole;Sachindra Joshi;Ashish Verma
#t 2009
#c 18
#! Lack of supervision in clustering algorithms often leads to clusters that are not useful or interesting to human reviewers. We investigate if supervision can be automatically transferred to a clustering task in a target domain, by providing a relevant supervised partitioning of a dataset from a different source domain. The target clustering is made more meaningful for the human user by trading off intrinsic clustering goodness on the target dataset for alignment with relevant supervised partitions in the source dataset, wherever possible. We propose a cross-guided clustering algorithm that builds on traditional k-means by aligning the target clusters with source partitions. The alignment process makes use of a cross-domain similarity measure that discovers hidden relationships across domains with potentially different vocabularies. Using multiple real-world datasets, we show that our approach improves clustering accuracy significantly over traditional k-means.

#index 1318600
#* Audio Classification of Bird Species: A Statistical Manifold Approach
#@ Forrest Briggs;Raviv Raich;Xiaoli Z. Fern
#t 2009
#c 18
#! Our goal is to automatically identify which species of bird is present in an audio recording using supervised learning. Devising effective algorithms for bird species classification is a preliminary step toward extracting useful ecological data from recordings collected in the field. We propose a probabilistic model for audio features within a short interval of time, then derive its Bayes risk-minimizing classifier, and show that it is closely approximated by a nearest-neighbor classifier using Kullback-Leibler divergence to compare histograms of features. We note that feature histograms can be viewed as points on a statistical manifold, and KL divergence approximates geodesic distances defined by the Fisher information metric on such manifolds. Motivated by this fact, we propose the use of another approximation to the Fisher information metric, namely the Hellinger metric. The proposed classifiers achieve over 90% accuracy on a data set containing six species of bird, and outperform support vector machines.

#index 1318601
#* Finding Associations and Computing Similarity via Biased Pair Sampling
#@ Andrea Campagna;Rasmus Pagh
#t 2009
#c 18
#! Sampling-based methods have previously been proposed for the problem of finding interesting associations in data, even for low-support items. While these methods do not guarantee precise results, they can be vastly more efficient than approaches that rely on exact counting. However, for many similarity measures no such methods have been known. In this paper we show how a wide variety of measures can be supported by a simple biased sampling method. The method also extends to find high-confidence association rules. We demonstrate theoretically that our method is superior to exact methods when the threshold for "interesting similarity/confidence" is above the average pairwise similarity/confidence, and the average support is not too low. Our method is particularly good when transactions contain many items. We confirm in experiments on standard association mining benchmarks that this gives a significant speedup on real data sets (sometimes much larger than the theoretical guarantees). Reductions in computation time of over an order of magnitude, and significant savings in space, are observed.

#index 1318602
#* Beyond Banditron: A Conservative and Efficient Reduction for Online Multiclass Prediction with Bandit Setting Model
#@ Guangyun Chen;Gang Chen;Jianwen Zhang;Shuo Chen;Changshui Zhang
#t 2009
#c 18
#! In this paper, we consider a recently proposed supervised learning problem, called online multiclass prediction with bandit setting model. Aiming at learning from partial feedback of online classification results, i.e. “true” when the predicting label is right or “false” when the predicting label is wrong, this new kind of problems arouses much of researchers’ interest due to its close relations to real world internet applications and human cognitive procedure. While some algorithms have been brought forward, we propose a novel algorithm to deal with such problems. First, we reduce the multiclass prediction problem to binary based on Conservative one-versus-all others Reduction scheme; Then Online Passive-Aggressive Algorithm is embedded as binary learning algorithm to solve the reduced problem. Also we derive a pleasing cumulative mistake bound for our algorithm and a time complexity bound linear to the sample size. Further experimental evaluation on several real world multiclass datasets including RCV1, MNIST, 20 Newsgroups and USPS shows that our method outperforms the existing algorithms with a great improvement.

#index 1318603
#* Probabilistic Similarity Query on Dimension Incomplete Data
#@ Wei Cheng;Xiaoming Jin;Jian-Tao Sun
#t 2009
#c 18
#! Retrieving similar data has drawn many research efforts in the literature due to its importance in data mining, database and information retrieval. This problem is challenging when the data is incomplete. In previous research, data incompleteness refers to the fact that data values for some dimensions are unknown. However, in many practical applications (e.g., data collection by sensor network under bad environment), not only data values but even data dimension information may also be missing, which will make most similarity query algorithms infeasible. In this work, we propose the novel similarity query problem on dimension incomplete data and adopt a probabilistic framework to model this problem. For this problem, users can give a distance threshold and a probability threshold to specify their retrieval requirements. The distance threshold is used to specify the allowed distance between query and data objects and the probability threshold is used to require that the retrieval results satisfy the distance condition at least with the given probability. Instead of enumerating all possible cases to recover the missed dimensions, we propose an efficient approach to speed up the retrieval process by leveraging the inherent relations between query and dimension incomplete data objects. During the query process, we estimate the lower/upper bounds of the probability that the query is satisfied by a given data object, and utilize these bounds to filter irrelevant data objects efficiently. Furthermore, a probability triangle inequality is proposed to further speed up query processing. According to our experiments on real data sets, the proposed similarity query method is verified to be effective and efficient on dimension incomplete data.

#index 1318604
#* An Effective Approach to Inverse Frequent Set Mining
#@ Antonella Guzzo;Domenico Saccà;Edoardo Serra
#t 2009
#c 18
#! The inverse frequent set mining problem is the problem of computing a database on which a given collection of itemsets must emerge to be frequent. Earlier studies focused on investigating computational and approximability properties of this problem. In this paper, we face it under the pragmatic perspective of defining heuristic solution approaches that are effective and scalable in real scenarios. In particular, a general formulation of the problem is considered where minimum and maximum support constraints can be defined on each itemset, and where no bound is given beforehand on the size of the resulting output database. Within this setting, an algorithm is proposed that always satisfies the maximum support constraints, but which treats minimum support constraints as soft ones that are enforced as long as possible. A thorough experimentation evidences that minimum support constraints are hardly violated in practice, and that such negligible degradation in accuracy (which is unavoidable due to the theoretical intractability of the problem) is compensated by very good scaling performances.

#index 1318605
#* Parallel PathFinder Algorithms for Mining Structures from Graphs
#@ Samson Hauguel;ChengXiang Zhai;Jiawei Han
#t 2009
#c 18
#! PathFinder networks are increasingly used in Data Mining for different purposes, like network visualization or knowledge extraction. This novel way of representing graphical data has been proven to give better results than other link reduction algorithms, like minimum spanning networks However, this increase in quality comes with a high computation cost, typically of the order of n^3 or higher, where n is the number of nodes in the graph. While this problem has previously been tackled by using mathematical properties to speed up the algorithm, in this paper, we propose two new algorithms to speed up PathFinder computation based on parallelization techniques to take advantage of the increasingly available multi-core hardware platform. Experiments show that both new algorithms are more efficient than the state of the art algorithms; one of them can achieve speed-ups of up to x127 with an average of x23 on recent hardware (2007).

#index 1318606
#* Modeling Syntactic Structures of Topics with a Nested HMM-LDA
#@ Jing Jiang
#t 2009
#c 18
#! Latent Dirichlet Allocation (LDA) is a commonly used topic modeling method for text analysis and mining. Standard LDA treats documents as bags of words, ignoring the syntactic structures of sentences. In this paper, we propose a hybrid model that embeds hidden Markov models (HMMs) within LDA topics to jointly model both the topics and the syntactic structures within each topic. Our model is general and subsumes standard LDA and HMM as special cases. Compared with standard LDA and HMM, our model can simultaneously discover both topic-specific content words and background functional words shared among topics. Our model can also automatically separate content words that play different roles within a topic. Using perplexity as evaluation metric, our model returns lower perplexity for unseen test documents compared with standard LDA, which shows its better generalization power than LDA.

#index 1318607
#* Redistricting Using Heuristic-Based Polygonal Clustering
#@ Deepti Joshi;Leen-Kiat Soh;Ashok Samal
#t 2009
#c 18
#! Redistricting is the process of dividing a geographic area into districts or zones. This process has been considered in the past as a problem that is computationally too complex for an automated system to be developed that can produce unbiased plans. In this paper we present a novel method for redistricting a geographic area using a heuristic-based approach for polygonal spatial clustering. While clustering geospatial polygons several complex issues need to be addressed – such as: removing order dependency, clustering all polygons assuming no outliers, and strategically utilizing domain knowledge to guide the clustering process. In order to address these special needs, we have developed the Constrained Polygonal Spatial Clustering (CPSC) algorithm that holistically integrates do-main knowledge in the form of cluster-level and instance-level constraints and uses heuristic functions to grow clusters. In order to illustrate the usefulness of our algorithm we have applied it to the problem of formation of unbiased congressional districts. Furthermore, we compare and contrast our algorithm with two other approaches proposed in the literature for redistricting, namely – graph partitioning and simulated annealing.

#index 1318608
#* A Walk from 2-Norm SVM to 1-Norm SVM
#@ Jussi Kujala;Timo Aho;Tapio Elomaa
#t 2009
#c 18
#! This paper studies how useful the standard 2-norm regularized SVM is in approximating the 1-norm SVM problem. To this end, we examine a general method that is based on iteratively re-weighting the features and solving a 2-norm optimization problem. The convergence rate of this method is unknown. Previous work indicates that it might require an excessive number of iterations. We study how well we can do with just a small number of iterations. In theory the convergence rate is fast, except for coordinates of the current solution that are close to zero. Our empirical experiments confirm this. In many problems with irrelevant features, already one iteration is often enough to produce accuracy as good as or better than that of the 1-norm SVM. Hence, it seems that in these problems we do not need to converge to the 1-norm SVM solution near zero values. The benefit of this approach is that we can build something similar to the 1-norm regularized solver based on any 2-norm regularized solver. This is quick to implement and the solution inherits the good qualities of the solver such as scalability and stability.

#index 1318609
#* VIF Regression: A Fast Regression Algorithm for Large Data
#@ Dongyu Lin;Dean P. Foster
#t 2009
#c 18
#! We propose a fast regression algorithm that can substantially reduce the computational complexity of searching, yet retain good accuracy. It also guarantees to discover correlated features that are collectively predictive, and avoid model over-fitting. Its capability of controlling mFDR (marginal False Discovery Rate) statistically enables the one-pass search of the fast algorithm and guarantees the accuracy of the sparse model chosen by the algorithm without cross validation. Numerical results show that our algorithm is much faster than any other algorithm and is competitively as accurate as the best but slower algorithms.

#index 1318610
#* flowNet: Flow-Based Approach for Efficient Analysis of Complex Biological Networks
#@ Young-Rae Cho;Lei Shi;Aidong Zhang
#t 2009
#c 18
#! Biological networks having complex connectivity have been widely studied recently. By characterizing their inherent and structural behaviors in a topological perspective, these studies have attempted to discover hidden knowledge in the systems. However, even though various algorithms with graph-theoretical modeling have provided fundamentals in the network analysis, the availability of practical approaches to efficiently handle the complexity has been limited. In this paper, we present a novel flow-based approach, called flowNet, to efficiently analyze large-sized, complex networks. Our approach is based on the functional influence model that quantifies the influence of a biological component on another. We introduce a dynamic flow simulation algorithm to generate a flow pattern which is a unique characteristic for each component. The set of patterns can be used in identifying functional modules (i.e., clustering). The proposed flow simulation algorithm runs very efficiently in sparse networks. Since our approach uses a weighted network as an input, we also discuss supervised and unsupervised weighting schemes for unweighted biological networks. As experimental results in real applications to the yeast protein interaction network, we demonstrate that our approach outperforms previous graph clustering methods with respect to accuracy.

#index 1318611
#* ?-Anomica: A Fast Support Vector Based Novelty Detection Technique
#@ Santanu Das;Kanishka Bhaduri;Nikunj C. Oza;Ashok N. Srivastava
#t 2009
#c 18
#! In this paper we propose ν-Anomica, a novel anomaly detection technique that can be trained on huge data sets with much reduced running time compared to the benchmark one-class Support Vector Machines algorithm. In ν-Anomica, the idea is to train the machine such that it can provide a close approximation to the exact decision plane using fewer training points and without losing much of the generalization performance of the classical approach. We have tested the proposed algorithm on a variety of continuous data sets under different conditions. We show that under all test conditions the developed procedure closely preserves the accuracy of standard one- class Support Vector Machines while reducing both the training time and the test time by 5 − 20 times.

#index 1318612
#* Temporal Neighborhood Discovery Using Markov Models
#@ Sandipan Dey;Vandana P. Janeja;Aryya Gangopadhyay
#t 2009
#c 18
#! Temporal data, which is a sequence of data tuples measured at successive time instances, is typically very large. Hence instead of mining the entire data, we are interested in dividing the huge data into several smaller intervals of interest which we call temporal neighborhoods. In this paper we propose an approach to generate temporal neighborhoods through unequal depth discretization. We describe two novel algorithms (a) Similarity based Merging (SMerg) and, (b) Stationary distribution based Merging (StMerg). These algorithms are based on the robust framework of Markov models and the Markov Stationary distribution respectively. We identify temporal neighborhoods with distinct demarcations based on unequal depth discretization of the data. We discuss detailed experimental results in both synthetic and real world data. Specifically we show (i) the efficacy of our approach through precision and recall of labeled bins, (ii) the ground truth validation in real world datasets and, (iii) knowledge discovery in the temporal neighborhoods such as global anomalies. Our results indicate that we are able to identify valuable knowledge based on our ground truth validation from real world traffic data.

#index 1318613
#* Active Learning with Generalized Queries
#@ Jun Du;Charles X. Ling
#t 2009
#c 18
#! Active learning can actively select or construct examples to label to reduce the number of labeled examples needed for building accurate classifiers. However, previous works of active learning can only ask specific queries. For example, to predict osteoarthritis from a patient dataset with 30 attributes, specific queries always contain values of all these 30 attributes, many of which may be irrelevant. A more natural way is to ask "generalized queries" with don't-care attributes, such as "are people over 50 with knee pain likely to have osteoarthritis?" (with only two attributes: age and type of pain). We assume that the oracle (and human experts) can readily answer those generalized queries by returning probabilistic labels. The power of such generalized queries is that one generalized query may be equivalent to many specific ones. However, overly general queries may receive highly uncertain labels from the oracle, and this makes learning difficult. In this paper, we propose a novel active learning algorithm that asks generalized queries. We demonstrate experimentally that our new method asks significantly fewer queries compared with the previous works of active learning. Our method can be readily deployed in real-world tasks where obtaining labeled examples is costly.

#index 1318614
#* Conditional Models for Non-smooth Ranking Loss Functions
#@ Avinava Dubey;Jinesh Machchhar;Chiranjib Bhattacharyya;Soumen Chakrabarti
#t 2009
#c 18
#! Learning to rank is an important area at the interface of machine learning, information retrieval and Web search. The central challenge in optimizing various measures of ranking loss is that the objectives tend to be non-convex and discontinuous. To make such functions amenable to gradient based optimization procedures one needs to design clever bounds. In recent years, boosting, neural networks, support vector machines, and many other techniques have been applied. However, there is little work on directly modeling a conditional probability Pr(y|x_q) where y is a permutation of the documents to be ranked and x_q represents their feature vectors with respect to a query q. A major reason is that the space of y is huge: n! if n documents must be ranked. We first propose an intuitive and appealing expected loss minimization objective, and give an efficient shortcut to evaluate it despite the huge space of ys. Unfortunately, the optimization is non-convex, so we propose a convex approximation. We give a new, efficient Monte Carlo sampling method to compute the objective and gradient of this approximation, which can then be used in a quasi-Newton optimizer like LBFGS. Extensive experiments with the widely-used LETOR dataset show large ranking accuracy improvements beyond recent and competitive algorithms.

#index 1318615
#* Semi-supervised Density-Based Clustering
#@ Levi Lelis;Jörg Sander
#t 2009
#c 18
#! Most of the effort in the semi-supervised clustering literature was devoted to variations of the K-means algorithm. In this paper we show how background knowledge can be used to bias a partitional density-based clustering algorithm. Our work describes how labeled objects can be used to help the algorithm detecting suitable density parameters for the algorithm to extract density-based clusters in specific parts of the feature space. Considering the set of constraints estabilished by the labeled dataset we show that our algorithm, called SSDBSCAN, automatically finds density parameters for each natural cluster in a dataset. Four of the most interesting characteristics of SSDBSCAN are that (1) it only requires a single, robust input parameter, (2) it does not need any user intervention, (3) it automaticaly finds the noise objects according to the density of the natural clusters and (4) it is able to find the natural cluster structure even when the density among clusters vary widely. The algorithm presented in this paper is evaluated with artificial and real-world datasets, demonstrating better results when compared to other unsupervised and semi-supervised density-based approaches.

#index 1318616
#* Sparse Norm-Regularized Reconstructive Coefficients Learning
#@ Bin Liu;Shuo Chen;Mingjie Qian;Changshui Zhang
#t 2009
#c 18
#! Inspired by the fact that the final decision rule is mainly affected by a small subset of the training samples, i.e., Support Vector Machine(SVM) shows that the decision function relies on the few samples that are on or over the margin. We propose a new framework that explicitly strengthen this intuitive fact by adding an $l_1$-norm regularizer. We give different formulations for our framework in different scenarios, and the experiments show that our framework can not only lead to high sparse solutions but also better performance than traditional methods.

#index 1318617
#* A Contrast Pattern Based Clustering Quality Index for Categorical Data
#@ Qingbao Liu;Guozhu Dong
#t 2009
#c 18
#! Since clustering is unsupervised and highly explorative, clustering validation (i.e. assessing the quality of clustering solutions) has been an important and long standing research problem. Existing validity measures have significant shortcomings. This paper proposes a novel Contrast Pattern based Clustering Quality index (CPCQ) for categorical data, by utilizing the quality and diversity of the contrast patterns (CPs) which contrast the clusters in clusterings. High quality CPs can characterize clusters and discriminate them against each other. Experiments show that the CPCQ index (1) can recognize that expert-determined classes are the best clusters for many datasets from the UCI repository; (2) does not give inappropriate preference to larger number of clusters; (3) does not require a user to provide a distance function.

#index 1318618
#* Multi-document Summarization by Information Distance
#@ Chong Long;Minlie Huang;Xiaoyan Zhu;Ming Li
#t 2009
#c 18
#! Fast changing knowledge on the Internet can be acquired more efficiently with the help of automatic document summarization and updating techniques. This paper described a novel approach for multi-document update summarization. The best summary is defined to be the one which has the minimum information distance to the entire document set. The best update summary has the minimum conditional information distance to a document cluster given that a prior document cluster has already been read. Experiments on the DUC 2007 dataset and the TAC 2008 dataset have proved that our method closely correlates with the human summaries and outperforms other programs such as LexRank in many categories under the ROUGE evaluation criterion.

#index 1318619
#* On the (In)Security and (Im)Practicality of Outsourcing Precise Association Rule Mining
#@ Ian Molloy;Ninghui Li;Tiancheng Li
#t 2009
#c 18
#! The recent interest in outsourcing IT services onto the cloud raises two main concerns: security and cost. One task that could be outsourced is data mining. In VLDB 2007, Wong et al. propose an approach for outsourcing association rule mining. Their approach maps a set of real items into a set of pseudo items, then maps each transaction non-deterministically. This paper, analyzes both the security and costs associated with outsourcing association rule mining. We show how to break the encoding scheme from Wong et al. without using context specific information and reduce the security to a one-to-one mapping. We present a stricter notion of security than used by Wong et al., and then consider the practicality of outsourcing association rule mining. Our results indicate that outsourcing association rule mining may not be practical, if the data owner is concerned with data confidentiality.

#index 1318620
#* Promoting Total Efficiency in Text Clustering via Iterative and Interactive Metric Learning
#@ Michinari Momma;Satoshi Morinaga;Daisuke Komura
#t 2009
#c 18
#! In this paper, we propose a framework to make the text clustering process, as a whole, efficient. In a real text clustering task, an analyst usually has some expectation on the results in mind. However, a single run of a clustering algorithm on the preprocessed data would not satisfy the expectation. Then the analyst faces labor-intensive trials for improving the results that involve repetitive feature refinement and parameter tuning. We develop the Iterative and Interactive Metric Learning System (IIMLS) for addressing the challenge. Specifically, IIMLS allows analysts to input feedback on a current clustering result. Given the feedback, IIMLS optimizes metric in the feature space so that the clustering algorithm applied with the refined metric would reflect the feedback. As a byproduct, learned metric may be used for a similar dataset. Illustrative examples on a real-world dataset show IIMLS can dramatically improve efficiency of a text clustering task. The learned “knowledge”, or the metric, is visualized for gaining insights of the optimized feature metric.

#index 1318621
#* Unsupervised Class Separation of Multivariate Data through Cumulative Variance-Based Ranking
#@ Andrew Foss;Osmar R. Zaïane;Sandra Zilles
#t 2009
#c 18
#! This paper introduces a new extension of outlier detection approaches and a new concept, class separation through variance. We show that accumulating information about the outlierness of points in multiple subspaces leads to a ranking in which classes with differing variance naturally tend to separate. Exploiting this leads to a highly effective and efficient unsupervised class separation approach, especially useful in the difficult case of heavily overlapping distributions. Unlike typical outlier detection algorithms, this method can be applied beyond the `rare classes' case with great success. Two novel algorithms that implement this approach are provided. Additionally, experiments show that the novel methods typically outperform other state-of-the-art outlier detection methods on high dimensional data such as Feature Bagging, SOE1, LOF, ORCA and Robust Mahalanobis Distance and competes even with the leading supervised classification methods.

#index 1318622
#* Execution Anomaly Detection in Distributed Systems through Unstructured Log Analysis
#@ Qiang Fu;Jian-Guang Lou;Yi Wang;Jiang Li
#t 2009
#c 18
#! Detection of execution anomalies is very important for the maintenance, development, and performance refinement of large scale distributed systems. Execution anomalies include both work flow errors and low performance problems. People often use system logs produced by distributed systems for troubleshooting and problem diagnosis. However, manually inspecting system logs to detect anomalies is unfeasible due to the increasing scale and complexity of distributed systems. Therefore, there is a great demand for automatic anomalies detection techniques based on log analysis. In this paper, we propose an unstructured log analysis technique for anomalies detection. In the technique, we propose a novel algorithm to convert free form text messages in log files to log keys without heavily relying on application specific knowledge. The log keys correspond to the log-print statements in the source code which can provide cues of system execution behavior. After converting log messages to log keys, we learn a Finite State Automaton (FSA) from training log sequences to present the normal work flow for each system component. At the same time, a performance measurement model is learned to characterize the normal execution performance based on the log mes-sages’ timing information. With these learned models, we can automatically detect anomalies in newly input log files. Experiments on Hadoop and SILK show that the technique can effectively detect running anomalies.

#index 1318623
#* Learning the Shared Subspace for Multi-task Clustering and Transductive Transfer Classification
#@ Quanquan Gu;Jie Zhou
#t 2009
#c 18
#! There are many clustering tasks which are closely related in the real world, e.g. clustering the web pages of different universities. However, existing clustering approaches neglect the underlying relation and treat these clustering tasks either individually or simply together. In this paper, we will study a novel clustering paradigm, namely multi-task clustering, which performs multiple related clustering tasks together and utilizes the relation of these tasks to enhance the clustering performance. We aim to learn a subspace shared by all the tasks, through which the knowledge of the tasks can be transferred to each other. The objective of our approach consists of two parts: (1) Within-task clustering: clustering the data of each task in its input space individually; and (2) Cross-task clustering: simultaneous learning the shared subspace and clustering the data of all the tasks together. We will show that it can be solved by alternating minimization, and its convergence is theoretically guaranteed. Furthermore, we will show that given the labels of one task, our multi-task clustering method can be extended to transductive transfer classification (a.k.a. cross-domain classification, domain adaption). Experiments on several cross-domain text data sets demonstrate that the proposed multi-task clustering outperforms traditional single-task clustering methods greatly. And the transductive transfer classification method is comparable to or even better than several existing transductive transfer classification approaches.

#index 1318624
#* Accurate Estimation of the Degree Distribution of Private Networks
#@ Michael Hay;Chao Li;Gerome Miklau;David Jensen
#t 2009
#c 18
#! We describe an efficient algorithm for releasing a provably private estimate of the degree distribution of a network. The algorithm satisfies a rigorous property of differential privacy, and is also extremely efficient, running on networks of 100 million nodes in a few seconds. Theoretical analysis shows that the error scales linearly with the number of unique degrees, whereas the error of conventional techniques scales linearly with the number of nodes. We complement the theoretical analysis with a thorough empirical analysis on real and synthetic graphs, showing that the algorithm's variance and bias is low, that the error diminishes as the size of the input graph increases, and that common analyses like fitting a power-law can be carried out very accurately.

#index 1318625
#* A Linear-Time Graph Kernel
#@ Shohei Hido;Hisashi Kashima
#t 2009
#c 18
#! The design of a good kernel is fundamental for knowledge discovery from graph-structured data. Existing graph kernels exploit only limited information about the graph structures but are still computationally expensive. We propose a novel graph kernel based on the structural characteristics of graphs. The key is to represent node labels as binary arrays and characterize each node using logical operations on the label set of the connected nodes. Our kernel has a linear time complexity with respect to the number of nodes times the average number of neighboring nodes in the given graphs. The experimental result shows that the proposed kernel performs comparable and much faster than a state-of-the-art graph kernel for benchmark data sets and shows high scalability for new applications with large graphs.

#index 1318626
#* A New Clustering Algorithm Based on Regions of Influence with Self-Detection of the Best Number of Clusters
#@ Fabrice Muhlenbach;Stéphane Lallich
#t 2009
#c 18
#! Clustering methods usually require to know the best number of clusters, or another parameter, e.g. a threshold, which is not ever easy to provide. This paper proposes a new graph-based clustering method called GBC which detects automatically the best number of clusters, without requiring any other parameter. In this method based on regions of influence, a graph is constructed and the edges of the graph having the higher values are cut according to a hierarchical divisive procedure. An index is calculated from the size average of the cut edges which self-detects the more appropriate number of clusters. The results of GBC for 3 quality indices (Dunn, Silhouette and Davies-Bouldin) are compared with those of K-Means, Ward's hierarchical clustering method and DBSCAN on 8 benchmarks. The experiments show the good performance of GBC in the case of well separated clusters, even if the data are unbalanced, non-convex or with presence of outliers, whatever the shape of the clusters.

#index 1318627
#* Automatically Extracting Dialog Models from Conversation Transcripts
#@ Sumit Negi;Sachindra Joshi;Anup K. Chalamalla;L. Venkata Subramaniam
#t 2009
#c 18
#! There is a growing need for task-oriented natural language dialog systems that can interact with a user to accomplish a given objective. Recent work on building task-oriented dialog systems have emphasized the need for acquiring task-specific knowledge from un-annotated conversational data. In our work we acquire task-specific knowledge by defining \textit{sub-task} as the key unit of a task-oriented conversation. We propose an unsupervised, apriori like algorithm that extracts the sub-tasks and their valid orderings from un-annotated human-human conversations. Modeling dialogues as a combination of sub-tasks and their valid orderings easily captures the variability in conversations. It also provides us the ability to map our dialogue model to AIML constructs and therefore use off-the-shelf AIML interpreters to build task-oriented chat-bots. We conduct experiments on real world data sets to establish the effectiveness of the sub-task extraction process. We codify the extracted sub-tasks in an AIML knowledge base and build a chatbot using this knowledge base. We also show the usefulness of the chatbot in automatically handling customer requests by performing a user evaluation study.

#index 1318628
#* To Trust or Not to Trust? Predicting Online Trusts Using Trust Antecedent Framework
#@ Viet-An Nguyen;Ee-Peng Lim;Jing Jiang;Aixin Sun
#t 2009
#c 18
#! This paper analyzes the trustor and trustee factors that lead to inter-personal trust using a well studied Trust Antecedent framework in management science \cite{mayer}. To apply these factors to trust ranking problem in online rating systems, we derive features that correspond to each factor and develop different trust ranking models. The advantage of this approach is that features relevant to trust can be systematically derived so as to achieve good prediction accuracy. Through a series of experiments on real data from Epinions, we show that even a simple model using the derived features yields good accuracy and outperforms MoleTrust, a trust propagation based model. SVM classifiers using these features also show improvements.

#index 1318629
#* Analysis of Subsequence Time-Series Clustering Based on Moving Average
#@ Miho Ohsaki;Masakazu Nakase;Shigeru Katagiri
#t 2009
#c 18
#! Subsequence time-series clustering (STSC), which consists of subsequence cutout with a sliding window and k-means clustering, had been commonly used in time-series data mining. However, a problem was pointed out that STSC always generates moderate sinusoidal patterns independently of the input. To address this problem, we theoretically explain and empirically confirm the similarity between STSC and moving average. The present analysis is consistent with, and simpler than, one of the most important analyses of STSC. We also question the pattern extraction in the time domain and discuss another solution.

#index 1318630
#* Permutation Tests for Studying Classifier Performance
#@ Markus Ojala;Gemma C. Garriga
#t 2009
#c 18
#! We explore the framework of permutation-based p-values for assessing the behavior of the classification error. In this paper we study two simple permutation tests. The first test estimates the null distribution by permuting the labels in the data; this has been used extensively in classification problems in computational biology. The second test produces permutations of the features within classes, inspired by restricted randomization techniques traditionally used in statistics. We study the properties of these tests and present an extensive empirical evaluation on real and synthetic data. Our analysis shows that studying the classification error via permutation tests is effective; in particular, the restricted permutation test clearly reveals whether the classifier exploits the interdependency between the features in the data.

#index 1318631
#* Interaction-Based Clustering of Multivariate Time Series
#@ Claudia Plant;Afra M. Wohlschläger;Andrew Zherdin
#t 2009
#c 18
#! In this paper, we present a novel approach to clustering multivariate time series. In contrast to previous approaches, we base our cluster notion on the interactions between the univariate time series within a data object. Our objective is to assign objects with a similar intrinsic interaction pattern to a common cluster. To formalize this idea, we define a cluster by a set of mathematical models describing the cluster-specific interaction pattern. In addition, we propose interaction K-means (IKM), an efficient algorithm for partitioning clustering of multivariate time series. The cluster-specific interaction patterns detected by IKM provide valuable information for interpretation of the cluster content. An extensive experimental evaluation on synthetic and real world data demonstrates the effectiveness and efficiency of our approach.

#index 1318632
#* GSML: A Unified Framework for Sparse Metric Learning
#@ Kaizhu Huang;Yiming Ying;Colin Campbell
#t 2009
#c 18
#! There has been significant recent interest in sparse metric learning (SML) in which we simultaneously learn both a good distance metric and a low-dimensional representation. Unfortunately, the performance of existing sparse metric learning approaches is usually limited because the authors assumed certain problem relaxations or they target the SML objective indirectly. In this paper, we propose a Generalized Sparse Metric Learning method (GSML). This novel framework offers a unified view for understanding many of the popular sparse metric learning algorithms including the Sparse Metric Learning framework proposed, the Large Margin Nearest Neighbor (LMNN), and the D-ranking Vector Machine (D-ranking VM). Moreover, GSML also establishes a close relationship with the Pairwise Support Vector Machine. Furthermore, the proposed framework is capable of extending many current non-sparse metric learning models such as Relevant Vector Machine (RCA) and a state-of-the-art method proposed into their sparse versions. We present the detailed framework, provide theoretical justifications, build various connections with other models, and propose a practical iterative optimization method, making the framework both theoretically important and practically scalable for medium or large datasets. A series of experiments show that the proposed approach can outperform previous methods in terms of both test accuracy and dimension reduction, on six real-world benchmark datasets.

#index 1318633
#* GRAPE: A Graph-Based Framework for Disambiguating People Appearances in Web Search
#@ Lili Jiang;Jianyong Wang;Ning An;Shengyuan Wang;Jian Zhan;Lian Li
#t 2009
#c 18
#! Finding information about people using search engines is one of the most common activities on the Web. However, search engines usually return a long list of Web pages, which may be relevant to many namesakes, especially given the explosive growth of Web data. To address the challenge caused by name ambiguity in Web people search, this paper proposes a novel graph-based framework, GRAPE (abbr. a Graph-based fRamework for disAmbiguating People appEarances in Web search). In GRAPE, people tag information (e.g., people name, organization, and email address) surrounding the queried people name is extracted from the search results, a graph-based unsupervised algorithm is then developed to cluster the extracted tags, where a new method, Cohesion, is introduced to measure the importance of a tag for clustering, and each final cluster of tags represents a unique people entity. Experimental results show that our proposed framework outperforms the state-of-the-art Web people name disambiguation approaches.

#index 1318634
#* A Tree-Based Framework for Difference Summarization
#@ Ruoming Jin;Yuri Breitbart;Rong Li
#t 2009
#c 18
#! Understanding the differences between two datasets is a fundamental data mining question and is also ubiquitously important across many real world scientific applications. In this paper, we propose a tree-based framework to provide a parsimonious explanation of the difference between two distributions based on rigorous two-sample statistical test. We develop two efficient approaches. The first one is a dynamic programming approach that finds a minimal number of data subsets that describe the difference between two data sets. The second one is a greedy approach that approximates the dynamic programming approach. We employ the well-known Friedman's MST (minimal spanning tree) statistics for two-sample statistical tests in our summarization tree construction, and develop novel techniques to speedup its computational procedure. We performed a detailed experimental evaluation on both real and synthetic datasets and demonstrated the effectiveness of our tree-summarization approach.

#index 1318635
#* TrBagg: A Simple Transfer Learning Method and its Application to Personalization in Collaborative Tagging
#@ Toshihiro Kamishima;Masahiro Hamasaki;Shotaro Akaho
#t 2009
#c 18
#! The aim of transfer learning is to improve prediction accuracy on a target task by exploiting the training examples for tasks that are related to the target one. Transfer learning has received more attention in recent years, because this technique is considered to be helpful in reducing the cost of labeling. In this paper, we propose a very simple approach to transfer learning: TrBagg, which is the extension of bagging. TrBagg is composed of two stages: Many weak classifiers are first generated as in standard bagging, and these classifiers are then filtered based on their usefulness for the target task. This simplicity makes it easy to work reasonably well without severe tuning of learning parameters. Further, our algorithm equips an algorithmic scheme to avoid negative transfer. We applied TrBagg to personalized tag prediction tasks for social bookmarks Our approach has several convenient characteristics for this task such as adaptation to multiple tasks with low computational cost.

#index 1318636
#* PEGASUS: A Peta-Scale Graph Mining System Implementation and Observations
#@ U. Kang;Charalampos E. Tsourakakis;Christos Faloutsos
#t 2009
#c 18
#! In this paper, we describe PEGASUS, an open source Peta Graph Mining library which performs typical graph mining tasks such as computing the diameter of the graph, computing the radius of each node and finding the connected components. As the size of graphs reaches several Giga-, Tera- or Peta-bytes, the necessity for such a library grows too. To the best of our knowledge, PEGASUS is the first such library, implemented on the top of the Hadoop platform, the open source version of MapReduce. Many graph mining operations (PageRank, spectral clustering, diameter estimation, connected components etc.) are essentially a repeated matrix-vector multiplication. In this paper we describe a very important primitive for PEGASUS, called GIM-V (Generalized Iterated Matrix-Vector multiplication). GIM-V is highly optimized, achieving (a) good scale-up on the number of available machines (b) linear running time on the number of edges, and (c) more than 5 times faster performance over the non-optimized version of GIM-V. Our experiments ran on M45, one of the top 50 supercomputers in the world. We report our findings on several real graphs, including one of the largest publicly available Web Graphs, thanks to Yahoo!, with 6,7 billion edges.

#index 1318637
#* PUB: A Class Description Technique Based on Partial Coverage of Subspace
#@ Ardian Kristanto Poernomo;Vivekanand Gopalkrishnan
#t 2009
#c 18
#! A good description of a class should be accurate and interpretable. Previous works describe classes either by analyzing the correlation of each attribute with the class, or by producing rules as in building a classifier. These solutions suffer from issues in accuracy and interpretability. A description naturally consists of sentences, where each sentence consists of a set of terms. Normally, a sentence is defined as a disjunction or conjunction of several terms, each of which specifies a constraint (range/set of values) on an attribute. From the data analysis point of view, a sentence specifies a subspace in the database. In this paper, we create a richer yet interpretable form of a sentence, i.e., a sentence describes an object if any $k$ attributes of that object satisfy the specified constraints. To that end, we design \textsc{Pub}, an algorithm that produces descriptions with our form of sentences. While constructing a sentence (within the description), \textsc{Pub} finds the optimal range/set of values for each attribute in linear time. We also empirically show that \textsc{Pub} is efficient, and able to produce more accurate, concise and interpretable descriptions than current approaches on various real datasets.

#index 1318638
#* Online and Batch Learning of Generalized Cosine Similarities
#@ Ali Mustafa Qamar;Eric Gaussier
#t 2009
#c 18
#! In this paper, we define an online algorithm to learn the generalized cosine similarity measures for kNN classification and hence a similarity matrix A corresponding to a bilinear form. In contrary to the standard cosine measure, the normalization is itself dependent on the similarity matrix which makes it impossible to use directly the algorithms developed for learning Mahanalobis distances, based on positive, semi-definite (PSD) matrices. We follow the approach where we first find an appropriate matrix and then project it onto the cone of PSD matrices, which we have adapted to the particular form of generalized cosine similarities, and more particularly to the fact that such measures are normalized. The resulting online algorithm as well as its batch version is fast and has got better accuracy as compared with state-of-the-art methods on standard data sets.

#index 1318639
#* Discovering Organizational Structure in Dynamic Social Network
#@ Jiangtao Qiu;Zhangxi Lin;Changjie Tang;Shaojie Qiao
#t 2009
#c 18
#! Applying the concept of organizational structure to social network analysis may well represent the power of members and the scope of their power in a social network. In this paper, we propose a data structure, called Community Tree, to represent the organizational structure in the social network. We combine the PageRank algorithm and random walks on graph to derive the community tree from the social network. In the real world, a social network is constantly changing. Hence, the organizational structure in the social network is also constantly changing. In order to present the organizational structure in a dynamic social network, we propose a tree learning algorithm to derive an evolving community tree. The evolving community tree enables a smooth transition between the two community trees and well represents the evolution of organizational structure in the dynamic social network. Experiments conducted on real data show our methods are effective at discovering the organizational structure and representing the evolution of organizational structure in a dynamic social network.

#index 1318640
#* Kernel Conditional Quantile Estimation via Reduction Revisited
#@ Novi Quadrianto;Kristian Kersting;Mark D. Reid;Tibério S. Caetano;Wray L. Buntine
#t 2009
#c 18
#! Quantile regression refers to the process of estimating the quantiles of a conditional distribution and has many important applications within econometrics and data mining, among other domains. In this paper, we show how to estimate these conditional quantile functions within a Bayes risk minimization framework using a Gaussian process prior. The resulting non-parametric probabilistic model is easy to implement and allows non-crossing quantile functions to be enforced. Moreover, it can directly be used in combination with tools and extensions of standard Gaussian Processes such as principled hyperparameter estimation, sparsification, and quantile regression with input-dependent noise rates. No existing approach enjoys all of these desirable properties. Experiments on benchmark datasets show that our method is competitive with state-of-the-art approaches."

#index 1318641
#* Naive Bayes Classification of Uncertain Data
#@ Jiangtao Ren;Sau Dan Lee;Xianlu Chen;Ben Kao;Reynold Cheng;David Cheung
#t 2009
#c 18
#! Traditional machine learning algorithms assume that data are exact or precise. However, this assumption may not hold in some situations because of data uncertainty arising from measurement errors, data staleness, and repeated measurements, etc. With uncertainty, the value of each data item is represented by a probability distribution function (pdf). In this paper, we propose a novel naive Bayes classification algorithm for uncertain data with a pdf. Our key solution is to extend the class conditional probability estimation in the Bayes model to handle pdf’s. Extensive experiments on UCI datasets show that the accuracy of naive Bayes model can be improved by taking into account the uncertainty information.

#index 1318642
#* Constraint-Based Pattern Mining in Dynamic Graphs
#@ Céline Robardet
#t 2009
#c 18
#! Dynamic graphs are used to represent relationships between entities that evolve over time. Meaningful patterns in such structured data must capture strong interactions and their evolution over time. In social networks, such patterns can be seen as dynamic community structures, i.e., sets of individuals who strongly and repeatedly interact. In this paper, we propose a constraint-based mining approach to uncover evolving patterns. We propose to mine dense and isolated subgraphs defined by two user-parameterized constraints. The temporal evolution of such patterns is captured by associating a temporal event type to each identified subgraph. We consider five basic temporal events: The formation, dissolution, growth, diminution and stability of subgraphs from one time stamp to the next. We propose an algorithm that finds such subgraphs in a time series of graphs processed incrementally. The extraction is feasible due to efficient patterns and data pruning strategies. We demonstrate the applicability of our method on several real-world dynamic graphs and extract meaningful evolving communities.

#index 1318643
#* Efficient Discovery of Frequent Correlated Subgraph Pairs
#@ Yiping Ke;James Cheng;Jeffrey Xu Yu
#t 2009
#c 18
#! The recent proliferation of graph data in a wide spectrum of applications has led to an increasing demand for advanced data analysis techniques. In view of this, many graph mining techniques, such as frequent subgraph mining and correlated subgraph mining, have been proposed. In many applications, both frequency and correlation play an important role. Thus, this paper studies a new problem of mining the set of frequent correlated subgraph pairs. A simple algorithm that combines existing algorithms for mining frequent subgraphs and correlated subgraphs results in a multiplication of the mining operations, the majority of which are redundant. We discover that most of the graphs correlated to a common graph are also highly correlated. We establish theoretical foundations for this finding and derive a tight lower bound on the correlation of any two graphs that are correlated to a common graph. This theoretical result leads to the design of a very effective skipping mechanism, by which we skip the processing of a majority of graphs in the mining process. Our algorithm, FCP-Miner, is a fast approximate algorithm, but we show that the missing pairs are only a small set of marginally correlated pairs. Extensive experiments verify both the efficiency and effectiveness of FCP-Miner.

#index 1318644
#* Self-Adaptive Anytime Stream Clustering
#@ Philipp Kranen;Ira Assent;Corinna Baldauf;Thomas Seidl
#t 2009
#c 18
#! Clustering streaming data requires algorithms which are capable of updating clustering results for the incoming data. As data is constantly arriving, time for processing is limited. Clustering has to be performed in a single pass over the incoming data and within the possibly varying inter-arrival times of the stream. Likewise, memory is limited, making it impossible to store all data. For clustering, we are faced with the challenge of maintaining a current result that can be presented to the user at any given time. In this work, we propose a parameter free algorithm that automatically adapts to the speed of the data stream. It makes best use of the time available under the current constraints to provide a clustering of the objects seen up to that point. Our approach incorporates the age of the objects to reflect the greater importance of more recent data. Moreover, we are capable of detecting concept drift, novelty and outliers in the stream. For efficient and effective handling, we introduce the ClusTree, a compact and self-adaptive index structure for maintaining stream summaries. Our experiments show that our approach is capable of handling a multitude of different stream characteristics for accurate and scalable anytime stream clustering.

#index 1318645
#* Improving SVM Classification on Imbalanced Data Sets in Distance Spaces
#@ Suzan Köknar-Tezel;Longin Jan Latecki
#t 2009
#c 18
#! Imbalanced data sets present a particular challenge to the data mining community. Often, it is the rare event that is of interest and the cost of misclassifying the rare event is higher than misclassifying the usual event. When the data is highly skewed toward the usual, it can be very difficult for a learning system to accurately detect the rare event. There have been many approaches in recent years for handling imbalanced data sets, from under-sampling the majority class to adding synthetic points to the minority class in feature space. Distances between time series are known to be non-Euclidean and nonmetric, since comparing time series requires warping in time. This fact makes it impossible to apply standard methods like SMOTE to insert synthetic data points in feature spaces. We present an innovative approach that augments the minority class by adding synthetic points in distance spaces. We then use Support Vector Machines for classification. Our experimental results on standard time series show that our synthetic points significantly improve the classification rate of the rare events, and in many cases also improves the overall accuracy of SVM.

#index 1318646
#* CoCoST: A Computational Cost Efficient Classifier
#@ Liyun Li;Umut Topkara;Baris Coskun;Nasir Memon
#t 2009
#c 18
#! Computational cost of classification is as important as accuracy in on-line classification systems. The computational cost is usually dominated by the cost of computing implicit features of the raw input data. Very few efforts have been made to design classifiers which perform effectively with limited computational power; instead, feature selection is usually employed as a pre-processing step to reduce the cost of running traditional classifiers. We present CoCoST, a novel and effective approach for building classifiers which achieve state-of-the-art classification accuracy, while keeping the expected computational cost of classification low, even without feature selection. CoCost employs a wide range of novel cost-aware decision trees, each of which is tuned to specialize in classifying instances from a subset of the input space, and judiciously consults them depending on the input instance in accordance with a cost-aware meta-classifier. Experimental results on a network flow detection application show that, our approach can achieve better accuracy than classifiers such as SVM and random forests, while achieving 75%-90% reduction in the computational costs.

#index 1318647
#* Semi-naive Exploitation of One-Dependence Estimators
#@ Nan Li;Yang Yu;Zhi-Hua Zhou
#t 2009
#c 18
#! It is well known that the key of Bayesian classifier learning is to balance the two important issues, that is, the exploration of attribute dependencies in high orders for ensuring a sufficient flexibility in approximating the ground-truth dependencies, and the exploration of low orders for ensuring a stable probability estimate from limited training samples. By allowing one-order attribute dependencies, one-dependence estimators (ODEs) have been shown to be able to approximate the ground-truth attribute dependencies whilst keeping the effectiveness of probability estimation, and therefore leading to excellent performance. In previous studies, however, ODEs were exploited in simple ways, such as by averaging, for classification. In this paper, we propose a semi-naive exploitation of ODEs that fits a function of ODEs to pursue higher-order attribute dependencies. Extensive experiments show that the proposed SNODE approach can achieve better performance than many state-of-the-art Bayesian classifiers.

#index 1318648
#* Global Slope Change Synopses for Measurement Maps
#@ Frank Rosenthal;Ulrike Fischer;Peter B. Volk;Wolfgang Lehner
#t 2009
#c 18
#! Quality control using scalar quality measures is standard practice in manufacturing. However, there are also quality measures that are determined at a large number of positions on a product, since the spatial distribution is important. We denote such a mapping of local coordinates on the product to values of a measure as a measurement map. In this paper, we examine how measurement maps can be clustered according to a novel notion of similarity—mapscape similarity—that considers the overall course of the measure on the map. We present a class of synopses called global slope change that uses the profile of the measure along several lines from a reference point to different points on the borders to represent a measurement map. We conduct an evaluation of global slope change using a real-world data set from manufacturing and demonstrate its superiority over other synopses.

#index 1318649
#* Aspect Guided Text Categorization with Unobserved Labels
#@ Dan Roth;Yuancheng Tu
#t 2009
#c 18
#! This paper proposes a novel multiclass classification method and exhibits its advantage in the domain of text categorization with a large label space and, most importantly, when some of the labels were not observed in the training data. The key insight is the introduction of intermediate aspect variables that encode properties of the labels. Aspect variables serve as a joint representation for observed and unobserved labels. This way the classification problem can be viewed as a structure learning problem with natural constraints on assignments to the aspect variables. We solve the problem as a constrained optimization problem over multiple learners and show significant improvement in classifying short sentences into a large label space of categories, including previously unobserved categories.

#index 1318650
#* A Fully Automated Method for Discovering Community Structures in High Dimensional Data
#@ Jianhua Ruan
#t 2009
#c 18
#! Identifying modules, or natural communities, in large complex networks is fundamental in many fields, including social sciences, biological sciences and engineering. Recently several methods have been developed to automatically identify communities from complex networks by optimizing the modularity function. The advantage of this type of approaches is that the algorithm does not require any parameter to be tuned. However, the modularity-based methods for community discovery assume that the network structure is given explicitly and is correct. In addition, these methods work best if the network is unweighted and/or sparse. In reality, networks are often not directly defined, or may be given as an affinity matrix. In the first case, each node of the network is defined as a point in a high dimensional space and different networks can be obtained with different network construction methods, resulting in different community structures. In the second case, an affinity matrix may define a dense weighted graph, for which modularity-based methods do not perform well. In this work, we propose a very simple algorithm to automatically identify community structures from these two types of data. Our approach utilizes a k-nearest-neighbor network construction method to capture the topology embedded in high dimensional data, and applies a modularity-based algorithm to identify the optimal community structure. A key to our approach is that the network construction is incorporated with the community identification process and is totally parameter-free. Furthermore, our method can suggest appropriate pre-processing / normalization of the data to improve the results of community identification. We tested our methods on several synthetic and real data sets, and evaluated its performance by internal or external accuracy indices. Compared with several existing approaches, our method is not only fully automatic, but also has the best accuracy overall.

#index 1318651
#* Hierarchical Probabilistic Segmentation of Discrete Events
#@ Guy Shani;Christopher Meek;Asela Gunawardana
#t 2009
#c 18
#! Segmentation, the task of splitting a long sequence of discrete symbols into chunks, can provide important information about the nature of the sequence that is understandable to humans. Algorithms for segmenting mostly belong to the supervised learning family, where a labeled corpus is available to the algorithm in the learning phase. We are interested, however, in the unsupervised scenario, where the algorithm never sees examples of successful segmentation, but still needs to discover meaningful segments. In this paper we present an unsupervised learning algorithm for segmenting sequences of symbols or categorical events. Our algorithm, Hierarchical Multigram, hierarchically builds a lexicon of segments and computes a maximum likelihood segmentation given the current lexicon. Thus, our algorithm is most appropriate to hierarchical sequences, where smaller segments are grouped into larger segments. Our probabilistic approach also allows us to suggest conditional entropy as a measurement of the quality of a segmentation in the absence of labeled data. We compare our algorithm to two previous approaches from the unsupervised segmentation literature, showing it to provide superior segmentation over a number of benchmarks. We also compare our algorithm to previous approaches over a segmentation of the unlabeled interactions of a web service and its client.

#index 1318652
#* Topic Modeling for Sequences of Temporal Activities
#@ Zhiyong Shen;Ping Luo;Yuhong Xiong;Jun Sun;Yidong Shen
#t 2009
#c 18
#! Temporally-ordered activity sequences are popular in many real-world domains. This paper presents an LDA-style topic model for sequences of temporal activities that captures three features of such sequences: 1) the counts of unique activities, 2) the Markov transition dependence and 3) the absolute or relative timestamp on each activity. In modeling the first two features we propose the concept of global transition probability and distinguish it with local transition probability used in previous work. In modeling the third feature, we employ a continuous time distribution to depict the time range of latent topics. The combination of the global transition probability and the temporal information helps to refine the mixture distribution over topics for temporal sequence analysis. We present results on the data of system call traces, showing better next activity prediction and sequence clustering.

#index 1318653
#* A Framework for Computing the Privacy Scores of Users in Online Social Networks
#@ Kun Liu;Evimaria Terzi
#t 2009
#c 18
#! A large body of work has been devoted to address corporate-scale privacy concerns related to social networks. The main focus was on how to share social networks owned by organizations without revealing the identities or sensitive relationships of the users involved. Not much attention has been given to the privacy risk of users posed by their information sharing activities. In this paper, we approach the privacy concerns arising in online social networks from the individual users’ viewpoint: we propose a framework to compute a privacy score of a user, which indicates the potential privacy risk caused by his participation in the network. Our definition of privacy score satisfies the following intuitive properties: the more sensitive the information revealed by a user, the higher his privacy risk. Also, the more visible the disclosed information becomes in the network, the higher the privacy risk. We develop mathematical models to estimate both sensitivity and visibility of the information. We apply our methods to synthetic and real-world data and demonstrate their efficacy and practical utility.

#index 1318654
#* Least Square Incremental Linear Discriminant Analysis
#@ Li-Ping Liu;Yuan Jiang;Zhi-Hua Zhou
#t 2009
#c 18
#! Linear discriminant analysis (LDA) is a well-known dimension reduction approach, which projects high-dimensional data into a low-dimensional space with the best separation of different classes. In many tasks, the data accumulates over time, and thus incremental LDA is more desirable than batch LDA. Several incremental LDA algorithms have been developed and achieved success; however, the eigen-problem involved requires a large computation cost, which hampers the efficiency of these algorithms. In this paper, we propose a new incremental LDA algorithm, LS-ILDA, based on the least square solution of LDA. When new samples are received, LS-ILDA incrementally updates the least square solution of LDA. Our analysis discloses that this algorithm produces the exact least square solution of batch LDA, while its computational cost is O(min(n; d) 拢 d) for one update on dataset containing n instances in d-dimensional space. Experimental results show that comparing with state-of-the-art incremental LDA algorithms, our proposed LS-ILDA achieves high accuracy with low time cost.

#index 1318655
#* Unified Solution to Nonnegative Data Factorization Problems
#@ Xiaobai Liu;Shuicheng Yan;Jun Yan;Hai Jin
#t 2009
#c 18
#! In this paper, we restudy the non-convex data factorization problems (regularized or not, unsupervised or supervised), where the optimization is confined in the \emph{nonnegative} orthant, and provide a \emph{unified} convergency provable solution based on multiplicative nonnegative update rules. This solution is general for optimization problems with block-wisely quadratic objective functions, and thus direct update rules can be derived by skipping over the tedious specific procedure deduction process and algorithmic convergence proof. By taking this unified solution as a general template, we i) re-explain several existing nonnegative data factorization algorithms, ii) develop a variant of nonnegative matrix factorization formulation for handling out-of-sample data, and iii) propose a new nonnegative data factorization algorithm, called Correlated Co-Decomposition (CCD), to simultaneously factorize two feature spaces by exploring the inter-correlated information. Experiments on both face recognition and multi-label image annotation tasks demonstrate the wide applicability of the unified solution as well as the effectiveness of two proposed new algorithms.

#index 1318656
#* Extended Boolean Matrix Decomposition
#@ Haibing Lu;Jaideep Vaidya;Vijayalakshmi Atluri;Yuan Hong
#t 2009
#c 18
#! With the vast increase in collection and storage of data, the problem of data summarization is most critical for effective data management. Since much of this data is categorical in nature, it can be viewed in terms of a Boolean matrix. Boolean matrix decomposition (BMD) has been used to provide concise and interpretable representations of Boolean data sets. A Boolean matrix can be expressed as a product of two Boolean matrices, where the first matrix represents a set of meaningful concepts, and the second describes how the observed data can be expressed as combinations of those concepts. Typically, the combination is only in terms of the set union. In other words, a successful Boolean matrix decomposition gives a set of concepts and shows how every column of the input data can be expressed as a union of some subset of those concepts. However, this way of modeling only incompletely represents real data semantics. Essentially, it ignores a critical component -- the set difference operation: a column can be expressed as the combination of union of certain concepts as well as the exclusion of other concepts. This has two significant benefits. First, the total number of concepts required to describe the data may itself be reduced. Second, a more succinct summarization may be found for every column. In this paper, we propose the extended Boolean matrix decomposition (EBMD) problem, which aims to factor Boolean matrices using both the set union and set difference operations. We study several variants of the problem, show that they are NP-hard, and propose efficient heuristics to solve them. Extensive experimental results demonstrate the power of EBMD.

#index 1318657
#* Active Learning with Adaptive Heterogeneous Ensembles
#@ Zhenyu Lu;Xindong Wu;Josh Bongard
#t 2009
#c 18
#! One common approach to active learning is to iteratively train a single classifier by choosing data points based on its uncertainty, but it is nontrivial to design uncertainty measures unbiased by the choice of classifier. Query by committee suggests that given an ensemble of diverse but accurate classifiers, the most informative data points are those that cause maximal disagreement among the predictions of the ensemble members. However the method for finding ensembles appropriate to a given data set remains an open question. In this paper, the random subspace method is combined with active learning to create multiple instances of different classifier types, and an algorithm is introduced that adapts the ratio of different classifier types in the ensemble towards better overall accuracy. Here we show that the proposed algorithm outperforms C4.5 with uncertainty sampling, Naive Bayes with uncertainty sampling, bagging, boosting and the random subspace method with random sampling. To the best of our knowledge, our work is the first to adapt the ratio of classifiers in a heterogeneous ensemble for active learning.

#index 1318658
#* Combining Super-Structuring and Abstraction on Sequence Classification
#@ Adrian Silvescu;Cornelia Caragea;Vasant Honavar
#t 2009
#c 18
#! We present an approach to adapting the data representation used by a learner on sequence classification tasks. Our approach that exploits the complementary strengths of super-structuring (constructing complex features by combining existing features) and abstraction (grouping of similar features to generate more abstract features), yields smaller and, at the same time, accurate models. Super-structuring provides a way to increase the predictive accuracy of the learned models by enriching the data representation (and hence, increases the complexity of the learned models) whereas abstraction helps reduce the number of model parameters by simplifying the data representation. The results of our experiments on two data sets drawn from macromolecular sequence classification applications show that adapting data representation by combining super-structuring and abstraction, makes it possible to construct predictive models that use significantly smaller number of features (by one to three orders of magnitude) than those that are obtained using super-structuring alone, without sacrificing predictive accuracy. Our experiments also show that simplifying data representation using abstraction yields better performing models than those obtained using feature selection.

#index 1318659
#* A Global-Model Naive Bayes Approach to the Hierarchical Prediction of Protein Functions
#@ Carlos N. Silla Jr.;Alex A. Freitas
#t 2009
#c 18
#! In this paper we propose a new global--model approach for hierarchical classification, where a single global classification model is built by considering all the classes in the hierarchy -- rather than building a number of local classification models as it is more usual in hierarchical classification. The method is an extension of the flat classification algorithm naive Bayes. We present the extension made to the original algorithm as well as its evaluation on eight protein function hierarchical classification datasets. The achieved results are positive and show that the proposed global model is better than using a local model approach.

#index 1318660
#* Spatio-temporal Energy Based Gait Recognition
#@ Shamsher Singh;K. K. Biswas
#t 2009
#c 18
#! Recently there has been lot of interest in using the gait energy image (GEI) of human walk sequence for individual recognition. Researchers have reported very good recognition rates using both unsupervised and supervised methods for normal walk sequences. However, the performance degrades when there is a variant like change in clothing or carrying a bag. This paper shows that the performance for the variant situations can be improved by constructing the GEI with sway alignment instead of upper body alignment, and dynamically selecting just the required number of rows from the bottom of the silhouette as inputs for an unsupervised feature selection approach. The improvement in recognition rates are established with performance testing on a large gait dataset.

#index 1318661
#* Feature Selection in the Tensor Product Feature Space
#@ Aaron Smalter;Jun Huan;Gerald Lushington
#t 2009
#c 18
#! Classifying objects that are sampled jointly from two or more domains has many applications. The tensor product feature space is useful for modeling interactions between feature sets in different domains but feature selection in the tensor product feature space is challenging. Conventional feature selection methods ignore the structure of the feature space and may not provide the optimal results. In this paper we propose methods for selecting features in the original feature spaces of different domains. We obtained sparsity through two approaches, one using integer quadratic programming and another using L1-norm regularization. Experimental studies on biological data sets validate our approach.

#index 1318662
#* Topic Distributions over Links on Web
#@ Jie Tang;Jing Zhang;Jeffrey Xu Yu;Zi Yang;Keke Cai;Rui Ma;Li Zhang;Zhong Su
#t 2009
#c 18
#! It is well known that Web users create links with different intentions. However, a key question, which is not well studied, is how to categorize the links and how to quantify the strength of the influence of a web page on another if there is a link between the two linked web pages. In this paper, we focus on the problem of link semantics analysis, and propose a novel supervised learning approach to build a model, based on a training link-labeled and link-weighted graph where a link-label represents the category of a link and a link-weight represents the influence of one web page on the other in a link. Based on the model built, we categorize links and quantify the influence of web pages on the others in a large graph in the same application domain. We discuss our proposed approach, namely Pairwise Restricted Boltzmann Machines (PRBMs), and conduct extensive experimental studies to demonstrate the effectiveness of our approach using large real datasets.

#index 1318663
#* Clustering with Multiple Graphs
#@ Wei Tang;Zhengdong Lu;Inderjit S. Dhillon
#t 2009
#c 18
#! In graph-based learning models, entities are often represented as vertices in an undirected graph with weighted edges describing the relationships between entities. In many real-world applications, however, entities are often associated with relations of different types and/or from different sources, which can be well captured by multiple undirected graphs over the same set of vertices. How to exploit such multiple sources of information to make better inferences on entities remains an interesting open problem. In this paper, we focus on the problem of clustering the vertices based on multiple graphs in both unsupervised and semi-supervised settings. As one of our contributions, we propose Linked Matrix Factorization (LMF) as a novel way of fusing information from multiple graph sources. In LMF, each graph is approximated by matrix factorization with a graph-specific factor and a factor common to all graphs, where the common factor provides features for all vertices. Experiments on SIAM journal data show that (1) we can improve the clustering accuracy through fusing multiple sources of information with several models, and (2) LMF yields superior or competitive results compared to other graph-based clustering methods.

#index 1318664
#* Non-negative Laplacian Embedding
#@ Dijun Luo;Chris Ding;Heng Huang;Tao Li
#t 2009
#c 18
#! Laplacian embedding provides a low dimensional representation for a matrix of pairwise similarity data using the eigenvectors of the Laplacian matrix. The true power of Laplacian embedding is that it provides an approximation of the Ratio Cut clustering. However, Ratio Cut clustering requires the solution to be {\it nonnegative}. In this paper, we propose a new approach, nonnegative Laplacian embedding, which approximates Ratio Cut clustering in a more direct way than traditional approaches. From the solution of our approach, clustering structures can be read off directly. We also propose an efficient algorithm to optimize the objective function utilized in our approach. Empirical studies on many real world datasets show that our approach leads to more accurate Ratio Cut solution and improves clustering accuracy at the same time.

#index 1318665
#* Scalable Algorithms for Distribution Search
#@ Yasuko Matsubara;Yasushi Sakurai;Masatoshi Yoshikawa
#t 2009
#c 18
#! Distribution data naturally arise in countless domains, such as meteorology, biology, geology, industry and economics. However, relatively little attention has been paid to data mining for large distribution sets. Given n distributions of multiple categories and a query distribution Q, we want to find similar clouds (i.e., distributions), to discover patterns, rules and outlier clouds. For example, consider the numerical case of sales of items, where, for each item sold, we record the unit price and quantity; then, each customer is represented as a distribution of 2-d points (one for each item he/she bought). We want to find similar users, e.g., for market segmentation, anomaly/fraud detection. We propose to address this problem and present D-Search, which includes fast and effective algorithms for similarity search in large distribution datasets. Our main contributions are (1) approximate KL divergence, which can speed up cloud-similarity computations, (2) multi-step sequential scan, which efficiently prunes a significant number of search candidates and leads to a direct reduction in the search cost. We also introduce an extended version of D-Search: (3) time-series distribution mining, which finds similar subsequences in time-series distribution datasets. Extensive experiments on real multi-dimensional datasets show that our solution achieves up to 2,300 faster wall-clock time over the naive implementation while it does not sacrifice accuracy.

#index 1318666
#* A Deep Non-linear Feature Mapping for Large-Margin kNN Classification
#@ Renqiang Min;David A. Stanley;Zineng Yuan;Anthony Bonner;Zhaolei Zhang
#t 2009
#c 18
#! KNN is one of the most popular data mining methods for classification, but it often fails to work well with inappropriate choice of distance metric or due to the presence of numerous class-irrelevant features. Linear feature transformation methods have been widely applied to extract class-relevant information to improve kNN classification, which is very limited in many applications. Kernels have also been used to learn powerful non-linear feature transformations, but these methods fail to scale to large datasets. In this paper, we present a scalable non-linear feature mapping method based on a deep neural network pretrained with Restricted Boltzmann Machines for improving kNN classification in a large-margin framework, which we call DNet-kNN. DNet-kNN can be used for both classification and for supervised dimensionality reduction. The experimental results on two benchmark handwritten digit datasets and one newsgroup text dataset show that DNet-kNN has much better performance than large-margin kNN using a linear mapping and kNN based on a deep autoencoder pretrained with Restricted Boltzmann Machines.

#index 1318667
#* Finding Time Series Motifs in Disk-Resident Data
#@ Abdullah Mueen;Eamonn Keogh;Nima Bigdely-Shamlo
#t 2009
#c 18
#! Time series motifs are sets of very similar subsequences of a long time series. They are of interest in their own right, and are also used as inputs in several higher-level data mining algorithms including classification, clustering, rule-discovery and summarization. In spite of extensive research in recent years, finding exact time series motifs in massive databases is an open problem. Previous efforts either found approximate motifs or considered relatively small datasets residing in main memory. In this work, we describe for the first time a disk-aware algorithm to find exact time series motifs in multi-gigabyte databases which contain on the order of tens of millions of time series. We have evaluated our algorithm on datasets from diverse areas including medicine, anthropology, computer networking and image processing and show that we can find interesting and meaningful motifs in datasets that are many orders of magnitude larger than anything considered before.

#index 1318668
#* Relevant Subspace Clustering: Mining the Most Interesting Non-redundant Concepts in High Dimensional Data
#@ Emmanuel Müller;Ira Assent;Stephan Günnemann;Ralph Krieger;Thomas Seidl
#t 2009
#c 18
#! Subspace clustering aims at detecting clusters in any subspace projection of a high dimensional space. As the number of possible subspace projections is exponential in the number of dimensions, the result is often tremendously large. Recent approaches fail to reduce results to relevant subspace clusters. Their results are typically highly redundant, i.e. many clusters are detected multiple times in several projections. In this work, we propose a novel model for relevant subspace clustering (RESCU). We present a global optimization which detects the most interesting non-redundant subspace clusters. We prove that computation of this model is NP-hard. For RESCU, we propose an approximative solution that shows high accuracy with respect to our relevance model. Thorough experiments on synthetic and real world data show that RESCU successfully reduces the result to manageable sizes. It reliably achieves top clustering quality while competing approaches show greatly varying performance.

#index 1318669
#* Two Heads Better Than One: Metric+Active Learning and its Applications for IT Service Classification
#@ Fei Wang;Jimeng Sun;Tao Li;Nikos Anerousis
#t 2009
#c 18
#! Large IT service providers track service requests and their execution through problem/change tickets. It is important to classify the tickets based on the problem/change description in order to understand service quality and to optimize service processes. However, two challenges exist in solving this classification problem: 1) ticket descriptions from different classes are of highly diverse characteristics, which invalidates most standard distance metrics; 2) it is very expensive to obtain high-quality labeled data. To address these challenges, we develop two seemingly independent methods 1) Discriminative Neighborhood Metric Learning (DNML) and 2) Active Learning with Median Selection (ALMS), both of which are, however, based on the same core technique: iterated representative selection. A case study on real IT service classification application is presented to demonstrate the effectiveness and efficiency of our proposed methods.

#index 1318670
#* Maximum Margin Clustering on Data Manifolds
#@ Fei Wang;Xin Wang;Tao Li
#t 2009
#c 18
#! Clustering is one of the most fundamental and important problems in computer vision and pattern recognition communities. Maximum Margin Clustering(MMC) is a recently proposed clustering technique which has shown promising experimental results. The main theme behind MMC is to extend the standard maximum margin principle in Support Vector Machine (SVM) to the unsupervised scenario. This paper will consider the problem of maximum margin clustering on data manifolds. Specifically, we propose an approach called Manifold Regularized Maximum Margin clustering (MRMMC) which combines both the maximum margin data discrimination and data manifold information in a unified clustering objective and propose an efficient algorithm to solve it. Finally the experimental results on several real world data sets are presented to show the effectiveness of our method.

#index 1318671
#* Discovering Contexts and Contextual Outliers Using Random Walks in Graphs
#@ Xiang Wang;Ian Davidson
#t 2009
#c 18
#! The identifying of contextual outliers allows the discovery of anomalous behavior that other forms of outlier detection cannot find. What may appear to be normal behavior with respect to the entire data set can be shown to be anomalous by subsetting the data according to specific spatial or temporal context. However, in many real-world applications, we may not have sufficient a priori contextual information to discover these contextual outliers. This paper addresses the problem by proposing a probabilistic approach based on random walks, which can simultaneously explore meaningful contexts and score contextual outliers therein. Our approach has several advantages including producing outlier scores which can be interpreted as stationary expectations and their calculation in closed form in polynomial time. In addition, we show that point outlier detection using the stationary distribution is a special case of our approach. It allows us to find both global and contextual outliers simultaneously and to create a meaningful ranked list consisting of both types of outliers. This is a major departure from existing work where an algorithm typically identifies one type of outlier. The effectiveness of our method is justified by empirical results on real data sets, with comparison to related work.

#index 1318672
#* Effective Criterion Functions for Efficient Agglomerative Clustering on Very Large Networks
#@ Yang Wang;Mingyuan An
#t 2009
#c 18
#! As the agglomerative clustering algorithm is widely used in data mining, image processing, bioinformatics and pattern recognition. it has attracted great interests from both academical and industrial communities. However, existing studies neglect the decisive factor of the efficiency of the agglomerative clustering algorithm for large complex networks and usually use criterion functions which lead to inefficiency. In this paper, we propose three effective criterion functions for improving performance of agglomerative clustering algorithm. We note that clustering efficiency is determined by two factors: a) the number of neighbors of two merged clusters in each merge step; b) the number of neighbors shared by the two clusters. Based on these observations, we propose a framework for designing criterion functions in order to efficiently find clusters in very large networks. We devise three criterion functions that can effectively control the number of neighbors of clusters, and they can efficiently produce high-quality clusters. We have implemented our method and compared with existing studies on real networks, and our method outperforms state-of-the-art approaches significantly on large networks.

#index 1318673
#* Binomial Matrix Factorization for Discrete Collaborative Filtering
#@ Jinlong Wu
#t 2009
#c 18
#! Matrix factorization (MF) models have proved efficient and well scalable for collaborative filtering (CF) problems. Many researchers also present the probabilistic interpretation of MF. They usually assume that the factor vectors of users and items are from normal distributions, and so are the ratings when the user and item factors are given. Then they can derive the exact MF algorithm by finding a MAP estimate of the model parameters. In this paper we suggest a new probabilistic perspective on MF for discrete CF problems. We assume that all ratings are from binomial distributions with different preference parameters instead of the original normal distributions. The new interpretation is more reasonable for discrete CF problems since they only allow several legal discrete rating values. We also present two effective algorithms to learn the new model and make predictions. They are applied to the Netflix Prize data set and acquire considerably better accuracy than those of MF.

#index 1318674
#* Non-sparse Multiple Kernel Learning for Fisher Discriminant Analysis
#@ Fei Yan;Josef Kittler;Krystian Mikolajczyk;Atif Tahir
#t 2009
#c 18
#! We consider the problem of learning a linear combination of pre-specified kernel matrices in the Fisher discriminant analysis setting. Existing methods for such a task impose an $\ell_1$ norm regularisation on the kernel weights, which produces sparse solution but may lead to loss of information. In this paper, we propose to use $\ell_2$ norm regularisation instead. The resulting learning problem is formulated as a semi-infinite program and can be solved efficiently. Through experiments on both synthetic data and a very challenging object recognition benchmark, the relative advantages of the proposed method and its $\ell_1$ counterpart are demonstrated, and insights are gained as to how the choice of regularisation norm should be made.

#index 1318675
#* Stacked Gaussian Process Learning
#@ Marion Neumann;Kristian Kersting;Zhao Xu;Daniel Schulz
#t 2009
#c 18
#! Triggered by a market relevant application that involves making joint predictions of pedestrian and public transit flows in urban areas, we address the question of how to utilize hidden common cause relations among variables of interest in order to improve performance in the two related regression tasks. Specifically, we propose stacked Gaussian process learning, a meta-learning scheme in which a base Gaussian process is enhanced by adding the posterior covariance functions of other related tasks to its covariance function in a stage-wise optimization. The idea is that the stacked posterior covariances encode the hidden common causes among variables of interest that are shared across the related regression tasks. Stacked Gaussian process learning is efficient, capable of capturing shared common causes, and can be implemented with any kind of standard Gaussian process regression model such as sparse approximations and relational variants. Our experimental results on real-world data from the market relevant application show that stacked Gaussian processes learning can significantly improve prediction performance of a standard Gaussian process.

#index 1318676
#* Evaluating Statistical Tests for Within-Network Classifiers of Relational Data
#@ Jennifer Neville;Brian Gallagher;Tina Eliassi-Rad
#t 2009
#c 18
#! Recently a number of modeling techniques have been developed for data mining and machine learning in relational and network domains where the instances are not independent and identically distributed (i.i.d.). These methods specifically exploit the statistical dependencies among instances in order to improve classification accuracy. However, there has been little focus on how these same dependencies affect our ability to draw accurate conclusions about the performance of the models. More specifically, the complex link structure and attribute dependencies in network data violate the assumptions of many conventional statistical tests and make it difficult to use these tests to assess the models in an unbiased manner. In this work, we examine the task of within-network classification and the question of whether two algorithms will learn models which will result in significantly different levels of performance. We show that the commonly-used form of evaluation (paired t-test on overlapping network samples) can result in an unacceptable level of Type I error. Furthermore we show that Type I error increases as (1) the correlation among instances increases and (2) the size of the evaluation set increases (i.e., the proportion of labeled nodes in the network decreases). We propose a method for network cross-validation that combined with paired t-tests produces more acceptable levels of Type I error while still providing reasonable levels of statistical power (i.e., Type II error).

#index 1318677
#* Discovering Excitatory Networks from Discrete Event Streams with Applications to Neuronal Spike Train Analysis
#@ Debprakash Patnaik;Srivatsan Laxman;Naren Ramakrishnan
#t 2009
#c 18
#! Mining temporal network models from discrete event streams is an important problem with applications in computational neuroscience, physical plant diagnostics, and human-computer interaction modeling. We focus in this paper on temporal models representable as excitatory networks where all connections are stimulative, rather than inhibitory. Through this emphasis on excitatory networks, we show how they can be learned by creating bridges to frequent episode mining. Specifically, we show that frequent episodes help identify nodes with high mutual information relationships and which can be summarized into a dynamic Bayesian network (DBN). To demonstrate the practical feasibility of our approach, we show how excitatory networks can be inferred from both mathematical models of spiking neurons as well as real neuroscience datasets.

#index 1318678
#* Clustering Trajectories of Moving Objects in an Uncertain World
#@ Nikos Pelekis;Ioannis Kopanakis;Evangelos Kotsifakos;Elias Frentzos;Yannis Theodoridis
#t 2009
#c 18
#! Mining Trajectory Databases (TD) has recently gained great interest due to the popularity of tracking devices. On the other hand, the inherent presence of uncertainty in TD (e.g., due to GPS errors) has not been taken yet into account during the mining process. In this paper, we study the effect of uncertainty in TD clustering and introduce a three-step approach to deal with it. First, we propose an intuitionistic point vector representation of trajectories that encompasses the underlying uncertainty and introduce an effective distance metric to cope with uncertainty. Second, we devise CenTra, a novel algorithm which tackles the problem of discovering the Centroid Trajectory of a group of movements. Third, we propose a variant of the Fuzzy C-Means (FCM) clustering algorithm, which embodies CenTra at its update procedure. The experimental evaluation over real world TD demonstrates the efficiency and effectiveness of our approach.

#index 1318679
#* Semi-Supervised Sequence Labeling with Self-Learned Features
#@ Yanjun Qi;Pavel Kuksa;Ronan Collobert;Kunihiko Sadamasa;Koray Kavukcuoglu;Jason Weston
#t 2009
#c 18
#! Typical information extraction (IE) systems can be seen as tasks assigning labels to words in a natural language sequence. The performance is restricted by the availability of labeled words. To tackle this issue, we propose a semi-supervised approach to improve the sequence labeling procedure in IE through a class of algorithms with {\em self-learned features} (SLF). A supervised classifier can be trained with annotated text sequences and used to classify each word in a large set of unannotated sentences. By averaging predicted labels over all cases in the unlabeled corpus, SLF training builds class label distribution patterns for each word (or word attribute) in the dictionary and re-trains the current model iteratively adding these distributions as extra word {\em features}. Basic SLF models how likely a word could be assigned to target class types. Several extensions are proposed, such as learning words' class boundary distributions. SLF exhibits robust and scalable behaviour and is easy to tune. We applied this approach on four classical IE tasks: named entity recognition (German and English), part-of-speech tagging (English) and one gene name recognition corpus. Experimental results show effective improvements over the supervised baselines on all tasks. In addition, when compared with the closely related self-training idea, this approach shows favorable advantages.

#index 1318680
#* Bi-relational Network Analysis Using a Fast Random Walk with Restart
#@ Jing Xia;Doina Caragea;William H. Hsu
#t 2009
#c 18
#! Identification of nodes relevant to a given node in a relational network is a basic problem in network analysis with great practical importance. Most existing network analysis algorithms utilize one single relation to define relevancy among nodes. However, in real world applications multiple relationships exist between nodes in a network. Therefore, network analysis algorithms that can make use of more than one relation to identify the relevance set for a node are needed. In this paper, we show how the Random Walk with Restart (RWR) approach can be used to study relevancy in a bi-relational network from the bibliographic domain, and show that making use of two relations results in better results as compared to approaches that use a single relation. As relational networks can be very large, we also propose a fast implementation for RWR by adapting an existing Iterative Aggregation and Disaggregation (IAD) approach. The IAD-based RWR exploits the block-wise structure of real world networks. Experimental results show significant increase in running time for the IAD-based RWR compared to the traditional power method based RWR.

#index 1318681
#* A New MCA-Based Divisive Hierarchical Algorithm for Clustering Categorical Data
#@ Tengke Xiong;Shengrui Wang;André Mayers;Ernest Monga
#t 2009
#c 18
#! Clustering categorical data faces two challenges, one is lacking of inherent similarity measure, and the other is that the clusters are prone to being embedded in different subspace. In this paper, we propose the first divisive hierarchical clustering algorithm for categorical data. The algorithm, which is based on Multiple Correspondence Analysis (MCA), is systematic, efficient and effective. In our algorithm, MCA plays an important role in analyzing the data globally. The proposed algorithm has five merits. First, our algorithm yields a dendrogram representing nested groupings of patterns and similarity levels at different granularities. Second, it is parameter-free, fully automatic and, most importantly, requires no assumption regarding the number of clusters. Third, it is independent of the order in which the data are processed. Forth, it is scalable to large data sets; and finally, using the novel data representation and Chi-square distance measures makes our algorithm capable of seamlessly discovering the clusters embedded in the subspaces. Experiments on both synthetic and real data demonstrate the superior performance of our algorithm.

#index 1318682
#* Multirelational Topic Models
#@ Jia Zeng;William K. Cheung;Chun-hung Li;Jiming Liu
#t 2009
#c 18
#! In this paper we propose the multirelational topic model (MRTM) for multiple types of link modeling such as citation and coauthor links in document networks. In the citation network, the MRTM models the citation link between each pair of documents as a binary variable conditioned on their topic distributions. In the coauthor network, the MRTM models the coauthor link between each pair of authors as a binary variable conditioned on their expertise distributions. The topic discovery is collectively regularized by multiple relations in both citation and coauthor networks. This model can summarize topics from the document network, predict citation links between documents and coauthor links between authors. Efficient inference and learning algorithms are derived based on Gibbs sampling. Experiments demonstrate that the MRTM significantly outperforms other state-of-the-art single-relational link modeling methods for large scientific document networks.

#index 1318683
#* Learning Local Components to Understand Large Bayesian Networks
#@ Yifeng Zeng;Yanping Xiang;Jorge Cordero H.;Yujian Lin
#t 2009
#c 18
#! Bayesian networks are known for providing an intuitive and compact representation of probabilistic information and allowing the creation of models over a large and complex domain. Bayesian learning and reasoning are nontrivial for a large Bayesian network. In parallel, it is a tough job for users (domain experts) to extract accurate information from a large Bayesian network due to dimensional difficulty. We define a formulation of local components and propose a clustering algorithm to learn such local components given complete data. The algorithm groups together most inter-relevant attributes in a domain. We evaluate its performance on three benchmark Bayesian networks and provide results in support. We further show that the learned components may represent local knowledge more precisely in comparison to the full Bayesian networks when working with a small amount of data.

#index 1318684
#* A Cost-Effective LSH Filter for Fast Pairwise Mining
#@ Gang Zhao;Yun Xiong;Longbing Cao;Dan Luo;Xuchun Su;Yangyong Zhu
#t 2009
#c 18
#! The pairwise mining problem is to discover pairwise objects having measures greater than the user-specified minimum threshold from a collection of objects. It is essential in a large variety of database and data-mining applications. Of late, there has been increasing interest in applying a Locality-Sensitive Hashing (LSH) scheme for pairwise mining. LSH-type methods have shown themselves to be simply implementable and capable of achieving significant performance gain in running time over most exact methods. However, the present LSH-type methods still suffer from some bottlenecks, such as ”the curse of threshold”. In this paper, we proposed a novel LSHbased method, namely Cost-effective LSH filter (Ce-LSH for short), for pairwise mining. Compared with previous LSH-type methods, it uses a lower fixed number of LSH functions and is thus more cost-effective. Substantial experiments evidence that our method gives significant improvement in running time over existing LSH-type methods and some recently reported method based on upper-bound. Experimental results also indicate that it scales well even for a relatively low minimum threshold and for a fairly small miss ratio.

#index 1318685
#* Semi-Markov kMeans Clustering and Activity Recognition from Body-Worn Sensors
#@ Matthew W. Robards;Peter Sunehag
#t 2009
#c 18
#! Subsequence clustering aims to find patterns that appear repeatedly in time series data. We introduce a novel subsequence clustering technique that we call semi-Markov kmeans clustering. The clustering results in ideal examples of the repeating patterns and in labeled segmentations that can be used as training data for sophisticated discriminative methods like max-margin semi-Markov models. We are applying the new clustering technique to activity recognition from body-worn sensors by showing how it can enable a system to learn from data that is only annotated by an ordered list of activity types that have been undertaken. This kind of annotation, unlike a detailed segmentation of the sensor data, is easily provided by a non-expert user. We show that we can achieve equally good results using only an ordered list of activity types for training as when using a full detailed labeled segmentation.

#index 1318686
#* A Sparsification Approach for Temporal Graphical Model Decomposition
#@ Ning Ruan;Ruoming Jin;Victor E. Lee;Kun Huang
#t 2009
#c 18
#! Temporal causal modeling can be used to recover the causal structure among a group of relevant time series variables. Several methods have been developed to explicitly construct temporal causal graphical models. However, how to best understand and conceptualize these complicated causal relationships is still an open problem. In this paper, we propose a decomposition approach to simplify the temporal graphical model. Our method clusters time series variables into groups such that strong interactions appear among the variables within each group and weak (or no) interactions exist for cross-group variable pairs. Specifically, we formulate the clustering problem for temporal graphical models as a regression-coefficient sparsification problem and define an interesting objective function which balances the model prediction power and its cluster structure. We introduce an iterative optimization approach utilizing the Quasi-Newton method and generalized ridge regression to minimize the objective function and to produce a clustered temporal graphical model. We also present a novel optimization procedure utilizing a graph theoretical tool based on the maximum weight independent set problem to speed up the Quasi-Newton method for a large number of variables. Finally, our detailed experimental study on both synthetic and real datasets demonstrates the effectiveness of our methods.

#index 1318687
#* Resolving Identity Uncertainty with Learned Random Walks
#@ Ted Sandler;Lyle H. Ungar;Koby Crammer
#t 2009
#c 18
#! A pervasive problem in large relational databases is identity uncertainty which occurs when multiple entries in a database refer to the same underlying entity in the world. Relational databases exhibit rich graphical structure and are naturally modeled as graphs whose nodes represent entities and whose typed-edges represent relations between them. We propose using random walk models for resolving identity uncertainty since they have proven effective for finding points which are proximately located in a network. Because not all types of relations are equally helpful in alleviating identity uncertainty, we develop a supervised approach to learning the usefulness of different database relations from a training set of database entries whose true identities are known. When tested on the task of resolving uncertainty of ambiguously named authors in bibliographical data, the learned random walk models yield performance superior to support vector machines, and to a related spectral clustering method.

#index 1318688
#* Discriminative Mixed-Membership Models
#@ Hanhuai Shan;Arindam Banerjee;Nikunj C. Oza
#t 2009
#c 18
#! Although mixed-membership models have achieved great success in unsupervised learning, they have not been widely applied to classification problems. In this paper, we propose a family of discriminative mixed-membership models for classification by combining unsupervised mixed-membership models with multi-class logistic regression. In particular, we propose two variants respectively applicable to text classification based on latent Dirichlet allocation and usual feature vector classification based on mixed-membership naive Bayes models. The proposed models allow the number of components in the mixed membership to be different from the number of classes. We propose two variational inference based algorithms for learning the models, including a fast variational inference which is substantially more efficient than mean-field variational approximation. Through extensive experiments on UCI and text classification benchmark datasets, we show that the models are competitive with the state of the art, and can discover components not explicitly captured by the class labels.

#index 1318689
#* Extending Semi-supervised Learning Methods for Inductive Transfer Learning
#@ Yuan Shi;Zhenzhong Lan;Wei Liu;Wei Bi
#t 2009
#c 18
#! Inductive transfer learning and semi-supervised learning are two different branches of machine learning. The former tries to reuse knowledge in labeled out-of-domain instances while the later attempts to exploit the usefulness of unlabeled in-domain instances. In this paper, we bridge the two branches by pointing out that many semi-supervised learning methods can be extended for inductive transfer learning, if the step of labeling an unlabeled instance is replaced by re-weighting a diff-distribution instance. Based on this recognition, we develop a new transfer learning method, namely COITL, by extending the co-training method in semi-supervised learning. Experimental results reveal that COITL can achieve significantly higher generalization and robustness, compared with two state-of-the-art methods in inductive transfer learning.

#index 1318690
#* A New Kernel-Based Classification Algorithm
#@ Xiaofei Zhou;Wenhan Jiang;Yingjie Tian;Peng Zhang;Guangli Nie;Yong Shi
#t 2009
#c 18
#! A new kernel-based learning algorithm called kernel affine subspace nearest point (KASNP) approach is proposed in this paper. Inspired by the geometrical explanation of Support Vector Machines (SVMs) and its nearest point problem in convex hulls, we extend the convex hull of each class to its corresponding affine subspace in high dimensional space induced by kernel. In two class affine subspaces, KASNP finds the nearest points and then constructs a separating hyperplane, which bisects the line segment joining them. The nearest point problem of KASNP is only an unconstrained optimal problem whose solution can be directly computed. Compared with SVM, KASNP avoids solving convex quadratic programming. Experiments on two-spiral dataset, two UCI credit datasets, and face recognition datasets show that our proposed KASNP is effective for data classification.

#index 1318691
#* iTopicModel: Information Network-Integrated Topic Modeling
#@ Yizhou Sun;Jiawei Han;Jing Gao;Yintao Yu
#t 2009
#c 18
#! Document networks, i.e., networks associated with text information, are becoming increasingly popular due to the ubiquity of Web documents, blogs, and various kinds of online data. In this paper, we propose a novel topic modeling framework for document networks, which builds a unified generative topic model that is able to consider both text and structure information for documents. A graphical model is proposed to describe the generative model. On the top layer of this graphical model, we define a novel multivariate Markov Random Field for topic distribution random variables for each document, to model the dependency relationships among documents over the network structure. On the bottom layer, we follow the traditional topic model to model the generation of text for each document. A joint distribution function for both the text and structure of the documents is thus provided. A solution to estimate this topic model is given, by maximizing the log-likelihood of the joint probability. Some important practical issues in real applications are also discussed, including how to decide the topic number and how to choose a good network structure. We apply the model on two real datasets, DBLP and Cora, and the experiments show that this model is more effective in comparison with the state-of-the-art topic modeling algorithms.

#index 1318692
#* Uncoverning Groups via Heterogeneous Interaction Analysis
#@ Lei Tang;Xufei Wang;Huan Liu
#t 2009
#c 18
#! With the pervasive availability of Web 2.0 and social networking sites, people can interact with each other easily through various social media. For instance, popular sites like Del.icio.us, Flickr, and YouTube allow users to comment shared content (bookmark, photos, videos), and users can tag their own favorite content. Users can also connect to each other, and subscribe to or become a fan or a follower of others. These diverse individual activities result in a multi-dimensional network among actors, forming cross-dimension group structures with group members sharing certain similarities. It is challenging to effectively integrate the network information of multiple dimensions in order to discover cross-dimension group structures. In this work, we propose a two-phase strategy to identify the hidden structures shared across dimensions in multi-dimensional networks. We extract structural features from each dimension of the network via modularity analysis, and then integrate them all to find out a robust community structure among actors. Experiments on synthetic and real-world data validate the superiority of our strategy, enabling the analysis of collective behavior underneath diverse individual activities in a large scale.

#index 1318693
#* Significance of Episodes Based on Minimal Windows
#@ Nikolaj Tatti
#t 2009
#c 18
#! Discovering episodes, frequent sets of events from a sequence has been an active field in pattern mining. Traditionally, a level-wise approach is used to discover all frequent episodes. While this technique is computationally feasible it may result in a vast number of patterns, especially when low thresholds are used. In this paper we propose a new quality measure for episodes. We say that an episode is significant if the average length of its minimal windows deviates greatly when compared to the expected length according to the independence model. We can apply this measure as a post-pruning step to test whether the discovered frequent episodes are truly interesting and consequently to reduce the number of output. As a main contribution we introduce a technique that allows us to compute the distribution of lengths of minimal windows using the independence model. Such a computation task is surpisingly complex and in order to solve it we compute the distribution iteratively starting from simple episodes and progressively moving towards the more complex ones. In our experiments we discover candidate episodes that have a sufficient amount of minimal windows and test each candidate for significance. The experimental results demonstrate that our approach finds significant episodes while ignoring uninteresting ones.

#index 1318694
#* Convex Non-negative Matrix Factorization in the Wild
#@ Christian Thurau;Kristian Kersting;Christian Bauckhage
#t 2009
#c 18
#! Non-negative matrix factorization (NMF) has recently received a lot of attention in data mining, information retrieval, and computer vision. It factorizes a non-negative input matrix V into two non-negative matrix factors V = WH such that W describes "clusters" of the datasets. Analyzing genotypes, social networks, or images, it can be beneficial to ensure V to contain meaningful ``cluster centroids'', i.e., to restrict W to be convex combinations of data points. But how can we run this convex NMF in the wild, i.e., given millions of data points? Triggered by the simple observation that each data point is a convex combination of vertices of the data convex hull, we propose to restrict W further to be vertices of the convex hull. The benefits of this convex-hull NMF approach are twofold. First, the expected size of the convex hull of the candidate set typically grows much slower than the data set. Second, distance preserving low-dimensional embeddings allow one to compute candidate vertices efficiently. Our extensive experimental evaluation shows that convex-hull NMF compares favorably to convex NMF for large data sets both in terms of speed and reconstruction quality. Moreover, we show that our method can easily be applied to large-scale, real-world data sets, in our case consisting of 1.6 million images respectively 160 million votes on World of Warcraft guilds.

#index 1318695
#* On K-Means Cluster Preservation Using Quantization Schemes
#@ Deepak S. Turaga;Michail Vlachos;Olivier Verscheure
#t 2009
#c 18
#! This work examines under what conditions compression methodologies can retain the outcome of clustering operations. We focus on the popular k-Means clustering algorithm and we demonstrate how a properly constructed compression scheme based on post-clustering quantization is capable of maintaining the global cluster structure. Our analytical derivations indicate that a 1-bit moment preserving quantizer per cluster is sufficient to retain the original data clusters. Merits of the proposed compression technique include: a) reduced storage requirements with clustering guarantees, b) data privacy on the original values, and c) shape preservation for data visualization purposes. We evaluate quantization scheme on various high-dimensional datasets, including 1-dimensional and 2-dimensional time-series (shape datasets) and demonstrate the cluster preservation property. We also compare with previously proposed simplification techniques in the time-series area and show significant improvements both on the clustering and shape preservation of the compressed datasets.

#index 1318696
#* Scalable Classification in Large Scale Spatiotemporal Domains Applied to Voltage-Sensitive Dye Imaging
#@ Igor Vainer;Sarit Kraus;Gal Kaminka;Hamutal Slovin
#t 2009
#c 18
#! We present an approach for learning models that obtain accurate classification of large scale data objects, collected in spatiotemporal domains. The model generation is structured in three phases: pixel selection (spatial dimension reduction), spatiotemporal features extraction and feature selection. Novel techniques for the first two phases are presented, with two alternatives for the middle phase. Model generation based on the combinations of techniques from each phase is explored. The introduced methodology is applied on datasets from the Voltage-Sensitive Dye Imaging (VSDI) domain, where the generated classification models successfully decode neuronal population responses in the visual cortex of behaving animals. VSDI currently is the best technique enabling simultaneous high spatial (10,000 points) and temporal (10 ms or less) resolution imaging from neuronal population in the cortex. We demonstrate that not only our approach is scalable enough to handle computationally challenging data, but it also contributes to the neuroimaging field of study with its decoding abilities.

#index 1318697
#* Extracting Output Metadata from Scientific Deep Web Data Sources
#@ Fan Wang;Gagan Agrawal
#t 2009
#c 18
#! Increasingly, many data sources appear as online databases, hidden behind query forms, thus forming the deep web. The popularity of this new medium for data dissemination is leading to new problems in data integration. Particularly, to enable data integration from multiple deep web data sources, one needs to obtain the metadata for each of the data sources. Obtaining the metadata, particularly, the output schema, can be very challenging. This is because, given an input query, many deep web data sources only return a subset of the output schema attributes, i.e, the ones that have a non-NULL value for the corresponding input. In this paper, we propose two approaches, which are the sampling model approach and the mixture model approach, respectively, to efficiently obtain an approximately complete set of output schema attributes from a deep web data source. Our experiments show while each of the above two approaches has limitations, a hybrid strategy, where we combine the two approaches, achieves high recall with good precision for most data sources.

#index 1318698
#* Semi-supervised Multi-task Learning with Task Regularizations
#@ Fei Wang;Xin Wang;Tao Li
#t 2009
#c 18
#! Multi-task learning refers to the learning problem of performing inference by jointly considering multiple related tasks. There have already been many research efforts on supervised multi-task learning. However, collecting sufficient labeled data for each task is usually time consuming and expensive. In this paper, we consider the semi-supervised multitask learning (SSMTL) problem, where we are given a small portion of labeled points together with a large pool of unlabeled data within each task. We assume that the different tasks can form some task clusters and the task in the same cluster share similar classifier parameters. The final learning problem is relaxed to a convex one and an efficient gradient descent strategy is proposed. Finally the experimental results on both synthetic and real world data sets are presented to show the effectiveness of our method.

#index 1318699
#* Fast Online Training of Ramp Loss Support Vector Machines
#@ Zhuang Wang;Slobodan Vucetic
#t 2009
#c 18
#! A fast online algorithm OnlineSVMR for training Ramp-Loss Support Vector Machines (SVMRs) is proposed. It finds the optimal SVMR for t+1 training examples using SVMR built on t previous examples. The algorithm retains the Karush–Kuhn–Tucker conditions on all previously observed examples. This is achieved by an SMO-style incremental learning and decremental unlearning under the Concave-Convex Procedure framework. Further speedup of training time could be achieved by dropping the requirement of optimality. A variant, called OnlineASVMR, is a greedy approach that approximately optimizes the SVMR objective function and is suitable for online active learning. The proposed algorithms were comprehensively evaluated on 9 large benchmark data sets. The results demonstrate that OnlineSVMR (1) has the similar computational cost as its offline counterpart; (2) outperforms IDSVM, its competing online algorithm that uses hinge-loss, in terms of accuracy, model sparsity and training time. The experiments on online active learning show that for a fixed number of label queries OnlineASVMR (1) achieves consistently better accuracy than QueryAll and competitive accuracy to Greedy approach; (2) outperforms the active learning version of IDSVM.

#index 1318700
#* Mining Peculiarity Groups in Day-by-Day Behavioral Datasets
#@ Yun Xiong;Yangyong Zhu
#t 2009
#c 18
#! Behavior mining is one of the most important issues in data mining. The growing interest in the study of behavior mining has been credited to the availability of a large amount of individual behavioral data. Some objects containing common behavioral patterns in the dataset are dramatically different from other individual objects and show their peculiarities. It is very important for behavior analysis to mine these peculiar objects' groups as this has great potential in practice. However, to the best of our knowledge, it has not been explored before. In this paper, we identify this interesting and practical problem of behavior mining: mining peculiarity groups and defining a measurement of the degree of peculiarity. As the first attempt to tackle the problem, we present a set-value-oriented day-by-day behavioral data expression mode considering that daily behaviors with respect to an object should be recorded as a set of behaviors, and devise a peculiarity group mining algorithm in view of the set-value-oriented data expression which cannot be very well handled by existing methods. Furthermore, we show that our method is practical and efficient using real datasets.

#index 1318701
#* Online System Problem Detection by Mining Patterns of Console Logs
#@ Wei Xu;Ling Huang;Armando Fox;David Patterson;Michael Jordan
#t 2009
#c 18
#! We describe a novel application of using data mining and statistical learning methods to automatically monitor and detect abnormal execution traces from console logs in an online setting. Different from existing solutions, we use a two stage detection system. The first stage uses frequent pattern mining and distribution estimation techniques to capture the dominant patterns (both frequent sequences and time duration). The second stage use principal component analysis based anomaly detection technique to identify actual problems. Using real system data from a 203-node Hadoop [1] cluster, we show that we can not only achieve highly accurate and fast problem detection, but also help operators better understand execution patterns in their system.

#index 1318702
#* Synthesizing Novel Dimension Reduction Algorithms in Matrix Trace Oriented Optimization Framework
#@ Jun Yan;Ning Liu;Shuicheng Yan;Qiang Yang;Zheng Chen
#t 2009
#c 18
#! Dimension Reduction (DR) algorithms are generally categorized into feature extraction and feature selection algorithms. In the past, few works have been done to contrast and unify the two algorithm categories. In this work, we introduce a matrix trace oriented optimization framework to provide a unifying view for both feature extraction and selection algorithms. We show that the unified view of DR algorithms allows us to discover some essential relationships among many state-of- the-art DR algorithms. Inspired by these essential insights, we propose to synthesize unlimited number of novel DR algorithms by combining, mapping and integrating the state- of-the-art algorithms. We present examples of newly synthesized DR algorithms with experimental results to show the effectiveness of our automatically synthesized algorithms.

#index 1318703
#* Peculiarity Analysis for Classifications
#@ Jian Yang;Ning Zhong;Yiyu Yao;Jue Wang
#t 2009
#c 18
#! Peculiarity-oriented mining (POM) is a new data mining method consisting of peculiar data identification and peculiar data analysis. Peculiarity factor (PF) and local peculiarity factor (LPF) are important concepts employed to describe the peculiarity of points in the identification step. One can study the notions at both attribute and record levels. In this paper, a new record LPF called distance based record LPF (D-record LPF) is proposed, which is defined as the sum of distances between a point and its nearest neighbors. It is proved mathematically that D-record LPF can characterize accurately the probability density function of a continuous m-dimensional distribution. This provides a theoretical basis for some existing distance based anomaly detection techniques. More important, it also provides an effective method for describing the class conditional probabilities in the Bayesian classifier. The result enables us to apply peculiarity analysis for classification problems. A novel algorithm called LPF-Bayes classifier and its kernelized implementation are presented, which have some connection to the Bayesian classifier. Experimental results on several benchmark data sets demonstrate that the proposed classifiers are effective.

#index 1318704
#* Filtering and Refinement: A Two-Stage Approach for Efficient and Effective Anomaly Detection
#@ Xiao Yu;Lu An Tang;Jiawei Han
#t 2009
#c 18
#! Anomaly detection is an important data mining task. Most existing methods treat anomalies as inconsistencies and spend the majority amount of time on modeling normal instances. A recently proposed, sampling-based approach may substantially boost the efficiency in anomaly detection but may also lead to weaker accuracy and robustness. In this study, we propose a two-stage approach to find anomalies in complex datasets with high accuracy as well as low time complexity and space cost. Instead of analyzing normal instances, our algorithm first employs an efficient deterministic space partition algorithm to eliminate obvious normal instances and generates a small set of anomaly candidates with a single scan of the dataset. It then checks each candidate with density-based multiple criteria to determine the final results. This two-stage framework also detects anomalies of different notions. Our experiments show that this new approach finds anomalies successfully in different conditions and ensures a good balance of efficiency, accuracy, and robustness.

#index 1318705
#* Mining Data Streams with Labeled and Unlabeled Training Examples
#@ Peng Zhang;Xingquan Zhu;Li Guo
#t 2009
#c 18
#! In this paper, we propose a framework to build prediction models from data streams which contain both labeled and unlabeled examples. We argue that due to the increasing data collection ability but limited resources for labeling, stream data collected at hand may only have a small number of labeled examples, whereas a large portion of data remain unlabeled but can be beneficial for learning. Unleashing the full potential of the unlabeled instances for stream data mining is, however, a significant challenge, consider that even fully labeled data streams may suffer from the concept drifting, and inappropriate uses of the unlabeled samples may only make the problem even worse. To build prediction models, we first categorize the stream data into four different categories, each of which corresponds to the situation where concept drifting may or may not exist in the labeled and unlabeled data. After that, we propose a relational k-means based transfer semi-supervised SVM learning framework (RK-TS3VM), which intends to leverage labeled and unlabeled samples to build prediction models. Experimental results and comparisons on both synthetic and real-world data streams demonstrate that the proposed framework is able to help build prediction models more accurate than other simple approaches can offer.

#index 1318706
#* Maximum Margin Clustering with Multivariate Loss Function
#@ Bin Zhao;James Kwok;Changshui Zhang
#t 2009
#c 18
#! This paper presents a simple but powerful extension of the maximum margin clustering (MMC) algorithm that optimizes multivariate performance measure specifically defined for clustering, including Normalized Mutual In- formation, Rand Index and F-measure. Different from previous MMC algorithms that always employ the error rate as the loss function, our formulation involves a multivariate loss function that is a non-linear combination of the individual clustering results. Computationally, we propose a cutting plane algorithm to approximately solve the resulting optimization problem with a guaranteed accuracy. Experimental evaluations show clear improvements in clustering performance of our method over previous maximum margin clustering algorithms.

#index 1318707
#* Efficient Discovery of Confounders in Large Data Sets
#@ Wenjun Zhou;Hui Xiong
#t 2009
#c 18
#! Given a large transaction database, association analysis is concerned with efficiently finding strongly related objects. Unlike traditional associate analysis, where relationships among variables are searched at a global level, we examine confounding factors at a local level. Indeed, many real-world phenomena are localized to specific regions and times. These relationships may not be visible when the entire data set is analyzed. Specially, confounding effects that change the direction of correlation is the most significant. Along this line, we propose to efficiently find confounding effects attributable to local associations. Specifically, we derive an upper bound by a necessary condition of confounders, which can help us prune the search space and efficiently identify confounders. Experimental results show that the proposed CONFOUND algorithm can effectively identify confounders and the computational performance is an order of magnitude faster than benchmark methods.

#index 1318708
#* Vague One-Class Learning for Data Streams
#@ Xingquan Zhu;Xindong Wu;Chengqi Zhang
#t 2009
#c 18
#! In this paper, we formulate a new research problem of learning from vaguely labeled one-class data streams, where the main objective is to allow users to label instance groups, instead of single instances, as positive samples for learning. The batch-labeling, however, raises serious issues because labeled groups may contain non-positive samples, and users may change their labeling interests at any time. To solve this problem, we propose a Vague One-Class Learning (VOCL) framework which employs a double weighting approach, at both instance and classifier levels, to build an ensembling framework for learning. At instance level, both local and global filterings are considered for instance weight adjustment. Two solutions are proposed to take instance weight values into the classifier training process. At classifier level, a weight value is assigned to each classifier of the ensemble to ensure that learning can quickly adapt to users’ interests. Experimental results on synthetic and real-world data streams demonstrate that the proposed VOCL framework significantly outperforms other methods for vaguely labeled one-class data streams.

#index 1318709
#* Inverse Time Dependency in Convex Regularized Learning
#@ Zeyuan Allen Zhu;Weizhu Chen;Chenguang Zhu;Gang Wang;Haixun Wang;Zheng Chen
#t 2009
#c 18
#! In the conventional regularized learning, training time increases as the training set expands. Recent work on L2 linear SVM challenges this common sense by proposing the inverse time dependency on the training set size. In this paper, we first put forward a Primal Gradient Solver (PGS) to effectively solve the convex regularized learning problem. This solver is based on the stochastic gradient descent method and the Fenchel conjugate adjustment, employing the well-known online strongly convex optimization algorithm with logarithmic regret. We then theoretically prove the inverse dependency property of our PGS, embracing the previous work of the L2 linear SVM as a special case and enable the l_p-norm optimization to run within a bounded sphere, which qualifies more convex loss functions in PGS. We further illustrate this solver in three examples: SVM, logistic regression and regularized least square. Experimental results substantiate the property of the inverse dependency on training data size.

#index 1318710
#* P-packSVM: Parallel Primal grAdient desCent Kernel SVM
#@ Zeyuan Allen Zhu;Weizhu Chen;Gang Wang;Chenguang Zhu;Zheng Chen
#t 2009
#c 18
#! It is an extreme challenge to produce a nonlinear SVM classifier on very large scale data. In this paper we describe a novel P-packSVM algorithm that can solve the Support Vector Machine (SVM) optimization problem with an arbitrary kernel. This algorithm embraces the best known stochastic gradient descent method to optimize the primal objective, and has 1/ϵ dependency in complexity to obtain a solution of optimization error ϵ. The algorithm can be highly parallelized with a special packing strategy, and experiences sub-linear speed-up with hundreds of processors. We demonstrate that P-packSVM achieves accuracy sufficiently close to that of SVM-light, and overwhelms the state-of-the-art parallel SVM trainer PSVM in both accuracy and efficiency. As an illustration, our algorithm trains CCAT dataset with 800k samples in 13 minutes and 95% accuracy, while PSVM needs 5 hours but only has 92% accuracy. We at last demonstrate the capability of P-packSVM on 8 million training samples.

#index 1318711
#* An L-infinity Norm Visual Classifier
#@ Anushka Anand;Leland Wilkinson;Dang Nhon Tuan
#t 2009
#c 18
#! We introduce a mathematical framework, based on the L-infinity norm distance metric, to describe human interactions in a visual data mining environment. We use the framework to build a classifier that involves an algebra on hyper-rectangles. Our classifier, called VisClassifier, generates set-wise rules from simple gestures in an exploratory visual GUI. Logging these rules allows us to apply our analysis to a new sample or batch of data so that we can assess the predictive power of our visual-processing motivated classifier. The accuracy of this classifier on widely-used benchmark datasets rivals the accuracy of competitive classifiers.

#index 1318712
#* Outlier Detection Using Inductive Logic Programming
#@ Fabrizio Angiulli;Fabio Fassetti
#t 2009
#c 18
#! We present a novel definition of outlier in the context of inductive logic programming. Given a set of positive and negative examples, the definition aims at singling out the examples showing anomalous behavior. We note that the task here pursued is different from noise removal, and, in fact, the anomalous observations we discover are different in nature from noisy ones. We discuss pecularities of the novel approach, present an algorithm for detecting outliers, discuss some examples of knowledge mined, and compare it with alternative approaches.

#index 1318713
#* Joint Emotion-Topic Modeling for Social Affective Text Mining
#@ Shenghua Bao;Shengliang Xu;Li Zhang;Rong Yan;Zhong Su;Dingyi Han;Yong Yu
#t 2009
#c 18
#! This paper is concerned with the problem of social affective text mining, which aims to discover the connections between social emotions and affective terms based on user-generated emotion labels. We propose a joint emotion-topic model by augmenting latent Dirichlet allocation with an additional layer for emotion modeling. It first generates a set of latent topics from emotions, followed by generating affective terms from each topic. Experimental results on an online news collection show that the proposed model can effectively identify meaningful latent topics for each emotion. Evaluation on emotion prediction further verifies the effectiveness of the proposed model.

#index 1318714
#* Algorithms for Large, Sparse Network Alignment Problems
#@ Mohsen Bayati;Margot Gerritsen;David F. Gleich;Amin Saberi;Ying Wang
#t 2009
#c 18
#! We propose a new distributed algorithm for sparse variants of the network alignment problem, which occurs in a variety of data mining areas including systems biology, database matching, and computer vision. Our algorithm uses a belief propagation heuristic and provides near optimal solutions for this NP-hard combinatorial optimization problem. We show that our algorithm is faster and outperforms or ties existing algorithms on synthetic problems, a problem in bioinformatics, and a problem in ontology matching. We also provide a unified framework for studying and comparing all network alignment solvers.

#index 1318715
#* Dirichlet Mixture Allocation for Multiclass Document Collections Modeling
#@ Wei Bian;Dacheng Tao
#t 2009
#c 18
#! Topic model, Latent Dirichlet Allocation (LDA), is an effective tool for statistical analysis of large collections of documents. In LDA, each document is modeled as a mixture of topics and the topic proportions are generated from the unimodal Dirichlet distribution prior. When a collection of documents are drawn from multiple classes, this unimodal prior is insufficient for data fitting. To solve this problem, we exploit the multimodal Dirichlet mixture prior, and propose the Dirichlet mixture allocation (DMA). We report experiments on the popular TDT2 Corpus demonstrating that DMA models a collection of documents more precisely than LDA when the documents are obtained from multiple classes.

#index 1318716
#* SLIDER: Mining Correlated Motifs in Protein-Protein Interaction Networks
#@ Peter Boyen;Frank Neven;Dries Van Dyck;Aalt-Jan van Dijk;Roeland C. H. J. van Ham
#t 2009
#c 18
#! Correlated motif mining (CMM) is the problem to find overrepresented pairs of patterns, called motif pairs, in interacting protein sequences. Algorithmic solutions for CMM thereby provide a computational method for predicting binding sites for protein interaction. In this paper, we adopt a motif-driven approach where the support of candidate motif pairs is evaluated in the network. We experimentally establish the superiority of the Chi-square-based support measure over other support measures. Furthermore, we obtain that CMM is an NP-hard problem for a large class of support measures (including Chi-square) and reformulate the search for correlated motifs as a combinatorial optimization problem. We then present the method SLIDER which uses local search with a neighborhood function based on sliding motifs and employs the Chi-square-based support measure. We show that SLIDER outperforms existing motif-driven CMM methods and scales to large protein-protein interaction networks.

#index 1318717
#* Effective Anomaly Detection in Sensor Networks Data Streams
#@ Saha Budhaditya;Duc-Son Pham;Mihai Lazarescu;Svetha Venkatesh
#t 2009
#c 18
#! This paper addresses a major challenge in data mining applications where the full information about the underlying processes, such as sensor networks or large online database, cannot be practically obtained due to physical limitations such as low bandwidth or memory, storage, or computing power. Motivated by the recent theory on direct information sampling called compressed sensing (CS), we propose a framework for detecting anomalies from these large-scale data mining applications where the full information is not practically possible to obtain. Exploiting the fact that the intrinsic dimension of the data in these applications are typically small relative to the raw dimension and the fact that compressed sensing is capable of capturing most information with few measurements, our work show that spectral methods that used for volume anomaly detection can be directly applied to the CS data with guarantee on performance. Our theoretical contributions are supported by extensive experimental results on large datasets which show satisfactory performance.

#index 1318718
#* Hierarchical Bayesian Models for Collaborative Tagging Systems
#@ Markus Bundschus;Shipeng Yu;Volker Tresp;Achim Rettinger;Mathaeus Dejori;Hans-Peter Kriegel
#t 2009
#c 18
#! Collaborative tagging systems with user generated content have become a fundamental element of websites such as Delicious, Flickr or CiteULike. By sharing common knowledge, massively linked semantic data sets are generated that provide new challenges for data mining. In this paper, we reduce the data complexity in these systems by finding meaningful topics that serve to group similar users and serve to recommend tags or resources to users. We propose a well-founded probabilistic approach that can model every aspect of a collaborative tagging system. By integrating both user information and tag information into the well-known Latent Dirichlet Allocation framework, the developed models can be used to solve a number of important information extraction and retrieval tasks.

#index 1318719
#* Efficient Algorithm for Computing Link-Based Similarity in Real World Networks
#@ Yuanzhe Cai;Gao Cong;Xu Jia;Hongyan Liu;Jun He;Jiaheng Lu;Xiaoyong Du
#t 2009
#c 18
#! Similarity calculation has many applications, such as information retrieval, and collaborative filtering, among many others. It has been shown that link-based similarity measure, such as SimRank, is very effective in characterizing the object similarities in networks, such as the Web, by exploiting the object-to-object relationship. Unfortunately, it is prohibitively expensive to compute the link-based similarity in a relatively large graph. In this paper, based on the observation that link-based similarity scores of real world graphs follow the power-law distribution, we propose a new approximate algorithm, namely Power-SimRank, with guaranteed error bound to efficiently compute link-based similarity measure. We also prove the convergence of the proposed algorithm. Extensive experiments conducted on real world datasets and synthetic datasets show that the proposed algorithm outperforms SimRank by four-five times in terms of efficiency while the error generated by the approximation is small.

#index 1354578
#* 2008 IEEE International Conference on Data Mining Workshops
#@ F. Bonchi
#t 2009
#c 18

#index 1398303
#* Proceedings of the 7th industrial conference on Advances in data mining: theoretical aspects and applications
#@ Petra Perner
#t 2007
#c 18

#index 1398304
#* Case based reasoning and the search for knowledge
#@ Michael M. Richter
#t 2007
#c 18
#% 176887
#% 490944
#% 494596
#% 494597
#% 866949
#% 1476276
#! A major goal of this paper is to compare Case Based Reasoning with other methods searching for knowledge. We consider knowledge as a resource that can be traded. It has no value in itself; the value is measured by the usefulness of applying it in some process. Such a process has info-needs that have to be satisfied. The concept to measure this is the economical term utility. In general, utility depends on the user and its context, i.e., it is subjective. Here we introduce levels of context from general to individual. We illustrate that Case Based Reasoning on the lower, i.e., more personal levels CBR is quite useful, in particular in comparison with traditional informational retrieval methods.

#index 1398305
#* Subsets more representative than random ones
#@ Ilia Nouretdinov
#t 2007
#c 18
#% 464286
#% 466258
#% 1273833
#% 1650581
#! Suppose we have a database that describes a set of objects, and our aim is to find its representative subset of a smaller size. Representativeness here means the measure of quality of prediction when the subset is used instead of the whole set in a typical machine learning procedure. We research how to find a subset that is more representative than a random selection of the same size.

#index 1398306
#* Concepts for novelty detection and handling based on a case-based reasoning process scheme
#@ Petra Perner
#t 2007
#c 18
#% 345829
#% 374537
#% 397133
#% 443158
#% 731721
#% 731722
#% 739899
#% 740757
#% 798820
#% 891559
#% 939943
#% 1046491
#% 1345404
#! Novelty detection, the ability to identify new or unknown situations that were never experienced before, is useful for intelligent systems aspiring to operate in environments where data are acquired incrementally. This characteristic is common to numerous problems in medical diagnosis and visual perception. We propose to see novelty detection as a case-based reasoning process. Our novelty-detection method is able to detect the novel situation, as well as to use the novel events for immediate reasoning. To ensure this capacity we combine statistical and similarity inference and learning. This view of CBR takes into account the properties of data, such as the uncertainty, and the underlying concepts, such as storage, learning, retrieval and indexing can be formalized and performed efficiently.

#index 1398307
#* An efficient algorithm for instance-based learning on data streams
#@ Jürgen Beringer;Eyke Hüllermeier
#t 2007
#c 18
#% 5182
#% 92533
#% 204531
#% 209023
#% 229947
#% 246243
#% 342600
#% 378388
#% 458245
#% 458300
#% 466408
#% 480825
#% 548654
#% 576119
#% 577221
#% 578560
#% 729932
#% 810542
#% 824795
#% 926881
#% 998561
#% 1016144
#% 1673562
#! The processing of data streams in general and the mining of such streams in particular have recently attracted considerable attention in various research fields. A key problem in stream mining is to extend existing machine learning and data mining methods so as to meet the increased requirements imposed by the data stream scenario, including the ability to analyze incoming data in an online, incremental manner, to observe tight time and memory constraints, and to appropriately respond to changes of the data characteristics and underlying distributions, amongst others. This paper considers the problem of classification on data streams and develops an instance-based learning algorithm for that purpose. The experimental studies presented in the paper suggest that this algorithm has a number of desirable properties that are not, at least not as a whole, shared by currently existing alternatives. Notably, our method is very flexible and thus able to adapt to an evolving environment quickly, a point of utmost importance in the data stream context. At the same time, the algorithm is relatively robust and thus applicable to streams with different characteristics.

#index 1398308
#* Softening the margin in discrete SVM
#@ Carlotta Orsenigo;Carlo Vercellis
#t 2007
#c 18
#% 190581
#% 309208
#% 393059
#% 420077
#% 722756
#% 722943
#% 1000316
#% 1290045
#! Discrete support vector machines are models for classification recently introduced in the context of statistical learning theory. Their distinctive feature is the formulation of mixed integer programming problems aimed at deriving optimal separating hyperplanes with minimum empirical error and maximum generalization capability. A new family of discrete SVM is proposed in this paper, for which the hyperplane establishes a variable softening of the margin to improve the separation among distinct classes. Theoretical bounds are derived to finely tune the parameters of the optimization problem. Computational tests on benchmark datasets in the biolife science application domain indicate the effectiveness of the proposed approach, that appears dominating against traditional SVM in terms of accuracy and percentage of support vectors.

#index 1398309
#* Feature selection using ant colony optimization (ACO): a new method and comparative study in the application of face recognition system
#@ Hamidreza Rashidy Kanan;Karim Faez;Sayyed Mostafa Taheri
#t 2007
#c 18
#% 68777
#% 177826
#% 294103
#% 366687
#% 443306
#% 445216
#% 466205
#% 713207
#% 860400
#% 900161
#% 1681500
#% 1777121
#% 1780532
#! Feature Selection (FS) and reduction of pattern dimensionality is a most important step in pattern recognition systems. One approach in the feature selection area is employing population-based optimization algorithms such as Genetic Algorithm (GA)-based method and Ant Colony Optimization (ACO)- based method. This paper presents a novel feature selection method that is based on Ant Colony Optimization (ACO). ACO algorithm is inspired of ant's social behavior in their search for the shortest paths to food sources. Most common techniques for ACO-Based feature selection use the priori information of features. However, in the proposed algorithm, classifier performance and the length of selected feature vector are adopted as heuristic information for ACO. So, we can select the optimal feature subset without the priori information of features. This approach is easily implemented and because of using one simple classifier in it, its computational complexity is very low. Simulation results on face recognition system and ORL database show the superiority of the proposed algorithm.

#index 1398310
#* Outlier detection with streaming dyadic decomposition
#@ Chetan Gupta;Robert Grossman
#t 2007
#c 18
#% 169292
#% 210173
#% 248790
#% 300136
#% 300183
#% 310537
#% 318790
#% 320942
#% 438137
#% 479791
#% 479799
#% 551620
#% 566132
#% 594012
#% 727930
#% 937189
#% 1016200
#% 1860078
#! In this work we introduce a new algorithm for detecting outliers on streaming data in Rn. The basic idea is to compute a dyadic decomposition into cubes in Rn of the streaming data. Dyadic decomposition can be obtained by recursively bisecting the cube the data lies in. Dyadic decomposition obtained under streaming setting is understood as streaming dyadic decomposition. If we view the streaming dyadic decomposition as a tree with a fixed maximum (and sufficient) size (depth), then outliers are naturally defined by cubes that contain a small number of points in the cube itself or the cube itself and its neighboring cubes. We discuss some properties of detecting outliers with streaming dyadic decomposition and we present experimental results over real and artificial data sets.

#index 1398311
#* VISRED: numerical data mining with linear and nonlinear techniques
#@ Antonio Dourado;Edgar Ferreira;Paulo Barbeiro
#t 2007
#c 18
#% 231845
#% 391311
#% 577961
#% 1786334
#% 1861181
#! Numerical data mining is a task for which several techniques have been developed that can provide a quick insight into a practical problem, if an easy to use common software platform is available. VISRED- Data Visualisation by Space Reduction presented here, aims to be such a tool for data classification and clustering. It allows the quick application of Principal Component Analysis, Nonlinear Principal Component Analysis, Multi-dimensional Scaling (classical and non classical). For clustering several techniques have been included: hierarchical, k-means, subtractive, fuzzy kmeans, SOM- Self Organizing Map (batch and recursive versions). It reads from and writes to Excel sheets. Its utility is shown with two applications: the visbreaker process part of an oil refinery and the UCI benchmark problem of breast cancer diagnosis.

#index 1398312
#* Clustering by random projections
#@ Thierry Urruty;Chabane Djeraba;Dan A. Simovici
#t 2007
#c 18
#% 36672
#% 41374
#% 248792
#% 273891
#% 296738
#% 420078
#% 645190
#% 801683
#% 835018
#% 926881
#! Clustering algorithms for multidimensional numerical data must overcome special difficulties due to the irregularities of data distribution. We present a clustering algorithm for numerical data that combines ideas from random projection techniques and density-based clustering. The algorithm consists of two phases: the first phase that entails the use of random projections to detect clusters, and the second phase that consists of certain post-processing techniques of clusters obtained by several random projections. Experiments were performed on synthetic data consisting of randomly-generated points in Rn, synthetic images containing colored regions randomly distributed, and, finally, real images. Our results suggest the potential of our algorithm for image segmentation.

#index 1398313
#* Lightweight clustering technique for distributed data mining applications
#@ Lamine M. Aouad;Nhien-An Le-Khac;Tahar M. Kechadi
#t 2007
#c 18
#% 296738
#% 420097
#% 444006
#% 481281
#% 577292
#% 799757
#% 844314
#% 861429
#% 879405
#% 915837
#% 1781525
#% 1861495
#! Many parallel and distributed clustering algorithms have already been proposed. Most of them are based on the aggregation of local models according to some collected local statistics. In this paper, we propose a lightweight distributed clustering algorithm based on minimum variance increases criterion which requires a very limited communication overhead. We also introduce the notion of distributed perturbation to improve the globally generated clustering. We show that this algorithm improves the quality of the overall clustering and manage to find the real structure and number of clusters of the global dataset.

#index 1398314
#* Predicting page occurrence in a click-stream data: statistical and rule-based approach
#@ Petr Berka;Martin Labsky
#t 2007
#c 18
#% 169673
#% 252472
#% 290482
#% 320930
#% 449566
#% 465922
#% 504568
#% 584891
#% 630984
#% 804426
#! We present an analysis of the click-stream data with the aim to predict the next page that will be visited by an user based on a history of visited pages. We present one statistical method (based on Markov models) and two rule induction methods (first based on well known set covering approach, the other base on our compositional algorithm KEX). We compare the achieved results and discuss interesting patterns that appear in the data.

#index 1398315
#* Improved IR in cohesion model for link detection system
#@ K. Lakshmi;Saswati Mukherjee
#t 2007
#c 18
#% 309100
#% 413593
#% 575570
#% 817448
#% 827581
#% 862860
#% 995518
#% 1275581
#! Given two stories, Story Link Detection System identifies whether they are discussing the same event. Standard approach in link detection system is to use cosine similarity measure to find whether the two documents are linked. Many researchers applied query expansion technique successfully in link detection system, where models are built from the relevant documents retrieved from the collection using query expansion. In this approach, success depends on the quality of the information retrieval system. In the current research, we propose a new information retrieval system for query expansion that uses intra-cluster similarity of the retrieved documents in addition to the similarity with respect to the query document. Our technique enhances the quality of the retrieval system thus improving the performance of the Link Detection System. Combining this improved IR with our Cohesion Model provides excellent result in link detection. Experimental results confirm the effect of the improved retrieval system in query expansion technique.

#index 1398316
#* Improving a state-of-the-art named entity recognition system using the world wide web
#@ Richárd Farkas;György Szarvas;Róbert Ormándi
#t 2007
#c 18
#% 73372
#% 136350
#% 278107
#% 754104
#% 854799
#% 855108
#% 855114
#% 926881
#% 1291356
#% 1663706
#! The development of highly accurate Named Entity Recognition (NER) systems can be beneficial to a wide range of Human Language Technology applications. In this paper we introduce three heuristics that exploit a variety of knowledge sources (the World Wide Web, Wikipedia and WordNet) and are capable of improving further a state-of-the-art multilingual and domain independent NER system. Moreover we describe our investigations on entity recognition in simulated speech-to-text output. Our web-based heuristics attained a slight improvement over the best results published on a standard NER task, and proved to be particularly effective in the speech-to-text scenario.

#index 1398317
#* ISOR-2: a case-based reasoning system to explain exceptional dialysis patients
#@ Olga Vorobieva;Alexander Rumyantsev;Rainer Schmidt
#t 2007
#c 18
#% 490915
#% 566459
#% 584766
#% 813997
#% 1389749
#% 1389774
#% 1718292
#! In medicine many exceptions occur. In medical practice and in knowledge-based systems too, it is necessary to consider them and to deal with them appropriately. In medical studies and in research, exceptions shall be explained. We present a system that helps to explain cases that do not fit into a theoretical hypothesis. Our starting points are situations where neither a well-developed theory nor reliable knowledge nor a priori a proper case base is available. So, instead of reliable theoretical knowledge and intelligent experience, we have just some theoretical hypothesis and a set of measurements. In this paper, we propose to combine CBR with a statistical model. We use CBR to explain those cases that do not fit the model. The case base has to be set up incrementally, it contains the exceptional cases, and their explanations are the solutions, which can be used to help to explain further exceptional cases.

#index 1398318
#* The role of prototypical cases in biomedical case-based reasoning
#@ Isabelle Bichindaritz
#t 2007
#c 18
#% 65653
#% 176887
#% 490277
#% 490464
#% 490602
#% 490618
#% 490930
#% 494252
#% 494267
#% 494440
#% 503627
#% 566456
#% 1046489
#% 1389760
#! Representing biomedical knowledge is an essential task in biomedical informatics intelligent systems. Case-based reasoning (CBR) holds the promise of representing contextual knowledge in a way that was not possible before with traditional knowledge representation and knowledge-based methods. A main issue in biomedical CBR has been dealing with maintenance of the case base, and particularly in medical domains, with the rate of generation of new knowledge, which often makes the content of a case base partially obsolete. This article proposes to make use of the concept of prototypical case to ensure that a CBR system would keep up-to-date with current research advances in the biomedical field. It proposes to illustrate and discuss the different roles that prototypical cases can serve in biomedical CBR systems, among which to organize and structure the memory, to guide the retrieval as well as the reuse of cases, and to serve as bootstrapping a CBR system memory when real cases are not available in sufficient quantity and/or quality. This paper presents knowledge maintenance as another role that these prototypical cases can play in biomedical CBR systems.

#index 1398319
#* A search space reduction methodology for large databases: a case study
#@ Angel Kuri-Morales;Fátima Rodríguez-Erazo
#t 2007
#c 18
#% 248790
#% 273889
#% 296738
#% 300132
#% 321607
#% 322417
#% 420136
#% 420138
#% 481281
#% 729985
#% 741027
#% 809251
#% 875014
#% 900335
#! Given the present need for Customer Relationship and the increased growth of the size of databases, many new approaches to large database clustering and processing have been attempted. In this work we propose a methodology based on the idea that statistically proven search space reduction is possible in practice. Two clustering models are generated: one corresponding to the full data set and another pertaining to the sampled data set. The resulting empirical distributions were mathematically tested to verify a tight non-linear significant approximation.

#index 1398320
#* Combining traditional and neural-based techniques for ink feed control in a newspaper printing press
#@ Cristofer Englund;Antanas Verikas
#t 2007
#c 18
#% 947548
#% 1093486
#% 1664370
#% 1790291
#% 1854465
#% 1854473
#! To achieve robust ink feed control an integrating controller and a multiple models-based controller are combined. Experimentally we have shown that the multiple models-based controller operating in the training region is superior to the integrating controller. However, for data originating from outside the multiple models training region, the integrating controller has the advantage. It is, therefore, suggested to combine the two techniques in order to improve robustness of the control system.

#index 1398321
#* Active learning strategies: a case study for detection of emotions in speech
#@ Alexis Bondu;Vincent Lemaire;Barbara Poulain
#t 2007
#c 18
#% 116165
#% 169717
#% 170649
#% 236729
#% 296738
#% 464268
#% 466887
#% 732227
#% 862547
#% 1455666
#! Machine learning indicates methods and algorithms which allow a model to learn a behavior thanks to examples. Active learning gathers methods which select examples used to build a training set for the predictive model. All the strategies aim to use the less examples as possible and to select the most informative examples. After having formalized the active learning problem and after having located it in the literature, this article synthesizes in the first part the main approaches of active learning. Taking into account emotions in Human-machine interactions can be helpful for intelligent systems designing. The main difficulty, for the conception of calls center's automatic shunting system, is the cost of data labeling. The last section of this paper propose to reduce this cost thanks to two active learning strategies. The study is based on real data resulting from the use of a vocal stock exchange server.

#index 1398322
#* Neural business control system
#@ M. Lourdes Borrajo;Juan M. Corchado;E. S. Corchado;M. A. Pellicer
#t 2007
#c 18
#% 156164
#% 163780
#% 168280
#% 168656
#% 176887
#% 258186
#% 362205
#% 495106
#% 629699
#% 778543
#% 856217
#% 1722137
#! The firms have need of a control mechanism in order to analyse whether they are achieving their goals. A tool that automates the business control process has been developed based on a case-based reasoning system. The objective of the system is to facilitate the process of internal auditing. The system analyses the data that characterises each one of the activities carried out by the firm, then determines the state of each activity and calculates the associated risk. This system uses a different problem solving method in each of the steps of the reasoning cycle. A Maximum Likelihood Hebbian Learning-based method that automates the organization of cases and the retrieval stage of case-based reasoning systems is presented in this paper. The proposed methodology has been derived as an extension of the Principal Component Analysis, and groups similar cases, identifying clusters automatically in a data set in an unsupervised mode. The system has been tested in 10 small and medium companies in the textile sector, located in the northwest of Spain and the results obtained have been very encouraging.

#index 1398323
#* A framework for discovering and analyzing changing customer segments
#@ Mirko Böttcher;Martin Spott;Detlef Nauck
#t 2007
#c 18
#% 152934
#% 751575
#% 861467
#% 1345620
#% 1345699
#% 1346852
#! Identifying customer segments and tracking their change over time is an important application for enterprises who need to understand what their customers expect from them. Customer segmentation is typically done by applying some form of cluster analysis. In this paper we present an alternative approach based on associaton rule mining and a notion of interestingness. Our approach allows us to detect arbitrary segments and analyse their temporal development. Our approach is assumption-free and pro-active and can be run continuously. Newly discovered segments or relevant changes will be reported automatically based on the application of an interestingness measure.

#index 1398324
#* Collaborative filtering using electrical resistance network models
#@ Jérôme Kunegis;Stephan Schmidt
#t 2007
#c 18
#% 66167
#% 431273
#% 465928
#% 734590
#% 1650569
#! In a recommender system where users rate items we predict the rating of items users have not rated. We define a rating graph containing users and items as vertices and ratings as weighted edges. We extend the work of [1] that uses the resistance distance on the bipartite rating graph incorporating negative edge weights into the calculation of the resistance distance. This algorithm is then compared to other rating prediction algorithms using data from two rating corpora.

#index 1398325
#* Visual query and exploration system for temporal relational database
#@ Shaul Ben Michael;Ronen Feldman
#t 2007
#c 18
#% 55700
#% 287364
#% 443261
#% 535354
#% 677512
#% 1180249
#! This research is focused on developing effective visualization tools for query construction and advanced exploration of temporal relational databases. Temporal databases enable the retrieval of each of the states observed in the past and even planned future states. Several query languages for relational databases have been introduced, but only a few of them deal with temporal databases. Moreover, most users are not highly skilled in query formulation and hence are not able to define complex queries. The visual approach introduced here aims at simplifying the query construction process. It gives the user the option to define complex temporal constructs and provides visual tools with which to explore the returned networks intuitively. The exploration process should provide better insight into networks of entities, reveal patterns between the entities, and enable the user to forecast the behavior of entities in the future. A visual query language as an isolated subsystem is not sufficient in itself for a complete data analysis process. A query's output should be further explored to find patterns that are hidden in the output.

#index 1398326
#* Towards an online image-based tree taxonomy
#@ Paul M. de Zeeuw;Elena Ranguelova;Eric J. Pauwels
#t 2007
#c 18
#% 576206
#! This paper reports on a first implementation of a webservice that supports image-based queries within the domain of tree taxonomy. As such, it serves as an example relevant to many other possible applications within the field of biodiversity and photo-identification. Without any human intervention matching results are produced through a chain of computer vision and image processing techniques, including segmentation and automatic shape matching. A selection of shape features is described and the architecture of the webservice is explained. Classification techniques are presented and preliminary results shown with respect to the success rate. Necessary future enhancements are discussed. Benefits are highlighted that could result from redesigning image-based expert systems as web services, open to the public at large.

#index 1398327
#* Distributed generative data mining
#@ Ruy Ramos;Rui Camacho
#t 2007
#c 18
#% 92776
#% 261139
#% 316709
#% 390532
#% 427307
#% 443091
#% 785141
#% 881575
#% 1718456
#! A process of Knowledge Discovery in Databases (KDD) involving large amounts of data requires a considerable amount of computational power. The process may be done on a dedicated and expensive machinery or, for some tasks, one can use distributed computing techniques on a network of affordable machines. In either approach it is usual the user to specify the workflow of the sub-tasks composing the whole KDD process before execution starts. In this paper we propose a technique that we call Distributed Generative Data Mining. The generative feature of the technique is due to its capability of generating new sub-tasks of the Data Mining analysis process at execution time. The workflow of sub-tasks of the DM is, therefore, dynamic. To deploy the proposed technique we extended the Distributed Data Mining system HARVARD and adapted an Inductive Logic Programming system (IndLog) used in a Relational Data Ming task. As a proof-of-concept, the extended system was used to analyse an artificial dataset of a credit scoring problem with eighty million records.

#index 1398328
#* Privacy-preserving discovery of frequent patterns in time series
#@ Josenildo Costa da Silva;Matthias Klusch
#t 2007
#c 18
#% 23638
#% 300184
#% 333876
#% 459006
#% 463903
#% 466260
#% 575967
#% 577233
#% 586838
#% 635215
#% 662757
#% 664070
#% 799397
#% 905914
#% 954159
#% 1386180
#% 1707820
#! We present DPD-HE, a privacy preserving algorithm for mining time series data. We assume data is split among several sites. The problem is to find all frequent subsequences of time series without revealing local data to any site. Our solution exploit density estimate and secure multiparty computation techniques to provide privacy to a given extent.

#index 1398329
#* Efficient non linear time series prediction using non linear signal analysis and neural networks in chaotic diode resonator circuits
#@ M. P. Hanias;D. A. Karras
#t 2007
#c 18
#% 226598
#% 260645
#% 356892
#! A novel non linear signal prediction method is presented using non linear signal analysis and deterministic chaos techniques in combination with neural networks for a diode resonator chaotic circuit. Multisim is used to simulate the circuit and show the presence of chaos. The Time series analysis is performed by the method proposed by Grasberger and Procaccia, involving estimation of the correlation and minimum embedding dimension as well as of the corresponding Kolmogorov entropy. These parameters are used to construct the first stage of a one step / multistep predictor while a back-propagation Artificial Neural Network (ANN) is involved in the second stage to enhance prediction results. The novelty of the proposed two stage predictor lies on that the backpropagation ANN is employed as a second order predictor, that is as an error predictor of the non-linear signal analysis stage application. This novel two stage predictor is evaluated through an extensive experimental study.

#index 1398330
#* Using disjunctions in association mining
#@ Martin Ralbovsky;Tomáš Kuchař
#t 2007
#c 18
#% 152934
#% 232136
#% 570151
#% 783595
#! The paper focuses on usage of disjunction of items in association rules mining. We used the GUHA method instead of the traditional apriori algorithm and enhanced the former implementations of the method with ability of disjunctions setting between items. Experiments were conducted in our Ferda data mining environment on data from the medical domain. We found strong and meaningful association rules that could not be obtained without the usage of disjunction.

#index 1489111
#* Proceedings of the 10th industrial conference on Advances in data mining: applications and theoretical aspects
#@ Petra Perner
#t 2010
#c 18

#index 1489112
#* Moving targets: when data classes depend on subjective judgement, or they are crafted by an adversary to mislead pattern analysis algorithms - the cases of content based image retrieval and adversarial classification
#@ Giorgio Giacinto
#t 2010
#c 18
#% 204531
#% 266787
#% 296375
#% 318785
#% 729437
#% 769885
#% 860956
#% 863446
#% 864873
#% 990272
#% 1040539
#% 1041843
#% 1042935
#% 1080354
#% 1182656
#% 1213215
#% 1229243
#% 1245976
#% 1294653
#% 1299962
#% 1320446
#% 1331279
#% 1356643
#% 1375781
#% 1412624
#% 1435381
#% 1468469
#! The vast majority of pattern recognition applications assume that data can be subdivided into a number of data classes on the basis of the values of a set of suitable features. Supervised techniques assume the data classes are given in advance, and the goal is to find the most suitable set of feature and classification algorithm that allows the effective partition of the data. On the other hand, unsupervised techniques allow discovering the "natural" data classes in which data can be partitioned, for a given set of features. These approaches are showing their limitation to handle the challenges issued by applications where, for each instance of the problem, patterns can be assigned to different data classes, and the definition itself of data classes is not uniquely fixed. As a consequence, the set of features providing for an effective discrimination of patterns, and the related discrimination rule, should be set for each instance of the classification problem. Two applications from different domains share similar characteristics: Content-Based Multimedia Retrieval and Adversarial Classification. The retrieval of multimedia data by content is biased by the high subjectivity of the concept of similarity. On the other hand, in an adversarial environment, the adversary carefully craft new patterns so that they are assigned to the incorrect data class. In this paper, the issues of the two application scenarios will be discussed, and some effective solutions and future reearch directions will be outlined.

#index 1489113
#* Bioinformatics contributions to data mining
#@ Isabelle Bichindaritz
#t 2010
#c 18
#% 748001
#% 833786
#% 1417842
#! The field of bioinformatics shows a tremendous growth at the crossroads of biology, medicine, information science, and computer science. Figures clearly demonstrate that today bioinformatics research is as productive as data mining research as a whole. However most bioinformatics research deals with tasks of prediction, classification, and tree or network induction from data. Bioinformatics tasks consist mainly in similarity-based sequence search, microarray data analysis, 2D or 3D macromolecule shape prediction, and phylogenetic classification. It is therefore interesting to consider how the methods of bioinformatics can be pertinent advances in data mining and to highlight some examples of how these bioinformatics algorithms can potentially be applied to domains outside biology.

#index 1489114
#* Bootstrap feature selection for ensemble classifiers
#@ Rakkrit Duangsoithong;Terry Windeatt
#t 2010
#c 18
#% 177826
#% 209021
#% 256615
#% 283145
#% 466410
#% 551746
#% 793239
#% 796212
#% 926881
#% 1030118
#% 1041316
#% 1108900
#% 1254261
#% 1267764
#% 1268062
#% 1385952
#% 1702629
#% 1861763
#! Small number of samples with high dimensional feature space leads to degradation of classifier performance for machine learning, statistics and data mining systems. This paper presents a bootstrap feature selection for ensemble classifiers to deal with this problem and compares with traditional feature selection for ensemble (select optimal features from whole dataset before bootstrap selected data). Four base classifiers: Multilayer Perceptron, Support Vector Machines, Naive Bayes and Decision Tree are used to evaluate the performance of UCI machine learning repository and causal discovery datasets. Bootstrap feature selection algorithm provides slightly better accuracy than traditional feature selection for ensemble classifiers.

#index 1489115
#* Evaluating the quality of clustering algorithms using cluster path lengths
#@ Faraz Zaidi;Daniel Archambault;Guy Melançon
#t 2010
#c 18
#% 288652
#% 296738
#% 397597
#% 637359
#% 755402
#% 806990
#% 829253
#% 907289
#% 944938
#% 1055207
#% 1546427
#% 1835483
#! Many real world systems can be modeled as networks or graphs. Clustering algorithms that help us to organize and understand these networks are usually referred to as, graph based clustering algorithms. Many algorithms exist in the literature for clustering network data. Evaluating the quality of these clustering algorithms is an important task addressed by different researchers. An important ingredient of evaluating these clustering techniques is the node-edge density of a cluster. In this paper, we argue that evaluation methods based on density are heavily biased to networks having dense components, such as social networks, but are not well suited for data sets with other network topologies where the nodes are not densely connected. Example of such data sets are the transportation and Internet networks. We justify our hypothesis by presenting examples from real world data sets. We present a new metric to evaluate the quality of a clustering algorithm to overcome the limitations of existing cluster evaluation techniques. This new metric is based on the path length of the elements of a cluster and avoids judging the quality based on cluster density. We show the effectiveness of the proposed metric by comparing its results with other existing evaluation methods on artificially generated and real world data sets.

#index 1489116
#* Finding irregularly shaped clusters based on entropy
#@ Angel Kuri-Morales;Edwin Aldana-Bobadilla
#t 2010
#c 18
#% 160838
#% 207195
#% 361966
#% 430746
#% 479799
#% 566128
#! In data clustering the more traditional algorithms are based on similarity criteria which depend on a metric distance. This fact imposes important constraints on the shape of the clusters found. These shapes generally are hyperspherical in the metric's space due to the fact that each element in a cluster lies within a radial distance relative to a given center. In this paper we propose a clustering algorithm that does not depend on simple distance metrics and, therefore, allows us to find clusters with arbitrary shapes in n-dimensional space. Our proposal is based on some concepts stemming from Shannon's information theory and evolutionary computation. Here each cluster consists of a subset of the data where entropy is minimized. This is a highly non-linear and usually nonconvex optimization problem which disallows the use of traditional optimization techniques. To solve it we apply a rugged genetic algorithm (the so-called Vasconcelos' GA). In order to test the efficiency of our proposal we artificially created several sets of data with known properties in a tridimensional space. The result of applying our algorithm has shown that it is able to find highly irregular clusters that traditional algorithms cannot. Some previous work is based on algorithms relying on similar approaches (such as ENCLUS' and CLIQUE's). The differences between such approaches and ours are also discussed.

#index 1489117
#* Fuzzy conceptual clustering
#@ Petra Perner;Anja Attig
#t 2010
#c 18
#% 65440
#% 374537
#% 451051
#% 451052
#% 793403
#% 1407624
#% 1807663
#! Grouping unknown data into groups of similar data is a necessary first step for classification, indexing of data bases, and prediction. Most of today's applications, such as news classification, blog indexing, image classification, and medical diagnosis, obtain their data in temporal sequence or on-line. The necessity for data exploration requires a graphical method that allows the expert in the field to study the determined groups of data. Therefore, incremental hierarchical clustering methods that can create explicit cluster descriptions are convenient. The noisy and uncertain nature of the data makes it necessary to develop fuzzy clustering methods. We propose a novel fuzzy conceptual clustering algorithm. We describe the fuzzy objective function for incremental building of the clusters and the relation among the clusters in a hierarchy. The operations that can incrementally re-optimize the fuzzy-based hierarchy based on the newly arrived data are explained. Finally, we evaluate our method and present results.

#index 1489118
#* Mining concept similarities for heterogeneous ontologies
#@ Konstantin Todorov;Peter Geibel;Kai-Uwe Kühnberger
#t 2010
#c 18
#% 348187
#% 420077
#% 425048
#% 515992
#% 722929
#% 722932
#% 722938
#% 787639
#% 924747
#% 1289178
#% 1409921
#% 1418379
#! We consider the problem of discovering pairs of similar concepts, which are part of two given source ontologies, in which each concept node is mapped to a set of instances. The similarity measures we propose are based on learning a classifier for each concept that allows to discriminate the respective concept from the remaining concepts in the same ontology. We present two new measures that are compared experimentally: (1) one based on comparing the sets of support vectors from the learned SVMs and (2) one which considers the list of discriminating variables for each concept. These lists are determined using a novel variable selection approach for the SVM. We compare the performance of the two suggested techniques with two standard approaches (Jaccard similarity and class-means distance). We also present a novel recursive matching algorithm based on concept similarities.

#index 1489119
#* Re-mining positive and negative association mining results
#@ Ayhan Demiriz;Gurdal Ertek;Tankut Atan;Ufuk Kula
#t 2010
#c 18
#% 152934
#% 210160
#% 232106
#% 248785
#% 451441
#% 464822
#% 570887
#% 729416
#% 751710
#% 766206
#% 818916
#% 1389714
#% 1663074
#! Positive and negative association mining are well-known and extensively studied data mining techniques to analyze market basket data. Efficient algorithms exist to find both types of association, separately or simultaneously. Association mining is performed by operating on the transaction data. Despite being an integral part of the transaction data, the pricing and time information has not been incorporated into market basket analysis so far, and additional attributes have been handled using quantitative association mining. In this paper, a new approach is proposed to incorporate price, time and domain related attributes into data mining by re-mining the association mining results. The underlying factors behind positive and negative relationships, as indicated by the association rules, are characterized and described through the second data mining stage re-mining. The applicability of the methodology is demonstrated by analyzing data coming from apparel retailing industry, where price markdown is an essential tool for promoting sales and generating increased revenue.

#index 1489120
#* Multi-agent based clustering: towards generic multi-agent data mining
#@ Santhana Chaimontree;Katie Atkinson;Frans Coenen
#t 2010
#c 18
#% 296825
#% 375017
#% 378965
#% 835018
#% 992249
#% 1254271
#% 1264415
#! A framework for Multi Agent Data Mining (MADM) is described. The framework comprises a collection of agents cooperating to address given data mining tasks. The fundamental concept underpinning the framework is that it should support generic data mining. The vision is that of a system that grows in an organic manner. The central issue to facilitating this growth is the communication medium required to support agent interaction. This issue is partly addressed by the nature of the proposed architecture and partly through an extendable ontology; both are described. The advantages offered by the framework are illustrated in this paper by considering a clustering application. The motivation for the latter is that no "best" clustering algorithm has been identified, and consequently an agent-based approach can be adopted to identify "best" clusters. The application serves to demonstrates the full potential of MADM.

#index 1489121
#* Describing data with the support vector shell in distributed environments
#@ Peng Wang;Guojun Mao
#t 2010
#c 18
#% 280481
#% 310500
#% 342639
#% 378388
#% 393059
#% 466589
#% 578388
#% 732387
#% 743284
#% 785219
#% 818916
#% 881938
#% 1861692
#! Distributed data streams mining is increasingly demanded in most extensive application domains, like web traffic analysis and financial transactions. In distributed environments, it is impractical to transmit all data to one node for global model. It is reasonable to extract the essential parts of local models of subsidiary nodes, thereby integrating into the global model. In this paper we proposed an approach SVDDS to do this model integration in distributed environments. It is based on SVM theory, and trades off between the risk of the global model and the total transmission load. Our analysis and experiments show that SVDDS obviously lowers the total transmission load while the global accuracy drops comparatively little.

#index 1489122
#* Robust clustering using discriminant analysis
#@ Vasudha Bhatnagar;Sangeeta Ahuja
#t 2010
#c 18
#% 51647
#% 273890
#% 280417
#% 466083
#% 551737
#% 571905
#% 727903
#% 731938
#% 744117
#% 769935
#% 774878
#% 803762
#% 818916
#% 829253
#% 902497
#! Cluster ensemble technique has attracted serious attention in the area of unsupervised learning. It aims at improving robustness and quality of clustering scheme, particularly in scenarios where either randomization or sampling is the part of the clustering algorithm. In this paper, we address the problem of instability and non robustness in K-means clusterings. These problems arise naturally because of random seed selection by the algorithm, order sensitivity of the algorithm and presence of noise and outliers in data. We propose a cluster ensemble method based on Discriminant Analysis to obtain robust clustering using K-means clusterer. The proposed algorithm operates in three phases. The first phase is preparatory in which multiple clustering schemes generated and the cluster correspondence is obtained. The second phase uses discriminant analysis and constructs a label matrix. In the final stage, consensus partition is generated and noise, if any, is segregated. Experimental analysis using standard public data sets provides strong empirical evidence of the high quality of resultant clustering scheme.

#index 1489123
#* New approach in data stream association rule mining based on graph structure
#@ Samad Gahderi Mojaveri;Esmaeil Mirzaeian;Zarrintaj Bornaee;Saeed Ayat
#t 2010
#c 18
#% 152934
#% 300120
#% 881520
#% 915241
#! Discovery of useful information and valuable knowledge from transactions has attracted many researchers due to increasing use of very large databases and data warehouses. Furthermore most of proposed methods are designed to work on traditional databases in which re-scanning the transactions is allowed. These methods are not useful for mining in data streams (DS) because it is not possible to re-scan the transactions duo to huge and continues data in DS. In this paper, we proposed an effective approach to mining frequent itemsets used for association rule mining in DS named GRM1. Unlike other semi-graph methods, our method is based on graph structure and has the ability to maintain and update the graph in one pass of transactions. In this method data storing is optimized by memory usage criteria and mining the rules is done in a linear processing time. Efficiency of our implemented method is compared with other proposed method and the result is presented.

#index 1489124
#* Fast training of neural networks for image compression
#@ Yevgeniy Bodyanskiy;Paul Grimm;Sergey Mashtalir;Vladimir Vinarski
#t 2010
#c 18
#% 361100
#% 361966
#% 983724
#% 1758583
#% 1760811
#! The paper considers the problem of image compression by using artificial neural networks (ANN). The main concept of this approach is the reduction of the original feature spaces, what allows us to eliminate the image redundancy and accordingly leads to their compression. Two variants of the neural networks: two layers ANN with the self-learning algorithm based on the weighted informational criterion and auto-associative four-layers feedforward network have been proposed and analyzed.

#index 1489125
#* Processing handwritten words by intelligent use of OCR results
#@ Benjamin Mund;Karl-Heinz Steinke
#t 2010
#c 18
#% 658758
#% 753298
#% 849993
#! About 3.5 million dried plants on paper sheets are deposited in the Botanical Museum Berlin in Germany. Frequently they have handwritten annotations (see figure 1). So a procedure had to be developed in order to process the handwriting on the sheet. In the present work an approach tries to identify the writer by handwritten words and to read handwritten keywords. Therefore the word is cut out and transformed into a 6-dimensional time series and compared e.g. by means of DTW-method. A recognition rate of 98.6% is achieved with 12 different words (1200 samples). All herbar documents contain several printed tokens which indicate more information about the plant. With the token it is possible to get information who has found this plant, where this plant was found (country and sometimes the town), what kind of plant it is and so on. By using the local connections of the text it is possible to get more information from the herbar document, e.g. to find and recognize handwritten text in a defined area.

#index 1489126
#* Saliency-based candidate inspection region extraction in tape automated bonding
#@ Martina Dümcke;Hiroki Takahashi
#t 2010
#c 18
#% 268121
#! Electronic circuits are composed of components connected by traces which conduct the current. While the interconnections between the components can be created by assembling individual pieces of wire, it is nowadays common to use printed circuit boards. Tape automated bonding (TAB) is a technique to assemble chips and printed circuit boards. Because TAB become smaller, their inspection methods are required to adapt to the decreasing size of the electric circuits' pattern. An image of a TAB is taken during the manufacturing process and analysed using image processing algorithms to inspect it for flaws in its pattern. This paper proposes an algorithm to find candidate inspection regions in a TAB pattern based on visual saliency. Orientation information contained in the image is processed to detect probable error regions and exclude correct regions from further inspection. The algorithm finds all the flaws in an image and in the case of regular patterns, marks only 5% of the image pixels as belonging to a candidate inspection region. The results show that a saliency-based approach is applicable on the task of finding flaws in the pattern of an electric circuit.

#index 1489127
#* Image classification using histograms and time series analysis: a study of age-related macular degeneration screening in retinal image data
#@ Mohd Hanafi Ahmad Hijazi;Frans Coenen;Yalin Zheng
#t 2010
#c 18
#% 162877
#% 168280
#% 301174
#% 325683
#% 430763
#% 584926
#% 662750
#% 889273
#% 1030599
#! An approach to image mining is described that combines a histogram based representation with a time series analysis technique. More specifically a Dynamic Time Warping (DTW) approach is applied to histogram represented image sets that have been enhanced using CLAHE and noise removal. The focus of the work is the screening (classification) of retinal image sets to identify age-related macular degeneration (AMD). Results are reported from experiments conducted to compare different image enhancement techniques, combination of two different histograms for image classification, and different histogram based approaches. The experiments demonstrated that: the image enhancement techniques produce improved results, the usage of two histograms improved the classifier performance, and that the proposed DTW procedure out-performs other histogram based techniques in terms of classification accuracy.

#index 1489128
#* Entropic quadtrees and mining mars craters
#@ Rosanne Vetro;Dan A. Simovici
#t 2010
#c 18
#% 42090
#% 44067
#% 126662
#% 150390
#% 321652
#% 1810871
#! This paper introduces entropic quadtrees, which are structures derived from quadtrees by allowing nodes to split only when nodes point to sufficiently diverse sets of objects. Diversity is evaluated using entropy attached to the histograms of the values of features for sets designated by the nodes. As an application, we used entropic quadtrees to locate craters on the surface of Mars, represented by circles in digital images.

#index 1489129
#* Hybrid DIAAF/RS: statistical textual feature selection for language-independent text classification
#@ Yanbo J. Wang;Fan Li;Frans Coenen;Robert Sanderson;Qin Xin
#t 2010
#c 18
#% 46803
#% 73046
#% 111304
#% 136350
#% 152934
#% 169777
#% 288211
#% 321635
#% 344447
#% 396747
#% 466483
#% 622700
#% 629642
#% 748499
#% 785382
#% 809535
#% 942741
#% 1099010
#% 1099036
#% 1107646
#% 1279298
#% 1676579
#% 1707806
#! Textual Feature Selection (TFS) is an important phase in the process of text classification. It aims to identify the most significant textual features (i.e. key words and/or phrases), in a textual dataset, that serve to distinguish between text categories. In TFS, basic techniques can be divided into two groups: linguistic vs. statistical. For the purpose of building a language-independent text classifier, the study reported here is concerned with statistical TFS only. In this paper, we propose a novel statistical TFS approach that hybridizes the ideas of two existing techniques, DIAAF (Darmstadt Indexing Approach Association Factor) and RS (Relevancy Score). With respect to associative (text) classification, the experimental results demonstrate that the proposed approach can produce greater classification accuracy than other alternative approaches.

#index 1489130
#* Multimedia summarization in law courts: a clustering-based environment for browsing and consulting judicial folders
#@ E. Fersini;E. Messina;F. Archetti
#t 2010
#c 18
#% 46803
#% 730232
#% 839995
#% 1048456
#% 1112566
#% 1180376
#% 1254290
#% 1733312
#! Digital videos represent a fundamental informative source of those events that occur during a penal proceedings, which thanks to the technologies available nowadays, can be stored, organized and retrieved in short time and with low cost. However, considering the dimension that a video source can assume during a trial recording, several requirements have been pointed out by judicial actors: fast navigation of the stream, efficient access to data inside and effective representation of relevant contents. One of the possible solutions to these requirements is represented by multimedia summarization aimed at deriving a synthetic representation of audio/video contents, characterized by a limited loss of meaningful information. In this paper a multimedia summarization environment is proposed for defining a storyboard for proceedings celebrated into courtrooms.

#index 1489131
#* Comparison of redundancy and relevance measures for feature selection in tissue classification of CT images
#@ Benjamin Auffarth;Maite López;Jesús Cerquides
#t 2010
#c 18
#% 5182
#% 397133
#% 717417
#% 793239
#% 814023
#% 926881
#% 950267
#% 961134
#% 1041316
#% 1074124
#% 1272304
#% 1405926
#! In this paper we report on a study on feature selection within the minimum-redundancy maximum-relevance framework. Features are ranked by their correlations to the target vector. These relevance scores are then integrated with correlations between features in order to obtain a set of relevant and least-redundant features. Applied measures of correlation or distributional similarity for redunancy and relevance include Kolmogorov-Smirnov (KS) test, Spearman correlations, Jensen-Shannon divergence, and the sign-test. We introduce a metric called "value difference metric" (VDM) and present a simple measure, which we call "fit criterion" (FC). We draw conclusions about the usefulness of different measures. While KS-test and sign-test provided useful information, Spearman correlations are not fit for comparison of data of different measurement intervals. VDM was very good in our experiments as both redundancy and relevance measure. Jensen-Shannon and the sign-test are good redundancy measure alternatives and FC is a good relevance measure alternative.

#index 1489132
#* Quantile regression model for impact toughness estimation
#@ Satu Tamminen;Ilmari Juutilainen;Juha Röning
#t 2010
#c 18
#% 33176
#% 361100
#% 845712
#% 977207
#% 1860717
#! The purpose of this study was to develop a product design model for estimating the impact toughness of low-alloy steel plates. The rejection probability in a Charpy-V test (CVT) is predicted with process variables and chemical composition. The proposed method is suitable for the whole production line of a steel plate mill, including all grades of steel in production. The quantile regression model was compared to the joint model of mean and dispersion and the constant variance model. The quantile regression model proved out to be the most effective method for modelling a highly complicated property at this extent. Next, the developed model will be implemented into a graphical simulation tool that is in daily use in the product planning department and already contains some other mechanical property models. The model will guide designers in predicting the related risk of rejection and in producing desired properties in the product at lower cost.

#index 1489133
#* Mining for paths in flow graphs
#@ Adam Jocksch;José Nelson Amaral;Marcel Mitran
#t 2010
#c 18
#% 152934
#% 242184
#% 459006
#% 463903
#% 464996
#% 478274
#% 481290
#% 501374
#% 629708
#% 654079
#% 769951
#% 978335
#% 1060647
#% 1117006
#% 1117936
#% 1204896
#% 1410715
#% 1729771
#% 1736356
#! This paper presents FlowGSP, a data-mining algorithm that discovers frequent sequences of attributes in subpaths of a flow graph. FlowGSP was evaluated using flow graphs derived from the execution of transactions in the IBM® WebSphere® Application Server, a large real-world enterprise application server. The vertices of this flow graph may represent single instructions, bytecodes, basic blocks, regions, or entire methods. These vertices are annotated with attributes that correspond to run-time characteristics of the execution of the program. FlowGSP successfully identified a number of existing characteristics of the Web-Sphere Application Server which had previously been discovered only through extensive manual examination. In addition, a multithreaded implementation of FlowGSP demonstrates the algorithm's suitability for exploiting the resources of modern multi-core computers.

#index 1489134
#* Combining unsupervised and supervised data mining techniques for conducting customer portfolio analysis
#@ Zhiyuan Yao;Annika H. Holmbom;Tomas Eklund;Barbro Back
#t 2010
#c 18
#% 60576
#% 386001
#% 391311
#% 420084
#% 750187
#% 881898
#% 920176
#% 1083112
#% 1136455
#% 1174465
#% 1417922
#% 1663452
#% 1860652
#! Leveraging the power of increasing amounts of data to analyze customer base for attracting and retaining the most valuable customers is a major problem facing companies in this information age. Data mining technologies extract hidden information and knowledge from large data stored in databases or data warehouses, thereby supporting the corporate decision making process. In this study, we apply a two-level approach that combines SOM-Ward clustering and decision trees to conduct customer portfolio analysis for a case company. The created two-level model was then used to identify potential high-value customers from the customer base. It was found that this hybrid approach could provide more detailed and accurate information about the customer base for tailoring actionable marketing strategies.

#index 1489135
#* Managing product life cycle with multiagent data mining system
#@ Serge Parshutin
#t 2010
#c 18
#% 95130
#% 341700
#% 393812
#% 818916
#% 835018
#% 962852
#% 1185576
#% 1252958
#% 1335273
#! Production planning is the main aspect for a manufacturer affecting an income of a company. Correct production planning policy, chosen for the right product at the right time, lessens production, storing and other related costs. The task of choosing a production policy in most cases is solved by an expert group, what not an every company can support. Thus a topic of having an intelligent system for supporting production management process becomes actual. The main tasks such system should be able to solve are defining the present Product Life Cycle (PLC) phase of a product as also determining a transition point - a moment of time (period), when the PLC phase is changed; as the results obtained will affect the decision of what production planning policy should be used. The paper presents the MultiAgent Data Mining system, meant for supporting a production manager in his/her production planning decisions. The developed system is based on the analysis of historical demand for products and on the information about transitions between phases in life cycles of those products. The architecture of the developed system is presented as also an analysis of testing on the real-world data results is given.

#index 1489136
#* Modeling pricing strategies using game theory and support vector machines
#@ Cristián Bravo;Nicolás Figueroa;Richard Weber
#t 2010
#c 18
#% 61477
#% 309208
#% 573280
#% 763699
#% 799511
#% 799512
#! Data Mining is a widely used discipline with methods that are heavily supported by statistical theory. Game theory, instead, develops models with solid economical foundations but with low applicability in companies so far. This work attempts to unify both approaches, presenting a model of price competition in the credit industry. Based on game theory and sustained by the robustness of Support Vector Machines to structurally estimate the model, it takes advantage from each approach to provide strong results and useful information. The model consists of a market-level game that determines the marginal cost, demand, and efficiency of the competitors. Demand is estimated using Support Vector Machines, allowing the inclusion of multiple variables and empowering standard economical estimation through the aggregation of client-level models. The model is being applied by one competitor, which created new business opportunities, such as the strategic chance to aggressively cut prices given the acquired market knowledge.

#index 1489137
#* Determination of the fault quality variables of a multivariate process using independent component analysis and support vector machine
#@ Yuehjen E. Shao;Chi-Jie Lu;Yu-Chiun Wang
#t 2010
#c 18
#% 190581
#% 313975
#% 444032
#% 1065750
#% 1157092
#% 1196987
#% 1860941
#% 1861267
#! The multivariate statistical process control (MSPC) chart plays an important role in monitoring a multivariate process. Once a process disturbance has occurred, the MSPC out-of-control signal would be triggered. The process personnel then begin to search for the root causes of a disturbance in order to take remedial action to compensate for the effects of the disturbance. However, the use of MSPC chart encounters a difficulty in practice. This difficult issue involves which quality variable or which set of the quality variables is responsible for the generation of the out-of-control signal. This determination is not straightforward, and it usually confused the process personnel. This study proposes a hybrid approach which is composed of independent component analysis (ICA) and support vector machine (SVM) to determine the fault quality variables when a step-change disturbance existed in a process. The well-known Hotelling T2 control chart is employed to monitor the multivariate process. The proposed hybrid ICA-SVM scheme first uses ICA to the Hotelling T2 statistics generating independent components (ICs). The hidden useful information of the fault quality variables could be discovered in these ICs. The ICs are then used as the input variables of the SVM for building the classification model. The performance of various process designs is investigated and compared with the typical classification method.

#index 1489138
#* Dynamic pattern extraction of parameters in laser welding process
#@ Gissel Velarde;Christian Binroth
#t 2010
#c 18
#% 366687
#% 925584
#% 1046491
#% 1098984
#! Tuning parameters is essential for the results of the welding process. In order to optimize the tuning process of welding parameters, we propose a system based on historical data of laser welding machines. On a given combination of materials, the system extracts patterns dynamically and classifies new cases with a relative accuracy, which depends on the selected data set. The analysis of the generated patterns helps decision makers to visualize important features in large databases and therefore, achieve optimal results.

#index 1489139
#* Trajectory clustering for vibration detection in aircraft engines
#@ Aurélien Hazan;Michel Verleysen;Marie Cottrell;Jérôme Lacaille
#t 2010
#c 18
#% 53342
#% 135968
#% 157045
#% 383741
#! The automatic detection of the vibration signature of rotating parts of an aircraft engine is considered. This paper introduces an algorithm that takes into account the variation over time of the level of detection of orders, i.e. vibrations ate multiples of the rotating speed. The detection level over time at a specific order are gathered in a socalled trajectory. It is shown that clustering the trajectories to classify them into detected and non-detected orders improves the robustness to noise and other external conditions, compared to a traditional statistical signal detection by an hypothesis test. The algorithms are illustrated in real aircraft engine data.

#index 1489140
#* Episode rule-based prognosis applied to complex vacuum pumping systems using vibratory data
#@ Florent Martin;Nicolas Méger;Sylvie Galichet;Nicolas Becourt
#t 2010
#c 18
#% 420063
#% 445343
#% 463903
#% 533632
#% 799764
#% 1397490
#! This paper presents a local pattern-based method that addresses system prognosis. It also details a successful application to complex vacuum pumping systems. More precisely, using historical vibratory data, we first model the behavior of systems by extracting a given type of episode rules, namely First Local Maximum episode rules (FLM-rules). A subset of the extracted FLM-rules is then selected in order to further predict pumping system failures in a vibratory datastream context. The results that we got for production data are very encouraging as we predict failures with a good time scale precision. We are now deploying our solution for a customer of the semi-conductor market.

#index 1489141
#* Predicting disk failures with HMM- and HSMM-based approaches
#@ Ying Zhao;Xiang Liu;Siqing Gan;Weimin Zheng
#t 2010
#c 18
#% 464446
#% 829020
#% 967021
#% 978977
#% 1009844
#% 1095871
#! Understanding and predicting disk failures are essential for both disk vendors and users to manufacture more reliable disk drives and build more reliable storage systems, in order to avoid service downtime and possible data loss. Predicting disk failure from observable disk attributes, such as those provided by the Self-Monitoring and Reporting Technology (SMART) system, has been shown to be effective. In the paper, we treat SMART data as time series, and explore the prediction power by using HMM- and HSMM-based approaches. Our experimental results show that our prediction models outperform other models that do not capture the temporal relationship among attribute values over time. Using the best single attribute, our approach can achieve a detection rate of 46% at 0% false alarm. Combining the two best attributes, our approach can achieve a detection rate of 52% at 0% false alarm.

#index 1489142
#* Aircraft engine health monitoring using self-organizing maps
#@ Etienne Côme;Marie Cottrell;Michel Verleysen;Jérôme Lacaille
#t 2010
#c 18
#% 135968
#% 1192438
#% 1224197
#! Aircraft engines are designed to be used during several tens of years. Ensuring a proper operation of engines over their lifetime is therefore an important and difficult task. The maintenance can be improved if efficients procedures for the understanding of data flows produced by sensors for monitoring purposes are implemented. This paper details such a procedure aiming at visualizing in a meaningful way successive data measured on aircraft engines. The core of the procedure is based on Self-Organizing Maps (SOM) which are used to visualize the evolution of the data measured on the engines. Rough measurements can not be directly used as inputs, because they are influenced by external conditions. A preprocessing procedure is set up to extract meaningful information and remove uninteresting variations due to change of environmental conditions. The proposed procedure contains three main modules to tackle these difficulties: environmental conditions normalization (ECN), change detection and adaptive signal modeling (CD) and finally visualization with Self-Organizing Maps (SOM). The architecture of the procedure and of modules are described in details in this paper and results on real data are also supplied.

#index 1489143
#* Finding temporal patterns in noisy longitudinal data: a study in diabetic retinopathy
#@ Vassiliki Somaraki;Deborah Broadbent;Frans Coenen;Simon Harding
#t 2010
#c 18
#% 280409
#% 481290
#% 607791
#% 729417
#% 993961
#% 1113098
#% 1248661
#% 1395500
#% 1489147
#! This paper describes an approach to temporal pattern mining using the concept of user defined temporal prototypes to define the nature of the trends of interests. The temporal patterns are defined in terms of sequences of support values associated with identified frequent patterns. The prototypes are defined mathematically so that they can be mapped onto the temporal patterns. The focus for the advocated temporal pattern mining process is a large longitudinal patient database collected as part of a diabetic retinopathy screening programme, The data set is, in itself, also of interest as it is very noisy (in common with other similar medical datasets) and does not feature a clear association between specific time stamps and subsets of the data. The diabetic retinopathy application, the data warehousing and cleaning process, and the frequent pattern mining procedure (together with the application of the prototype concept) are all described in the paper. An evaluation of the frequent pattern mining process is also presented.

#index 1489144
#* Selection of high risk patients with ranked models based on the CPL criterion functions
#@ Leon Bobrowski
#t 2010
#c 18
#% 51647
#% 729437
#% 1168822
#! Important practical problems in computer support medical diagnosis are related to screening procedures. Identification of high risk patients can serve as an example of such a problem. The identification results should allow to select a patient in an objective manner for additional therapeutic treatment. The designing of the screening tools can be based on the minimisation of the convex and piecewise linear (CPL) criterion functions. Particularly ranked models can be designed in this manner for the purposes of screening procedures.

#index 1489145
#* Medical datasets analysis: a constructive induction approach
#@ Wiesław Paja;Mariusz Wrzesień
#t 2010
#c 18
#% 170415
#% 224475
#% 351595
#% 567416
#% 923811
#% 1166166
#! The main goal of our research was to compile new methodology for building simplified learning models in a form of decision rule set. Every investigated source informational dataset was extended by application of constructive induction method to get a new, additional, descriptive attribute, and then sets of decision rules were developed for source and for extended database, respectively. In the last step, obtained set of rules were optimized and compared to earlier set of rules.

#index 1489146
#* Regression models for spatial data: an example from precision agriculture
#@ Georg Ruß;Rudolf Kruse
#t 2010
#c 18
#% 116149
#% 400847
#% 1103382
#% 1252952
#% 1402657
#! The term precision agriculture refers to the application of state-of-theart GPS technology in connection with small-scale, sensor-based treatment of the crop. This data-driven approach to agriculture poses a number of data mining problems. One of those is also an obviously important task in agriculture: yield prediction. Given a precise, geographically annotated data set for a certain field, can a season's yield be predicted? Numerous approaches have been proposed to solving this problem. In the past, classical regression models for non-spatial data have been used, like regression trees, neural networks and support vector machines. However, in a cross-validation learning approach, issues with the assumption of statistical independence of the data records appear. Therefore, the geographical location of data records should clearly be considered while employing a regression model. This paper gives a short overview about the available data, points out the issues with the classical learning approaches and presents a novel spatial cross-validation technique to overcome the problems and solve the aforementioned yield prediction task.

#index 1489147
#* Trend mining in social networks: a study using a large cattle movement database
#@ Puteri N. E. Nohuddin;Rob Christley;Frans Coenen;Christian Setzkorn
#t 2010
#c 18
#% 361966
#% 478448
#% 498483
#% 839727
#% 1113098
#% 1272187
#% 1395500
#! This paper reports on a mechanism to identify temporal spatial trends in social networks. The trends of interest are defined in terms of the occurrence frequency of time stamped patterns across social network data. The paper proposes a technique for identifying such trends founded on the Frequent Pattern Mining paradigm. The challenge of this technique is that, given appropriate conditions, many trends may be produced; and consequently the analysis of the end result is inhibited. To assist in the analysis, a Self Organising Map (SOM) based approach, to visualizing the outcomes, is proposed. The focus for the work is the social network represented by the UK's cattle movement data base. However, the proposed solution is equally applicable to other large social networks.

#index 1489148
#* Spam email filtering using network-level properties
#@ Paulo Cortez;André Correia;Pedro Sousa;Miguel Rocha;Miguel Rio
#t 2010
#c 18
#% 197394
#% 741673
#% 889273
#% 889653
#% 992948
#% 1072123
#% 1125004
#% 1263886
#% 1277382
#% 1280738
#% 1860547
#! Spam is serious problem that affects email users (e.g. phishing attacks, viruses and time spent reading unwanted messages). We propose a novel spam email filtering approach based on network-level attributes (e.g. the IP sender geographic coordinates) that are more persistent in time when compared to message content. This approach was tested using two classifiers, Naive Bayes (NB) and Support Vector Machines (SVM), and compared against bag-of-words models and eight blacklists. Several experiments were held with recent collected legitimate (ham) and non legitimate (spam) messages, in order to simulate distinct user profiles from two countries (USA and Portugal). Overall, the network-level based SVM model achieved the best discriminatory performance. Moreover, preliminary results suggests that such method is more robust to phishing attacks.

#index 1489149
#* Domain-specific identification of topics and trends in the blogosphere
#@ Rafael Schirru;Darko Obradović;Stephan Baumann;Peter Wortmann
#t 2010
#c 18
#% 282905
#% 466425
#% 643008
#% 797693
#% 1077150
#% 1110110
#% 1728235
#! Staying tuned to the trends and opinions in a certain domain is an important task in many areas. E. g., market researchers want to know about the acceptance of products. Traditionally this is done by screening broadcast media, but in recent years social media like the blogosphere have gained more and more importance. As manual screening of the blogosphere is a tedious task, automated knowledge discovery techniques for trend analysis and topic detection are needed. Our system "Social Media Miner" supports professionals in these tasks. The system aggregates relevant blog articles in a specified domain from blog search services, analyzes their link structure and their importance, provides an overview of the most active topics and identifies general trends in the area. For every topic it gives the analyst access to the most relevant articles. Experiments show that our system achieves a high degree of sound automated processing.

#index 1489150
#* Combining business process and data discovery techniques for analyzing and improving integrated care pathways
#@ Jonas Poelmans;Guido Dedene;Gerda Verheyden;Herman Van Der Mussele;Stijn Viaene;Edward Peters
#t 2010
#c 18
#% 384416
#% 873057
#% 1252969
#% 1415595
#! Hospitals increasingly use process models for structuring their care processes. Activities performed to patients are logged to a database but these data are rarely used for managing and improving the efficiency of care processes and quality of care. In this paper, we propose a synergy of process mining with data discovery techniques. In particular, we analyze a dataset consisting of the activities performed to 148 patients during hospitalization for breast cancer treatment in a hospital in Belgium. We expose multiple quality of care issues that will be resolved in the near future, discover process variations and best practices and we discover issues with the data registration system. For example, 25% of patients receiving breast-conserving therapy did not receive the key intervention "revalidation". We found this was caused by lowering the length of stay in the hospital over the years without modifying the care process. Whereas the process representations offered by Hidden Markov Models are easier to use than those offered by Formal Concept Analysis, this data discovery technique has proven to be very useful for analyzing process anomalies and exceptions in detail.

#index 1489151
#* Interest-determining web browser
#@ Khaled Bashir Shaban;Joannes Chan;Raymond Szeto
#t 2010
#c 18
#% 608756
#% 748613
#% 869484
#! This paper investigates the application of data-mining techniques on a user's browsing history for the purpose of determining the user's interests. More specifically, a system is outlined that attempts to determine certain keywords that a user may or may not be interested in. This is done by first applying a term-frequency/inverse-document frequency filter to extract keywords from webpages in the user's history, after which a Self-Organizing Map (SOM) neural network is utilized to determine if these keywords are of interest to the user. Such a system could enable web-browsers to highlight areas of web pages that may be of higher interest to the user. It is found that while the system is indeed successful in identifying many keywords of user-interest, it also misclassifies many uninteresting words boasting only a 62% accuracy rate.

#index 1489152
#* Web-site boundary detection
#@ Ayesh Alshukri;Frans Coenen;Michele Zito
#t 2010
#c 18
#% 290830
#% 300966
#% 309749
#% 393812
#% 482652
#% 503216
#% 565488
#% 807431
#% 881481
#% 1026854
#% 1055779
#% 1440454
#% 1702891
#! Defining the boundaries of a web-site, for (say) archiving or information retrieval purposes, is an important but complicated task. In this paper a web-page clustering approach to boundary detection is suggested. The principal issue is feature selection, hampered by the observation that there is no clear understanding of what a web-site is. This paper proposes a definition of a web-site, founded on the principle of user intention, directed at the boundary detection problem; and then reports on a sequence of experiments, using a number of clustering techniques, and a wide range of features and combinations of features to identify website boundaries. The preliminary results reported seem to indicate that, in general, a combination of features produces the most appropriate result.

#index 1489153
#* An application of element oriented analysis based credit scoring
#@ Yihao Zhang;Mehmet A. Orgun;Rohan Baxter;Weiqiang Lin
#t 2010
#c 18
#% 312781
#% 780568
#% 1164315
#% 1264136
#! In this paper, we present an application of an Element Oriented Analysis (EOA) credit scoring model used as a classifier for assessing the bad risk records. The model building methodology we used is the Element Oriented Analysis. The objectives in this study are: 1) to develop a stratified model based on EOA to classify the risk for the Brazilian credit card data; 2) to investigate if this model is a satisfactory classifier for this application; 3) to compare the characteristics of our model to the conventional credit scoring models in this specific domain. Classifier performance is measured using the Area under Receiver Operating Characteristic curve (AUC) and overall error rate in out-of-sample tests.

#index 1489154
#* A semi-supervised approach for reject inference in credit scoring using SVMs
#@ Sebastián Maldonado;Gonzalo Paredes
#t 2010
#c 18
#% 697
#% 192878
#% 252011
#% 316509
#% 466263
#% 875970
#% 920212
#% 938769
#% 983807
#% 1193588
#% 1455666
#! This paper presents a novel semi-supervised approach that determines a linear predictor using Support Vector Machines (SVMs) and incorporates information on rejected loans, assuming that the labeled data (accepted applicants) and unlabeled data (rejected applicants) are not drawn from the same distribution. We use a self-training algorithm in order to predict how likely a rejected applicant would have repaid had the applicant received credit. A modification to the self-training algorithm based on Platt's probabilistic output for SVMs is introduced. Experiments with two toy data sets; one well-known benchmark Credit Scoring data set, and one project performed for a Chilean financial institution demonstrate that our approach accomplishes the best classification performance compared to well-known reject inference alternatives and another state-of-the-art semi-supervised method for SVMs (Transductive SVM).

#index 1489155
#* Data mining with neural networks and support vector machines using the R/rminer tool
#@ Paulo Cortez
#t 2010
#c 18
#% 580510
#% 630973
#% 741673
#% 771846
#% 1015722
#% 1277382
#% 1280738
#% 1332126
#% 1860659
#! We present rminer, our open source library for the R tool that facilitates the use of data mining (DM) algorithms, such as neural Networks (NNs) and support vector machines (SVMs), in classification and regression tasks. Tutorial examples with real-world problems (i.e. satellite image analysis and prediction of car prices) were used to demonstrate the rminer capabilities and NN/SVM advantages. Additional experiments were also held to test the rminer predictive capabilities, revealing competitive performances.

#index 1489156
#* The orange customer analysis platform
#@ Raphaël Féraud;Marc Boullé;Fabrice Clérot;Françoise Fessant;Vincent Lemaire
#t 2010
#c 18
#% 1331
#% 136350
#% 246831
#% 479973
#% 722929
#% 829042
#% 893138
#% 893465
#% 929722
#% 1014661
#! In itself, the continuous exponential increase of the data-warehouses size does not necessarily lead to a richer and finer-grained information since the processing capabilities do not increase at the same rate. Current state-of-the-art technologies require the user to strike a delicate balance between the processing cost and the information quality. We describe an industrial approach which leverages recent advances in treatment automatization and relevant data/instance selection and indexing so as to dramatically improve our capability to turn huge volumes of raw data into useful information.

#index 1489157
#* Semi-supervised learning for false alarm reduction
#@ Chien-Yi Chiu;Yuh-Jye Lee;Chien-Chung Chang;Wen-Yang Luo;Hsiu-Chuan Huang
#t 2010
#c 18
#% 252011
#% 340031
#% 340039
#% 790040
#% 832574
#% 978633
#% 1192538
#% 1702372
#! Intrusion Detection Systems (IDSs) which have been deployed in computer networks to detect a wide variety of attacks are suffering how to manage of a large number of triggered alerts. Thus, reducing false alarms efficiently has become the most important issue in IDS. In this paper, we introduce the semi-supervised learning mechanism to build an alert filter, which will reduce up to 85% false alarms and still keep a high detection rate. In our semi-supervised learning approach, we only need a very small amount of label information. This will save a huge security officer's effort and make the alert filter be more practical for the real systems. Numerical comparison with conventional supervised learning approach with the same small portion labeled data, our method has significantly superior detection rate as well as in the false alarm reduction rate.

#index 1489158
#* Learning from humanoid cartoon designs
#@ Md. Tanvirul Islam;Kaiser Md. Nahiduzzaman;Why Yong Peng;Golam Ashraf
#t 2010
#c 18
#% 1952
#% 190581
#% 443645
#% 736085
#% 771041
#% 905218
#% 935496
#% 974970
#% 986052
#% 986106
#% 986107
#% 1657376
#% 1717696
#! Character design is a key ingredient to the success of any comic-book, graphic novel, or animated feature. Artists typically use shape, size and proportion as the first design layer to express role, physicality and personality traits. In this paper, we propose a knowledge mining framework that extracts primitive shape features from finished art, and trains models with labeled metadata attributes. The applications are in shape-based query of character databases as well as label-based generation of basic shape scaffolds, providing an informed starting point for sketching new characters. It paves the way for more intelligent shape indexing of arbitrary well-structured objects in image libraries. Furthermore, it provides an excellent tool for novices and junior artists to learn from the experts. We first describe a novel primitive based shape signature for annotating character body-parts. We then use support vector machine to classify these characters using their body part's shape signature as features. The proposed data transformation is computationally light and yields compact storage. We compare the learning performance of our shape representation with a low-level point feature representation, with substantial improvement.

#index 1489159
#* Mining relationship associations from knowledge about failures using ontology and inference
#@ Weisen Guo;Steven B. Kraines
#t 2010
#c 18
#% 478274
#% 665856
#% 727814
#% 785396
#% 1412475
#% 1696343
#! Mining general knowledge about relationships between concepts described in the analyses of failure cases could help people to avoid repeating previous failures. Furthermore, by representing knowledge using ontologies that support inference, we can identify relationships between concepts more effectively than text-mining techniques. A relationship association is a form of knowledge generalization that is based on binary relationships between entities in semantic graphs. Specifically, relationship associations involve two binary relationships that share a connecting entity and that co-occur frequently in a set of semantic graphs. Such connected relationships can be considered as generalized knowledge mined from a set of knowledge resources, such as failure case descriptions, that are formally represented by the semantic graphs. This paper presents the application of a technique to mine relationship associations from formalized semantic descriptions of failure cases. Results of mining relationship associations in a knowledge base containing 291 semantic graphs representing failure cases are presented.

#index 1489160
#* Event prediction in network monitoring systems: performing sequential pattern mining in Osmius monitoring tool
#@ Rafael García;Luis Llana;Constantino Malagón;Jesús Pancorbo
#t 2010
#c 18
#% 152934
#% 329537
#% 443350
#% 534433
#% 564496
#% 729418
#% 769931
#% 951835
#% 985041
#% 990822
#% 1408783
#% 1417751
#% 1440242
#! Event prediction is one of the most challenging problems in network monitoring systems. This type of inductive knowledge provides monitoring systems with valuable real time predictive capabilities. By obtaining this knowledge, system and network administrators can anticipate and prevent failures. In this paper we present a prediction module for the monitoring software Osmius (www.osmius.net). Osmius has been developed by Peopleware (peopleware.es) under GPL licence. We have extended the Osmius database to store the knowledge we obtain from the algorithms in a highly parametrized way. Thus system administrators can apply the most appropriate settings for each system. Results are presented in terms of positive predictive values and false discovery rates over a huge event database. They confirm that these pattern mining processes will provide network monitoring systems with accurate real time predictive capabilities.

#index 1489161
#* Selection of effective network parameters in attacks for intrusion detection
#@ Gholam Reza Zargar;Peyman Kabiri
#t 2010
#c 18
#% 190581
#% 248792
#% 501015
#% 615776
#% 664662
#% 709657
#% 722929
#% 818916
#% 1059485
#% 1145047
#% 1677431
#! Current Intrusion Detection Systems (IDS) examine a large number of data features to detect intrusion or misuse patterns. Some of the features may be redundant or with a little contribution to the detection process. The purpose of this study is to identify important input features in building an IDS that are computationally efficient and effective. This paper proposes and investigates a selection of effective network parameters for detecting network intrusions that are extracted from Tcpdump DARPA1998 dataset. Here PCA method is used to determine an optimal feature set. An appropriate feature set helps to build efficient decision model as well as to reduce the population of the feature set. Feature reduction will speed up the training and the testing process for the attack identification system considerably. Tcpdump of DARPA1998 intrusion dataset was used in the experiments as the test data. Experimental results indicate a reduction in training and testing time while maintaining the detection accuracy within tolerable range.

#index 1534183
#* Proceedings of the 2010 IEEE International Conference on Data Mining
#@ 
#t 2010
#c 18

#index 1535322
#* Learning a Bi-Stochastic Data Similarity Matrix
#@ Fei Wang;Ping Li;Arnd Christian Konig
#t 2010
#c 18
#! An idealized clustering algorithm seeks to learn a cluster-adjacency matrix such that, if two data points belong to the same cluster, the corresponding entry would be 1, otherwise the entry would be 0. This integer (1/0) constraint makes it difficult to find the optimal solution. We propose a relaxation on the cluster-adjacency matrix, by deriving a bi-stochastic matrix from a data similarity (e.g., kernel) matrix according to the Bregman divergence. Our general method is named the {\em Bregmanian Bi-Stochastication} (BBS) algorithm. We focus on two popular choices of the Bregman divergence: the Euclidian distance and the KL divergence. Interestingly, the BBS algorithm using the KL divergence is equivalent to the Sinkhorn-Knopp (SK) algorithm for deriving bi-stochastic matrices. We show that the BBS algorithm using the Euclidian distance is closely related to the relaxed $k$-means clustering and can often produce noticeably superior clustering results than the SK algorithm (and other algorithms such as Normalized Cut), through extensive experiments on public data sets.

#index 1535323
#* Active Spectral Clustering
#@ Xiang Wang;Ian Davidson
#t 2010
#c 18
#! The technique of spectral clustering is widely used to segment a range of data from graphs to images. Our work marks a natural progression of spectral clustering from the original passive unsupervised formulation to our active semi-supervised formulation. We follow the widely used area of constrained clustering and allow supervision in the form of pair wise relations between two nodes: Must-Link and Cannot-Link. Unlike most previous constrained clustering work, our constraints are specified incrementally by querying an oracle (domain expert). Since in practice, each query comes with a cost, our goal is to maximally improve the result with as few queries as possible. The advantages of our approach include: 1) it is principled by querying the constraints which maximally reduce the expected error, 2) it can incorporate both hard and soft constraints which are prevalent in practice. We empirically show that our method significantly outperforms the baseline approach, namely constrained spectral clustering with randomly selected constraints, on UCI benchmark data sets.

#index 1535324
#* Discovering Overlapping Groups in Social Media
#@ Xufei Wang;Lei Tang;Huiji Gao;Huan Liu
#t 2010
#c 18
#! The increasing popularity of social media is shortening the distance between people. Social activities, e.g., tagging in Flickr, book marking in Delicious, twittering in Twitter, etc. are reshaping people’s social life and redefining their social roles. People with shared interests tend to form their groups in social media, and users within the same community likely exhibit similar social behavior (e.g., going for the same movies, having similar political viewpoints), which in turn reinforces the community structure. The multiple interactions in social activities entail that the community structures are often overlapping, i.e., one person is involved in several communities. We propose a novel co-clustering framework, which takes advantage of networking information between users and tags in social media, to discover these overlapping communities. In our method, users are connected via tags and tags are connected to users. This explicit representation of users and tags is useful for understanding group evolution by looking at who is interested in what. The efficacy of our method is supported by empirical evaluation in both synthetic and online social networking data.

#index 1535325
#* Adaptive Distances on Sets of Vectors
#@ Adam Woznica;Alexandros Kalousis
#t 2010
#c 18
#! Recently, there has been a growing interest in learning distances directly from training data. While the previous works focused mainly on adapting distance measures over vectorial data, it is a well-known fact that many real-world data could not be easily represented as fixed length tuples of constants. In this paper we address this limitation and propose a novel class of distance learning techniques for learning problems in which instances are set of vectors, examples of such problems include, among others, automatic image annotation and graph classification. We investigate the behavior of the adaptive set distances on a number of artificial and real-world problems and demonstrate that they improve over the standard set distances.

#index 1535326
#* SMILE: A Similarity-Based Approach for Multiple Instance Learning
#@ Yanshan Xiao;Bo Liu;Longbing Cao;Jie Yin;Xindong Wu
#t 2010
#c 18
#! Multiple instance learning (MIL) is a generalization of supervised learning which attempts to learn useful information from bags of instances. In MIL, the true labels of the instances in positive bags are not always available for training. This leads to a critical challenge, namely, handling the ambiguity of instance labels in positive bags. To address this issue, this paper proposes a novel MIL method named SMILE (Similarity-based Multiple Instance LEarning). It introduces a similarity weight to each instance in positive bag, which represents the instance similarity towards the positive and negative classes. The instances in positive bags, together with their similarity weights, are thereafter incorporated into the learning phase to build an extended SVM-based predictive classifier. Experiments on three real-world datasets consisting of 12 subsets show that SMILE achieves markedly better classification accuracy than state-of-the-art MIL methods.

#index 1535327
#* Term Filtering with Bounded Error
#@ Zi Yang;Wei Li;Jie Tang;Juanzi Li
#t 2010
#c 18
#! In this paper, we consider a novel problem referred to as term filtering with bounded error to reduce the term (feature) space by eliminating terms without (or with bounded) information loss. Different from existing works, the obtained term space provides a complete view of the original term space. More interestingly, several important questions can be answered such as: 1) how different terms interact with each other and 2) how the filtered terms can be represented by the other terms. We perform a theoretical investigation of the term filtering problem and link it to the Geometric Covering By Discs problem, and prove its NP-hardness. We present two novel approaches for both loss less and lossy term filtering with bounds on the introduced error. Experimental results on multiple text mining tasks validate the effectiveness of the proposed approaches.

#index 1535328
#* Personalizing Web Page Recommendation via Collaborative Filtering and Topic-Aware Markov Model
#@ Qingyan Yang;Ju Fan;Jianyong Wang;Lizhu Zhou
#t 2010
#c 18
#! Web-page recommendation is to predict the next request of pages that Web users are potentially interested in when surfing the Web. This technique can guide Web users to find more useful pages without asking for them explicitly and has attracted much attention in the community of Web mining. However, few studies on Web page recommendation consider personalization, which is an indispensable feature to meet various preferences of users. In this paper, we propose a personalized Web page recommendation model called PIGEON (abbr. for PersonalIzed web paGe rEcommendatiON) via collaborative filtering and a topic-aware Markov model. We propose a graph-based iteration algorithm to discover users' interested topics, based on which user similarities are measured. To recommend topically coherent pages, we propose a topic-aware Markov model to learn users' navigation patterns which capture both temporal and topical relevance of pages. A thorough experimental evaluation conducted on a large real dataset demonstrates PIGEON's effectiveness and efficiency.

#index 1535329
#* Passive Sampling for Regression
#@ Hwanjo Yu;Sungchul Kim
#t 2010
#c 18
#! Active sampling (also called active learning or selective sampling) has been extensively researched for classification and rank learning methods, which is to select the most informative samples from unlabeled data such that, once the samples are labeled, the accuracy of the function learned from the samples is maximized. While active sampling methods require learning a function at each iteration to find the most informative samples, this paper proposes passive sampling techniques for regression, which find the informative samples not based on the learned function but based on the samples' geometric characteristics in the feature space. Passive sampling is more efficient than active sampling, as it does not require, at each iteration, learning and validating the regression functions and evaluating the unlabeled data using the function. For regression, passive sampling is also more effective, Active sampling for regression suffers from serious performance fluctuations in practice, because it selects the samples of highest regression errors and such samples are likely noisy. Passive sampling, on the other hand, shows more stable performance. We observe from our extensive experiments that our passive sampling methods perform even better than the ``omniscient'' active sampling that knows the labels of unlabeled data.

#index 1535330
#* Modeling Experts and Novices in Citizen Science Data for Species Distribution Modeling
#@ Jun Yu;Weng-Keen Wong;Rebecca A. Hutchinson
#t 2010
#c 18
#! Citizen scientists, who are volunteers from the community that participate as field assistants in scientific studies [3], enable research to be performed at much larger spatial and temporal scales than trained scientists can cover. Species distribution modeling [6], which involves understanding species-habitat relationships, is a research area that can benefit greatly from citizen science. The eBird project [16] is one of the largest citizen science programs in existence. By allowing birders to upload observations of bird species to an online database, eBird can provide useful data for species distribution modeling. However, since birders vary in their levels of expertise, the quality of data submitted to eBird is often questioned. In this paper, we develop a probabilistic model called the Occupancy-Detection-Expertise (ODE) model that incorporates the expertise of birders submitting data to eBird. We show that modeling the expertise of birders can improve the accuracy of predicting observations of a bird species at a site. In addition, we can use the ODE model for two other tasks: predicting birder expertise given their history of eBird checklists and identifying bird species that are difficult for novices to detect.

#index 1535331
#* Causal Discovery from Streaming Features
#@ Kui Yu;Xindong Wu;Hao Wang;Wei Ding
#t 2010
#c 18
#! In this paper, we study a new research problem of causal discovery from streaming features. A unique characteristic of streaming features is that not all features can be available before learning begins. Feature generation and selection often have to be interleaved. Managing streaming features has been extensively studied in classification, but little attention has been paid to the problem of causal discovery from streaming features. To this end, we propose a novel algorithm to solve this challenging problem, denoted as CDFSF (Causal Discovery From Streaming Features) which consists of two phases: growing and shrinking. In the growing phase, CDFSF finds candidate parents or children for each feature seen so far, while in the shrinking phase the algorithm dynamically removes false positives from the current sets of candidate parents and children. In order to improve the efficiency of CDFSF, we present S-CDFSF, a faster version of CDFSF, using two symmetry theorems. Experimental results validate our algorithms in comparison with other state-of-art algorithms of causal discovery.

#index 1535332
#* ABS: The Anti Bouncing Model for Usage Data Streams
#@ Chongsheng Zhang;Florent Masseglia;Yves Lechevallier
#t 2010
#c 18
#! Usage data mining is an important research area with applications in various fields. However, usage data is usually considered streaming, due to its high volumes and rates. Because of these characteristics, we only have access, at any point in time, to a small fraction of the stream. When the data is observed through such a limited window, it is challenging to give a reliable description of the recent usage data. We study the important consequences of these constraints, through the “bounce rate” problem and the clustering of usage data streams. Then, we propose the ABS (Anti-Bouncing Stream) model which combines the advantages of previous models but discards their drawbacks. First, under the same resource constraints as existing models in the literature, ABS can better model the recent data. Second, owing to its simple but effective management approach, the data in ABS is available at any time for analysis. We demonstrate its superiority through a theoretical study and experiments on two real-world data sets.

#index 1535333
#* Modeling Information Diffusion in Implicit Networks
#@ Jaewon Yang;Jure Leskovec
#t 2010
#c 18
#! Social media forms a central domain for the production and dissemination of real-time information. Even though such flows of information have traditionally been thought of as diffusion processes over social networks, the underlying phenomena are the result of a complex web of interactions among numerous participants. Here we develop the Linear Influence Model where rather than requiring the knowledge of the social network and then modeling the diffusion by predicting which node will influence which other nodes in the network, we focus on modeling the global influence of a node on the rate of diffusion through the (implicit) network. We model the number of newly infected nodes as a function of which other nodes got infected in the past. For each node we estimate an influence function that quantifies how many subsequent infections can be attributed to the influence of that node over time. A nonparametric formulation of the model leads to a simple least squares problem that can be solved on large datasets. We validate our model on a set of 500 million tweets and a set of 170 million news articles and blog posts. We show that the Linear Influence Model accurately models influences of nodes and reliably predicts the temporal dynamics of information diffusion. We find that patterns of influence of individual participants differ significantly depending on the type of the node and the topic of the information.

#index 1535334
#* Exploiting Unlabeled Data to Enhance Ensemble Diversity
#@ Min-Ling Zhang;Zhi-Hua Zhou
#t 2010
#c 18
#! Ensemble learning aims to improve generalization ability by using multiple base learners. It is well-known that to construct a good ensemble, the base learners should be accurate as well as diverse. In this paper, unlabeled data is exploited to facilitate ensemble learning by helping augment the diversity among the base learners. Specifically, a semi-supervised ensemble method named UDEED is proposed. Unlike existing semi-supervised ensemble methods where error-prone pseudo-labels are estimated for unlabeled data to enlarge the labeled data to improve accuracy, UDEED works by maximizing accuracies of base learners on labeled data while maximizing diversity among them on unlabeled data. Experiments show that UDEED can effectively utilize unlabeled data for ensemble learning and is highly competitive to well-established semi-supervised ensemble methods.

#index 1535335
#* Constraint Based Dimension Correlation and Distance Divergence for Clustering High-Dimensional Data
#@ Xianchao Zhang;Yao Wu;Yang Qiu
#t 2010
#c 18
#! Clusters are hidden in subspaces of high dimensional data, i.e., only a subset of features is relevant for each cluster. Subspace clustering is challenging since the search for the relevant features of each cluster and the detection of the final clusters are circular dependent and should be solved simultaneously. In this paper, we point out that feature correlation and distance divergence are important to subspace clustering, but both have not been considered in previous works. Feature correlation groups correlated features independently thus helps to reduce the search space for the relevant features search problem. Distance divergence distinguishes distances on different dimensions and helps to find the final clusters accurately. We tackle the two problems with the aid of a small amount domain knowledge in the form of must-links and cannot-links. We then devise a semi-supervised subspace clustering algorithm CDCDD. CDCDD integrates our solutions of the feature correlation and distance divergence problems, and uses an adaptive dimension voting scheme, which is derived from a previous unsupervised subspace clustering algorithm FINDIT. Experimental results on both synthetic data sets and real data sets show that the proposed CDCDD algorithm outperforms FINDIT in terms of accuracy, and outperforms the other constraint based algorithm SCMINER in terms of both accuracy and efficiency.

#index 1535336
#* Active Learning from Multiple Noisy Labelers with Varied Costs
#@ Yaling Zheng;Stephen Scott;Kun Deng
#t 2010
#c 18
#! In active learning, where a learning algorithm has to purchase the labels of its training examples, it is often assumed that there is only one labeler available to label examples, and that this labeler is noise-free. In reality, it is possible that there are multiple labelers available (such as human labelers in the online annotation tool Amazon Mechanical Turk) and that each such labeler has a different cost and accuracy. We address the active learning problem with multiple labelers where each labeler has a different (known) cost and a different (unknown) accuracy. Our approach uses the idea of {\em adjusted cost}, which allows labelers with different costs and accuracies to be directly compared. This allows our algorithm to find low-cost combinations of labelers that result in high-accuracy labelings of instances. Our algorithm further reduces costs by pruning under performing labelers from the set under consideration, and by halting the process of estimating the accuracy of the labelers as early as it can. We found that our algorithm often outperforms, and is always competitive with, other algorithms in the literature.

#index 1535337
#* A Novel Contrast Co-learning Framework for Generating High Quality Training Data
#@ Zeyu Zheng;Jun Yan;Shuicheng Yan;Ning Liu;Zheng Chen;Ming Zhang
#t 2010
#c 18
#! The good performances of most classical learning algorithms are generally founded on high quality training data, which are clean and unbiased. The availability of such data is however becoming much harder than ever in many real world problems due to the difficulties in collecting large scale unbiased data and precisely labeling them for training. In this paper, we propose a general Contrast Co-learning (CCL) framework to refine the biased and noisy training data when an unbiased yet unlabeled data pool is available. CCL starts with multiple sets of probably biased and noisy training data and trains a set of classifiers individually. Then under the assumption that the confidently classified data samples may have higher probabilities to be correctly classified, CCL iteratively and automatically filtering out possible data noises as well as adding those confidently classified samples from the unlabeled data pool to correct the bias. Through this process, we can generate a cleaner and unbiased training dataset with theoretical guarantees. Extensive experiments on two public text datasets clearly show that CCL consistently improves the algorithmic classification performance on biased and noisy training data compared with several state-of-the-art classical algorithms.

#index 1535338
#* Classifier and Cluster Ensembles for Mining Concept Drifting Data Streams
#@ Peng Zhang;Xingquan Zhu;Jianlong Tan;Li Guo
#t 2010
#c 18
#! Ensemble learning is a commonly used tool for building prediction models from data streams, due to its intrinsic merits of handling large volumes stream data. Despite of its extraordinary successes in stream data mining, existing ensemble models, in stream data environments, mainly fall into the ensemble classifiers category, without realizing that building classifiers requires labor intensive labeling process, and it is often the case that we may have a small number of labeled samples to train a few classifiers, but a large number of unlabeled samples are available to build clusters from data streams. Accordingly, in this paper, we propose a new ensemble model which combines both classifiers and clusters together for mining data streams. We argue that the main challenges of this new ensemble model include (1) clusters formulated from data streams only carry cluster IDs, with no genuine class label information, and (2) concept drifting underlying data streams makes it even harder to combine clusters and classifiers into one ensemble framework. To handle challenge (1), we present a label propagation method to infer each cluster's class label by making full use of both class label information from classifiers, and internal structure information from clusters. To handle challenge (2), we present a new weighting schema to weight all base models according to their consistencies with the up-to-date base model. As a result, all classifiers and clusters can be combined together, through a weighted average mechanism, for prediction. Experiments on real-world data streams demonstrate that our method outperforms simple classifier ensemble and cluster ensemble for stream data mining.

#index 1535339
#* Graph-Based Semi-supervised Learning with Adaptive Similarity Estimation
#@ Xianchao Zhang;Yansheng Jiang;Wenxin Liang;Xin Han
#t 2010
#c 18
#! Graph-based semi-supervised learning algorithms have attracted a lot of attention. Constructing a good graph is playing an essential role for all these algorithms. Many existing graph construction methods(e.g. Gaussian Kernel etc.) require user input parameter, which is hard to configure manually. In this paper, we propose a parameter-free similarity measure Adaptive Similarity Estimation (ASE), which constructs the graph by adaptively optimizing linear combination of its neighbors. Experimental results show the effectiveness of our proposed method.

#index 1535340
#* K-AP: Generating Specified K Clusters by Efficient Affinity Propagation
#@ Xiangliang Zhang;Wei Wang;Kjetil Norvag;Michele Sebag
#t 2010
#c 18
#! The Affinity Propagation (AP) clustering algorithm proposed by Frey and Dueck (2007) provides an understandable, nearly optimal summary of a data set. However, it suffers two major shortcomings: i) the number of clusters is vague with the user-defined parameter called self-confidence, and ii) the quadratic computational complexity. When aiming at a given number of clusters due to prior knowledge, AP has to be launched many times until an appropriate setting of self-confidence is found. The re-launched AP increases the computational cost by one order of magnitude. In this paper, we propose an algorithm, called K-AP, to exploit the immediate results of K clusters by introducing a constraint in the process of message passing. Through theoretical analysis and experimental validation, K-AP was shown to be able to directly generate K clusters as user defined, with a negligible increase of computational cost compared to AP. In the meanwhile, KAP preserves the clustering quality as AP in terms of the distortion. K-AP is more effective than k-medoids w.r.t. the distortion minimization and higher clustering purity.

#index 1535341
#* MoodCast: Emotion Prediction via Dynamic Continuous Factor Graph Model
#@ Yuan Zhang;Jie Tang;Jimeng Sun;Yiran Chen;Jinghai Rao
#t 2010
#c 18
#! Human emotion is one important underlying force affecting and affected by the dynamics of social networks. An interesting question is “can we predict a person’s mood based on his historic emotion log and his social network?”. In this paper, we propose a Mood Cast method based on a dynamic continuous factor graph model for modeling and predicting users’ emotions in a social network. Mood Cast incorporates users’ dynamic status information (e.g., locations, activities, and attributes) and social influence from users’ friends into a unified model. Based on the historical information (e.g., network structure and users’ status from time 0 to t−1), Mood Cast learns a discriminative model for predicting users’ emotion status at time t. To the best of our knowledge, this work takes the first step in designing a principled model for emotion prediction in social networks. Our experimental results on both real social network and virtual web-based network show that we can accurately predict emotion status of more than 62% of users and 8+% improvement than the baseline methods.

#index 1535342
#* Hierarchical Ensemble Clustering
#@ Li Zheng;Tao Li;Chris Ding
#t 2010
#c 18
#! Ensemble clustering has emerged as an important elaboration of the classical clustering problems. Ensemble clustering refers to the situation in which a number of different (input) clusterings have been obtained for a particular dataset and it is desired to find a single (consensus) clustering which is a better fit in some sense than the existing clusterings. Many approaches have been developed to solve ensemble clustering problems over the last few years. However, most of these ensemble techniques are designed for partitional clustering methods. Few research efforts have been reported for ensemble hierarchical clustering methods. In this paper, we propose a hierarchical ensemble clustering framework which can naturally combine both partitional clustering and hierarchical clustering results. We notice the importance of ultra-metric distance for hierarchical clustering and propose a novel method for learning the ultra-metric distance from the aggregated distance matrices and generating final hierarchical clustering with enhanced cluster separation. Experimental results demonstrate the effectiveness of our proposed approaches.

#index 1535343
#* Network Simplification with Minimal Loss of Connectivity
#@ Fang Zhou;Sebastien Malher;Hannu Toivonen
#t 2010
#c 18
#! We propose a novel problem to simplify weighted graphs by pruning least important edges from them. Simplified graphs can be used to improve visualization of a network, to extract its main structure, or as a pre-processing step for other data mining algorithms. We define a graph connectivity function based on the best paths between all pairs of nodes. Given the number of edges to be pruned, the problem is then to select a subset of edges that best maintains the overall graph connectivity. Our model is applicable to a wide range of settings, including probabilistic graphs, flow graphs and distance graphs, since the path quality function that is used to find best paths can be defined by the user. We analyze the problem, and give lower bounds for the effect of individual edge removal in the case where the path quality function has a natural recursive property. We then propose a range of algorithms and report on experimental results on real networks derived from public biological databases. The results show that a large fraction of edges can be removed quite fast and with minimal effect on the overall graph connectivity. A rough semantic analysis of the removed edges indicates that few important edges were removed, and that the proposed approach could be a valuable tool in aiding users to view or explore weighted graphs.

#index 1535344
#* Improving Kernel Methods through Complex Data Mapping
#@ Hang Zhou;Fabio Ramos;Eric Nettleton
#t 2010
#c 18
#! This paper introduces a simple yet powerful data transformation strategy for kernel machines. Instead of adapting the parameters of the kernel function w.r.t. the given data (as in conventional methods), we adjust both the kernel hyper-parameters and the given data itself. Using this approach, the input data is transformed to be more representative of the assumptions encoded in the kernel function. A novel complex mapping is proposed to nonlinearly adjust the data. Optimization of the data transformation parameters is performed in two different manners. Firstly, the complex data mapping parameters and kernel hyper-parameters are selected separately, with the former guided by frequency metrics and the latter under the Bayesian framework. Next, the complex data mapping parameters and kernel hyper-parameters are optimized simultaneously in a Bayesian formulation by creating a new category of "integrated kernel" with the complex data mapping embedded. Experiments using Gaussian Process learning have shown that both methods improve the learning accuracy in either classification or regression tasks, with the complex mapping embedded kernel approach outperforming the separate complex mapping one.

#index 1535345
#* NESVM: A Fast Gradient Method for Support Vector Machines
#@ Tianyi Zhou;Dacheng Tao;Xindong Wu
#t 2010
#c 18
#! Support vector machines (SVMs) are invaluable tools for many practical applications in artificial intelligence, e.g., classification and event recognition. However, popular SVM solvers are not sufficiently efficient for applications with a great deal of samples as well as a large number of features. In this paper, thus, we present NESVM, a fast gradient SVM solver that can optimize various SVM models, e.g., classical SVM, linear programming SVM and least square SVM. Compared against SVM-Perf \cite{SVM_Perf}\cite{PerfML} (whose convergence rate in solving the dual SVM is upper bounded by $\mathcal O(1/\sqrt{k})$ where $k$ is the number of iterations) and Pegasos \cite{Pegasos} (online SVM that converges at rate $\mathcal O(1/k)$ for the primal SVM), NESVM achieves the optimal convergence rate at $\mathcal O(1/k^{2})$ and a linear time complexity. In particular, NESVM smoothes the non-differentiable hinge loss and $\ell_1$-norm in the primal SVM. Then the optimal gradient method without any line search is adopted to solve the optimization. In each iteration round, the current gradient and historical gradients are combined to determine the descent direction, while the Lipschitz constant determines the step size. Only two matrix-vector multiplications are required in each iteration round. Therefore, NESVM is more efficient than existing SVM solvers. In addition, NESVM is available for both linear and nonlinear kernels. We also propose ``homotopy NESVM'' to accelerate NESVM by dynamically decreasing the smooth parameter and using the continuation method. Our experiments on census income categorization, indoor/outdoor scene classification, event recognition and scene recognition suggest the efficiency and the effectiveness of NESVM. The MATLAB code of NESVM will be available on our website for further assessment.

#index 1535346
#* Clustering Large Attributed Graphs: An Efficient Incremental Approach
#@ Yang Zhou;Hong Cheng;Jeffrey Xu Yu
#t 2010
#c 18
#! In recent years, many networks have become available for analysis, including social networks, sensor networks, biological networks, etc. Graph clustering has shown its effectiveness in analyzing and visualizing large networks. The goal of graph clustering is to partition vertices in a large graph into clusters based on various criteria such as vertex connectivity or neighborhood similarity. Many existing graph clustering methods mainly focus on the topological structures, but largely ignore the vertex properties which are often heterogeneous. Recently, a new graph clustering algorithm, SA-Cluster, has been proposed which combines structural and attribute similarities through a unified distance measure. SA-Cluster performs matrix multiplication to calculate the random walk distances between graph vertices. As the edge weights are iteratively adjusted to balance the importance between structural and attribute similarities, matrix multiplication is repeated in each iteration of the clustering process to recalculate the random walk distances which are affected by the edge weight update. In order to improve the efficiency and scalability of SA-Cluster, in this paper, we propose an efficient algorithm Inc-Cluster to incrementally update the random walk distances given the edge weight increments. Complexity analysis is provided to estimate how much runtime cost Inc-Cluster can save. Experimental results demonstrate that Inc-Cluster achieves significant speedup over SA-Cluster on large graphs, while achieving exactly the same clustering quality in terms of intra-cluster structural cohesiveness and attribute value homogeneity.

#index 1535347
#* Frequent Instruction Sequential Pattern Mining in Hardware Sample Data
#@ Jia Zou;Jing Xiao;Rui Hou;Yanqi Wang
#t 2010
#c 18
#! When parallelism and heterogeneity has become the trend for computer system design, both the size and the complexity of the hardware sample data generated by Performance Monitoring Unit (PMU) increase fast, thus automatic analysis methods, i.e. data mining methods, are urgently needed to accelerate hardware sample data analysis. We are the first to study instruction sequential pattern mining for hardware sample data. It is a challenging task due to the implicit sequential relationship contained in the data and due to the importance of low frequency patterns. As a solution, we i) provide a novel algorithm ProfSpan, ii) adapt two existing algorithms, which are based on candidate generation and projected database generation, to hardware sample data. Our evaluation results show ProfSpan can reduce up to 75% and 80% of execution time compared with other two algorithms. Particularly, up to 50% of frequent patterns mined by ProfSpan in hardware sample data are crossing basic block boundaries and can not be found by existing methods for source code or disassembly code. We also analyze three example patterns identified by ProfSpan: consecutive loads, JIT entry sequence, and conditional code dependency sequence, to illustrate how ProfSpan can benefit performance analysis. Finally, we apply patterns to module classification and obtain promising results.

#index 1535348
#* Efficient Episode Mining with Minimal and Non-overlapping Occurrences
#@ Huisheng Zhu;Peng Wang;Xianmang He;Yujia Li;Wei Wang;Baile Shi
#t 2010
#c 18
#! Frequent serial episodes within an event sequence describe the behavior of users or systems about the application. Existing mining algorithms calculate the frequency of an episode based on overlapping or non-minimal occurrences, which is prone to over-counting the support of long episodes or poorly characterizing the followed-by-closely relationship over event types. In addition, due to utilizing the Apriori-style level wise approach, these algorithms are computationally expensive. In this paper, we propose an efficient algorithm MANEPI (Minimal And Non-overlapping EPIsode) for mining more interesting frequent episodes within the given event sequence. The proposed frequency measure takes both minimal and non-overlapping occurrences of an episode into consideration and ensures better mining quality. The introduced depth first search strategy with the Apriori Property for performing episode growth greatly improves the efficiency of mining long episodes because of scanning the given sequence only once and not generating candidate episodes. Moreover, an optimization technique is presented to narrow down search space and speed up the mining process. Experimental evaluation on both synthetic and real-world datasets demonstrates that our algorithms are more efficient and effective.

#index 1535349
#* Spatial and Spatio-temporal Data Mining
#@ Vania Bogorny;Shashi Shekhar
#t 2010
#c 18
#! The recent advances and price reduction of technologies for collecting spatial and spatio-temporal data like Satellite Images, Cellular Phones, Sensor Networks, and GPS devices has facilitated the collection of data referenced in space and time. These huge collections of data often hide interesting information which conventional systems and classical data mining techniques are unable to discover. Spatial and spatio-temporal data are embedded in continuous space, whereas classical datasets (e.g. transactions) are often discrete. Spatial and spatio-temporal data require complex data preprocessing, transformation, data mining, and post-processing techniques to extract novel, useful, and understandable patterns. The importance of spatial and spatio-temporal data mining is growing with the increasing incidence and importance of large geo-spatial datasets such as maps, repositories of remote-sensing images, trajectories of moving objects generated by mobile devices, etc. Applications include Mobile-commerce industry (location-based services), climatologically effects of El Nino, land-use classification and global change using satellite imagery, finding crime hot spots, local instability in traffic, migration of birds, fishing control, pedestrian behavior analysis, and so on. Thus, new methods are needed to analyze spatial and spatio-temporal data to extract interesting, useful, and non-trivial patterns. The main goal of this tutorial is to disseminate this research field, giving an overview of the current state of the art and the main methodologies and algorithms for spatial and spatio-temporal data mining. This tutorial is directed to researches and practitioners, experts in data mining, analysts of spatial and spatio-temporal data, as well as knowledge engineers and domain experts from different application areas.

#index 1535350
#* Knowledge Discovery in Academic Drug Discovery Programs: Opportunities and Challenges
#@ Jun Huan
#t 2010
#c 18
#! In United State several universities and research institutes including the national health institute (NIH) recently started programs aiming for drug discovery. With the initiatives, huge volumes of data have been collected and shared with public free of charge. Those initiatives provide an unprecedented opportunity for data miner and machine learner to study knowledge discovery problems associated with drug design. In this tutorial, the presenter will review the knowledge discovery and management needs in the drug discovery process. Latest methodology development, primarily those from data mining, machine learning, and statistical learning will be discussed.

#index 1535351
#* How to Do Good Data Mining Research and Get it Published in Top Venues
#@ Eamonn Keogh
#t 2010
#c 18
#! While ICDM has traditionally enjoyed an unusually high quality of reviewing, there is no doubt that publishing in ICDM is very challenging. In this tutorial Dr. Keogh will demonstrate some simple ideas to enhance the probability of success in getting your paper published in a top data mining conference, and after the work is published, getting it highly cited.

#index 1535352
#* Mother Fugger: Mining Historical Manuscripts with Local Color Patches
#@ Qiang Zhu;Eamonn Keogh
#t 2010
#c 18
#! Initiatives such as the Google Print Library Project and the Million Book Project have already archived more than ten million books in digital format, and within the next decade the majority of world’s books will be online. Although most of the data will naturally be text, there will also be tens of millions of pages of images, many in color. While there is an active research community pursuing data mining of text from historical manuscripts, there has been very little work that exploits the rich color information which is often present. In this work we introduce a simple color measure which both addresses and exploits typical features of historical manuscripts. To enable the efficient mining of massive archives, we propose a tight lower bound to the measure. Beyond the fast similarity search, we show how this lower bound allows us to build several higher-level data mining tools, including motif discovery and link analyses. We demonstrate our ideas in several data mining tasks on manuscripts dating back to the fifteenth century.

#index 1535353
#* D-LDA: A Topic Modeling Approach without Constraint Generation for Semi-defined Classification
#@ Fuzhen Zhuang;Ping Luo;Zhiyong Shen;Qing He;Yuhong Xiong;Zhongzhi Shi
#t 2010
#c 18
#! We study what we call semi-defined classification, which deals with the categorization tasks where the taxonomy of the data is not well defined in advance. It is motivated by the real-world applications, where the unlabeled data may also come from some other unknown classes besides the known classes for the labeled data. Given the unlabeled data, our goal is to not only identify the instances belonging to the known classes, but also cluster the remaining data into other meaningful groups. It differs from traditional semi-supervised clustering in the sense that in semi-supervised clustering the supervision knowledge is too far from being representative of a target classification, while in semi-defined classification the labeled data may be enough to supervise the learning on the known classes. In this paper we propose the model of Double-latent-layered LDA (D-LDA for short) for this problem. Compared with LDA with only one latent variable y for word topics, D-LDA contains another latent variable z for (known and unknown) document classes. With this double latent layers consisting of y and z and the dependency between them, D-LDA directly injects the class labels into z to supervise the exploiting of word topics in y. Thus, the semi-supervised learning in D-LDA does not need the generation of pair wise constraints, which is required in most of the previous semi-supervised clustering approaches. We present the experimental results on ten different data sets for semi-defined classification. Our results are either comparable to (on one data sets), or significantly better (on the other nine data set) than the six compared methods, including the state-of-the-art semi-supervised clustering methods.

#index 1535354
#* SONNET: Efficient Approximate Nearest Neighbor Using Multi-core
#@ Mohammad Al Hasan;Hilmi Yildirim;Abhirup Chakraborty
#t 2010
#c 18
#! Approximate Nearest Neighbor search over high dimensional data is an important problem with a wide range of practical applications. In this paper, we propose SONNET, a simple multi-core friendly approximate nearest neighbor algorithm that is based on rank aggregation. SONNET is particularly suitable for very high dimensional data, its performance gets better as the dimension increases, whereas the majority of the existing algorithms show a reverse trend. Furthermore, most of the existing algorithms are hard to parallelize either due to the sequential nature of the algorithm or due to the inherent complexity of the algorithm. On the other hand, SONNET has inherent parallelism embedded in the core concept of the algorithm, which earns it almost a linear speed-up as the number of cores increases. Finally, SONNET is very easy to implement and it has an approximation parameter which is intuitively simple.

#index 1535355
#* Two of a Kind or the Ratings Game? Adaptive Pairwise Preferences and Latent Factor Models
#@ Suhrid Balakrishnan;Sumit Chopra
#t 2010
#c 18
#! While latent factor models are built using ratings data, which is typically assumed static, the ability to incorporate different kinds of subsequent user feedback is an important asset. For instance, the user might want to provide additional information to the system in order to improve his personal recommendations. To this end, we examine a novel scheme for efficiently learning (or refining) user parameters from such feedback. We propose a scheme where users are presented with a sequence of pair wise preference questions: "Do you prefer item A over B?". User parameters are updated based on their response, and subsequent questions are chosen adaptively after incorporating the feedback. We operate in a Bayesian framework and the choice of questions is based on an information gain criterion. We validate the scheme on the Netflix movie ratings data set. A user study and automated experiments validate our findings.

#index 1535356
#* Document Similarity Self-Join with MapReduce
#@ Ranieri Baraglia;Gianmarco De Francisci Morales;Claudio Lucchese
#t 2010
#c 18
#! iven a collection of objects, the Similarity Self-Join problem requires to discover all those pairs of objects whose similarity is above a user defined threshold. In this paper we focus on document collections, which are characterized by a sparseness that allows effective pruning strategies. Our contribution is a new parallel algorithm within the MapReduce framework. This work borrows from the state of the art in serial algorithms for similarity join and MapReduce-based techniques for set-similarity join. The proposed algorithm shows that it is possible to leverage a distributed file system to support communication patterns that do not naturally fit the MapReduce framework. Scalability is achieved by introducing a partitioning strategy able to overcome memory bottlenecks. Experimental evidence on real world data shows that our algorithm outperforms the state of the art by a factor 4.5.

#index 1535357
#* Discovering Multiple Clustering Solutions: Grouping Objects in Different Views of the Data
#@ Emmanuel Muller;Stephan Gunnemann;Ines Farber;Thomas Seidl
#t 2010
#c 18
#! Traditional clustering algorithms identify just a single clustering of the data. Today's complex data, however, allow multiple interpretations leading to several valid groupings hidden in different views of the database. Each of these multiple clustering solutions is valuable and interesting as different perspectives on the same data and several meaningful groupings for each object are given. Especially for high dimensional data where each object is described by multiple attributes, alternative clusters in different attribute subsets are of major interest. In this tutorial, we describe several real world application scenarios for multiple clustering solutions. We abstract from these scenarios and provide the general challenges in this emerging research area. We describe state-of-the-art paradigms, we highlight specific techniques, and we give an overview of this topic by providing a taxonomy of the existing methods. By focusing on open challenges, we try to attract young researchers for participating in this emerging research field.

#index 1535358
#* Mining Billion-node Graphs: Patterns, Generators and Tools
#@ Christos Faloutsos
#t 2010
#c 18

#index 1535359
#* Assessing the Significance of Groups in High-Dimensional Data
#@ Geoff McLachlan
#t 2010
#c 18

#index 1535360
#* 10 Years of Data Mining Research: Retrospect and Prospect
#@ Xindong Wu
#t 2010
#c 18

#index 1535361
#* Detecting Novel Discrepancies in Communication Networks
#@ James Abello;Tina Eliassi-Rad;Nishchal Devanur
#t 2010
#c 18
#! We address the problem of detecting characteristic patterns in communication networks. We introduce a scalable approach based on set-system discrepancy. By implicitly labeling each network edge with the sequence of times in which its two endpoints communicate, we view an entire communication network as a set-system. This view allows us to use combinatorial discrepancy as a mechanism to "observe" system behavior at different time scales. We illustrate our approach, called Discrepancy-based Novelty Detector (DND), on networks obtained from emails, blue tooth connections, IP traffic, and tweets. DND has almost linear runtime complexity and linear storage complexity in the number of communications. Examples of novel discrepancies that it detects are (i) asynchronous communications and (ii) disagreements in the firing rates of nodes and edges relative to the communication network as a whole.

#index 1535362
#* Multi-agent Random Walks for Local Clustering on Graphs
#@ Morteza Alamgir;Ulrike von Luxburg
#t 2010
#c 18
#! We consider the problem of local graph clustering where the aim is to discover the local cluster corresponding to a point of interest. The most popular algorithms to solve this problem start a random walk at the point of interest and let it run until some stopping criterion is met. The vertices visited are then considered the local cluster. We suggest a more powerful alternative, the multi-agent random walk. It consists of several ``agents'' connected by a fixed rope of length l. All agents move independently like a standard random walk on the graph, but they are constrained to have distance at most l from each other. The main insight is that for several agents it is harder to simultaneously travel over the bottleneck of a graph than for just one agent. Hence, the multi-agent random walk has less tendency to mistakenly merge two different clusters than the original random walk. In our paper we analyze the multi-agent random walk theoretically and compare it experimentally to the major local graph clustering algorithms from the literature. We find that our multi-agent random walk consistently outperforms these algorithms.

#index 1535363
#* Spatiotemporal Event Detection in Mobility Network
#@ Tom S. Au;Rong Duan;Heeyoung Kim;Guang-Qin Ma
#t 2010
#c 18
#! Learning and identifying events in network traffic is crucial for service providers to improve their mobility network performance. In fact, large special events attract cell phone users to relative small areas, which causes sudden surge in network traffic. To handle such increased load, it is necessary to measure the increased network traffic and quantify the impact of the events, so that relevant resources can be optimized to enhance the network capability. However, this problem is challenging due to several issues: (1) Multiple periodic temporal traffic patterns (i.e., nonhomogeneous process) even for normal traffic, (2) Irregularly distributed spatial neighbor information, (3) Different temporal patterns driven by different events even for spatial neighborhoods, (4) Large scale data set. This paper proposes a systematic event detection method that deals with the above problems. With the additivity property of Poisson process, we propose an algorithm to integrate spatial information by aggregating the behavior of temporal data under various areas. Markov Modulated Nonhomogeneous Poisson Process (MMNHPP) is employed to estimate the probability with which event happens, when and where the events take place, and assess the spatial and temporal impacts of the events. Localized events are then ranked globally for prioritizing more significant events. Synthetic data are generated to illustrate our procedure and validate the performance. An industrial example from a telecommunication company is also presented to show the effectiveness of the proposed method.

#index 1535364
#* Feature Selection for Unsupervised Learning Using Random Cluster Ensembles
#@ Haytham Elghazel;Alex Aussem
#t 2010
#c 18
#! In this paper, we propose another extension of the Random Forests paradigm to unlabeled data, leading to localized unsupervised feature selection (FS). We show that the way internal estimates are used to measure variable importance in Random Forests are also applicable to FS in unsupervised learning. We first illustrate the clustering performance of the proposed method on various data sets based on widely used external criteria of clustering quality. We then assess the accuracy and the scalability of the FS procedure on UCI and real labeled data sets and compare its effectiveness against other FS methods.

#index 1535365
#* Quantification via Probability Estimators
#@ Antonio Bella;Cesar Ferri;Jose Hernandez-Orallo;Maria Jose Ramirez-Quintana
#t 2010
#c 18
#! Quantification is the name given to a novel machine learning task which deals with correctly estimating the number of elements of one class in a set of examples. The output of a quantifier is a real value, since training instances are the same as a classification problem, a natural approach is to train a classifier and to derive a quantifier from it. Some previous works have shown that just classifying the instances and counting the examples belonging to the class of interest classify count typically yields bad quantifiers, especially when the class distribution may vary between training and test. Hence, adjusted versions of classify count have been developed by using modified thresholds. However, previous works have explicitly discarded (without a deep analysis) any possible approach based on the probability estimations of the classifier. In this paper, we present a method based on averaging the probability estimations of a classifier with a very simple scaling that does perform reasonably well, showing that probability estimators for quantification capture a richer view of the problem than methods based on a threshold.

#index 1535366
#* Learning Collaborative Filtering and Its Application to People to People Recommendation in Social Networks
#@ Xiongcai Cai;Michael Bain;Alfred Krzywicki;Wayne Wobcke;Yang Sok Kim;Paul Compton;Ashesh Mahidadia
#t 2010
#c 18
#! Predicting people who other people may like has recently become an important task in many online social networks. Traditional collaborative filtering (CF) approaches are popular in recommender systems to effectively predict user preferences for items. One major problem in CF is computing similarity between users or items. Traditional CF methods often use heuristic methods to combine the ratings given to an item by similar users, which may not reflect the characteristics of the active user and can give unsatisfactory performance. In contrast to heuristic approaches we have developed CollabNet, a novel algorithm that uses gradient descent to learn the relative contributions of similar users or items to the ranking of recommendations produced by a recommender system, using weights to represent the contributions of similar users for each active user. We have applied CollabNet to the challenging problem of people to people recommendation in social networks, where people have a dual role as both "users" and "items", e.g., both initiating and receiving communications, to recommend other users to a given user, based on user similarity in terms of both taste (whom they like) and attractiveness (who likes them). Evaluation of CollabNet recommendations on datasets from a commercial online social network shows improved performance over standard CF.

#index 1535367
#* Approximation of Frequentness Probability of Itemsets in Uncertain Data
#@ Toon Calders;Calin Garboni;Bart Goethals
#t 2010
#c 18
#! Mining frequent item sets from transactional datasets is a well known problem with good algorithmic solutions. Most of these algorithms assume that the input data is free from errors. Real data, however, is often affected by noise. Such noise can be represented by uncertain datasets in which each item has an existence probability. Recently, Bernecker et al. (2009) proposed the frequentness probability, i.e., the probability that a given item set is frequent, to select item sets in an uncertain database. A dynamic programming approach to evaluate this measure was given as well. We argue, however, that for the setting of Bernecker et al. (2009), that assumes independence between the items, already well-known statistical tools exist. We show how the frequentness probability can be approximated extremely accurately using a form of the central limit theorem. We experimentally evaluated our approximation and compared it to the dynamic programming approach. The evaluation shows that our approximation method is extremely accurate even for very small databases while at the same time it has much lower memory overhead and computation time.

#index 1535368
#* On Finding Frequent Patterns in Event Sequences
#@ Andrea Campagna;Rasmus Pagh
#t 2010
#c 18
#! Given a directed a cyclic graph with labeled vertices, we consider the problem of finding the most common label sequences ("traces") among all paths in the graph (of some maximum length m). Since the number of paths can be huge, we propose novel algorithms whose time complexity depends only on the size of the graph, and on the frequency \varepsilon of the most frequent traces. In addition, we apply techniques from streaming algorithms to achieve space usage that depends only on \varepsilon, and not on the number of distinct traces. The abstract problem considered models a variety of tasks concerning finding frequent patterns in event sequences. Our motivation comes from working with a data set of 2 million RFID readings from baggage trolleys at Copenhagen Airport. The question of finding frequent passenger movement patterns is mapped to the above problem. We report on experimental findings for this data set.

#index 1535369
#* Active Improvement of Hierarchical Object Features under Budget Constraints
#@ Nicolas Cebron
#t 2010
#c 18
#! When we think of an object in a supervised learning setting, we usually perceive it as a collection of fixed attribute values. Although this setting may be suited well for many classification tasks, we propose a new object representation and therewith a new challenge in data mining: an object is no longer described by one set of attributes but is represented in a hierarchy of attribute sets in different levels of quality. Obtaining a more detailed representation of an object comes with a cost. This raises the interesting question of which objects we want to enhance under a given budget and cost model. This new setting is very useful whenever resources like computing power, memory or time are limited. We propose a new Active Adaptive Algorithm (AAA) to improve objects in an iterative fashion. We demonstrate how to create a hierarchical object representation and prove the effectiveness of our new selection algorithm on these datasets.

#index 1535370
#* An Unsupervised Approach to Modeling Personalized Contexts of Mobile Users
#@ Tengfei Bao;Happia Cao;Enhong Chen;Jilei Tian;Hui Xiong
#t 2010
#c 18
#! Mobile context modeling is a process of recognizing and reasoning about contexts and situations in a mobile environment, which is critical for the success of context-aware mobile services. While there are prior work on mobile context modeling, the use of unsupervised learning techniques for mobile context modeling is still under-explored. Indeed, unsupervised techniques have the ability to learn personalized contexts which are difficult to be predefined. To that end, in this paper, we propose an unsupervised approach to modeling personalized contexts of mobile users. Along this line, we first segment the raw context data sequences of mobile users into context sessions where a context session contains a group of adjacent context records which are mutually similar and usually reflect the similar contexts. Then, we exploit topic models to learn personalized contexts in the form of probabilistic distributions of raw context data from the context sessions. Finally, experimental results on real-world data show that the proposed approach is efficient and effective for mining personalized contexts of mobile users.

#index 1535371
#* Fast and Flexible Multivariate Time Series Subsequence Search
#@ Kanishka Bhaduri;Qiang Zhu;Nikunj C. Oza;Ashok N. Srivastava
#t 2010
#c 18
#! Multivariate Time-Series (MTS) are ubiquitous, and are generated in areas as disparate as sensor recordings in aerospace systems, music and video streams, medical monitoring, and financial systems. Domain experts are often interested in searching for interesting multivariate patterns from these MTS databases which can contain up to several gigabytes of data. Surprisingly, research on MTS search is very limited. Most existing work only supports queries with the same length of data, or queries on a fixed set of variables. In this paper, we propose an efficient and flexible subsequence search framework for massive MTS databases, that, for the first time, enables querying on any subset of variables with arbitrary time delays between them. We propose two provably correct algorithms to solve this problem #x2014; (1) an R*-tree Based Search (RBS) which uses Minimum Bounding Rectangles (MBR) to organize the subsequences, and (2) a List Based Search (LBS) algorithm which uses sorted lists for indexing. We demonstrate the performance of these algorithms using two large MTS databases from the aviation domain, each containing several millions of observations. Both these tests show that our algorithms have very high prune rates (95%) thus needing actual disk access for only less than 5% of the observations. To the best of our knowledge, this is the first flexible MTS search algorithm capable of subsequence search on any subset of variables. Moreover, MTS subsequence search has never been attempted on datasets of the size we have used in this paper.

#index 1535372
#* iSAX 2.0: Indexing and Mining One Billion Time Series
#@ Alessandro Camerra;Themis Palpanas;Jin Shieh;Eamonn Keogh
#t 2010
#c 18
#! There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of time series. Examples of such applications come from astronomy, biology, the web, and other domains. It is not unusual for these applications to involve numbers of time series in the order of hundreds of millions to billions. However, all relevant techniques that have been proposed in the literature so far have not considered any data collections much larger than one-million time series. In this paper, we describe iSAX 2.0, a data structure designed for indexing and mining truly massive collections of time series. We show that the main bottleneck in mining such massive datasets is the time taken to build the index, and we thus introduce a novel bulk loading mechanism, the first of this kind specifically tailored to a time series index. We show how our method allows mining on datasets that would otherwise be completely untenable, including the first published experiments to index one billion time series, and experiments in mining massive data from domains as diverse as entomology, DNA and web-scale image collections.

#index 1535373
#* Abstraction Augmented Markov Models
#@ Cornelia Caragea;Adrian Silvescu;Doina Caragea;Vasant Honavar
#t 2010
#c 18
#! High accuracy sequence classification often requires the use of higher order Markov models (MMs). However, the number of MM parameters increases exponentially with the range of direct dependencies between sequence elements, thereby increasing the risk of over fitting when the data set is limited in size. We present abstraction augmented Markov models (AAMMs) that effectively reduce the number of numeric parameters of kth order MMs by successively grouping strings of length k (i.e., k-grams) into abstraction hierarchies. We evaluate AAMMs on three protein sub cellular localization prediction tasks. The results of our experiments show that abstraction makes it possible to construct predictive models that use significantly smaller number of features (by one to three orders of magnitude) as compared to MMs. AAMMs are competitive with and, in some cases, significantly outperform MMs. Moreover, the results show that AAMMs often perform significantly better than variable order Markov models, such as decomposed context tree weighting, prediction by partial match, and probabilistic suffix trees.

#index 1535374
#* Pseudo Conditional Random Fields: Joint Training Approach to Segmenting and Labeling Sequence Data
#@ Shing-Kit Chan;Wai Lam
#t 2010
#c 18
#! Cascaded approach has been used for a long time to conduct sub-tasks in order to accomplish a major task. We put cascaded approach in a probabilistic framework and analyze possible reasons for cascaded errors. To reduce the occurrence of cascaded errors, we need to add a constraint when performing joint training. We suggest a pseudo Conditional Random Field (pseudo-CRF) approach that models two sub-tasks as two Conditional Random Fields (CRFs). We then present the formulation in the context of a linear chain CRF for solving problems on sequence data. In conducting joint training for a pseudo-CRF, we reuse all existing well-developed efficient inference algorithms for a linear chain CRF, which would otherwise require the use of approximate inference algorithms or simulations that involve long computational time. Our experimental results show an interesting fact that a jointly trained CRF model in a pseudo-CRF may perform worse than a separately trained CRF on a sub-task. However the overall system performance of a pseudo-CRF would outperform that of a cascaded approach. We implement the implicit constraint in the form of a soft constraint such that users can define the penalty cost for violating the constraint. In order to work on large-scale datasets, we further suggest a parallel implementation of the pseudo-CRF approach, which can be implemented on a multi-core CPU or GPU on a graphics card that supports multi-threading. Our experimental results show that it can achieve a 12 times increase in speedup.

#index 1535375
#* Location and Scatter Matching for Dataset Shift in Text Mining
#@ Bo Chen;Wai Lam;Ivor Tsang;Tak-Lam Wong
#t 2010
#c 18
#! Dataset shift from the training data in a source domain to the data in a target domain poses a great challenge for many statistical learning methods. Most algorithms can be viewed as exploiting only the first-order statistics, namely, the empirical mean discrepancy to evaluate the distribution gap. Intuitively, considering only the empirical mean may not be statistically efficient. In this paper, we propose a non-parametric distance metric with a good property which jointly considers the empirical mean (Location) and sample covariance (Scatter) difference. More specifically, we propose an improved symmetric Stein's loss function which combines the mean and covariance discrepancy into a unified Bregman matrix divergence of which Jensen-Shannon divergence between normal distributions is a particular case. Our target is to find a good feature representation which can reduce the distribution gap between different domains, at the same time, ensure that the new derived representation can encode most discriminative components with respect to the label information. We have conducted extensive experiments on several document classification datasets to demonstrate the effectiveness of our proposed method.

#index 1535376
#* Learning Preferences with Millions of Parameters by Enforcing Sparsity
#@ Xi Chen;Bing Bai;Yanjun Qi;Qihang Lin;Jaime Carbonell
#t 2010
#c 18
#! We study the retrieval task that ranks a set of objects for a given query in the pair wise preference learning framework. Recently researchers found out that raw features (e.g. words for text retrieval) and their pair wise features which describe relationships between two raw features (e.g. word synonymy or polysemy) could greatly improve the retrieval precision. However, most existing methods can not scale up to problems with many raw features (e.g. English vocabulary), due to the prohibitive computational cost on learning and the memory requirement to store a quadratic number of parameters. In this paper, we propose to learn a sparse representation of the pair wise features under the preference learning framework using the L1 regularization. Based on stochastic gradient descent, an online algorithm is devised to enforce the sparsity using a mini-batch shrinkage strategy. On multiple benchmark datasets, we show that our method achieves better performance with fast convergence, and takes much less memory on models with millions of parameters.

#index 1535377
#* QMAS: Querying, Mining and Summarization of Multi-modal Databases
#@ Robson L. F. Cordeiro;Fan Guo;Donna S. Haverkamp;James H. Horne;Ellen K. Hughes;Gunhee Kim;Agma J. M. Traina;Caetano Traina Jr.;Christos Faloutsos
#t 2010
#c 18
#! Given a large collection of images, very few of which have labels, how can we guess the labels of the remaining majority, and how can we spot those images that need brand new labels, different from the existing ones? Current automatic labeling techniques usually scale super linearly with the data size, and/or they fail when only a tiny amount of labeled data is provided. In this paper, we propose QMAS (Querying, Mining And Summarization of Multi-modal Databases), a fast solution to the following problems: (i) low-labor labeling (L3) – given a collection of images, very few of which are labeled with keywords, find the most suitable labels for the remaining ones, and (ii) mining and attention routing – in the same setting, find clusters, the top-NO outlier images, and the top-NR representative images. We report experiments on real satellite images, two large sets (1.5GB and 2.25GB) of proprietary images and a smaller set (17MB) of public images. We show that QMAS scales linearly with the data size, being up to 40 times faster than top competitors (GCap), obtaining better or equal accuracy. In contrast to other methods, QMAS does low-labor labeling (L3), that is, it works even with tiny initial label sets. It also solves both presented problems and spots tiles that potentially require new labels.

#index 1535378
#* Active Learning with Human-Like Noisy Oracle
#@ Jun Du;Charles X. Ling
#t 2010
#c 18
#! When active learning is applied to real-world applications, human experts usually act as oracles to provide labels. However, human make mistakes, thus noise might be introduced during the learning process. Most previous studies simplify the problem by assuming uniformly-distributed noise over the sample space. Such assumption, however, might fail to precisely reflect the human experts' behaviour in real-world situations. In this paper, we therefore study active learning with such human-like oracles, by making a more realistic assumption that the noise is example-dependent (i.e., non-uniformly distributed over the sample space). More specifically, when the human-like oracle is highly confident in labelling examples, it is naturally less likely to provide incorrect answers, whereas when such confidence is low, the noise would be more likely to be introduced. Based on the analysis of such human-like oracle, we propose a generic yet simple active learning algorithm to simultaneously explore the unlabelled data and exploit the labelled data. Empirical study on both synthetic and real-world data sets verifies the superiority of the proposed algorithm, compared with the traditional uncertainty sampling.

#index 1535379
#* A Graph-Based Approach for Multi-folder Email Classification
#@ Sharma Chakravarthy;Aravind Venkatachalam;Aditya Telang
#t 2010
#c 18
#! This paper presents a novel framework for multi-folder email classification using graph mining as the underlying technique. Although several techniques exist (e.g., SVM, TF-IDF, n-gram) for addressing this problem in a delimited context, they heavily rely on extracting high-frequency keywords, thus ignoring the inherent structural aspects of an email (or document in general) which can play a critical role in classification. Some of the models (e.g., n-gram) consider only the words without taking into consideration where in the structure these words appear together. This paper presents a supervised learning model that leverages graph mining techniques for multi-folder email classification. A ranking formula is presented for ordering the representative - common and recurring - substructures generated from pre-classified emails. These ranked representative substructures are then used for categorizing incoming emails. This approach is based on a global ranking model that incorporates several relevant parameters for email classification and overcomes numerous problems faced by extant approaches used for multi-folder classification. A number of parameters which influence the generation of representative substructures are analyzed, reexamined, and adapted to multiple folders. The effect of graph representations has been analyzed. The effectiveness of the proposed approach has been validated experimentally.

#index 1535380
#* Scalable Influence Maximization in Social Networks under the Linear Threshold Model
#@ Wei Chen;Yifei Yuan;Li Zhang
#t 2010
#c 18
#! Influence maximization is the problem of finding a small set of most influential nodes in a social network so that their aggregated influence in the network is maximized. In this paper, we study influence maximization in the linear threshold model, one of the important models formalizing the behavior of influence propagation in social networks. We first show that computing exact influence in general networks in the linear threshold model is #P-hard, which closes an open problem left in the seminal work on influence maximization by Kempe, Kleinberg, and Tardos, 2003. As a contrast, we show that computing influence in directed a cyclic graphs (DAGs) can be done in time linear to the size of the graphs. Based on the fast computation in DAGs, we propose the first scalable influence maximization algorithm tailored for the linear threshold model. We conduct extensive simulations to show that our algorithm is scalable to networks with millions of nodes and edges, is orders of magnitude faster than the greedy approximation algorithm proposed by Kempe et al. and its optimized versions, and performs consistently among the best algorithms while other heuristic algorithms not design specifically for the linear threshold model have unstable performances on different real-world networks.

#index 1535381
#* CLUSMASTER: A Clustering Approach for Sampling Data Streams in Sensor Networks
#@ Alzennyr Da Silva;Raja Chiky;Georges Hebrail
#t 2010
#c 18
#! The growing usage of embedded devices and sensors in our daily lives has been profoundly reshaping the way we interact with our environment and our peers. As more and more sensors will pervade our future cities, increasingly efficient infrastructures to collect, process, and store massive amounts of data streams from a wide variety of sources will be required. Despite the different application-specific features and hardware platforms, sensor network applications share a common goal: periodically sample and store data collected from different sensors in a common persistent memory. In this article we present a clustering approach for rapidly and efficiently computing the best sampling rate which minimizes the SSE (Sum of Square Errors) for each particular sensor in a network. In order to evaluate the efficiency of the proposed approach, we carried out experiments on real electric power consumption data streams produced by a 1-thousand sensor network provided by the French energy group – EDF (Electricite de France).

#index 1535382
#* Bayesian Maximum Margin Clustering
#@ Bo Dai;Baogang Hu;Gang Niu
#t 2010
#c 18
#! Most well-known discriminative clustering models, such as spectral clustering (SC) and maximum margin clustering (MMC), are non-Bayesian. Moreover, they merely considered to embed domain-dependent prior knowledge into data-specific kernels, while other forms of prior knowledge were seldom considered in these models. In this paper, we propose a Bayesian maximum margin clustering model (BMMC) based on the low-density separation assumption, which unifies the merits of both Bayesian and discriminative approaches. In addition to stating prior distribution on functions explicitly as traditional Gaussian processes, special prior knowledge can be embedded into BMMC implicitly via the Universum set easily. Furthermore, it is much easier to solve a BMMC than an MMC since the integer variables in the optimization are eliminated. Experimental results show that the BMMC achieves comparable or even better performance than state-of-the-art clustering methods and solving BMMC is more efficiently.

#index 1535383
#* Block-GP: Scalable Gaussian Process Regression for Multimodal Data
#@ Kamalika Das;Ashok N. Srivastava
#t 2010
#c 18
#! Regression problems on massive data sets are ubiquitous in many application domains including the Internet, earth and space sciences, and finances. In many cases, regression algorithms such as linear regression or neural networks attempt to fit the target variable as a function of the input variables without regard to the underlying joint distribution of the variables. As a result, these global models are not sensitive to variations in the local structure of the input space. Several algorithms, including the mixture of experts model, classification and regression trees (CART), and others have been developed, motivated by the fact that a variability in the local distribution of inputs may be reflective of a significant change in the target variable. While these methods can handle the non-stationarity in the relationships to varying degrees, they are often not scalable and, therefore, not used in large scale data mining applications. In this paper we develop Block-GP, a Gaussian Process regression framework for multimodal data, that can be an order of magnitude more scalable than existing state-of-the-art nonlinear regression algorithms. The framework builds local Gaussian Processes on semantically meaningful partitions of the data and provides higher prediction accuracy than a single global model with very high confidence. The method relies on approximating the covariance matrix of the entire input space by smaller covariance matrices that can be modeled independently, and can therefore be parallelized for faster execution. Theoretical analysis and empirical studies on various synthetic and real data sets show high accuracy and scalability of Block-GP compared to existing nonlinear regression techniques.

#index 1535384
#* Monotone Relabeling in Ordinal Classification
#@ Ad Feelders
#t 2010
#c 18
#! In many applications of data mining we know beforehand that the response variable should be increasing (or decreasing) in the attributes. Such relations between response and attributes are called monotone. In this paper we present a new algorithm to compute an optimal monotone classification of a data set for convex loss functions. Moreover, we show how the algorithm can be extended to compute all optimal monotone classifications with little additional effort. Monotone relabeling is useful for at least two reasons. Firstly, models trained on relabeled data sets often have better predictive performance than models trained on the original data. Secondly, relabeling is an important building block for the construction of monotone classifiers. We apply the new algorithm to investigate the effect on the prediction error of relabeling the training sample for $k$ nearest neighbour classification and classification trees. In contrast to previous work in this area, we consider {\em all} optimal monotone relabelings. The results show that, for small training samples, relabeling the training data results in significantly better predictive performance.

#index 1535385
#* The Effect of History on Modeling Systems' Performance: The Problem of the Demanding Lord
#@ George Giannakopoulos;Themis Palpanas
#t 2010
#c 18
#! In several concept attainment systems, ranging from recommendation systems to information filtering, a sliding window of learning instances has been used in the learning process to allow the learner to follow concepts that change over time. However, no analytic study has been performed on the relation between the size of the sliding window and the performance of a learning system. In this work, we present such an analytic model that describes the effect of the sliding window size on the prediction performance of a learning system based on iterative feedback. Using a signal-to-noise approach to model the learning ability of the underlying machine learning algorithms, we can provide good estimates of the average performance of a modeling system independently of the supervised machine learning algorithm employed. We experimentally validate the effectiveness of the proposed methodology with detailed experiments using synthetic and real datasets, and a variety of learning algorithms, including Support Vector Machines, Naive Bayes, Nearest Neighbor and Decision Trees. The results validate the analysis and indicate very good estimation performance in different settings.

#index 1535386
#* Resilient K-d Trees: K-Means in Space Revisited
#@ Fabian Gieseke;Gabriel Moruz;Jan Vahrenhold
#t 2010
#c 18
#! We develop a k-d tree variant that is resilient to a pre-described number of memory corruptions while still using only linear space. We show how to use this data structure in the context of clustering in high-radiation environments and demonstrate that our approach leads to a significantly higher resiliency rate compared to previous results.

#index 1535387
#* Advertising Campaigns Management: Should We Be Greedy?
#@ Sertan Girgin;Jeremie Mary;Philippe Preux;Olivier Nicol
#t 2010
#c 18
#! We consider the problem of displaying advertisements on web pages in the "cost per click" model, which necessitates to learn the appeal of visitors for the different advertisements in order to maximize the revenue. In a realistic context, the advertisements have constraints such as a certain number of clicks to draw, as well as a lifetime. This problem is thus inherently dynamic, and intimately combines combinatorial and statistical issues. To set the stage, it is also noteworthy that we deal with very rare events of interest, since the base probability of one click is in the order of 10^-4. We introduce an adaptive policy learning algorithm based on linear programming, and investigate its performance through simulations on a realistic model designed with an important commercial web actor.

#index 1535388
#* Accelerating Radius-Margin Parameter Selection for SVMs Using Geometric Bounds
#@ Ben Goodrich;David Albrecht;Peter Tischer
#t 2010
#c 18
#! By considering the geometric properties of the Support Vector Machine (SVM) and Minimal Enclosing Ball (MEB) optimization problems, we show that upper and lower bounds on the radius-margin ratio of an SVM can be efficiently computed at any point during training. We use these bounds to accelerate radius-margin parameter selection by terminating training routines as early as possible, while still obtaining a guarantee that the parameters minimize the radius-margin ratio. Once an SVM has been partially trained on any set of parameters, we also show that these bounds can be used to evaluate and possibly reject neighboring parameter values with little or no additional training required. Empirical results show that, when selecting two parameter values, this process can reduce the number of training iterations required by a factor of 10 or more, while suffering no loss of precision in minimizing the radius-margin ratio.

#index 1535389
#* Viral Marketing for Multiple Products
#@ Samik Datta;Anirban Majumder;Nisheeth Shrivastava
#t 2010
#c 18
#! Viral Marketing, the idea of exploiting social interactions of users to propagate awareness for products, has gained considerable focus in recent years. One of the key issues in this area is to select the best seeds that maximize the influence propagated in the social network. In this paper, we define the seed selection problem (called t-Influence Maximization, or t-IM) for multiple products. Specifically, given the social network and t products along with their seed requirements, we want to select seeds for each product that maximize the overall influence. As the seeds are typically sent promotional messages, to avoid spamming users, we put a hard constraint on the number of products for which any single user can be selected as a seed. In this paper, we design two efficient techniques for the t-IM problem, called Greedy and FairGreedy. The Greedy algorithm uses simple greedy hill climbing, but still results in a 1/3-approximation to the optimum. Our second technique, FairGreedy, allocates seeds with not only high overall influence (close to Greedy in practice), but also ensures fairness across the influence of different products. We also design efficient heuristics for estimating the influence of the selected seeds, that are crucial for running the seed selection on large social network graphs. Finally, using extensive simulations on real-life social graphs, we show the effectiveness and scalability of our techniques compared to existing and naive strategies.

#index 1535390
#* Finding Local Anomalies in Very High Dimensional Space
#@ Timothy de Vries;Sanjay Chawla;Michael E. Houle
#t 2010
#c 18
#! Time, cost and energy efficiency are critical factors for many data analysis techniques when the size and dimensionality of data is very large. We investigate the use of Local Outlier Factor (LOF) for data of this type, providing a motivating example from real world data. We propose Projection-Indexed Nearest-Neighbours (PINN), a novel technique that exploits extended nearest neighbour sets in the a reduced dimensional space to create an accurate approximation for k-nearest-neighbour distances, which is used as the core density measurement within LOF. The reduced dimensionality allows for efficient sub-quadratic indexing in the number of items in the data set, where previously only quadratic performance was possible. A detailed theoretical analysis of Random Projection(RP) and PINN shows that we are able to preserve the density of the intrinsic manifold of the data set after projection. Experimental results show that PINN outperforms the standard projection methods RP and PCA when measuring LOF for many high-dimensional real-world data sets of up to 300000 elements and 102600 dimensions.

#index 1535391
#* PGLCM: Efficient Parallel Mining of Closed Frequent Gradual Itemsets
#@ Trong Dinh Thac Do;Anne Laurent;Alexandre Termier
#t 2010
#c 18
#! Numerical data (e.g., DNA micro-array data, sensor data) pose a challenging problem to existing frequent pattern mining methods which hardly handle them. In this framework, gradual patterns have been recently proposed to extract covariations of attributes, such as: "When X increases, Y decreases". There exist some algorithms for mining frequent gradual patterns, but they cannot scale to real-world databases. We present in this paper GLCM, the first algorithm for mining closed frequent gradual patterns, which proposes strong complexity guarantees: the mining time is linear with the number of closed frequent gradual item sets. Our experimental study shows that GLCM is two orders of magnitude faster than the state of the art, with a constant low memory usage. We also present PGLCM, a parallelization of GLCM capable of exploiting multicore processors, with good scale-up properties on complex datasets. These algorithms are the first algorithms capable of mining large real world datasets to discover gradual patterns.

#index 1535392
#* Sequential Latent Dirichlet Allocation: Discover Underlying Topic Structures within a Document
#@ Lan Du;Wray Lindsay Buntine;Huidong Jin
#t 2010
#c 18
#! Understanding how topics within a document evolve over its structure is an interesting and important problem. In this paper, we address this problem by presenting a novel variant of Latent Dirichlet Allocation (LDA): Sequential LDA (SeqLDA). This variant directly considers the underlying sequential structure, {\it i.e.}, a document consists of multiple segments ({\it e.g.}, chapters, paragraphs), each of which is correlated to its previous and subsequent segments. In our model, a document and its segments are modelled as random mixtures of the same set of latent topics, each of which is a distribution over words, and the topic distribution of each segment depends on that of its previous segment, the one for first segment will depend on the document topic distribution. The progressive dependency is captured by using the nested two-parameter Poisson Dirichlet process (PDP). We develop an efficient collapsed Gibbs sampling algorithm to sample from the posterior of the PDP. Our experimental results on patent documents show that by taking into account the sequential structure within a document, our SeqLDA model has a higher fidelity over LDA in terms of perplexity (a standard measure of dictionary-based compressibility). The SeqLDA model also yields a nicer sequential topic structure than LDA, as we show in experiments on books such as Melville's "The Whale''.

#index 1535393
#* Enhancing Single-Objective Projective Clustering Ensembles
#@ Francesco Gullo;Carlotta Domeniconi;Andrea Tagarelli
#t 2010
#c 18
#! Projective Clustering Ensembles (PCE) has recently been formulated to solve the problem of deriving a robust projective consensus clustering from an ensemble of projective clustering solutions. PCE is formalized as an optimization problem with either a two-objective or a single-objective function, depending on whether the object-based and the feature-based representations of the clusters in the ensemble are treated separately. A major result in is that single-objective PCE outperforms two-objective PCE in terms of efficiency, at the cost of lower accuracy in consensus clustering. In this paper, we enhance the single-objective PCE formulation, with the ultimate goal of providing more effective formulations capable of reducing the accuracy gap with the two-objective counterpart, while maintaining the efficiency advantages. We provide theoretical insights into the single-objective function, and introduce two heuristics that overcome the major limitations of the previous single-objective PCE formulation. Experimental evidence has demonstrated the significance of our proposed heuristics. In fact, results have not only confirmed a far better efficiency w.r.t. two-objective PCE, but have also shown the claimed improvements in accuracy of the consensus clustering obtained by the new single-objective PCE.

#index 1535394
#* Minimizing the Variance of Cluster Mixture Models for Clustering Uncertain Objects
#@ Francesco Gullo;Giovanni Ponti;Andrea Tagarelli
#t 2010
#c 18
#! The increasing demand for dealing with uncertainty in data has led to the development of effective and efficient approaches in the data management and mining contexts. Clustering uncertain data objects has particularly attracted great attention in the data mining community. Most existing clustering methods however have urgently to come up with a number of issues, some of which are related to a poor efficiency mainly due to an expensive computation of the distance between uncertain objects. In this work, we propose a novel formulation to the problem of clustering uncertain objects, which allows for reaching accurate solutions by minimizing the variance of the mixture models that represent the clusters to be identified. We define a heuristic, MMVar, which exploits some analytical properties about the computation of variance for mixture models to compute local minima of the objective function at the basis of the proposed formulation. This characteristic allows MMVar to discard any distance measure between uncertain objects and, therefore, to achieve high efficiency. Experiments have shown that MMVar outperforms state-of-the-art algorithms from an efficiency viewpoint, while achieving better average performance in terms of accuracy.

#index 1535395
#* Subspace Clustering Meets Dense Subgraph Mining: A Synthesis of Two Paradigms
#@ Stephan Gunnemann;Ines Farber;Brigitte Boden;Thomas Seidl
#t 2010
#c 18
#! Today's applications deal with multiple types of information: graph data to represent the relations between objects and attribute data to characterize single objects. Analyzing both data sources simultaneously can increase the quality of mining methods. Recently, combined clustering approaches were introduced, which detect densely connected node sets within one large graph that also show high similarity according to all of their attribute values. However, for attribute data it is known that this full-space clustering often leads to poor clustering results. Thus, subspace clustering was introduced to identify locally relevant subsets of attributes for each cluster. In this work, we propose a method for finding homogeneous groups by joining the paradigms of subspace clustering and dense sub graph mining, i.e. we determine sets of nodes that show high similarity in subsets of their dimensions and that are as well densely connected within the given graph. Our twofold clusters are optimized according to their density, size, and number of relevant dimensions. Our developed redundancy model confines the clustering to a manageable size of only the most interesting clusters. We introduce the algorithm Gamer for the efficient calculation of our clustering. In thorough experiments on synthetic and real world data we show that Gamer achieves low runtimes and high clustering qualities.

#index 1535396
#* Multi-stream Join Answering for Mining Significant Cross-Stream Correlations
#@ Robert Gwadera
#t 2010
#c 18
#! Sliding-window multi-stream join (SWMJ) is a fundamental operation for correlating information from different streams. We provide a solution to the problem of assessing significance of the SWMJ result by focusing on the relative frequency of windows satisfying a given equijoin predicate as the most important parameter of the SWMJ result. In particular, we derive an analytic formula for computing the average relative frequency of windows satisfying a given equijoin predicate that can be evaluated in quadratic time in the window size given a probabilistic model of the multi-stream. In experiments we demonstrated remarkable accuracy of our method, which confirmed our theoretical analysis.

#index 1535397
#* Category Mining by Heterogeneous Data Fusion Using PdLSI Model in a Retail Service
#@ Tsukasa Ishigaki;Takeshi Takenaka;Yoichi Motomura
#t 2010
#c 18
#! This paper describes an appropriate category discovery method that simultaneously involves a customer's lifestyle category and item category for the sustainable management of retail services, designated as ``category mining''. Category mining is realized using a large-scale ID-POS data and customer's questionnaire responses with respect to their lifestyle. For the heterogeneous data fusion, we propose a probabilistic double-latent semantic indexing (PdLSI) model that is an extension of PLSI model. In the PdLSI model, customers and items are classified probabilistically into some latent lifestyle categories and latent item category. Then, understanding of relation between the latent categories and various purchased situations is realized using Bayesian network modeling. This method provides useful knowledge based on a large-scale data for efficient customer relationship management and category management, and can be applicable for other service industries.

#index 1535398
#* Subgroup Discovery Meets Bayesian Networks -- An Exceptional Model Mining Approach
#@ Wouter Duivesteijn;Arno Knobbe;Ad Feelders;Matthijs van Leeuwen
#t 2010
#c 18
#! Whenever a dataset has multiple discrete target variables, we want our algorithms to consider not only the variables themselves, but also the interdependencies between them. We propose to use these interdependencies to quantify the quality of subgroups, by integrating Bayesian networks with the Exceptional Model Mining framework. Within this framework, candidate subgroups are generated. For each candidate, we fit a Bayesian network on the target variables. Then we compare the network’s structure to the structure of the Bayesian network fitted on the whole dataset. To perform this comparison, we define an edit distance-based distance metric that is appropriate for Bayesian networks. We show interesting subgroups that we experimentally found with our method on datasets from music theory, semantic scene classification, biology and zoogeography.

#index 1535399
#* Learning Attribute-to-Feature Mappings for Cold-Start Recommendations
#@ Zeno Gantner;Lucas Drumond;Christoph Freudenthaler;Steffen Rendle;Lars Schmidt-Thieme
#t 2010
#c 18
#! Cold-start scenarios in recommender systems are situations in which no prior events, like ratings or clicks, are known for certain users or items. To compute predictions in such cases, additional information about users (user attributes, e.g. gender, age, geographical location, occupation) and items (item attributes, e.g. genres, product categories, keywords) must be used. We describe a method that maps such entity (e.g. user or item) attributes to the latent features of a matrix (or higher-dimensional) factorization model. With such mappings, the factors of a MF model trained by standard techniques can be applied to the new-user and the new-item problem, while retaining its advantages, in particular speed and predictive accuracy. We use the mapping concept to construct an attribute-aware matrix factorization model for item recommendation from implicit, positive-only feedback. Experiments on the new-item problem show that this approach provides good predictive accuracy, while the prediction time only grows by a constant factor.

#index 1535400
#* An Extensive Empirical Study on Semi-supervised Learning
#@ Yuanyuan Guo;Xiaoda Niu;Harry Zhang
#t 2010
#c 18
#! Semi-supervised classification methods utilize unlabeled data to help learn better classifiers, when only a small amount of labeled data is available. Many semi-supervised learning methods have been proposed in the past decade. However, some questions have not been well answered, e.g., whether semi-supervised learning methods outperform base classifiers learned only from the labeled data, when different base classifiers are used, whether selecting unlabeled data with efforts is superior to random selection, and how the quality of the learned classifier changes at each iteration of learning process. This paper conducts an extensive empirical study on the performance of several commonly used semi-supervised learning methods when different Bayesian classifiers (NB, NBTree, TAN, HGC, HNB, and DNB) are used as the base classifier, respectively. Results on Transductive SVM and a graph-based semi-supervised learning method LLGC are also studied for comparison. The experimental results on 26 UCI datasets and 6 widely used benchmark datasets show that these semi-supervised learning methods generally do not obtain better performance than classifiers learned only from the labeled data. Moreover, for standard self-training and co-training, when selecting the most confident unlabeled instances during learning process, the performance is not necessarily better than that of random selection of unlabeled instances. We especially discovered interesting outcomes when drawing learning curves for using NB in self-training on some UCI datasets. The accuracy of the learned classifier on the testing set may fluctuate or decrease as more unlabeled instances are used. Also on the mushroom dataset, even when all the selected unlabeled instances are correctly labeled in each iteration, the accuracy on the testing set still goes down.

#index 1535401
#* Efficient Discovery of the Top-K Optimal Dependency Rules with Fisher's Exact Test of Significance
#@ Wilhelmiina Hamalainen
#t 2010
#c 18
#! Statistical dependency analysis is the basis of all empirical science. A commonly occurring problem is to find the most significant dependency rules, which describe either positive or negative dependencies between categorical attributes. For example, in medical science one is interested in genetic factors, which can either predispose or prevent diseases. The requirement of statistical significance is essential, because the discoveries should hold also in the future data. Typically, the significance is estimated either by Fisher's exact test or the $\chi^2$-measure. The problem is computationally very difficult, because the number of all possible dependency rules increases exponentially with the number of attributes. As a solution, different kinds of restrictions and heuristics have been applied, but a general, scalable search method has been missing. In this paper, we introduce an efficient algorithm for searching for the top-K globally optimal dependency rules using Fisher's exact test as a measure function. The rules can express either positive or negative dependencies between a set of positive attributes and a single consequent attribute. The algorithm is based on an application of the branch-and-bound search strategy, supplemented by several pruning properties. Especially, we prove a new lower-bound for the Fisher's p, and introduce a new effective pruning principle. The general search algorithm is applicable to other goodness measures, like the $\chi^2$-measure, as well. According to our experiments on classical benchmark data, the algorithm is well scalable and can efficiently handle even dense and high dimensional data sets. In addition, the quality of rules is significantly better than with the $\chi^2$-measure using the same search algorithm.

#index 1535402
#* Exponential Family Tensor Factorization for Missing-Values Prediction and Anomaly Detection
#@ Kohei Hayashi;Takashi Takenouchi;Tomohiro Shibata;Yuki Kamiya;Daishi Kato;Kazuo Kunieda;Keiji Yamada;Kazushi Ikeda
#t 2010
#c 18
#! In this paper, we study probabilistic modeling of heterogeneously attributed multi-dimensional arrays. The model can manage the heterogeneity by employing an individual exponential-family distribution for each attribute of the tensor array. These entries are connected by latent variables and are shared information across the different attributes. Because a Bayesian inference for our model is intractable, we cast the EM algorithm approximated by using the Lap lace method and Gaussian process. This approximation enables us to derive a predictive distribution for missing values in a consistent manner. Simulation experiments show that our method outperforms other methods such as PARAFAC and Tucker decomposition in missing-values prediction for cross-national statistics and is also applicable to discover anomalies in heterogeneous office-logging data.

#index 1535403
#* Content-Based Methods for Predicting Web-Site Demographic Attributes
#@ Santosh Kabbur;Eui-Hong Han;George Karypis
#t 2010
#c 18
#! Demographic information plays an important role in gaining valuable insights about a web-site's user-base and is used extensively to target online advertisements and promotions. This paper investigates machine-learning approaches for predicting the demographic attributes of web-sites using information derived from their content and their hyper linked structure and not relying on any information directly or indirectly obtained from the web-site's users. Such methods are important because users are becoming increasingly more concerned about sharing their personal and behavioral information on the Internet. Regression-based approaches are developed and studied for predicting demographic attributes that utilize different content-derived features, different ways of building the prediction models, and different ways of aggregating web-page level predictions that take into account the web's hyper linked structure. In addition, a matrix-approximation based approach is developed for coupling the predictions of individual regression models into a model designed to predict the probability mass function of the attribute. Extensive experiments show that these methods are able to achieve an RMSE of 8-10% and provide insights on how to best train and apply such models.

#index 1535404
#* Discrimination Aware Decision Tree Learning
#@ Faisal Kamiran;Toon Calders;Mykola Pechenizkiy
#t 2010
#c 18
#! Recently, the following discrimination aware classification problem was introduced: given a labeled dataset and an attribute B, find a classifier with high predictive accuracy that at the same time does not discriminate on the basis of the given attribute B. This problem is motivated by the fact that often available historic data is biased due to discrimination, e.g., when B denotes ethnicity. Using the standard learners on this data may lead to wrongfully biased classifiers, even if the attribute B is removed from training data. Existing solutions for this problem consist in “cleaning away” the discrimination from the dataset before a classifier is learned. In this paper we study an alternative approach in which the non-discrimination constraint is pushed deeply into a decision tree learner by changing its splitting criterion and pruning strategy. Experimental evaluation shows that the proposed approach advances the state-of-the-art in the sense that the learned decision trees have a lower discrimination than models provided by previous methods, with little loss in accuracy.

#index 1535405
#* Patterns on the Connected Components of Terabyte-Scale Graphs
#@ U. Kang;Mary McGlohon;Leman Akoglu;Christos Faloutsos
#t 2010
#c 18
#! How do connected components evolve? What are the regularities that govern the dynamic growth process and the static snapshot of the connected components? In this work, we study patterns in connected components of large, real-world graphs. First, we study one of the largest static Web graphs with billions of nodes and edges and analyze the regularities among the connected components using GFD(Graph Fractal Dimension) as our main tool. Second, we study several time evolving graphs and find dynamic patterns and rules that govern the dynamics of connected components. We analyze the growth rates of top connected components and study their relation over time. We also study the probability that a newcomer absorbs to disconnected components as a function of the current portion of the disconnected components and the degree of the newcomer. Finally, we propose a generative model that explains both the dynamic growth process and the static regularities of connected components.

#index 1535406
#* Attribution of Conversion Events to Multi-channel Media
#@ Brendan Kitts;Liang Wei;Dyng Au;Amanda Powter;Brian Burdick
#t 2010
#c 18
#! This paper presents a practical method for measuring the impact of multiple marketing events on sales, including marketing events that are not traditionally trackable. The technique infers which of several competing media events are likely to have caused a given conversion. We test the method using hold-out sets, and also a live media experiment in which we test whether the method can accurately predict television-generated web conversions.

#index 1535407
#* Mining Public Transport Usage for Personalised Intelligent Transport Systems
#@ Neal Lathia;Jon Froehlich;Licia Capra
#t 2010
#c 18
#! Traveller information, route planning, and service updates have become essential components of public transport systems: they help people navigate built environments by providing access to information regarding delays and service disruptions. However, one aspect that these systems lack is a way of tailoring the information they offer in order to provide personalised trip time estimates and relevant notifications to each traveller. Mining each user’s travel history, collected by automated ticketing systems, has the potential to address this gap. In this work, we analyse one such dataset of travel history on the London underground. We then propose and evaluate methods to (a) predict personalised trip times for the system users and (b) rank stations based on future mobility patterns, in order to identify the subset of stations that are of greatest interest to the user and thus provide useful travel updates.

#index 1535408
#* Micro-blogging Sentiment Detection by Collaborative Online Learning
#@ Guangxia Li;Steven C. H. Hoi;Kuiyu Chang;Ramesh Jain
#t 2010
#c 18
#! We study the online micro-blog sentiment detection problem, which aims to determine whether a micro-blog post expresses emotions. This problem is challenging because a micro-blog post is very short and individuals have distinct ways of expressing emotions. A single classification model trained on the entire corpus may fail to capture characteristics unique to each user. On the other hand, a personalized model for each user may be inaccurate due to the scarcity of training data, especially at the very beginning where users have just posted a few entries. To overcome these challenges, we propose learning a global model over all micro-bloggers, which is then leveraged to continuously refine the individual models through a collaborative online learning way. We evaluate our algorithm on a real-life micro-blog dataset collected from the popular micro-blog site – Twitter. Results show that our algorithm is effective and efficient for timely sentiment detection in real micro-blogging applications.

#index 1535409
#* A Variance Reduction Framework for Stable Feature Selection
#@ Yue Han;Lei Yu
#t 2010
#c 18
#! Besides high accuracy, stability of feature selection has recently attracted strong interest in knowledge discovery from high-dimensional data. In this study, we present a theoretical framework about the relationship between the stability and accuracy of feature selection based on a formal bias-variance decomposition of feature selection error. The framework also suggests a variance reduction approach for improving the stability of feature selection algorithms. Furthermore, we propose an empirical variance reduction framework, margin based instance weighting, which weights training instances according to their influence to the estimation of feature relevance. We also develop an efficient algorithm under this framework. Experiments based on synthetic data and real-world micro array data verify both the theoretical framework and the effectiveness of the proposed algorithm on variance reduction. The proposed algorithm is also shown to be effective at improving subset stability, while maintaining comparable classification accuracy based on selected features.

#index 1535410
#* Rare Category Characterization
#@ Jingrui He;Hanghang Tong;Jaime Carbonell
#t 2010
#c 18
#! Rare categories abound and their characterization has heretofore received little attention. Fraudulent banking transactions, network intrusions, and rare diseases are examples of rare classes whose detection and characterization are of high value. However, accurate characterization is challenging due to high-skewness and non-separability from majority classes, e.g., fraudulent transactions masquerade as legitimate ones. This paper proposes the RACH algorithm by exploring the compactness property of the rare categories. It is based on an optimization framework which encloses the rare examples by a minimum-radius hyper ball. The framework is then converted into a convex optimization problem, which is in turn effectively solved in its dual form by the projected sub gradient method. RACH can be naturally kernelized. Experimental results validate the effectiveness of RACH.

#index 1535411
#* Algorithm for Discovering Low-Variance 3-Clusters from Real-Valued Datasets
#@ Zhen Hu;Raj Bhatnagar
#t 2010
#c 18
#! The concept of Triclusters has been investigated recently in the context of two relational datasets that share labels along one of the dimensions. By simultaneously processing two datasets to unveil triclusters, new useful knowledge and insights can be obtained. However, some recently reported methods are either closely linked to specific problems or constrain datasets to have some specific distributions. Algorithms for generating triclusters whose cell-values demonstrate simple well known statistical properties, such as upper bounds on standard deviations, are needed for many applications. In this paper we present a 3-Clustering algorithm that searches for meaningful combinations of biclusters in two related datasets. The algorithm can handle situations involving: (i) datasets in which a few data objects may be present in only one dataset and not in both datasets, (ii) the two datasets may have different numbers of objects and/or attributes, and (iii) the cell-value distributions in two datasets may be different. In our formulation the cell-values of each selected tricluster, formed by two independent biclusters, are such that the standard deviations in each bicluster obeys an upper bound and the sets of objects in the two biclusters overlap to the maximum possible extent. We present validation of our algorithm by presenting the properties of the 3-Clusters discovered from a synthetic dataset and from a real world cross-species genomic dataset. The results of our algorithm unveil interesting insights for the cross-species genomic domain.

#index 1535412
#* Improved Consistent Sampling, Weighted Minhash and L1 Sketching
#@ Sergey Ioffe
#t 2010
#c 18
#! We propose a new Consistent Weighted Sampling method, where the probability of drawing identical samples for a pair of inputs is equal to their Jaccard similarity. Our method takes deterministic constant time per non-zero weight, improving on the best previous approach which takes expected constant time. The samples can be used as Weighted Minhash for efficient retrieval and compression (sketching) under Jaccard or L1 metric. A method is presented for using simple data statistics to reduce the running time of hash computation by two orders of magnitude. We compare our method with the random projection method and show that it has better characteristics for retrieval under L1. We present a novel method of mapping hashes to short bit-strings, apply it to Weighted Minhash, and achieve more accurate distance estimates from sketches than existing methods, as long as the inputs are sufficiently distinct. We show how to choose the optimal number of bits per hash for sketching, and demonstrate experimental results which agree with the theoretical analysis.

#index 1535413
#* An Approach Based on Tree Kernels for Opinion Mining of Online Product Reviews
#@ Peng Jiang;Chunxia Zhang;Hongping Fu;Zhendong Niu;Qing Yang
#t 2010
#c 18
#! Opinion mining is a challenging task to identify the opinions or sentiments underlying user generated contents, such as online product reviews, blogs, discussion forums, etc. Previous studies that adopt machine learning algorithms mainly focus on designing effective features for this complex task. This paper presents our approach based on tree kernels for opinion mining of online product reviews. Tree kernels alleviate the complexity of feature selection and generate effective features to satisfy the special requirements in opinion mining. In this paper, we define several tree kernels for sentiment expression extraction and sentiment classification, which are subtasks of opinion mining. Our proposed tree kernels encode not only syntactic structure information, but also sentiment related information, such as sentiment boundary and sentiment polarity, which are important features to opinion mining. Experimental results on a benchmark data set indicate that tree kernels can significantly improve the performance of both sentiment expression extraction and sentiment classification. Besides, a linear combination of our proposed tree kernels and traditional feature vector kernel achieves the best performances using the benchmark data set.

#index 1535414
#* Enforcing Vocabulary k-Anonymity by Semantic Similarity Based Clustering
#@ Junqiang Liu;Ke Wang
#t 2010
#c 18
#! Web query logs provide a rich wealth of information, but also present serious privacy risks. We consider publishing vocabularies, bags of query-terms extracted from web query logs, which has a variety of applications. We aim at preventing identity disclosure of such bag-valued data. The key feature of such data is the extreme sparsity, which renders conventional anonymization techniques not working well in retaining enough utility. We propose a semantic similarity based clustering approach to address the issue. We measure the semantic similarity between two vocabularies by a weighted bipartite matching and present a greedy algorithm to cluster vocabularies by the semantic similarities. Extensive experiments on the AOL query log show that our approach retains more data utility than existing approaches.

#index 1535415
#* Efficient Probabilistic Latent Semantic Analysis with Sparsity Control
#@ Sen Liu;Chaolun Xia;Xiaohong Jiang
#t 2010
#c 18
#! Probabilistic latent semantic analysis is a topic modeling technique to discover the hidden structure in binary and count data. As a mixture model, it performs a probabilistic mixture decomposition on the co-occurrence matrix, which produces two matrices assigned with probabilistic explanations. However, the factorized matrices may be rather smooth, which means we may obtain global feature and topic representations rather than expected local ones. To resolve this problem, one of the solutions is to revise the decomposition process with considerations of sparsity. In this paper, we present an approach that provides direct control over sparsity during the expectation maximization process. Furthermore, by using the log penalty function as sparsity measurement instead of the widely used L2 norm, we can approximate the re-estimation of parameters in linear time, as same as original PLSA does, while many other approaches require much more time. Experiments on face databases are reported to show visual representations on obtaining local features, and detailed improvements in clustering tasks compared with the original process.

#index 1535416
#* Understanding of Internal Clustering Validation Measures
#@ Yanchi Liu;Zhongmou Li;Hui Xiong;Xuedong Gao;Junjie Wu
#t 2010
#c 18
#! Clustering validation has long been recognized as one of the vital issues essential to the success of clustering applications. In general, clustering validation can be categorized into two classes, external clustering validation and internal clustering validation. In this paper, we focus on internal clustering validation and present a detailed study of 11 widely used internal clustering validation measures for crisp clustering. From five conventional aspects of clustering, we investigate their validation properties. Experiment results show that S\_Dbw is the only internal validation measure which performs well in all five aspects, while other measures have certain limitations in different application scenarios.

#index 1535417
#* Transfer Learning via Cluster Correspondence Inference
#@ Mingsheng Long;Wei Cheng;Xiaoming Jin;Jianmin Wang;Dou Shen
#t 2010
#c 18
#! Transfer learning targets to leverage knowledge from one domain for tasks in a new domain. It finds abundant applications, such as text/sentiment classification. Many previous works are based on cluster analysis, which assume some common clusters shared by both domains. They mainly focus on the one-to-one cluster correspondence to bridge different domains. However, such a correspondence scheme might be too strong for real applications where each cluster in one domain corresponds to many clusters in the other domain. In this paper, we propose a Cluster Correspondence Inference (CCI) method to iteratively infer many-to-many correspondence among clusters from different domains. Specifically, word clusters and document clusters are exploited for each domain using nonnegative matrix factorization, then the word clusters from different domains are corresponded in a many-to-many scheme, with the help of shared word space as a bridge. These two steps are run iteratively and label information is transferred from source domain to target domain through the inferred cluster correspondence. Experiments on various real data sets demonstrate that our method outperforms several state-of-the-art approaches for cross-domain text classification.

#index 1535418
#* Supervised Link Prediction Using Multiple Sources
#@ Zhengdong Lu;Berkant Savas;Wei Tang;Inderjit S. Dhillon
#t 2010
#c 18
#! Link prediction is a fundamental problem in social network analysis and modern-day commercial applications such as Face book and My space. Most existing research approaches this problem by exploring the topological structure of a social network using only one source of information. However, in many application domains, in addition to the social network of interest, there are a number of auxiliary social networks and/or derived proximity networks available. The contribution of the paper is twofold: (1) a supervised learning framework that can effectively and efficiently learn the dynamics of social networks in the presence of auxiliary networks, (2) a feature design scheme for constructing a rich variety of path-based features using multiple sources, and an effective feature selection strategy based on structured sparsity. Extensive experiments on three real-world collaboration networks show that our model can effectively learn to predict new links using multiple sources, yielding higher prediction accuracy than unsupervised and single-source supervised models.

#index 1535419
#* Sparse Boolean Matrix Factorizations
#@ Pauli Miettinen
#t 2010
#c 18
#! Matrix factorizations are commonly used methods in data mining. When the input data is Boolean, replacing the standard matrix multiplication with Boolean matrix multiplication can yield more intuitive results. Unfortunately, finding a good Boolean decomposition is known to be computationally hard, with even many sub-problems being hard to approximate. Many real-world data sets are sparse, and it is often required that also the factor matrices are sparse. This requirement has motivated many new matrix decomposition methods and many modifications of the existing methods. This paper studies how Boolean matrix factorizations behave with sparse data: can we assume some sparsity on the factor matrices, and does the sparsity help with the computationally hard problems. The answer to these problems is shown to be positive.

#index 1535420
#* A Pairwise-Systematic Microaggregation for Statistical Disclosure Control
#@ Md. Enamul Kabir;Hua Wang;Yanchun Zhang
#t 2010
#c 18
#! Microdata protection in statistical databases has recently become a major societal concern and has been intensively studied in recent years. Statistical Disclosure Control (SDC) is often applied to statistical databases before they are released for public use. Micro aggregation for SDC is a family of methods to protect micro data from individual identification. SDC seeks to protect micro data in such a way that can be published and mined without providing any private information that can be linked to specific individuals. Micro aggregation works by partitioning the micro data into groups of at least k records and then replacing the records in each group with the centroid of the group. An optimal micro aggregation method must minimize the information loss resulting from this replacement process. The challenge is how to minimize the information loss during the micro aggregation process. This paper presents a pair wise systematic (P-S) micro aggregation method to minimize the information loss. The proposed technique simultaneously forms two distant groups at a time with the corresponding similar records together in a systematic way and then anonymized with the centroid of each group individually. The structure of P-S problem is defined and investigated and an algorithm of the proposed problem is developed. The performance of the P-S algorithm is compared against the most recent micro aggregation methods. Experimental results show that P-S algorithm incurs less than half information loss than the latest micro aggregation methods for all of the test situations.

#index 1535421
#* Multi-label Feature Selection for Graph Classification
#@ Xiangnan Kong;Philip S. Yu
#t 2010
#c 18
#! Nowadays, the classification of graph data has become an important and active research topic in the last decade, which has a wide variety of real world applications, e.g. drug activity predictions and kinase inhibitor discovery. Current research on graph classification focuses on single-label settings. However, in many applications, each graph data can be assigned with a set of multiple labels simultaneously. Extracting good features using multiple labels of the graphs becomes an important step before graph classification. In this paper, we study the problem of multi-label feature selection for graph classification and propose a novel solution, called gMLC, to efficiently search for optimal sub graph features for graph objects with multiple labels. Different from existing feature selection methods in vector spaces which assume the feature set is given, we perform multi-label feature selection for graph data in a progressive way together with the sub graph feature mining process. We derive an evaluation criterion, named gHSIC, to estimate the dependence between sub graph features and multiple labels of graphs. Then a branch-and-bound algorithm is proposed to efficiently search for optimal sub graph features by judiciously pruning the sub graph search space using multiple labels. Empirical studies on real-world tasks demonstrate that our feature selection approach can effectively boost multi-label graph classification performances and is more efficient by pruning the sub graph search space using multiple labels.

#index 1535422
#* A Binary Decision Diagram-Based One-Class Classifier
#@ Takuro Kutsuna
#t 2010
#c 18
#! We propose a novel approach for one-class classification problems where a logical formula is used to estimate the region that covers all examples. A formula is viewed as a model that represents a region and is approximated with respect to its hierarchical local densities. The approximation is done quite efficiently via direct manipulations of a binary decision diagram that is a compressed representation of a Boolean formula. The proposed method has only one parameter to be tuned, and the parameter can be selected properly with the help of the minimum description length principle, which requires no labeled training data. In other words, a one-class classifier is generated from an unlabeled training data thoroughly and automatically. Experimental results show that the proposed method works quite well with synthetic data and some realistic data.

#index 1535423
#* Detecting Blackhole and Volcano Patterns in Directed Networks
#@ Zhongmou Li;Hui Xiong;Yanchi Liu;Aoying Zhou
#t 2010
#c 18
#! In this paper, we formulate a novel problem for finding black hole and volcano patterns in a large directed graph. Specifically, a black hole pattern is a group which is made of a set of nodes in a way such that there are only in links to this group from the rest nodes in the graph. In contrast, a volcano pattern is a group which only has out links to the rest nodes in the graph. Both patterns can be observed in real world. For instance, in a trading network, a black hole pattern may represent a group of traders who are manipulating the market. In the paper, we first prove that the black hole mining problem is a dual problem of finding volcanoes. Therefore, we focus on finding the black hole patterns. Along this line, we design two pruning schemes to guide the black hole finding process. In the first pruning scheme, we strategically prune the search space based on a set of pattern-size-independent pruning rules and develop an iBlack hole algorithm. The second pruning scheme follows a divide-and-conquer strategy to further exploit the pruning results from the first pruning scheme. Indeed, a target directed graphs can be divided into several disconnected sub graphs by the first pruning scheme, and thus the black hole finding can be conducted in each disconnected sub graph rather than in a large graph. Based on these two pruning schemes, we also develop an iBlackhole-DC algorithm. Finally, experimental results on real-world data show that the iBlackhole-DC algorithm can be several orders of magnitude faster than the iBlackhole algorithm, which has a huge computational advantage over a brute-force method.

#index 1535424
#* Multi-document Summarization Using Minimum Distortion
#@ Tengfei Ma;Xiaojun Wan
#t 2010
#c 18
#! Document summarization plays an important role in the area of natural language processing and text mining. This paper proposes several novel information-theoretic models for multi-document summarization. They consider document summarization as a transmission system and assume that the best summary should have the minimum distortion. By defining a proper distortion measure and a new representation method, the combination of the last two models (the linear representation model and the facility location model) gains good experimental results on the DUC2002 and DUC2004 datasets. Moreover, we also indicate that the model has high interpretability and extensibility.

#index 1535425
#* Addressing Concept-Evolution in Concept-Drifting Data Streams
#@ Mohammad M. Masud;Qing Chen;Latifur Khan;Charu Aggarwal;Jing Gao;Jiawei Han;Bhavani Thuraisingham
#t 2010
#c 18
#! The problem of data stream classification is challenging because of many practical aspects associated with efficient processing and temporal behavior of the stream. Two such well studied aspects are infinite length and concept-drift. Since a data stream may be considered a continuous process, which is theoretically infinite in length, it is impractical to store and use all the historical data for training. Data streams also frequently experience concept-drift as a result of changes in the underlying concepts. However, another important characteristic of data streams, namely, concept-evolution is rarely addressed in the literature. Concept-evolution occurs as a result of new classes evolving in the stream. This paper addresses concept-evolution in addition to the existing challenges of infinite-length and concept-drift. In this paper, the concept-evolution phenomenon is studied, and the insights are used to construct superior novel class detection techniques. First, we propose an adaptive threshold for outlier detection, which is a vital part of novel class detection. Second, we propose a probabilistic approach for novel class detection using discrete Gini Coefficient, and prove its effectiveness both theoretically and empirically. Finally, we address the issue of simultaneous multiple novel class occurrence, and provide an elegant solution to detect more than one novel classes at the same time. We also consider feature-evolution in text data streams, which occurs because new features (i.e., words) evolve in the stream. Comparison with state-of-the-art data stream classification techniques establishes the effectiveness of the proposed approach.

#index 1535426
#* On the Computation of Stochastic Search Variable Selection in Linear Regression with UDFs
#@ Mario Navas;Carlos Ordonez;Veerabhadran Baladandayuthapani
#t 2010
#c 18
#! Computing Bayesian statistics with traditional techniques is extremely slow, specially when large data has to be exported from a relational DBMS. We propose algorithms for large scale processing of stochastic search variable selection (SSVS) for linear regression that can work entirely inside a DBMS. The traditional SSVS algorithm requires multiple scans of the input data in order to compute a regression model. Due to our optimizations, SSVS can be done in either one scan over the input table for large number of records with sufficient statistics, or one scan per iteration for high-dimensional data. We consider storage layouts which efficiently exploit DBMS parallel processing of aggregate functions. Experimental results demonstrate correctness, convergence and performance of our algorithms. Finally, the algorithms show good scalability for data with a very large number of records, or a very high number of dimensions.

#index 1535427
#* Data Editing Techniques to Allow the Application of Distance-Based Outlier Detection to Streams
#@ Vit Niennattrakul;Eamonn Keogh;Chotirat Ann Ratanamahatana
#t 2010
#c 18
#! The problem of finding outliers in data has broad applications in areas as diverse as data cleaning, fraud detection, network monitoring, invasive species monitoring, etc. While there are dozens of techniques that have been proposed to solve this problem for static data collections, very simple distance-based outlier detection methods are known to be competitive or superior to more complex methods. However, distance-based methods have time and space complexities that make them impractical for streaming data and/or resource limited sensors. In this work, we show that simple data-editing techniques can make distance-based outlier detection practical for very fast streams and resource limited sensors. Our technique generalizes to produce two algorithms, which, relative to the original algorithm, can guarantee to produce no false positives, or guarantee to produce no false negatives. Our methods are independent of both data type and distance measure, and are thus broadly applicable.

#index 1535428
#* Anomaly Detection Using an Ensemble of Feature Models
#@ Keith Noto;Carly Brodley;Donna Slonim
#t 2010
#c 18
#! We present a new approach to semi-supervised anomaly detection. Given a set of training examples believed to come from the same distribution or class, the task is to learn a model that will be able to distinguish examples in the future that do not belong to the same class. Traditional approaches typically compare the position of a new data point to the set of ``normal'' training data points in a chosen representation of the feature space. For some data sets, the normal data may not have discernible positions in feature space, but do have consistent relationships among some features that fail to appear in the anomalous examples. Our approach learns to predict the values of training set features from the values of other features. After we have formed an ensemble of predictors, we apply this ensemble to new data points. To combine the contribution of each predictor in our ensemble, we have developed a novel, information-theoretic anomaly measure that our experimental results show selects against noisy and irrelevant features. Our results on 47 data sets show that for most data sets, this approach significantly improves performance over current state-of-the-art feature space distance and density-based approaches.

#index 1535429
#* Assessing Data Mining Results on Matrices with Randomization
#@ Markus Ojala
#t 2010
#c 18
#! Randomization is a general technique for evaluating the significance of data analysis results. In randomization-based significance testing, a result is considered to be interesting if it is unlikely to obtain as good result on random data sharing some basic properties with the original data. Recently, the randomization approach has been applied to assess data mining results on binary matrices and limited types of real-valued matrices. In these works, the row and column value distributions are approximately preserved in randomization. However, the previous approaches suffer from various technical and practical shortcomings. In this paper, we give solutions to these problems and introduce a new practical algorithm for randomizing various types of matrices while preserving the row and column value distributions more accurately. We propose a new approach for randomizing matrices containing features measured in different scales. Compared to previous work, our approach can be applied to assess data mining results on different types of real-life matrices containing dissimilar features, nominal values, non-Gaussian value distributions, missing values and sparse structure. We provide an easily usable implementation that does not need problematic manual tuning as theoretically justified parameter values are given. We perform extensive experiments on various real-life datasets showing that our approach produces reasonable results on practically all types of matrices while being easy and fast to use.

#index 1535430
#* Exploiting Local Data Uncertainty to Boost Global Outlier Detection
#@ Bo Liu;Jie Yin;Yanshan Xiao;Longbing Cao;Philip S. Yu
#t 2010
#c 18
#! This paper presents a novel hybrid approach to outlier detection by incorporating local data uncertainty into the construction of a global classifier. To deal with local data uncertainty, we introduce a confidence value to each data example in the training data, which measures the strength of the corresponding class label. Our proposed method works in two steps. Firstly, we generate a pseudo training dataset by computing a confidence value of each input example on its class label. We present two different mechanisms: kernel k-means clustering algorithm and kernel LOF-based algorithm, to compute the confidence values based on the local data behavior. Secondly, we construct a global classifier for outlier detection by generalizing the SVDD-based learning framework to incorporate both positive and negative examples as well as their associated confidence values. By integrating local and global outlier detection, our proposed method explicitly handles the uncertainty of the input data and enhances the ability of SVDD in reducing the sensitivity to noise. Extensive experiments on real life datasets demonstrate that our proposed method can achieve a better tradeoff between detection rate and false alarm rate as compared to four state-of-the-art outlier detection algorithms.

#index 1535431
#* Training Conditional Random Fields Using Transfer Learning for Gesture Recognition
#@ Jie Liu;Kai Yu;Yi Zhang;Yalou Huang
#t 2010
#c 18
#! Recently, combining Conditional Random Fields (CRF) with Neural Network has shown the success of learning high-level features in sequence labeling tasks. However, such models are difficult to train because of the increase of the parameters to tune which needs enormous of labeled data to avoid over fitting. In this paper, we propose a transfer learning framework for the sequence labeling task of gesture recognition. Taking advantage of the frame correlation, we design an unsupervised sequence model as a pseudo auxiliary task to capture the underlying information from both the labeled and unlabeled data. The knowledge learnt by the auxiliary task can be transferred to the main task of CRF with a deep architecture by sharing the hidden layers, which is very helpful for learning meaningful representation and reducing the need of labeled data. We evaluate our model under 3 gesture recognition datasets. The experimental results of both supervised learning and semi-supervised learning show that the proposed model improves the performance of the CRF with Neural Network and other baseline models.

#index 1535432
#* Stratified Sampling for Data Mining on the Deep Web
#@ Tantan Liu;Fan Wang;Gagan Agrawal
#t 2010
#c 18
#! In recent years, one mode of data dissemination has become extremely popular, which is the deep web. Like any other data source, data mining on the deep web can produce important insights or summary of results. However, data mining on the deep web is challenging because the databases cannot be accessed directly, and therefore, data mining must be performed based on sampling of the datasets. The samples, in turn, can only be obtained by querying the deep web databases with specific inputs. In this paper, we target two related data mining problems, which are association mining and differential rule mining. We develop stratified sampling methods to perform these mining tasks on a deep web source. Our contributions include a novel greedy stratification approach, which processes the query space of a deep web data source recursively, and considers both the estimation error and the sampling costs. We have also developed an optimized sample allocation method that integrates estimation error and sampling costs. Our experiment results show that our algorithms effectively and consistently reduce sampling costs, compared with a stratified sampling method that only considers estimation error. In addition, compared with simple random sampling, our algorithm has higher sampling accuracy and lower sampling costs.

#index 1535433
#* Learning Markov Network Structure with Decision Trees
#@ Daniel Lowd;Jesse Davis
#t 2010
#c 18
#! Traditional Markov network structure learning algorithms perform a search for globally useful features. However, these algorithms are often slow and prone to finding local optima due to the large space of possible structures. Ravikumar et al. recently proposed the alternative idea of applying L1 logistic regression to learn a set of pair wise features for each variable, which are then combined into a global model. This paper presents the DTSL algorithm, which uses probabilistic decision trees as the local model. Our approach has two significant advantages: it is more efficient, and it is able to discover features that capture more complex interactions among the variables. Our approach can also be seen as a method for converting a dependency network into a consistent probabilistic model. In an extensive empirical evaluation on 13 datasets, our algorithm obtains comparable accuracy to three standard structure learning algorithms while running 1-4 orders of magnitude faster.

#index 1535434
#* A Generalized Linear Threshold Model for Multiple Cascades
#@ Nishith Pathak;Arindam Banerjee;Jaideep Srivastava
#t 2010
#c 18
#! This paper presents a generalized version of the linear threshold model for simulating multiple cascades on a network while allowing nodes to switch between them. The proposed model is shown to be a rapidly mixing Markov chain and the corresponding steady state distribution is used to estimate highly likely states of the cascades' spread in the network. Results on a variety of real world networks demonstrate the high quality of the estimated solution.

#index 1535435
#* Recommending Social Events from Mobile Phone Location Data
#@ Daniele Quercia;Neal Lathia;Francesco Calabrese;Giusy Di Lorenzo;Jon Crowcroft
#t 2010
#c 18
#! A city offers thousands of social events a day, and it is difficult for dwellers to make choices. The combination of mobile phones and recommender systems can change the way one deals with such abundance. Mobile phones with positioning technology are now widely available, making it easy for people to broadcast their whereabouts, recommender systems can now identify patterns in people’s movements in order to, for example, recommend events. To do so, the system relies on having mobile users who share their attendance at a large number of social events: cold-start users, who have no location history, cannot receive recommendations. We set out to address the mobile cold-start problem by answering the following research question: how can social events be recommended to a cold-start user based only on his home location? To answer this question, we carry out a study of the relationship between preferences for social events and geography, the first of its kind in a large metropolitan area. We sample location estimations of one million mobile phone users in Greater Boston, combine the sample with social events in the same area, and infer the social events attended by 2,519 residents. Upon this data, we test a variety of algorithms for recommending social events. We find that the most effective algorithm recommends events that are popular among residents of an area. The least effective, instead, recommends events that are geographically close to the area. This last result has interesting implications for location-based services that emphasize recommending nearby events.

#index 1535436
#* On Normalizing Fuzzy Coincidence Matrices to Compare Fuzzy and/or Possibilistic Partitions with the Rand Index
#@ R. Quere;H. Le Capitaine;N. Fraisseix;C. Frelicot
#t 2010
#c 18
#! Most already existing indices used to compare two strict partitions with different number of clusters are based on coincidence matrices. To extend such indices to fuzzy partitions, one can define fuzzy coincidence matrices by means of triangular norms. It has been shown this can require some kind of normalization to reinforce the corresponding indices. We propose in this paper a generic solution to perform this normalization considering the generators of the used triangular norms. Although the solution is not index-dependant, we focus on the Rand index and some of its fuzzy counterparts.

#index 1535437
#* Financial Forecasting with Gompertz Multiple Kernel Learning
#@ Han Qin;Dejing Dou;Yue Fang
#t 2010
#c 18
#! Financial forecasting is the basis for budgeting activities and estimating future financing needs. Applying machine learning and data mining models to financial forecasting is both effective and efficient. Among different kinds of machine learning models, kernel methods are well accepted since they are more robust and accurate than traditional models, such as neural networks. However, learning from multiple data sources is still one of the main challenges in the financial forecasting area. In this paper, we focus on applying the multiple kernel learning models to the multiple major international stock indexes. Our experiment results indicate that applying multiple kernel learning to the financial forecasting problem suffers from both the short training period problem and non-stationary problem. Therefore we propose a novel multiple kernel learning model to address the challenge by introducing the Gompertz model and considering a non-linear combination of different kernel matrices. The experiment results show that our Gompertz multiple kernel learning model addresses the challenges and achieves better performance than the original multiple kernel learning model and single SVM models.

#index 1535438
#* Leveraging D-Separation for Relational Data Sets
#@ Matthew J. H. Rattigan;David Jensen
#t 2010
#c 18
#! Testing for marginal and conditional independence is a common task in machine learning and knowledge discovery applications. Prior work has demonstrated that conventional independence tests suffer from dramatically increased rates of Type I errors when naively applied to relational data. We use graphical models to specify the conditions under which these errors occur, and use those models to devise novel and accurate conditional independence tests.

#index 1535439
#* Factorization Machines
#@ Steffen Rendle
#t 2010
#c 18
#! In this paper, we introduce Factorization Machines (FM) which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models. Like SVMs, FMs are a general predictor working with any real valued feature vector. In contrast to SVMs, FMs model all interactions between variables using factorized parameters. Thus they are able to estimate interactions even in problems with huge sparsity (like recommender systems) where SVMs fail. We show that the model equation of FMs can be calculated in linear time and thus FMs can be optimized directly. So unlike nonlinear SVMs, a transformation in the dual form is not necessary and the model parameters can be estimated directly without the need of any support vector in the solution. We show the relationship to SVMs and the advantages of FMs for parameter estimation in sparse settings. On the other hand there are many different factorization models like matrix factorization, parallel factor analysis or specialized models like SVD++, PITF or FPMC. The drawback of these models is that they are not applicable for general prediction tasks but work only with special input data. Furthermore their model equations and optimization algorithms are derived individually for each task. We show that FMs can mimic these models just by specifying the input data (i.e. the feature vectors). This makes FMs easily applicable even for users without expert knowledge in factorization models.

#index 1535440
#* Towards Structural Sparsity: An Explicit l2/l0 Approach
#@ Dijun Luo;Chris Ding;Heng Huang
#t 2010
#c 18
#! In many cases of machine learning or data mining applications, we are not only aimed to establish accurate {\em black box} predictors, we are also interested in discovering predictive patterns in data which enhance our interpretation and understanding of underlying physical, biological and other natural processes. Sparse representation is one of the focuses in this direction. More recently, structural sparsity has attracted increasing attentions. The structural sparsity is often achieved by imposing l2/l1 norms. In this paper, we present the explicit l2/l0 norm to directly achieve structural sparsity. To tackle the problem of intractable l2/l0 optimization, we develop a general Lipschitz auxiliary function which leads to simple iterative algorithms. In each iteration, optimal solution is achieved for the induced sub-problem and a guarantee of convergence is provided. Further more, the local convergent rate is also theoretically bounded. We test our optimization techniques in the multi-task feature learning problem. Experimental results suggest that our approaches outperform other approaches in both synthetic and real world data sets.

#index 1535441
#* A Log-Linear Model with Latent Features for Dyadic Prediction
#@ Aditya Krishna Menon;Charles Elkan
#t 2010
#c 18
#! In dyadic prediction, labels must be predicted for pairs (dyads) whose members possess unique identifiers and, sometimes, additional features called side-information. Special cases of this problem include collaborative filtering and link prediction. We present a new {log-linear} model for dyadic prediction that is the first to satisfy several important desiderata: (i) labels may be ordinal or nominal, (ii) side-information can be easily exploited if present, (iii) with or without side-information, latent features are inferred for dyad members, (iv) the model is resistant to sample-selection bias, (v) it can learn well-calibrated probabilities, and (vi) it can scale to large datasets. To our knowledge, no existing method satisfies all the above criteria. In particular, many methods assume that the labels are binary or numerical, and cannot use side-information. Experimental results show that the new method is competitive with previous specialized methods for collaborative filtering and link prediction. Other experimental results demonstrate that the new method succeeds for dyadic prediction tasks where previous methods cannot be used. In particular, the new method predicts nominal labels accurately, and by using side-information it solves the cold-start problem in collaborative filtering.

#index 1535442
#* Edge Weight Regularization over Multiple Graphs for Similarity Learning
#@ Pradeep Muthukrishnan;Dragomir Radev;Qiaozhu Mei
#t 2010
#c 18
#! The growth of the web has directly influenced the increase in the availability of relational data. One of the key problems in mining such data is computing the similarity between objects with heterogeneous feature types. For example, publications have many heterogeneous features like text, citations, authorship information, venue information, etc. In most approaches, similarity is estimated using each feature type in isolation and then combined in a linear fashion. However, this approach does not take advantage of the dependencies between the different feature spaces. In this paper, we propose a novel approach to combine the different sources of similarity using a regularization framework over edges in multiple graphs. We show that the objective function induced by the framework is convex. We also propose an efficient algorithm using coordinate descent [1] to solve the optimization problem. We extrinsically evaluate the performance of the proposed unified similarity measure on two different tasks, clustering and classification. The proposed similarity measure outperforms three baselines and a state-of-the-art classification algorithm on a variety of standard, large data sets.

#index 1535443
#* A New SVM Approach to Multi-instance Multi-label Learning
#@ Nam Nguyen
#t 2010
#c 18
#! In this paper, we address the problem of multi-instance multi-label learning (MIML) where each example is associated with not only multiple instances but also multiple class labels. In our novel approach, given an MIML example, each instance in the example is only associated with a single label and the label set of the example is the aggregation of all instance labels. Many real-world tasks such as scene classification, text categorization and gene sequence encoding can be properly formalized under our proposed approach. We formulate our MIML problem as a combination of two optimizations: (1) a quadratic programming (QP) that minimizes the empirical risk with L2-norm regularization, and (2) an integer programing (IP) assigning each instance to a single label. We also present an efficient method combining the stochastic gradient decent and alternating optimization approaches to solve our QP and IP optimizations. In our experiments with both an artificially generated data set and real-world applications, i.e. scene classification and text categorization, our proposed method achieves superior performance over existing state-of-the-art MIML methods such as MIMLBOOST, MIMLSVM, M$^3$MIML and MIMLRBF.

#index 1535444
#* Bayesian Aggregation of Binary Classifiers
#@ Sunho Park;Seungjin Choi
#t 2010
#c 18
#! Multiclass classification problems are often decomposed into multiple binary problems that are solved by individual binary classifiers whose results are integrated into a final answer. Various methods have been developed to aggregate binary classifiers, including voting heuristics, loss-based decoding, and probabilistic decoding methods, but a little work on the optimal aggregation has been done. In this paper we present a Bayesian method for optimally aggregating binary classifiers where class membership probabilities are determined by predictive probabilities. We model the class membership probability as a softmax function whose input argument is a linear combination of discrepancies between code words and probability estimates obtained by the binary classifiers. We consider a lower bound on the softmax function, which is represented as a product of logistic sigmoids, and we formulate the problem of learning aggregation weights as a variational logistic regression. Predictive probabilities computed by variational logistic regression yield the class membership probabilities. We stress two notable advantages over existing methods in the viewpoint of complexity and over fitting. Numerical experiments on several datasets confirm its useful behavior.

#index 1535445
#* Accelerating Dynamic Time Warping Subsequence Search with GPUs and FPGAs
#@ Doruk Sart;Abdullah Mueen;Walid Najjar;Eamonn Keogh;Vit Niennattrakul
#t 2010
#c 18
#! Many time series data mining problems require subsequence similarity search as a subroutine. Dozens of similarity/distance measures have been proposed in the last decade and there is increasing evidence that Dynamic Time Warping (DTW) is the best measure across a wide range of domains. Given DTW’s usefulness and ubiquity, there has been a large community-wide effort to mitigate its relative lethargy. Proposed speedup techniques include early abandoning strategies, lower-bound based pruning, indexing and embedding. In this work we argue that we are now close to exhausting all possible speedup from software, and that we must turn to hardware-based solutions. With this motivation, we investigate both GPU (Graphics Processing Unit) and FPGA (Field Programmable Gate Array) based acceleration of subsequence similarity search under the DTW measure. As we shall show, our novel algorithms allow GPUs to achieve two orders of magnitude speedup and FPGAs to produce four orders of magnitude speedup. We conduct detailed case studies on the classification of astronomical observations and demonstrate that our ideas allow us to tackle problems that would be untenable otherwise.

#index 1535446
#* An Approach for Automatic Sleep Stage Scoring and Apnea-Hypopnea Detection
#@ Tim Schluter;Stefan Conrad
#t 2010
#c 18
#! This paper presents an application of data mining to the medical domain sleep research, i.e. an approach for automatic sleep stage scoring and apnea-hypopnea detection. By several combined techniques (Fourier and wavelet transform, DDTW and waveform recognition), our approach extracts meaningful features (frequencies and special patterns) from EEG, ECG, EOG and EMG data, on which a decision trees classifier is built for classifying epochs into their sleep stages (according to the rules by Rechtschaffen and Kales) and annotating occurrences of apnea-hypopnea (total or partial cessation of respiration). After that, case-based reasoning is applied to improve quality. We evaluated our approach on 3 large public databases from PhysioBank, which showed an overall accuracy of 95.2% for sleep stage scoring and 94.5% for classifying apneic/non-apneic minutes.

#index 1535447
#* Bonsai: Growing Interesting Small Trees
#@ Stephan Seufert;Srikanta Bedathur;Julian Mestre;Gerhard Weikum
#t 2010
#c 18
#! Graphs are increasingly used to model a variety of loosely structured data such as biological or social networks and entity-relationships. Given this profusion of large-scale graph data, efficiently discovering interesting substructures buried within is essential. These substructures are typically used in determining subsequent actions, such as conducting visual analytics by humans or designing expensive biomedical experiments. In such settings, it is often desirable to constrain the size of the discovered results in order to directly control the associated costs. In this paper, we address the problem of finding cardinality-constrained connected sub trees in large node-weighted graphs that maximize the sum of weights of selected nodes. We provide an efficient constant-factor approximation algorithm for this strongly NP-hard problem. Our techniques can be applied in a wide variety of application settings, for example in differential analysis of graphs, a problem that frequently arises in bioinformatics but also has applications on the web.

#index 1535448
#* Mixed-Membership Stochastic Block-Models for Transactional Networks
#@ Mahdi Shafiei;Hugh Chipman
#t 2010
#c 18
#! Transactional network data can be thought of as a list of one-to-many communications (e.g., email) between nodes in a social network. Most social network models convert this type of data into binary relations between pairs of nodes. We develop a latent mixed membership model capable of modeling richer forms of transactional network data, including relations between more than two nodes. The model can cluster nodes and predict transactions. The block-model nature of the model implies that groups can be characterized in very general ways. This flexible notion of group structure enables discovery of rich structure in transactional networks. Estimation and inference are accomplished via a variational EM algorithm. Simulations indicate that the learning algorithm can recover the correct generative model. Interesting structure is discovered in the Enron email dataset and another dataset extracted from the Reddit website. Analysis of the Reddit data is facilitated by a novel performance measure for comparing two soft clusterings. The new model is superior at discovering mixed membership in groups and in predicting transactions.

#index 1535449
#* Generalized Probabilistic Matrix Factorizations for Collaborative Filtering
#@ Hanhuai Shan;Arindam Banerjee
#t 2010
#c 18
#! Probabilistic matrix factorization (PMF) methods have shown great promise in collaborative filtering. In this paper, we consider several variants and generalizations of PMF framework inspired by three broad questions: Are the prior distributions used in existing PMF models suitable, or can one get better predictive performance with different priors? Are there suitable extensions to leverage side information? Are there benefits to taking into account row and column biases? We develop new families of PMF models to address these questions along with efficient approximate inference algorithms for learning and prediction. Through extensive experiments on movie recommendation datasets, we illustrate that simpler models directly capturing correlations among latent factors can outperform existing PMF models, side information can benefit prediction accuracy, and accounting for row/column biases leads to improvements in predictive performance.

#index 1535450
#* Topic Modeling Ensembles
#@ Zhiyong Shen;Ping Luo;Shengwen Yang;Xukun Shen
#t 2010
#c 18
#! In this paper we propose a framework of topic modeling ensembles, a novel solution to combine the models learned by topic modeling over each partition of the whole corpus. It has the potentials for applications such as distributed topic modeling for large corpora, and incremental topic modeling for rapidly growing corpora. Since only the base models, not the original documents, are required in the ensemble, all these applications can be performed in a privacy preserving manner. We explore the theoretical foundation of the proposed framework, give its geometric interpretation, and implement it for both PLSA and LDA. The evaluation of the implementations over the synthetic and real-life data sets shows that the proposed framework is much more efficient than modeling the original corpus directly while achieves comparable effectiveness in terms of perplexity and classification accuracy.

#index 1535451
#* Permutations as Angular Data: Efficient Inference in Factorial Spaces
#@ Sergey M. Plis;Terran Lane;Vince D. Calhoun
#t 2010
#c 18
#! Distributions over permutations arise in applications ranging from multi-object tracking to ranking of instances. The difficulty of dealing with these distributions is caused by the size of their domain, which is factorial in the number of considered entities ($n!$). It makes the direct definition of a multinomial distribution over permutation space impractical for all but a very small $n$. In this work we propose an embedding of all $n!$ permutations for a given $n$ in a surface of a hyper sphere defined in $\mathbbm{R}^{(n-1)}$. As a result of the embedding, we acquire ability to define continuous distributions over a hyper sphere with all the benefits of directional statistics. We provide polynomial time projections between the continuous hyper sphere representation and the $n!$-element permutation space. The framework provides a way to use continuous directional probability densities and the methods developed thereof for establishing densities over permutations. As a demonstration of the benefits of the framework we derive an inference procedure for a state-space model over permutations. We demonstrate the approach with simulations on a large number of objects hardly manageable by the state of the art inference methods, and an application to a real flight traffic control dataset.

#index 1535452
#* Separation of Interleaved Web Sessions with Heuristic Search
#@ Marko Pozenel;Viljan Mahnic;Matjaz Kukar
#t 2010
#c 18
#! We describe a heuristic search-based method for interleaved HTTP (Web) session reconstruction building upon first order Markov models. An interleaved session is generated by a user who is concurrently browsing the same web site in two or more web sessions (browser tabs or windows). In order to assure data quality for subsequent phases in analyzing user's browsing behavior, such sessions need to be separated in advance. We propose a separating process based on best-first search and trained first order Markov chains. We develop a testing method based on various measures of reconstructed sessions similarity to original ones. We evaluate the developed method on two real world click stream data sources: a web shop and a university student records information system. Preliminary results show that the proposed method performs well.

#index 1535453
#* Consequences of Variability in Classifier Performance Estimates
#@ Troy Raeder;T. Ryan Hoens;Nitesh V. Chawla
#t 2010
#c 18
#! The prevailing approach to evaluating classifiers in the machine learning community involves comparing the performance of several algorithms over a series of usually unrelated data sets. However, beyond this there are many dimensions along which methodologies vary wildly. We show that, depending on the stability and similarity of the algorithms being compared, these sometimes-arbitrary methodological choices can have a significant impact on the conclusions of any study, including the results of statistical tests. In particular, we show that performance metrics and data sets used, the type of cross-validation employed, and the number of iterations of cross-validation run have a significant, and often predictable, effect. Based on these results, we offer a series of recommendations for achieving consistent, reproducible results in classifier performance comparisons.

#index 1535454
#* Mining Sensor Streams for Discovering Human Activity Patterns over Time
#@ Parisa Rashidi;Diane J. Cook
#t 2010
#c 18
#! In recent years, new emerging application domains have introduced new constraints and methods in data mining field. One of such application domains is activity discovery from sensor data. Activity discovery and recognition plays an important role in a wide range of applications from assisted living to security and surveillance. Most of the current approaches for activity discovery assume a static model of the activities and ignore the problem of mining and discovering activities from a data stream over time. Inspired by the unique requirements of activity discovery application domain, in this paper we propose a new stream mining method for finding sequential patterns over time from streaming non-transaction data using multiple time granularities. Our algorithm is able to find sequential patterns, even if the patterns exhibit discontinuities (interruptions) or variations in the sequence order. Our algorithm also addresses the problem of dealing with rare events across space and over time. We validate the results of our algorithms using data collected from two different smart apartments.

#index 1535455
#* Decision Trees for Uplift Modeling
#@ Piotr Rzepakowski;Szymon Jaroszewicz
#t 2010
#c 18
#! Most classification approaches aim at achieving high prediction accuracy on a given dataset. However, in most practical cases, some action, such as mailing an offer or treating a patient, is to be taken on the classified objects and we should model not the class probabilities themselves, but instead, the change in class probabilities caused by the action. The action should then be performed on those objects for which it will be most profitable. This problem is known as uplift modeling, differential response analysis or true lift modeling, but has received very little attention in Machine Learning literature. In the paper we present a tree based classifier tailored specifically to this task. To this end, we design new splitting criteria and pruning methods. The experiments confirm the usefulness of the proposed approach and show significant improvement over previous uplift modeling techniques.

#index 1535456
#* LogTree: A Framework for Generating System Events from Raw Textual Logs
#@ Liang Tang;Tao Li
#t 2010
#c 18
#! Modern computing systems are instrumented to generate huge amounts of system logs and these data can be utilized for understanding and complex system behaviors. One main fundamental challenge in automated log analysis is the generation of system events from raw textual logs. Recent works apply clustering techniques to translate the raw log messages into system events using only the word/term information. In this paper, we first illustrate the drawbacks of existing techniques for event generation from system logs. We then propose Log Tree, a novel and algorithm-independent framework for events generation from raw system log messages. Log Tree utilizes the format and structural information of the raw logs in the clustering process to generate system events with better accuracy. In addition, an indexing data structure, Message Segment Table, is proposed in Log Tree to significantly improve the efficiency of events creation. Extensive experiments on real system logs demonstrate the effectiveness and efficiency of Log Tree.

#index 1535457
#* Interval-valued Matrix Factorization with Applications
#@ Zhiyong Shen;Liang Du;Xukun Shen;Yidong Shen
#t 2010
#c 18
#! In this paper, we propose the Interval-valued Matrix Factorization (IMF) framework. Matrix Factorization (MF) is a fundamental building block of data mining. MF techniques, such as Nonnegative Matrix Factorization (NMF) and Probabilistic Matrix Factorization (PMF), are widely used in applications of data mining. For example, NMF has shown its advantage in Face Analysis (FA) while PMF has been successfully applied to Collaborative Filtering (CF). In this paper, we analyze the data approximation in FA as well as CF applications and construct interval-valued matrices to capture these approximation phenomenons. We adapt basic NMF and PMF models to the interval-valued matrices and propose Interval-valued NMF (I-NMF) as well as Interval-valued PMF (I-PMF). We conduct extensive experiments to show that proposed I-NMF and I-PMF significantly outperform their single-valued counterparts in FA and CF applications.

#index 1535458
#* Efficient Semi-supervised Spectral Co-clustering with Constraints
#@ Xiaoxiao Shi;Wei Fan;Philip S. Yu
#t 2010
#c 18
#! Co-clustering was proposed to simultaneously cluster objects and features to explore inter-correlated patterns. For example, by analyzing the blog click-through data, one finds the group of users who are interested in a specific group of blogs in order to perform applications such as recommendations. However, it is usually very difficult to achieve good co-clustering quality by just analyzing the object-feature correlation data due to the sparsity of the data and the noise. Meanwhile, one may have some prior knowledge that indicates the internal structure of the co-clusters. For instance, one may find user cluster information from the social network system, and the blog-blog similarity from the social tags or contents. This prior information provides some supervision toward the co-cluster structures, and may help reduce the effect of sparsity and noise. However, most co-clustering algorithms do not use this information and may produce unmeaningful results. In this paper we study the problem of finding the optimal co-clusters when some objects and features are believed to be in the same cluster a priori. A matrix decomposition based approach is proposed to formulate as a trace minimization problem, and solve it efficiently with the selected eigenvectors. The asymptotic complexity of the proposed approach is the same as co-clustering without constraints. Experiments include graph-pattern co-clustering and document-word co-clustering. For instance, in graph-pattern data set, the proposed model can improve the normalized mutual information by as much as 5.5 times and 10 times faster than two naive solutions that expand the edges and vertices in the graphs.

#index 1535459
#* Transfer Learning on Heterogenous Feature Spaces via Spectral Transformation
#@ Xiaoxiao Shi;Qi Liu;Wei Fan;Philip S. Yu;Ruixin Zhu
#t 2010
#c 18
#! Labeled examples are often expensive and time-consuming to obtain. One practically important problem is: can the labeled data from other related sources help predict the target task, even if they have (a) different feature spaces (e.g., image vs. text data), (b) different data distributions, and (c) different output spaces? This paper proposes a solution and discusses the conditions where this is possible and highly likely to produce better results. It works by first using spectral embedding to unify the different feature spaces of the target and source data sets, even when they have completely different feature spaces. The principle is to cast into an optimization objective that preserves the original structure of the data, while at the same time, maximizes the similarity between the two. Second, a judicious sample selection strategy is applied to select only those related source examples. At last, a Bayesian-based approach is applied to model the relationship between different output spaces. The three steps can bridge related heterogeneous sources in order to learn the target task. Among the 12 experiment data sets, for example, the images with wavelet-transformed-based features are used to predict another set of images whose features are constructed from color-histogram space. By using these extracted examples from heterogeneous sources, the models can reduce the error rate by as much as~50\%, compared with the methods using only the examples from the target task.

#index 1535460
#* One-Class Matrix Completion with Low-Density Factorizations
#@ Vikas Sindhwani;Serhat S. Bucak;Jianying Hu;Aleksandra Mojsilovic
#t 2010
#c 18
#! Consider a typical recommendation problem. A company has historical records of products sold to a large customer base. These records may be compactly represented as a sparse customer-times-product ``who-bought-what" binary matrix. Given this matrix, the goal is to build a model that provides recommendations for which products should be sold next to the existing customer base. Such problems may naturally be formulated as collaborative filtering tasks. However, this is a {\it one-class} setting, that is, the only known entries in the matrix are one-valued. If a customer has not bought a product yet, it does not imply that the customer has a low propensity to {\it potentially} be interested in that product. In the absence of entries explicitly labeled as negative examples, one may resort to considering unobserved customer-product pairs as either missing data or as surrogate negative instances. In this paper, we propose an approach to explicitly deal with this kind of ambiguity by instead treating the unobserved entries as optimization variables. These variables are optimized in conjunction with learning a weighted, low-rank non-negative matrix factorization (NMF) of the customer-product matrix, similar to how Transductive SVMs implement the low-density separation principle for semi-supervised learning. Experimental results show that our approach gives significantly better recommendations in comparison to various competing alternatives on one-class collaborative filtering tasks.

#index 1535461
#* Visualizing Graphs Using Minimum Spanning Dendrograms
#@ Daniel Svonava;Michail Vlachos
#t 2010
#c 18
#! We present a novel visualization methodology for graphs and high-dimensional data which combines the neighborhood preservation characteristics of the minimum spanning trees, with the grouping properties of dendrograms. We call the method `minimum spanning dendrogram'. We highlight the ability of the mapping to accurately capture both neighborhood and cluster structures. The technique accommodates the interactive cluster formation at progressively more granular levels, allowing the user to explore data relationships at different resolutions. We also compare our work with other visualization methodologies, such as ISOMAP, and highlight the distinct merits of our approach.

#index 1535462
#* Co-clustering of Lagged Data
#@ Eran Shaham;David Sarne;Boaz Ben-Moshe
#t 2010
#c 18
#! The paper focuses on mining clusters that are characterized by a lagged relationship between the data objects. We call such clusters lagged co-clusters. A lagged co-cluster of a matrix is a sub matrix determined by a subset of rows and their corresponding lag over a subset of columns. Extracting such subsets (not necessarily successive) may reveal an underlying governing regulatory mechanism. Such a regulatory mechanism is quite common in real life settings. It appears in a variety of fields: meteorology, seismic activity, stock market behavior, neuronal brain activity, river flow and navigation, are but a limited list of examples. Mining such lagged co-clusters not only helps in understanding the relationship between objects in the domain, but assists in forecasting their future behavior. For most interesting variants of this problem, finding an optimal lagged co-cluster is an NP-complete problem. We present a polynomial-time Monte-Carlo algorithm for finding a set of lagged co-clusters whose error does not exceed a pre-specified value, which handles noise, anti-correlations, missing values, and overlapping patterns. Moreover, we prove that the list includes, with fixed probability, a lagged co-cluster which is optimal in its dimensions. The algorithm was extensively evaluated using various environments. First, artificial data, enabling the evaluation of specific, isolated properties of the algorithm. Secondly, real-world data, using river flow and topographic data, enabling the evaluation of the algorithm to efficiently mine relevant and coherent lagged co-clusters in environments that are temporal, i.e., time reading data, and non-temporal, respectively.

#index 1535463
#* Polishing the Right Apple: Anytime Classification Also Benefits Data Streams with Constant Arrival Times
#@ Jin Shieh;Eamonn Keogh
#t 2010
#c 18
#! Classification of items taken from data streams requires algorithms that operate in time sensitive and computationally constrained environments. Often, the available time for classification is not known a priori and may change as a consequence of external circumstances. Many traditional algorithms are unable to provide satisfactory performance while supporting the highly variable response times that exemplify such applications. In such contexts, anytime algorithms, which are amenable to trading time for accuracy, have been found to be exceptionally useful and constitute an area of increasing research activity. Previous techniques for improving anytime classification have generally been concerned with optimizing the probability of correctly classifying individual objects. However, as we shall see, serially optimizing the probability of correctly classifying individual objects K times, generally gives inferior results to batch optimizing the probability of correctly classifying K objects. In this work, we show that this simple observation can be exploited to improve overall classification performance by using an anytime framework to allocate resources among a set of objects buffered from a fast arriving stream. Our ideas are independent of object arrival behavior, and, perhaps unintuitively, even in data streams with constant arrival rates our technique exhibits a marked improvement in performance. The utility of our approach is demonstrated with extensive experimental evaluations conducted on a wide range of diverse datasets.

#index 1535464
#* Discovering Correlated Subspace Clusters in 3D Continuous-Valued Data
#@ Kelvin Sim;Zeyar Aung;Vivekanand Gopalkrishnan
#t 2010
#c 18
#! Subspace clusters represent useful information in high-dimensional data. However, mining significant subspace clusters in continuous-valued 3D data such as stock-financial ratio-year data, or gene-sample-time data, is difficult. Firstly, typical metrics either find subspaces with very few objects, or they find too many insignificant subspaces – those which exist by chance. Besides, typical 3D subspace clustering approaches abound with parameters, which are usually set under biased assumptions, making the mining process a ‘guessing game’. We address these concerns by proposing an information theoretic measure, which allows us to identify 3D subspace clusters that stand out from the data. We also develop a highly effective, efficient and parameter-robust algorithm, which is a hybrid of information theoretical and statistical techniques, to mine these clusters. From extensive experimentations, we show that our approach can discover significant 3D subspace clusters embedded in 110 synthetic datasets of varying conditions. We also perform a case study on real-world stock datasets, which shows that our clusters can generate higher profits compared to those mined by other approaches.

#index 1535465
#* gSkeletonClu: Density-Based Network Clustering via Structure-Connected Tree Division or Agglomeration
#@ Heli Sun;Jianbin Huang;Jiawei Han;Hongbo Deng;Peixiang Zhao;Boqin Feng
#t 2010
#c 18
#! Community detection is an important task for mining the structure and function of complex networks. Many pervious approaches are difficult to detect communities with arbitrary size and shape, and are unable to identify hubs and outliers. A recently proposed network clustering algorithm, SCAN, is effective and can overcome this difficulty. However, it depends on a sensitive parameter: minimum similarity threshold $\varepsilon$, but provides no automated way to find it. In this paper, we propose a novel density-based network clustering algorithm, called gSkeletonClu (graph-skeleton based clustering). By projecting a network to its Core-Connected Maximal Spanning Tree (CCMST), the network clustering problem is converted to finding core-connected components in the CCMST. We discover that all possible values of the parameter $\varepsilon$ lie in the edge weights of the corresponding CCMST. By means of tree divisive or agglomerative clustering, our algorithm can find the optimal parameter $\varepsilon$ and detect communities, hubs and outliers in large-scale undirected networks automatically without any user interaction. Extensive experiments on both real-world and synthetic networks demonstrate the superior performance of gSkeletonClu over the baseline methods.

#index 1535466
#* A System for Mining Temporal Physiological Data Streams for Advanced Prognostic Decision Support
#@ Jimeng Sun;Daby Sow;Jianying Hu;Shahram Ebadollahi
#t 2010
#c 18
#! We present a mining system that can predict the future health status of the patient using the temporal trajectories of health status of a set of similar patients. The main novelties of this system are its use of stream processing technology for handling the incoming physiological time series data and incorporating domain knowledge in learning the similarity metric between patients represented by their temporal data. The proposed approach and system were tested using the MIMIC II database, which consists of physiological waveforms, and accompanying clinical data obtained for ICU patients. The study was carried out on 1500 patients from this database. In the experiments we report the efficiency and throughput of the stream processing unit for feature extraction, the effectiveness of the supervised similarity measure both in the context of classification and retrieval tasks compared to unsupervised approaches, and the accuracy of the temporal projections of the patient data.

#index 1535467
#* Averaged Stochastic Gradient Descent with Feedback: An Accurate, Robust, and Fast Training Method
#@ Xu Sun;Hisashi Kashima;Takuya Matsuzaki;Naonori Ueda
#t 2010
#c 18
#! On large datasets, the popular training approach has been stochastic gradient descent (SGD). This paper proposes a modification of SGD, called averaged SGD with feedback (ASF), that significantly improves the performance (robustness, accuracy, and training speed) over the traditional SGD. The proposal is based on three simple ideas: averaging the weight vectors across SGD iterations, feeding the averaged weights back into the SGD update process, and deciding when to perform the feedback (linearly slowing down feedback). Theoretically, we demonstrate the reasonable convergence properties of the ASF. Empirically, the ASF outperforms several strong baselines in terms of accuracy, robustness over the noise, and the training speed. To our knowledge, this is the first study of ``feedback'' in stochastic gradient learning. Although we choose latent conditional models for verifying the ASF in this paper, the ASF is a general purpose technique just like SGD, and can be directly applied to other models.

#index 1535468
#* Tru-Alarm: Trustworthiness Analysis of Sensor Networks in Cyber-Physical Systems
#@ Lu-An Tang;Xiao Yu;Sangkyum Kim;Jiawei Han;Chih-Chieh Hung;Wen-Chih Peng
#t 2010
#c 18
#! A Cyber-Physical System (CPS) integrates physical devices (e.g., sensors, cameras) with cyber (or informational)components to form a situation-integrated analytical system that responds intelligently to dynamic changes of the real-world scenarios. One key issue in CPS research is trustworthiness analysis of the observed data: Due to technology limitations and environmental influences, the CPS data are inherently noisy that may trigger many false alarms. It is highly desirable to sift meaningful information from a large volume of noisy data. In this paper, we propose a method called Tru-Alarm which finds out trustworthy alarms and increases the feasibility of CPS. Tru-Alarm estimates the locations of objects causing alarms, constructs an object-alarm graph and carries out trustworthiness inferences based on linked information in the graph. Extensive experiments show that Tru-Alarm filters out noises and false information efficiently and guarantees not missing any meaningful alarms.

#index 1535469
#* Node Similarities from Spreading Activation
#@ Kilian Thiel;Michael R. Berthold
#t 2010
#c 18
#! In this paper we propose two methods to derive two different kinds of node similarities in a network based on their neighborhood. The first similarity measure focuses on the overlap of direct and indirect neighbors. The second similarity compares nodes based on the structure of their - possibly also very distant - neighborhoods. Instead of using standard node measures, both similarities are derived from spreading activation patterns over time. Whereas in the first method the activation patterns are directly compared, in the second method the relative change of activation over time is compared. We apply both methods to a real-world graph dataset and discuss the results.

#index 1535470
#* On the Vulnerability of Large Graphs
#@ Hanghang Tong;B. Aditya Prakash;Charalampos Tsourakakis;Tina Eliassi-Rad;Christos Faloutsos;Duen Horng Chau
#t 2010
#c 18
#! Given a large graph, like a computer network, which k nodes should we immunize (or monitor, or remove), to make it as robust as possible against a computer virus attack? We need (a) a measure of the ‘Vulnerability’ of a given network, b) a measure of the ‘Shield-value’ of a specific set of k nodes and (c) a fast algorithm to choose the best such k nodes. We answer all these three questions: we give the justification behind our choices, we show that they agree with intuition as well as recent results in immunology. Moreover, we propose Net Shield, a fast and scalable algorithm. Finally, we give experiments on large real graphs, where Net Shield achieves tremendous speed savings exceeding 7 orders of magnitude, against straightforward competitors.

#index 1535471
#* Testing the Significance of Patterns in Data with Cluster Structure
#@ Niko Vuokko;Petteri Kaski
#t 2010
#c 18
#! Clustering is one of the basic operations in data analysis, and the cluster structure of a dataset often has a marked effect on observed patterns in data. Testing whether a data mining result is implied by the cluster structure can give substantial information on the formation of the dataset. We propose a new method for empirically testing the statistical significance of patterns in real-valued data in relation to the cluster structure. The method relies on principal component analysis and is based on the general idea of decomposing the data for the purpose of isolating the null model. We evaluate the performance of the method and the information it provides on various real datasets. Our results show that the proposed method is robust and provides nontrivial information about the origin of patterns in data, such as the source of classification accuracy and the observed correlations between attributes.

#index 1535472
#* Mining Closed Strict Episodes
#@ Nikolaj Tatti;Boris Cule
#t 2010
#c 18
#! Discovering patterns in a sequence is an important aspect of data mining. One popular choice of such patterns are episodes, patterns in sequential data describing events that often occur in the vicinity of each other. Episodes also enforce in which order events are allowed to occur. In this work we introduce a technique for discovering closed episodes. Adopting existing approaches for discovering traditional patterns, such as closed item sets, to episodes is not straightforward. First of all, we cannot define a unique closure based on frequency because an episode may have several closed super episodes. Moreover, to define a closedness concept for episodes we need a subset relationship between episodes, which is not trivial to define. We approach these problems by introducing strict episodes. We argue that this class is general enough, and at the same time we are able to define a natural subset relationship within it and use it efficiently. In order to mine closed episodes we define an auxiliary closure operator. We show that this closure satisfies the needed Galois connection so that we can use the existing framework for mining closed patterns. Discovering the true closed episodes can be done as a post-processing step. We combine these observations into an efficient mining algorithm and demonstrate empirically its performance in practice.

#index 1535473
#* Multi-dimensional Mass Estimation and Mass-based Clustering
#@ Kai Ming Ting;Jonathan R. Wells
#t 2010
#c 18
#! Mass estimation, an alternative to density estimation, has been shown recently to be an effective base modelling mechanism for three data mining tasks of regression, information retrieval and anomaly detection. This paper advances this work in two directions. First, we generalise the previously proposed one-dimensional mass estimation to multi-dimensional mass estimation, and significantly reduce the time complexity to $O(\psi h)$ from $O({\psi}^{h})—making it feasible for a full range of generic problems. Second, we introduce the first clustering method based on mass#x2014;it is unique because it does not employ any distance or density measure. The structure of the new mass model enables different parts of a cluster to be identified and merged without expensive evaluations. The characteristics of the new clustering method are: (i) it can identify arbitrary-shape clusters, (ii) it is significantly faster than existing density-based or distance-based methods, and (iii) it is noise-tolerant.

#index 1535474
#* minCEntropy: A Novel Information Theoretic Approach for the Generation of Alternative Clusterings
#@ Nguyen Xuan Vinh;Julien Epps
#t 2010
#c 18
#! Traditional clustering has focused on creating a single good clustering solution, while modern, high dimensional data can often be interpreted, and hence clustered, in different ways. Alternative clustering aims at creating multiple clustering solutions that are both of high quality and distinctive from each other. Methods for alternative clustering can be divided into objective-function-oriented and data-transformation-oriented approaches. This paper presents a novel information theoretic-based, objective-function-oriented approach to generate alternative clusterings, in either an unsupervised or semi-supervised manner. We employ the conditional entropy measure for quantifying both clustering quality and distinctiveness, resulting in an analytically consistent combined criterion. Our approach employs a computationally efficient nonparametric entropy estimator, which does not impose any assumption on the probability distributions. We propose a partitional clustering algorithm, named minCEntropy, to concurrently optimize both clustering quality and distinctiveness. minCEntropy requires setting only some rather intuitive parameters, and performs competitively with existing methods for alternative clustering.

#index 1535475
#* A Conscience On-line Learning Approach for Kernel-Based Clustering
#@ Chang-Dong Wang;Jian-Huang Lai;Jun-Yong Zhu
#t 2010
#c 18
#! Kernel-based clustering is one of the most popular methods for partitioning nonlinearly separable dataset. However, exhaustive search for the global optimum is NP-hard. Iterative procedure such as k-means can be used to seek one of the local minima. Unfortunately, it is easily trapped into degenerate local minima when the prototypes of clusters are ill-initialized. In this paper, we restate the optimization problem of kernel-based clustering in an on-line learning framework, whereby a conscience mechanism is easily integrated to tackle the ill-initialization problem and faster convergence rate is achieved. Thus, we propose a novel approach termed conscience on-line learning (COLL). For each randomly taken data point, our method selects the winning prototype based on the conscience mechanism to bias the ill-initialized prototype to avoid degenerate local minima, and efficiently updates the winner by the on-line learning rule. Therefore, it can more efficiently obtain smaller distortion error than k-means with the same initialization. Experimental results on synthetic and large-scale real-world datasets, as well as that in the application of video clustering, have demonstrated the significant improvement over existing kernel clustering methods.

#index 1535476
#* Weighted Feature Subset Non-negative Matrix Factorization and Its Applications to Document Understanding
#@ Dingding Wang;Tao Li;Chris Ding
#t 2010
#c 18
#! Keyword (Feature) selection enhances and improves many Information Retrieval (IR) tasks such as document categorization, automatic topic discovery, etc. The problem of keyword selection is usually solved using supervised algorithms. In this paper, we propose an unsupervised approach that combines keyword selection and document clustering (topic discovery) together. The proposed approach extends non-negative matrix factorization (NMF) by incorporating a weight matrix to indicate the importance of the keywords. The proposed approach is further extended to a weighted version in which each document is also assigned a weight to assess its importance in the cluster. This work considers both theoretical and empirical weighted feature subset selection for NMF and draws the connection between unsupervised feature selection and data clustering. We apply our proposed approaches to various document understanding tasks including document clustering, summarization, and visualization. Experimental results demonstrate the effectiveness of our approach for these tasks.

#index 1535477
#* Compressed Nonnegative Sparse Coding
#@ Fei Wang;Ping Li
#t 2010
#c 18
#! Sparse Coding (SC), which models the data vectors as sparse linear combinations over basis vectors, has been widely applied in machine learning, signal processing and neuroscience. In this paper, we propose a dual random projection method to provide an efficient solution to Nonnegative Sparse Coding (NSC) using small memory. Experiments on real world data demonstrate the effectiveness of the proposed method.

#index 1535478
#* Anonymizing Temporal Data
#@ Ke Wang;Yabo Xu;Raymond Chi-Wing Wong;Ada Wai-Chee Fu
#t 2010
#c 18
#! Temporal data are time-critical in that the snapshot at each timestamp must be made available to researchers in a timely fashion. However, due to the limited data, each snapshot likely has a skewed distribution on sensitive values, which renders classical anonymization methods not possible. In this work, we propose the “reposition model” to allow a record to be published within a close proximity of original timestamp. We show that reposition over a small proximity of timestamp is sufficient for reducing the skewness of a snapshot, therefore, minimizing the impact on window queries. We formalize the optimal reposition problem and present a linear-time solution. The contribution of this work is that it enables classical methods on temporal data.

#index 1535479
#* Homotopy Regularization for Boosting
#@ Zheng Wang;Yangqiu Song;Changshui Zhang
#t 2010
#c 18
#! In this paper, we present a homotopy regularization algorithm for boosting. We introduce a regularization term with adaptive weight into the boosting framework and compose a homotopy objective function. Optimization of this objective approximately composes a solution path for the regularized boosting. Following this path, we can find suitable solution efficiently using early stopping. Experiments show that this adaptive regularization method gives a more efficient parameter selection strategy than regularized boosting and semi supervised boosting algorithms, and significantly improves the performances of traditional AdaBoost and related methods.

#index 1535480
#* What Do People Want in Microblogs? Measuring Interestingness of Hashtags in Twitter
#@ Jianshu Weng;Ee-Peng Lim;Qi He;Cane Wing-Ki Leung
#t 2010
#c 18
#! When micro logging becomes a very popular social media, finding interesting posts from high volume stream of user posts is a challenging research problem. To organize large number of posts, users can assign tags to posts so that these posts can be navigated and searched by tag. In this paper, we focus on modeling the interestingness of hash tags in Twitter, the largest and most active micro logging site. We propose to first construct communities based on both follow links and tagged interactions. We then measure the dispersion and divergence of users and tweets using hash tags among the constructed communities. The interestingness of hash tags are then derived from these community-based dispersion and divergence features. We further introduce a supervised approach to rank hash tags by interestingness. Our experiments on a Twitter dataset show that the proposed approach achieves a fairly good performance.

#index 1535481
#* Probabilistic Inference Protection on Anonymized Data
#@ Raymond Chi-Wing Wong;Ada Wai-Chee Fu;Ke Wang;Yabo Xu;Jian Pei;Philip S. Yu
#t 2010
#c 18
#! Background knowledge is an important factor in privacy preserving data publishing. Probabilistic distribution-based background knowledge is a powerful kind of background knowledge which is easily accessible to adversaries. However, to the best of our knowledge, there is no existing work that can provide a privacy guarantee under adversary attack with such background knowledge. The difficulty of the problem lies in the high complexity of the probability computation and the non-monotone nature of the privacy condition. The only solution known to us relies on approximate algorithms with no known error bound. In this paper, we propose a new bounding condition that overcomes the difficulties of the problem and gives a privacy guarantee. This condition is based on probability deviations in the anonymized data groups, which is much easier to compute and which is a monotone function on the grouping sizes.

#index 1535482
#* Collaborative Learning between Visual Content and Hidden Semantic for Image Retrieval
#@ Jun Wu;Ming-Yu Lu;Chun-Li Wang
#t 2010
#c 18
#! Similarity measure is a critical component in image retrieval systems, and learning similarity measure from the relevance feedback has become a promising way to enhance retrieval performance. Existing approaches mainly focus on learning the visual similarity measure from online feedbacks or constructing the semantic similarity measure depended on historical feedbacks log. However, there is still a big room to elevate the retrieval performance, because few works take the relationship between the visual similarity and the semantic similarity into account. This paper proposes the collaborative learning similarity measure, CoSim, which focuses on the collaborative learning between the visual content of images and the hidden semantic in log. Concretely, the semantic similarity is first learned from log data and serves as prior knowledge. Then, the visual similarity is learned from a mixture of labeled and unlabeled images. In particular, unlabeled images are exploited for the relevant and irrelevant classes in different ways. Finally, the collaborative learning similarity is produced by integrating the visual similarity and the semantic similarity in a nonlinear way. An empirical study shows that the proposed CoSim is significantly more effective than some existing approaches.

#index 1535483
#* Max-Clique: A Top-Down Graph-Based Approach to Frequent Pattern Mining
#@ Yan Xie;Philip S. Yu
#t 2010
#c 18
#! Frequent pattern mining is a fundamental problem in data mining research. We note that almost all state-of-the art algorithms may not be able to mine very long patterns in a large database with a huge set of frequent patterns. In this paper, we point our research to solve this difficult problem from a different perspective: we focus on mining top-k long maximal frequent patterns because long patterns are in general more interesting ones. Different from traditional level-wise mining or tree-growth strategies, our method works in a top-down manner. We pull large maximal cliques from a pattern graph constructed after some fast initial processing, and directly use such large-sized maximal cliques as promising candidates for long frequent patterns. A separate refinement stage is needed to further transform these candidates into true maximal patterns.

#index 1617024
#* Proceedings of the 11th international conference on Advances in data mining: applications and theoretical aspects
#@ Petra Perner
#t 2011
#c 18

#index 1617025
#* Improvements over adaptive local hyperplane to achieve better classification
#@ Hongmin Cai
#t 2011
#c 18
#% 224113
#% 229972
#% 425048
#% 443148
#% 444044
#% 722929
#% 722935
#% 729437
#% 814023
#% 975162
#% 1036164
#% 1083123
#! A new classification model called adaptive local hyperplane (ALH) has been shown to outperform many state-of-the-arts classifiers on benchmark data sets. By representing the data in a local subspace spanned by samples carefully chosen by Fisher's feature weighting scheme, ALH attempts to search for optimal pruning parameters after large number of iterations. However, the feature weight scheme is less accurate in quantifying multi-class problems and samples being rich of redundance. It results in an unreliable selection of prototypes and degrades the classification performance. In this paper, we propose improvement over standard ALH in two aspects. Firstly, we quantify and demonstrate that feature weighting after mutual information is more accurate and robust. Secondly, we propose an economical numerical algorithm to facilitate the matrix inversion, which is a key step in hyperplane construction. The proposed step could greatly low the computational cost and is promising fast applications, such as on-line data mining. Experimental results on both synthetic and real benchmarks data sets have shown that the improvements achieved better performance.

#index 1617026
#* Prognostic models based on linear separability
#@ Leon Bobrowski
#t 2011
#c 18
#% 51647
#% 111349
#% 729437
#% 1168822
#% 1489144
#! Prognostic models are often designed on the basis of learning sets in accordance with multivariate regression methods. Recently, the interval regression and the ranked regression methods have been developed. Both these methods are useful in modeling censored data used in survival analysis. Designing the interval regression models as well as the ranked regression models can be treated similarly as the problem of linear classifier designing and linked to the concept of linear separability used in pattern recognition. The term linear separability refers to the examination of separation of two sets by a hyperplane in a given feature space.

#index 1617027
#* One class classification for anomaly detection: support vector data description revisited
#@ Eric J. Pauwels;Onkar Ambekar
#t 2011
#c 18
#% 302406
#% 304870
#% 722810
#% 791413
#% 985005
#! The Support Vector Data Description (SVDD) has been introduced to address the problem of anomaly (or outlier) detection. It essentially fits the smallest possible sphere around the given data points, allowing some points to be excluded as outliers. Whether or not a point is excluded, is governed by a slack variable. Mathematically, the values for the slack variables are obtained by minimizing a cost function that balances the size of the sphere against the penalty associated with outliers. In this paper we argue that the SVDD slack variables lack a clear geometric meaning, and we therefore re-analyze the cost function to get a better insight into the characteristics of the solution. We also introduce and analyze two new definitions of slack variables and show that one of the proposed methods behaves more robustly with respect to outliers, thus providing tighter bounds compared to SVDD.

#index 1617028
#* How to interpret decision trees?
#@ Petra Perner
#t 2011
#c 18
#% 52824
#% 92537
#% 170393
#% 329539
#% 420093
#% 1046491
#% 1274557
#% 1414233
#! Data mining methods are widely used across many disciplines to identify patterns, rules or associations among huge volumes of data. While in the past mostly black box methods such as neural nets and support vector machines have been heavily used in technical domains, methods that have explanation capability are preferred in medical domains. Nowadays, data mining methods with explanation capability are also used for technical domains after more work on advantages and disadvantages of the methods has been done. Decision tree induction such as C4.5 is the most preferred method since it works well on average regardless of the data set being used. This method can easily learn a decision tree without heavy user interaction while in neural nets a lot of time is spent on training the net. Cross-validation methods can be applied to decision tree induction methods; these methods ensure that the calculated error rate comes close to the true error rate. The error rate and the particular goodness measures described in this paper are quantitative measures that provide help in understanding the quality of the model. The data collection problem with its noise problem has to be considered. Specialized accuracy measures and proper visualization methods help to understand this problem. Since decision tree induction is a supervised method, the associated data labels constitute another problem. Re-labeling should be considered after the model has been learnt. This paper also discusses how to fit the learnt model to the experts knowledge. The problem of comparing two decision trees in accordance with its explanation power is discussed. Finally, we summarize our methodology on interpretation of decision trees.

#index 1617029
#* Comparing classifiers and metaclassifiers
#@ Elio Lozano;Edgar Acuña
#t 2011
#c 18
#% 136350
#% 482502
#% 551721
#% 551723
#% 551745
#% 1001522
#% 1200774
#% 1277523
#% 1347890
#! A metaclassifier is a technique that integrates multiple base classifiers. In this paper a hybrid meta-classifier algorithm based on generative and non-generative methods is proposed. Five well-know strong classifiers are used for the non-generative method and bagging was used for generative method. The performances of the five base classifiers, their ensembles based on bagging, and the proposed hybrid metaclassifier are compared using classification error rates. Eight different datasets coming from the UCI Machine Learning database repository are used in the experiments.

#index 1617030
#* Fast data acquisition in cost-sensitive learning
#@ Victor S. Sheng
#t 2011
#c 18
#% 136350
#% 280437
#% 477640
#% 769875
#% 770791
#% 785413
#% 832575
#% 1250597
#% 1272369
#% 1289281
#% 1673023
#% 1699589
#! Data acquisition is the first and one of the most important steps in many data mining applications. It is a time consuming and costly task. Acquiring an insufficient number of examples makes the learned model and future prediction inaccurate, while acquiring more examples than necessary wastes time and money. Thus it is very important to estimate the number examples needed for learning algorithms in machine learning. However, most previous learning algorithms learn from a given and fixed set of examples. To our knowledge, little previous work in machine learning can dynamically acquire examples as it learns, and decide the ideal number of examples needed. In this paper, we propose a simple on-line framework for fast data acquisition (FDA). FDA is an extrapolation method that estimates the number of examples needed in each acquisition and acquire them simultaneously. Comparing to the naïve step-by-step data acquisition strategy, FDA reduces significantly the number of times of data acquisition and model building. This would significantly reduce the total cost of misclassification, data acquisition arrangement, computation, and examples acquired costs.

#index 1617031
#* Application of a unified medical data miner (UMDM) for prediction, classification, interpretation and visualization on medical datasets: the diabetes dataset case
#@ Nawaz Mohamudally;Dost Muhammad Khan
#t 2011
#c 18
#% 36672
#% 136350
#% 590114
#% 769935
#% 936239
#% 1372824
#% 1372825
#% 1406366
#% 1406367
#% 1406369
#% 1406371
#% 1406372
#% 1406373
#% 1406375
#% 1809518
#! Medical datasets hold huge number of records about the patients, the doctors and the diseases. The extraction of useful information which will provide knowledge in decision making process for the diagnosis and treatment of the diseases are becoming increasingly determinant. Knowledge Discovery and data mining make use of Artificial Intelligence (AI) algorithms which are applied to discover hidden patterns and relations in complex datasets using intelligent agents. The existing data mining algorithms and techniques are designed to solve the individual problems, such as classification or clustering. Up till now, no unifying theory is developed. Among the different algorithms in data mining for prediction, classification, interpretation and visualization, 'k-means clustering', 'Decision Trees (C4.5)', 'Neural Network (NNs)' and 'Data Visualization (2D or 3D scattered graphs)' algorithms are frequently utilized in data mining tools. The choice of the algorithm depends on the intended use of extracted knowledge. In this paper, the mentioned algorithms are unified into a tool, called Unified Medical Data Miner (UMDM) that will enable prediction, classification, interpretation and visualization on a diabetes dataset.

#index 1617032
#* Melanoma diagnosis and classification web center system: the non-invasive diagnosis support subsystem
#@ Wiesław Paja;Mariusz Wrzesień
#t 2011
#c 18
#% 458200
#% 1489145
#! In this paper, computer-aided diagnosing and classification of melanoid skin lesions is briefly described. The main goal of our research was to elaborate and to present new version of the developed melanoma diagnosis support system, available on the Internet. It is a subsystem of our complementary melanoma diagnosis and classification web center system. Here, we present functionality, structure and operation of this subsystem. In its current version, five learning models are implemented to provide five independent results of diagnosis. Then, a specific voting algorithm is applied to select the correct class (concept) of the diagnosed skin lesion. Developed tool enables users to make early, non-invasive diagnosing of melanocytic lesions. It is possible using builtin set of instructions that animate diagnosis of four basic lesions types: benign nevus, blue nevus, suspicious nevus and melanoma malignant.

#index 1617033
#* Characterizing cell types through differentially expressed gene clusters using a model-based approach
#@ Juliane Perner;Elena Zotenko
#t 2011
#c 18
#% 832620
#% 906621
#% 1039129
#% 1041503
#% 1211824
#! Expression profiles of all genes can aid in getting more insight into the biological foundation of observed phenotypes or in identifying marker genes for use in clinical practice. With the invention of highthroughput DNA Microarrays profiling the expression state of cells on a whole-genome scale became feasible. Here, we propose a method based on model-based clustering to detect marker gene clusters that are most important in classifying different cell types. We show at the example of Acute Lymphoblastic Leukemia that these modules capture the expression state of different sample classes and that they give more biological insight into the different cell types than using just marker genes. Additionally, our method suggests groups of genes that can serve as clinical relevant markers.

#index 1617034
#* Experiments with hybridization and optimization of the rules knowledge base for classification of MMPI profiles
#@ Jerzy Gomuła;Wiesław Paja;Krzysztof Pancerz;Teresa Mroczek;Mariusz Wrzesień
#t 2011
#c 18
#% 136350
#% 236752
#% 320536
#% 366687
#% 375421
#% 500530
#% 567416
#% 742990
#% 923811
#% 925584
#% 926881
#% 927966
#% 1136585
#% 1166166
#% 1197048
#% 1399914
#% 1530916
#% 1729772
#! In the paper, we investigate a problem of hybridization and optimization of the knowledge base for the Copernicus system. Copernicus is a tool for computer-aided diagnosis of mental disorders based on personality inventories. Currently, Copernicus is used to analyze and classify patients' profiles obtained from the Minnesota Multiphasic Personality Inventory (MMPI) test. The knowledge base embodied in the Copernicus system consists of, among others, classification functions, classification rule sets as well as nosological category patterns. A special attention is focused on selection of a suitable set of rules classifying new cases. In experiments, rule sets have been generated by different data mining tools and have been optimized by generic operations implemented in the RuleSEEKER system.

#index 1617035
#* Unsupervised classification of hyperspectral images on spherical manifolds
#@ Dalton Lunga;Okan Ersoy
#t 2011
#c 18
#% 329562
#% 557305
#% 643008
#! Traditional statistical models for remote sensing data have mainly focused on the magnitude of feature vectors. To perform clustering with directional properties of feature vectors, other valid models need to be developed. Here we first describe the transformation of hyperspectral images onto a unit hyperspherical manifold using the recently proposed spherical local embedding approach. Spherical local embedding is a method that computes high-dimensional local neighborhood preserving coordinates of data on constant curvature manifolds. We then propose a novel von Mises-Fisher (vMF) distribution based approach for unsupervised classification of hyperspectral images on the established spherical manifold. A vMF distribution is a natural model for multivariate data on a unit hypersphere. Parameters for the model are estimated using the Expectation-Maximization procedure. A set of experimental results on modeling hyperspectral images as vMF mixture distributions demonstrate the advantages.

#index 1617036
#* Recognition of porosity in wood microscopic anatomical images
#@ Shen Pan;Mineichi Kudo
#t 2011
#c 18
#% 136350
#% 999038
#% 1022592
#% 1148739
#% 1301004
#% 1543670
#! The size and configuration of pores are key features for wood identification. In this paper, these features are extracted and then used for construction of a decision tree to recognize three different kinds of pore distributions in wood microscopic images. The contribution of this paper lies in three aspects. Firstly, two different sets of features about pores were proposed and extracted; Secondly, two decision trees were built with those two sets by C4.5 algorithm; Finally, the acceptable recognition results of up to 75.6% were obtained and the possibility to improve was discussed.

#index 1617037
#* Exploratory hierarchical clustering for management zone delineation in precision agriculture
#@ Georg Ruß;Rudolf Kruse
#t 2011
#c 18
#% 248792
#% 296738
#% 421123
#% 443531
#% 560844
#% 566128
#% 657738
#% 715529
#% 949309
#% 958293
#% 1125745
#% 1311568
#% 1486512
#% 1489146
#% 1726655
#! Precision Agriculture has become an emerging topic over the last ten years. It is concerned with the integration of information technology into agricultural processes. This is especially true for the ongoing and growing data collection in agriculture. Novel ground-based sensors, aerial and satellite imagery as well as soil sampling provide large georeferenced data sets with high spatial resolution. However, these data lead to the data mining problem of finding novel and useful information in these data sets. One of the key tasks in the area of precision agriculture is management zone delineation: given a data set of georeferenced data records with high spatial resolution, we would like to discover spatially mostly contiguous zones on the field which exhibit similar characteristics within the zones and different characteristics between zones. From a data mining point of view, this task comes down to a variant of spatial clustering with a constraint of keeping the resulting clusters spatially mostly contiguous. This article presents a novel approach tailored to the specifics of the available data, which do not allow for using an existing algorithm. A variant of hierarchical agglomerative clustering will be presented, in conjunction with a spatial constraint. Results on available multi-variate data sets and subsets will be presented.

#index 1617038
#* High classification rates for continuous cow activity recognition using low-cost GPS positioning sensors and standard machine learning techniques
#@ Torben Godsk;Mikkel Baun Kjærgaard
#t 2011
#c 18
#% 944184
#% 1055696
#% 1201390
#% 1729086
#! In precision livestock farming, spotting cows in need of extra attention due to health or welfare issues are essential, since the time a farmer can devote to each animal is decreasing due to growing herd sizes and increasing efficiency demands. Often, the symptoms of health and welfare state changes, affects the behavior of the individual animal, e.g., changes in time spend on activities like standing, lying, eating or walking. Low-cost and infrastructure-less GPS positioning sensors attached to the animals' collars give the opportunity to monitor the movements of cows and recognize cow activities. By preprocessing the raw cow position data, we obtain high classification rates using standard machine learning techniques to recognize cow activities. Our objectives were to (i) determine to what degree it is possible to robustly recognize cow activities from GPS positioning data, using low-cost GPS receivers; and (ii) determine which types of activities can be classified, and what robustness to expect within the different classes. To provide data for this study low-cost GPS receivers were mounted on 14 dairy cows on grass for a day while they were observed from a distance and their activities manually logged to serve as ground truth. For our dataset we managed to obtain an average classification success rate of 86.2% of the four activities: eating/seeking (90.0%), walking (100%), lying (76.5%), and standing (75.8%) by optimizing both the preprocessing of the raw GPS data and the succeeding feature extraction.

#index 1617039
#* Mining pixel evolutions in satellite image time series for agricultural monitoring
#@ Andreea Julea;Nicolas Méger;Christophe Rigotti;Emmanuel Trouvé;Philippe Bolon;Vasile Lăzărescu
#t 2011
#c 18
#% 248785
#% 316552
#% 329537
#% 459006
#% 463903
#% 464989
#% 477791
#% 478456
#% 479971
#% 660658
#% 798170
#% 844292
#% 907184
#% 949146
#% 975028
#% 976716
#% 1038716
#% 1707794
#! In this paper, we present a technique to help the experts in agricultural monitoring, by mining Satellite Image Time Series over cultivated areas. We use frequent sequential patterns extended to this spatiotemporal context in order to extract sets of connected pixels sharing a similar temporal evolution. We show that a pixel connectivity constraint can be partially pushed to prune the search space, in conjunction with a support threshold. Together with a simple maximality constraint, the method reveals meaningful patterns in real data.

#index 1617040
#* Robust, non-redundant feature selection for yield analysis in semiconductor manufacturing
#@ Eric St. Pierre;Eugene Tuv
#t 2011
#c 18
#% 400847
#% 793239
#% 1385952
#! Thousands of variables are measured in line during the manufacture of central processing units (cpus). Once the manufacturing process is complete, each chip undergoes a series of tests for functionality that determine the yield of the manufacturing process. Traditional statistical methods such as ANOVA have been used for many years to find relationships between end of line yield and in line variables that can be used to sustain and improve process yield. However, a large increase in the number of variables being measured in line due to modern manufacturing trends has overwhelmed the capability of traditional methods. A filter is needed between the tens of thousands of variables in the database and the traditional methods. In this paper, we propose using true multivariate feature selection capable of dealing with complex, mixed typed data sets as an initial step in yield analysis to reduce the number of variables that receive additional investigation using traditional methods. We demonstrate this approach on a historical data set with over 30,000 variables and successfully isolate the cause of a specific yield problem.

#index 1617041
#* Integrated use of ICA and ANN to recognize the mixture control chart patterns in a process
#@ Yuehjen E. Shao;Yini Lin;Ya-Chi Chan
#t 2011
#c 18
#% 1201592
#% 1297250
#% 1581207
#! The quality of a product is important to the success of an enterprise. In process designs, statistical process control (SPC) charts provide a comprehensive and systematic approach to ensure that products meet or exceed customer expectations. The primary function of SPC charts is to identify the assignable causes when the process is out-of-control. The unusual control chart patterns (CCPs) are typically associated with specific assignable causes which affect the operation of a process. Consequently, the effective recognition of CCPs has become a very promising research area. Many studies have assumed that the observed process outputs which need to be recognized are basic or single types of abnormal patterns. However, in most practical applications, the observed process outputs could exhibit mixed patterns which combine two basic types of abnormal patterns in the process. This seriously raises the degree of difficulty in recognizing the basic types of abnormal patterns from a mixture of CCPs. In contrast to typical approaches which applied individually artificial neural network (ANN) or support vector machine (SVM) for the recognition tasks, this study proposes a two-step integrated approach to solve the recognition problem. The proposed approach includes the integration of independent component analysis (ICA) and ANN. The proposed ICA-ANN scheme initially applies ICA to the mixture patterns for generating independent components (ICs). The ICs then serve as the input variables of the ANN model to recognize the CCPs. In this study, different operating modes of the combination of CCPs are investigated and the results prove that the proposed approach could achieve superior recognition capability.

#index 1617042
#* Optimized fuzzy decision tree data mining for engineering applications
#@ Liam Evans;Niels Lohse
#t 2011
#c 18
#% 444865
#% 445338
#% 722357
#% 1277579
#% 1780725
#! Manufacturing organizations are striving to remain competitive in an era of increased competition and every-changing conditions. Manufacturing technology selection is a key factor in the growth of an organization and a fundamental challenge is effectively managing the computation of data to support future decision-making. Classification is a data mining technique used to predict group membership for data instances. Popular methods include decision trees and neural networks. This paper investigates a unique fuzzy reasoning method suited to engineering applications using fuzzy decision trees. The paper focuses on the inference stages of fuzzy decision trees to support decision-engineering tasks. The relaxation of crisp decision tree boundaries through fuzzy principles increases the importance of the degree of confidence exhibited by the inference mechanism. Industrial philosophies have a strong influence on decision practices and such strategic views must be considered. The paper is organized as follows: introduction to the research area, literature review, proposed inference mechanism and numerical example. The research is concluded and future work discussed.

#index 1617043
#* Graph-based data warehousing using the core-facets model
#@ Dung N. Lam;Alexander Y. Liu;Cheryl E. Martin
#t 2011
#c 18
#% 393530
#% 393641
#% 818916
#% 1019118
#% 1083699
#% 1176876
#% 1318636
#% 1372657
#% 1451221
#% 1661196
#% 1673591
#! There are a growing number of data-mining techniques that model and analyze data in the form of graphs. Graphs can link otherwise disparate data to form a holistic view of the dataset. Unfortunately, it can be challenging to manage the resulting large graph and use it during data analysis. To facilitate managing and operating on graphs, the Core-Facets model offers a framework for graph-based data warehousing. The Core-Facets model builds a heterogeneous attributed core graph from multiple data sources and creates facet graphs for desired analyses. Facet graphs can transform the heterogeneous core graph into various purpose-specific homogeneous graphs, thereby enabling the use of traditional graph analysis techniques. The Core-Facets model also supports new opportunities for multi-view data mining. This paper discusses an implementation of the Core-Facets model, which provides a data warehousing framework for tasks ranging from data collection to graph modeling to graph preparation for analysis.

#index 1617044
#* General sales forecast models for automobile markets based on time series analysis and data mining techniques
#@ Marco Hülsmann;Detlef Borscheid;Christoph M. Friedrich;Dirk Reith
#t 2011
#c 18
#% 190581
#% 400847
#% 403980
#% 404849
#% 928355
#% 1252962
#! In this paper, various enhanced sales forecast methodologies and models for the automobile market are presented. The methods used deliver highly accurate predictions while maintaining the ability to explain the underlying model at the same time. The representation of the economic training data is discussed, as well as its effects on the newly registered automobiles to be predicted. The methodology mainly consists of time series analysis and classical Data Mining algorithms, whereas the data is composed of absolute and/or relative market-specific exogenous parameters on a yearly, quarterly, or monthly base. It can be concluded that the monthly forecasts were especially improved by this enhanced methodology using absolute, normalized exogenous parameters. Decision Trees are considered as the most suitable method in this case, being both accurate and explicable. The German and the US-American automobile market are presented for the evaluation of the forecast models.

#index 1617045
#* Towards a spatial instance learning method for deep web pages
#@ Ermelinda Oro;Massimo Ruffolo
#t 2011
#c 18
#% 275915
#% 331772
#% 431536
#% 480648
#% 480824
#% 729978
#% 801668
#% 805845
#% 805846
#% 807333
#% 837605
#% 838491
#% 902460
#% 1328069
#% 1364949
#% 1394469
#% 1523976
#! A large part of information available on the Web is hidden to conventional research engines because Web pages containing such information are dynamically generated as answers to query submitted by search form filled in by keywords. Such pages are referred as Deep Web pages and contain huge amount of relevant information for different application domain. For these reasons there is a constant high interest in efficiently extracting data from Deep Web data sources. In this paper we present a spatial instance learning method from Deep Web pages that exploits both the spatial arrangement and the visual features of data records and data items/fields produced by layout engines of web browsers. The proposed method is independent from the DeepWeb pages encoding and from the presentation layout of data records. Furthermore, it allows for recognizing data records in Deep Web pages having multiple data regions. In the paper the effectiveness of the proposed method is proven by experiments carried out on a dataset of 100 Web pages randomly selected from most known Deep Web sites. Results obtained by using the proposed method show that the method has a very high precision and recall and that system works much better than MDR and ViNTS approaches applied to the same dataset.

#index 1617046
#* Applying user signatures on fraud detection in telecommunications networks
#@ João Lopes;Orlando Belo;Carlos Vieira
#t 2011
#c 18
#% 310488
#% 420123
#% 644438
#% 1727245
#! Fraud in telecommunications is increasing dramatically with the expansion of modern technology, resulting in the loss of billions of dollars worldwide each year. Although prevention technologies are the best way to reduce fraud,. Fraudsters are adaptive, searching systematically for new ways to commit fraud and, in most of the cases, will usually find some way to circumvent companies prevention measures. In this paper we expose some of the ways in which fraud is being used against organizations, evaluating the limitations of existing strategies and methods to detect and prevent it in todays telecommunications companies. Additionally, we expose a data mining profiling technique based on signatures that was developed for a real mobile telecommunications network operator and integrated into one of its Fraud Management Systems (FMS), currently under operation.

#index 1617047
#* Methods in case-based classification in bioinformatics: lessons learned
#@ Isabelle Bichindaritz
#t 2011
#c 18
#% 761273
#% 783442
#% 833786
#% 926881
#% 928386
#% 961134
#% 1417842
#% 1486381
#! Bioinformatics datasets are often used to compare classification algorithms for highly dimensional data. Since genetic data are becoming more and more routinely used in medical settings, researchers and life scientists alike are interested in answering such questions as finding the gene signature of a disease, classifying data for diagnosis, or evaluating the severity of a disease. Since many different types of algorithms have been applied to this domain, often with comparable, although slightly different, results, it may be cumbersome to determine which one to use and how to make this determination. Therefore this paper proposes to study, on some of the most benchmarked datasets in bioinformatics, the performance of K-nearest-neighbor and related case-based classification algorithms in order to make methodological recommendations for applying these algorithms to this domain. In conclusion, K-nearest-neighbor classifiers perform as or among the best in combination with feature selection methods.

#index 1617048
#* Prediction of batch-end quality for an industrial polymerization process
#@ Geert Gins;Bert Pluymers;Ilse Y. Smets;Jairo Espinosa;Jan F. M. Van Impe
#t 2011
#c 18
#! In this paper, an inferential sensor for the final viscosity of an industrial batch polymerization reaction is developed using multivariate statistical methods. This inferential sensor tackles one of the main problems of chemical batch processes: the lack of reliable online quality estimates. In a data preprocessing step, all batches are brought to equal lengths and significant batch events are aligned via dynamic time warping. Next, the optimal input measurements and optimal model order of the inferential multiway partial least squares (MPLS) model are selected. Finally, a full batch model is trained and successfully validated. Additionally, intermediate models capable of predicting the final product quality after only 50% or 75% batch progress are developed. All models provide accurate estimates of the final polymer viscosity.

#index 1687992
#* Proceedings of the 2011 IEEE 11th International Conference on Data Mining
#@ 
#t 2011
#c 18

#index 1688415
#* Mining Dominant Patterns in the Sky
#@ Arnaud Soulet;Chedy Raïssi;Marc Plantevit;Bruno Cremilleux
#t 2011
#c 18
#! Pattern discovery is at the core of numerous data mining tasks. Although many methods focus on efficiency in pattern mining, they still suffer from the problem of choosing a threshold that influences the final extraction result. The goal of our study is to make the results of pattern mining useful from a user-preference point of view. To this end, we integrate into the pattern discovery process the idea of skyline queries in order to mine skyline patterns in a threshold-free manner. Because the skyline patterns satisfy a formal property of dominations, they not only have a global interest but also have semantics that are easily understood by the user. In this work, we first establish theoretical relationships between pattern condensed representations and skyline pattern mining. We also show that it is possible to compute automatically a subset of measures involved in the user query which allows the patterns to be condensed and thus facilitates the computation of the skyline patterns. This forms the basis for a novel approach to mining skyline patterns. We illustrate the efficiency of our approach over several data sets including a use case from chemo informatics and show that small sets of dominant patterns are produced under various measures.

#index 1688416
#* Interesting Multi-relational Patterns
#@ Eirini Spyropoulou;Tijl De Bie
#t 2011
#c 18
#! Mining patterns from multi-relational data is a problem attracting increasing interest within the data mining community. Traditional data mining approaches are typically developed for highly simplified types of data, such as an attribute-value table or a binary database, such that those methods are not directly applicable to multi-relational data. Nevertheless, multi-relational data is a more truthful and therefore often also a more powerful representation of reality. Mining patterns of a suitably expressive syntax directly from this representation, is thus a research problem of great importance. In this paper we introduce a novel approach to mining patterns in multi-relational data. We propose a new syntax for multi-relational patterns as complete connected sub graphs in a representation of the database as a k-partite graph. We show how this pattern syntax is generally applicable to multirelational data, while it reduces to well-known tiles [7] when the data is a simple binary or attribute-value table. We propose RMiner, an efficient algorithm to mine such patterns, and we introduce a method for quantifying their interestingness when contrasted with prior information of the data miner. Finally, we illustrate the usefulness of our approach by discussing results on real-world and synthetic databases.

#index 1688417
#* On Generating All Optimal Monotone Classifications
#@ Luite Stegeman;Ad Feelders
#t 2011
#c 18
#! In many applications of data mining one knows beforehand that the response variable should be monotone (either increasing or decreasing) in the attributes. In ordinal classification, changing the class labels of a data set (relabeling) so that the data becomes monotone, is useful for at least two reasons. Firstly, models trained on relabeled data tend to have better predictive performance than models trained on the original data. Secondly, relabeling is an important building block for the construction of monotone classifiers. However, optimal monotone relabelings are rarely unique, and so far an efficient algorithm to generate them all has been lacking. The main result of this paper is an efficient algorithm to produce the structure of all optimal monotone relabelings. We also show that counting the solutions is #P-complete and give algorithms for efficiently enumerating all solutions, as well as sampling uniformly from the set of solutions. Experiments show that relabeling non-monotone data can improve the predictive performance of models trained on that data.

#index 1688418
#* Recursive Multi-step Time Series Forecasting by Perturbing Data
#@ Souhaib Ben Taieb;Gianluca Bontempi
#t 2011
#c 18
#! The Recursive strategy is the oldest and most intuitive strategy to forecast a time series multiple steps ahead. At the same time, it is well-known that this strategy suffers from the accumulation of errors as long as the forecasting horizon increases. We propose a variant of the Recursive strategy, called RECNOISY, which perturbs the initial dataset at each step of the forecasting process in order to i) handle more properly the estimated values at each forecasting step and ii) decrease the accumulation of errors induced by the Recursive strategy. In addition to the RECNOISY strategy, we propose another strategy, called HYBRID, which for each horizon selects the most accurate approach among the REC and the RECNOISY strategies according to the estimated accuracy. In order to assess the effectiveness of the proposed strategies, we carry out an experimental session based on the 111 times series of the NN5 forecasting competition. Accuracy results are presented together with a paired comparison over the horizons and the time series. The preliminary results show that our proposed approaches are promising in terms of forecasting performance.

#index 1688419
#* Finding Robust Itemsets under Subsampling
#@ Nikolaj Tatti;Fabian Moerchen
#t 2011
#c 18
#! Mining frequent patterns is plagued by the problem of pattern explosion making pattern reduction techniques a key challenge in pattern mining. In this paper we propose a novel theoretical framework for pattern reduction. We do this by measuring the robustness of a property of an item set such as closed ness or non-derivability. The robustness of a property is the probability that this property holds on random subsets of the original data. We study four properties: closed, free, non-derivable and totally shattered item sets, demonstrating how we can compute the robustness analytically without actually sampling the data. Our concept of robustness has many advantages: Unlike statistical approaches for reducing patterns, we do not assume a null hypothesis or any noise model and the patterns reported are simply a subset of all patterns with this property as opposed to approximate patterns for which the property does not really hold. If the underlying property is monotonic, then the measure is also monotonic, allowing us to efficiently mine robust item sets. We further derive a parameter-free technique for ranking item sets that can be used for top-k approaches. Our experiments demonstrate that we can successfully use the robustness measure to reduce the number of patterns and that ranking yields interesting itemsets.

#index 1688420
#* Density Estimation Based on Mass
#@ Kai Ming Ting;Takashi Washio;Jonathan R. Wells;Fei Tony Liu
#t 2011
#c 18
#! Density estimation is the ubiquitous base modelling mechanism employed for many tasks such as clustering, classification, anomaly detection and information retrieval. Commonly used density estimation methods such as kernel density estimator and k-nearest neighbour density estimator have high time and space complexities which render them inapplicable in problems with large data size and even a moderate number of dimensions. This weakness sets the fundamental limit in existing algorithms for all these tasks. We propose the first density estimation method which stretches this fundamental limit to an extent that dealing with millions of data can now be done easily and quickly. We analyze the error of the new estimation (from the true density) using a bias-variance analysis. We then perform an empirical evaluation of the proposed method by replacing existing density estimators with the new one in two current density-based algorithms, namely, DBSCAN and LOF. The results show that the new density estimation method significantly improves the runtime of DBSCAN and LOF, while maintaining or improving their task-specific performances in clustering and anomaly detection, respectively. The new method empowers these algorithms, currently limited to small data size only, to process very large databases â聙" setting a new benchmark for what density-based algorithms can achieve.

#index 1688421
#* Diverse Dimension Decomposition of an Itemset Space
#@ Mikalai Tsytsarau;Francesco Bonchi;Aristides Gionis;Themis Palpanas
#t 2011
#c 18
#! We introduce the problem of diverse dimension decomposition in transactional databases. A dimension is a set of mutually-exclusive item sets, and our problem is to find a decomposition of the item set space into dimensions, which are orthogonal to each other, and that provide high coverage of the input database. The mining framework we propose effectively represents a dimensionality-reducing transformation from the space of all items to the space of orthogonal dimensions. Our approach relies on information-theoretic concepts, and we are able to formulate the dimension-finding problem with a single objective function that simultaneously captures constraints on coverage, exclusivity and orthogonality. We describe an efficient greedy method for finding diverse dimensions from transactional databases. The experimental evaluation of the proposed approach using two real datasets, flickr and delicious, demonstrates the effectiveness of our solution. Although we are motivated by the applications in the collaborative tagging domain, we believe that the mining task we introduce in this paper is general enough to be useful in other application domains.

#index 1688422
#* Conditional Anomaly Detection with Soft Harmonic Functions
#@ Michal Valko;Branislav Kveton;Hamed Valizadegan;Gregory F. Cooper;Milos Hauskrecht
#t 2011
#c 18
#! In this paper, we consider the problem of conditional anomaly detection that aims to identify data instances with an unusual response or a class label. We develop a new non-parametric approach for conditional anomaly detection based on the soft harmonic solution, with which we estimate the confidence of the label to detect anomalous mislabeling. We further regularize the solution to avoid the detection of isolated examples and examples on the boundary of the distribution support. We demonstrate the efficacy of the proposed method on several synthetic and UCI ML datasets in detecting unusual labels when compared to several baseline approaches. We also evaluate the performance of our method on a real-world electronic health record dataset where we seek to identify unusual patient-management decisions.

#index 1688423
#* Random Forest Based Feature Induction
#@ Celine Vens;Fabrizio Costa
#t 2011
#c 18
#! We propose a simple yet effective strategy to induce a task dependent feature representation using ensembles of random decision trees. The new feature mapping is efficient in space and time, and provides a metric transformation that is non parametric and not implicit in nature (i.e. not expressed via a kernel matrix), nor limited to the transductive setup. The main advantage of the proposed mapping lies in its flexibility to adapt to several types of learning tasks ranging from regression to multi-label classification, and to deal in a natural way with missing values. Finally, we provide an extensive empirical study of the properties of the learned feature representation over real and artificial datasets.

#index 1688424
#* Class Imbalance, Redux
#@ Byron C. Wallace;Kevin Small;Carla E. Brodley;Thomas A. Trikalinos
#t 2011
#c 18
#! Class imbalance (i.e., scenarios in which classes are unequally represented in the training data) occurs in many real-world learning tasks. Yet despite its practical importance, there is no established theory of class imbalance, and existing methods for handling it are therefore not well motivated. In this work, we approach the problem of imbalance from a probabilistic perspective, and from this vantage identify dataset characteristics (such as dimensionality, sparsity, etc.) that exacerbate the problem. Motivated by this theory, we advocate the approach of bagging an ensemble of classifiers induced over balanced bootstrap training samples, arguing that this strategy will often succeed where others fail. Thus in addition to providing a theoretical understanding of class imbalance, corroborated by our experiments on both simulated and real datasets, we provide practical guidance for the data mining practitioner working with imbalanced data.

#index 1688425
#* Combining Feature Context and Spatial Context for Image Pattern Discovery
#@ Hongxing Wang;Junsong Yuan;Yap-Peng Tan
#t 2011
#c 18
#! Once an image is decomposed into a number of visual primitives, e.g., local interest points or salient image regions, it is of great interests to discover meaningful visual patterns from them. Conventional clustering (e.g., k-means) of visual primitives, however, usually ignores the spatial dependency among them, thus cannot discover the high-level visual patterns of complex spatial structure. To overcome this problem, we propose to consider both spatial and feature contexts among visual primitives for pattern discovery. By discovering both spatial co-occurrence patterns among visual primitives and feature co-occurrence patterns among different types of features, our method can better handle the ambiguities of visual primitives, by leveraging these co-occurrences. We formulate the problem as a regularized k-means clustering, and propose an iterative bottom-up/top-down self-learning procedure to gradually refine the result until it converges. The experiments of image text on discovery and image region clustering convince that combining spatial and feature contexts can significantly improve the pattern discovery results.

#index 1688426
#* Algorithms for Mining the Evolution of Conserved Relational States in Dynamic Networks
#@ Rezwan Ahmed;George Karypis
#t 2011
#c 18
#! Dynamic networks have recently being recognized as a powerful abstraction to model and represent the temporal changes and dynamic aspects of the data underlying many complex systems. Significant insights regarding the stable relational patterns among the entities can be gained by analyzing temporal evolution of the complex entity relations. This can help identify the transitions from one conserved state to the next and may provide evidence to the existence of external factors that are responsible for changing the stable relational patterns in these networks. This paper presents a new data mining method that analyzes the time-persistent relations or states between the entities of the dynamic networks and captures all maximal non-redundant evolution paths of the stable relational states. Experimental results based on multiple datasets from real world applications show that the method is efficient and scalable.

#index 1688427
#* Infrastructure Pattern Discovery in Configuration Management Databases via Large Sparse Graph Mining
#@ Pranay Anchuri;Mohammed J. Zaki;Omer Barkol;Ruth Bergman;Yifat Felder;Shahar Golan;Arik Sityon
#t 2011
#c 18
#! A configuration management database (CMDB) can be considered to be a large graph representing the IT infrastructure entities and their inter-relationships. Mining such graphs is challenging because they are large, complex, and multi-attributed, and have many repeated labels. These characteristics pose challenges for graph mining algorithms, due to the increased cost of sub graph isomorphism (for support counting), and graph isomorphism (for eliminating duplicate patterns). The notion of pattern frequency or support is also more challenging in a single graph, since it has to be defined in terms of the number of its (potentially, exponentially many) embeddings. We present CMDB-Miner, a novel two-step method for mining infrastructure patterns from CMDB graphs. It first samples the set of maximal frequent patterns, and then clusters them to extract the representative infrastructure patterns. We demonstrate the effectiveness of CMDB-Miner on real-world CMDB graphs.

#index 1688428
#* Nonnegative Matrix Tri-factorization Based High-Order Co-clustering and Its Fast Implementation
#@ Hua Wang;Feiping Nie;Heng Huang;Chris Ding
#t 2011
#c 18
#! The fast growth of Internet and modern technologies has brought data involving objects of multiple types that are related to each other, called as Multi-Type Relational data. Traditional clustering methods for single-type data rarely work well on them, which calls for new clustering techniques, called as high-order co-clustering (HOCC), to deal with the multiple types of data at the same time. A major challenge in developing HOCC methods is how to effectively make use of all available information contained in a multi-type relational data set, including both inter-type and intra-type relationships. Meanwhile, because many real world data sets are often of large sizes, clustering methods with computationally efficient solution algorithms are of great practical interest. In this paper, we first present a general HOCC framework, named as Orthogonal Nonnegative Matrix Tri-factorization (O-NMTF), for simultaneous clustering of multi-type relational data. The proposed O-NMTF approach employs Nonnegative Matrix Tri-Factorization (NMTF) to simultaneously cluster different types of data using the inter-type relationships, and incorporate intra-type information through manifold regularization, where, different from existing works, we emphasize the importance of the orthogonal ties of the factor matrices of NMTF. Based on O-NMTF, we further develop a novel Fast Nonnegative Matrix Tri-Factorization (F-NMTF) approach to deal with large-scale data. Instead of constraining the factor matrices of NMTF to be nonnegative as in existing methods, F-NMTF constrains them to be cluster indicator matrices, a special type of nonnegative matrices. As a result, the optimization problem of the proposed method can be decoupled, which results in sub problems of much smaller sizes requiring much less matrix multiplications, such that our new algorithm scales well to real world data of large sizes. Extensive experimental evaluations have demonstrated the effectiveness of our new approaches.

#index 1688429
#* Detecting Community Kernels in Large Social Networks
#@ Liaoruo Wang;Tiancheng Lou;Jie Tang;John E. Hopcroft
#t 2011
#c 18
#! In many social networks, there exist two types of users that exhibit different influence and different behavior. For instance, statistics have shown that less than 1% of the Twitter users (e.g. entertainers, politicians, writers) produce 50% of its content, while the others (e.g. fans, followers, readers) have much less influence and completely different social behavior. In this paper, we define and explore a novel problem called community kernel detection in order to uncover the hidden community structure in large social networks. We discover that influential users pay closer attention to those who are more similar to them, which leads to a natural partition into different community kernels. We propose Greedy and We BA, two efficient algorithms for finding community kernels in large social networks. Greedy is based on maximum cardinality search, while We BA formalizes the problem in an optimization framework. We conduct experiments on three large social networks: Twitter, Wikipedia, and Coauthor, which show that We BA achieves an average 15%-50% performance improvement over the other state-of-the-art algorithms, and We BA is on average 6-2,000 times faster in detecting community kernels.

#index 1688430
#* ADANA: Active Name Disambiguation
#@ Xuezhi Wang;Jie Tang;Hong Cheng;Philip S. Yu
#t 2011
#c 18
#! Name ambiguity has long been viewed as a challenging problem in many applications, such as scientific literature management, people search, and social network analysis. When we search a person name in these systems, many documents (e.g., papers, web pages) containing that person's name may be returned. It is hard to determine which documents are about the person we care about. Although much research has been conducted, the problem remains largely unsolved, especially with the rapid growth of the people information available on the Web. In this paper, we try to study this problem from a new perspective and propose an ADANA method for disambiguating person names via active user interactions. In ADANA, we first introduce a pairwise factor graph (PFG) model for person name disambiguation. The model is flexible and can be easily extended by incorporating various features. Based on the PFG model, we propose an active name disambiguation algorithm, aiming to improve the disambiguation performance by maximizing the utility of the user's correction. Experimental results on three different genres of data sets show that with only a few user corrections, the error rate of name disambiguation can be reduced to 3.1%. A real system has been developed based on the proposed method and is available online.

#index 1688431
#* Document Clustering via Matrix Representation
#@ Xufei Wang;Jiliang Tang;Huan Liu
#t 2011
#c 18
#! Vector Space Model (VSM) is widely used to represent documents and web pages. It is simple and easy to deal computationally, but it also oversimplifies a document into a vector, susceptible to noise, and cannot explicitly represent underlying topics of a document. A matrix representation of document is proposed in this paper: rows represent distinct terms and columns represent cohesive segments. The matrix model views a document as a set of segments, and each segment is a probability distribution over a limited number of latent topics which can be mapped to clustering structures. The latent topic extraction based on the matrix representation of documents is formulated as a constraint optimization problem in which each matrix (i.e., a document) A_i is factorized into a common base determined by non-negative matrices L and R^\top, and a non-negative weight matrix M_i such that the sum of reconstruction error on all documents is minimized. Empirical evaluation demonstrates that it is feasible to use the matrix model for document clustering: (1) compared with vector representation, using matrix representation improves clustering quality consistently, and the proposed approach achieves a relative accuracy improvement up to 66\% on the studied datasets, and (2) the proposed method outperforms baseline methods such as k-means and NMF, and complements the state-of-the-art methods like LDA and PLSI. Furthermore, the proposed matrix model allows more refined information retrieval at a segment level instead of at a document level, which enables the return of more relevant documents in information retrieval tasks.

#index 1688432
#* Role-Behavior Analysis from Trajectory Data by Cross-Domain Learning
#@ Shin Ando;Einoshin Suzuki
#t 2011
#c 18
#! Behavior analysis using trajectory data presents a practical and interesting challenge for KDD. Conventional analyses address discriminative tasks of behaviors, e.g., classification and clustering typically using the subsequences extracted from the trajectory of an object as a numerical feature representation. In this paper, we explore further to identify the difference in the high-level semantics of behaviors such as roles and address the task in a cross-domain learning approach. The trajectory, from which the features are sampled, is intuitively viewed as a domain, and we assume that its intrinsic structure is characterized by the underlying role associated with the tracked object. We propose a novel hybrid method of spectral clustering and density approximation for comparing clustering structures of two independently sampled trajectory data and identifying patterns of behaviors unique to a role. We present empirical evaluations of the proposed method in two practical settings using real-world robotic trajectories.

#index 1688433
#* Semi-supervised Feature Importance Evaluation with Ensemble Learning
#@ Hasna Barkia;Haytham Elghazel;Alex Aussem
#t 2011
#c 18
#! We consider the problem of using a large amount of unlabeled data to improve the efficiency of feature selection in high dimensional datasets, when only a small set of labeled examples is available. We propose a new semi-supervised feature importance evaluation method (SSFI for short), that combines ideas from co-training and random forests with a new permutation-based out-of-bag feature importance measure. We provide empirical results on several benchmark datasets indicating that SSFI can lead to significant improvement over state-of-the-art semi-supervised and supervised algorithms.

#index 1688434
#* COMET: A Recipe for Learning and Using Large Ensembles on Massive Data
#@ Justin D. Basilico;M. Arthur Munson;Tamara G. Kolda;Kevin R. Dixon;W. Philip Kegelmeyer
#t 2011
#c 18
#! COMET is a single-pass MapReduce algorithm for learning on large-scale data. It builds multiple random forest ensembles on distributed blocks of data and merges them into a mega-ensemble. This approach is appropriate when learning from massive-scale data that is too large to fit on a single machine. To get the best accuracy, IVoting should be used instead of bagging to generate the training subset for each decision tree in the random forest. Experiments with two large datasets (5GB and 50GB compressed) show that COMET compares favorably (in both accuracy and training time) to learning on a sub sample of data using a serial algorithm. Finally, we propose a new Gaussian approach for lazy ensemble evaluation which dynamically decides how many ensemble members to evaluate per data point, this can reduce evaluation cost by 100X or more.

#index 1688435
#* Overlapping Correlation Clustering
#@ Francesco Bonchi;Aristides Gionis;Antti Ukkonen
#t 2011
#c 18
#! We introduce a new approach to the problem of overlapping clustering. The main idea is to formulate overlapping clustering as an optimization problem in which each data point is mapped to a small set of labels, representing membership to different clusters. The objective is to find a mapping so that the distances between data points agree as much as possible with distances taken over their label sets. To define distances between label sets, we consider two measures: a set-intersection indicator function and the Jaccard coefficient. To solve the main optimization problem we propose a local-search algorithm. The iterative step of our algorithm requires solving non-trivial optimization sub problems, which, for the measures of set-intersection and Jaccard, we solve using a greedy method and non-negative least squares, respectively. Since our frameworks uses pair wise similarities of objects as the input, it lends itself naturally to the task of clustering structured objects for which feature vectors can be difficult to obtain. As a proof of concept we show how easily our framework can be applied in two different complex application domains. Firstly, we develop overlapping clustering of animal trajectories, obtaining zoologically meaningful results. Secondly, we apply our framework for overlapping clustering of proteins based on pair wise similarities of amino acid sequences, outperforming the of state-of-the-art method in matching a ground truth taxonomy.

#index 1688436
#* Learning with Minimum Supervision: A General Framework for Transductive Transfer Learning
#@ Mohammad Taha Bahadori;Yan Liu;Dan Zhang
#t 2011
#c 18
#! Transductive transfer learning is one special type of transfer learning problem, in which abundant labeled examples are available in the source domain and only \textit{unlabeled} examples are available in the target domain. It easily finds applications in spam filtering, microblogging mining and so on. In this paper, we propose a general framework to solve the problem by mapping the input features in both the source domain and target domain into a shared latent space and simultaneously minimizing the feature reconstruction loss and prediction loss. We develop one specific example of the framework, namely latent large-margin transductive transfer learning (LATTL) algorithm, and analyze its theoretic bound of classification loss via Rademacher complexity. We also provide a unified view of several popular transfer learning algorithms under our framework. Experiment results on one synthetic dataset and three application datasets demonstrate the advantages of the proposed algorithm over the other state-of-the-art ones.

#index 1688437
#* Efficiently Mining Unordered Trees
#@ Mostafa Haghir Chehreghani
#t 2011
#c 18
#! Frequent tree patterns have many applications in different domains such as XML document mining, user web log analysis, network routing and bioinformatics. In this paper, we first introduce three new tree encodings and accordingly present an efficient algorithm for finding frequent patterns from rooted unordered trees with the assumption that children of every node in database trees are identically labeled. Then, we generalize the method and propose the UITree algorithm to find frequent patterns from rooted unordered trees without any restriction. Compared to other algorithms in the literature, UItree manages occurrences of a candidate tree in database trees more efficiently. Our extensive experiments on both real and synthetic datasets show that UITree significantly outperforms the most efficient existing works on mining unordered trees.

#index 1688438
#* Using Bayesian Network Learning Algorithm to Discover Causal Relations in Multivariate Time Series
#@ Zhenxing Wang;Laiwan Chan
#t 2011
#c 18
#! Many applications naturally involve time series data, and the vector auto regression (VAR) and the structural VAR (SVAR) are dominant tools to investigate relations between variables in time series. In the first part of this work, we show that the SVAR method is incapable of identifying contemporaneous causal relations when data follow Gaussian distributions. In addition, least squares estimators become unreliable when the scales of the problems are large and observations are limited. In the remaining part, we propose an approach to apply Bayesian network learning algorithms to identify SVARs from time series data in order to capture both temporal and contemporaneous causal relations and avoid high-order statistical tests. The difficulty of applying Bayesian network learning algorithms to time series is that the sizes of the networks corresponding to time series tend to be large and high-order statistical tests are required by Bayesian network learning algorithms in this case. To overcome the difficulty, we show that the search space of conditioning sets d-separating two vertices should be subsets of Markov blankets. Based on this fact, we propose an algorithm learning Bayesian networks locally and making the largest order of statistical tests independent of the scales of the problems. Empirical results show that our algorithm outperforms existing methods in terms of both efficiency and accuracy.

#index 1688439
#* Efficient Mining of a Concise and Lossless Representation of High Utility Itemsets
#@ Cheng Wei Wu;Philippe Fournier-Viger;Philip S. Yu;Vincent S. Tseng
#t 2011
#c 18
#! Mining high utility item sets from transactional databases is an important data mining task, which refers to the discovery of item sets with high utilities (e.g. high profits). Although several studies have been carried out, current methods may present too many high utility item sets for users, which degrades the performance of the mining task in terms of execution and memory efficiency. To achieve high efficiency for the mining task and provide a concise mining result to users, we propose a novel framework in this paper for mining closed+ high utility item sets, which serves as a compact and loss less representation of high utility item sets. We present an efficient algorithm called CHUD (Closed+ High Utility item set Discovery) for mining closed+ high utility item sets. Further, a method called DAHU (Derive All High Utility item sets) is proposed to recover all high utility item sets from the set of closed+ high utility item sets without accessing the original database. Results of experiments on real and synthetic datasets show that CHUD and DAHU are very efficient with a massive reduction (up to 800 times in our experiments) in the number of high utility item sets. In addition, when all high utility item sets are recovered by DAHU, the approach combining CHUD and DAHU also outperforms the state-of-the-art algorithms in mining high utility item sets.

#index 1688440
#* Understanding Propagation Error and Its Effect on Collective Classification
#@ Rongjing Xiang;Jennifer Neville
#t 2011
#c 18
#! Recent empirical evaluation has shown that the performance of collective classification models can vary based on the amount of class label information available for use during inference. In this paper, we further demonstrate that the relative performance of statistical relational models learned with different estimation methods changes as the availability of test set labels increases. We reason about the cause of this phenomenon from an information-theoretic perspective and this points to a previously unidentified consideration in the development of relational learning algorithms. In particular, we characterize the high propagation error of collective inference models that are estimated with maximum pseudolikelihood estimation (MPLE), and show how this affects performance across the spectrum of label availability when compared to MLE, which has low propagation error. Our formal study leads to a quantitative characterization that can be used to predict the confidence of local propagation for MPLE models. We use this to propose a mixture model that can learn the best trade-off between high and low propagation models. Empirical evaluation on synthetic and real-world data show that our proposed method achieves comparable, or superior, results to both MPLE and low propagation models across the full spectrum of label availability.

#index 1688441
#* Direct Robust Matrix Factorizatoin for Anomaly Detection
#@ Liang Xiong;Xi Chen;Jeff Schneider
#t 2011
#c 18
#! Matrix factorization methods are extremely useful in many data mining tasks, yet their performances are often degraded by outliers. In this paper, we propose a novel robust matrix factorization algorithm that is insensitive to outliers. We directly formulate robust factorization as a matrix approximation problem with constraints on the rank of the matrix and the cardinality of the outlier set. Then, unlike existing methods that resort to convex relaxations, we solve this problem directly and efficiently. In addition, structural knowledge about the outliers can be incorporated to find outliers more effectively. We applied this method in anomaly detection tasks on various data sets. Empirical results show that this new algorithm is effective in robust modeling and anomaly detection, and our direct solution achieves superior performance over the state-of-the-art methods based on the L1-norm and the nuclear norm of matrices.

#index 1688442
#* A New Markov Model for Clustering Categorical Sequences
#@ Tengke Xiong;Shengrui Wang;Qingshan Jiang;Joshua Zhexue Huang
#t 2011
#c 18
#! Clustering categorical sequences remains an open and challenging task due to the lack of an inherently meaningful measure of pair wise similarity between sequences. Model initialization is an unsolved problem in model-based clustering algorithms for categorical sequences. In this paper, we propose a simple and effective Markov model to approximate the conditional probability distribution (CPD) model, and use it to design a novel two-tier Markov model to represent a sequence cluster. Furthermore, we design a novel divisive hierarchical algorithm for clustering categorical sequences based on the two-tier Markov model. The experimental results on the data sets from three different domains demonstrate the promising performance of our models and clustering algorithm.

#index 1688443
#* Confidence in Predictions from Random Tree Ensembles
#@ Siddhartha Bhattacharyya
#t 2011
#c 18
#! Obtaining an indication of confidence of predictions is desirable for many data mining applications. Such confidence levels, together with the predicted value, can inform on the certainty or extent of reliability that may be associated with the prediction. This can be useful, for example, where model outputs are used in making potentially costly decisions, and one may then focus on the higher confidence predictions, and in general across risk sensitive applications. The conformal prediction framework presents a novel approach for complementing predictions from machine learning algorithms with valid confidence measures. Confidence levels are obtained from the underlying algorithm, using a non-conformity measure which indicates how 'atypical' a given example set is. The non-conformity measure is key to determining the usefulness and efficiency of the approach. This paper considers inductive conformal prediction in the context of random tree ensembles like random forests, which have been noted to perform favorably across problems. Focusing on classification tasks, and considering realistic data contexts including class imbalance, we develop non-conformity measures for assessing the confidence of predicted class labels from random forests. We examine the performance of these measures on multiple datasets. Results demonstrate the usefulness and validity of the measures, their relative differences, and highlight the effectiveness of conformal prediction random forests for obtaining predictions with associated confidence.

#index 1688444
#* Mining Heavy Subgraphs in Time-Evolving Networks
#@ Petko Bogdanov;Misael Mongiovì;Ambuj K. Singh
#t 2011
#c 18
#! Networks from different genres are not static entities, but exhibit dynamic behavior. The congestion level of links in transportation networks varies in time depending on the traffic. Similarly, social and communication links are employed at varying rates as information cascades unfold. In recent years there has been an increase of interest in modeling and mining dynamic networks. However, limited attention has been placed in high-scoring sub graph discovery in time-evolving networks. We define the problem of finding the highest-scoring temporal sub graph in a dynamic network, termed Heaviest Dynamic Sub graph (HDS). We show that HDS is NP-hard even with edge weights in {-1,1} and devise an efficient approach for large graph instances that evolve over long time periods. While a naive approach would enumerate all O(t^2) sub-intervals, our solution performs an effective pruning of the sub-interval space by considering O(t*log(t)) groups of sub-intervals and computing an aggregate of each group in logarithmic time. We also define a fast heuristic and a tight upper bound for approximating the static version of HDS, and use them for further pruning the sub-interval space and quickly verifying candidate sub-intervals. We perform an extensive experimental evaluation of our algorithm on transportation, communication and social media networks for discovering sub graphs that correspond to traffic congestions, communication overflow and localized social discussions. Our method is two orders of magnitude faster than a naive approach and scales well with network size and time length.

#index 1688445
#* Multi-Class L2,1-Norm Support Vector Machine
#@ Xiao Cai;Feiping Nie;Heng Huang;Chris Ding
#t 2011
#c 18
#! Feature selection is an essential component of data mining. In many data analysis tasks where the number of data point is much less than the number of features, efficient feature selection approaches are desired to extract meaningful features and to eliminate redundant ones. In the previous study, many data mining techniques have been applied to tackle the above challenging problem. In this paper, we propose a new $\ell_{2,1}$-norm SVM, that is, multi-class hinge loss with a structured regularization term for all the classes to naturally select features for multi-class without bothering further heuristic strategy. Rather than directly solving the multi-class hinge loss with $\ell_{2,1}$-norm regularization minimization, which has not been solved before due to its optimization difficulty, we are the first to give an efficient algorithm bridging the new problem with a previous solvable optimization problem to do multi-class feature selection. A global convergence proof for our method is also presented. Via the proposed efficient algorithm, we select features across multiple classes with jointly sparsity, \emph{i.e.}, each feature has either small or large score over all classes. Comprehensive experiments have been performed on six bioinformatics data sets to show that our method can obtain better or competitive performance compared with exiting state-of-art multi-class feature selection approaches.

#index 1688446
#* SolarMap: Multifaceted Visual Analytics for Topic Exploration
#@ Nan Cao;David Gotz;Jimeng Sun;Yu-Ru Lin;Huamin Qu
#t 2011
#c 18
#! Documents in rich text corpora often contain multiple facets of information. For example, an article from a medical document collection might consist of multifaceted information about symptoms, treatments, causes, diagnoses, prognoses, and preventions. Thus, documents in the collection may have different relations across each of these various facets. Topic analysis and exploration for such multi-relational corpora is a challenging visual analytic task. This paper presents Solar Map, a multifaceted visual analytic technique for visually exploring topics in multi-relational data. Solar Map simultaneously visualizes the topic distribution of the underlying entities from one facet together with keyword distributions that convey the semantic definition of each cluster along a secondary facet. Solar Map combines several visual techniques including 1) topic contour clusters and interactive multifaceted keyword topic rings, 2) a global layout optimization algorithm that aligns each topic cluster with its corresponding keywords, and 3) 2) an optimal temporal network segmentation and layout method that renders temporal evolution of clusters. Finally, the paper concludes with two case studies and quantitative user evaluation which show the power of the Solar Map technique.

#index 1688447
#* BibClus: A Clustering Algorithm of Bibliographic Networks by Message Passing on Center Linkage Structure
#@ Xiaoran Xu;Zhi-Hong Deng
#t 2011
#c 18
#! Multi-type objects with multi-type relations are ubiquitous in real-world networks, e.g. bibliographic networks. Such networks are also called heterogeneous information networks. However, the research on clustering for heterogeneous information networks is little. A new algorithm, called NetClus, has been proposed in recent two years. Although NetClus is applied on a heterogeneous information network with a star network schema, considering the relations between center objects and all attribute objects linking to them, it ignores the relations between center objects such as citation relations, which also contain rich information. Hence, we think the star network schema cannot be used to characterize all possible relations without integrating the linkage structure among center objects, which we call the Center Linkage Structure, and there has been no practical way good enough to solve it. In this paper, we present a novel algorithm, BibClus, for clustering heterogeneous objects with center linkage structure by taking a bibliographic information network as an example. In BibClus, we build a probabilistic model of pair wise hidden Markov random field (P-HMRF) to characterize the center linkage structure, and convert it to a factor graph. We further combine EM algorithm with factor graph theory, and design an efficient way based on message passing algorithm to inference marginal probabilities and estimate parameters at each iteration of EM. We also study how factor functions affect clustering performance with different function forms and constraints. For evaluating our proposed method, we have conducted thorough experiments on a real dataset that we had crawled from ACM Digital Library. The experimental results show that BibClus is effective and has a much higher quantity than the recently proposed algorithm, NetClus, in both recall and precision.

#index 1688448
#* Multi-instance Metric Learning
#@ Ye Xu;Wei Ping;Andrew T. Campbell
#t 2011
#c 18
#! Multi-instance learning, like other machine learning and data mining tasks, requires distance metrics. Although metric learning methods have been studied for many years, metric learners for multi-instance learning remain almost untouched. In this paper, we propose a framework called Multi-Instance MEtric Learning (MIMEL) to learn an appropriate distance under the multi-instance setting. The distance metric between two bags is defined using the Mahalanobis distance function. The problem is formulated by minimizing the KL divergence between two multivariate Gaussians under the constraints of maximizing the between-class bag distance and minimizing the within-class bag distance. To exploit the mechanism of how instances determine bag labels in multi-instance learning, we design a nonparametric density-estimation-based weighting scheme to assign higher â聙聹weightsâ聙聺 to the instances that are more likely to be positive in positive bags. The weighting scheme itself has a small workload, which adds little extra computing costs to the proposed framework. Moreover, to further boost the classification accuracy, a kernel version of MIMEL is presented. We evaluate MIMEL, using not only several typical multi-instance tasks, but also two activity recognition datasets. The experimental results demonstrate that MIMEL achieves better classification accuracy than many state-of-the-art distance based algorithms or kernel methods for multi-instance learning.

#index 1688449
#* Multi-task Learning with Task Relations
#@ Zhao Xu;Kristian Kersting
#t 2011
#c 18
#! Multi-task and relational learning with Gaussian processes are two active but also orthogonal areas of research. So far, there has been few attempt at exploring relational information within multi-task Gaussian processes. While existing relational Gaussian process methods have focused on relations among entities and in turn could be employed within an individual task, we develop a class of Gaussian process models which incorporates relational information across multiple tasks. As we will show, inference and learning within the resulting class of models, called relational multi-task Gaussian processes, can be realized via a variational EM algorithm. Experimental results on synthetic and real-world datasets verify the usefulness of this approach: The observed relational knowledge at the level of tasks can indeed reveal additional pair wise correlations between tasks of interest and, in turn, improve prediction performance.

#index 1688450
#* Secure Clustering in Private Networks
#@ Bin Yang;Issei Sato;Hiroshi Nakagawa
#t 2011
#c 18
#! Many clustering methods have been proposed for analyzing the relations inside networks with complex structures. Some of them can detect a mixture of assortative and disassortative structures in networks. All these methods are based on the fact that the entire network is observable. However, in the real world, the entities in networks, for example a social network, may be private, and thus, cannot be observed. We focus on private peer-to-peer networks in which all vertices are independent and private, and each vertex only knows about itself and its neighbors. We propose a privacy-preserving Gibbs sampling for clustering these types of private networks and detecting their mixed structures without revealing any private information about any individual entity. Moreover, the running cost of our method is related only to the number of clusters and the maximum degree, but is nearly independent of the number of vertices in the entire network.

#index 1688451
#* LPTA: A Probabilistic Model for Latent Periodic Topic Analysis
#@ Zhijun Yin;Liangliang Cao;Jiawei Han;Chengxiang Zhai;Thomas Huang
#t 2011
#c 18
#! This paper studies the problem of latent periodic topic analysis from time stamped documents. The examples of time stamped documents include news articles, sales records, financial reports, TV programs, and more recently, posts from social media websites such as Flickr, Twitter, and Face book. Different from detecting periodic patterns in traditional time series database, we discover the topics of coherent semantics and periodic characteristics where a topic is represented by a distribution of words. We propose a model called LPTA (Latent Periodic Topic Analysis) that exploits the periodicity of the terms as well as term co-occurrences. To show the effectiveness of our model, we collect several representative datasets including Seminar, DBLP and Flickr. The results show that our model can discover the latent periodic topics effectively and leverage the information from both text and time well.

#index 1688452
#* Structured Feature Selection and Task Relationship Inference for Multi-task Learning
#@ Hongliang Fei;Jun Huan
#t 2011
#c 18
#! Multi-task Learning (MTL) aims to enhance the generalization performance of supervised regression or classification by learning multiple related tasks simultaneously. In this paper, we aim to extend the current MTL techniques to high dimensional data sets with structured input and structured output (SISO), where the SI means the input features are structured and the SO means the tasks are structured. We investigate a completely ignored problem in MTL with SISO data: the interaction of structured feature selection and task relationship modeling. We hypothesize that combining the structure information of features and task relationship inference enables us to build more accurate MTL models. Based on the hypothesis, we have designed an efficient learning algorithm, in which we utilize a task covariance matrix related to the model parameters to capture the task relationship. In addition, we design a regularization formulation for incorporating the structure of features in MTL. We have developed an efficient iterative optimization algorithm to solve the corresponding optimization problem. Our algorithm is based on the accelerated first order gradient method in conjunction with the projected gradient scheme. Using two real-world data sets, the experimental results demonstrate the utility of the proposed learning methods.

#index 1688453
#* A Taxi Driving Fraud Detection System
#@ Yong Ge;Hui Xiong;Chuanren Liu;Zhi-Hua Zhou
#t 2011
#c 18
#! Advances in GPS tracking technology have enabled us to install GPS tracking devices in city taxis to collect a large amount of GPS traces under operational time constraints. These GPS traces provide unparallel opportunities for us to uncover taxi driving fraud activities. In this paper, we develop a taxi driving fraud detection system, which is able to systematically investigate taxi driving fraud. In this system, we first provide functions to find two aspects of evidences: travel route evidence and driving distance evidence. Furthermore, a third function is designed to combine the two aspects of evidences based on Dempster-Shafer theory. To implement the system, we first identify interesting sites from a large amount of taxi GPS logs. Then, we propose a parameter-free method to mine the travel route evidences. Also, we introduce route mark to represent a typical driving path from an interesting site to another one. Based on route mark, we exploit a generative statistical model to characterize the distribution of driving distance and identify the driving distance evidences. Finally, we evaluate the taxi driving fraud detection system with large scale real-world taxi GPS logs. In the experiments, we uncover some regularity of driving fraud activities and investigate the motivation of drivers to commit a driving fraud by analyzing the produced taxi fraud data.

#index 1688454
#* Isograph: Neighbourhood Graph Construction Based on Geodesic Distance for Semi-supervised Learning
#@ Marjan Ghazvininejad;Mostafa Mahdieh;Hamid R. Rabiee;Parisa Khanipour Roshan;Mohammad Hossein Rohban
#t 2011
#c 18
#! Semi-supervised learning based on manifolds has been the focus of extensive research in recent years. Convenient neighbourhood graph construction is a key component of a successful semi-supervised classification method. Previous graph construction methods fail when there are pairs of data points that have small Euclidean distance, but are far apart over the manifold. To overcome this problem, we start with an arbitrary neighbourhood graph and iteratively update the edge weights by using the estimates of the geodesic distances between points. Moreover, we provide theoretical bounds on the values of estimated geodesic distances. Experimental results on real-world data show significant improvement compared to the previous graph construction methods.

#index 1688455
#* D-cores: Measuring Collaboration of Directed Graphs Based on Degeneracy
#@ Christos Giatsidis;Dimitrios M. Thilikos;Michalis Vazirgiannis
#t 2011
#c 18
#! Community detection and evaluation is an important task in graph mining. In many cases, a community is defined as a sub graph characterized by dense connections or interactions among its nodes. A large variety of measures have been proposed to evaluate the quality of such communities â聙" in most cases ignoring the directed nature of edges. In this paper, we introduce novel metrics for evaluating the collaborative nature of directed graphs â聙" a property not captured by the single node metrics or by other established community evaluation metrics. In order to accomplish this objective, we capitalize on the concept of graph degeneracy and define a novel D-core framework, extending the classic graph-theoretic notion of k-cores for undirected graphs to directed ones. Based on the D-core, which essentially can be seen as a measure of the robustness of a community under degeneracy, we devise a wealth of novel metrics used to evaluate graph collaboration features of directed graphs. We applied the D-core approach on large real-world graphs such as Wikipedia and DBLP and report interesting results at the graph as well at node level.

#index 1688456
#* SIMPATH: An Efficient Algorithm for Influence Maximization under the Linear Threshold Model
#@ Amit Goyal;Wei Lu;Laks V. S. Lakshmanan
#t 2011
#c 18
#! There is significant current interest in the problem of influence maximization: given a directed social network with influence weights on edges and a number k, find k seed nodes such that activating them leads to the maximum expected number of activated nodes, according to a propagation model. Kempe et al. showed, among other things, that under the Linear Threshold Model, the problem is NP-hard, and that a simple greedy algorithm guarantees the best possible approximation factor in PTIME. However, this algorithm suffers from various major performance drawbacks. In this paper, we propose Simpath, an efficient and effective algorithm for influence maximization under the linear threshold model that addresses these drawbacks by incorporating several clever optimizations. Through a comprehensive performance study on four real data sets, we show that Simpath consistently outperforms the state of the art w.r.t. running time, memory consumption and the quality of the seed set chosen, measured in terms of expected influence spread achieved.

#index 1688457
#* Causal Associative Classification
#@ Kui Yu;Xindong Wu;Wei Ding;Hao Wang;Hongliang Yao
#t 2011
#c 18
#! Associative classifiers have received considerable attention due to their easy to understand models and promising performance. However, with a high dimensional dataset, associative classifiers inevitably face two challenges: (1) how to extract a minimal set of strong predictive rules from an explosive number of generated association rules, and (2) how to deal with the highly sensitive choice of the minimal support threshold. In order to address these two challenges, we introduce causality into associative classification, and propose a new framework of causal associative classification. In this framework, we use causal Bayesian networks to bridge irrelevant and redundant features with irrelevant and redundant rules in associative classification. Without loss of prediction power, the feature space involved with the antecedent of a classification rule is reduced to the space of the direct causes, direct effects, and direct causes of the direct effects, a.k.a. the Markov blanket, of the consequent of the rule in causal Bayesian networks. The proposed framework is instantiated via baseline classifiers using emerging patterns. Experimental results show that our framework significantly reduces the model complexity while outperforming the other state-of-the-art algorithms.

#index 1688458
#* Multi-task Learning for Bayesian Matrix Factorization
#@ Chao Yuan
#t 2011
#c 18
#! Data sparsity is a big challenge for collaborative filtering. This problem becomes more serious if the dataset is newly created and has even fewer ratings. By sharing knowledge among different datasets, multi-task learning is a promising technique to address this issue. Most prior work methods directly share objects (users or items) across different datasets. However, object identities and correspondences may not be known in many cases. We extend the previous work of Bayesian matrix factorization with Dirichlet process mixture into a multi-task learning approach by sharing latent parameters among different tasks. Our method does not require object identities and thus is more widely applicable. The proposed model is fully non-parametric in that the dimension of latent feature vectors is automatically determined. Inference is performed using the variational Bayesian algorithm, which is much faster than Gibbs sampling used by most other related Bayesian methods.

#index 1688459
#* Enabling Fast Lazy Learning for Data Streams
#@ Peng Zhang;Byron J. Gao;Xingquan Zhu;Li Guo
#t 2011
#c 18

#index 1688460
#* Clusterability Analysis and Incremental Sampling for Nyström Extension Based Spectral Clustering
#@ Xianchao Zhang;Quanzeng You
#t 2011
#c 18
#! To alleviate the memory and computational burdens of spectral clustering for large scale problems, some kind of low-rank matrix approximation is usually employed. Nyström method is an efficient technique to generate low rank matrix approximation and its most important aspect is sampling. The matrix approximation errors of several sampling schemes have been theoretically analyzed for a number of learning tasks. However, the impact of matrix approximation error on the clustering performance of spectral clustering has not been studied. In this paper, we firstly analyze the performance of Nyström method in terms of cluster ability, thus answer the impact of matrix approximation error on the clustering performance of spectral clustering. Our analysis immediately suggests an incremental sampling scheme for the Nyström method based spectral clustering. Experimental results show that the proposed incremental sampling scheme outperforms existing sampling schemes on various clustering tasks and image segmentation applications, and its efficiency is comparable with existing sampling schemes.

#index 1688461
#* Fast and Robust Graph-based Transductive Learning via Minimum Tree Cut
#@ Yan-Ming Zhang;Kaizhu Huang;Cheng-Lin Liu
#t 2011
#c 18
#! In this paper, we propose an efficient and robust algorithm for graph-based transductive classification. After approximating a graph with a spanning tree, we develop a linear-time algorithm to label the tree such that the cut size of the tree is minimized. This significantly improves typical graph-based methods, which either have a cubic time complexity (for a dense graph) or $O(kn^2)$ (for a sparse graph with $k$ denoting the node degree). %In addition to its great scalability on large data, our proposed algorithm demonstrates high robustness and accuracy. In particular, on a graph with 400,000 nodes (in which 10,000 nodes are labeled) and 10,455,545 edges, our algorithm achieves the highest accuracy of $99.6\%$ but takes less than $10$ seconds to label all the unlabeled data. Furthermore, our method shows great robustness to the graph construction both theoretically and empirically, this overcomes another big problem of traditional graph-based methods. In addition to its good scalability and robustness, the proposed algorithm demonstrates high accuracy. In particular, on a graph with $400,000$ nodes (in which $10,000$ nodes are labeled) and $10,455,545$ edges, our algorithm achieves the highest accuracy of $99.6\%$ but takes less than $10$ seconds to label all the unlabeled data.

#index 1688462
#* CEMiner -- An Efficient Algorithm for Mining Closed Patterns from Time Interval-Based Data
#@ Yi-Cheng Chen;Wen-Chih Peng;Suh-Yin Lee
#t 2011
#c 18
#! The mining of closed sequential patterns has attracted researchers for its capability of using compact results to preserve the same expressive power as conventional mining. However, existing studies only focus on time point-based data. Few research efforts have elaborated on discovering closed sequential patterns from time interval-based data, where each data persists for a period of time. Mining closed time interval-based patterns, also called closed temporal patterns, is an arduous problem since the pair wise relationships between two interval-based events are intrinsically complex. In this paper, an efficient algorithm, CEMiner is developed to discover closed temporal patterns from interval-based data. Algorithm CEMiner employs some optimization techniques to effectively reduce the search space. The experimental results on both synthetic and real datasets indicate that CEMiner not only significantly outperforms the prior interval-based mining algorithms in terms of execution time but also possesses graceful scalability. The experiment conducted on real dataset shows the practicability of time interval-based closed pattern mining.

#index 1688463
#* LinkBoost: A Novel Cost-Sensitive Boosting Framework for Community-Level Network Link Prediction
#@ Prakash Mandayam Comar;Pang-Ning Tan;Anil K. Jain
#t 2011
#c 18
#! Link prediction is a challenging task due to the inherent skew ness of network data. Typical link prediction methods can be categorized as either local or global. Local methods consider the link structure in the immediate neighborhood of a node pair to determine the presence or absence of a link, whereas global methods utilize information from the whole network. This paper presents a community (cluster) level link prediction method without the need to explicitly identify the communities in a network. Specifically, a variable-cost loss function is defined to address the data skew ness problem. We provide theoretical proof that shows the equivalence between maximizing the well-known modularity measure used in community detection and minimizing a special case of the proposed loss function. As a result, any link prediction method designed to optimize the loss function would result in more links being predicted within a community than between communities. We design a boosting algorithm to minimize the loss function and present an approach to scale-up the algorithm by decomposing the network into smaller partitions and aggregating the weak learners constructed from each partition. Experimental results show that our proposed Link Boost algorithm consistently performs as good as or better than many existing methods when evaluated on 4 real-world network datasets.

#index 1688464
#* Learning Dirichlet Processes from Partially Observed Groups
#@ Avinava Dubey;Indrajit Bhattacharya;Mrinal Das;Tanveer Faruquie;Chiranjib Bhattacharyya
#t 2011
#c 18
#! Motivated by the task of vernacular news analysis using known news topics from national news-papers, we study the task of topic analysis, where given source datasets with observed topics, data items from a target dataset need to be assigned either to observed source topics or to new ones. Using Hierarchical Dirichlet Processes for addressing this task imposes unnecessary and often inappropriate generative assumptions on the observed source topics. In this paper, we explore Dirichlet Processes with partially observed groups (POG-DP). POG-DP avoids modeling the given source topics. Instead, it directly models the conditional distribution of the target data as a mixture of a Dirichlet Process and the posterior distribution of a Hierarchical Dirichlet Process with known groups and topics. This introduces coupling between selection probabilities of all topics within a source, leading to effective identification of source topics. We further improve on this with a Combinatorial Dirichlet Process with partially observed groups (POG-CDP) that captures finer grained coupling between related topics by choosing intersections between sources. We evaluate our models in three different real-world applications. Using extensive experimentation, we compare against several baselines to show that our model performs significantly better in all three applications.

#index 1688465
#* Exploiting False Discoveries -- Statistical Validation of Patterns and Quality Measures in Subgroup Discovery
#@ Wouter Duivesteijn;Arno Knobbe
#t 2011
#c 18
#! Subgroup discovery suffers from the multiple comparisons problem: we search through a large space, hence whenever we report a set of discoveries, this set will generally contain false discoveries. We propose a method to compare subgroups found through subgroup discovery with a statistical model we build for these false discoveries. We determine how much the subgroups we find deviate from the model, and hence statistically validate the found subgroups. Furthermore we propose to use this subgroup validation to objectively compare quality measures used in subgroup discovery, by determining how much the top subgroups we find with each measure deviate from the statistical model generated with that measure. We thus aim to determine how good individual measures are in selecting significant findings. We invoke our method to experimentally compare popular quality measures in several subgroup discovery settings.

#index 1688466
#* An Efficient Greedy Method for Unsupervised Feature Selection
#@ Ahmed K. Farahat;Ali Ghodsi;Mohamed S. Kamel
#t 2011
#c 18
#! In data mining applications, data instances are typically described by a huge number of features. Most of these features are irrelevant or redundant, which negatively affects the efficiency and effectiveness of different learning algorithms. The selection of relevant features is a crucial task which can be used to allow a better understanding of data or improve the performance of other learning tasks. Although the selection of relevant features has been extensively studied in supervised learning, feature selection with the absence of class labels is still a challenging task. This paper proposes a novel method for unsupervised feature selection, which efficiently selects features in a greedy manner. The paper first defines an effective criterion for unsupervised feature selection which measures the reconstruction error of the data matrix based on the selected subset of features. The paper then presents a novel algorithm for greedily minimizing the reconstruction error based on the features selected so far. The greedy algorithm is based on an efficient recursive formula for calculating the reconstruction error. Experiments on real data sets demonstrate the effectiveness of the proposed algorithm in comparison to the state-of-the-art methods for unsupervised feature selection.

#index 1688467
#* Positive and Unlabeled Learning for Graph Classification
#@ Yuchen Zhao;Xiangnan Kong;Philip S. Yu
#t 2011
#c 18
#! The problem of graph classification has drawn much attention in the last decade. Conventional approaches on graph classification focus on mining discriminative sub graph features under supervised settings. The feature selection strategies strictly follow the assumption that both positive and negative graphs exist. However, in many real-world applications, the negative graph examples are not available. In this paper we study the problem of how to select useful sub graph features and perform graph classification based upon only positive and unlabeled graphs. This problem is challenging and different from previous works on PU learning, because there are no predefined features in graph data. Moreover, the sub graph enumeration problem is NP-hard. We need to identify a subset of unlabeled graphs that are most likely to be negative graphs. However, the negative graph selection problem and the sub graph feature selection problem are correlated. Before the reliable negative graphs can be resolved, we need to have a set of useful sub graph features. In order to address this problem, we first derive an evaluation criterion to estimate the dependency between sub graph features and class labels based on a set of estimated negative graphs. In order to build accurate models for the PU learning problem on graph data, we propose an integrated approach to concurrently select the discriminative features and the negative graphs in an iterative manner. Experimental results illustrate the effectiveness and efficiency of the proposed method.

#index 1688468
#* Finding Novel Diagnostic Gene Patterns Based on Interesting Non-redundant Contrast Sequence Rules
#@ Yuhai Zhao;Guoren Wang;Yuan Li;Zhanghui Wang
#t 2011
#c 18
#! Diagnostic genes refer to the genes closely related to a specific disease phenotype, the powers of which to distinguish between different classes are often high. Most methods to discovering the powerful diagnostic genes are either singleton discriminability-based or combination discriminability-based. However, both ignore the abundant interactions among genes, which widely exist in the real world. In this paper, we tackle the problem from a new point of view and make the following contributions: (1) we propose an EWave model, which profitably exploits the ordered expressions among genes based on the defined equivalent dimension group sequences taking into account the "noise" universal in the real data, (2) we devise a novel sequence rule, namely interesting non-redundant contrast sequence rule, which is able to capture the difference between different phenotypes in a high accuracy using as few as possible genes, (3) we present an efficient algorithm called NRMINER to find such rules. Unlike the conventional column enumeration and the more recent row enumeration, it performs a novel template-driven enumeration by making use of the special characteristic of micro array data modeled by EWave. Extensive experiments conducted on various synthetic and real datasets show that: (1) NRMINER is significantly faster than the competing algorithm by up to about one order of magnitude, (2) it provides a higher accuracy using fewer genes. Many diagnostic genes discovered by NRMINER are proved biologically related to some disease.

#index 1688469
#* Semi-supervised Hierarchical Clustering
#@ Li Zheng;Tao Li
#t 2011
#c 18
#! Semi-supervised clustering (i.e., clustering with knowledge-based constraints) has emerged as an important variant of the traditional clustering paradigms. However, most existing semi-supervised clustering algorithms are designed for partitional clustering methods and few research efforts have been reported on semi-supervised hierarchical clustering methods. In addition, current semi-supervised clustering methods have been focused on the use of background information in the form of instance level must-link and cannot-link constraints, which are not suitable for hierarchical clustering where data objects are linked over different hierarchy levels. In this paper, we propose a novel semi-supervised hierarchical clustering framework based on ultra-metric dendrogram distance. The proposed framework is able to incorporate triple-wise relative constraints. We establish the connection between hierarchical clustering and ultra-metric transformation of dissimilarity matrix and propose two techniques (the constrained optimization technique and the transitive dissimilarity based technique) for semi-supervised hierarchical clustering. Experimental results demonstrate the effectiveness and the efficiency of our proposed methods.

#index 1688470
#* Handling Conditional Discrimination
#@ Indre Zliobaite;Faisal Kamiran;Toon Calders
#t 2011
#c 18
#! Historical data used for supervised learning may contain discrimination. We study how to train classifiers on such data, so that they are discrimination free with respect to a given sensitive attribute, e.g., gender. Existing techniques that deal with this problem aim at removing all discrimination and do not take into account that part of the discrimination may be explainable by other attributes, such as, e.g., education level. In this context, we introduce and analyze the issue of conditional non-discrimination in classifier design. We show that some of the differences in decisions across the sensitive groups can be explainable and hence tolerable. We observe that in such cases, the existing discrimination aware techniques will introduce a reverse discrimination, which is undesirable as well. Therefore, we develop local techniques for handling conditional discrimination when one of the attributes is considered to be explanatory. Experimental evaluation demonstrates that the new local techniques remove exactly the bad discrimination, allowing differences in decisions as long as they are explainable.

#index 1688471
#* On the Hardness of Graph Anonymization
#@ Charu C. Aggarwal;Yao Li;Philip S. Yu
#t 2011
#c 18
#! In this paper, we examine the problem of node re-identification from anonymized graphs. Typical graphs encountered in real applications are massive and sparse. In this paper, we will show that massive and sparse graphs have certain theoretical properties which make them susceptible to re-identification attacks. We design a systematic way to exploit these theoretical properties in order to construct {\em re-identification signatures}, which are also known as characteristic vectors. These signatures have the property that they are extremely robust to perturbations, especially for massive and sparse graphs. Our results show that even low levels of anonymization require perturbation levels which are significant enough to result in a massive loss of utility. Our experimental results also show that the true anonymization level of graphs is much lower than is implied by measures such as $k$-anonymity. Thus, the results of this paper establish that the problem of massive graph anonymization has fundamental theoretical barriers which prevent a fully effective solution.

#index 1688472
#* Beyond 'Caveman Communities': Hubs and Spokes for Graph Compression and Mining
#@ U. Kang;Christos Faloutsos
#t 2011
#c 18
#! Given a real world graph, how should we lay-out its edges? How can we compress it? These questions are closely related, and the typical approach so far is to find clique-like communities, like the `cavemen graph', and compress them. We show that the block-diagonal mental image of the `cavemen graph' is the wrong paradigm, in full agreement with earlier results that real world graphs have no good cuts. Instead, we propose to envision graphs as a collection of hubs connecting spokes, with super-hubs connecting the hubs, and so on, recursively. Based on the idea, we propose the Slash Burn method (burn the hubs, and slash the remaining graph into smaller connected components). Our view point has several advantages: (a) it avoids the `no good cuts' problem, (b) it gives better compression, and (c) it leads to faster execution times for matrix-vector operations, which are the back-bone of most graph processing tools. Experimental results show that our Slash Burn method consistently outperforms other methods on all datasets, giving good compression and faster running time.

#index 1688473
#* Cross Domain Random Walk for Query Intent Pattern Mining from Search Engine Log
#@ Siyu Gu;Jun Yan;Lei Ji;Shuicheng Yan;Junshi Huang;Ning Liu;Ying Chen;Zheng Chen
#t 2011
#c 18
#! Understanding search intents of users through their condensed short queries has attracted much attention both in academia and industry. The search intents of users are generally assumed to be associated with various query patterns, such as "MobileName price", where "MobileName" could be any named entity of mobile phone model and this pattern indicates that the user intends to buy a mobile phone. However, discovering the query intent patterns for general search is challenging mainly due to the difficulty in collecting sufficient training data for learning query patterns across a large number of searchable domains. In this work, we propose Cross Domain Random Walk (CDRW) algorithm, which is semi-supervised, to discover the query intent patterns across different domains from search engine click-through log data. Starting with some manually tagged seed queries in one or more independent domains, CDRW takes the query patterns as bridge and propagates the transition probability across domains to collect the query intent patterns among different domains based on the assumption that "users who have similar intent in different but similar domains will have high probability to share similar query patterns across domains". Different from classical random walk algorithms, CDRW walks across different domains to disseminate the shared knowledge in a transfer learning manner. Extensive experiment results on real log data of a commercial search engine well validate the effectiveness and efficiency of the proposed algorithm.

#index 1688474
#* Flexible Fault Tolerant Subspace Clustering for Data with Missing Values
#@ Stephan Gunnemann;Emmanuel Muller;Sebastian Raubach;Thomas Seidl
#t 2011
#c 18
#! In today's applications, data analysis tasks are hindered by many attributes per object as well as by faulty data with missing values. Subspace clustering tackles the challenge of many attributes by cluster detection in any subspace projection of the data. However, it poses novel challenges for handling missing values of objects, which are part of multiple subspace clusters in different projections of the data. In this work, we propose a general fault tolerance definition enhancing subspace clustering models to handle missing values. We introduce a flexible notion of fault tolerance that adapts to the individual characteristics of subspace clusters and ensures a robust parameterization. Allowing missing values in our model increases the computational complexity of subspace clustering. Thus, we prove novel monotonicity properties for an efficient computation of fault tolerant subspace clusters. Experiments on real and synthetic data show that our fault tolerance model yields high quality results even in the presence of many missing values. For repeatability, we provide all datasets and executables on our website.

#index 1688475
#* Heuristic Updatable Weighted Random Subspaces for Non-stationary Environments
#@ T. Ryan Hoens;Nitesh V. Chawla;Robi Polikar
#t 2011
#c 18
#! Learning in non-stationary environments is an increasingly important problem in a wide variety of real-world applications. In non-stationary environments data arrives incrementally, however the underlying generating function may change over time. While there is a variety of research into such environments, the research mainly consists of detecting concept drift (and then relearning the model), or developing classiï卢聛ers which adapt to drift incrementally. We introduce Heuristic Up datable Weighted Random Subspaces (HUWRS), a new technique based on the Random Subspace Method that detects drift in individual features via the use of He llinger distance, a distributional divergence metric. Through the use of subspaces, HUWRS allows for a more ï卢聛ne-grained approach to dealing with concept drift which is robust to feature drift even without class labels. We then compare our approach to two state of the art algorithms, concluding that for a wide range of datasets and window sizes HUWRS outperforms the other methods.

#index 1688476
#* Learning Tags from Unsegmented Videos of Multiple Human Actions
#@ Timothy M. Hospedales;Shaogang Gong;Tao Xiang
#t 2011
#c 18
#! Providing methods to support semantic interaction with growing volumes of video data is an increasingly important challenge for data mining. To this end, there has been some success in recognition of simple objects and actions in video, however most of this work requires strongly supervised training data. The supervision cost of these approaches therefore renders them economically non-scalable for real world applications. In this paper we address the problem of learning to annotate and retrieve semantic tags of human actions in realistic video data with sparsely provided tags of semantically salient activities. This is challenging because of (1) the multi-label nature of the learning problem and (2) realistic videos are often dominated by (semantically uninteresting) background activity un-supported by any tags of interest, leading to a strong irrelevant data problem. To address these challenges, we introduce a new topic model based approach to video tag annotation. Our model simultaneously learns a low dimensional representation of the video data, which dimensions are semantically relevant (supported by tags), and how to annotate videos with tags. Experimental evaluation on three different video action/activity datasets demonstrate the challenge of this problem, and value of our contribution.

#index 1688477
#* Generating Breakpoint-based Timeline Overview for News Topic Retrospection
#@ Po Hu;Minlie Huang;Peng Xu;Weichang Li;Adam K. Usadi;Xiaoyan Zhu
#t 2011
#c 18
#! Though news readers can easily access a large number of news articles from the Internet, they can be overwhelmed by the quantity of information available, making it hard to get a concise, global picture of a news topic. In this paper we propose a novel method to address this problem. Given a set of articles for a given news topic, the proposed method models theme variation through time and identifies the breakpoints, which are time points when decisive changes occur. For each breakpoint, a brief summary is automatically constructed based on articles associated with the particular time point. Summaries are then ordered chronologically to form a timeline overview of the news topic. In this fashion, readers can easily track various news topics efficiently. We have conducted experiments on 15 popular topics in 2010. Empirical experiments show the effectiveness of our approach and its advantages over other approaches.

#index 1688478
#* SPO: Structure Preserving Oversampling for Imbalanced Time Series Classification
#@ Hong Cao;Xiao-Li Li;Yew-Kwong Woon;See-Kiong Ng
#t 2011
#c 18
#! This paper presents a novel structure preserving over sampling (SPO) technique for classifying imbalanced time series data. SPO generates synthetic minority samples based on multivariate Gaussian distribution by estimating the covariance structure of the minority class and regularizing the unreliable eigen spectrum. By preserving the main covariance structure and intelligently creating protective variances in the trivial eigen feature dimensions, the synthetic samples expand effectively into the void area in the data space without being too closely tied with existing minority-class samples. Extensive experiments based on several public time series datasets demonstrate that our proposed SPO in conjunction with support vector machines can achieve better performances than existing over sampling methods and state-of-the-art methods in time series classification.

#index 1688479
#* Manifold Learning and Missing Data Recovery through Unsupervised Regression
#@ Miguel A. Carreira-Perpinán;Zhengdong Lu
#t 2011
#c 18
#! We propose an algorithm that, given a high-dimensional dataset with missing values, achieves the distinct goals of learning a nonlinear low-dimensional representation of the data (the dimensionality reduction problem) and reconstructing the missing high-dimensional data (the matrix completion, or imputation, problem). The algorithm follows the Dimensionality Reduction by Unsupervised Regression approach, where one alternately optimizes over the latent coordinates given the reconstruction and projection mappings, and vice versa, but here we also optimize over the missing data, using an efficient, globally convergent Gauss-Newton scheme. We also show how to project or reconstruct test data with missing values. We achieve impressive reconstructions while learning good latent representations in image restoration with 50% missing pixels.

#index 1688480
#* Characterizing Inverse Time Dependency in Multi-class Learning
#@ Danqi Chen;Weizhu Chen;Qiang Yang
#t 2011
#c 18
#! The training time of most learning algorithms increases as the size of training data increases. Yet, recent advances in linear binary SVM and LR challenge this commonsense by proposing an inverse dependency property, where the training time decreases as the size of training data increases. In this paper, we study the inverse dependency property of multi-class classification problem. We describe a general framework for multi-class classification problem with a single objective to achieve inverse dependency and extend it to three popular multi-class algorithms. We present theoretical results demonstrating its convergence and inverse dependency guarantee. We conduct experiments to empirically verify the inverse dependency of all the three algorithms on large-scale datasets as well as to ensure the accuracy.

#index 1688481
#* Supervised Lazy Random Walk for Topic-Focused Multi-document Summarization
#@ Pan Du;Jiafeng Guo;Xueqi Cheng
#t 2011
#c 18
#! Topic-focused multi-document summarization aims to produce a summary given a specific topic description and a set of related documents. It has become a crucial text processing task in many real applications that can help users consume the massive information. This paper presents a novel extractive approach based on supervised lazy random walk (Super Lazy). This approach naturally combines the rich features of sentences with the intrinsic sentence graph structure in a principled way, and thus enjoys the advantages of both the existing supervised and unsupervised approaches. Moreover, our approach can achieve the three major goals of topic-focused multi-document summarization (i.e. relevance, salience and diversity) simultaneously with a unified ranking process. Experiments on the benchmark dataset TAC2008 and TAC2009 are performed and the ROUGE evaluation results demonstrate that our approach can significantly outperform both the state-of-the-art supervised and unsupervised methods.

#index 1688482
#* Unsupervised Anomaly Intrusion Detection via Localized Bayesian Feature Selection
#@ Wentao Fan;Nizar Bouguila;Djemel Ziou
#t 2011
#c 18
#! In recent years, an increasing number of security threats have brought a serious risk to the internet and computer networks. Intrusion Detection System (IDS) plays a vital role in detecting various kinds of attacks. Developing adaptive and flexible oriented IDSs remains a challenging and demanding task due to the incessantly appearance of new types of attacks and sabotaging approaches. In this paper, we propose a novel unsupervised statistical approach for detecting network based attacks. In our approach, patterns of normal and intrusive activities are learned through finite generalized Dirichlet mixture models, in the context of Bayesian variational inference. Under the proposed variational framework, the parameters, the complexity of the mixture model, and the features saliency can be estimated simultaneously, in a closed-form. We evaluate the proposed approach using the popular KDD CUP 1999 data set. Experimental results show that this approach is able to detect many different types of intrusions accurately with a low false positive rate.

#index 1688483
#* Identifying Differentially Expressed Genes via Weighted Rank Aggregation
#@ Qiong Fang;Jianlin Feng;Wilfred Ng
#t 2011
#c 18
#! Identifying differentially expressed genes is an important problem in gene expression analysis, since these genes, exhibiting sufficiently different expression levels under distinct experiment conditions, could be critical for tracing the progression of a disease. In a micro array study, genes are usually sorted in terms of their differentiation abilities with the more differentially expressed genes being ranked higher in the list. As more micro array studies are conducted, rank aggregation becomes an important means to combine such ranked gene lists in order to discover more reliable differentially expressed genes. In this paper, we study a novel weighted gene rank aggregation problem whose complexity is at least NP-hard. To tackle the problem, we develop a new Markov-chain based rank aggregation method called Weighted MC (WMC). The WMC algorithm makes use of rank-based weight information to generate the transition matrix. Extensive experiments on the real biological datasets show that our approach is more efficient in aggregating long gene lists. Importantly, the WMC method is much more robust for identifying biologically significant genes compared with the state-of-the-art methods.

#index 1688484
#* A Robust Clustering Algorithm Based on Aggregated Heat Kernel Mapping
#@ Hao Huang;Shinjae Yoo;Hong Qin;Dantong Yu
#t 2011
#c 18
#! Current spectral clustering algorithms suffer from both sensitivity to scaling parameter selection in similarity matrix construction, and data perturbation. This paper aims to improve robustness in clustering algorithms and combat these two limitations based on heat kernel theory. Heat kernel can statistically depict traces of random walk, so it has an intrinsic connection with diffusion distance, with which we can ensure robustness during any clustering process. By integrating heat distributed along time scale, we propose a novel method called Aggregated Heat Kernel (AHK) to measure the distance between each point pair in their eigen space. Using AHK and Laplace-Beltrami Normalization (LBN) we are able to apply an advanced noise-resisting robust spectral mapping to original dataset. Moreover it offers stability on scaling parameter tuning. Experimental results show that, compared to other popular spectral clustering methods, our algorithm can achieve robust clustering results on both synthetic and UCI real datasets.

#index 1688485
#* Patent Maintenance Recommendation with Patent Information Network Model
#@ Xin Jin;Scott Spangler;Ying Chen;Keke Cai;Rui Ma;Li Zhang;Xian Wu;Jiawei Han
#t 2011
#c 18
#! Patents are of crucial importance for businesses, because they provide legal protection for the invented techniques, processes or products. A patent can be held for up to 20 years. However, large maintenance fees need to be paid to keep it enforceable. If the patent is deemed not valuable, the owner may decide to abandon it by stopping paying the maintenance fees to reduce the cost. For large companies or organizations, making such decisions is difficult because too many patents need to be investigated. In this paper, we introduce the new patent mining problem of automatic patent maintenance prediction, and propose a systematic solution to analyze patents for recommending patent maintenance decision. We model the patents as a heterogeneous time-evolving information network and propose new patent features to build model for a ranked prediction on whether to maintain or abandon a patent. In addition, a network-based refinement approach is proposed to further improve the performance. We have conducted experiments on the large scale United States Patent and Trademark Office (USPTO) database which contains over four million granted patents. The results show that our technique can achieve high performance.

#index 1688486
#* S-preconditioner for Multi-fold Data Reduction with Guaranteed User-Controlled Accuracy
#@ Ye Jin;Sriram Lakshminarasimhan;Neil Shah;Zhenhuan Gong;C. S. Chang;Jackie Chen;Stephane Ethier;Hemanth Kolla;Seung-Hoe Ku;Scott Klasky;Robert Latham;Robert Ross;Karen Schuchardt;Nagiza F. Samatova
#t 2011
#c 18
#! The growing gap between the massive amounts of data generated by petascale scientific simulation codes and the capability of system hardware and software to effectively analyze this data necessitates data reduction. Yet, the increasing data complexity challenges most, if not all, of the existing data compression methods. In fact, loss less compression techniques offer no more than 10% reduction on scientific data that we have experience with, which is widely regarded as effectively incompressible. To bridge this gap, in this paper, we advocate a transformative strategy that enables fast, accurate, and multi-fold reduction of double-precision floating-point scientific data. The intuition behind our method is inspired by an effective use of preconditioners for linear algebra solvers optimized for a particular class of computational "dwarfs" (e.g., dense or sparse matrices). Focusing on a commonly used multi-resolution wavelet compression technique as the underlying "solver" for data reduction we propose the S-preconditioner, which transforms scientific data into a form with high global regularity to ensure a significant decrease in the number of wavelet coefficients stored for a segment of data. Combined with the subsequent EQ-$calibrator, our resultant method (called S-Preconditioned EQ-Calibrated Wavelets (SW)), robustly achieved a 4-to 5-fold data reduction-while guaranteeing user-defined accuracy of reconstructed data to be within 1% point-by-point relative error, lower than 0.01 Normalized RMSE, and higher than 0.99 Pearson Correlation. In this paper, we show the results we obtained by testing our method on six petascale simulation codes including fusion, combustion, climate, astrophysics, and subsurface groundwater in addition to 13 publicly available scientific datasets. We also demonstrate that application-driven data mining tasks performed on decompressed variables or their derived quantities produce results of comparable quality with the ones for the original data.

#index 1688487
#* Learning Markov Logic Networks via Functional Gradient Boosting
#@ Tushar Khot;Sriraam Natarajan;Kristian Kersting;Jude Shavlik
#t 2011
#c 18
#! Recent years have seen a surge of interest in Statistical Relational Learning (SRL) models that combine logic with probabilities. One prominent example is Markov Logic Networks (MLNs). While MLNs are indeed highly expressive, this expressiveness comes at a cost. Learning MLNs is a hard problem and therefore has attracted much interest in the SRL community. Current methods for learning MLNs follow a two-step approach: first, perform a search through the space of possible clauses and then learn appropriate weights for these clauses. We propose to take a different approach, namely to learn both the weights and the structure of the MLN simultaneously. Our approach is based on functional gradient boosting where the problem of learning MLNs is turned into a series of relational functional approximation problems. We use two kinds of representations for the gradients: clause-based and tree-based. Our experimental evaluation on several benchmark data sets demonstrates that our new approach can learn MLNs as good or better than those found with state-of-the-art methods, but often in a fraction of the time.

#index 1688488
#* Efficient Mining of Closed Sequential Patterns on Stream Sliding Window
#@ Chuancong Gao;Jianyong Wang;Qingyan Yang
#t 2011
#c 18
#! As a typical data mining research topic, sequential pattern mining has been studied extensively for the past decade. Recently, mining various sequential patterns incrementally over stream data has raised great interest. Due to the challenges of mining stream data, many difficulties not so obvious in static data mining have to be reconsidered carefully. In this paper, we propose a novel algorithm which stores only frequent closed prefixes in its enumeration tree structure, used for mining and maintaining patterns in the current sliding window, to solve the frequent closed sequential pattern mining problem efficiently over stream data. Some effective search space pruning and pattern closure checking strategies have been also devised to accelerate the algorithm. Experimental results show that our algorithm outperforms other state-of-the-art algorithm significantly in both running time and memory use.

#index 1688489
#* A Spectral Framework for Detecting Inconsistency across Multi-source Object Relationships
#@ Jing Gao;Wei Fan;Deepak Turaga;Srinivasan Parthasarathy;Jiawei Han
#t 2011
#c 18
#! In this paper, we propose to conduct anomaly detection across multiple sources to identify objects that have inconsistent behavior across these sources. We assume that a set of objects can be described from various perspectives (multiple information sources). The underlying clustering structure of normal objects is usually shared by multiple sources. However, anomalous objects belong to different clusters when considering different aspects. For example, there exist movies that are expected to be liked by kids by genre, but are liked by grown-ups based on user viewing history. To identify such objects, we propose to compute the distance between different eigen decomposition results of the same object with respect to different sources as its anomalous score. We also give interpretations from the perspectives of constrained spectral clustering and random walks over graph. Experimental results on several UCI as well as DBLP and Movie Lens datasets demonstrate the effectiveness of the proposed approach.

#index 1688490
#* Tracking and Connecting Topics via Incremental Hierarchical Dirichlet Processes
#@ Zekai J. Gao;Yangqiu Song;Shixia Liu;Haixun Wang;Hao Wei;Yang Chen;Weiwei Cui
#t 2011
#c 18
#! Much research has been devoted to topic detection from text, but one major challenge has not been addressed: revealing the rich relationships that exist among the detected topics. Finding such relationships is important since many applications are interested in how topics come into being, how they develop, grow, disintegrate, and finally disappear. In this paper, we present a novel method that reveals the connections between topics discovered from the text data. Specifically, our method focuses on how one topic splits into multiple topics, and how multiple topics merge into one topic. We adopt the hierarchical Dirichlet process (HDP) model, and propose an incremental Gibbs sampling algorithm to incrementally derive and refine the labels of clusters. We then characterize the splitting and merging patterns among clusters based on how labels change. We propose a global analysis process that focuses on cluster splitting and merging, and a finer granularity analysis process that helps users to better understand the content of the clusters and the evolution patterns. We also develop a visualization process to present the results.

#index 1688491
#* Learning Protein Folding Energy Functions
#@ Wei Guan;Arkadas Ozakin;Alexander Gray;Jose Borreguero;Shashi Pandit;Anna Jagielska;Liliana Wroblewska;Jeffrey Skolnick
#t 2011
#c 18
#! A critical open problem in \emph{ab initio} protein folding is protein energy function design, which pertains to defining the energy of protein conformations in a way that makes folding most efficient and reliable. In this paper, we address this issue as a weight optimization problem and utilize a machine learning approach, learning-to-rank, to solve this problem. We investigate the ranking-via-classification approach, especially the Ranking SVM method and compare it with the state-of-the-art approach to the problem using the MINUIT optimization package. To maintain the physicality of the results, we impose non-negativity constraints on the weights. For this we develop two efficient non-negative support vector machine (NNSVM) methods, derived from L2-norm SVM and L1-norm SVMs, respectively. We demonstrate an energy function which maintains the correct ordering with respect to structure dissimilarity to the native state more often, is more efficient and reliable for learning on large protein sets, and is qualitatively superior to the current state-of-the-art energy function.

#index 1688492
#* How Does Research Evolve? Pattern Mining for Research Meme Cycles
#@ Dan He;Xingquan Zhu;D. Stott Parker
#t 2011
#c 18
#! Recent years have witnessed a great deal of attention in tracking news memes over the web, modeling shifts in the ebb and flow of their popularity. One of the most important features of news memes is that they seldom occur repeatedly, instead, they tend to shift to different but similar memes. In this work, we consider patterns in research memes, which differ significantly from news memes and have received very little attention. One significant difference between research memes and news memes lies in that research memes have cyclic development, motivating the need for models of cycles of research memes. Furthermore, these cycles may reveal important patterns of evolving research, shedding lights on how research progresses. In this paper, we formulate the modeling of the cycles of research memes, and propose solutions to the problem of identifying cycles and discovering patterns among these cycles. Experiments on two different domain applications indicate that our model does find meaningful patterns and our algorithms for pattern discovery are efficient for large scale data analysis.

#index 1688493
#* Constraint Selection-Based Semi-supervised Feature Selection
#@ Mohammed Hindawi;Kais Allab;Khalid Benabdeslem
#t 2011
#c 18
#! In this paper, we present a novel feature selection approach based on an efficient selection of pair wise constraints. This aims at selecting the most coherent constraints extracted from labeled part of data. The relevance of features is then evaluated according to their efficient locality preserving and chosen constraint preserving ability. Finally, experimental results are provided for validating our proposal with respect to other known feature selection methods.

#index 1688494
#* Improving Product Classification Using Images
#@ Anitha Kannan;Partha Pratim Talukdar;Nikhil Rasiwasia;Qifa Ke
#t 2011
#c 18
#! Product classification in Commerce search (\eg{} Google Product Search, Bing Shopping) involves associating categories to offers of products from a large number of merchants. The categorized offers are used in many tasks including product taxonomy browsing and matching merchant offers to products in the catalog. Hence, learning a product classifier with high precision and recall is of fundamental importance in order to provide high quality shopping experience. A product offer typically consists of a short textual description and an image depicting the product. Traditional approaches to this classification task is to learn a classifier using only the textual descriptions of the products. In this paper, we show that the use of images, a weaker signal in our setting, in conjunction with the textual descriptions, a more discriminative signal, can considerably improve the precision of the classification task, irrespective of the type of classifier being used. We present a novel classification approach, \Cross Adapt{} (\CrossAdaptAcro{}), that is cognizant of the disparity in the discriminative power of different types of signals and hence makes use of the confusion matrix of dominant signal (text in our setting) to prudently leverage the weaker signal (image), for an improved performance. Our evaluation performed on data from a major Commerce search engine's catalog shows a 12\% (absolute) improvement in precision at 100\% coverage, and a 16\% (absolute) improvement in recall at 90\% precision compared to classifiers that only use textual description of products. In addition, \CrossAdaptAcro{} also provides a more accurate classifier based only on the dominant signal (text) that can be used in situations in which only the dominant signal is available during application time.

#index 1688495
#* Signature Pattern Covering via Local Greedy Algorithm and Pattern Shrink
#@ Hyungsul Kim;Sungjin Im;Tarek Abdelzaher;Jiawei Han;David Sheridan;Shobha Vasudevan
#t 2011
#c 18
#! Pattern mining is a fundamental problem that has a wide range of applications. In this paper, we study the problem of finding a minimum set of signature patterns that explain all data. In the problem, we are given objects where each object has an item set and a label. A pattern is called a signature pattern if all objects with the pattern have the same label. This problem has many interesting applications such as assertion mining in hardware design and identifying failure causes from various log data. We show that the previous pattern mining methods are not suitable for mining signature patterns and identify the problems. Then we propose a novel pattern enumeration method which we call Pattern Shrink. Our method is strongly coupled with another novel method that is very similar to finding a local optimum with a negligible loss in performance. Our proposed methods show a speedup of more than ten times over the previous methods. Our methods are flexible enough to be extended to mining high confidence patterns, instead of signature patterns.

#index 1688496
#* TWITOBI: A Recommendation System for Twitter Using Probabilistic Modeling
#@ Younghoon Kim;Kyuseok Shim
#t 2011
#c 18
#! Twitter provides search services to help people find new users to follow by recommending popular users or their friends' friends. However, these services do not offer the most relevant users to follow for a user. Furthermore, Twitter does not provide yet the search services to find the most interesting tweet messages for a user either. In this paper, we propose TWITOBI, a recommendation system for Twitter using probabilistic modeling for collaborative filtering which can recommend top-K users to follow and top-K tweets to read for a user. Our novel probabilistic model utilizes not only tweet messages but also the relationships between users. We develop an estimation algorithm for learning our model parameters and present its parallelized algorithm using MapReduce to handle large data. Our performance study with real-life data sets confirms the effectiveness and scalability of our algorithms.

#index 1688497
#* Maximum Entropy Modelling for Assessing Results on Real-Valued Data
#@ Kleanthis-Nikolaos Kontonasios;Jilles Vreeken;Tijl De Bie
#t 2011
#c 18
#! Statistical assessment of the results of data mining is increasingly recognised as a core task in the knowledge discovery process. It is of key importance in practice, as results that might seem interesting at first glance can often be explained by well-known basic properties of the data. In pattern mining, for instance, such trivial results can be so overwhelming in number that filtering them out is a necessity in order to identify the truly interesting patterns. In this paper, we propose an approach for assessing results on real-valued rectangular databases. More specifically, using our analytical model we are able to statistically assess whether or not a discovered structure may be the trivial result of the row and column marginal distributions in the database. Our main approach is to use the Maximum Entropy principle to fit a background model to the data while respecting its marginal distributions. To find these distributions, we employ an MDL based histogram estimator, and we fit these in our model using efficient convex optimization techniques. Subsequently, our model can be used to calculate probabilities directly, as well as to efficiently sample data with the purpose of assessing results by means of empirical hypothesis testing. Notably, our approach is efficient, parameter-free, and naturally deals with missing values. As such, it represents a well-founded alternative to swap randomisation

#index 1688498
#* Local Models for Expectation-Driven Subgroup Discovery
#@ Florian Lemmerich;Frank Puppe
#t 2011
#c 18
#! Subgroup discovery (also known as Pattern Mining or Supervised Descriptive Rule Discovery) searches for descriptions of subsets in a dataset that differ from the total population with respect to a given target concept. In this paper we argue that in the traditional approach potentially interesting complex patterns with an unexpected relative increase of the target share remain undiscovered while on the other hand less surprising patterns are returned. Therefore, we present a generalized approach on subgroup discovery, in which the target share in the subgroup is not compared to the target share in the total population, but to the expectations a user has given the knowledge of more general (simpler) patterns. We claim that the resulting complex patterns are more interesting for the user and are less biased towards simpler patterns with a positive influence on the target concept. In order to estimate these expectations we utilize local models, i.e., fragments of Bayesian Networks. The proposed approach is evaluated using data from the UCI repository as well as on two totally different real world applications that investigate university student drop-out rates and identify spammers in a social book marking system.

#index 1688499
#* Twin Gaussian Processes for Binary Classification
#@ Jianjun He;Hong Gu;Shaorui Jiang
#t 2011
#c 18
#! Gaussian process classifiers (GPCs) have recently attracted more and more attention from the machine learning community. However, because the posterior needs to be approximated by using a tractable Gaussian distribution, they usually suffer from high computational cost which is prohibitive for practical applications. In this paper, we present a new Gaussian process model termed as twin Gaussian processes for binary classification. The basic idea is to make predictions based on two latent functions with Gaussian process prior, each of which is close to one of the two classes and is as far as possible from the other. Being compared with the published GPCs, the proposed algorithm allows for an explicit inference based on analytical methods, thereby avoiding the high computational cost caused by approximating the posterior with Gaussian distribution. Experimental results on several benchmark data sets show that the proposed algorithm is valid and can achieve superior performance to the published algorithms.

#index 1688500
#* Discovering the Intrinsic Cardinality and Dimensionality of Time Series Using MDL
#@ Bing Hu;Thanawin Rakthanmanon;Yuan Hao;Scott Evans;Stefano Lonardi;Eamonn Keogh
#t 2011
#c 18
#! Most algorithms for mining or indexing time series data do not operate directly on the original data, but instead they consider alternative representations that include transforms, quantization, approximation, and multi-resolution abstractions. Choosing the best representation and abstraction level for a given task/dataset is arguably the most critical step in time series data mining. In this paper, we investigate techniques to discover the natural intrinsic representation model, dimensionality and alphabet cardinality of a time series. The ability to discover these intrinsic features has implications beyond selecting the best parameters for particular algorithms, as characterizing data in such a manner is useful in its own right and an important sub-routine in algorithms for classification, clustering and outlier discovery. We will frame the discovery of these intrinsic features in the Minimal Description Length (MDL) framework. Extensive empirical tests show that our method is simpler, more general and significantly more accurate than previous methods, and has the important advantage of being essentially parameter-free.

#index 1688501
#* Discovery of Versatile Temporal Subspace Patterns in 3-D Datasets
#@ Zhen Hu;Raj Bhatnagar
#t 2011
#c 18
#! Most existing methods for clustering temporal data are based on either a strict similarity metric or a precisely defined temporal profile such as a sine, exponential wave etc. Also, these methods compute similarity metric across the entire time-span of the objects. However these types of temporal patterns are more useful in many biological analysis, where it is important to observe gene expression pattens across arbitrary subintervals. These types of temporal patterns are very useful in bioinformatics, where it is important to observe gene expression pattens across arbitrary subintervals. In this paper we present an algorithm for searching for multiple contiguous temporal subintervals within which the selected objects demonstrate existence of clear patterns. We demonstrate the power and advantages of our algorithm by using a synthetic dataset and a pharmacokinetics dataset for which other researchers have recently published their results. We compare and contrast our results with these results to show superiority of our approach.

#index 1688502
#* A Fixed Parameter Tractable Integer Program for Finding the Maximum Order Preserving Submatrix
#@ Jens Humrich;Thomas Gartner;Gemma C. Garriga
#t 2011
#c 18
#! Order-preserving sub matrices are an important tool for the analysis of gene expression data. As finding large order-preserving sub matrices is a computationally hard problem, previous work has investigated both exact but exponential-time as well as polynomial-time but inexact algorithms for finding large order-preserving sub matrices. In this paper, we propose a novel exact algorithm to find maximum order preserving sub matrices which is fixed parameter tractable with respect to the number of columns of the provided gene expression data. In particular, our algorithm is based on solving a sequence of mixed integer linear programs and it exhibits better guarantees as well as better runtime performance as compared to the state-of-the-art exact algorithms. Our empirical study in benchmark datasets shows large improvement in terms of computational speed.

#index 1688503
#* ASAP: A Self-Adaptive Prediction System for Instant Cloud Resource Demand Provisioning
#@ Yexi Jiang;Chang-shing Perng;Tao Li;Rong Chang
#t 2011
#c 18
#! The promise of cloud computing is to provide computing resources instantly whenever they are needed. The state-of-art virtual machine (VM) provisioning technology can provision a VM in tens of minutes. This latency is unacceptable for jobs that need to scale out during computation. To truly enable on-the-fly scaling, new VM needs to be ready in seconds upon request. In this paper, We present an online temporal data mining system called ASAP, to model and predict the cloud VM demands. ASAP aims to extract high level characteristics from VM provisioning request stream and notify the provisioning system to prepare VMs in advance. For quantification issue, we propose Cloud Prediction Cost to encodes the cost and constraints of the cloud and guide the training of prediction algorithms. Moreover, we utilize a two-level ensemble method to capture the characteristics of the high transient demands time series. Experimental results using historical data from an IBM cloud in operation demonstrate that ASAP significantly improves the cloud service quality and provides possibility for on-the-fly provisioning.

#index 1688504
#* Learning from Negative Examples in Set-Expansion
#@ Prateek Jindal;Dan Roth
#t 2011
#c 18
#! This paper addresses the task of set-expansion on free text. Set-expansion has been viewed as a problem of generating an extensive list of instances of a concept of interest, given a few examples of the concept as input. Our key contribution is that we show that the concept definition can be significantly improved by specifying some negative examples in the input, along with the positive examples. The state-of-the art centroid-based approach to set-expansion doesn't readily admit the negative examples. We develop an inference-based approach to set-expansion which naturally allows for negative examples and show that it performs significantly better than a strong baseline.

#index 1688505
#* Context-Aware Multi-instance Learning Based on Hierarchical Sparse Representation
#@ Bing Li;Weihua Xiong;Weiming Hu
#t 2011
#c 18
#! Multi-instance learning (MIL), a variant of supervised learning framework, has been applied in many applications. More recently, researchers focus on two important issues for MIL: Instances' contextual structures representation in the same bag and online MIL schemes. In this paper, we present an effective context-aware multi-instance learning technique using a hierarchical sparse representation (HSR-MIL) that addresses the two challenges simultaneously. We firstly construct the inner contextual structure among instances in the same bag based on a novel sparse $\varepsilon$-graph. We then propose a graph kernel based sparse bag classifier through a modified kernel sparse coding in higher-dimension feature space. At last, the HSR-MIL approach is extended to achieve online learning manner with an incremental kernel matrix update scheme. The experiments on several data sets demonstrate that our method has better performances and online learning ability.

#index 1688506
#* The Joint Inference of Topic Diffusion and Evolution in Social Communities
#@ Cindy Xide Lin;Qiaozhu Mei;Jiawei Han;Yunliang Jiang;Marina Danilevsky
#t 2011
#c 18
#! The prevalence of Web 2.0 techniques has led to the boom of various online communities, where topics spread ubiquitously among user-generated documents. Working together with this diffusion process is the evolution of topic content, where novel contents are introduced by documents which adopt the topic. Unlike explicit user behavior (e.g., buying a DVD), both the diffusion paths and the evolutionary process of a topic are implicit, making their discovery challenging. In this paper, we track the evolution of an arbitrary topic and reveal the latent diffusion paths of that topic in a social community. A novel and principled probabilistic model is proposed which casts our task as an joint inference problem, which considers textual documents, social influences, and topic evolution in a unified way. Specifically, a mixture model is introduced to model the generation of text according to the diffusion and the evolution of the topic, while the whole diffusion process is regularized with user-level social influences through a Gaussian Markov Random Field. Experiments on both synthetic data and real world data show that the discovery of topic diffusion and evolution benefits from this joint inference, and the probabilistic model we propose performs significantly better than existing methods.

#index 1688507
#* Towards Optimal Discriminating Order for Multiclass Classification
#@ Dong Liu;Shuicheng Yan;Yadong Mu;Xian-Sheng Hua;Shih-Fu Chang;Hong-Jiang Zhang
#t 2011
#c 18
#! In this paper, we investigate how to design an optimized discriminating order for boosting multiclass classification. The main idea is to optimize a binary tree architecture, referred to as Sequential Discriminating Tree (SDT), that performs the multiclass classification through a hierarchical sequence of coarse-to-fine binary classifiers. To infer such a tree architecture, we employ the constrained large margin clustering procedure which enforces samples belonging to the same class to locate at the same side of the hyper plane while maximizing the margin between these two partitioned class subsets. The proposed SDT algorithm has a theoretic error bound which is shown experimentally to effectively guarantee the generalization performance. Experiment results indicate that SDT clearly beats the state-of-the-art multiclass classification algorithms.

#index 1688508
#* A Hypergraph-based Method for Discovering Semantically Associated Itemsets
#@ Haishan Liu;Paea Le Pendu;Ruoming Jin;Dejing Dou
#t 2011
#c 18
#! In this paper, we address an interesting data mining problem of finding semantically associated item sets, i.e., items connected via indirect links. We propose a novel method for discovering semantically associated item sets based on a hyper graph representation of the database. We describe two similarity measures to compute the strength of associations between items. Specifically, we introduce the average commute time similarity, $\mathbf{s_{CT}}$, based on the random walk model on hyper graph, and the inner-product similarity, $\mathbf{s_{L+}}$, based on the Moore-Penrose pseudoinverse of the hyper graph Laplacian matrix. Given semantically associated 2-itemsets generated by these measures, we design a hyper graph expansion method with two search strategies, namely, the clique and connected component search, to generate $k$-item sets ($k2$). We show the proposed method is indeed capable of capturing semantically associated item sets through experiments performed on three datasets ranging from low to high dimensionality. The semantically associated item sets discovered in our experiment is promising to provide valuable insights on interrelationship between medical concepts and other domain specific concepts.

#index 1688509
#* Personalized Travel Package Recommendation
#@ Qi Liu;Yong Ge;Zhongmou Li;Enhong Chen;Hui Xiong
#t 2011
#c 18
#! As the worlds of commerce, entertainment, travel, and Internet technology become more inextricably linked, new types of business data become available for creative use and formal analysis. Indeed, this paper provides a study of exploiting online travel information for personalized travel package recommendation. A critical challenge along this line is to address the unique characteristics of travel data, which distinguish travel packages from traditional items for recommendation. To this end, we first analyze the characteristics of the travel packages and develop a Tourist-Area-Season Topic (TAST) model, which can extract the topics conditioned on both the tourists and the intrinsic features (i.e. locations, travel seasons) of the landscapes. Based on this TAST model, we propose a cocktail approach on personalized travel package recommendation. Finally, we evaluate the TAST model and the cocktail approach on real-world travel package data. The experimental results show that the TAST model can effectively capture the unique characteristics of the travel data and the cocktail approach is thus much more effective than traditional recommendation methods for travel package recommendation.

#index 1688510
#* Entropy-Based Graph Clustering: Application to Biological and Social Networks
#@ Edward Casey Kenley;Young-Rae Cho
#t 2011
#c 18
#! Complex systems have been widely studied to characterize their structural behaviors from a topological perspective. High modularity is one of the recurrent features of real-world complex systems. Various graph clustering algorithms have been applied to identifying communities in social networks or modules in biological networks. However, their applicability to real-world systems has been limited because of the massive scale and complex connectivity of the networks. In this study, we exploit a novel information-theoretic model for graph clustering. The entropy-based clustering approach finds locally optimal clusters by growing a random seed in a manner that minimizes graph entropy. We design and analyze modifications that further improve its performance. Assigning priority in seed-selection and seed-growth is well applicable to the scale-free networks characterized by the hub-oriented structure. Computing seed-growth in parallel streams also decomposes an extremely large network efficiently. The experimental results with real biological and social networks show that the entropy-based approach has better performance than competing methods in terms of accuracy and efficiency.

#index 1688511
#* Semi-supervised Discriminant Hashing
#@ Saehoon Kim;Seungjin Choi
#t 2011
#c 18
#! Hashing refers to methods for embedding high dimensional data into a similarity-preserving low-dimensional Hamming space such that similar objects are indexed by binary codes whose Hamming distances are small. Learning hash functions from data has recently been recognized as a promising approach to approximate nearest neighbor search for high dimensional data. Most of 隆®learning to hash' methods resort to either unsupervised or supervised learning to determine hash functions. Recently semi-supervised learning approach was introduced in hashing where pair wise constraints (must link and cannot-link) using labeled data are leveraged while unlabeled data are used for regularization to avoid over-fitting. In this paper we base our semi-supervised hashing on linear discriminant analysis, where hash functions are learned such that labeled data are used to maximize the separability between binary codes associated with different classes while unlabeled data are used for regularization as well as for balancing condition and pair wise decor relation of bits. The resulting method is referred to as semi-supervised discriminant hashing (SSDH). Numerical experiments on MNIST and CIFAR-10 datasets demonstrate that our method outperforms existing methods, especially in the case of short binary codes.

#index 1688512
#* Using Frequent Closed Itemsets for Data Dimensionality Reduction
#@ Petr Krajca;Jan Outrata;Vilem Vychodil
#t 2011
#c 18
#! We address important issues of dimensionality reduction of transactional data sets where the input data consists of lists of transactions, each of them being a finite set of items. The reduction consists in finding a small set of new items, so-called factor-items, which is considerably smaller than the original set of items while comprising full or nearly full information about the original items. Using this type of reduction, the original data set can be represented by a smaller transactional data set using factor-items instead of the original items, thus reducing its dimensionality. The procedure utilized in this paper is based on approximate Boolean matrix decomposition. In this paper, we focus on the role of frequent closed item sets that can be used to determine factor-items. We present the factorization problem, its reduction to Boolean matrix decompositions, experiments with publicly available data sets, and an algorithm for computing decompositions.

#index 1688513
#* Modeling High-Level Behavior Patterns for Precise Similarity Analysis of Software
#@ Taeho Kwon;Zhendong Su
#t 2011
#c 18
#! The analysis of software similarity has many applications such as detecting code clones, software plagiarism, code theft, and polymorphic malware. Because often source code is unavailable and code obfuscation is used to avoid detection, there has been much research on developing effective models to capture runtime behavior to aid detection. Existing models focus on low-level information such as dependency or purely occurrence of function calls, and suffer from poor precision, poor scalability, or both. To overcome limitations of existing models, this paper introduces a precise and succinct behavior representation that characterizes high-level object-accessing patterns as regular expressions. We first distill a set of high-level patterns (the alphabet S of the regular language) based on two pieces of information: function call patterns to access objects and type state information of the objects. Then we abstract a runtime trace of a program P into a regular expression e over the pattern alphabet S to produce P's behavior signature. We show that software instances derived from the same code exhibit similar behavior signatures and develop effective algorithms to cluster and match behavior signatures. To evaluate the effectiveness of our behavior model, we have applied it to the similarity analysis of polymorphic malware. Our results on a large malware collection demonstrate that our model is both precise and succinct for effective and scalable matching and detection of polymorphic malware.

#index 1688514
#* Co-clustering for Binary and Categorical Data with Maximum Modularity
#@ Lazhar Labiod;Mohamed Nadif
#t 2011
#c 18
#! To tackle the co-clustering problem for binary and categorical data, we propose a generalized modularity measure and a spectral approximation of the modularity matrix. A spectral algorithm maximizing the modularity measure is then presented. Experimental results are performed on a variety of simulated and real-world data sets confirming the interest of the use of the modularity in co-clustering and assessing the number of clusters contexts.

#index 1688515
#* Tag Clustering and Refinement on Semantic Unity Graph
#@ Yang Liu;Fei Wu;Yin Zhang;Jian Shao;Yueting Zhuang
#t 2011
#c 18
#! Recently, there has been extensive research towards the user-provided tags on photo sharing websites which can greatly facilitate image retrieval and management. However, due to the arbitrariness of the tagging activities, these tags are often imprecise and incomplete. As a result, quite a few technologies has been proposed to improve the user experience on these photo sharing systems, including tag clustering and refinement, etc. In this work, we propose a novel framework to model the relationships among tags and images which can be applied to many tag based applications. Different from previous approaches which model images and tags as heterogeneous objects, images and their tags are uniformly viewed as compositions of Semantic Unities in our framework. Then Semantic Unity Graph (SUG) is introduced to represent the complex and high-order relationships among these Semantic Unities. Based on the representation of Semantic Unity Graph, the relevance of images and tags can be naturally measured in terms of the similarity of their Semantic Unities. Then Tag clustering and refinement can then be performed on SUG and the polysemy of images and tags is explicitly considered in this framework. The experiment results conducted on NUS-WIDE and MIR-Flickr datasets demonstrate the effectiveness and efficiency of the proposed approach.

#index 1688516
#* Minimizing Seed Set for Viral Marketing
#@ Cheng Long;Raymond Chi-Wing Wong
#t 2011
#c 18
#! Viral marketing has attracted considerable concerns in recent years due to its novel idea of leveraging the social network to propagate the awareness of products. Specifically, viral marketing is to first target a limited number of users (seeds) in the social network by providing incentives, and these targeted users would then initiate the process of awareness spread by propagating the information to their friends via their social relationships. Extensive studies have been conducted for maximizing the awareness spread given the number of seeds. However, all of them fail to consider the common scenario of viral marketing where companies hope to use as few seeds as possible yet influencing at least a certain number of users. In this paper, we propose a new problem, called J-MIN-Seed, whose objective is to minimize the number of seeds while at least J users are influenced. J-MIN-Seed, unfortunately, is proved to be NP-hard in this work. In such case, we develop a greedy algorithm that can provide error guarantees for J-MIN-Seed. Furthermore, for the problem setting where J is equal to the number of all users in the social network, denoted by Full-Coverage, we design other efficient algorithms. Extensive experiments were conducted on real datasets to verify our algorithm.

#index 1688517
#* Privacy Risk in Graph Stream Publishing for Social Network Data
#@ Nigel Medforth;Ke Wang
#t 2011
#c 18
#! To understand how social networks evolve over time, graphs representing the networks need to be published periodically or on-demand. The identity of the participants (nodes) must be anonymized to protect the privacy of the individuals and their relationships (edges) to the other members in the social network. We identify a new form of privacy attack, which we name the degree-trail attack. This attack re-identifies the nodes belonging to a target participant from a sequence of published graphs by comparing the degree of the nodes in the published graphs with the degree evolution of a target. The power of this attack is that the adversary can actively influence the degree of the target individual by interacting with the social network. We show that the adversary can succeed with a high probability even if published graphs are anonymized by strongest known privacy preserving techniques in the literature. Moreover, this success does not depend on the distinctiveness of the target nodes nor require the adversary to behave differently from a normal participant. One of our contributions is a formal method to assess the privacy risk of this type of attacks and empirically study the severity on real social network data.

#index 1688518
#* Boolean Tensor Factorizations
#@ Pauli Miettinen
#t 2011
#c 18
#! Tensors are multi-way generalizations of matrices, and similarly to matrices, they can also be factorized, that is, represented (approximately) as a product of factors. These factors are typically either all matrices or a mixture of matrices and tensors. With the widespread adoption of matrix factorization techniques in data mining, also tensor factorizations have started to gain attention. In this paper we study the Boolean tensor factorizations. We assume that the data is binary multi-way data, and we want to factorize it to binary factors using Boolean arithmetic (i.e. defining that 1+1=1). Boolean tensor factorizations are, therefore, natural generalization of the Boolean matrix factorizations. We will study the theory of Boolean tensor factorizations and show that at least some of the benefits Boolean matrix factorizations have over normal matrix factorizations carry over to the tensor data. We will also present algorithms for Boolean variations of CP and Tucker decompositions, the two most-common types of tensor factorizations. With experimentation done with synthetic and real-world data, we show that Boolean tensor factorizations are a viable alternative when the data is naturally binary.

#index 1688519
#* Sparse Domain Adaptation in Projection Spaces Based on Good Similarity Functions
#@ Emilie Morvant;Amaury Habrard;Stephane Ayache
#t 2011
#c 18
#! We address the problem of domain adaptation for binary classification which arises when the distributions generating the source learning data and target test data are somewhat different. We consider the challenging case where no target labeled data is available. From a theoretical standpoint, a classifier has better generalization guarantees when the two domain marginal distributions are close. We study a new direction based on a recent framework of Balcan et al. allowing to learn linear classifiers in an explicit projection space based on similarity functions that may be not symmetric and not positive semi-definite. We propose a general method for learning a good classifier on target data with generalization guarantees and we improve its efficiency thanks to an iterative procedure by reweighting the similarity function - compatible with Balcan et al. framework - to move closer the two distributions in a new projection space. Hyper parameters and reweighting quality are controlled by a reverse validation procedure. Our approach is based on a linear programming formulation and shows good adaptation performances with very sparse models. We evaluate it on a synthetic problem and on real image annotation task.

#index 1688520
#* Calculating Feature Weights in Naive Bayes with Kullback-Leibler Measure
#@ Chang-Hwan Lee;Fernando Gutierrez;Dejing Dou
#t 2011
#c 18
#! Naive Bayesian learning has been popular in data mining applications. However, the performance of naive Bayesian learning is sometimes poor due to the unrealistic assumption that all features are equally important and independent given the class value. Therefore, it is widely known that the performance of naive Bayesian learning can be improved by mitigating this assumption, and many enhancements to the basic naive Bayesian learning have been proposed to resolve this problem including feature selection and feature weighting. In this paper, we propose a new method for calculating the weights of features in naive Bayesian learning using Kullback-Leibler measure. Empirical results are presented comparing this new feature weighting method with some other methods for a number of datasets.

#index 1688521
#* Scalable Diversified Ranking on Large Graphs
#@ Rong-Hua Li;Jeffery Xu Yu
#t 2011
#c 18
#! Enhancing diversity in ranking on graphs has been identified as an important retrieval and mining task. Nevertheless, many existing diversified ranking algorithms cannot be scalable to large graphs as they have high time or space complexity. In this paper, we propose a scalable algorithm to find the top-K diversified ranking list on graphs. The key idea of our algorithm is that we first compute the Page rank of the nodes of the graph, and then perform a carefully designed vertex selection algorithm to find the top-K diversified ranking list. Specifically, we firstly present a new diversified ranking measure, which can capture both \emph{relevance} and \emph{diversity}. Secondly, we prove the sub modularity of the proposed measure. And then we propose an efficient greedy algorithm with linear time and space complexity with respect to the size of the graph to achieve near-optimal diversified ranking. Finally, we evaluate the proposed method through extensive experiments on four real networks. The experimental results indicate that the proposed method outperforms existing diversified ranking algorithms both on improving diversity in ranking and the efficiency of the algorithms.

#index 1688522
#* Web Horror Image Recognition Based on Context-Aware Multi-instance Learning
#@ Bing Li;Weihua Xiong;Weiming Hu
#t 2011
#c 18
#! Along with the ever-growing Web, horror contents sharing in the Internet has interfered with our daily life and affected our, especially children's, health. Therefore horror image recognition is becoming more important for web objectionable content filtering. This paper presents a novel context-aware multi-instance learning (CMIL) model for this task. This work is distinguished by three key contributions. Firstly, the traditional multi-instance learning is extended to context-aware multi-instance learning model through integrating an undirected graph in each bag that represents contextual relationships among instances. Secondly, by introducing a novel energy function, a heuristic optimization algorithm based on Fuzzy Support Vector Machine (FSVM) is given out to find the optimal classifier on CMIL. Finally, the CMIL is applied to recognize horror images. Experimental results on an image set collected from the Internet show that the proposed method is effective on horror image recognition.

#index 1688523
#* Mixture of Softmax sLDA
#@ Xiaoxu Li;Junyu Zeng;Xiaojie Wang;Yixin Zhong
#t 2011
#c 18
#! In this paper, we propose a new variant of supervised Latent Dirichlet Allocation(sLDA): mixture of soft max sLDA, for image classification. Ensemble classification methods can combine multiple weak classifiers to construct a strong classifier. Inspired by the ensemble idea, we try to improve sLDA model using the idea. The mixture of soft max model is a probabilistic ensemble classification model, it can fit the training data and class label well. We embed the mixture of soft max model into LDA model under the framwork of sLDA, and construct an ensemble supervised topic model for image classification. Meanwhile, we derive an elegant parameters estimation algorithm based on variational EM method, and give a simple and efficient approximation method for classifying a new image. Finally, we demonstrate the effectiveness of our model by comparing with some existing approaches on two real world datasets. The results show that our model enhances classification accuracy by 7% on the 1600-image Label Me dataset and 9% on the 1791-image UIUC-Sport dataset.

#index 1688524
#* Optimizing Performance Measures for Feature Selection
#@ Qi Mao;Ivor Wai-Hung Tsang
#t 2011
#c 18
#! Feature selection with specific multivariate performance measures is the key to the success of many applications, such as information retrieval and bioinformatics. The existing feature selection methods are usually designed for classification error. In this paper, we present a unified feature selection framework for general loss functions. In particular, we study the novel feature selection paradigm by optimizing multivariate performance measures. The resultant formulation is a challenging problem for high-dimensional data. Hence, a two-layer cutting plane algorithm is proposed to solve this problem, and the convergence is presented. Extensive experiments on large-scale and high-dimensional real world datasets show that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a small subset of features, and achieves significantly improved performances over SVM$^{perf}$ in terms of $F_1$-score.

#index 1688525
#* Helix: Unsupervised Grammar Induction for Structured Activity Recognition
#@ Huan-Kai Peng;Pang Wu;Jiang Zhu;Joy Ying Zhang
#t 2011
#c 18
#! The omnipresence of mobile sensors has brought tremendous opportunities to ubiquitous computing systems. In many natural settings, however, their broader applications are hindered by three main challenges: rarity of labels, uncertainty of activity granularities, and the difficulty of multi-dimensional sensor fusion. In this paper, we propose building a grammar to address all these challenges using a language-based approach. The proposed algorithm, called Helix, first generates an initial vocabulary using unlabeled sensor readings, followed by iteratively combining statistically collocated sub-activities across sensor dimensions and grouping similar activities together to discover higher level activities. The experiments using a 20-minute ping-pong game demonstrate favorable results compared to a Hierarchical Hidden Markov Model (HHMM) baseline. Closer investigations to the learned grammar also shows that the learned grammar captures the natural structure of the underlying activities.

#index 1688526
#* Incremental Elliptical Boundary Estimation for Anomaly Detection in Wireless Sensor Networks
#@ Masud Moshtaghi;Christopher Leckie;Shanika Karunasekera;James C. Bezdek;Sutharshan Rajasegarar;Marimuthu Palaniswami
#t 2011
#c 18
#! Wireless Sensor Networks (WSNs) provide a low cost option for gathering spatially dense data from different environments. However, WSNs have limited energy resources that hinder the dissemination of the raw data over the network to a central location. This has stimulated research into efficient data mining approaches, which can exploit the restricted computational capabilities of the sensors to model their normal behavior. Having a normal model of the network, sensors can then forward anomalous measurements to the base station. Most of the current data modeling approaches proposed for WSNs require a fixed offline training period and use batch training in contrast to the real streaming nature of data in these networks. In addition they usually work in stationary environments. In this paper we present an efficient online model construction algorithm that captures the normal behavior of the system. Our model is capable of tracking changes in the data distribution in the monitored environment. We illustrate the proposed algorithm with numerical results on both real-life and simulated data sets, which demonstrate the efficiency and accuracy of our approach compared to existing methods.

#index 1688527
#* Learning Classification with Auxiliary Probabilistic Information
#@ Quang Nguyen;Hamed Valizadegan;Milos Hauskrecht
#t 2011
#c 18
#! Finding ways of incorporating auxiliary information or auxiliary data into the learning process has been the topic of active data mining and machine learning research in recent years. In this work we study and develop a new framework for classification learning problem in which, in addition to class labels, the learner is provided with an auxiliary (probabilistic) information that reflects how strong the expert feels about the class label. This approach can be extremely useful for many practical classification tasks that rely on subjective label assessment and where the cost of acquiring additional auxiliary information is negligible when compared to the cost of the example analysis and labelling. We develop classification algorithms capable of using the auxiliary information to make the learning process more efficient in terms of the sample complexity. We demonstrate the benefit of the approach on a number of synthetic and real world data sets by comparing it to the learning with class labels only.

#index 1688528
#* Word Cloud Model for Text Categorization
#@ Tam T. Nguyen;Kuiyu Chang;Siu Cheung Hui
#t 2011
#c 18
#! In centroid-based classification, each class is represented by a prototype or centroid document vector that is formed by averaging all member vectors during the training phase. In the prediction phase, the label of a test document vector is assigned to that of its nearest class prototype. Recently there has been revived interest in reformulating the prototype/centroid to improve classification performance. In this paper, we study the theoretical properties of the recently proposed Class Feature Centroid (CFC) classifier by considering the rate of change of each prototype vector with respect to individual dimensions (terms). The implication of our theoretical finding is that CFC is inherently biased towards large (dominant majority) classes, which means it is destined to perform poorly for highly class-imbalanced data. Another practical concern about CFC lies in its overly-aggressive design in weeding out terms that appear in all classes. To overcome these CFC limitations while retaining its intrinsic and worthy design goals, we propose an improved and robust centroid-based classifier that uses precise term-class distribution properties instead of simple presence or absence of terms in classes. Specifically, terms are weighted based on the Kullback-Leibler divergence measure between pairs of class-conditional term probabilities, we call this the CFC-KL centroid classifier. We then generalized CFC-KL to handle multi-class data by summing pair wise class-conditioned word probability ratios. Our proposed approach has been evaluated on 5 datasets, on which it consistently outperforms CFC and the baseline Support Vector Machine classifier. We also devise a word cloud visualization approach to highlight the important class-specific words picked out by our CFC-KL, and visually compare it with other popular term weigthing approaches. Our encouraging results show that the centroid based generalized CFC-KL classifier is both robust and efficient to deal with real-world text classification.

#index 1688529
#* SLIM: Sparse Linear Methods for Top-N Recommender Systems
#@ Xia Ning;George Karypis
#t 2011
#c 18
#! This paper focuses on developing effective and efficient algorithms for top-N recommender systems. A novel Sparse Linear Method (SLIM) is proposed, which generates top-N recommendations by aggregating from user purchase/rating profiles. A sparse aggregation coefficient matrix W is learned from SLIM by solving an `1-norm and `2-norm regularized optimization problem. W is demonstrated to produce high quality recommendations and its sparsity allows SLIM to generate recommendations very fast. A comprehensive set of experiments is conducted by comparing the SLIM method and other state-of-the-art top-N recommendation methods. The experiments show that SLIM achieves significant improvements both in run time performance and recommendation quality over the best existing methods.

#index 1688530
#* Novel Recommendation Based on Personal Popularity Tendency
#@ Jinoh Oh;Sun Park;Hwanjo Yu;Min Song;Seung-Taek Park
#t 2011
#c 18
#! Recently, novel recommender systems have attracted considerable attention in the research community. Recommending popular items may not always satisfy users. For example, although most users likely prefer popular items, such items are often not very surprising or novel because users may already know about the items. Also, such recommender systems hardly satisfy a group of users who prefer relatively obscure items. Existing novel recommender systems, however, still recommend mainly popular items or degrade the quality of recommendation. They do so because they do not consider the balance between novelty and preference-based recommendation. This paper proposes an efficient novel-recommendation method called Personal Popularity Tendency Matching (PPTM) which recommends novel items by considering an individual's Personal Popularity Tendency (or PPT). Considering PPT helps to diversify recommendations by reasonably penalizing popular items while improving the recommendation accuracy. We experimentally show that the proposed method, PPTM, is better than other methods in terms of both novelty and accuracy.

#index 1688531
#* Detecting Recurring and Novel Classes in Concept-Drifting Data Streams
#@ Mohammad M. Masud;Tahseen M. Al-Khateeb;Latifur Khan;Charu Aggarwal;Jing Gao;Jiawei Han;Bhavani Thuraisingham
#t 2011
#c 18
#! Concept-evolution is one of the major challenges in data stream classification, which occurs when a new class evolves in the stream. This problem remains unaddressed by most state-of-the-art techniques. A recurring class is a special case of concept-evolution. This special case takes place when a class appears in the stream, then disappears for a long time, and again appears. Existing data stream classification techniques that address the concept-evolution problem, wrongly detect the recurring classes as novel class. This creates two main problems. First, much resource is wasted in detecting a recurring class as novel class, because novel class detection is much more computationally- and memory-intensive, as compared to simply recognizing an existing class. Second, when a novel class is identified, human experts are involved in collecting and labeling the instances of that class for future modeling. If a recurrent class is reported as novel class, it will be only a waste of human effort to find out whether it is really a novel class. In this paper, we address the recurring issue, and propose a more realistic novel class detection technique, which remembers a class and identifies it as "not novel" when it reappears after a long disappearance. Our approach has shown significant reduction in classification error over state-of-the-art stream classification techniques on several benchmark data streams.

#index 1688532
#* Performances and Characteristics of DIGRank, Ranking in the Incomplete Networks
#@ Xiang Niu;Lusong Li;Xiaobing Xiong;Daniel Tkach;He Li;Ke Xu
#t 2011
#c 18
#! Page Rank has been widely used in ranking retrieval results on the web, finding the top influential papers in citation networks or detecting valuable users in online social networks. However, in practice, it is usually hard to obtain a complete structure of any above networks to rank nodes. Thus, some researchers have begun to explore how to get estimated ranks efficiently without acquiring the whole network. They have proposed some approximating methods, however, it is difficult to determine which method is the best one or which is suitable to a certain application. In this case, we set experiments in small-world and scale-free generated networks to certify the feasibility and characteristics of four approximating methods. We also use eleven real networks to mention different optimal conditions for these methods. We find the DIG Rank method performs better than other local estimation methods in almost every given sub graph. Besides, Mean field approach method tends to perform well in networks that have low average shortest path length, small amount of nodes with the same low in degree, or weak community structure. Finally, we apply the most versatile method DIG Rank to Sina micro-blog website to precisely classify users in a group as elites, grassroots or mummy users.

#index 1688533
#* Cross-Temporal Link Prediction
#@ Satoshi Oyama;Kohei Hayashi;Hisashi Kashima
#t 2011
#c 18
#! The increasing interest in dynamically changing networks has led to growing interest in a more general link prediction problem called temporal link prediction in the data mining and machine learning communities. However, only links in identical time frames are considered in temporal link prediction. We propose a new link prediction problem called cross-temporal link prediction in which the links among nodes in different time frames are inferred. A typical example of cross-temporal link prediction is cross-temporal entity resolution to determine the identity of real entities represented by data objects observed in different time periods. In dynamic environments, the features of data change over time, making it difficult to identify cross-temporal links by directly comparing observed data. Other examples of cross-temporal links are asynchronous communications in social networks such as Face book and Twitter, where a message is posted in reply to a previous message. We adopt a dimension reduction approach to cross-temporal link prediction, that is, data objects in different time frames are mapped into a common low-dimensional latent feature space, and the links are identified on the basis of the distance between the data objects. The proposed method uses different low-dimensional feature projections in different time frames, enabling it to adapt to changes in the latent features over time. Using multi-task learning, it jointly learns a set of feature projection matrices from the training data, given the assumption of temporal smoothness of the projections. The optimal solutions are obtained by solving a single generalized eigenvalue problem. Experiments using a real-world set of bibliographic data for cross-temporal entity resolution showed that introducing time-dependent feature projections improves the accuracy of link prediction.

#index 1688534
#* Distance Preserving Graph Simplification
#@ Ning Ruan;Ruoming Jin;Yan Huang
#t 2011
#c 18
#! Large graphs are difficult to represent, visualize, and understand. In this paper, we introduce â聙聹gate graphâ聙聺 - a new approach to perform graph simplification. A gate graph provides a simplified topological view of the original graph. Specifically, we construct a gate graph from a large graph so that for any â聙聹non-localâ聙聺 vertex pair (distance greater than some threshold) in the original graph, their shortest-path distance can be recovered by consecutive â聙聹localâ聙聺 walks through the gate vertices in the gate graph. We perform a theoretical investigation on the gate-vertex set discovery problem. We characterize its computational complexity and reveal the upper bound of minimum gate vertex set using VC-dimension theory. We propose an efficient mining algorithm to discover a gate-vertex set with guaranteed logarithmic bound. The detailed experimental results using both real and synthetic graphs demonstrate the effectiveness and efficiency of our approach.

#index 1688535
#* Clustering with Attribute-Level Constraints
#@ Jana Schmidt;Elisabeth Maria Brandle;Stefan Kramer
#t 2011
#c 18
#! In many clustering applications the incorporation of background knowledge in the form of constraints is desirable. In this paper, we introduce a new constraint type and the corresponding clustering problem: attribute constrained clustering. The goal is to induce clusters of binary instances that satisfy constraints on the attribute level. These constraints specify whether instances may or may not be grouped to a cluster, depending on specific attribute values. We show how the well-established instance-level constraints, must-link and cannot-link, can be adapted to the attribute level. A variant of the k-Medoids algorithm taking into account attribute level constraints is evaluated on synthetic and real-world data. Experimental results show that such constraints may provide better clustering results at lower specification costs if constraints can be expressed on the attribute level.

#index 1688536
#* An Analysis of Performance Measures for Binary Classifiers
#@ Charles Parker
#t 2011
#c 18
#! If one is given two binary classifiers and a set of test data, it should be straightforward to determine which of the two classifiers is the superior. Recent work, however, has called into question many of the methods heretofore accepted as standard for this task. In this paper, we analyze seven ways of determining if one classifier is better than another, given the same test data. Five of these are long established and two are relative newcomers. We review and extend work showing that one of these methods is clearly inappropriate, and then conduct an empirical analysis with a large number of datasets to evaluate the real-world implications of our theoretical analysis. Both our empirical and theoretical results converge strongly towards one of the newer methods.

#index 1688537
#* Detection of Cross-Channel Anomalies from Multiple Data Channels
#@ Duc Son Pham;Budhaditya Saha;Dinh Q. Phung;Svetha Venkatesh
#t 2011
#c 18
#! We identify and formulate a novel problem: cross channel anomaly detection from multiple data channels. Cross channel anomalies are common amongst the individual channel anomalies, and are often portent of significant events. Using spectral approaches, we propose a two-stage detection method: anomaly detection at a single-channel level, followed by the detection of cross-channel anomalies from the amalgamation of single channel anomalies. Our mathematical analysis shows that our method is likely to reduce the false alarm rate. We demonstrate our method in two applications: document understanding with multiple text corpora, and detection of repeated anomalies in video surveillance. The experimental results consistently demonstrate the superior performance of our method compared with related state-of-art methods, including the one-class SVM and principal component pursuit. In addition, our framework can be deployed in a decentralized manner, lending itself for large scale data stream analysis.

#index 1688538
#* Threshold Conditions for Arbitrary Cascade Models on Arbitrary Networks
#@ B. Aditya Prakash;Deepayan Chakrabarti;Michalis Faloutsos;Nicholas Valler;Christos Faloutsos
#t 2011
#c 18
#! Given a network of who-contacts-whom or who links-to-whom, will a contagious virus/product/meme spread and 'take-over' (cause an epidemic) or die-out quickly? What will change if nodes have partial, temporary or permanent immunity? The epidemic threshold is the minimum level of virulence to prevent a viral contagion from dying out quickly and determining it is a fundamental question in epidemiology and related areas. Most earlier work focuses either on special types of graphs or on specific epidemiological/cascade models. We are the first to show the G2-threshold (twice generalized) theorem, which nicely de-couples the effect of the topology and the virus model. Our result unifies and includes as special case older results and shows that the threshold depends on the first eigenvalue of the connectivity matrix, (a) for any graph and (b) for all propagation models in standard literature (more than 25, including H.I.V.) [20], [12]. Our discovery has broad implications for the vulnerability of real, complex networks, and numerous applications, including viral marketing, blog dynamics, influence propagation, easy answers to 'what-if' questions, and simplified design and evaluation of immunization policies. We also demonstrate our result using extensive simulations on one of the biggest available social contact graphs containing more than 31 million interactions among more than 1 million people representing the city of Portland, Oregon, USA.

#index 1688539
#* Time Series Epenthesis: Clustering Time Series Streams Requires Ignoring Some Data
#@ Thanawin Rakthanmanon;Eamonn J. Keogh;Stefano Lonardi;Scott Evans
#t 2011
#c 18
#! Given the pervasiveness of time series data in all human endeavors, and the ubiquity of clustering as a data mining application, it is somewhat surprising that the problem of time series clustering from a single stream remains largely unsolved. Most work on time series clustering considers the clustering of individual time series, e.g., gene expression profiles, individual heartbeats or individual gait cycles. The few attempts at clustering time series streams have been shown to be objectively incorrect in some cases, and in other cases shown to work only on the most contrived datasets by carefully adjusting a large set of parameters. In this work, we make two fundamental contributions. First, we show that the problem definition for time series clustering from streams currently used is inherently flawed, and a new definition is necessary. Second, we show that the Minimum Description Length (MDL) framework offers an efficient, effective and essentially parameter-free method for time series clustering. We show that our method produces objectively correct results on a wide variety of datasets from medicine, zoology and industrial process analyses.

#index 1688540
#* Mining Historical Documents for Near-Duplicate Figures
#@ Thanawin Rakthanmanon;Qiang Zhu;Eamonn J. Keogh
#t 2011
#c 18
#! The increasing interest in archiving all of humankind's cultural artifacts has resulted in the digitization of millions of books, and soon a significant fraction of the world's books will be online. Most of the data in historical manuscripts is text, but there is also a significant fraction devoted to images. This fact has driven much of the recent increase in interest in query-by-content systems for images. While querying/indexing systems can undoubtedly be useful, we believe that the historical manuscript domain is finally ripe for true unsupervised discovery of patterns and regularities. To this end, we introduce an efficient and scalable system which can detect approximately repeated occurrences of shape patterns both within and between historical texts. We show that this ability to find repeated shapes allows automatic annotation of manuscripts, and allows users to trace the evolution of ideas. We demonstrate our ideas on datasets of scientific and cultural manuscripts dating back to the fourteenth century.

#index 1688541
#* Analysis of Textual Variation by Latent Tree Structures
#@ Teemu Roos;Yuan Zou
#t 2011
#c 18
#! We introduce Semstem, a new method for the reconstruction of so called stemmatic trees, i.e., trees encoding the copying relationships among a set of textual variants. Our method is based on a structural expectation-maximization (structural EM) algorithm. It is the first computer-based method able to estimate general latent tree structures, unlike earlier methods that are usually restricted to bifurcating trees where all the extant texts are placed in the leaf nodes. We present experiments on two well known benchmark data sets, showing that the new method outperforms current state-of-the-art both in terms of a numerical score as well as interpretability.

#index 1688542
#* A Fast and Flexible Clustering Algorithm Using Binary Discretization
#@ Mahito Sugiyama;Akihiro Yamamoto
#t 2011
#c 18
#! We present in this paper a new clustering algorithm for multivariate data. This algorithm, called BOOL (Binary coding Oriented clustering), can detect arbitrarily shaped clusters and is noise tolerant. BOOL handles data using a two-step procedure: data points are first discretized and represented as binary words, clusters are then iteratively constructed by agglomerating smaller clusters using this representation. This latter step is carried out with linear complexity by sorting such binary representations, which results in dramatic speedups when compared with other techniques. Experiments show that BOOL is faster than K-means, and about two to three orders of magnitude faster than two state-of-the-art algorithms that can detect non-convex clusters of arbitrary shapes. We also show that BOOL's results are robust to changes in parameters, whereas most algorithms for arbitrarily shaped clusters are known to be overly sensitive to such changes. The key to the robustness of BOOL is the hierarchical structure of clusters that is introduced automatically by increasing the accuracy of the discretization.

#index 1688543
#* A New Multi-task Learning Method for Personalized Activity Recognition
#@ Xu Sun;Hisashi Kashima;Ryota Tomioka;Naonori Ueda;Ping Li
#t 2011
#c 18
#! Personalized activity recognition usually faces the problem of data sparseness. We aim at improving accuracy of personalized activity recognition by incorporating the information from other persons. We propose a new online multi-task learning method for personalized activity recognition. The proposed online multi-task learning method automatically learns the ``transfer-factors" (similarities) among different tasks (i.e., among different persons in our case). Experiments demonstrate that the proposed method significantly outperforms existing methods. The novelty of this paper is twofold: (1) A new multi-task learning framework, which can naturally learn similarities among tasks, (2) To our knowledge, this is the first study of large-scale personalized activity recognition.

#index 1688544
#* Identities Anonymization in Dynamic Social Networks
#@ Chih-Hua Tai;Peng-Jui Tseng;Philip S. Yu;Ming-Syan Chen
#t 2011
#c 18
#! Privacy in social network data publishing is always an important concern. Nowadays most prior privacy protection techniques focus on static social networks. However, there are additional privacy disclosures in dynamic social networks due to the sequential publications. In this paper, we first show that the risks of vertex and community re-identification exist in a dynamic social network, even if the release at each time instance is protected by a static anonymity scheme. To prevent vertex and community re-identification in a dynamic social network, we propose novel dynamic k^w-structural diversity anonymity, where w is the time that an adversary can monitor a victim. This scheme extends the k-structural diversity anonymity to a dynamic scenario. We also present a heuristic to anonymize the releases of networks to satisfy the proposed privacy scheme. The evaluations show that our approach can retain much of the characteristics of the networks while confirming the privacy protection.

#index 1688545
#* Discovering Emerging Topics in Social Streams via Link Anomaly Detection
#@ Toshimitsu Takahashi;Ryota Tomioka;Kenji Yamanishi
#t 2011
#c 18
#! Detection of emerging topics are now receiving renewed interest motivated by the rapid growth of social networks. Conventional term-frequency-based approaches may not be appropriate in this context, because the information exchanged are not only texts but also images, URLs, and videos. We focus on the social aspects of theses networks. That is, the links between users that are generated dynamically intentionally or unintentionally through replies, mentions, and retweets. We propose a probability model of the mentioning behaviour of a social network user, and propose to detect the emergence of a new topic from the anomaly measured through the model. We combine the proposed mention anomaly score with a recently proposed change-point detection technique based on the Sequentially Discounting Normalized Maximum Likelihood (SDNML), or with Kleinberg's burst model. Aggregating anomaly scores from hundreds of users, we show that we can detect emerging topics only based on the reply/mention relationships in social network posts. We demonstrate our technique in a number of real data sets we gathered from Twitter. The experiments show that the proposed mention-anomaly-based approaches can detect new topics at least as early as the conventional term-frequency-based approach, and sometimes much earlier when the keyword is ill-defined.

#index 1688546
#* Finding Communities in Dynamic Social Networks
#@ Chayant Tantipathananandh;Tanya Y. Berger-Wolf
#t 2011
#c 18
#! Communities are natural structures observed in social networks and are usually characterized as "relatively dense" subsets of nodes. Social networks change over time and so do the underlying community structures. Thus, to truly uncover this structure we must take the temporal aspect of networks into consideration. Previously, we have represented framework for finding dynamic communities using the social cost model and formulated the corresponding optimization problem [33], assuming that partitions of individuals into groups are given in each time step. We have also presented heuristics and approximation algorithms for the problem, with the same assumption [32]. In general, however, dynamic social networks are represented as a sequence of graphs of snapshots of the social network and the assumption that we have partitions of individuals into groups does not hold. In this paper, we extend the social cost model and formulate an optimization problem of finding community structure from the sequence of arbitrary graphs. We propose a semi definite programming formulation and a heuristic rounding scheme. We show, using synthetic data sets, that this method is quite accurate on synthetic data sets and present its results on a real social network.

#index 1688547
#* Healing Sample Selection Bias by Source Classifier Selection
#@ Chun-Wei Seah;Ivor Wai-Hung Tsang;Yew-Soon Ong
#t 2011
#c 18
#! Domain Adaptation (DA) methods are usually carried out by means of simply reducing the marginal distribution differences between the source and target domains, and subsequently using the resultant trained classifier, namely source classifier, for use in the target domain. However, in many cases, the true predictive distributions of the source and target domains can be vastly different especially when their class distributions are skewed, causing the issues of sample selection bias in DA. Hence, DA methods which leverage the source labeled data may suffer from poor generalization in the target domain, resulting in negative transfer. In addition, we observed that many DA methods use either a source classifier or a linear combination of source classifiers with a fixed weighting for predicting the target unlabeled data. Essentially, the labels of the target unlabeled data are spanned by the prediction of these source classifiers. Motivated by these observations, in this paper, we propose to construct many source classifiers of diverse biases and learn the weight for each source classifier by directly minimizing the structural risk defined on the target unlabeled data so as to heal the possible sample selection bias. Since the weights are learned by maximizing the margin of separation between opposite classes on the target unlabeled data, the proposed method is established here as Maximal Margin Target Label Learning (MMTLL), which is in a form of Multiple Kernel Learning problem with many label kernels. Extensive experimental studies of MMTLL against several state-of-the-art methods on the Sentiment and Newsgroups datasets with various imbalanced class settings showed that MMTLL exhibited robust accuracies on all the settings considered and was resilient to negative transfer, in contrast to other counterpart methods which suffered significantly in prediction accuracy.

#index 1688548
#* An In-depth Study of Stochastic Kronecker Graphs
#@ C. Seshadhri;Ali Pinar;Tamara G. Kolda
#t 2011
#c 18
#! Graph analysis is playing an increasingly important role in science and industry. Due to numerous limitations in sharing real-world graphs, models for generating massive graphs are critical for developing better algorithms. In this paper, we analyze the stochastic Kronecker graph model (SKG), which is the foundation of the Graph500 supercomputer benchmark due to its many favorable properties and easy parallelization. Our goal is to provide a deeper understanding of the parameters and properties of this model so that its functionality as a benchmark is increased. We develop a rigorous mathematical analysis that shows this model cannot generate a power-law distribution or even a lognormal distribution. However, we formalize an enhanced version of the SKG model that uses random noise for smoothing. We prove both in theory and in practice that this enhancement leads to a lognormal distribution. Additionally, we provide a precise analysis of isolated vertices, showing that graphs that are produced by SKG might be quite different than intended. For example, between 50% and 75% of the vertices in the Graph500 benchmarks will be isolated. Finally, we show that this model tends to produce extremely small core numbers (compared to most social networks and other real graphs) for common parameter choices.

#index 1688549
#* Learning Spectral Embedding for Semi-supervised Clustering
#@ Fanhua Shang;Yuanyuan Liu;Fei Wang
#t 2011
#c 18
#! In recent years, semi-supervised clustering (SSC) has aroused considerable interests from the machine learning and data mining communities. In this paper, we propose a novel semi-supervised clustering approach with enhanced spectral embedding (ESE) which not only considers structure information contained in data sets but also makes use of prior side information such as pair wise constraints. Specially, we first construct a symmetry-favored k-NN graph which is highly robust to noisy objects and can reflect the underlying manifold structure of data. Then we learn the enhanced spectral embedding towards an ideal representation as consistent with the pair wise constraints as possible. Finally, through taking advantage of Laplacian regularization, we formulate learning spectral representation as semi definite-quadratic-linear programs (SQLPs) under the squared loss function or small semi definitive programs (SDPs) under the hinge loss function, which both can be efficiently solved. Experimental results on a variety of synthetic and real-world data sets show that our approach outperforms the state-of-the-art SSC algorithms on both vector-based and graph-based clustering.

#index 1688550
#* Detection of Arbitrarily Oriented Synchronized Clusters in High-Dimensional Data
#@ Junming Shao;Claudia Plant;Qinli Yang;Christian Bohm
#t 2011
#c 18
#! How to address the challenges of the "curse of dimensionality" in clustering? Clustering is a powerful data mining technique for structuring and organizing vast amounts of data. However, the high-dimensional data space is usually very sparse and meaningful clusters can only be found in lower dimensional subspaces. In many applications the subspaces hosting the clusters provide valuable information for interpreting the major patterns in the data. Detection of subspace clusters is challenging since usually many of the attributes are noisy, some attributes may exhibit correlations among each other and only few of the attributes truly contribute to the cluster structure. In this paper, we propose ORSC (Arbitrarily ORiented Synchronized Clusters), a novel effective and efficient method to subspace clustering inspired by synchronization. Synchronization is a basic phenomenon prevalent in nature, capable of controlling even highly complex processes such as opinion formation in a group. Control of complex processes is achieved by simple operations based on interactions between objects. Relying on the interaction model for synchronization, our approach ORSC (1) naturally detects correlation clusters in arbitrarily oriented subspaces, including (2) arbitrarily shaped non-linear correlation clusters. Our approach is (3) robust against noise points and outliers. In contrast to previous methods, ORSC is (4) easy to parameterize, since there is no need to specify the subspace dimensionality and all interesting subspace clusters can be detected. Finally, (5) ORSC outperforms most comparison methods in terms of runtime efficiency and is highly scalable to large and high-dimensional data sets.

#index 1688551
#* Review Graph Based Online Store Review Spammer Detection
#@ Guan Wang;Sihong Xie;Bing Liu;Philip S. Yu
#t 2011
#c 18
#! Online reviews provide valuable information about products and services to consumers. However, spammers are joining the community trying to mislead readers by writing fake reviews. Previous attempts for spammer detection used reviewers' behaviors, text similarity, linguistics features and rating patterns. Those studies are able to identify certain types of spammers, e.g., those who post many similar reviews about one target entity. However, in reality, there are other kinds of spammers who can manipulate their behaviors to act just like genuine reviewers, and thus cannot be detected by the available techniques. In this paper, we propose a novel concept of a heterogeneous review graph to capture the relationships among reviewers, reviews and stores that the reviewers have reviewed. We explore how interactions between nodes in this graph can reveal the cause of spam and propose an iterative model to identify suspicious reviewers. This is the first time such intricate relationships have been identified for review spam detection. We also develop an effective computation method to quantify the trustiness of reviewers, the honesty of reviews, and the reliability of stores. Different from existing approaches, we don't use review text information. Our model is thus complementary to existing approaches and able to find more difficult and subtle spamming activities, which are agreed upon by human judges after they evaluate our results.

#index 1688552
#* Classifying Categorical Data by Rule-Based Neighbors
#@ Jiabing Wang;Pei Zhang;Guihua Wen;Jia Wei
#t 2011
#c 18
#! A new learning algorithm for categorical data, named CRN (Classification by Rule-based Neighbors) is proposed in this paper. CRN is a nonmetric and parameter-free classifier, and can be regarded as a hybrid of rule induction and instance-based learning. Based on a new measure of attributes quality and the separate-and-conquer strategy, CRN learns a collection of feature sets such that for each pair of instances belonging to different classes, there is a feature set on which the two instances disagree. For an unlabeled instance I and a labeled instance J, J is a neighbor of I if and only if they agree on all attributes of a feature set. Then, CRN classifies an unlabeled instance I based on I's neighbors on those learned feature sets. To validate the performance of CRN, CRN is compared with six state-of-the-art classifiers on twenty-four datasets. Experimental results demonstrate that although the underlying idea of CRN is simple, the predictive accuracy of CRN is comparable to or better than that of the state-of-the-art classifiers on most datasets.

#index 1688553
#* Tensor Fold-in Algorithms for Social Tagging Prediction
#@ Miao Zhang;Chris Ding;Zhifang Liao
#t 2011
#c 18
#! Social tagging predictions involve the co occurrence of users, items and tags. The tremendous growth of users require the recommender system to produce tag recommendations for millions of users and items at any minute. The triplets of users, items and tags are most naturally described by a 3D tensor, and tensor decomposition-based algorithms can produce high quality recommendations. However, each day, thousands of new users are added to the system and the decompositions must be updated daily in a online fashion. In this paper, we provide analysis of the new user problem, and present fold-in algorithms for Tucker, Para Fac, and Low-order tensor decompositions. We show that these algorithm can very efficiently compute the needed decompositions. We evaluate the fold-in algorithms experimentally on several datasets and the results demonstrate the effectiveness of these algorithms.

#index 1688554
#* Discovering Thematic Patterns in Videos via Cohesive Sub-graph Mining
#@ Gangqiang Zhao;Junsong Yuan
#t 2011
#c 18
#! One category of videos usually contains the same thematic pattern, e.g., the spin action in skating videos. The discovery of the thematic pattern is essential to understand and summarize the video contents. This paper addresses two critical issues in mining thematic video patterns: (1) automatic discovery of thematic patterns without any training or supervision information, and (2) accurate localization of the occurrences of all thematic patterns in videos. The major contributions are two-fold. First, we formulate the thematic video pattern discovery as a cohesive sub-graph selection problem by finding a sub-set of visual words that are spatio-temporally collocated. Then spatio-temporal branch-and-bound search can locate all instances accurately. Second, a novel method is proposed to efficiently find the cohesive sub-graph of maximum overall mutual information scores. Our experimental results on challenging commercial and action videos show that our approach can discover different types of thematic patterns despite variations in scale, view-point, color and lighting conditions, or partial occlusions. Our approach is also robust to the videos with cluttered and dynamic backgrounds.

#index 1688555
#* Low Rank Metric Learning with Manifold Regularization
#@ Guoqiang Zhong;Kaizhu Huang;Cheng-Lin Liu
#t 2011
#c 18
#! In this paper, we present a semi-supervised method to learn a low rank Mahalanobis distance function. Based on an approximation to the projection distance from a manifold, we propose a novel parametric manifold regularizer. In contrast to previous approaches that usually exploit side information only, our proposed method can further take advantages of the intrinsic manifold information from data. In addition, we focus on learning a metric of low rank directly, this is different from traditional approaches that often enforce the l_1 norm on the metric. The resulting configuration is convex with respect to the manifold structure and the distance function, respectively. We solve it with an alternating optimization algorithm, which proves effective to find a satisfactory solution. For efficient implementation, we even present a fast algorithm, in which the manifold structure and the distance function are learned independently without alternating minimization. Experimental results over 12 standard UCI data sets demonstrate the advantages of our method.

#index 1688556
#* A Generalized Fast Subset Sums Framework for Bayesian Event Detection
#@ Kan Shao;Yandong Liu;Daniel B. Neill
#t 2011
#c 18
#! We present Generalized Fast Subset Sums (GFSS), a new Bayesian framework for scalable and accurate detection of irregularly shaped spatial clusters using multiple data streams. GFSS extends the previously proposed Multivariate Bayesian Scan Statistic (MBSS) and Fast Subset Sums (FSS) approaches for detection of emerging events. The detection power of MBSS is primarily limited by computational considerations, which limit it to searching over circular spatial regions. GFSS enables more accurate and timely detection by defining a hierarchical prior over all subsets of the N locations, first selecting a local neighborhood consisting of a center location and its neighbors, and introducing a sparsity parameter p to describe how likely each location in the neighborhood is to be affected. This approach allows us to consider all possible subsets of locations (including irregularly-shaped regions) but also puts higher weight on more compact regions. We demonstrate that MBSS and FSS are both special cases of this general framework (assuming p = 1 and p = 0.5 respectively), but substantially higher detection power can be achieved by choosing an appropriate value of p. Thus we show that the distribution of the sparsity parameter p can be accurately learned from a small number of labeled events. Our evaluation results (on synthetic disease outbreaks injected into real-world hospital data) show that the GFSS method with learned sparsity parameter has higher detection power and spatial accuracy than MBSS and FSS, particularly when the affected region is irregular or elongated. We also show that the learned models can be used for event characterization, accurately distinguishing between two otherwise identical event types based on the sparsity of the affected spatial region.

#index 1688557
#* Learning to Rank for Query-Focused Multi-document Summarization
#@ Chao Shen;Tao Li
#t 2011
#c 18
#! In this paper, we explore how to use ranking SVM to train the feature weights for query-focused multi-document summarization. To apply a supervised learning method to sentence extraction in multi-document summarization, we need to derive the sentence labels for training corpus from the existing human labeling data in form of. However, this process is not trivial, because the human summaries are abstractive, and do not necessarily well match the sentences in the documents. In this paper, we try to address the above problem from the following two aspects. First, we make use of sentence-to-sentence relationships to better estimate the probability of a sentence in the document set to be a summary sentence. Second, to make the derived training data less sensitive, we adopt a cost sensitive loss in the ranking SVM's objective function. The experimental results demonstrate the effectiveness of our proposed method.

#index 1688558
#* Simple Multiple Noisy Label Utilization Strategies
#@ Victor S. Sheng
#t 2011
#c 18
#! With the outsourcing of small tasks becoming easier, it is possible to obtain non-expert/imperfect labels at low cost. With low-cost imperfect labeling, it is straightforward to collect multiple labels for the same data items. This paper addresses the strategies of utilizing these multiple labels for improving the performance of supervised learning, based on two basic ideas: majority voting and pair wise solutions. We show several interesting results based on our experiments. The soft majority voting strategies can reduce the bias and roughness, and improve the performance of the directed hard majority voting strategy. Pair wise strategies can completely avoid the bias by having both sides (potential correct and incorrect/noisy information) considered (for binary classification). They have very good performance whenever there are a few or many labels available. However, it could also keep the noise. The improved variation that reduces the impact of the noisy information is recommended. All five strategies investigated are labeling quality agnostic strategies, and can be applied to real world applications directly. The experimental results show some of them perform better than or at least very close to the gnostic strategies.

#index 1688559
#* Partitionable Kernels for Mapping Kernels
#@ Kilho Shin
#t 2011
#c 18
#! Many of tree kernels in the literature are designed tanking advantage of the mapping kernel framework. The most important advantage of using this framework is that we have a strong theorem to examine positive definiteness of the resulting tree kernels. In the mapping kernel framework, each data object is viewed as a collection of components, and a mapping kernel for a pair of data objects is determined as a sum of kernel values of component pairs over a certain range determined according to the purpose of use of the resulting mapping kernel. For those tree kernels known to belong to the mapping kernel category, the string kernel of the product type is commonly used to compute the kernel values of component pairs. This is because it is known that use of the product-type string kernel together with the mapping kernel framework allows us to have recursive formulas to calculate the resulting tree kernels efficiently. We significantly generalizes this result. In fact, we show that we can use partition able kernels, a new class of string kernels instead of the product-type string kernel to enjoy the same advantage, that is, efficient computation based on recursive formulas. The class of partition able kernels is abundant, and contains the product-type string kernels just as an instance. Also, this result, not limited to tree kernels, can be applied to general mapping kernels after we formalize the decomposition properties of trees as the new notion of pretty decomposability.

#index 1688560
#* Ranking Web-Based Partial Orders by Significance Using a Markov Reference Model
#@ Michel Speiser;Gianluca Antonini;Abderrahim Labbi
#t 2011
#c 18
#! Mining web traffic data has been addressed in literature mostly using sequential pattern mining techniques. Recently, a more powerful pattern called partial order was introduced, with the hope of providing a more compact result set. A further approach towards this goal, valid for both sequential patterns and partial orders, consists in building a statistical significance test for frequent patterns. Our method is based on probabilistic generative models and provides a direct way to rank the extracted patterns. It leaves open the number of patterns of interest, which depends on the application, but provides an alternative criterion to frequency of occurrence: statistical significance. In this paper, we focus on the construction of an algorithm which calculates the probability of partial orders under a first-order Markov reference model, and we show how to use those probabilities to assess the statistical significance of a set of mined partial orders.

#index 1688561
#* A Study of Laplacian Spectra of Graph for Subgraph Queries
#@ Lei Zhu;Qinbao Song
#t 2011
#c 18
#! The spectrum of graph has been widely used in graph mining to extract graph topological information. It has also been employed as a characteristic of graph to check the sub graph isomorphism testing since it is an invariant of a graph. However, the spectrum cannot be directly applied to a graph and its sub graph, which is a bottleneck for sub graph isomorphism testing. In this paper, we study the Laplacian spectra between a graph and its sub graph, and propose a method by straightforward adoption of them for sub graph queries. In our proposed method, we first encode every vertex and graph by extracting their Laplacian spectra, and generate a novel two-step filtering conditions. Then, we follow the filtering-and verification framework to conduct sub graph queries. Extensive experiments show that, compared with existing counterpart method, as a graph feature, Laplacian spectra can be used to efficiently improves the efficiency of sub graph queries and thus indicate that it have considerable potential.

#index 1688562
#* Text Clustering via Constrained Nonnegative Matrix Factorization
#@ Yan Zhu;Liping Jing;Jian Yu
#t 2011
#c 18
#! Semi-supervised nonnegative matrix factorization (NMF)receives more and more attention in text mining field. The semi-supervised NMF methods can be divided into two types, one is based on the explicit category labels, the other is based on the pair wise constraints including must-link and cannot-link. As it is hard to obtain the category labels in some tasks, the latter one is more widely used in real applications. To date, all the constrained NMF methods treat the must-link and cannot-link constraints in a same way. However, these two kinds of constraints play different roles in NMF clustering. Thus a novel constrained NMF method is proposed in this paper. In the new method, must-link constraints are used to control the distance of the data in the compressed form, and cannot-ink constraints are used to control the encoding factor. Experimental results on real-world text data sets have shown the good performance of the proposed method.

#index 1722136
#* Proceedings of the 4th international conference on Advances in Data Mining: applications in Image Mining, Medicine and Biotechnology, Management and Environmental Control, and Telecommunications
#@ Petra Perner
#t 2004
#c 18

#index 1722137
#* Neuro-symbolic system for business internal control
#@ Juan M. Corchado;M. Lourdes Borrajo;María A. Pellicer;J. Carlos Yáñez
#t 2004
#c 18
#% 47148
#% 168280
#% 176887
#% 258186
#% 362205
#% 374537
#% 405727
#% 442751
#% 454954
#! The complexity of current organization systems, and the increase in importance of the realization of internal controls in firms, make it necessary to construct models that automate and facilitate the work of auditors. An intelligent system has been developed to automate the internal control process. This system is composed of two case-based reasoning systems. The objective of the system is to facilitate the process of internal auditing in small and medium firms from the textile sector. The system, analyses the data that characterises each one of the activities carried out by the firm, then determines the state of each activity, calculates the associated risk, detects the erroneous processes, and generates recommendations to improve these processes. As such, the system is a useful tool for the internal auditor in order to make decisions based on the risk generated. Each one of the case-based reasoning systems that integrates the system uses a different problem solving method in each of the steps of the reasoning cycle: fuzzy clustering during the retrieval phase, a radial basis function network and a multi-criterion discreet method during the reuse phase and a rule based system for recommendation generation. The system has been proven successfully in several small and medium companies in the textile sector, located in the northwest of Spain. The accuracy of the technologies employed in the system has been demonstrated by the results obtained over the last two years.

#index 1722138
#* Applying case based reasoning approach in analyzing organizational change management data
#@ Orit Raphaeli;Jacob Zahavi;Ron Kenett
#t 2004
#c 18
#% 1772
#% 176887
#% 229101
#% 271009
#% 329633
#% 354024
#% 359837
#% 490117
#% 564555
#% 566463
#% 566635
#% 1414233
#% 1722138
#% 1803977
#! This work is a first step towards the application of a Case Based Reasoning (CBR) model to support the management of Enterprise System Implementation (ESI) related organizational change processes. Those processes are characterized by the occurrences of unplanned problems and events, which may lead to major restructuring of the process. We rely on ESI theory developed by the BEST project. The paper’s focus is the matching process within the retrieval phase. We propose a procedure for similarity assessment between current experiences and past experiences. We enhance the applicability of CBR to ESI by encoding domain knowledge, according to BEST approach. The similarity measures are based on nearest-neighbor approach and Tversky’s Contrast model. The proposed method assesses the similarity between events, while accounting their context similarity. Plans for future work are outlined.

#index 1722139
#* Improving the K-NN classification with the euclidean distance through linear data transformations
#@ Leon Bobrowski;Magdalena Topczewska
#t 2004
#c 18
#% 51647
#% 80995
#% 168280
#% 729437
#% 1414233
#! One of the most popular techniques in pattern recognition applications is the nearest neighbours (K-NN) classification rule based on the Euclidean distance function. This rule can be modified by data transformations. Variety of distance functions can be induced from data sets in this way. We take into considerations inducing distance functions by linear data transformations. The results of our experiments show the possibility of improving K-NN rules through such transformations.

#index 1722140
#* An IBR system to quantify the ocean’s carbon dioxide budget
#@ Juan M. Corchado;Emilio S. Corchado;Jim Aiken
#t 2004
#c 18
#% 318436
#% 1012144
#% 1389749
#% 1776440
#! The interaction of the atmosphere and the ocean has a profound effect on climate, while the uptake by the oceans of a major fraction of atmospheric carbon dioxide has a moderating influence. By improving accuracy in the quantification of the ocean’s carbon dioxide budget, a more precise estimation can be made of the terrestrial fraction of global carbon dioxide budget and its subsequent effect on climate change. First steps have been taken towards this from an environmental and economic point of view, by using an instance based reasoning system, which incorporates a novel clustering and retrieval method. This paper reviews the problems of measuring the ocean’s carbon dioxide budget and presents the model developed to resolve them.

#index 1722141
#* A beta-cooperative CBR system for constructing a business management model
#@ Emilio S. Corchado;Juan M. Corchado;Lourdes Sáiz;Ana Lara
#t 2004
#c 18
#% 235633
#% 318436
#% 1012144
#% 1776440
#! Knowledge has become the most strategic resource in the new business environment. A case-based reasoning system has been developed for identifying critical situations in business processes. The CBR system can be used to categorize the necessities for the Acquisition, Transfer and Updating of Knowledge of the different departments of a firm. This technique is used as a tool to develop a part of a Global and Integral Model of Business Management, which brings about a global improvement in the firm, adding value, flexibility and competitiveness. From this perspective, the data mining model tries to generalize the hypothesis of organizational survival and competitiveness, so that the organization that is able to identify, strengthen, and use key knowledge will reach a pole position. This case-based reasoning system incorporates a novel artificial neural architecture called Beta-Cooperative Learning in order to categorize the necessities for the Acquisition, Transfer and Updating of Knowledge of the different departments of a firm. This architecture is used to retrieve the most similar cases to a given subject.

#index 1722142
#* Braving the semantic gap: mapping visual concepts from images and videos
#@ Da Deng
#t 2004
#c 18
#% 282201
#% 318785
#% 341442
#% 522284
#% 589729
#% 738542
#% 1011582
#% 1857842
#% 1857902
#! A set of feature descriptors have been proposed and rigorously in the MPEG-7 core experiments. We propose to extend the use of these descriptors onto semantics extraction from images and videos, so as to bridge the semantic gap in content-based image retrieval and enable multimedia data mining on semantics level. A computational framework consisting of a clustering process for feature mapping and a classification process for object extraction is introduced. We also present some preliminary results obtained from the experiments we have conducted.

#index 1722143
#* Mining images to find general forms of biological objects
#@ Petra Perner;Horst Perner;Angela Bühring;Silke Jänichen
#t 2004
#c 18
#% 828
#% 49238
#% 131055
#% 1414233
#% 1854406
#! We propose and evaluate a method for the recognition of airborne fungi spores. We suggest a case-based object-recognition method to identify spores in a digital microscopic image. We do not use the gray values of the case, but the object edges instead. The similarity measure measures the average angle between the vectors of the template and the object. Case generation is done semi-automatically by manually tracing the object, automatic shape alignment, similarity calculation, clustering, and prototype calculation.

#index 1722144
#* The main steps to data quality
#@ Joachim Schmid
#t 2004
#c 18
#% 228356
#% 287631
#% 318946
#% 912094
#% 987120
#! To gain knowledge out of your data, your data has to be of high quality. Bad data quality becomes more and more the problem for companies, who start to exploit their data stocks. This article will show the main obstacles on the way to perfect data quality. It is based on our experience to improve data quality in large customer or business partner databases. The examples mentioned in this paper show data defects we have found during our daily work. There are also some notes how to improve data quality and avoid data defects.

#index 1722145
#* Cost-Sensitive design of claim fraud screens
#@ Stijn Viaene;Dirk Van Gheel;Mercedes Ayuso;Montserrat Guillén
#t 2004
#c 18
#% 191910
#% 331909
#% 466086
#% 729437
#% 1289281
#! In this paper we perform an exploratory study on the design of claim fraud detection for a typical property and casualty (P&C) insurance company using cost-sensitive classification. We contrast several cost incorporation scenarios based on different assumptions concerning the available cost information at claim screening time. Our empirical trials are based on a data set of real-life Spanish closed automobile insurance claims that were previously investigated for suspicion of fraud by domain experts and for which we obtained detailed cost information. The reported results show the added value of cost-sensitive claim fraud screening and provide guidance on how to operationalize this strategy.

#index 1722146
#* An early warning system for vehicle related quality data
#@ Matthias Grabert;Markus Prechtel;Tomas Hrycej;Winfried Günther
#t 2004
#c 18
#% 385321
#! Vehicle production audit tests, warranty claims and car control unit data are stored in a central data warehouse for data mining analysis. Neural network based part failure rate estimations, adjusted for mileage and seasonality, are used for monitoring warranty claims. Association and sequence analysis connect production audit data, car control unit data and warranty claims for an early detection of quality changes both in production state and car field usage. Calculations are performed via grid computing.

#index 1722147
#* Shape-Invariant cluster validity indices
#@ Greet Frederix;Eric J. Pauwels
#t 2004
#c 18
#% 104472
#% 294840
#% 296738
#% 387914
#! This paper discusses two cluster validity indices that quantify the quality of a putative clustering in terms of label-homogeneity and connectivity. Because the indices are defined in terms of local data-density, they do not favour spherical or ellipsoidal clusters as other validity indices tend to do. A statistics-based decision framework is outlined that uses these indices to decide on the correct number of clusters.

#index 1722148
#* Mining indirect association rules
#@ Shinichi Hamano;Masako Sato
#t 2004
#c 18
#% 152934
#% 227919
#% 280436
#% 280487
#% 464822
#% 478298
#% 577214
#% 715817
#! A large database, such as POS data, could give us many insights about customer behavior. Many techniques and measures have been proposed to extract interesting rules. As the study of Association rule mining has proceeded, the rules about items that are not bought together at the same transaction have been regarded as important. Although this concept, Negative Association rule mining, is quite useful, it is difficult for the user to analyze the interestingness of Negative Association rules because we would get them too many. To settle this issue, Indirect Association rule mining has proposed. In this paper, we propose a new framework of Indirect Association rule via a mediator and a new measure μ based on measures PA and PD due to Zhang to mine Negative Association rules effectively without the domain knowledge. The μ measure has the advantage over the IS measure that is proposed with the first framework of Indirect Association rule mining, and satisfies all of the well-known properties for a good measure. Finally, we are going to analyze the retail data and present interpretations for derived Indirect Association rules.

#index 1722149
#* An association mining method for time series and its application in the stock prices of TFT-LCD industry
#@ Chiung-Fen Huang;Yen-Chu Chen;An-Pin Chen
#t 2004
#c 18
#% 152934
#% 210160
#% 232106
#% 300120
#% 316709
#% 318994
#% 351155
#% 366687
#% 376266
#% 420116
#% 481290
#% 481754
#% 630973
#! TFT-LCD is one of industries currently promoted by the “Two Trillion and Twin Star Industries Development Plan” in Taiwan. This study endeavors to find out the stock price associations between the suppliers and manufacturers in the value chain of the TFT-LCD industry by means of data mining techniques, and meanwhile, to improve the Apriori algorithm so that it can facilitate association mining of discrete data points in a time series. An efficient data mining method which consists of two phases is proposed. In the first phase, data are classified and preprocessed using the algorithm proposed by R. Agrawal et al. (1996), then Apriori algorithm is applied to extract the strong association rules. The second phase further improves the Apriori algorithm by breaking down the traditional limitation of relying on pattern matching of continuous data for disclosing stock market behavior. By mining the association rules from the discrete data points in a time series and testing the corresponding hypotheses, statistically significant outcomes can be obtained. The proposed data mining method was applied to some real time-series of the stock prices of companies in the supply chain of TFT-LCD industry in Taiwan. It is suggested that a positive correlation does not necessarily exist between the companies’ stock prices in the supply chain of TFT-LCD industry. For instance the result shows that, if the stock price of Sintek Phonrotic Corp., a company in the up stream of the value chain, soars for more than 5% in a day, the stock price of Tatung, a company in the down stream of the same value chain, may not respond positively accordingly. If an investor can short the stock of Tatung on the 7th day and long it back on the 10th day after Sintek’s stock price soaring for more than 5%, the annual return of investment is 199.88% with 95% confidence interval. In conclusion, the results may reveal helpful information for the investors to make leveraged arbitrage profit investing decisions, and it might be interesting to apply this proposed data mining method to the time series in other industries or problems and investigate the results further.

#index 1722150
#* Clustering of web sessions using levenshtein metric
#@ Andrei Scherbina;Sergey Kuznetsov
#t 2004
#c 18
#% 104472
#% 232102
#% 261741
#% 300211
#% 430746
#% 488554
#% 659240
#% 661023
#% 1788198
#! Various commercial and scientific applications require analysis of user behaviour in the Internet. For example, web marketing or network technical support can benefit from web users classification. This is achievable by tracking pages visited by the user during one session (one visit to the particular site). For automated user sessions classification we propose distance that compares sessions judging by the sequence of pages in them and by categories of these pages. Proposed distance is based on Levenshtein metric. Fuzzy C Medoids algorithm was used for clustering, since it has almost linear complexity. Davies-Bouldin, Entropy, and Bezdek validity indices were used to assess the qualities of proposed method. As testing shows, our distance outperforms in this domain both Euclidian and Edit distances.

#index 1722151
#* A data mining approach for call admission control and resource reservation in wireless mobile networks
#@ Sherif Rashad;Mehmed Kantardzic;Anup Kumar
#t 2004
#c 18
#% 220795
#% 333747
#% 345127
#% 417877
#% 553317
#% 630822
#! In this paper a mobility-based predictive scheme for call admission control (CAC) and resource reservation (RR) is proposed. The main goal is to reduce the call dropping probability and the call blocking probability and to maximize the bandwidth utilization. Mining the previous movements of the mobile users, generates local and global profiles, which are utilized effectively in prediction of the future path of the mobile user. This scheme is based on high level of prediction of the next base stations for the mobile user. The simulation is used to compare the performance of the proposed technique with other two techniques: FR-CAT2 and PR-CAT4. Simulation results show that the proposed scheme has a significantly better performance (in average about 25%) compared to the other two schemes.

#index 1722152
#* Mining of an alarm log to improve the discovery of frequent patterns
#@ Françoise Fessant;Fabrice Clérot;Christophe Dousson
#t 2004
#c 18
#% 252207
#% 252209
#% 252210
#% 386573
#% 391311
#% 1273818
#% 1860652
#! In this paper we propose a method to pre-process a telecommunication alarm log with the aim of discovering more accurately frequent patterns. In a first step, the alarm types which present the same temporal behavior are clustered with a self organizing map. Then, the log areas which are rich in alarms of the clusters are searched. The sublogs are built based on the selected areas. We will show the efficiency of our preprocessing method through experiments on an actual alarm log from an ATM network.

#index 1722153
#* Feature selection and classification model construction on type 2 diabetic patient’s data
#@ Yue Huang;Paul McCullagh;Norman Black;Roy Harper
#t 2004
#c 18
#% 169659
#% 290482
#% 629619
#% 727663
#% 1786790
#% 1843620
#! Diabetes is a disorder of the metabolism where the amount of glucose in the blood is too high because the body cannot produce or properly use insulin. In order to achieve more effective diabetes clinic management, data mining techniques have been applied to a patient database. In an attempt to improve the efficiency of data mining algorithms, a feature selection technique ReliefF is used with the data, which can rank the important attributes affecting Type 2 diabetes control. After selecting suitable attributes, classification techniques are applied to the data to predict how well the patients are controlling their condition. Preliminary results have been confirmed by the clinician and this provides optimism that data mining can be used to generate prediction models.

#index 1722154
#* Knowledge based phylogenetic classification mining
#@ Isabelle Bichindaritz;Stephen Potter;Société Française de Systématique
#t 2004
#c 18
#% 89782
#% 366657
#! Phylsyst is an intelligent system that mines phylogenetic classifications. Its idea stems from the work of phylogeneticists of the Société Française de Systématique and proposes to test an innovative method for inferring phylogenetic classifications. The main idea in Phylsyst is to represent the reasoning of an expert phylogeneticist constructing a cladogram following Hennig principles. Several methods of artificial intelligence concur to Phylsyst’s efficient implementation of a phylogeneticist expert reasoning, the main one being data mining. Although phylogenetic tree mining has been little addressed in the data mining community, we hypothesize that this community has much to contribute to the worldwide efforts worldwide to Assemble the Tree Of Life. Phylsyst is such an attempt, and has been successfully distributed worldwide as a digital supplement to a special issue of Biosystema journal.

#index 1727204
#* Proceedings of the 6th Industrial Conference on Data Mining conference on Advances in Data Mining: applications in Medicine, Web Mining, Marketing, Image and Signal Mining
#@ Petra Perner
#t 2006
#c 18

#index 1727205
#* Using prototypes and adaptation rules for diagnosis of dysmorphic syndromes
#@ Rainer Schmidt;Tina Waligora
#t 2006
#c 18
#% 65653
#% 68717
#% 168280
#% 176887
#% 373871
#% 490464
#% 494600
#% 565893
#% 1786836
#! Since diagnosis of dysmorphic syndromes is a domain with incomplete knowledge and where even experts have seen only few syndromes themselves during their lifetime, documentation of cases and the use of case-oriented techniques are popular. In dysmorphic systems, diagnosis usually is performed as a classification task, where a prototypicality measure is applied to determine the most probable syndrome. These measures differ from the usual Case-Based Reasoning similarity measures, because here cases and syndromes are not represented as attribute value pairs but as long lists of symptoms, and because query cases are not compared with cases but with prototypes. In contrast to these dysmorphic systems our approach additionally applies adaptation rules. These rules do not only consider single symptoms but combinations of them, which indicate high or low probabilities of specific syndromes.

#index 1727206
#* OVA scheme vs. single machine approach in feature selection for microarray datasets
#@ Chia Huey Ooi;Madhu Chetty;Shyh Wei Teng
#t 2006
#c 18
#% 297684
#% 376266
#% 464444
#% 717417
#% 722929
#% 769966
#% 832876
#% 832992
#% 1712352
#% 1860941
#! The large number of genes in microarray data makes feature selection techniques more crucial than ever. From rank-based filter techniques to classifier-based wrapper techniques, many studies have devised their own feature selection techniques for microarray datasets. By combining the OVA (one-vs.-all) approach and differential prioritization in our feature selection technique, we ensure that class-specific relevant features are selected while guarding against redundancy in predictor set at the same time. In this paper we present the OVA version of our differential prioritization-based feature selection technique and demonstrate how it works better than the original SMA (single machine approach) version.

#index 1727207
#* Similarity searching in DNA sequences by spectral distortion measures
#@ Tuan D. Pham
#t 2006
#c 18
#% 137711
#% 382113
#% 832978
#! Searching for similarity among biological sequences is an important research area of bioinformatics because it can provide insight into the evolutionary and genetic relationships between species that open doors to new scientific discoveries such as drug design and treament. In this paper, we introduce a novel measure of similarity between two biological sequences without the need of alignment. The method is based on the concept of spectral distortion measures developed for signal processing. The proposed method was tested using a set of six DNA sequences taken from Escherichia coli K-12 and Shigella flexneri, and one random sequence. It was further tested with a complex dataset of 40 DNA sequences taken from the GenBank sequence database. The results obtained from the proposed method are found superior to some existing methods for similarity measure of DNA sequences.

#index 1727208
#* Multispecies gene entropy estimation, a data mining approach
#@ Xiaoxu Han
#t 2006
#c 18
#% 114736
#% 303025
#% 356892
#% 391311
#% 393812
#% 451154
#% 577958
#% 577959
#% 1722154
#! This paper presents a data mining approach to estimate multispecies gene entropy by using a self-organizing map (SOM) to mine a homologous gene set. The gene distribution function for each gene in the feature space is approximated by its probability distribution in the feature space. The phylogenetic applications of the multispecies gene entropy are investigated in an example of inferring the species phylogeny of eight yeast species. It is found that genes with the nearest K-L distances to the minimum entropy gene are more likely to be phylogenetically informative. The K-L distances of genes are strongly correlated with the spectral radiuses of their identity percentage matrices. The images of identity percentage matrices of the genes with small K-L distances to the minimum entropy gene are more similar to the image of the minimum entropy gene in their frequency domains after fast Fourier transforms (FFT) than the images of those genes with large K-L distances to the minimum entropy gene. Finally, a K-L distance based gene concatenation approach under gene clustering is proposed to infer species phylogenies robustly and systematically.

#index 1727209
#* A unified approach for discovery of interesting association rules in medical databases
#@ Harleen Kaur;Siri Krishan Wasan;Ahmed Sultan Al-Hegami;Vasudha Bhatnagar
#t 2006
#c 18
#% 152934
#% 172386
#% 220757
#% 290482
#% 310496
#% 316709
#% 341700
#% 393812
#% 443092
#% 445403
#% 477784
#% 487518
#% 727876
#% 1499588
#! Association rule discovery is an important technique for mining knowledge from large databases. Data mining researchers have studied subjective measures of interestingness to reduce the volume of discovered rules and to improve the overall efficiency of the knowledge discovery in databases process (KDD). The objective of this paper is to provide a framework that uses subjective measures of interestingness to discover interesting patterns from association rules algorithms. The framework works in an environment where the medical databases are evolving with time. In this paper we consider a unified approach to quantify interestingness of association rules. We believe that the expert mining can provide a basis for determining user threshold which will ultimately help us in finding interesting rules. The framework is tested on public datasets in medical domain and results are promising.

#index 1727210
#* Named relationship mining from medical literature
#@ Isabelle Bichindaritz
#t 2006
#c 18
#% 226545
#% 280512
#% 316709
#% 345764
#% 771355
#% 786497
#% 1389790
#% 1705326
#! This article addresses the task of mining named relationships between concepts from biomedical literature for indexing purposes or for scientific discovery from medical literature. This research builds on previous work on concept mining from medical literature for indexing purposes and proposes to learn semantic relationships names between concepts learnt. Previous ConceptMiner system did learn pairs of concepts, expressing a relationship between two concepts, but did not learn relationships semantic names. Building on ConceptMiner, RelationshipMiner is interested in learning as well the relationships with their name identified from the Unified Medical Language System (UMLS) knowledge-base as a basis for creating higher-level knowledge structures, such as rules, cases, and models, in future work. Current system is focused on learning semantically typed relationships as predefined in the UMLS, for which a dictionary of synonyms and variations has been created. An evaluation is presented showing that actually this relationship mining task improves the concept mining task results by enabling a better screening of the relationships between concepts for relevant ones.

#index 1727211
#* Experimental study of evolutionary based method of rule extraction from neural networks in medical data
#@ Urszula Markowska-Kaczmar;Rafal Matkowski
#t 2006
#c 18
#% 254721
#% 491999
#% 566123
#! In the paper the method of rule extraction from neural networks based on evolutionary approach, called GEX, is presented. Its details are described but the main stress is focussed on the experimental studies, the aim of which was to examine its usefulness in knowledge discovery and rule extraction for classification task of medical data. The tests were made using the well-known benchmark data sets from UCI, as well as two other data sets collected by Lower Silesian Oncology Center.

#index 1727212
#* HTTPHunting: an IBR approach to filtering dangerous HTTP Traffic
#@ F. Fdez-Riverola;L. Borrajo;R. Laza;F. J. Rodríguez;D. Martínez
#t 2006
#c 18
#% 36672
#% 168280
#% 198016
#% 250482
#% 290482
#% 296738
#% 315637
#% 321550
#% 364282
#% 664488
#% 761373
#% 790040
#% 810175
#% 978633
#! Recently, there has been significant interest in applying artificial intelligence techniques to intrusion detection problem. To find the solution to the difficulties in acquiring and representing existing knowledge in almost systems, we proposed a novel instance-based intrusion detection system called httpHunting. It will provide a framework to intrusion detection problem, incorporating several artificial intelligence techniques that help to overcome some of those limitations. httpHunting is able to classify in real time, traffic data arriving at the network interface of the host that is protecting, detecting anomalous traffic patterns. From our initial experiments, we can conclude that there are important key benefits of such an approach to network traffic-filtering domain.

#index 1727213
#* A comparative performance study of feature selection methods for the anti-spam filtering domain
#@ J. R. Méndez;F. Fdez-Riverola;F. Díaz;E. L. Iglesias;J. M. Corchado
#t 2006
#c 18
#% 115462
#% 190581
#% 260001
#% 269218
#% 280481
#% 311034
#% 344447
#% 406493
#% 423979
#% 453325
#% 465754
#% 483245
#% 494594
#% 748499
#% 950475
#% 1290045
#% 1389749
#% 1860547
#! In this paper we analyse the strengths and weaknesses of the mainly used feature selection methods in text categorization when they are applied to the spam problem domain. Several experiments with different feature selection methods and content-based filtering techniques are carried out and discussed. Information Gain, χ2-text, Mutual Information and Document Frequency feature selection methods have been analysed in conjunction with Naïve Bayes, boosting trees, Support Vector Machines and ECUE models in different scenarios. From the experiments carried out the underlying ideas behind feature selection methods are identified and applied for improving the feature selection process of SpamHunting, a novel anti-spam filtering software able to accurate classify suspicious e-mails.

#index 1727214
#* Evaluation of web robot discovery techniques: a benchmarking study
#@ Nick Geens;Johan Huysmans;Jan Vanthienen
#t 2006
#c 18
#% 197533
#% 420132
#% 494702
#% 497208
#% 630984
#% 711323
#% 1273802
#! This paper describes part of a web usage mining study executed on log files obtained from a Belgian e-commerce company. From these log files, it can be observed that numerous web robots are active on the site. Most of these robots show a crawling behavior that is radically different from the browsing behavior of human visitors. Because the owners of the e-shop desire information about the paths that human visitors follow through the site, it is of crucial importance to remove these robotic visits from the log files. Several existing methods for web robot discovery are evaluated and compared, none of them leading to satisfying results. Therefore, a new technique is developed that results in a successful and reliable identification of web robots.

#index 1727215
#* Data preparation of web log files for marketing aspects analyses
#@ Meike Reichle;Petra Perner;Klaus-Dieter Althoff
#t 2006
#c 18
#% 451540
#% 494702
#% 497208
#% 928618
#% 1705276
#% 1722150
#! This article deals with several aspects of a marketing-oriented analysis of web log files. It discusses their preprocessing and possible ways to enrich the raw data that can be gained from a web log file in order to facilitate a later use in different analyses. Further, we look at the question which requirements a good web log analysis software needs to meet and offer an overview over current and future analysis practices including their advantages and disadvantages.

#index 1727216
#* UP-DRES: user profiling for a dynamic REcommendation system
#@ Enza Messina;Daniele Toscani;Francesco Archetti
#t 2006
#c 18
#% 124010
#% 169803
#% 173879
#% 220707
#% 220709
#% 220711
#% 228248
#% 232708
#% 258826
#% 266281
#% 308739
#% 314933
#% 413553
#% 420495
#% 428243
#% 451536
#% 494702
#% 497208
#% 635154
#% 643519
#% 648320
#% 723398
#% 731615
#% 754126
#% 1048456
#% 1275346
#% 1650569
#% 1733312
#! The WWW is actually the most dynamic and attractive information exchange place. Finding useful information is hard due to huge data amount, varied topics and unstructured contents. In this paper we present a web browsing support system that proposes personalized contents. It is integrated in the content management system and it runs on the server hosting the site. It processes periodically site contents, extracting vectors of the most significant words. A topology tree is defined applying hierarchical clustering. During online browsing, viewed contents are processed and mapped in the vector space previously defined. The centroid of these vectors is compared with the topology tree nodes' centroids to find the most similar; its contents are presented to the user as link suggestions or dynamically created pages. Personal profile is saved after every session and included in the analysis during same user's subsequent visits, avoiding the cold start problem.

#index 1727217
#* Improving effectiveness on clickstream data mining
#@ Cristina Wanzeller;Orlando Belo
#t 2006
#c 18
#% 168280
#% 176887
#% 194874
#% 405727
#% 466676
#% 478112
#% 478466
#% 630984
#! Developing and applying data mining processes are often very complex tasks to users without deep knowledge in this domain, particularly when such tasks involve clickstream data processing. One important and known challenge arises in the selection of mining methods to apply on a specific data analysis problem, trying to get better and useful results for a particular goal. Our approach to address this challenge relies on the reuse of the acquired experience from similar problems, which had provided successful mining processes in the past. In order to accomplish such goal, we implemented a prototype mining plans selection system, based on the Case-Based Reasoning paradigm. In this paper we explain how this paradigm and the implemented system may be explored to assist decisions on the data mining or Web usage mining specific scope. Additionally, we also identify the underlying issues and the approaches that were followed.

#index 1727218
#* Conceptual knowledge retrieval with FooCA: improving web search engine results with contexts and concept hierarchies
#@ Bjoern Koester
#t 2006
#c 18
#% 248218
#% 268079
#% 384416
#% 388301
#% 519555
#% 742991
#% 1704974
#% 1704993
#% 1705156
#% 1705162
#% 1738865
#% 1740465
#% 1740484
#! This paper presents a new approach to accessing information on the Web. FooCA, an application in the field of Conceptual Knowledge Processing, is introduced to support a holistic representation of today's standard sequential Web search engine retrieval results. FooCA uses the itemset consisting of the title, a short description, and the URL to build a context and the appropriate concept hierarchy. In order to generate a nicely arranged concept hierarchy using line diagrams to retrieve and analyze the data, the prior context can be iteratively explored and enhanced. The combination of Web Mining techniques and Formal Concept Analysis (FCA) with contextual attribute elicitation gives the user more insight and more options than a traditional search engine interface. Besides serving as a tool for holistic data exploration, FooCA also enables the regular user to learn step by step how to run new, optimized search queries for his personal information need on the Web.

#index 1727219
#* A pruning based incremental construction algorithm of concept lattice
#@ Zhang Ji-Fu;Hu Li-Hua;Zhang Su-Lan
#t 2006
#c 18
#% 90513
#% 169705
#% 316709
#! The concept lattice has played an important role in knowledge discovery. However due to inevitable occurrence of redundant information in the construction process of concept lattice, the low construction efficiency has been a main concern in the literature. In this work, an improved incremental construction algorithm of concept lattice over the traditional Godin algorithm, called the pruning based incremental algorithm is proposed, which uses a pruning process to detect and eliminate possible redundant information during the construction. Our pruning based construction algorithm is in nature superior to the Godin algorithm. It can achieve the same structure with the Godin algorithm but with less computational complexity. In addition, our pruning based algorithm is also experimentally validated by taking the star spectra from the LAMOST project as the formal context.

#index 1727220
#* Association rule mining with chi-squared test using alternate genetic network programming
#@ Kaoru Shimada;Kotaro Hirasawa;Jinglu Hu
#t 2006
#c 18
#% 201894
#% 227919
#% 452845
#% 481290
#% 631970
#% 767654
#% 868999
#% 1414321
#% 1781667
#! A method of association rule mining using Alternate Genetic Network Programming (aGNP) is proposed. GNP is one of the evolutionary optimization techniques, which uses directed graph structures as genes. aGNP is an extended GNP in terms of including two kinds of sets of node functions. The proposed system can extract important association rules whose antecedent and consequent are composed of the attributes of each family defined by users. The method measures the significance of association via chi-squared test using GNP's features. Rule extraction is done without identifying frequent itemsets used in Apriori-like methods. Therefore, the method can be applied to rule extraction from dense database, and can extract dependent pairs of the sets of attributes in the database. Extracted rules are stored in a pool all together through generations and reflected in genetic operators as acquired information. In this paper, we describe the algorithm capable of finding the important association rules and present some experimental results.

#index 1727221
#* Ordinal classification with monotonicity constraints
#@ Tomáš Horváth;Peter Vojtáš
#t 2006
#c 18
#% 398839
#% 399790
#% 449588
#% 458623
#! Classification methods commonly assume unordered class values. In many practical applications – for example grading – there is a natural ordering between class values. Furthermore, some attribute values of classified objects can be ordered, too. The standard approach in this case is to convert the ordered values into a numeric quantity and apply a regression learner to the transformed data. This approach can be used just in case of linear ordering. The proposed method for such a classification lies on the boundary between ordinal classification trees, classification trees with monotonicity constraints and multi-relational classification trees. The advantage of the proposed method is that it is able to handle non-linear ordering on the class and attribute values. For the better understanding, we use a toy example from the semantic web environment – prediction of rules for the user's evaluation of hotels.

#index 1727222
#* Local modelling in classification on different feature subspaces
#@ Gero Szepannek;Claus Weihs
#t 2006
#c 18
#% 771846
#% 1272365
#! Sometimes one may be confronted with classification problems where classes are constituted of several subclasses that possess different distributions and therefore destroy accurate models of the entire classes as one similar group. An issue is modelling via local models of several subclasses. In this paper, a method is presented of how to handle such classification problems where the subclasses are furthermore characterized by different subsets of the variables. Situations are outlined and tested where such local models in different variable subspaces dramatically improve the classification error.

#index 1727223
#* Supervised selection of dynamic features, with an application to telecommunication data preparation
#@ Sylvain Ferrandiz;Marc Boullé
#t 2006
#c 18
#% 243728
#% 722929
#% 770774
#% 894018
#% 1705281
#! In the field of data mining, data preparation has more and more in common with a bottleneck. Indeed, collecting and storing data becomes cheaper while modelling costs remain unchanged. As a result, feature selection is now usually performed. In the data preparation step, selection often relies on feature ranking. In the supervised classification context, ranking is based on the information that the explanatory feature brings on the target categorical attribute. With the increasing presence in the database of feature measured over time, i.e. dynamic features, new supervised ranking methods have to be designed. In this paper, we propose a new method to evaluate dynamic features, which is derived from a probabilistic criterion. The criterion is non-parametric and handles automatically the problem of overfitting the data. The resulting evaluation produces reliable results. Furthermore, the design of the criterion relies on an understandable and simple approach. This allows to provide meaningful visualization of the evaluation, in addition to the computed score. The advantages of the new method are illustrated on a telecommunication dataset.

#index 1727224
#* Using multi-SOMs and multi-neural-gas as neural classifiers
#@ Nils Goerke;Alexandra Scherbart
#t 2006
#c 18
#% 356892
#% 361966
#% 566611
#! Within this paper we present the extension of two neural network paradigms for clustering tasks. The Self Organizing feature Maps (SOM) are extended to the Multi SOM approach, and the Neural Gas is extended to a Multi Neural Gas. Some common cluster analysis coefficients (Silhouette Coefficient, Gap Statistics, Calinski-Harabasz Coefficient)have been adapted for the new paradigms. Both new neural clustering methods are described and evaluated briefly using exemplary data sets.

#index 1727225
#* Derivative free stochastic discrete gradient method with adaptive mutation
#@ Ranadhir Ghosh;Moumita Ghosh;Adil Bagirov
#t 2006
#c 18
#% 33917
#! In data mining we come across many problems such as function optimization problem or parameter estimation problem for classifiers for which a good learning algorithm for searching is very much necessary. In this paper we propose a stochastic based derivative free algorithm for unconstrained optimization problem. Many derivative-based local search methods exist which usually stuck into local solution for non-convex optimization problems. On the other hand global search methods are very time consuming and works for only limited number of variables. In this paper we investigate a derivative free multi search gradient based method which overcomes the problems of local minima and produces global solution in less time. We have tested the proposed method on many benchmark dataset in literature and compared the results with other existing algorithms. The results are very promising.

#index 1727226
#* Association analysis of customer services from the enterprise customer management system
#@ Sung-Ju Kim;Dong-Sik Yun;Byung-Soo Chang
#t 2006
#c 18
#% 393812
#! The communications market has seen rising competition among businesses. While securing new customers is still important, it is more crucial to maintain and manage existing customers by providing optimized service and efficient marketing strategies for each customer in order to preserve existing customers from business rivals and ultimately maximize corporate sales. This thesis investigates how to obtain useful methodologies for customer management by applying the technological concepts of data-mining and association analysis to KT's secure customer data.

#index 1727227
#* Feature selection in an electric billing database considering attribute inter-dependencies
#@ Manuel Mejía-Lavalle;Eduardo F. Morales
#t 2006
#c 18
#% 52824
#% 243728
#% 452821
#% 458371
#% 478122
#% 596099
#% 629619
#% 722929
#% 762666
#% 770799
#% 793239
#% 1012295
#% 1673006
#% 1860903
#! With the increasing size of databases, feature selection has become a relevant and challenging problem for the area of knowledge discovery in databases. An effective feature selection strategy can significantly reduce the data mining processing time, improve the predicted accuracy, and help to understand the induced models, as they tend to be smaller and make more sense to the user. Many feature selection algorithms assumed that the attributes are independent between each other given the class, which can produce models with redundant attributes and/or exclude sets of attributes that are relevant when considered together. In this paper, an effective best first search algorithm, called buBF, for feature selection is described. buBF uses a novel heuristic function based on n-way entropy to capture inter-dependencies among variables. It is shown that buBF produces more accurate models than other state-of-the-art feature selection algorithms when compared on several real and synthetic datasets. Specifically we apply buBF to a Mexican Electric Billing database and obtain satisfactory results.

#index 1727228
#* Learning the reasons why groups of consumers prefer some food products
#@ Juan José del Coz;Jorge Díez;Antonio Bahamonde;Carlos Sañudo;Matilde Alfonso;Philippe Berge;Eric Dransfield;Costas Stamataris;Demetrios Zygoyiannis;Tyri Valdimarsdottir;Edi Piasentier;Geoffrey Nute;Alan Fisher
#t 2006
#c 18
#% 269217
#% 413456
#% 425048
#% 577224
#% 722938
#% 722941
#% 770800
#% 1272396
#% 1673593
#! In this paper we propose a method for learning the reasons why groups of consumers prefer some food products instead of others of the same type. We emphasize the role of groups given that, from a practical point of view, they may represent market segments that demand different products. Our method starts representing in a metric space people preferences; there we are able to define similarity functions that allow a clustering algorithm to discover significant groups of consumers with homogeneous tastes. Finally in each cluster, we learn, with a SVM, a function that explains the tastes of the consumers grouped in the cluster. Additionally, a feature selection process highlights the essential properties of food products that have a major influence on their acceptability. To illustrate our method, a real case of consumers of lamb meat was studied. The panel was formed by 773 people of 216 families from 6 European countries. Different tastes between Northern and Southern families were enhanced.

#index 1727229
#* Exploiting randomness for feature selection in multinomial logit: a CRM cross-sell application
#@ Anita Prinzie;Dirk Van den Poel
#t 2006
#c 18
#% 243728
#% 400847
#% 425047
#% 464444
#% 785395
#% 796212
#% 943927
#% 1781611
#% 1861376
#! Data mining applications addressing classification problems must master two key tasks: feature selection and model selection. This paper proposes a random feature selection procedure integrated within the multinomial logit (MNL) classifier to perform both tasks simultaneously. We assess the potential of the random feature selection procedure (exploiting randomness) as compared to an expert feature selection method (exploiting domain-knowledge) on a CRM cross-sell application. The results show great promise as the predictive accuracy of the integrated random feature selection in the MNL algorithm is substantially higher than that of the expert feature selection method.

#index 1727230
#* Data mining analysis on italian family preferences and expenditures
#@ Paola Annoni;Pier Alda Ferrari;Silvia Salini
#t 2006
#c 18
#% 232136
#% 393792
#! Italian expenditures are a complex system. Every year the Italian National Bureau of Statistics (ISTAT) carries out a survey on the expenditure behavior of Italian families. The survey regards household expenditures on durable and daily goods and on various services. Our goal is here twofold: firstly we describe the most important characteristics of family behavior with respect to expenditures on goods and usage of different services; secondly possible relationships among these behaviors are highlighted and explained by social-demographical features of families. Different data mining techniques are jointly used to these aims so as to identify different capabilities of selected methods within these kinds of issues. In order to properly focalize on service usage, further investigation will be needed about the nature of investigated services (private or public) and, most of all, about their supply and effectiveness along the national territory.

#index 1727231
#* Multiobjective evolutionary induction of subgroup discovery fuzzy rules: a case study in marketing
#@ Francisco Berlanga;María José del Jesus;Pedro González;Francisco Herrera;Mikel Mesonero
#t 2006
#c 18
#% 191910
#% 232106
#% 232126
#% 232136
#% 369236
#% 389460
#% 392343
#% 402388
#% 466374
#% 477497
#% 550575
#% 763701
#% 769691
#% 1272357
#% 1777209
#! This paper presents a multiobjective genetic algorithm which obtains fuzzy rules for subgroup discovery in disjunctive normal form. This kind of fuzzy rules lets us represent knowledge about patterns of interest in an explanatory and understandable form which can be used by the expert. The evolutionary algorithm follows a multiobjective approach in order to optimize in a suitable way the different quality measures used in this kind of problems. Experimental evaluation of the algorithm, applying it to a market problem studied in the University of Mondragón (Spain), shows the validity of the proposal. The application of the proposal to this problem allows us to obtain novel and valuable knowledge for the experts.

#index 1727232
#* A scatter search algorithm for the automatic clustering problem
#@ Rasha S. Abdule-Wahab;Nicolas Monmarché;Mohamed Slimane;Moaid A. Fahdil;Hilal H. Saleh
#t 2006
#c 18
#% 246206
#% 294730
#% 316709
#% 655368
#% 683550
#% 839740
#! We present a new hybrid algorithm for data clustering. This new proposal uses one of the well known evolutionary algorithms called Scatter Search. Scatter Search operates on a small set of solutions and makes only a limited use of randomization for diversification when searching for globally optimal solutions. The proposed method discovers automatically cluster number and cluster centres without prior knowledge of a possible number of class, and without any initial partition. We have applied this algorithm on standard and real world databases and we have obtained good results compared to the K-means algorithm and an artificial ant based algorithm, the Antclass algorithm.

#index 1727233
#* Multi-objective parameters selection for SVM classification using NSGA-II
#@ Li Xu;Chunping Li
#t 2006
#c 18
#% 190581
#% 269217
#% 392343
#% 425040
#% 466759
#% 544337
#% 959434
#% 1656021
#% 1656047
#% 1777209
#! Selecting proper parameters is an important issue to extend the classification ability of Support Vector Machine (SVM), which makes SVM practically useful. Genetic Algorithm (GA) has been widely applied to solve the problem of parameters selection for SVM classification due to its ability to discover good solutions quickly for complex searching and optimization problems. However, traditional GA in this field relys on single generalization error bound as fitness function to select parameters. Since there have several generalization error bounds been developed, picking and using single criterion as fitness function seems intractable and insufficient. Motivated by the multi-objective optimization problems, this paper introduces an efficient method of parameters selection for SVM classification based on multi-objective evolutionary algorithm NSGA-II. We also introduce an adaptive mutation rate for NSGA-II. Experiment results show that our method is better than single-objective approaches, especially in the case of tiny training sets with large testing sets.

#index 1727234
#* Effectiveness evaluation of data mining based IDS
#@ Agustín Orfila;Javier Carbó;Arturo Ribagorda
#t 2006
#c 18
#% 310519
#% 318765
#% 321553
#% 340031
#% 340039
#% 593093
#% 641048
#% 664716
#% 754414
#% 829208
#% 829230
#% 926881
#% 1705277
#% 1705310
#% 1705641
#! Data mining has been widely applied to the problem of Intrusion Detection in computer networks. However, the misconception of the underlying problem has led to out of context results. This paper shows that factors such as the probability of intrusion and the costs of responding to detected intrusions must be taken into account in order to compare the effectiveness of machine learning algorithms over the intrusion detection domain. Furthermore, we show the advantages of combining different detection techniques. Results regarding the well known 1999 KDD dataset are shown.

#index 1727235
#* Spectral discrimination of southern victorian salt tolerant vegetation
#@ Chris Matthews;Rob Clark;Leigh Callinan
#t 2006
#c 18
#% 136350
#% 342634
#% 926881
#! The use of remotely sensed data to map aspects of the landscape is both efficient and cost effective. In geographically large and sparsely populated countries such as Australia these approaches are attracting interest as an aid in the identification of areas affected by environmental problems such as dryland salinity. This paper investigates the feasibility of using visible and near infra-red spectra to distinguish between salt tolerant and salt sensitive vegetation species in order to identify saline areas in Southern Victoria, Australia. A series of classification models were built using a variety of data mining techniques and these together with a discriminant analysis suggested that excellent generalisation results could be achieved on a laboratory collected spectra data base. The results form a basis for continuing work on the development of methods to distinguish between vegetation species based on remotely sensed rather than laboratory based measurements.

#index 1727236
#* A generative graphical model for collaborative filtering of visual content
#@ Sabri Boutemedjet;Djemel Ziou
#t 2006
#c 18
#% 173879
#% 280819
#% 301259
#% 424016
#% 424028
#% 734590
#% 769243
#% 788938
#% 1650569
#% 1855694
#! In this paper, we propose a novel generative graphical model for collaborative filtering of visual content. The preferences of the ”like-minded” users are modelled in order to predict the relevance of visual documents represented by their visual features. We formulate the problem using a probabilistic latent variable model where user's preferences and items' classes are combined into a unified framework in order to provide an accurate and a generative model that overcomes the new item problem, generally encountered in traditional collaborative filtering systems.

#index 1727237
#* A variable initialization approach to the EM algorithm for better estimation of the parameters of hidden markov model based acoustic modeling of speech signals
#@ Md. Shamsul Huda;Ranadhir Ghosh;John Yearwood
#t 2006
#c 18
#% 207195
#% 312387
#% 345829
#% 449660
#% 624716
#% 668895
#% 814035
#% 1023186
#% 1051482
#% 1546159
#% 1781080
#! The traditional method for estimation of the parameters of Hidden Markov Model (HMM) based acoustic modeling of speech uses the Expectation-Maximization (EM) algorithm. The EM algorithm is sensitive to initial values of HMM parameters and is likely to terminate at a local maximum of likelihood function resulting in non-optimized estimation for HMM and lower recognition accuracy. In this paper, to obtain better estimation for HMM and higher recognition accuracy, several candidate HMMs are created by applying EM on multiple initial models. The best HMM is chosen from the candidate HMMs which has highest value for likelihood function. Initial models are created by varying maximum frame number in the segmentation step of HMM initialization process. A binary search is applied while creating the initial models. The proposed method has been tested on TIMIT database. Experimental results show that our approach obtains improved values for likelihood function and improved recognition accuracy.

#index 1727238
#* Mining dichromatic colours from video
#@ Vassili A. Kovalev
#t 2006
#c 18
#% 318785
#% 393453
#% 426686
#% 435729
#% 592155
#% 611556
#% 643933
#% 775240
#% 800182
#% 1112566
#% 1705303
#% 1775213
#% 1775354
#% 1775356
#% 1775357
#% 1775389
#% 1775440
#% 1775445
#% 1855340
#% 1857842
#! It is commonly accepted that the most powerful approaches for increasing the efficiency of visual content delivery are personalisation and adaptation of visual content according to user's preferences and his/her individual characteristics. In this work, we present results of a comparative study of colour contrast and characteristics of colour change between successive video frames for normal vision and two most common types of colour blindness: the protanopia and deuteranopia. The results were obtained by colour mining from three videos of different kind including their original and simulated colour blind versions. Detailed data regarding the reduction of colour contrast, decreasing of the number of distinguishable colours, and reduction of inter-frame colour change rate in dichromats are provided.

#index 1727239
#* Feature analysis and classification of classical musical instruments: an empirical study
#@ Christian Simmermacher;Da Deng;Stephen Cranefield
#t 2006
#c 18
#% 136350
#% 267568
#% 793239
#% 899454
#% 926881
#% 991007
#% 1767185
#% 1857847
#! We present an empirical study on classical music instrument classification. A methodology with feature extraction and evaluation is proposed and assessed with a number of experiments, whose final stage is to detect instruments in solo passages. In feature selection it is found that similar but different rankings for individual tone classification and solo passage instrument recognition are reported. Based on the feature selection results, excerpts from concerto and sonata files are processed, so as to detect and distinguish four major instruments in solo passages: trumpet, flute, violin, and piano. Nineteen features selected from the Mel-frequency cepstral coefficients (MFCC) and the MPEG-7 audio descriptors achieve a recognition rate of around 94% by the best classifier assessed by cross validation.

#index 1727240
#* Automated classification of images from crystallisation experiments
#@ Julie Wilson
#t 2006
#c 18
#% 58636
#% 116390
#! Protein crystallography can often provide the three-dimensional structures of macro-molecules necessary for functional studies and drug design. However, identifying the conditions that will provide diffraction quality crystals often requires numerous experiments. The use of robots has led to a dramatic increase in the number of crystallisation experiments performed in most laboratories and, in structural genomics centres, tens of thousands of experiments can be produced daily. The results of these experiments must be assessed repeatedly over time and inspection of the results by eye is becoming increasingly impractical. A number of systems are now available for automated imaging of crystallisation experiments and the primary aim of this research is the development of software to automate image analysis.

#index 1727241
#* An efficient algorithm for frequent itemset mining on data streams
#@ Xie Zhi-jun;Chen Hong;Cuiping Li
#t 2006
#c 18
#% 232136
#% 300120
#% 310500
#% 333926
#% 336610
#% 378388
#% 397354
#% 481290
#% 769898
#% 993960
#! In order to mining frequent itemsets on data stream efficiently, a new approach was proposed in this paper. The memory efficient and accurate one-pass algorithm divides all the frequent itemsets into frequent equivalence classes and prune all the redundant itemsets except for those represent the GLB(Greatest Lower Bound) and LUB(Least Upper Bound) of the frequent equivalence class and the number of GLB and LUB is much less than that of frequent itemsets. In order to maintain these equivalence classes, A compact data structure, the frequent itemset enumerate tree (FIET) was proposed in the paper. The detailed experimental evaluation on synthetic and real datasets shows that the algorithm is very accurate in practice and requires significantly lower memory than Jin and Agrawal's one pass algorithm.

#index 1727242
#* Discovering key sequences in time series data for pattern classification
#@ Peter Funk;Ning Xiong
#t 2006
#c 18
#% 232106
#% 280473
#% 316560
#% 333941
#% 459006
#% 463903
#% 479971
#% 631923
#% 632088
#% 769628
#% 821868
#% 1705293
#% 1705296
#% 1722149
#% 1781027
#! This paper addresses the issue of discovering key sequences from time series data for pattern classification. The aim is to find from a symbolic database all sequences that are both indicative and non-redundant. A sequence as such is called a key sequence in the paper. In order to solve this problem we first we establish criteria to evaluate sequences in terms of the measures of evaluation base and discriminating power. The main idea is to accept those sequences appearing frequently and possessing high co-occurrences with consequents as indicative ones. Then a sequence search algorithm is proposed to locate indicative sequences in the search space. Nodes encountered during the search procedure are handled appropriately to enable completeness of the search results while removing redundancy. We also show that the key sequences identified can later be utilized as strong evidences in probabilistic reasoning to determine to which class a new time series most probably belongs.

#index 1727243
#* Data alignment via dynamic time warping as a prerequisite for batch-end quality prediction
#@ Geert Gins;Jairo Espinosa;Ilse Y. Smets;Wim Van Brempt;Jan F. M. Van Impe
#t 2006
#c 18
#! In this work, a 4-phase dynamic time warping is implemented to align measurement profiles from an existing chemical batch reactor process, making all batch measurement profiles equal in length, while also matching the major events occurring during each batch run. This data alignment is the first step towards constructing an inferential batch-end quality sensor, capable of predicting 3 quality variables before batch run completion using a multivariate statistical partial least squares model. This inferential sensor provides on-line quality predictions, allowing corrective actions to be performed when the quality of the polymerization product does not meet the specifications, saving valuable production time and reducing operation cost.

#index 1727244
#* A distance measure for determining similarity between criminal investigations
#@ Tim K. Cocx;Walter A. Kosters
#t 2006
#c 18
#% 342612
#% 549426
#% 858459
#% 858549
#% 1339867
#! The information explosion has led to problems and possibilities in many areas of society, including that of law enforcement. In comparing individual criminal investigations on similarity, we seize one of the opportunities of the information surplus to determine what crimes may or may not have been committed by the same group of individuals. For this purpose we introduce a new distance measure that is specifically suited to the comparison between investigations that differ largely in terms of available intelligence. It employs an adaptation of the probability density function of the normal distribution to constitute this distance between all possible couples of investigations. We embed this distance measure in a four-step paradigm that extracts entities from a collection of documents and use it to transform a high dimensional vector table into input for a police operable tool. The eventual report is a two-dimensional representation of the distances between the various investigations and will assist the police force on the job to get a clearer picture of the current situation.

#index 1727245
#* Establishing fraud detection patterns based on signatures
#@ Pedro Ferreira;Ronnie Alves;Orlando Belo;Luís Cortesão
#t 2006
#c 18
#% 158832
#% 280515
#% 308753
#% 420064
#% 420123
#% 493574
#% 580231
#% 769888
#% 769933
#% 772838
#% 781774
#! All over the world we have been assisting to a significant increase of the telecommunication systems usage. People are faced day after day with strong marketing campaigns seeking their attention to new telecommunication products and services. Telecommunication companies struggle in a high competitive business arena. It seems that their efforts were well done, because customers are strongly adopting the new trends and use (and abuse) systematically communication services in their quotidian. Although fraud situations are rare, they are increasing and they correspond to a large amount of money that telecommunication companies lose every year. In this work, we studied the problem of fraud detection in telecommunication systems, especially the cases of superimposed fraud, providing an anomaly detection technique, supported by a signature schema. Our main goal is to detect deviate behaviors in useful time, giving better basis to fraud analysts to be more accurate in their decisions in the establishment of potential fraud situations.

#index 1727246
#* Intelligent information systems for knowledge work(ers)
#@ Klaus-Dieter Althoff;Björn Decker;Alexandre Hanft;Jens Mänz;Régis Newo;Markus Nick;Jörg Rech;Martin Schaaf
#t 2006
#c 18
#% 127957
#% 168280
#% 176887
#% 373871
#% 474987
#% 644949
#% 742781
#! Our society needs and expects more high-value services. Such “knowledge-intensive” services can only be delivered if the necessary organizational and technical requirements are fulfilled. In addition, the cost-benefit analysis from the service provider point of view needs to be positive. Continuous improvement and goal-directed (partial) automation of such services is therefore of crucial importance. As a contribution to this we describe our current research vision for (partially) automated support of knowledge work(ers) based on intelligent information systems focusing on the use of experience. For the implementation of such a vision we base on the integration of approaches from artificial intelligence and software engineering. A “deep” integration of case-based reasoning and experience factory is a first successful step in this direction [33, 28]. We envision the further integration of software product-lines and multi-agent systems as the next one.

#index 1727247
#* Nonparametric approaches for e-learning data
#@ Paolo Baldini;Silvia Figini;Paolo Giudici
#t 2006
#c 18
#! In the paper we propose nonparametric approaches for e-learning data. In particular we want to supply a measure of the relative exercises importance, to estimate the acquired Knowledge for each student and finally to personalize the e-learning platform. The methodology employed is based on a comparison between nonparametric statistics for kernel density classification and parametric models such as generalized linear models and generalized additive models.

#index 1727248
#* An intelligent manufacturing process diagnosis system using hybrid data mining
#@ Joon Hur;Hongchul Lee;Jun-Geol Baek
#t 2006
#c 18
#% 136350
#% 174161
#% 207252
#% 230458
#% 316709
#% 364517
#% 376266
#% 393792
#% 449588
#% 487684
#% 769687
#! The high cost of maintaining a complex manufacturing process necessitates the enhancement of an efficient maintenance system. For the efficient maintenance of manufacturing process, precise diagnosis of the manufacturing process should be performed and the appropriate maintenance action should be executed when the current condition of the manufacturing system is diagnosed as being in abnormal condition. This paper suggests an intelligent manufacturing process diagnosis system using hybrid data mining. In this system, the cause-and-effect rules for the manufacturing process condition are inferred by hybrid decision tree/evolution strategies learning and the most effective maintenance action is recommended by a decision network and AHP (analytical hierarchy process). To verify the hybrid learning proposed in this paper, we compared the accuracy of the hybrid learning with that of the general decision tree learning algorithm (C4.5) and hybrid decision tree/genetic algorithm learning by using datasets from the well-known dataset repository at UCI (University of California at Irvine).

#index 1727249
#* Computer network monitoring and abnormal event detection using graph matching and multidimensional scaling
#@ H. Bunke;P. Dickinson;A. Humm;Ch. Irniger;M. Kraetzl
#t 2006
#c 18
#% 288990
#% 296738
#% 344399
#% 616822
#% 727871
#% 771769
#% 1705277
#% 1705310
#% 1863041
#! Computer network monitoring and abnormal event detection have become important areas of research. In previous work, it has been proposed to represent a computer network as a time series of graphs and to compute the difference, or distance, of consecutive graphs in such a time series. Whenever the distance of two graphs exceeds a given threshold, an abnormal event is reported. In the present paper we go one step further and compute graph distances between all pairs of graphs in a time series. Given these distances, a multidimensional scaling procedure is applied that maps each graph onto a point in the two-dimensional real plane, such that the distances between the graphs are reflected, as closely as possible, in the distances between the points in the two-dimensional plane. In this way the behaviour of a network can be visualised and abnormal events as well as states or clusters of states of the network can be graphically represented. We demonstrate the feasibility of the proposed method by means of synthetically generated graph sequences and data from real computer networks.

#index 1892054
#* Proceedings of the 12th Industrial conference on Advances in Data Mining: applications and theoretical aspects
#@ Petra Perner
#t 2012
#c 18

#index 1892055
#* Application of classification algorithms on IDDM rat data
#@ Rainer Schmidt;Heike Weiss;Georg Fuellen
#t 2012
#c 18
#% 136350
#% 140588
#% 400847
#% 1038778
#% 1301004
#% 1617033
#% 1617047
#! In our study, we intend to investigate the mechanism of tolerance induction by the modulatory anti CD4 monoclonal antibody RIB 5/2 in insulin dependent diabetes mellitus rats. The aim of this investigation is to identify the key mechanisms of immune tolerance on the level of T cell, cytokine, and chemokine biomarkers in the blood, lymphatic organs, and pancreas. Additionally, it should be possible to define good biomarkers of autoimmunity and tolerance for prediction of diabetes onset. We mainly applied decision trees and later on some other classification algorithms on a rather small data set. Unfortunately, the results are not significant but are good enough to satisfy our biological partners.

#index 1892056
#* Research themes in the case-based reasoning in health sciences core literature
#@ Isabelle Bichindaritz
#t 2012
#c 18
#% 89782
#% 490430
#% 494598
#% 566459
#% 866957
#% 1046495
#% 1109927
#% 1291578
#% 1291582
#% 1557671
#% 1868180
#! Research in case-based reasoning (CBR) in the health sciences started more than 20 years ago and has been steadily expanding during these years. This paper describes the state of the research through an analysis of its mainstream, or core, literature. The methodology followed involves first the definition of a classification and indexing scheme for this research area using a tiered approach to paper categorization based on application domain, purpose of the research, memory organization, reasoning characteristics, and system design. A research theme can be tied to any of the previous classification elements. The paper further analyzes the evolution of the literature, its characteristics in terms of highest impact, or most cited, papers, and draws conclusions from this analysis. Finally, a comparison with the themes automatically learned through clustering co-citations matrices with the Ensemble Non-negative Matrix Factorization (NMF) algorithm in the CBR conference literature is proposed. This comparison helps better understand the main characteristics of the field and propose future directions.

#index 1892057
#* Research on application of data mining methods to diagnosing gastric cancer
#@ Arnis Kirshners;Serge Parshutin;Marcis Leja
#t 2012
#c 18
#% 269634
#% 393812
#% 443494
#% 449566
#% 763701
#% 818916
#% 835018
#! Constantly evolving technologies bring new possibilities for supporting decision making in different areas - finance, marketing, production, social area, healthcare and others. Decision support systems are widely used in medicine in developed countries and show positive results. This research reveals several possibilities of application of data mining methods to diagnosing gastric cancer, which is the fourth leading cancer type in incidence after the breast, lung and colorectal cancers. A simple decision support system model was introduced and tested using gastric cancer inquiry form statistical data. The obtained results reveal both the benefits and potential of application of DSS aimed to support a medical expert decision, and some shortcomings mainly connected with performing an appropriate data preprocessing before mining knowledge and building the model. The paper presents the technologies behind the DSS and shows the detailed evaluation process with discussions.

#index 1892058
#* SOHAC: efficient storage of tick data that supports search and analysis
#@ Gabor I. Nagy;Krisztian Buza
#t 2012
#c 18
#% 314054
#% 443984
#% 739871
#% 835018
#% 1040840
#% 1332369
#% 1567948
#% 1603737
#% 1674762
#% 1861495
#! Storage of tick data is a challenging problem because two criteria have to be fulfilled simultaneously: the storage structure should allow fast execution of queries and the data should not occupy too much space on the hard disk or in the main memory. In this paper, we present a clustering-based solution, and we introduce a new clustering algorithm that is designed to support the storage of tick data. We evaluate our algorithm both on publicly available real-world datasets, as well as real-world tick data from the financial domain provided by one of the world-wide most renowned investment bank. In our experiments we compare our approach, SOHAC, against a large collection of conventional hierarchical clustering algorithms from the literature. The experiments show that our algorithm substantially outperforms --- both in terms of statistical significance and practical relevance --- the examined clustering algorithms for the tick data storage problem.

#index 1892059
#* Electricity consumption time series profiling: a data mining application in energy industry
#@ Hongyan Liu;Zhiyuan Yao;Tomas Eklund;Barbro Back
#t 2012
#c 18
#% 234978
#% 261840
#% 316709
#% 361100
#% 386001
#% 391311
#% 750187
#% 920176
#% 1197355
#% 1489134
#% 1663452
#% 1860652
#! The ongoing deployment of Automated Meter Reading systems (AMR) in the European electricity industry has created new challenges for electricity utilities in terms of how to fully utilise the wealth of timely measured AMR data, not only to enhance day-to-day operations, but also to facilitate demand response programs. In this study we investigate a visual data mining approach for decision-making support with respect to pricing differentiation or designing demand response tariffs. We cluster the customers in our sample according to the customers' actual consumption behaviour in 2009, and profile their electricity consumption with a focus on the comparison of two sets of seasonal and time based variables. The results suggest that such an analytical approach can visualise deviations and granular information in consumption patterns, allowing the electricity companies to gain better knowledge about the customers' electricity usage. The investigated electricity consumption time series profiling approach will add empirical understanding of the problem domain to the related research community and to the future practice of the energy industry.

#index 1892060
#* Wind turbines fault diagnosis using ensemble classifiers
#@ Pedro Santos;Luisa F. Villa;Aníbal Reñones;Andrés Bustillo;Jesús Maudes
#t 2012
#c 18
#% 551723
#% 742990
#% 889165
#% 992779
#% 1100754
#% 1350738
#% 1472490
#! Fault diagnosis in machines that work under a wide range of speeds and loads is currently an active area of research. Wind turbines are one of the most recent examples of these machines in industry. Conventional vibration analysis applied to machines throughout their operation is of limited utility when the speed variation is too high. This work proposes an alternative methodology for fault diagnosis in machines: the combination of angular resampling techniques for vibration signal processing and the use of data mining techniques for the classification of the operational state of wind turbines. The methodology has been validated over a test-bed with a large variation of speeds and loads which simulates, on a smaller scale, the real conditions of wind turbines. Over this test-bed two of the most common typologies of faults in wind turbines have been generated: imbalance and misalignment. Several data mining techniques have been used to analyze the dataset obtained by order analysis, having previously processed signals with angular resampling technique. Specifically, the methods used are ensemble classifiers built with Bagging, Adaboost, Geneneral Boosting Projection and Rotation Forest; the best results having been achieved with Adaboost using C4.5 decision trees as base classifiers.

#index 1892061
#* Bus bunching detection by mining sequences of headway deviations
#@ Luís Moreira-Matias;Carlos Ferreira;João Gama;João Mendes-Moreira;Jorge Freire de Sousa
#t 2012
#c 18
#% 459006
#% 463903
#% 464996
#% 481290
#% 870909
#% 951180
#! In highly populated urban zones, it is common to notice headway deviations (HD) between pairs of buses. When these events occur in a bus stop, they often cause bus bunching (BB) in the following bus stops. Several proposals have been suggested to mitigate this problem. In this paper, we propose to find BBS (Bunching Black Spots) --- sequences of bus stops where systematic HD events cause the formation of BB. We run a sequence mining algorithm, named PrefixSpan, to find interesting events available in time series. We prove that we can accurately model the BB trip usual pattern like a frequent sequence mining problem. The subsequences proved to be a promising way of identify the route' schedule points to adjust in order to mitigate such events.

#index 1892062
#* Detecting abnormal patterns in call graphs based on the aggregation of relevant vertex measures
#@ Ronnie Alves;Pedro Ferreira;Joel Ribeiro;Orlando Belo
#t 2012
#c 18
#% 867050
#% 907530
#% 1594652
#% 1710593
#% 1727245
#! Graphs are a very important abstraction to model complex structures and respective interactions, with a broad range of applications including web analysis, telecommunications, chemical informatics and bioinformatics. In this work we are interested in the application of graph mining to identify abnormal behavior patterns from telecom Call Detail Records (CDRs). Such behaviors could also be used to model essential business tasks in telecom, for example churning, fraud, or marketing strategies, where the number of customers is typically quite large. Therefore, it is important to rank the most interesting patterns for further analysis. We propose a vertex relevant ranking score as a unified measure for focusing the search of abnormal patterns in weighted call graphs based on CDRs. Classical graph-vertex measures usually expose a quantitative perspective of vertices in telecom call graphs. We aggregate wellknown vertex measures for handling attribute-based information usually provided by CDRs. Experimental evaluation carried out with real data streams, from a local mobile telecom company, showed us the feasibility of the proposed strategy.

#index 1892063
#* Real-time mass flow estimation in circulating fluidized bed
#@ Andriy Ivannikov;Mikko Jegoroff;Tommi Kärkkäinen
#t 2012
#c 18
#% 51712
#% 1252966
#% 1254206
#% 1428420
#! The mass flow parameter identification is important for modeling and control purposes in Circulating Fluidized Bed technology. In this article we propose a novel method for estimating the mass flow in the Circulating Fluidized Bed and consider aspects of its application. The method is based on combining information obtained from both mass of fuel silo and velocity of fuel screw signals. The information from mass of fuel silo measurements is extracted by following the lower edge of the signal.

#index 1892064
#* Representation in case-based reasoning applied to control reconfiguration
#@ Ons Lejri;Moncef Tagina
#t 2012
#c 18
#% 168280
#% 176887
#% 220157
#% 373871
#% 494606
#% 742814
#% 866956
#% 866962
#% 1276874
#! Cased-Based Reasoning (CBR) is based on the use of previous experiences to solve new problems. In this work, we propose to use CBR paradigm for solving control reconfiguration problems. The reconfiguration task aims to maintain the system working despite some situations that may affect it (faults, change in production strategy, …). The main issue is then to find the new laws or rules to use in each different situation. In this article, we especially focus on the representation part. In fact, representation is a very important task in this type of problematic as the structure of the case will affect all the other phases of the CBR cycle.

#index 1892065
#* The influence of input and output measurement noise on batch-end quality prediction with partial least squares
#@ Jef Vanlaer;Pieter Van den Kerkhof;Geert Gins;Jan F. M. Van Impe
#t 2012
#c 18
#! In this paper, the influence of measurement noise on batch-end quality prediction by Partial Least Squares (PLS) is discussed. Realistic computer-generated data of an industrial process for penicillin production are used to investigate the influence of both input and output noise on model input and model order selection, and online and offline prediction of the final penicillin concentration. Techniques based on PLS show a large potential in assisting human operators in their decisions, especially for batch processes where close monitoring is required to achieve satisfactory product quality. However, many (bio)chemical companies are still reluctant to implement these monitoring techniques since, among other things, little is known about the influence of measurement noise characteristics on their performance. The results of this study indicate that PLS predictions are only slightly worsened by the presence of measurement noise. Moreover, for the considered case study, model predictions are better than offline quality measurements.

#index 1892066
#* An evolving associative classifier for incomplete database
#@ Kaoru Shimada
#t 2012
#c 18
#% 466483
#% 481290
#% 1014660
#% 1034722
#% 1447344
#% 1727220
#% 1776894
#! An associative classification method for incomplete database is proposed based on an evolutionary rule extraction method. The method can extract class association rules directly from the database including missing values and build an associative classifier. Instances including missing values are classified by the classifier. In addition, an evolving associative classifier is proposed. The proposed method evolves the classifier using the labeled instances by itself as acquired information. The performance of the classification was evaluated using artificial incomplete data set. The results showed that the proposed evolving associative classifier has a potential to expand the target data for classification through its evolutionary process and gather useful information itself.

#index 1892067
#* Improving classifier performance by knowledge-driven data preparation
#@ Laura Welcker;Stephan Koch;Frank Dellmann
#t 2012
#c 18
#% 191910
#% 199539
#% 232102
#% 314784
#% 346826
#% 420072
#% 478745
#% 644273
#% 894409
#% 912094
#% 918322
#% 1136044
#% 1228061
#% 1273368
#% 1442655
#% 1567974
#! Classification is a widely used technique in data mining. Thereby achieving a reasonable classifier performance is an increasingly important goal. This paper aims to empirically show how classifier performance can be improved by knowledge-driven data preparation using business, data and methodological know-how. To point out the variety of knowledge-driven approaches, we firstly introduce an advanced framework that breaks down the data preparation phase to four hierarchy levels within the CRISP-DM process model. The first 3 levels reflect methodological knowledge; the last level clarifies the use of business and data know-how. Furthermore, we present insights from a case study to show the effect of variable derivation as a subtask of data preparation. The impact of 9 derivation approaches and 4 combinations of them on classifier performance is assessed on a real world dataset using decision trees and gains charts as performance measure. The results indicate that our approach improves the classifier performance.

#index 1892068
#* CWFM: closed contingency weighted frequent itemsets mining
#@ Eunkyoung Park;Younghee Kim;Ieejoon Kim;Jaeyeol Yoon;Jiyeon Lim;Ungmo Kim
#t 2012
#c 18
#% 152934
#% 300120
#% 459006
#% 463903
#% 464996
#% 729933
#% 942894
#% 1707844
#! Weighted pattern mining have been studied the importance of items. So far, in weight constraint based pattern mining, the weight has been considered the item's price. The price considered as the weight has a limit. The weight characteristic of weighted pattern mining should be considered case-by-case situation. Thus, we motivate by considering the special and individual case-by-case situation to find the exact frequent patterns. We propose how to set weight into frequent patterns mining with a case-by-case condition, called CWFM (closed contingency weighted pattern miming). Moreover, we devise information tables by using statistical and empirical data as strategic decision. In addition, we calculate the contingency weight using outer variables and values which are from information tables. CWFM extracts more meaningful and appropriate patterns reflected case-by-case situation. The proposed new mining method finds closed contingency weighted frequent patterns having a significance which represents the case-by-case situation.

#index 1892069
#* Prognostic modeling with high dimensional and censored data
#@ Leon Bobrowski;Tomasz Łukaszuk
#t 2012
#c 18
#% 51647
#% 111349
#% 729437
#% 833786
#% 1168822
#% 1489144
#! Designing linear prognostic models on the base of multivariate learning set with censored dependent variable is considered in the paper. The task of linear regression model designing has been reformulated here as a problem of testing the linear separability of two sets. The convex and piecewise linear (CPL) criterion functions are used here both for estimation of the model parameters and for the feature selection task. The feature selection is aimed on neglecting a possibly large amount of independent variables while improving resulting model quality. Particular attention is paid to modeling censored data used in survival analysis. Experiments with the use of the RLS method of gene subset selection in prognostic model selection with the censored dependent variable is also described in the paper.

#index 1892070
#* SHACUN: semi-supervised hierarchical active clustering based on ranking constraints
#@ Eya Ben Ahmed;Ahlem Nabli;Faïez Gargouri
#t 2012
#c 18
#% 36672
#% 246832
#% 449588
#% 464608
#% 466086
#% 1044472
#% 1100087
#% 1136346
#% 1183429
#% 1545563
#% 1727637
#% 1796614
#! Semi-supervised approaches have proven to be efficient in clustering tasks. They allow user input, thus enhancing the quality of the clustering. However, the user intervention is generally limited to integrate boolean constraints in form of must-link and cannot-link constraints between pairs of objects. This paper investigates the issue of satisfying ranked constraints in performing hierarchical clustering. $\mathcal{SHACUN}$ is a new introduced method for handling cases when some constraints are more important than others and must be firstly enforced. Carried out experiments on real log files used for decision-maker groupization in data warehouse confirm the soundness of our approach.

#index 1892071
#* A minimum spanning tree-inspired clustering-based outlier detection technique
#@ Xiaochun Wang;Xia Li Wang;D. Mitch Wilkes
#t 2012
#c 18
#% 289519
#% 300136
#% 300183
#% 334990
#% 342625
#% 478624
#% 479791
#% 479986
#% 501988
#% 570886
#% 578689
#% 729912
#% 781774
#% 785358
#% 789012
#% 814646
#% 994564
#% 1010466
#% 1083673
#% 1202160
#% 1246153
#% 1406392
#% 1412299
#% 1669937
#! Due to its important applications in data mining, many techniques have been developed for outlier detection. In this paper, an efficient three-phase outlier detection technique. First, we modify the famous k-means algorithm for an efficient construction of a spanning tree which is very close to a minimum spanning tree of the data set. Second, the longest edges in the obtained spanning tree are removed to form clusters. Based on the intuition that the data points in small clusters may be most likely all outliers, they are selected and regarded as outlier candidates. Finally, density-based outlying factors, LOF, are calculated for potential outlier candidates and accessed to pinpoint the local outliers. Extensive experiments on real and synthetic data sets show that the proposed approach can efficiently identify global as well as local outliers for large-scale datasets with respect to the state-of-the-art methods.

#index 1892072
#* ML-DS: a novel deterministic sampling algorithm for association rules mining
#@ Samir A. Mohamed Elsayed;Sanguthevar Rajasekaran;Reda A. Ammar
#t 2012
#c 18
#% 152934
#% 248791
#% 280406
#% 300120
#% 333648
#% 463883
#% 466490
#% 481290
#% 481779
#% 495058
#% 577261
#% 614619
#% 729915
#% 729942
#% 863385
#% 1023484
#! Due to the explosive growth of data in every aspect of our life, data mining algorithms often suffer from scalability issues. One effective way to tackle this problem is to employ sampling techniques. This paper introduces, ML-DS, a novel deterministic sampling algorithm for mining association rules in large datasets. Unlike most algorithms in the literature that use randomness in sampling, our algorithm is fully deterministic. The process of sampling proceeds in stages. The size of the sample data in any stage is half that of the previous stage. In any given stage, the data is partitioned into disjoint groups of equal size. Some distance measure is used to determine the importance of each group in identifying accurate association rules. The groups are then sorted based on this measure. Only the best 50% of the groups move to the next stage. We perform as many stages of sampling as needed to produce a sample of a desired target size. The resultant sample is then employed to identify association rules. Empirical results show that our approach outperforms simple randomized sampling in accuracy and is competitive in comparison with the state-of-the-art sampling algorithms in terms of both time and accuracy.

#index 1892073
#* Decision rules development using set of generic operations approach
#@ Wiesław Paja;Mariusz Wrzesień
#t 2012
#c 18
#% 236752
#% 567416
#% 923811
#% 926881
#% 1530916
#! The main goal of presented research was to compile new approach for development learning models in a form of decision rule set. This approach devotes to using primary decision table as a primitive set of rules. Thus, each of learning cases is treated as a single classification rule. Next, a set of generic operations are applied to find the final, qualitative learning model. These generic operations are implemented in the RuleSEEKER system. During this research a few well-known algorithm for rule generation were compared with proposed solution. Obtained results are similar, sometimes even better and suggests that this method is a promising solution.

#index 1892074
#* Redundant dictionary spaces as a general concept for the analysis of non-vectorial data
#@ Sebastian Klenk;Jürgen Dippon;Andre Burkovski;Gunther Heidemann
#t 2012
#c 18
#% 391311
#% 458379
#% 722803
#% 731607
#% 854646
#% 1022958
#% 1472270
#% 1607571
#% 1761822
#% 1861551
#! Many types of data we are facing today are non-vectorial. But most of the analysis techniques are based on vector spaces and heavily depend on the underlying vector space properties. In order to apply such vector space techniques to non-vectorial data, so far only highly specialized methods have been suggested. We present a uniform and general approach to construct vector spaces from non-vectorial data. For this we develop a procedure to map each data element in a special kind of coordinate space which we call redundant dictionary space (RDS). The mapped vector space elements can be added, scaled and analyzed like vectors and thus allows any vector space analysis techniques to be used with any kind of data. The only requirement is the existence of a suitable inner product kernel.

#index 1892075
#* Human-centered text mining: a new software system
#@ Jonas Poelmans;Paul Elzinga;Alexei A. Neznanov;Guido Dedene;Stijn Viaene;Sergei O. Kuznetsov
#t 2012
#c 18
#% 477661
#% 1252969
#% 1272078
#% 1489150
#% 1489528
#% 1525409
#% 1590420
#% 1616223
#% 1647480
#% 1705150
#% 1892076
#! In this paper we introduce a novel human-centered data mining software system which was designed to gain intelligence from unstructured textual data. The architecture takes its roots in several case studies which were a collaboration between the Amsterdam-Amstelland Police, GasthuisZusters Antwerpen (GZA) hospitals and KU Leuven. It is currently being implemented by bachelor and master students of Moscow Higher School of Economics. At the core of the system are concept lattices which can be used to interactively explore the data. They are combined with several other complementary statistical data analysis techniques such as Emergent Self Organizing Maps and Hidden Markov Models.

#index 1892076
#* Text mining scientific papers: a survey on FCA-Based information retrieval research
#@ Jonas Poelmans;Dmitry I. Ignatov;Stijn Viaene;Guido Dedene;Sergei O. Kuznetsov
#t 2012
#c 18
#% 65948
#% 154954
#% 209020
#% 232518
#% 384416
#% 466177
#% 742991
#% 747041
#% 753439
#% 796802
#% 958320
#% 982067
#% 1004664
#% 1004814
#% 1017654
#% 1077150
#% 1099484
#% 1104999
#% 1105004
#% 1116215
#% 1141694
#% 1195903
#% 1199439
#% 1217587
#% 1265917
#% 1303208
#% 1349274
#% 1389044
#% 1489528
#% 1535886
#% 1590420
#% 1698987
#% 1704995
#% 1705153
#% 1705154
#% 1712432
#% 1716954
#% 1727218
#% 1727294
#% 1727298
#% 1727309
#% 1727835
#% 1734365
#% 1738864
#% 1738869
#% 1740465
#! Formal Concept Analysis (FCA) is an unsupervised clustering technique and many scientific papers are devoted to applying FCA in Information Retrieval (IR) research. We collected 103 papers published between 2003-2009 which mention FCA and information retrieval in the abstract, title or keywords. Using a prototype of our FCA-based toolset CORDIET, we converted the pdf-files containing the papers to plain text, indexed them with Lucene using a thesaurus containing terms related to FCA research and then created the concept lattice shown in this paper. We visualized, analyzed and explored the literature with concept lattices and discovered multiple interesting research streams in IR of which we give an extensive overview. The core contributions of this paper are the innovative application of FCA to the text mining of scientific papers and the survey of the FCA-based IR research.

#index 1978086
#* Proceedings of the 2012 IEEE 12th International Conference on Data Mining
#@ 
#t 2012
#c 18

#index 1978688
#* Efficient Algorithms for Finding Richer Subgroup Descriptions in Numeric and Nominal Data
#@ Michael Mampaey;Siegfried Nijssen;Ad Feelders;Arno Knobbe
#t 2012
#c 18
#! Subgroup discovery systems are concerned with finding interesting patterns in labeled data. How these systems deal with numeric and nominal data has a large impact on the quality of their results. In this paper, we consider two ways to extend the standard pattern language of subgroup discovery: using conditions that test for interval membership for numeric attributes, and value set membership for nominal attributes. We assume a greedy search setting, that is, iteratively refining a given subgroup, with respect to a (convex) quality measure. For numeric attributes, we propose an algorithm that finds the optimal interval in linear (rather than quadratic) time, with respect to the number of examples and split points. Similarly, for nominal attributes, we show that finding the optimal set of values can be achieved in linear (rather than exponential) time, with respect to the number of examples and the size of the domain of the attribute. These algorithms operate by only considering subgroup refinements that lie on a convex hull in ROC space, thus significantly narrowing down the search space. We further provide efficient algorithms specifically for the popular Weighted Relative Accuracy quality measure, taking advantage of some of its properties. Our algorithms are shown to perform well in practice, and furthermore provide additional expressive power leading to higher-quality results.

#index 1978689
#* A General Framework for Publishing Privacy Protected and Utility Preserved Graph
#@ Mingxuan Yuan;Lei Chen;Weixiong Rao;Hong Mei
#t 2012
#c 18
#! The privacy protection of graph data has become more and more important in recent years. Many works have been proposed to publish a privacy preserving graph. All these works prefer publishing a graph, which guarantees the protection of certain privacy with the smallest change to the original graph. However, there is no guarantee on how the utilities are preserved in the published graph. In this paper, we propose a general fine-grained adjusting framework to publish a privacy protected and utility preserved graph. With this framework, the data publisher can get a trade-off between the privacy and utility according to his customized preferences. We used the protection of a weighted graph as an example to demonstrate the implementation of this framework.

#index 1978690
#* Robust Nonnegative Matrix Factorization via Half-Quadratic Minimization
#@ Liang Du;Xuan Li;Yi-Dong Shen
#t 2012
#c 18
#! Nonnegative matrix factorization (NMF) is a popular technique for learning parts-based representation and data clustering. It usually uses the squared residuals to quantify the quality of factorization, which is optimal specifically to zero-mean, Gaussian noise and sensitive to outliers in general cases. In this paper, we propose a robust NMF method based on the correntropy induced metric, which is much more insensitive to outliers. A half-quadratic optimization algorithm is developed to solve the proposed problem efficiently. The proposed method is further extended to handle outlier rows by incorporating structural knowledge about the outliers. Experimental results on data sets with and without apparent outliers demonstrate the effectiveness of the proposed algorithms.

#index 1978691
#* RankTopic: Ranking Based Topic Modeling
#@ Dongsheng Duan;Yuhua Li;Ruixuan Li;Rui Zhang;Aiming Wen
#t 2012
#c 18
#! Topic modeling has become a widely used tool for document management due to its superior performance. However, there are few topic models distinguishing the importance of documents on different topics. In this paper, we investigate how to utilize the importance of documents to improve topic modeling and propose to incorporate link based ranking into topic modeling. Specifically, topical pagerank is used to compute the topic level ranking of documents, which indicates the importance of documents on different topics. By retreating the topical ranking of a document as the probability of the document involved in corresponding topic, a generalized relation is built between ranking and topic modeling. Based on the relation, a ranking based topic model Rank Topic is proposed. With Rank Topic, a mutual enhancement framework is established between ranking and topic modeling. Extensive experiments on paper citation data and Twitter data are conducted to compare the performance of Rank Topic with that of some state-of-the-art topic models. Experimental results show that Rank Topic performs much better than some baseline models and is comparable with the state-of-the-art link combined relational topic model (RTM) in generalization performance, document clustering and classification by setting a proper balancing parameter. It is also demonstrated in both quantitative and qualitative ways that topics detected by Rank Topic are more interpretable than those detected by some baseline models and still competitive with RTM.

#index 1978692
#* An Ellipsoidal K-Means for Document Clustering
#@ Fabon Dzogang;Christophe Marsala;Marie-Jeanne Lesot;Maria Rifqi
#t 2012
#c 18
#! We propose an extension of the spherical K-means algorithm to deal with settings where the number of data points is largely inferior to the number of dimensions. We assume the data to lie in local and dense regions of the original space and we propose to embed each cluster into its specific ellipsoid. A new objective function is introduced, analytical solutions are derived for both the centroids and the associated ellipsoids. Furthermore, a study on the complexity of this algorithm highlights that it is of same order as the regular K-means algorithm. Results on both synthetic and real data show the efficiency of the proposed method.

#index 1978693
#* Reconstructing Graphs from Neighborhood Data
#@ Dora Erdos;Rainer Gemulla;Evimaria Terzi
#t 2012
#c 18
#! Consider a social network and suppose that we are given the number of common friends between each pair of users. Can we reconstruct the underlying network? Similarly, consider a set of documents and the words that appear in them. If we know the number of common words for every pair of documents, as well as the number of common documents for every pair of words, can we infer which words appear in which documents? In this paper, we develop a general methodology for answering questions like the ones above. We formalize these questions in what we call the Reconstruct problem: Given information about the common neighbors of nodes in a network, our goal is to reconstruct the hidden binary matrix that indicates the presence or absence of relationships between individual nodes. We propose an effective and practical heuristic, which exploits properties of the singular value decomposition of the hidden binary matrix. More specifically, we show that using the available neighborhood information, we can reconstruct the hidden matrix by finding the components of its singular value decomposition and then combining them appropriately. Our extensive experimental study suggests that our methods are able to reconstruct binary matrices of different characteristics with up to 100% accuracy.

#index 1978694
#* Isometric Multi-manifold Learning for Feature Extraction
#@ Mingyu Fan;Hong Qiao;Bo Zhang;Xiaoqin Zhang
#t 2012
#c 18
#! Manifold learning is an important topic in pattern recognition and computer vision. However, most manifold learning algorithms implicitly assume the data are aligned on a single manifold, which is too strict in actual applications. Isometric feature mapping (Isomap), as a promising manifold learning method, fails to work on data which distribute on clusters in a single manifold or manifolds. In this paper, we propose a new multi-manifold learning algorithm (M-Isomap). The algorithm first discovers the data manifolds and then reduces the dimensionality of the manifolds separately. Meanwhile, a skeleton representing the global structure of whole data set is built and kept in low-dimensional space. Secondly, by referring to the low-dimensional representation of the skeleton, the embeddings of the manifolds are relocated to a global coordinate system. Compared with previous methods, these algorithms can keep both of the intra and inter manifolds geodesics faithfully. The features and effectiveness of the proposed multi-manifold learning algorithms are demonstrated and compared through experiments.

#index 1978695
#* Tuple MapReduce: Beyond Classic MapReduce
#@ Pedro Ferrera;Ivan de Prado;Eric Palacios;Jose Luis Fernandez-Marquez;Giovanna Di Marzo Serugendo
#t 2012
#c 18
#! This paper proposes Tuple Map Reduce, a new foundational model extending Map Reduce with the notion of tuples. Tuple Map Reduce allows to bridge the gap between the low-level constructs provided by Map Reduce and higher-level needs required by programmers, such as compound records, sorting or joins. This paper presents as well Pangool, an open-source framework implementing Tuple Map Reduce. Pangool eases the design and implementation of applications based on Map Reduce and increases their flexibility, still maintaining Hadoop's performance.

#index 1978696
#* Rapid and Robust Denoising of Pyrosequenced Amplicons for Metagenomics
#@ Byunghan Lee;Joonhong Park;Sungroh Yoon
#t 2012
#c 18
#! Metagenomic sequencing has become a crucial tool for obtaining a gene catalogue of operational taxonomic units (OTUs) in a microbial community. High-throughput pyrosequencing is a next-generation sequencing technique very popular in microbial community analysis due to its longer read length compared to alternative methods. Computational tools are inevitable to process raw data from pyrosequencers, and in particular, noise removal is a critical data-mining step to obtain robust sequence reads. However, the slow rate of existing denoisers has bottlenecked the whole pyrosequencing process, let alone hindering efforts to improve robustness. To address these, we propose a new approach that can accelerate the denoising process substantially. By using our approach, it now takes only about 2 hours to denoise 62,873 pyrosequenced amplicons from a mixture of 91 full-length 16S rRNA clones. It would otherwise take nearly 2.5 days if existing software tools were used. Furthermore, our approach can effectively reduce overestimating the number of OTUs, producing 6.7 times fewer species-level OTUs on average than a state-of-the-art alternative under the same condition. Leveraged by our approach, we hope that metagenomic sequencing will become an even more appealing tool for microbial community analysis.

#index 1978697
#* CT-IC: Continuously Activated and Time-Restricted Independent Cascade Model for Viral Marketing
#@ Wonyeol Lee;Jinha Kim;Hwanjo Yu
#t 2012
#c 18
#! Influence maximization problem with applications to viral marketing has gained much attention. Underlying influence diffusion models affect influence maximizing nodes because they focus on difference aspect of influence diffusion. Nevertheless, existing diffusion models overlook two important aspects of real-world marketing - continuous trials and time restriction. This paper proposes a new realistic influence diffusion model called Continously activated and Time-restricted IC (CT-IC) model which generalizes the IC model by embedding the above two aspects. We first prove that CT-IC model satisfies two crucial properties -- monotonicity and submodularity. We then provide an efficient method for calculating exact influence spread when a social network is restricted to a directed tree and a simple path. Finally, we propose a scalable algorithm for influence maximization under CT-IC model called CT-IPA. Our experiments show that CT-IC model provides seeds of higher influence spread than IC model and CT-IPA is four orders of magnitude faster than the greedy algorithm while providing similar influence spread to the greedy algorithm.

#index 1978698
#* Estimating the Expected Effectiveness of Text Classification Solutions under Subclass Distribution Shifts
#@ Nedim Lipka;Benno Stein;James G. Shanahan
#t 2012
#c 18
#! Automated text classification is one of the most important learning technologies to fight information overload. However, the information society is not only confronted with an information flood but also with an increase in "information volatility", by which we understand the fact that kind and distribution of a data source's emissions can significantly vary. In this paper we show how to estimate the expected effectiveness of a classification solution when the underlying data source undergoes a shift in the distribution of its subclasses (modes). Subclass distribution shifts are observed among others in online media such as tweets, blogs, or news articles, where document emissions follow topic popularity. To estimate the expected effectiveness of a classification solution we partition a test sample by means of clustering. Then, using repetitive resampling with different margin distributions over the clustering, the effectiveness characteristics is studied. We show that the effectiveness is normally distributed and introduce a probabilistic lower bound that is used for model selection. We analyze the relation between our notion of expected effectiveness and the mean effectiveness over the clustering both theoretically and on standard text corpora. An important result is a heuristic for expected effectiveness estimation that is solely based on the initial test sample and that can be computed without resampling.

#index 1978699
#* Metric Learning from Relative Comparisons by Minimizing Squared Residual
#@ Eric Yi Liu;Zhishan Guo;Xiang Zhang;Vladimir Jojic;Wei Wang
#t 2012
#c 18
#! Recent studies [1] -- [5] have suggested using constraints in the form of relative distance comparisons to represent domain knowledge: d(a, b)

#index 1978700
#* Direct Discovery of High Utility Itemsets without Candidate Generation
#@ Junqiang Liu;Ke Wang;Benjamin C. M. Fung
#t 2012
#c 18
#! Utility mining emerged recently to address the limitation of frequent itemset mining by introducing interestingness measures that reflect both the statistical significance and the user's expectation. Among utility mining problems, utility mining with the itemset share framework is a hard one as no anti-monotone property holds with the interestingness measure. The state-of-the-art works on this problem all employ a two-phase, candidate generation approach, which suffers from the scalability issue due to the huge number of candidates. This paper proposes a high utility itemset growth approach that works in a single phase without generating candidates. Our basic approach is to enumerate itemsets by prefix extensions, to prune search space by utility upper bounding, and to maintain original utility information in the mining process by a novel data structure. Such a data structure enables us to compute a tight bound for powerful pruning and to directly identify high utility itemsets in an efficient and scalable way. We further enhance the efficiency significantly by introducing recursive irrelevant item filtering with sparse data, and a lookahead strategy with dense data. Extensive experiments on sparse and dense, synthetic and real data suggest that our algorithm outperforms the state-of-the-art algorithms over one order of magnitude.

#index 1978701
#* Graph-Oriented Learning via Automatic Group Sparsity for Data Analysis
#@ Yuqiang Fang;Ruili Wang;Bin Dai
#t 2012
#c 18
#! The key task in graph-oriented learning is con-structing an informative graph to model the geometrical and discriminant structure of a data manifold. Since traditional graph construction methods are sensitive to noise and less datum-adaptive to changes in density, a new graph construction method so-calledl1-Graph has been proposed [1] recently. A graph construction method needs to have two important properties: sparsity and locality. However, the l1-Graph is strong in sparsity property, but weak in locality. In order to overcome such limitation, we propose a new method of constructing an informative graph using automatic group sparse regularization based on the work ofl1-Graph, which is called as group sparse graph (GroupSp-Graph). The newly developed GroupSp-Graph has the same noise-insensitive property asl1-Graph, and also can successively preserve the group and local information in the graph. In other words, the proposed group sparse graph has both properties of sparsity and locality simultaneously. Furthermore, we integrate the proposed graph with several graph-oriented learning algorithms: spectral em-bedding, spectral clustering, subspace learning and manifold regularized non-negative matrix factorization. The empirical studies on benchmark data sets show that the proposed algo-rithms achieve considerable improvement over classic graph constructing methods and the l1-Graph method in various learning task.

#index 1978702
#* Assessing the Significance of Data Mining Results on Graphs with Feature Vectors
#@ Stephan Gunnemann;Phuong Dao;Mohsen Jamali;Martin Ester
#t 2012
#c 18
#! Assessing the significance of data mining results is an important step in the knowledge discovery process. While results might appear interesting at a first glance, they can often be explained by already known characteristics of the data. Randomization is an established technique for significance testing, and methods to assess data mining results on vector data or network data have been proposed. In many applications, however, both sources are simultaneously given. Since these sources are rarely independent of each other but highly correlated, naively applying existing randomization methods on each source separately is questionable. In this work, we present a method to assess the significance of mining results on graphs with binary features vectors. We propose a novel null model that preserves correlation information between both sources. Our randomization exploits an adaptive Metropolis sampling and interweaves attribute randomization and graph randomization steps. In thorough experiments, we demonstrate the application of our technique. Our results indicate that while simultaneously using both sources is beneficial, often one source of information is dominant for determining the mining results.

#index 1978703
#* Sequential Network Change Detection with Its Applications to Ad Impact Relation Analysis
#@ Yu Hayashi;Kenji Yamanishi
#t 2012
#c 18
#! We are concerned with the issue of tracking changes of variable dependencies from multivariate time series. Conventionally, this issue has been addressed in the batch scenario where the whole data set is given at once, and the change detection must be done in a retrospective way. This paper addresses this issue in a sequential scenario where multivariate data are sequentially input and the detection must be done in a sequential fashion. We propose a new method for sequential tracking of variable dependencies. In it we employ a Bayesian network as a representation of variable dependencies. The key ideas of our method are, 1) we extend the theory of dynamic model selection (DMS), which has been developed in the batch-learning scenario, into the sequential setting, and apply it to our issue, 2) we conduct the change detection sequentially using dynamic programming per a window where we employ the Hoeffding's bound to automatically determine the window size. We empirically demonstrate that our proposed method is able to perform change detection more efficiently than a conventional batch method. Further, we give a new framework of an application of variable dependency change detection, which we call Ad Impact Relation analysis (AIR). In it, we detect the time point when a commercial message advertisement has given an impact on the market and effectively visulaize the impact through network changes. We employ real data sets to demonstrate the validity of AIR.

#index 1978704
#* Hierarchical Multi-task Learning with Application to Wafer Quality Prediction
#@ Jingrui He;Yada Zhu
#t 2012
#c 18
#! Many real problems of multi-task learning exhibit hierarchical task relatedness. In other words, the tasks are partitioned into multiple groups. Different tasks within the same group are related on the task-level, whereas different groups are related on the group-level. For example, in semiconductor manufacturing, the problem of wafer quality prediction can be considered as hierarchical multi-task learning, where each task corresponds to a single side of a chamber with side-level relatedness, and a group of tasks corresponds to a chamber of multiple sides with chamber-level relatedness. Motivated by this application, in this paper, we propose an optimization framework for hierarchical multi-task learning, which partitions all the input features into 2 sets based on their characteristics, and models task-level and group-level relatedness by imposing different constraints on the coefficient vectors of the 2 sets. This is different from existing work on task clustering where the goal is to uncover the grouping of tasks, the tasks do not exhibit group-level relatedness, and the input features are not discriminated in the prediction model to model task-level and group-level relatedness. To solve this framework, we propose the \hear\ algorithm based on block coordinate descent, and demonstrate its effectiveness on both synthetic and real data sets from domains of semiconductor manufacturing and document classification.

#index 1978705
#* Dimensional Testing for Multi-step Similarity Search
#@ Michael E. Houle;Xiguo Ma;Michael Nett;Vincent Oria
#t 2012
#c 18
#! In data mining applications such as subspace clustering or feature selection, changes to the underlying feature set can require the reconstruction of search indices to support fundamental data mining tasks. For such situations, multi-step search approaches have been proposed that can accommodate changes in the underlying similarity measure without the need to rebuild the index. In this paper, we present a heuristic multi-step search algorithm that utilizes a measure of intrinsic dimension, the generalized expansion dimension (GED), as the basis of its search termination condition. Compared to the current state-of-the-art method, experimental results show that our heuristic approach is able to obtain significant improvements in both the number of candidates and the running time, while losing very little in the accuracy of the query results.

#index 1978706
#* Progressive Mining of Transition Dynamics for Autonomous Control
#@ Steven Loscalzo;Robert Wright;Kevin Acunto;Lei Yu
#t 2012
#c 18
#! Autonomous agents are emerging in diverse areas and many rely on reinforcement learning (RL) to learn optimal control policies by acting in the environment. This form of learning generates large amounts of transition dynamics data, which can be mined to improve the agent's understanding of the environment. There could be many uses for this data, here we focus on mining it to identify a relevant feature subspace. This is vital since RL performs poorly in high-dimensional spaces, such as those that autonomous agents would commonly face in real-world problems. This paper demonstrates the necessity and feasibility of integrating data mining into the learning process while an agent is learning, enabling it to learn to act by both acting and understanding. Doing so requires overcoming challenges regarding data quantity and quality, and difficulty measuring feature relevance with respect to the control policy. We propose the progressive mining framework to address these challenges by relying on cyclic interaction between data mining and RL. We show that a feature selection algorithm developed under this framework, PROFESS, can improve RL scalability better than a competing approach.

#index 1978707
#* Analysis of Temporal High-Dimensional Gene Expression Data for Identifying Informative Biomarker Candidates
#@ Qiang Lou;Zoran Obradovic
#t 2012
#c 18
#! Identifying informative biomarkers from a large pool of candidates is the key step for accurate prediction of an individualâs health status. In clinical applications traditional static feature selection methods that flatten the temporal data cannot be directly applied since the patientâs observed clinical condition is a temporal multivariate time series where different variables can capture various stages of temporal change in the patientâs health status. In this study, in order to identify informative genes in temporal microarray data, a margin based feature selection filter is proposed. The proposed method is based on well-established machine learning techniques without any assumptions about the data distribution. The objective function of temporal margin-based feature selection is defined to maximize each subject's temporal margin in its own relevant subspace. In the objective function, the uncertainty in calculating nearest neighbors is taken into account by considering the change in feature weights in each iteration. A fixed-point gradient descent method is proposed to solve the formulated objective function. The experimental results on both synthetic and real data provide evidence that the proposed method can identify more informative features than the alternatives that flatten the temporal data in advance.

#index 1978708
#* Heterogeneous Constraint Propagation with Constrained Sparse Representation
#@ Zhiwu Lu;Yuxin Peng
#t 2012
#c 18
#! This paper presents a graph-based method for heterogeneous constraint propagation on multi-modal data using constrained sparse representation. Since heterogeneous pair wise constraints are defined over pairs of data points from different modalities, heterogeneous constraint propagation is more challenging than the transitional homogeneous constraint propagation on single-modal data which has been studied extensively in previous work. The main difficulty of heterogeneous constraint propagation lies in how to effectively propagate heterogeneous pair wise constraints across different modalities. To address this issue, we decompose heterogeneous constraint propagation into semi-supervised learning sub problems which can then be efficiently solved by graph-based label propagation. Moreover, we develop a constrained sparse representation method for graph construction over each modality using homogeneous pair wise constraints. The experimental results in cross-modal retrieval have shown the superior performance of our heterogeneous constraint propagation.

#index 1978709
#* A Classification Based Framework for Concept Summarization
#@ Dhruv Mahajan;Sundararajan Sellamanickam;Subhajit Sanyal;Amit Madaan
#t 2012
#c 18
#! In this paper we propose a novel classification based framework for finding a small number of images that summarize a given concept. Our method exploits metadata information available with the images to get category information using Latent Dirichlet Allocation. Using this category information for each image, we solve the underlying classification problem by building a sparse classifier model for each concept. We demonstrate that the images that specify the sparse model form a good summary. In particular, our summary satisfies important properties such as likelihood, diversity and balance in both visual and semantic sense. Furthermore, the framework allows users to specify desired distributions over categories to create personalized summaries.\eat{ We demonstrate the efficacy of our method on seven broad query types - sports, news, celebrities, events, travel, country and abstract.} Experimental results on seven broad query types show that the proposed method performs better than state-of-the-art methods.\eat{ in terms of satisfying important visual and semantic properties both qualitatively and quantitatively. We observe from editorial evaluation that around $78$\% of our summaries are of high enough quality to be shown directly to the web users with minimal or no modifications.

#index 1978710
#* A Similarity Model and Segmentation Algorithm for White Matter Fiber Tracts
#@ Son T. Mai;Sebastian Goebl;Claudia Plant
#t 2012
#c 18
#! Recently, fiber segmentation has become an emerging technique in neuroscience. Grouping fiber tracts into anatomical meaningful bundles allows to study the structure of the brain and to investigate onset and progression of neurodegenerative and mental diseases. In this paper, we propose a novel technique for fiber tracts based on shape similarity and connection similarity. For shape similarity, we propose some new techniques adapted from existing similarity measures for trajectory data. We also propose a new technique called Warped Longest Common Subsequence (WLCS) for which we additionally developed a lower-bounding distance function to speed up the segmentation process. Our segmentation is based on an outlier-robust density-based clustering algorithm. Extensive experiments on diffusion tensor images demonstrate the efficiency and effectiveness of our technique.

#index 1978711
#* Discovery of Causal Rules Using Partial Association
#@ Zhou Jin;Jiuyong Li;Lin Liu;Thuc Duy Le;Bingyu Sun;Rujing Wang
#t 2012
#c 18
#! Discovering causal relationships in large databases of observational data is challenging. The pioneering work in this area was rooted in the theory of Bayesian network (BN) learning, which however, is a NP-complete problem. Hence several constraint-based algorithms have been developed to efficiently discover causations in large databases. These methods usually use the idea of BN learning, directly or indirectly, and are focused on causal relationships with single cause variables. In this paper, we propose an approach to mine causal rules in large databases of binary variables. Our method expands the scope of causality discovery to causal relationships with multiple cause variables, and we utilise partial association tests to exclude noncausal associations, to ensure the high reliability of discovered causal rules. Furthermore an efficient algorithm is designed for the tests in large databases. We assess the method with a set of real-world diagnostic data. The results show that our method can effectively discover interesting causal rules in large databases.

#index 1978712
#* Bounded Matrix Low Rank Approximation
#@ Ramakrishnan Kannan;Mariya Ishteva;Haesun Park
#t 2012
#c 18
#! Matrix lower rank approximations such as non-negative matrix factorization (NMF) have been successfully used to solve many data mining tasks. In this paper, we propose a new matrix lower rank approximation called Bounded Matrix Low Rank Approximation (BMA) which imposes a lower and an upper bound on every element of a lower rank matrix that best approximates a given matrix with missing elements. This new approximation models many real world problems, such as recommender systems, and performs better than other methods, such as singular value decompositions (SVD) or NMF. We present an efficient algorithm to solve BMA based on coordinate descent method. BMA is different from NMF as it imposes bounds on the approximation itself rather than on each of the low rank factors. We show that our algorithm is scalable for large matrices with missing elements on multi core systems with low memory. We present substantial experimental results illustrating that the proposed method outperforms the state of the art algorithms for recommender systems such as Stochastic Gradient Descent, Alternating Least Squares with regularization, SVD++, Bias-SVD on real world data sets such as Jester, Movie lens, Book crossing, Online dating and Netflix.

#index 1978713
#* Active Evaluation of Classifiers on Large Datasets
#@ Namit Katariya;Arun Iyer;Sunita Sarawagi
#t 2012
#c 18
#! The goal of this work is to estimate the accuracy of a classifier on a large unlabeled dataset based on a small labeled set and a human labeler. We seek to estimate accuracy and select instances for labeling in a loop via a continuously refined stratified sampling strategy. For stratifying data we develop a novel strategy of learning r bit hash functions to preserve similarity in accuracy values. We show that our algorithm provides better accuracy estimates than existing methods for learning distance preserving hash functions. Experiments on a wide spectrum of real datasets show that our estimates achieve between 15% and 62% relative reduction in error compared to existing approaches. We show how to perform stratified sampling on unlabeled data that is so large that in an interactive setting even a single sequential scan is impractical. We present an optimal algorithm for performing importance sampling on a static index over the data that achieves close to exact estimates while reading three orders of magnitude less data.

#index 1978714
#* ConfDTree: Improving Decision Trees Using Confidence Intervals
#@ Gilad Katz;Asaf Shabtai;Lior Rokach;Nir Ofek
#t 2012
#c 18
#! Decision trees have three main disadvantages: reduced performance when the training set is small, rigid decision criteria and the fact that a single "uncharacteristic" attribute might "derail" the classification process. In this paper we present ConfDTree - a post-processing method which enables decision trees to better classify outlier instances. This method, which can be applied on any decision trees algorithm, uses confidence intervals in order to identify these hard-to-classify instances and proposes alternative routes. The experimental study indicates that the proposed post-processing method consistently and significantly improves the predictive performance of decision trees, particularly for small, imbalanced or multi-class datasets in which an average improvement of 5%-9% in the AUC performance is reported.

#index 1978715
#* ETM: Entity Topic Models for Mining Documents Associated with Entities
#@ Hyungsul Kim;Yizhou Sun;Julia Hockenmaier;Jiawei Han
#t 2012
#c 18
#! Topic models, which factor each document into different topics and represent each topic as a distribution of terms, have been widely and successfully used to better understand collections of text documents. However, documents are also associated with further information, such as the set of real-world entities mentioned in them. For example, news articles are usually related to several people, organizations, countries or locations. Since those associated entities carry rich information, it is highly desirable to build more expressive, entity-based topic models, which can capture the term distributions for each topic, each entity, as well as each topic-entity pair. In this paper, we therefore introduce a novel Entity Topic Model (ETM) for documents that are associated with a set of entities. ETM not only models the generative process of a term given its topic and entity information, but also models the correlation of entity term distributions and topic term distributions. A Gibbs sampling-based algorithm is proposed to learn the model. Experiments on real datasets demonstrate the effectiveness of our approach over several state-of-the-art baselines.

#index 1978716
#* Outlier Detection in Arbitrarily Oriented Subspaces
#@ Hans-Peter Kriegel;Peer Kroger;Erich Schubert;Arthur Zimek
#t 2012
#c 18
#! In this paper, we propose a novel outlier detection model to find outliers that deviate from the generating mechanisms of normal instances by considering combinations of different subsets of attributes, as they occur when there are local correlations in the data set. Our model enables to search for outliers in arbitrarily oriented subspaces of the original feature space. We show how in addition to an outlier score, our model also derives an explanation of the outlierness that is useful in investigating the results. Our experiments suggest that our novel method can find different outliers than existing work and can be seen as a complement of those approaches.

#index 1978717
#* Learning Attitudes and Attributes from Multi-aspect Reviews
#@ Julian McAuley;Jure Leskovec;Dan Jurafsky
#t 2012
#c 18
#! Most online reviews consist of plain-text feedback together with a single numeric score. However, understanding the multiple `aspects' that contribute to users' ratings may help us to better understand their individual preferences. For example, a user's impression of an audio book presumably depends on aspects such as the story and the narrator, and knowing their opinions on these aspects may help us to recommend better products. In this paper, we build models for rating systems in which such dimensions are explicit, in the sense that users leave separate ratings for each aspect of a product. By introducing new corpora consisting of five million reviews, rated with between three and six aspects, we evaluate our models on three prediction tasks: First, we uncover which parts of a review discuss which of the rated aspects. Second, we summarize reviews by finding the sentences that best explain a user's rating. Finally, since aspect ratings are optional in many of the datasets we consider, we recover ratings that are missing from a user's evaluation. Our model matches state-of-the-art approaches on existing small-scale datasets, while scaling to the real-world datasets we introduce. Moreover, our model is able to `disentangle' content and sentiment words: we automatically learn content words that are indicative of a particular aspect as well as the aspect-specific sentiment words that are indicative of a particular rating.

#index 1978718
#* Learning Heterogeneous Similarity Measures for Hybrid-Recommendations in Meta-Mining
#@ Phong Nguyen;Jun Wang;Melanie Hilario;Alexandros Kalousis
#t 2012
#c 18
#! The notion of meta-mining has appeared recently and extends traditional meta-learning in two ways. First it provides support for the whole data-mining process. Second it pries open the so called algorithm black-box approach where algorithms and workflows also have descriptors. With the availability of descriptors both for datasets and datamining workflows we are faced with a problem the nature of which is much more similar to those appearing in recommendation systems. In order to account for the metamining specificities we derive a novel metric-based-learning recommender approach. Our method learns two homogeneous metrics, one in the dataset and one in the workflow space, and a heterogeneous one in the dataset-workflow space. All learned metrics reflect similarities established from the datasetworkflow preference matrix. The latter is constructed from the performance results obtained by the application of workflows to datasets. We demonstrate our method on meta-mining over biological (microarray datasets) problems. The application of our method is not limited to the meta-mining problem, its formulation is general enough so that it can be applied on problems with similar requirements.

#index 1978719
#* Scaling Inference for Markov Logic via Dual Decomposition
#@ Feng Niu;Ce Zhang;Christopher Re;Jude Shavlik
#t 2012
#c 18
#! Markov logic is a knowledge-representation language that allows one to specify large graphical models. However, the resulting large graphical models can make inference for Markov logic a computationally challenging problem. Recently, dual decomposition (DD) has become a popular approach for scalable inference on graphical models. We study how to apply DD to scale up inference in Markov logic. A standard approach for DD first partitions a graphical model into multiple tree-structured sub problems. We apply this approach to Markov logic and show that DD can outperform prior inference approaches. Nevertheless, we observe that the standard approach for DD is suboptimal as it does not exploit the rich structure often present in the Markov logic program. Thus, we describe a novel decomposition strategy that partitions a Markov logic program into parts based on its structure. A crucial advantage of our approach is that we can use specialized algorithms for portions of the input problem -- some of which have been studied for decades, e.g., coreference resolution. Empirically, we show that our program-level decomposition approach outperforms both non-decomposition and graphical model-based decomposition approaches to Markov logic inference on several data-mining tasks.

#index 1978720
#* Mining User Mobility Features for Next Place Prediction in Location-Based Services
#@ Anastasios Noulas;Salvatore Scellato;Neal Lathia;Cecilia Mascolo
#t 2012
#c 18
#! Mobile location-based services are thriving, providing an unprecedented opportunity to collect fine grained spatio-temporal data about the places users visit. This multi-dimensional source of data offers new possibilities to tackle established research problems on human mobility, but it also opens avenues for the development of novel mobile applications and services. In this work we study the problem of predicting the next venue a mobile user will visit, by exploring the predictive power offered by different facets of user behavior. We first analyze about 35 million check-ins made by about 1 million Foursquare users in over 5 million venues across the globe, spanning a period of five months. We then propose a set of features that aim to capture the factors that may drive users' movements. Our features exploit information on transitions between types of places, mobility flows between venues, and spatio-temporal characteristics of user check-in patterns. We further extend our study combining all individual features in two supervised learning models, based on linear regression and M5 model trees, resulting in a higher overall prediction accuracy. We find that the supervised methodology based on the combination of multiple features offers the highest levels of prediction accuracy: M5 model trees are able to rank in the top fifty venues one in two user check-ins, amongst thousands of candidate items in the prediction list.

#index 1978721
#* Clustering by Learning Constraints Priorities
#@ Masayuki Okabe;Seiji Yamada
#t 2012
#c 18
#! A method for creating a constrained clustering ensemble by learning the priorities of pair wise constraints is proposed in this paper. This method integrates multiple clusters produced by using a simple constrained K-means algorithm that we modify to utilize the constraints priorities. The cluster ensemble is executed according to a boosting framework, which adaptively learns the constraints priorities and provides them for the modified constrained K-means to create diverse clusters that finally improve the clustering performance. The experimental results show that our proposed method outperforms the original constrained K-means and is comparable to several state-of-the-art constrained clustering methods.

#index 1978722
#* Understanding Data Completeness in Network Monitoring Systems
#@ Flip Korn;Ruilin Liu;Hui (Wendy) Wang
#t 2012
#c 18
#! In many networks including Internet Service Providers, transportation monitoring systems and the electric grid, measurements from a set of objects are continuously taken over time and used for important decisions such as provisioning and pricing. It is therefore vital to understand the completeness and reliability of such data. Given the large volume of data generated by these systems, rather than enumerating the times and objects incurring missing or spurious data, it is more effective to provide patterns (groups of tuples) concisely summarizing trends that may not otherwise be readily observable. In this paper, we define the Graph Tableau Discovery Problem where the measured tuples can be thought of as edges in a bipartite graph on an ordered attribute (time) and an unordered attribute (object identifiers). We define the problem of finding an optimal summary, show that it is NP-complete, and then provide a polynomial-time approximation algorithm with guarantees to find a good summary. Experiments on real and synthetic data demonstrate the effectiveness and efficiency of our approach.

#index 1978723
#* Effective and Robust Mining of Temporal Subspace Clusters
#@ Hardy Kremer;Stephan Gunnemann;Arne Held;Thomas Seidl
#t 2012
#c 18
#! Mining temporal multivariate data by clustering is an important research topic. In today's complex data, interesting patterns are often neither bound to the whole dimensional nor temporal extent of the data domain. This challenge is met by temporal subspace clustering methods. Their effectiveness, however, is impeded by aspects unavoidable in real world data: Misalignments between time series, for example caused by out-of-sync sensors, and measurement errors. Under these conditions, existing temporal subspace clustering approaches miss the patterns contained in the data. In this paper, we propose a novel clustering method that mines temporal subspace clusters reflected by sets of objects and relevant intervals. We enable flexible handling of misaligned time series by adaptively shifting time series in the time domain, and we achieve robustness to measurement errors by allowing certain fractions of deviating values in each relevant point in time. We show the effectiveness of our method in experiments on real and synthetic data.

#index 1978724
#* Dynamic Multi-relational Chinese Restaurant Process for Analyzing Influences on Users in Social Media
#@ Himabindu Lakkaraju;Indrajit Bhattacharya;Chiranjib Bhattacharyya
#t 2012
#c 18
#! We study the problem of analyzing influence of various factors affecting individual messages posted in social media. The problem is challenging because of various types of influences propagating through the social media network that act simultaneously on any user. Additionally, the topic composition of the influencing factors and the susceptibility of users to these influences evolve over time. This problem has not been studied before, and off-the-shelf models are unsuitable for this purpose. To capture the complex interplay of these various factors, we propose a new non-parametric model called the Dynamic Multi-Relational Chinese Restaurant Process. This accounts for the user network for data generation and also allows the parameters to evolve over time. Designing inference algorithms for this model suited for large scale social-media data is another challenge. To this end, we propose a scalable and multi-threaded inference algorithm based on online Gibbs Sampling. Extensive evaluations on large-scale Twitter and Face book data show that the extracted topics when applied to authorship and commenting prediction outperform state-of-the-art baselines. More importantly, our model produces valuable insights on topic trends and user personality trends beyond the capability of existing approaches.

#index 1978725
#* Nested Subtree Hash Kernels for Large-Scale Graph Classification over Streams
#@ Bin Li;Xingquan Zhu;Lianhua Chi;Chengqi Zhang
#t 2012
#c 18
#! Most studies on graph classification focus on designing fast and effective kernels. Several fast subtree kernels have achieved a linear time-complexity w.r.t. the number of edges under the condition that a common feature space (e.g., a subtree pattern list) is needed to represent all graphs. This will be infeasible when graphs are presented in a stream with rapidly emerging subtree patterns. In this case, computing a kernel matrix for graphs over the entire stream is difficult since the graphs in the expired chunks cannot be projected onto the unlimitedly expanding feature space again. This leads to a big trouble for graph classification over streams -- Different portions of graphs have different feature spaces. In this paper, we aim to enable large-scale graph classification over streams using the classical ensemble learning framework, which requires the data in different chunks to be in the same feature space. To this end, we propose a Nested Subtree Hashing (NSH) algorithm to recursively project the multi-resolution subtree patterns of different chunks onto a set of common low-dimensional feature spaces. We theoretically analyze the derived NSH kernel and obtain a number of favorable properties: 1) The NSH kernel is an unbiased and highly concentrated estimator of the fast subtree kernel. 2) The bound of convergence rate tends to be tighter as the NSH algorithm steps into a higher resolution. 3) The NSH kernel is robust in tolerating concept drift between chunks over a stream. We also empirically test the NSH kernel on both a large-scale synthetic graph data set and a real-world chemical compounds data set for anticancer activity prediction. The experimental results validate that the NSH kernel is indeed efficient and robust for graph classification over streams.

#index 1978726
#* Efficient Behavior Targeting Using SVM Ensemble Indexing
#@ Jun Li;Peng Zhang;Yanan Cao;Ping Liu;Li Guo
#t 2012
#c 18
#! Behavior targeting (BT) is a promising tool for online advertising. The state-of-the-art BT methods, which are mainly based on regression models, have two limitations. First, learning regression models for behavior targeting is difficult since user clicks are typically several orders of magnitude fewer than views. Second, the user interests are not fixed, but often transient and influenced by media and pop culture. In this paper, we propose to formulate behavior targeting as a classification problem. Specifically, we propose to use an SVM ensemble for behavior prediction. The challenge of using ensemble SVM for BT stems from the computational complexity (it takes 53 minutes in our experiments to predict behavior for 32 million users, which is inadequate for online application). To this end, we propose a fast ensemble SVM prediction framework, which builds an indexing structure for SVM ensemble to achieve sub-linear prediction time complexity. Experimental results on real-world large scale behavior targeting data demonstrate that the proposed method is efficient and outperforms existing linear regression based BT models.

#index 1978727
#* Spatial Interpolation Using Multiple Regression
#@ Orlando Ohashi;Luis Torgo
#t 2012
#c 18
#! Many real world data mining applications involve analyzing geo-referenced data. Frequently, this type of data sets are incomplete in the sense that not all geographical coordinates have measured values of the variable(s) of interest. This incompleteness may be caused by poor data collection, measurement errors, costs management and many other factors. These missing values may cause several difficulties in many applications. Spatial imputation/interpolation methods try to fill in these unknown values in geo-referenced data sets. In this paper we propose a new spatial imputation method based on machine learning algorithms and a series of data pre-processing steps. The key distinguishing factor of this method is allowing the use of data from faraway regions, contrary to the state of the art on spatial data mining. Images (e.g. from a satellite or video surveillance cameras) may also suffer from this incompleteness where some pixels are missing, which again may be caused by many factors. An image can be seen as a spatial data set in a Cartesian coordinates system, where each pixel (location) registers some value (e.g. degree of gray on a black and white image). Being able to recover the original image from a partial or incomplete version of the reality is a key application in many domains (e.g. surveillance, security, etc.). In this paper we evaluate our general methodology for spatial interpolation on this type of problems. Namely, we check the ability of our method to fill in unknown pixels on several images. We compare it to state of the art methods and provide strong experimental evidence of the advantages of our proposal.

#index 1978728
#* Exclusive Row Biclustering for Gene Expression Using a Combinatorial Auction Approach
#@ Amichai Painsky;Saharon Rosset
#t 2012
#c 18
#! The availability of large microarray data has led to a growing interest in biclustering methods in the past decade. Several algorithms have been proposed to identify subsets of genes and conditions according to different similarity measures and under varying constraints. In this paper we focus on the exclusive row biclusteing problem (also known as projected clustering) for gene expression data sets, in which each row can only be a member of a single bicluster while columns can participate in multiple clusters. This type of biclustering may be adequate, for example, for clustering groups of cancer patients where each patient (row) is expected to be carrying only a single type of cancer, while each cancer type is associated with multiple (and possibly overlapping) genes (columns). In this paper we present a novel method to identify these exclusive row biclusters through a combination of existing biclustering algorithms and combinatorial auction techniques. We devise an approach for tuning the threshold for our algorithm based on comparison to a null model in the spirit of the Gap statistic approach. We demonstrate our approach on both synthetic and real-world gene expression data and show its power in identifying large span non-overlapping rows sub matrices, while considering their unique nature. The Gap statistic approach succeeds in identifying appropriate thresholds in all our examples.

#index 1978729
#* Topic Models over Spoken Language
#@ Niketan Pansare;Chris Jermaine;Peter Haas;Nitendra Rajput
#t 2012
#c 18
#! Virtually all work on topic modeling has assumed that the topics are to be learned over a text-based document corpus. However, there exist important applications where topic models must be learned over an audio corpus of spoken language. Unfortunately, speech-to-text programs can have very low accuracy. We therefore propose a novel topic model for spoken language that incorporates a statistical model of speech-to-text software behavior. Crucially, our model exploits the uncertainty numbers returned by the software. Our ideas apply to any domain in which it would be useful to build a topic model over data in which uncertainties are explicitly represented.

#index 1978730
#* Multiplicative Algorithms for Constrained Non-negative Matrix Factorization
#@ Chengbin Peng;Ka-Chun Wong;Alyn Rockwood;Xiangliang Zhang;Jinling Jiang;David Keyes
#t 2012
#c 18
#! Non-negative matrix factorization (NMF) provides the advantage of parts-based data representation through additive only combinations. It has been widely adopted in areas like item recommending, text mining, data clustering, speech denoising, etc. In this paper, we provide an algorithm that allows the factorization to have linear or approximately linear constraints with respect to each factor. We prove that if the constraint function is linear, algorithms within our multiplicative framework will converge. This theory supports a large variety of equality and inequality constraints, and can facilitate application of NMF to a much larger domain. Taking the recommender system as an example, we demonstrate how a specialized weighted and constrained NMF algorithm can be developed to fit exactly for the problem, and the tests justify that our constraints improve the performance for both weighted and unweighted NMF algorithms under several different metrics. In particular, on the Movie lens data with 94\% of items, the Constrained NMF improves recall rate 3\% compared to SVD50 and 45\% compared to SVD150, which were reported as the best two in the top-N metric.

#index 1978731
#* Granger Causality for Time-Series Anomaly Detection
#@ Huida Qiu;Yan Liu;Niranjan A. Subrahmanya;Weichang Li
#t 2012
#c 18
#! Recent developments in industrial systems provide us with a large amount of time series data from sensors, logs, system settings and physical measurements, etc. These data are extremely valuable for providing insights about the complex systems and could be used to detect anomalies at early stages. However, the special characteristics of these time series data, such as high dimensions and complex dependencies between variables, as well as its massive volume, pose great challenges to existing anomaly detection algorithms. In this paper, we propose Granger graphical models as an effective and scalable approach for anomaly detection whose results can be readily interpreted. Specifically, Granger graphical models are a family of graphical models that exploit the temporal dependencies between variables by applying L1-regularized learning to Granger causality. Our goal is to efficiently compute a robust "correlation anomaly" score for each variable via Granger graphical models that can provide insights on the possible reasons of anomalies. We evaluate the effectiveness of our proposed algorithms on both synthetic and application datasets. The results show the proposed algorithm achieves significantly better performance than other baseline algorithms and is scalable for large-scale applications.

#index 1978732
#* Co-labeling: A New Multi-view Learning Approach for Ambiguous Problems
#@ Wen Li;Lixin Duan;Ivor Wai-Hung Tsang;Dong Xu
#t 2012
#c 18
#! We propose a multi-view learning approach called co-labeling which is applicable for several machine learning problems where the labels of training samples are uncertain, including semi-supervised learning (SSL), multi-instance learning (MIL) and max-margin clustering (MMC). Particularly, we first unify those problems into a general ambiguous problem in which we simultaneously learn a robust classifier as well as find the optimal training labels from a finite label candidate set. To effectively utilize multiple views of data, we then develop our co-labeling approach for the general multi-view ambiguous problem. In our work, classifiers trained on different views can teach each other by iteratively passing the predictions of training samples from one classifier to the others. The predictions from one classifier are considered as label candidates for the other classifiers. To train a classifier with a label candidate set for each view, we adopt the Multiple Kernel Learning (MKL) technique by constructing the base kernel through associating the input kernel calculated from input features with one label candidate. Compared with the traditional co-training method which was specifically designed for SSL, the advantages of our co-labeling are two-fold: 1) it can be applied to other ambiguous problems such as MIL and MMC, 2) it is more robust by using the MKL method to integrate multiple labeling candidates obtained from different iterations and biases. Promising results on several real-world multi-view data sets clearly demonstrate the effectiveness of our proposed co-labeling for both MIL and SSL.

#index 1978733
#* A General and Scalable Approach to Mixed Membership Clustering
#@ Frank Lin;William W. Cohen
#t 2012
#c 18
#! Spectral clustering methods are elegant and effective graph-based node clustering methods, but they do not allow mixed membership clustering. We describe an approach that first transforms the data from a node-centric representation to an edge-centric one, and then use this representation to define a scalable and competitive mixed membership alternative to spectral clustering methods. Experimental results show the proposed approach improves substantially in mixed membership clustering tasks over node clustering methods.

#index 1978734
#* Time Constrained Influence Maximization in Social Networks
#@ Bo Liu;Gao Cong;Dong Xu;Yifeng Zeng
#t 2012
#c 18
#! Influence maximization is a fundamental research problem in social networks. Viral marketing, one of its applications, is to get a small number of users to adopt a product, which subsequently triggers a large cascade of further adoptions by utilizing """"Word-of-Mouth"""" effect in social networks. Influence maximization problem has been extensively studied recently. However, none of the previous work considers the time constraint in the influence maximization problem. In this paper, we propose the time constrained influence maximization problem. We show that the problem is NP-hard, and prove the monotonicity and submodularity of the time constrained influence spread function. Based on this, we develop a greedy algorithm with performance guarantees. To improve the algorithm scalability, we propose two Influence Spreading Path based methods. Extensive experiments conducted over four public available datasets demonstrate the efficiency and effectiveness of the Influence Spreading Path based methods.

#index 1978735
#* A Stochastic Model for Context-Aware Anomaly Detection in Indoor Location Traces
#@ Chuanren Liu;Hui Xiong;Yong Ge;Wei Geng;Matt Perkins
#t 2012
#c 18
#! Rapid growth in the development of real-time location system solutions has led to an increased interest in indoor location-aware services, such as hospital asset management. Although there are extensive studies in the literature on the analysis of outdoor location traces, the studies of indoor location traces are less touched and fragmented. To that end, in this paper, we provide a focused study of indoor location traces collected by the sensors attached to medical devices in a hospital environment. Along this line, we first introduce some unique properties of these indoor location traces. We show that they can capture the movement patterns of the medical devices, which are tightly coupled with the work flow in the controlled hospital environment. Based on this observation, we propose a stochastic model for context-aware anomaly detection in indoor location traces, which exploits the hospital work flow and models the movements of medical devices as transitions in finite state machines. In detail, we first develop a density-based method to identify the hotspots filled with high-level abnormal activities in the indoor environment. The discovered hotspots serve as the context for nearby trajectories. Then, we introduce an N-gram based method for measuring the degree of anomaly based on the detected hotspots, which is able to predict the missing events possibly due to the devices being stolen. Besides, to address the noisy nature of the indoor sensor networks, we also propose an iterative algorithm to estimate the transition probabilities. This algorithm allows to effectively recover the missing location records which are critical for the abnormality estimation. Finally, the experimental results on the real-world date sets validate the effectiveness of the proposed context-aware anomaly detection method for identifying abnormal events.

#index 1978736
#* Reliable Clustering on Uncertain Graphs
#@ Lin Liu;Ruoming Jin;Charu Aggrawal;Yelong Shen
#t 2012
#c 18
#! Many graphs in practical applications are not deterministic, but are probabilistic in nature because the existence of the edges is inferred with the use of a variety of statistical approaches. In this paper, we will examine the problem of clustering uncertain graphs. Uncertain graphs are best clustered with the use of a possible worlds model in which the most reliable clusters are discovered in the presence of uncertainty. Reliable clusters are those which are not likely to be disconnected in the context of different instantiations of the uncertain graph. We present experimental results which illustrate the effectiveness of our model and approach.

#index 1978737
#* Active Label Correction
#@ Umaa Rebbapragada;Carla E. Brodley;Damien Sulla-Menashe;Mark A. Friedl
#t 2012
#c 18
#! Active Label Correction (ALC) is an interactive method that cleans an established training set of mislabeled examples in conjunction with a domain expert. ALC presumes that the expert who conducts this review is either more accurate than the original annotator or has access to additional resources that ensure a high quality label. A high-cost re-review is possible because ALC proceeds iteratively, scoring the full training set but selecting only small batches of examples that are likely mislabeled. The expert reviews each batch and corrects any mislabeled examples, after which the classifier is retrained and the process repeats until the expert terminates it. We compare several instantiations of ALC to fully-automated methods that attempt to discard or correct label noise in a single pass. Our empirical results show that ALC outperforms single-pass methods in terms of selection efficiency and classifier accuracy. We evaluate the best ALC instantiation on our motivating task of detecting mislabeled and poorly formulated sites within a land cover classification training set from the geography domain.

#index 1978738
#* Inductive Model Generation for Text Categorization Using a Bipartite Heterogeneous Network
#@ Rafael Geraldeli Rossi;Thiago de Paulo Faleiros;Alneu de Andrade Lopes;Solange Oliveira Rezende
#t 2012
#c 18
#! Usually, algorithms for categorization of numeric data have been applied for text categorization after a preprocessing phase which assigns weights for textual terms deemed as attributes. However, due to characteristics of textual data, some algorithms for data categorization are not efficient for text categorization. Characteristics of textual data such as sparsity and high dimensionality sometimes impair the quality of general purpose classifiers. Here, we propose a text classifier based on a bipartite heterogeneous network used to represent textual document collections. Such algorithm induces a classification model assigning weights to objects that represents terms of the textual document collection. The induced weights correspond to the influence of the terms in the classification of documents they appear. The least-mean-square algorithm is used in the inductive process. Empirical evaluation using a large amount of textual document collections shows that the proposed IMBHN algorithm produces significantly better results than the k-NN, C4.5, SVM and Naïve Bayes algorithms.

#index 1978739
#* Sparse Subspace Representation for Spectral Document Clustering
#@ Budhaditya Saha;Dinh Phung;Duc Son Pham;Svetha Venkatesh
#t 2012
#c 18
#! We present a novel method for document clustering using sparse representation of documents in conjunction with spectral clustering. An \ell_{1} - norm optimization formulation is posed to learn the sparse representation of each document, allowing us to characterize the affinity between documents by considering the overall information instead of traditional pair wise similarities. This document affinity is encoded through a graph on which spectral clustering is performed. The decomposition into multiple subspaces allows documents to be part of a sub-group that shares a smaller set of similar vocabulary, thus allowing for cleaner clusters. Extensive experimental evaluations on two real-world datasets from Reuters-21578 and 20Newsgroup corpora show that our proposed method consistently outperforms state-of-the-art algorithms. Significantly, the performance improvement over other methods is prominent for this datasets.

#index 1978740
#* Learning Target Predictive Function without Target Labels
#@ Chun-Wei Seah;Ivor Wai-Hung Tsang;Yew-Soon Ong;Qi Mao
#t 2012
#c 18
#! In the absence of the labeled samples in a domain referred to as target domain, Domain Adaptation (DA) techniques come in handy. Generally, DA techniques assume there are available source domains that share similar predictive function with the target domain. Two core challenges of DA typically arise, variance that exists between source and target domains, and the inherent source hypothesis bias. In this paper, we first propose a Stability Transfer criterion for selecting relevant source domains with low variance. With this criterion, we introduce a TARget learning Assisted by Source Classifier Adaptation (TARASCA) method to address the two core challenges that have impeded the performances of DA techniques. To verify the robustness of TARASCA, extensive experimental studies are carried out with comparison to several state-of-the-art DA methods on the real-world Sentiment and Newsgroups datasets, where various settings for the class ratios of the source and target domains are considered.

#index 1978741
#* Low-Rank Transfer Subspace Learning
#@ Ming Shao;Carlos Castillo;Zhenghong Gu;Yun Fu
#t 2012
#c 18
#! One of the most important challenges in machine learning is performing effective learning when there are limited training data available. However, there is an important case when there are sufficient training data coming from other domains (source). Transfer learning aims at finding ways to transfer knowledge learned from a source domain to a target domain by handling the subtle differences between the source and target. In this paper, we propose a novel framework to solve the aforementioned knowledge transfer problem via low-rank representation constraints. This is achieved by finding an optimal subspace where each datum in the target domain can be linearly represented by the corresponding subspace in the source domain. Extensive experiments on several databases, i.e., Yale B, CMU PIE, UB Kin Face databases validate the effectiveness of the proposed approach and show the superiority to the existing, well-established methods.

#index 1978742
#* Socialized Gaussian Process Model for Human Behavior Prediction in a Health Social Network
#@ Yelong Shen;Ruoming Jin;Dejing Dou;Nafisa Chowdhury;Junfeng Sun;Brigitta Piniewski;David Kil
#t 2012
#c 18
#! Modeling and predicting human behaviors, such as the activity level and intensity, is the key to prevent the cascades of obesity, and help spread wellness and healthy behavior in a social network. In this work, we propose a Socialized Gaussian Process (SGP) for socialized human behavior modeling. In the proposed SGP model, we naturally incorporates human's personal behavior factor and social correlation factor into a unified model, where basic Gaussian Process model is leveraged to capture individual's personal behavior pattern. Furthermore, we extend the Gaussian Process Model to socialized Gaussian Process (SGP) which aims to capture social correlation phenomena in the social network. The detailed experimental evaluation has shown the SGP model achieves the best prediction accuracy compared with other baseline methods.

#index 1978743
#* Robust Prediction and Outlier Detection for Spatial Datasets
#@ Xutong Liu;Feng Chen;Chang-Tien Lu
#t 2012
#c 18
#! Spatial kriging is a widely used predictive model for spatial datasets. In spatial kriging model, the observations are assumed to be Gaussian for computational convenience. However, its predictive accuracy could be significantly compromised if the observations are contaminated by outliers. This deficiency can be systematically addressed by increasing the robustness of spatial kriging model using heavy tailed distributions, such as the Huber, Laplace, and Student's t distributions. This paper presents a novel Robust and Reduced Rank Spatial Kriging Model (R$^3$-SKM), which is resilient to the influences of outliers and allows for fast spatial inference. Furthermore, three effective and efficient algorithms are proposed based on R$^3$-SKM framework that can perform robust parameter estimation, spatial prediction, and spatial outlier detection with a linear-order time complexity. Extensive experiments on both simulated and real data sets demonstrated the robustness and efficiency of our proposed techniques.

#index 1978744
#* Profit Maximization over Social Networks
#@ Wei Lu;Laks V. S. Lakshmanan
#t 2012
#c 18
#! Influence maximization is the problem of finding a set of influential users in a social network such that the expected spread of influence under a certain propagation model is maximized. Much of the previous work has neglected the important distinction between social influence and actual product adoption. However, as recognized in the management science literature, an individual who gets influenced by social acquaintances may not necessarily adopt a product (or technology), due, e.g., to monetary concerns. In this work, we distinguish between influence and adoption by explicitly modeling the states of being influenced and of adopting a product. We extend the classical Linear Threshold (LT) model to incorporate prices and valuations, and factor them into users' decision-making process of adopting a product. We show that the expected profit function under our proposed model maintains submodularity under certain conditions, but no longer exhibits monotonicity, unlike the expected influence spread function. To maximize the expected profit under our extended LT model, we employ an unbudgeted greedy framework to propose three profit maximization algorithms. The results of our detailed experimental study on three real-world datasets demonstrate that of the three algorithms, PAGE, which assigns prices dynamically based on the profit potential of each candidate seed, has the best performance both in the expected profit achieved and in running time.

#index 1978745
#* Parallelization with Multiplicative Algorithms for Big Data Mining
#@ Dijun Luo;Chris Ding;Heng Huang
#t 2012
#c 18
#! We propose a nontrivial strategy to parallelize a series of data mining and machine learning problems, including 1-class and 2-class support vector machines, nonnegative least square problems, and $\ell_1$ regularized regression (LASSO) problems. Our strategy fortunately leads to extremely simple multiplicative algorithms which can be straightforwardly implemented in parallel computational environments, such as Map Reduce, or CUDA. We provide rigorous analysis of the correctness and convergence of the algorithm. We demonstrate the scalability and accuracy of our algorithms in comparison with other current leading algorithms.

#index 1978746
#* Community Preserving Lossy Compression of Social Networks
#@ Hossein Maserrat;Jian Pei
#t 2012
#c 18
#! Compression plays an important role in social network analysis from both practical and theoretical points of view. Although there are a few pioneering studies on social network compression, they mainly focus on lossless approaches. In this paper, we tackle the novel problem of community preserving lossy compression of social networks. The trade-off between space and information preserved in a lossy compression presents an interesting angle for social network analysis, and, at the same time, makes the problem very challenging. We propose a sequence graph compression approach, discuss the design of objective functions towards community preservation, and present an interesting and practically effective greedy algorithm. Our experimental results on both real data sets and synthetic data sets demonstrate the promise of our method.

#index 1978747
#* Automatically Discovering Talented Musicians with Acoustic Analysis of YouTube Videos
#@ Eric Nichols;Charles DuHadway;Hrishikesh Aradhye;Richard F. Lyon
#t 2012
#c 18
#! Online video presents a great opportunity for up-and-coming singers and artists to be visible to a worldwide audience. However, the sheer quantity of video makes it difficult to discover promising musicians. We present a novel algorithm to automatically identify talented musicians using machine learning and acoustic analysis on a large set of "home singing" videos. We describe how candidate musician videos are identified and ranked by singing quality. To this end, we present new audio features specifically designed to directly capture singing quality. We evaluate these vis-a-vis a large set of generic audio features and demonstrate that the proposed features have good predictive performance. We also show that this algorithm performs well when videos are normalized for production quality.

#index 1978748
#* An AdaBoost Algorithm for Multiclass Semi-supervised Learning
#@ Jafar Tanha;Maarten van Someren;Hamideh Afsarmanesh
#t 2012
#c 18
#! We present an algorithm for multiclass Semi-Supervised learning which is learning from a limited amount of labeled data and plenty of unlabeled data. Existing semi-supervised algorithms use approaches such as one-versus-all to convert the multiclass problem to several binary classification problems which is not optimal. We propose a multiclass semi-supervised boosting algorithm that solves multiclass classification problems directly. The algorithm is based on a novel multiclass loss function consisting of the margin cost on labeled data and two regularization terms on labeled and unlabeled data. Experimental results on a number of UCI datasets show that the proposed algorithm performs better than the state-of-the-art boosting algorithms for multiclass semi-supervised learning.

#index 1978749
#* A Cluster-Oriented Genetic Algorithm for Alternative Clustering
#@ Duy Tin Truong;Roberto Battiti
#t 2012
#c 18
#! Supervised alternative clusterings is the problem of finding a set of clusterings which are of high quality and different from a given negative clustering. The task is therefore a clear multi-objective optimization problem. Optimizing two conflicting objectives requires dealing with trade-offs. Most approaches in the literature optimize these objectives sequentially or indirectly, resulting in solutions which are dominated. We develop a multi-objective algorithm, called COGNAC, able to optimize the objectives directly and simultaneously and producing solutions approximating the Pareto front. COGNAC performs the recombination operator at the cluster level instead of the object level as in traditional genetic algorithms. It can accept arbitrary clustering quality and dissimilarity objectives and provide solutions dominating those of other state-of-the-art algorithms. COGNAC can also be used to generate a sequence of alternative clusterings, each of which is guaranteed to be different from all previous ones.

#index 1978750
#* A New Proposal for Score Normalization in Biometric Signature Recognition Based on Client Threshold Prediction
#@ Carlos Vivaracho-Pascual;Arancha Simon-Hurtado;Esperanza Manso-Martinez;Juan M. Pascual-Gaspar
#t 2012
#c 18
#! Score Normalization is a usual technique in pattern recognition to standardize the classifier output ranges so as to, for example, fuse these outputs. The use of score normalization in biometric recognition is a very important part of the system, specially in those based on behavioral traits, such as written signature or voice, conditioning the final system performance. Then, many works can be found that focus on the problem. A successful new approach for client threshold prediction, based on Multiple Linear Prediction, has been presented in recent works. Here, a new approach for score normalization, based on this proposal for biometric manuscript signature user verification, is shown. This proposal is compared with the state of the art methods, achieving an improvement of 19% and 16% for Equal Error Rate (EER) and 60% and 26% for Detection Cost Function (DCF) performance measures, for random and skilled forgeries, respectively.

#index 1978751
#* Signal Disaggregation via Sparse Coding with Featured Discriminative Dictionary
#@ Bingsheng Wang;Feng Chen;Haili Dong;Arnold P. Boedihardjo;Chang-Tien Lu
#t 2012
#c 18
#! As the issue of freshwater shortage is increasing daily, it's critical to take effective measures for water conservation. Based on previous studies, device level consumption could lead to significant conservation of freshwater. However, current smart meter deployments only produce low sample rate aggregated data. In this paper, we examine the task of separating whole-home water consumption into its component appliances. A key challenge is to address the unique features of low sample rate data. To this end, we propose Sparse Coding with Featured Discriminative Dictionary (SCFDD) by incorporating inherent shape and activation features to capture the discriminative characteristics of devices. In addition, extensive experiments were performed to validate the effectiveness of SCFDD.

#index 1978752
#* Cost-Sensitive Online Classification
#@ Jialei Wang;Peilin Zhao;Steven C. H. Hoi
#t 2012
#c 18
#! Both cost-sensitive classification and online learning have been studied extensively in data mining and machine learning communities, respectively. It is a bit surprising that there was very limited comprehensive study for addressing an important intersecting problem, that is, cost-sensitive online classification. In this paper, we formally study this problem, and propose a new framework for cost-sensitive online classification by exploiting the idea of online gradient descent techniques. Based on the framework, we propose a family of cost-sensitive online classification algorithms, which are designed to directly optimize two well-known cost-sensitive measures: (i) maximization of weighted sum of sensitivity and specificity, and (ii) minimization of weighted misclassification cost. We analyze the theoretical bounds of the cost-sensitive measures made by the proposed algorithms, and extensively examine their empirical performance on a variety of cost-sensitive online classification tasks.

#index 1978753
#* Labels vs. Pairwise Constraints: A Unified View of Label Propagation and Constrained Spectral Clustering
#@ Xiang Wang;Buyue Qian;Ian Davidson
#t 2012
#c 18
#! In many real-world applications we can model the data as a graph with each node being an instance and the edges indicating a degree of similarity. Side information is often available in the form of labels for a small subset of instances, which gives rise to two problem settings and two types of algorithms. In the label propagation style algorithms, the known labels are propagated to the unlabeled nodes. In the constrained clustering style algorithms, known labels are first converted to pair wise constraints (Must-Link and Cannot-Link), then a constrained cut is computed as a tradeoff between minimizing the cut cost and maximizing the constraint satisfaction. Both techniques are evaluated by their ability to recover the ground truth labeling, i.e. by 0/1 loss function either directly on the labels or on the pair wise relations derived from the labels. These two fields have developed separately, but in this paper, we show that they are indeed related. This insight allows us to propose a novel way to generate constraints from the propagated labels, which our empirical study shows outperforms and is more stable than the state-of-the-art label propagation and constrained spectral clustering algorithms.

#index 1978754
#* Dynamic Boolean Matrix Factorizations
#@ Pauli Miettinen
#t 2012
#c 18
#! Boolean matrix factorization is a method to decompose a binary matrix into two binary factor matrices. Akin to other matrix factorizations, the factor matrices can be used for various data analysis tasks. Many (if not most) real-world data sets are dynamic, though, meaning that new information is recorded over time. Incorporating this new information into the factorization can require a re-computation of the factorization -- something we cannot do if we want to keep our factorization up-to-date after each update. This paper proposes a method to dynamically update the Boolean matrix factorization when new data is added to the data base. This method is extended with a mechanism to improve the factorization with a trade-off in speed of computation. The method is tested with a number of real-world and synthetic data sets including studying its efficiency against off-line methods. The results show that with good initialization the proposed online and dynamic methods can beat the state-of-the-art offline Boolean matrix factorization algorithms.

#index 1978755
#* Outlier Ranking via Subspace Analysis in Multiple Views of the Data
#@ Emmanuel Muller;Ira Assent;Patricia Iglesias;Yvonne Mulle;Klemens Bohm
#t 2012
#c 18
#! Outlier mining is an important task for finding anomalous objects. In practice, however, there is not always a clear distinction between outliers and regular objects as objects have different roles w.r.t. different attribute sets. An object may deviate in one subspace, i.e. a subset of attributes. And the same object might appear perfectly regular in other subspaces. One can think of subspaces as multiple views on one database. Traditional methods consider only one view (the full attribute space). Thus, they miss complex outliers that are hidden in multiple subspaces. In this work, we propose Outrank, a novel outlier ranking concept. Outrank exploits subspace analysis to determine the degree of outlierness. It considers different subsets of the attributes as individual outlier properties. It compares clustered regions in arbitrary subspaces and derives an outlierness score for each object. Its principled integration of multiple views into an outlierness measure uncovers outliers that are not detectable in the full attribute space. Our experimental evaluation demonstrates that Outrank successfully determines a high quality outlier ranking, and outperforms state-of-the-art outlierness measures.

#index 1978756
#* Clash of the Contagions: Cooperation and Competition in Information Diffusion
#@ Seth A. Myers;Jure Leskovec
#t 2012
#c 18
#! In networks, contagions such as information, purchasing behaviors, and diseases, spread and diffuse from node to node over the edges of the network. Moreover, in real-world scenarios multiple contagions spread through the network simultaneously. These contagions not only propagate at the same time but they also interact and compete with each other as they spread over the network. While traditional empirical studies and models of diffusion consider individual contagions as independent and thus spreading in isolation, we study how different contagions interact with each other as they spread through the network. We develop a statistical model that allows for competition as well as cooperation of different contagions in information diffusion. Competing contagions decrease each other's probability of spreading, while cooperating contagions help each other in being adopted throughout the network. We evaluate our model on 18,000 contagions simultaneously spreading through the Twitter network. Our model learns how different contagions interact with each other and then uses these interactions to more accurately predict the diffusion of a contagion through the network. Moreover, the model also provides a compelling hypothesis for the principles that govern content interaction in information diffusion. Most importantly, we find very strong effects of interactions between contagions. Interactions cause a relative change in the spreading probability of a contagion by em 71% on the average.

#index 1978757
#* High Performance Offline and Online Distributed Collaborative Filtering
#@ Ankur Narang;Abhinav Srivastava;Naga Praveen Kumar Katta
#t 2012
#c 18
#! Big data analytics is a hot research area both in academia and industry. It envisages processing massive amounts of data at high rates to generate new insights leading to positive impact (for both users and providers) of industries such as E-commerce, Telecom, Finance, Life Sciences and so forth. We consider collaborative filtering (CF) and Clustering algorithms that are key fundamental analytics kernels that help in achieving these aims. High throughput CF and co-clustering on highly sparse and massive datasets, along with a high prediction accuracy, is a computationally challenging problem. In this paper, we present a novel hierarchical design for soft real-time (less than 1-minute.) distributed co-clustering based collaborative filtering algorithm. We study both the online and offline variants of this algorithm. Theoretical analysis of the time complexity of our algorithm proves the efficacy of our approach. Further, we present the impact of load balancing based optimizations on multi-core cluster architectures. Using the Netflix dataset(900M training ratings with replication) as well as the Yahoo KDD Cup(2.3B training ratings with replication) datasets, we demonstrate the performance and scalability of our algorithm on a large multi-core cluster architecture. In offline mode, our distributed algorithm demonstrates around 4x better performance (on Blue Gene/P) as compared to the best prior work, along with high accuracy. In online mode, we demonstrated around 3x better performance compared to baseline MPI implementation. To the best of our knowledge, our algorithm provides the best known online and offline performance and scalability results with high accuracy on multi-core cluster architectures.

#index 1978758
#* Efficient Episode Mining of Dynamic Event Streams
#@ Debprakash Patnaik;Srivatsan Laxman;Badrish Chandramouli;Naren Ramakrishnan
#t 2012
#c 18
#! Discovering frequent episodes over event sequences is an important data mining problem. Existing methods typically require multiple passes over the data, rendering them unsuitable for streaming contexts. We present the first streaming algorithm for mining frequent episodes over a window of recent events in the stream. We derive approximation guarantees for our algorithm in terms of: (i) the separation of frequent episodes from infrequent ones, and (ii) the rate of change of stream characteristics. Our parameterization of the problem provides a new sweet spot in the tradeoff between making distributional assumptions over the stream and algorithmic efficiencies of mining. We illustrate how this yields significant benefits when mining practical streams from neuroscience and telecommunications logs.

#index 1978759
#* Collaborative Filtering with Aspect-Based Opinion Mining: A Tensor Factorization Approach
#@ Yuanhong Wang;Yang Liu;Xiaohui Yu
#t 2012
#c 18
#! Collaborative filtering (CF) aims to produce user specific recommendations based on other users' ratings of items. Most existing CF methods rely only on users' overall ratings of items, ignoring the variety of opinions users may have towards different aspects of the items. Using the movie domain as a case study, we propose a framework that is able to capture users' opinions on different aspects from the textual reviews, and use that information to improve the effectiveness of CF. This framework has two components, an opinion mining component and a rating inference component. The former extracts and summarizes the opinions on multiple aspects from the reviews, generating ratings on the various aspects. The latter component, on the other hand, infers the overall ratings of items based on the aspect ratings, which forms the basis for item recommendation. Our core contribution is in the proposal of a tensor factorization approach for the rating inference. Operating on the tensor composed of the overall and aspect ratings, this approach is able to capture the intrinsic relationships between users, items, and aspects, and provide accurate predictions on unknown ratings. Experiments on a movie dataset show that our proposal significantly improves the prediction accuracy compared with two baseline methods.

#index 1978760
#* Towards Annotating Media Contents through Social Diffusion Analysis
#@ Tong Xu;Dong Liu;Enhong Chen;Huanhuan Cao;Jilei Tian
#t 2012
#c 18
#! Recently, the boom of media contents on the Internet raises challenges in managing them effectively and thus requires automatic media annotation techniques. Motivated by the observation that media contents are usually shared frequently in online communities and thus have a lot of social diffusion records, we propose a novel media annotating approach depending on these social diffusion records instead of metadata. The basic assumption is that the social diffusion records reflect the common interests (CI) between users, which can be analyzed for generating annotations. With this assumption, we present a novel CI-based social diffusion model and translate the automatic annotating task into the CI-based diffusion maximization (CIDM) problem. Moreover, we propose to solve the CIDM problem through two optimization tasks, corresponding to the training and test stages in supervised learning. Extensive experiments on real-world data sets show that our approach can effectively generate high quality annotations, and thus demonstrate the capability of social diffusion analysis in annotating media.

#index 1978761
#* An Approach to Evaluate the Local Completeness of an Event Log
#@ Hedong Yang;Lijie Wen;Jianmin Wang
#t 2012
#c 18
#! Process mining links traditional model-driven Business Process Management and data mining by means of deriving knowledge from event logs to improve operational business processes. As an impact factor of the quality of process mining results, the degree of completeness of the given event log should be necessarily measured. In this paper an approach is proposed in the context of mining control-flow dependencies to evaluate the local completeness of an event log without knowing any information about the original process model. Experiment results show that the proposed approach works robustly and gives better estimation than approaches available.

#index 1978762
#* Community-Affiliation Graph Model for Overlapping Network Community Detection
#@ Jaewon Yang;Jure Leskovec
#t 2012
#c 18
#! One of the main organizing principles in real-world networks is that of network communities, where sets of nodes organize into densely linked clusters. Communities in networks often overlap as nodes can belong to multiple communities at once. Identifying such overlapping communities is crucial for the understanding the structure as well as the function of real-world networks. Even though community structure in networks has been widely studied in the past, practically all research makes an implicit assumption that overlaps between communities are less densely connected than the non-overlapping parts themselves. Here we validate this assumption on 6 large scale social, collaboration and information networks where nodes explicitly state their community memberships. By examining such ground-truth communities we find that the community overlaps are more densely connected than the non-overlapping parts, which is in sharp contrast to the conventional wisdom that community overlaps are more sparsely connected than the communities themselves. Practically all existing community detection methods fail to detect communities with dense overlaps. We propose Community-Affiliation Graph Model, a model-based community detection method that builds on bipartite node-community affiliation networks. Our method successfully captures overlapping, non-overlapping as well as hierarchically nested communities, and identifies relevant communities more accurately than the state-of-the-art methods in networks ranging from biological to social and information networks.

#index 1978763
#* Robust Ensemble Clustering by Matrix Completion
#@ Jinfeng Yi;Tianbao Yang;Rong Jin;Anil K. Jain;Mehrdad Mahdavi
#t 2012
#c 18
#! Data clustering is an important task and has found applications in numerous real-world problems. Since no single clustering algorithm is able to identify all different types of cluster shapes and structures, ensemble clustering was proposed to combine different partitions of the same data generated by multiple clustering algorithms. The key idea of most ensemble clustering algorithms is to find a partition that is consistent with most of the available partitions of the input data. One problem with these algorithms is their inability to handle uncertain data pairs, i.e. data pairs for which about half of the partitions put them into the same cluster and the other half do the opposite. When the number of uncertain data pairs is large, they can mislead the ensemble clustering algorithm in generating the final partition. To overcome this limitation, we propose an ensemble clustering approach based on the technique of matrix completion. The proposed algorithm constructs a partially observed similarity matrix based on the data pairs whose cluster memberships are agreed upon by most of the clustering algorithms in the ensemble. It then deploys the matrix completion algorithm to complete the similarity matrix. The final data partition is computed by applying an efficient spectral clustering algorithm to the completed matrix. Our empirical studies with multiple real-world datasets show that the proposed algorithm performs significantly better than the state-of-the-art algorithms for ensemble clustering.

#index 1978764
#* Robust Matrix Completion via Joint Schatten p-Norm and lp-Norm Minimization
#@ Feiping Nie;Hua Wang;Xiao Cai;Heng Huang;Chris Ding
#t 2012
#c 18
#! The low-rank matrix completion problem is a fundamental machine learning problem with many important applications. The standard low-rank matrix completion methods relax the rank minimization problem by the trace norm minimization. However, this relaxation may make the solution seriously deviate from the original solution. Meanwhile, most completion methods minimize the squared prediction errors on the observed entries, which is sensitive to outliers. In this paper, we propose a new robust matrix completion method to address these two problems. The joint Schatten $p$-norm and $\ell_p$-norm are used to better approximate the rank minimization problem and enhance the robustness to outliers. The extensive experiments are performed on both synthetic data and real world applications in collaborative filtering and social network link prediction. All empirical results show our new method outperforms the standard matrix completion methods.

#index 1978765
#* Healing Truncation Bias: Self-Weighted Truncation Framework for Dual Averaging
#@ Hidekazu Oiwa;Shin Matsushima;Hiroshi Nakagawa
#t 2012
#c 18
#! We propose a new truncation framework for online supervised learning. Learning a compact predictive model in an online setting has recently attracted a great deal of attention. The combination of online learning with sparsity-inducing regularization enables faster learning with a smaller memory space than a conventional learning framework. However, a simple combination of these triggers the truncation of weights whose corresponding features rarely appear, even if these features are crucial for prediction. Furthermore, it is difficult to emphasize these features in advance while preserving the advantages of online learning. We develop an extensional truncation framework to Dual Averaging, which retains rarely occurring but informative features. Our proposed framework integrates information on all previous sub gradients of the loss functions into a regularization term. Our enhancement of a conventional L1-regularization accomplishes the automatic adjustment of each feature's truncations. This extension enables us to identify and retain rare but informative features without preprocessing. In addition, our framework achieves the same computational complexity and regret bound as standard Dual Averaging. Experiments demonstrated that our framework outperforms other sparse online learning algorithms.

#index 1978766
#* Unsupervised Multi-class Regularized Least-Squares Classification
#@ Tapio Pahikkala;Antti Airola;Fabian Gieseke;Oliver Kramer
#t 2012
#c 18
#! Regularized least-squares classification is one of the most promising alternatives to standard support vector machines, with the desirable property of closed-form solutions that can be obtained analytically, and efficiently. While the supervised, and mostly binary case has received tremendous attention in recent years, unsupervised multi-class settings have not yet been considered. In this work we present an efficient implementation for the unsupervised extension of the multi-class regularized least-squares classification framework, which is, to the best of the authors' knowledge, the first one in the literature addressing this task. The resulting kernel-based framework efficiently combines steepest descent strategies with powerful meta-heuristics for avoiding local minima. The computational efficiency of the overall approach is ensured through the application of matrix algebra shortcuts that render efficient updates of the intermediate candidate solutions possible. Our experimental evaluation indicates the potential of the novel method, and demonstrates its superior clustering performance over a variety of competing methods on real-world data sets.

#index 1978767
#* Utilizing Real-World Transportation Data for Accurate Traffic Prediction
#@ Bei Pan;Ugur Demiryurek;Cyrus Shahabi
#t 2012
#c 18
#! For the first time, real-time high-fidelity spatiotemporal data on transportation networks of major cities have become available. This gold mine of data can be utilized to learn about traffic behavior at different times and locations, potentially resulting in major savings in time and fuel, the two important commodities of 21st century. As a first step towards the utilization of this data, in this paper, we study the real-world data collected from Los Angeles County transportation network in order to incorporate the data's intrinsic behavior into a time-series mining technique to enhance its accuracy for traffic prediction. In particular, we utilized the spatiotemporal behaviors of rush hours and events to perform a more accurate prediction of both short-term and long-term average speed on road-segments, even in the presence of infrequent events (e.g., accidents). Our result shows that taking historical rush-hour behavior we can improve the accuracy of traditional predictors by up to 67% and 78% in short-term and long-term predictions, respectively. Moreover, we can incorporate the impact of an accident to improve the prediction accuracy by up to 91%.

#index 1978768
#* A Novel Semantic Smoothing Method Based on Higher Order Paths for Text Classification
#@ Mitat Poyraz;Zeynep Hilal Kilimci;Murat Can Ganiz
#t 2012
#c 18
#! It has been shown that Latent Semantic Indexing (LSI) takes advantage of implicit higher-order (or latent) structure in the association of terms and documents. Higher order relations in LSI capture "latent semantics". Inspired by this, a novel Bayesian framework for classification named Higher Order Naïve Bayes (HONB), which can explicitly make use of these higher-order relations, has been introduced previously. We present a novel semantic smoothing method named Higher Order Smoothing (HOS) for the Naive Bayes algorithm. HOS is built on a similar graph based data representation of HONB which allows semantics in higher order paths to be exploited. Additionally, we take the concept one step further in HOS and exploited the relationships between instances of different classes in order to improve the parameter estimation when dealing with insufficient labeled data. As a result, we have not only been able to move beyond instance boundaries, but also class boundaries to exploit the latent information in higher-order paths. The results of our extensive experiments demonstrate the value of HOS on several benchmark datasets.

#index 1978769
#* Hashing with Generalized Nyström Approximation
#@ Jeong-Min Yun;Saehoon Kim;Seungjin Choi
#t 2012
#c 18
#! Hashing, which involves learning binary codes to embed high-dimensional data into a similarity-preserving low-dimensional Hamming space, is often formulated as linear dimensionality reduction followed by binary quantization. Linear dimensionality reduction, based on maximum variance formulation, requires leading eigenvectors of data covariance or graph Laplacian matrix. Computing leading singular vectors or eigenvectors in the case of high-dimension and large sample size, is a main bottleneck in most of data-driven hashing methods. In this paper we address the use of generalized Nystrom method where a subset of rows and columns are used to approximately compute leading singular vectors of the data matrix, in order to improve the scalability of hashing methods in the case of high-dimensional data with large sample size. Especially we validate the useful behavior of generalized Nystrom approximation with uniform sampling, in the case of a recently-developed hashing method based on principal component analysis (PCA) followed by an iterative quantization, referred to as PCA+ITQ, developed by Gong and Lazebnik. We compare the performance of generalized Nystrom approximation with uniform and non-uniform sampling, to the full singular value decomposition (SVD) method, confirming that the uniform sampling improves the computational and space complexities dramatically, while the performance is not much sacrificed. In addition we present low-rank approximation error bounds for generalized Nystrom approximation with uniform sampling, which is not a trivial extension of available results on the non-uniform sampling case.

#index 1978770
#* Detecting Spam and Promoting Campaigns in the Twitter Social Network
#@ Xianchao Zhang;Shaoping Zhu;Wenxin Liang
#t 2012
#c 18
#! The Twitter social network has become a target platform for both promoters and stammers to disseminate their target messages. There are a large number of campaigns containing coordinated spam or promoting accounts in Twitter, which are more harmful than the traditional methods, such as email spamming. Since traditional solutions mainly check individual accounts or messages, it is an urgent task to detect spam and promoting campaigns in Twitter. In this paper, we propose a scalable framework to detect both spam and promoting campaigns. Our framework consists of three steps: firstly linking accounts who post URLs for similar purposes, secondly extracting candidate campaigns which may exist for spam or promoting purpose and finally distinguishing their intents. One salient aspect of the framework is introducing a URL-driven estimation method to measure the similarity between accounts' purposes of posting URLs, the other one is proposing multiple features to distinguish the candidate campaigns based on a machine learning method. Over a large-scale dataset from Twitter, we can extract the actual campaigns with high precision and recall and distinguish the majority of the candidate campaigns correctly.

#index 1978771
#* Cross-Language Opinion Target Extraction in Review Texts
#@ Xinjie Zhou;Xiaojun Wan;Jianguo Xiao
#t 2012
#c 18
#! Opinion target extraction is a subtask of opinion mining which is very useful in many applications. In this study, we investigate the problem in a cross-language scenario which leverages the rich labeled data in a source language for opinion target extraction in a different target language. The English labeled corpus is used as training set. We generate two Chinese training datasets with different features. Two labeling models for Chinese opinion target extraction are learned based on Conditional Random Fields (CRF). After that, we use a monolingual co-training algorithm to improve the performance of both models by leveraging the enormous unlabeled Chinese review texts on the web. Experimental results show the effectiveness of our proposed approach.

#index 1978772
#* Sparse Bayesian Adversarial Learning Using Relevance Vector Machine Ensembles
#@ Yan Zhou;Murat Kantarcioglu;Bhavani Thuraisingham
#t 2012
#c 18
#! Data mining tasks are made more complicated when adversaries attack by modifying malicious data to evade detection. The main challenge lies in finding a robust learning model that is insensitive to unpredictable malicious data distribution. In this paper, we present a sparse relevance vector machine ensemble for adversarial learning. The novelty of our work is the use of individualized kernel parameters to model potential adversarial attacks during model training. We allow the kernel parameters to drift in the direction that minimizes the likelihood of the positive data. This step is interleaved with learning the weights and the weight priors of a relevance vector machine. Our empirical results demonstrate that an ensemble of such relevance vector machine models is more robust to adversarial attacks.

#index 1978773
#* Mining Personal Context-Aware Preferences for Mobile Users
#@ Hengshu Zhu;Enhong Chen;Kuifei Yu;Huanhuan Cao;Hui Xiong;Jilei Tian
#t 2012
#c 18
#! In this paper, we illustrate how to extract personal context-aware preferences from the context-rich device logs (i.e., context logs) for building novel personalized context-aware recommender systems. A critical challenge along this line is that the context log of each individual user may not contain sufficient data for mining his/her context-aware preferences. Therefore, we propose to first learn common context-aware preferences from the context logs of many users. Then, the preference of each user can be represented as a distribution of these common context-aware preferences. Specifically, we develop two approaches for mining common context-aware preferences based on two different assumptions, namely, context independent and context dependent assumptions, which can fit into different application scenarios. Finally, extensive experiments on a real-world data set show that both approaches are effective and outperform baselines with respect to mining personal context-aware preferences for mobile users.

#index 1978774
#* Online Induction of Probabilistic Real Time Automata
#@ Jana Schmidt;Stefan Kramer
#t 2012
#c 18
#! Probabilistic real time automata (PRTAs) are a representation of dynamic processes arising in the sciences and industry. Currently, the induction of automata is divided into two steps: the creation of the prefix tree acceptor (PTA) and the merge procedure based on clustering of the states. These two steps can be very time intensive when a PRTA is to be induced for massive or even unbounded data sets. The latter one can be efficiently processed, as there exist scalable online clustering algorithms. However, the creation of the PTA still can be very time consuming. To overcome this problem, we propose a genuine online PRTA induction approach that incorporates new instances by first collapsing them and then using a maximum frequent pattern based clustering. The approach is tested against a predefined synthetic automaton and real-world data sets, for which the approach is scalable and stable. Moreover, we present a broad evaluation on a real world disease group data set that shows the applicability of such a model to the analysis of medical processes.

#index 1978775
#* Dimensionality Reduction on Heterogeneous Feature Space
#@ Xiaoxiao Shi;Philip Yu
#t 2012
#c 18
#! Combining correlated data sources may help improve the learning performance of a given task. For example, in recommendation problems, one can combine (1) user profile database ({\eg} genders, age, {\etc}), (2) users' log data ({\eg}, click through data, purchasing records, {\etc}), and (3) users' social network (useful in social targeting) to build a recommendation model. All these data sources provide informative but heterogeneous features. For instance, user profile database usually has nominal features reflecting users' background, log data provides term-based features about users' historical behaviors, and social network database has graph relational features. Given multiple heterogeneous data sources, one important challenge is to find a unified feature subspace that captures the knowledge from all sources. To this aim, we propose a principle of \emph{collective component analysis} (CoCA), in order to handle dimensionality reduction across a mixture of vector-based features and graph relational features. The CoCA principle is to find a feature subspace with maximal variance under two constraints. First, there should be consensus among the projections from different feature spaces. Second, the similarity between connected data (in any of the network databases) should be maximized. The optimal solution is obtained by solving an eigenvalue problem. Moreover, we discuss how to use prior knowledge to distinguish informative data sources, and optimally weight them in CoCA. Since there is no previous model that can be directly applied to solve the problem, we devised a straightforward comparison method by performing dimension reduction on the concatenation of the data sources. Three sets of experiments show that CoCA substantially outperforms the comparison method.

#index 1978776
#* Online Maritime Abnormality Detection Using Gaussian Processes and Extreme Value Theory
#@ Mark Smith;Steven Reece;Stephen Roberts;Iead Rezek
#t 2012
#c 18
#! Novelty, or abnormality, detection aims to identify patterns within data streams that do not conform to expected behaviour. This paper introduces a novelty detection technique using a combination of Gaussian Processes and extreme value theory to identify anomalous behaviour in streaming data. The proposed combination of continuous and count stochastic processes is a principled approach towards dynamic extreme value modeling that accounts for the dynamics in the time series, the streaming nature of its observation as well as its sampling process. The approach is tested on both synthetic and real data, showing itself to be effective in our primary application of maritime vessel track analysis.

#index 1978777
#* Distributed Matrix Completion
#@ Christina Teflioudi;Faraz Makari;Rainer Gemulla
#t 2012
#c 18
#! We discuss parallel and distributed algorithms for large-scale matrix completion on problems with millions of rows, millions of columns, and billions of revealed entries. We focus on in-memory algorithms that run on a small cluster of commodity nodes, even very large problems can be handled effectively in such a setup. Our DALS, ASGD, and DSGD++ algorithms are novel variants of the popular alternating least squares and stochastic gradient descent algorithms, they exploit thread-level parallelism, in-memory processing, and asynchronous communication. We provide some guidance on the asymptotic performance of each algorithm and investigate the performance of both our algorithms and previously proposed Map Reduce algorithms in large-scale experiments. We found that DSGD++ outperforms competing methods in terms of overall runtime, memory consumption, and scalability. Using DSGD++, we can factor a matrix with 10B entries on 16 compute nodes in around 40 minutes.

#index 1978778
#* Sparse Group Selection on Fused Lasso Components for Identifying Group-Specific DNA Copy Number Variations
#@ Ze Tian;Huanan Zhang;Rui Kuang
#t 2012
#c 18
#! Detecting DNA copy number variations (CNVs) from arrayCGH or genotyping-array data to correlate with cancer outcomes is crucial for understanding the molecular mechanisms underlying cancer. Previous methods either focus on detecting CNVs in each individual patient sample or common CNVs across all the patient samples. These methods ignore the discrepancies introduced by the heterogeneity in the patient samples, which implies that common CNVs might only be shared within some groups of samples instead of all samples. In this paper, we propose a latent feature model that couples sparse sample group selection with fused lasso on CNV components to identify group-specific CNVs. Assuming a given group structure on patient samples by clinical information, sparse group selection on fused lasso (SGS-FL) identifies the optimal latent CNV components, each of which is specific to the samples in one or several groups. The group selection for each CNV component is determined dynamically by an adaptive algorithm to achieve a desired sparsity. Simulation results show that SGS-FL can more accurately identify the latent CNV components when there is a reliable underlying group structure in the samples. In the experiments on arrayCGH breast cancer and bladder cancer datasets, SGS-FL detected CNV regions that are more relevant to cancer, and provided latent feature weights that can be used for better sample classification.

#index 1978779
#* Inferring the Underlying Structure of Information Cascades
#@ Bo Zong;Yinghui Wu;Ambuj K. Singh;Xifeng Yan
#t 2012
#c 18
#! In social networks, information and influence diffuse among users as cascades. While the importance of studying cascades has been recognized in various applications, it is difficult to observe the complete structure of cascades in practice. In this paper we study the cascade inference problem following the independent cascade model, and provide a full treatment from complexity to algorithms: (a) we propose the idea of consistent trees as the inferred structures for cascades, these trees connect source nodes and observed nodes with paths satisfying the constraints from the observed temporal information. (b) We introduce metrics to measure the likelihood of consistent trees as inferred cascades, as well as several optimization problems for finding them. (c) We show that the decision problems for consistent trees are in general NP-complete, and that the optimization problems are hard to approximate. (d) We provide approximation algorithms with performance guarantees on the quality of the inferred cascades, as well as heuristics. We experimentally verify the efficiency and effectiveness of our inference algorithms, using real and synthetic data.

#index 1978780
#* Kernel-Based Weighted Multi-view Clustering
#@ Grigorios Tzortzis;Aristidis Likas
#t 2012
#c 18
#! Exploiting multiple representations, or views, for the same set of instances within a clustering framework is a popular practice for boosting clustering accuracy. However, some of the available sources may be misleading (due to noise, errors in measurement etc.) in revealing the true structure of the data, thus, their inclusion in the clustering process may have negative influence. This aspect seems to be overlooked in the multi-view literature where all representations are equally considered. In this work, views are expressed in terms of given kernel matrices and a weighted combination of the kernels is learned in parallel to the partitioning. Weights assigned to kernels are indicative of the quality of the corresponding views' information. Additionally, the combination scheme incorporates a parameter that controls the admissible sparsity of the weights to avoid extremes and tailor them to the data. Two efficient iterative algorithms are proposed that alternate between updating the view weights and recomputing the clusters to optimize the intra-cluster variance from different perspectives. The conducted experiments reveal the effectiveness of our methodology compared to other multi-view methods.

#index 1978781
#* Local and Global Algorithms for Learning Dynamic Bayesian Networks
#@ Nguyen Xuan Vinh;Madhu Chetty;Ross Coppel;Pramod P. Wangikar
#t 2012
#c 18
#! Learning optimal Bayesian networks (BN) from data is NP-hard in general. Nevertheless, certain BN classes with additional topological constraints, such as the dynamic BN (DBN) models, widely applied in specific fields such as systems biology, can be efficiently learned in polynomial time. Such algorithms have been developed for the Bayesian-Dirichlet (BD), Minimum Description Length (MDL), and Mutual Information Test (MIT) scoring metrics. The BD-based algorithm admits a large polynomial bound, hence it is impractical for even modestly sized networks. The MDL-and MIT-based algorithms admit much smaller bounds, but require a very restrictive assumption that all variables have the same cardinality, thus significantly limiting their applicability. In this paper, we first propose an improvement to the MDL-and MIT-based algorithms, dropping the equicardinality constraint, thus significantly enhancing their generality. We also explore local Markov blanket based algorithms for constructing BN in the context of DBN, and show an interesting result: under the faithfulness assumption, the mutual information test based local Markov blanket algorithms yield the same network as learned by the global optimization MIT-based algorithm. Experimental validation on small and large scale genetic networks demonstrates the effectiveness of our proposed approaches.

#index 1978782
#* Class Probability Estimates are Unreliable for Imbalanced Data (and How to Fix Them)
#@ Byron C. Wallace;Issa J. Dahabreh
#t 2012
#c 18
#! Obtaining good probability estimates is imperative for many applications. The increased uncertainty and typically asymmetric costs surrounding rare events increases this need. Experts (and classification systems) often rely on probabilities to inform decisions. However, we demonstrate that class probability estimates attained via supervised learning in imbalanced scenarios systematically underestimate the probabilities for minority class instances, despite ostensibly good overall calibration. To our knowledge, this problem has not previously been explored. Motivated by our exposition of this issue, we propose a simple, effective and theoretically motivated method to mitigate the bias of probability estimates for imbalanced data that bags estimators calibrated over balanced bootstrap samples. This approach drastically improves performance on the minority instances without greatly affecting overall calibration. We show that additional uncertainty can be exploited via a Bayesian approach by considering posterior distributions over bagged probability estimates.

#index 1978783
#* Scalable and Memory-Efficient Clustering of Large-Scale Social Networks
#@ Joyce Jiyoung Whang;Xin Sui;Inderjit S. Dhillon
#t 2012
#c 18
#! Clustering of social networks is an important task for their analysis, however, most existing algorithms do not scale to the massive size of todayâs social networks. A popular class of graph clustering algorithms for large-scale networks, such as PMetis, KMetis and Graclus, is based on a multilevel framework. Generally, these multilevel algorithms work reasonably well on networks with a few million vertices. However, when the network size increases to the scale of 10 million vertices or greater, the performance of these algorithms rapidly degrades. Furthermore, an inherent property of social networks, the power law degree distribution, makes these algorithms infeasible to apply to large-scale social networks. In this paper, we propose a scalable and memory-efficient clustering algorithm for large-scale social networks. We name our algorithm GEM, by mixing two key concepts of the algorithm, Graph Extraction and weighted kernel k-Means. GEM efficiently extracts a good skeleton graph from the original graph, and propagates the clustering result of the extracted graph to the rest of the network. Experimental results show that GEM produces clusters of quality comparable to or better than existing state-of-the-art graph clustering algorithms, while it is much faster and consumes much less memory. Furthermore, the parallel implementation of GEM, called PGEM, not only produces higher quality of clusters but also achieves much better scalability than most current parallel graph clustering algorithms.

#index 1978784
#* Ensemble Pruning via Constrained Eigen-Optimization
#@ Linli Xu;Bo Li;Enhong Chen
#t 2012
#c 18
#! An ensemble is composed of a set of base learners that make predictions jointly. The generalization performance of an ensemble has been justified both theoretically and in practice. However, existing ensemble learning methods sometimes produce unnecessarily large ensembles, with an expense of extra computational costs and memory consumption. The purpose of ensemble pruning is to select a subset of base learners with comparable or better prediction performance. In this paper, we formulate the ensemble pruning problem into a combinatorial optimization problem with the goal to maximize the accuracy and diversity at the same time. Solving this problem exactly is computationally hard. Fortunately, we can relax and reformulate it as a constrained eigenvector problem, which can be solved with an efficient algorithm that is guaranteed to converge globally. Convincing experimental results demonstrate that this optimization based ensemble pruning algorithm outperforms the state-of-the-art heuristics in the literature.

#index 1978785
#* Handling Ambiguity via Input-Output Kernel Learning
#@ Xinxing Xu;Ivor W. Tsang;Dong Xu
#t 2012
#c 18
#! Data ambiguities exist in many data mining and machine learning applications such as text categorization and image retrieval. For instance, it is generally beneficial to utilize the ambiguous unlabeled documents to learn a more robust classifier for text categorization under the semi-supervised learning setting. To handle general data ambiguities, we present a unified kernel learning framework named Input-Output Kernel Learning (IOKL). Based on our framework, we further propose a novel soft margin group sparse Multiple Kernel Learning (MKL) formulation by introducing a group kernel slack variable to each group of base input-output kernels. Moreover, an efficient block-wise coordinate descent algorithm with an analytical solution for the kernel combination coefficients is developed to solve the proposed formulation. We conduct comprehensive experiments on benchmark datasets for both semi-supervised learning and multiple instance learning tasks, and also apply our IOKL framework to a computer vision application called text-based image retrieval on the NUS-WIDE dataset. Promising results demonstrate the effectiveness of our proposed IOKL framework.

#index 1978786
#* Efficient Learning for Hashing Proportional Data
#@ Zhao Xu;Kristian Kersting;Christian Bauckhage
#t 2012
#c 18
#! Spectral hashing (SH) seeks compact binary codes of data points so that Hamming distances between codes correlate with data similarity. Quickly learning such codes typically boils down to principle component analysis (PCA). However, this is only justified for normally distributed data. For proportional data (normalized histograms), this is not the case. Due to the sum-to-unity constraint, features that are as independent as possible will not all be uncorrelated. In this paper, we show that a linear-time transformation efficiently copes with sum-to-unity constraints: first, we select a small number K of diverse data points by maximizing the volume of the simplex spanned by these prototypes; second, we represent each data point by means of its cosine similarities to the K selected prototypes. This maximum volume hashing is sensible since each dimension in the transformed space is likely to follow a von Mises (vM) distribution, and, in very high dimensions, the vM distribution closely resembles a Gaussian distribution. This justifies to employ PCA on the transformed data. Our extensive experiments validate this: maximum volume hashing outperforms spectral hashing and other state of the art techniques.

#index 1978787
#* Defining and Evaluating Network Communities Based on Ground-Truth
#@ Jaewon Yang;Jure Leskovec
#t 2012
#c 18
#! Nodes in real-world networks organize into densely linked communities where edges appear with high concentration among the members of the community. Identifying such communities of nodes has proven to be a challenging task mainly due to a plethora of definitions of a community, intractability of algorithms, issues with evaluation and the lack of a reliable gold-standard ground-truth. In this paper we study a set of 230 large real-world social, collaboration and information networks where nodes explicitly state their group memberships. For example, in social networks nodes explicitly join various interest based social groups. We use such groups to define a reliable and robust notion of ground-truth communities. We then propose a methodology which allows us to compare and quantitatively evaluate how different structural definitions of network communities correspond to ground-truth communities. We choose 13 commonly used structural definitions of network communities and examine their sensitivity, robustness and performance in identifying the ground-truth. We show that the 13 structural definitions are heavily correlated and naturally group into four classes. We find that two of these definitions, Conductance and Triad-participation-ratio, consistently give the best performance in identifying ground-truth communities. We also investigate a task of detecting communities given a single seed node. We extend the local spectral clustering algorithm into a heuristic parameter-free community detection method that easily scales to networks with more than hundred million nodes. The proposed method achieves 30% relative improvement over current local clustering methods.

#index 1978788
#* Predicting Links in Multi-relational and Heterogeneous Networks
#@ Yang Yang;Nitesh Chawla;Yizhou Sun;Jiawei Hani
#t 2012
#c 18
#! Link prediction is an important task in network analysis, benefiting researchers and organizations in a variety of fields. Many networks in the real world, for example social networks, are heterogeneous, having multiple types of links and complex dependency structures. Link prediction in such networks must model the influence propagating between heterogeneous relationships to achieve better link prediction performance than in homogeneous networks. In this paper, we introduce Multi-Relational Influence Propagation (MRIP), a novel probabilistic method for heterogeneous networks. We demonstrate that MRIP is useful for predicting links in sparse networks, which present a significant challenge due to the severe disproportion of the number of potential links to the number of real formed links. We also explore some factors that can inform the task of classification yet remain unexplored, such as temporal information. In this paper we make use of the temporal-related features by carefully investigating the issues of feasibility and generality. In accordance with our work in unsupervised learning, we further design an appropriate supervised approach in heterogeneous networks. Our experiments on co-authorship prediction demonstrate the effectiveness of our approach.

#index 1978789
#* Scalable Training of Sparse Linear SVMs
#@ Guo-Xun Yuan;Kwan-Liu Ma
#t 2012
#c 18
#! Sparse linear support vector machines have been widely applied to variable selection in many applications. For large data, managing the cost of training a sparse model with good predication performance is an essential topic. In this work, we propose a scalable training algorithm for large-scale data with millions of examples and features. We develop a dual alternating direction method for solving L1-regularized linear SVMs. The learning procedure simply involves quadratic programming in the same form as the standard SVM dual, followed by a soft-thresholding operation. The proposed training algorithm possesses two favorable properties. First, it is a decomposable algorithm by which a large problem can be reduced to small ones. Second, the sparsity of intermediate solutions is maintained throughout the training process. It naturally promotes the solution sparsity by soft-thresholding. We demonstrate that, by experiments, our method outperforms state-of-the-art approaches on large-scale benchmark data sets. We also show that it is well suited for training large sparse models on a distributed system.

#index 1978790
#* Keynotes [3 abstracts]
#@ 
#t 2012
#c 18
#! Provides an abstract for each of the three keynote presentations and a brief professional biography of each presenter.

#index 1978791
#* Topic-Aware Social Influence Propagation Models
#@ Nicola Barbieri;Francesco Bonchi;Giuseppe Manco
#t 2012
#c 18
#! We study social influence from a topic modeling perspective. We introduce novel topic-aware influence-driven propagation models that experimentally result to be more accurate in describing real-world cascades than the standard propagation models studied in the literature. In particular, we first propose simple topic-aware extensions of the well-known Independent Cascade and Linear Threshold models. Next, we propose a different approach explicitly modeling authoritativeness, influence and relevance under a topic-aware perspective. We devise methods to learn the parameters of the models from a dataset of past propagations. Our experimentation confirms the high accuracy of the proposed models and learning schemes.

#index 1978792
#* Scalable Coordinate Descent Approaches to Parallel Matrix Factorization for Recommender Systems
#@ Hsiang-Fu Yu;Cho-Jui Hsieh;Si Si;Inderjit Dhillon
#t 2012
#c 18
#! Matrix factorization, when the matrix has missing values, has become one of the leading techniques for recommender systems. To handle web-scale datasets with millions of users and billions of ratings, scalability becomes an important issue. Alternating Least Squares (ALS) and Stochastic Gradient Descent (SGD) are two popular approaches to compute matrix factorization. There has been a recent flurry of activity to parallelize these algorithms. However, due to the cubic time complexity in the target rank, ALS is not scalable to large-scale datasets. On the other hand, SGD conducts efficient updates but usually suffers from slow convergence that is sensitive to the parameters. Coordinate descent, a classical optimization approach, has been used for many other large-scale problems, but its application to matrix factorization for recommender systems has not been explored thoroughly. In this paper, we show that coordinate descent based methods have a more efficient update rule compared to ALS, and are faster and have more stable convergence than SGD. We study different update sequences and propose the CCD++ algorithm, which updatesrank-one factors one by one. In addition, CCD++ can be easily parallelized on both multi-core and distributed systems. We empirically show that CCD++ is much faster than ALS and SGD in both settings. As an example, on a synthetic dataset with 2 billion ratings, CCD++ is 4 times faster than both SGD and ALS using a distributed system with 20 machines.

#index 1978793
#* Clustering Time Series Using Unsupervised-Shapelets
#@ Jesin Zakaria;Abdullah Mueen;Eamonn Keogh
#t 2012
#c 18
#! Time series clustering has become an increasingly important research topic over the past decade. Most existing methods for time series clustering rely on distances calculated from the entire raw data using the Euclidean distance or Dynamic Time Warping distance as the distance measure. However, the presence of significant noise, dropouts, or extraneous data can greatly limit the accuracy of clustering in this domain. Moreover, for most real world problems, we cannot expect objects from the same class to be equal in length. As a consequence, most work on time series clustering only considers the clustering of individual time series "behaviors," e.g., individual heart beats or individual gait cycles, and contrives the time series in some way to make them all equal in length. However, contriving the data in such a way is often a harder problem than the clustering itself. In this work, we show that by using only some local patterns and deliberately ignoring the rest of the data, we can mitigate the above problems and cluster time series of different lengths, i.e., cluster one heartbeat with multiple heartbeats. To achieve this we exploit and extend a recently introduced concept in time series data mining called shapelets. Unlike existing work, our work demonstrates for the first time the unintuitive fact that shapelets can be learned from unlabeled time series. We show, with extensive empirical evaluation in diverse domains, that our method is more accurate than existing methods. Moreover, in addition to accurate clustering results, we show that our work also has the potential to give insights into the domains to which it is applied.

#index 1978794
#* Self-Training with Selection-by-Rejection
#@ Yan Zhou;Murat Kantarcioglu;Bhavani Thuraisingham
#t 2012
#c 18
#! Practical machine learning and data mining problems often face shortage of labeled training data. Self-training algorithms are among the earliest attempts of using unlabeled data to enhance learning. Traditional self-training algorithms label unlabeled data on which classifiers trained on limited training data have the highest confidence. In this paper, a self-training algorithm that decreases the disagreement region of hypotheses is presented. The algorithm supplements the training set with self-labeled instances. Only instances that greatly reduce the disagreement region of hypotheses are labeled and added to the training set. Empirical results demonstrate that the proposed self-training algorithm can effectively improve classification performance.

#index 1978795
#* Multiple Kernel Learning Clustering with an Application to Malware
#@ Blake Anderson;Curtis Storlie;Terran Lane
#t 2012
#c 18
#! With the increasing prevalence of richer, more complex data sources, learning with multiple views is becoming more widespread. Multiple kernel learning (MKL) has been developed to address this problem, but in general, the solutions provided by traditional MKL are restricted to a classification objective function. In this work, we develop a novel multiple kernel learning algorithm that is based on a spectral clustering objective function which is able to find an optimal kernel weight vector for the clustering problem. We go on to show how this optimization problem can be cast as a semidefinite program and efficiently solved using off-the-shelf interior point methods.

#index 1978796
#* Risks of Friendships on Social Networks
#@ Cuneyt Gurcan Akcora;Barbara Carminati;Elena Ferrari
#t 2012
#c 18
#! In this paper, we explore the risks of friends in social networks caused by their friendship patterns, by using real life social network data and starting from a previously defined risk model. Particularly, we observe that risks of friendships can be mined by analyzing users' attitude towards friends of friends. This allows us to give new insights into friendship and risk dynamics on social networks.

#index 1978797
#* Semantic Aspect Discovery for Online Reviews
#@ Md. Hijbul Alam;SangKeun Lee
#t 2012
#c 18
#! The number of opinions and reviews about different products and services is growing online. Users frequently look for important aspects of a product or service in the reviews. Usually, they are interested in semantic (i.e., sentiment-oriented) aspects. However, extracting semantic aspects with supervised methods is very expensive. We propose a domain independent unsupervised model to extract semantic aspects, and conduct qualitative and quantitative experiments to evaluate the extracted aspects. The experiments show that our model effectively extracts semantic aspects with correlated top words. In addition, the conducted evaluation on aspect sentiment classification shows that our model outperforms other models by 5-7% in terms of macro-average F1.

#index 1978798
#* Differentially Private Histogram Publishing through Lossy Compression
#@ Gergely Acs;Claude Castelluccia;Rui Chen
#t 2012
#c 18
#! Differential privacy has emerged as one of the most promising privacy models for private data release. It can be used to release different types of data, and, in particular, histograms, which provide useful summaries of a dataset. Several differentially private histogram releasing schemes have been proposed recently. However, most of them directly add noise to the histogram counts, resulting in undesirable accuracy. In this paper, we propose two sanitization techniques that exploit the inherent redundancy of real-life datasets in order to boost the accuracy of histograms. They lossily compress the data and sanitize the compressed data. Our first scheme is an optimization of the Fourier Perturbation Algorithm (FPA) presented in \cite{RN10}. It improves the accuracy of the initial FPA by a factor of 10. The other scheme relies on clustering and exploits the redundancy between bins. Our extensive experimental evaluation over various real-life and synthetic datasets demonstrates that our techniques preserve very accurate distributions and considerably improve the accuracy of range queries over attributed histograms.

#index 1978799
#* Spotting Culprits in Epidemics: How Many and Which Ones?
#@ B. Aditya Prakash;Jilles Vreeken;Christos Faloutsos
#t 2012
#c 18
#! Given a snapshot of a large graph, in which an infection has been spreading for some time, can we identify those nodes from which the infection started to spread? In other words, can we reliably tell who the culprits are? In this paper we answer this question affirmatively, and give an efficient method called NETSLEUTH for the well-known Susceptible-Infected virus propagation model. Essentially, we are after that set of seed nodes that best explain the given snapshot. We propose to employ the Minimum Description Length principle to identify the best set of seed nodes and virus propagation ripple, as the one by which we can most succinctly describe the infected graph. We give an highly efficient algorithm to identify likely sets of seed nodes given a snapshot. Then, given these seed nodes, we show we can optimize the virus propagation ripple in a principled way by maximizing likelihood. With all three combined, NETSLEUTH can automatically identify the correct number of seed nodes, as well as which nodes are the culprits. Experimentation on our method shows high accuracy in the detection of seed nodes, in addition to the correct automatic identification of their number. Moreover, we show NETSLEUTH scales linearly in the number of nodes of the graph.

#index 1978800
#* Self-Adjusting Models for Semi-supervised Learning in Partially Observed Settings
#@ Ferit Akova;Murat Dundar;Yuan Qi;Bartek Rajwa
#t 2012
#c 18
#! We present a new direction for semi-supervised learning where self-adjusting generative models replace fixed ones and unlabeled data can potentially improve learning even when labeled data is only partially-observed. We model each class data by a mixture model and use a hierarchical Dirichlet process (HDP) to model observed as well as unobserved classes. We extend the standard HDP model to accommodate unlabeled samples and introduce a new sharing strategy, within the context of Gaussian mixture models, that restricts sharing with covariance matrices while leaving the mean vectors free. Our research is mainly driven by real-world applications with evolving data-generating mechanisms where obtaining a fully-observed labeled data set is impractical. We demonstrate the feasibility of the proposed approach for semi-supervised learning in two such applications.

#index 1978801
#* Stream Classification with Recurring and Novel Class Detection Using Class-Based Ensemble
#@ Tahseen Al-Khateeb;Mohammad M. Masud;Latifur Khan;Charu Aggarwal;Jiawei Han;Bhavani Thuraisingham
#t 2012
#c 18
#! Concept-evolution has recently received a lot of attention in the context of mining data streams. Concept-evolution occurs when a new class evolves in the stream. Although many recent studies address this issue, most of them do not consider the scenario of recurring classes in the stream. A class is called recurring if it appears in the stream, disappears for a while, and then reappears again. Existing data stream classification techniques either misclassify the recurring class instances as another class, or falsely identify the recurring classes as novel. This increases the prediction error of the classifiers, and in some cases causes unnecessary waste in memory and computational resources. In this paper we address the recurring class issue by proposing a novel "class-based" ensemble technique, which substitutes the traditional "chunk-based" ensemble approaches and correctly distinguishes between a recurring class and a novel one. We analytically and experimentally confirm the superiority of our method over state-of-the-art techniques.

#index 1978802
#* Feature Weighting and Selection Using Hypothesis Margin of Boosting
#@ Malak Alshawabkeh;Javed A. Aslam;Jennifer G. Dy;David Kaeli
#t 2012
#c 18
#! Utilizing the concept of hypothesis margins to measure the quality of a set of features has been a growing line of research in the last decade. However, most previous algorithms have been developed under the large hypothesis margin principles of the 1-NN algorithm, such as Simba. Little attention has been paid so far to exploiting the hypothesis margins of boosting to evaluate features. Boosting is well known to maximize the training examples' hypothesis margins, in particular, the average margins which are known to be the first statistics that considers the whole margin distribution. In this paper, we describe how to utilize the training examples' mean margins of boosting to select features. A weight criterion, termed Margin Fraction (MF), is assigned to each feature that contributes to the average margin distribution combined in the final output produced by boosting. Applying the idea of MF to a sequential backward selection method, a new embedded selection algorithm is proposed, called SBS-MF. Experimentation is carried out using different data sets, which compares the proposed SBS-MF with two boosting based feature selection approaches, as well as to Simba. The results show that SBS-MF is effective in most of the cases.

#index 1978803
#* Rough Set Subspace Error-Correcting Output Codes
#@ Mohammad Ali Bagheri;Qigang Gao;Sergio Escalera
#t 2012
#c 18
#! Among the proposed methods to deal with multi-class classification problems, the Error-Correcting Output Codes (ECOC) represents a powerful framework. The key factor in designing any ECOC matrix is the independency of the binary classifiers, without which the ECOC method would be ineffective. This paper proposes an efficient new approach to the ECOC framework in order to improve independency among classifiers. The underlying rationale for our work is that we design three-dimensional codematrix, where the third dimension is the feature space of the problem domain. Using rough set-based feature selection, a new algorithm, named "Rough Set Subspace ECOC (RSS-ECOC)" is proposed. We introduce the Quick Multiple Reduct algorithm in order to generate a set of reducts for a binary problem, where each reduct is used to train a dichotomizer. In addition to creating more independent classifiers, ECOC matrices with longer codes can be built. The numerical experiments in this study compare the classification accuracy of the proposed RSS-ECOC with classical ECOC, one-versus-one, and one-versus-all methods on 24 UCI datasets. The results show that the proposed technique increases the classification accuracy in comparison with the state of the art coding methods.

#index 1978804
#* Co-clustering of Multi-view Datasets: A Parallelizable Approach
#@ Gilles Bisson;Clement Grimal
#t 2012
#c 18
#! In many applications, entities of the domain are described through different views that clustering methods often process one by one. We introduce here the architecture MVSim, that is able to deal simultaneously with all the information contained in such multi-view datasets by using several instances of a co-similarity algorithm. We show that this architecture provides better results than both single-view and multi-view approaches and that it can be easily parallelized thus reducing both time and space complexities of the computations.

#index 1978805
#* Multi-task Learning for Classifying Proteins Using Dual Hierarchies
#@ Anveshi Charuvaka;Huzefa Rangwala
#t 2012
#c 18
#! Several biological databases organize information in taxonomies/hierarchies. These databases differ in terms of curation process, input data, coverage and annotation errors. SCOP and CATH are examples of two databases that classify proteins hierarchically into structurally related groups based on experimentally determined structures. Given the large number of protein sequences with unavailable structure, there is a need to develop prediction methods to classify protein sequences into structural classes. We have developed a novel classification approach that utilizes the underlying relationships across multiple hierarchical source databases within a multi-task learning (MTL) framework. MTL is used to simultaneously learn multiple related tasks, and has been shown to improve generalization performance. Specifically, we have developed and evaluated an MTL approach for predicting the structural class, as defined by two hierarchical databases, CATH and SCOP, using protein sequence information only. We define one task per node of the hierarchies and formulate the MTL problem as a combination of these binary classification tasks. Our experimental evaluation demonstrates that the MTL approach that integrates both the hierarchies outperforms the base-line approach that trains independent models per task, as well as a MTL approach that integrates tasks across a single hierarchical database. We also performed extensive experiments that evaluate different regularization penalties and incorporate different task relationships that achieve superior classification performance.

#index 1978806
#* Privacy-Preserving SimRank over Distributed Information Network
#@ Yu-Wei Chu;Chih-Hua Tai;Ming-Syan Chen;Philip S. Yu
#t 2012
#c 18
#! Information network analysis has drawn a lot attention in recent years. Among all the aspects of network analysis, similarity measure of nodes has been shown useful in many applications, such as clustering, link prediction and community identification, to name a few. As linkage data in a large network is inherently sparse, it is noted that collecting more data can improve the quality of similarity measure. This gives different parties a motivation to cooperate. In this paper, we address the problem of link-based similarity measure of nodes in an information network distributed over different parties. Concerning the data privacy, we propose a privacy-preserving Sim Rank protocol based on fully-homomorphic encryption to provide cryptographic protection for the links.

#index 1978807
#* Adapting Component Analysis
#@ Fatemeh Dorri;Ali Ghodsi
#t 2012
#c 18
#! A main problem in machine learning is to predict the response variables of a test set given the training data and its corresponding response variables. A predictive model can perform satisfactorily only if the training data is an appropriate representative of the test data. This is usually reï¬ected in the assumption that the training data and the test data are drawn from the same underlying probability distribution. However, the assumption may not be correct in many applications for various reasons. We propose a method based on kernel distribution embedding and Hilbert-Schmidt Independence Criterion (HSIC) to address this problem. The proposed method explores a new representation of the data in a new feature space with two properties: (i) the distributions of the training and the test data sets are as close as possible in the new feature space, and (ii) the important structural information of the data is preserved. The algorithm can reduce the dimensionality of the data while it preserves the aforementioned properties and therefore it can be seen as a dimensionality reduction method as well. Our method has a closed-form solution and the experimental results show that it works well in practice.

#index 1978808
#* Simultaneously Combining Multi-view Multi-label Learning with Maximum Margin Classification
#@ Zheng Fang;Zhongfei (Mark) Zhang
#t 2012
#c 18
#! Multiple feature views arise in various important data classification scenarios. However, finding a consensus feature view from multiple feature views for a classifier is still a challenging task. We present a new classification framework using the multi-label correlation information to address the problem of simultaneously combining multiple feature views and maximum margin classification. Under this framework, we propose a novel algorithm that iteratively computes the multiple view feature mapping matrices, the consensus feature view representation, and the coefficients of the classifier. Extensive experimental evaluations demonstrate the effectiveness and promise of this framework as well as the algorithm for discovering a consensus view from multiple feature views.

#index 1978809
#* GPU-Accelerated Feature Selection for Outlier Detection Using the Local Kernel Density Ratio
#@ Fatemeh Azmandian;Ayse Yilmazer;Jennifer G. Dy;Javed A. Aslam;David R. Kaeli
#t 2012
#c 18
#! Effective outlier detection requires the data to be described by a set of features that captures the behavior of normal data while emphasizing those characteristics of outliers which make them different than normal data. In this work, we present a novel non-parametric evaluation criterion for filter-based feature selection which caters to outlier detection problems. The proposed method seeks the subset of features that represents the inherent characteristics of the normal dataset while forcing outliers to stand out, making them more easily distinguished by outlier detection algorithms. Experimental results on real datasets show the advantage of our feature selection algorithm compared to popular and state-of-the-art methods. We also show that the proposed algorithm is able to overcome the small sample space problem and perform well on highly imbalanced datasets. Furthermore, due to the highly parallelizable nature of the feature selection, we implement the algorithm on a graphics processing unit (GPU) to gain significant speedup over the serial version. The benefits of the GPU implementation are two-fold, as its performance scales very well in terms of the number of features, as well as the number of data points.

#index 1978810
#* Sequential Alternating Proximal Method for Scalable Sparse Structural SVMs
#@ P. Balamurugan;Shirish Shevade;T. Ravindra Babu
#t 2012
#c 18
#! Structural Support Vector Machines (SSVMs) have recently gained wide prominence in classifying structured and complex objects like parse-trees, image segments and Part-of-Speech (POS) tags. Typical learning algorithms used in training SSVMs result in model parameters which are vectors residing in a large-dimensional feature space. Such a high-dimensional model parameter vector contains many non-zero components which often lead to slow prediction and storage issues. Hence there is a need for sparse parameter vectors which contain a very small number of non-zero components. L1-regularizer and elastic net regularizer have been traditionally used to get sparse model parameters. Though L1-regularized structural SVMs have been studied in the past, the use of elastic net regularizer for structural SVMs has not been explored yet. In this work, we formulate the elastic net SSVM and propose a sequential alternating proximal algorithm to solve the dual formulation. We compare the proposed method with existing methods for L1-regularized Structural SVMs. Experiments on large-scale benchmark datasets show that the proposed dual elastic net SSVM trained using the sequential alternating proximal algorithm scales well and results in highly sparse model parameters while achieving a comparable generalization performance. Hence the proposed sequential alternating proximal algorithm is a competitive method to achieve sparse model parameters and a comparable generalization performance when elastic net regularized Structural SVMs are used on very large datasets.

#index 1978811
#* Computational Television Advertising
#@ Suhrid Balakrishnan;Sumit Chopra;David Applegate;Simon Urbanek
#t 2012
#c 18
#! Ever wonder why that Kia Ad ran during Iron Chef? Traditional advertising methodology on television is a fascinating mix of marketing, branding, measurement, and predictive modeling. While still a robust business, it is at risk with the recent growth of online and time-shifted (recorded) television. A particular issue is that traditional methods for television advertising are far less efficient than their counterparts in the online world which employ highly sophisticated computational techniques. This paper formalizes an approach to eliminate some of these inefficiencies by recasting the process of television advertising media campaign generation in a computational framework. We describe efficient mathematical approaches to solve for the task of finding optimal campaigns for specific target audiences. In two case studies, our campaigns report gains in key operational metrics of up to 56% compared to campaigns generated by traditional methods.

#index 1978812
#* GUISE: Uniform Sampling of Graphlets for Large Graph Analysis
#@ Mansurul A. Bhuiyan;Mahmudur Rahman;Mahmuda Rahman;Mohammad Al Hasan
#t 2012
#c 18
#! Graphlet frequency distribution (GFD) has recently become popular for characterizing large networks. However, the computation of GFD for a network requires the exact count of embedded graphlets in that network, which is a computationally expensive task. As a result, it is practically infeasible to compute the GFD for even a moderately large network. In this paper, we propose GUISE, which uses a Markov Chain Monte Carlo (MCMC) sampling method for constructing the approximate GFD of a large network. Our experiments on networks with millions of nodes show that GUISE obtains the GFD within few minutes, whereas the exhaustive counting based approach takes several days.

#index 1978813
#* Hierarchical Multilabel Classification with Minimum Bayes Risk
#@ Wei Bi;James T. Kwok
#t 2012
#c 18
#! Hierarchical multilabel classification (HMC) allows an instance to have multiple labels residing in a hierarchy. A popular loss function used in HMC is the H-loss, which penalizes only the first classification mistake along each prediction path. However, the H-loss metric can only be used on tree-structured label hierarchies, but not on DAG hierarchies. Moreover, it may lead to misleading predictions as not all misclassifications in the hierarchy are penalized. In this paper, we overcome these deficiencies by proposing a hierarchy-aware loss function that is more appropriate for HMC. Using Bayesian decision theory, we then develop a Bayes-optimal classifier with respect to this loss function. Instead of requiring an exhaustive summation and search for the optimal multilabel, the proposed classification problem can be efficiently solved using a greedy algorithm on both tree-and DAG-structured label hierarchies. Experimental results on a large number of real-world data sets show that the proposed algorithm outperforms existing HMC methods.

#index 1978814
#* Geodesic Based Semi-supervised Multi-manifold Feature Extraction
#@ Mingyu Fan;Xiaoqin Zhang;Zhouchen Lin;Zhongfei Zhang;Hujun Bao
#t 2012
#c 18
#! Manifold learning is an important feature extraction approach in data mining. This paper presents a new semi-supervised manifold learning algorithm, called Multi-Manifold Discriminative Analysis (Multi-MDA). The proposed method is designed to explore the discriminative information hidden in geodesic distances. The main contributions of the proposed method are: 1) we propose a semi-supervised graph construction method which can effectively capture the multiple manifolds structure of the data, 2) each data point is replaced with an associated feature vector whose elements are the graph distances from it to the other data points. Information of the nonlinear structure is contained in the feature vectors which are helpful for classification, 3) we propose a new semi-supervised linear dimension reduction method for feature vectors which introduces the class information into the manifold learning process and establishes an explicit dimension reduction mapping. Experiments on benchmark data sets are conducted to show the effectiveness of the proposed method.

#index 1978815
#* Self-Taught Active Learning from Crowds
#@ Meng Fang;Xingquan Zhu;Bin Li;Wei Ding;Xindong Wu
#t 2012
#c 18
#! The emergence of social tagging and crowdsourcing systems provides a unique platform where multiple weak labelers can form a crowd to fulfill a labeling task. Yet crowd labelers are often noisy, inaccurate, and have limited labeling knowledge, and worst of all, they act independently without seeking complementary knowledge from each other to improve labeling performance. In this paper, we propose a Self-Taught Active Learning (STAL) paradigm, where imperfect labelers are able to learn complementary knowledge from one another to expand their knowledge sets and benefit the underlying active learner. We employ a probabilistic model to characterize the knowledge of each labeler through which a weak labeler can learn complementary knowledge from a stronger peer. As a result, the self-taught active learning process eventually helps achieve high classification accuracy with minimized labeling costs and labeling errors.

#index 1978816
#* Mining Permission Request Patterns from Android and Facebook Applications
#@ Mario Frank;Ben Dong;Adrienne Porter Felt;Dawn Song
#t 2012
#c 18
#! Android and Face book provide third-party applications with access to users' private data and the ability to perform potentially sensitive operations (e.g., post to a user's wall or place phone calls). As a security measure, these platforms restrict applications' privileges with permission systems: users must approve the permissions requested by applications before the applications can make privacy-or security-relevant API calls. However, recent studies have shown that users often do not understand permission requests and are unsure of which permissions are typical for applications. As a first step towards simplifying permission systems, we cluster a corpus of 188,389 Android applications and 27,029 Face book applications to find patterns in permission requests. Using a method for Boolean matrix factorization to find overlapping clusters of permissions, we find that Face book permission requests follow a clear structure that can be fitted well with only five patterns, whereas Android applications demonstrate more complex permission requests. We also find that low-reputation applications often deviate from the permission request patterns that we identified for high-reputation applications, which suggests that permission request patterns can be indicative of user satisfaction or application quality.

#index 1978817
#* Estimating Local Information Trustworthiness via Multi-source Joint Matrix Factorization
#@ Liang Ge;Jing Gao;Xiao Yu;Wei Fan;Aidong Zhang
#t 2012
#c 18
#! We investigate how to estimate information trustworthiness by considering multiple information sources jointly in a latent matrix space. We particularly focus on user review and recommendation systems, as there are multiple platforms where people can rate items and services that they have purchased, and many potential customers rely on these opinions to make decisions. Information trustworthiness is a serious problem because ratings are generated freely by end-users so that many stammers take advantage of freedom of speech to promote their business or damage reputation of competitors. We propose to simply use customer ratings to estimate each individual source's reliability by exploring correlations among multiple sources. Ratings of items are provided by users of diverse tastes and styles, and thus may appear noisy and conflicting across sources, however, they share some underlying common behavior. Therefore, we can group users based on their opinions, and a source is reliable on an item if its opinions given by latent groups are consistent across platforms. Inspired by this observation, we solve the problem by a two-step model -- a joint matrix factorization procedure followed by reliability score computation. We propose two effective approaches to decompose rating matrices as the products of group membership and group rating matrices, and then compute consistency degrees from group rating matrices as source reliability scores. We conduct experiments on both synthetic data and real user ratings collected from Orbitz, Priceline and Trip Advisor on all the hotels in Las Vegas and New York City. Results show that the proposed method is able to give accurate estimates of source reliability and thus successfully identify inconsistent, conflicting and unreliable information.

#index 1978818
#* Towards Active Learning on Graphs: An Error Bound Minimization Approach
#@ Quanquan Gu;Jiawei Han
#t 2012
#c 18
#! Active learning on graphs has received increasing interest in the past years. In this paper, we propose a \textit{nonadaptive} active learning approach on graphs, based on generalization error bound minimization. In particular, we present a data-dependent error bound for a graph-based learning method, namely learning with local and global consistency (LLGC). We show that the empirical transductive Rademacher complexity of the function class for LLGC provides a natural criterion for active learning. The resulting active learning approach is to select a subset of nodes on a graph such that the empirical transductive Rademacher complexity of LLGC is minimized. We propose a simple yet effective sequential optimization algorithm to solve it. Experiments on benchmark datasets show that the proposed method outperforms the state-of-the-art active learning methods on graphs.

#index 1978819
#* The Mixture of Multi-kernel Relevance Vector Machines Model
#@ Konstantinos Blekas;Aristidis Likas
#t 2012
#c 18
#! We present a new regression mixture model where each mixture component is a multi-kernel version of the Relevance Vector Machine (RVM). In the proposed model, we exploit the enhanced modeling capability of RVMs due to their embedded sparsity enforcing properties. %The main contribution of this %work is the employment of RVM models as components of a mixture %model and their application to the time series clustering problem. Moreover, robustness is achieved with respect to the kernel parameters, by employing a weighted multi-kernel scheme. The mixture model is trained using the maximum a posteriori (MAP) approach, where the Expectation Maximization (EM) algorithm is applied offering closed form update equations for the model parameters. An incremental learning methodology is also presented to tackle the parameter initialization problem of the EM algorithm. The efficiency of the proposed mixture model is empirically demonstrated on the time series clustering problem using various artificial and real benchmark datasets and by performing comparisons with other regression mixture models.

#index 1978820
#* Diffusion of Information in Social Networks: Is It All Local?
#@ Ceren Budak;Divyakant Agrawal;Amr El Abbadi
#t 2012
#c 18
#! Recent studies on the diffusion of information in social networks have largely focused on models based on the influence of local friends. In this paper, we challenge the generalizability of this approach and revive theories introduced by social scientists in the context of diffusion of innovations to model user behavior. To this end, we study various diffusion models in two different online social networks, Digg and Twitter. We first evaluate the applicability of two representative local influence models and show that the behavior of most social networks users are not captured by these local models. Next, driven by theories introduced in the diffusion of innovations research, we introduce a novel diffusion model called Gaussian Logit Curve Model (GLCM) that models user behavior with respect to the behavior of the general population. Our analysis shows that GLCM captures user behavior significantly better than local models, especially in the context of Digg. Aiming to capture both the local and global signals, we introduce various hybrid models and evaluate them through statistical methods. Our methodology models each user separately, automatically determining which users are driven by their local relations and which users are better defined through adopter categories, therefore capturing the complexity of human behavior.

#index 1978821
#* Efficient Pattern-Based Time Series Classification on GPU
#@ Kai-Wei Chang;Biplab Deka;Wen-Mei W. Hwu;Dan Roth
#t 2012
#c 18
#! Time series shapelet discovery algorithm finds subsequences from a set of time series for use as primitives for time series classification. This algorithm has drawn a lot of interest because of the interpretability of its results. However, computation requirements restrict the algorithm from dealing with large data sets and may limit its application in many domains. In this paper, we address this issue by redesigning the algorithm for implementation on highly parallel Graphics Process Units (GPUs). We investigate several concepts of GPU programming and propose a dynamic programming algorithm that is suitable for implementation on GPUs. Results show that the proposed GPU implementation significantly reduces the running time of the shapelet discovery algorithm. For example, on the largest sample dataset from the original authors, the running time is reduced from half a day to two minutes.

#index 1978822
#* Inferring the Root Cause in Road Traffic Anomalies
#@ Sanjay Chawla;Yu Zheng;Jiafeng Hu
#t 2012
#c 18
#! We propose a novel two-step mining and optimization framework for inferring the root cause of anomalies that appear in road traffic data. We model road traffic as a time-dependent flow on a network formed by partitioning a city into regions bounded by major roads. In the first step we identify link anomalies based on their deviation from their historical traffic profile. However, link anomalies on their own shed very little light on what caused them to be anomalous. In the second step we take a generative approach by modeling the flow in a network in terms of the origin-destination (OD) matrix which physically relates the latent flow between origin and destination and the observable flow on the links. The key insight is that instead of using all of link traffic as the observable vector we only use the link anomaly vector. By solving an L1 inverse problem we infer the routes (the origin-destination pairs) which gave rise to the link anomalies. Experiments on a very large GPS data set consisting on nearly eight hundred million data points demonstrate that we can discover routes which can clearly explain the appearance of link anomalies. The use of optimization techniques to explain observable anomalies in a generative fashion is, to the best of our knowledge, entirely novel.

#index 1978823
#* Student-t Based Robust Spatio-temporal Prediction
#@ Yang Chen;Feng Chen;Jing Dai;T. Charles Clancy;Yao-Jan Wu
#t 2012
#c 18
#! This paper describes an efficient and effective design of Robust Spatio-Temporal Prediction based on Student's $t$ distribution, namely, St-RSTP, to provide estimations based on observations over spatio-temporal neighbors. The proposed St-RSTP is more resilient to outliers or other small departures from model assumptions than its ancestor, the Spatio-Temporal Random Effects (STRE) model. STRE is a state-of-the-art statistical model with linear order complexity for large scale processing. However, it assumes Gaussian observations, which has the well-known limitation of non-robustness. In our St-RSTP design, the measurement error follows Student's $t$ distribution, instead of a traditional Gaussian distribution. This design reduces the influence of outliers, improves prediction quality, and keeps the problem analytically intractable. We propose a novel approximate inference approach, which approximates the model into the form that separates the high dimensional latent variables into groups, and then estimates the posterior distributions of different groups of variables separately in the framework of Expectation Propagation. As a good property, our approximate approach decentralizes to the standard STRE based prediction, when the degree of freedom of the Student's $t$ distribution is set to infinite. Extensive experimental evaluations based on both simulation and real-life data sets demonstrated the robustness and the efficiency of our Student-t prediction model. The proposed approach provides critical functionality for stochastic processes on spatio-temporal data.

#index 1978824
#* Transductive Representation Learning for Cross-Lingual Text Classification
#@ Yuhong Guo;Min Xiao
#t 2012
#c 18
#! In cross-lingual text classification problems, it is costly and time-consuming to annotate documents for each individual language. To avoid the expensive re-labeling process, domain adaptation techniques can be applied to adapt a learning system trained in one language domain to another language domain. In this paper we develop a transductive subspace representation learning method to address domain adaptation for cross-lingual text classifications. The proposed approach is formulated as a nonnegative matrix factorization problem and solved using an iterative optimization procedure. Our empirical study on cross-lingual text classification tasks shows the proposed approach consistently outperforms a number of comparison methods.

#index 1978825
#* IceCube: Efficient Targeted Mining in Data Cubes
#@ Shrutendra K. Harsola;Prasad M. Deshpande;Jayant R. Haritsa
#t 2012
#c 18
#! We address the problem of mining targeted association rules over multidimensional market-basket data. Here, each transaction has, in addition to the set of purchased items, ancillary dimension attributes associated with it. Based on these dimensions, transactions can be visualized as distributed over cells of an n-dimensional cube. In this framework, a targeted association rule is of the form {X - Y}R, where R is a convex region in the cube and X - Y is a traditional association rule within region R. We first describe the TOARM algorithm, based on classical techniques, for identifying targeted association rules. Then, we discuss the concepts of bottom-up aggregation and cubing, leading to the Cell Union technique. This approach is further extended, using notions of cube-count interleaving and credit-based pruning, to derive the Ice Cube algorithm. Our experiments demonstrate that Ice Cube consistently provides the best execution time performance, especially for large and complex data cubes.

#index 1978826
#* A New Anomaly Detection Algorithm Based on Quantum Mechanics
#@ Hao Huang;Hong Qin;Shinjae Yoo;Dantong Yu
#t 2012
#c 18
#! The primary originality of this paper lies at the fact that we have made the first attempt to apply quantum mechanics theory to anomaly (outlier) detection in high-dimensional datasets for data mining. We propose Fermi Density Descriptor (FDD) which represents the probability of measuring a fermion at a specific location for anomaly detection. We also quantify and examine different Laplacian normalization effects and choose the best one for anomaly detection. Both theoretical proof and quantitative experiments demonstrate that our proposed FDD is substantially more discriminative and robust than the commonly-used algorithms.

#index 1978827
#* Towards Automatic Image Understanding and Mining via Social Curation
#@ Katsuhiko Ishiguro;Akisato Kimura;Koh Takeuchi
#t 2012
#c 18
#! The amount and variety of multimedia data such as images, movies and music available on over social networks are increasing rapidly. However, the ability to analyze and exploit these unorganized multimedia data remains inadequate, even with state-of-the-art media processing techniques. Our finding in this paper is that the emerging social curation service is a promising information source for the automatic understanding and mining of images distributed and exchanged via social media. One remarkable virtue of social curation service datasets is that they are weakly supervised: the content in the service is manually collected, selected and maintained by users. This is very different from other social information sources, and we can utilize this characteristics for media content mining without expensive media processing techniques. In this paper we present a machine learning system for predicting view counts of images in social curation data as the first step to automatic image content evaluation. Our experiments confirm that the simple features extracted from a social curation corpus are much superior in terms of count prediction than the gold-standard image features of computer vision research.

#index 1978828
#* Learning to Refine an Automatically Extracted Knowledge Base Using Markov Logic
#@ Shangpu Jiang;Daniel Lowd;Dejing Dou
#t 2012
#c 18
#! A number of text mining and information extraction projects such as Text Runner and NELL seek to automatically build knowledge bases from the rapidly growing amount of information on the web. In order to scale to the size of the web, these projects often employ ad hoc heuristics to reason about uncertain and contradictory information rather than reasoning jointly about all candidate facts. In this paper, we present a Markov logic-based system for cleaning an extracted knowledge base. This allows a scalable system such as NELL to take advantage of joint probabilistic inference, or, conversely, allows Markov logic to be applied to a web scale problem. Our system uses only the ontological constraints and confidence values of the original system, along with human-labeled data if available. The labeled data can be used to calibrate the confidence scores from the original system or learn the effectiveness of individual extraction patterns. To achieve scalability, we introduce a neighborhood grounding method that only instantiates the part of the network most relevant to the given query. This allows us to partition the knowledge cleaning task into tractable pieces that can be solved individually. In experiments on NELL's knowledge base, we evaluate several variants of our approach and find that they improve both F1 and area under the precision-recall curve.

#index 1978829
#* IRIE: Scalable and Robust Influence Maximization in Social Networks
#@ Kyomin Jung;Wooram Heo;Wei Chen
#t 2012
#c 18
#! Influence maximization is the problem of selecting top $k$ seed nodes in a social network to maximize their influence coverage under certain influence diffusion models. In this paper, we propose a novel algorithm IRIE that integrates the advantages of influence ranking (IR) and influence estimation (IE) methods for influence maximization in both the independent cascade (IC) model and its extension IC-N that incorporates negative opinion propagations. Through extensive experiments, we demonstrate that IRIE matches the influence coverage of other algorithms while scales much better than all other algorithms. Moreover IRIE is much more robust and stable than other algorithms both in running time and memory usage for various density of networks and cascade size. It runs up to two orders of magnitude faster than other state-of-the-art algorithms such as PMIA for large networks with tens of millions of nodes and edges, while using only a fraction of memory.

#index 1978830
#* Efficient Kernel Clustering Using Random Fourier Features
#@ Radha Chitta;Rong Jin;Anil K. Jain
#t 2012
#c 18
#! Kernel clustering algorithms have the ability to capture the non-linear structure inherent in many real world data sets and thereby, achieve better clustering performance than Euclidean distance based clustering algorithms. However, their quadratic computational complexity renders them non-scalable to large data sets. In this paper, we employ random Fourier maps, originally proposed for large scale classification, to accelerate kernel clustering. The key idea behind the use of random Fourier maps for clustering is to project the data into a low-dimensional space where the inner product of the transformed data points approximates the kernel similarity between them. An efficient linear clustering algorithm can then be applied to the points in the transformed space. We also propose an improved scheme which uses the top singular vectors of the transformed data matrix to perform clustering, and yields a better approximation of kernel clustering under appropriate conditions. Our empirical studies demonstrate that the proposed schemes can be efficiently applied to large data sets containing millions of data points, while achieving accuracy similar to that achieved by state-of-the-art kernel clustering algorithms.

#index 1978831
#* Detecting Anomalies in Bipartite Graphs with Mutual Dependency Principles
#@ Hanbo Dai;Feida Zhu;Ee-Peng Lim;HweeHwa Pang
#t 2012
#c 18
#! Bipartite graphs can model many real life applications including users-rating-products in online marketplaces, users-clicking-webpages on the World Wide Web and users referring- users in social networks. In these graphs, the anomalousness of nodes in one partite often depends on that of their connected nodes in the other partite. Previous studies have shown that this dependency can be positive (the anomalousness of a node in one partite increases or decreases along with that of its connected nodes in the other partite) or negative (the anomalousness of a node in one partite rises or falls in opposite direction to that of its connected nodes in the other partite). In this paper, we unify both positive and negative mutual dependency relationships in an unsupervised framework for detecting anomalous nodes in bipartite graphs. This is the first work that integrates both mutual dependency principles to model the complete set of anomalous behaviors of nodes that cannot be identified by either principle alone. We formulate our principles and design an iterative algorithm to simultaneously compute the anomaly scores of nodes in both partites. Moreover, we mathematically prove that the ranking of nodes by anomaly scores in each partite converges. Our framework is examined on synthetic graphs and the results show that our model outperforms existing models with only positive or negative mutual dependency principles. We also apply our framework to two real life datasets: Goodreads as a users-rating-books setting and Buzzcity as a users-clicking advertisements setting. The results show that our method is able to detect suspected spamming users and spammed books in Goodreads and achieve higher precision in identifying fraudulent advertisement publishers than existing approaches.

#index 1978832
#* Link Prediction and Recommendation across Heterogeneous Social Networks
#@ Yuxiao Dong;Jie Tang;Sen Wu;Jilei Tian;Nitesh V. Chawla;Jinghai Rao;Huanhuan Cao
#t 2012
#c 18
#! Link prediction and recommendation is a fundamental problem in social network analysis. The key challenge of link prediction comes from the sparsity of networks due to the strong disproportion of links that they have potential to form to links that do form. Most previous work tries to solve the problem in single network, few research focus on capturing the general principles of link formation across heterogeneous networks. In this work, we give a formal definition of link recommendation across heterogeneous networks. Then we propose a ranking factor graph model (RFG) for predicting links in social networks, which effectively improves the predictive performance. Motivated by the intuition that people make friends in different networks with similar principles, we find several social patterns that are general across heterogeneous networks. With the general social patterns, we develop a transfer-based RFG model that combines them with network structure information. This model provides us insight into fundamental principles that drive the link formation and network evolution. Finally, we verify the predictive performance of the presented transfer model on 12 pairs of transfer cases. Our experimental results demonstrate that the transfer of general social patterns indeed help the prediction of links.

#index 1978833
#* Multi-task Semi-supervised Semantic Feature Learning for Classification
#@ Changying Du;Fuzhen Zhuang;Qing He;Zhongzhi Shi
#t 2012
#c 18
#! Multi-task learning has proven to be useful to boost the learning of multiple related but different tasks. Meanwhile, latent semantic models such as LSA and LDA are popular and effective methods to extract discriminative semantic features of high dimensional dyadic data. In this paper, we present a method to combine these two techniques together by introducing a new matrix tri-factorization based formulation for semi-supervised latent semantic learning, which can incorporate labeled information into traditional unsupervised learning of latent semantics. Our inspiration for multi-task semantic feature learning comes from two facts, i.e., 1) multiple tasks generally share a set of common latent semantics, and 2) a semantic usually has a stable indication of categories no matter which task it is from. Thus to make multiple tasks learn from each other we wish to share the associations between categories and those common semantics among tasks. Along this line, we propose a novel joint Nonnegative matrix tri-factorization framework with the aforesaid associations shared among tasks in the form of a semantic-category relation matrix. Our new formulation for multi-task learning can simultaneously learn (1) discriminative semantic features of each task, (2) predictive structure and categories of unlabeled data in each task, (3) common semantics shared among tasks and specific semantics exclusive to each task. We give alternating iterative algorithm to optimize our objective and theoretically show its convergence. Finally extensive experiments on text data along with the comparison with various baselines and three state-of-the-art multi-task learning algorithms demonstrate the effectiveness of our method.

#index 1978834
#* Decision Theory for Discrimination-Aware Classification
#@ Faisal Kamiran;Asim Karim;Xiangliang Zhang
#t 2012
#c 18
#! Social discrimination (e.g., against females) arising from data mining techniques is a growing concern worldwide. In recent years, several methods have been proposed for making classifiers learned over discriminatory data discrimination-aware. However, these methods suffer from two major shortcomings: (1) They require either modifying the discriminatory data or tweaking a specific classification algorithm and (2) They are not flexible w.r.t. discrimination control and multiple sensitive attribute handling. In this paper, we present two solutions for discrimination-aware classification that neither require data modification nor classifier tweaking. Our first and second solutions exploit, respectively, the reject option of probabilistic classifier(s) and the disagreement region of general classifier ensembles to reduce discrimination. We relate both solutions with decision theory for better understanding of the process. Our experiments using real-world datasets demonstrate that our solutions outperform existing state-of-the-art methods, especially at low discrimination which is a significant advantage. The superior performance coupled with flexible control over discrimination and easy applicability to multiple sensitive attributes makes our solutions an important step forward in practical discrimination-aware classification.

#index 1978835
#* Deep Learning to Hash with Multiple Representations
#@ Yoonseop Kang;Saehoon Kim;Seungjin Choi
#t 2012
#c 18
#! Hashing seeks an embedding of high-dimensional objects into a similarity-preserving low-dimensional Hamming space such that similar objects are indexed by binary codes with small Hamming distances. A variety of hashing methods have been developed, but most of them resort to a single view (representation) of data. However, objects are often described by multiple representations. For instance, images are described by a few different visual descriptors (such as SIFT, GIST, and HOG), so it is desirable to incorporate multiple representations into hashing, leading to multi-view hashing. In this paper we present a deep network for multi-view hashing, referred to as deep multi-view hashing, where each layer of hidden nodes is composed of view-specific and shared hidden nodes, in order to learn individual and shared hidden spaces from multiple views of data. Numerical experiments on image datasets demonstrate the useful behavior of our deep multi-view hashing (DMVH), compared to recently-proposed multi-modal deep network as well as existing shallow models of hashing.

#index 1978836
#* Low Dimensional Localized Clustering (LDLC)
#@ Pooyan Khajehpour Tadavani;Ali Ghodsi
#t 2012
#c 18
#! In the space of high-dimensional data, it is generally reasonable to assume that the data points are on (or close to) one or more submanifolds. Each of these submanifolds can be modeled by a number of linear subspaces. This is in fact the main intuition behind a majority of subspace clustering algorithms. In many cases, however, the subspaces computed by these algorithms consist of disconnected subsets of the underlying submanifolds and therefore, do not form localized and compact clusters. To address this problem, we propose "Low Dimensional Localized Clustering (LDLC)", a new method for subspace clustering. Unlike existing methods, LDLC respects the topology of the underling submanifolds and assigns the data points to localized clusters such that the total reconstruction error is minimized. This is a valuable property in many tasks, such as semi-supervised classification, data visualization and local dimensionality reduction. We establish connections between LDLC, K-Means, and VQPCA from different perspectives, and validate our method through various experiments on synthetic and real data sets.

#index 1978837
#* A Semi-definite Positive Linear Discriminant Analysis and Its Applications
#@ Deguang Kong;Chris Ding
#t 2012
#c 18
#! Linear Discriminant Analysis (LDA) is widely used for dimension reduction in classification tasks. However, standard LDA formulation is not semi definite positive (s.d.p), and thus it is difficult to obtain the global optimal solution when standard LDA formulation is combined with other loss functions or graph embedding. In this paper, we present an alternative approach to LDA. We rewrite the LDA criterion as a convex formulation (semi-definite positive LDA, i.e., sdpLDA) using the largest eigen-value of the generalized eigen-value problem of standard LDA. We give applications by incorporating sdpLDA as a regularization term into discriminant regression analysis. Another application is to incorporate sdpLDA into standard Laplacian embedding, which utilizes the supervised information to improve the Laplacian embedding performance. Proposed sdpLDA formulation can be used for both multi-class classification tasks. Extensive experiments results on 10 multi-class datasets indicate promising results of proposed method.

#index 1978838
#* Predicting Directed Links Using Nondiagonal Matrix Decompositions
#@ Jerome Kunegis;Jorg Fliege
#t 2012
#c 18
#! We present a method for trust prediction based on no diagonal decompositions of the asymmetric adjacency matrix of a directed network. The method we propose is based on a no diagonal decomposition into directed components (DEDICOM), which we use to learn the coefficients of a matrix polynomial of the network's adjacency matrix. We show that our method can be used to compute better low-rank approximations to a polynomial of a network's adjacency matrix than using the singular value decomposition, and that a higher precision can be achieved at the task of predicting directed links than by undirected or bipartite methods.

#index 1978839
#* Fast Kernel Sparse Representation Approaches for Classification
#@ Yifeng Li;Alioune Ngom
#t 2012
#c 18
#! Sparse representation involves two relevant procedures - sparse coding and dictionary learning. Learning a dictionary from data provides a concise knowledge representation. Learning a dictionary in a higher feature space might allow a better representation of a signal. However, it is usually computationally expensive to learn a dictionary if the numbers of training data and(or) dimensions are very large using existing algorithms. In this paper, we propose a kernel dictionary learning framework for three models. We reveal that the optimization has dimension-free and parallel properties. We devise fast active-set algorithms for this framework. We investigated their performance on classification. Experimental results show that our kernel sparse representation approaches can obtain better accuracy than their linear counterparts. Furthermore, our active-set algorithms are faster than the existing interior-point and proximal algorithms.

#index 2025138
#* Proceedings of the 13th international conference on Advances in Data Mining: applications and theoretical aspects
#@ Petra Perner
#t 2013
#c 18

#index 2025139
#* Mining and information integration practice for chinese bibliographic database of life sciences
#@ Heng Chen;Yi Jin;Yan Zhao;Yongjuan Zhang;Chengcai Chen;Jilin Sun;Shen Zhang
#t 2013
#c 18
#! With fast development of life science research, countless achievements have been generated and scattered in various literatures. Information providers are facing the challenge of satisfying users' needs for more efficient and intelligent retrieval. Information integration and mining are promising ways that become more and more important. This paper describes how protein related information is mined from the Chinese Biological Abstract (CBA) database, and integrated with corresponding information in the Universal Protein Resource (Uniprot database). With the collaboration of European Bioinformatics Institute (EBI), integration with corresponding protein information in the Uniprot database is achieved. This paper describes the integration and mapping between Chinese bibliographic databases and authoritative factual databases through relevant text mining works. It would be helpful for extension, utilization and mining of Chinese bibliographic resources, as well as cross lingual information retrieval, integration, and mining.

#index 2025140
#* An automated search space reduction methodology for large databases
#@ Angel Kuri-Morales
#t 2013
#c 18
#% 248790
#% 273889
#% 296738
#% 300132
#% 321607
#% 322417
#% 420136
#% 420138
#% 481281
#% 729985
#% 741027
#% 809251
#% 875014
#% 900335
#% 1166355
#! Given the present need for Customer Relationship and the increased growth of the size of databases, many new approaches to large database clustering and processing have been attempted. In this work we propose a methodology based on the idea that statistically proven search space reduction is possible in practice. Following a previous methodology two clustering models are generated: one corresponding to the full data set and another pertaining to the sampled data set. The resulting empirical distributions were mathematically tested by applying an algorithmic verification.

#index 2025141
#* Towards a high productivity automatic analysis framework for classification: an initial study
#@ Thomas Ludescher;Thomas Feilhauer;Anton Amann;Peter Brezany
#t 2013
#c 18
#% 802930
#% 1290045
#% 1899470
#! Due to the recent explosion of research data based on novel scientific instruments and corresponding experiments, automatic features, in particular in data analysis, has become more essential than ever. In this paper we present a new Automatic Analysis Framework (AAF) that is able to increase the productivity of data analysis. The AAF can be used for classifications, predictions and clustering. It is built upon the workflow engine Taverna, which is widely used in different domains and there exists a large number of Taverna activities for various kinds of analytical methods. The AAF enables scientists to modify our predefined Taverna workflow and to extend it with other available activities. For the execution of the analytical methods, in particular for the computation of the results, we use our own cloud-based Code Execution Framework (CEF). It provides web services to execute problem solving environment code, such as MATLAB, Octave, and R scripts, in parallel in the cloud. This combination of the AAF and CEF enables scientists to easily conduct time-consuming calculations without the need to manually combine potential combinations of independent variables. It furthermore automatically evaluates all identified models and provides service for the scientists conducting the analysis. The framework has been tested and evaluated with real breath gas data.

#index 2025142
#* Extending statistical models for batch-end quality prediction to batch control
#@ Geert Gins;Jef Vanlaer;Pieter Van den Kerkhof;Jan F. M. Van Impe
#t 2013
#c 18
#% 1617048
#! The control and optimization of batch processes is a challenging problem faced by (bio)chemical industry. Traditionally, (full) factorial tests are executed to investigate the effect of the manipulated variables (MV) on the (quality of the) process. Due to their nature, these tests are very time-consuming for batch processes. This paper investigates whether suitable data-driven models for batch optimization and control can be identified from a more limited set of tests. Based on the results of two case studies, it is concluded that statistical inference models can predict the final quality of batches where the MV changes occur at time points not present in the training data, provided they fall inside of the time range used for training. Furthermore, the models provide accurate predictions for batches with multiple MV changes. This is a valuable result for industrial acceptance because it implies that fewer experiments are required for model identification.

#index 2025143
#* Pattern-based solution risk model for strategic IT outsourcing
#@ Robert Gwadera
#t 2013
#c 18
#% 413624
#% 443310
#% 452846
#% 481290
#% 767654
#% 794935
#% 1108862
#% 1127267
#% 1737787
#! We present a pattern-based solution risk model for assessing risk of incurring a cost-overrun in Strategic IT Outsourcing (SO) by the SO provider based on historical deals and their corresponding cost overruns. The approach is based on finding co-occurring patterns of solution elements and cost-overrun elements, i.e., elements that had to be implemented as not foreseen in the project planning phase. In order to find such co-occurring patterns we apply closed itemset-mining augmented with item cost information and build corresponding association rules with risk information. Such rules can be used by project managers of SO contracts to minimize the gap between the proposed and implemented solutions. In experiments, conducted on a sample of deals of a multi-national SO provider, we show the applicability of the framework for predicting significant cost-overruns. The introduced model is a general solution risk model for service delivery, whose task is to minimize the gap between proposed and implemented service elements by the provider based on historical deals.

#index 2025144
#* Mining semantic relationships between concepts across documents incorporating wikipedia knowledge
#@ Peng Yan;Wei Jin
#t 2013
#c 18
#% 727861
#% 752367
#% 838471
#% 855147
#% 956570
#% 972299
#% 1117013
#% 1250362
#% 1275012
#% 1922696
#! The ongoing astounding growth of text data has created an enormous need for fast and efficient text mining algorithms. Traditional approaches for document representation are mostly based on the Bag of Words (BOW) model which takes a document as an unordered collection of words. However, when applied in fine-grained information discovery tasks, such as mining semantic relationships between concepts, sorely relying on the BOW representation may not be sufficient to identify all potential relationships since the resulting associations based on the BOW approach are limited to the concepts that appear in the document collection literally. In this paper, we attempt to complement existing information in the corpus by proposing a new hybrid approach, which mines semantic associations between concepts across multiple text units through incorporating extensive knowledge from Wikipedia. The experimental evaluation demonstrates that search performance has been significantly enhanced in terms of accuracy and coverage compared with a purely BOW-based approach and alternative solutions where only the article contents of Wikipedia or category information are considered.

#index 2025145
#* Estimating risk management in software engineering projects
#@ Jaime Santos;Orlando Belo
#t 2013
#c 18
#% 380342
#% 758066
#! Independently from the nature of a project, process management variables like cost, quality, schedule, and scope are critical decision factors for a good and successful execution of a project. In software engineering, project planning and execution are highly influenced by the creative nature of all the individuals involved with the project. Thus, managing the risks of different project stages is a key task with extreme importance for project managers (and sponsors) that should be focused on control and monitoring effectively the referred variables, as well as all the others concerned with their context. In this work, we used a small "cocktail" of data mining techniques and methods to explore potential correlations and influences contained in some of the most relevant parameters related to experience, complexity, organization maturity and project innovation in Software Engineering, developing in a model that could be deployed in any project management process, assisting project managers in planning and monitoring the state of one project (or program) under its supervision.

#index 2025146
#* Wastewater treatment plant performance prediction with support vector machines
#@ Daniel Ribeiro;António Sanfins;Orlando Belo
#t 2013
#c 18
#% 116149
#% 190581
#% 197394
#% 243728
#% 269634
#% 420077
#% 722929
#% 768632
#% 833915
#% 872759
#% 883341
#% 1210458
#% 1290045
#% 1317536
#% 1363131
#% 1558464
#% 1567948
#% 1734419
#% 1860542
#% 1860710
#% 1879630
#! Wastewater treatment plants are essential infrastructures to maintain the environmental balance of the regions where they were installed. The dynamic and complex wastewater treatment procedure must be handled efficiently to ensure good quality effluents. This paper presents a research and development work implemented to predict the performance of a wastewater treatment plant located in the northern Portugal, serving a population of about 45,000 inhabitants. The data we used were recorded based on the daily averaged values of the measured parameters during the period of one year. The predictive models were developed supported by two implementations of Support Vector Machines methods for regression, due to the presence of two lines of treatment in the selected case of study, using two of the most relevant output parameters of a wastewater treatment plant: the biochemical oxygen demand and the total suspended solids. We describe here the wastewater treatment plant we studied as well the data sets used in the mining processes, analyzing and comparing the regression models for both predictive parameters that were selected.

#index 2025147
#* Mining floating train data sequences for temporal association rules within a predictive maintenance framework
#@ Wissam Sammouri;Etienne Côme;Latifa Oukhellou;Patrice Aknin
#t 2013
#c 18
#% 152934
#% 248785
#% 329537
#% 420063
#% 481290
#% 632028
#% 1332596
#% 1651689
#% 1737786
#! In order to meet the mounting social and economic demands, railway operators and manufacturers are striving for a longer availability and a better reliability of railway transportation systems. Commercial trains are being equipped with state-of-the-art onboard intelligent sensors monitoring various subsystems all over the train. These sensors provide real-time spatio-temporal data consisting of georeferenced timestamped events that tend sometimes to occur in bursts. Once ordered with respect to time, these events can be considered as long temporal sequences that can be mined for possible relationships leading to association rules. In this paper, we propose a methodology for discovering association rules in very bursty and challenging floating train data sequences with multiple constraints. This methodology is based on using null models to discover significant co-occurrences between pairs of events. Once identified and scrutinized by various metrics, these co-occurrences are then used to derive temporal association rules that can predict the imminent arrival of severe failures. Experiments performed on Alstom's TrainTracerTM data show encouraging results.

#index 2025148
#* Online shopping customer data analysis by using association rules and cluster analysis
#@ Serhat Güden;Umman Tugba Gursoy
#t 2013
#c 18
#% 818916
#% 1786795
#! Data Mining is the process of exploration and analysis of large quantities of data in order to discover meaningful patterns and rules. Data mining is considered as the only solution towards efficient use of increasing amounts of data worldwide. The process of converting data into information is achieved by means of data mining. In this study, first the concept of data mining is presented, then CRISP-DM process are described. In this paper Cluster Analysis and Association Rules are used to analyze the data. k-means Algorithm, Confidence and Support Ratios are theoretically explained and these techniques applied to a data set obtained from 314 customers from 7 regions of Turkey to identify their profile.

#index 2025149
#* A study on multi-label classification
#@ Clifford A. Tawiah;Victor S. Sheng
#t 2013
#c 18
#% 311034
#% 913246
#% 950571
#% 1451240
#% 1583287
#% 1606401
#% 1647889
#! Multi-label classifications exist in many real world applications. This paper empirically studies the performance of a variety of multi-label classification algorithms. Some of them are developed based on problem transformation. Some of them are developed based on adaption. Our experimental results show that the adaptive Multi-Label K-Nearest Neighbor performs the best, followed by Random k-Label Set, followed by Classifier Chain and Binary Relevance. Adaboost.MH performs the worst, followed by Pruned Problem Transformation. Our experimental results also provide us the confidence of existing correlations among multi-labels. These insights shed light for future research directions on multi-label classifications.

#index 2025150
#* Robust feature selection for SVMs under uncertain data
#@ Hoai An Le Thi;Xuan Thanh Vo;Tao Pham Dinh
#t 2013
#c 18
#% 416553
#% 422103
#% 572922
#% 576520
#% 770766
#% 846429
#% 875970
#% 945232
#% 961180
#% 961195
#% 1612333
#! In this paper, we consider the problem of feature selection and classification under uncertain data that is inherently prevalent in almost all datasets. Using principles of Robust Optimization, we propose a robust scheme to handle data with ellipsoidal model uncertainty. The difficulty in treating zero-norm ℓ0 in feature selection problem is overcome by using an appropriate approximation and DC (Difference of Convex functions) programming and DCA (DC Algorithm). The computational results show that the proposed robust optimization approach is more performant than a traditional approach in immunizing perturbation of the data.

#index 2025151
#* A hybrid machine learning method and its application in municipal waste prediction
#@ Emadoddin Livani;Raymond Nguyen;Jörg Denzinger;Günther Ruhe;Scott Banack
#t 2013
#c 18
#% 261691
#% 296738
#% 818916
#% 912044
#% 926881
#% 1191934
#% 1251085
#% 1345387
#% 1456619
#! Prediction methods combining clustering and classification techniques have the potential of creating more accurate results than the individual techniques, particularly for large datasets. In this paper, a hybrid prediction method is proposed from combining weighted k-means clustering and linear regression. Weighted k-means is used to cluster the dataset. Then, linear regression is performed on each cluster to build the final predictors. The proposed method has been applied to the problem of municipal waste prediction and evaluated with a dataset including 63,000 records. The results showed that it outperforms the single application of linear regression and k-means clustering in terms of prediction accuracy and robustness. The prediction model is integrated into a decision support system for strategic and operational planning of waste and recycling services at the City of Calgary in Canada. The potential usage of the prediction model is to improve the resource utilization, like personnel and vehicles.

#index 2025152
#* BiETopti-BiClustering ensemble using optimization techniques
#@ Geeta Aggarwal;Neelima Gupta
#t 2013
#c 18
#% 33816
#% 274612
#% 469422
#% 551737
#% 722902
#% 726725
#% 727903
#% 744117
#% 774878
#% 906512
#% 1318596
#% 1377384
#% 1411489
#% 1565889
#! In this paper, we present an ensemble method for the biclustering problem that uses optimization techniques to generate consensus. Experiments have shown that the proposed method provides superior bi-clusters than the existing bi-clustering solutions most of the times. Bi-clustering problem has many applications including analysis of gene expression data.

#index 2025153
#* Multiple buying behavior as an indicator of brand loyalty: an association rule application
#@ Diren Bulut;Umman Tuğba Gursoy;Kemal Kurtulus
#t 2013
#c 18
#% 332064
#% 576207
#% 731603
#% 1089009
#% 1786790
#! Brands are working hard to build a brand equity which hope to lead the companies to have more loyal customers. Loyal customers are more cost efficient and have the intention to make multiple buying. The aim of this paper to track multiple buying behavior among customers with high brand loyalty. In order to see the relations between products chosen and preferences, data mining technique was used. Associations between products and future buying intentions were examined. High degrees of associations between products are presented. The future intentions were parallel to loyalty and satisfaction levels.

#index 2025154
#* Matching semi-structured documents using similarity of regions through fuzzy rule-based system
#@ Alireza Ensan;Yevgen Biletskiy
#t 2013
#c 18
#% 223517
#% 321635
#% 344447
#% 465914
#% 1155702
#% 1166217
#% 1177819
#! The present work briefly describes a novel approach for categorizing semi-structure documents by using fuzzy rule-based system. We propose fuzzy logic representation for semi-structured documents and then by proposing new metric, categorize documents into different classes. The idea behind of our approach is to divide web pages into different semantic sections and by using fuzzy logic system extract features and weight harvested terms to represent semi-structure documents. A set of metrics are also used to measure similarity between documents based on the weight of each region in the text. A clustering algorithm is also explained that categorized documents into several categories. This idea is inspired as a subfield of the area of Matchmaking that tries to match document creators and users in order to find the best similarities between them and connect them for further collaborations.

#index 2025155
#* Data mining application for cyber credit-card fraud detection system
#@ John Akhilomen
#t 2013
#c 18
#! Since the evolution of the internet, many small and large companies have moved their businesses to the internet to provide services to customers worldwide. Cyber credit card fraud or no card present fraud is increasingly rampant in the recent years for the reason that the credit card is majorly used to request payments by these companies on the internet. Therefore the need to ensure secured transactions for credit-card owners when consuming their credit cards to make electronic payments for goods and services provided on the internet is a criterion. Data mining has popularly gained recognition in combating cyber credit-card fraud because of its effective artificial intelligence (AI) techniques and algorithms that can be implemented to detect or predict fraud through Knowledge Discovery from unusual patterns derived from gathered data. In this study, a system's model for cyber credit card fraud detection is discussed and designed. This system implements the supervised anomaly detection algorithm of Data mining to detect fraud in a real time transaction on the internet, and thereby classifying the transaction as legitimate, suspicious fraud and illegitimate transaction. The anomaly detection algorithm is designed on the Neural Networks which implements the working principal of the human brain (as we humans learns from past experience and then make our present day decisions on what we have learned from our past experience). To understand how cyber credit card fraud are being committed, in this study the different types of cyber fraudsters that commit cyber credit card fraud and the techniques used by these cyber fraudsters to commit fraud on the internet is discussed.

#index 2025156
#* Feature representation for customer attrition risk prediction in retail banking
#@ Yanbo J. Wang;Gang Di;Junxuan Yu;Juan Lei;Frans Coenen
#t 2013
#c 18
#% 116149
#% 136350
#% 290482
#% 341700
#% 449588
#% 926881
#% 1567948
#% 1892067
#% 1988511
#! Nowadays, customer attrition is increasingly serious in commercial banks, particularly with respect tomiddle- and high-valued customers in retail banking. To combat this attrition it is incumbent for banks to develop a prediction mechanism so as to identify customers who might be at risk of attrition. This prediction mechanism can be considered to be a classifier. In particular, the problem of predicting risk of customer attrition can be prototyped as a binary classification task in data mining. In this paper we identify a set of features, for customer "attrition vs. non-attrition" classification, based on the RFM (Recency, Frequency and Monetary) model. The reported evaluation indicates that proposed set of features produces a much more effective classifier than that generated using previously suggested features.

#index 2025157
#* An evolutionary method for associative local distribution rule mining
#@ Kaoru Shimada;Takashi Hanioka
#t 2013
#c 18
#% 466483
#% 735356
#% 927257
#% 1447344
#% 1776894
#% 1826275
#% 1892066
#! A method for rule mining for continuous value prediction has been proposed using a graph structure based evolutionary computation technique. The method extracts the rules named associative local distribution rule whose consequent part has a narrow distribution of continuous value. A set of associative local distribution rules is applied to the continuous value prediction. The experimental results showed that the method can bring us useful rules for the continuous value prediction. In addition, two cases of contrast rules are defined based on the associative local distribution rules. The performances of the contrast rule extraction were evaluated and the results showed that the proposed method has a potential to realize contrast analysis between two datasets.

#index 2025158
#* Application of data mining techniques on EMG registers of hemiplegic patients
#@ Ana Aguilera;Alberto Subero;Ramón Mata-Toledo
#t 2013
#c 18
#% 136350
#% 169665
#% 400847
#% 458696
#% 755460
#% 1144395
#% 1148663
#% 1273830
#% 1292328
#% 1693324
#! Gait analysis provides a very large data volume coming from kinematic, kinetic, electromyographic (EMG) registers and physical examinations. The analysis and treatment of these data is difficult and time consuming. This work applies and explores exhaustively different analysis methods from data mining on these gait data. This study aims to provide a classification system based in gait patterns obtained from EMG records in children with spastic hemiplegia. The methods studied from data mining specifically for the classification task include SVM, neural networks, decision trees, regression logistic models and others. Different techniques of feature extraction and selection have been also employed and combined with classifications methods. The LMT algorithm provides the best result with 97% of instances classified correctly taking into account the indicators for 2 legs. A qualitative and quantitative validation were performed on the data.

#index 2025159
#* Configurations and couplings: an exploratory study
#@ Warwick Graco;Hari Koesmarno
#t 2013
#c 18
#% 391311
#% 818916
#% 1165480
#% 1414233
#% 1890201
#% 2010361
#! This is an exploratory study to see if configurations that were coupled to an output variable could be found in data. The focus in this study was on the modal configurations, which are profiles of best fit for clusters, and their average cluster scores for an output variable. A multistage procedure explained in the paper below was applied to a crime dataset to identify the modal configurations for a sample of cities and towns of the USA and their links to the incidence of violent crime. Three coupled configurations were found including one that was indicative of an African American Configuration having the highest rate of violent crime followed by one indicative of a High Divorce Configuration and one indicative of an Economic Hardship Configuration. The results indicated that using this multistage procedure is feasible for finding modal configurations and their couplings in data. The advantages of this approach are discussed and future directions with the research are outlined.

