#index 210404
#* Proceedings of the workshop on Intelligent agents II : agent theories, architectures, and languages: agent theories, architectures, and languages
#@ Michael Wooldridge;Jörg P. Müller;Milind Tambe
#t 1996
#c 11

#index 454995
#* Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence
#@ Thomas Dean
#t 1999
#c 11

#index 455003
#* Selected and Invited Papers from the Workshop on Fuzzy Logic in Artificial Intelligence
#@ Anca L. Ralescu;James G. Shanahan
#t 1997
#c 11

#index 495556
#* PEBM: A Probabilistic Exemplar Based Model
#@ Andres F. Rodriguez;Sunil Vadera
#t 1999
#c 11

#index 495624
#* A Case Based Approach to the Generation of Musical Expression
#@ Taizan Suzuki;Takenobu Tokunaga;Hozumi Tanaka
#t 1999
#c 11

#index 495625
#* UPML: A Framework for Knowledge System Reuse
#@ Dieter Fensel;V. Richard Benjamins;Enrico Motta;Bob J. Wielinga
#t 1999
#c 11

#index 495627
#* Branch and Bound with Mini-Bucket Heuristics
#@ Kalev Kask;Rina Dechter
#t 1999
#c 11

#index 495628
#* Using Focus Rules in Requirements Elicitation Dialogues
#@ Renaud Lecoeuche;Catherine Barry;David Stuart Robertson
#t 1999
#c 11

#index 495629
#* A New Framework for Reasoning about Points, Intervals and Durations
#@ Arun K. Pujari;Abdul Sattar
#t 1999
#c 11

#index 495630
#* Scalable Temporal Reasoning
#@ Steffen Staab;Udo Hahn
#t 1999
#c 11

#index 495631
#* Robotics in the Home, Office, and Playing Field
#@ Minoru Asada;Henrik I. Christensen
#t 1999
#c 11

#index 495632
#* Verifying Integrity Constraints on Web Sites
#@ Mary F. Fernandez;Daniela Florescu;Alon Y. Levy;Dan Suciu
#t 1999
#c 11

#index 495756
#* Processing Symbols at Variable Speed in DUAL: Connectionist Activation as Power Supply
#@ Alexander A. Petrov;Boicho N. Kokinov
#t 1999
#c 11

#index 495757
#* Bounding the Suboptimality of Reusing Subproblem
#@ Michael H. Bowling;Manuela M. Veloso
#t 1999
#c 11

#index 495758
#* Convergence of Reinforcement Learning with General Function Approximators
#@ Vassilis A. Papavassiliou;Stuart J. Russell
#t 1999
#c 11

#index 495759
#* Postulates for Conditional Belief Revision
#@ Gabriele Kern-Isberner
#t 1999
#c 11

#index 495760
#* A Spatiotemporal/Spatiotemporal-Frequency Interpretation of Apparent Motion Reversal
#@ Todd R. Reed
#t 1999
#c 11

#index 495761
#* Reactive Control of Dynamic Progressive Processing
#@ Shlomo Zilberstein;Abdel-Illah Mouaddib
#t 1999
#c 11

#index 495762
#* The Symmetric Alldiff Constraint
#@ Jean-Charles Régin
#t 1999
#c 11

#index 495763
#* Generalized Physical Networks for Automated Model Building
#@ Matthew Easley;Elizabeth Bradley
#t 1999
#c 11

#index 495764
#* Computational Complexity of Planning and Approximate Planning in Presence of Incompleteness
#@ Chitta Baral;Vladik Kreinovich;Raul Trejo
#t 1999
#c 11

#index 495765
#* On the Relations between Probabilistic Logic and p-CMS
#@ Pierre Hansen;Brigitte Jaumard;A. D. Parreira
#t 1999
#c 11

#index 495766
#* Solving Strategies for Highly Symmetric CSPs
#@ Pedro Meseguer;Carme Torras
#t 1999
#c 11

#index 495767
#* Process-Oriented Estimation of Generalization Error
#@ Pedro Domingos
#t 1999
#c 11

#index 495768
#* On the Use of Integer Programming Models in AI Planning
#@ Thomas Vossen;Michael Ball;Amnon Lotem;Dana S. Nau
#t 1999
#c 11

#index 495769
#* Debugging Functional Programs
#@ Markus Stumptner;Franz Wotawa
#t 1999
#c 11

#index 495770
#* Maximum Entropy and Variable Strength Defaults
#@ Rachel A. Bourne;Simon Parsons
#t 1999
#c 11

#index 495771
#* Qualitative and Quantitative Representations of Locomotion and their Application in Robot Navigation
#@ Alexandra Musto;Klaus Stein;Andreas Eisenkolb;Thomas Röfer
#t 1999
#c 11

#index 495772
#* Temporal Planning with Mutual Exclusion Reasoning
#@ David E. Smith;Daniel S. Weld
#t 1999
#c 11

#index 495773
#* Rights, Duties and Commitments between Agents
#@ Leendert W. N. van der Torre;Yao-Hua Tan
#t 1999
#c 11

#index 495774
#* Complexity Results for Propositional Closed World Reasoning and Circumscription from Tractable Knowledge Bases
#@ Sylvie Coste-Marquis;Pierre Marquis
#t 1999
#c 11

#index 495775
#* Conceptual Grouping in Word Co-Occurrence Networks
#@ Anne Veling;Peter van der Weerd
#t 1999
#c 11

#index 495776
#* Stable Model Checking Made Easy
#@ Christoph Koch;Nicola Leone
#t 1999
#c 11

#index 495777
#* Behavior Networks for Continuous Domains using Situation-Dependent Motivations
#@ Klaus Dorer
#t 1999
#c 11

#index 495778
#* Agent-Based Computing: Promise and Perils
#@ Nicholas R. Jennings
#t 1999
#c 11

#index 495779
#* Coevolution, Memory and Balance
#@ Jan Paredis
#t 1999
#c 11

#index 495780
#* Generalized Connectionist Associative Memory
#@ Nigel P. Duffy;Arun K. Jagota
#t 1999
#c 11

#index 495781
#* Solving Non-Markovian Control Tasks with Neuro-Evolution
#@ Faustino J. Gomez;Risto Miikkulainen
#t 1999
#c 11

#index 495782
#* Shopbots and Pricebots
#@ Amy R. Greenwald;Jeffrey O. Kephart
#t 1999
#c 11

#index 495783
#* The Multilingual Generation Game: Authoring Fluent Texts in Unfamiliar Languages
#@ Donia Scott
#t 1999
#c 11

#index 495784
#* Compiling Knowledge into Decomposable Negation Normal Form
#@ Adnan Darwiche
#t 1999
#c 11

#index 495785
#* Constructive Induction: A Version Space-based Approach
#@ Michèle Sebag
#t 1999
#c 11

#index 495786
#* Reinforcement Algorithms Using Functional Approximation for Generalization and their Application to Cart Centering and Fractal Compression
#@ Clifford Claussen;Srinivas Gutta;Harry Wechsler
#t 1999
#c 11

#index 495787
#* Modeling the Basic Meanings of Path Relations
#@ Christian Kray;Anselm Blocher
#t 1999
#c 11

#index 495788
#* Hybrid Thematic Role Processor: Symbolic Linguistic Relations Revised by Connectionist Learning
#@ João Luís Garcia Rosa;Edson Françozo
#t 1999
#c 11

#index 495789
#* Automata Theory for Reasoning About Actions
#@ Eugenia Ternovskaia
#t 1999
#c 11

#index 495790
#* Diagnosis as a Variable Assignment Problem: A Case Study in a Space Robot Fault Diagnosis
#@ Luigi Portinale;Pietro Torasso
#t 1999
#c 11

#index 495791
#* A Neural Reinforcement Learning Approach to Learn Local Dispatching Policies in Production Scheduling
#@ Simone C. Riedmiller;Martin A. Riedmiller
#t 1999
#c 11

#index 495792
#* Reasoning About Actions in Narrative Understanding
#@ Srinivas Narayanan
#t 1999
#c 11

#index 495793
#* A New Tractable Subclass of the Rectangle Algebra
#@ Philippe Balbiani;Jean-François Condotta;Luis Fariñas del Cerro
#t 1999
#c 11

#index 495794
#* Highly Reactive Decision Making: A Game with Time
#@ Thierry Vidal;Silvia Coradeschi
#t 1999
#c 11

#index 495795
#* The Cluster-Abstraction Model: Unsupervised Learning of Topic Hierarchies from Text Data
#@ Thomas Hofmann
#t 1999
#c 11

#index 495796
#* Towards a Possibilistic Logic Handling of Preferences
#@ Salem Benferhat;Didier Dubois;Henri Prade
#t 1999
#c 11

#index 495797
#* Tracking Many Objects with Many Sensors
#@ Hanna Pasula;Stuart J. Russell;Michael Ostland;Yaacov Ritov
#t 1999
#c 11

#index 495798
#* An Evaluation of Criteria for Measuring the Quality of Clusters
#@ Bhavani Raskutti;Christopher Leckie
#t 1999
#c 11

#index 495919
#* Lean Semantic Interpretation
#@ Martin Romacker;Udo Hahn;Katja Markert
#t 1999
#c 11

#index 495920
#* Abducing Priorities to Derive Intended Conclusions
#@ Katsumi Inoue;Chiaki Sakama
#t 1999
#c 11

#index 495921
#* Using a Cognitive Architecture to Plan Dialogs for the Adaptive Explanation of Proofs
#@ Armin Fiedler
#t 1999
#c 11

#index 495922
#* Improvements to the Evaluation of Quantified Boolean Formulae
#@ Jussi Rintanen
#t 1999
#c 11

#index 495923
#* Qualitative Outline Theory
#@ Antony Galton;Richard C. Meathrel
#t 1999
#c 11

#index 495924
#* Maximization of the Average Quality of Anytime Contract Algorithms over a Time Interval
#@ Arnaud Delhay;Max Dauchet;Patrick Taillibert;Philippe Vanheeghe
#t 1999
#c 11

#index 495925
#* Electronic Commerce: From Economic and Game-Theoretic Models to Working Protocols
#@ Moshe Tennenholtz
#t 1999
#c 11

#index 495926
#* On the Complexity of Model Checking for Propositional Default Logics: New Results and Tractable Cases
#@ Robert Baumgartner;Georg Gottlob
#t 1999
#c 11

#index 495927
#* A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes
#@ Michael J. Kearns;Yishay Mansour;Andrew Y. Ng
#t 1999
#c 11

#index 495928
#* Real-Time Problem-Solving with Contract Algorithms
#@ Shlomo Zilberstein;François Charpillet;Philippe Chassaing
#t 1999
#c 11

#index 495929
#* Latent Class Models for Collaborative Filtering
#@ Thomas Hofmann;Jan Puzicha
#t 1999
#c 11

#index 495930
#* Efficient SQL-Querying Method for Data Mining in Large Data Bases
#@ Son H. Nguyen
#t 1999
#c 11

#index 495931
#* GIB: Steps Toward an Expert-Level Bridge-Playing Program
#@ Matthew L. Ginsberg
#t 1999
#c 11

#index 495932
#* Towards Multi-paper Summarization Using Reference Information
#@ Hidetsugu Nanba;Manabu Okumura
#t 1999
#c 11

#index 495933
#* Efficient Reinforcement Learning in Factored MDPs
#@ Michael J. Kearns;Daphne Koller
#t 1999
#c 11

#index 495934
#* Using Walk-SAT and Rel-Sat for Cryptographic Key Search
#@ Fabio Massacci
#t 1999
#c 11

#index 495935
#* Credulous Nonmonotonic Inference
#@ Alexander Bochman
#t 1999
#c 11

#index 495936
#* Multiple Path Coordination for Mobile Robots: A Geometric Algorithm
#@ Stephane Leroy;Jean-Paul Laumond;Thierry Siméon
#t 1999
#c 11

#index 495937
#* Domain-Specific Keyphrase Extraction
#@ Eibe Frank;Gordon W. Paynter;Ian H. Witten;Carl Gutwin;Craig G. Nevill-Manning
#t 1999
#c 11

#index 495938
#* Programming Resource-Bounded Deliberative Agents
#@ Michael Fisher;Chiara Ghidini
#t 1999
#c 11

#index 495939
#* How Latent is Latent Semantic Analysis?
#@ Peter M. Wiemer-Hastings
#t 1999
#c 11

#index 495940
#* Acquisition of Qualitative Spatial Representation by Visual Observation
#@ Takushi Sogo;Hiroshi Ishiguro;Toru Ishida
#t 1999
#c 11

#index 495941
#* Learning Rules for Large Vocabulary Word Sense Disambiguation
#@ Georgios Paliouras;Vangelis Karkaletsis;Constantine D. Spyropoulos
#t 1999
#c 11

#index 495942
#* SHOP: Simple Hierarchical Ordered Planner
#@ Dana S. Nau;Yue Cao;Amnon Lotem;Hector Muñoz-Avila
#t 1999
#c 11

#index 495943
#* Relational Learning for NLP using Linear Threshold Elements
#@ Roni Khardon;Dan Roth;Leslie G. Valiant
#t 1999
#c 11

#index 495944
#* A Machine Learning Approach to Building Domain-Specific Search Engines
#@ Andrew McCallum;Kamal Nigam;Jason Rennie;Kristie Seymore
#t 1999
#c 11

#index 495945
#* Computing Near Optimal Strategies for Stochastic Investment Planning Problems
#@ Milos Hauskrecht;Gopal Pandurangan;Eli Upfal
#t 1999
#c 11

#index 495946
#* SARDSRN: A Neural Network Shift-Reduce Parser
#@ Marshall R. Mayberry;Risto Miikkulainen
#t 1999
#c 11

#index 495947
#* A Context-Dependent Attention System for a Social Robot
#@ Cynthia Breazeal;Brian Scassellati
#t 1999
#c 11

#index 495948
#* Finding Relations in Polynomial Time
#@ Gilles Caporossi;Pierre Hansen
#t 1999
#c 11

#index 495949
#* Transduction with Confidence and Credibility
#@ Craig Saunders;Alexander Gammerman;Volodya Vovk
#t 1999
#c 11

#index 495950
#* Projection Using Regression and Sensors
#@ Giuseppe De Giacomo;Hector J. Levesque
#t 1999
#c 11

#index 495951
#* Was the Title of This Talk Gernerated Automatically? Prospects on Intelligent Interfaces and Language
#@ Oliviero Stock
#t 1999
#c 11

#index 495952
#* Extending Consistent Domains of Numeric CSP
#@ Hélène Collavizza;François Delobel;Michel Rueher
#t 1999
#c 11

#index 495953
#* An Iterative Sampling Procedure for Resource Constrained Project Scheduling with Time Windows
#@ Amedeo Cesta;Angelo Oddi;Stephen F. Smith
#t 1999
#c 11

#index 495954
#* Discovering Admissible Model Equations from Observed Data Based on Scale-Types and Identity Constrains
#@ Takashi Washio;Hiroshi Motoda;Niwa Yuji
#t 1999
#c 11

#index 495955
#* Exploratory Interaction with a Bayesian Argumentation System
#@ Ingrid Zukerman;Richard McConachy;Kevin B. Korb;Deborah Pickett
#t 1999
#c 11

#index 495956
#* Situated Grounded Word Semantics
#@ Luc Steels;Frédéric Kaplan
#t 1999
#c 11

#index 495957
#* Cooperation of Heterogeneous Provers
#@ Jörg Denzinger;Dirk Fuchs
#t 1999
#c 11

#index 495958
#* Confidence Based Dual Reinforcement Q-Routing: An adaptive online network routing algorithm
#@ Shailesh Kumar;Risto Miikkulainen
#t 1999
#c 11

#index 495959
#* Diagrammatic Proofs
#@ Norman Y. Foo;Maurice Pagnucco;Abhaya C. Nayak
#t 1999
#c 11

#index 495960
#* Switching from Bidirectional to Unidirectional Search
#@ Hermann Kaindl;Gerhard Kainz;Roland Steiner;Andreas Auer;Klaus Radda
#t 1999
#c 11

#index 496081
#* Multi-Value-Functions: Efficient Automatic Action Hierarchies for Multiple Goal MDPs
#@ Andrew W. Moore;Leemon Baird;Leslie Pack Kaelbling
#t 1999
#c 11

#index 496082
#* On the Role of Context-Specific Independence in Probabilistic Inference
#@ Nevin Lianwen Zhang;David Poole
#t 1999
#c 11

#index 496083
#* Dynamic Refinement of Feature Weights Using Quantitative Introspective Learning
#@ Zhong Zhang;Qiang Yang
#t 1999
#c 11

#index 496084
#* Be Patient and Tolerate Imprecision: How Autonomous Agents can Coordinate Effectively
#@ Sudhir K. Rustogi;Munindar P. Singh
#t 1999
#c 11

#index 496085
#* Leave-One-Out Support Vector Machines
#@ Jason Weston
#t 1999
#c 11

#index 496086
#* Improving Search Using Indexing: A Study with Temporal CSPs
#@ Nikos Mamoulis;Dimitris Papadias
#t 1999
#c 11

#index 496087
#* Discovering Chronicles with Numerical Time Constraints from Alarm Logs for Monitoring Dynamic Systems
#@ Christophe Dousson;Thang Vu Duong
#t 1999
#c 11

#index 496088
#* Domain-Dependent Single-Agent Search Enhancements
#@ Andreas Junghanns;Jonathan Schaeffer
#t 1999
#c 11

#index 496089
#* Lemma Generation for Model Elimination by Combining Top-Down and Bottom-Up Inference
#@ Marc Fuchs
#t 1999
#c 11

#index 496090
#* An Anthropocentric Tool for Decision Making Support
#@ Elisabeth Le Saux;Philippe Lenca;Philippe Picouet;Jean-Pierre Barthelemy
#t 1999
#c 11

#index 496091
#* Optimizing Recursive Information-Gathering Plans
#@ Eric Lambrecht;Subbarao Kambhampati;Senthil Gnanaprakasam
#t 1999
#c 11

#index 496092
#* A Lattice Machine Approach to Automated Casebase Design: Marrying Lazy and Eager Learning
#@ Hui Wang;Werner Dubitzky;Ivo Düntsch;David A. Bell
#t 1999
#c 11

#index 496093
#* Combining General Hand-Made and Automatically Constructed Thesauri for Query Expansion in Information Retrieval
#@ Rila Mandala;Takenobu Tokunaga;Hozumi Tanaka
#t 1999
#c 11

#index 496094
#* Taming the Computational Complexity of Combinatorial Auctions: Optimal and Approximate Approaches
#@ Yuzo Fujishima;Kevin Leyton-Brown;Yoav Shoham
#t 1999
#c 11

#index 496095
#* Speeding Up Ascending-Bid Auctions
#@ Yuzo Fujishima;David McAdams;Yoav Shoham
#t 1999
#c 11

#index 496096
#* An Inconsistency Tolerant Model for Belief Representation and Belief Revision
#@ Samir Chopra;Rohit Parikh
#t 1999
#c 11

#index 496097
#* Genetic Heuristic for Search Space Exploration
#@ Manuel Clergue;Philippe Collard
#t 1999
#c 11

#index 496098
#* FACILE: Classifying Texts Integrating Pattern Matching and Information Extraction
#@ Fabio Ciravegna;Alberto Lavelli;Luca Gilardoni;Johannes Matiasek;Nadia Mana;Silvia Mazza;Massimo Ferraro;William J. Black;Fabio Rinaldi;David Mowatt
#t 1999
#c 11

#index 496099
#* A New Method to Index and Query Sets
#@ Jörg Hoffmann;Jana Koehler
#t 1999
#c 11

#index 496100
#* Monitoring Piecewise Continuous Behaviors by Refining Semi-Quantative Trackers
#@ Bernhard Rinner;Benjamin Kuipers
#t 1999
#c 11

#index 496101
#* Axiomatic Foundations for Qualitative/Ordinal Decisions with Partial Preferences
#@ Adriana Zapico
#t 1999
#c 11

#index 496102
#* Decomposition Search: A Combinatorial Games Approach to Game Tree Search, with Applications to Solving Go Endgames
#@ Martin Müller, III
#t 1999
#c 11

#index 496103
#* Computing Least Common Subsumers in Description Logics with Existential Restrictions
#@ Franz Baader;Ralf Küsters;Ralf Molitor
#t 1999
#c 11

#index 496104
#* Demand-Driven Discovery of Adaptation Knowledge
#@ David McSherry
#t 1999
#c 11

#index 496105
#* A Distributed Case-Based Reasoning Application for Engineering Sales Support
#@ Ian Watson;Dan Gardingen
#t 1999
#c 11

#index 496106
#* An Experimental Study of Phase Transitions in Matching
#@ Attilio Giordana;Marco Botta;Lorenza Saitta
#t 1999
#c 11

#index 496107
#* Adaptive Web Sites: Conceptual Cluster Mining
#@ Mike Perkowitz;Oren Etzioni
#t 1999
#c 11

#index 496108
#* Reasoning in Expressive Description Logics with Fixpoints based on Automata on Infinite Trees
#@ Diego Calvanese;Giuseppe De Giacomo;Maurizio Lenzerini
#t 1999
#c 11

#index 496109
#* Investigating the Emergence of Speech Sounds
#@ Bart G. de Boer
#t 1999
#c 11

#index 496110
#* Structured Modeling Language for Automated Modeling in Causal Networks
#@ Yousri El Fattah
#t 1999
#c 11

#index 496111
#* Unifying SAT-based and Graph-based Planning
#@ Henry A. Kautz;Bart Selman
#t 1999
#c 11

#index 496112
#* Improving Graphplan's Search with EBL & DDB Techniques
#@ Subbarao Kambhampati
#t 1999
#c 11

#index 496113
#* Preference Moore Machines for Neural Fuzzy Integration
#@ Stefan Wermter
#t 1999
#c 11

#index 496114
#* Variable Resolution Discretization for High-Accuracy Solutions of Optimal Control Problems
#@ Rémi Munos;Andrew W. Moore
#t 1999
#c 11

#index 496115
#* Knowledge Modeling and Reusability in ExClaim
#@ Liviu Badea
#t 1999
#c 11

#index 496116
#* Learning Probabilistic Relational Models
#@ Nir Friedman;Lise Getoor;Daphne Koller;Avi Pfeffer
#t 1999
#c 11

#index 496117
#* Constraint Propagation and Value Acquisition: Why we should do it Interactively
#@ Evelina Lamma;Paola Mello;Michela Milano;Rita Cucchiara;Marco Gavanelli;Massimo Piccardi
#t 1999
#c 11

#index 496118
#* Logic-Based Subsumption Architecture
#@ Eyal Amir;Pedrito Maynard-Reid, II
#t 1999
#c 11

#index 496119
#* From Interaction Data to Plan Libraries: A Clustering Approach
#@ Mathias Bauer
#t 1999
#c 11

#index 496120
#* Markov Localization using Correlation
#@ Kurt Konolige;Ken Chou
#t 1999
#c 11

#index 496121
#* Path Consistency on Triangulated Constraint Graphs
#@ Christian Bliek;Djamila Sam-Haroud
#t 1999
#c 11

#index 496122
#* Integrating Problem-Solving Methods into CYC
#@ James S. Aitken;Dimitrios Sklavakis
#t 1999
#c 11

#index 496241
#* Designing Comprehensible Agents
#@ Phoebe Sengers
#t 1999
#c 11

#index 496242
#* On the Relation of Resolution and Tableaux Proof Systems for Description Logics
#@ Ullrich Hustadt;Renate A. Schmidt
#t 1999
#c 11

#index 496243
#* The Detection and Exploitation of Symmetry in Planning Problems
#@ Maria Fox;Derek Long
#t 1999
#c 11

#index 496244
#* Temporal Coherence and Prediction Decay in TD Learning
#@ Donald F. Beal;Martin C. Smith
#t 1999
#c 11

#index 496245
#* SAT-Encodings, Search Space Structure, and Local Search Performance
#@ Holger H. Hoos
#t 1999
#c 11

#index 496246
#* Cyclic Scheduling
#@ Denise Draper;Ari K. Jónsson;David P. Clements;David Joslin
#t 1999
#c 11

#index 496247
#* An assessment of submissions made to the Predictive Toxicology Evaluation Challenge
#@ Ashwin Srinivasan;Ross D. King;Douglas W. Bristol
#t 1999
#c 11

#index 496248
#* An Effective Ship Berthing Algorithm
#@ Andrew Lim
#t 1999
#c 11

#index 496249
#* Search in a Small World
#@ Toby Walsh
#t 1999
#c 11

#index 496250
#* An Algorithm for Optimal Winner Determination in Combinatorial Auctions
#@ Tuomas Sandholm
#t 1999
#c 11

#index 496251
#* Sequential Auctions for the Allocation of Resources with Complementarities
#@ Craig Boutilier;Moisés Goldszmidt;Bikash Sabata
#t 1999
#c 11

#index 496252
#* Risk Control in Multi-agent Coordination by Negotiation with a Trusted Third Party
#@ Shih-Hung Wu;Von-Wun Soo
#t 1999
#c 11

#index 496253
#* Automatic Diagnosis of Student Programs in Programming Learning Environments
#@ Songwen Xu;Yam San Chee
#t 1999
#c 11

#index 496254
#* Towards Efficient Metaquerying
#@ Rachel Ben-Eliyahu-Zohary;Ehud Gudes
#t 1999
#c 11

#index 496255
#* Autonomous Concept Formation
#@ Edwin D. de Jong
#t 1999
#c 11

#index 496256
#* Reasoning with Cause and Effect
#@ Judea Pearl
#t 1999
#c 11

#index 496257
#* Preferential Semantics for Causal Systems
#@ Pavlos Peppas;Maurice Pagnucco;Mikhail Prokopenko;Norman Y. Foo;Abhaya C. Nayak
#t 1999
#c 11

#index 496258
#* To Encode or Not to Encode - Linear Planning
#@ Ronen I. Brafman;Holger H. Hoos
#t 1999
#c 11

#index 496259
#* Pre-sending Documents on the WWW: A Comparative Study
#@ David W. Albrecht;Ingrid Zukerman;Ann E. Nicholson
#t 1999
#c 11

#index 496260
#* A Near-Optimal Poly-Time Algorithm for Learning a class of Stochastic Games
#@ Ronen I. Brafman;Moshe Tennenholtz
#t 1999
#c 11

#index 496261
#* A Divide and Conquer Bidirectional Search: First Results
#@ Richard E. Korf
#t 1999
#c 11

#index 496262
#* Combining Weak Knowledge Sources for Sense Disambiguation
#@ Mark Stevenson;Yorick Wilks
#t 1999
#c 11

#index 496263
#* Utilizing Device Behavior in Structure-Based Diagnosis
#@ Adnan Darwiche
#t 1999
#c 11

#index 496264
#* Toward a Probabilistic Formalization of Case-Based Inference
#@ Eyke Hüllermeier
#t 1999
#c 11

#index 496265
#* Reasoning with Concrete Domains
#@ Carsten Lutz
#t 1999
#c 11

#index 496266
#* Efficiency and Equilibrium in Task Allocation Economies with Hierarchical Dependencies
#@ William E. Walsh;Michael P. Wellman
#t 1999
#c 11

#index 496267
#* Computing Factored Value Functions for Policies in Structured MDPs
#@ Daphne Koller;Ronald Parr
#t 1999
#c 11

#index 496268
#* Towards Flexible Multi-Agent Decision-Making Under Time Pressure
#@ Sanguk Noh;Piotr J. Gmytrasiewicz
#t 1999
#c 11

#index 496269
#* Efficient Mining of Statistical Dependencies
#@ Tim Oates;Matthew D. Schmill;Paul R. Cohen
#t 1999
#c 11

#index 496270
#* Exploiting a Common Property Resource under a Fairness Constraint: a Case Study
#@ Michel Lemaître;Gérard Verfaillie;Nicolas Bataille
#t 1999
#c 11

#index 496271
#* Preferred Arguments are Harder to Compute than Stable Extension
#@ Yannis Dimopoulos;Bernhard Nebel;Francesca Toni
#t 1999
#c 11

#index 496272
#* Sequential Optimality and Coordination in Multiagent Systems
#@ Craig Boutilier
#t 1999
#c 11

#index 496273
#* Multi-Dimensional Description Logics
#@ Frank Wolter;Michael Zakharyaschev
#t 1999
#c 11

#index 496274
#* A Protocol-Based Semantics for an Agent Communication Language
#@ Jeremy Pitt;Abe Mamdani
#t 1999
#c 11

#index 496275
#* A Potts Spin MFT Network Solving Multiple Causal Interactions
#@ Lotfi Ben Romdhane
#t 1999
#c 11

#index 496276
#* The Difference All-Difference Makes
#@ Kostas Stergiou;Toby Walsh
#t 1999
#c 11

#index 496277
#* The LPSAT Engine & Its Application to Resource Planning
#@ Steven A. Wolfman;Daniel S. Weld
#t 1999
#c 11

#index 496278
#* The Role of Saliency in Generating Natural Language Arguments
#@ Chris Reed
#t 1999
#c 11

#index 496279
#* Maximal Tractable Fragments of the Region Connection Calculus: A Complete Analysis
#@ Jochen Renz
#t 1999
#c 11

#index 496280
#* Incremental Learning in a Fuzzy Intelligent System
#@ Yi Lu Murphey;Tie Qi Chen
#t 1999
#c 11

#index 496281
#* Automatic Concept Formation in Pure Mathematics
#@ Simon Colton;Alan Bundy;Toby Walsh
#t 1999
#c 11

#index 496282
#* Learning in Natural Language
#@ Dan Roth
#t 1999
#c 11

#index 496283
#* A Qualitative-Fuzzy Framework for Nonlinear Black-Box System Identification
#@ Riccardo Bellazzi;Raffaella Guglielmann;Liliana Ironi
#t 1999
#c 11

#index 496284
#* Expressive Reasoning about Action in Nondeterministic Polynomial Time
#@ Thomas Drakengren;Marcus Bjäreland
#t 1999
#c 11

#index 496403
#* Dealing with Geometric Constraints in Game-Theoretic Planning
#@ Patrick Fabiani;Jean-Claude Latombe
#t 1999
#c 11

#index 496404
#* Semi-Quantitative Comparative Analysis
#@ Ivayla Vatcheva;Hidde de Jong
#t 1999
#c 11

#index 496405
#* A Logic of Intention
#@ Xiaoping Chen;Guiquan Liu
#t 1999
#c 11

#index 496406
#* Managing Temporal Uncertainty Through Waypoint Controllability
#@ Paul H. Morris;Nicola Muscettola
#t 1999
#c 11

#index 496407
#* Considerations on a Similarity-Based Approach to Beleif Change
#@ James P. Delgrande
#t 1999
#c 11

#index 496408
#* Model-based Diagnosis in the Real World: Lessons Learned and Challenges Remaining
#@ Luca Console;Oskar Dressler
#t 1999
#c 11

#index 496409
#* Reachability, Relevance, Resolution and the Planning as Satisfiability Approach
#@ Ronen I. Brafman
#t 1999
#c 11

#index 496410
#* Decision Tree Grafting From the All Tests But One Partition
#@ Geoffrey I. Webb
#t 1999
#c 11

#index 496411
#* Improved Classification for a Data Fusing Kohonen Self Organizing Map Using A Dynamic Thresholding Technique
#@ Odin Taylor;John MacIntyre;John Tait
#t 1999
#c 11

#index 496412
#* Physical Constraints on Human Robot Interaction
#@ Michita Imai;Kazuo Hiraki;Tsutomu Miyasato
#t 1999
#c 11

#index 496413
#* State Space Construction by Attention Control
#@ Hiroshi Ishiguro;Masatoshi Kamiharako;Toru Ishida
#t 1999
#c 11

#index 496414
#* Two Fielded Teams and Two Experts: A RoboCup Challenge Response from the Trenches
#@ Milind Tambe;Gal A. Kaminka;Stacy Marsella;Ion Muslea;Taylor Raines
#t 1999
#c 11

#index 496415
#* Query Evaluation and Progression in AOL Knowledge Bases
#@ Gerhard Lakemeyer;Hector J. Levesque
#t 1999
#c 11

#index 496416
#* Visual Planning: A Practical Approach to Automated Presentation Design
#@ Michelle X. Zhou
#t 1999
#c 11

#index 496417
#* Remembering to Add: Competence-preserving Case-Addition Policies for Case Base Maintenance
#@ Jun Zhu;Qiang Yang
#t 1999
#c 11

#index 496418
#* A Possibilistic Planner that Deals with Non-Determinism and Contingency
#@ Emmanuel Guere;Rachid Alami
#t 1999
#c 11

#index 496419
#* A Brief Introduction to Boosting
#@ Robert E. Schapire
#t 1999
#c 11

#index 496888
#* A Brief Logopedics for the Data Used in a Neuro-Fuzzy Milieu
#@ Vesa A. Niskanen
#t 1997
#c 11

#index 496889
#* Evaluation of Fuzzy Quantified Expressions
#@ Anca L. Ralescu;Dan Ralescu;Kaoru Hirota
#t 1997
#c 11

#index 496890
#* The Place of Fuzzy Logic in AI
#@ Didier Dubois;Henri Prade
#t 1997
#c 11

#index 496891
#* Some Reflections on the Relationship between AI and Fuzzy Logic (FL) - A Heretical View
#@ Lotfi A. Zadeh
#t 1997
#c 11

#index 496892
#* Mass Assignment Fundamentals for Computing with Words
#@ James F. Baldwin
#t 1997
#c 11

#index 496893
#* Reasoning with Words about Geographic Information
#@ Hans W. Guesgen
#t 1997
#c 11

#index 496894
#* Pattern Recognition of Strong Graphs Based on Possibilistic c-means and k-formulae Matching
#@ Laurent Wendling;Jacky Desachy
#t 1997
#c 11

#index 496895
#* A Method to Use Uncertain Domain Knowledge in the Induction of Classification Knowledge Based on ID3
#@ Hiroshi Narazaki;Ichiro Shigaki
#t 1997
#c 11

#index 496896
#* From Numerical Interpolation to Constructing Intelligent Behaviors
#@ Jianwei Zhang;Alois Knoll
#t 1997
#c 11

#index 496897
#* System Identification of Fuzzy Cartesian Granules Feature Models Using Genetic Programming
#@ James F. Baldwin;Trevor P. Martin;James G. Shanahan
#t 1997
#c 11

#index 496898
#* FRIL++ a Language for Object-Oriented Programming with Uncertainty
#@ James F. Baldwin;Trevor P. Martin;Maria Vargas-Vera
#t 1997
#c 11

#index 497018
#* A Fuzzy-Neural Model for Co-ordination in Air Traffic Flow Management
#@ Leïla Zerrouki;Bernadette Bouchon-Meunier;Rèmy Fondacci
#t 1997
#c 11

#index 497019
#* Case-Based Reasoning: A Fuzzy Approach
#@ Didier Dubois;Francesc Esteva;Pere Garcia;Lluis Godo;Ramon López de Mántaras;Henri Prade
#t 1997
#c 11

#index 497020
#* Fuzzy Morphology and Fuzzy Distances: New Definitions and Links in both Euclidean and Geodesic Cases
#@ Isabelle Bloch
#t 1997
#c 11

#index 497021
#* An Application of Possibility Theory Information Fusion to Satellite Image Classification
#@ Ludovic Roux
#t 1997
#c 11

#index 497022
#* Deep Fusion of Symbolic and Computational Processing for Next Generation User Interface
#@ Shun'ichi Tano
#t 1997
#c 11

#index 566716
#* Continual Computation Policies for Allocating Offline and Real-Time Resources
#@ Eric Horvitz
#t 1999
#c 11

#index 566717
#* The Ramification Problem in the Event Calculus
#@ Murray Shanahan
#t 1999
#c 11

#index 566718
#* A Comparison of Structural CSP Decomposition Methods
#@ Georg Gottlob;Nicola Leone;Francesco Scarcello
#t 1999
#c 11

#index 566719
#* Algorithms for Optimizing Leveled Commitment Contracts
#@ Tuomas Sandholm;Sandeep Sikka;Samphel Norden
#t 1999
#c 11

#index 566720
#* Computer Aided Tracing of Children?s Physics Learning: a Teacher Oriented View
#@ Filippo Neri
#t 1999
#c 11

#index 566721
#* Model Checking for Nonmonotonic Logics: Algorithms and Complexity
#@ Riccardo Rosati
#t 1999
#c 11

#index 675883
#* Proceedings of the IJCAI''97 workshop on Abduction and Induction in AI
#@ Peter A. Flach;Antonis Kakas
#t 1997
#c 11
#! This report contains the workshop notes for the IJCAI97 workshop on Abduction and Induction in AI.

#index 759218
#* Ijcai-03: Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (International Joint Conference on Artificial Intelligence//Proceedings)
#@ 
#t 2004
#c 11

#index 919084
#* Agent-Mediated Electronic Commerce. Designing Trading Agents and Mechanisms: AAMAS 2005 Workshop, AMEC 2005, Utrecht, Netherlands, July 25, 2005, and IJCAI ... Papers (Lecture Notes in Computer Science)
#@ Han La Poutré;Norman Sadeh;Sverker Janson
#t 2006
#c 11

#index 936222
#* Intelligent Techniques for Web Personalization: IJCAI 2003 Workshop, ITWP 2003, Acapulco, Mexico, August 11, 2003, Revised Selected Papers (Lecture Notes ... / Lecture Notes in Artificial Intelligence)
#@ Bamshad Mobasher;Sarabjot Singh Anand
#t 2005
#c 11

#index 1271829
#* Proceedings of the Fifteenth international joint conference on Artifical intelligence - Volume 2
#@ Martha E. Pollack
#t 1997
#c 11

#index 1271830
#* Unbiased assessment of learning algorithms
#@ Tobias Scheffer;Ralf Herbrich
#t 1997
#c 11
#% 136350
#% 191910
#% 217058
#% 243728
#% 449508
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a minimal error rate on the test set. The same rate is then used to rank the algorithm, which causes an optimistic bias. We quantify this bias, showing, in particular, that an algorithm with more parameters will probably be ranked higher than an equally good algorithm with fewer parameters. We demonstrate this result, showing the number of parameters and trials required in order to pretend to outperform C4.5 or FOIL, respectively, for various benchmark problems. We then describe out how unbiased ranking experiments should be conducted.

#index 1271831
#* Is nonparametric learning practical in very high dimensional spaces?
#@ Gregory Z. Grudic;Peter D. Lawrence
#t 1997
#c 11
#% 136350
#% 169358
#% 191910
#% 209021
#! Many of the challenges faced by the field of Computational Intelligence in building intelligent agents, involve determining mappings between numerous and varied sensor inputs and complex and flexible action sequences. In applying nonparametric learning techniques to such problems we must therefore ask: "Is nonparametric learning practical in very high dimensional spaces?" Contemporary wisdom states that variable selection and a "greedy" choice of appropriate functional structures are essential ingredients for nonparametric learning algorithms. However, neither of these strategies is practical when learning problems have thousands of input variables, and tens of thousands of learning examples. We conclude that such nonparametric learning is practical by using a methodology which does not use either of these techniques. We propose a simple nonparametric learning algorithm to support our conclusion. The algorithm is evaluated first on 10 well known regression data sets, where it is shown to produce regression functions which are as good or better than published results on 9 of these data sets. The algorithm is further evaluated on 15 large, very high dimensional data sets (40,000 learning examples of 100, 200, 400, 800 and 1600 dimensional data) and is shown to construct effective regression functions despite the presence of noise in both inputs and outputs.

#index 1271832
#* Discovering admissible models of complex systems based on scale-types and identity constraints
#@ Takashi Washio;Hiroshi Motoda
#t 1997
#c 11
#% 9526
#% 17145
#% 24538
#% 163086
#% 451038
#% 451039
#! SDS is a discovery system from numeric measurement data. It outperforms the existing systems in every aspect of search efficiency, noise tolerancy, credibility of the resulting equations and complexity of the target system that it can handle. The power of SDS comes from the use of the scale-types of the measurement data and mathematical property of identity by which to constrain the admissible solutions. Its algorithm is described with a complex working example and the performance comparison with other systems are discussed.

#index 1271833
#* An adaptive architecture for modular Q-learning
#@ Takayuki Kohri;Kei Matsubayashi;Mario Tokoro
#t 1997
#c 11
#% 476730
#! Reinforcement learning is a technique to learn suitable action policies that maximize utility, via the clue of reinforcement signals: reward or punishment. Q-learning, a widely used reinforcement learning method, has been analyzed in much research on autonomous agents. However, as the size of the problem space increases, agents need more computational resources and require more time to learn appropriate policies. Whitehead proposed an architecture called modular Q-learning, that decomposes the whole problem space into smaller subproblem spaces, and distributes them among multiple modules. Thus, each module takes charge of part of the whole problem. In modular Q-learning, however, human designers have to decompose the problem space, and create a suitable set of modules manually. Agents with such a fixed module architecture cannot adapt themselves to dynamic environments. Here, we propose a new architecture for reinforcement learning called AMQL (Automatic Modular Q-Learning), that enables agents to obtain a suitable set of modules by themselves using a selection method. Through experiments, we show that agents can automatically obtain suitable modules to gain a reward. Furthermore, we show that agents can adapt themselves to dynamic environments efficiently, through reconstructing modules.

#index 1271834
#* A convergent reinforcement learning algorithm in the continuous case based on a finite difference method
#@ Remi Munos
#t 1997
#c 11
#% 22348
#% 458385
#! In this paper, we propose a convergent Reinforcement Learning algorithm for solving optimal control problems for which the state space and the time are continuous variables. The problem of computing a good approximation of the value function, which is essential because this provides the optimal control, is a difficult task in the continuous case. Indeed, as it has been pointed out by several authors, the use of parameterized functions such as neural networks for approximating the value function may produce very bad results and even diverge. In fact, we show that classical algorithms, like Q-learning, used with a simple look-up table built on a regular grid, may fail to converge. The main reason is that the discretization of the state space implies a lost of the Markov property even for deterministic continuous processes. We propose to approximate the value function with a convergent numerical scheme based on a Finite Difference approximation of the Hamilton-Jacobi-Bellman equation. Then we present a model-free reinforcement learning algorithrn, called Finite Difference Reinforcement Learning, and prove its convergence to the value function of the continuous problem.

#index 1271835
#* Ants and reinforcement learning: a case study in routing in dynamic networks
#@ Devika Subramanian;Peter Druschel;Johnny Chen
#t 1997
#c 11
#% 1272286
#! We investigate two new distributed routing algorithms for data networks based on simple biological "ants" that explore the network and rapidly learn good routes, using a novel variation of reinforcement learning. These two algorithms are fully adaptive to topology changes and changes in link costs in the network, and have space and computational overheads that are competitive with traditional packet routing algorithms: although they can generate more routing traffic when the rate of failures in a network is low, they perform much better under higher failure rates. Both algorithms are more resilient than traditional algorithms, in the sense that random corruption of routing state has limited impact on the computation of paths. We present convergence theorems for both of our algorithms drawing on the theory of non-stationary and stationary discrete-time Markov chains over the reals. We present an extensive empirical evaluation of our algorithms on a simulator that is widely used in the computer networks community for validating and testing protocols. We present comparative results on data delivery performance, aggregate routing traffic (algorithm overhead), as well as the degree of resilience for our new algorithms and two traditional routing algorithms in current use. We also show that the performance of our algorithms scale well with increase in network size-using a realistic topology.

#index 1271836
#* Integrating models of discrimination and characterization for learning from examples in open domains
#@ Paul Davidsson
#t 1997
#c 11
#% 51647
#% 92148
#% 92533
#% 126935
#% 136350
#% 172486
#% 449588
#! It is argued that in applications of concept learning from examples where not every possible category of the domain is present in the training set (i.e., most real world applications), classification performance can be improved by integrating suitable discriminative and characteristic classification schemes. The suggested approach is to first discriminate between the categories present in the training set and then characterize each of these categories against all possible categories. To show the viability of this approach, a number of different discriminators and characterizers are integrated and tested. In particular, a novel characterization method that makes use of the information about the statistical distribution of feature values that can be extracted from the training examples is used. The experimental results strongly supports the thesis of the paper.

#index 1271837
#* Decision tree grafting
#@ Geoffrey I. Webb
#t 1997
#c 11
#% 21533
#% 42994
#% 73372
#% 132938
#% 136350
#% 209021
#% 527527
#% 1272290
#! This paper extends recent work on decision tree grafting. Grafting is an inductive process that adds nodes to inferred decision trees. This process is demonstrated to frequently improve predictive accuracy. Superficial analysis might suggest that decision tree grafting is the direct reverse of pruning. To the contrary, it is argued that the two processes are complementary. This is because, like standard tree growing techniques, pruning uses only local information, whereas grafting uses non-local information. The use of both pruning and grafting in conjunction is demonstrated to provide the best general predictive accuracy over a representative selection of learning tasks.

#index 1271838
#* Noise-tolerant windowing
#@ Johannes Furnkranz
#t 1997
#c 11
#% 136350
#% 164368
#% 277919
#% 449566
#% 465582
#% 481779
#% 1478808
#! Windowing has been proposed as a procedure for efficient memory use in the ID3 decision tree learning algorithm. However, it was shown that it may often lead to a decrease in performance, in particular in noisy domains. Following up on previous work, where we have demonstrated that the ability of rule learning algorithms to learn rules independently can be exploited for more efficient windowing procedures, we demonstrate in this paper how this property can be exploited to achieve noisetolerance in windowing.

#index 1271839
#* Ensembles as a sequence of classifiers
#@ Lars Asker;Richard Maclin
#t 1997
#c 11
#% 80995
#% 96699
#% 105684
#% 132938
#% 163316
#% 184065
#% 209021
#% 443616
#% 1022958
#% 1042787
#% 1275295
#! An ensemble is a classifier created by combining the predictions of multiple component classifiers. We present a new method for combining classifiers into an ensemble based on a simple estimation of each classifier's competence. The classifiers are grouped into an ordered list where each classifier has a corresponding threshold. To classify an example, the first classifier on the list is consulted and if that classifier's confidence for predicting the example is above the classifier's threshold, then that classifier's prediction is used. Otherwise, the next classifier and its threshold is consulted and so on. If none of the classifiers predicts the example above its confidence threshold then the class of the example is predicted by averaging all of the component classifier predictions. The key to this method is the selection of the confidence threshold for each classifier. We have implemented this method in a system called SEQUEL which has been applied to the task of recognizing volcanos in SAR images of Venus. In this domain, SEQUEL outperforms each individual classifier as well as the simple approach of using an ensemble constructed from the average prediction of all the classifiers.

#index 1271840
#* Stacked generalization: when does it work?
#@ Kai Ming Ting;Ian H. Witten
#t 1997
#c 11
#% 92533
#% 132938
#% 136350
#% 140588
#% 184197
#% 191854
#% 208181
#% 209021
#% 465764
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271841
#* Alignment algorithms for learning to read aloud
#@ Charles X. Ling;Handong Wang
#t 1997
#c 11
#% 23803
#% 89881
#% 136350
#% 449529
#% 449588
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271842
#* Socially embedded learning of the office-conversant mobile robot Jijo-2
#@ Hideki Asoh;Satoru Hayamizu;Isao Hara;Yoichi Motomura;Shotaro Akaho;Toshihiro Matsui
#t 1997
#c 11
#% 126853
#% 135414
#% 180156
#% 181333
#% 203611
#% 375503
#% 644560
#% 1275241
#% 1290038
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271843
#* Tractable induction and classification in first order logic via stochastic matching
#@ Michele Sebag;Celine Rouveirol
#t 1997
#c 11
#% 697
#% 44625
#% 106668
#% 124708
#% 160275
#% 396021
#% 449508
#% 550250
#% 1022829
#% 1272290
#% 1290056
#! Learning in first-order logic (FOL) languages suffers from a specific difficulty: both induction and classification are potentially exponential in the size of hypotheses. This difficulty is usually dealt with by limiting the size of hypotheses, via either syntactic restrictions or search strategies. This paper is concerned with polynomial induction and use of FOL hypotheses with no size restrictions. This is done via stochastic matching: instead of exhaustively exploring the set of matchings between any example and any short candidate hypothesis, one stochastically explores the set of matchings between any example and any candidate hypothesis. The user sets the number of matching samples to consider and thereby controls the cost of induction and classification. One advantage of this heuristic is to allow for resource-bounded learning, without any a priori knowledge about the problem domain. Experiments on a real-world problem pertaining to organic chemistry fully demonstrate the potentialities of the approach regarding both predictive accuracy and computational cost.

#index 1271844
#* RHB+: a type-oriented ILP system learning from positive data
#@ Yutaka Sasaki;Masahiko Haruno
#t 1997
#c 11
#% 7679
#% 33376
#% 92776
#% 178902
#% 179873
#% 449508
#% 1272165
#! This paper presents the type-oriented relational learner RHB+. Attaching type information to hypotheses is effective in avoiding overgeneralization as well as enhancing readability and comprehensibility. In many areas, such as NLP, type information is actually available, while negative examples are not. Unfortunately, learning performance is usually poor if types are attached when only positive examples are available. RHB+ makes use of type information to efficiently compute informativity from positive examples only and to judge a stopping condition. The new technique of dynamic type restriction by positive examples lets covered positive examples decide the types appropriate for the current clause. The current version of RHB+, written in the typed logic programming language LIFE, directly manipulates types as structured background knowledge when operations related to types are required. These features make RHB+ efficient and effective in attaching types selected from thousands of possible types. This leads to advantages over several previous learners, such as FOIL and PROGOL. Experimental results demonstrate RHB+ 's fine performance for both artificial and real data.

#index 1271845
#* Integrating explanatory and descriptive learning in ILP
#@ Yannis Dimopoulos;Saso Dzeroski;Antonis Kakas
#t 1997
#c 11
#% 33376
#% 42003
#% 175383
#% 185232
#% 226437
#% 458178
#% 543238
#% 550255
#% 782325
#! A learning framework that combines the two frameworks of explanatory and descriptive Inductive Logic Programming (ILP) is presented. The induced hypotheses in this framework are pairs of the form (T, IC) where T is a definite clausal theory and IC is a set of integrity constraints. The two components allow us to combine complementary information from the same data by applying both explanatory and descriptive learning methods. This non-trivial integration is achieved using a nonmonotonic entailment relation for the basic notion of coverage in the combined language of rules and constraints where the constraints can restrict the conclusions derivable by the rules. We present a semantics for the new framework and then discuss different cases where combining information from explanatory and descriptive ILP could be useful. We present some basic algorithmic frameworks for learning in the new framework, and report on some preliminary experiments with encouraging results.

#index 1271846
#* Combining knowledge acquisition and machine learning to control dynamic systems
#@ G. M. Shiraz;C. Sammut
#t 1997
#c 11
#% 78791
#% 126926
#% 191922
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271847
#* Skill reconstruction as induction of LQ controllers with subgoals
#@ Dorian Suc;Ivan Bratko
#t 1997
#c 11
#% 22348
#% 126926
#% 476406
#! Controlling a complex dynamic system, such as a plane or a crane, usually requires a skilled operator. Such a control skill is typically hard to reconstruct through introspection. Therefore an attractive approach to the reconstruction of control skill involves machine learning from operators' control traces, also known as behavioural cloning. In the most common approach to behavioural cloning, a controller is induced in the form of a rule set or a decision or regression tree that maps system states to actions. Unfortunately, induced controllers usually suffer from lack of robustness and lack typical elements of human control strategies, such as subgoals and substages of the control plan. In this paper we present a new approach to behavioural cloning which involves the induction of a model of the controlled system and enables the identification of subgoals that the operator is pursuing at various stages of the execution trace. The underlying formal basis for the present approach to behavioural cloning is the theory of LQ controllers. Experimental results show that this approach greatly improves the robustness of the induced controllers and also offers a new way of understanding the operator's subcognitive skill.

#index 1271848
#* Learning topological maps with weak local odometric information
#@ Hagit Shatkay;Leslie Pack Kaelbling
#t 1997
#c 11
#% 10237
#% 181628
#% 229084
#% 646934
#% 1290038
#% 1476261
#! Topological maps provide a useful abstraction for robotic navigation and planning. Although stochastic maps can theoretically be learned using the Baum-Welch algorithm, without strong prior constraint on the structure of the model it is slow to converge, requires a great deal of data, and is often stuck in local minima. In this paper, we consider a special case of hidden Markov models for robot-navigation environments, in which states are associated with points in a metric configuration space. We assume that the robot has some odometric ability to measure relative transformations between its configurations. Such odometry is typically not precise enough to suffice for building a global map, but it does give valuable local information about relations between adjacent states. We present an extension of the Baum-Welch algorithm that takes advantage of this local odometric information, yielding faster convergence to better solutions with less data.

#index 1271849
#* Discovering interesting holes in data
#@ Bing Liu;Liang-Ping Ku;Wynne Hsu
#t 1997
#c 11
#% 2115
#% 10131
#% 24538
#% 136350
#% 152934
#% 451038
#% 451042
#% 451052
#% 1499588
#! Current machine learning and discovery techniques focus on discovering rules or regularities that exist in data. An important aspect of the research that has been ignored in the past is the learning or discovering of interesting holes in the database. If we view each case in the database as a point in a it-dimensional space, then a hole is simply a region in the space that contains no data point. Clearly, not every hole is interesting. Some holes are obvious because it is known that certain value combinations are not possible. Some holes exist because there are insufficient cases in the database. However, in some situations, empty regions do carry important information. For instance, they could warn us about some missing value combinations that are either not known before or are unexpected. Knowing these missing value combinations may lead to significant discoveries. In this paper, we propose an algorithm to discover holes in databases.

#index 1271850
#* An analysis on crossovers for real number chromosomes in an infinite population size
#@ Tatsuya Nomura
#t 1997
#c 11
#% 518421
#% 1022793
#! In this paper, as one approach for mathematical analysis of evolutionary algorithms with real number chromosomes, we focus our attention on crossovers, give a general framework of the description for the change of the distribution of the population through them, and verify the properties of crossovers based on the framework. This framework includes various crossover which have been proposed and we apply our result to these crossover methods.

#index 1271851
#* Minimum splits based discretization for continuous features
#@ Ke Wang;Han Chong Goh
#t 1997
#c 11
#% 99397
#% 136350
#% 140389
#% 156186
#% 458283
#% 1272280
#! Discretization refers to splitting the range of continuous values into intervals so as to provide useful information about classes. This is usually done by minimizing a goodness measure, subject to constraints such as the maximal number of intervals, the minimal number of examples per interval, or some stopping criterion for splitting. We take a different approach by searching for minimum splits that minimize the number of intervals with respect to a threshold of impurity (i.e., badness). We propose a "total entropy" motivated selection of the "best" split from minimum splits, without requiring additional constraints. Experiments show that the proposed method produces better decision trees.

#index 1271852
#* Dynamically improving explanations: a revision-based approach to explanation generation
#@ Charles B. Callaway;James C. Lester
#t 1997
#c 11
#% 69588
#% 91528
#% 135335
#% 149389
#% 177915
#% 199036
#% 491736
#% 555582
#% 679521
#% 701452
#% 741059
#% 741182
#% 748142
#! Recent years have witnessed rapid progress in explanation generation. Despite these advances, the quality of prose produced by explanation generators warrants significant improvement. Revision-based explanation generation offers a promising means for improving explanations at runtime. In contrast to singledraft explanation generation architectures, a revision-based generator could dynamically create, evaluate, and refine multiple drafts of explanations. However, because of the inherent complexity of revision, previous multisentential revision-based approaches have not scaled up. We have developed a scalable revision-based model of explanation generation that dynamically improves multi-sentential explanations. By operating on abstract discourse plans encoded in a minimalist representation, it combats both the conceptual complexities and the efficiency problems posed by revision. This approach has been implemented in REVISOR, a unification-based revision system. Evaluations of REVISOR'S performance in generating a corpus of extended multi-sentential scientific explanations yielded encouraging results.

#index 1271853
#* Exploiting the addressee's inferential capabilities in presenting mathematical proofs
#@ Detlef Fehrer;Helmut Horacek
#t 1997
#c 11
#% 2192
#% 365790
#% 423966
#% 520427
#% 555579
#% 560927
#% 569104
#% 740937
#% 748590
#! Proof presentation systems and, in some more general context, many natural language generation systems suffer from a crucial problem: they present too much information explicitly which the intended audience could more naturally infer from a less detailed text. Moreover, proofs in mathematical textbooks make extensive use of building chains of inferences in specialized notations, which is not sufficiently taken into account by proof presentation systems. Encouraged by these observations, we present a model for presenting mathematical proofs that (1) features the implicit conveyance of information through concise texts, (2) organizes major lines in the proof presentation around focused chains of inferences in a specialized notation, (3) can adapt its output to some of the capabilities of its audience. The methods described in this paper allow us to present proofs of moderately complex size in a quality approaching that of proofs found in mathematical textbooks.

#index 1271854
#* Proof verbalization as an application of NLG
#@ Xiaorong Huang;Armin Fiedler
#t 1997
#c 11
#% 51055
#% 365790
#% 370475
#% 491736
#% 560582
#% 746887
#% 748514
#% 756795
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271855
#* Corpus-based Chinese-Korean abstracting translation system
#@ Jun-Jie Li;Key-Sun Choi
#t 1997
#c 11
#% 1660
#% 756686
#% 756798
#% 757301
#% 757853
#% 757855
#! A Corpus-Based Chinese-Korean Abstracting Translation System is designed and implemented. Firstly, a text indexing method called Natural Hierarchical Network(NHN) is introduced, and then a Corpus-Based Word Segmentation algorithm is developed with the segmentation correctness of 98% for open test. Based on a words weighting function and a sentence importance weighting function which can dynamically calculate the importance of words and sentences by using the word frequency both in corpus and context, word length, sentence length and so on, an abstracting system is implemented to produce abstracts of texts in deferent languages and domains by any abstracting rate. Experiments show that generally abstracts produced by 10% to 20% abstracting rates can cover 90% of the important sentences of the input texts. Finally, combines with an Example-Based Chinese-Korean Machine Translation System, the generated abstracts are translated into target language with the correctness of translation of more than 70% by the important words oriented machine translation strategy.

#index 1271856
#* A hybrid approach to interactive machine translation: integrating rule-based, corpus-based, and example-based method
#@ Kiyoshi Yamabana;Shin-ichiro Kamei;Kazunori Muraki;Shinichi Doi;Shinko Tamura;Kenji Satoh
#t 1997
#c 11
#% 742443
#% 756194
#% 756962
#% 757301
#% 757364
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271857
#* Improving performance of transfer-driven machine translation with extra-linguistic information from context, situation and environment
#@ Hideki Mima;Osamu Furuse;Hitoshi Iida
#t 1997
#c 11
#% 748865
#% 756059
#% 756103
#% 757341
#% 757346
#% 757881
#! This paper describes an improvement in the performance of Transfer-Driven Machine Translation (TDMT) by the use of extralinguistic information. In evaluating what constitutes natural speech, particular attention was paid to word usage that depended on the extra-linguistic information from the context, situation, environment and so on. We discuss what types of extra-linguistic information a spoken-language translation system requires to create naturally communicative dialogs. We then propose a method of improving the precision of translation by utilizing this extralinguistic information. Preliminary experimentation showing performance improvements in TDMT makes us believe that the proposed scheme can improve the performance of dialog MT.

#index 1271858
#* Dynamic, user-centered resolution in interactive stories
#@ Nikitas M. Sgouros
#t 1997
#c 11
#% 154456
#% 198113
#% 214541
#% 1499489
#! One of the most important parts of a story is its ending. This is the point in which all open questions and conflicts in the narrative must be resolved. This paper presents a dynamic resolution method for interactive stories. The type of stories we support allows the user to participate as one of the characters and influence dynamically the development of the plot. The rest of the cast consists of discrete computer characters. Our resolution method takes into account the motives of the user character to decide on: (i) the outcome of all character actions and (ii) the presentation sequence for these outcomes. The decision process is based on the current story context. In addition, it addresses the need to avoid ambiguities, to preserve consistency and to create suspense during the end. We have integrated this method in PEGASUS, an interactive story system set in ancient Greece.

#index 1271859
#* "Tall", "good", "high": compared to what?
#@ Steffen Staab;Udo Hahn
#t 1997
#c 11
#% 744298
#% 756182
#% 1478825
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271860
#* Charts, interaction-free grammars, and the compact representation of ambiguity
#@ Marc Dymetman
#t 1997
#c 11
#% 23804
#% 175652
#% 740934
#% 748315
#% 748507
#! Recently researchers working in the LFG framework have proposed algorithms for taking advantage of the implicit context-free components of a unification grammar [Maxwell and Kaplan, 1996]. This paper clarifies the mathematical foundations of these techniques, provides a uniform framework in which they can be formally studied and eliminates the need for special purpose runtime datastructures recording ambiguity. The paper posits the identity: Ambiguous Feature Structures = Grammars, which states that (finitely) ambiguous representations are best seen as unification grammars of a certain type, here called "interactionfree" grammars, which generate in a backtrackfree way each of the feature structures subsumed by the ambiguous representation. This work extends a line of research [Billot and Lang, 1989; Lang, 1994] which stresses the connection between charts and grammars: a chart can be seen as a specialization of the reference grammar for a given input string. We show how this specialization grammar can be transformed into an interaction-free form which has the same practicality as a listing of the individual solutions, but is produced in less time and space.

#index 1271861
#* On the interaction of metonymies and anaphora
#@ Katja Markert;Udo Hahn
#t 1997
#c 11
#% 21141
#% 145393
#% 740330
#% 748453
#% 748733
#! From the analysis of naturally occurring texts we obtained evidence for the systematic interaction between nominal anaphora and metonymies. This leads us to postulate an integrated model incorporating both phenomena simultaneously. The consideration of discourse constraints for metonymy resolution allows us to challenge the commonly held view that the interpretation of metonymies should proceed from a literal-meaning-first approach. Thus, we argue for an equally balanced treatment of literal and figurative language use.

#index 1271862
#* Computing parallelism in discourse
#@ Claire Gardent;Michael Kohlhase
#t 1997
#c 11
#% 216097
#% 504473
#% 748584
#% 748698
#! Although much has been said about parallelism in discourse, a formal, computational theory of parallelism structure is still outstanding. In this paper, we present a theory which given two parallel utterances predicts which are the parallel elements. The theory consists of a sorted, higher-order abductive calculus and we show that it reconciles the insights of discourse theories of parallelism with those of Higher-Order Unification approaches to discourse semantics, there by providing a natural framework in which to capture the effect of parallelism on discourse semantics.

#index 1271863
#* Content ordering in the generation of persuasive discourse
#@ Chris Reed;Derek Long
#t 1997
#c 11
#% 9197
#% 21801
#% 70387
#% 145399
#% 216021
#% 459409
#% 459583
#% 541512
#% 740937
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271864
#* ARTIMIS: natural dialogue meets rational agency
#@ M. D. Sadek;P. Bretier;F. Panaget
#t 1997
#c 11
#% 68239
#% 136356
#% 412963
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271865
#* An information-based approach for guiding multi-modal human-computer-interaction
#@ Matthias Denecke
#t 1997
#c 11
#% 117568
#% 437544
#! Much work has been done in dialogue modeling for spoken and multi-modal humancomputer interaction. Problems can arise in situations that do not correspond to the dialogue model. For this reason, we propose information-centered dialogue processing in which the actions to be taken by the dialogue system are determined as a function of the information available in the discourse, the database and the domain model. In order to arrive at fully specified representations of the intended actions, the specificity of the representations is increased by unification, integrating information from multi-modal input, database access and domain knowledge. Our approach differs from other state-of-the-art systems in that it does not rely on explicit dialogue models. Instead, we show how partial and underspecified representations of the situation can be used in a spoken dialogue system to generate clarification questions and to guide the user to arrive at his or her communicative goal. We show furthermore how probabilistic information can be used to disambiguate without clarification questions. Evaluation results and dialogue examples demonstrate the flexibility and naturalness of our approach.

#index 1271866
#* Interactive disambguation of natural language input: a methodology and two implementations for French and English
#@ Herve Blanchon
#t 1997
#c 11
#% 365671
#% 762156
#! As natural language is highly ambiguous even in restricted domains, interactive disambiguation is seen as a necessity for achieving more robust and user-friendly interactive systems, face-to-face translation systems and Dialogue-Based Machine Translation systems. We have proposed a methodology which distinguishes between two parts in a disambiguation module: an engine (language- and application-independent) and a lingware (language- and application-dependent). The engine is, thus, to be reused in the design of any disambiguation module. This paper presents the current state of our work, that is: an engine that has been used to design two interactive disambiguation modules, for French, and English.

#index 1271867
#* A method of generating calligraphy of Japanese character using deformable contours
#@ Lisong Wang;Tsuyoshi Nakamura;Minkai Wang;Hirohisa Seki;Hidenori Itoh
#t 1997
#c 11
#% 2219
#% 119513
#% 443926
#! This article considers the problem of generating various calligraphy of Japanese character from some limited existing fonts. We propose a generation method based on the deformable contour model g-snake. By representing the outline of each stroke that makes of a character with a g-snake, we cast the generation problem into global and local deformation of g-snake under different control parameters, meanwhile, the local deformation obeys the energy minimization principle of regularization technique. The base value of the control parameters are learned from given sample fonts. The experimental results, i.e. the generated calligraphy show such a process as a reasonable way of generating characteristic calligraphy.

#index 1271868
#* The representation and use of a visual lexicon for automated graphics generation
#@ Michelle X. Zhou;Steven K. Feiner
#t 1997
#c 11
#% 18610
#% 95829
#% 145661
#% 174161
#% 178976
#% 214546
#% 364088
#% 435915
#% 436127
#% 641092
#% 689569
#% 741064
#% 834997
#! Most automated graphics generation systems employ either a constructive or a parametric graphics synthesis approach. Constructive graphics synthesis is a deductive approach that builds visual presentations from scratch by gluing together the most basic visual variables. Conversely, parametric graphics synthesis defines a set of parametrized visual models and interprets the information to be presented through instantiation of the selected model. To increase efficiency, we have combined parametric and constructive approaches in a system called IMPROVISE. In this paper, we focus on the parametric aspect of our approach. We present a comprehensive, general, and extensible formalism to represent a visual lexicon for use in automated graphics generation. A visual lexicon is a collection of parametrized primitive visual objects that serve as building blocks for constructing more complex visual presentations. We also illustrate how this representation can be effectively employed to aid the selection and instantiation of a visual lexical item in the graphics generation process. Examples are given from IMPROVISE to demonstrate the representation and use of this visual lexicon.

#index 1271869
#* On the efficient classification of data structures by neural networks
#@ Paolo Frasconi;Marco Gori;Alessandro Sperduti
#t 1997
#c 11
#% 43029
#% 90391
#% 109728
#% 1275293
#% 1860191
#% 1862649
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271870
#* On the role of hierarchy for neural network interpretation
#@ Jurgen Rahmel;Christian Blum;Peter Hahn
#t 1997
#c 11
#% 114736
#% 136350
#% 169026
#% 1860147
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271871
#* Law discovery using neural networks
#@ Kazumi Saito;Ryohei Nakano
#t 1997
#c 11
#% 24538
#% 65445
#% 68818
#% 90074
#% 92148
#% 105667
#% 106657
#% 132590
#% 232215
#% 369349
#% 451048
#! This paper proposes a new connectionist approach to numeric law discovery; i.e., neural networks (law-candidates) are trained by using a newly invented second-order learning algor ithm based on a quasi-Newton method, called BPQ, and the Minimum Description Length criterion selects the most suitable from lawcandidates. The main advantage of our method over previous work of symbolic or connectionist approach is that it can efficiently discover numeric laws whose power values are not restricted to integers. Experiments showed that the proposed method works well in discovering such laws even from data containing irrelevant variables or a small amount of noise.

#index 1271872
#* Active diagnosis by self-organization: an approach by the immune network metaphor
#@ Yoshiteru Ishida
#t 1997
#c 11
#% 6199
#% 20718
#% 24547
#% 181537
#! We propose a concept of active diagnosis that differs from the conventional passive (i.e. event-driven) diagnosis in temporal (diagnosis is carried out by always monitoring normal condition as opposed to identifying faulty only when abnormal condition is detected) sense as well as spatial (diagnosis is carried out by agents distributed in the sensor network) sense. As one way of realizing active diagnosis, we present immunity-based agents approach based on the self creating, monitoring, and maintaining feature of immune systems. We apply the approach to process diagnosis where the agents are defined on the sensor network. Each agent corresponding to sensor or process constraint evaluates a kind of reliability by communicating other agents. System level recognition of sensor/process fault can be attained by continuously and mutually monitoring and maintaining consistency among sensor values and process constraints.

#index 1271873
#* Meaning and the mental lexicon
#@ Will Lowe
#t 1997
#c 11
#% 75522
#% 136369
#% 148049
#% 361100
#% 565900
#% 740898
#! This paper presents a network model of the mental lexicon and its formation. Models of word meaning typically postulate a network of nodes with connection strengths, or distances, that reflect semantic similarity, but seldom explain how the network is formed or how it could be represented in the brain. The model presented here is an attempt to address these questions. The network organizes semantically similar words into clusters when exposed to sequentially presented text. Lexical co-occurrence information is calculated and used to create a hierarchical semantic representation. The output is similar to semantic networks first described by [Collins and Loftus, 1975], but is created automatically.

#index 1271874
#* Extracting propositions from trained neural networks
#@ Hiroshi Tsukimoto
#t 1997
#c 11
#% 136350
#% 156699
#% 170665
#% 202294
#% 204714
#% 217939
#! This paper presents an algorithm for extracting propositions from trained neural networks. The algorithm is a decompositional approach which can be applied to any neural network whose output function is monotone such as sigmoid function. Therefore, the algorithm can be applied to multi-layer neural networks, recurrent neural networks and so on. The algorithm does not depend on training methods. The algorithm is polynomial in computational complexity. The basic idea is that the units of neural networks are approximated by Boolean functions. But the computational complexity of the approximation is exponential, so a polynomial algorithm is presented. The authors have applied the algorithm to several problems to extract understandable and accurate propositions. This paper shows the results for votes data and mushroom data. The algorithm is extended to the continuous domain, where extracted propositions are continuous Boolean functions. Roughly speaking, the representation by continuous Boolean functions means the representation using conjunction, disjunction, direct proportion and reverse proportion. This paper shows the results for iris data.

#index 1271875
#* Convergence time characteristics of an associative memory for natural language processing
#@ Nigel Collier
#t 1997
#c 11
#% 67602
#% 1051521
#% 1051550
#! We take a new look at one of the fundamental properties of discrete time associative memory and show how it can be adapted for natural language processing (NLP). Many tasks in NLP could benefit from such associative functionality particularly those which are traditionally regarded as being context driven such as word sense disambiguation. The results describe the typical time to convergence of a Hopfield network when trained on patterns representing sentences from a large corpus. Through numerical simulation we estimate the time order of convergence and compare this to previous findings for randomly generated, unbiased and uncorrected patterns.

#index 1271876
#* Combining probabilistic population codes
#@ Richard S. Zemel;Peter Dayan
#t 1997
#c 11
#% 215637
#% 1051451
#! We study the problem of statistically correct inference in networks whose basic representations are population codes. Population codes are ubiquitous in the brain, and involve the simultaneous activity of many units coding for some low dimensional quantity. A classic example are place cells in the rat hippocampus: these fire when the animal is at a particular place in an environment, so the underlying quantity has two dimensions of spatial location. We show how to interpret the activity as encoding whole probability distributions over the underlying variable rather then just single values, and propose a method of inductively learning mappings between population codes that are computationally tractable and yet offer good approximations to statistically optimal inference. We simulate the method on some simple examples to prove its competence.

#index 1271877
#* Self-organization and segmentation with laterally connected spiking neurons
#@ Yoonsuck Choe;Risto Miikkulainen
#t 1997
#c 11
#% 209269
#% 215233
#% 225595
#% 1042797
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271878
#* A music stream segregation system based on adaptive multi-agents
#@ Kunio Kashino;Hiroshi Murase
#t 1997
#c 11
#% 6199
#% 190861
#% 704183
#% 1275247
#% 1275248
#! A principal problem of auditory scene analysis is stream segregation: decomposing an input acoustic signal into signals of individual sound sources included in the input. While existing signal processing algorithms cannot properly solve this inverse problem, a multiagentbased architecture has been considered to be a promising methodology in its modularity and scalability. However, most attempts made so far depend on subjectively defined rules to deal with variability of sounds. Here we propose a quantitatively principled architecture in agent interaction by formulating the problem as least-squares optimization. In this architecture, adaptation of the agents is the essential idea. We have developed two kinds of processing to realize adaptivity: template filtering and phase tracking. These mechanisms enable each agent to optimally, in the least-squares sense, track the individual sound. As an example application of the proposed architecture, we have built a music recognition system that recognizes instrument names and pitches of the notes included in ensemble music performances. Experimental results show that these adaptive mechanisms significantly improve the recognition accuracy.

#index 1271879
#* An effective learning method for max-min neural networks
#@ Loo-Nin Teow;Kia-Fock Loe
#t 1997
#c 11
#% 25443
#% 92148
#% 120855
#% 136606
#% 160861
#% 167962
#% 169143
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271880
#* Avoiding overfitting with BP-SOM
#@ Ton Weijters;H. Jaap Van Den Herik;Antal Van Den Bosch;Eric Postma
#t 1997
#c 11
#% 60576
#% 92148
#% 96692
#% 106567
#% 136350
#% 140193
#% 669192
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271881
#* Evolvable hardware for generalized neural networks
#@ Masahiro Murakawa;Shuji Yoshizawa;Isamu Kajitani;Tetsuya Higuchi
#t 1997
#c 11
#% 41590
#% 77376
#% 91740
#% 170838
#% 198380
#% 369236
#% 479286
#% 1042868
#! This paper describes an evolvable hardware (EHW) system for generalized neural network learning. We have developed an ASIC VLSI chip, which is a building block to configure a scalable neural network hardware system. In our system, both the topology and the hidden layer node functions of a neural network mapped on the chips are dynamically changed using a genetic algorithm. Thus, the most desirable network topology and choice of node function (e.g. Gaussian or sigmoid) for a given application can be determined adaptively. This approach is particularly suited to applications requiring ability to cope with time-varying problems and real-time timing constraints. The chip consists of 15 Digital Signal Processors (DSPs), whose functions and interconnections are reconfigured dynamically according to the chromosomes of the genetic algorithm. Incorporation of local learning hardware increases the learning speed significantly. Simulation results on adaptive equalization in digital mobile communication are also given. Our system is two orders of magnitude faster than a Sun SS20 on the corresponding problem.

#index 1271882
#* Prioritized goal decomposition of Markov decision processes: toward a synthesis of classical and decision theoretic planning
#@ Craig Boutilier;Ronen I. Brafman;Christopher Geib
#t 1997
#c 11
#% 75936
#% 179955
#% 224762
#% 363744
#% 644560
#% 1290041
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271883
#* Model minimization, regression, and propositional STRIPS planning
#@ Robert Givan;Thomas Dean
#t 1997
#c 11
#% 31484
#% 115513
#% 131877
#% 145388
#% 167629
#% 1290041
#% 1478746
#% 1650710
#! Propositional STRIPS planning problems can be viewed as finite state automata (FSAs) represented in a factored form. Automaton minimization is a well-known technique for reducing the size of an explicit FSA. Recent work in computer-aided verification on model checking has extended this technique to provide automaton minimization algorithms for factored FSAs. In this paper, we consider the relationship between STRIPS problem-solving techniques such as regression and the recently developed automaton minimization techniques for factored FSAs. We show that regression computes a partial and approximate minimized form of the FSA corresponding to the STRIPS problem. We then define a systematic form of regression which computes a partial but exact minimized form of the associated FSA. We also relate minimization to methods for performing reachability analysis to detect irrelevant fluents. Finally, we show that exact computation of the minimized automaton is NP-complete under the assumption that this automaton is polynomial in size.

#index 1271884
#* Automatic SAT-compilation of planning problems
#@ Michael D. Ernst;Todd D. Millstein;Daniel S. Weld
#t 1997
#c 11
#% 131357
#% 1290109
#% 1476298
#% 1478779
#! Recent work by Kautz et al., provides tantalizing evidence that large, classical planning problems may be efficiently solved by translating them into propositional satisfiability problems, using stochastic search techniques, and translating the resulting truth assignments back into plans for the original problems. We explore the space of such transformations, providing a simple framework that generates eight major encodings (generated by selecting one of four action representations and one of two frame axioms) and a number of subsidiary ones. We describe a fully-implemented compiler that can generate each of these encodings, and we test the compiler on a suite of STRIPS planning problems in order to determine which encodings have the best properties.

#index 1271885
#* A reactive planner for a model-based executive
#@ Brian C. Williams;P. Pandurang Nayak
#t 1997
#c 11
#% 23012
#% 241013
#% 1476265
#% 1476298
#! A new generation of reactive, model-based executives are emerging that make extensive use of componentbased declarative models to analyze anomalous situations and generate novel sequences for the internal control of complex autonomous systems. Burton, a generative, model-based planner offers a core element that bridges the gap between current and target states within the reactive loop. Burton is a sound, complete, reactive planner that generates a single control action of a valid plan in average case constant time, and compensates for anomalies at every step. Burton will not generate irreversible, potentially damaging sequences, except to effect repairs. We present model compilation, causal analysis, and online policy construction methods that are key to Burton's performance.

#index 1271886
#* Modeling command entities
#@ Michael D. Howard
#t 1997
#c 11
#% 23011
#% 59947
#% 76462
#% 181632
#% 182491
#% 189698
#% 557050
#% 1290103
#! A Command Entity (CE) is a goal-oriented intelligent agent specifically designed to command and control other agents. The CE niche, most often a military battlefield, is a complex, dynamic, adversarial environment in which a CE must balance the needs for thorough planning with the need for quick reactions to changing conditions. We describe the requirements of this environment, and how it constrains the design of CEs. Examples from several CE designs are used. The paper concentrates on the areas of planning, knowledge and teamwork.

#index 1271887
#* Vision-motion planning of a mobile robot considering vision uncertainty and planning cost
#@ Jun Miura;Yoshiaki Shirai
#t 1997
#c 11
#% 85070
#% 110379
#% 174102
#! This paper proposes a planning method for a vision-guided mobile robot under vision uncertainty and limited computational resources. The method considers the following two tradeoffs: (1) granularity in approximating a probabilistic distribution vs. plan quality, and (2) search depth vs. plan quality. The first tradeoff is managed by predicting the plan quality for a granularity using a learned relationship between them, and by adaptively selecting the best granularity. The second trade-off is managed by formulating the planning process as a search in the space of feasible plans, and by appropriately limiting the search considering the merit of each step of the search. Simulation results and experiments using a real robot show the feasibility of the method.

#index 1271888
#* Handling duration uncertainty in meta-level control of progressive processing
#@ Abdel-Illah Mouaddib;Shlomo Zilberstein
#t 1997
#c 11
#% 74395
#% 91210
#% 159239
#% 172505
#% 567474
#% 1275327
#% 1290101
#% 1476303
#! Progressive processing is a resource-bounded reasoning technique that allows a system to incrementally construct a solution to a problem using a hierarchy of processing levels. This paper focuses on the problem of meta-level control of progressive processing in domains characterized by rapid change and high level of duration uncertainty. We show that progressive processing facilitates efficient run-time monitoring and meta-level control. Our solution is based on an incremental scheduler that can handle duration uncertainty by dynamically revising the schedule during execution time based on run-time information. We also show that a probabilistic representation of duration uncertainty reduces the frequency of schedule revisions and thus improves the performance of the system. Finally, an experimental evaluation shows the contributions of this approach and its suitability for a data transmission application.

#index 1271889
#* Adaptive goal recognition
#@ Neal Lesh
#t 1997
#c 11
#% 21145
#% 31919
#% 159114
#% 242310
#% 748860
#% 1290117
#% 1650681
#! Because observing the same actions can warrant different conclusions depending on who executed the actions, a goal recognizer that works well on one person might not work well on another. Two problems that arise in providing user-specific recognition are how to consider the vast number of possible adaptations that might be made to the goal recognizer and how to evaluate a particular set of adaptations. For the first problem, we evaluate the use of hillclimbing to search the space of all combinations of an input set of adaptations. For the second problem, we present an algorithm that estimates the accuracy and coverage of a recognizer on a set of action sequences the individual has recently executed. We use these techniques to construct Adapt, a recognizer-independent unsupervised-learning algorithm for adapting a recognizer to a person's idiosyncratic behaviors. Our experiments in two domains show that applying Adapt to the BOCE recognizer can improve its performance by a factor of two to three.

#index 1271890
#* Reasoning about plans
#@ Witold Lukaszewicz;Ewa Madalinska-Bugaj
#t 1997
#c 11
#% 36565
#% 68059
#% 95320
#% 183459
#% 384051
#% 539320
#% 539353
#% 539467
#% 1290148
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271891
#* Reasoning about concurrent execution, prioritized interrupts, and exogenous actions in the situation calculus
#@ Giuseppe De Giacomo;Yves Lesperance;Hector J. Levesque
#t 1997
#c 11
#% 1791
#% 84010
#% 117869
#% 167161
#% 214385
#% 215674
#% 369768
#% 1499563
#! As an alternative to planning, an approach to highlevel agent control based on concurrent program execution is considered. A formal definition in the situation calculus of such a programming language is presented and illustrated with a detailed example. The language includes facilities for prioritizing the concurrent execution, interrupting the execution when certain conditions become true, and dealing with exogenous actions. The language differs from other procedural formalisms for concurrency in that the initial state can be incompletely specified and the primitive actions can be user-defined by axioms in the situation calculus.

#index 1271892
#* Learning to improve both efficiency and quality of planning
#@ Tara A. Estlin;Raymond J. Mooney
#t 1997
#c 11
#% 2194
#% 65441
#% 90056
#% 114353
#% 131557
#% 145388
#% 154075
#% 170413
#% 215888
#% 216992
#% 449508
#% 449587
#% 451031
#% 647206
#% 679780
#% 1499590
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271893
#* Robust periodic planning and execution for autonomous spacecraft
#@ Barney Pell;Erann Gat;Ron Keesing;Nicola Muscettola;Ben Smith
#t 1997
#c 11
#% 108751
#% 109935
#% 137994
#% 179961
#% 181632
#% 194654
#% 241013
#% 1272287
#% 1476265
#! The New Millennium Remote Agent (NMRA) will be the first on-board AI system to control an actual spacecraft. The spacecraft domain raises a number of challenges for planning and execution, ranging from extended agency and long-term planning to dynamic recoveries and robust concurrent execution, all in the presence of tight real-time deadlines, changing goals, scarce resource constraints, and a wide variety of possible failures. NMRA is one of the first systems to integrate closed-loop planning and execution of concurrent temporal plans. It is also the first autonomous system that will be able to achieve a sustained, multi-stage, multiyear mission without communication or guidance from earth.

#index 1271894
#* System assistance in structured domain model development
#@ Susanne Biundo;Werner Stephan
#t 1997
#c 11
#% 215892
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271895
#* Par-KAP: a knowledge acquisition tool for building practical planning systems
#@ Leliane Nunes De Barros;James Hendler;V. Richard Benjamins
#t 1997
#c 11
#% 21145
#% 84384
#% 170808
#% 182494
#% 360013
#% 362942
#% 395156
#% 444996
#% 459617
#! Recently, attention has been focused on providing Knowledge Acquisition (KA) support for building practical planning systems. Such support is needed to guide a knowledge engineer in selecting planning methods, as well as for building and validating the planning knowledge-base for a given practical domain. Following current practice in knowledge acquisition, developing KA tools for planning requires that a number of planning knowledge components are made explicit. This includes explicating (i) a planning domain ontology, (ii) a library of problem-solving methods (PSMs) used in planning, and (iii) a set of domain requirements that are used to select a suitable PSM. In this paper, we summarize the planning knowledge components which we have identified in previous work, and, based on these, present an implementation (Par-KAP) that can exploit these models to aid knowledge engineers in constructing practical planning systems.

#index 1271896
#* Combining local search and look-ahead for scheduling and constraint satisfaction problems
#@ Andrea Schaerf
#t 1997
#c 11
#% 119087
#% 126390
#% 160221
#% 176413
#% 442898
#% 445042
#% 1275301
#% 1499502
#% 1499520
#% 1499521
#! We propose a solution technique for scheduling and constraint satisfaction problems that combines backtracking-free constructive methods and local search techniques. Our technique incrementally constructs the solution, performing a local search on partial solutions each time the construction reaches a dead-end. Local search on the space of partial solutions is guided by a cost function based on three components: the distance to feasibility of the partial solution, a look-ahead factor, and (for optimization problems) a lower bound of the objective function. In order to improve search effectiveness, we make use of an adaptive relaxation of constraints and an interleaving of different lookahead factors. The new technique has been successfully experimented on two real-life problems: university course scheduling and sport tournament scheduling.

#index 1271897
#* Automatic generation of heuristics for scheduling
#@ Robert A. Morris;John L. Bresina;Stuart M. Rodgers
#t 1997
#c 11
#% 4275
#% 1272289
#% 1290102
#% 1499506
#! This paper presents a technique, called GENH, that automatically generates search heuristics for scheduling problems. The impetus for developing this technique is the growing consensus that heuristics encode advice that is, at best, useful in solving most, or typical, problem instances, and, at worst, useful in solving only a narrowly defined set of instances. In either case, heuristic problem solvers, to be broadly applicable, should have a means of automatically adjusting to the idiosyncrasies of each problem instance. GENH generates a search heuristic for a given problem instance by hillclimbing in the space of possible multiattribute heuristics, where the evaluation of a candidate heuristic is based on the quality of the solution found under its guidance. We present empirical results obtained by applying GENH to the real world problem of telescope observation scheduling. These results demonstrate that GENH is a simple and effective way of improving the performance of an heuristic scheduler.

#index 1271898
#* Development of iterative real-time scheduler to planner feedback
#@ Charles B. McVey;Ella M. Atkins;Edmund H. Durfee;Kang G. Shin
#t 1997
#c 11
#% 67498
#% 181338
#% 191678
#% 677158
#% 1650759
#! Planning for real-time applications involves decisions not only about what actions to take in what states to progress toward achieving goals (the traditional decision problem faced by AI planning systems), but also about how to realize those actions within hard real-time deadlines given the inherent limitations of an execution platform. Determining how to arrange actions in a sequence such that timely execution is guaranteed within constraints is a manifestation of the scheduling problem. All cases of the scheduling problem in any domain of nontrivial complexity are difficult to solve (NP-Hard). To more efficiently solve the real-time plan scheduling problem, we propose and analyze an iterative feedback/constraint relaxation method in which a scheduler and planner iteratively interact to efficiently develop a well-utilized schedule which includes as many planned actions as possible. This method has been successfully implemented within the Cooperative Intelligent Real-time Control Architecture (CIRCA).

#index 1271899
#* Object identification in a Bayesian context
#@ Timothy Huang;Stuart Russell
#t 1997
#c 11
#% 32357
#% 156131
#% 526985
#! Object identification--the task of deciding that two observed objects are in fact one and the same object--is a fundamental requirement for any situated agent that reasons about individuals. Object identity, as represented by the equality operator between two terms in predicate calculus, is essentially a first-order concept. Raw sensory observations, on the other hand, are essentially propositional-- especially when formulated as evidence in standard probability theory. This paper describes patterns of reasoning that allow identity sentences to be grounded in sensory observations, thereby bridging the gap. We begin by defining a physical event space over which probabilities are defined. We then introduce an identity criterion, which selects those events that correspond to identity between observed objects. From this, we are able to compute the probability that any two objects are the same, given a stream of observations of many objects. We show that the appearance probability, which defines how an object can be expected to appear at subsequent observations given its current appearance, is a natural model for this type of reasoning. We apply the theory to the task of recognizing cars observed by cameras at widely separated sites in a freeway network, with new heuristics to handle the inevitable complexity of matching large numbers of objects and with online learning of appearance probability models. Despite extremely noisy observations, we are able to achieve high levels of performance.

#index 1271900
#* Probabilistic partial evaluation: exploiting rule structure in probabilistic inference
#@ David Poole
#t 1997
#c 11
#% 44876
#% 105240
#% 147677
#% 1272302
#% 1290041
#% 1650763
#% 1650767
#% 1650778
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271901
#* Space-efficient inference in dynamic probabilistic networks
#@ John Binder;Kevin Murphy;Stuart Russell
#t 1997
#c 11
#% 75936
#% 128629
#% 174161
#% 185079
#% 1290046
#% 1290139
#% 1650756
#! Dynamic probabilistic networks (DPNs) are a useful tool for modeling complex stochastic processes. The simplest inference task in DPNs is monitoring- that is, computing a posterior distribution for the state variables at each time step given all observations up to that time. Recursive, constant-space algorithms are well-known for monitoring in DPNs and other models. This paper is concerned with hindsight -that is, computing a posterior distribution given both past and future observations. Hindsight is an essential subtask of learning DPN models from data. Existing algorithms for hindsight in DPNs use O(SN) space and time, where N is the total length of the observation sequence and S is the state space size for each time step. They are therefore impractical for hindsight in complex models with long observation sequences. This paper presents an O(S log N) space, O(SN log N) time hindsight algorithm. We demonstrates the effectiveness of the algorithm in two real-world DPN learning problems. We also discuss the possibility of an O(S)-space, O(SiV)-time algorithm.

#index 1271902
#* Mini-buckets: a general scheme for generating approximations in automated reasoning
#@ Rina Dechter
#t 1997
#c 11
#% 241
#% 1675
#% 36814
#% 119308
#% 157433
#% 179784
#% 288165
#% 534182
#% 1272302
#% 1650778
#! The class of algorithms for approximating reasoning tasks presented in this paper is based on approximating the general bucket elimination framework. The algorithms have adjustable levels of accuracy and efficiency, and they can be applied uniformly across many areas and problem tasks. We introduce these algorithms in the context of combinatorial optimization and probabilistic inference.

#index 1271903
#* A study of causal discovery with weak links and small samples
#@ Honghua Dai;Kevin Korb;Chris Wallace;Xindong Wu
#t 1997
#c 11
#% 44876
#% 101217
#% 174161
#% 197387
#% 360087
#% 527830
#% 1650638
#% 1650659
#! Weak causal relationships and small sample size pose two significant difficulties to the automatic discovery of causal models from observational data. This paper examines the influence of weak causal links and varying sample sizes on the discovery of causal models. The experimental results illustrate the effect of larger sample sizes for discovering causal models reliably and the relevance of the strength of causal links and the complexity of the original causal model. We present indicative evidence of the superior robustness of MML (Minimum Message Length) methods to standard significance tests in the recovery of causal links. The comparative results show that the MML-CI (the MML Causal Inducer) causal discovery system finds better models than TETRAD II given small samples from linear causal models. The experimental results also reveal that MML-CI finds weak links with smaller sample sizes than can TETRAD II.

#index 1271904
#* ILP with noise and fixed example size: a Bayesian approach
#@ Eric McCreath;Arun Sharma
#t 1997
#c 11
#% 40096
#% 449508
#% 451057
#% 550254
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271905
#* Learning probabilities for noisy first-order rules
#@ Daphne Roller;Avi Pfeffer
#t 1997
#c 11
#% 44876
#% 89958
#% 103309
#% 147677
#% 185079
#% 1650675
#% 1650767
#% 1650783
#! First-order logic is the traditional basis for knowledge representation languages. However, its applicability to many real-world tasks is limited by its inability to represent uncertainty. Bayesian belief networks, on the other hand, are inadequate for complex KR tasks due to the limited expressivity of the underlying (prepositional) language. The need to incorporate uncertainty into an expressive language has led to a resurgence of work on first-order probabilistic Logic. This paper addresses one of the main objections to the incorporation of probabilities into the language: "Where do the numbers come from?" We present an approach that takes a knowledge base in an expressive rule-based first-order language, and leams the probabilistic parameters associated with those rules from data cases. Our approach, which is based on algorithms for learning in traditional Bayesian networks, can handle data cases where many of the relevant aspects of the situation are unobserved. It is also capable of utilizing a rich variety of data cases, including instances with varying causal structure, and even involving a varying number of individuals. These features allow the approach to be used for a wide range of tasks, such as learning genetic propagation models or learning first-order STRIPS planning operators with uncertain effects.

#index 1271906
#* A symmetric view of utilities and probabilities
#@ Yoav Shoham
#t 1997
#c 11
#% 74817
#% 1650788
#! Motivated by the need to reason about utilities, and inspired by the success of bayesian networks in representing and reasoning about probabilities, we introduce the notion of utility distributions, in which utilities have the structure of probabilities. We furthermore define the notion of a bi-distribution, a structure that includes in a symmetric fashion both a probability distribution and autility distribution. We give several examples of bi-distributions. We also show that every state space with standard probability distribution and utility function can be embedded in a bi-distribution, and provide bounds on the size requirements of this bi-distribution. Finally, we suggest a reinterpretation of the von-Neumann and Morgenstern theorem in light of this new model.

#index 1271907
#* PRISM: a language for symbolic-statistical modeling
#@ Taisuke Sato;Yoshitaka Kameya
#t 1997
#c 11
#% 44876
#% 92776
#% 144840
#% 147677
#% 172036
#% 363592
#% 443631
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271908
#* Multi-robot exploration of an unknown environment, efficiently reducing the odometry error
#@ Ioannis M. Rekleitis;Gregory Dudek;Evangelos E. Milios
#t 1997
#c 11
#% 2115
#% 34601
#% 39652
#% 184278
#% 634206
#% 1081023
#! This paper deals with the intelligent exploration of an unknown environment by autonomous robots. In particular, we present an algorithm and associated analysis for collaborative exploration using two mobile robots. Our approach is based on robots with range sensors limited by distance. By appropriate behavioural strategies, we show that odometry (motion) errors that would normally present problems for mapping can be severely reduced. Our analysis includes polynomial complexity bounds and a discussion of possible heuristics.

#index 1271909
#* Active mobile robot localization
#@ Wolfram Burgard;Dieter Fox;Sebastian Thrun
#t 1997
#c 11
#% 39654
#% 82083
#% 263035
#% 380686
#% 407995
#% 646959
#% 1081247
#% 1290038
#% 1476254
#% 1476261
#% 1650672
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271910
#* Reactive combination of belief over time using direct perception
#@ Robin R. Murphy;Dale K. Hawkins;Marcel J. Schoppers
#t 1997
#c 11
#% 10024
#% 75936
#% 101255
#% 103309
#% 128612
#! One issue for autonomous mobile robots operating in unknown, or partially known, domains is how to handle uncertainty in their sensor observations over time. Methods such as probablistic belief networks and survivor functions are generally unsatisfactory because they require explicit models of the robot's interactions with its environment, including possible contravening events. This information is difficult to obtain, and is philosophically incompatible with reactive behaviors. This paper presents an approach which eliminates the need for explicit models and reasoning; instead, it relies solely on directly perceivable attributes of the robot, object, and environment. The attributes qualitatively rate whether the robot's current observations are from an inherently more informed state than previous readings (e.g., from a better viewpoint). Observations from more informed states have different rates for the accrual and attrition of belief than those taken from less informed states. This paper describes the implementation, focusing on how the information state is computed using fuzzy logic, and how the state dynamically adapts a variation of Dempster's rule to generate the total belief. Data from a mobile robot tracking an unknown object demonstrates that the reactive computation of belief over time performs well for six canonical accrual and attrition cases.

#index 1271911
#* Scaling the dynamic approach to autonomous path planning: planning horizon dynamics
#@ Edward W. Large;Henrik I. Christensen;Ruzena Bajcsy
#t 1997
#c 11
#% 4216
#% 367254
#% 1042865
#! In the dynamical systems approach to robot path planning both sensed and remembered information contribute to shape a nonlinear vector field that governs the behavior of an autonomous agent. Such systems perform well with partial knowledge of the environment and in dynamically changing environments. Nevertheless, it is a local heuristic approach to path planning, and it is not guaranteed to find existing paths. We describe a method of adjusting the spatial resolution of the planner using a dynamical system that operates at a faster time scale than the planning dynamics. This improves the system's ability to utilize both sensed and remembered information, and to solve a larger range of problems without resorting to global path planning.

#index 1271912
#* Learning to coordinate controllers-reinforcement learning on a control basis
#@ Manfred Huber;Roderic A. Grupen
#t 1997
#c 11
#% 92070
#% 120808
#% 446005
#% 677083
#% 677685
#% 1818930
#! Autonomous robot systems operating in an uncertain environment have to be reactive and adaptive in order to cope with changing environment conditions and task requirements. To achieve this, the hybrid control architecture presented in this paper uses reinforcement learning on top of a Discrete Event Dynamic System (DEDS) framework to learn to supervise a set of basis controllers in order to achieve a given task. The use of an abstract system model in the automatically derived supervisor reduces the complexity of the learning problem. In addition, safety constraints may be imposed a priori, such that the system learns on-line in a single trial without the need for an outside teacher. To demonstrate the applicability of the approach, the architecture is used to learn a turning gait on a four legged robot platform.

#index 1271913
#* Situated actions and cognition
#@ Jacques Penders;Peter J. Braspenning
#t 1997
#c 11
#% 4216
#% 4332
#! The paper addresses the concept of cognition starting from the role of a sensor basis in the design of robots. The field of robotics forces the discussion to be pragmatic which is considered to be advantageous. In addition, we introduce the notion of cognitive basis in order to discuss the cognitive abilities of an artificial creature. As cognition cannot be fully separated from action and acting, we present finally the notion of motor-schema basis. This basis involves actions and acting as integral parts of cognition.

#index 1271914
#* Interleaved depth-first search
#@ Pedro Meseguer
#t 1997
#c 11
#% 444270
#% 534311
#% 1275306
#% 1499508
#! In tree search, depth-first search (DFS) often uses ordering successor heuristics. If the heuristic makes a mistake ordering a bad successor (without goals in its subtree) before good ones (with goals in their subtrees), DFS has to unsuccessfully traverse the whole bad subtree before finding a goal. To prevent this useless work, we present a new strategy called interleaved depthfirst search (IDFS), which searches depth-first several subtrees -- called active -- in parallel. IDFS assumes a single processor on which it interleaves DFS on active subtrees. When IDFS finds a mistake, it traverses partially the bad subtree. IDFS does not reexpand nodes and uses a memory amount linear in search depth (with a bounded number of active subtrees). IDFS outperforms DFS if the heuristic improves from the first to the second tree level. Experimental results on hard solvable problems confirm the practical validity of IDFS.

#index 1271915
#* Depth-bounded discrepancy search
#@ Toby Walsh
#t 1997
#c 11
#% 2194
#% 120809
#% 137995
#% 175378
#% 179960
#% 198950
#% 1275306
#% 1275311
#% 1499508
#! Many search trees are impractically large to explore exhaustively. Recently, techniques like limited discrepancy search have been proposed for improving the chance of finding a goal in a limited amount of search. Depth-bounded discrepancy search offers such a hope. The motivation behind depth-bounded discrepancy search is that branching heuristics are more likely to be wrong at the top of the tree than at the bottom. We therefore combine one of the best features of limited discrepancy search-the ability to undo early mistakes-with the completeness of iterative deepening search. We show theoretically and experimentally that this novel combination outperforms existing techniques.

#index 1271916
#* From approximate to optimal solutions: constructing pruning and propagation rules
#@ Ian P. Gent;Toby Walsh
#t 1997
#c 11
#% 1019
#% 180109
#% 288165
#% 408396
#% 693451
#% 1275261
#% 1499508
#! At the heart of many optimization procedures are powerful pruning and propagation rules. This paper presents a case study in the construction of such rules. We develop a new algorithm, Complete Decreasing Best Fit, that finds the optimal packing of objects into bins. The algorithm use a branching rule based on the well known Decreasing Best Fit approximation algorithm. In addition, it includes a powerful pruning rule derived from a bound on the solution to the remaining subproblem. The bound is constructed by using modular arithmetic to decompose the numerical constraints. We show that the pruning rule adds essentially a constant factor overhead to runtime, whilst reducing search significantly. On the hardest problems, runtime can be reduced by an order of magnitude. Finally we demonstrate how propagation rules can be built by adding lookahead to pruning rules. This general approach -optimization procedures built from branching rules based on good approximation algorithms, and pruning and propagation rules derived from bounds on the remaining subproblem-may be effective on other NP-complete problems.

#index 1271917
#* An approximate 0-1 edge-labeling algorithm for constrained bin-packing problem
#@ Ho Soo Lee;Mark Trumbo
#t 1997
#c 11
#% 25469
#% 25470
#% 86465
#% 408396
#% 936550
#! This paper describes a constrained bin-packing problem (CBPP) and an approximate, anytime algorithm for solutions. A CBPP is a constrained version of the bin-packing problem, in which a set of items allocated to a bin are ordered in a way to satisfy constraints defined on them and achieve near-optimality. The algorithm for CBPP uses a heuristic search for labeling edges with a binary value, together with a beam search and constraint propagation. Some experimental results are provided. This algorithm has been successfully applied to industrial-scale scheduling problems.

#index 1271918
#* Applications of the situation calculus to formalizing control-and strategic information: the prolog cut operator
#@ Fangzhen Lin
#t 1997
#c 11
#% 117869
#% 140412
#% 544331
#! We argue that the situation calculus is a natural formalism for representing and reasoning about control and strategic information. As a case study, in this paper we provide a situation calculus semantics for the Prolog cut operator, the central search control operator in Prolog. We show that our semantics is well-behaved when the programs are properly stastified. We also show that according to this semantics, the conventional implementation of the negationas-failure operator using cut is provably correct with respect to the stable model semantics.

#index 1271919
#* Reasoning by regression: pre-and postdiction procedures for logics of action and change with nondeterminism
#@ Marcus Bjareland;Lars Karlsson
#t 1997
#c 11
#% 34011
#% 68059
#% 117869
#% 183459
#% 1290148
#% 1499565
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271920
#* Change, change, change: three approaches
#@ Tom Costello
#t 1997
#c 11
#% 3035
#% 181391
#% 184795
#% 242576
#% 1290151
#% 1478798
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271921
#* Reasoning with incomplete initial information and nondeterminism in situation calculus
#@ Lars Karlsson
#t 1997
#c 11
#% 7047
#% 36550
#% 100129
#% 117869
#% 124601
#% 1068305
#% 1476290
#% 1499565
#! Situation Calculus is arguably the most widely studied and used formalism for reasoning about action and change. The main reason for its popularity is the ability to reason about different action sequences as explicit objects. In particular, planning can be formulated as an existence problem. This paper shows how these properties break down when incomplete information about the initial state and nondeterministic action effects are introduced, basically due to the fact that this incompleteness is not adequately manifested on the object level. A version of Situation Calculus is presented which adequately models the alternative ways the world can develop relative to a choice of actions.

#index 1271922
#* Defeasible specifications in action theories
#@ Chitta Baral;Jorge Lobo
#t 1997
#c 11
#% 117869
#% 1290157
#% 1476295
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271923
#* Reasoning about action in polynomial time
#@ Thomas Drakengren;Marcus Bjareland
#t 1997
#c 11
#% 179952
#% 183459
#% 1080946
#% 1272313
#% 1290150
#% 1476304
#% 1499524
#! Although many formalisms for reasoning about action exist, surprisingly few approaches have taken computational complexity into consideration. The contributions of this paper are the following: a temporal logic with a restriction for which deciding satisfiability is tractable, a tractable extension for reasoning about action, and NP-completeness results for the unrestricted problems. Many interesting reasoning problems can be modelled, involving nondeterminism, concurrency and memory of actions. The reasoning process is proved to be sound and complete.

#index 1271924
#* Qualitative temporal reasoning with points and durations
#@ Isabel Navarrete;Roque Marin
#t 1997
#c 11
#% 21136
#% 107137
#% 126395
#% 137043
#% 319244
#% 408396
#! We present here a qualitative temporal reasoning system that takes both points and durations as primitive objects and allows relative and indefinite information. We formaly define a point duration network, as a structure formed by two point algebra (PA) networks separately but not independently, since ternary constraints are introduced for relating point and duration information. We adapt some of the concepts and reasoning techniques developed for the point algebra networks, such as consistency and minimality. We prove that the problem of determining consistency in a point duration network is NP-complete. A simpler and polynomial-time decision problem is introduced for a restricted kind of point duration networks. Finally we suggest how to determine consistency and find minimal point duration network in the general case.

#index 1271925
#* On finding a solution in temporal constraint satisfaction problems
#@ Alfonso Gerevini;Matteo Cristani
#t 1997
#c 11
#% 70370
#% 107137
#% 181229
#% 184792
#% 288927
#% 319244
#% 568137
#% 1499525
#! Computing a consistent interpretation of the variables involved in a set of temporal constraints is an important task for many areas of AI requiring temporal reasoning. We focus on the important classes of the qualitative relations in Nebel and Biirckert's ORD-Horn algebra, and of the metric constraints forming a STP, possibly augmented w i th inequations. For these tractable classes we present three new algorithms for solving the problem of finding a solution, and an efficient algorithm for determining the consistency of a STP augmented with in equations.

#index 1271926
#* Towards a complete classification of tractability in Allen's algebra
#@ Thomas Drakengren;Peter Jonsson
#t 1997
#c 11
#% 84513
#% 103864
#% 107137
#% 137041
#% 152555
#% 181229
#% 183459
#% 319244
#% 1272310
#% 1272313
#% 1476304
#% 1499524
#! We characterise the set of subalgebras of Allen's algebra which have a tractable satisfiability problem, and in addition contain certain basic relations. The conclusion is that no tractable subalgebra that is not known in the literature can contain more than the three basic relations (≡), (b) and (b-), where b ∈ {d,o,s,f}. This means that concerning algebras for specifying complete knowledge about temporal information, there is no hope of finding yet unknown classes with much expressivity. Furthermore, we show that there are exactly two maximal tractable algebras which contain the relation (). Both of these algebras can express the notion of sequentially; thus we have a complete characterisation of tractable inference using that notion.

#index 1271927
#* Comparing random starts local search with key feature matching
#@ J. Ross Beveridge;Christopher R. Graves;Jim Steinborn
#t 1997
#c 11
#% 3478
#% 28302
#% 90846
#% 98397
#% 146667
#% 236293
#% 372042
#% 634574
#! A new variant on key feature object recognition is presented. It is applied to optimal matching problems involving 2D line segment models and data. A single criterion function ranks both key features and complete object model matches. Empirical studies suggest that the key feature algorithm has run times which are dramatically less than a more general random starts local search algorithm. However, they also show the key feature algorithm to be brittle: failing on some apparently simple problems, while local search appears to be robust.

#index 1271928
#* Chain of circles for matching and recognition of planar shapes
#@ Jae-Moon Chung;Noboru Ohnishi
#t 1997
#c 11
#% 8175
#% 15504
#% 36778
#% 109388
#% 149102
#% 183534
#% 183546
#% 443711
#% 443730
#% 625139
#! Based on a resulting medial axis configuration of planar shapes, a new shape descriptor called the chain of circles (CoCs) is defined herein. The CoCs representation is directly extracted along the boundary contour of silhouette images, and can be controlled in a hierarchical manner which appeals to intuition. The coarsetofine hierarchy makes matching of shapes possible with less computational complexity and greater robustness to noise, spatial quantization and local deformation of shapes. The dissimilarity vector calculated in the matching, which is executed via the dynamic programming technique, may be used to facilitate the searching process in the digital library. The capability of the proposed method is shown by matching several complex shapes such as map images.

#index 1271929
#* Name-it: naming and detecting faces in video by the integration of image and natural language processing
#@ Shin'ichi Satoh;Yuichi Nakamura;Takeo Kanade
#t 1997
#c 11
#% 592110
#% 1022958
#! We have been developing Name-It, a system that associates faces and names in news videos. First, as the only knowledge source, the system is given news videos which include image sequences and transcripts obtained from audio tracks or closed caption texts. The system can then either infer the name of a given face and output the name candidates, or can locate the faces in news videos by a name. To accomplish this task, the system extracts faces from image sequences and names from transcripts, both of which might correspond to key persons in news topics. The proposed system takes full advantage of advanced image and natural language processing. The image processing contributes to the extraction of face sequences which provide rich information for face-name association. The processing also helps to select the best frontal view of a face in a face sequence to enhance the face identification which is required for the processing. On the other hand, the natural language processing effectively extracts names by using lexical/grammatical analysis and knowledge of the news video topics structure. The success of our experiments demonstrates the benefits of the advanced image and natural language processing methods and their incorporation.

#index 1271930
#* Neural network based photometric stereo using illumination planning
#@ Yuji Iwahori;Wataru Kato;Md. Shoaib Bhuiyan;Robert J. Woodham;Naohiro Ishii
#t 1997
#c 11
#% 122110
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271931
#* A general expression of the fundamental matrix for both perspective and affine cameras
#@ Zhengyou Zhang;Gang Xu
#t 1997
#c 11
#% 109393
#% 137661
#% 154449
#% 170755
#% 180659
#% 180660
#% 198350
#% 402952
#% 410837
#% 443818
#% 457339
#% 457375
#! This paper addresses the recovery of structure and motion from two uncalibrated images of a scene under full perspective or under affine projection. Epipolar geometry, projective reconstruction, and affine reconstruction are elaborated in a way such that everyone having knowledge of linear algebra can understand the discussion without difficulty. A general expression of the fundamental matrix is derived which is valid for any projection model without lens distortion (including full perspective and affine camera). A new technique for affine reconstruction from two affine images is developed, which consists in first estimating the affine epipolar geometry and then performing a triangulation for each point match with respect to an implicit common affine basis. This technique is very efficient.

#index 1271932
#* The next big thing: position statements
#@ Munindar P. Singh;Daniel G. Bobrow;Michael N. Huhns;Margaret King;Hiroaki Kitano;Ray Reiter
#t 1997
#c 11
#% 68239
#% 117869
#% 122904
#% 135520
#% 136356
#% 183459
#% 212606
#% 215532
#% 216292
#% 236024
#% 250867
#% 362927
#% 403195
#% 434076
#% 437558
#% 467485
#% 518937
#% 534312
#% 701158
#% 742402
#% 1271891
#% 1476322
#% 1793201
#! This panel is a celebration of artificial intelligence (AI). Basing its claims to interest on the past accomplishments of AI, it highlights some of the new exciting concepts and technologies that compete for the title The Next Big Thing.

#index 1271933
#* Robust real-time face tracking and gesture recognition
#@ J. Heizmann;A. Zelinsky
#t 1997
#c 11
#% 170561
#% 443672
#% 457645
#% 593492
#% 625115
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271934
#* PAC-personality and cognition: an interactive system for modeling agent scenarios
#@ Lin Padgham;Guy Taylor
#t 1997
#c 11
#% 159119
#% 521360
#! PAC is an interactive system for experimenting with scenarios of agents, where the agents are modelled as having both cognition and personality, as well as a physical realisation. The aim of the system is to provide an environment where scenarios can quickly and easily be built up, varying aspects of agent personality (or emotions) and agent cognition (plans and beliefs). This will allow us to experiment with different combinations of agents in different worlds. We can then investigate the effect of various parameters on emergent behaviour of the agent system.

#index 1271935
#* Modularity in computer assisted reasoning systems
#@ Alessandro Agostini
#t 1997
#c 11
#% 671662

#index 1271936
#* Describing time-varying data
#@ Sarah Boyd
#t 1997
#c 11
#% 217067
#% 1290062

#index 1271937
#* Automation of diagrammatic proofs in mathematics
#@ Mateja Jamnik
#t 1997
#c 11

#index 1271938
#* Toward the automatic discovery of misconceptions
#@ Raymund C. Sison
#t 1997
#c 11
#% 1273714

#index 1271939
#* Control structures for software agents
#@ Hongjun Song
#t 1997
#c 11
#! Control Structure is one of the most important issues which has to be addressed while designing and developing a software agent system. Based on the research and development of several agent systems, this thesis describes new agent architectures and a number of general principles.

#index 1271940
#* Algorithm evolution for signal understanding
#@ Astro Teller
#t 1997
#c 11
#% 240255
#% 243355

#index 1271941
#* The use of neural network approach in financial asset management
#@ Francesco Virili
#t 1997
#c 11
#% 395769

#index 1271942
#* Constrained object hierarchy: an architecture for intelligent systems
#@ Hongxue Wang
#t 1997
#c 11

#index 1271943
#* Let's plan it deductively!
#@ W. Bibel
#t 1997
#c 11
#% 7051
#% 23011
#% 29844
#% 36818
#% 38668
#% 83257
#% 89961
#% 92771
#% 97615
#% 117869
#% 157412
#% 169168
#% 169335
#% 174161
#% 181625
#% 192282
#% 224765
#% 366657
#% 374912
#% 420611
#% 515580
#% 541177
#% 544327
#% 1290109
#% 1476298
#% 1499560
#! The paper describes a transition logic, TL, and a deductive formalism for it. It shows how various important aspects (such as ramification, qualification, specificity, simultaneity, indeterminism etc.) involved in planning can be modelled in TL in a rather natural way. (The deductive formalism for) TL extends the linear connection method proposed earlier by the author by embedding the latter into classical logic, so that classical and resource-sensitive reasoning coexist within TL. The attraction of a logical and deductive approach to planning is emphasised and the state of automated deduction briefly described.

#index 1271944
#* Modeling social action for AI agents
#@ Cristiano Castelfranchi
#t 1997
#c 11
#% 97618
#% 110015
#% 131315
#% 154041
#% 157180
#% 174161
#% 179883
#% 215532
#% 241019
#% 518817
#% 1128793

#index 1271945
#* Vehicles capable of dynamic vision
#@ Ernst D. Dickmanns
#t 1997
#c 11
#% 47659
#% 49723
#% 78916
#% 117663
#% 128201
#% 361283
#% 592255
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271946
#* Remote-brained robots
#@ Masayuki Inaba
#t 1997
#c 11
#% 21063
#% 98060
#% 634307
#% 669154
#! We introduce our research approach to investigating real world intelligence by building 'Remote-Brained Robots'. The key idea is that of interfacing AI systems with real-world behaviors through wireless technology. In this approach the robot system is designed to have the brain and body separate, both conceptually and physically. It allows us to tie AI directly to the world, enabling the verification of high-level AI techniques which could previously only be used in simulation. For robotics research, this approach opens the way to the use of large-scale powerful parallel computers. For AI, this approach allows experiments with realistic agents, an essential step to the application of AI in the real world. In this presentation we introduce the remote-brained approach, describe some remote-brained robots and discuss experiments.

#index 1271947
#* Generating multimedia briefings: language generation in a coordinated multimedia environment
#@ Kathleen R. McKeown
#t 1997
#c 11
#% 91526
#% 109058
#% 111873
#% 144013
#% 194251
#% 194252
#% 198296
#% 217067
#% 219844
#% 232486
#% 742436
#% 748472
#! Communication can be more effective when several media (such as text, speech, or graphics) are integrated and coordinated to present information. This changes the nature of media specific generation (e.g., language generation) which must take into account the multimedia context in which it occurs. In this paper, 1 will present work on coordinating and integrating speech, text, static and animated 3D graphics, and stored images, as part of several systems we have developed at Columbia University. A particular focus of our work has been on the generation of presentations that brief a user on information of interest.

#index 1271948
#* Inheritance comes of age: applying nonmonotonic techniques to problems in industry
#@ Leora Morgenstern
#t 1997
#c 11
#% 3035
#% 18534
#% 22296
#% 36236
#% 36534
#% 68241
#% 73518
#% 77841
#% 108693
#% 120807
#% 145389
#% 167538
#% 251993
#% 366370
#% 367665
#! Nonmonotonic reasoning is virtually absent from industry and has been so since its inception; the result is that the field is becoming marginalized within AI. I argue that this is because researchers in the area focus exclusively on commonsense problems which are irrelevant to industry and because few efficient algorithms and/or tools have been developed. A sensible strategy is thus to focus on industry problems and to develop solutions within tractable subtheories of nonmonotonic logic. I examine one of the few examples of nonmonotonic reasoning in industry -- inheritance of business rules in the medical insurance domain -- and show how the paradigm of inheritance with exceptions can be extended to a broader and more powerful kind of nonmonotonic reasoning. Finally I discuss the underlying lessons that can be generalized to other industry problems.

#index 1271949
#* Machine learning techniques to make computers easier to use
#@ Hiroshi Motoda;Kenichi Yoshida
#t 1997
#c 11
#% 49483
#% 96265
#% 96314
#% 124708
#% 136350
#% 151043
#% 159113
#% 172753
#% 172760
#% 184048
#% 212076
#% 449508
#% 449588
#% 1275346
#% 1275347
#! In order to rank the performance of machine learning algorithms, many researchers conduct experiments on benchmark data sets. Since most learning algorithms have domain-specific parameters, it is a popular custom to adapt these parameters to obtain a ...

#index 1271950
#* The origins of syntax in visually grounded robotic agents
#@ Luc Steels
#t 1997
#c 11
#% 171106
#% 458323
#! The paper proposes a set of principles and a general architecture that may explain how language and meaning may originate and complexify in a group of physically grounded distributed agents. An experimental setup is introduced for concretising and validating specific mechanisms based on these principles. The setup consists of two robotic heads that watch a scene in which a robot moves around in its ecosystem. The first results from experiments showing the emergence of distinctions, of a lexicon, and of primitive syntactic structures are reported.

#index 1271951
#* Numerica: a modeling language for global optimization
#@ Pascal Van Hentenryck
#t 1997
#c 11
#% 1145
#% 54223
#% 68877
#% 218134
#% 224739
#% 225336
#% 257934
#% 836002
#% 1080884

#index 1271952
#* Relationship between natural language processing and AI
#@ Aravind K. Joshi
#t 1997
#c 11
#! The use of constrained formal/computational systems just adequate for modeling various aspects of language-syntax, semantics, pragmatics and discourse, among others-has proved to be not only an effective research strategy but has led to deeper understanding of these aspects, with implications to both machine processing as well as human processing. This approach enables one to distinguish between universal and stipulative constraints. The other approach is to start with the most general and most powerful formal/computational system and use it to model these phenomena, thus making all constraints stipulative, in a sense. The tension between these approaches, together with the increasing use of empirical methods combining structural and statistical information, has made the relationship between natural language processing and AI quite stormy. I will review some of the past and current research following the first approach and also suggest how the stormy relationship could be improved.

#index 1273673
#* Proceedings of the 15th international joint conference on Artifical intelligence - Volume 1
#@ Martha E. Pollack
#t 1997
#c 11

#index 1273674
#* The predictive toxicology evaluation challenge
#@ A. Srinivasan;R. D. King;S. H. Muggleton;M. J. E. Sternberg
#t 1997
#c 11
#% 217072
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular structure to cancerous activity. Vital to this are the rodent carcinogenicity tests conducted within the US National Toxicology Program by the National Institute of Environmental Health Sciences (NIEHS). This has resulted in a large database of compounds classified as carcinogens or otherwise. The Predictive-Toxicology Evaluation project of the NIEHS provides the opportunity to compare carcinogenicity predictions on previously untested chemicals. This presents a formidable challenge for programs concerned with knowledge discovery. Desirable features of this problem are: (1) involvement in genuine scientific discovery; (2) availability of a large database with expert-certified classifications; (3) strong competition from methods used by chemists; and (4) participation in true blind trials, with results available by next IJCAI. We describe the materials and methods constituting this challenge, and provide some initial benchmarks. These show the Inductive Logic Programming tool Progol to be competitive with current state-of-the-art. The challenge described here is aimed at encouraging AI programs to avail themselves the opportunity of contributing to an enterprise with immediate scientific value.

#index 1273675
#* Challenge: what is the impact of Bayesian networks on learning?
#@ Nir Friedman;Moises Goldszmidt;David Heckerman;Stuart Russell
#t 1997
#c 11
#% 44876
#% 80006
#% 129987
#% 130114
#% 130878
#% 132678
#% 183490
#% 185079
#% 246832
#% 476708
#% 1272279
#% 1290046
#% 1476309
#% 1650659
#% 1650684
#% 1650783
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273676
#* Adaptive web sites: an AI challenge
#@ Mike Perkowitz;Oren Etzioni
#t 1997
#c 11
#% 31919
#% 68279
#% 227995
#% 240957
#% 405121
#% 1290117
#! The creation of a complex web site is a thorny problem in user interface design. First, different visitors have distinct goals. Second, even a single visitor may have different needs at different times. Much of the information at the site may also be dynamic or time-dependent. Third, as the site grows and evolves, its original design may no longer be appropriate. Finally, a site may be designed for a particular purpose but used in unexpected ways. Web servers record data about user interactions and accumulate this data over time. We believe that AI techniques can be used to examine user access logs in order to automatically improve the site. We challenge the AI community to create adaptive web sites: sites that automatically improve their organization and presentation based on user access data. Several unrelated research projects in plan recognition, machine learning, knowledge representation, and user modeling have begun to explore aspects of this problem. We hope that posing this challenge explicitly will bring these projects together and stimulate fundamental AI research. Success would have a broad and highly visible impact on the web and the AI community.

#index 1273677
#* The RoboCup synthetic agent challenge 97
#@ Hiroaki Kitano;Milind Tambe;Peter Stone;Manuela Veloso;Silvia Coradeschi;Eiichi Osawa;Hitoshi Matsubara;Itsuki Noda;Minora Asada
#t 1997
#c 11
#% 75896
#% 121991
#% 189698
#% 241027
#% 1499477
#! RoboCup Challenge offers a set of challenges for intelligent agent researchers using a friendly competition in a dynamic, real-time, multiagent domain. While RoboCup in general envisions longer range challenges over the next few decades, RoboCup Challenge presents three specific challenges for the next two years: (i) learning of individual agents and teams; (ii) multi-agent team planning and plan-execution in service of teamwork; and (iii) opponent modeling. RoboCup Challenge provides a novel opportunity for machine learning, planning, and multi-agent researchers it not only supplies a concrete domain to evaluate their techniques, but also challenges researchers to evolve these techniques to face key constraints fundamental to this domain: real-time, uncertainty, and teamwork.

#index 1273678
#* Understanding three simultaneous speeches
#@ Hiroshi G. Okuno;Tomohiro Nakatani;Takeshi Kawabata
#t 1997
#c 11
#% 125036
#% 173497
#% 257158
#% 968594
#% 1275248
#% 1476282
#% 1476322
#! Understanding three simultaneous speeches is proposed as a challenge problem to foster artificial intelligence, speech and sound understanding or recognition, and computational auditory scene analysis research. Automatic speech recognition under noisy environments is attacked by speech enhancement techniques such as noise reduction and speaker adaptation. However, the signal-to-noise ratio of speech in two simultaneous speeches is too poor to apply these techniques. Therefore, novel techniques need to be developed. One candidate is to use speech stream segregation as a front-end of automatic speech recognition systems. Preliminary experiments on understanding two simultaneous speeches show that the proposed challenge problem will be feasible with speech stream segregation. The detailed plan of the research on and benchmark sounds for the proposed challenge problem is also presented.

#index 1273679
#* Distributed vision system: a perceptual information infrastructure for robot navigation
#@ Hiroshi Ishiguro
#t 1997
#c 11
#% 1180146
#% 1476287
#! This paper proposes a Distributed Vision System as a Perceptual Information Infrastructure for robot navigation in a dynamically changing world. The distributed vision system, consisting of vision agents connected with a computer network, monitors the environment, maintains the environment models, and actively provides various information for the robots by organizing communication between the vision agents. In addition to conceptual discussions and fundamental issues, this paper provides a prototype of the distributed vision system for navigating mobile robots.

#index 1273680
#* Challenges in bridging plan synthesis paradigms
#@ Subbarao Kambhampati
#t 1997
#c 11
#% 163715
#% 194651
#% 210195
#% 1290109
#% 1476298
#! In the last three years, several "radically new" and promising approaches have been developed for tackling the plan synthesis problem. Currently, these approaches exist in isolation as there is no coherent explanation of their sources of strength vis a vis the traditional refinement planners. In this paper, I provide a generalized view of refinement planning, that subsumes both traditional and newer approaches to plan synthesis. I will interpret the contributions of the new approaches in terms of a new subclass of refinement planners called "disjunctive planners". This unifying view raises several intriguing possibilities for complementing the strengths of the various approaches. I will identify and pose these as challenges to the planning community.

#index 1273681
#* Ten challenges in propositional reasoning and search
#@ Bart Selman;Henry Kautz;David McAllester
#t 1997
#c 11
#% 41220
#% 131357
#% 160270
#% 179960
#% 210195
#% 288165
#% 1275264
#% 1290109
#% 1476265
#% 1476298
#! The past several years have seen much progress in the area of propositional reasoning and satisfiability testing. There is a growing consensus by researchers on the key technical challenges that need to be addressed in order to maintain this momentum. This paper outlines concrete technical challenges in the core areas of systematic search, stochastic search, problem encodings, and criteria for evaluating progress in this area.

#index 1273682
#* Challenge: how IJCAI 1999 can prove the value of AI by using AI
#@ James Geller
#t 1997
#c 11
#% 363135
#! The challenge formulated in this paper is a direct reaction to the reviewer selection process of IJCAI 1997, which relied on an unintelligent string matching program. We challenge the AI community to implement an intelligent knowledge-based reviewer selection program for IJCAI 1999.

#index 1273683
#* Qualitative relevance and independence: a roadmap
#@ Didier Dubois;Luis Farinas Del Cerro;Andreas Herzig;Henri Prade
#t 1997
#c 11
#% 111942
#% 115327
#% 160378
#% 459569
#% 782308
#% 1650764
#! Several qualitative notions of epistemic dependence between propositions are studied. They are closely related to the ordinal notion of conditional possibility. What this paper proposes is a systematic investigation of how the fact of learning a new piece of evidence individually affects previous beliefs. Namely a new piece of information A can either leave a previous belief untouched, or cancel it from the set of accepted beliefs, or even refute it. On the contrary, A can justify a new belief, not previously held, or fail to justify it. We provide axiomatizations of epistemic independence and relevance and show the close links between qualitative independence and the theory of belief change. It turns out that qualitative independence and AGM belief change operations have the same expressive power. Lastly, it is briefly suggested how qualitative independence can be applied to plausible reasoning.

#index 1273684
#* The complexity of belief update
#@ Paolo Liberatore
#t 1997
#c 11
#% 90860
#% 101922
#% 131559
#% 136678
#% 676271
#% 1290098
#% 1499547
#% 1499549
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273685
#* Anytime belief revision
#@ Mary-Anne Williams
#t 1997
#c 11
#% 100149
#% 131559
#% 160378
#% 167544
#% 521201
#% 782324
#% 1290097
#! Belief Revision is a ubiquitous process underlying many forms of intelligent behavior. The AGM paradigm is a powerful framework for modeling and implementing belief revision systems based on the principle of Minimal Change; it provides a rich and rigorous foundation for computer-based belief revision architectures. Maxi-adjustment is a belief revision strategy for theory bases that can be implemented using a standard theorem prover, and one that has been used successfully for several applications. In this paper we provide an anytime decision procedure for maxi-adjustments, and study its complexity. Furthermore, we outline a set of guidelines that serve as a protomethodology for building belief revision systems employing a maxi-adjustment. The algorithm is under development in the belief revision module of the CIN Project.

#index 1273686
#* Towards generalized rule-based updates
#@ Yan Zhang;Norman Y. Foo
#t 1997
#c 11
#% 173565
#% 499487
#% 1272277
#! Recent work on rule-based updates provided new frameworks for updates in more general knowledge domains [Marek and Truszczriski, 1994; Baral, 1994; Przymusinski and Turner, 1995]. In this paper, we consider a simple generalization of rule-based updates where incomplete knowledge bases are allowed and update rules may contain two types of negations. It turns out that previous methods cannot deal with this generalized rule-based update properly. To overcome the difficulty, we argue that necessary preferences between update rules and inertia rules must be taken into account in update specifications. From this motivation, we propose prioritized logic programs (PLPs) by adding preferences into extended logic programs. [Gelfond and Lifschitz, 1991]. Formal semantics of PLPs is provided in terms of the answer set semantics of extended logic programs. We then show that the procedure of generalized rule-based update can be formalized in the framework of PLPs. The minimal change property of the update is also investigated.

#index 1273687
#* Representation theorems for multiple belief changes
#@ Dongmo Zhang;Shifu Chen;Wujia Zhu;Zhaoqian Chen
#t 1997
#c 11
#% 160378
#% 194987
#% 495494
#% 555518
#% 555526
#% 555527
#% 782324
#! This paper aims to develop further and systemize the theory of multiple belief change based on the previous work on the package contraction, developed by [Fuhrmann and Hansson 1994] and the general belief changes, developed by [Zhang 1996]. Two main representation theorems for general contractions are given, one is based on partial meet models and the other on nice-ordered partition models. An additional principle, called Limit Postulate, for the general belief changes is introduced which specifies properties of infinite belief changes. The results of this paper provides a foundation for investigating the connection between infinite nonmonotonic reasoning and multiple belief revision.

#index 1273688
#* Nonmonotonic reasoning and multiple belief revision
#@ Dongmo Zhang;Shifu Chen;Wujia Zhu;Hongbing Li
#t 1997
#c 11
#% 42003
#% 64371
#% 77841
#% 115327
#% 160378
#% 163719
#% 167537
#% 194987
#% 459669
#% 495653
#% 555427
#% 555518
#% 555526
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273689
#* High performance ATP systems by combining several AI methods
#@ Jorg Denzinger;Marc Fuchs;Matthias Fuchs
#t 1997
#c 11
#% 528879
#% 539339
#% 539465
#% 560754
#% 560913
#% 560928
#% 563684
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273690
#* Equational reasoning using AC constraints
#@ David A. Plaisted;Yunshan Zhu
#t 1997
#c 11
#% 4339
#% 5363
#% 45220
#% 101945
#% 145708
#% 167190
#% 289294
#% 289304
#% 384112
#% 413012
#% 515581
#% 528576
#% 529044
#% 556943
#% 560394
#% 837647
#! Unfailing completion is a commonly used technique for equational reasoning. For equational problems with associative and commutative functions, unfailing completion often generates a large number of rewrite rules. By comparing it with a ground completion procedure, we show that many of the rewrite rules generated are redundant. A set of consistency constraints is formulated to detect redundant rewrite rules. We propose a new completion algorithm, consistent unfailing completion, in which only consistent rewrite rules are used for critical pair generation and rewriting. Our approach does not need to use flattened terms. Thus it avoids the double exponential worst case complexity of AC unification. It also allows the use of more flexible termination orderings. We present some sufficient conditions for detecting inconsistent rewrite rules. The proposed algorithm is implemented in PROLOG.

#index 1273691
#* Strategies in rigid-variable methods
#@ Andrei Voronkov
#t 1997
#c 11
#% 19975
#% 33376
#% 53384
#% 73573
#% 101949
#% 114569
#% 167187
#% 217668
#% 288366
#% 288555
#% 289292
#% 289318
#% 289377
#% 489007
#% 489116
#% 506102
#% 546324
#% 564567
#% 587371
#% 599558
#% 696456
#% 1275271
#! We study complexity of methods using rigid variables, like the method of matings or the tableau method, on a decidable class of predicate calculus with equality. We show some intrinsic complications introduced by rigid variables. We also consider strategies for increasing multiplicity in rigid-variable methods, and formally show that the use of intelligent strategies can result in an essential gain in efficiency.

#index 1273692
#* Tractable cover compilations
#@ Yacine Boufkhad;Eric Gregoire;Pierre Marquis;Bertrand Mazure;Lakhdar Sais
#t 1997
#c 11
#% 90324
#% 154456
#% 172459
#% 204396
#% 216972
#% 289115
#% 1275334
#% 1275335
#% 1499539
#% 1499540
#% 1499541
#! Tractable covers are introduced as a new approach to equivalence-preserving compilation of propositional knowledge bases. First, a general framework is presented. Then, two specific cases are considered. In the first one, partial interpretations are used to shape the knowledge base into tractable formulas from several possible classes. In the second case, they are used to derive renamable Horn formulas. This last case is proved less space-consuming than prime implicants cover compilations for every knowledge base. Finally, experimental results show that the new approaches can prove efficient w.r.t. direct query answering and offer significant time and space savings w.r.t. prime implicants covers.

#index 1273693
#* A four-valued fuzzy propositional logic
#@ Umberto Straccia
#t 1997
#c 11
#% 167544
#% 564584
#! It is generally accepted that knowledge based systems would be smarter and more robust if they can manage inconsistent, incomplete or imprecise knowledge. This paper is about a four-valued fuzzy propositional logic, which is the result of the combination of a four-valued logic and a fuzzy propositional logic. Besides the nice computational properties, the logic enables us also to deal both with inconsistency and imprecise predicates in a simple way.

#index 1273694
#* Autoepistemic description logics
#@ Francesco M. Donini;Daniele Nardi;Riccardo Rosati
#t 1997
#c 11
#% 130784
#% 175359
#% 198463
#% 211584
#% 495675
#% 558406
#% 1478795
#! We present Autoepistemic Description Logics (ADLs), in which the language of Description Logics is augmented with modal operators interpreted according to the nonmonotonic logic MKNF. We provide decision procedures for query answering in two very expressive ADLs. We show their representational features by addressing defaults, integrity constraints, role and concept closure. Hence, ADLs provide a formal characterization of a wide variety of nonmonotonic features commonly available in frame-based systems and needed in the development of practical applications.

#index 1273695
#* Reifying concepts in description logics
#@ Liviu Badea
#t 1997
#c 11
#% 84990
#% 101435
#% 189739
#% 1275330
#! Practical applications of description logics (DLs) in knowledge-based systems have forced us to introduce the following features which are absent from existing DLs: • allowing a concept to be regarded at the same time as an individual (the instance of some other meta-level concept) • allowing an individual to represent a collection (set) of other individuals. The first extension, called concept reification, is more general and thus can cover the second one too. We argue that the absence of these features from existing DLs is an important reason for the lack of a unified approach to description logics and object-oriented databases. We also show that concept reification cannot be dealt with by the standard DL semantics and propose a slightly modified semantics that takes care of the inherent higher-order features of reification in a first-order setting. A sound and complete inference algorithm for checking consistency in reified ACCOE knowledge bases is subsequently put forward.

#index 1273696
#* Circumscribing inconsistency
#@ Philippe Besnard;Torsten H. Schaub
#t 1997
#c 11
#% 57927
#% 66101
#% 67902
#% 90829
#% 121992
#% 196352
#% 217503
#% 442939
#% 495671
#% 503651
#% 637527
#! We present a new logical approach to reasoning from inconsistent information. The idea is to restore modelhood of inconsistent formulas by providing a third truth-value tolerating inconsistency. The novelty of our approach stems first from the restriction of entailment to three-valued models as similar as possible to two-valued models and second from an implication connective providing a notion of restricted monotonicity. After developing the semantics, we present a corresponding proof system that relies on a circumscription schema furnishing the syntactic counterpart of model minimization.

#index 1273697
#* A default interpretation of defeasible network
#@ Xianchang Wang;Jia-Huai You;Li Yan Yuan
#t 1997
#c 11
#% 22296
#% 36540
#% 95247
#% 103705
#% 107149
#% 129971
#% 145389
#% 167538
#% 499491
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273698
#* A cumulative-model semantics for dynamic preferences on assumptions
#@ Ulrich Junker
#t 1997
#c 11
#% 3035
#% 42003
#% 77841
#% 116294
#% 121992
#% 179921
#% 503361
#% 1272277
#! Explicit preferences on assumptions as used in prioritized circumscription [McCarthy, 1986; Lifschitz, 1985; Grosof, 1991] and preferred subtheories [Brewka, 1989] provide a clear and declarative method for defining preferred models. In this paper, we show how to embed preferences in the logical theory itself. This gives a high freedom for expressing statements about preferences. Preferences can now depend on other assumptions and are thus dynamic. We elaborate a preferential semantics based on Lehmann's cumulative models, as well as a corresponding constructive characterization, which specifies how to correctly treat dynamic preferences in the default reasoning system EXCEPT. [Junker, 1992].

#index 1273699
#* Compiling reasoning with and about preferences into default logic
#@ James P. Delgrande;Torsten H. Schaub
#t 1997
#c 11
#% 2435
#% 3035
#% 42003
#% 107140
#% 116294
#% 179921
#% 383293
#% 495651
#% 780340
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273700
#* Learning extended logic programs
#@ Katsumi Inoue;Yoshimitsu Kudoh
#t 1997
#c 11
#% 380466
#% 396021
#% 458262
#% 565242
#! This paper presents a method to generate nonmonotonic rules with exceptions from positive/ negative examples and background knowledge in Inductive Logic Programming. We adopt extended logic programs as the form of programs to be learned, where two kinds of negation--negation as failure and classical negation--are effectively used in the presence of incomplete information. While default rules axe generated as specialization of general rules that cover positive examples, exceptions to general rules are identified from negative examples and are then generalized to rules for cancellation of defaults. We implemented the learning system LELP based on the proposed method. In LELP, when the numbers of positive and negative examples are very close, either parallel default rules with positive and negative consequents or nondeterministic rules are learned. Moreover, hierarchical defaults can also be learned by recursively calling the exception identification algorithm.

#index 1273701
#* Compiling prioritized circumscription into extended logic programs
#@ Toshiko Wakaki;Ken Satoh
#t 1997
#c 11
#% 53388
#% 57926
#% 61221
#% 132176
#% 499481
#! We propose a method of compiling circumscription into Extended Logic Programs which is widely applicable to a class of parallel circumscription as well as a class of prioritized circumscription. In this paper, we show theoretically that any circumscription whose theory contains both the domain closure axiom and the uniqueness of names axioms can always be compiled into an extended logic program II, so that, whether a ground literal is provable from circumscription or not, can always be evaluated by deciding whether the literal is true in all answer sets of II, which can be computed by running II under the existing logic programming interpreter.

#index 1273702
#* Prefixed tableaux systems for modal logics with enriched languages
#@ Philippe Balbiani;Stephane Demri
#t 1997
#c 11
#% 3812
#% 68240
#% 72548
#% 188086
#% 365436
#% 517101
#% 560744
#% 567511
#! We present sound and complete prefixed tableaux systems for various modal logics with enriched languages including the "difference" modal operator [≠] and the "only if" modal operator [--R]. These logics are of special interest in Artificial Intelligence since their expressive power is higher than the standard modal logics and for most of them the satisfiability problem remains decidable. We also include in the paper decision procedures based on these systems. In the conclusion, we relate our work with similar ones from the literature and we propose extensions to other logics.

#index 1273703
#* A set-theoretic approach to automated deduction in graded modal logics
#@ A. Montanari;A. Policriti
#t 1997
#c 11
#% 486415
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273704
#* On evaluating decision procedures for modal logic
#@ Ullrich Hustadt;Renate A. Schmidt
#t 1997
#c 11
#% 556363
#% 560918
#% 560931
#! This paper investigates the evaluation method of decision procedures for multi-modal logic proposed by Giunchiglia and Sebastiani as an adaptation from the evaluation method of Mitchell et al of decision procedures for propositional logic. We compare three different theorem proving approaches, namely the Davis-Putnam-based procedure KSAT, the tableaux-based system KTUS and a translation approach combined with first-order resolution. Our results do not support the claims of Giunchiglia and Sebastiani concerning the computational superiority of KSAT over KRIS, and an easy-hard-easy pattern for randomly generated modal formulae.

#index 1273705
#* Preduction: a common form of induction and analogy
#@ Jun Arima
#t 1997
#c 11
#% 3514
#% 90029
#% 100142
#% 543263
#! Deduction, induction, and analogy pervade all our thinking. In contrast with deduction, understanding logical aspects of induction and analogy is still an important and challenging issue of artificial intelligence. This paper describes a logical formalization, called production, of common conjectural reasoning of both induction and analogy. By introduction of preduction, analogical reasoning is refined into "preduction + deduction" and (empirical) inductive reasoning is refined into "preduction + mathematical induction". We examine generality of preduction through applications to various examples on induction and analogy.

#index 1273706
#* Analogy and abduction in automated deduction
#@ Gilles Defourneaux;Nicolas Peltier
#t 1997
#c 11
#% 55937
#% 58008
#% 145393
#% 204100
#% 495669
#% 560729
#% 561216
#% 1275251
#% 1275265
#! A method is presented for analogical reasoning in Automated Deduction. We focus on the abductive aspects of analogy and give a unified treatment for theorems and non-theorems. Abduction allows to deal with partial analogies thus strongly increasing the application field of the method. It also allows to detect "bad analogies" in several cases. Explanatory examples as well as more realistic examples quantifying the effects of using analogy (for theorem-proving and for counter-example building) are given.

#index 1273707
#* How similar is very young to 43 years of age? on the representation and comparison of polymorphic properties
#@ Werner Dubitzky;Alfons Schuster;John G. Hughes;David A. Bell;Kenneth Adamson
#t 1997
#c 11
#% 25443
#% 160906
#% 379636
#% 383684
#% 403600
#% 490431
#% 490449
#% 527845
#! Intelligent computer systems rely on more or less complex computational entities that represent occurrences and events in the real world. Usually, such entities are formed from representational primitives called properties, attributes, features, etc. To reflect varying degrees of uncertainty, originating from human judgement and the intrinsic nature of the world, such property values occur as more or less vague linguistic symbols or exact numeric expressions. Determining similarity between two properties is usually done on either the symbolic or the numeric level. This seems to be too restrictive for case-based reasoning and similar approaches as these often face mixed specifications. In this paper we propose a flexible and systematic scheme for representing crisp properties and two types of fuzzy properties. It also provides a consistent mechanism to establish similarity scores for the various instance combinations.

#index 1273708
#* The competence of sub-optimal theories of structure mapping on hard analogies
#@ Tony Veale;Mark Keane
#t 1997
#c 11
#% 65345
#% 70596
#% 408396
#! Structure-mapping is a provably NP-Hard problem which is argued to lie at the core of the human metaphoric and analogical reasoning faculties. This NP-Hardness has meant that early attempts at optimal solutions to the problem have had to be augmented with sub-optimal heuristics to ensure tractable performance. This paper considers various grounds for qualifying the competence of such heuristic approaches, and offers an evaluation of the sub-optimal performance of three different models of analogy, SME, ACME and Sapper.

#index 1273709
#* An average-case analysis of the k-nearest neighbor classifier for noisy domains
#@ Seishi Okamoto;Yugami Nobuhiro
#t 1997
#c 11
#% 92533
#% 120634
#% 129991
#% 494257
#! This paper presents an average-case analysis of the fc-nearest neighbor classifier (k-NN). Our analysis deals with m-of-n// concepts, and handles three types of noise: relevant attribute noise, irrelevant attribute noise, and class noise. We formally compute the expected classification accuracy of fc-NN after a certain fixed number of training instances. This accuracy is represented as a function of the domain characteristics. Then, the predicted behavior of fc-NN for each type of noise is explored by using the accuracy function. We examine the classification accuracy of fc-NN at various noise levels, and show how noise affects the accuracy of fc-NN. We also show the relationship between the optimal value of k and the number of training instances in noisy domains. Our analysis is supported with Monte Carlo simulations.

#index 1273710
#* Learning to integrate multiple knowledge sources for case-based reasoning
#@ David B. Leake;Andrew Kinley;David Wilson
#t 1997
#c 11
#% 55921
#% 168280
#% 362441
#% 366694
#% 1478834
#% 1499567
#! The case based reasoning process depends on multiple overlapping knowledge sources, each of which provides an opportunity for learning. Exploiting these opportunities requires not only determining the learning mechanisms to use for each individual knowledge source, but also how the different learning mechanisms interact and their combined utility. This paper presents a case study examining the relative contributions and costs involved in learning processes for three different knowledge sources--cases, case adaptation knowledge, and similarity information--in a casebased planner. It demonstrates the importance of interactions between different learning processes and identifies a promising method for integrating multiple learning methods to improve case-based reasoning.

#index 1273711
#* Aggregating features and matching cases on vague linguistic expressions
#@ Alfons Schuster;Werner Dubitzky;Philippe Lopes;Kenneth Adamson;David A. Bell;John G. Hughes;John A. White
#t 1997
#c 11
#% 25443
#% 168280
#% 403600
#% 405727
#% 585042
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273712
#* Using case-based reasoning in interpreting unsupervised inductive learning results
#@ Tu Bao Ho;Chi Mai Luong
#t 1997
#c 11
#% 92533
#% 129975
#% 136350
#% 169705
#% 191680
#% 209020
#% 217868
#% 232117
#% 246083
#% 363670
#% 375388
#% 451052
#% 1272280
#! The objective of this work is to interpret inductive results obtained by the unsupervised learning method OSHAM. We briefly introduce the learning process of OSHAM, that extracts concept hierarchies from unlabelled data, based on a representation combining the classical, prototype and exemplar views on concepts. The interpretive process is considered as an intrinsic part in OSHAM and is carried out by a combination of case-based reasoning with matching approaches in inductive learning. An experimental comparative study of some learning methods in terms of knowledge description and prediction is given.

#index 1273713
#* Acquisition of human feelings in music arrangement
#@ Masayuki Numao;Masashi Kobayashi;Katsuyuki Sakaniwa
#t 1997
#c 11
#% 90129
#% 126940
#% 360348
#% 449508
#% 540915
#% 540926
#! We often make decisions based on our feelings, which are implicit and very difficult to express as knowledge. This paper details an attempt to acquire feelings automatically. We assume that some relations or constraints exist between impressions felt and situations, which consist of an object and its environment. For example, in music arrangement, the object is a music score and its environment contains listeners, etc. Our project validates this assumption through three levels of experiments. At the first level, a program simply mimics human arrangements in order to transfer their impressions to another arrangement. This implies that the program is capable of distinguishing patterns that result in some impressions. At the second level, in order to produce a music recognition model, the program locates relations and constraints between a music score and its impressions, by which we show that machine learning techniques may provide a powerful tool for composing music and analyzing human feelings. Finally, we examine the generality of the model by modifying some arrangements to provide the subjects with a specified impression.

#index 1273714
#* Using data and theory in multistrategy (mis) concept (ion) discovery
#@ Raymund Sison;Masayuki Numao;Masamichi Shimura
#t 1997
#c 11
#% 3033
#% 90105
#% 107031
#% 107036
#% 143187
#% 178510
#% 449530
#% 451051
#% 451052
#% 1271938
#! Most conceptual clustering systems rely solely on data to form concepts without supervision; the few that exploit causalities in the background knowledge do so only after the completion of a similarity-based learning phase. In this paper, we describe a multistrategy misconception discovery system, MMD, that utilizes data and theory in a more tightly coupled way. The integration of similarity- and causality-based learning in MMD is shown to be essential for the automatic construction of accurate and meaningful misconceptions that account for errors in novice behavior.

#index 1273715
#* An aggregation procedure for building episodic memory
#@ Olivier Ferret;Brigitte Grau
#t 1997
#c 11
#% 2298
#% 65447
#% 156188
#% 373871
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273716
#* An achievement test for knowledge-based systems: QUEM
#@ Caroline Clarke Hayes;Michael I. Parzen
#t 1997
#c 11
#% 142755
#% 153486
#! This paper describes QUEM, a method for assessing the skill level of a knowledge-based system based on the quality of the solutions it produces. QUEM is demonstrated by using it to assess the performance of a particular knowledge-based system, P3. QUEM can be viewed as an achievement or job placement test given to know ledge-based systems to help system designers determine how the system should be used, and in what capacity by what level of users. In general, it is difficult to find useful metrics for assessing a system's overall performance. Most literature on evaluation deals with validation, verification and testing in which the primary concern is the correctness and consistency in the databases and rulebases. However, these properties alone may not be sufficient to determine how well a system performs its task. QUEM allows software developers to assess their system's performance by constructing a skill function based on human performance data that relates experience and solution quality. QUEM can be used to gauge the experience level of an individual system, compare two systems, or compare a system to its intended users. This represents an important advance in quantitative measures of over-all system performance that can be applied to a broad range of systems.

#index 1273717
#* A functional theory of design patterns
#@ Sambasiva R. Bhatta;Ashok K. Goel
#t 1997
#c 11
#% 65345
#% 66512
#% 84378
#% 168251
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273718
#* Mental tracking: a computational model of spatial development
#@ Kazuo Hiraki;Akio Sashima;Steven Phillips
#t 1997
#c 11
#% 100336
#% 669154
#% 1275241
#! Psychological experiments on children's development of spatial knowledge suggest experience at self-locomotion with visual tracking as important factors. Yet, the mechanism underlying development is unknown. We propose a robot that learns to mentally track a target object (i.e., maintaining a representation of an object's position when outside the field-of-view) as a model for spatial development. Mental tracking is considered as prediction of an object's position given the previous environmental state and motor commands, and the current environment state resulting from movement. Following Jordan and Rumelhart's (1992) forward modeling architecture the system consists of two components: an inverse model of sensory input to desired motor commands; and a forward model of motor commands to desired sensory input (goals). The robot was tested on the "three cups" paradigm (where children are required to select the cup containing the hidden object under various movement conditions). Consistent with child development, without the capacity for self-locomotion the robot's errors are self-center based. When given the ability of self-locomotion the robot responds allocentrically.

#index 1273719
#* In the quest of the missing link
#@ Guilherme Bittencourt
#t 1997
#c 11
#% 18600
#% 92135
#% 92555
#% 288366
#% 369236
#% 370701
#% 1275296
#% 1290160
#! This paper presents a generic model for a cognitive agent based on the hypothesis that the cognitive activity has three main characteristics: self-organization, evolutionary nature and history dependence. According to this model, a cognitive agent presents three levels: reactive, instinctive and cognitive. Each level, together with its lower levels, is intended to model a complete agent, each new level just increasing the behavior complexity. The generic model is instantiated into a computational architecture that integrates connectionist, evolutionary computation and symbolic approaches.

#index 1273720
#* Implementing BDI-like systems by direct execution
#@ Michael Fisher
#t 1997
#c 11
#% 97617
#% 101955
#% 114677
#% 136356
#% 181537
#% 181576
#% 181584
#% 214197
#% 244315
#% 467485
#% 472546
#% 500001
#% 557072
#% 564211
#! While the Belief, Desire, Intention (BDI) framework is one of the most influential and appealing approaches to rational agent architectures, a gulf often exists between the high-level BDI model and its practical realisation. In contrast, the Concurrent METATEM language, being based upon executable formal specifications, presents a close link between the theory and implementation, yet lacks some of the features considered central to the representation of rational agents. In this paper, we introduce a hybrid approach combining the direct execution of Concurrent METATEM with elements of rationality from the BDI framework. We show how this system can capture a range of agent behaviours, while retaining many of the advantages of executable specifications.

#index 1273721
#* Managing decision resources in plan execution
#@ Michael Freed;Roger Remington
#t 1997
#c 11
#% 241013
#% 647161
#% 695783
#! We describe an approach to the problem of managing resources in routine decision-making tasks. The central feature of this approach is the use of reusable RAP-like plans to generate decisions. This allows our system, APEX, to take advantage of the flexibility in scheduling and method selection provided by execution mechanisms and thereby minimize or circumvent resource conflicts. We then discuss an application of APEX for simulating a human air traffic controller in order to aid in the evaluation of radar display designs.

#index 1273722
#* Use of abstraction and complexity levels in intelligent educational systems design
#@ Ruddy Lelouche;Jean-Francois Morin
#t 1997
#c 11
#% 1409
#% 13917
#% 33190
#% 36105
#% 55211
#% 55234
#% 374912
#% 456691
#! We are interested in problem-solving domains, like engineering and most "exact science" disciplines. In these domains, the knowledge to be acquired by the student is twofold: the domain knowledge itself, but also and mainly the knowledge necessary to solve problems in that domain. As a result, an educationoriented system in such a domain must encompass three knowledge types: the domain knowledge and the problem-solving knowledge, constituting the knowledge to be acquired and mastered by the student, and the tutoring knowledge, used by the system to facilitate the student's learning process. In this paper, we show how these three knowledge types can be modelled, how they should interact with one another in order to fulfil the system educational purpose, and above all how the abstraction and complexity levels can shed a uniformizing light on the system operation and make it more userfriendly. We thus hope to bring some contribution to the general and important problem of finding a generic architecture to intelligent tutoring systems.

#index 1273723
#* Reasoning symbolically about partially matched cases
#@ Kevin D. Ashley;Vincent Aleven
#t 1997
#c 11
#% 109941
#% 168280
#% 367665
#% 490271
#% 490450
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273724
#* Task ontology makes it easier to use authoring tools
#@ Mitsuru Ikeda;Kazuhisa Seta;Riichiro Mizoguchi
#t 1997
#c 11
#% 552641
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273725
#* Semiring-based constraint logic programming
#@ Stefano Bistarelli;Ugo Montanari;Francesca Rossi
#t 1997
#c 11
#% 35562
#% 126386
#% 228803
#% 230551
#% 364947
#% 503496
#% 1275308
#! We extend the Constraint Logic Programming (CLP) formalism in order to handle semiringbased constraint systems. This allows us to perform in the same language both constraint solving and optimization. In fact, constraint systems based on semirings are able to model both classical constraint solving and more sophisticated features like uncertainty, probability, fuzzyness, and optimization. We then provide this class of languages with three equivalent semantics: model-theoretic, fixpoint, and proof-theoretic, in the style of CLP programs.

#index 1273726
#* Computational complexity of multi-way, dataflow constraint problems
#@ Gilles Trombettoni;Bertrand Neveu
#t 1997
#c 11
#% 31834
#% 68047
#% 130070
#% 200033
#% 203484
#! Although it is acknowledged that multiway dataflow constraints are useful in interactive applications, concerns about their tractability have hindered their acceptance. Certain local propagation algorithms that solve these constraints are polynomial, others (such as Sky-Blue) are exponential. Every system handles a specific problem and the influence of any particular restriction on the computational complexity is not yet precisely determined. In this paper, we present three theoretical results that allow us to classify existing multi-way constraint problems. Especially, we prove that the problem handled by SkyBlue is NP-hard.

#index 1273727
#* Heuristics based on unit propagation for satisfiability problems
#@ Chu Min Li;Anbulagan Anbulagan
#t 1997
#c 11
#% 41220
#% 198885
#% 210195
#% 327779
#% 601159
#! The paper studies new unit propagation based heuristics for Davis-Putnam-Loveland (DPL) procedure. These are the novel combinations of unit propagation and the usual "Maximum Occurrences in clauses of Minimum Size" heuristics. Based on the experimental evaluations of different alternatives a new simple unit propagation based heuristic is put forward. This compares favorably with the heuristics employed in the current state-of-the-art DPL implementations (C-SAT, Tableau, POSIT).

#index 1273728
#* Hidden gold in random generation of SAT satisfiable instances
#@ Thierry Castell;Michel Cayrol
#t 1997
#c 11
#% 41220
#% 160270
#% 327779
#% 1275266
#% 1275307
#! Can an AI program contribute to scientific discovery? An area where this gauntlet has been thrown is that of understanding the mechanisms of chemical carcinogenesis. One approach is to obtain Structure-Activity Relationships (SARs) relating molecular ...

#index 1273729
#* Proceedings of the 16th international joint conference on Artifical intelligence - Volume 1
#@ 
#t 1999
#c 11

#index 1273730
#* Lemma generation for model elimination by combining top-down and bottom-up inference
#@ Marc Fuchs
#t 1999
#c 11
#% 49210
#% 114994
#% 124073
#% 420604
#% 420636
#% 558272
#% 560585
#% 560754
#! A very promising approach for integrating top-down and bottom-up proof search is the use of bottom-up generated lemmas in top-down provers. When generating lemmas, however) the currently used lemma generation procedures suffer from the well-known problems of forward reasoning methods, e.g., the proof goal is ignored. In order to overcome these problems we propose two relevancy-based lemma generation methods for top-down provers. The first approach employs a bottom-up level saturation procedure controlled by top-down generated patterns which represent promising subgoals. The second approach uses evolutionary search and provides a self-adaptive control of lemma generation and goal decomposition.

#index 1273731
#* Cooperation of heterogeneous provers
#@ Jorg Denzinger;Dirk Fuchs
#t 1999
#c 11
#% 2194
#% 294452
#% 472544
#% 529075
#% 539339
#% 558272
#% 560754
#% 585627
#% 1273689
#! We present a methodology for achieving co-operation between already existing theorem provers employing different proof paradigms and/or different search controls, and using different but related logics. Cooperation between the provers is achieved by periodically interchanging clauses which are selected by so-called referees. By employing referees both on the side of a sending prover and a receiving prover the communication is both success- and demand-driven, which results in a rather small communication overhead and synergetical effects. We report on experiments regarding the cooperation of the provers SPASS, SETHEO and DISCOUNT in domains of the TPTP library and with problems stemming from an application in software component retrieval. The experiments show significant improvements in the number of problems solved as well as in the solution times.

#index 1273732
#* UPML: a framework for knowledge system reuse
#@ Dieter Fensel;V. Richard Benjamins;Enrico Motta;Bob Wielinga
#t 1999
#c 11
#% 134111
#% 156337
#% 189739
#% 270804
#% 362942
#% 444996
#% 459645
#% 515050
#! Problem-solving methods provide reusable architectures and components for implementing the reasoning part of knowledge-based systems. The Unified Problem-solving Method Development Language, UPML, has been developed to describe and implement such architectures and components and to facilitate their semiautomatic reuse and adaptation. In a nutshell, UPML is a framework for developing knowledge-intensive reasoning systems based on libraries of generic problem-solving components. The paper describes the components, architectural constraints, development guidelines, and tools provided by UPML. Our focus is hereby on the meta ontology that has been developed to formalize the architectural structure and elements of UPML.

#index 1273733
#* Complexity results for propositional closed world reasoning and circumscription from tractable knowledge bases
#@ Sylvie Coste-Marquis;Pierre Marquis
#t 1999
#c 11
#% 3035
#% 8420
#% 57551
#% 107149
#% 136678
#% 166793
#% 183609
#% 211581
#% 216990
#% 235882
#% 266112
#% 289115
#% 556918
#% 936786
#% 1273692
#% 1499541
#! This paper presents new complexity results for propositional closed world reasoning (CWR) from tractable knowledge bases (KBs). Both (basic) CWR, generalized CWR, extended generalized CWR, careful CWR and extended CWR (equivalent to circumscription) are considered. The focus is laid on tractable KBs belonging to target classes for exact compilation functions: Blake formulas, DNFs, disjunctions of Horn formulas, and disjunctions of renamable Horn formulas. The complexity of inference is identified for all the forms of CWR listed above. For each of them, new tractable fragments are exhibited. Our results suggest knowledge compilation as a valuable approach to deal with the complexity of CWR in some situations.

#index 1273734
#* Credulous nonmonotonic inference
#@ Alexander Bochman
#t 1999
#c 11
#% 77841
#% 160378
#% 167537
#% 366370
#% 503676
#! We present a formal characterization and semantic representation for a number of credulous inference relations based on the notion of an epistemic state. It is shown, in particular, that credulous inference can be naturally represented in terms of expectations (see [Gardenfors and Makinson, 1994]). We describe also the relationships between credulous and usual skeptical nonmonotonic inference and show how they can facilitate each other.

#index 1273735
#* Preferred arguments are harder to compute than stable extensions
#@ Yannis Dimopoulos;Bernhard Nebel;Francesca Toni
#t 1999
#c 11
#% 99297
#% 189980
#% 231742
#% 231883
#% 267597
#% 268779
#% 383293
#! Based on an abstract framework for nonmonotonic reasoning, Bondarenko et at. have extended the logic programming semantics of admissible and preferred arguments to other nonmonotonic formalisms such as circumscription, autoepisternic logic and default logic. Although the new semantics have been tacitly assumed to mitigate the computational problems of nonmonotonic reasoning under the standard semantics of stable extensions, it seems questionable whether they improve the worst-case behaviour. As a matter of fact, we show that credulous reasoning under the new semantics in propositional logic programming and prepositional default logic has the same computational complexity as under the standard semantics. Furthermore, sceptical reasoning under the admissibility semantics is easier - since it is trivialised to monotonic reasoning. Finally, sceptical reasoning under the preferability semantics is harder than under the standard semantics.

#index 1273736
#* Abducing priorities to derive intended conclusions
#@ Katsumi Inoue;Chiaki Sakama
#t 1999
#c 11
#% 26351
#% 77167
#% 179921
#% 181220
#% 480594
#! We introduce a framework for finding preference information to derive desired conclusions in nonmonotonic reasoning. A new abductive framework called preference abduction enables us to infer an appropriate set of priorities to explain the given observation skeptically, thereby resolving the multiple extension problem in the answer set semantics for extended logic programs. Preference abduction is also combined with a usual form of abduction in abductive logic programming, and has applications such as specification of rule preference in legal reasoning and preference view update. The issue of learning abducibles and priorities is also discussed, in which abduction to a particular cause is equivalent to abduction to preference.

#index 1273737
#* Maximum entropy and variable strength defaults
#@ Rachel A. Bourne;Simon Parsons
#t 1999
#c 11
#% 77841
#% 91010
#% 115327
#% 216970
#% 443633
#! A new algorithm for computing the maximum entropy ranking over models is presented. The algorithm handles arbitrary sets of propositional defaults with associated strength assignments and succeeds whenever the set satisfies a robustness condition. Failure of this condition implies the problem may not be sufficiently specified for a unique solution to exist. This work extends the applicability of the maximum entropy approach detailed in [Goldszmidt et al., 1993]) and clarifies the assumptions on which the method is based.

#index 1273738
#* On the relationship between probabilistic logic and π-CMS
#@ P. Hansen;B. Jaumard;A. D. Parreira
#t 1999
#c 11
#% 3034
#% 3460
#% 21138
#% 71578
#% 95582
#% 196387
#% 383492
#% 503495
#! We discuss the relationship between probabilistic logic and π-CMS. Given a set of logical sentences and their probabilities of being true, the outcome of a probabilistic logic system consists of lower and upper bounds on the probability of an additional sentence to be true. These bounds are computed using a linear programming formulation. In π-CMS systems, the outcome is defined by the probabilities of the support and the plausibility (with the assumptions being independent) after a first phase which consists of computing the prime implicants depending only on the variables of the assumptions. We propose to reformulate a π-CMS system without independence conditions on the assumptions, using the linear programming framework of probabilistic logic, and show how to exploit its particular structure to solve it efficiently. When an independence condition is imposed on the assumptions the two systems give different results. Comparisons are made on small problems using the assumption-based evidential language program (ABEL) of [Anrig et al., 1998] and the PSAT program of [Jaumard et al., 1991].

#index 1273739
#* On the complexity of model checking for propositional default logics: new results and tractable cases
#@ Robert Baumgartner;Georg Gottlob
#t 1999
#c 11
#% 95643
#% 100155
#% 107149
#% 147546
#% 189738
#% 189980
#% 383293
#% 464519
#% 495350
#% 495816
#% 590310
#% 1275338
#! We analyse the complexity of standard and weak model checking for propositional default logic; in particular, we solve the open problem of complexity in case of normal default theories and introduce a new ample class of default theories with a tractable model checking problem.

#index 1273740
#* Stable model checking made easy
#@ Christoph Koch;Nicola Leone
#t 1999
#c 11
#% 114723
#% 231786
#% 235018
#% 443134
#% 499509
#% 561083
#! Disjunctive logic programming (DLP) with stable model semantics is a powerful nonmonotonic formalism for knowledge representation and reasoning. Reasoning with DLP is harder than with normal (V-free) logic programs; liecause stable model checking - deciding whether a given model is a stable model of a propositional DLP program is co-NP-complete, while it is polynomial for normal logic programs. This paper proposes a new transformation ΓM(P) which reduces stable model checking to UNSAT - i.e., to deciding whether a given CNF formula is unsatisfiable. Thus, the stability of a model AI for a program P can be verified by calling a Satisfiability Checker on the CNF formula ΓM(P). The transformation is parsimonious and efficiently computable, as it runs in logarithmic space. Moreover, the size of the generated CNF formula never exceeds the size of the input. The proposed approach to stable model checking lias been implemented in a DLP system, and a number of experiments and benchmarks have been run.

#index 1273741
#* Model checking for nonmonotonic logics: algorithms and complexity
#@ Riccardo Rosati
#t 1999
#c 11
#% 1146
#% 8418
#% 89976
#% 101922
#% 130838
#% 383293
#% 544788
#% 548767
#% 1478795
#! We study the complexity of model checking in proposit ional nonmonotonic logics. Specifically, we first define the problem of model checking in such formalisms, based on the fact that several nonmonotonic logics make use of interpretation structures (i.e. default extensions, stable expansions, universal Kripke models) which are more complex than standard interpretations of propositional logic. Then, we analyze the complexity of checking whether a given interpretation structure satisfies a nonmonotonic theory. In particular, we characterize the complexity of model checking for Reiter's default logie and its restrictions, Moore's autoepistemie logic, and several nonmonotonic modal logics. The results obtained show that, in all such formalisms, model checking is computationally easier than logical inference.

#index 1273742
#* Reasoning in expressive description logics with fixpoints based on automata on infinite trees
#@ Diego Calvanese;Giuseppe De Giacomo;Maurizio Lenzerini
#t 1999
#c 11
#% 34773
#% 109626
#% 117899
#% 179613
#% 223455
#% 237191
#% 244095
#% 248026
#% 262249
#% 266095
#% 442977
#% 459240
#% 464717
#% 494344
#% 543351
#% 555513
#% 1272306
#% 1275330
#% 1499471
#! In the last years, the investigation on Description Logics (DLs) has been driven by the goal of applying them in several areas, such as, software engineering, information systems, databases, information integration, and intelligent access to the web. The modeling requirements arising in the above areas have stimulated the need for very rich languages, including fixpoint constructs to represent recursive structures. We study a DL comprising the most general form of fixpoint constructs on concepts, all classical concept forming constructs, plus inverse roles, n-ary relations, qualified number restrictions, and inclusion assertions. We establish the EXPTIME decidability of such logic by presenting a decision procedure based on a reduction to nonemptiness of alternating automata on infinite trees. We observe that this is the first decidability result for a logic combining inverse roles, number restrictions, and general fixpoints.

#index 1273743
#* Reasoning with concrete domains
#@ Carsten Lutz
#t 1999
#c 11
#% 58347
#% 101435
#% 108681
#% 539012
#% 539462
#% 671261
#% 671264
#! Description logics are formalisms for the representation of and reasoning about conceptual knowledge on an abstract level. Concrete domains allow the integration of description logic reasoning with reasoning about concrete objects such as numbers, time intervals, or spatial regions. The importance of this combined approach, especially for building real-world applications, is widely accepted. However, the complexity of reasoning with concrete domains has never been formally analyzed and efficient algorithms have not been developed. This paper closes the gap by providing a tight bound for the complexity of reasoning with concrete domains and presenting optimal algorithms.

#index 1273744
#* Computing least common subsumers in description logics with existential restrictions
#@ Franz Baader;Ralf Kusters;Ralf Molitor
#t 1999
#c 11
#% 222440
#% 384978
#% 539635
#% 671260
#! Computing the least common subsunier (les) is an inference task that can be used to support, the "bottom-up" construction of knowledge bases for KR systems based on description logics. Previous work on how to compute the lcs has concentrated on description logics that allow for universal value restrictions, but not for existential restrictions. The main new contribution of this paper is the treatment of description logics with existential restrictions. Our approach for computing the lcs is based on an appropriate representation of concept descriptions by certain trees, and a characterization of subsumption by homomorphisins between these trees. The lcs operation then corresponds to the product operation on trees.

#index 1273745
#* Multi-dimensional description logics
#@ Frank Wolter;Michael Zakharyaschev
#t 1999
#c 11
#% 101435
#% 188086
#% 244095
#% 459654
#% 1275331
#! In this paper, we construct a new concept description language intended for representing dynamic and intensional knowledge. The most important feature distinguishing this language from its predecessors in the literature is that it allows applications of modal operators to all kinds of syntactic terms: concepts, roles and formulas. Moreover, the language may contain both local (i.e., state-dependent) and global (i.e., state-independent) concepts, roles and objects. All this provides us with the most complete and natural means for reflecting the dynamic and intensional behaviour of application domains. We construct a satisfiability checking (mosaic-type) algorithm for this language (based on ALC) in (i) arbitrary multimodal frames, (ii) frames with universal accessibility relations (for knowledge) and (iii) frames with transitive, symmetrical and euclidean relations (for beliefs). On the other hand, it is shown that the satisfaction problem becomes undecidable if the underlying frames are arbitrary linear orders or the language contains the common knowledge operator for n ≥ 2 agents.

#index 1273746
#* On the relation of resolution and tableaux proof systems for description logics
#@ Ullrich Hustadt;Renate A. Schmidt
#t 1999
#c 11
#% 395540
#% 420611
#% 420676
#% 517254
#% 549056
#% 558265
#% 561242
#% 1273704
#! This paper investigates the relationship between resolution and tableaux proof system for the satisfiability of general knowledge bases in the description logic ALC. We show that resolution proof systems can polynornially simulate their tableaux counterpart. Our resolution proof system is based on a selection refinement and utilises standard redundancy elimination criteria to ensure termination.

#index 1273747
#* Preferential semantics for causal systems
#@ Pavlos Peppas;Maurice Pagnucco;Mikhail Prokopenko;Norman Y. Foo;Abhaya Nayak
#t 1999
#c 11
#% 18262
#% 224765
#% 486302
#% 1290152
#! In the present work we examine the causal theory of actions put forward by McCain and Turner [McCain and Turner, 1995] for determining ramifications. Our principal aim is to provide a characterisation of this causal theory of actions in terms of a Shoham-like preferential semantics [Shoham, 1988]. This would have a twofold advantage: it would place McCain and Turner's theory in perspective, allowing a comparison with other logics of action; and, it would allow us to glean further insights into the nature of causality underlying their work. We begin by showing that our aim is not attainable by a preferential mechanism alone. At this point we do not abandon preferential semantics altogether but augment it in order to arrive at the desired result. We draw the following moral which is at the heart of our paper: two components -- minimal change under a preferential structure and causality -- are required to provide a concise solution to the frame and ramification problems.

#index 1273748
#* Query evaluation and progression in AOL knowledge bases
#@ Gerhard Lakemeyer;Hector J. Levesque
#t 1999
#c 11
#% 400
#% 68240
#% 117869
#% 229083
#% 326595
#% 1476290
#! Recently Lakemeyer and Levesque proposed the logic AOC, which amalgamates both the situation calculus and Levesques logic of only knowing. While very expressive the practical relevance of the formalism is unclear because it heavily relies on second-order logic. In this paper we demonstrate that the picture is not as bleak as it may seem. In particular, we show that for large classes of AOL knowledge bases and queries, including epistemic ones, query evaluation requires first-order reasoning only. We also provide a simple semantic definition of progressing a knowledge base. For a particular class of knowledge bases, adapted from earlier results by Lin and Reiter, we show that progression is first-order representable and easy to compute.

#index 1273749
#* Axiomatic foundations for qualitative/ordinal decisions with partial preferences
#@ Adriana Zapico
#t 1999
#c 11
#% 1290145
#! The representational issues of preferences in the framework of a possibilistic (qualitative/ordinal) decision model under uncertainty, were originally introduced few years ago by Dubois and Prade, and more recently linked to case-based decision problem by Dubois et al.. In this approach, the uncertainty is assumed to be of possibilistic nature. Uncertainty (or similarity) and preferences on consequences are both measured on commensurate ordinal scales. However, in case-based decision problems, similarity or preferences on consequences may sometimes take values that are incomparable. In order to cope with some of these situations, we propose an extension of the model where both preferences and uncertainty arc graded on distributive lattices, providing axiomatic settings for characterising a pessimistic and an optimistic qualitative utilities. Finally, we extend our proposal to also include belief states that may be partially inconsistent, supplying elements for a qualitative case-based decision methodology.

#index 1273750
#* The ramification problem in the event calculus
#@ Murray Shanahan
#t 1999
#c 11
#% 224765
#% 236024
#! Finding a solution to the frame problem that is robust in the presence of actions with indirect effects has proven to be a difficult task. Examples that feature the instantaneous propagation of interacting indirect effects are particularly taxing. This article shows that an already widely known predicate calculus formalism, namely the event calculus, can handle such examples with only minor enhancements.

#index 1273751
#* Logic-based subsumption architecture
#@ Eyal Amir;Pedrito Maynard-Reid
#t 1999
#c 11
#% 3035
#% 18600
#% 49210
#% 57551
#% 126345
#% 243707
#% 252479
#! We describe a logic-based AI architecture based on Brooks' subsumption architecture. In this architecture, we axiomatize different layers of control in First-Order Logic (FOL) and use independent theorem provers to derive each layer's outputs given its inputs. We implement the subsumption of lower layers by higher layers using circumscription to make assumptions in lower layers, and nonmonotonically retract them when higher layers draw new conclusions. WTe also give formal semantics to our approach. Finally, we describe four layers designed for the task of robot control and an experiment that empirically shows the feasibility of using fully expressive FOL theorem provers for robot control with our architecture.

#index 1273752
#* Automata theory for reasoning about actions
#@ Eugenia Ternovskaia
#t 1999
#c 11
#% 101943
#% 117869
#% 183459
#% 284106
#% 532632
#! In this paper, we show decidability of a rather expressive fragment of the situation calculus. We allow second order quantification over finite and infinite sets of situations. We do not impose a domain closure assumption on actions; therefore, infinite and even uncountable domains are allowed. The decision procedure is based on automata accepting infinite trees.

#index 1273753
#* Projection using regression and sensors
#@ Giuseppe De Giacomo;Hector J. Levesque
#t 1999
#c 11
#% 117869
#% 229083
#% 244412
#% 266387
#% 1275246
#% 1476290
#! In this paper, we consider the projection task (determining what does or does not hold after performing a sequence of actions) in a general setting where a solution to the frame problem may or may not be available, and where online information from sensors may or may not be applicable. We formally characterize the projection task for actions theories of this sort, and show how a generalized form of regression produces correct answers whenever it can be used. We characterize conditions on action theories, sequences of actions, and sensing information that are sufficient to guarantee that regression can be used, and present a provably correct regressionbased procedure in Prolog for performing the task under these conditions.

#index 1273754
#* Expressive reasoning about action in nondeterministic polynomial time
#@ Thomas Drakengren;Marcus Bjareland
#t 1999
#c 11
#% 243707
#% 1080946
#% 1271923
#% 1290152
#! The rapid development of efficient heuristics for deciding satisfiability for propositional logic motivates thorough investigations of the usability of NP-complete problems in general. In this paper we introduce a logic of action and change which is expressive in the sense that it can represent most propositional benchmark examples in the literature, and some new examples involving parallel composition of actions, and actions that may or may not be executed. We prove that satisfiability of a scenario in this logic is NP-complete, and that it subsumes an NP-complete logic (which in turn includes a nontrivial polynomial-time fragment) previously introduced by Drakengren and Bjareland.

#index 1273755
#* A logic of intention
#@ Xiaoping Chen;Guiquan Liu
#t 1999
#c 11
#% 36815
#% 68239
#% 205381
#% 371172
#% 521359
#! There is a lot of research on formalization of intention. The common idea of these theories is to interprete intention as an unary modal operator in Kripkean semantics. These theories suffer from the side-effect problem seriously. We introduce an alternative approach by establishing a nonclassical logic of intention. This logic is based on a novel non-Kripkean semantics which embodies some cognitive features. We show that this logic does provide a formal specification and a decidable inference mechanism of intention consequences. All and only the instances of sideeffects, except ones in absorbent forms, are forbidden in the logic.

#index 1273756
#* Considerations on a similarity-based approach to belief change
#@ James P. Delgrande
#t 1999
#c 11
#! A foundational approach to modelling belief contraction and revision is presented, based on a notion of similarity between belief sets. In contracting α from a belief set, the result is the belief set(s) most similar to the original in which α is not believed; similar considerations apply to belief revision. The modelling of belief change generalises the Grove modelling based on a system of spheres, where instead of having a total order on sets of possible worlds, we have a total order on sets of belief sets. Given this modelling, sets of postulates are determined for contraction and revision. The resulting postulate sets subsume those in the AGM approach. The approach sheds light on the foundations of belief revision in that, first, it provides a more general framework than the AGM approach; second, it, illustrates assumptions under lying the AGM approach; and third, it allows a "fine-grained" investigation of proposed principles underlying belief change. Lastly, it demonstrates that, at their most, basic, revision and contraction of beliefs are not interdefinable notions, but rather distinct concepts.

#index 1273757
#* Postulates for conditional belief revision
#@ Gabriele Kern-Isberner
#t 1999
#c 11
#% 109945
#% 163719
#% 211580
#% 224753
#% 250115
#! In this paper, we present a scheme of postulates for revising epistemic states by conditional beliefs. These postulates are supported mainly by following the specific, non-classical nature of conditionals, and the aim of preserving conditional beliefs is achieved by studying specific interactions between conditionals, represented properly by two relations. Because one of the postulates claims propositional belief revision to be a special case of conditional belief revision, our framework also covers the work of Darwiche and Pearl [Darwiche and Pearl, 1997], and we show that all postulates presented there may be derived from our postulates. We state representation theorems for the principal postulates, and finally, we present a conditional belief operator obeying all of the postulates by using ordinal conditional functions as representations of epistemic states.

#index 1273758
#* An inconsistency tolerant model for belief representation and belief revision
#@ Samir Chopra;Rohit Parikh
#t 1999
#c 11
#% 18600
#% 296028
#% 555526
#% 781173
#% 782324
#% 1290096
#! We propose a new model for representing and revising belief structures, which relies on a notion of partial language splitting and tolerates some amount of inconsistency while retaining classical logic. The model preserves an agent's ability to answer queries in a coherent way using Belnap's four-valued logic. Axioms analogous to the AGM axioms hold for this new model. The distinction between implicit and explicit beliefs is represented and psychologically plausible, computationally tractable procedures for query answering and belief base revision are obtained.

#index 1273759
#* Programming resource-bounded deliberative agents
#@ Michael Fisher;Chiara Ghidini
#t 1999
#c 11
#% 4599
#% 101955
#% 116625
#% 160385
#% 181576
#% 188086
#% 244315
#% 1273720
#! This paper is concerned with providing a common framework for both the logical specification and execution of agents. While numerous high-level agent theories have been proposed in order to model agents, such as theories of intention, these often have little formal connection to practical agentbased systems. On the other hand, many of the agent-based programming languages used for implementing real agents lack firm logical semantics. Our approach is to define a logical framework in which agents can be specified, and then show how such specifications can be directly executed in order to implement the agent's behaviour. We here extend this approach to capture an important aspect of practical agents, namely their resource-bounded nature. We present a logic in which resource-boundedness can be specified, and then consider how specifications within this logic can be directly executed. The mechanism we use to capture finite resources is to replace the standard modal logic previously used to represent an agent's beliefs, with a multi-context representation of belief, thus providing tight control over the agent's reasoning capabilities where necessary. This logical framework provides the basis for the specification and execution of agents comprising dynamic (temporal) activity, deliberation concerning goals, and resource-bounded reasoning.

#index 1273760
#* Exploiting a common property resource under a fairness constraint: a case study
#@ Michel Lemaitre;Gerard Verfaillie;Nicolas Bataille
#t 1999
#c 11
#% 126386
#% 266129
#% 535469
#% 1275308
#% 1275309
#% 1499492
#! Resources co-funded by several agents must be exploited in such a way that three kinds of constraints are met: (1) physical problem (hard) constraints; (2) efficiency constraints, aiming at maximizing the satisfaction of each agent; (3) a fairness constraint, which is ideally satisfied when each agent receives an amount of the resource exactly proportional to its financial contribution. This paper investigates a decision problem for which the common property resource is an earth observation satellite. The problem is to decide on the daily selection of a subset of pictures, among a set of candidate pictures which could be taken the next day considering the satellite trajectory. This subset must satisfy the three kinds of constraints stated above. Although fair division problems have received considerable attention for a long time, especially from microeconomists, this specific problem does not fall entirely within a classical approach. This is because the candidate pictures may be incompatible, and because a picture is only of value to the agent requesting it. As in the general case, efficiency and fairness constraints are antagonistic. We propose three ways for solving this share problem. The first one gives priority to fairness, the second one to efficiency, and the third one computes a set of compromises.

#index 1273761
#* Maximization of the average quality of anytime contract algorithms over a time interval
#@ Arnaud Delhay;Max Dauchet;Patrick Taillibert;Philippe Vanheeghe
#t 1999
#c 11
#% 68238
#% 205385
#% 297321
#% 1275327
#! Previous studies considered quality optimization of anytime algorithms by taking into account the quality of the final result. The problem we are interested in is the maximization of the average quality of a contract algorithm over a time interval. We first informally illustrate and motivate this problem with few concrete situations. Then we prove that the problem is NPhard, but quadratic if the time interval is large enough. Eventually we give empirical results.

#index 1273762
#* Demand-driven discovery of adaptation knowledge
#@ David McSherry
#t 1999
#c 11
#% 257885
#% 359837
#% 405727
#% 490457
#% 490605
#% 494277
#% 566457
#% 1273710
#! A case-based approach to adaptation for estimation tasks is presented in which there is no requirement for explicit adaptation knowledge. Instead, a target case is estimated from the values of three existing cases, one retrieved for its similarity to the target case and the others to provide the knowledge required to adapt the similar case. With recursive application of the adaptation process, any problem space can be fully covered by fewer than nk selected cases, where n is the number of case attributes and k is the number of values of each attribute. Moreover, a k × k problem space is fully covered by any set of 2k - 1 known cases provided there is no redundancy in the case library. Circumstances in which the approach is appropriate are identified by theoretical analysis and confirmed by experimental results.

#index 1273763
#* Dynamic refinement of feature weights using quantitative introspective learning
#@ Zhong Zhang;Qiang Yang
#t 1999
#c 11
#% 117076
#% 166780
#% 168280
#% 168427
#% 229972
#% 490439
#% 494248
#% 494577
#% 1275276
#! Recently more and more researchers have been supporting the view that learning is a goaldriven process. One of the key properties of a goal-driven learner is introspectiveness-the ability to notice the gaps in its knowledge and to reason about the information required to fill in those gaps. In this paper, we introduce a quantitative introspective learning paradigm into case-based reasoning (CBR). The result is an integrated problem-solving model which will learn introspectively feature weights in a case base in order to be responsive dynamically to its users. In contrast to the existing qualitative methods for introspective learning, our model has the advantage of being able to capture accurate learning information in the interactions with its users. A CBR system equipped with quantitative introspective learning ability can allow the feature weights to be captured automatically and to track its users' changing preferences continuously. In such a system, while the reasoning part is still case-based, the learning part is shouldered by a quantitative introspective learning model. Weight learning and evolution are accomplished in the background. The effectiveness of this integration will be demonstrated through a series of empirical experiments.

#index 1273764
#* Remembering to add: competence-preserving case-addition policies for case-base maintenance
#@ Jim Zhu;Qiang Yang
#t 1999
#c 11
#% 68243
#% 89781
#% 92533
#% 154075
#% 194651
#% 210182
#% 243193
#% 258186
#% 362441
#% 408396
#% 494248
#% 494448
#% 494577
#% 494593
#% 566460
#% 1272367
#% 1275276
#% 1290056
#! Case-base maintenance is gaining increasing recognition in research and the practical applications of case-based reasoning (CBR). This intense interest is highlighted by Smyth and Keane's research on case deletion policies. In their work, Smyth and Keane advocated a case deletion policy, whereby the cases in a case base are classified and deleted based on their coverage potential and adaptation power. The algorithm was empirically shown to improve the competence of a CBR system and outperform a number of previous deletion-based strategies. In this paper, we present a different case-base maintenance policy that is based on case addition rather than deletion. The advantage of our algorithm is that we can place a lower bound on the competence of the resulting case base; we demonstrate that the coverage of the computed case base cannot be worse than the optimal case base in coverage by a fixed lower bound, and the coverage is often much closer to optimum. We also show that the Smyth and Keane's deletion based policy cannot guarantee any such lower bound. Our result highlights the importance of finding the right case-base maintenance algorithm in order to guarantee the best case-base coverage. We demonstrate the effectiveness of our algorithm through an experiment in case-based planning.

#index 1273765
#* PEBM: a probabilistic exemplar based model
#@ Andres F. M. Rodriguez;Sunil Vadera
#t 1999
#c 11
#% 44876
#% 65653
#% 89782
#% 168280
#% 229972
#% 458291
#% 490449
#! A central problem in case based reasoning (CBR) is how to store and retrieve cases. One approach to this problem is to use exemplar based models, where only the prototypical cases are stored. However, the development of an exemplar based model (EBM) requires the solution of several problems: (i) how can a EBM be represented? (ii) given a new case, how can a suitable exemplar be retrieved? (iii) what makes a good exemplar? (iv) how can an EBM be learned incrementally? This paper develops a new model, called a probabilistic exemplar based model, that addresses these questions. The model utilizes Bayesian networks to develop a suitable representation and uses probabilistic propagation for assessing and retrieving exemplars when a new case is presented. The model learns incrementally by revising the exemplars retained and by updating the conditional probabilities required by the Bayesian network. The paper also presents the results of evaluating the model on three datasets.

#index 1273766
#* Toward a probabilistic formalization of case-based inference
#@ Eyke Hullermeier
#t 1999
#c 11
#% 92533
#% 176887
#% 264644
#% 494585
#% 566639
#% 670205
#! We propose a formal framework for modelling case-based inference (CBI), which is a crucial part of the case-based reasoning (CBR) methodology. As a representation of the similarity structure of a system, the concept of a similarity profile is introduced. This concept makes it possible to formalize the CBR hypothesis that "similar problems have similar solutions" and to realize CBI in the form of constraint-based inference. In order to exploit the similarity structure more efficiently, a probabilistic generalization of the constraintbased view is developed. This formalization allows for realizing CBI in the context of probabilistic reasoning and statistical inference and, hence, makes a powerful methodological framework accessible to CBR. Within the generalized setting, a (formalized) CBR hypothesis corresponds to the assumption of a certain stochastic model, and a memory of cases can be seen as statistical data underlying the inference process. As a particular result we establish an approximate probabilistic reasoning scheme which generalizes the constraint-based approach.

#index 1273767
#* A Lattice machine approach to automated casebase design: marrying lazy and eager learning
#@ Hui Wang;Werner Dubitzky;Ivo Duntsch;David Bell
#t 1999
#c 11
#% 44625
#% 246243
#% 359837
#% 376266
#% 454954
#% 490442
#% 566460
#% 1275276
#! Case-based reasoning (CBR) is concerned with solving new problems by adapting solutions that worked for similar problems in the past. Years of experience in building and fielding CBR systems have shown that the "rase approach" is not free from problems. It has been realized that the knowledge engineering effort required for designing many real-world easebases can be prohibitively high. Based on the wide-spread use of databases and powerful machine learning methods, some CBR researchers have been investigating the possibility of designing casebases automatically. This paper proposes a flexible model for the automatic discovery of abstract cases from data bases based on the Lattice Machine. It also proposes an efficient and effective algorithm for retrieving such cases. Besides the known benefits associated with abstract cases, the main advantages of this approach are that the discovery process is fully automated (no knowledge engineering costs).

#index 1273768
#* Adaptive web sites: conceptual cluster mining
#@ Mike Perkowitz;Oren Etzioni
#t 1999
#c 11
#% 18713
#% 46809
#% 61792
#% 68279
#% 73374
#% 115478
#% 262045
#% 266283
#% 405121
#% 449569
#% 451052
#% 481290
#% 481754
#% 481779
#% 1273676
#! The creation of a complex web site is a thorny problem in. user interface design. In IJCAI '97, we challenged the AI community to address this problem by creating adaptive web sites. In response, we investigate the problem of index page synthesis - the automatic creation of pages that facilitate a visitor's navigation of a Web site. Previous work has employed statistical methods to generate candidate index pages that are of limited value because they do not correspond to concepts or topics that are intuitive to people. In this paper we formalize index page synthesis as a conceptual clustering problem and introduce a novel approach which we call conceptual cluster mining: we search for a small number of cohesive clusters that correspond to concepts in a given concept description language L. Next, we present SGML, an algorithm schema that combines a statistical clustering algorithm with a concept learning algorithm. The clustering algorithm is used to generate seed clusters, and the concept learning algorithm to describe these seed clusters using expressions in L. Finally, we offer preliminary experimental evidence that instantiations of SGML outperform existing algorithms (e.g., COBWEB) in this domain.

#index 1273769
#* An assessment of submissions made to the predictive toxicology evaluation challenge
#@ A. Srinivasan;R. D. King;D. W. Bristol
#t 1999
#c 11
#% 1273674
#! Constructing "good" models for chemical carcinogenesis was identified in IJCAI-97 as providing a substantial challenge to "knowledge discovery" programs. Attention was drawn to a comparative exercise which called for predictions on the outcome of 30 rodent carcinogenicity bioassays. This-the Predictive Toxicology Evaluation (or PTE) Challenge - was seen to provide AI programs with an opportunity to participate in an enterprise of scientific merit, and a yardstick for comparison against strong competition. Here we provide an assessment of the machine learning (ML) submissions made. Models submitted are assessed on: (1) their accuracy, in comparison to models developed with expert collaboration; and (2) their explanatory value for toxicology. The principal findings were: (a) using structural information available from a standard modelling package, layman-devised features, and outcomes of established biological tests, results from MLderived models were at least as good as those with expert-derived techniques. This was surprising; (b) the combined use of structural and biological features by ML-derived models was unusual, and suggested new avenues for toxicology modelling. This was also unexpected; and (c) significant effort was required to interpret the output of even the most "symbolic" of ML-derived models. Much of this could have been alleviated with measures for converting the results into a more "toxicology-friendly" form. As it stands, their absence is sufficient to prevent a whole-hearted acceptance of these promising methods by toxicologists. This suggests that ML techniques have been able to respond -not fully, but nevertheless substantially -to the PTE Challenge.

#index 1273770
#* Two fielded teams and two experts: a RoboCup challenge response from the trenches
#@ Milind Tambe;Gal A. Kaminka;Stacy Marsella;Ion Muslea;Taylor Raines
#t 1999
#c 11
#% 75896
#% 136350
#% 265798
#% 506280
#% 567057
#% 1272316
#% 1273677
#! The RoboCup (robot world-cup soccer) effort, initiated to stimulate research in multi-agents and robotics, has blossomed into a significant effort of international proportions. RoboCup is simultaneously a fundamental research effort and a set of competitions for testing research ideas. At IJCAI'97, a broad research challenge was issued for the RoboCup synthetic agents, covering areas of multi-agent learning, teamwork and agent modeling. This paper outlines our attack on the entire breadth of the RoboCup research challenge, on all of its categories, in the form of two fielded, contrasting RoboCup teams, and two off-line soccer analysis agents. We compare the teams and the agents to generalize the lessons learned in learning, teamwork and agent modeling.

#index 1273771
#* Compiling knowledge into decomposable negation normal form
#@ Adnan Darwiche
#t 1999
#c 11
#% 204396
#% 219474
#! We propose a method for compiling propositional theories into a new tractable form that we refer to as decomposable negation normal form (DNNF). We show a number of results about our compilation approach. First, we show that every propositional theory can be compiled into DNNF and present an algorithm to this effect. Second, we show that if a clausal form has a bounded treewidth, then its DNNF compilation has a linear size and can be computed in linear time - treewidth is a graphtheoretic parameter which measures the connectivity of the clausal form. Third, we show that once a propositional theory is compiled into DNNF, a number of reasoning tasks, such as satisfiability and forgetting, can be performed in linear time. Finally, we propose two techniques for approximating the DNNF compilation of a theory when the size of such compilation is too large to be practical. One of the techniques generates a sound but incomplete compilation, while the other generates a complete but unsound compilation. Together, these approximations bound the exact compilation from below and above in terms for their ability to answer queries.

#index 1273772
#* Using Walk-SAT and Rel-SAT for cryptographic key search
#@ Fabio Massacci
#t 1999
#c 11
#% 3873
#% 160270
#% 169600
#% 191721
#% 210195
#% 261386
#% 514013
#% 1273681
#% 1478761
#! Computer security depends heavily on the strength of cryptographic algorithms. Thus, cryptographic key search is often THE search problem for many governments and corporations. In the recent years, AI search techniques have achieved notable successes in solving "real world" problems. Following a recent result which showed that the properties of the U.S. Data Encryption Standard can be encoded in propositional logic, this paper advocates the use of cryptographic key search as a benchmark for propositional reasoning and search. Benchmarks based on the encoding of cryptographic algorithms optimally share the features of "real world" and random problems. In this paper, two state-of-the-art AI search algorithms, Walk-SAT by Kautz & Selman and Rel-SAT by Bayardo & Schrag, have been tested on the encoding of the Data Encryption Standard, to see whether they are up the task, and we discuss what lesson can be learned from the analysis on this benchmark to improve SAT solvers. New challenges in this field conclude the paper.

#index 1273773
#* SAT-encodings, search space structure, and local search performance
#@ Holger H. Hoos
#t 1999
#c 11
#% 116559
#% 126390
#% 539605
#% 1271884
#% 1272321
#% 1273681
#% 1476298
#% 1478779
#% 1650591
#! Stochastic local search (SLS) algorithms for prepositional satisfiability testing (SAT) have become popular and powerful tools for solving suitably encoded hard combinatorial from different domains like, e.g., planning. Consequently, there is a considerable interest in finding SAT-encodings which facilitate the efficient application of SLS algorithms. In this work, we study how two encodings schemes for combinatorial problems, like the well-known Constraint Satisfaction or Hamilton Circuit Problem, affect SLS performance on the SAT-encoded instances. To explain the observed performance differences, we identify features of the induces search spaces which affect SLS performance. We furthermore present initial results of a comparitive analysis of the performance of the SAT-encoding and-solving approach versus that of native SLS algorithms directly applied to the unencoded problem instances.

#index 1273774
#* On the use of integer programming models in AI planning
#@ Thomas Vossen;Michael Ball;Amnon Lotem;Dana Nau
#t 1999
#c 11
#% 11728
#% 40368
#% 224480
#% 266680
#% 283198
#% 1273681
#% 1476298
#% 1478837
#! Recent research has shown the promise of using propositional reasoning and search to solve AI planning problems. In this paper, we further explore this area by applying Integer Programming to solve AI planning problems. The application of Integer Programming to AI planning has a potentially significant advantage, as it allows quite naturally for the incorporation of numerical constraints and objectives into the planning domain. Moreover, the application of Integer Programming to AI planning addresses one of the challenges in propositional reasoning posed by Kautz and Selman, who conjectured that the principal technique used to solve Integer Programs--the linear programming (LP) relaxation--is not useful when applied to propositional search. We discuss various IP formulations for the class of planning problems based on STRIPS-style planning operators. Our main objective is to show that a carefully chosen IP formulation significantly improves the "strength" of the LP relaxation, and that the resultant LPs are useful in solving the IP and the associated planning problems. Our results clearly show the importance of choosing the "right" representation, and more generally the promise of using Integer Programming techniques in the AI planning domain.

#index 1273775
#* The LPSAT engine & its application to resource planning
#@ Steven A. Wolfman;Daniel S. Weld
#t 1999
#c 11
#% 56471
#% 82637
#% 97290
#% 103050
#% 109935
#% 115193
#% 179938
#% 237069
#% 266200
#% 283088
#% 283198
#% 318185
#% 495768
#% 544766
#% 695972
#% 1271884
#% 1271951
#% 1273681
#% 1273727
#% 1290109
#% 1476298
#% 1478761
#! Compilation to boolean satisfiability has become a powerful paradigm for solving AI problems. However, domains that require metric reasoning cannot be compiled efficiently to SAT even if they would otherwise benefit from compilation. We address this problem by introducing the LCNF representation which combines propositional logic with metric constraints. We present LPSAT, an engine which solves LCNF problems by interleaving calls to an incremental simplex algorithm with systematic satisfaction methods. We describe a compiler which converts metric resource planning problems into LCNF for processing by LPSAT. The experimental section of the paper explores several optimizations to LPSAT, including learning from constraint failure and randomized cutoffs.

#index 1273776
#* Unifying SAT-based and graph-based planning
#@ Henry Kautz;Bart Selman
#t 1999
#c 11
#% 131357
#% 154075
#% 155827
#% 160270
#% 215878
#% 266200
#% 266388
#% 266398
#% 283196
#% 283220
#% 544766
#% 544782
#% 544784
#% 669578
#% 1271884
#% 1273680
#% 1273727
#% 1290109
#% 1476298
#% 1478761
#! The Blackbox planning system unifies the planning as satisfiability framework (Kautz and Selman 1992, 1996) with the plan graph approach to STRIPS planning (Blum and Furst 1995). We show that STRIPS problems can be directly translated into SAT and efficiently solved using new randomized systematic solvers. For certain computationally challenging benchmark problems this unified approach outperforms both SATPLAN and Graphplan alone. We also demonstrate that polynomialtime SAT simplification algorithms applied to the encoded problem instances are a powerful complement to the "mutex" propagation algorithm that works directly on the plan graph.

#index 1273777
#* Temporal planning with mutual exclusion reasoning
#@ David E. Smith;Daniel S. Weld
#t 1999
#c 11
#% 107137
#% 179938
#% 224480
#% 266387
#% 534160
#% 544766
#% 1272392
#% 1290109
#! Many planning domains require a richer notion of time in which actions can overlap and have different durations. The key to fast performance in classical planners (e.g., Graphplan, IPP, and Blackbox) has been the use of a disjunctive representation with powerful mutual exclusion reasoning. This paper presents TGP, a new algorithm for temporal planning. TGP operates by incrementally expanding a compact planning graph representation that handles actions of differing duration. The key to TGP performance is tight mutual exclusion reasoning which is based on an expressive language for bounding mutexes and includes mutexes between actions and propositions. Our experiments demonstrate that mutual exclusion reasoning remains valuable in a rich temporal setting.

#index 1273778
#* An anthropocentric tool for decision making support
#@ Elisabeth Le Saux;Philippe Lenca;Philippe Picouet;Jean-Pierre Barthelemy
#t 1999
#c 11
#% 136350
#% 449588
#! Nowadays, firms, formerly considering the human operator as the main error source in process control, bend their efforts towards anthropocentric approaches to (re)integrate the human factor, especially the knowledge he/she has been developping, as the essential resource for a high quality decision process. As the expert operator remains a rare resource and in order to capitalize his/her knowledge and know-how, the development, of tools integrating this new dimension has become an important challenge. This paper deals with a tool for knowledge acquisition under cognitive constraints, assuming that cognitive principles could be sometimes useful to improve machine learning tools results. Additionally, we have to cope with the difficulty linked to the fact that the acquired strategies have to be adapted on-line. After describing the underlying cognitive principles, we will introduce the decision representation space and its related notations. We will then show the difficulties linked to the search of an optimal representation of the expert strategies set and how the heuristics used by the algorithm studied avoid these NP-complete problems. Finally, the current results and our work perspectives are stated.

#index 1273779
#* Autonomous concept formation
#@ Edwin D. De Jong
#t 1999
#c 11
#% 100336
#% 154046
#% 266288
#% 269999
#% 281061
#% 370109
#% 377895
#% 384911
#% 449588
#% 702594
#! A model for the formation of situation concepts is described. A characteristic of this form of concept formation is that it does not require instructive feedback. This renders it suitable for concept formation by autonomous agents. It is experimentally demonstrated that situation concepts constructed independently by several agents can convey useful information between agents through a learned system of communication. A relation was found between the development of the learned system of communication and the duration of the situations.

#index 1273780
#* Reasoning about actions in narrative understanding
#@ Srinivas Narayanan
#t 1999
#c 11
#% 380725
#% 706138
#% 1290150
#! Reasoning about actions has been a focus of interest in AI from the beginning and continues to receive attention. Rut the range of situations considered has been rather narrow and falls well short of what is needed for understanding natural language. Language understanding requires sophisticated reasoning about actions and events and the world's languages employ a variety of grammatical and lexical devices to construe, direct attention and focus on, and control inferences about actions and events. We implemented a neurally inspired computational model that is able to reason about, linguistic action and event descriptions, such as those found in news stories. The system uses an active. event representation that also seems to provide natural and cognitiveIy motivated solutions to classical problems in logical theories of reasoning about actions. For logical approaches to reasoning about actions, we suggest, that looking at story understanding sets up fairly strong desiderata both in terms of the fine-grained event and action distinctions and the kinds of real-time inferences required.

#index 1273781
#* Using a cognitive architecture to plan dialogs for the adaptive explanation of proofs
#@ Armin Fiedler
#t 1999
#c 11
#% 75896
#% 91525
#% 110352
#% 145400
#% 423966
#% 569104
#% 756795
#% 1271854
#! In order to generate high quality explanations in technical or mathematical domains, the presentation must be adapted to the knowledge of the intended audience. Current proof presentation systems only communicate proofs on a fixed degree of abstraction independently of the addressee's knowledge. In this paper we propose an architecture for an interactive proof explanation system, called Prex. Based on the theory of human cognition ACT-R., its dialog planner exploits a cognitive model, in which both the user's knowledge and his cognitive processes are modeled. By this means, his cognitive states are traced during the explanation. The explicit representation of the user's cognitive states in ACT-R allows the dialog planner to choose a degree of abstraction tailored to the user for each proof step to be explained. Moreover, the system can revise its assumptions about the user's knowledge and react to his interactions.

#index 1273782
#* Investigating the emergence of speech sounds
#@ Bart De Boer
#t 1999
#c 11
#% 211883
#% 747814
#! This paper presents a system that simulates the emergence of realistic vowel systems in a population of agents that try to imitate each other as well as possible. The agents start with no knowledge of the sound system at all. Although none of the agents has a global view of the language, and none of the agents does explicit optimization, a coherent vowel system emerges that happens to be optimal for acoustic distinctiveness. The results presented here fit in and confirm the theory of Luc Steels [Steels 1995, 1997, 1998] that views languages as a complex dynamic system and the origins of language as the result of self-organization and cultural evolution.

#index 1273783
#* Computer-aided tracing of children's physics learning: a teacher oriented view
#@ Filippo Neri
#t 1999
#c 11
#% 73373
#% 75896
#% 143185
#% 178508
#% 218962
#% 265799
#% 1499526
#! For an effective Teacher-Student interaction, the Teacher has to maintain a constant understanding of "what is going on" in the Student's mind. When coming to Physics, the Teacher's ability to propose and to relate explanations at different levels of abstraction - as a chains of causal interactions (deep) or as a set of observable phenomena (shallow) - may determine a successful and lasting learning in the Student. Here, we describe a knowledge representation to be used by the teacher to depict to herself the student's mental model and to tune her future lessons according to the current student comprehension. Supported by a cognitive theory of children physics learning, we used the system WHY for modeling the evolution of a student's learning as it appeared at the teacher's eyes. Two of WHY's features turned out to be essential: (a) to deal with explanations having different levels of abstraction, and (b) the possibility to continuously evaluate the coherence of the hypothesized learner's model with respect to her explanation. In the long term, the work's outcome might contribute to the development of teaching assistant systems that support the teacher in identifying "what has to be explained next".

#index 1273784
#* Diagrammatic proofs
#@ Norman Y. Foo;Maurice Pagnucco;Abhaya C. Nayak
#t 1999
#c 11
#% 248287
#% 375245
#% 380335
#% 759098
#! Diagrammatic reasoning comprises phenomena that range from the so-called "free-rides" (e.g. almost immediate understanding of visually perceived relationships) to conventions about tokens. Such reasoning must involve cognitive processes that are highly perceptual in content. In the domain of mathematical proofs where diagrams have had a long history, we have an opportunity to investigate in detail and in a controlled setting the various perceptual devices and cognitive processes that facilitate diagrammatically based arguments. This paper continues recent work by examining two kinds of diagrammatic proofs, called Categories 1 and 3 by [Jamnik, et al., 97], the first being one in which generalization of a diagram instance is implied, and the second being one in which an infinite completion is represented by an ellipsis. We provide explanations of why these proofs work, a semantics for ellipses, and conjectures about the underlying cognitive processes that seem to resonate with such proofs.

#index 1273785
#* Modeling the basic meanings of path relations
#@ Christian Kray;Anselm Blocher
#t 1999
#c 11
#% 180124
#% 370876
#% 526851
#% 850551
#! In the field of spatial reasoning, point-to-point relations have been thoroughly examined, but only little attention has been payed to the modeling of path relations. We propose a computational model that extends the existing referential semantics for point-to-point relations to path relations. On the linguistic side, we present some research on German path prepositions as well as results on their English counterparts. This analysis of path prepositions is used to extract a semantic model for path relations. On the geometric side, we examine the characteristics of trajectories and propose a computational method to find an appropriate path relation for a given situation. Finally, we show how our findings on the linguistic and the geometric sides can be brought together to form a consistent model.

#index 1273786
#* A comparison of structural CSP decomposition methods
#@ Georg Gottlob;Nicola Leone;Francesco Scarcello
#t 1999
#c 11
#% 2028
#% 36814
#% 39265
#% 55926
#% 93660
#% 159244
#% 237054
#% 273683
#% 289332
#% 289424
#% 408396
#% 475714
#% 593867
#% 836134
#! We compare tractable classes of constraint satisfaction problems (CSPs). We first give a uniform presentation of the major structural CSP decomposition methods. We then introduce a new class of tractable CSPs based on the concept of hypertree decomposition recently developed in Database Theory. We introduce a framework for comparing parametric decomposition-based methods according to tractability criteria and compare the most relevant methods. We show that the method of hypertree decomposition dominates the others in the case of general (nonbinary) CSPs.

#index 1273787
#* Solving strategies for highly symmetric CSPs
#@ Pedro Meseguer;Carme Torras
#t 1999
#c 11
#% 319789
#% 484962
#% 497307
#% 923608
#! Symmetry often appears in real-world constraint satisfaction problems, but strategies for exploiting it are only beginning to be developed. Here, a rationale for exploiting symmetry within depth-first search is proposed, leading to an heuristic for variable selection and a domain pruning procedure. These strategies are then applied to a highly symmetric combinatorial problem, namely the generation of balanced incomplete block designs. Experimental results show that these strategies achieve a reduction of up to two orders of magnitude in computational effort. Interestingly, two previously developed strategies are shown to be particular instances of this approach.

#index 1273788
#* Extending consistent domains of numeric CSP
#@ Helene Collavizza;Francois Delobel;Michel Rueher
#t 1999
#c 11
#% 21144
#% 160383
#% 181030
#% 225336
#! This paper introduces a new framework for extending consistent domains of numeric CSP. The aim is to offer the greatest possible freedom of choice for one variable to the designer of a CAD application. Thus, we provide here an efficient and incremental algorithm which computes the maximal extension of the domain of one variable. The key point of this framework is the definition, for each inequality, of an univariate extrema function which computes the left most and right most solutions of a selected variable (in a space delimited by the domains of the other variables). We show how these univariate extrema functions can be implemented efficiently. The capabilities of this approach are illustrated on a ballistic example.

#index 1273789
#* The difference all-difference makes
#@ Kostas Stergiou;Toby Walsh
#t 1999
#c 11
#% 160208
#% 224767
#% 266117
#% 496249
#% 688914
#% 1275265
#% 1478764
#! We perform a comprehensive theoretical and experimental analysis of the use of all-different constraints. We prove that generalized arc-consistency on such constraints lies between neighborhood inverse consistency and, under a simple restriction, path inverse consistency on the binary representation of the problem. By generalizing the arguments of Kondrak and van Beek, we prove that a search algorithm that maintains generalized arc-consistency on all-different constraints dominates a search algorithm that maintains arc-consistency on the binary representation. Our experiments show the practical value of achieving these high levels of consistency. For example, we can solve almost all benchmark quasigroup completion problems up to order 25 with just a few branches of search. These results demonstrate the benefits of using non-binary constraints like all-different to identify structure in problems.

#index 1273790
#* The symmetric alldiff constraint
#@ Jean-Charles Regin
#t 1999
#c 11
#% 1451
#% 160208
#% 1068448
#! The symmetric alldiff constraint is a particular case of the all diff constraint, a case in which variables and values are defined from the same set 5. That is, every variable represents an element c of S and its values represent the elements of S that are compatible with c. This constraint requires that all the values taken by the variables are different (similar to the classical all diff constraint) and that if the variable representing the element i is assigned to the value representing the element j, then the variable representing the element j is assigned to the value representing the element?. This constraint is present in many real-world problems, such sports scheduling where it expresses matches between teams. In this paper, we show how to compute the arc consistency of this constraint in O(n,m) (m = Σi|D(i)|), where n is the number of involved variables and D(i) the domain of the variable i. We also propose a filtering algorithm of less complexity (O(m)).

#index 1273791
#* Branch and bound with mini-bucket heuristics
#@ Kalev Kask;Rina Dechter
#t 1999
#c 11
#% 44876
#% 101250
#% 527842
#% 1650617
#% 1650711
#% 1650778
#! The paper describes a branch and bound scheme that uses heuristics generated mechanically by the mini-bucket approximation. This scheme is presented and evaluated for optimization tasks such as finding the Most Probable Explanation (MPE) in Bayesian networks. The mini-bucket scheme yields monotonic heuristics of varying strengths which cause different amounts of pruning, allowing a controlled tradeoff between preprocessing and search. The resulting Branch and Bound with Mini-Bucket heuristic (BBMB), is evaluated using random networks, probabilistic decoding and medical diagnosis networks. Results show that the BBMB scheme overcomes the memory explosion of bucket-elimination allowing a gradual tradeoff of space for time, and of time for accuracy.

#index 1273792
#* Improving search using indexing: a study with temporal CSPs
#@ Nikos Mamoulis;Dimitris Papadias
#t 1999
#c 11
#% 2115
#% 36814
#% 66926
#% 126395
#% 172500
#% 283089
#% 319244
#% 427199
#% 479620
#% 534160
#% 1499502
#! Most studies concerning constraint satisfaction problems (CSPs) involve variables that take values from small domains. This paper deals with an alternative form of temporal CSPs; the number of variables is relatively small and the domains are large collections of intervals. Such situations may arise in temporal databases where several types of queries can be modeled and processed as CSPs. For these problems, systematic CSP algorithms can take advantage of temporal indexing to accelerate search. Directed search versions of chronological backtracking and forward checking are presented and tested. Our results show that indexing can drastically improve search performance.

#index 1273793
#* A new tractable subclass of the rectangle algebra
#@ P. Balbiani;J.-F. Condotta;L. Farinas Del Cerro
#t 1999
#c 11
#% 126395
#% 131372
#% 160209
#% 319244
#% 549078
#% 1499525
#! This paper presents the 169 permitted relations between two rectangles whose sides are parallel to the axes of some orthogonal basis in a 2-dimensional Euclidean space. Elaborating rectangle algebra just like interval algebra, it defines the concept of convexity as well as the ones of weak preconvexity and strong preconvexity. It introduces afterwards the fundamental operations of intersection, composition and inversion and demonstrates that the concept of weak preconvexity is preserved by the operation of composition whereas the concept of strong preconvexity is preserved by the operation of intersection. Finally, fitting the propagation techniques conceived to solve interval networks, it shows that the polynomial path-consistency algorithm is a decision method for the problem of proving the consistency of strongly preconvex rectangle networks.

#index 1273794
#* Maximal tractable fragments of the region connection calculus: a complete analysis
#@ Jochen Renz
#t 1999
#c 11
#% 82720
#% 121993
#% 181229
#% 270714
#% 319244
#% 408396
#% 1271925
#% 1499525
#! We present a general method for proving tractability of reasoning over disjunctions of jointly exhaustive and pairwise disjoint relations. Examples of these kinds of relations are Allen's temporal interval relations and their spatial counterpart, the R.CC8 relations by Randell, Cui, and Colin. Applying this method does not require detailed knowledge about the considered relations; instead, it is rather sufficient to have a subset of the considered set of relations for which path-consistency is known to decide consistency. Using this method, we give a complete classification of tractability of reasoning over RCC8 by identifying two large new maximal tractable subsets and show that these two subsets together with H∞, the already known maximal tractable subset, are the only such sets for RCC8 that contain all base relations. We also apply our method to Allen's interval algebra and derive the known maximal tractable subset.

#index 1273795
#* Path consistency on triangulated constraint graphs
#@ Christian Bliek;Djamila Sam-Haroud
#t 1999
#c 11
#% 1604
#% 3463
#% 42007
#% 231740
#% 1499494
#! Among the local consistency techniques used in the resolution of constraint satisfaction problems (CSPs), path consistency (PC) has received a great deal of attention. A constraint graph G is PC if for any valuation of a pair of variables that satisfy the constraint in G between them, one can find values for the intermediate variables on any other path in G between those variables so that all the constraints along that path are satisfied. On complete graphs, Montanari showed that PC holds if and only if each path of length two is PC. By convention, it is therefore said that a CSP is PC if the completion of its constraint graph is PC. In this paper, we show that Montanari's theorem extends to triangulated graphs. One can therefore enforce PC on sparse graphs by triangulating instead of completing them. The advantage is that with triangulation much less universal constraints need to be added. We then compare the pruning capacity of the two approaches. We show that when the constraints are convex, the pruning capacity of PC on triangulated graphs and their completion are identical on the common edges. Furthermore, our experiments show that there is little difference for general nonconvex problems.

#index 1273796
#* A new method to index and query sets
#@ Jorg Hoffmann;Jana Koehler
#t 1999
#c 11
#% 166347
#% 224480
#% 237204
#% 544766
#! Let us consider the following problem: Given a (probably huge) set of sets S and a query set g, is there some set s Ε S such s ⊆ q; that This problem occurs in at least four application areas: the matching of a large number (usually several 100,000s) of production rules, the processing of queries in data bases supporting set-valued attributes, the identification of inconsistent subgoals during artificial intelligence planning and the detection of potential periodic chains in labeled tableau systems for modal logics. In this paper, we introduce a data structure and algorithm that allow a compact representation of such a huge set of sets and an efficient answering of subset and superset queries. The algorithm has been used successfully in the IPP system and enabled this planner to win the ADL track of the first planning competition.

#index 1273797
#* Constraint propagation and value acquisition: why we should do it interactively
#@ E. Lamma;P. Mello;M. Milano;R. Cucchiara;M. Gavanelli;M. Piccardi
#t 1999
#c 11
#% 8421
#% 33204
#% 49239
#% 56471
#% 135486
#% 208702
#% 497973
#! In Constraint Satisfaction Problems (CSPs) values belonging to variable domains should be completely known before the constraint propagation process starts. In many applications, however, the acquisition of domain values is a computational expensive process or some domain values could not be available at the beginning of the computation. For this purpose, we introduce an Interactive Constraint Satisfaction Problem (ICSP) model as extension of the widely used CSP model. The variable domain values can be acquired when needed during the resolution process by means of Interactive Constraints, which retrieve (possibly consistent) information. Experimental results on randomly generated CSPs and for 3D object recognition show the effectiveness of the proposed approach.

#index 1273798
#* Sequential optimality and coordination in multiagent systems
#@ Craig Boutilier
#t 1999
#c 11
#% 39250
#% 363744
#% 393786
#% 1650766
#! Coordination of agent activities is a key problem in multiagent systems. Set in a larger decision theoretic context, the existence of coordination problems leads to difficulty in evaluating the utility of a situation. This in turn makes defining optimal policies for sequential decision processes problematic. We propose a method for solving sequential multi-agent decision problems by allowing agents to reason explicitly about specific coordination mechanisms. We define an extension of value iteration in which the system's state space is augmented with the state of the coordination mechanism adopted, allowing agents to reason about the short and long term prospects for coordination, the long term consequences of (mis)coordination, and make decisions to engage or avoid coordination problems based on expected value. We also illustrate the benefits of mechanism generalization.

#index 1273799
#* A protocol-based semantics for an agent communication language
#@ Jeremy Pitt;Abe Mamdani
#t 1999
#c 11
#% 241284
#% 256538
#% 438021
#% 501927
#% 618417
#% 636348
#% 636365
#! There are fundamental limitations on using mental attitudes to formalise the semantics of an Agent Communication Language (ACL). Instead, we define a general semantic framework for an ACL in terms of protocols. We then argue that the proper role of mental attitudes is to link what an agent 'thinks' about the content of a message to what it 'does' in response to receiving that message. We formalise this connection through normative and informative specifications and demonstrate its use in communication between two BDI-style agents.

#index 1273800
#* Towards flexible multi-agent decision-making under time pressure
#@ Sanguk Noh;Piotr J. Gmytrasiewicz
#t 1999
#c 11
#% 101219
#% 107169
#% 136350
#% 163547
#% 205385
#% 423984
#% 449566
#% 636352
#% 1272375
#% 1275315
#! To perform rational decision-making, autonomous agents need considerable computational resources. In multi-agent settings, when other agents are present in the environment, these demands are even more severe. We investigate ways in which the agent's knowledge and the results of deliberative decision-making can be compiled to reduce the complexity of decision-making procedures and to save time in urgent situations. We use machine learning algorithms to compile decision-theoretic deliberations into condition-action rules on how to coordinate in a multi-agent environment. Using different learning algorithms, we endow a resource-bounded agent with a tapestry of decision making tools, ranging from purely reactive to fully deliberative ones. The agent can then select a method depending on the time constraints of the particular situation. We also propose combining the decision-making tools, so that, for example, more reactive methods serve as a pre-processing stage to the more accurate but slower deliberative decision-making ones. We validate our framework with experimental results in simulated coordinated defense. The experiments show that compiling the results of decision-making saves deliberation time while offering good performance in our multi-agent domain.

#index 1273801
#* Risk control in multi-agent coordination by negotiation with a trusted third party
#@ Shih-Hung Wu;Von-Wun Soo
#t 1999
#c 11
#% 233137
#% 233138
#% 252199
#% 257694
#% 271038
#! In multi-agent coordination, the uncertainty may come from two major sources: the moves of the nature agent and the unpredictable behavior of other autonomous agents. The uncertainty may affect the expected payoff and the risk of an agent. A rational agent would not always play the strategy that gives the highest expected payoff if the risk is too high. To tackle the uncertainty in multi-agent coordination, a risk control mechanism is necessary in multi-agent decision making. We assume agents may have different risk preferences, e.g. risk-averse, risk-neutral, and risk-seeking, and separate the risk preference from the utility function of a given strategy. Taking agent's risk preference into account extends the notions of the dominant strategy, the Nash equilibrium, and the Pareto-efficiency in traditional game theory. We show how the risk control can be carried out by a negotiation protocol using communication actions of asking guarantee and offering compensation via a trusted third party.

#index 1273802
#* Shopbots and pricebots
#@ Amy R. Greenwald;Jeffrey O. Kephart
#t 1999
#c 11
#% 543212
#! Shopbots are agents that automatically search the Internet to obtain information about prices and other attributes of goods and services. They herald a future in which autonomous agents profoundly influence electronic markets. In this study, a simple economic model is proposed and analyzed, which is intended to quantify some of the likely impacts of a proliferation of shopbots and other economically-motivated software agents. In addition, this paper reports on simulations of pricebots-adaptive, price-setting agents which firms may well implement to combat, or even take advantage of, the growing community of shopbots. This study forms part of a larger research program that aims to provide insights into the impact of agent technology on the nascent information economy.

#index 1273803
#* Be patient and tolerate imprecision: how autonomous agents can coordinate effectively
#@ Sudhir K. Rustogi;Munindar P. Singh
#t 1999
#c 11
#% 203565
#% 274915
#% 636312
#% 1272372
#! A decentralized multiagent system comprises agents who act autonomously based on local knowledge. Achieving coordination in such a system is nontrivial, hut is essential in most applications, where disjointed or incoherent behavior would be undesirable. Coordination in decentralized systems is a richer phenomenon than previously believed. In particular, five major attributes are crucial: the extent of the local knowledge and choices of the member agents, the extent of their shared knowledge, the level of their inertia, and the level of precision of the required coordination. Interestingly, precision and inertia turn out to control the coordination process. They define different regions within each of which the other attributes relate nicely with coordination, but among which their relationships are altered or even reversed. Based on our study, we propose simple design rules to obtain coordinated behavior in decentralized multiagent systems.

#index 1273804
#* Efficiency and equilibrium in task allocation economies with hierarchical dependencies
#@ William E. Walsh;Michael P. Wellman
#t 1999
#c 11
#% 267752
#% 274891
#% 306530
#% 430211
#% 496094
#% 635842
#% 636336
#% 636338
#! We analyze economic efficiency and equilibrium properties in decentralized task allocation problems involving hierarchical dependencies and resource contention. We bound the inefficiency of a type of approximate equilibrium in proportion to the number of agents and the bidding parameters in a particular market protocol. This protocol converges to an approximate equilibrium with respect to all agents, except those which may acquire unneeded inputs. We introduce a decommitment phase to allow such agents to decommit from their input contracts. Experiments indicate that the augmented market protocol produces highly efficient allocations on average.

#index 1273805
#* Sequential auctions for the allocation of resources with complementarities
#@ Craig Boutilier;Moises Goldszmidt;Bikash Sabata
#t 1999
#c 11
#% 16363
#% 203554
#% 252803
#% 267752
#% 496250
#! Market-based mechanisms such as auctions are being studied as an appropriate means for resource allocation in distributed and inultiagenl decision problems. When agents value resources in combination rather than in isolation, one generally relies on combinatorial auctions where agents bid tor resource bundles. or simultaneous auctions for all resources. We develop a different model, where agents bid for required reources sequentially. This model has the advantage that it can be applied in settings where combinatorial and simultaneous models are infeasible (e.g.. when resources are made available at different points in time by different parties), as well as certain benefits in settings where combinatorial models are applicable. We develop a dynamic programming model tor agents to compute bidding policies based on estimated distributions over prices. We also describe how these distributions are updated to provide a learning model for bidding behavior.

#index 1273806
#* Algorithms for optimizing leveled commitment contracts
#@ Tuomas Sandholm;Sandeep Sikka;Samphel Norden
#t 1999
#c 11
#% 132779
#% 174569
#% 256502
#% 1013352
#% 1499484
#! In automated negotiation systems consisting of self-interested agents, contracts have traditionally been binding. Leveled commitment contracts-i.e. contracts where each party can decommit by paying a predetermined penalty were recently shown to improve Pareto efficiency even if agents rationally decommit in Nash equilibrium using inflated thresholds on how good their outside offers must be before they decommit. This paper operationalizes the four leveled commitment contracting protocols by presenting algorithms for using them. Algorithms are presented for computing the Nash equilibrium decommitting thresholds and decommitting probabilities given the contract price and the penalties. Existence and uniqueness of the equilibrium are analyzed. Algorithms are also presented for optimizing the contract itself (price and penalties). Existence and uniqueness of the optimum are analyzed. Using the algorithms we offer a contract optimization service on the web as part of Mediator, our next generation electronic commerce server. Finally, the algorithms are generalized to contracts involving more than two agents.

#index 1273807
#* An algorithm for optimal winner determination in combinatorial auctions
#@ Tuomas Sandholm
#t 1999
#c 11
#% 2194
#% 267752
#% 282457
#% 511137
#% 656708
#! Combinatorial auctions, i.e. auctions where bidders can bid on combinations of items, tend to lead to more efficient allocations than traditional auctions in multi-item auctions where the agents' valuations of the items are not additive. However, determining the winners so as to maximize revenue is NP complete. We present a search algorithm for optimal winner determination. Experiments are shown on several bid distributions. The algorithm allows combinatorial auctions to scale up to significantly larger numbers of items and bids than prior approaches to optimal winner determination by capitalizing on the fact that the space of bids is necessarily sparsely populated in practice. We do this via provably sufficient selective generation of children in the search and by using a method for fast child generation, heuristics that are accurate and optimized for speed, and four methods for preprocessing the search space.

#index 1273808
#* Taming the computational complexity of combinatorial auctions: optimal and approximate approaches
#@ Yuzo Fujishima;Kevin Leyton-Brown;Yoav Shoham
#t 1999
#c 11
#% 203554
#% 496250
#% 650291
#% 978268
#! In combinatorial auctions, multiple goods are sold simultaneously and bidders may bid for arbitrary combinations of goods. Determining the outcome of such an auction is an optimization problem that is NP-complete in the general case. We propose two methods of overcoming this apparent intractability. The first method, which is guaranteed to be optimal, reduces running time by structuring the search space so that a modified depth-first search usually avoids even considering allocations that contain conflicting bids. Caching and pruning are also used to speed searching. Our second method is a heuristic, market-based approach. It sets up a virtual multi-round auction in which a virtual agent represents each original bid bundle and places bids, according to a fixed strategy, for each good in that bundle. We show through experiments on synthetic data that (a) our first method finds optimal allocations quickly and offers good anytime performance, and (b) in many cases our second method, despite lacking guarantees regarding optimality or running time, quickly reaches solutions that are nearly optimal.

#index 1273809
#* Speeding up ascending-bid auctions
#@ Yuzo Fujishima;David McAdams;Yoav Shoham
#t 1999
#c 11
#% 203554
#! In recent years auctions have grown in interest within the AI community as innovative mechanisms for resource allocation. The primary contribution of this paper is to identify a family of hybrid auctions, called survival auctions, which combine the benefits of both sealed-bid auctions (namely, quick and predictable termination time) and ascending-bid auctions (namely, more information revelation often leading, among other things, to better allocations and greater expected revenue). Survival auctions are multi-round sealed-bid auctions with an information-revelation component, in which some bidders are eliminated from the auction from one round to the next. These auctions are intuitive, easy to implement, and most importantly provably optimal. More precisely, we show that (a) the survival auction in which all but the lowest bidder make it into the next round (the auction lasts for (n - 1) rounds when there are n bidders) is strategically equivalent to the Japanese ascending-bid auction, which itself has been proven to be optimal in many settings, and that (b) under certain symmetry conditions, even a survival auction in which only the two highest bidders make it into the next round (the auction lasts only two rounds) is Nash outcome equivalent to the Japanese auction.

#index 1273810
#* Temporal coherence and prediction decay in TD learning
#@ Don F. Beal;Martin C. Smith
#t 1999
#c 11
#% 124689
#% 449561
#% 652445
#! This paper describes improvements to the temporal difference TD(λ) learning method. The standard form of the TD(λ) method has the problem that two control parameters, learning rate and temporal discount, need to be chosen appropriately. These parameters can have a major effect on performance, particularly the learning rate parameter, which affects the stability of the process as well as the number of observations required. Our extension to the TD(λ) algorithm automatically sets and subsequently adjusts these parameters. The learning rate adjustment is based on a new concept we call temporal coherence (TC). The experiments reported here compare the extended TD(λ) algorithm performance with human-chosen parameters and with an earlier method for learning rate adjustment, in a complex game domain. The learning task was that of learning the relative values of pieces, without any initial domain-specific knowledge, and from self-play only. The results show that the improved method leads to better learning (i.e. faster and less subject to the effects of noise), than the selection of human-chosen values for the control parameters, and a comparison method.

#index 1273811
#* Domain-dependent single-agent search enhancements
#@ Andreas Junghanns;Jonathan Schaeffer
#t 1999
#c 11
#% 189701
#% 266197
#% 533951
#% 534113
#% 1476298
#% 1478838
#! AI research has developed an extensive collection of methods to solve state-space problems. Using the challenging domain of Sokoban, this paper studies the effect of search enhancements on program performance. We show that the current state of the art in AT generally requires a large programming and research effort into domain-dependent: methods to solve even moderately complex problems in such difficult domains. The application of domain-specific knowledge to exploit properties of the search space can result in large reductions in the size of the search tree, often several orders of magnitude per search enhancement. Understanding the effect of these enhancements on the search leads to a new taxonomy of search enhancements, and a new framework for developing single-agent search applications. This is used to illustrate the large gap between what is portrayed in the literature versus what is needed in practice.

#index 1273812
#* Decomposition search: a combinatorial games approach to game tree search, with applications to solving go endgames
#@ Martin Muller
#t 1999
#c 11
#! We develop a new method called decomposition search for computing minimax solutions to games that can be partitioned into independent subgames. The method does not use traditional minimax search algorithms such as alpha-beta, but relies on concepts from combinatorial game theory to do locally restricted searches. This divide-and-conquer approach allows the exact solution of much larger problems than is possible with alpha-beta. We show an application of decomposition search to the game of Go, which has been traditionally regarded as beyond the range of exact search-based solution methods. Our experiments with solving endgames show that alpha-beta searches already become impractical in positions with about 15 remaining moves. However, an endgame solver based on decomposition search can solve a much larger class of endgame problems with solution lengths exceeding 60 moves.

#index 1273813
#* GIB: steps toward an expert-level bridge-playing program
#@ Matthew L. Ginsberg
#t 1999
#c 11
#% 39261
#% 120809
#% 235559
#% 251781
#% 266213
#% 1290051
#% 1499481
#% 1499499
#% 1499500
#! This paper describes GIB, the first bridge-playing program to approach the level of a human expert. (GIB finished twelfth in a handpicked field of thirty-four experts at an invitational event at the 1998 World Bridge Championships.) We give a basic overview of the algorithms used, describe their strengths and weaknesses, and present the results of experiments comparing GIB to both human opponents and other programs.

#index 1273814
#* An effective ship berthing algorithm
#@ Andrew Lim
#t 1999
#c 11
#! Singapore has one of the busiest ports in the world. Ship berthing is one of the problems faced by the planners at the port. In this paper, we study the ship berthing problem. We first provide the problem formulation and study the complexity of the problem with different restrictions. In general, the ship berthing problem is NP-complete, although, some of its variants may be solved quickly. While a geometrical model is intuitive, the model cannot be easily extended to handle clearance constraints and berth restriction. Rather than solving the problem geometrically, we transform the problem into the problem of fixing directions of edges in graph to form directed acyclic graph with minimal lonqest path. Since the problem is NP-complete, solving the problem exactly in polynomial time is highly unlikely. As a result, we devise a fast and effective greedy algorithm to can generate good solutions. The greedy method together with a tabu search like post optimization algorithm is able to return optimal or near optimal solutions.

#index 1273815
#* A distributed case-based reasoning application for engineering sales support
#@ Ian Watson;Dan Gardingen
#t 1999
#c 11
#% 140191
#% 258186
#% 490445
#% 494248
#% 494605
#% 566457
#! This paper describes the implementation of a distributed case-based reasoning application that supports engineering sales staff. The application operates on the world wide web and uses the XML standard as a communications protocol between client and server side Java applets. The paper describes the distributed architecture of the application, the two case retrieval techniques used, its implementation, trial, roll-out and subsequent improvements to its architecture and retrieval techniques using introspective reasoning to improve retrieval efficiency. The benefits it has provided to the company are detailed.

#index 1273816
#* Knowledge modeling and reusability in ExClaim
#@ Liviu Badea
#t 1999
#c 11
#% 100170
#% 189739
#% 362942
#% 1273695
#! This paper presents ExClaim, a hybrid language for knowledge representation and reasoning. Originally developed as an operationalization language for the KADS knowledge based systems (KBS) development methodology, ExClaim has a meta-level architecture: it structures the knowledge on three levels, namely the domain, inference and task level. An extension of a description logic is used for implementing the domain level. The inference and task levels are general logic programs integrated with the domain level by means of upward and downward reflection rules which describe the automatic domain operations performed whenever arguments of inferences or tasks are accessed. Inferences and tasks support non-deterministic reasoning, which in turn requires a non-monotonic domain level. Description logics offer a set of inference services (some not available in other knowledge representation languages) which are extremely useful in knowledge modeling. Such inference services include domain-level deduction, semantic consistency verification and automatic classification of concepts. We argue that such validation and verification facilities are important in assisting a knowledge engineer in developing models. These models are reusable due to the layered architecture as well as to the possibility of writing generic inferences using a reified membership relation.

#index 1273817
#* Verifying integrity constraints on web sites
#@ Mary Fernandez;Daniela Florescu;Alon Levy;Dan Suciu
#t 1999
#c 11
#% 140410
#% 248799
#% 248819
#% 250678
#% 252208
#% 458746
#% 464717
#% 464825
#% 565262
#% 1273676
#! Data-intensive Web sites have created a new form of knowledge base, as richly structured bodies of data. Several novel systems for creating data-intensive Web sites support declarative specification of a site's structure and content (i.e., the pages, the data available in each page, and the links between pages). Declarative systems provide a platform on which A1 techniques can be developed that, further simplify the tasks of constructing and maintaining Web sites. This paper addresses the problem of specifying and verifying integrity constraints on a Web site's structure. We describe a language that can capture many practical constraints and an accompanying sound and complete verification algorithm. The algorithm has the important property that if the constraints are violated, it proposes fixes to either the constraints or to the site definition. Finally, we establish tight bounds on the complexity of the verification problem we consider.

#index 1273818
#* Discovering chronicles with numerical time constraints from alarm logs for monitoring dynamic systems
#@ Christophe Dousson;Thang Vu Duong
#t 1999
#c 11
#% 107137
#% 252207
#% 252209
#% 252210
#! We address the problem of knowledge acquisition for alarm correlation in a complex dynamic system like a telecommunications network. To reduce the amount of information coming from telecommunications equipment, one needs to preprocess the alarm stream and we propose here a way to acquire some knowledge to do that. The key idea is that only the frequent alarm sets are relevant for reducing the information stream: we aggregate frequent relevant information and suppress frequent noisy information. We propose algorithms for analysing alarm logs: first stage is to discover frequently occurring temporally-constrained alarm sets (called chronicles) and second stage is to filter them according to their interdependency level. We also show experimental results with an actual telecommunications ATM network.

#index 1273819
#* Integrating problem-solving methods into Cyc
#@ James Stuart Aitken;Dimitrios Sklavakis
#t 1999
#c 11
#% 134111
#% 179610
#% 225467
#% 405391
#% 1499535
#! This paper argues that the reuse of domain knowledge must be complemented by the reuse of problem-solving methods. Problem-solving methods (PSMs) provide a means to structure search, and can provide tractable solutions to reasoning with a very large knowledge base. We show that PSMs can be used in a way which complements large-scale representation techniques, and optimisations such as those for taxonornie reasoning found in Cyc. Our approach illustrates the advantages of task-oriented knowledge modelling and we demonstrate that the resulting ontologies have both task-dependent and task-independent elements. Further, we show how the task ontology can be organised into conceptual levels to reflect knowledge typing principles.

#index 1273820
#* Visual planning: a practical approach to automated presentation design
#@ Michelle X. Zhou
#t 1999
#c 11
#% 44836
#% 109058
#% 109935
#% 144558
#% 145641
#% 151567
#% 214546
#% 247315
#% 319244
#% 364088
#% 702549
#% 709045
#% 1478783
#% 1499486
#! Based on a set of design principles, automated visual presentation systems promise to simplify an application programmer's design tasks by automatically constructing appropriate visual explanations for different information. However, these automated presentation systems must be equipped with a powerful inference approach to suit practical applications. Here, we present a planning-based, practical inference approach that can design a series of connected visual presentations in interactive environments. Our emphasis here is on a set of important visual planning features and how they facilitate visual design. This set of features includes a knowledge-rich representation of visual planning variables and constraints, a novel object-decomposition model that can be used with action decomposition to simplify the visual synthesis process, and practical temporal and spatial reasoning capabilities to facilitate coherent visual design and presentation. In addition, we have implemented our visual planning approach in a visual planner called PREVISE, as part of our automated presentation testbed system. A set of examples is also given to illustrate the necessity and utility of our visual planning approach.

#index 1273821
#* A case based approach to the generation of musical expression
#@ Taizan Suzuki;Takenobu Tokunaga;Hozumi Tanaka
#t 1999
#c 11
#% 173491
#! The majority of naturally sounding musical performance has musical expression (fluctuation in tempo, volume, etc.). Musical expression is affected by various factors, such as the performer, performative style, mood, and so forth. However, in past research on the computerized generation of musical expression, these factors are treated as being less significant, or almost ignored. Hence, the majority of past approaches find it relatively hard to generate multiple performance for a given piece of music with varying musical expression. In this paper, we propose a case-based approach to the generation of expressively modulated performance. This method enables the generation of varying musical expression for a single piece of music. We have implemented the proposed case-based method in a musical performance system, and, we also describe the system architecture and experiments performed on the system.

#index 1273822
#* Using focus rules in requirements elicitation dialogues
#@ Renaud Lecoeuche;Dave Robertson;Catherine Barry
#t 1999
#c 11
#% 2860
#% 6834
#% 7047
#% 9197
#% 212687
#% 261693
#% 287631
#% 669423
#% 743496
#! Requirements engineering is a complex task which benefits from computer support. Despite the progress made in automatic reasoning on requirements, the tools supporting requirements elicitation remain difficult to use. In this paper we propose a novel approach where a tool's reasoning is intimately linked to the dialogue it has with its users. Because the dialogue is guided by rules ensuring coherence, the interaction with the tool is more natural. We discuss in detail the rules we use to organise the dialogue and how we apply them to the requirements elicitation tool. We present an evaluation of this approach demonstrating improvements in usability during the elicitation process.

#index 1273823
#* Proceedings of the 16th international joint conference on Artificial intelligence - Volume 2
#@ 
#t 1999
#c 11

#index 1273824
#* A machine learning approach to building domain-specific search engines
#@ Andrew McCallum;Kamal Nigam;Jason Rennie;Kristie Seymore
#t 1999
#c 11
#% 245828
#% 252750
#% 252834
#% 266215
#% 311027
#% 465757
#% 466078
#% 466250
#% 742424
#% 1272286
#! Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This paper proposes the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific search engines. We describe new research in reinforcement learning, text classification and information extraction that enables efficient spidering, populates topic hierarchies, and identifies informative text segments. Using these techniques, we have built a demonstration system: a search engine for computer science research papers available at www.cora.justrcsettrch.com.

#index 1273825
#* Domain-specific keyphrase extraction
#@ Eibe Frank;Gordon W. Paynter;Ian H. Witten;Carl Gutwin;Craig G. Nevill-Manning
#t 1999
#c 11
#! Keyphrases are an important means of document summarization, clustering, and topic search. Only a small minority of documents have author-assigned keyphrases, and manually assigning keyphrases to existing documents is very laborious. Therefore it is highly desirable to automate the keyphrase extraction process. This paper shows that a simple procedure for keyphrase extraction based on the naive Bayes learning scheme performs comparably to the state of the art. It goes on to explain how this procedure's performance can be boosted by automatically tailoring the extraction process to the particular document collection at hand. Results on a large collection of technical reports in computer science show that the quality of the extracted keyphrases improves significantly when domain-specific information is exploited.

#index 1273826
#* Learning rules for large vocabulary word sense disambiguation
#@ Georgios Paliouras;Vangelis Karkaletsis;Constantine D. Spyropoulos
#t 1999
#c 11
#% 40100
#% 136350
#% 286069
#% 741080
#% 741083
#% 741084
#% 741085
#% 748550
#% 748594
#% 756938
#% 756952
#% 757130
#% 817954
#% 817955
#! Word Sense Disambiguation (WSD) is the process of distinguishing between different senses of a word. In general, the disambiguation rules differ for different words. For this reason, the automatic construction of disambiguation rules is highly desirable. One way to achieve this aim is by applying machine learning techniques to training data containing the various senses of the ambiguous words. In the work presented here, the decision tree learning algorithm C4.5 is applied on a corpus of financial news articles. Instead of concentrating on a small set of ambiguous words, as done in most of the related previous work, all content words of the examined corpus are disambiguated. Furthermore, the effectiveness of word sense disambiguation for different parts of speech (nouns and verbs) is examined empirically.

#index 1273827
#* The cluster-abstraction model: unsupervised learning of topic hierarchies from text data
#@ Thomas Hofmann
#t 1999
#c 11
#% 46809
#% 262059
#% 668807
#% 748465
#! This paper presents a novel statistical latent class model for text mining and interactive information access. The described learning architecture, called Cluster-Abstraction Model (CAM), is purely data driven and utilizes contact-specific word occurrence statistics. In an intertwined fashion, the CAM extracts hierarchical relations between groups of documents as well as an abstractive organization of keywords. An annealed version of the Expectation-Maximization (EM) algorithm for maximum likelihood estimation of the model parameters is derived. The benefits of the CAM for interactive retrieval and automated cluster summarization are investigated experimentally.

#index 1273828
#* Latent class models for collaborative filtering
#@ Thomas Hofmann;Jan Puzicha
#t 1999
#c 11
#% 124010
#% 173879
#% 205380
#% 269188
#% 304908
#% 668807
#! This paper presents a statistical approach to collaborative filtering and investigates the use of latent class models for predicting individual choices and preferences based on observed preference behavior. Two models are discussed and compared: the aspect model, a probabilistic latent space model which models individual preferences as a convex combination of preference factors, and the two-sided clustering model, which simultaneously partitions persons and objects into clusters. We present EM algorithms for different variants of the aspect model and derive an approximate EM algorithm based on a variational principle for the two-sided clustering model. The benefits of the different models are experimentally investigated on a large movie data set.

#index 1273829
#* Conceptual grouping in word co-occurrence networks
#@ Anne Veling;Peter Van Der Weerd
#t 1999
#c 11
#% 248058
#% 363038
#% 451052
#% 748689
#! Information Retrieval queries often result in a large number of documents found to be relevant. These documents are usually sorted by relevance, not by an analysis of what the user meant. If the document collection contains many documents on one of those meanings, it is hard to find other documents. We present a technique called conceptual grouping that automatically distinguishes between different meanings of a user query, given a document collection. By analysing a word co-occurrence network of a text database, we are able to form groups of words related to the query, grouped by semantic coherence. These groups are used to reorganise the results according to what the user has meant by his query. Testing shows that this automated technique can improve precision, help users find what they need more easily and give them a semantic overview of the document collection.

#index 1273830
#* Decision tree grafting from the all-tests-but-one partition
#@ Geoffrey I. Webb
#t 1999
#c 11
#% 92539
#% 132583
#% 209021
#% 424997
#% 1271837
#% 1272290
#% 1290030
#! Decision tree grafting adds nodes to an existing decision tree with the objective of reducing prediction error. A new grafting algorithm is presented that considers one set of training data only for each leaf of the initial decision tree, the set of cases that fail at most one test on the path to the leaf. This new technique is demonstrated to retain the error reduction power of the original grafting algorithm while dramatically reducing compute time and the complexity of the inferred tree. Bias/variance analyses reveal that the original grafting technique operated primarily by variance reduction while the new technique reduces both bias and variance.

#index 1273831
#* Constructive induction: a version space-based approach
#@ Michele Sebag
#t 1999
#c 11
#% 44625
#% 136350
#% 156186
#% 218098
#% 239245
#% 272995
#% 449508
#% 465908
#% 466063
#% 466076
#% 550551
#% 1271843
#% 1273674
#! By automatically reformulating the problem domain, constructive induction ideally overcomes the defects of the initial description. The reformulation presented here uses the Version Space primitives D(E, F), defined for any pair of examples E and F, as the set of hypotheses covering E and discriminating F. From these primitives we derive a polynomial number of M-of-N concept. Experimentally, many of these concepts turn out to be significant and consistent. A simple learning strategy thus consists of exhaustively exploring these concepts, and retaining those with sufficient quality. Tunable complexity is achieved in the MONKEI algorithm, by considering a user-supplied number of primitives D(Ei, Fi), where Ei and Fi are stochastically sampled in the training set. MONKEI demonstrates good performances on some benchmark problems, and obtains outstanding results on the Predictive Toxicology Evaluation challenge.

#index 1273832
#* Process-oriented estimation of generalization error
#@ Pedro Domingos
#t 1999
#c 11
#% 73374
#% 90155
#% 99396
#% 136350
#% 150153
#% 180945
#% 190581
#% 246834
#% 252042
#% 307109
#% 449566
#% 458229
#% 465736
#% 465927
#% 1290030
#! Methods to avoid overfitting fall into two broad categories: data-oriented (using separate data for validation) and representation-oriented (penalizing complexity in the model). Both have limitations that are hard to overcome. We argue that fully adequate model evaluation is only possible if the search process by which models are obtained is also taken into account. To this end, we recently proposed a method for process-oriented evaluation (P0E), and successfully applied it to rule induction [Domingos, 1998b]. However, for the sake of simplicity this treatment made a number of rather artificial assumptions. In this paper the assumptions are removed, and a simple formula for error estimation is obtained. Empirical trials show the new, better-founded form of POE to be as accurate as the previous one, while further reducing theory sizes.

#index 1273833
#* Transduction with confidence and credibility
#@ C. Saunders;A. Gammerman;V. Vovk
#t 1999
#c 11
#% 96673
#% 190581
#% 304876
#% 466081
#% 1650581
#! In this paper we follow the same general ideology as in [Gammerman et al., 1998], and describe a new transductive learning algorithm using Support Vector Machines. The algorithm presented provides confidence values for its predicted classifications of new examples. We also obtain a measure of "credibility" which serves as an indicator of the reliability of the data upon which we make our prediction. Experiments compare the new algorithm to a standard Support Vector Machine and other transductive methods which use Support Vector Machines, such as Vapnik's margin transduction. Empirical results show that the new algorithm not only produces confidence and credibility measures, but is comparable to, and sometimes exceeds the performance of the other algorithms.

#index 1273834
#* Leave-one-out support vector machines
#@ Jason Weston
#t 1999
#c 11
#% 190581
#% 197394
#! We present a new learning algorithm for pattern recognition inspired by a recent upper bound on leave-one-out error [Jaakkola and Haussler, 1999] proved for Support Vector Machines (SVMs) [Vapnik, 1995; 1998]. The new approach directly minimizes the expression given by the bound in an attempt to minimize leave-one-out error. This gives a convex optimization problem which constructs a sparse linear classifier in feature space using the kernel technique. As such the algorithm possesses many of the same properties as SVMs. The main novelty of the algorithm is that apart from the choice of kernel, it is parameterless - the selection of the number of training errors is inherent in the algorithm and not chosen by an extra free parameter as in SVMs. First experiments using the method on benchmark datasets from the UCI repository show results similar to SVMs which have been tuned to have the best choice of parameter.

#index 1273835
#* A near-optimal poly-time algorithm for learning in a class of stochastic games
#@ Ronen I. Brafman;Moshe Tennenholtz
#t 1999
#c 11
#% 465913
#% 466075
#% 1272320
#! We present a new algorithm for polynomial time learning of near optimal behavior in stochastic games. This algorithm incorporates and integrates important recent results of Kearns and Singh [1998] in reinforcement learning and of Monderer and Tennenholtz [1997] in repeated games. In stochastic games we face an exploration vs. exploitation dilemma more complex than in Markov decision processes. Namely, given information about particular parts of a game matrix, how much effort should the agent invest in learning its unknown parts. We explain and address these issues within the class of single controller stochastic games. This solution can be extended to stochastic games in general.

#index 1273836
#* Efficient reinforcement learning in factored MDPs
#@ Michael Kearns;Daphne Koller
#t 1999
#c 11
#% 143314
#% 265807
#% 466075
#% 1290139
#% 1650568
#! Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This ...

#index 1273837
#* Convergence of reinforcement learning with general function approximators
#@ Vassilis A. Papavassiliou;Stuart Russell
#t 1999
#c 11
#% 145224
#% 203336
#% 393786
#% 449561
#! A key open problem in reinforcement learning is to assure convergence when using a compact hypothesis class to approximate the value function. Although the standard temporal-difference learning algorithm has been shown to converge when the hypothesis class is a linear combination of fixed basis functions, it may diverge with a general (non-linear) hypothesis class. This paper describes the Bridge algorithm, a new method for reinforcement learning, and shows that it converges to an approximate global optimum for any agnostically learnable hypothesis class. Convergence is demonstrated on a simple example for which temporal-difference learning fails. Weak conditions are identified under which the Bridge algorithm converges for any hypothesis class. Finally, connections are made between the complexity of reinforcement learning and the PAC-learnability of the hypothesis class.

#index 1273838
#* Confidence based dual reinforcement Q-routing: an adaptive online network routing algorithm
#@ Shailesh Kumar;Risto Mukkulainen
#t 1999
#c 11
#% 371812
#% 644560
#% 679789
#! This paper describes and evaluates the Confidence-based Dual Reinforcement Q-Routing algorithm (CDRQ-Routing) for adaptive packet routing in communication networks. CDRQ-Routing is based on the Q-learning framework of Q-Routing. The main contribution of this work is the increased quantity and improved quality of exploration in CDRQ-Routing, which lead to faster adaptation and better routing policies learned as compared to Q-Routing, the state-of-the-art adaptive Bellman-Ford Routing, and the non-adaptive shortest path routing. Experiments over several network topologies have shown that at different loads, CDRQ-Routing learns superior policies significantly faster than Q-Routing. Moreover, CDRQ-Routing learns policies that sustain higher load levels than Q-Routing. Analysis shows that overhead due to exploration is insignificant as eqmpared to the improvements in CDRQ-Routing.

#index 1273839
#* A neural reinforcement learning approach to learn local dispatching policies in production scheduling
#@ Simone Riedmiller;Martin Riedmiller
#t 1999
#c 11
#% 465910
#% 515225
#% 636345
#% 1290042
#! Finding optimal solutions for job shop scheduling problems requires high computational effort, especially under consideration of uncertainty and frequent replanning. In contrast to computational solutions, domain experts are often able to derive good local dispatching heuristics by looking at typical problem instances. They can be efficiently applied by looking at few relevant features. However, these rules are usually not optimal, especially in complex decision situations. Here we describe an approach that tries to combine both worlds. A neural network based agent autonomously optimizes its local dispatching policy with respect to a global optimization goal, defined for the overall plant. On two benchmark scheduling problems, we show both learning and generalization abilities of the proposed approach.

#index 1273840
#* Discovering admissible model equations from observed data based on scale-types and identity constraints
#@ Takashi Washio;Hiroshi Motoda;Yuji Niwa
#t 1999
#c 11
#% 9526
#% 24538
#% 266091
#% 451038
#% 451039
#% 495954
#% 1499592
#! Most conventional law equation discovery systems such as BACON require experimental environments to acquire their necessary data. The mathematical techniques such as linear system identification and neural network fitting presume the classes of equations to model given observed data sets. The study reported in this paper proposes a novel method to discover an admissible model equation from a given set of observed data, while the equation is ensured to reflect first principles governing the objective system. The power of the proposed method comes from the use of the scale-types of the observed quantities, a mathematical property of identity and quasi-bi-variate fitting to the given data set. Its principles and algorithm are described with moderately complex examples, and its practicality is demonstrated through a real application to psychological and sociological law equation discovery.

#index 1273841
#* Finding relations in polynomial time
#@ Gilles Caporossi;Pierre Hansen
#t 1999
#c 11
#% 24538
#% 52181
#% 226544
#% 836006
#! Given a set of m observations on n variables, an O(mn2) algorithm is proposed to find a basis of all affine relations between these variables satisfied by the observations. On a 25 variables example, this new algorithm is 130 000 times faster than the "all subsets" option for linear regression of the SAS package which is a non polynomial alternative. Extension to the cases where squares, ratios, products of pairs of variables or logarithms of such terms appear in the relations is straightforward and remains polynomial. The method is first tested with data for several classical discoveries studied previously by the Bacon programs. Then it is added to the AutoGraphiX system for computer-aided graph theory thus making it entirely automated. To demonstrate the power of the resulting system, five novel relations (or conjectures) in graph theory are found, two of which pertain to mathematical chemistry. Three conjectures involve five invariants, which is more than in most propositions of graph theory. Proofs of two conjectures are also given.

#index 1273842
#* Automatic concept formation in pure mathematics
#@ Simon Colton;Alan Bundy;Toby Walsh
#t 1999
#c 11
#% 52181
#% 157417
#% 687433
#% 696837
#! The HR program forms concepts and makes conjectures in domains of pure mathematics and uses theorem prover OTTER and model generator MACE to prove or disprove the conjectures. HR measures properties of concepts and assesses the theorems and proofs involving them to estimate the interestingness of each concept and employ a best first search. This approach has led HR to the discovery of interesting new mathematics and enables it to build theories from just the axioms of finite algebras.

#index 1273843
#* Efficient mining of statistical dependencies
#@ Tim Oates;Matthew D. Schmill;Paul R. Cohen
#t 1999
#c 11
#% 616998
#! The Multi-Stream Dependency Detection algorithm finds rules that capture statistical dependencies between patterns in multivariate time series of categorical data [Oates and Cohen, 1996c]. Rule strength is measured by the G statistic [Wickens, 1989], and an upper bound on the value of G for the descendants of a node allows MSDD'S search space to be pruned. However, in the worst case, the algorithm will explore exponentially many rules. This paper presents and empirically evaluates two ways of addressing this problem. The first is a set of three methods for reducing the size of MSDD'S search space based on information collected during the search process. Second, we discuss an implementation of MSDD that distributes its computations over multiple machines on a network.

#index 1273844
#* Towards efficient metaquerying
#@ Rachel Ben-Eliyahu-Zohary;Ehud Gudes
#t 1999
#c 11
#% 68183
#% 116147
#% 232102
#% 232146
#% 408396
#% 443084
#! Metaquery (also known as metapattem) is a datamining tool useful for learning rules involving more than one relation in the database. A metaquery is a template, or a second-order proposition in a language L, that describes the type of pattern to be discovered. This tool has already been successfully applied to several real-world applications. In this paper we advance the state of the art in metaqueries research in several ways. First, we analyze the related computational problem and classify it as NP-hard, with a tractable subset that is quite immediately evident. Second, we argue that the notion of support for meta-queries, where support is intuitively some indication to the relevance of the rules to be discovered, is not adequately defined in the literature, and propose our own definition. Third, we propose some efficient algorithms for computing support and present preliminary experimental results that indicate that our algorithms are indeed quite useful.

#index 1273845
#* Efficient SQL-querying method for data mining in large data bases
#@ Nguyen Hung Son
#t 1999
#c 11
#% 99397
#% 129980
#% 136350
#% 366687
#% 386105
#% 618434
#% 1478474
#% 1478477
#! Data mining can be understood as a process of extraction of knowledge hidden in very large data sets. Often data mining techniques (e.g. discretization or decision tree) are based on searching for an optimal partition of data with respect to some optimization criterion. In this paper, we investigate the problem of optimal binary partition of continuous attribute domain for large data sets stored in relational data bases (RDB). The critical for time complexity of algorithms solving this problem is the number of simple SQL queries like SELECT COUNT FROM ... WHERE attribute BETWEEN ... (related to some interval of attribute values) necessary to construct such partitions. We assume that the answer time for such queries does not depend on the interval length. Using straightforward approach to optimal partition selection (with respect to a given measure), the number of necessary queries is of order O(N), where N is the number of preassumed partitions of the searching space. We show some properties of considered optimization measures, that allow to reduce the size of searching space. Moreover, we prove that using only O(logiV) simple queries, one can construct the partition very close to optimal.

#index 1273846
#* A Potts spin MFT network solving multiple causal interactions
#@ Lotfi Ben Romdhane
#t 1999
#c 11
#% 107135
#% 747457
#% 1784259
#% 1848492
#! In this paper, we propose a Potts spin Mean Field annealed network to address the open, independent and incompatibility classes of causal reasoning (also said abduction, abductive diagnosis). The strong feature of the current work is its characterization of the reasoning task in these classes by an energy/target function. Computation of a scenario (also said explanation) is done by means of Mean Field equations. The application of the model to small and large-scale causal problems reveals its efficacy and robustness in handling varied and multiple causal interactions.

#index 1273847
#* SARDSRN: a neural network shift-reduce parser
#@ Marshall R. Mayberry;Risto Miikkulainen
#t 1999
#c 11
#% 36369
#% 90391
#% 90394
#% 111449
#% 130351
#% 136369
#% 158685
#% 234978
#% 372552
#% 496740
#% 519223
#% 746924
#% 748336
#! Simple Recurrent Networks (SRNs) have been widely used in natural language tasks. SARDSRN extends the SRN by explicitly representing the input sequence in a SARDNET self-organizing map. The distributed SRN component leads to good generalization and robust cognitive properties, whereas the SARDNET map provides exact representations of the sentence constituents. This combination allows SARDSRN to learn to parse sentences with more complicated structure than can the SRN alone, and suggests that the approach could scale up to realistic natural language.

#index 1273848
#* Improved classification for a data fusing Kohonen self organizing map using a dynamic thresholding technique
#@ Odin Taylor;John Tait;John Macintyre
#t 1999
#c 11
#% 60576
#% 361100
#! The use of linear data fusion is a fast developing area in the field of military information and combat systems. However, the use of data fusion in conventional application areas is not as wide spread. To date linear data fusion has been used only in applications in which substantial knowledge of both the problem domain and the sensor devices in use are available. However, in applications such as condition monitoring the problem domain can be very complex, with little or no knowledge about the interactions between measured parameters. This paper describes the use of non-linear self-learning or self-organising systems as a tool for data fusion, since these systems can learn complex interrelationships between a number of parameters, and use this information as a tool for improved classification.

#index 1273849
#* Generalized connectionist associative memory
#@ Nigel Duffy;Arun Jagota
#t 1999
#c 11
#% 91872
#% 116890
#% 138312
#% 165190
#! This paper presents a generalized associative memory model, which stores a collection of tuples whose components are sets rather than scalars. It is shown that all library patterns are stored stably. On the other hand spurious memories may develop. Applications of this model to storage and retrieval of naturally-arising generalized sequences in bioinformatics are presented. The model is shown to work well for detection of novel generalized sequences against a large database of stored sequences, and for removal of noisy black pixels in a probe image against a very large set of stored images.

#index 1273850
#* Preference Moore machines for neural fuzzy integration
#@ Stefan Wermter
#t 1999
#c 11
#% 25443
#% 136369
#% 176660
#% 362205
#% 394146
#% 394261
#% 703084
#! This paper describes multidimensional neural preference classes and preference Moore machines as a principle for integrating different neural and/or symbolic knowledge sources. We relate neural preferences to multidimensional fuzzy set representations. Furthermore, we introduce neural preference Moore machines and relate traditional symbolic transducers with simple recurrent networks by using neural preference Moore machines. Finally, we demonstrate how the concepts of preference classes and preference Moore machines can be used to integrate knowledge from different neural and/or symbolic machines. We argue that our new concepts for preference Moore machines contribute a new potential approach towards general principles of neural symbolic integration.

#index 1273851
#* Processing symbols at variable speed in DUAL: connectionist activation as power supply
#@ Alexander A. Petrov;Boicho N. Kokinov
#t 1999
#c 11
#% 75896
#% 136370
#% 207194
#% 320603
#% 360525
#% 370964
#% 373996
#% 383886
#! This article explores the advantages and one potential implementation of a new style of computation in which multiple lines of symbolic processing are pursued at different speeds within a hybrid multi-agent system. The cognitive architecture DUAL consists of small hybrid computational entities called DUAL agents. Each agent has a symbolic processor capable of simple symbol manipulations. There is also an activation level associated with each agent. Activation spreads according to connectionist rules. The speed of each symbolic processor is proportional to the activation level of the corresponding DUAL agent and varies dynamically. Thus multiple candidate-solutions to a given problem can be explored in parallel. More computational resources are dedicated to the more promising candidates and the degree of 'promise' is reevaluated dynamically. This allows for flexible and efficient behavior of the system as a whole. The exact relationship between symbolic speed and connectionist activation is based on an energetic analogy. The symbolic processor is conceptualized as a machine converting connectionist activation into symbolic work. A language for implementing variable-speed symbol manipulations using delayed evaluation is introduced: S-LlSP. A small example from a DUAL-based cognitive model illustrates variable-speed marker passing in a semantic network.

#index 1273852
#* Hybrid thematic role processor: symbolic linguistic relations revised by connectionist learning
#@ Joao Luis Garcia Rosa;Edson Franeozo
#t 1999
#c 11
#% 36369
#% 90394
#% 92148
#% 160857
#% 170665
#% 204434
#% 443022
#% 443333
#% 1042790
#% 1860361
#! In linguistics, the semantic relations between words in a sentence are accounted for, inter alia, as the assignment of thematic roles, e.g. AGENT, INSTRUMENT, etc. As in predicate logic, simple linguistic expressions are decomposed into one predicate (often the verb) and its arguments. The predicate assigns thematic roles to the arguments, so that each sentence has a thematic grid, a structure with all thematic roles assigned by the predicate. In order to reveal the thematic grid of a sentence, a system called HTRP (Hybrid Thematic Role Processor) is proposed, in which the connectionist architecture has, as input, a featural representation of the words of a sentence, and, as output, its thematic grid. Both a random initial weight version (RIW) and a biased initial weight version (BIW) are proposed to account for systems without and with initial knowledge, respectively. In BIW, initial connection weights reflect symbolic rules for thematic roles. For both versions, after supervised training, a set of final symbolic rules is extracted, which is consistently correlated to linguistic - symbolic - knowledge. In the case of BIW, this amounts to a revision of the initial rules. In RIW, symbolic rules seem to be induced from the connectionist architecture and training.

#index 1273853
#* Situated grounded word semantics
#@ Luc Steels;Frederic Kaplan
#t 1999
#c 11
#% 262742
#% 361952
#% 382676
#% 747814
#! The paper reports on experiments in which autonomous visually grounded agents bootstrap an ontology and a shared lexicon without prior design nor other forms of human intervention. The agents do so while playing a particular languagegame called the guessing game. We show that synonymy and polysemy arise as emergent properties in the language but also that there are tendencies to dampen it so as to make the language more coherent and thus more optimal from the viewpoints of communicative success, cognitive complexity, and learnability.

#index 1273854
#* Lean semantic interpretation
#@ Martin Romacker;Katja Markert;Udo Hahn
#t 1999
#c 11
#% 36776
#% 150930
#% 177237
#% 266218
#% 747586
#% 748226
#% 748859
#% 1271859
#% 1271861
#! We introduce two abstraction mechanisms for streamlining the process of semantic interpretation. Configurational descriptions of dependency graphs increase the linguistic generality of interpretation schemata, while interfacing them to lexical and conceptual inheritance hierarchies reduces the amount and complexity of semantic specifications.

#index 1273855
#* The role of saliency in generating natural language arguments
#@ Chris Reed
#t 1999
#c 11
#% 9197
#% 21801
#% 207678
#% 217068
#% 1271863
#! Generating expressions which communicate information already known to the hearer, building enthymematic arguments, and characterising refutations all pose significant problems to traditional natural language generation techniques. After exploring these problems, an approach is proposed which through its employment of a notion of saliency handles them cleanly, and offers support for further features including clue word generation. It is argued that propositional salience and its interaction with intentional, attentional, epistemic and structural components of a text generation system have a key role to play in the design and realisation of persuasive text.

#index 1273856
#* Combining weak knowledge sources for sense disambiguation
#@ Mark Stevenson;Yoriek Wilks
#t 1999
#c 11
#% 131320
#% 132648
#% 179876
#% 286069
#% 449566
#% 742327
#% 742368
#% 747839
#% 748550
#% 748703
#% 756938
#% 756952
#% 757130
#% 815341
#! Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This ...

#index 1273857
#* FACILE: classifying texts integrating pattern matching and information extraction
#@ Fabio Ciravegna;Alberto Lavelli;Nadia Mana;Johannes Matiasek;Luca Gilardoni;Silvia Mazza;Massimo Ferraro;William J. Black;Fabio Rinaldi;David Mowatt
#t 1999
#c 11
#% 81589
#% 461692
#% 478258
#% 744552
#! Successfully managing information means being able to find relevant new information and to correctly integrate it with pre-existing knowledge. Much information is nowadays stored as multilingual textual data; therefore advanced classification systems are currently considered as strategic components for effective knowledge management. We describe an experience integrating different innovative AI technologies such as hierarchical pattern matching and information extraction to provide flexible multilingual classification adaptable to user needs. Pattern matching produces fairly accurate and fast categorisation over a large number of classes, while information extraction provides fine-grained classification for a reduced number of classes. The resulting system was adopted by the main Italian financial news agency providing a pay-to-view service.

#index 1273858
#* Learning in natural language
#@ Dan Roth
#t 1999
#c 11
#% 697
#% 116172
#% 116179
#% 131686
#% 145224
#% 150153
#% 151232
#% 151252
#% 190581
#% 203344
#% 266368
#% 272517
#% 278102
#% 744501
#% 747797
#% 837668
#! Statistics-based classifiers in natural language are developed typically by assuming a generative model for the data, estimating its parameters from training data and then using Bayes rule to obtain a classifier. For many problems the assumptions made by the generative models are evidently wrong, leaving open the question of why these approaches work. This paper presents a learning theory account of the major statistical approaches to learning in natural language. A class of Linear Statistical Queries (LSQ) hypotheses is defined and learning with it is shown to exhibit some robustness properties. Many statistical learners used in natural language, including naive Bayes, Markov Models and Maximum Entropy models are shown to be LSQ hypotheses, explaining the robustness of these predictors even when the underlying probabilistic assumptions do not hold. This coherent view of when and why learning approaches work in this context may help to develop better learning methods and an understanding of the role of learning in natural language inferences.

#index 1273859
#* An evaluation of criteria for measuring the quality of clusters
#@ Bhavani Raskutti;Christopher Leckie
#t 1999
#c 11
#% 115478
#% 262045
#% 840583
#! An important problem in clustering is how to decide what is the best set of clusters for a given data set, in terms of both the number of clusters and the membership of those clusters. In this paper we develop four criteria for measuring the quality of different sets of clusters. These criteria are designed so that different criteria prefer cluster sets that generalise at different levels of granularity. We evaluate the suitability of these criteria for non-hierarchical clustering of the results returned by a search engine. We also compare the number of clusters chosen by these criteria with the number of clusters chosen by a group of human subjects. Our results demonstrate that our criteria match the variability exhibited by human subjects, indicating there is no single perfect criterion. Instead, it is necessary to select the correct criterion to match a human subject's generalisation needs.

#index 1273860
#* Relational learning for NLP using linear threshold elements
#@ Roni Khardon;Dan Roth;Leslie G. Valiant
#t 1999
#c 11
#% 23804
#% 116147
#% 129993
#% 145393
#% 163545
#% 179693
#% 196896
#% 252025
#% 252047
#% 266368
#% 271294
#% 278102
#% 396021
#% 451055
#% 494355
#% 550395
#% 550407
#% 550561
#% 653092
#% 747797
#% 1272373
#% 1272374
#! We describe a coherent view of learning and reasoning with relational representations in the context of natural language processing. In particular, we discuss the Neuroidal Architecture, Inductive Logic Programming and the SNoW system explaining the relationships among these, and thereby offer an explanation of the theoretical basis for the SNoW system. We suggest that extensions of this system along the lines suggested by the theory may provide new levels of scalability and functionality.

#index 1273861
#* Combining general hand-made and automatically constructed thesauri for information retrieval
#@ Rila Mandala;Takenobu Tokunaga;Hozumi Tanaka
#t 1999
#c 11
#% 129655
#% 144029
#% 144031
#% 169729
#% 229348
#% 232668
#% 363038
#% 740329
#% 744551
#% 748691
#% 840583
#% 1275285
#! One of the most intuitive ideas for enhancing the effectiveness of an information retrieval system is to include the use of a thesaurus. WordNet, as a hand-crafted and general-purpose thesaurus, intuitively should also work fine in information retrieval, but unfortunately, experimental results by many researchers have not been promising. Thereby in this paper we investigate why the use of Word-Net in information retrieval has not been successful. Based on this analysis we propose a method to combine WordNet with predicate-argument-based and co-occurrence-based automatically constructed thesauri. Experiments using large test collection shows that our method results in a significant improvement of information retrieval performance.

#index 1273862
#* Towards multi-paper summarization reference information
#@ Hidetsugu Nanba;Manabu Okumura
#t 1999
#c 11
#% 194251
#% 266370
#% 375017
#% 748612
#% 756744
#% 757294
#! This paper presents a system to support writing a survey of a specific domain. The system utilizes reference information that consists of reference relationships between papers and the information derived from the description around citations. We think the following are inevitable for writing a survey : collecting papers of the specific domain, and understanding their essence and differences among them. Therefore, we firstly extract fragments of papers where the author describes the essence of a referred paper and the differences between his paper and it (we call them reference areas). Then with the information of reference areas, we identify the types of reference relationships that indicate the reasons for citations(we call them reference types). These types make it possible to collect papers in the same domain. The system can display the collection of the papers. It can also show abstracts and reference areas of the collected papers. With the system, we can understand the relationships between the collected papers.

#index 1273863
#* How latent is latent semantic analysis?
#@ Peter Wiemer-Hastings
#t 1999
#c 11
#! Latent Semantic Analysis (LSA) is a statistical, corpus-based text comparison mechanism that was originally developed for the task of information retrieval, but in recent years has produced remarkably human-like abilities in a variety of language tasks. LSA has taken the Test of English as a Foreign Language and performed as well as non-native English speakers who were successful college applicants. It has shown an ability to learn words at a rate similar to humans. It has even graded papers as reliably as human graders. We have used LSA as a mechanism for evaluating the quality of student responses in an intelligent tutoring system, and its performance equals that of human raters with intermediate domain knowledge. It has been claimed that LSA's text-comparison abilities stem primarily from its use of a statistical technique called singular value decomposition (SVD) which compresses a large amount of term and document co-occurrence information into a smaller space. This compression is said to capture the semantic information that is latent in the corpus itself. We test this claim by comparing LSA to a version of LSA without SVD, as well as a simple keyword matching model.

#index 1273864
#* Dealing with geometric constraints in game-theoretic planning
#@ Patrick Fabiani;Jean-Claude Latombe
#t 1999
#c 11
#% 22348
#% 44876
#% 169498
#% 194653
#% 214929
#% 367254
#% 527124
#% 592413
#% 1290145
#! Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This ...

#index 1273865
#* Computational complexity of planning and approximate planning in presence of incompleteness
#@ Chitta Baral;Vladik Kreinovich;Raul Trejo
#t 1999
#c 11
#% 194648
#% 244412
#% 1478845
#! In the last several years the computational complexity of classical planning and HTN planning have been studied. But in both cases it is assumed that the planner has complete knowledge about the initial state. Recently, there has been proposal to use 'sensing' actions to plan in presence of incompleteness. In this paper we study the complexity of planning in such cases. In our study we use the action description language A proposed in 1993 by M. Gelfond and V. Lifschitz and its extensions. The language A allows planning in the situations with complete information. It is known that, if we consider only plans of feasible (polynomial) length, the planning problem for such situations is NP-complete: even checking whether a given objective is attainable from a given initial state is NP-complete. In this paper, we show that the planning problem in presence of incompleteness is indeed harder: it belongs to the next level of complexity hierarchy (in precise terms, it is Σ2P-complete). To overcome the complexity of this problem, C. Baral and T. Son have proposed several approximations. We show that under certain conditions, one of these approximations - O-approximation - makes the problem NP-complete (thus indeed reducing its complexity).

#index 1273866
#* The detection and exploitation of symmetry in planning problems
#@ Maria Fox;Derek Long
#t 1999
#c 11
#% 224480
#% 544782
#% 1272340
#% 1272392
#! Many planning problems exhibit a high degree of symmetry that cannot yet be exploited successfully by modern planning technology. For example, problems in the Gripper domain, in which a robot with two grippers must transfer balls from one room to another, are trivial to the human problem-solver because the high degree of symmetry in the domain means that the order in which pairs of balls are transported is irrelevant to the length of the shortest transportation plan. However, planners typically search all possible orderings giving rise to an exponential explosion of the search space. This paper describes a way of detecting and exploiting symmetry in the solution of problems that demonstrate these characteristics. We have implemented our techniques in STAN, a Graphplan-based planner that uses state analysis techniques in a number of ways to exploit the underlying structures of domains. We have achieved a dramatic improvement in performance in solving problems exhibiting symmetry. We present a range of results and indicate the further developments we are now pursuing.

#index 1273867
#* From interaction data to plan libraries: a clustering approach
#@ Mathias Bauer
#t 1999
#c 11
#% 150994
#% 184048
#% 266283
#% 266395
#% 451052
#! Plan libraries are the most important knowledge source of many plan recognition systems. The plan decompositions they contain provide information about how a plan has to be executed to actually achieve its associated goals and be recognized by the system. This paper presents an approach to the automatic acquisition of plan decompositions from sample action sequences. In particular a clustering algorithm is introduced that allows groups of "similar" sequences to be discovered and used for the generation of plan libraries. Empirical tests indicate that these libraries can indeed be successfully used for plan recognition purposes.

#index 1273868
#* SHOP: simple hierarchical ordered planner
#@ Dana Nau;Yue Cao;Amnon Lotem;Hector Munoz-Avila
#t 1999
#c 11
#% 23012
#% 103050
#% 109935
#% 132174
#% 215878
#% 243343
#% 266680
#% 296170
#% 544766
#! SHOP (Simple Hierarchical Ordered Planner) is a domain-independent HTN planning system with the following characteristics. • SHOP plans for tasks in the same order that they will later be executed. This avoids some goal-interaction issues that arise in other HTN planners, so that the planning algorithm is relatively simple. • Since SHOP knows the complete world-state at each step of the planning process, it can use highly expressive domain representations. For example, it can do planning problems that require complex numeric computations. • In our tests, SHOP was several orders of magnitude faster man Blackbox and several times faster than TLpian, even though SHOP is coded in Lisp and the other planners are coded in C.

#index 1273869
#* Reachability, relevance, resolution and the planning as satisfiability approach
#@ Rouen I. Brafman
#t 1999
#c 11
#% 131357
#% 179939
#% 198885
#% 266200
#% 327779
#% 544782
#% 544784
#% 1271884
#% 1273727
#% 1476298
#% 1478761
#% 1478840
#% 1650567
#! We investigate the ability of two central encoding methods to propagate reachability and relevance information using resolution steps. More specifically, we compare the ability of unit-propagation and higher-order resolution steps to propagate reachability and relevance information in the context of the linear and GRAPHPLAN encoding schemes to the ability of a natural class of reachability and relevance algorithms that operate at the plan level. As a result of our observations and additional considerations, we experiment with a preprocessing step based on limited binary resolution that shows nice results.

#index 1273870
#* Improving Graphplan's search with EBL & DDB techniques
#@ Subbarao Kambhampati
#t 1999
#c 11
#% 216992
#% 224480
#% 262237
#% 283223
#% 544784
#% 676283
#% 1478761
#! I highlight some inefficiencies of Graphplan's backward search algorithm, and describe how these can be eliminated by adding explanation-based learning and dependency-directed backtracking capabilities to Graphplan. I will then demonstrate the effectiveness of these augmentations by describing results of empirical studies that show dramatic improvements in run-time (w 100× speedups) as well as solvability-horizons on benchmark problems across seven different domains.

#index 1273871
#* To encode or not to encode-1: linear planning
#@ Ronen I. Brafman;Holger H. Hoos
#t 1999
#c 11
#% 131357
#% 160270
#% 163715
#% 266200
#% 266398
#% 375400
#% 496245
#% 496409
#% 1271884
#% 1272333
#% 1476298
#% 1478779
#% 1650591
#! Stochastic local search (SLS) techniques are very effective in solving hard prepositional satisfiability problems. This has lead to the popularity of the encode & solve paradigm in which different problems are encoded as propositional satisfiability problems to which SLS techniques are applied. In AI, planning is the main area in which this methodology is used. Yet, it seems plausible that SLS methods should perform better when applied to the original problem space whose structure they can exploit. As part of our attempts to validate this thesis, we experimented with LPSP, a planner that applies SLS techniques to the space of linear plans. LPSP out-performs SLS applied to encoded planning problems that enforce a similar linearity assumption because of its ability to exploit the special structure of planning problems. Additional experiments (reported in a longer version of this paper) conducted on the Hamiltonian circuit problem lend farther support to our thesis.

#index 1273872
#* A possibilistic planner that deals with non-determinism and contingency
#@ Emmanuel Guere;Rachid Alami
#t 1999
#c 11
#% 194652
#% 224480
#% 266386
#% 266387
#% 544766
#% 544773
#% 1272287
#! Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This ...

#index 1273873
#* Highly reactive decision making: a game with time
#@ Silvia Coradeschi;Thierry Vidal
#t 1999
#c 11
#% 241
#% 162493
#% 231740
#% 518136
#% 618539
#% 618573
#! Real-time monitoring calls for decision making capabilities in reaction to observed events. Associative models provide efficiency by matching the observed situation to a recorded pattern equipped with an accurate decision. We rely on a decision tree accounting for the context and temporal chronicles expressing dynamic patterns. In highly reactive domains, i.e. when actions get as frequent as observations, the decision must anticipate the complete recognition of a pattern, comparing possible evolutions. This paper focuses on the on-line decision process, a game against Nature in the general case: a timed game automaton gathers the possible next steps with associated goodness values, and uses an opportunistic algorithm to compute a temporally expressive decision, maximizing its utility, i.e. the chances of "winning".

#index 1273874
#* Real-time problem-solving with contract algorithms
#@ Shlomo Zilberstein;Francois Charpillet;Philippe Chassaing
#t 1999
#c 11
#% 107169
#% 158402
#% 205385
#% 661039
#% 1290101
#% 1476303
#% 1478774
#! This paper addresses the problem of building an interruptible real-time system using contract algorithms. Contract algorithms offer a trade-off between computation time and quality of results, but their run-time must be determined when they are activated. Many AI techniques provide useful contract algorithms that are not interruptible. We show how to optimally sequence contract algorithms to create the best interruptible system with or without stochastic information about the deadline. These results extend the foundation of real-time problem-solving and provide useful guidance for embedding contract algorithms in applications.

#index 1273875
#* Cyclic scheduling
#@ Denise L. Draper;Ari K. Jonsson;David P. Clements;David E. Joslin
#t 1999
#c 11
#% 137020
#% 179960
#% 258657
#% 1275306
#! In this paper we consider the problem of cyclic schedules such as arise in manufacturing. We introduce a new formulation of this problem that is a very simple modification of a standard job shop scheduling formulation, and which enables us to use existing constraint reasoning techniques to generate cyclic schedules. We present evidence for the effectiveness of this formulation, and describe extensions for handling multiple-capacity resources and for recovering from breaks in cyclic schedules.

#index 1273876
#* An iterative sampling procedure for resource constrained project scheduling ith time windows
#@ Amedeo Cesta;Angelo Oddi;Stephen F. Smith
#t 1999
#c 11
#% 69607
#% 179958
#% 421206
#% 1290110
#% 1478777
#! In this paper, we extend and integrate previously reported techniques for resource constrained scheduling to develop a CSP procedure for solving RCPSP/max, the resource constrained project scheduling problem with time windows (generalized precedence relations between start time of activities). RCPSP/max is a well-studied problem within the Operations Research community and the presence of a large set of benchmark problems provides a good opportunity for comparative performance analysis. Our base CSP scheduling model generalizes previous profile-based approaches to cumulative scheduling by focusing on global analysis of minimal conflicting sets rather than pairwise conflict analysis. This generalization increases the tendency for more effective conflict resolution. Since RCPSP/max is an optimization problem, other ideas from prior work are adapted to embed this base CSP model within a multi-pass, iterative sampling procedure. The overall procedure, called ISES (Iterative Sampling Earliest Solutions), is applied to the above mentioned set of benchmark problems. ISES is shown to perform quite well in comparison to current state-of-the-art procedures for RCPSP/max, particularly as search space size becomes limiting for systematic procedures.

#index 1273877
#* Semi-quantitative comparative analysis
#@ Ivayla Vatcheva;Hidde De Jong
#t 1999
#c 11
#% 46271
#% 179985
#% 243703
#% 837629
#% 1290130
#! SQCA is an implemented technique for the semi-quantitative comparative analysis of dynamical systems. It is both able to deal with incompletely specified models and make precise predictions by exploiting semiquantitative information in the form of numerical bounds on the variables and functions occuring in the models. The technique has a solid mathematical foundation which facilitates proofs of correctness and convergence properties.

#index 1273878
#* A qualitative-fuzzy framework for nonlinear black-box system identification
#@ Riccardo Bellazzi;Raffaella Guglielmann;Liliana Ironi
#t 1999
#c 11
#% 91863
#% 156986
#% 166232
#% 1776222
#% 1787850
#% 1788929
#! This paper presents a novel approach to non-linear black-box system identification which combines Qualitative Reasoning (QR) methods with fuzzy logic systems. Such a method aims at building a good initialization of a fuzzy identifier, so that it will converge to the input-output relation which captures the nonlinear dynamics of the system. Fuzzy inference procedures should be initialized with a rule-base predefined by the human expert: when such a base is not available or poorly defined, the inference procedure becomes extremely inefficient. Our method aims at solving the problem of the construction of a meaningful rule-base: fuzzy rules are automatically generated by encoding the knowledge of the system dynamics described by the outcomes of its qualitative simulation. Both efficiency and robustness of the method are demonstrated by its application to the identification of the kinetics of Thiamine (vitamin B1) and its phosphoesters in the cells of the intestine tissue.

#index 1273879
#* Generalized physical networks for automated model building
#@ Matthew Easley;Elizabeth Bradley
#t 1999
#c 11
#% 6200
#% 82637
#% 109848
#% 109851
#% 132175
#% 266089
#% 417617
#% 669468
#% 1776221
#! We present a new knowledge representation and reasoning framework for modeling nonlinear dynamical systems. The goals of this framework are to smoothly incorporate varying levels of domain knowledge and to tailor the reasoning methods - and hence the search space -- accordingly. Our solution exploits generalized physical networks (GPN), a rneta-level representation of idealized two-terminal elements, together with a hierarchy of qualitative and quantitative analysis tools, to produce a dynamic modeling domain whose complexity naturally adapts to the amount of available information about the target system.

#index 1273880
#* Acquisition of qualitative spatial representation by visual observation
#@ Takushi Sogo;Hiroshi Ishiguro;Toru Ishida
#t 1999
#c 11
#% 36780
#% 89749
#% 109857
#% 151254
#% 549078
#% 1273679
#! In robot navigation, one of the important and fundamental issues is to reconstruct positions of landmarks or vision sensors locating around the robot. This paper proposes a method for reconstructing qualitative positions of multiple vision sensors from qualitative information observed by the vision sensors, i.e., motion directions of moving objects. The process iterates the following steps: (1) observing motion directions of moving objects from the vision sensors, (2) classifying the vision sensors into spatially classified pairs, (3) acquiring three point constraints, and (4) propagating the constraints. The method have been evaluated with simulations.

#index 1273881
#* Qualitative outline theory
#@ Antony Galton;Richard Meathrel
#t 1999
#c 11
#% 36778
#% 77823
#% 150552
#! A theory of shape is important for AI both for recognition and description of objects and for reasoning about the possible behaviours of objects. Theories of shape may be loosely classified as either volume-based or outline-based. We present a theory of the latter type, initially confined to two-dimensional outlines. We represent outlines by means of strings over an alphabet of seven qualitative curvature types, and give a regular grammar which generates the strings corresponding to possible outlines. We use subsets of the curvature-type alphabet to characterise cognitively salient subclasses of outlines, with corresponding regular subgrammars, and use decusping, smoothing, and merging operators to simplify outlines for representation at coarser granularity. We give an algorithm for deriving the curvature sequence of an outline, using only local information obtained as the outline is traversed. Finally, we indicate how more detailed (including quantitative) information can be incorporated into the theory.

#index 1273882
#* Qualitative and quantitative representations of locomotion and their application in robot navigation
#@ Alexandra Musto;Klaus Stein;Andreas Eisenkolb;Thomas Rofer
#t 1999
#c 11
#% 243705
#! Qualitative and quantitative representations of space in general and motion in particular have their typical fields of application which are unified in an autonomously moving robot interacting with human beings. Therefore it is necessary to make some considerations on both approaches when dealing with such a robot. This paper presents quantitative and qualitative representations of locomotion and algorithms to deal with them. This work was applied to the navigation of a semi-autonomous wheelchair along routes in networks of corridors.

#index 1273883
#* Debugging functional programs
#@ Markus Stumptner;Franz Wotawa
#t 1999
#c 11
#% 21137
#% 21138
#% 244722
#% 373774
#% 445824
#% 701890
#% 1271885
#! In this paper, we use a logic-based system description for a simple (non-logic) functional language to examine the ways in which a diagnosis system can use its system description to improve debugging performance. The key concept is that the notion of expression replacement, which is the basis for repairing a program, can also serve as a fundamental heuristic for searching the source of an error. We formally define replacements in terms of fault modes, explicitly define a replacement order, and use the replacement heuristic for finding diagnoses. Finally, we incorporate the use of multiple test cases and discuss their use in discriminating between diagnoses.

#index 1273884
#* Monitoring piecewise continuous behaviors by refining semi-quantitative trackers
#@ Bernhard Rinner;Benjamin Kuipers
#t 1999
#c 11
#% 21138
#% 166232
#% 179983
#% 266103
#% 444764
#% 444791
#% 679794
#% 679797
#% 704728
#! We present a model-based monitoring method for dynamic systems that exhibit both discrete and continuous behaviors. MIMIC [Dvorak and Kuipers, 1991] uses qualitative and semiquantitative models to monitor dynamic systems even with incomplete knowledge. Recent advances have improved the quality of semi-quantitative behavior predictions, used observations to refine static envelopes around monotonic functions, and provided a semiquantitative system identification method. Using these, we reformulate and extend MIMIC to handle discontinuous changes between models. Each hypothesis being monitored is embodied as a tracker, which uses the observation stream to refine its behavioral predictions, its underlying model, and the time uncertainty of any discontinuous transitions.

#index 1273885
#* Diagnosis as a variable assignment problem: a case study in a space robot fault diagnosis
#@ Luigi Portinale;Pietro Torasso
#t 1999
#c 11
#% 21137
#% 78634
#% 110365
#% 132173
#% 376266
#% 1290122
#% 1784168
#! In the present paper we introduce the notion of Variable Assignment Problem (VAP) as an abstract framework for characterizing diagnosis. Components of the system to be diagnosed are put in correspondence with variables, behavioral modes of the components are the values of the variables and a diagnosis is a variable assignment which explains the observations of the diagnostic problem, by considering the constraints put by the domain theory. In order to have a concise representation of diagnoses and to reduce the search space, we introduce the notion of scenario for representing a set of diagnoses. The paper discusses the definition of preference criteria for ranking solutions and their use for guiding the heuristic search for diagnoses. Experimental data are reported for the evaluation of such a heuristic search on a real-world diagnostic problem, concerning the identification of faults in a space robot arm; in this domain, where a high number of diagnoses may be possible, our approach allows one to get a concise representation of the large number of solutions and to define effective diagnostic strategies able to provide relevant information about fault localization and identification.

#index 1273886
#* Utilizing device behavior in structure-based diagnosis
#@ Adnan Darwiche
#t 1999
#c 11
#% 44876
#% 125529
#% 205376
#% 1272329
#! Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This ...

#index 1273887
#* Automatic diagnosis of student programs in programming learning environments
#@ Songwen Xu;Yam San Chee
#t 1999
#c 11
#% 2097
#% 19622
#% 82314
#% 117427
#% 132222
#% 249406
#% 257642
#% 289060
#% 369141
#% 440662
#! This paper describes a method to automate the diagnosis of students' programming errors in programming learning environments. In order to recognize correct students' programs as well as to identify errors in incorrect student programs, programs are represented using an improved dependence graph representation. The student program is compared with a specimen program (also called a model program) at the semantic level after both are standardized by program transformations. The method is implemented using Smalltalk in SIPLeS-II, an automatic program diagnosis system for Samlltalk programming learning environments. The system has been tested on approximately 330 student programs for various tasks. Experimental results show that, using the method, semantic errors in a student program can be identified rigorously and safely. Semantics-preserving variations in a student program can be eliminated or accommodated. The tests also show that the system can identify a wide range of errors as well as produce indications of the corrections needed. This method is essential for the development of programming learning environments. The techniques of the improved program dependence graph representation, program standardization by transformations, and semantic level program comparison are also useful in other research fields including program understanding and software maintenance.

#index 1273888
#* Structured modeling language for automated modeling in causal networks
#@ Yousri El Fattah
#t 1999
#c 11
#% 1117
#% 25884
#% 25885
#% 44876
#% 109848
#% 160188
#% 175376
#% 836134
#% 1290122
#% 1650731
#% 1650734
#% 1650799
#! The paper presents a structured modeling language (SML) and a relational database framework for specification and automated generation of causal models. The framework describes a relational database scheme for encoding a library of causal network templates modeling the basic components in a modeling domain. SML provides a formal language for specifying models as structured components that can be composed from the basic components. The language enables specification of models as parameterized relational queries that can be instantiated for specific model instances. The paper describes an algorithm that, given a library and a specification, computes a causal model in time and space linear in the number of basic components. The algorithm enables model reuse by combining model fragments from the template library to compose new models. The present automated modeling approach has been implemented using the structured query language (SQL) and a relational database environment. The approach has been successfully used for modeling an automated work-cell in a real-life digital manufacturing application.

#index 1273889
#* Multiple path coordination for mobile robots: a geometric algorithm
#@ S. Leroy;J. P. Laumond;T. Simeon
#t 1999
#c 11
#% 6451
#% 194045
#% 367254
#% 418626
#% 550174
#! This paper presents a geometric based approach for multiple mobile robot motion coordination. All the robot paths being computed independently, we address the problem of coordinating the motion of the robots along their own path in such a way they do not collide each other. The proposed algorithm is based on a bounding box representation of the obstacles in the so-called coordination diagram. The algorithm is resolution-complete. Its efficiency is illustrated by examples involving more than 100 robots.

#index 1273890
#* Physical constraints on human robot interaction
#@ Michita Imai;Kazuo Hiraki;Tsutomu Miyasato
#t 1999
#c 11
#% 179705
#% 241052
#% 265782
#% 1271950
#! This paper conducts an experiment to investigate the effect of a physical constraint on a subject's viewpoint when using spoken language to navigate a robot. In addition, a robot navigation environment named Spondia-II has been developed for the experiment with an actual autonomous mobile robot. It is well known that the meaning of an utterance, such as a demonstrative pronoun, depends on the viewpoint of the speaker or the hearer. In a conversation between people, the primary factor in determining viewpoint is the physical constraints that are mediated by their body movements. This paper notes that these physical constraints also have an effect on viewpoint even when people instruct a robot. Furthermore, it is argued that, the utterance process also would greatly improve if the robot were able to comprehend the constraints.

#index 1273891
#* State space construction by attention control
#@ Hiroshi Ishiguro;Masatoshi Kamiharako;Toru Ishida
#t 1999
#c 11
#% 97619
#% 120808
#% 150613
#% 188519
#% 1275243
#! In order to understand cognitive aspects of autonomous robots, it is fruitful to develop a mechanism by which the robot autonomously analyzes physical sensor data and construct a state space. This paper proposes a coherent approach to constructing such a robot oriented state space by statistically analyzing sensor patterns and rewards given as the result of task executions. In the state space construction, the robot creates sensor pattern classifiers called Empirically Obtained Perceivers (EOPs) which, when combined, represent internal states of the robot. A novel feature of this method is that the EOP directs attention to select necessary information, and the state space is obtained with the attention control mechanism using EOPs. We have confirmed that the robot can effectively construct state spaces through its vision sensor and execute a navigation task with the obtained state spaces in a complicated simulated world.

#index 1273892
#* A spatiotemporal/spatiotemporal-frequency interpretation of apparent motion reversal
#@ Todd R. Reed
#t 1999
#c 11
#% 23270
#% 85044
#% 626639
#! Temporal aliasing artifacts are common in both computer generated and natural motion sequences. One of the most striking manifestations of temporal aliasing is the apparent reversal of motion commonly referred to as the "wagon wheel effect." In this paper, we examine temporal aliasing from the standpoint of joint spatiotemporal/spatiotemporal-frequency representations. We show that apparent motion reversal can be explained using these representations, and demonstrate that a motion estimation algorithm based on such a representation (the 3-D Gabor transform) can accurately predict this illusion.

#index 1273893
#* A context-dependent attention system for a social robot
#@ Cynthia Breazeal;Brian Scassellati
#t 1999
#c 11
#% 2740
#% 215893
#% 266402
#% 268121
#% 329376
#! This paper presents part of an on-going project to integrate perception, attention, drives, emotions, behavior arbitration, and expressive acts for a robot designed to interact socially with humans. We present the design of a visual attention system based on a model of human visual search behavior from Wolfe (1994). The attention system integrates perceptions (motion detection, color saliency, and face popouts) with habituation effects and influences from the robot's motivational and behavioral state to create a context-dependent attention activation map. This activation map is used to direct eye movements and to satiate the drives of the motivational system.

#index 1273894
#* Markov localization using correlation
#@ Kurt Konolige;Ken Chou
#t 1999
#c 11
#% 265782
#% 1271909
#! Localization is one of the most important capabilities for autonomous mobile agents. Markov Localization (ML), applied to dense range images, has proven to be an effective technique. But its computational and storage requirements put a large burden on robot systems, and make it difficult to update the map dynamically. In this paper we introduce a new technique, based on correlation of a sensor scan with the map, that is several orders of magnitude more efficient than ML. CBML (correlation-based ML) permits video-rate localization using dense range scans, dynamic map updates, and a more precise error model than ML. In this paper we present the basic method of CBML, and validate its efficiency and correctness in a series of experiments on an implemented mobile robot base.

#index 1273895
#* Tracking many objects with many sensors
#@ Hanna Pasula;Stuart Russell;Michael Ostland;Ya'acov Ritov
#t 1999
#c 11
#% 32357
#% 110918
#% 217824
#% 262739
#% 1271899
#% 1290139
#! Keeping track of multiple objects over time is a problem that arises in many real-world domains. The problem is often complicated by noisy sensors and unpredictable dynamics. Previous work by Huang and Russell, drawing on the data association literature, provided a probabilistic analysis and a threshold-based approximation algorithm for the case of multiple objects detected by two spatially separated sensors. This paper analyses the case in which large numbers of sensors are involved. We show that the approach taken by Huang and Russell, who used pairwise sensor-based appearance probabilities as the elementary probabilistic model, does not scale. When more than two observations are made, the objects' intrinsic properties must be estimated. These provide the necessary conditional independencies to allow a spatial decomposition of the global probability model. We also replace Huang and Russell's threshold algorithm for object identification with a polynomial-time approximation scheme based on Markov chain Monte Carlo simulation. Using sensor data from a freeway traffic simulation, we show that this allows accurate estimation of long-range origin/destination information even when the individual links in the sensor chain are highly unreliable.

#index 1273896
#* Search in a small world
#@ Toby Walsh
#t 1999
#c 11
#% 175378
#% 210191
#% 266200
#% 266201
#% 319789
#% 1478764
#! In a graph with a "small world" topology, nodes are highly clustered yet the path length between them is small. Such a topology can make search problems very difficult since local decisions quickly propagate globally. We show that graphs associated with many different search problems have a small world topology, and that the cost of solving such search problems can have a heavy-tailed distribution. The strategy of randomization and restarts appears to eliminate these heavy tails. A novel restart schedule in which the cutoff bound is increased geometrically appears particularly effective.

#index 1273897
#* Switching from bidirectional to unidirectional search
#@ Hermann Kaindl;Gerhard Kainz;Roland Steiner;Andreas Auer;Klaus Radda
#t 1999
#c 11
#% 1722
#% 2194
#% 57552
#% 64788
#% 130194
#% 160388
#% 174161
#% 180112
#% 189701
#% 289063
#% 443807
#% 533951
#% 1271916
#% 1272322
#% 1275257
#% 1275261
#% 1476299
#! Recently, we showed that for traditional bidirectional search with "front-to-end" evaluations, it is not the meeting of search fronts but the cost of proving the optimality of a solution that is problematic. Using our improved understanding of the problem, we developed a new approach to improving this kind of search: switching to unidirectional search after the search frontiers meet for the first time (with the first solution found). This new approach shows improvements over previous bidirectional search approaches and (partly) also over the corresponding unidirectional search approaches in different domains. Together with a special-purpose improvement for the TSP, this approach showed better results than the standard search algorithms using the same knowledge.

#index 1273898
#* Divide-and-conquer bidirectional search: first results
#@ Richard E. Korf
#t 1999
#c 11
#% 2194
#% 46465
#% 88613
#% 191263
#% 211586
#% 266203
#% 268042
#% 321332
#! Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This ...

#index 1273899
#* Improvements to the evaluation of quantified boolean formulae
#@ Jussi Rintanen
#t 1999
#c 11
#% 181220
#% 183640
#% 266109
#% 327779
#% 590256
#% 1113937
#% 1273727
#% 1476298
#! We present a theorem-prover for quantified Boolean formulae and evaluate it on random quantified formulae and formulae that represent problems from automated planning. Even though the notion of quantified Boolean formula is theoretically important, automated reasoning with QBF has not been thoroughly investigated. Universal quantifiers are needed in representing many computational problems that cannot be easily translated to the propositional logic and solved by satisfiability algorithms. Therefore efficient reasoning with QBF is important. The Davis-Putnam procedure can be extended to evaluate quantified Boolean formulae. A straightforward algorithm of this kind is not very efficient. We identify universal quantifiers as the main area where improvements to the basic algorithm can be made. We present a number of techniques for reducing the amount of search that is needed, and evaluate their effectiveness by running the algorithm on a collection of formulae obtained from planning and generated randomly. For the structured problems we consider, the techniques lead to a dramatic speed-up.

#index 1273900
#* An experimental study of phase transitions in matching
#@ Attilio Giordana;Marco Botta;Lorenza Saitta
#t 1999
#c 11
#% 36358
#% 175367
#% 175378
#% 210191
#% 210195
#% 216995
#% 266141
#% 266195
#% 1499505
#! Finding models of a predicate logic formula is a well-known hard problem, whose complexity is exponential in the number of variables. However, even though this number is kept constant, substantial differences in complexity arise when searching for solutions in different problem instances. Such a behavior appears to be quite general, according to recent results reported in the literature; in fact, several classes of hard problems exhibit a narrow phase transition with respect to some order parameter, in correspondence of which the complexity dramatically rises up, still remaining tractable elsewhere. In this paper we provide an extensive experimental study on the emergence of a phase transition in the problem of matching a Horn clause to a universe, searching for a model of the clause or for a proof that no such model exists. As it turns out, phase transition in the matching problem depends in an essential way on two order parameters, one capturing syntactic aspects of the clause structure (intensional aspect), while the other related to the structure of the universe (extensional aspect).

#index 1273901
#* Optimizing recursive information gathering plans
#@ Eric Lambrecht;Subbarao Kambhampati;Senthil Gnanaprakasam
#t 1999
#c 11
#% 53400
#% 210176
#% 213437
#% 224758
#% 237190
#% 248014
#% 340306
#% 368248
#% 464203
#% 481786
#% 481923
#% 1478768
#! In this paper we describe two optimization techniques that are specially tailored for information gathering. The first is a greedy minimization algorithm that minimizes an information gathering plan by removing redundant and overlapping information sources without loss of completeness. We then discuss a set of heuristics that guide the greedy minimization algorithm so as to remove costlier information sources first. In contrast to previous work, our approach can handle recursive query plans that arise commonly in practice. Second, we present a method for ordering the access to sources to reduce the execution cost. Sources on the Internet have a variety of access limitations and the execution cost in information gathering is affected both by network traffic and by the connection setup costs. We describe a way of representing the access capabilities of sources, and provide a greedy algorithm for ordering source calls that respects source limitations, and takes both access costs and traffic costs into account, without requring full source statistics. Finally, we will discuss implementation and empirical evaluation of these methods in Emerac, our prototype information gathering system.

#index 1273902
#* Coevolution, memory and balance
#@ Jan Paredis
#t 1999
#c 11
#% 221970
#% 242242
#% 249270
#% 458388
#% 466542
#% 478834
#% 1819484
#! This paper studies the role of two mechanisms - memory and balance - to exploit the arms race resulting from predator-prey interactions when solving a given problem. Memory ensures that individuals are not only well adapted to the current members of the opposite population but also to earlier generations of opponents. A balanced (co)evolution, on the other hand, adapts the speed of evolution (i.e. the reproduction rate) to the performance of a population. It leads to a steady progress in both populations. Indirectly, a balanced (co)evolution avoids a premature loss of genetic diversity. This in turn, diminishes the need for a long memory span. The current paper shows how both mechanisms can be incorporated in Coevolutionary Genetic Algorithms (CGAs). Empirical results support the importance of, and interaction between, both mechanisms.

#index 1273903
#* Genetic heuristic for search space exploration
#@ Manuel Clergue;Philippe Collard
#t 1999
#c 11
#% 114994
#% 369236
#% 466546
#% 477377
#% 535587
#! This paper deals with the way dual genetic algorithms (DGA), an extension of the standard ones, explore the search space. After a brief introduction presenting genetic algorithms and dualism, the fitness distance correlation is discussed in the context of dualism. From this discussion, a conjecture is made about the genetic: heuristic used by dual genetic algorithms to explore the search space. This conjecture is reinforced by the visualization of the population centroid trajectories in the plane fitness distance. These trajectories help to point out "leg-up" behaviors, which allow the dual genetic algorithm to reach the global optimum from walks on deceptive paths.

#index 1273904
#* Designing comprehensible agents
#@ Phoebe Sengers
#t 1999
#c 11
#% 179994
#% 243112
#% 704951
#% 705548
#% 708759
#! For many applications, it is important that agents be not only correct, but also comprehensible to human users. Typically, people have tried to make agents' behavior and reasoning understandable by adding post-hoc special-purpose explanation systems, with often disappointing results. Here, I instead take the comprehensibility of agent behavior as a central agent design consideration from the start. I describe an agent architecture, the Expressivator, that supports comprehensibility on top of a behavior-based framework, using four technical innovations: (1) structuring the agent's behavior according to the signs and signifiers it is intended to communicate; (2) allowing the agent to keep track of its impression on the user with sign management, (3) using behavioral transitions to explain the reasons for agent, behavior, and (4) expressing behavioral interrelationships directly using meta-level controls.

#index 1273905
#* Behavior networks for continuous domains using situation-dependent motivations
#@ Klaus Dorer
#t 1999
#c 11
#% 178012
#% 194658
#% 252823
#% 258566
#! The problem of action selection by autonomous agents becomes increasingly difficult when acting in continuous, non-deterministic and dynamic environments pursuing multiple and possibly conflicting goals. We propose a method that exploits additional information gained from continuous states, is able to deal with unexpected situations, and takes multiple and conflicting goals into account including additional motivational aspects such as dynamic goals, which allow for situation-dependent motivational influence on the agent. Further we show some domain independent properties of this algorithm along with empirical results gained using the RoboCup simulated soccer environment.

#index 1273906
#* Rights, duties and commitments between agents
#@ Leendert Van Der Torre;Yao-Hua Tan
#t 1999
#c 11
#% 136356
#% 457142
#! In this paper we introduce a multi agent deontic update semantics, that builds on a logic of prescriptive obligations (norms) and a logic of descriptive obligations (normative propositions). In this preference-based logic we formalize rights as a new type of strong prescriptive permissions and duties and commitments as prescriptive obligations between agents.

#index 1273907
#* Scalable temporal reasoning
#@ Steffen Staab;Udo Hahn
#t 1999
#c 11
#% 47522
#% 82720
#% 107137
#% 131562
#% 216976
#% 231740
#% 243705
#% 266107
#% 266238
#% 319244
#% 618513
#% 618563
#% 1271859
#% 1275342
#! We introduce two mechanisms for scaling computations in the framework of temporal reasoning. The first one addresses abstraction at the methodological level. Operators are defined that engender flexible switching between different granularities of temporal representation structures. The second one accounts for abstractions at the interface level of a temporal reasoning engine. Various generalizations of temporal relations are introduced that approximate more fine-grained representations by abstracting away irrelevant details.

#index 1273908
#* Managing temporal uncertainty through waypoint controllability
#@ Paul Morris;Nicola Muscettola
#t 1999
#c 11
#% 70370
#% 107137
#% 252826
#% 262737
#% 266108
#% 266225
#% 618539
#! Simple Temporal Networks have proved useful in applications that involve metric time. However, many applications involve events whose timing is not controlled by the execution agent. A number of properties relating to overall controllability in such cases have been introduced in [Vidal and Ghallab, 1996] and [Vidal and Fargier, 1997], including Weak and Strong Controllability. We derive some new results concerning these properties. In particular, we prove the negation of Weak Controllability is NP-hard, confirming a conjecture in [Vidal and Fargier, 1997]. We also introduce a more general controllability property of which Weak and Strong Controllability are special cases. A propagation algorithm is provided for determining whether the property holds, and we identify tractable cases where the algorithm runs in polynomial time.

#index 1273909
#* A new framework for reasoning about points, intervals and durations
#@ Arun K. Pujari;Abdul Sattar
#t 1999
#c 11
#% 24108
#% 82720
#% 107137
#% 137043
#% 181229
#% 216976
#% 257699
#% 266248
#% 419926
#% 419928
#% 1271924
#% 1271925
#! We present a new framework for reasoning about points, intervals and durations--Point Interval Duration Network (PIDN). The PIDN adequately handles both qualitative and quantitaive temporal information. We show that Interval Algebra, Point Algebra, TCSP, PDN and APDN become special cases of PIDN. The underlying algebraic structure of PIDN is closed under composition and intersection. Determinig consistency of P I DN is NP-Ilard. However, we identify some tractable subclasses of PIDN. We show that path consistency is not sufficient to ensure global consistency of the tractable subclasses of PIDN. We identify a subclass for which enforcing 4-consistency suffices to ensure the global consistency, and prove that this subclass is maximal for qualitative constraints. Our approach is based on the geometric interpretation of the domains of temporal objects. Interestingly, the classical Helly's Theorem of 1923 is used to prove the complexity for the tractable subclass.

#index 1273910
#* Reactive control of dynamic progressive processing
#@ Shlomo Zilberstein;Abdel-Illah Mouaddib
#t 1999
#c 11
#% 91210
#% 98073
#% 205385
#% 1271888
#% 1476303
#% 1478774
#! Progressive processing is a model of computation that allows a system to tradeoff computational resources against the quality of results. This paper generalizes the existing model to maice it suitable for dynamic composition of information retrieval techniques. The new framework addresses effectively the uncertainty associated with the duration and output quality of each component. We show how to construct an optimal meta-level controller for a single task based on solving a corresponding Markov decision problem, and how to extend the solution to the case of multiple and dynamic tasks using the notion of an opportunity cost.

#index 1273911
#* Pre-sending documents on the WWW: a comparative study
#@ David Albrecht;Ingrid Zukerman;Ann Nicholson
#t 1999
#c 11
#% 284823
#% 423985
#% 464228
#% 520720
#% 1275346
#! Users' waiting time for information on the WWW may be reduced by pre-sending documents they are likely to request, albeit at a possible expense of additional transmission costs. In this paper, we describe a prediction model which anticipates the documents a user is likely to request next, and present a decision-theoretic approach for pre-sending documents based on the predictions made by this model. We introduce two evaluation methods which measure the immediate and the eventual benefit of pre-sending a document. We use these evaluation methods to compare the performance of our decision-theoretic policy to that of a naive pre-sending policy, and to identify the domain parameter configurations for which each of these policies provides a clear overall benefit to the user.

#index 1273912
#* Thinking ahead: continual computation policies for allocating idle and real-time resources to solve future challenges
#@ Eric Horvitz
#t 1999
#c 11
#% 68238
#% 260005
#% 1290112
#% 1476322
#% 1478774
#! Research on continual computation centers on developing precomputation policies that can effectively harness available resources to solve future challenges. We focus on integrating a consideration of offline and real-time resources in continual computation. We review precomputation policies for flexible procedures and present strategies that account for the expected future real-time refinement of a result following precomputation. Finally, we address policies that consider the tradeoff between the efficiency of solving current and potential future challenges.

#index 1273913
#* On the role of context-specific independence in probabilistic inference
#@ Nevin L. Zhang;David Poole
#t 1999
#c 11
#% 44876
#% 138515
#% 205380
#% 449588
#% 1271900
#% 1272302
#% 1650704
#% 1650767
#% 1650778
#! Context-specific independence (CSI) refers to conditional independencies that are true only in specific contexts. It has been found useful in various inference algorithms for Bayesian networks. This paper studies the role of CSI in general. We provide a characterization of the computational leverages offered by CSI without referring to particular inference algorithms. We identify the issues that need to be addressed in order to exploit the leverages and show how those issues can be addressed. We also provide empirical evidence that demonstrates the usefulness of CSI.

#index 1273914
#* Exploratory interaction with a Bayesian argumentation system
#@ Ingrid Zukerman;Richard McConachy;Kevin Korb;Deborah Pickett
#t 1999
#c 11
#% 44876
#% 145393
#% 266372
#% 373996
#% 748543
#% 835738
#% 1290079
#! We describe an interactive system which supports the exploration of arguments generated from Bayesian networks. In particular, we consider key features which support interactive behaviour: (1) an attentional mechanism which updates the activation of concepts as the interaction progresses; (2) a set of exploratory responses; and (3) a set of probabilistic patterns and an Argument Grammar which support the generation of natural language arguments from Bayesian networks. A preliminary evaluation assesses the effect of our exploratory responses on user's beliefs.

#index 1273915
#* Learning probabilistic relational models
#@ Nir Friedman;Lise Getoor;Daphne Koller;Avi Pfeffer
#t 1999
#c 11
#% 147677
#% 197387
#% 228812
#% 266215
#% 266230
#% 277480
#% 304908
#% 396021
#% 465762
#% 1271905
#! A large portion of real-world data is stored in commercial relational database systems. In contrast, most statistical learning methods work only with "flat" data representations. Thus, to apply these methods, we are forced to convert our data into a flat form, thereby losing much of the relational structure present in our database. This paper builds on the recent work on probabilistic relational models (PRMs), and describes how to learn them from databases. PRMs allow the properties of an object to depend probabilistically both on other properties of that object and on properties of related objects. Although PRMs are significantly more expressive than standard models, such as Bayesian networks, we show how to extend well-known statistical methods for learning Bayesian networks to learn these models. We describe both parameter estimation and structure learning -- the automatic induction of the dependency structure in a model. Moreover, we show how the learning procedure can exploit standard database retrieval techniques for efficient learning from large datasets. We present experimental results on both real and synthetic relational databases.

#index 1273916
#* Computing near optimal strategies for stochastic investment planning problems
#@ Milos Hauskrecht;Gopal Pandurangan;Eli Upfal
#t 1999
#c 11
#% 224762
#% 265807
#% 363744
#% 389689
#% 644560
#% 1290041
#% 1290043
#! We present efficient techniques for computing near optimal strategies for a class of stochastic commodity trading problems modeled as Markov decision processes (MDPs). The process has a continuous state space and a large action space and cannot be solved efficiently by standard dynamic programming methods. We exploit structural properties of the process, and combine it with Monte-Carlo estimation techniques to obtain novel and efficient algorithms that closely approximate the optimal strategies.

#index 1273917
#* Multi-value-functions: efficient automatic action hierarchies for multiple goal MDPs
#@ Andrew W. Moore;Leemon C. Baird;Leslie Kaelbling
#t 1999
#c 11
#% 51999
#% 160859
#% 272662
#% 272663
#% 466066
#% 476730
#! If you have planned to achieve one particular goal in a stochastic delayed rewards problem and then someone asks about a different goal what should you do? What if you need to be ready to quickly supply an answer for any possible goal? This paper shows that by using a new kind of automata caily generated abstract action hierarchy that with N states, preparing for all of N possible goals can be much much cheaper than N times the work of preparing for one goal. In goal-based Markov Decision Problems, it is usual to generate a policy π(x) mapping states to actions, and a value function J(x) mapping states to an estimate of minimum expected cost-to-goal, starting at x. In this paper we will use the terminology that a multipolicy π*(x, y) (for all state-pairs (x, y)) maps a state x to the first action it should take in order to reach y with expected minimum cost and a multi-valuefunction J*(x, y) is a definition of this minimum cost. Building these objects quickly and with little memory is the main purpose of this paper, but a secondary result is a natural, automatic, way to create a set of parsimonious yet powerful abstractactions for MDPs. The paper concludes with a set of empirical results on increasingly large MDPs.

#index 1273918
#* A sparse sampling algorithm for near-optimal planning in large Markov decision processes
#@ Michael Kearns;Yishay Mansour;Andrew Y. Ng
#t 1999
#c 11
#% 174161
#% 178906
#% 265807
#% 305085
#% 408638
#% 1650568
#! An issue that is critical for the application of Markov decision processes (MDPs) to realistic problems is how the complexity of planning scales with the size of the MDP. In stochastic environments with very large or even infinite state spaces, traditional planning and reinforcement learning algorithms are often inapplicable, since their running time typically scales linearly with the state space size. In this paper we present a new algorithm that, given only a generative model (simulator) for an arbitrary MDP, performs near-optimal planning with a running time that has no dependence on the number of states. Although the running time is exponential in the horizon time (which depends only on the discount factor 7 and the desired degree of approximation to the optimal policy), our results establish for the first time that there are no theoretical barriers to computing near-optimal policies in arbitrarily large, unstructured MDPs. Our algorithm is based on the idea of sparse sampling. We prove that a randomly sampled look-ahead tree that covers only a vanishing fraction of the full look-ahead tree nevertheless suffices to compute near-optimal actions from any state of an MDP. Practical implementations of the algorithm are discussed, and we draw ties to our related recent results on finding a near-best strategy from a given class of strategies in very large partially observable MDPs [KMN99].

#index 1273919
#* Computing factored value functions for policies in structured MDPs
#@ Daphne Koller;Ronald Parr
#t 1999
#c 11
#% 203598
#% 265807
#% 272665
#% 305095
#% 707761
#% 1650568
#% 1650710
#! Many large Markov decision processes (MDPs) can be represented compactly using a structured representation such as a dynamic Bayesian network. Unfortunately, the compact representation does not help standard MDP algorithms, because the value function for the MDP does not retain the structure of the process description. We argue that in many such MDPs, structure is approximately retained. That is, the value functions are nearly additive: closely approximated by a linear function over factors associated with small subsets of problem features. Based on this idea, we present a convergent, approximate value determination algorithm for structured MDPs. The algorithm maintains an additive value function, alternating dynamic programming steps with steps that project the result back into the restricted space of additive functions. We show that both the dynamic programming and the projection steps can be computed efficiently, despite the fact that the number of states is exponential in the number of state variables.

#index 1273920
#* Bounding the suboptimality of reusing subproblems
#@ Michael Bowling;Manuela Veloso
#t 1999
#c 11
#% 22348
#% 179766
#% 677443
#% 1272286
#% 1290043
#% 1650589
#% 1650613
#! We are interested in the problem of determining a course of action to achieve a desired objective in a non-deterministic environment. Markov decision processes (MDPs) provide a framework for representing this action selection problem, and there are a number of algorithms that learn optimal policies within this formulation. This framework has also been used to study state space abstraction, problem decomposition, and policy reuse. These techniques sacrifice optimality of their solution for improved learning speed. In this paper we examine the suboptimality of reusing policies that are solutions to subproblems. This is done within a restricted class of MDPs, namely those where non-zero reward is received only upon reaching a goal state. We introduce the definition of a subproblem within this class and provide motivation for how reuse of subproblem solutions can speed up learning. The contribution of this paper is the derivation of a tight bound on the loss in optimality from this reuse. We examine a bound that is based on Bellman error, which applies to all MDPs, but is not tight enough to be useful. We contribute our own theoretical result that gives an empirically tight bound on this suboptimality.

#index 1273921
#* Variable resolution discretization for high-accuracy solutions of optimal control problems
#@ Remi Munos;Andrew Moore
#t 1999
#c 11
#% 135455
#% 201257
#% 305089
#% 314789
#% 363744
#! State abstraction is of central importance in remforcement learning and Markov Decision Processes. This paper studies the case of variable resolution state abstraction for continuous-state, deterministic dynamic control problems in which near-optimal policies are required. We describe variable resolution policy and value function representations based on Kuhn triangulations embedded in a kd-tree. We then consider top-down approaches to choosing which cells to split in order to generate improved policies. We begin with local approaches based on value function properties and policy properties that use only features of individual cells in making splitting choices. Later, by introducing two new non-local measures, influence and variance, we derive a splitting criterion that allows one cell to efficiently take into account its impact on other cells when deciding whether to split. We evaluate the performance of a variety of splitting criteria on many benchmark problems (published on the web), paying careful attention to their number-of-cells versus closeness-to-optimality tradeoff curves.

#index 1273922
#* Solving non-Markovian control tasks with neuroevolution
#@ Faustino J. Gomez;Risto Miikkulainen
#t 1999
#c 11
#% 124694
#% 199975
#% 203594
#% 235332
#% 258868
#% 446024
#% 690846
#! The success of evolutionary methods on standard control learning tasks has created a need for new benchmarks. The classic pole balancing problem is no longer difficult enough to serve as a viable yardstick for measuring the learning efficiency of these systems. The double pole case, where two poles connected to the cart must be balanced simultaneously is much more difficult, especially when velocity information is not available. In this article, we demonstrate a neuroevolution system, Enforced Sub-populations (ESP), that is used to evolve a controller for the standard double pole task and a much harder, non-Markovian version. In both cases, our results show that ESP is faster than other neuroevolution methods. In addition, we introduce an incremental method that evolves on a sequence of tasks, and utilizes a local search technique (Delta-Coding) to sustain diversity. This method enables the system to solve even more difficult versions of the task where direct evolution cannot.

#index 1273923
#* Reinforcement algorithms using functional approximation for generalization and their application to cart centering and fractal compression
#@ Clifford Claussen;Srinivas Gutta;Harry Wechsler
#t 1999
#c 11
#% 52018
#% 124074
#% 124691
#% 172632
#% 367222
#% 384911
#! We address the conflict between identification and control or alternatively, the conflict between exploration and exploitation, within the framework of reinforcement learning. Q-learning has recently become a popular off-policy reinforcement learning method. The conflict between exploration and exploitation slows down Q-learning algorithms; their performance does not scale up and degrades rapidly as the number of states and actions increases. One reason for this slowness is that exploration lacks the ability to extrapolate and interpolate from learning and to a large extent has to "reinvent the wheel". Moreover, not all reinforcement problems one encounters are finite state and action systems. Our approach to solving continuous state and action problems is to approximate the continuous state and action spaces with finite sets of states and actions and then to apply a finite state and action learning method. This approach provides the means for solving continuous state and action problems but does not yet address the performance problem associated with scaling up states and actions. We address the scaling problem using functional approximation methods. Towards that end, this paper introduces two new reinforcement algorithms, QLVQ and Quad-Q-learning, respectively, and shows their successful application for cart centering and fractal compression.

#index 1273924
#* Towards a possibilistic logic handling of preferences
#@ Salem Benferhat;Didier Dubois;Henri Prade
#t 1999
#c 11
#% 229087
#% 266232
#% 393800
#% 442844
#% 566111
#% 638794
#% 1273683
#! The classical way of encoding preferences in decision theory is by means of utility or value functions. However agents are not always able to deliver such a function directly. In this paper, we relate three different ways of specifying preferences, namely by means of a set of particular types of constraints on the utility function, by means of an ordered set of prioritized goals expressed by logical propositions, and by means of an ordered set of subsets of possible candidates reaching the same level of satisfaction. These different expression modes can be handled in a weighted logical setting, here the one of possibilistic logic. The aggregation of preferences pertaining to different criteria can then be handled by fusing sets of prioritized goals. Apart from a better expressivity, the benefits of a logical representation of preferences are to put them in a suitable format for reasoning purposes, or for modifying or revising them.

#index 1273925
#* Incremental learning in a fuzzy intelligent system
#@ Yi Lu Murphey;Tie Qi Chen
#t 1999
#c 11
#% 172486
#% 376266
#% 449529
#% 858814
#% 1860028
#! This paper presents an incremental learning algorithm within the framework of a fuzzy intelligent system. The incremental learning algorithm is based on priority values attached to fuzzy rules. The priority value of a fuzzy rule is generated based on the fuzzy belief values of the fuzzy rule derived from the training data. The fuzzy incremental algorithm has three important properties. It can detect and recover from incorrect knowledge once new knowledge is available; it will not lose the useful knowledge generated from the old data while it attempts to learn from new data; and it provides a mechanism allowing to emphasize on knowledge learnt from the new data. The incremental fuzzy learning algorithm has been implemented in a fuzzy intelligent system for automotive engineering diagnosis. Its performance is presented in the paper.

#index 1273926
#* Robotics in the home, office, and playing field
#@ Minoru Asada;Henrik I. Christensen
#t 1999
#c 11
#% 67564
#% 455258
#% 455259
#! Robots are gradually entering into diverse application domains such as home, office, and playing field. This article presents advanced research activities related to these domains. First is RoboCup which is an attempt to promote AI and robotics research by providing a common task for evaluation of various performance, theories, algorithms, and robot architectures. In order for robots (both physical robots and soft agents) to play a soccer game reasonably well, a wide range of technologies need to be integrated and a number of technical breakthrough must be accomplished. The recent results from the last two RoboCups are reviewed and future leagues are introduced. Second, the richer domain of service robotics has also received significant interest recently. The task here is to serve as a human assistant in an office or domestic environment, for tasks like cleaning and delivery. The human-robot interaction is a key issue to success, which poses new challenges in terms of integration of spoken dialogue, gestures, body language, etc. In addition mobile manipulation and safe navigation around humans is essential to success. These two areas integrates many different disciplines including control, perception, natural language processing, hybrid systems and handling of uncertainty, and applied to tour guiding, mail delivery, domestic services, and rescue activities.

#index 1273927
#* Model-based diagnosis in the real world: lessons learned and challenges remaining
#@ Luca Console;Oskar Dressier
#t 1999
#c 11
#% 1120
#% 1121
#% 3460
#% 21137
#% 21138
#% 44876
#% 53410
#% 78634
#% 105619
#% 107135
#% 110365
#% 125529
#% 125549
#% 125587
#% 132145
#% 132173
#% 179968
#% 181220
#% 257696
#% 262241
#% 443070
#% 445130
#% 445184
#% 461710
#% 669901
#% 789372
#% 802496
#% 936862
#% 1290121
#% 1476265
#% 1478745
#% 1478847
#! This paper discusses some trends in model-based diagnosis. We consider some recent applications and discuss why they were possible, the lessons we learned from them, the new impulse that they gave to research in the field and the new challenges that emerged from them.

#index 1273928
#* A brief introduction to boosting
#@ Robert E. Schapire
#t 1999
#c 11
#% 697
#% 66937
#% 68820
#% 73372
#% 116149
#% 136350
#% 157162
#% 180945
#% 190581
#% 197394
#% 198701
#% 214401
#% 235377
#% 252009
#% 262085
#% 266255
#% 272539
#% 311034
#% 312727
#% 424997
#% 465751
#% 564279
#% 1272365
#% 1478814
#% 1499573
#% 1809314
#! Boosting is a general method for improving the accuracy of any given learning algorithm. This short paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting. Some examples of recent applications of boosting are also described.

#index 1273929
#* The multilingual generation game: authoring fluent texts in unfamiliar languages
#@ Donia R. Scott
#t 1999
#c 11
#% 183418
#% 192492
#% 696827
#% 742245
#% 747784
#% 748317
#% 1290078
#! There are obvious reasons for trying to automate the production of multilingual documents. Among them are the rapidly growing need for such documents, the high cost and low availability of good translators, and the fact that translators often need more time than is available to produce good multilingual versions. These problems are compounded when equivalent versions of a document are needed in not just two or three, but many, languages -- as is often the case in Europe, where there are now eleven official languages in the European Community. This talk presents some recent developments in Multilingual Natural Language Generation (MNLG). These allow the automatic production of high-quality multilingual documents, while avoiding many of the well-known pitfalls of the more familiar alternative of Machine Translation (MT) -- for example, the difficulty of information extraction from a source document and the danger of source-language bias.

#index 1273930
#* Was the title of this talk generated automatically?: prospects on intelligent interfaces and language
#@ Oliviero Stock
#t 1999
#c 11
#% 145628
#% 145661
#% 192823
#% 215532
#% 239575
#% 239619
#% 257582
#% 265782
#% 741112
#% 1275351
#! We are beginning to make use of technology that intervenes in the contents of the communication. Language processing has indeed a large practical potential if we take into account multiple modalities of communication. Multimodality refers to the perception of different co-ordinated media used in delivering a message but also to the combination of various attitudes in relation to communication and information access (e.g. goal-oriented and exploration-oriented). In the paper reference is made to some prototypes developed at IRST, conceived for cultural tourism. In a recent one the specificity is the combination of two forms of navigation taking place at the same time - one in information space, the other in the physical space. Some challenges for the future are discussed toward the end.

#index 1273931
#* Electronic commerce: from economic and game-theoretic models to working protocols
#@ Moshe Tennenholtz
#t 1999
#c 11
#% 52273
#% 216969
#% 220808
#% 233131
#% 233135
#% 265785
#% 267752
#% 283007
#% 496094
#% 496250

#index 1273932
#* Agent-based computing: promise and perils
#@ Nicholas R. Jennings
#t 1999
#c 11
#% 135520
#% 174161
#% 187264
#% 189698
#% 198069
#% 214028
#% 228354
#% 250125
#% 252831
#% 274921
#% 370029
#% 743155
#! Agent-based computing represents an exciting new synthesis both for Artificial Intelligence (AI) and, more generally, Computer Science. It has the potential to significantly improve the theory and the practice of modelling, designing, and implementing complex systems. Yet, to date, there has been little systematic analysis of what makes an agent such an appealing and powerful conceptual model. Moreover, even less effort has been devoted to exploring the inherent disadvantages that stem from adopting an agent-oriented view. Here both sets of issues are explored. The standpoint of this analysis is the role of agent-based software in solving complex, real-world problems. In particular, it will be argued that the development of robust and scalable software systems requires autonomous agents that can complete their objectives while situated in a dynamic and uncertain environment, that can engage in rich, high-level social interactions, and that can operate within flexible organisational structures.

#index 1273933
#* Reasoning with cause and effect
#@ Judea Pearl
#t 1999
#c 11
#! This paper summarizes concepts, principles, and tools that were found useful in applications involving causal modeling. The principles are based on structural-model semantics, in which functional (or counterfactual) relationships, representing autonomous physical processes are the fundamental building blocks. The paper presents the formal basis of this semantics, illustrates its application in simple problems and discusses its ramifications to computational and cognitive problems concerning causation.

#index 1274753
#* Proceedings of the 20th international joint conference on Artifical intelligence
#@ Rajeev Sangal;Harish Mehta;R. K. Bagga
#t 2007
#c 11

#index 1274754
#* Cooperating reasoning processes: more than just the sum of their parts
#@ Alan Bundy
#t 2007
#c 11
#% 57056
#% 90828
#% 107544
#% 222437
#% 333458
#% 371498
#% 409394
#% 417690
#% 420761
#% 472557
#% 472850
#% 496281
#% 559900
#% 561052
#% 848429
#% 918149
#% 1036400
#% 1344022
#% 1344388
#% 1703693
#% 1718493
#! Using the achievements of my research group over the last 30+ years, I provide evidence to support the following hypothesis: By complementing each other, cooperating reasoning process can achieve much more than they could if they only acted individually. Most of the work of my group has been on processes for mathematical reasoning and its applications, e.g. to formal methods. The reasoning processes we have studied include: Proof Search: by meta-level inference, proof planning, abstraction, analogy, symmetry, and reasoning with diagrams. Representation Discovery, Formation and Evolution: by analysing, diagnosing and repairing failed proof and planning attempts, forming and repairing new concepts and conjectures, and forming logical representations of informally stated problems. Other: learning of new proof methods from example proofs, finding counter-examples, reasoning under uncertainty, the presentation of and interaction with proofs, the automation of informal argument. In particular, we have studied how these different kinds of process can complement each other, and cooperate to achieve complex goals. We have applied this work to the following areas: proof by mathematical induction and co-induction; analysis; equation solving, mechanics problems; the building of ecological models; the synthesis, verification, transformation and editing of both hardware and software, including logic, functional and imperative programs, security protocols and process algebras; the configuration of hardware; game playing and cognitive modelling.

#index 1274755
#* Learning and multiagent reasoning for autonomous agents
#@ Peter Stone
#t 2007
#c 11
#% 18600
#% 34880
#% 116297
#% 124694
#% 136350
#% 169359
#% 181058
#% 263059
#% 271067
#% 286423
#% 290482
#% 305081
#% 348578
#% 364575
#% 368024
#% 369236
#% 384911
#% 418626
#% 418731
#% 418831
#% 433914
#% 449561
#% 449980
#% 452359
#% 455258
#% 455259
#% 455260
#% 455261
#% 455262
#% 466418
#% 504942
#% 506270
#% 558916
#% 581051
#% 643103
#% 713046
#% 734920
#% 769923
#% 773254
#% 804739
#% 809099
#% 811676
#% 817714
#% 820330
#% 820339
#% 820340
#% 820343
#% 820404
#% 829020
#% 876006
#% 882286
#% 961164
#% 1022791
#% 1248838
#% 1250387
#% 1250388
#% 1250392
#% 1250585
#% 1250660
#% 1269488
#% 1269498
#% 1269569
#% 1271827
#% 1271997
#% 1272381
#% 1274860
#% 1275109
#% 1279356
#% 1279507
#% 1289471
#% 1499477
#% 1693743
#% 1730316
#% 1730332
#% 1730341
#% 1730377
#! One goal of Artificial Intelligence is to enable the creation of robust, fully autonomous agents that can coexist with us in the real world. Such agents will need to be able to learn, both in order to correct and circumvent their inevitable imperfections, and to keep up with a dynamically changing world. They will also need to be able to interact with one another, whether they share common goals, they pursue independent goals, or their goals are in direct conflict. This paper presents current research directions in machine learning, multiagent reasoning, and robotics, and advocates their unification within concrete application domains. Ideally, new theoretical results in each separate area will inform practical implementations while innovations from concrete multiagent applications will drive new theoretical pursuits, and together these synergistic research approaches will lead us towards the goal of fully autonomous agents.

#index 1274756
#* The logic behind weighted CSP
#@ Carlos Ansótegui;María Luisa Bonet;Jordi Levy;Felip Manyà
#t 2007
#c 11
#% 126386
#% 289947
#% 639107
#% 789556
#% 1279246
#% 1289364
#% 1289381
#% 1499492
#% 1728041
#! We define a translation from Weighted CSP to signed Max-SAT, and a complete resolution-style calculus for solving signed Max-SAT. Based on these results, we then describe an original exact algorithm for solving Weighted CSP. Finally, we define several derived rules and prove that they enforce the main soft arc consistency defined in the literature when applied toWeighted CSP instances.

#index 1274757
#* QCSP made practical by virtue of restricted quantification
#@ Marco Benedetti;Arnaud Lallouet;Jérémie Vautard
#t 2007
#c 11
#% 4599
#% 131357
#% 278105
#% 443134
#% 535134
#% 1223207
#% 1250509
#% 1250529
#% 1269402
#% 1403039
#% 1675277
#% 1728052
#% 1732238
#! The QCSP+ language we introduce extends the framework of Quantified Constraint Satisfaction Problems (QCSPs) by enabling us to neatly express restricted quantifications via a chain of nested CSPs to be interpreted as alternately conjuncted and disjuncted. Restricted quantifiers turn out to be a convenient solution to the crippling modeling issues we encounter in QCSP and--surprisingly-- they help to reuse propagation technology and to prune the search space. Our QCSP+ solver--which also handles arithmetic and global constraints-- exhibits state-of-the-art performances.

#index 1274758
#* Learning implied global constraints
#@ Christian Bessiere;Remi Coletta;Thierry Petit
#t 2007
#c 11
#% 57056
#% 334459
#% 534983
#% 1499496
#% 1732232
#! Finding a constraint network that will be efficiently solved by a constraint solver requires a strong expertise in Constraint Programming. Hence, there is an increasing interest in automatic reformulation. This paper presents a general framework for learning implied global constraints in a constraint network assumed to be provided by a non-expert user. The learned global constraints can then be added to the network to improve the solving process. We apply our technique to global cardinality constraints. Experiments show the significance of the approach.

#index 1274759
#* Query-driven constraint acquisition
#@ Christian Bessiere;Remi Coletta;Barry O'Sullivan;Mathias Paulin
#t 2007
#c 11
#% 749132
#% 787003
#% 1699577
#! The modelling and reformulation of constraint networks are recognised as important problems. The task of automatically acquiring a constraint network formulation of a problem from a subset of its solutions and non-solutions has been presented in the literature. However, the choice of such a subset was assumed to be made independently of the acquisition process. We present an approach in which an interactive acquisition system actively selects a good set of examples. We show that the number of examples required to acquire a constraint network is significantly reduced using our approach.

#index 1274760
#* A general framework for scheduling in a stochastic environment
#@ Julien Bidot;Thierry Vidal;Philippe Laborie;J. Christopher Beck
#t 2007
#c 11
#% 722504
#% 1289215
#% 1289542
#% 1499491
#! There are many systems and techniques that address stochastic scheduling problems, based on distinct and sometimes opposite approaches, especially in terms of how scheduling and schedule execution are combined, and if and when knowledge about the uncertainties are taken into account. In many real-life problems, it appears that all these approaches are needed and should be combined, which to our knowledge has never been done. Hence it it first desirable to define a thorough classification of the techniques and systems, exhibiting relevant features: in this paper, we propose a tree-dimension typology that distinguishes between proactive, progressive, and revision techniques. Then a theoretical representation model integrating those three distinct approaches is defined. This model serves as a general template within which parameters can be tuned to implement a system that will fit specific application needs: we briefly introduce in this paper our first experimental prototypes which validate our model.

#index 1274761
#* New constraint programming approaches for the computation of leximin-optimal solutions in constraint networks
#@ Sylvain Bouveret;Michel Lemaître
#t 2007
#c 11
#% 40313
#% 126389
#% 269391
#% 496270
#% 857276
#% 1279243
#! We study the problem of computing a leximin-optimal solution of a constraint network. This problem is highly motivated by fairness and efficiency requirements in many real-world applications implying human agents. We compare several generic algorithms which solve this problem in a constraint programming framework. The first one is entirely original, and the other ones are partially based on existing works adapted to fit with this problem.

#index 1274762
#* Optimal soft arc consistency
#@ M. C. Cooper;S. De Givry;T. Schiex
#t 2007
#c 11
#% 1436
#% 53085
#% 419942
#% 575676
#% 578663
#% 578951
#% 751442
#% 757482
#% 816233
#% 850495
#% 866433
#% 1250510
#% 1250517
#% 1275309
#% 1289364
#! The Valued (VCSP) framework is a generic optimization framework with a wide range of applications. Soft arc consistency operations transform a VCSP into an equivalent problem by shifting weights between cost functions. The principal aim is to produce a good lower bound on the cost of solutions, an essential ingredient of a branch and bound search. But soft AC is much more complex than traditional AC: there may be several closures (fixpoints) and finding the closure with a maximum lower bound has been shown to be NP-hard for integer costs [Cooper and Schiex, 2004]. We introduce a relaxed variant of soft arc consistency using rational costs. In this case, an optimal closure can be found in polynomial time. Furthermore, for finite rational costs, the associated lower bound is shown to provide an optimal arc consistent reformulation of the initial problem. Preliminary experiments on random and structured problems are reported, showing the strength of the lower bound produced.

#index 1274763
#* Quantified constraint satisfaction problems: from relaxations to explanations
#@ Alex Ferguson;Barry O'Sullivan
#t 2007
#c 11
#% 126386
#% 535134
#% 795601
#% 1250145
#% 1269415
#% 1289372
#! The Quantified Constraint Satisfaction Problem (QCSP) is a generalisation of the classical CSP in which some of variables can be universally quantified. In this paper, we extend two well-known concepts in classical constraint satisfaction to the quantified case: problem relaxation and explanation of inconsistency. We show that the generality of the QCSP allows for a number of different forms of relaxation not available in classical CSP. We further present an algorithmfor computing a generalisation of conflict-based explanations of inconsistency for the QCSP.

#index 1274764
#* The design of ESSENCE: a constraint language for specifying combinatorial problems
#@ Alan M. Frisch;Matthew Grum;Chris Jefferson;Bernadette Martínez Hernández;Ian Miguel
#t 2007
#c 11
#% 56176
#% 181043
#% 269391
#% 419960
#% 878211
#% 1289368
#% 1665010
#% 1705334
#% 1797049
#! ESSENCE is a new formal language for specifying combinatorial problems in a manner similar to natural rigorous specifications that use a mixture of natural language and discrete mathematics. ESSENCE provides a high level of abstraction, much of which is the consequence of the provision of decision variables whose values can be combinatorial objects, such as tuples, sets, multisets, relations, partitions and functions. ESSENCE also allows these combinatorial objects to be nested to arbitrary depth, thus providing, for example, sets of partitions, sets of sets of partitions, and so forth. Therefore, a problem that requires finding a complex combinatorial object can be directly specified by using a decision variable whose type is precisely that combinatorial object.

#index 1274765
#* Conditional constraint satisfaction: logical foundations and complexity
#@ Georg Gottlob;Gianluigi Greco;Toni Mancini
#t 2007
#c 11
#% 321058
#% 331899
#% 398173
#% 447404
#% 534484
#% 644201
#% 816232
#% 1272035
#% 1289356
#% 1477074
#! Conditional Constraint Satisfaction Problems (CCSPs) are generalizations of classical CSPs that support conditional activation of variables and constraints. Despite the interest emerged for CCSPs in the context of modelling the intrinsic dynamism of diagnosis, structural design, and product configuration applications, a complete characterization of their computational properties and of their expressiveness is still missing. In fact, the aim of the paper is precisely to face these open research issues. First, CCSPs are formally characterized in terms of a suitable fragment of first-order logic. Second, the complexity of some basic reasoning tasks for CCSPs is studied, by establishing completeness results for the first and the second level of the polynomial hierarchy. Finally, motivated by the hardness results, an island of tractability for CCSPs is identified, by extending structural decomposition methods originally proposed for CSPs.

#index 1274766
#* Generalized interval projection: a new technique for consistent domain extension
#@ Carlos Grandón;Gilles Chabert;Bertrand Neveu
#t 2007
#c 11
#% 14187
#% 305369
#% 477281
#% 495952
#% 874376
#% 874378
#! This paper deals with systems of parametric equations over the reals, in the framework of interval constraint programming. As parameters vary within intervals, the solution set of a problem may have a non null volume. In these cases, an inner box (i.e., a box included in the solution set) instead of a single punctual solution is of particular interest, because it gives greater freedom for choosing a solution. Our approach is able to build an inner box for the problem starting with a single point solution, by consistently extending the domain of every variable. The key point is a new method called generalized projection. The requirements are that each parameter must occur only once in the system, variable domains must be bounded, and each variable must occur only once in each constraint. Our extension is based on an extended algebraic structure of intervals called generalized intervals, where improper intervals are allowed (e.g. [1,0]).

#index 1274767
#* Techniques for efficient interactive configuration of distribution networks
#@ Tarik Hadžic;Andrzej Wasowski;Henrik R. Andersen
#t 2007
#c 11
#% 3873
#% 345434
#% 386158
#% 399764
#% 408396
#% 644201
#% 874128
#% 1250516
#! Recovering from power outages is an essential task in distribution of electricity. Our industrial partner postulates that the recovery should be interactive rather than automatic: supporting the operator by preventing choices that destabilize the network. Interactive configurators, successfully used in specifying products and services, support users in selecting logically constrained parameters in a sound, complete and backtrack-free manner. Interactive restoration algorithms based on reduced ordered binary decision diagrams (BDDs) had been developed also for power distribution networks, however they did not scale to the large instances, as BDDs representing these could not be compiled. We discuss the theoretical hardness of the interactive configuration and then provide techniques used to compile two classes of networks. We handle the largest industrial instances available. Our techniques rely on symbolic reachability computation, early variable quantification, domain specific ordering heuristics and conjunctive decomposition.

#index 1274768
#* Distance constraints in constraint satisfaction
#@ Emmanuel Hebrard;Barry O'Sullivan;Toby Walsh
#t 2007
#c 11
#% 230551
#% 283228
#% 787003
#% 1269417
#% 1272026
#% 1738929
#! Users can often naturally express their preferences in terms of ideal or non-ideal solutions. We show how to reason about logical combinations of distance constraints on ideals and non-ideals using a novel global constraint. We evaluate our approach on both randomly generated and real-world configuration problem instances.

#index 1274769
#* Dynamic heuristics for backtrack search on tree-decomposition of CSPs
#@ Philippe Jégou;Samba Ndojh Ndiaye;Cyril Terrioux
#t 2007
#c 11
#% 451
#% 55926
#% 322912
#% 331899
#% 581814
#% 1275309
#! This paper deals with methods exploiting tree-decomposition approaches for solving constraint networks. We consider here the practical efficiency of these approaches by defining five classes of variable orders more and more dynamic which preserve the time complexity bound. For that, we define extensions of this theoretical time complexity bound to increase the dynamic aspect of these orders. We define a constant k allowing us to extend the classical bound from O(exp(w + 1)) firstly to O(exp(w + k + 1)), and finally to O(exp(2(w + k+1)-s-)), with w the "tree-width" of a CSP and s- the minimum size of its separators. Finally, we assess the defined theoretical extension of the time complexity bound from a practical viewpoint.

#index 1274770
#* Symmetric component caching
#@ Matthew Kitching;Fahiem Bacchus
#t 2007
#c 11
#% 319936
#% 329486
#% 336874
#% 529186
#% 723877
#% 1223215
#! Caching, symmetries, and search with decomposition are powerful techniques for pruning the search space of constraint problems. In this paper we present an innovative way of efficiently combining these techniques with branch and bound for solving certain types of constraint optimization problems (COPs). Our new method significantly reduces the overhead of performing decomposition during search when dynamic variable orderings are employed. In addition, it supports the exploitation of dynamic symmetries that appear only during search. Symmetries have not previously been combined with decomposition. Finally, we achieve a superior integration of decomposition and caching with branch and bound than previous approaches. We test our methods on the Maximum Density Still Life problem and show that each of our ideas yields a significant gain in search performance.

#index 1274771
#* A study of residual supports in arc consistency
#@ Christophe Lecoutre;Fred Hemery
#t 2007
#c 11
#% 336874
#% 769573
#% 838024
#% 1289359
#% 1289382
#! In an Arc Consistency (AC) algorithm, a residual support, or residue, is a support that has been stored during a previous execution of the procedure which determines if a value is supported by a constraint. The point is that a residue is not guaranteed to represent a lower bound of the smallest current support of a value. In this paper, we study the theoretical impact of exploiting residues with respect to the basic algorithm AC3. First, we prove that AC3rm (AC3 with multi-directional residues) is optimal for low and high constraint tightness. Second, we show that when AC has to be maintained during a backtracking search, MAC2001 presents, with respect to MAC3rm, an overhead in O(µed) per branch of the binary tree built by MAC, where µ denotes the number of refutations of the branch, e the number of constraints and d the greatest domain size of the constraint network. One consequence is that MAC3rm admits a better worst-case time complexity than MAC2001 for a branch involving µ refutations when either µ d2 or µ d and the tightness of any constraint is either low or high. Our experimental results clearly show that exploiting residues allows enhancing MAC and SAC algorithms.

#index 1274772
#* Nogood recording from restarts
#@ Christophe Lecoutre;Lakhdar Sais;Sébastien Tabary;Vincent Vidal
#t 2007
#c 11
#% 68183
#% 160253
#% 319789
#% 336874
#% 420713
#% 477221
#% 534978
#% 644201
#% 785546
#% 838024
#% 1269420
#% 1478761
#! In this paper, nogood recording is investigated within the randomization and restart framework. Our goal is to avoid the same situations to occur from one run to the next one. More precisely, no-goods are recorded when the current cutoff value is reached, i.e. before restarting the search algorithm. Such a set of nogoods is extracted from the last branch of the current search tree. Interestingly, the number of nogoods recorded before each new run is bounded by the length of the last branch of the search tree. As a consequence, the total number of recorded nogoods is polynomial in the number of restarts. Experiments over a wide range of CSP instances demonstrate the effectiveness of our approach.

#index 1274773
#* Arc consistency during search
#@ Chavalit Likitvivatanavong;Yuanlin Zhang;Scott Shannon;James Bowen;Eugene C. Freuder
#t 2007
#c 11
#% 477221
#% 838024
#! Enforcing arc consistency (AC) during search has proven to be a very effective method in solving Constraint Satisfaction Problems and it has been widely-used in many Constraint Programming systems. Although much effort has been made to design efficient standalone AC algorithms, there is no systematic study on how to efficiently enforce AC during search, as far as we know. The significance of the latter is clear given the fact that AC will be enforced millions of times in solving hard problems. In this paper, we propose a framework for enforcing AC during search (ACS) and complexity measurements of ACS algorithms. Based on this framework, several ACS algorithms are designed to take advantage of the residual data left in the data structures by the previous invocation(s) of ACS. The algorithms vary in the worst-case time and space complexity and other complexity measurements. Empirical study shows that some of the new ACS algorithms perform better than the conventional implementation of AC algorithms in a search procedure.

#index 1274774
#* Probabilistic consistency boosts MAC and SAC
#@ Deepak Mehta;M. R. C. Van Dongen
#t 2007
#c 11
#% 419990
#% 528016
#% 785505
#% 1289190
#% 1289359
#% 1289382
#% 1289388
#! Constraint Satisfaction Problems (CSPs) are ubiquitous in Artificial Intelligence. The backtrack algorithms that maintain some local consistency during search have become the de facto standard to solve CSPs. Maintaining higher levels of consistency, generally, reduces the search effort. However, due to ineffective constraint propagation, it often penalises the search algorithm in terms of time. If we can reduce ineffective constraint propagation, then the effectiveness of a search algorithm can be enhanced significantly. In order to do so, we use a probabilistic approach to resolve when to propagate and when not to. The idea is to perform only the useful consistency checking by not seeking a support when there is a high probability that a support exists. The idea of probabilistic support inference is general and can be applied to any kind of local consistency algorithm. However, we shall study its impact with respect to arc consistency and singleton arc consistency (SAC). Experimental results demonstrate that enforcing probabilistic SAC almost always enforces SAC, but it requires significantly less time than SAC. Likewise, maintaining probabilistic arc consistency and maintaining probabilistic SAC require significantly less time than maintaining arc consistency and maintaining SAC.

#index 1274775
#* Constraint and variable ordering heuristics for compiling configuration problems
#@ Nina Narodytska;Toby Walsh
#t 2007
#c 11
#% 3873
#% 202870
#% 212157
#% 233825
#% 260405
#% 302153
#% 650944
#% 729052
#! To facilitate interactive design, the solutions to configuration problems can be compiled into a decision diagram. We develop three heuristics for reducing the time and space required to do this. These heuristics are based on the distinctive clustered and hierarchical structure of the constraint graphs of configuration problems. The first heuristic attempts to limit the growth in the size of the decision diagram by providing an order in which constraints are added to the decision diagram. The second heuristic provides an initial order for the variables within the decision diagram. Finally, the third heuristic groups variables together so that they can be reordered by a dynamic variable reordering procedure used during the construction of the decision diagram. These heuristics provide one to two orders magnitude improvement in the time to compile a wide range of configuration.

#index 1274776
#* A theoretical framework for learning Bayesian networks with parameter inequality constraints
#@ Radu Stefan Niculescu;Tom M. Mitchell;R. Bharat Rao
#t 2007
#c 11
#% 132779
#% 205380
#% 277480
#% 413457
#% 496116
#% 528154
#% 677787
#% 716892
#% 857076
#% 1349571
#% 1650731
#% 1650767
#% 1673041
#! The task of learning models for many real-world problems requires incorporating domain knowledge into learning algorithms, to enable accurate learning from a realistic volume of training data. Domain knowledge can come in many forms. For example, expert knowledge about the relevance of variables relative to a certain problem can help perform better feature selection. Domain knowledge about the conditional independence relationships among variables can help learning of the Bayesian Network structure. This paper considers a different type of domain knowledge for constraining parameter estimates when learning Bayesian Networks. In particular, we consider domain knowledge that comes in the form of inequality constraints among subsets of parameters in a Bayesian Network with known structure. These parameter constraints are incorporated into learning procedures for Bayesian Networks, by formulating this task as a constrained optimization problem. The main contribution of this paper is the derivation of closed form Maximum Likelihood parameter estimators in the above setting.

#index 1274777
#* Grounding for model expansion in k-guarded formulas with inductive definitions
#@ Murray Patterson;Yongmei Liu;Eugenia Ternovska;Arvind Gupta
#t 2007
#c 11
#% 103705
#% 248033
#% 333865
#% 343623
#% 427161
#% 880394
#% 1269412
#% 1269426
#% 1279223
#% 1655194
#% 1674536
#! Mitchell and Ternovska [2005] proposed a constraint programming framework based on classical logic extended with inductive definitions. They formulate a search problem as the problem of model expansion (MX), which is the problem of expanding a given structure with new relations so that it satisfies a given formula. Their long-term goal is to produce practical tools to solve combinatorial search problems, especially those in NP. In this framework, a problem is encoded in a logic, an instance of the problem is represented by a finite structure, and a solver generates solutions to the problem. This approach relies on propositionalisation of high-level specifications, and on the efficiency of modern SAT solvers. Here, we propose an efficient algorithm which combines grounding with partial evaluation. Since the MX framework is based on classical logic, we are able to take advantage of known results for the so-called guarded fragments. In the case of k-guarded formulas with inductive definitions under a natural restriction, the algorithm performs much better than naive grounding by relying on connections between k-guarded formulas and tree decompositions.

#index 1274778
#* PC-DPOP: a new partial centralization algorithm for distributed optimization
#@ Adrian Petcu;Boi Faltings;Roger Mailler
#t 2007
#c 11
#% 643099
#% 644201
#% 773217
#% 773232
#% 823973
#% 830716
#% 862314
#% 890434
#% 1272107
#% 1275309
#% 1289386
#% 1289393
#! Fully decentralized algorithms for distributed constraint optimization often require excessive amounts of communication when applied to complex problems. The OptAPO algorithm of [Mailler and Lesser, 2004] uses a strategy of partial centralization to mitigate this problem. We introduce PC-DPOP, a new partial centralization technique, based on the DPOP algorithm of [Petcu and Faltings, 2005]. PC-DPOP provides better control over what parts of the problem are centralized and allows this centralization to be optimal with respect to the chosen communication structure. Unlike OptAPO, PC-DPOP allows for a priory, exact predictions about privacy loss, communication, memory and computational requirements on all nodes and links in the network. Upper bounds on communication and memory requirements can be specified. We also report strong efficiency gains over OptAPO in experiments on three problem domains.

#index 1274779
#* A dynamic approach to MPE and weighted MAX-SAT
#@ Tian Sang;Paul Beame;Henry Kautz
#t 2007
#c 11
#% 230551
#% 336874
#% 427631
#% 578749
#% 578757
#% 1250520
#% 1269433
#% 1279378
#% 1289364
#% 1289386
#% 1289558
#% 1672980
#% 1698709
#% 1839670
#! The problem of Most Probable Explanation (MPE) arises in the scenario of probabilistic inference: finding an assignment to all variables that has the maximum likelihood given some evidence. We consider the more general CNF-based MPE problem, where each literal in a CNF-formula is associated with a weight. We describe reductions between MPE and weighted MAX-SAT, and show that both can be solved by a variant of weighted model counting. The MPE-SAT algorithm is quite competitive with the state-of-the-art MAX-SAT, WCSP, and MPE solvers on a variety of problems.

#index 1274780
#* Backtracking procedures for hypertree, hyperspread and connected hypertree decomposition of CSPs
#@ Sathiamoorthy Subbarayan;Henrik Reif Andersen
#t 2007
#c 11
#% 2028
#% 159244
#% 331899
#% 643572
#% 644201
#% 727988
#% 788060
#% 1289362
#! Hypertree decomposition has been shown to be the most general CSP decomposition method. However, so far the exact methods are not able to find optimal hypertree decompositions of realistic instances. We present a backtracking procedure which, along with isomorphic component detection, results in optimal hypertree decompositions. We also make the procedure generic; variations of which results in two new tractable decompositions: hyperspread and connected hypertree. We show that the hyperspread width is bounded by both the hypertree width and the spread cut width, which solves a recently stated open problem. In our experiments on several realistic instances, our methods find many optimal decompositions, while the previous methods can find at most one.

#index 1274781
#* A call admission control scheme using neuroevolution algorithm in cellular networks
#@ Xu Yang;John Bigham
#t 2007
#c 11
#% 284521
#% 384911
#% 444565
#% 753008
#% 795627
#% 1768440
#! This paper proposes an approach for learning call admission control (CAC) policies in a cellular network that handles several classes of traffic with different resource requirements. The performance measures in cellular networks are long term revenue, utility, call blocking rate (CBR) and handoff failure rate (CDR). Reinforcement Learning (RL) can be used to provide the optimal solution, however such method fails when the state space and action space are huge. We apply a form of NeuroEvolution (NE) algorithm to inductively learn the CAC policies, which is called CN (Call Admission Control scheme using NE). Comparing with the Q-Learning based CAC scheme in the constant traffic load shows that CN can not only approximate the optimal solution very well but also optimize the CBR and CDR in a more flexibility way. Additionally the simulation results demonstrate that the proposed scheme is capable of keeping the handoff dropping rate below a pre-specified value while still maintaining an acceptable CBR in the presence of smoothly varying arrival rates of traffic, in which the state space is too large for practical deployment of the other learning scheme.

#index 1274782
#* Fast algorithm for connected row convex constraints
#@ Yuanlin Zhang
#t 2007
#c 11
#% 189747
#% 496121
#% 1250518
#% 1279250
#! Many interesting tractable problems are identified under the model of Constraint Satisfaction Problems. These problems are usually solved by forcing a certain level of local consistency. In this paper, for the class of connected row convex constraints, we propose a novel algorithm which is based on the ideas of variable elimination and efficient composition of row convex and connected constraints. Compared with the existing work including randomized algorithms, the new algorithm has better worst case time and space complexity.

#index 1274783
#* Conflict directed backjumping for Max-CSPs
#@ Roie Zivan;Amnon Meisels
#t 2007
#c 11
#% 224767
#% 267576
#% 348819
#% 535468
#% 644201
#% 789556
#% 1271955
#% 1279246
#! Max-CSPs are Constraint Optimization Problems that are commonly solved using a Branch and Bound algorithm. The B&B algorithm was enhanced by consistency maintenance procedures [Wallace and Freuder, 1993; Larrosa and Meseguer, 1996; Larrosa et al., 1999; Larrosa and Schiex, 2003; 2004]. All these algorithms traverse the search space in a chronological order and gain their efficiency from the quality of the consistency maintenance procedure. The present study introduces Conflict-directed Backjumping (CBJ) for Branch and Bound algorithms. The proposed algorithm maintains Conflict Sets which include only assignments whose replacement can lead to a better solution. The algorithm backtracks according to these sets. CBJ can be added to all classes of the Branch and Bound algorithm, in particular to versions of Branch & Bound that use advanced maintenance procedures of local consistency levels, NC, AC and FDAC [Larrosa and Schiex, 2003; 2004]. The experimental evaluation of B&B CBJ on random Max-CSPs shows that the performance of all algorithms is improved both in the number of assignments and in the time for completion.

#index 1274784
#* The mathematical morpho-logical view on reasoning about space
#@ Marco Aiello;Brammert Ottens
#t 2007
#c 11
#% 71879
#% 240288
#% 270714
#% 337494
#% 572057
#% 733595
#% 934170
#% 939431
#! Qualitative reasoning about mereotopological relations has been extensively investigated, while more recently geometrical and spatio-temporal reasoning are gaining increasing attention. We propose to consider mathematical morphology operators as the inspiration for a new language and inference mechanism to reason about space. Interestingly, the proposed morpho-logic captures not only traditional mereotopological relations, but also notions of relative size and morphology. The proposed representational framework is a hybrid arrow logic theory for which we define a resolution calculus which is, to the best of our knowledge, the first such calculus for arrow logics.

#index 1274785
#* An information-theoretic analysis of memory bounds in a distributed resource allocation mechanism
#@ Ricardo M. Araujo;Luis C. Lamb
#t 2007
#c 11
#% 252803
#% 578716
#% 739899
#% 785571
#% 840855
#% 1289481
#! Multiagent distributed resource allocation requires that agents act on limited, localized information with minimum communication overhead in order to optimize the distribution of available resources. When requirements and constraints are dynamic, learning agents may be needed to allow for adaptation. One way of accomplishing learning is to observe past outcomes, using such information to improve future decisions. When limits in agents' memory or observation capabilities are assumed, one must decide on how large should the observation window be. We investigate how this decision influences both agents' and system's performance in the context of a special class of distributed resource allocation problems, namely dispersion games. We show by numerical experiments over a specific dispersion game (the Minority Game) that in such scenario an agent's performance is non-monotonically correlated with her memory size when all other agents are kept unchanged. We then provide an information-theoretic explanation for the observed behaviors, showing that a downward causation effect takes place.

#index 1274786
#* A description logic of change
#@ Alessandro Artale;Carsten Lutz;David Toman
#t 2007
#c 11
#% 6246
#% 260043
#% 264856
#% 295566
#% 496125
#% 776454
#! We combine the modal logic S5 with the description logic (DL) ALCQI. The resulting multi-dimensional DL S5ALCQI supports reasoning about change by allowing to express that concepts and roles change over time. It cannot, however, discriminate between changes in the past and in the future. Our main technical result is that satisfiability of S5ALCQI concepts with respect to general TBoxes (including GCIs) is decidable and 2-EXPTIME-complete. In contrast, reasoning in temporal DLs that are able to discriminate between past and future is inherently undecidable. We argue that our logic is sufficient for reasoning about temporal conceptual models with time-stamping constraints.

#index 1274787
#* From generic knowledge to specific reasoning for medical image interpretation using graph based representations
#@ Jamal Atif;Céline Hudelot;Geoffroy Fouquier;Isabelle Bloch;Elsa Angelini
#t 2007
#c 11
#% 222206
#% 230495
#% 279098
#% 318785
#% 766116
#% 940474
#% 1347050
#% 1707617
#% 1740285
#! In several domains of spatial reasoning, such as medical image interpretation, spatial relations between structures play a crucial role since they are less prone to variability than intrinsic properties of structures. Moreover, they constitute an important part of available knowledge. We show in this paper how this knowledge can be appropriately represented by graphs and fuzzy models of spatial relations, which are integrated in a reasoning process to guide the recognition of individual structures in images. However pathological cases may deviate substantially from generic knowledge. We propose a method to adapt the knowledge representation to take into account the influence of the pathologies on the spatial organization of a set of structures, based on learning procedures. We also propose to adapt the reasoning process, using graph based propagation and updating.

#index 1274788
#* Completing description logic knowledge bases using formal concept analysis
#@ Franz Baader;Bernhard Ganter;Baris Sertkaya;Ulrike Sattler
#t 2007
#c 11
#% 384416
#% 466329
#% 665856
#% 1279264
#% 1379024
#% 1655436
#% 1667771
#% 1705149
#! We propose an approach for extending both the terminological and the assertional part of a Description Logic knowledge base by using information provided by the knowledge base and by a domain expert. The use of techniques from Formal Concept Analysis ensures that, on the one hand, the interaction with the expert is kept to a minimum, and, on the other hand, we can show that the extended knowledge base is complete in a certain, well-defined sense.

#index 1274789
#* Non-monotonic temporal logics for goal specification
#@ Chitta Baral;Jicheng Zhao
#t 2007
#c 11
#% 98066
#% 101955
#% 175389
#% 289333
#% 342119
#% 417597
#% 544738
#% 557446
#% 1250543
#% 1289217
#! One of the main ways to specify goals of agents is to use temporal logics. Most existing temporal logics are monotonic. However, in representing goals of agents, we often require that goals be changed non-monotonically. For example, the initial goal of the agent may be to be always in states where p is true. The agent may later realize that under certain conditions (exceptions) it is ok to be in states where p is not true. In this paper, we propose a simple extension of LTL, which we call N-LTL, that allows non-monotonic specification of goals. We study properties of N-LTL. We also consider a translation from N-LTL to logic programs and study the relationship between N-LTL and logic programs.

#index 1274790
#* Using the probabilistic logic programming language P-log for causal and counterfactual reasoning and non-naive conditioning
#@ Chitta Baral;Matt Hunsaker
#t 2007
#c 11
#% 3034
#% 89958
#% 90371
#% 144840
#% 147677
#% 165651
#% 216970
#% 228812
#% 233132
#% 674154
#% 729449
#% 796028
#% 850430
#% 1250167
#% 1289247
#% 1650280
#% 1673040
#! P-log is a probabilistic logic programming language, which combines both logic programming style knowledge representation and probabilistic reasoning. In earlier papers various advantages of P-log have been discussed. In this paper we further elaborate on the KR prowess of P-log by showing that: (i) it can be used for causal and counterfactual reasoning and (ii) it provides an elaboration tolerant way for non-naive conditioning.

#index 1274791
#* Context-driven predictions
#@ Marc G. Bellemare;Doina Precup
#t 2007
#c 11
#% 165062
#% 252183
#% 449561
#% 702594
#% 799825
#% 891060
#% 964204
#! Markov models have been a keystone in Artificial Intelligence for many decades. However, they remain unsatisfactory when the environment modelled is partially observable. There are pathological examples where no history of fixed length is sufficient for accurate prediction or decision making. On the other hand, working with a hidden state (like in Hidden Markov Models or Partially Observable Markov Decision Processes) has a high computational cost. In order to circumvent this problem, we suggest the use of a context-based model. Our approach replaces strict transition probabilities by influences on transitions. The method proposed provides a trade-off between a fully and partially observable model. We also discuss the capacity of our framework to model hierarchical knowledge and abstraction. Simple examples are given in order to show the advantages of the algorithm.

#index 1274792
#* Entailment semantics for rules with priorities
#@ David Billington
#t 2007
#c 11
#% 167542
#% 198464
#% 275032
#% 318597
#% 411814
#! We define a new general rule-based nonmonotonic framework which allows an external acyclic priority relation between rules to be interpreted in several ways. Several entailment semantics are defined via a constructive digraph, with one being given a declarative fixed-point characterisation as well. Each of these semantics satisfies Principle 1 of [Brewka and Eiter 1999]. The framework encompasses Default Logic [Reiter 1980], ground Answer Set Programming (ASP) [Baral 2003], and Defeasible Logic [Nute 1994]. Default Logic is provided with a new semantics which is ambiguity blocking, rather than the usual ambiguity propagating semantics. Also Reiter-extensions are given a new fixed-point characterisation; and Lukaszewicz's [1990] m-extensions are given a much simpler construction and fixed-point characterisation.

#index 1274793
#* Higher-order potentialities and their reducers: a philosophical foundation unifying dynamic modelling methods
#@ Tibor Bosse;Jan Treur
#t 2007
#c 11
#% 23011
#% 203666
#% 203668
#% 1722638
#! In the development of disciplines addressing dynamics, a major role was played by the assumption that processes can be modelled by introducing state properties, called potentialities, anticipating in which respect a next state will be different. A second assumption often made is that these state properties can be related to other state properties, called reducers. The current paper proposes a philosophical framework in terms of potentialities and their reducers to obtain a common philosophical foundation for methods in AI and Cognitive Science to model dynamics. This framework provides a unified philosophical foundation for numerical, symbolic, and hybrid approaches.

#index 1274794
#* Contextual default reasoning
#@ Gerhard Brewka;Floris Roelofsen;Luciano Serafini
#t 2007
#c 11
#% 28185
#% 103705
#% 160385
#% 245349
#% 334493
#% 400992
#% 757481
#% 1289440
#! In this paper we introduce a multi-context variant of Reiter's default logic. The logic provides a syntactical counterpart of Roelofsen and Serafini's information chain approach (IJCAI-05), yet has several advantages: it is closer to standard ways of representing nonmonotonic inference and a number of results from that area come "for free"; it is closer to implementation, in particular the restriction to logic programming gives us a computationally attractive framework; and it allows us to handle a problem with the information chain approach related to skeptical reasoning.

#index 1274795
#* EQL-lite: effective first-order query processing in description logics
#@ Diego Calvanese;Giuseppe De Giacomo;Domenico Lembo;Maurizio Lenzerini;Riccardo Rosati
#t 2007
#c 11
#% 400
#% 130784
#% 248026
#% 251786
#% 326595
#% 384978
#% 665856
#% 1269453
#% 1269632
#% 1289408
#% 1289425
#% 1374364
#! Querying Description Logic knowledge bases has received great attention in the last years. In such a problem, the need of coping with incomplete information is the distinguishing feature with respect to querying databases. Due to this feature, we have to deal with two conflicting needs: on the one hand, we would like to query the knowledge base with sophisticated mechanisms provided by full first-order logic (FOL); on the other hand, the presence of incomplete information makes query answering a much more difficult task than in databases. In this paper we advocate the use of a nonmonotonic epistemic FOL query language as a means for expressing sophisticated queries over Description Logic knowledge bases. We show that through a controlled use of the epistemic operator, resulting in the language called EQL-Lite, we are able to formulate full FOL queries over Description Logic knowledge bases, while keeping computational complexity of query answering under control. In particular, we show that EQL-Lite queries over DL-Lite knowledge bases are FOL reducible (i.e., compilable into SQL) and hence can be answered in LOGSPACE through standard database technologies.

#index 1274796
#* A lattice-based approach to computing warranted beliefs in skeptical argumentation frameworks
#@ Carlos Iván Chesñevar;Guillermo Ricardo Simari
#t 2007
#c 11
#% 198464
#% 337502
#% 752766
#% 873958
#% 908926
#% 1250162
#% 1656401
#! This paper introduces a novel approach to model warrant computation in a skeptical abstract argumentation framework. We show that such search space can be defined as a lattice, and illustrate how the so-called dialectical constraints can play a role for guiding the efficient computation of warranted arguments.

#index 1274797
#* A framework for decentralized qualitative model-based diagnosis
#@ Luca Console;Claudia Picardi;Daniele Theseider Dupré
#t 2007
#c 11
#% 1121
#% 105619
#% 132173
#% 257696
#% 643161
#% 819614
#% 850906
#! In this paper we propose a framework for decentralized model-based diagnosis of complex systems modeled with qualitative constraints and whose models are distributed among their subsystems. We assume that Local Diagnosers are associated with subsystems and are coordinated by a Supervisor which acts as the diagnoser for the complex system. The Local Diagnosers and the Supervisor communicate via a standard interface and share a common modeling ontology. In this diagnostic architecture, connections between subsystems only need to be known at runtime, thus allowing for dynamic (re)configuration of the system. The approach is designed to compute partial hypotheses in order to avoid unnecessary queries to Local Diagnosers.

#index 1274798
#* Exploiting independence in a decentralised and incremental approach of diagnosis
#@ Marie-Odile Cordier;Alban Grastien
#t 2007
#c 11
#% 794929
#% 819614
#% 926913
#! It is well-known that the size of the model is a bottleneck when using model-based approaches to diagnose complex systems. To answer this problem, decentralised/distributed approaches have been proposed. Another problem, which is far less considered, is the size of the diagnosis itself. However, it can be huge enough, especially in the case of on-line monitoring and when dealing with uncertain observations. We define two independence properties (state and transition-independence) and show their relevance to get a tractable representation of diagnosis in the context of both decentralised and incremental approaches. To illustrate the impact of these properties on the diagnosis size, experimental results on a toy example are given.

#index 1274799
#* A logical framework for modularity of ontologies
#@ Bernardo Cuenca Grau;Ian Horrocks;Yevgeny Kazakov;Ulrike Sattler
#t 2007
#c 11
#% 742769
#% 790852
#% 1289422
#! Modularity is a key requirement for collaborative ontology engineering and for distributed ontology reuse on the Web. Modern ontology languages, such as OWL, are logic-based, and thus a useful notion of modularity needs to take the semantics of ontologies and their implications into account. We propose a logic-based notion of modularity that allows the modeler to specify the external signature of their ontology, whose symbols are assumed to be defined in some other ontology. We define two restrictions on the usage of the external signature, a syntactic and a slightly less restrictive, semantic one, each of which is decidable and guarantees a certain kind of "black-box" behavior, which enables the controlled merging of ontologies. Analysis of real-world ontologies suggests that these restrictions are not too onerous.

#index 1274800
#* Embedding non-ground logic programs into autoepistemic logic for knowledge-base combination
#@ Jos De Bruijn;Thomas Eiter;Axel Polleres;Hans Tompits
#t 2007
#c 11
#% 1146
#% 144552
#% 147513
#% 147516
#% 147520
#% 147618
#% 326595
#% 344506
#% 398266
#% 754131
#% 1656396
#% 1693236
#! In the context of the Semantic Web, several approaches to the combination of ontologies, given in terms of theories of classical first-order logic, and rule bases have been proposed. They either cast rules into classical logic or limit the interaction between rules and ontologies. Autoepistemic logic (AEL) is an attractive formalismwhich allows to overcome these limitations, by serving as a uniform host language to embed ontologies and nonmonotonic logic programs into it. For the latter, so far only the propositional setting has been considered. In this paper, we present several embeddings of normal and disjunctive non-ground logic programs under the stable-model semantics into first-order AEL, and compare them in combination with classical theories, with respect to stable expansions and autoepistemic consequences. Our results reveal differences and correspondences of the embeddings and provide a useful guidance in the choice of a particular embedding for knowledge combination.

#index 1274801
#* Modeling when connections are the problem
#@ Johan De Kleer
#t 2007
#c 11
#% 1120
#% 21138
#% 125529
#% 132173
#% 979225
#! Most AI diagnostic reasoning approaches model components and but not their interconnections, and when they do model interconnections, they model the possibility that a connection can break, not that two connections may join (e.g., through fluid leakage or electrical short circuit). Two reasons for this limitation are (1) that modeling these interconnection failures could require an exponential number (in the number of interconnections) failure possibilities, and (2) that modeling interconnection failures requires modeling the system at a more precise level which requires far more complex models. A fundamental contribution of this paper is a more powerful approach to modeling connections which does not require special-case post-processing and is computationally tractable. We illustrate our approach in the context of digital systems.

#index 1274802
#* Tractable temporal reasoning
#@ Clare Dixon;Michael Fisher;Boris Konev
#t 2007
#c 11
#% 1729
#% 297770
#% 330048
#% 399031
#% 401404
#% 567514
#% 600496
#% 855347
#% 870777
#% 1344978
#! Temporal reasoning is widely used within both Computer Science and A.I. However, the underlying complexity of temporal proof in discrete temporal logics has led to the use of simplified formalisms and techniques, such as temporal interval algebras or model checking. In this paper we show that tractable sub-classes of propositional linear temporal logic can be developed, based on the use of XOR fragments of the logic. We not only show that such fragments can be decided, tractably, via clausal temporal resolution, but also show the benefits of combining multiple XOR fragments. For such combinations we establish completeness and complexity (of the resolution method), and also describe how such a temporal language might be used in application areas, for example the verification of multi-agent systems. This new approach to temporal reasoning provides a framework in which tractable temporal logics can be engineered by intelligently combining appropriate XOR fragments.

#index 1274803
#* Chronicle recognition improvement using temporal focusing and hierarchization
#@ Christophe Dousson;Pierre Le Maigat
#t 2007
#c 11
#% 107137
#% 618628
#% 1279396
#! This article falls under the problem of the symbolic monitoring of real-time complex systems or of video interpretation systems. Among the various techniques used for the on-line monitoring, we are interested here in the temporal scenario recognition. In order to reduce the complexity of the recognition and, consequently, to improve its performance, we explore two methods: the first one is the focus on particular events (in practice, uncommon ones) and the second one is the factorization of common temporal scenarios in order to do a hierarchical recognition. In this article, we present both concepts and merge them to propose a focused hierarchical recognition. This approach merges and generalizes the two main approaches in symbolic recognition of temporal scenarios: the Store Totally Recognized Scenarios (STRS) approach and the Store Partially Recognized Scenarios (SPRS) approach.

#index 1274804
#* Complexity results for checking equivalence of stratified logic programs
#@ Thomas Eiter;Michael Fink;Hans Tompits;Stefan Woltran
#t 2007
#c 11
#% 23898
#% 340738
#% 342389
#% 342829
#% 400986
#% 411814
#% 417651
#% 464530
#% 481128
#% 591778
#% 765952
#% 957649
#% 1269468
#% 1289419
#! Recent research in nonmonotonic logic programming under the answer-set semantics focuses on different notions of program equivalence. However, previous results do not address the important classes of stratified programs and its subclass of acyclic (i.e., recursion-free) programs, although they are recognized as important tools for knowledge representation and reasoning. In this paper, we consider such programs, possibly augmented with constraints. Our results show that in the propositional setting, where reasoning is well-known to be polynomial, deciding strong and uniform equivalence is as hard as for arbitrary normal logic programs (and thus coNP-complete), but is polynomial in some restricted cases. Nonground programs behave similarly. However, exponential lower bounds already hold for small programs (i.e., with constantly many rules). In particular, uniform equivalence is undecidable even for small Horn programs plus a single negative constraint.

#index 1274805
#* On reversing actions: algorithms and complexity
#@ Thomas Eiter;Esra Erdem;Wolfgang Faber
#t 2007
#c 11
#% 318489
#% 322612
#% 322911
#% 440778
#% 495996
#% 540593
#% 744224
#% 752496
#% 763743
#% 936786
#% 1272399
#% 1655814
#! Reversing actions is the following problem: After executing a sequence of actions, which sequence of actions brings the agent back to the state just before this execution (an action reversal). Notably, this problem is different from a vanilla planning problem since the state we have to get back to is in general unknown. It emerges, for example, if an agent needs to find out which action sequences are undoable, and which ones are committed choices. It has applications related to plan execution and monitoring in nondeterministic domains, such as recovering from a failed execution by partially undoing the plan, dynamically switching from one executed plan to another, or restarting plans. We formalize action reversal in a logic-based action framework and characterize its computational complexity. Since unsurprisingly, the problem is intractable in general, we present a knowledge compilation approach that constructs offline a reverse plan library for efficient (in some cases, linear time) on-line computation of action reversals. Our results for the generic framework can be easily applied for expressive action languages such as C+ or κ.

#index 1274806
#* Fault-model-based test generation for embedded software
#@ M. Esser;P. Struss
#t 2007
#c 11
#% 160260
#% 1274847
#! Testing embedded software systems on the control units of vehicles is a safety-relevant task, and developing the test suites for performing the tests on test benches is time-consuming. We present the foundations and results of a case study to automate the generation of tests for control software of vehicle control units based on a specification of requirements in terms of finite state machines. This case study builds upon our previous work on generation of tests for physical systems based on relational behavior models. In order to apply the respective algorithms, the finite state machine representation is transformed into a relational model. We present the transformation, the application of the test generation algorithm to a real example, and discuss the results and some specific challenges regarding software testing.

#index 1274807
#* Semantic precision and recall for ontology alignment evaluation
#@ Jérôme Euzenat
#t 2007
#c 11
#% 466501
#% 551850
#% 747995
#% 924747
#! In order to evaluate ontology matching algorithms it is necessary to confront them with test ontologies and to compare the results with some reference. The most prominent comparison criteria are precision and recall originating from information retrieval. Precision and recall are thought of as some degree of correction and completeness of results. However, when the objects to compare are semantically defined, like ontologies and alignments, it can happen that a fully correct alignment has low precision. This is due to the restricted set-theoretic foundation of these measures. Drawing on previous syntactic generalizations of precision and recall, semantically justified measures that satisfy maximal precision and maximal recall for correct and complete alignments is proposed. These new measures are compatible with classical precision and recall and can be computed.

#index 1274808
#* Operator component matrix model for IMP program diagnosis
#@ Zhao-Fu Fan;Yunfei Jiang
#t 2007
#c 11
#% 21137
#% 135428
#% 166296
#% 345432
#% 581903
#! This paper presents a new modeling approach for IMP programs with operator component matrix (OCM) model, which can be used in IMP program diagnosis. Using this model and model-based diagnosis method, some logic errors can be found in IMP programs. The model can also be extended to all kinds of imperative programs. The advantages of this diagnosis method lie in its simple and regular presentation, uniform diagnosed objects, usage of isomorphism assumptions in structure, and usage of assertions about the expected program. These advantages make diagnoses more accurate, and even help to correct the faults by mutation of operator components.

#index 1274809
#* On valued negation normal form formulas
#@ Hélène Fargier;Pierre Marquis
#t 2007
#c 11
#% 233849
#% 342378
#% 567872
#% 1223274
#% 1272349
#% 1275308
#% 1275309
#% 1289403
#% 1289570
#! Subsets of the Negation Normal Form formulas (NNFs) of propositional logic have received much attention in AI and proved as valuable representation languages for Boolean functions. In this paper, we present a new framework, called VNNF, for the representation of a much more general class of functions than just Boolean ones. This framework supports a larger family of queries and transformations than in the NNF case, including optimization ones. As such, it encompasses a number of existing settings, e.g. NNFs, semiring CSPs, mixed CSPs, SLDDs, ADD, AADDs. We show how the properties imposed on NNFs to define more "tractable" fragments (decomposability, determinism, decision, read-once) can be extended to VNNFs, giving rise to subsets for which a number of queries and transformations can be achieved in polynomial time.

#index 1274810
#* A logic program characterization of causal theories
#@ Paolo Ferraris
#t 2007
#c 11
#% 243712
#% 258787
#% 340738
#% 398246
#% 417649
#% 763743
#% 763744
#% 1250641
#% 1478800
#% 1656398
#! Nonmonotonic causal logic, invented by McCain and Turner, is a formalism well suited for representing knowledge about actions, and the definite fragment of that formalism has been implemented in the reasoning and planning system called CCalc. A 1997 theorem due to McCain shows howto translate definite causal theories into logic programming under the answer set semantics, and thus opens the possibility of using answer set programming for the implementation of such theories. In this paper we propose a generalization of McCain's theorem that extends it in two directions. First, it is applicable to arbitrary causal theories, not only definite. Second, it covers causal theories of a more general kind, which can describe non-Boolean fluents.

#index 1274811
#* A new perspective on stable models
#@ Paolo Ferraris;Joohyung Lee;Vladimir Lifschitz
#t 2007
#c 11
#% 877
#% 1146
#% 3035
#% 36550
#% 129971
#% 167541
#% 243712
#% 340738
#% 400992
#% 420607
#% 484342
#% 501041
#% 752744
#% 790727
#% 873959
#% 906658
#% 1274822
#% 1478800
#% 1656398
#! The definition of a stable model has provided a declarative semantics for Prolog programs with negation as failure and has led to the development of answer set programming. In this paper we propose a new definition of that concept, which covers many constructs used in answer set programming (including disjunctive rules, choice rules and conditional literals) and, unlike the original definition, refers neither to grounding nor to fixpoints. Rather, it is based on a syntactic transformation, which turns a logic program into a formula of second-order logic that is similar to the formula familiar from the definition of circumscription.

#index 1274812
#* Conflict-based diagnosis: adding uncertainty to model-based diagnosis
#@ Ildikó Flesch;Peter Lucas;Theo Van der Weide
#t 2007
#c 11
#% 1121
#% 21137
#% 44876
#% 95580
#% 132173
#% 216980
#% 263129
#% 351595
#% 741445
#! Consistency-based diagnosis concerns using a model of the structure and behaviour of a system in order to analyse whether or not the system is malfunctioning. A well-known limitation of consistency-based diagnosis is that it is unable to cope with uncertainty. Uncertainty reasoning is nowadays done using Bayesian networks. In this field, a conflict measure has been introduced to detect conflicts between a given probability distribution and associated data. In this paper, we use a probabilistic theory to represent logical diagnostic systems and show that in this theory we are able to determine consistent and inconsistent states as traditionally done in consistency-based diagnosis. Furthermore, we analyse how the conflict measure in this theory offers a way to favour particular diagnoses above others. This enables us to add uncertainty reasoning to consistency-based diagnosis in a seamless fashion.

#index 1274813
#* Conflict-driven answer set solving
#@ Martin Gebser;Benjamin Kaufmann;André Neumann;Torsten Schaub
#t 2007
#c 11
#% 53385
#% 103705
#% 336874
#% 400992
#% 411814
#% 644201
#% 655781
#% 772065
#% 865743
#% 880394
#% 891761
#% 918148
#% 1250521
#% 1289431
#% 1692897
#! We introduce a new approach to computing answer sets of logic programs, based on concepts from constraint processing (CSP) and satisfiability checking (SAT). The idea is to view inferences in answer set programming (ASP) as unit propagation on no-goods. This provides us with a uniform constraint-based framework for the different kinds of inferences in ASP. It also allows us to apply advanced techniques from the areas of CSP and SAT. We have implemented our approach in the new ASP solver clasp. Our experiments show that the approach is competitive with state-of-the-art ASP solvers.

#index 1274814
#* Ranking alternatives on the basis of generic constraints and examples: a possibilistic approach
#@ Romain Gérard;Souhila Kaci;Henri Prade
#t 2007
#c 11
#% 188062
#% 418171
#% 780340
#% 1250234
#% 1705575
#% 1788140
#! The paper presents and discusses a method for rank-ordering alternatives on the basis of constraints induced by generic principles (expressing for instance the relative importance of criteria), or by examples of orderings between particular alternatives, without resorting to the use of an aggregation operation for evaluating the alternatives. The approach, which remains qualitative, is based on the minimal specificity principle of possibility theory in order to complete the constraints. It is compared on an illustrative example to an aggregation-based approach using Choquet integral. The way constraints expressed in the Choquet integral setting translate into constraints in the proposed approach is discussed.

#index 1274815
#* Conjunctive query answering for the description logic SHIQ
#@ Birte Glimm;Ian Horrocks;Carsten Lutz;Uli Sattler
#t 2007
#c 11
#% 248026
#% 529498
#% 561419
#% 665856
#% 1250550
#% 1289425
#! Conjunctive queries play an important role as an expressive query language for Description Logics (DLs). Although modern DLs usually provide for transitive roles, it was an open problem whether conjunctive query answering over DL knowledge bases is decidable if transitive roles are admitted in the query. In this paper, we consider conjunctive queries over knowledge bases formulated in the popular DL SHIQ and allow transitive roles in both the query and the knowledge base. We show that query answering is decidable and establish the following complexity bounds: regarding combined complexity, we devise a deterministic algorithm for query answering that needs time single exponential in the size of the KB and double exponential in the size of the query. Regarding data complexity, we prove co-NP-completeness.

#index 1274816
#* A dual-pathway neural network model of control relinquishment in motor skill learning
#@ Ashish Gupta;David C. Noelle
#t 2007
#c 11
#% 272374
#% 390534
#% 892465
#! Cognitive psychologists have long recognized that the acquisition of a motor skill involves a transition from attention-demanding controlled processing to more fluent automatic processing. Neuroscientific studies suggest that controlled and automatic processing rely on two largely distinct neural pathways. The controlled pathway, which includes the prefrontal cortex, is seen as acquiring declarative representations of skills. In comparison, the automatic pathway is thought to develop procedural representations. Automaticity in motor skill learning involves a reduction in dependence on frontal systems and an increased reliance on the automatic pathway. In this paper, we propose a biologically plausible computational model of motor skill automaticity. This model offers a dual-pathway neurocomputational account of the translation of declarative knowledge into procedural knowledge during motor learning. In support of the model, we review some previously reported human experimental results involving the learning of a sequential key pressing task, and we demonstrate, through simulation, howthe model provides a parsimonious explanation for these results.

#index 1274817
#* Some effects of a reduced relational vocabulary on the Whodunit problem
#@ Daniel T. Halstead;Kenneth D. Forbus
#t 2007
#c 11
#% 136370
#% 232136
#% 359837
#% 459462
#% 1269481
#! A key issue in artificial intelligence lies in finding the amount of input detail needed to do successful learning. Too much detail causes overhead and makes learning prone to over-fitting. Too little detail and it may not be possible to learn anything at all. The issue is particularly relevant when the inputs are relational case descriptions, and a very expressive vocabulary may also lead to inconsistent representations. For example, in the Whodunit Problem, the task is to form hypotheses about the identity of the perpetrator of an event described using relational propositions. The training data consists of arbitrary relational descriptions of many other similar cases. In this paper, we examine the possibility of translating the case descriptions into an alternative vocabulary which has a reduced number of predicates and therefore produces more consistent case descriptions. We compare how the reduced vocabulary affects three different learning algorithms: exemplar-based analogy, prototype-based analogy, and association rule learning. We find that it has a positive effect on some algorithms and a negative effect on others, which gives us insight into all three algorithms and indicates when reduced vocabularies might be appropriate.

#index 1274818
#* Counting complexity of propositional abduction
#@ Miki Hermann;Reinhard Pichler
#t 2007
#c 11
#% 78634
#% 147677
#% 181220
#% 183738
#% 416007
#% 480594
#% 502365
#% 578665
#% 600496
#% 917695
#% 1289163
#% 1656421
#! Abduction is an important method of non-monotonic reasoning with many applications in AI and related topics. In this paper, we concentrate on propositional abduction, where the background knowledge is given by a propositional formula. Decision problems of great interest are the existence and the relevance problems. The complexity of these decision problems has been systematically studied while the counting complexity of propositional abduction has remained obscure. The goal of this work is to provide a comprehensive analysis of the counting complexity of propositional abduction in various classes of theories.

#index 1274819
#* Extracting chatbot knowledge from online discussion forums
#@ Jizhou Huang;Ming Zhou;Dan Yang
#t 2007
#c 11
#% 269217
#% 325050
#% 343142
#% 344447
#% 577224
#% 737237
#% 766456
#% 939368
#% 939776
#! This paper presents a novel approach for extracting high-quality 〈thread-title, reply〉 pairs as chat knowledge from online discussion forums so as to efficiently support the construction of a chatbot for a certain domain. Given a forum, the high-quality 〈thread-title, reply〉 pairs are extracted using a cascaded framework. First, the replies logically relevant to the thread title of the root message are extracted with an SVM classifier from all the replies, based on correlations such as structure and content. Then, the extracted 〈thread-title, reply〉 pairs are ranked with a ranking SVM based on their content qualities. Finally, the Top-N 〈thread-title, reply〉 pairs are selected as chatbot knowledge. Results from experiments conducted within a movie forum show the proposed approach is effective.

#index 1274820
#* Improving author coreference by resource-bounded information gathering from the web
#@ Pallika Kanani;Andrew McCallum;Chris Pal
#t 2007
#c 11
#% 218098
#% 460812
#% 464268
#% 466231
#% 754068
#% 809459
#% 855119
#% 1699589
#! Accurate entity resolution is sometimes impossible simply due to insufficient information. For example, in research paper author name resolution, even clever use of venue, title and coauthorship relations are often not enough to make a confident coreference decision. This paper presents several methods for increasing accuracy by gathering and integrating additional evidence from the web. We formulate the coreference problem as one of graph partitioning with discriminatively-trained edge weights, and then incorporate web information either as additional features or as additional nodes in the graph. Since the web is too large to incorporate all its data, we need an efficient procedure for selecting a subset of web queries and data. We formally describe the problem of resource bounded information gathering in each of these contexts, and show significant accuracy improvement with low cost.

#index 1274821
#* Combining topological and directional information for spatial reasoning
#@ Sanjiang Li
#t 2007
#c 11
#% 152555
#% 181229
#% 319244
#% 420709
#% 495793
#% 496279
#% 527331
#% 861763
#% 862119
#% 1693257
#! Current research on qualitative spatial representation and reasoning usually focuses on one single aspect of space. However, in real world applications, several aspects are often involved together. This paper extends the well-known RCC8 constraint language to deal with both topological and directional information, and then investigates the interaction between the two kinds of information. Given a topological (RCC8) constraint network and a directional constraint network, we ask when the joint network is satisfiable. We show that when the topological network is over one of the three maximal tractable subclasses of RCC8, the problem can be reduced into satisfiability problems in the RCC8 algebra and the rectangle algebra (RA). Therefore, reasoning techniques developed for RCC8 and RA can be used to solve the satisfiability problem of a joint network.

#index 1274822
#* From answer set logic programming to circumscription via logic of GK
#@ Fangzhen Lin;Yi Zhou
#t 2007
#c 11
#% 1146
#% 3035
#% 131560
#% 340738
#% 387592
#% 417649
#% 417651
#% 501041
#% 880394
#% 1274811
#% 1289433
#% 1656398
#! We first provide a mapping from Pearce's equilibrium logic and Ferraris's general logic programs to Lin and Shoham's logic of knowledge and justified assumptions, a nonmonotonic modal logic that has been shown to include as special cases both Reiter's default logic in the propositional case and Moore's autoepistemic logic. From this mapping, we obtain a mapping from general logic programs to circumscription, both in the propositional and first-order case. Furthermore, we show that this mapping can be used to check the strong equivalence between two propositional logic programs in classical logic.

#index 1274823
#* Incremental learning of perceptual categories for open-domain sketch recognition
#@ Andrew Lovett;Morteza Dehghani;Kenneth Forbus
#t 2007
#c 11
#% 65345
#% 1250195
#% 1269481
#% 1289573
#% 1709794
#! Most existing sketch understanding systems require a closed domain to achieve recognition. This paper describes an incremental learning technique for open-domain recognition. Our system builds generalizations for categories of objects based upon previous sketches of those objects and uses those generalizations to classify new sketches. We represent sketches qualitatively because we believe qualitative information provides a level of description that abstracts away details that distract from classification, such as exact dimensions. Bayesian reasoning is used in building representations to deal with the inherent uncertainty in perception. Qualitative representations are compared using SME, a computational model of analogy and similarity that is supported by psychological evidence, including studies of perceptual similarity. We use SEQL to produce generalizations based on the common structure found by SME in different sketches of the same object. We report on the results of testing the system on a corpus of sketches of everyday objects, drawn by ten different people.

#index 1274824
#* Conservative extensions in expressive description logics
#@ Carsten Lutz;Dirk Walther;Frank Wolter
#t 2007
#c 11
#% 505940
#! The notion of a conservative extension plays a central role in ontology design and integration: it can be used to formalize ontology refinements, safe mergings of two ontologies, and independent modules inside an ontology. Regarding reasoning support, the most basic task is to decide whether one ontology is a conservative extension of another. It has recently been proved that this problem is decidable and 2ExpTime-complete if ontologies are formulated in the basic description logic ALC. We consider more expressive description logics and begin to map out the boundary between logics for which conservativity is decidable and those for which it is not. We prove that conservative extensions are 2ExpTime-complete in ALCQI, but undecidable in ALCQIO. We also show that if conservative extensions are defined model-theoretically rather than in terms of the consequence relation, they are undecidable already in ALC.

#index 1274825
#* Towards a computational model of melody identification in polyphonic music
#@ Søren Tjagvad Madsen;Gerhard Widmer
#t 2007
#c 11
#% 261882
#% 364075
#% 375017
#% 849872
#% 877321
#% 882872
#% 911000
#! This paper presents first steps towards a simple, robust computational model of automatic melody identification. Based on results from music psychology that indicate a relationship between melodic complexity and a listener's attention, we postulate a relationship between musical complexity and the probability of a musical line to be perceived as the melody. We introduce a simple measure of melodic complexity, present an algorithm for predicting the most likely melody note at any point in a piece, and show experimentally that this simple approach works surprisingly well in rather complex music.

#index 1274826
#* Modelling well-structured argumentation lines
#@ Diego C. Martínez;Alejandro J. García;Guillermo R. Simari
#t 2007
#c 11
#% 116292
#% 224479
#% 290540
#% 459606
#% 752766
#% 1650564
#! Abstract argumentation systems are formalisms for defeasible reasoning where some components remain unspecified, the structure of arguments being the main abstraction. In the dialectical process carried out to identify accepted arguments in the system some controversial situations may appear. These relate to the reintroduction of arguments into the process which cause the onset of circularity. This must be avoided in order to prevent an infinite analysis. Some systems apply the sole restriction of not allowing the introduction of previously considered arguments in an argumentation line. However, repeating an argument is not the only possible cause for the risk mentioned, as subarguments must be taken into account. In this work, we introduce an extended argumentation framework and a definition for progressive defeat path. A credulous extension is also presented.

#index 1274827
#* Abstract interpretation of programs for model-based debugging
#@ Wolfgang Mayer;Markus Stumptner
#t 2007
#c 11
#% 21137
#% 139016
#% 301782
#% 301787
#% 345432
#% 349117
#% 772034
#% 782462
#% 807094
#% 1290120
#% 1395206
#! Developing model-based automatic debugging strategies has been an active research area for several years. We present a model-based debugging approach that is based on Abstract Interpretation, a technique borrowed from program analysis. The Abstract Interpretation mechanism is integrated with a classical model-based reasoning engine. We test the approach on sample programs and provide the first experimental comparison with earlier models used for debugging. The results show that the Abstract Interpretation based model provides more precise explanations than previous models or standard non-model based approaches.

#index 1274828
#* A faithful integration of description logics with logic programming
#@ Boris Motik;Riccardo Rosati
#t 2007
#c 11
#% 130784
#% 181400
#% 207489
#% 342829
#% 344506
#% 665856
#% 1289425
#% 1374388
#! Integrating description logics (DL) and logic programming (LP) would produce a very powerful and useful formalism. However, DLs and LP are based on quite different principles, so achieving a seamless integration is not trivial. In this paper, we introduce hybrid MKNF knowledge bases that faithfully integrate DLs with LP using the logic of Minimal Knowledge and Negation as Failure (MKNF) [Lifschitz, 1991]. We also give reasoning algorithms and tight data complexity bounds for several interesting fragments of our logic.

#index 1274829
#* Evaluating a decision-theoretic approach to Tailored example selection
#@ Kasia Muldner;Cristina Conati
#t 2007
#c 11
#% 156189
#% 206427
#% 1111430
#! We present the formal evaluation of a framework that helps students learn from analogical problem solving, i.e., from problem-solving activities that involve worked-out examples. The framework incorporates an innovative example-selection mechanism, which tailors the choice of example to a given student so as to trigger studying behaviors that are known to foster learning. This involves a two-phase process based on 1) a probabilistic user model and 2) a decision-theoretic mechanism that selects the example with the highest overall utility for learning and problem-solving success. We describe this example-selection process and present empirical findings from its evaluation.

#index 1274830
#* Expectation failure as a basis for agent-based model diagnosis and mixed initiative model adaptation during anomalous plan execution
#@ Alice Mulvehill;Brett Benyo;Michael Cox;Renu Bostwick
#t 2007
#c 11
#% 286419
#% 334633
#! Plans provide an explicit expectation of future observed behavior based upon the domain knowledge and a set of action models available to a planner. Incorrect or missing models lead to faulty plans usually characterized by catastrophic goal failure. Non-critical anomalies occur, however, when actual behavior during plan execution differs only slightly from expectations, and plans still achieve the given goal conjunct. Such anomalies provide the basis for model adjustments that represent small adaptations to the planner's background knowledge. In a multi-agent environment where 1000 or more individual plans can be executing at any one time, automation is required to support model anomaly detection, evaluation and revision. We provide an agent-based algorithm that generates hypotheses about the cause of plan anomalies. This algorithm leverages historical plan data and a hierarchy of models in a novel integration of hypothesis generation and verification. Because many hypotheses can be generated by the software agents, we provide a mechanism where only the most important hypotheses are presented to a user as suggestions for model repair.

#index 1274831
#* Consistency checking of basic cardinal constraints over connected regions
#@ Isabel Navarrete;Antonio Morales;Guido Sciavicco
#t 2007
#c 11
#% 126395
#% 588791
#% 644201
#% 710974
#% 741459
#% 784115
#% 806735
#% 939431
#! In this paper we study a recent formal model for qualitative spatial reasoning with cardinal direction relations. We give an O(n4) algorithm to check the consistency of a network of basic cardinal constraints with variables ranging over the set of connected regions homeomorphic to the closed unit disk (which includes a wide variety of irregular-shaped regions). To the best of our knowledge, this was an open problem. A previous algorithm for a domain that includes also disconnected regions works in O(n5), but, for the problem we consider here, such an algorithm cannot be used. Using the new algorithm we also show that the problem of deciding the consistency of a network of disjunctive cardinal constraints with variables ranging over the set of connected regions is NP-Complete. Our main contribution is based on results from the field of combinatorial geometry.

#index 1274832
#* Probabilistic go theories
#@ Austin Parker;Fusun Yaman;Dana Nau;V. S. Subrahmanian
#t 2007
#c 11
#% 181340
#% 939431
#% 1289449
#% 1391867
#% 1426821
#% 1774729
#! There are numerous cases where we need to reason about vehicles whose intentions and itineraries are not known in advance to us. For example, Coast Guard agents tracking boats don't always know where they are headed. Likewise, in drug enforcement applications, it is not always clear where drug-carrying airplanes (which do often show up on radar) are headed, and how legitimate planes with an approved flight manifest can avoid them. Likewise, traffic planners may want to understand how many vehicles will be on a given road at a given time. Past work on reasoning about vehicles (such as the "logic of motion" by Yaman et. al. [Yaman et al., 2004]) only deals with vehicles whose plans are known in advance and don't capture such situations. In this paper, we develop a formal probabilistic extension of their work and show that it captures both vehicles whose itineraries are known, and those whose itineraries are not known. We show how to correctly answer certain queries against a set of statements about such vehicles. A prototype implementation shows our system to work efficiently in practice.

#index 1274833
#* Surprise as shortcut for anticipation: clustering mental states in reasoning
#@ Michele Piunti;Cristiano Castelfranchi;Rino Falcone
#t 2007
#c 11
#% 773219
#% 890357
#% 1223331
#! To enhance effectiveness in real world applications, autonomous agents have to develop cognitive competencies and anticipatory capabilities. Here we point out their strong liaison with the functional roles of affective mental states as those of humanlike metaphor: not only the root elements for both surprise and anticipation are expectations, but also part of the effects of the former elicit efforts on the latter. By analyzing different kinds of expectations, we provide a general architecture enhancing practical reasoning with mental states, describing and empirically evaluating how mental and behavioral attitudes, emerging from mental states, can be applied for augmenting agent reactivity, opportunism and efficacy in terms of anticipation.

#index 1274834
#* Automated benchmark model generators for model-based diagnostic inference
#@ Gregory Provan;Jun Wang
#t 2007
#c 11
#% 21137
#% 107135
#% 439276
#% 1272329
#! The task of model-based diagnosis is NP-complete, but it is not known whether it is computationally difficult for the "average" real-world system. There has been no systematic study of the complexity of diagnosing real-world problems, and few good benchmarks exist to test this. Real-world-graphs, a mathematical framework that has been proposed as a model for complex systems, have empirically been shown to capture several topological properties of real-world systems. We describe the adequacy with which a real-world-graph can characterise the complexity of model-based diagnostic inference on real-world systems. We empirically compare the inference complexity of diagnosing models automatically generated using the real-world-graph framework with comparable models from well-known ISCAS circuit benchmarks. We identify parameters necessary for the real-world-graph framework to generate benchmark diagnosis circuit models with realistic properties.

#index 1274835
#* Automated heart wall motion abnormality detection from ultrasound images using Bayesian networks
#@ Maleeha Qazi;Glenn Fung;Sriram Krishnan;Romer Rosales;Harald Steck;R. Bharat Rao;Don Poldermans;Dhanalakshmi Chandrasekaran
#t 2007
#c 11
#% 388024
#% 458174
#% 784534
#% 812523
#% 1562509
#! Coronary Heart Disease can be diagnosed by measuring and scoring regional motion of the heart wall in ultrasound images of the left ventricle (LV) of the heart. We describe a completely automated and robust technique that detects diseased hearts based on detection and automatic tracking of the endocardium and epicardium of the LV. The local wall regions and the entire heart are then classified as normal or abnormal based on the regional and global LV wall motion. In order to leverage structural information about the heart we applied Bayesian Networks to this problem, and learned the relations among the wall regions off of the data using a structure learning algorithm. We checked the validity of the obtained structure using anatomical knowledge of the heart and medical rules as described by doctors. The resultant Bayesian Network classifier depends only on a small subset of numerical features extracted from dual-contours tracked through time and selected using a filter-based approach. Our numerical results confirm that our system is robust and accurate on echocardiograms collected in routine clinical practice at one hospital; our system is built to be used in real-time.

#index 1274836
#* Qualitative spatial and temporal reasoning: efficient algorithms for everyone
#@ Jochen Renz
#t 2007
#c 11
#% 181229
#% 319244
#% 496279
#% 1272384
#! In the past years a lot of research effort has been put into finding tractable subsets of spatial and temporal calculi. It has been shown empirically that large tractable subsets of these calculi not only provide efficient algorithms for reasoning problems that can be expressed with relations contained in the tractable subsets, but also surprisingly efficient solutions to the general, NP-hard reasoning problems of the full calculi. An important step in this direction was the refinement algorithm which provides a heuristic for proving tractability of given subsets of relations. In this paper we extend the refinement algorithm and present a procedure which identifies large tractable subsets of spatial and temporal calculi automatically without any manual intervention and without the need for additional NP-hardness proofs. While we can only guarantee tractability of the resulting sets, our experiments show that for RCC8 and the Interval Algebra, our procedure automatically identifies all maximal tractable subsets. Using our procedure, other researchers and practitioners can automatically develop efficient reasoning algorithms for their spatial or temporal calculi without any theoretical knowledge about how to formally analyse these calculi.

#index 1274837
#* Diagnosability testing with satisfiability algorithms
#@ Jussi Rintanen;Alban Grastien
#t 2007
#c 11
#% 121397
#% 204396
#% 342378
#% 491583
#% 937600
#% 1274838
#% 1279265
#% 1476298
#! We show how testing whether a system is diagnosable can be reduced to the satisfiability problem and how satisfiability algorithms yield a very efficient approach to testing diagnosability. Diagnosability is the question whether it is always possible to know whether a given system has exhibited a failure behavior. This is a basic question that underlies diagnosis, and it is also closely related to more general questions about the possibility to know given facts about system behavior. The work combines the twin plant construct of Jiang et al., which is the basis of diagnosability testing of systems with an enumerative representation, and SAT-based techniques to AI planning which form a very promising approach to finding paths in very large transition graphs.

#index 1274838
#* Diagnosers and diagnosability of succinct transition systems
#@ Jussi Rintanen
#t 2007
#c 11
#% 101922
#% 167629
#% 420152
#% 515291
#% 539106
#% 1274837
#% 1718872
#! Reasoning about the knowledge of an agent is an important problem in many areas of AI. For example in diagnosis a basic question about a system is whether it is possible to diagnose it, that is, whether it is always possible to know whether a faulty behavior has occurred. In this paper we investigate the complexity of this diagnosability problem and the size of automata that perform diagnosis. There are algorithms for testing diagnosability in polynomial time in the number of states in the system. For succinct system representations, which may be exponentially smaller than the state space of the system, the diagnosability problem is consequently in EXPTIME. We show that this upper bound is not tight and that the decision problem is in fact PSPACE-complete. On-line diagnosis can be carried out by diagnosers which are automata that recognize faulty behavior. We show that diagnosers in the worst case have a size that is exponential in the number of states, both for explicit and succinct system representations. This is a consequence of the diagnoser having to maintain beliefs about the state of the system.

#index 1274839
#* Is the turing test good enough?: the fallacy of resource-unbounded intelligence
#@ Virginia Savova;Leonid Peshkin
#t 2007
#c 11
#! This goal of this paper is to defend the plausibility of the argument that passing the Turing test is a sufficient condition for the presence of intelligence. To this effect, we put forth new objections to two famous counter-arguments: Searle's "Chinese Room" and Block's "Aunt Bertha." We take Searle's argument to consist of two points: 1) intelligence is not merely an ability to manipulate formal symbols; it is also the ability of relating those symbols to a multi-sensory real-world experience; and 2) intelligence presupposes an internal capacity for generalization. On the first point, while we concede that multi-sensory real-world experience is not captured by the test, we show that intuitions about the relevance of this experience to intelligence are not clear-cut. Therefore, it is not obvious that the Turing test should be dismissed on this basis alone. On the second point, we strongly disagree with the notion that the test cannot distinguish a machine with internal capacity for generalization from a machine which has no such capacity. This view is best captured by Ned Block, who argues that a sufficiently large look-up table is capable of passing any Turing test of finite length. We claim that, contrary to Block's assumption, it is impossible to construct such a table, and show that it is possible to ensure that a machine relying solely on such table will fail an appropriately constructed Turing test

#index 1274840
#* OSS: a semantic similarity function based on hierarchical ontologies
#@ Vincent Schickel-Zuber;Boi Faltings
#t 2007
#c 11
#% 115462
#% 465914
#% 577373
#% 734590
#% 805849
#% 1275285
#% 1739997
#! Various approaches have been proposed to quantify the similarity between concepts in an ontology. We present a novel approach that allows similarities to be asymmetric while still using only information contained in the structure of the ontology. We show through experiments on the WordNet and GeneOntology that the new approach achieves better accuracy than existing techniques.

#index 1274841
#* Description logics with approximate definitions precise modeling of vague concepts
#@ Stefan Schlobach;Michel Klein;Linda Peelen
#t 2007
#c 11
#% 46839
#% 229401
#% 561740
#% 752488
#% 1271958
#% 1271965
#% 1275331
#! We extend traditional Description Logics (DL) with a simple mechanism to handle approximate concept definitions in a qualitative way. Often, for example in medical applications, concepts are not definable in a crisp way but can fairly exhaustively be constrained through a particular sub- and a particular super-concept. We introduce such lower and upper approximations based on rough-set semantics, and show that reasoning in these languages can be reduced to standard DL satisfiability. This allows us to apply Rough Description Logics in a study of medical trials about sepsis patients, which is a typical application for precise modeling of vague knowledge. The study shows that Rough DL-based reasoning can be done in a realistic use case and that modeling vague knowledge helps to answer important questions in the design of clinical trials.

#index 1274842
#* A size-based qualitative approach to the representation of spatial granularity
#@ Hedda R. Schmidtke;Woontack Woo
#t 2007
#c 11
#% 418215
#% 438456
#% 571808
#% 649802
#% 1115196
#% 1275336
#% 1379035
#% 1665554
#% 1704354
#! A local spatial context is an area currently under consideration in a spatial reasoning process. The boundary between this area and the surrounding space together with the spatial granularity of the representation separates what is spatially relevant from what is irrelevant at a given time. The approach discussed in this article differs from other approaches to spatial granularity as it focusses not on a partitioning of the spatial domain, but on the notions of grain-size and the limited extent of a spatial context as primary factors of spatial granularity. Starting from a mereotopological characterization of these concepts, the notions of relevant and irrelevant extension in a context are defined. The approach is qualitative in the sense that quantitative, metric concepts are not required. The axiomatic characterization is thoroughly evaluated: it is compared to other mereotopological characterizations of spatial granularity; soundness is proven with an example model; and applicability for Knowledge Representation is illustrated with definitions for common sense conceptualizations of sameness, and adjacency of locations.

#index 1274843
#* Qualitative temporal reasoning about vague events
#@ Steven Schockaert;Martine De Cock;Etienne E. Kerre
#t 2007
#c 11
#% 82720
#% 181229
#% 231751
#% 307179
#% 319244
#% 331899
#% 618615
#% 657751
#% 733125
#% 736897
#% 776449
#% 807756
#% 879716
#% 1271958
#% 1290144
#% 1733345
#% 1740259
#! The temporal boundaries of many real-world events are inherently vague. In this paper, we discuss the problem of qualitative temporal reasoning about such vague events. We show that several interesting reasoning tasks, such as checking satisfiability, checking entailment, and calculating the best truth value bound, can be reduced to reasoning tasks in a well-known point algebra with disjunctions. Furthermore, we identify a maximal tractable subset of qualitative relations to support efficient reasoning.

#index 1274844
#* Scalable diagnosability checking of event-driven systems
#@ Anika Schumann;Yannick Pencolé
#t 2007
#c 11
#% 819614
#% 850907
#% 1279265
#! Diagnosability of systems is an essential property that determines how accurate any diagnostic reasoning can be on a system given any sequence of observations. Generally, in the literature of dynamic event-driven systems, diagnosability analysis is performed by algorithms that consider a system as a whole and their response is either a positive answer or a counter example. In this paper, we present an original framework for diagnosability checking. The diagnosability problem is solved in a distributed way in order to take into account the distributed nature of realistic problems. As opposed to all other approaches, our algorithm also provides an exhaustive and synthetic view of the reasons why the system is not diagnosable. Finally, the presented algorithm is scalable in practice: it provides an approximate and useful solution if the computational resources are not sufficient.

#index 1274845
#* Hierarchical diagnosis of multiple faults
#@ Sajjad Siddiqi;Jinbo Huang
#t 2007
#c 11
#% 3873
#% 32214
#% 342378
#% 439224
#% 577836
#% 770597
#% 776981
#% 1250637
#% 1269406
#! Due to large search spaces, diagnosis of combinational circuits is often practical for finding only single and double faults. In principle, system models can be compiled into a tractable representation (such as DNNF) on which faults of arbitrary cardinality can be found efficiently. For large circuits, however, compilation can become a bottleneck due to the large number of variables necessary to model the health of individual gates. We propose a novel method that greatly reduces this number, allowing the compilation, as well as the diagnosis, to scale to larger circuits. The basic idea is to identify regions of a circuit, called cones, that are dominated by single gates, and model the health of each cone with a single health variable. When a cone is found to be possibly faulty, we diagnose it by again identifying the cones inside it, and so on, until we reach a base case. We show that results combined from these hierarchical sessions are sound and complete with respect to minimum-cardinality diagnoses. We implement this method on top of the diagnoser developed by Huang and Darwiche in 2005, and present evidence that it significantly improves the efficiency and scalability of diagnosis on the ISCAS-85 circuits.

#index 1274846
#* Detection of cognitive states from fMRI data using machine learning techniques
#@ Vishwajeet Singh;K. P. Miyapuram;Raju S. Bapi
#t 2007
#c 11
#% 311027
#% 376266
#% 768668
#! Over the past decade functional Magnetic Resonance Imaging (fMRI) has emerged as a powerful technique to locate activity of human brain while engaged in a particular task or cognitive state. We consider the inverse problem of detecting the cognitive state of a human subject based on the fMRI data. We have explored classification techniques such as Gaussian Naive Bayes, k-Nearest Neighbour and Support Vector Machines. In order to reduce the very high dimensional fMRI data, we have used three feature selection strategies. Discriminating features and activity based features were used to select features for the problem of identifying the instantaneous cognitive state given a single fMRI scan and correlation based features were used when fMRI data from a single time interval was given. A case study of visuo-motor sequence learning is presented. The set of cognitive states we are interested in detecting are whether the subject has learnt a sequence, and if the subject is paying attention only towards the position or towards both the color and position of the visual stimuli. We have successfully used correlation based features to detect position-color related cognitive states with 80% accuracy and the cognitive states related to learning with 62.5% accuracy.

#index 1274847
#* Model-based optimization of testing through reduction of stimuli
#@ P. Struss
#t 2007
#c 11
#% 125540
#% 160260
#% 1274806
#! The paper presents the theoretical foundations and an algorithm to reduce the efforts of testing physical systems. A test is formally described as a set of stimuli (inputs to the system) to shift the system into a particular situation or state, and a set of varia-bles whose observation or measurement refutes hypotheses about the behavior mode the system is operating in. Tests (either generated automatically or by humans) may contain redundancy in the sense that some of its stimuli and/or observables maybe irrelevant for achieving the result of the test. Identifying and dropping them contributes to redu-cing the cost of set-up actions and measurements. We define different kinds of irrelevant stimuli, discuss their practical importance, and present criteria and algorithms for computing reduced tests.

#index 1274848
#* A general framework for reasoning about inconsistency
#@ V. S. Subrahmanian;Leila Amgoud
#t 2007
#c 11
#% 90371
#% 198464
#! Numerous logics have been developed for reasoning about inconsistency which differ in (i) the logic to which they apply, and (ii) the criteria used to draw inferences. In this paper, we propose a general framework for reasoning about inconsistency in a wide variety of logics including ones for which inconsistency resolution methods have not yet been studied (e.g. various temporal and epistemic logics). We start with Tarski and Scott's axiomatization of logics, but drop their monotonicity requirements that we believe are too strong for AI. For such a logic L, we define the concept of an option. Options are sets of formulas in L that are closed and consistent according to the notion of consequence and consistency in L. We show that by defining an appropriate preference relation on options, we can capture several existing works such as Brewka's subtheories. We also provide algorithms to compute most preferred options.

#index 1274849
#* Appearance based recognition methodology for recognising fingerspelling alphabets
#@ M. G. Suraj;D. S. Guru
#t 2007
#c 11
#% 245502
#% 420065
#% 632427
#% 646688
#% 727684
#% 794110
#% 940186
#% 1022958
#% 1377618
#% 1784728
#! In this paper, a study on the suitability of an appearance based model, specifically PCA based model, for the purpose of recognising fingerspelling (sign language) alphabets is made. Its recognition performance on a large and varied real time dataset is analysed. In order to enhance the performance of a PCA based model, we suggest to incorporate a sort of pre-processing operation both during training and recognition. An exhaustive experiment conducted on a large number of fingerspelling alphabet images taken from 20 different individuals in real environment has revealed that the suggested pre-processing has a drastic impact in improving the performance of a conventional PCA based model.

#index 1274850
#* Resource constraints on computation and communication in the brain
#@ Sashank Varma
#t 2007
#c 11
#% 157175
#% 306426
#% 768668
#% 879715
#% 1269507
#% 1786805
#% 1786999
#% 1845558
#! This paper contributes to the emerging literature at the border between AI and cognitive neuroscience, analyzing the resource constraints that shape brain function. The brain is conceptualized as a set of areas that collaborate to perform complex cognitive tasks. Both (1) computation within individual areas and (2) communication between collaborating areas are viewed as resource-consuming activities. The efficient deployment of limited resources is formalized as a Linear Programming problem which the brain is hypothesized to solve on a moment-by-moment basis. A model of language processing is analyzed within this framework and found to exhibit resource utilization profiles consistent with those observed in functional neuroimaging studies of humans.

#index 1274851
#* An experience on reputation models interoperability based on a functional ontology
#@ Laurent Vercouter;Sara J. Casare;Jaime S. Sichman;Anarosa A. F. Brandão
#t 2007
#c 11
#% 334325
#% 409387
#% 636340
#% 657509
#% 823907
#% 823908
#% 1705137
#! Interaction between heterogeneous agents can raise some problems since agents may not use the same models and concepts. Therefore, the use of some mechanisms to achieve interoperability between models allows agents to interact. In this paper we consider the case of reputation models by describing an experience of using several existing technologies to allow agents to interoperate when they use reputation notions/values during interactions. For this purpose, we have implemented agents on the ART testbed and we make them use a functional ontology of reputation which was developed to allow the interoperability among reputation models.

#index 1274852
#* A labeling approach to the computation of credulous acceptance in argumentation
#@ Bart Verheij
#t 2007
#c 11
#% 198464
#% 428343
#% 561726
#% 733126
#% 735151
#% 873958
#! In recent years, the combinatorics of argumentation with arguments that can attack each other has been studied extensively. Especially, attack graphs (put in the focus of attention by Dung's seminal work 1995) have proven to be a productive tool of analysis. In this paper a new style of algorithm is presented that computes the minimal admissible sets containing or attacking the argument. It is a breadth-first algorithm using labelings. The algorithm is applied to the computation of the preferred and stable extensions of a given attack graph.

#index 1274853
#* A convergent solution to tensor subspace learning
#@ Huan Wang;Shuicheng Yan;Thomas Huang;Xiaoou Tang
#t 2007
#c 11
#% 80995
#% 235342
#% 812370
#% 846431
#% 913838
#% 1279292
#! Recently, substantial efforts have been devoted to the subspace learning techniques based on tensor representation, such as 2DLDA [Ye et al., 2004], DATER [Yan et al., 2005] and Tensor Subspace Analysis (TSA) [He et al., 2005]. In this context, a vital yet unsolved problem is that the computational convergency of these iterative algorithms is not guaranteed. In this work, we present a novel solution procedure for general tensor-based subspace learning, followed by a detailed convergency proof of the solution projection matrices and the objective function value. Extensive experiments on real-world databases verify the high convergence speed of the proposed procedure, as well as its superiority in classification capability over traditional solution procedures.

#index 1274854
#* All common subsequences
#@ Hui Wang
#t 2007
#c 11
#% 289101
#% 312054
#% 477479
#% 481609
#% 617211
#% 729931
#% 769896
#% 841783
#% 1289355
#! Time series data abounds in real world problems. Measuring the similarity of time series is a key to solving these problems. One state of the art measure is the longest common subsequence. This measure advocates using the length of the longest common subsequence as an indication of similarity between sequences, but ignores information contained in the second, third..., longest subsequences. In order to capture the common information in sequences maximally we propose a novel measure of sequence similarity - the number of all common subsequences. We show that this measure satisfies the common properties of similarity functions. Calculating this measure is not trivial as a brute force approach is exponential in time. We present a novel dynamic programming algorithm to calculate this number in polynomial time. We also suggest a different way of extending a class of such measures to multidimensional, real-valued time series, in the spirit of probabilistic metric spaces. We conducted an experimental study on the new similarity measure and the extension method for classification. It was found that both the new similarity and the extension method are consistently competitive.

#index 1274855
#* Representations for action selection learning from real-time observation of task experts
#@ Mark A. Wood;Joanna J. Bryson
#t 2007
#c 11
#% 132678
#% 136350
#% 360691
#% 361100
#% 711814
#% 1042718
#% 1781827
#! The association of perception and action is key to learning by observation in general, and to program-level task imitation in particular. The question is how to structure this information such that learning is tractable for resource-bounded agents. By introducing a combination of symbolic representation with Bayesian reasoning, we demonstrate both theoretical and empirical improvements to a general-purpose imitation system originally based on a model of infant social learning. We also show how prior task knowledge and selective attention can be rigorously incorporated via loss matrices and Automatic Relevance Determination respectively.

#index 1274856
#* Epistemic reasoning in logic programs
#@ Yan Zhang
#t 2007
#c 11
#% 103704
#% 338753
#% 772065
#% 865743
#! Although epistemic logic programming has an enhanced capacity to handle complex incomplete information reasoning and represent agents' epistemic behaviours, it embeds a significantly higher computational complexity than non-disjunctive and disjunctive answer set programming. In this paper, we investigate some important properties of epistemic logic programs. In particular, we show that Lee and Lifschitz's result on loop formulas for disjunctive logic programs can be extended to a special class of epistemic logic programs. We also study the polysize model property for epistemic logic programs. Based on these discoveries, we identify two non-trivial classes of epistemic logic programs whose consistency checking complexity is reduced from PSPACE-complete to NP-complete and Σ2P -complete respectively. We observe that many important applications on epistemic representation fall into these two classes of epistemic logic programs.

#index 1274857
#* Keep the decision tree and estimate the class probabilities using its decision boundary
#@ Isabelle Alvarez;Stephan Bernard;Guillaume Deffuant
#t 2007
#c 11
#% 136350
#% 290482
#% 458229
#% 464280
#% 580510
#% 1378224
#! This paper proposes a new method to estimate the class membership probability of the cases classified by a Decision Tree. This method provides smooth class probabilities estimate, without any modification of the tree, when the data are numerical. It applies a posteriori and doesn't use additional training cases. It relies on the distance to the decision boundary induced by the decision tree. The distance is computed on the training sample. It is then used as an input for a very simple one-dimension kernel-based density estimator, which provides an estimate of the class membership probability. This geometric method gives good results even with pruned trees, so the intelligibility of the tree is fully preserved.

#index 1274858
#* Updates for nonlinear discriminants
#@ Edin Andelic;Martin Schafföner;Marcel Katz;Sven E. Krüger;Andreas Wendemuth
#t 2007
#c 11
#% 91771
#% 132676
#% 187651
#% 292664
#% 430739
#% 450264
#% 466597
#% 722918
#% 725787
#% 1051498
#% 1861197
#! A novel training algorithm for nonlinear discriminants for classification and regression in Reproducing Kernel Hilbert Spaces (RKHSs) is presented. It is shown how the overdetermined linear least squares-problem in the corresponding RKHS may be solved within a greedy forward selection scheme by updating the pseudoinverse in an order-recursive way. The described construction of the pseudoinverse gives rise to an update of the orthogonal decomposition of the reduced Gram matrix in linear time. Regularization in the spirit of Ridge regression may then easily be applied in the orthogonal space. Various experiments for both classification and regression are performed to show the competitiveness of the proposed method.

#index 1274859
#* A fully connectionist model generator for covered first-order logic programs
#@ Sebastian Bader;Pascal Hitzler;Steffen Hölldobler;Andreas Witzel
#t 2007
#c 11
#% 877
#% 50262
#% 52018
#% 53385
#% 409507
#% 418100
#! We present a fully connectionist system for the learning of first-order logic programs and the generation of corresponding models: Given a program and a set of training examples, we embed the associated semantic operator into a feed-forward network and train the network using the examples. This results in the learning of first-order knowledge while damaged or noisy data is handled gracefully.

#index 1274860
#* General game learning using knowledge transfer
#@ Bikramjit Banerjee;Peter Stone
#t 2007
#c 11
#% 147065
#% 169359
#% 384911
#% 823852
#% 875951
#! We present a reinforcement learning game player that can interact with a General Game Playing system and transfer knowledge learned in one game to expedite learning in many other games. We use the technique of value-function transfer where general features are extracted from the state space of a previous game and matched with the completely different state space of a new game. To capture the underlying similarity of vastly disparate state spaces arising from different games, we use a game-tree lookahead structure for features. We show that such feature-based value function transfer learns superior policies faster than a reinforcement learning agent that does not use knowledge transfer. Furthermore, knowledge transfer using lookahead features can capture opponent-specific value-functions, i.e. can exploit an opponent's weaknesses to learn faster than a reinforcement learner that uses lookahead with minimax (pessimistic) search against the same opponent.

#index 1274861
#* Learning by analogy: a classification rule for binary and nominal data
#@ Sabri Bayoudh;Laurent Miclet;Arnaud Delhay
#t 2007
#c 11
#% 729437
#% 757810
#% 926881
#% 1289532
#! This paper deals with learning to classify by using an approximation of the analogical proportion between four objects. These objects are described by binary and nominal attributes. Firstly, the paper recalls what is an analogical proportion between four objects, then it introduces a measure called "analogical dissimilarity", reflecting how close four objects are from being in an analogical proportion. Secondly, it presents an analogical instance-based learning method and describes a fast algorithm. Thirdly, a technique to assign a set of weights to the attributes of the objects is given: a weight is chosen according to the type of the analogical proportion involved. The weights are obtained from the learning sample. Then, some results of the method are presented. They compare favorably to standard classification techniques on six benchmarks. Finally, the relevance and complexity of the method are discussed.

#index 1274862
#* Interactive clustering of text collections according to a user-specified criterion
#@ Ron Bekkerman;Hema Raghavan;James Allan;Koji Eguchi
#t 2007
#c 11
#% 46809
#% 769881
#% 815915
#% 840840
#% 879626
#% 939346
#% 1250186
#% 1261565
#% 1289476
#% 1289485
#! Document clustering is traditionally tackled from the perspective of grouping documents that are topically similar. However, many other criteria for clustering documents can be considered: for example, documents' genre or the author's mood. We propose an interactive scheme for clustering document collections, based on any criterion of the user's preference. The user holds an active position in the clustering process: first, she chooses the types of features suitable to the underlying task, leading to a task-specific document representation. She can then provide examples of features-- if such examples are emerging, e.g., when clustering by the author's sentiment, words like 'perfect', 'mediocre', 'awful' are intuitively good features. The algorithm proceeds iteratively, and the user can fix errors made by the clustering system at the end of each iteration. Such an interactive clustering method demonstrates excellent results on clustering by sentiment, substantially outperforming an SVM trained on a large amount of labeled data. Even if features are not provided because they are not intuitively obvious to the user--e.g., what would be good features for clustering by genre using part-of-speech trigrams?--our multi-modal clustering method performs significantly better than k-means and Latent Dirichlet Allocation (LDA).

#index 1274863
#* Heuristic selection of actions in multiagent reinforcement learning
#@ Reinaldo A. C. Bianchi;Carlos H. C. Ribeiro;Anna H. R. Costa
#t 2007
#c 11
#% 174161
#% 379184
#% 449561
#% 464283
#% 646956
#% 734918
#% 1272286
#% 1289261
#% 1289288
#! This work presents a new algorithm, called Heuristically Accelerated Minimax-Q (HAMMQ), that allows the use of heuristics to speed up the well-known Multiagent Reinforcement Learning algorithm Minimax-Q. A heuristic function H that influences the choice of the actions characterises the HAMMQ algorithm. This function is associated with a preference policy that indicates that a certain action must be taken instead of another. A set of empirical evaluations were conducted for the proposed algorithm in a simplified simulator for the robot soccer domain, and experimental results show that even very simple heuristics enhances significantly the performance of the multiagent reinforcement learning algorithm.

#index 1274864
#* Unsupervised discretization using kernel density estimation
#@ Marenglen Biba;Floriana Esposito;Stefano Ferilli;Nicola Di Mauro;Teresa M. A. Basile
#t 2007
#c 11
#% 91780
#! Discretization, defined as a set of cuts over domains of attributes, represents an important pre-processing task for numeric data analysis. Some Machine Learning algorithms require a discrete feature space but in real-world applications continuous attributes must be handled. To deal with this problem many supervised discretization methods have been proposed but little has been done to synthesize unsupervised discretization methods to be used in domains where no class information is available. Furthermore, existing methods such as (equal-width or equal-frequency) binning, are not well-principled, raising therefore the need for more sophisticated methods for the unsupervised discretization of continuous features. This paper presents a novel unsupervised discretization method that uses non-parametric density estimators to automatically adapt sub-interval dimensions to the data. The proposed algorithm searches for the next two sub-intervals to produce, evaluating the best cut-point on the basis of the density induced in the sub-intervals by the current cut and the density given by a kernel density estimator for each sub-interval. It uses cross-validated log-likelihood to select the maximal number of intervals. The new proposed method is compared to equal-width and equal-frequency discretization methods through experiments on well known benchmarking data.

#index 1274865
#* Case-based multilabel ranking
#@ Klaus Brinker;Eyke Hüllermeier
#t 2007
#c 11
#% 311034
#% 330769
#% 581822
#% 790593
#% 801673
#% 833617
#% 1223287
#% 1665172
#! We present a case-based approach to multilabel ranking, a recent extension of the well-known problem of multilabel classification. Roughly speaking, a multilabel ranking refines a multilabel classification in the sense that, while the latter only splits a predefined label set into relevant and irrelevant labels, the former furthermore puts the labels within both parts of this bipartition in a total order. We introduce a conceptually novel framework, essentially viewing multilabel ranking as a special case of aggregating rankings which are supplemented with an additional virtual label and in which ties are permitted. Even though this framework is amenable to a variety of aggregation procedures, we focus on a particular technique which is computationally efficient and prove that it computes optimal aggregations with respect to the (generalized) Spearman rank correlation as an underlying loss (utility) function. Moreover, we propose an elegant generalization of this loss function and empirically show that it increases accuracy for the subtask of multilabel classification.

#index 1274866
#* Locality sensitive discriminant analysis
#@ Deng Cai;Xiaofei He;Kun Zhou;Jiawei Han;Hujun Bao
#t 2007
#c 11
#% 235342
#% 305004
#% 443605
#% 729437
#% 812578
#% 812580
#% 1022958
#! Linear Discriminant Analysis (LDA) is a popular data-analytic tool for studying the class relationship between data points. A major disadvantage of LDA is that it fails to discover the local geometrical structure of the data manifold. In this paper, we introduce a novel linear algorithm for discriminant analysis, called Locality Sensitive Discriminant Analysis (LSDA). When there is no sufficient training samples, local structure is generally more important than global structure for discriminant analysis. By discovering the local manifold structure, LSDA finds a projection which maximizes the margin between data points from different classes at each local area. Specifically, the data points are mapped into a subspace in which the nearby points with the same label are close to each other while the nearby points with different labels are far apart. Experiments carried out on several standard face databases show a clear improvement over the results of LDA-based recognition.

#index 1274867
#* Exploiting known taxonomies in learning overlapping concepts
#@ Lijuan Cai;Thomas Hofmann
#t 2007
#c 11
#% 269218
#% 309141
#% 311034
#% 425033
#% 466078
#% 479817
#% 722816
#% 770763
#% 770796
#% 783478
#% 840928
#% 875967
#! Many real-world classification problems involve large numbers of overlapping categories that are arranged in a hierarchy or taxonomy. We propose to incorporate prior knowledge on category taxonomy directly into the learning architecture. We present two concrete multi-label classification methods, a generalized version of Perceptron and a hierarchical multi-label SVM learning. Our method works with arbitrary, not necessarily singly connected taxonomies, and can be applied more generally in settings where categories are characterized by attributes and relations that are not necessarily induced by a taxonomy. Experimental results on WIPO-alpha collection show that our hierarchical methods bring significant performance improvement.

#index 1274868
#* Learning and transferring action schemas
#@ Paul R. Cohen;Yu-Han Chang;Clayton T. Morrison
#t 2007
#c 11
#% 188076
#% 1272377
#! Jean is a model of early cognitive development based loosely on Piaget's theory of sensorimotor and pre-operational thought. Like an infant, Jean repeatedly executes schemas, gradually transferring them to new situations and extending them as necessary to accommodate new experiences. We model this process of accommodation with the Experimental State Splitting (ESS) algorithm. ESS learns elementary action schemas, which comprise controllers and maps of the expected dynamics of executing controllers in different conditions. ESS also learns compositions of action schemas called gists. We present tests of the ESS algorithm in three transfer learning experiments, in which Jean transfers learned gists to new situations in a real time strategy military simulator.

#index 1274869
#* Online learning and exploiting relational models in reinforcement learning
#@ Tom Croonenborghs;Jan Ramon;Hendrik Blockeel;Maurice Bruynooghe
#t 2007
#c 11
#% 108755
#% 160859
#% 183499
#% 384911
#% 425074
#% 465917
#% 729982
#% 770823
#% 1269503
#% 1272095
#% 1699623
#! In recent years, there has been a growing interest in using rich representations such as relational languages for reinforcement learning. However, while expressive languages have many advantages in terms of generalization and reasoning, extending existing approaches to such a relational setting is a non-trivial problem. In this paper, we present a first step towards the online learning and exploitation of relational models. We propose a representation for the transition and reward function that can be learned online and present a method that exploits thesemodels by augmenting Relational Reinforcement Learning algorithms with planning techniques. The benefits and robustness of our approach are evaluated experimentally.

#index 1274870
#* Permanents, transport polytopes and positive definite kernels on histograms
#@ Marco Cuturi
#t 2007
#c 11
#% 325683
#% 393059
#% 402289
#% 766230
#% 794860
#% 829033
#% 852092
#% 906248
#! For two integral histograms r = (r1,..., rd) and c = (c1,..., cd) of equal sum N, the Monge-Kantorovich distance dMK(r, c) between r and c parameterized by a d × d distance matrix T is the minimum of all costs 〈 F,T 〉 taken over matrices F of the transportation polytope U(r, c). Recent results suggest that this distance is not negative definite, and hence, through Schoenberg's well-known result, exp(-1/tdMK) may not be a positive definite kernel for all t 0. Rather than using directly dMK to define a similarity between r and c, we propose in this paper to investigate kernels on r and c based on the whole transportation polytope U(r, c). We prove that when r and c have binary counts, which is equivalent to stating that r and c represent clouds of points of equal size, the permanent of an adequate Gram matrix induced by the distance matrix T is a positive definite kernel under favorable conditions on T. We also show that the volume of the polytope U(r, c), that is the number of integral transportation plans, is a positive definite quantity in r and c through the Robinson-Schensted-Knuth correspondence between transportation matrices and Young Tableaux. We follow by proposing a family of positive definite kernels related to the generating function of the polytope through recent results obtained separately by A. Barvinok on the one hand, and C. Berg and A.J. Duran on the other hand. We finally present preliminary results led on a subset of the MNIST database to compare clouds of points through the permanent kernel.

#index 1274871
#* Utile distinctions for relational reinforcement learning
#@ William Dabney;Amy McGovern
#t 2007
#c 11
#% 246747
#% 252183
#% 333786
#% 384911
#% 420090
#% 464449
#% 702594
#% 748024
#% 1650364
#! We introduce an approach to autonomously creating state space abstractions for an online reinforcement learning agent using a relational representation. Our approach uses a tree-based function approximation derived from McCallum's [1995] UTree algorithm. We have extended this approach to use a relational representation where relational observations are represented by attributed graphs [McGovern et al., 2003]. We address the challenges introduced by a relational representation by using stochastic sampling to manage the search space [Srinivasan, 1999] and temporal sampling to manage autocorrelation [Jensen and Neville, 2002]. Relational UTree incorporates Iterative Tree Induction [Utgoff et al., 1997] to allow it to adapt to changing environments. We empirically demonstrate that Relational UTree performs better than similar relational learning methods [Finney et al., 2002; Driessens et al., 2001] in a blocks world domain. We also demonstrate that Relational UTree can learn to play a sub-task of the game of Go called Tsume-Go [Ramon et al., 2001].

#index 1274872
#* Boosting kernel discriminant analysis and its application to tissue classification of gene expression data
#@ Guang Dai;Dit-Yan Yeung
#t 2007
#c 11
#% 235377
#% 266426
#% 316783
#% 784525
#% 791368
#% 833529
#% 836827
#% 857439
#% 940372
#% 1378300
#% 1861142
#% 1861431
#! Kernel discriminant analysis (KDA) is one of the most effective nonlinear techniques for dimensionality reduction and feature extraction. It can be applied to a wide range of applications involving high-dimensional data, including images, gene expressions, and text data. This paper develops a new algorithm to further improve the overall performance of KDA by effectively integrating the boosting and KDA techniques. The proposed method, called boosting kernel discriminant analysis (BKDA), possesses several appealing properties. First, like all kernel methods, it handles nonlinearity in a disciplined manner that is also computationally attractive; second, by introducing pairwise class discriminant information into the discriminant criterion and simultaneously employing boosting to robustly adjust the information, it further improves the classification accuracy; third, by calculating the significant discriminant information in the null space of the within-class scatter operator, it also effectively deals with the small sample size problem which is widely encountered in real-world applications for KDA; fourth, by taking advantage of the boosting and KDA techniques, it constitutes a strong ensemble-based KDA framework. Experimental results on gene expression data demonstrate the promising performance of the proposed methodology.

#index 1274873
#* Case base mining for adaptation knowledge acquisition
#@ M. d'Aquin;F. Badra;S. Lafrogne;J. Lieber;A. Napoli;L. Szathmary
#t 2007
#c 11
#% 341700
#% 405727
#% 490793
#% 566457
#% 1289287
#% 1300591
#% 1499567
#! In case-based reasoning, the adaptation of a source case in order to solve the target problem is at the same time crucial and difficult to implement. The reason for this difficulty is that, in general, adaptation strongly depends on domain-dependent knowledge. This fact motivates research on adaptation knowledge acquisition (AKA). This paper presents an approach to AKA based on the principles and techniques of knowledge discovery from databases and data-mining. It is implemented in CABAMAKA, a system that explores the variations within the case base to elicit adaptation knowledge. This system has been successfully tested in an application of case-based reasoning to decision support in the domain of breast cancer treatment.

#index 1274874
#* Learning classifiers when the training data is not IID
#@ Murat Dundar;Balaji Krishnapuram;Jinbo Bi;R. Bharat Rao
#t 2007
#c 11
#% 803771
#! Most methods for classifier design assume that the training samples are drawn independently and identically from an unknown data generating distribution, although this assumption is violated in several real life problems. Relaxing this i.i.d. assumption, we consider algorithms from the statistics literature for the more realistic situation where batches or sub-groups of training samples may have internal correlations, although the samples from different batches may be considered to be uncorrelated. Next, we propose simpler (more efficient) variants that scale well to large datasets; theoretical results from the literature are provided to support their validity. Experimental results from real-life computer aided diagnosis (CAD) problems indicate that relaxing the i.i.d. assumption leads to statistically significant improvements in the accuracy of the learned classifier. Surprisingly, the simpler algorithm proposed here is experimentally found to be even more accurate than the original version.

#index 1274875
#* Kernel carpentry for online regression using randomly varying coefficient model
#@ Narayanan U. Edakunni;Stefan Schaal;Sethu Vijayakumar
#t 2007
#c 11
#% 273319
#% 277516
#% 418819
#% 855330
#% 857421
#! We present a Bayesian formulation of locally weighted learning (LWL) using the novel concept of a randomly varying coefficient model. Based on this, we propose a mechanism for multivariate non-linear regression using spatially localised linear models that learns completely independent of each other, uses only local information and adapts the local model complexity in a data driven fashion. We derive online updates for the model parameters based on variational Bayesian EM. The evaluation of the proposed algorithm against other state-of-the-art methods reveal the excellent, robust generalization performance beside surprisingly efficient time and space complexity properties. This paper, for the first time, brings together the computational efficiency and the adaptability of 'non-competitive' locally weighted learning schemes and the modelling guarantees of the Bayesian formulation.

#index 1274876
#* Occam's razor just got sharper
#@ Saher Esmeir;Shaul Markovitch
#t 2007
#c 11
#% 26125
#% 61792
#% 136350
#% 420102
#% 677237
#% 770795
#% 1272290
#! Occam's razor is the principle that, given two hypotheses consistent with the observed data, the simpler one should be preferred. Many machine learning algorithms follow this principle and search for a small hypothesis within the version space. The principle has been the subject of a heated debate with theoretical and empirical arguments both for and against it. Earlier empirical studies lacked sufficient coverage to resolve the debate. In this work we provide convincing empirical evidence for Occam's razor in the context of decision tree induction. By applying a variety of sophisticated sampling techniques, our methodology samples the version space for many real-world domains and tests the correlation between the size of a tree and its accuracy. We show that indeed a smaller tree is likely to be more accurate, and that this correlation is statistically significant across most domains.

#index 1274877
#* Sequence labelling in structured domains with hierarchical recurrent neural networks
#@ Santiago Fernández;Alex Graves;Jürgen Schmidhuber
#t 2007
#c 11
#% 464434
#% 836836
#% 856275
#% 875991
#% 1272315
#% 1579211
#% 1762951
#! Modelling data in structured domains requires establishing the relations among patterns at multiple scales. When these patterns arise from sequential data, the multiscale structure also contains a dynamic component that must be modelled, particularly, as is often the case, if the data is unsegmented. Probabilistic graphical models are the predominant framework for labelling unsegmented sequential data in structured domains. Their use requires a certain degree of a priori knowledge about the relations among patterns and about the patterns themselves. This paper presents a hierarchical system, based on the connectionist temporal classification algorithm, for labelling unsegmented sequential data at multiple scales with recurrent neural networks only. Experiments on the recognition of sequences of spoken digits show that the system outperforms hidden Markov models, while making fewer assumptions about the domain.

#index 1274878
#* Predicting and preventing coordination problems in cooperative Q-learning systems
#@ Nancy Fulda;Dan Ventura
#t 2007
#c 11
#% 164502
#% 178898
#% 256565
#% 266286
#% 418626
#% 418731
#% 464283
#% 465913
#% 466730
#% 659906
#% 734918
#% 1272372
#! We present a conceptual framework for creating Q-learning-based algorithms that converge to optimal equilibria in cooperative multiagent settings. This framework includes a set of conditions that are sufficient to guarantee optimal system performance. We demonstrate the efficacy of the framework by using it to analyze several well-known multi-agent learning algorithms and conclude by employing it as a design tool to construct a simple, novel multi-agent learning algorithm.

#index 1274879
#* Feature selection and kernel design via linear programming
#@ Glenn Fung;Romer Rosales;R. Bharat Rao
#t 2007
#c 11
#% 26125
#% 224113
#% 272510
#% 309208
#% 464291
#% 492792
#% 577213
#% 763697
#% 770767
#% 770831
#% 881492
#% 1502433
#! The definition of object (e.g., data point) similarity is critical to the performance of many machine learning algorithms, both in terms of accuracy and computational efficiency. However, it is often the case that a similarity function is unknown or chosen by hand. This paper introduces a formulation that given relative similarity comparisons among triples of points of the form object i is more like object j than object k, it constructs a kernel function that preserves the given relationships. Our approach is based on learning a kernel that is a combination of functions taken from a set of base functions (these could be kernels as well). The formulation is based on defining an optimization problem that can be solved using linear programming instead of a semidefinite program usually required for kernel learning. We show how to construct a convex problem from the given set of similarity comparisons and then arrive to a linear programming formulation by employing a subset of the positive definite matrices. We extend this formulation to consider representation/evaluation efficiency based on formulating a novel form of feature selection using kernels (that is not much more expensive to solve). Using publicly available data, we experimentally demonstrate how the formulation introduced in this paper shows excellent performance in practice by comparing it with a baseline method and a related state-of-the art approach, in addition of being much more efficient computationally.

#index 1274880
#* Learning restart strategies
#@ Matteo Gagliolo;Jürgen Schmidhuber
#t 2007
#c 11
#% 155827
#% 159239
#% 167643
#% 283230
#% 329487
#% 420713
#% 466598
#% 593734
#% 738969
#% 779652
#% 945273
#% 1250528
#% 1269575
#% 1273727
#% 1664970
#! Restart strategies are commonly used for minimizing the computational cost of randomized algorithms, but require prior knowledge of the run-time distribution in order to be effective. We propose a portfolio of two strategies, one fixed, with a provable bound on performance, the other based on a model of run-time distribution, updated as the two strategies are run on a sequence of problems. Computational resources are allocated probabilistically to the two strategies, based on their performances, using a well-known K-armed bandit problem solver. We present bounds on the performance of the resulting technique, and experiments with a satisfiability problem solver, showing rapid convergence to a near-optimal execution time.

#index 1274881
#* Incremental construction of structured hidden Markov models
#@ Ugo Galassi;Attilio Giordana;Lorenza Saitta
#t 2007
#c 11
#% 235941
#% 292235
#% 423630
#% 978636
#! This paper presents an algorithm for inferring a Structured Hidden Markov Model (S-HMM) from a set of sequences. The S-HMMs are a subclass of the Hierarchical Hidden Markov Models and are well suited to problems of process/user profiling. The learning algorithm is unsupervised, and follows a mixed bottom-up/top-down strategy, in which elementary facts in the sequences (motifs) are progressively grouped, thus building up the abstraction hierarchy of a S-HMM, layer after layer. The algorithm is validated on a suite of artificial datasets, where the challenge for the learning algorithm is to reconstruct the model that generated the data. Then, an application to a real problem of molecular biology is briefly described.

#index 1274882
#* On mining closed sets in multi-relational data
#@ Gemma C. Garriga;Roni Khardon;Luc De Raedt
#t 2007
#c 11
#% 33376
#% 226437
#% 232136
#% 300120
#% 384416
#% 398844
#% 495944
#% 729938
#% 765529
#% 772329
#% 1718448
#! We investigate the problem of mining closed sets in multi-relational databases. Previous work introduced different semantics and associated algorithms for mining closed sets in multirelational databases. However, insight into the implications of semantic choices and the relationships among them was still lacking. Our investigation shows that the semantic choices are important because they imply different properties, which in turn affect the range of algorithms that can mine for such sets. Of particular interest is the question whether the seminal LCM algorithm by Uno et al. can be upgraded towards multi-relational problems. LCM is attractive since its run time is linear in the number of closed sets and it does not need to store outputs in order to avoid duplicates. We provide a positive answer to this question for some of the semantic choices, and report on experiments that evaluate the scalability and applicability of the upgraded algorithm on benchmark problems.

#index 1274883
#* Improving embeddings by flexible exploitation of side information
#@ Ali Ghodsi;Dana Wilkinson;Finnegan Southey
#t 2007
#c 11
#% 593047
#% 757953
#% 1502529
#! Dimensionality reduction is a much-studied task in machine learning in which high-dimensional data is mapped, possibly via a non-linear transformation, onto a low-dimensional manifold. The resulting embeddings, however, may fail to capture features of interest. One solution is to learn a distance metric which prefers embeddings that capture the salient features. We propose a novel approach to learning a metric from side information to guide the embedding process. Our approach admits the use of two kinds of side information. The first kind is class-equivalence information, where some limited number of pairwise "same/different class" statements are known. The second form of side information is a limited set of distances between pairs of points in the target metric space. We demonstrate the effectiveness of the method by producing embeddings that capture features of interest.

#index 1274884
#* State similarity based approach for improving performance in RL
#@ Sertan Girgin;Faruk Polat;Reda Alhajj
#t 2007
#c 11
#% 124692
#% 286423
#% 384911
#% 458686
#% 464442
#% 477283
#% 477304
#% 655325
#% 677517
#% 715736
#% 720089
#% 770777
#% 840937
#% 1223288
#% 1271827
#% 1272286
#! This paper employs state similarity to improve reinforcement learning performance. This is achieved by first identifying states with similar sub-policies. Then, a tree is constructed to be used for locating common action sequences of states as derived from possible optimal policies. Such sequences are utilized for defining a similarity function between states, which is essential for reflecting updates on the action-value function of a state onto all similar states. As a result, the experience acquired during learning can be applied to a broader context. Effectiveness of the method is demonstrated empirically.

#index 1274885
#* Optimistic active learning using mutual information
#@ Yuhong Guo;Russ Greiner
#t 2007
#c 11
#% 156186
#% 169717
#% 236729
#% 464268
#% 464466
#% 466419
#% 466576
#% 466887
#% 565531
#% 763705
#% 770771
#% 1272282
#% 1387560
#% 1775158
#! An "active learning system" will sequentially decide which unlabeled instance to label, with the goal of efficiently gathering the information necessary to produce a good classifier. Some such systems greedily select the next instance based only on properties of that instance and the few currently labeled points -- e.g., selecting the one closest to the current classification boundary. Unfortunately, these approaches ignore the valuable information contained in the other unlabeled instances, which can help identify a good classifier much faster. For the previous approaches that do exploit this unlabeled data, this information is mostly used in a conservative way. One common property of the approaches in the literature is that the active learner sticks to one single query selection criterion in the whole process. We propose a system, MM+M, that selects the query instance that is able to provide the maximum conditional mutual information about the labels of the unlabeled instances, given the labeled data, in an optimistic way. This approach implicitly exploits the discriminative partition information contained in the unlabeled data. Instead of using one selection criterion, MM+M also employs a simple on-line method that changes its selection rule when it encounters an "unexpected label". Our empirical results demonstrate that this new approach works effectively.

#index 1274886
#* Continuous time associative bandit problems
#@ András György;Levente Kocsis;Ivett Szabó;Csaba Szepesvári
#t 2007
#c 11
#% 304312
#% 363744
#% 425053
#! In this paper we consider an extension of the multiarmed bandit problem. In this generalized setting, the decision maker receives some side information, performs an action chosen from a finite set and then receives a reward. Unlike in the standard bandit settings, performing an action takes a random period of time. The environment is assumed to be stationary, stochastic and memoryless. The goal is to maximize the average reward received in one unit time, that is, to maximize the average rate of return. We consider the on-line learning problem where the decisionmaker initially does not know anything about the environment but must learn about it by trial and error. We propose an "upper confidence bound"-style algorithm that exploits the structure of the problem. We show that the regret of this algorithm relative to the optimal algorithm that has perfect knowledge about the problem grows at the optimal logarithmic rate in the number of decisions and scales polynomially with the parameters of the problem.

#index 1274887
#* Maximum margin coresets for active and noise tolerant learning
#@ Sariel Har-Peled;Dan Roth;Dav Zimak
#t 2007
#c 11
#% 169757
#% 190581
#% 235377
#% 425046
#% 450951
#% 451056
#% 453564
#% 466576
#% 722797
#% 722814
#% 770763
#% 803575
#% 837668
#% 881477
#! We study the problem of learning largemargin half-spaces in various settings using coresets and show that coresets are a widely applicable tool for large margin learning. A large margin coreset is a subset of the input data sufficient for approximating the true maximum margin solution. In this work, we provide a direct algorithm and analysis for constructing large margin coresets. We show various applications including a novel coreset based analysis of large margin active learning and a polynomial time (in the number of input data and the amount of noise) algorithm for agnostic learning in the presence of outlier noise. We also highlight a simple extension to multi-class classification problems and structured output learning.

#index 1274888
#* Real boosting a la carte with an application to boosting oblique decision trees
#@ Claudia Henry;Richard Nock;Frank Nielsen
#t 2007
#c 11
#% 63820
#% 73372
#% 136350
#% 235377
#% 272403
#% 278833
#% 302391
#% 449559
#% 1223291
#% 1272347
#% 1777251
#! In the past ten years, boosting has become a major field of machine learning and classification. This paper brings contributions to its theory and algorithms. We first unify a well-known top-down decision tree induction algorithm due to [Kearns and Mansour, 1999], and discrete AdaBoost [Freund and Schapire, 1997], as two versions of a same higher-level boosting algorithm. It may be used as the basic building block to devise simple provable boosting algorithms for complex classifiers. We provide one example: the first boosting algorithm for Oblique Decision Trees, an algorithm which turns out to be simpler, faster and significantly more accurate than previous approaches.

#index 1274889
#* Self-adjusting ring modules (SARMs) for flexible gait pattern generation
#@ Manfred Hild;Frank Pasemann
#t 2007
#c 11
#% 61477
#% 185916
#% 251831
#% 846476
#% 1391674
#% 1861229
#! Using the principle of homeostasis, we derive a learning rule for a specific recurrent neural network structure, the so-called Self-Adjusting Ring Module (SARM). Several of these Ring Modules can be plugged together to drive segmented artificial organisms, for example centipede-like robots. Controlling robots of variable morphologies by SARMs has major advantages over using Central Pattern Generators (CPGs). SARMs are able to immediately reconfigure themselves after reassembly of the robot's morphology. In addition, there is no need to decide on a singular place for the robot's control processor, since SARMs represent inherently distributed control structures.

#index 1274890
#* Analogical learning in a turn-based strategy game
#@ Thomas R. Hinrichs;Kenneth D. Forbus
#t 2007
#c 11
#% 65345
#% 137994
#% 198055
#% 362441
#% 449561
#% 495942
#% 895697
#% 1250572
#% 1272286
#% 1705993
#% 1837386
#! A key problem in playing strategy games is learning how to allocate resources effectively. This can be a difficult task for machine learning when the connections between actions and goal outputs are indirect and complex. We show how a combination of structural analogy, experimentation, and qualitative modeling can be used to improve performance in optimizing food production in a strategy game. Experimentation bootstraps a case library and drives variation, while analogical reasoning supports retrieval and transfer. A qualitative model serves as a partial domain theory to support adaptation and credit assignment. Together, these techniques can enable a system to learn the effects of its actions, the ranges of quantities, and to apply training in one city to other, structurally different cities. We describe experiments demonstrating this transfer of learning.

#index 1274891
#* Constructing new and better evaluation measures for machine learning
#@ Jin Huang;Charles X. Ling
#t 2007
#c 11
#% 136350
#% 349550
#% 464606
#% 466086
#% 580510
#% 769882
#% 770788
#% 770822
#% 1279288
#% 1378224
#! Evaluation measures play an important role in machine learning because they are used not only to compare different learning algorithms, but also often as goals to optimize in constructing learning models. Both formal and empirical work has been published in comparing evaluation measures. In this paper, we propose a general approach to construct new measures based on the existing ones, and we prove that the new measures are consistent with, and finer than, the existing ones. We also show that the new measure is more correlated to RMS (Root Mean Square error) with artificial datasets. Finally, we demonstrate experimentally that the greedy-search based algorithm (such as artificial neural networks) trained with the new and finer measure usually can achieve better prediction performance. This provides a general approach to improve the predictive performance of existing learning algorithms based on greedy search.

#index 1274892
#* Improving anytime point-based value iteration using principled point selections
#@ Michael R. James;Michael E. Samples;Dmitri A. Dolgov
#t 2007
#c 11
#% 788097
#% 1272075
#% 1279358
#% 1289695
#% 1699604
#! Planning in partially-observable dynamical systems (such as POMDPs and PSRs) is a computationally challenging task. Popular approximation techniques that have proven successful are point-based planning methods including pointbased value iteration (PBVI), which works by approximating the solution at a finite set of points. These point-based methods typically are anytime algorithms, whereby an initial solution is obtained using a small set of points, and the solution may be incrementally improved by including additional points. We introduce a family of anytime PBVI algorithms that use the information present in the current solution for identifying and adding new points that have the potential to best improve the next solution. We motivate and present two different methods for choosing points and evaluate their performance empirically, demonstrating that high-quality solutions can be obtained with significantly fewer points than previous PBVI approaches.

#index 1274893
#* A three-stage neural model for attribute based classification and indexing of fly ashes
#@ M. A. Jayaram;M. C. Nataraja;C. N. Ravikumar
#t 2007
#c 11
#% 97428
#% 107046
#% 234978
#! The primary objective of this work is to categorize the available fly ashes in different parts of the world into distinct groups based on its compositional attributes. Kohonen's selforganizing feature map and radial basis function networks are utilized for the classification of fly ashes in terms of its chemical parameters. The basic procedure of the methodology consists of three stages: (1) apply self - organizing neural net and delineate distinct groups of fly ashes and identify the group sensitive attributes; (2) find mean values of sensitive attributes of the elicited groups and augment them as start-up prototypes for k-means algorithm and find the refined centroids of these groups; (3) incorporate the centroids in a two layer radial basis function network and refine the delineation of the groups and develop an indexing equation using the weights of the stabilized network. Further, to demonstrate the utility of this classification scheme, the so formed groups were correlated with their performance in High Volume Fly Ash Concrete System [HVFAC]. The categorization was found to be excellent and compares well with Canadian Standard Association's [CSA A 3000] classification scheme.

#index 1274894
#* Selective supervision: guiding supervised learning with decision-theoretic active learning
#@ Ashish Kapoor;Eric Horvitz;Sumit Basu
#t 2007
#c 11
#% 132697
#% 236729
#% 464466
#% 466887
#% 565531
#% 715096
#% 917072
#% 945221
#% 1650300
#! An inescapable bottleneck with learning from large data sets is the high cost of labeling training data. Unsupervised learning methods have promised to lower the cost of tagging by leveraging notions of similarity among data points to assign tags. However, unsupervised and semi-supervised learning techniques often provide poor results due to errors in estimation. We look at methods that guide the allocation of human effort for labeling data so as to get the greatest boosts in discriminatory power with increasing amounts of work. We focus on the application of value of information to Gaussian Process classifiers and explore the effectiveness of the method on the task of classifying voice messages.

#index 1274895
#* Exploiting sensorimotor coordination for learning to recognize objects
#@ Yohannes Kassahun;Mark Edgington;Jose De Gea;Frank Kirchner
#t 2007
#c 11
#% 293772
#% 361100
#% 760805
#% 1784247
#! In this paper we present a system which learns to recognize objects through interaction by exploiting the principle of sensorimotor coordination. The system uses a learning architecture which is composed of reactive and deliberative layers. The reactive layer consists of a database of behaviors that aremodulated to produce a desired behavior. In this work we have implemented and installed in our architecture an object manipulation behavior inspired by the concept that infants learn about their environment through manipulation. While manipulating objects, both proprioceptive data and exteroceptive data are recorded. Both of these types of data are combined and statistically analyzed in order to extract important parameters that distinctively describe the object being manipulated. This data is then clustered using the standard k-means algorithm and the resulting clusters are labeled. The labeling is used to train a radial basis function network for classifying the clusters. The performance of the system has been tested on a kinematically complex walking robot capable of manipulating objects with two legs used as arms, and it has been found that the trained neural network is able to classify objects even when only partial sensory data is available to the system. Our preliminary results demonstrate that this method can be effectively used in a robotic system which learns from experience about its environment.

#index 1274896
#* Avoidance of model re-induction in SVM-based feature selection for text categorization
#@ Aleksander Kołcz;Abdur Chowdhury
#t 2007
#c 11
#% 197394
#% 219052
#% 260001
#% 280817
#% 413637
#% 425047
#% 425048
#% 458379
#% 722935
#% 763708
#% 766436
#% 770810
#% 770843
#% 818307
#% 844279
#% 844309
#! Searching the feature space for a subset yielding optimum performance tends to be expensive, especially in applications where the cardinality of the feature space is high (e.g., text categorization). This is particularly true for massive datasets and learning algorithms with worse than linear scaling factors. Linear Support Vector Machines (SVMs) are among the top performers in the text classification domain and often work best with very rich feature representations. Even they however benefit from reducing the number of features, sometimes to a large extent. In this work we propose alternatives to exact re-induction of SVM models during the search for the optimum feature subset. The approximations offer substantial benefits in terms of computational efficiency. We are able to demonstrate that no significant compromises in terms of model quality are made and, moreover, in some cases gains in accuracy can be achieved.

#index 1274897
#* Building portable options: skill transfer in reinforcement learning
#@ George Konidaris;Andrew Barto
#t 2007
#c 11
#% 263527
#% 272662
#% 286423
#% 384911
#% 431471
#% 464607
#% 464636
#% 466070
#% 466751
#% 677519
#% 677552
#% 840937
#% 876006
#% 1271827
#! The options framework provides methods for reinforcement learning agents to build new high-level skills. However, since options are usually learned in the same state space as the problem the agent is solving, they cannot be used in other tasks that are similar but have different state spaces. We introduce the notion of learning options in agentspace, the space generated by a feature set that is present and retains the same semantics across successive problem instances, rather than in problemspace. Agent-space options can be reused in later tasks that share the same agent-space but have different problem-spaces. We present experimental results demonstrating the use of agent-space options in building transferrable skills, and show that they perform best when used in conjunction with problem-space options.

#index 1274898
#* Marginalized multi-instance kernels
#@ James T. Kwok;Pak-Ming Cheung
#t 2007
#c 11
#% 224755
#% 272527
#% 464436
#% 464633
#% 565537
#% 722913
#% 770868
#% 771844
#% 875969
#% 876033
#% 1860548
#! Support vector machines (SVM) have been highly successful in many machine learning problems. Recently, it is also used for multi-instance (MI) learning by employing a kernel that is defined directly on the bags. As only the bags (but not the instances) have known labels, this MI kernel implicitly assumes all instances in the bag to be equally important. However, a fundamental property of MI learning is that not all instances in a positive bag necessarily belong to the positive class, and thus different instances in the same bag should have different contributions to the kernel. In this paper, we address this instance label ambiguity by using the method of marginalized kernels. It first assumes that all the instance labels are available and defines a label-dependent kernel on the instances. By integrating out the unknown instance labels, a marginalized kernel defined on the bags can then be obtained. A desirable property is that this kernel weights the instance pairs by the consistencies of their probabilistic instance labels. Experiments on both classification and regression data sets show that this marginalized MI kernel, when used in a standard SVM, performs consistently better than the original MI kernel. It also outperforms a number of traditional MI learning methods.

#index 1274899
#* r-grams: relational grams
#@ Niels Landwehr;Luc De Raedt
#t 2007
#c 11
#% 279755
#% 519258
#% 577225
#% 731606
#% 813847
#% 1272104
#% 1289474
#! We introduce relational grams (r-grams). They upgrade n-grams for modeling relational sequences of atoms. As n-grams, r-grams are based on smoothed n-th order Markov chains. Smoothed distributions can be obtained by decreasing the order of the Markov chain as well as by relational generalization of the r-gram. To avoid sampling object identifiers in sequences, r-grams are generative models at the level of variablized sequences with local object identity constraints. These sequences define equivalence classes of ground sequences, in which elements are identical up to local identifier renaming. The proposed technique is evaluated in several domains, including mobile phone communication logs, Unix shell user modeling, and protein fold prediction based on secondary protein structure.

#index 1274900
#* Generalized additive Bayesian network classifiers
#@ Jianguo Li;Changshui Zhang;Tao Wang;Yimin Zhang
#t 2007
#c 11
#% 44876
#% 73441
#% 129987
#% 246832
#% 290482
#% 361100
#% 400980
#% 757953
#% 799040
#% 840881
#% 1650623
#! Bayesian network classifiers (BNC) have received considerable attention in machine learning field. Some special structure BNCs have been proposed and demonstrate promise performance. However, recent researches show that structure learning in BNs may lead to a non-negligible posterior problem, i.e, there might be many structures have similar posterior scores. In this paper, we propose a generalized additive Bayesian network classifiers, which transfers the structure learning problem to a generalized additive models (GAM) learning problem. We first generate a series of very simple BNs, and put them in the framework of GAM, then adopt a gradient-based algorithm to learn the combining parameters, and thus construct a more powerful classifier. On a large suite of benchmark data sets, the proposed approach outperforms many traditional BNCs, such as naive Bayes, TAN, etc, and achieves comparable or better performance in comparison to boosted Bayesian network classifiers.

#index 1274901
#* Generalizing the bias term of support vector machines
#@ Wenye Li;Kwong-Sak Leung;Kin-Hong Lee
#t 2007
#c 11
#% 266882
#% 304942
#% 415336
#% 716271
#% 829023
#% 1650298
#! Based on the study of a generalized form of representer theorem and a specific trick in constructing kernels, a generic learning model is proposed and applied to support vector machines. An algorithm is obtained which naturally generalizes the bias term of SVM. Unlike the solution of standard SVM which consists of a linear expansion of kernel functions and a bias term, the generalized algorithm maps predefined features onto a Hilbert space as well and takes them into special consideration by leaving part of the space unregularized when seeking a solution in the space. Empirical evaluations have confirmed the effectiveness from the generalization in classification tasks.

#index 1274902
#* Robust object tracking with a case-base updating strategy
#@ Wenhui Liao;Yan Tong;Zhiwei Zhu;Qiang Ji
#t 2007
#c 11
#% 176887
#% 219732
#% 250710
#% 261320
#% 496417
#% 753302
#% 772887
#% 812350
#% 812414
#% 883837
#% 1562606
#% 1828393
#! The paper describes a simple but effective framework for visual object tracking in video sequences. The main contribution of this work lies in the introduction of a case-based reasoning (CBR) method to maintain an accurate target model automatically and efficiently under significant appearance changes without drifting away. Specifically, an automatic case-base maintenance algorithm is proposed to dynamically update the case base, manage the case base to be competent and representative, and to maintain the case base in a reasonable size for real-time performance. Furthermore, the method can provide an accurate confidence measurement for each tracked object so that the tracking failures can be identified in time. Under the framework, a real-time face tracker is built to track human faces robustly under various face orientations, significant facial expressions, and illumination changes.

#index 1274903
#* Explanation-based feature construction
#@ Shiau Hong Lim;Li-Lun Wang;Gerald DeJong
#t 2007
#c 11
#% 100193
#% 126894
#% 243727
#% 243728
#% 409857
#% 413955
#% 718871
#% 722909
#% 722942
#% 812488
#% 929722
#% 1289518
#! Choosing good features to represent objects can be crucial to the success of supervised machine learning algorithms. Good high-level features are those that concentrate information about the classification task. Such features can often be constructed as non-linear combinations of raw or native input features such as the pixels of an image. Using many nonlinear combinations, as do SVMs, can dilute the classification information necessitating many training examples. On the other hand, searching even a modestly-expressive space of nonlinear functions for high-information ones can be intractable. We describe an approach to feature construction where task-relevant discriminative features are automatically constructed, guided by an explanation-based interaction of training examples and prior domain knowledge. We show that in the challenging task of distinguishing handwritten Chinese characters, our automatic feature-construction approach performs particularly well on the most difficult and complex character pairs.

#index 1274904
#* Protein quaternary fold recognition using conditional graphical models
#@ Yan Liu;Jaime Carbonell;Vanathi Gopalakrishnan;Peter Weigele
#t 2007
#c 11
#% 464434
#% 527992
#% 906397
#% 1717572
#! Protein fold recognition is a crucial step in inferring biological structure and function. This paper focuses on machine learning methods for predicting quaternary structural folds, which consist of multiple protein chains that form chemical bonds among side chains to reach a structurally stable domain. The complexity associated with modeling the quaternary fold poses major theoretical and computational challenges to current machine learning methods. We propose methods to address these challenges and show how (1) domain knowledge is encoded and utilized to characterize structural properties using segmentation conditional graphical models; and (2) model complexity is handled through efficient inference algorithms. Our model follows a discriminative approach so that any informative features, such as those representative of overlapping or long-range interactions, can be used conveniently. The model is applied to predict two important quaternary folds, the triple β-spirals and double-barrel trimers. Cross-family validation shows that our method outperforms other state-of-the art algorithms.

#index 1274905
#* Automatic gait optimization with Gaussian process regression
#@ Daniel Lizotte;Tao Wang;Michael Bowling;Dale Schuurmans
#t 2007
#c 11
#% 132779
#% 269206
#% 761814
#% 840955
#% 891549
#% 1250215
#! Gait optimization is a basic yet challenging problem for both quadrupedal and bipedal robots. Although techniques for automating the process exist, most involve local function optimization procedures that suffer from three key drawbacks. Local optimization techniques are naturally plagued by local optima, make no use of the expensive gait evaluations once a local step is taken, and do not explicitly model noise in gait evaluation. These drawbacks increase the need for a large number of gait evaluations, making optimization slow, data inefficient, and manually intensive. We present a Bayesian approach based on Gaussian process regression that addresses all three drawbacks. It uses a global search strategy based on a posterior model inferred from all of the individual noisy evaluations. We demonstrate the technique on a quadruped robot, using it to optimize two different criteria: speed and smoothness. We show in both cases our technique requires dramatically fewer gait evaluations than state-of-the-art local gradient approaches.

#index 1274906
#* Recursive random fields
#@ Daniel Lowd;Pedro Domingos
#t 2007
#c 11
#% 175368
#% 384978
#% 765455
#% 850430
#% 864417
#! A formula in first-order logic can be viewed as a tree, with a logical connective at each node, and a knowledge base can be viewed as a tree whose root is a conjunction. Markov logic [Richardson and Domingos, 2006] makes this conjunction probabilistic, as well as the universal quantifiers directly under it, but the rest of the tree remains purely logical. This causes an asymmetry in the treatment of conjunctions and disjunctions, and of universal and existential quantifiers. We propose to overcome this by allowing the features of Markov logic networks (MLNs) to be nested MLNs. We call this representation recursive random fields (RRFs). RRFs can represent many first-order distributions exponentially more compactly than MLNs. We perform inference in RRFs using MCMC and ICM, and weight learning using a form of backpropagation. Weight learning in RRFs is more powerful than structure learning in MLNs. Applied to first-order knowledge bases, it provides a very flexible form of theory revision. We evaluate RRFs on the problem of probabilistic integrity constraints in databases, and obtain promising results.

#index 1274907
#* Prediction of probability of survival in critically ill patients optimizing the area under the ROC curve
#@ Oscar Luaces;José R. Quevedo;Francisco Taboada;Guillermo M. Albaiceta;Antonio Bahamonde
#t 2007
#c 11
#% 577224
#% 770800
#% 840882
#% 1699597
#! The paper presents a support vector method for estimating probabilities in a real world problem: the prediction of probability of survival in critically ill patients. The standard procedure with Support Vectors Machines uses Platt's method to fit a sigmoid that transforms continuous outputs into probabilities. The method proposed here exploits the difference between maximizing the AUC and minimizing the error rate in binary classification tasks. The conclusion is that it is preferable to optimize the AUC first (using a multivariate SVM) to then fit a sigmoid. We provide experimental evidence in favor of our proposal. For this purpose, we used data collected in general ICUs at 10 hospitals in Spain; 6 of these include coronary patients, while the other 4 do not treat coronary diseases. The total number of patients considered in our study was 2501.

#index 1274908
#* The ins and outs of critiquing
#@ David McSherry;David W. Aha
#t 2007
#c 11
#% 428439
#% 428440
#% 445152
#% 490786
#% 790460
#% 1374695
#% 1389762
#! Eliminating previously recommended products in critiquing limits the choices available to users when they attempt to navigate back to products they critiqued earlier in the dialogue (e.g., in search of cheaper alternatives). In the worst case, a user may find that the only product she is prepared to accept (e.g., having ruled out cheaper alternatives) has been eliminated. However, an equally serious problem if previous recommendations are not eliminated is that products that satisfy the user's requirements, if any, may be unreachable by any sequence of critiques. We present a new version of progressive critiquing that leaves open the option of repeating a previous recommendation while also addressing the unreachability problem. Our empirical results show that the approach is most effective when users refrain from over-critiquing attributes whose current values are acceptable.

#index 1274909
#* Learning from partial observations
#@ Loizos Michael
#t 2007
#c 11
#% 697
#% 26125
#% 55066
#% 81854
#% 115960
#% 145156
#% 180945
#% 203334
#% 224755
#% 240796
#% 264164
#% 296858
#% 449559
#% 451057
#! We present a general machine learning framework for modelling the phenomenon of missing information in data. We propose a masking process model to capture the stochastic nature of information loss. Learning in this context is employed as a means to recover as much of the missing information as is recoverable. We extend the Probably Approximately Correct semantics to the case of learning from partial observations with arbitrarily hidden attributes. We establish that simply requiring learned hypotheses to be consistent with observed values suffices to guarantee that hidden values are recoverable to a certain accuracy; we also show that, in some sense, this is an optimal strategy for achieving accurate recovery. We then establish that a number of natural concept classes, including all the classes of monotone formulas that are PAC learnable by monotone formulas, and the classes of conjunctions, disjunctions, k-CNF, k-DNF, and linear thresholds, are consistently learnable from partial observations. We finally show that the concept classes of parities and monotone term 1-decision lists are not properly consistently learnable from partial observations, if RP ≠ NP. This implies a separation of what is consistently learnable from partial observations versus what is learnable in the complete or noisy setting.

#index 1274910
#* Relevance estimation and value calibration of evolutionary algorithm parameters
#@ Volker Nannen;A. E. Eiben
#t 2007
#c 11
#% 10658
#% 414123
#% 729456
#% 876112
#% 1777088
#% 1777156
#% 1777313
#! The main objective of this paper is to present and evaluate a method that helps to calibrate the parameters of an evolutionary algorithm in a systematic and semi-automated manner. The method for Relevance Estimation and Value Calibration of EA parameters (REVAC) is empirically evaluated in two different ways. First, we use abstract test cases reflecting the typical properties of EA parameter spaces. Here we observe that REVAC is able to approximate the exact (hand-coded) relevance of parameters and it works robustly with measurement noise that is highly variable and not normally distributed. Second, we use REVAC for calibrating GAs for a number of common objective functions. Here we obtain a common sense validation, REVAC finds mutation rate pm much more sensitive than crossover rate pc and it recommends intuitively sound values: pm between 0.01 and 0.1, and 0.6 ≤ pc ≤ 1.0.

#index 1274911
#* Local search for balanced submodular clusterings
#@ M. Narasimhan;J. Bilmes
#t 2007
#c 11
#% 36672
#% 55327
#% 313959
#% 404719
#% 726508
#% 816193
#! In this paper, we consider the problem of producing balanced clusterings with respect to a submodular objective function. Submodular objective functions occur frequently in many applications, and hence this problem is broadly applicable. We show that the results of Patkar and Narayanan [8] can be applied to cases when the submodular function is derived from a bipartite object-feature graph, and moreover, in this case we have an efficient flow based algorithm for finding local improvements. We show the effectiveness of this approach by applying it to the clustering of words in language models.

#index 1274912
#* Kernel matrix evaluation
#@ Canh Hao Nguyen;Tu Bao Ho
#t 2007
#c 11
#% 722815
#% 722901
#% 743284
#% 763697
#% 771841
#% 771944
#% 829029
#% 846429
#! We study the problem of evaluating the goodness of a kernel matrix for a classification task. As kernel matrix evaluation is usually used in other expensive procedures like feature and model selections, the goodness measure must be calculated efficiently. Most previous approaches are not efficient, except for Kernel Target Alignment (KTA) that can be calculated in O(n2) time complexity. Although KTA is widely used, we show that it has some serious drawbacks. We propose an efficient surrogate measure to evaluate the goodness of a kernel matrix based on the data distributions of classes in the feature space. The measure not only overcomes the limitations of KTA, but also possesses other properties like invariance, efficiency and error bound guarantee. Comparative experiments show that the measure is a good indication of the goodness of a kernel matrix.

#index 1274913
#* Neighborhood MinMax projections
#@ Feiping Nie;Shiming Xiang;Changshui Zhang
#t 2007
#c 11
#% 80995
#% 224113
#% 235342
#% 451991
#% 729437
#! A new algorithm, Neighborhood MinMax Projections (NMMP), is proposed for supervised dimensionality reduction in this paper. The algorithm aims at learning a linear transformation, and focuses only on the pairwise points where the two points are neighbors of each other. After the transformation, the considered pairwise points within the same class are as close as possible, while those between different classes are as far as possible. We formulate this problem as a constrained optimization problem, in which the global optimum can be effectively and efficiently obtained. Compared with the popular supervised method, Linear Discriminant Analysis (LDA), our method has three significant advantages. First, it is able to extract more discriminative features. Second, it can deal with the case where the class distributions aremore complex than Gaussian. Third, the singularity problem existing in LDA does not occur naturally. The performance on several data sets demonstrates the effectiveness of the proposed method.

#index 1274914
#* Case-based learning from proactive communication
#@ Santiago Ontañón;Enric Plaza
#t 2007
#c 11
#% 176887
#% 378963
#% 496105
#% 866959
#% 866963
#% 1275276
#! We present a proactive communication approach that allows CBR agents to gauge the strengths and weaknesses of other CBR agents. The communication protocol allows CBR agents to learn from communicating with other CBR agents in such a way that each agent is able to retain certain cases provided by other agents that are able to improve their individual performance (without need to disclose all the contents of each case base). The selection and retention of cases is modeled as a case bartering process, where each individual CBR agent autonomously decides which cases offers for bartering and which offered barters accepts. Experimental evaluations show that the sum of all these individual decisions result in a clear improvement in individual CBR agent performance with only a moderate increase of individual case bases.

#index 1274915
#* Learning to count by think aloud imitation
#@ Laurent Orseau
#t 2007
#c 11
#% 92292
#% 150994
#% 236498
#% 959478
#% 1042867
#% 1272286
#% 1579092
#! Although necessary, learning to discover new solutions is often long and difficult, even for supposedly simple tasks such as counting. On the other hand, learning by imitation provides a simple way to acquire knowledge by watching other agents do. In order to learn more complex tasks by imitation than mere sequences of actions, a Think Aloud protocol is introduced, with a new neuro-symbolic network. The latter uses time in the same way as in a Time Delay Neural Network, and is added basic first order logic capacities. Tested on a benchmark counting task, learning is very fast, generalization is accurate, whereas there is no initial bias toward counting.

#index 1274916
#* A tighter error bound for decision tree learning using PAC learnability
#@ Chaithanya Pichuka;Raju S. Bapi;Chakravarthy Bhagvati;Arun K. Pujari;B. L. Deekshatulu
#t 2007
#c 11
#% 697
#% 276528
#% 359194
#% 376266
#% 562962
#% 803574
#% 840886
#! Error bounds for decision trees are generally based on depth or breadth of the tree. In this paper, we propose a bound for error rate that depends both on the depth and the breadth of a specific decision tree constructed from the training samples. This bound is derived from sample complexity estimate based on PAC learnability. The proposed bound is compared with other traditional error bounds on several machine learning benchmark data sets as well as on an image data set used in Content Based Image Retrieval (CBIR). Experimental results demonstrate that the proposed bound gives tighter estimation of the empirical error.

#index 1274917
#* Kernel conjugate gradient for fast kernel machines
#@ Nathan D. Ratliff;J. Andrew Bagnell
#t 2007
#c 11
#% 84149
#% 393059
#% 466597
#! We propose a novel variant of the conjugate gradient algorithm, Kernel Conjugate Gradient (KCG), designed to speed up learning for kernel machines with differentiable loss functions. This approach leads to a better conditioned optimization problem during learning. We establish an upper bound on the number of iterations for KCG that indicates it should require less than the square root of the number of iterations that standard conjugate gradient requires. In practice, for various differentiable kernel learning problems, we find KCG consistently, and significantly, outperforms existing techniques. The algorithm is simple to implement, requires no more computation per iteration than standard approaches, and is well motivated by Reproducing Kernel Hilbert Space (RKHS) theory. We further show that data-structure techniques recently used to speed up kernel machine approaches are well matched to the algorithm by reducing the dominant costs of training: function evaluation and RKHS inner product computation.

#index 1274918
#* Deictic option schemas
#@ Balaraman Ravindran;Andrew G. Barto;Vimal Mathew
#t 2007
#c 11
#% 111440
#% 286423
#% 334612
#% 655325
#% 669402
#% 702594
#% 1279356
#% 1650364
#! Deictic representation is a representational paradigm, based on selective attention and pointers, that allows an agent to learn and reason about rich complex environments. In this article we present a hierarchical reinforcement learning framework that employs aspects of deictic representation. We also present a Bayesian algorithm for learning the correct representation for a given sub-problem and empirically validate it on a complex game environment.

#index 1274919
#* Acquiring a robust case base for the robot soccer domain
#@ Raquel Ros;Josep Lluís Arcos
#t 2007
#c 11
#% 156188
#% 1499567
#% 1727823
#! This paper presents a mechanism for acquiring a case base for a CBR system that has to deal with a limited perception of the environment. The construction of case bases in these domains is very complex and requires mechanisms for autonomously adjusting the scope of the existing cases and for acquiring new cases. The work presented in this paper addresses these two goals: to find out the "right" scope of existing cases and to introduce new cases when no appropriate solution is found. We have tested the mechanism in the robot soccer domain performing experiments, both under simulation and with real robots.

#index 1274920
#* QuantMiner: a genetic algorithm for mining quantitative association rules
#@ Ansaf Salleb-Aouissi;Christel Vrain;Cyril Nortet
#t 2007
#c 11
#% 114994
#% 152934
#% 210160
#% 210162
#% 213977
#% 227953
#% 280458
#% 342640
#% 346543
#% 452863
#% 461909
#% 631971
#% 785419
#! In this paper, we propose QUANTMINER, a mining quantitative association rules system. This system is based on a genetic algorithm that dynamically discovers "good" intervals in association rules by optimizing both the support and the confidence. The experiments on real and artificial databases have shown the usefulness of QUANTMINER as an interactive data mining tool.

#index 1274921
#* Transfer learning in real-time strategy games using hybrid CBR/RL
#@ Manu Sharma;Michael Holmes;Juan Santamaria;Arya Irani;Charles Isbell;Ashwin Ram
#t 2007
#c 11
#% 168280
#% 176887
#% 252329
#% 359837
#% 384911
#% 449561
#% 1705996
#% 1706010
#! The goal of transfer learning is to use the knowledge acquired in a set of source tasks to improve performance in a related but previously unseen target task. In this paper, we present a multilayered architecture named CAse-Based Reinforcement Learner (CARL). It uses a novel combination of Case-Based Reasoning (CBR) and Reinforcement Learning (RL) to achieve transfer while playing against the Game AI across a variety of scenarios in MadRTSTM, a commercial Real Time Strategy game. Our experiments demonstrate that CARL not only performs well on individual tasks but also exhibits significant performance gains when allowed to transfer knowledge from previous tasks.

#index 1274922
#* Parametric kernels for sequence data analysis
#@ Young-In Shin;Donald Fussell
#t 2007
#c 11
#% 304917
#% 393059
#% 577221
#% 640416
#% 718832
#% 743284
#% 836859
#% 844814
#! A key challenge in applying kernel-based methods for discriminative learning is to identify a suitable kernel given a problem domain. Many methods instead transform the input data into a set of vectors in a feature space and classify the transformed data using a generic kernel. However, finding an effective transformation scheme for sequence (e.g. time series) data is a difficult task. In this paper, we introduce a scheme for directly designing kernels for the classification of sequence data such as that in handwritten character recognition and object recognition from sensor readings. Ordering information is represented by values of a parameter associated with each input data element. A similarity metric based on the parametric distance between corresponding elements is combined with their problemspecific similarity metric to produce a Mercer kernel suitable for use in methods such as support vector machine (SVM). This scheme directly embeds extraction of features from sequences of varying cardinalities into the kernel without needing to transform all input data into a common feature space before classification. We apply our method to object and handwritten character recognition tasks and compare against current approaches. The results show that we can obtain at least comparable accuracy to state of the art problem-specific methods using a systematic approach to kernel design. Our contribution is the introduction of a general technique for designing SVM kernels tailored for the classification of sequence data.

#index 1274923
#* Reinforcement learning of local shape in the game of go
#@ David Silver;Richard Sutton;Martin Müller
#t 2007
#c 11
#% 116297
#% 169359
#% 348578
#% 348582
#% 348585
#% 449561
#% 1404139
#! We explore an application to the game of Go of a reinforcement learning approach based on a linear evaluation function and large numbers of binary features. This strategy has proved effective in game playing programs and other reinforcement learning applications. We apply this strategy to Go by creating over a million features based on templates for small fragments of the board, and then use temporal difference learning and self-play. This method identifies hundreds of low level shapes with recognisable significance to expert Go players, and provides quantitive estimates of their values. We analyse the relative contributions to performance of templates of different types and sizes. Our results show that small, translation-invariant templates are surprisingly effective. We assess the performance of our program by playing against the Average Liberty Player and a variety of computer opponents on the 9×9 Computer Go Server. Our linear evaluation function appears to outperform all other static evaluation functions that do not incorporate substantial domain knowledge.

#index 1274924
#* Semi-supervised Gaussian process classifiers
#@ Vikas Sindhwani;Wei Chu;S. Sathiya Keerthi
#t 2007
#c 11
#% 840938
#% 891549
#% 961218
#! In this paper, we propose a graph-based construction of semi-supervised Gaussian process classifiers. Our method is based on recently proposed techniques for incorporating the geometric properties of unlabeled data within globally defined kernel functions. The full machinery for standard supervised Gaussian process inference is brought to bear on the problem of learning from labeled and unlabeled data. This approach provides a natural probabilistic extension to unseen test examples. We employ Expectation Propagation procedures for evidence-based model selection. In the presence of few labeled examples, this approach is found to significantly outperform cross-validation techniques. We present empirical results demonstrating the strengths of our approach.

#index 1274925
#* An experts algorithm for transfer learning
#@ Erik Talvitie;Satinder Singh
#t 2007
#c 11
#% 213010
#% 232319
#% 251784
#% 266792
#% 416988
#% 425075
#% 505086
#% 823852
#% 1279356
#% 1699611
#! A long-lived agent continually faces new tasks in its environment. Such an agent may be able to use knowledge learned in solving earlier tasks to produce candidate policies for its current task. There may, however, be multiple reasonable policies suggested by prior experience, and the agent must choose between them potentially without any a priori knowledge about their applicability to its current situation. We present an "experts" algorithm for efficiently choosing amongst candidate policies in solving an unknown Markov decision process task. We conclude with the results of experiments on two domains in which we generate candidate policies from solutions to related tasks and use our experts algorithm to choose amongst them.

#index 1274926
#* Direct code access in self-organizing neural networks for reinforcement learning
#@ Ah-Hwee Tan
#t 2007
#c 11
#% 23408
#% 96686
#% 111415
#% 124691
#% 384911
#% 577971
#% 690846
#% 716013
#% 770417
#% 831322
#% 831328
#% 1272286
#! TD-FALCON is a self-organizing neural network that incorporates Temporal Difference (TD) methods for reinforcement learning. Despite the advantages of fast and stable learning, TD-FALCON still relies on an iterative process to evaluate each available action in a decision cycle. To remove this deficiency, this paper presents a direct code access procedure whereby TD-FALCON conducts instantaneous searches for cognitive nodes that match with the current states and at the same time provide maximal reward values. Our comparative experiments show that TD-FALCON with direct code access produces comparable performance with the original TD-FALCON while improving significantly in computation efficiency and network complexity.

#index 1274927
#* Grounding abstractions in predictive state representations
#@ Brian Tanner;Vadim Bulitko;Anna Koop;Cosmin Paduraru
#t 2007
#c 11
#% 136350
#% 702594
#% 788097
#% 926881
#! This paper proposes a systematic approach of representing abstract features in terms of low-level, subjective state representations. We demonstrate that a mapping between the agent's predictive state representation and abstract features can be derived automatically from high-level training data supplied by the designer. Our empirical evaluation demonstrates that an experience-oriented state representation built around a single-bit sensor can represent useful abstract features such as "back against a wall", "in a corner", or "in a room". As a result, the agent gains virtual sensors that could be used by its control policy.

#index 1274928
#* Metric properties of structured data visualizations through generative probabilistic modeling
#@ Peter Tiňo;Nikolaos Gianniotis
#t 2007
#c 11
#% 257039
#% 341446
#% 577961
#% 769960
#% 796203
#% 1760430
#! Recently, generative probabilistic modeling principles were extended to visualization of structured data types, such as sequences. The models are formulated as constrained mixtures of sequence models - a generalization of density-based visualization methods previously developed for static data sets. In order to effectively explore visualization plots, one needs to understand local directional magnification factors, i.e. the extend to which small positional changes on visualization plot lead to changes in local noise models explaining the structured data. Magnification factors are useful for highlighting boundaries between data clusters. In this paper we present two techniques for estimating local metric induced on the sequence space by themodel formulation. We first verify our approach in two controlled experiments involving artificially generated sequences. We then illustrate our methodology on sequences representing chorals by J.S. Bach.

#index 1274929
#* Ensembles of partially trained SWMs with multiplicative updates
#@ Ivor W. Tsang;James T. Kwok
#t 2007
#c 11
#% 227736
#% 269218
#% 276511
#% 425065
#% 722815
#% 741972
#% 916798
#! The training of support vector machines (SVM) involves a quadratic programming problem, which is often optimized by a complicated numerical solver. In this paper, we propose a much simpler approach based on multiplicative updates. This idea was first explored in [Cristianini et al., 1999], but its convergence is sensitive to a learning rate that has to be fixed manually. Moreover, the update rule only works for the hard-margin SVM, which is known to have poor performance on noisy data. In this paper, we show that the multiplicative update of SVM can be formulated as a Bregman projection problem, and the learning rate can then be adapted automatically. Moreover, because of the connection between boosting and Bregman distance, we show that this multiplicative update for SVM can be regarded as boosting the (weighted) Parzen window classifiers. Motivated by the success of boosting, we then consider the use of an adaptive ensemble of the partially trained SVMs. Extensive experiments show that the proposed multiplicative update rule with an adaptive learning rate leads to faster and more stable convergence. Moreover, the proposed ensemble has efficient training and comparable or even better accuracy than the best-tuned soft-margin SVM.

#index 1274930
#* First order decision diagrams for relational MDPs
#@ Chenggang Wang;Saket Joshi;Roni Khardon
#t 2007
#c 11
#% 3873
#% 233849
#% 252221
#% 363744
#% 449559
#% 770823
#% 1279355
#% 1289241
#% 1650297
#! Dynamic programming algorithms provide a basic tool identifying optimal solutions in Markov Decision Processes (MDP). The paper develops a representation for decision diagrams suitable for describing value functions, transition probabilities, and domain dynamics of First Order or Relational MDPs (FOMDP). By developing appropriate operations for such diagrams the paper shows how value iteration can be performed compactly for such problems. This improves on previous approaches since the representation combines compact form with efficient operations. The work also raises interesting issues on suitability of different representations to different FOMDPs tasks.

#index 1274931
#* Self-adaptive neural networks based on a Poisson approach for knowledge discovery
#@ Haiying Wang;Huiru Zheng;Francisco Azuaje
#t 2007
#c 11
#% 176705
#% 216500
#% 232106
#% 234978
#% 252397
#% 1781280
#% 1860653
#! The ability to learn from data and to improve its performance through incremental learning makes self-adaptive neural networks (SANNs) a powerful tool to support knowledge discovery. However, the development of SANNs has traditionally focused on data domains that are assumed to be modeled by a Gaussian distribution. The analysis of data governed by other statistical models, such as the Poisson distribution, has received less attention from the data mining community. Based on special considerations of the statistical nature of data following a Poisson distribution, this paper introduces a SANN, Poisson-based Self-Organizing Tree Algorithm (PSOTA), which implements novel similarity matching criteria and neuron weight adaptation schemes. It was tested on synthetic and real world data (serial analysis of gene expression data). PSOTA-based data analysis supported the automated identification of more meaningful clusters. By visualizing the dendrograms generated by PSOTA, complex inter- and intra-cluster relationships encoded in the data were also highlighted and readily understood. This study indicate that, in comparison to the traditional Self-Organizing Tree Algorithm (SOTA), PSOTA offers significant improvements in pattern discovery and visualization in data modeled by the Poisson distribution, such as serial analysis of gene expression data.

#index 1274932
#* Dynamics of temporal difference learning
#@ Andreas Wendemuth
#t 2007
#c 11
#% 124695
#% 137597
#% 170657
#% 384911
#% 449561
#! In behavioural sciences, the problem that a sequence of stimuli is followed by a sequence of rewards r(t) is considered. The subject is to learn the full sequence of rewards from the stimuli, where the prediction is modelled by the Sutton-Barto rule. In a sequence of n trials, this prediction rule is learned iteratively by temporal difference learning. We present a closed formula of the prediction of rewards at trial time t within trial n. From that formula, we show directly that for n → ∞ the predictions converge to the real rewards. In this approach, a new quality of correlation type Toeplitz matrices is proven. We give learning rates which optimally speed up the learning process.

#index 1274933
#* Machine learning for on-line hardware reconfiguration
#@ Jonathan Wildstrom;Peter Stone;Emmett Witchel;Mike Dahlin
#t 2007
#c 11
#% 290482
#% 341938
#% 452379
#% 657616
#% 820358
#% 820398
#% 820402
#% 820404
#% 835188
#! As computer systems continue to increase in complexity, the need for AI-based solutions is becoming more urgent. For example, high-end servers that can be partitioned into logical subsystems and repartitioned on the fly are now becoming available. This development raises the possibility of reconfiguring distributed systems online to optimize for dynamically changing workloads. However, it also introduces the need to decide when and how to reconfigure. This paper presents one approach to solving this online reconfiguration problem. In particular, we learn to identify, from only low-level system statistics, which of a set of possible configurations will lead to better performance under the current unknown workload. This approach requires no instrumentation of the system's middleware or operating systems. We introduce an agent that is able to learn this model and use it to switch configurations online as the workload varies. Our agent is fully implemented and tested on a publicly available multi-machine, multi-process distributed system (the online transaction processing benchmark TPC-W). We demonstrate that our adaptive configuration is able to outperform any single fixed configuration in the set over a variety of workloads, including gradual changes and abrupt workload spikes.

#index 1274934
#* A primitive based generative model to infer timing information in unpartitioned handwriting data
#@ Ben H. Williams;Marc Toussaint;Amos J. Storkey
#t 2007
#c 11
#% 246836
#% 855261
#! Biological movement control and planning is based upon motor primitives. In our approach, we presume that each motor primitive takes responsibility for controlling a small sub-block of motion, containing coherent muscle activation outputs. A central timing controller cues these subroutines of movement, creating complete movement strategies that are built up by overlaying primitives, thus creating synergies of muscle activation. This partitioning allows the movement to be defined by a sparse code representing the timing of primitive activations. This paper shows that it is possible to use a factorial hidden Markov model to infer primitives in handwriting data. The variation in the handwriting data can to a large extent be explained by timing variation in the triggering of the primitives. Once an appropriate set of primitives has been inferred, the characters can be represented as a set of timings of primitive activations, along with variances, giving a very compact representation of the character. The model is naturally partitioned into a low level primitive output stage, and a top-down primitive timing stage. This partitioning gives us an insight into behaviours such as scribbling, and what is learnt in order to write a new character.

#index 1274935
#* A subspace kernel for nonlinear feature extraction
#@ Mingrui Wu;Jason Farquhar
#t 2007
#c 11
#% 190581
#% 425040
#% 722809
#% 794857
#% 840960
#! Kernel based nonlinear Feature Extraction (KFE) or dimensionality reduction is a widely used preprocessing step in pattern classification and data mining tasks. Given a positive definite kernel function, it is well known that the input data are implicitly mapped to a feature space with usually very high dimensionality. The goal of KFE is to find a low dimensional subspace of this feature space, which retains most of the information needed for classification or data analysis. In this paper, we propose a subspace kernel based on which the feature extraction problem is transformed to a kernel parameter learning problem. The key observation is that when projecting data into a low dimensional subspace of the feature space, the parameters that are used for describing this subspace can be regarded as the parameters of the kernel function between the projected data. Therefore current kernel parameter learning methods can be adapted to optimize this parameterized kernel function. Experimental results are provided to validate the effectiveness of the proposed approach.

#index 1274936
#* Understanding drawings by compositional analogy
#@ Patrick W. Yaner;Ashok K. Goel
#t 2007
#c 11
#% 65345
#% 197261
#% 529817
#% 1289334
#! We describe an analogical method for constructing a structuralmodel froman unlabelled 2D line drawing. The source case is represented as a schema that contains its 2D line drawing, the lines and intersections in the drawing, the shapes in drawing, and the structural model of the device depicted in the drawing. Given a target drawing and a relevant source case, our method first constructs a graphical representation of the lines and the intersections in the target drawing, then uses the mappings at the level of line intersections to transfer the shape representations from the source case to the target, next uses the mappings at the level of shapes to transfer the structural model of the device from the source to the target. The Archytas system implements and evaluates this method of compositional analogy.

#index 1274937
#* A scalable kernel-based algorithm for semi-supervised metric learning
#@ Dit-Yan Yeung;Hong Chang;Guang Dai
#t 2007
#c 11
#% 266426
#% 466890
#% 723241
#% 770782
#% 770811
#% 770813
#% 803668
#% 829025
#! In recent years, metric learning in the semisupervised setting has aroused a lot of research interests. One type of semi-supervised metric learning utilizes supervisory information in the form of pairwise similarity or dissimilarity constraints. However, most methods proposed so far are either limited to linear metric learning or unable to scale up well with the data set size. In this paper, we propose a nonlinear metric learning method based on the kernel approach. By applying low-rank approximation to the kernel matrix, our method can handle significantly larger data sets. Moreover, our low-rank approximation scheme can naturally lead to out-of-sample generalization. Experiments performed on both artificial and real-world data show very promising results.

#index 1274938
#* Managing domain knowledge and multiple models with boosting
#@ Peng Zang;Charles Isbell
#t 2007
#c 11
#% 73372
#% 266257
#% 278042
#% 302391
#% 464465
#% 465746
#% 520224
#% 562956
#% 646003
#% 770854
#! We present MBoost, a novel extension to AdaBoost that extends boosting to use multiple weak learners explicitly, and provides robustness to learning models that overfit or are poorly matched to data. We demonstrate MBoost on a variety of problems and compare it to cross validation for model selection.

#index 1274939
#* Concept sampling: towards systematic selection in large-scale mixed concepts in machine learning
#@ Yi Zhang;Xiaoming Jin
#t 2007
#c 11
#% 1331
#% 136350
#% 204531
#% 266787
#% 307100
#% 342639
#% 376266
#% 399587
#% 451221
#% 729932
#% 853724
#! This paper addresses the problem of concept sampling. In many real-world applications, a large collection of mixed concepts is available for decision making. However, the collection is often so large that it is difficult if not unrealistic to utilize those concepts directly, due to the domain-specific limitations of available space or time. This naturally yields the need for concept reduction. In this paper, we introduce the novel problem of concept sampling: to find the optimal subset of a large collection of mixed concepts in advance so that the performance of future decision making can be best preserved by selectively combining the concepts remained in the subset. The problem is formulized as an optimization process based on our derivation of a target function, which ties a clear connection between the composition of the concept subset and the expected error of future decision making upon the subset. Then, based on this target function, a sampling algorithm is developed and its effectiveness is discussed. Extensive empirical studies suggest that, the proposed concept sampling method well preserves the performance of decision making while dramatically reduces the number of concepts maintained and thus justify its usefulness in handling large-scale mixed concepts.

#index 1274940
#* Searching for interacting features
#@ Zheng Zhao;Huan Liu
#t 2007
#c 11
#% 167633
#% 169659
#% 243727
#% 290482
#% 425002
#% 466410
#% 720010
#% 722929
#% 770774
#% 770799
#% 793250
#! Feature interaction presents a challenge to feature selection for classification. A feature by itself may have little correlation with the target concept, but when it is combined with some other features, they can be strongly correlated with the target concept. Unintentional removal of these features can result in poor classification performance. Handling feature interaction can be computationally intractable. Recognizing the presence of feature interaction, we propose to efficiently handle feature interaction to achieve efficient feature selection and present extensive experimental results of evaluation.

#index 1274941
#* Learning user clicks in web search
#@ Ding Zhou;Levent Bolelli;Jia Li;C. Lee Giles;Hongyuan Zha
#t 2007
#c 11
#% 310567
#% 577224
#% 630984
#% 729967
#% 755395
#% 807348
#% 807420
#! Machine learning for predicting user clicks in Web-based search offers automated explanation of user activity. We address click prediction in the Web search scenario by introducing a method for click prediction based on observations of past queries and the clicked documents. Due to the sparsity of the problem space, commonly encountered when learning for Web search, new approaches to learn the probabilistic relationship between documents and queries are proposed. Two probabilistic models are developed, which differ in the interpretation of the query-document co-occurrences. A novel technique, namely, conditional probability hierarchy, flexibly adjusts the level of granularity in parsing queries, and, as a result, leverages the advantages of both models.

#index 1274942
#* An empirical study of the noise impact on cost-sensitive learning
#@ Xingquan Zhu;Xindong Wu;Taghi M. Khoshgoftaar;Yong Shi
#t 2007
#c 11
#% 160852
#% 280437
#% 449588
#% 458361
#% 464639
#% 466249
#% 727925
#% 769875
#% 785369
#! In this paper, we perform an empirical study of the impact of noise on cost-sensitive (CS) learning, through observations on how a CS learner reacts to the mislabeled training examples in terms of misclassification cost and classification accuracy. Our empirical results and theoretical analysis indicate that mislabeled training examples can raise serious concerns for cost-sensitive classification, especially when misclassifying some classes becomes extremely expensive. Compared to general inductive learning, the problem of noise handling and data cleansing is more crucial, and should be carefully investigated to ensure the success of CS learning.

#index 1274943
#* On the logic of normative systems
#@ Thomas Ågotnes;Wiebe Van Der Hoek;Juan A. Rodríguez-Aguilar;Carles Sierra;Michael Wooldridge
#t 2007
#c 11
#% 101955
#% 292245
#% 413871
#% 890221
#! We introduce Normative Temporal Logic (NTL), a logic for reasoning about normative systems. NTL is a generalisation of the well-known branching-time temporal logic CTL, in which the path quantifiers A ("on all paths... ") and E ("on some path... ") are replaced by the indexed deontic operators Oη and Pη, where for example Oη φ means "φ is obligatory in the context of normative system η". After defining the logic, we give a sound and complete axiomatisation, and discuss the logic's relationship to standard deontic logics. We present a symbolic representation language for models and normative systems, and identify four different model checking problems, corresponding to whether or not a model is represented symbolically or explicitly, and whether or not we are given an interpretation for the normative systems named in formulae to be checked. We show that the complexity of model checking varies from P-complete up to EXPTIME-hard for these variations.

#index 1274944
#* Quantified coalition logic
#@ Thomas Ågotnes;Wiebe Van Der Hoek;Michael Wooldridge
#t 2007
#c 11
#% 292245
#% 413871
#% 782011
#% 823865
#% 890213
#% 890215
#% 890221
#% 1223252
#% 1669672
#! We add a limited but useful form of quantification to Coalition Logic, a popular formalism for reasoning about cooperation in game-like multi-agent systems. The basic constructs of Quantified Coalition Logic (QCL) allow us to express properties as "there exists a coalition C satisfying property P such that C can achieve φ. We give an axiomatization of QCL, and show that while it is no more expressive than Coalition Logic, it is exponentially more succinct. The time complexity of QCL model checking for symbolic and explicit state representations is shown to be no worse than that of Coalition Logic. We illustrate the formalism by showing how to succinctly specify such social choice mechanisms as majority voting, which in Coalition Logic require specifications that are exponentially long in the number of agents.

#index 1274945
#* An axiomatic approach to personalized ranking systems
#@ Alon Altman;Moshe Tennenholtz
#t 2007
#c 11
#% 290830
#% 788101
#% 799636
#% 808358
#% 810734
#% 822003
#% 1250600
#% 1269378
#% 1289497
#! Personalized ranking systems and trust systems are an essential tool for collaboration in a multi-agent environment. In these systems, trust relations between many agents are aggregated to produce a personalized trust rating of the agents. In this paper we introduce the first extensive axiomatic study of this setting, and explore a wide array of well-known and new personalized ranking systems. We adapt several axioms (basic criteria) from the literature on global ranking systems to the context of personalized ranking systems, and prove strong properties implied by the combination of these axioms.

#index 1274946
#* Market based resource allocation with incomplete information
#@ Bo An;Chunyan Miao;Zhiqi Shen
#t 2007
#c 11
#% 162305
#% 203554
#% 451702
#% 814217
#% 1272101
#% 1781593
#! Although there are some research efforts toward resource allocation in multi-agent systems (MAS), most of these work assume that each agent has complete information about other agents. This research investigates interactions among selfish, rational, and autonomous agents in resource allocation, each with incomplete information about other entities, and each seeking to maximize its expected utility. This paper presents a proportional resource allocation mechanism and gives a game theoretical analysis of the optimal strategies and the analysis shows the existence of equilibrium in the incomplete information setting. By augmenting the resource allocation mechanism with a deal optimization mechanism, trading agents can be programmed to optimize resource allocation results by updating beliefs and resubmitting bids. Experimental results showed that by having a deal optimization stage, the resource allocation mechanism produced generally optimistic outcomes (close to market equilibrium).

#index 1274947
#* Efficiently exploiting symmetries in real time dynamic programming
#@ Shravan Matthur Narayanamurthy;Balaraman Ravindran
#t 2007
#c 11
#% 181627
#% 212402
#% 284645
#% 404909
#% 464442
#% 477304
#% 576214
#% 655325
#% 898290
#% 1250603
#% 1272354
#% 1279356
#% 1393537
#! Current approaches to solving Markov Decision Processes (MDPs) are sensitive to the size of the MDP. When applied to real world problems though, MDPs exhibit considerable implicit redundancy, especially in the form of symmetries. Existing model minimization methods do not exploit this redundancy due to symmetries well. In this work, given such symmetries, we present a time-efficient algorithm to construct a functionally equivalent reduced model of the MDP. Further, we present a Real Time Dynamic Programming (RTDP) algorithm which obviates an explicit construction of the reduced model by integrating the given symmetries into it. The RTDP algorithm solves the reduced model, while working with parameters of the original model and the given symmetries. As RTDP uses its experience to determine which states to backup, it focuses on parts of the reduced state set that are most relevant. This results in significantly faster learning and a reduced overall execution time. The algorithms proposed are particularly effective in the case of structured automorphisms even when the reduced model does not have fewer features. We demonstrate the results empirically on several domains.

#index 1274948
#* Spiteful bidding in sealed-bid auctions
#@ Felix Brandt;Tuomas Sandholm;Yoav Shoham
#t 2007
#c 11
#% 557381
#% 557552
#% 580522
#% 788092
#% 990190
#! We study the bidding behavior of spiteful agents who, contrary to the common assumption of self-interest, maximize a convex combination of their own profit and their competitors' losses. The motivation for this assumption stems from inherent spitefulness or, for example, from competitive scenarios such as in closed markets where the loss of a competitor will likely result in future gains for oneself. We derive symmetric Bayes Nash equilibria for spiteful agents in 1st-price and 2nd-price sealedbid auctions. In 1st-price auctions, bidders become "more truthful" the more spiteful they are. Surprisingly, the equilibrium strategy in 2nd-price auctions does not depend on the number of bidders. Based on these equilibria, we compare the revenue in both auction types. It turns out that expected revenue in 2nd-price auctions is higher than expected revenue in 1st-price auctions in the case of even the most modestly spiteful agents, provided they still care at least at little for their own profit. In other words, revenue equivalence only holds for auctions in which all agents are either self-interested or completely malicious. We furthermore investigate the impact of common knowledge on spiteful bidding. Divulging the bidders' valuations reduces revenue in 2nd-price auctions, whereas it has the opposite effect in 1st-price auctions.

#index 1274949
#* Multi-dimensional bid improvement algorithm for simultaneous auctions
#@ Teddy Candale;Sandip Sen
#t 2007
#c 11
#% 302061
#% 345429
#% 379012
#% 433915
#% 713046
#% 786984
#% 788061
#% 804975
#% 859847
#% 1269386
#% 1271997
#% 1279450
#! Bidding for multi-items in simultaneous auctions raises challenging problems. In multi-auction settings, the determination of optimal bids by potential buyers requires combinatorial calculations. While an optimal bidding strategy is known when bidding in sequential auctions, only suboptimal strategies are available when bidding for items being sold in simultaneous auctions. We investigate a multi-dimensional bid improvement scheme, motivated by optimization techniques, to derive optimal bids for item bundles in simultaneous auctions. Given a vector of initial bids, the proposed scheme systematically improves bids for each item. Such multi-dimensional improvements result in locally optimal bid vectors. Globally optimal bid vectors are guaranteed in the limit for infinite restarts. For ease of presentation we use two-item scenarios to explain the working of the algorithm. Experimental results show polynomial complexity of variants of this algorithm under different types of bidder valuations for item bundles.

#index 1274950
#* Bidding languages and winner determination for mixed multi-unit combinatorial auctions
#@ Jesús Cerquides;Ulle Endriss;Andrea Giovannucci;Juan A. Rodríguez-Aguilar
#t 2007
#c 11
#% 267752
#% 274891
#% 378898
#% 806744
#% 1272004
#% 1684552
#% 1684808
#! We introduce a new type of combinatorial auction that allows agents to bid for goods to buy, for goods to sell, and for transformations of goods. One such transformation can be seen as a step in a production process, so solving the auction requires choosing the sequence in which the accepted bids should be implemented. We introduce a bidding language for this type of auction and analyse the corresponding winner determination problem.

#index 1274951
#* Coalitional bargaining with agent type uncertainty
#@ Georgios Chalkiadakis;Craig Boutilier
#t 2007
#c 11
#% 212290
#% 773261
#% 773332
#! Coalition formation is a problem of great interest in AI, allowing groups of autonomous, individually rational agents to form stable teams. Automating the negotiations underlying coalition formation is, naturally, of special concern. However, research to date in both AI and economics has largely ignored the potential presence of uncertainty in coalitional bargaining. We present a model of discounted coalitional bargaining where agents are uncertain about the types (or capabilities) of potential partners, and hence the value of a coalition. We cast the problem as a Bayesian game in extensive form, and describe its Perfect Bayesian Equilibria as the solutions to a polynomial program. We then present a heuristic algorithm using iterative coalition formation to approximate the optimal solution, and evaluate its performance.

#index 1274952
#* Iterated weaker-than-weak dominance
#@ Shih-Fen Cheng;Michael P. Wellman
#t 2007
#c 11
#% 808367
#% 1250602
#% 1269438
#! We introduce a weakening of standard game-theoretic dominance conditions, called δ-dominance, which enables more aggressive pruning of candidate strategies at the cost of solution accuracy. Equilibria of a game obtained by eliminating a δ-dominated strategy are guaranteed to be approximate equilibria of the original game, with degree of approximation bounded by the dominance parameter, δ. We can apply elimination of δ-dominated strategies iteratively, but the δ for which a strategy may be eliminated depends on prior eliminations. We discuss implications of this order independence, and propose greedy heuristics for determining a sequence of eliminations to reduce the game as far as possible while keeping down costs. A case study analysis of an empirical 2-player game serves to illustrate the technique, and demonstrate the utility of weaker-than-weak dominance pruning.

#index 1274953
#* Reaching envy-free states in distributed negotiation settings
#@ Yann Chevaleyre;Ulle Endriss;Sylvia Estivie;Nicolas Maudet
#t 2007
#c 11
#% 267752
#% 754147
#% 819611
#% 890337
#% 1272101
#% 1289500
#! Mechanisms for dividing a set of goods amongst a number of autonomous agents need to balance efficiency and fairness requirements. A common interpretation of fairness is envy-freeness, while efficiency is usually understood as yielding maximal overall utility. We show how to set up a distributed negotiation framework that will allow a group of agents to reach an allocation of goods that is both efficient and envy-free.

#index 1274954
#* Privacy and artificial agents, or, is Google reading my email?
#@ Samir Chopra;Laurence White
#t 2007
#c 11
#% 247833
#% 294728
#% 390177
#% 420991
#% 421005
#% 421012
#% 768685
#% 1289538
#! We investigate legal and philosophical notions of privacy in the context of artificial agents. Our analysis utilizes a normative account of privacy that defends its value and the extent to which it should be protected: privacy is treated as an interest with moral value, to supplement the legal claim that privacy is a legal right worthy of protection by society and the law. We argue that the fact that the only entity to access my personal data (such as email) is an artificial agent is irrelevant to whether a breach of privacy has occurred. What is relevant are the capacities of the agent: what the agent is both able and empowered to do with that information. We show how concepts of legal agency and attribution of knowledge gained by agents to their principals are crucial to understanding whether a violation of privacy has occurred when artificial agents access users' personal data. As natural language processing and semantic extraction used in artificial agents become increasingly sophisticated, so the corporations that deploy those agents will be more likely to be attributed with knowledge of their users' personal information, thus triggering significant potential legal liabilities.

#index 1274955
#* Incremental mechanism design
#@ Vincent Conitzer;Tuomas Sandholm
#t 2007
#c 11
#% 314944
#% 341408
#% 453488
#% 580516
#% 580532
#% 808358
#% 868478
#% 1279324
#% 1289307
#% 1289503
#% 1650358
#! Mechanism design has traditionally focused almost exclusively on the design of truthful mechanisms. There are several drawbacks to this: 1. in certain settings (e.g. voting settings), no desirable strategy proof mechanisms exist; 2. truthful mechanisms are unable to take advantage of the fact that computationally bounded agents may not be able to find the best manipulation, and 3. when designing mechanisms automatically, this approach leads to constrained optimization problems for which current techniques do not scale to very large instances. In this paper, we suggest an entirely different approach: we start with a naïve (manipulable) mechanism, and incrementally make it more strategy proof over a sequence of iterations. We give examples of mechanisms that (variants of) our approach generate, including the VCG mechanism in general settings with payments, and the plurality-with-runoff voting rule. We also provide several basic algorithms for automatically executing our approach in general settings. Finally, we discuss how computationally hard it is for agents to find any remaining beneficial manipulation.

#index 1274956
#* Learning policies for embodied virtual agents through demonstration
#@ Jonathan Dinerstein;Parris K. Egbert;Dan Ventura
#t 2007
#c 11
#% 31686
#% 126926
#% 183499
#% 213469
#% 279381
#% 334536
#% 334544
#% 341661
#% 376266
#% 379208
#% 384911
#% 445389
#% 445555
#% 527859
#% 746674
#% 806240
#% 814218
#% 829022
#% 922845
#% 934582
#! Although many powerful AI and machine learning techniques exist, it remains difficult to quickly create AI for embodied virtual agents that produces visually lifelike behavior. This is important for applications (e.g., games, simulators, interactive displays) where an agent must behave in a manner that appears human-like. We present a novel technique for learning reactive policies that mimic demonstrated human behavior. The user demonstrates the desired behavior by dictating the agent's actions during an interactive animation. Later, when the agent is to behave autonomously, the recorded data is generalized to form a continuous state-to-action mapping. Combined with an appropriate animation algorithm (e.g., motion capture), the learned policies realize stylized and natural-looking agent behavior. We empirically demonstrate the efficacy of our technique for quickly producing policies which result in lifelike virtual agent behavior.

#index 1274957
#* Sharing the road: autonomous vehicles meet human drivers
#@ Kurt Dresner;Peter Stone
#t 2007
#c 11
#% 266254
#% 271067
#% 364575
#% 392811
#% 719141
#% 773254
#% 822616
#% 823903
#! In modern urban settings, automobile traffic and collisions lead to endless frustration as well as significant loss of life, property, and productivity. Recent advances in artificial intelligence suggest that autonomous vehicle navigation may soon be a reality. In previous work, we have demonstrated that a reservation-based approach can efficiently and safely govern interactions of multiple autonomous vehicles at intersections. Such an approach alleviates many traditional problems associated with intersections, in terms of both safety and efficiency. However, the system relies on all vehicles being equipped with the requisite technology-a restriction that would make implementing such a system in the real world extremely difficult. In this paper, we extend this system to allow for incremental deployability. The modified system is able to accommodate traditional human-operated vehicles using existing infrastructure. Furthermore, we show that as the number of autonomous vehicles on the road increases, traffic delays decrease monotonically toward the levels exhibited in our previous work. Finally, we develop a method for switching between various human-usable configurations while the system is running, in order to facilitate an even smoother transition. The work is fully implemented and tested in our custom simulator, and we present detailed experimental results attesting to its effectiveness.

#index 1274958
#* Communicating effectively in resource-constrained multi-agent systems
#@ Partha S. Dutta;Claudia V. Goldman;Nicholas R. Jennings
#t 2007
#c 11
#% 205385
#% 309384
#% 334662
#% 431543
#% 643096
#% 643164
#% 737241
#% 1272045
#% 1272081
#! Agents with partial observability need to share information to achieve decentralised coordination. However, in resource-constrained systems, indiscriminate communication can create performance bottlenecks by consuming valuable bandwidth. Therefore, there is a tradeoff between the utility attained by communication and its cost. Here we address this tradeoff by developing a novel strategy to make communication selective based on information redundancy; ensuring communication only occurs when necessary, while maintaining acceptable coordination. We apply this strategy to a state-of-the-art communication protocol to evaluate its resource saving benefit in a distributed network routing problem. Furthermore, we design a mechanism to adapt its selectivity level to the prevailing resource constraints to ensure further improvements. Empirical studies show our selective strategy achieves relative savings in bandwidth usage of 50-90%, with only a 5-10% relative reduction in coordination effectiveness and the adaptive strategy further improves relative bandwidth usage by up to 10% and also relative coordination effectiveness by up to 12% over the non-adaptive approach.

#index 1274959
#* Holonic multiagent multilevel simulation application to real-time pedestrians simulation in urban environment
#@ Nicolas Gaud;Franck Gechter;Stéphane Galland;Abderrafiâa Koukam
#t 2007
#c 11
#% 203665
#% 214028
#% 286829
#% 334248
#% 378924
#% 418725
#% 434595
#% 474076
#% 532528
#% 589569
#% 955809
#% 1392372
#% 1843237
#! Holonic Multi-Agent Systems (HMAS) are a convenient and relevant way to analyze, model and simulate complex and open systems. Accurately simulate in real-time complex systems, where a great number of entities interact, requires extensive computational resources and often distribution of the simulation over various computers. A possible solution to these issues is multilevel simulation. This kind of simulation aims at dynamically adapting the level of entities' behaviors (microscopic, macroscopic) while being as faithful as possible to the simulated model. We propose a holonic organizational multilevel model for real-time simulation of complex systems by exploiting the hierarchical and distributed properties of the holarchies. To fully exploit this model, we estimate the deviation of simulation accuracy between two adjacent levels through physics-based indicators. These indicators will then allow us to dynamically determine the most suitable level for each entity in the application to maintain the best compromise between simulation accuracy and available resources. Finally a 3D real-time multilevel simulation of pedestrians is presented as well as a discussion of experimental results.

#index 1274960
#* Coordination to avoid starvation of bottleneck agents in a large network system
#@ Rajesh Gautam;Kazuo Miyashita
#t 2007
#c 11
#% 79312
#% 215478
#% 274917
#% 643163
#% 643174
#% 782999
#% 783272
#% 823895
#% 1289503
#! In this paper, we present a multi-agent control method for a large-scale network system. We propose an extension of a token-based coordination technique to improve the tradeoff between two conflicting objectives of the network system: reducing the lead time and increasing throughput. In our system, CABS, information about an agent's urgency of jobs to fulfill demanded throughput and to maintain its utilization is passed from downstream agents in the network so that upstream agents can provide necessary and sufficient jobs to bottleneck agents whose loss of capacity degrades the total system performance. We empirically evaluate CABS performance using a benchmark problem of the semiconductor fabrication process, which is a good example of a large-scale network system.

#index 1274961
#* Sellers competing for buyers in online markets: reserve prices, shill bids, and auction fees
#@ Enrico H. Gerding;Alex Rogers;Rajdeep K. Dash;Nicholas R. Jennings
#t 2007
#c 11
#% 379012
#% 640703
#% 783440
#% 1343871
#! We consider competition between sellers offering similar items in concurrent online auctions through a mediating auction institution, where each seller must set its individual auction parameters (such as the reserve price) in such a way as to attract buyers. We show that in the case of two sellers with asymmetric production costs, there exists a pure Nash equilibrium in which both sellers set reserve prices above their production costs. In addition, we show that, rather than setting a reserve price, a seller can further improve its utility by shill bidding (i.e., bidding as a buyer in its own auction). This shill bidding is undesirable as it introduces inefficiencies within the market. However, through the use of an evolutionary simulation, we extend the analytical results beyond the two-seller case, and we then show that these inefficiencies can be effectively reduced when the mediating auction institution uses auction fees based on the difference between the auction closing and reserve prices.

#index 1274962
#* Complexity of pure equilibria in Bayesian games
#@ Georg Gottlob;Gianluigi Greco;Toni Mancini
#t 2007
#c 11
#% 92632
#% 164839
#% 567883
#% 578708
#% 631052
#% 754142
#% 898290
#% 1279322
#! In this paper we make a comprehensive study of the complexity of the problem of deciding the existence of equilibria in strategic games with incomplete information, in case of pure strategies. In particular, we show that this is NP-complete in general Bayesian Games in Standard Normal Form, and that it becomes PP-hard (and, in fixed-precision scenarios, PP-complete), when the game is represented succinctly in General Normal Form. Suitable restrictions in case of graphical games that make the problem tractable are also discussed.

#index 1274963
#* Characterizing solution concepts in games using knowledge-based programs
#@ Joseph Y. Halpern;Yoram Moses
#t 2007
#c 11
#% 760296
#% 788068
#% 790640
#% 794074
#% 859872
#% 890315
#% 1279254
#! We show how solution concepts in games such as Nash equilibrium, correlated equilibrium, rationalizability, and sequential equilibrium can be given a uniform definition in terms of knowledge-based programs. Intuitively, all solution concepts are implementations of two knowledge-based programs, one appropriate for games represented in normal form, the other for games represented in extensive form. These knowledge-based programs can be viewed as embodying rationality. The representation works even if (a) information sets do not capture an agent's knowledge, (b) uncertainty is not represented by probability, or (c) the underlying game is not common knowledge.

#index 1274964
#* Hybrid elections broaden complexity-theoretic resistance to control
#@ Edith Hemaspaandra;Lane A. Hemaspaandra;Jörg Rothe
#t 2007
#c 11
#% 330769
#% 529806
#% 578703
#% 631051
#% 654466
#% 1250608
#% 1269374
#% 1279324
#% 1698228
#! Electoral control refers to attempts by an election's organizer ("the chair") to influence the outcome by adding/deleting/partitioning voters or candidates. The groundbreaking work of Bartholdi, Tovey, and Trick [1992] on (constructive) control proposes computational complexity as a means of resisting control attempts: Look for election systems where the chair's task in seeking control is itself computationally infeasible. We introduce and study amethod of combining two or more candidate-anonymous election schemes in such a way that the combined scheme possesses all the resistances to control (i.e., all the NP-hardnesses of control) possessed by any of its constituents: It combines their strengths. Fromthis and new resistance constructions, we prove for the first time that there exists an election scheme that is resistant to all twenty standard types of electoral control.

#index 1274965
#* Truthful risk-managed combinatorial auctions
#@ Alan Holland;Barry O'Sullivan
#t 2007
#c 11
#% 267752
#% 314944
#% 413867
#% 578713
#% 656791
#% 808377
#% 1269418
#! Given a winning-bid withdrawal in a combinatorial auction, finding an alternative repair solution of adequate revenue without causing undue disturbance to the remaining winning bids in the original solution may be difficult or even impossible. This "bid-takers exposure problem" may be preemptively addressed by finding a solution that is robust to winning-bid withdrawal. We introduce the concept of monotonicity-in-expectation. We provide impossibility results concerning truthful mechanisms for robust solutions with bounded social-welfare losses in which the bid-taker cannot rescind items from winning bidders to repair a solution. We also show that this result extends to combinatorial auctions that include a form of leveled-commitment contract. However, we present a positive result regarding truthfulness for combinatorial auctions in a restricted setting that comprises a computationally efficient allocation algorithm that seeks to maximize expected social welfare.

#index 1274966
#* Adaptation of organizational models for multi-agent systems based on max flow networks
#@ Mark Hoogendoorn
#t 2007
#c 11
#% 288780
#% 636363
#% 931240
#% 936546
#% 1230540
#! Organizational models within multi-agent systems literature are of a static nature. Depending upon circumstances adaptation of the organizational model can be essential to ensure a continuous successful function of the system. This paper presents an approach based on max flow networks to dynamically adapt organizational models to environmental fluctuation. First, a formal mapping between a well-known organizational modeling framework and max flow networks is presented. Having such a mapping maintains the insightful structure of an organizational model whereas specifying efficient adaptation algorithms based on max flow networks can be done as well. Thereafter two adaptation mechanisms based on max flow networks are introduced each being appropriate for different environmental characteristics.

#index 1274967
#* Collaborative inductive logic programming for path planning
#@ Jian Huang;Adrian R. Pearce
#t 2007
#c 11
#% 379347
#% 398861
#% 418731
#% 484179
#% 489309
#% 794074
#% 916482
#% 1250612
#! In distributed systems, learning does not necessarily involve the participation of agents directly in the inductive process itself. Instead, many systems frequently employ multiple instances of induction separately. In this paper, we develop and evaluate a new approach for learning in distributed systems that tightly integrates processes of induction between agents, based on inductive logic programming techniques. The paper's main contribution is the integration of an epistemic approach to reasoning about knowledge with inverse entailment during induction. The new approach facilitates a systematic approach to the sharing of knowledge and invention of predicates only when required. We illustrate the approach using the well-known path planning problem and compare results empirically to (multiple instances of) single agent-based induction over varying distributions of data. Given a chosen path planning algorithm, our algorithm enables agents to combine their local knowledge in an effective way to avoid central control while significantly reducing communication costs.

#index 1274968
#* Mechanism design with partial revelation
#@ Nathanaël Hyafil;Craig Boutilier
#t 2007
#c 11
#% 314944
#% 413867
#% 453488
#% 460806
#% 578711
#% 723935
#% 788068
#% 818584
#% 819415
#% 830089
#% 868452
#% 879183
#% 959102
#% 1250613
#% 1650358
#! Classic direct mechanisms require full utility revelation from agents, which can be very difficult in practical multi-attribute settings. In this work, we study partial revelation within the framework of one-shot mechanisms. Each agent's type space is partitioned into a finite set of partial types and agents (should) report the partial type within which their full type lies. A classic result implies that implementation in dominant strategies is impossible in this model. We first show that a relaxation to Bayes-Nash implementation does not circumvent the problem. We then propose a class of partial revelation mechanisms that achieve approximate dominant strategy implementation, and describe a computationally tractable algorithm for myopically optimizing the partitioning of each agent's type space to reduce manipulability and social welfare loss. This allows for the automated design of one-shot partial revelation mechanisms with worst-case guarantees on both manipulability and efficiency.

#index 1274969
#* Augmented experiment: participatory design with multiagent simulation
#@ Toru Ishida;Yuu Nakajima;Yohei Murakami;Hideyuki Nakanishi
#t 2007
#c 11
#% 235072
#% 271092
#% 296865
#% 330272
#% 349998
#% 438672
#% 567491
#% 581034
#% 643125
#% 731421
#% 751860
#% 819582
#% 823870
#% 830735
#% 890200
#% 1269379
#% 1393838
#% 1704148
#! To test large scale socially embedded systems, this paper proposes a multiagent-based participatory design that consists of two steps; 1) participatory simulation, where scenario-guided agents and human-controlled avatars coexist in a shared virtual space and jointly perform simulations, and the extension of the participatory simulation into the 2) augmented experiment, where an experiment is performed in real space by human subjects enhanced by a large scale multiagent simulation. The augmented experiment, proposed in this paper, consist of 1) various sensors to collect the real world activities of human subjects and project them into the virtual space, 2) multiagent simulations to simulate human activities in the virtual space, and 3) communication channels to inform simulation status to human subjects in the real space. To create agent and interaction models incrementally from the participatory design process, we propose the participatory design loop that uses deductive machine learning technologies. Indoor and outdoor augmented experiments have been actually conducted in the city of Kyoto. Both experiments were intended to test new disaster evacuation systems based on mobile phones.

#index 1274970
#* Multi-issue negotiation protocol for agents: exploring nonlinear utility spaces
#@ Takayuki Ito;Hiromitsu Hattori;Mark Klein
#t 2007
#c 11
#% 378898
#% 723619
#% 773328
#% 773331
#% 791578
#% 823973
#% 851675
#! Multi-issue negotiation protocols have been studied widely and represent a promising field since most negotiation problems in the real world involve interdependent multiple issues. The vast majority of this work has assumed that negotiation issues are independent, so agents can aggregate the utilities of the issue values by simple summation, producing linear utility functions. In the real world, however, such aggregations are often unrealistic. We cannot, for example, just add up the value of car's carburetor and the value of car's engine when engineers negotiate over the design a car. These value of these choices are interdependent, resulting in nonlinear utility functions. In this paper, we address this important gap in current negotiation techniques. We propose a negotiation protocol where agents employ adjusted sampling to generate proposals, and a bidding-based mechanism is used to find social-welfare maximizing deals. Our experimental results show that our method substantially outperforms existing methods in large non-linear utility spaces like those found in real world contexts.

#index 1274971
#* A model for collective strategy diffusion in agent social law evolution
#@ Yichuan Jiang;Toru Ishida
#t 2007
#c 11
#% 181622
#% 233134
#% 233136
#% 303942
#% 431570
#% 431575
#% 641979
#% 958129
#% 1289654
#% 1345725
#! Social law is perceived as evolving through the competition of individual social strategies held by the agents. A strategy with strong authority, accepted by many agents, will tend to diffuse to the remaining agents. The authority of a social strategy is determined by not only the number of but also the collective social positions of its overlaid agents. This paper presents a novel collective strategy diffusion model in agent social law evolution. In the model, social strategies that have strong authority are impressed on the other agents. The agents will accept (partially or in full) or reject them based on their own social strategies and social positions. The diffusion of social strategies proceeds in a series of steps and the final result depends on the interplay between the forces driving diffusion and the counteracting forces.

#index 1274972
#* Sequential bundle-bid single-sale auction algorithms for decentralized control
#@ Sven Koenig;Craig Tovey;Xiaoming Zheng;Ilgaz Sungur
#t 2007
#c 11
#% 496251
#% 529167
#% 704123
#% 882285
#! We study auction-like algorithms for the distributed allocation of tasks to cooperating agents. To reduce the team cost of sequential single-item auction algorithms, we generalize them to assign more than one additional task during each round, which increases their similarity to combinatorial auction algorithms. We show that, for a given number of additional tasks to be assigned during each round, every agent needs to submit only a constant number of bids per round and the runtime of winner determination is linear in the number of agents. The communication and winner determination costs do not depend on the number of tasks and thus scale to a large number of tasks for small bundle sizes. We then demonstrate empirically that the team cost of sequential bundle-bid single-sale (= single-item) auction algorithms can be substantially smaller than that without bundles for multi-agent routing problems with capacity constraints.

#index 1274973
#* Vote and aggregation in combinatorial domains with structured preferences
#@ Jérôme Lang
#t 2007
#c 11
#% 767712
#% 1250233
#% 1272026
#% 1272103
#! In many real-world collective decision problems, the set of alternatives is a Cartesian product of finite value domains for each of a given set of variables. The prohibitive size of such domains makes it practically impossible to represent preference relations explicitly. Now, AI has been developing languages for representing preferences on such domains in a succinct way, exploiting structural properties such as conditional preferential independence. Here we reconsider voting and aggregation rules in the case where voters' preferences have a common preferential independence structure, and address the decompossition a voting rule or an aggregation function following a linear order over variables.

#index 1274974
#* Winner determination in sequential majority voting
#@ J. Lang;M. S. Pini;F. Rossi;K. B. Venable;T. Walsh
#t 2007
#c 11
#% 70370
#% 289348
#% 578703
#% 578715
#% 1279324
#! Preferences can be aggregated using voting rules. We consider here the family of rules which perform a sequence of pairwise majority comparisons between two candidates. The winner thus depends on the chosen sequence of comparisons, which can be represented by a binary tree. We address the difficulty of computing candidates that win for some trees, and then introduce and study the notion of fair winner, i.e. candidates who win in a balanced tree. We then consider the situation where we lack complete informations about preferences, and determine the computational complexity of computing winners in this case.

#index 1274975
#* RoxyBot-06: an (SAA)2TAC travel agent
#@ Seong Jae Lee;Amy Greenwald;Victor Naroditskiy
#t 2007
#c 11
#% 643137
#% 786984
#% 788061
#% 810182
#% 1271997
#% 1272022
#! In this paper, we describe our entrant in the travel division of the 2006 Trading Agent Competition (TAC). At a high level, the design of many successful autonomous trading agents can be summarized as follows: (i) price prediction: build a model of market prices; and (ii) optimization: solve for an approximately optimal set of bids, given this model. To predict, we simulate simultaneous ascending auctions. To optimize, we apply the sample average approximation method. Both of these procedures might naturally be abbreviated SAA; hence the title of this paper. Our agent dominated the preliminary and seeding rounds of TAC Travel in 2006, and emerged as champion in the finals in a photo finish.

#index 1274976
#* Automatic verification of knowledge and time with NuSMV
#@ Alessio Lomuscio;Charles Pecheur;Franco Raimondi
#t 2007
#c 11
#% 46786
#% 116625
#% 188086
#% 234819
#% 297770
#% 379079
#% 380578
#% 480681
#% 542265
#% 643130
#% 659831
#% 717089
#% 766972
#% 947931
#! We show that the problem ofmodel checking multi-dimensional modal logics can be reduced to the problem of model checking ARCTL, an extension of the temporal logic CTL with action labels and operators to reason about actions. In particular, we introduce a methodology for model checking a temporal-epistemic logic by building upon an extension of the model checker NuSMV that enables the verification of ARCTL. We briefly present the implementation and report experimental results for the verification of a typical security protocol involving temporal-epistemic properties: the protocol of the dining cryptographers.

#index 1274977
#* An energy-efficient, multi-agent sensor network for detecting diffuse events
#@ Rónán Mac Ruairí;Mark T. Keane
#t 2007
#c 11
#% 309433
#% 401221
#% 719917
#% 720270
#% 755707
#% 772633
#% 797877
#% 821389
#% 842054
#% 863307
#% 1831268
#! Monitoring a diffuse event with a wireless sensor network differs from well studied applications such as target tracking and habitat monitoring and therefore we suggest that new approaches are needed. In this paper we propose a novel low power technique based on a multiple agent framework. We show how a set of simple rules can produce complex behavior that encompasses event characterization and data routing. We demonstrate the approach and examine its accuracy and scalability using a simulated gaseous plume monitoring scenario.

#index 1274978
#* A multi-agent medical system for Indian rural infant and child care
#@ Vijay Kumar Mago;M. Syamala Devi
#t 2007
#c 11
#% 590192
#% 590212
#% 766773
#% 1778553
#% 1778786
#! In this paper, a Multi-agent System (MAS) is presented for providing clinical decision support to healthcare practitioners in rural or remote areas of India for young infants or children up to the age of 5 years. The government is unable to appoint child specialists in rural areas because of inadequate number of available pediatricians. It leads to a high Infant Mortality Rate (IMR). In such a scenario, software agents provide a realistic solution. The agent-based prototype has been developed that involves a knowledge component called an Intelligent Pediatric Assistant (IPA); and User Agents (UA) along with their Graphical User Interfaces (GUI). The GUI of UA provides the interface to the healthcare practitioner for submitting sign-symptoms and displaying the expert opinion as suggested by IPA. Depending upon the observations, the IPA decides the diagnosis and the treatment plan. The UA and IPA form client-server architecture for knowledge sharing.

#index 1274979
#* Infeasibility certificates and the complexity of the core in coalitional games
#@ Enrico Malizia;Luigi Palopoli;Francesco Scarcello
#t 2007
#c 11
#% 165011
#% 338466
#% 808378
#% 873944
#% 1250153
#! This paper characterizes the complexity of the core in coalitional games. There are different proposals for representing coalitional games in a compact way, where the worths of coalitions may be computed in polynomial time. In all those frameworks, it was shown that core non-emptiness is a co-NP-hard problem. However, for the most general of them, it was left as an open problem whether it belongs to co-NP or it actually is an harder problem. We solve this open problem in a positive way; indeed, we are able to show that, for the case of transferable payoffs, the problem belongs to co-NP for any compact representation of the game where the worths of coalitions may be computed in polynomial time (also, non-deterministic polynomial time), encompassing all previous proposals of this kind. This is proved by showing that games with empty cores have small infeasibility certificates. The picture is completed by looking at coalitional games with non-transferable payoffs. We propose a compact representation based on marginal contribution nets. Also in this case, we are able to settle the precise complexity of core non-emptiness, which turns out to be Σ2p-complete.

#index 1274980
#* Providing a recommended trading agent to a population: a novel approach
#@ Efrat Manisterski;Ron Katz;Sarit Kraus
#t 2007
#c 11
#% 378909
#% 378939
#% 773284
#% 801776
#% 1250154
#% 1784511
#! This paper presents a novel approach for providing automated trading agents to a population, focusing on bilateral negotiation with unenforceable agreements. A new type of agents, called semicooperative (SC) agents is proposed for this environment. When these agents negotiate with each other they reach a pareto-optimal solution that is mutually beneficial. Through extensive experiments we demonstrate the superiority of providing such agents for humans over supplying equilibrium agents or letting people design their own agents. These results are based on our observation that most people do not modify SC agents even though they are not in equilibrium. Our findings introduce a new factor -human response to provided agents - that should be taken into consideration when developing agents that are provided to a population.

#index 1274981
#* Enhancing MAS cooperative search through coalition partitioning
#@ Efrat Manisterski;David Sarne;Sarit Kraus
#t 2007
#c 11
#% 253310
#% 284645
#% 334648
#% 431562
#% 643178
#% 659838
#% 725207
#% 890234
#% 1250617
#% 1269384
#! In this paper we present new search strategies for agents with diverse preferences searching cooperatively in complex environments with search costs. The uniqueness of our proposed mechanism is in the integration of the coalition's ability to partition itself into sub-coalitions, which continue the search autonomously, into the search strategy (a capability that was neglected in earlier cooperative search models). As we show throughout the paper, this strategy is always favorable in comparison to currently known cooperative and autonomous search techniques: it has the potential to significantly improve the searchers' performance in various environments and in any case guarantees reaching at least as good a performance as that of other known methods. Furthermore, for many common environments we manage to significantly eliminate the consequential added computational complexity associated with the partitioning option, by introducing innovative efficient algorithms for extracting the coalition's optimal search strategy. We illustrate the advantages of the proposed model over currently known cooperative and individual search techniques, using an environment based on authentic settings.

#index 1274982
#* Multipotential games
#@ Dov Monderer
#t 2007
#c 11
#% 527993
#% 567883
#% 578708
#% 788040
#% 1279323
#% 1289289
#! We introduce and analyze q-potential games and q- congestion games, where q is a positive integer. A 1-potential (congestion) game is a potential (congestion) game. We show that a game is a q-potential game if and only if it is (up to an isomorphism) a q-congestion game. As a corollary, we derive the result that every game in strategic form is a q- congestion game for some q. It is further shown that every q-congestion game is isomorphic to a q- network game, where the network environment is defined by a directed graph with one origin and one destination. Finally we discuss our main agenda: The issue of representing q-congestion games with non-negative cost functions by congestion models with non-negative and monotonic facility cost functions. We provide some initial results in this regard.

#index 1274983
#* Multi-agent system that attains longevity via death
#@ Megan Olsen;Hava Siegelmann
#t 2007
#c 11
#% 125529
#% 314942
#% 379037
#% 581038
#% 804916
#% 840585
#% 1013352
#% 1478730
#! We propose a novel approach to self-regenerating systems which require continuous operation, such as security surveillance. For that aim we introduce HADES, a self-regenerating cooperative multi-agent system with local monitoring. When agents of HADES find local failures they repair them. However, in extreme cases repair may not be possible and irregular aggressive agents will multiply. These irregular agents may use all of the system's resources and thus take over the system. To optimize system longevity, we identify protocols for killing these irregular agents. Our primary contribution is a double communication protocol of alert and death signals among the agents, making the multi-agent system robust to failures and attacks.

#index 1274984
#* Argumentation based contract monitoring in uncertain domains
#@ Nir Oren;Timothy J. Norman;Alun Preece
#t 2007
#c 11
#% 198464
#% 856790
#% 894061
#% 939490
#% 1388092
#% 1675015
#! Few existing argumentation frameworks are designed to deal with probabilistic knowledge, and none are designed to represent possibilistic knowledge, making them unsuitable for many real world domains. In this paper we present a subjective logic based framework for argumentation which overcomes this limitation. Reasoning about the state of a literal in this framework can be done in polynomial time. A dialogue game making use of the framework and a utility based heuristic for playing the dialogue game are also presented. We then show how these components can be applied to contract monitoring. The dialogues that emerge bear some similarity to the dialogues that occur when humans argue about contracts, and our approach is highly suited to complex, partially observable domains with fallible sensors where determining environment state cannot be done for free.

#index 1274985
#* Dynamic verification of trust in distributed open systems
#@ Nardine Osman;David Robertson
#t 2007
#c 11
#% 1791
#% 172951
#% 369768
#% 613819
#% 664665
#% 804916
#% 1734846
#! In open and distributed systems, agents must engage in interactions of which they have no previous experience. Deontic models are widely used to describe aspects of permission, obligation, and trust anticipated by such agents, but no practical mechanism has been developed for testing deontic trust specifications against models of multi-agent interactions. This paper describes a way of doing this; an implementation of it via model checking; and some preliminary results on a realistic example.

#index 1274986
#* Quality guarantees on k-optimal solutions for distributed constraint optimization problems
#@ Jonathan P. Pearce;Milind Tambe
#t 2007
#c 11
#% 757953
#% 773232
#% 855910
#% 855913
#% 890289
#% 1269380
#% 1289393
#! A distributed constraint optimization problem (DCOP) is a formalism that captures the rewards and costs of local interactions within a team of agents. Because complete algorithms to solve DCOPs are unsuitable for some dynamic or anytime domains, researchers have explored incomplete DCOP algorithms that result in locally optimal solutions. One type of categorization of such algorithms, and the solutions they produce, is k- optimality; a k-optimal solution is one that cannot be improved by any deviation by k or fewer agents. This paper presents the first known guarantees on solution quality for k-optimal solutions. The guarantees are independent of the costs and rewards in the DCOP, and once computed can be used for any DCOP of a given constraint graph structure.

#index 1274987
#* MB-DPOP: a new memory-bounded algorithm for distributed optimization
#@ Adrian Petcu;Boi Faltings
#t 2007
#c 11
#% 2028
#% 329486
#% 420720
#% 644201
#% 773217
#% 830716
#% 855913
#% 890434
#% 1272107
#% 1289387
#% 1289393
#! In distributed combinatorial optimization problems, dynamic programming algorithms like DPOP ([Petcu and Faltings, 2005]) require only a linear number of messages, thus generating low communication overheads. However, DPOP's memory requirements are exponential in the induced width of the constraint graph, which may be prohibitive for problems with large width. We present MB-DPOP, a new hybrid algorithm that can operate with bounded memory. In areas of low width, MB-DPOP operates like standard DPOP (linear number of messages). Areas of high width are explored with bounded propagations using the idea of cycle-cuts [Dechter, 2003]. We introduce novel DFS-based mechanisms for determining the cycle-cutset, and for grouping cycle-cut nodes into clusters. We use caching ([Darwiche, 2001]) between clusters to reduce the complexity to exponential in the largest number of cycle cuts in a single cluster. We compare MB-DPOP with ADOPT [Modi et al., 2005], the current state of the art in distributed search with bounded memory. MB-DPOP consistently outperforms ADOPT on 3 problem domains, with respect to 3 metrics, providing speedups of up to 5 orders of magnitude.

#index 1274988
#* DiPRA: distributed practical reasoning architecture
#@ Giovanni Pezzulo;Gianguglielmo Calvi;Cristiano Castelfranchi
#t 2007
#c 11
#% 5561
#% 194658
#! DiPRA (Distributed Practical Reasoning Architecture) implements the main principles of practical reasoning via the distributed action selection paradigm. We introduce and motivate the underlying theoretical and computational peculiarities of DiPRA and we describe its components, also providing as a case study a guards-and-thieves task.

#index 1274989
#* Incompleteness and incomparability in preference aggregation
#@ M. S. Pini;F. Rossi;K. B. Venable;T. Walsh
#t 2007
#c 11
#% 578703
#% 578715
#% 767712
#% 1250233
#! We consider how to combine the preferences of multiple agents despite the presence of incompleteness and incomparability in their preference orderings. An agent's preference ordering may be incomplete because, for example, there is an ongoing preference elicitation process. It may also contain incomparability as this is useful, for example, in multi-criteria scenarios. We focus on the problem of computing the possible and necessary winners, that is, those outcomes which can be or always are the most preferred for the agents. Possible and necessary winners are useful in many scenarios including preference elicitation. First we show that computing the sets of possible and necessary winners is in general a difficult problem as is providing a good approximation of such sets. Then we identify general properties of the preference aggregation function which are sufficient for such sets to be computed in polynomial time. Finally, we show how possible and necessary winners can be used to focus preference elicitation.

#index 1274990
#* Gossip-based aggregation of trust in decentralized reputation systems
#@ Ariel D. Procaccia;Yoram Bachrach;Jeffrey S. Rosenschein
#t 2007
#c 11
#% 35764
#% 342695
#% 348160
#% 414383
#% 580555
#% 656792
#% 723903
#% 805881
#! Decentralized Reputation Systems have recently emerged as a prominent method of establishing trust among self-interested agents in online environments. A key issue is the efficient aggregation of data in the system; several approaches have been proposed, but they are plagued by major shortcomings. We put forward a novel, decentralized data management scheme grounded in gossip-based algorithms. Rumor mongering is known to possess algorithmic advantages, and indeed, our framework inherits many of their salient features: scalability, robustness, globality, and simplicity. We also demonstrate that our scheme motivates agents to maintain a sparkling clean reputation, and is inherently impervious to certain kinds of attacks.

#index 1274991
#* Multi-winner elections: complexity of manipulation, control, and winner-determination
#@ Ariel D. Procaccia;Jeffrey S. Rosenschein;Aviv Zohar
#t 2007
#c 11
#% 256685
#% 271176
#% 417561
#% 578703
#% 631051
#% 890278
#! Although recent years have seen a surge of interest in the computational aspects of social choice, no attention has previously been devoted to elections with multiple winners, e.g., elections of an assembly or committee. In this paper, we fully characterize the worst-case complexity of manipulation and control in the context of four prominent multi-winner voting systems. Additionally, we show that several tailor-made multi-winner voting schemes are impractical, as it is NP-hard to select the winners in these schemes.

#index 1274992
#* Opponent modeling in scrabble
#@ Mark Richards;Eyal Amir
#t 2007
#c 11
#% 348584
#% 348585
#% 495931
#% 576214
#% 646958
#! Computers have already eclipsed the level of human play in competitive Scrabble, but there remains room for improvement. In particular, there is much to be gained by incorporating information about the opponent's tiles into the decision-making process. In this work, we quantify the value of knowing what letters the opponent has. We use observations from previous plays to predict what tiles our opponent may hold and then use this information to guide our play. Our model of the oppoent, based on Bayes' theorem, sacrifices accuracy for simplicity and ease of computation. But even with this simplified model, we show significant improvement in play over an existing Scrabble program. These empirical results suggest that this simple approximation may serve as a suitable substitute for the intractable partially observable Markov decision process. Although this work focuses on computer-vs-computer Scrabble play, the tools developed can be of great use in training humans to play against other humans.

#index 1274993
#* Routing mediators
#@ Ola Rozenfeld;Moshe Tennenholtz
#t 2007
#c 11
#% 338466
#% 593991
#% 1250616
#% 1272023
#% 1656760
#! We introduce a general study of routing mediators. A routing mediator can act in a given multi-agent encounter on behalf of the agents that give it the right of play. Routing mediators differ from one another according to the information they may have. Our study concentrates on the use of routing mediators in order to reach correlated strong equilibrium, a multi-agent behavior which is stable against deviations by coalitions. We study the relationships between the power of different routing mediators in establishing correlated strong equilibrium. Surprisingly, our main result shows a natural class of routing mediators that allow to implement fair and efficient outcomes as a correlated super-strong equilibrium in a very wide class of games.

#index 1274994
#* An efficient protocol for negotiation over multiple indivisible resources
#@ Sabyasachi Saha;Sandip Sen
#t 2007
#c 11
#% 643101
#% 1272101
#! We study the problem of autonomous agents negotiating the allocation of multiple indivisible resources. It is difficult to reach optimal outcomes in bilateral or multi-lateral negotiations over multiple resources when the agents' preferences for the resources are not common knowledge. Self-interested agents often end up negotiating inefficient agreements in such situations. We present a protocol for negotiation over multiple indivisible resources which can be used by rational agents to reach efficient outcomes. Our proposed protocol enables the negotiating agents to identify efficient solutions using systematic distributed search that visits only a subspace of the whole solution space.

#index 1274995
#* Automated design of multistage mechanisms
#@ Tuomas Sandholm;Vincent Conitzer;Craig Boutilier
#t 2007
#c 11
#% 170378
#% 238182
#% 420084
#% 460806
#% 578715
#% 754178
#% 781210
#% 788099
#% 868465
#% 890383
#% 912341
#% 1250120
#% 1250613
#% 1289498
#% 1650358
#! Mechanism design is the study of preference aggregation protocols that work well in the face of self-interested agents. We present the first general-purpose techniques for automatically designing multistage mechanisms. These can reduce elicitation burden by only querying agents for information that is relevant given their answers to previous queries. We first show how to turn a given (e.g., automatically designed using constrained optimization techniques) single-stage mechanism into the most efficient corresponding multistage mechanism given a specified elicitation tree. We then present greedy and dynamic programming (DP) algorithms that determine the elicitation tree (optimal in the DP case). Next, we show how the query savings inherent in the multistage model can be used to design the underlying single-stage mechanism to maximally take advantage of this approach. Finally, we present negative results on the design of multistage mechanisms that do not correspond to dominant-strategy single-stage mechanisms: an optimal multistage mechanism in general has to randomize over queries to hide information from the agents.

#index 1274996
#* Emergence of norms through social learning
#@ Sandip Sen;Stéphane Airiau
#t 2007
#c 11
#% 124691
#% 348821
#% 430239
#% 529342
#% 724002
#% 830736
#% 842022
#% 859846
#! Behavioral norms are key ingredients that allow agent coordination where societal laws do not sufficiently constrain agent behaviors. Whereas social laws need to be enforced in a top-down manner, norms evolve in a bottom-up manner and are typically more self-enforcing. While effective norms can significantly enhance performance of individual agents and agent societies, there has been little work in multiagent systems on the formation of social norms. We propose a model that supports the emergence of social norms via learning from interaction experiences. In our model, individual agents repeatedly interact with other agents in the society over instances of a given scenario. Each interaction is framed as a stage game. An agent learns its policy to play the game over repeated interactions with multiple agents. We term this mode of learning social learning, which is distinct from an agent learning from repeated interactions against the same player. We are particularly interested in situations where multiple action combinations yield the same optimal payoff. The key research question is to find out if the entire population learns to converge to a consistent norm. In addition to studying such emergence of social norms among homogeneous learners via social learning, we study the effects of heterogeneous learners, population size, multiple social groups, etc.

#index 1274997
#* Information-based agency
#@ Carles Sierra;John Debenham
#t 2007
#c 11
#% 233134
#% 641963
#% 739899
#% 773270
#% 890398
#! Successful negotiators look beyond a purely utilitarian view. We propose a new agent architecture that integrates the utilitarian, information, and semantic views allowing the definition of strategies that take these three dimensions into account. Information-based agency values the information in dialogues in the context of a communication language based on a structured ontology and on the notion of commitment. This abstraction unifies measures such as trust, reputation, and reliability in a single framework.

#index 1274998
#* Formalizing communication protocols for multiagent systems
#@ Munindar P. Singh
#t 2007
#c 11
#% 101943
#% 557553
#% 643157
#% 890423
#% 1279310
#% 1704221
#! Protocols structure interactions among communicating agents. A commitment machine models a protocol in terms of how the commitments of the various parties evolve. Commitment machines thus support flexible behavior while providing a meaningful basis for compliance with a protocol. Unfortunately, current formulations of commitment machines are not sufficiently general or rigorous. This paper develops generalized commitment machines (GCMs) whose elements are described generically in terms of inferences, and whose computations are infinite (thus supporting nonterminating protocols). This paper shows how a GCM can be understood as a nondeterministic Büchi automaton (BA), whose acceptance condition accommodates infinite as well as finite executions. Deterministic BA are readily emulated by conventional software, e.g., a script running in a Web browser. In general, nondeterministic BA may have no equivalent deterministic BA. However, under well-motivated technical conditions, a GCM yields a deterministic Büchi automaton that, although not necessarily equivalent in automata theory terms, is sound (produces only computations allowed by the GCM) and complete (produces the effect of any computation allowed by the GCM).

#index 1274999
#* Control of agent swarms using generalized centroidal cyclic pursuit laws
#@ A. Sinha;D. Ghose
#t 2007
#c 11
#% 3084
#! One of the major tasks in swarm intelligence is to design decentralized but homogenoeus strategies to enable controlling the behaviour of swarms of agents. It has been shown in the literature that the point of convergence and motion of a swarm of autonomous mobile agents can be controlled by using cyclic pursuit laws. In cyclic pursuit, there exists a predefined cyclic connection between agents and each agent pursues the next agent in the cycle. In this paper we generalize this idea to a case where an agent pursues a point which is the weighted average of the positions of the remaining agents. This point correspond to a particular pursuit sequence. Using this concept of centroidal cyclic pursuit, the behavior of the agents is analyzed such that, by suitably selecting the agents' gain, the rendezvous point of the agents can be controlled, directed linear motion of the agents can be achieved, and the trajectories of the agents can be changed by switching between the pursuit sequences keeping some of the behaviors of the agents invariant. Simulation experiments are given to support the analytical proofs.

#index 1275000
#* On modeling multiagent task scheduling as a distributed constraint optimization problem
#@ Evan A. Sultanik;Pragnesh Jay Modi;William C. Regli
#t 2007
#c 11
#% 215489
#% 267574
#% 420008
#% 773232
#% 823973
#% 824063
#% 855913
#% 1289393
#! This paper investigates how to represent and solve multiagent task scheduling as a Distributed Constraint Optimization Problem (DCOP). Recently multiagent researchers have adopted the C_TÆMS language as a standard for multiagent task scheduling. We contribute an automated mapping that transforms C_TÆMS into a DCOP. Further, we propose a set of representational compromises for C_TÆMS that allow existing distributed algorithms for DCOP to be immediately brought to bear on C_TÆMS problems. Next, we demonstrate a key advantage of a constraint based representation is the ability to leverage the representation to do efficient solving. We contribute a set of pre-processing algorithms that leverage existing constraint propagation techniques to do variable domain pruning on the DCOP. We show that these algorithms can result in 96% reduction in state space size for a given set of C_TÆMS problems. Finally, we demonstrate up to a 60% increase in the ability to optimally solve C_TÆMS problems in a reasonable amount of time and in a distributed manner as a result of applying our mapping and domain pruning algorithms.

#index 1275001
#* Emotions as durative dynamic state for action selection
#@ Emmanuel Tanguy;Philip Willis;Joanna J. Bryson
#t 2007
#c 11
#% 108745
#% 238395
#% 589651
#% 773209
#% 773218
#% 773318
#% 814302
#% 1478731
#! This paper presents a representation system for maintaining interacting durative states to replicate realistic emotional control. Our model, the Dynamic Emotion Representation (DER) integrates emotional responses and keeps track of emotion intensities changing over time. The developer can specify an interacting network of emotional states with appropriate onsets, sustains and decays. The levels of these states can be used as input for action selection, including emotional expression. We present both a general representational framework and a specific instance of a DER network constructed for a virtual character. The character's DER uses three types of emotional state as classified by duration timescales, in keeping with current emotional theory. The system is demonstrated with a virtual actor.

#index 1275002
#* Generating Bayes-Nash equilibria to design autonomous trading agents
#@ Ioannis A. Vetsikas;Nicholas R. Jennings;Bart Selman
#t 2007
#c 11
#% 341923
#% 558918
#% 643138
#% 859387
#% 946097
#% 1269438
#% 1274948
#! This paper presents a methodology for designing trading agents for complex games. We compute, for the first time, Bayes-Nash equilibria for first-price single-unit auctions and mth-price multiunit auctions, when the auction has a set of possible closing times, one of which is chosen randomly for the auction to end at. To evaluate this approach we used our analysis to generate strategies for the International Trading Agent Competition. One of these was evaluated as the best overall and was subsequently used very successfully by our agent WhiteBear in the 2005 competition.

#index 1275003
#* Formal trust model for multiagent systems
#@ Yonghong Wang;Munindar P. Singh
#t 2007
#c 11
#% 378981
#% 397991
#% 507535
#% 607998
#% 636340
#% 823908
#% 823966
#% 878367
#% 1250382
#! Trust should be substantially based on evidence. Further, a key challenge for multiagent systems is how to determine trust based on reports from multiple sources, who might themselves be trusted to varying degrees. Hence an ability to combine evidence-based trust reports in a manner that discounts for imperfect trust in the reporting agents is crucial for multiagent systems. This paper understands trust in terms of belief and certainty: A's trust in B is reflected in the strength of A's belief that B is trustworthy. This paper formulates certainty in terms of evidence based on a statistical measure defined over a probability distribution of the probability of positive outcomes. This novel definition supports important mathematical properties, including (1) certainty increases as conflict increases provided the amount of evidence is unchanged, and (2) certainty increases as the amount of evidence increases provided conflict is unchanged. Moreover, despite a more subtle definition than previous approaches, this paper (3) establishes a bijection between evidence and trust spaces, enabling robust combination of trust reports and (4) provides an efficient algorithm for computing this bijection.

#index 1275004
#* Towards runtime behavior adaptation for embodied characters
#@ Peng Zang;Manish Mehta;Michael Mateas;Ashwin Ram
#t 2007
#c 11
#% 124601
#% 266387
#% 271075
#% 705548
#! Typically, autonomous believable agents are implemented using static, hand-authored reactive behaviors or scripts. This hand-authoring allows designers to craft expressive behavior for characters, but can lead to excessive authorial burden, as well as result in characters that are brittle to changing world dynamics. In this paper, we present an approach for the runtime adaptation of reactive behaviors for autonomous believable characters. Extending transformational planning, our system allows autonomous characters to monitor and reason about their behavior execution and to use this reasoning to dynamically rewrite their behaviors. In our evaluation, we transplant two characters in a sample tag game from the original world they were written for into a different one, resulting in behavior that violates the author intended personality. The reasoning layer successfully adapts the character's behaviors so as to bring its long-term behavior back into agreement with its personality.

#index 1275005
#* Using focal point learning to improve tactic coordination in human-machine interactions
#@ Inon Zuckerman;Sarit Kraus;Jeffrey S. Rosenschein
#t 2007
#c 11
#% 136350
#% 417720
#% 799730
#% 890299
#! We consider an automated agent that needs to coordinate with a human partner when communication between them is not possible or is undesirable (tactic coordination games). Specifically, we examine situations where an agent and human attempt to coordinate their choices among several alternatives with equivalent utilities. We use machine learning algorithms to help the agent predict human choices in these tactic coordination domains. Learning to classify general human choices, however, is very difficult. Nevertheless, humans are often able to coordinate with one another in communication-free games, by using focal points, "prominent" solutions to coordination problems. We integrate focal points into the machine learning process, by transforming raw domain data into a new hypothesis space. This results in classifiers with an improved classification rate and shorter training time. Integration of focal points into learning algorithms also results in agents that are more robust to changes in the environment.

#index 1275006
#* Phonetic models for generating spelling variants
#@ Rahul Bhagat;Eduard Hovy
#t 2007
#c 11
#% 131061
#% 144034
#% 208934
#% 219033
#% 232670
#% 252608
#% 278107
#% 279755
#% 317975
#% 579944
#% 643022
#% 746879
#% 939408
#% 939910
#% 1275581
#! Proper names, whether English or non-English, have several different spellings when transliterated from a non-English source language into English. Knowing the different variations can significantly improve the results of name-searches on various source texts, especially when recall is important. In this paper we propose two novel phonetic models to generate numerous candidate variant spellings of a name. Our methods show threefold improvement over the baseline and generate four times as many good name variants compared to a human while maintaining a respectable precision of 0.68.

#index 1275007
#* Sequence prediction exploiting similarity information
#@ István Bíró;Zoltán Szamonek;Csaba Szepesvári
#t 2007
#c 11
#% 278099
#% 342621
#% 478768
#% 748738
#% 770864
#% 803771
#% 968435
#! When data is scarce or the alphabet is large, smoothing the probability estimates becomes inescapable when estimating n-gram models. In this paper we propose a method that implements a form of smoothing by exploiting similarity information of the alphabet elements. The idea is to view the log-conditional probability function as a smooth function defined over the similarity graph. The algorithm that we propose uses the eigenvectors of the similarity graph as the basis of the expansion of the log conditional probability function whose coefficients are found by solving a regularized logistic regression problem. The experimental results demonstrate the superiority of the method when the similarity graph contains relevant information, whilst the method still remains competitive with state-of-the-art smoothing methods even in the lack of such information.

#index 1275008
#* Supervised latent semantic indexing using adaptive sprinkling
#@ Sutanu Chakraborti;Rahman Mukras;Robert Lothian;Nirmalie Wiratunga;Stuart Watt;David Harper
#t 2007
#c 11
#% 219053
#% 342670
#% 344447
#% 458379
#% 722930
#% 728295
#% 770810
#% 785426
#% 838437
#% 872021
#% 939346
#% 1289518
#% 1742120
#! Latent Semantic Indexing (LSI) has been shown to be effective in recovering from synonymy and polysemy in text retrieval applications. However, since LSI ignores class labels of training documents, LSI generated representations are not as effective in classification tasks. To address this limitation, a process called 'sprinkling' is presented. Sprinkling is a simple extension of LSI based on augmenting the set of features using additional terms that encode class knowledge. However, a limitation of sprinkling is that it treats all classes (and classifiers) in the same way. To overcome this, we propose a more principled extension called Adaptive Sprinkling (AS). AS leverages confusion matrices to emphasise the differences between those classes which are hard to separate. The method is tested on diverse classification tasks, including those where classes share ordinal or hierarchical relationships. These experiments reveal that AS can significantly enhance the performance of instance-based techniques (kNN) to make them competitive with the state-of-the-art SVM classifier. The revised representations generated by AS also have a favourable impact on SVM performance.

#index 1275009
#* A ranking approach to pronoun resolution
#@ Pascal Denis;Jason Baldridge
#t 2007
#c 11
#% 184073
#% 190444
#% 211044
#% 740995
#% 815876
#% 815896
#% 817441
#% 817563
#% 854813
#% 855234
#% 939353
#% 1260458
#% 1269531
#% 1290034
#! We propose a supervised maximum entropy ranking approach to pronoun resolution as an alternative to commonly used classification-based approaches. Classification approaches consider only one or two candidate antecedents for a pronoun at a time, whereas ranking allows all candidates to be evaluated together. We argue that this provides a more natural fit for the task than classification and show that it delivers significant performance improvements on the ACE datasets. In particular, our ranker obtains an error reduction of 9.7% over the best classification approach, the twin-candidate model. Furthermore, we show that the ranker offers some computational advantage over the twin-candidate classifier, since it easily allows the inclusion of more candidate antecedents during training. This approach leads to a further error reduction of 5.4% (a total reduction of 14.6% over the twin-candidate model).

#index 1275010
#* Word sense disambiguation through sememe labeling
#@ Xiangyu Duan;Jun Zhao;Bo Xu
#t 2007
#c 11
#% 44876
#% 464434
#% 741080
#% 756938
#% 770844
#% 816181
#% 854693
#% 927762
#% 939905
#% 943827
#% 1344871
#% 1673026
#! Currently most word sense disambiguation (WSD) systems are relatively individual word sense experts. Scarcely do these systems take word sense transitions between senses of linearly consecutive words or syntactically dependent words into consideration. Word sense transitions are very important. They embody the fluency of semantic expression and avoid sparse data problem effectively. In this paper, How Net knowledge base is used to decompose every word sense into several sememes. Then one transition between two words' senses becomes multiple transitions between sememes. Sememe transitions are much easier to be captured than word sense transitions due to much less sememes. When sememes are labeled, WSD is done. In this paper, multi-layered conditional random fields (MLCRF) is proposed to model sememe transitions. The experiments show that MLCRF performs better than a base-line system and a maximum entropy model. Syntactic and hypernym features can enhance the performance significantly.

#index 1275011
#* Case-based techniques used for dialogue understanding and planning in a human-robot dialogue system
#@ Karolina Eliasson
#t 2007
#c 11
#% 176887
#% 266227
#% 373871
#% 399855
#% 1271967
#! We describe an approach to the use of case-based techniques for natural language understanding and for action planning in a system for dialogue between a human and a robot, which in our case is a UAV (unmanned aerial vehicle). A single case base and case-based reasoning engine is used both for understanding and for planning actions by the UAV. This approach has been developed through the work on an experimental dialogue system, called CEDERIC. Dialogue experiments where a number of users have solved tasks by dialogue with this system showed very adequate success rates, while at the same time they indicated a few weak points in the system that could then easily be corrected.

#index 1275012
#* Computing semantic relatedness using Wikipedia-based explicit semantic analysis
#@ Evgeniy Gabrilovich;Shaul Markovitch
#t 2007
#c 11
#% 253191
#% 278099
#% 325502
#% 342963
#% 344447
#% 387427
#% 405391
#% 406493
#% 465914
#% 748845
#% 786511
#% 869500
#% 896031
#% 1250362
#% 1250381
#% 1250629
#% 1279327
#% 1289518
#! Computing semantic relatedness of natural language texts requires access to vast amounts of common-sense and domain-specific world knowledge. We propose Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia. We use machine learning techniques to explicitly represent the meaning of any text as a weighted vector of Wikipedia-based concepts. Assessing the relatedness of texts in this space amounts to comparing the corresponding vectors using conventional metrics (e.g., cosine). Compared with the previous state of the art, using ESA results in substantial improvements in correlation of computed relatedness scores with human judgments: from r = 0.56 to 0.75 for individual words and from r = 0.60 to 0.72 for texts. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users.

#index 1275013
#* On natural language processing and plan recognition
#@ Christopher W. Geib;Mark Steedman
#t 2007
#c 11
#% 101819
#% 241161
#% 297229
#% 334519
#% 368080
#% 567880
#% 741215
#% 743353
#% 744515
#% 746865
#% 938666
#% 939828
#% 1279397
#% 1279469
#% 1650593
#! The research areas of plan recognition and natural language parsing share many common features and even algorithms. However, the dialog between these two disciplines has not been effective. Specifically, significant recent results in parsing mildly context sensitive grammars have not been leveraged in the state of the art plan recognition systems. This paper will outline the relations between natural language processing(NLP) and plan recognition(PR), argue that each of them can effectively inform the other, and then focus on key recent research results in NLP and argue for their applicability to PR.

#index 1275014
#* Using ontologies and the web to learn lexical semantics
#@ Aarti Gupta;Tim Oates
#t 2007
#c 11
#% 198055
#% 198062
#% 747738
#% 815267
#! A variety of text processing tasks require or benefit from semantic resources such as ontologies and lexicons. Creating these resources manually is tedious, time consuming, and prone to error. We present a new algorithm for using the web to determine the correct concept in an existing ontology to lexicalize previously unknown words, such as might be discovered while processing texts. A detailed empirical comparison of our algorithm with two existing algorithms (Cilibrasi & Vitanyi 2004, Maedche et al. 2002) is described, leading to insights into the sources of the algorithms' strengths and weaknesses.

#index 1275015
#* Unsupervised anomaly detection
#@ David Guthrie;Louise Guthrie;Ben Allison;Yorick Wilks
#t 2007
#c 11
#% 731721
#% 746867
#! This paper describes work on the detection of anomalous material in text. We show several variants of an automatic technique for identifying an 'unusual' segment within a document, and consider texts which are unusual because of author, genre [Biber, 1998], topic or emotional tone. We evaluate the technique using many experiments over large document collections, created to contain randomly inserted anomalous segments. In order to successfully identify anomalies in text, we define more than 200 stylistic features to characterize writing, some of which are well-established stylistic determiners, but many of which are novel. Using these features with each of our methods, we examine the effect of segment size on our ability to detect anomaly, allowing segments of size 100 words, 500 words and 1000 words. We show substantial improvements over a baseline in all cases for all methods, and identify the method variant which performs consistently better than others.

#index 1275016
#* Named entity translation with web mining and transliteration
#@ Long Jiang;Ming Zhou;Lee-Feng Chien;Cheng Niu
#t 2007
#c 11
#% 741114
#% 747831
#% 747947
#% 748444
#% 760835
#% 786574
#% 815913
#% 818325
#% 854073
#% 854812
#% 855302
#% 938720
#% 939737
#! This paper presents a novel approach to improve the named entity translation by combining a transliteration approach with web mining, using web information as a source to complement transliteration, and using transliteration information to guide and enhance web mining. A Maximum Entropy model is employed to rank translation candidates by combining pronunciation similarity and bilingual contextual co-occurrence. Experimental results show that our approach effectively improves the precision and recall of the named entity translation by a large margin.

#index 1275017
#* Optimizing classifier performance in word sense disambiguation by redefining word sense classes
#@ Upali S. Kohomban;Wee Sun Lee
#t 2007
#c 11
#% 165663
#% 741839
#% 815297
#% 855287
#% 939336
#% 1910921
#% 1910936
#! Learning word sense classes has been shown to be useful in fine-grained word sense disambiguation [Kohomban and Lee, 2005]. However, the common choice for sense classes, WordNet lexicographer files, are not designed for machine learning based word sense disambiguation. In this work, we explore the use of clustering techniques in an effort to construct sense classes that are more suitable for word sense disambiguation end-task. Our results show that these classes can significantly improve classifier performance over the state of the art results of unrestricted word sense disambiguation.

#index 1275018
#* Learning from the report-writing behavior of individuals
#@ Mohit Kumar;Nikesh Garera;Alexander I. Rudnicky
#t 2007
#c 11
#% 290482
#% 340918
#% 387427
#% 428275
#% 740900
#% 741106
#% 817519
#% 855373
#% 939368
#% 961194
#% 1223713
#% 1264969
#! We describe a briefing system that learns to predict the contents of reports generated by users who create periodic (weekly) reports as part of their normal activity. The system observes content-selection choices that users make and builds a predictive model that could, for example, be used to generate an initial draft report. Using a feature of the interface the system also collects information about potential user-specific features. The system was evaluated under realistic conditions, by collecting data in a project-based university course where student group leaders were tasked with preparing weekly reports for the benefit of the instructors, using the material from individual student reports. This paper addresses the question of whether data derived from the implicit supervision provided by end-users is robust enough to support not only model parameter tuning but also a form of feature discovery. Results indicate that this is the case: system performance improves based on the feedback from user activity. We find that individual learned models (and features) are user-specific, although not completely idiosyncratic. Thismay suggest that approaches which seek to optimizemodels globally (say over a large corpus of data) may not in fact produce results acceptable to all individuals.

#index 1275019
#* SegGen: a genetic algorithm for linear text segmentation
#@ S. Lamprier;T. Amghar;B. Levrat;F. Saubion
#t 2007
#c 11
#% 36438
#% 114994
#% 144010
#% 211514
#% 369236
#% 378481
#% 387427
#% 448786
#% 706148
#% 740329
#% 741058
#% 742204
#% 748482
#% 815855
#% 817489
#! This paper describes SegGen, a new algorithm for linear text segmentation on general corpuses. It aims to segment texts into thematic homogeneous parts. Several existing methods have been used for this purpose, based on a sequential creation of boundaries. Here, we propose to consider boundaries simultaneously thanks to a genetic algorithm. SegGen uses two criteria: maximization of the internal cohesion of the formed segments and minimization of the similarity of the adjacent segments. First experimental results are promising and SegGen appears to be very competitive compared with existing methods.

#index 1275020
#* Cluster-based selection of statistical answering strategies
#@ Lucian Vlad Lita;Jaime Carbonell
#t 2007
#c 11
#% 179800
#% 464268
#% 741900
#% 766520
#% 816157
#! Question answering (QA) is a highly complex task that brings together classification, clustering, retrieval, and extraction. Question answering systems include various statistical and rule-based components that combine and form multiple strategies for finding answers. However, in real-life scenarios efficiency constraints make it infeasible to simultaneously use all available strategies in a QA system. To address this issue, we present an approach for carefully selecting answering strategies that are likely to benefit individual questions, without significantly reducing performance. We evaluate the impact of strategy selection on question answering performance at several important QA stages: document retrieval, answer extraction, and answer merging. We present strategy selection experiments using a statistical question answering system, and we show significant efficiency improvements. By selecting 10% of the available answering strategies, we obtained similar performance when compared to using all of the strategies combined.

#index 1275021
#* Automatically selecting answer templates to respond to customer emails
#@ Rahul Malik;L. Venkata Subramaniam;Saroj Kaushik
#t 2007
#c 11
#% 495937
#% 728351
#% 742083
#% 748600
#% 815206
#% 838508
#% 1250629
#! Contact center agents typically respond to email queries from customers by selecting predefined answer templates that relate to the questions present in the customer query. In this paper we present a technique to automatically select the answer templates corresponding to a customer query email. Given a set of query-response email pairs we find the associations between the actual questions and answers within them and use this information to map future questions to their answer templates. We evaluate the system on a small subset of the publicly available Pine-Info discussion list email archive and also on actual contact center data comprising customer queries, agent responses and templates.

#index 1275022
#* A predictive approach to help-desk response generation
#@ Yuval Marom;Ingrid Zukerman
#t 2007
#c 11
#% 406493
#% 509533
#% 816173
#% 817578
#% 939705
#% 1250278
#% 1734438
#! We are developing a corpus-based approach for the prediction of help-desk responses from features in customers' emails, where responses are represented at two levels of granularity: document and sentence. We present an automatic and human-based evaluation of our system's responses. The automatic evaluation involves textual comparisons between generated responses and responses composed by help-desk operators. Our results showthat both levels of granularity produce good responses, addressing inquiries of different kinds. The human-based evaluation measures response informativeness, and confirms our conclusion that both levels of granularity produce useful responses.

#index 1275023
#* Efficient HPSG parsing with supertagging and CFG-filtering
#@ Takuya Matsuzaki;Yusuke Miyao;Jun'ichi Tsujii
#t 2007
#c 11
#% 740916
#% 741425
#% 741931
#% 748222
#% 815896
#% 816169
#% 939342
#% 939658
#% 939689
#% 1261543
#% 1299529
#% 1677208
#! An efficient parsing technique for HPSG is presented. Recent research has shown that supertagging is a key technology to improve both the speed and accuracy of lexicalized grammar parsing. We show that further speed-up is possible by eliminating non-parsable lexical entry sequences from the output of the supertagger. The parsability of the lexical entry sequences is tested by a technique called CFG-filtering, where a CFG that approximates the HPSG is used to test it. Those lexical entry sequences that passed through the CFG-filter are combined into parse trees by using a simple shift-reduce parsing algorithm, in which structural ambiguities are resolved using a classifier and all the syntactic constraints represented in the original grammar are checked. Experimental results show that our system gives comparable accuracy with a speed-up by a factor of six (30 msec/sentence) compared with the best published result using the same grammar.

#index 1275024
#* A flexible unsupervised PP-attachment method using semantic information
#@ Srinivas Medimi;Pushpak Bhattacharyya
#t 2007
#c 11
#% 268079
#% 286069
#% 747788
#% 817554
#% 818061
#% 939905
#! In this paper we revisit the classical NLP problem of prepositional phrase attachment (PP-attachment). Given the pattern V -NP1-P-NP2 in the text, where V is verb, NP1 is a noun phrase, P is the preposition and NP2 is the other noun phrase, the question asked is where does P - NP2 attach: V or NP1? This question is typically answered using both the word and the world knowledge. Word Sense Disambiguation (WSD) and Data Sparsity Reduction (DSR) are the two requirements for PP-attachment resolution. Our approach described in this paper makes use of training data extracted from raw text, which makes it an unsupervised approach. The unambiguous V - P - N and N1 - P -N2 tuples of the training corpus TEACH the system how to resolve the attachments in the ambiguous V - N1 - P - N2 tuples of the test corpus. A graph based approach to word sense disambiguation (WSD) is used to obtain the accurate word knowledge. Further, the data sparsity problem is addressed by (i) detecting synonymy using the wordnet and (ii) doing a form of inferencing based on the matching of Vs and Ns in the unambiguous patterns of V - P - NP, NP1 - P - NP2. For experimentation, Brown Corpus provides the training data andWall Street Journal Corpus the test data. The accuracy obtained for PP-attachment resolution is close to 85%. The novelty of the system lies in the flexible use of WSD and DSR phases.

#index 1275025
#* Graph connectivity measures for unsupervised word sense disambiguation
#@ Roberto Navigli;Mirella Lapata
#t 2007
#c 11
#% 131450
#% 268079
#% 282905
#% 286069
#% 288780
#% 741836
#% 814007
#% 817962
#% 855226
#% 938688
#% 939513
#% 939904
#% 939905
#% 939950
#! Word sense disambiguation (WSD) has been a long-standing research objective for natural language processing. In this paper we are concerned with developing graph-based unsupervised algorithms for alleviating the data requirements for large scale WSD. Under this framework, finding the right sense for a given word amounts to identifying the most "important" node among the set of graph nodes representing its senses. We propose a variety of measures that analyze the connectivity of graph structures, thereby identifying the most relevant word senses. We assess their performance on standard datasets, and show that the best measures perform comparably to state-of-the-art.

#index 1275026
#* Shallow semantics for coreference resolution
#@ Vincent Ng
#t 2007
#c 11
#% 136350
#% 184073
#% 740992
#% 740995
#% 747738
#% 756121
#% 756964
#% 786555
#% 815329
#% 815876
#% 854652
#% 938670
#% 938671
#% 939352
#% 939505
#% 939857
#% 939866
#% 940015
#% 1344858
#! This paper focuses on the linguistic aspect of noun phrase coreference, investigating the knowledge sources that can potentially improve a learning-based coreference resolution system. Unlike traditional, knowledge-lean coreference resolvers, which rely almost exclusively on morpho-syntactic cues, we show how to induce features that encode semantic knowledge from labeled and unlabeled corpora. Experiments on the ACE data sets indicate that the addition of these new semantic features to a coreference system employing a fairly standard feature set significantly improves its performance.

#index 1275027
#* Subtree mining for question classification problem
#@ Minh Le Nguyen;Thanh Tri Nguyen;Akira Shimazu
#t 2007
#c 11
#% 73441
#% 197394
#% 211044
#% 348163
#% 496419
#% 568589
#% 577218
#% 732388
#% 740916
#% 742218
#% 815303
#% 816201
#% 853907
#% 905498
#% 939355
#% 983600
#! Question Classification, i.e., putting the questions into several semantic categories, is very important for question answering. This paper introduces a new application of using subtree mining for question classification problem. First, we formulate this problem as classifying a tree to a certain label among a set of labels. We then present a use of subtrees in the forest created by the training data to the tree classification problem in which maximum entropy and a boosting model are used as classifiers. Experiments on standard question classification data show that the uses of subtrees along with either maximum entropy or boosting models are promising. The results indicate that our method achieves a comparable or even better performance than kernel methods and also improves testing efficiency.

#index 1275028
#* Natural language query recommendation in conversation systems
#@ Shimei Pan;James Shaw
#t 2007
#c 11
#% 247339
#% 632441
#% 742223
#% 742436
#% 790441
#% 848643
#% 855281
#% 926881
#% 939401
#% 939895
#! In this paper, we address a critical problem in conversation systems: limited input interpretation capabilities. When an interpretation error occurs, users often get stuck and cannot recover due to a lack of guidance from the system. To solve this problem, we present a hybrid natural language query recommendation framework that combines natural language generation with query retrieval. When receiving a problematic user query, our system dynamically recommends valid queries that are most relevant to the current user request so that the user can revise his request accordingly. Compared with existing methods, our approach offers two main contributions: first, improving query recommendation quality by combining query generation with query retrieval; second, adapting generated recommendations dynamically so that they are syntactically and lexically consistent with the original user input. Our evaluation results demonstrate the effectiveness of this approach.

#index 1275029
#* A dual-layer CRFs based joint decoding method for cascaded segmentation and labeling tasks
#@ Yanxin Shi;Mengqiu Wang
#t 2007
#c 11
#% 226495
#% 464434
#% 742230
#% 770844
#% 815298
#% 855182
#% 855183
#% 855191
#% 855290
#% 927762
#% 938711
#% 939404
#% 939729
#% 939947
#% 1344885
#% 1344888
#! Many problems in NLP require solving a cascade of subtasks. Traditional pipeline approaches yield to error propagation and prohibit joint training/ decoding between subtasks. Existing solutions to this problem do not guarantee nonviolation of hard-constraints imposed by subtasks and thus give rise to inconsistent results, especially in cases where segmentation task precedes labeling task. We present a method that performs joint decoding of separately trained Conditional Random Field (CRF) models, while guarding against violations of hard-constraints. Evaluated on Chinese word segmentation and part-of-speech (POS) tagging tasks, our proposed method achieved state-of-the-art performance on both the Penn Chinese Treebank and First SIGHAN Bakeoff datasets. On both segmentation and POS tagging tasks, the proposed method consistently improves over baseline methods that do not perform joint decoding.

#index 1275030
#* Database-text alignment via structured multilabel classification
#@ Benjamin Snyder;Regina Barzilay
#t 2007
#c 11
#% 302391
#% 397142
#% 740915
#% 815896
#% 838412
#% 858035
#% 939863
#% 939895
#% 939977
#% 940005
#! This paper addresses the task of aligning a database with a corresponding text. The goal is to link individual database entries with sentences that verbalize the same information. By providing explicit semantics-to-text links, these alignments can aid the training of natural language generation and information extraction systems. Beyond these pragmatic benefits, the alignment problem is appealing from a modeling perspective: the mappings between database entries and text sentences exhibit rich structural dependencies, unique to this task. Thus, the key challenge is to make use of as many global dependencies as possible without sacrificing tractability. To this end, we cast text-database alignment as a structured multilabel classification task where each sentence is labeled with a subset of matching database entries. In contrast to existing multilabel classifiers, our approach operates over arbitrary global features of inputs and proposed labels. We compare our model with a baseline classifier that makes locally optimal decisions. Our results show that the proposed model yields a 15% relative reduction in error, and compares favorably with human performance.

#index 1275031
#* Dances with words
#@ Carlo Strapparava;Alessandro Valitutti;Oliviero Stock
#t 2007
#c 11
#% 402082
#% 428246
#% 722308
#% 939920
#% 1344857
#% 1672272
#! Animated text is an appealing field of creative graphical design. Manually designed text animation is largely employed in advertising, movie titles and web pages. In this paper we propose to link, through state of the art NLP techniques, the affective content detection of a piece of text to the animation of the words in the text itself. This methodology allows us to automatically generate affective text animation and opens some new perspectives for advertising, internet applications and intelligent interfaces.

#index 1275032
#* Word sense disambiguation with spreading activation networks generated from thesauri
#@ George Tsatsaronis;Michalis Vazirgiannis;Ion Androutsopoulos
#t 2007
#c 11
#% 144031
#% 152968
#% 252328
#% 323337
#% 740329
#% 741080
#% 741085
#% 743922
#% 744285
#% 746869
#% 748550
#% 754095
#% 762178
#% 939810
#% 1272061
#% 1279327
#% 1414358
#% 1673568
#% 1910925
#% 1910946
#! Most word sense disambiguation (WSD) methods require large quantities of manually annotated training data and/or do not exploit fully the semantic relations of thesauri. We propose a new unsupervised WSD algorithm, which is based on generating Spreading Activation Networks (SANs) from the senses of a thesaurus and the relations between them. A new method of assigning weights to the networks' links is also proposed. Experiments show that the algorithm outperforms previous unsupervised approaches to WSD.

#index 1275033
#* Morphological annotation of a large spontaneous speech corpus in Japanese
#@ Kiyotaka Uchimoto;Hitoshi Isahara
#t 2007
#c 11
#% 211044
#% 742220
#% 757892
#% 786543
#% 816081
#% 817479
#! We propose an efficient framework for humanaided morphological annotation of a large spontaneous speech corpus such as the Corpus of Spontaneous Japanese. In this framework, even when word units have several definitions in a given corpus, and not all words are found in a dictionary or in a training corpus, we can morphologically analyze the given corpus with high accuracy and low labor costs by detecting words not found in the dictionary and putting them into it. We can further reduce labor costs by expanding training corpora based on active learning.

#index 1275034
#* Speaker-invariant features for automatic speech recognition
#@ S. Umesh;D. R. Sanand;G. Praveen
#t 2007
#c 11
#! In this paper, we consider the generation of features for automatic speech recognition (ASR) that are robust to speaker-variations. One of the major causes for the degradation in the performance of ASR systems is due to inter-speaker variations. These variations are commonly modeled by a pure scaling relation between spectra of speakers enunciating the same sound. Therefore, current state-of-the art ASR systems overcome this problem of speaker variability by doing a brute-force search for the optimal scaling parameter. This procedure known as vocal-tract length normalization (VTLN) is computationally intensive. We have recently used Scale-Transform (a variation of Mellin transform) to generate features which are robust to speaker variations without the need to search for the scaling parameter. However, these features have poorer performance due to loss of phase information. In this paper, we propose to use the magnitude of Scale-Transform and a pre-computed "phase"-vector for each phoneme to generate speaker-invariant features. We compare the performance of the proposed features with conventional VTLN on a phoneme recognition task.

#index 1275035
#* Correlation clustering for crosslingual link detection
#@ Jurgen Van Gael;Xiaojin Zhu
#t 2007
#c 11
#% 464291
#% 532049
#% 765548
#% 770782
#% 815159
#% 815895
#% 1275191
#! The crosslingual link detection problem calls for identifying news articles in multiple languages that report on the same news event. This paper presents a novel approach based on constrained clustering. We discuss a general way for constrained clustering using a recent, graph-based clustering framework called correlation clustering. We introduce a correlation clustering implementation that features linear program chunking to allow processing larger datasets. We show how to apply the correlation clustering algorithm to the crosslingual link detection problem and present experimental results that show correlation clustering improves upon the hierarchical clustering approaches commonly used in link detection, and, hierarchical clustering approaches that take constraints into account.

#index 1275036
#* A hybrid ontology directed feedback selection algorithm for supporting creative problem solving dialogues
#@ Hao-Chuan Wang;Rohit Kumar;Carolyn Penstein Rosé;Tsai-Yen Li;Chun-Yen Chang
#t 2007
#c 11
#% 424041
#% 551704
#% 755864
#% 855189
#% 880578
#% 926881
#% 938685
#% 1111446
#% 1733277
#! We evaluate a new hybrid language processing approach designed for interactive applications that maintain an interaction with users over multiple turns. Specifically, we describe a method for using a simple topic hierarchy in combination with a standard information retrieval measure of semantic similarity to reason about the selection of appropriate feedback in response to extended language inputs in the context of an interactive tutorial system designed to support creative problem solving. Our evaluation demonstrates the value of using a machine learning approach that takes feedback from experts into account for optimizing the hierarchy based feedback selection strategy.

#index 1275037
#* Simple training of dependency parsers via structured boosting
#@ Qin Iris Wang;Dekang Lin;Dale Schuurmans
#t 2007
#c 11
#% 235377
#% 278104
#% 302391
#% 425065
#% 464434
#% 466892
#% 722816
#% 740916
#% 742218
#% 746865
#% 748561
#% 757329
#% 770763
#% 816186
#% 817430
#% 843647
#% 854674
#% 935763
#% 938706
#% 939343
#% 939398
#% 939505
#% 939658
#% 940011
#% 1249446
#% 1299532
#! Recently, significant progress has been made on learning structured predictors via coordinated training algorithms such as conditional random fields and maximum margin Markov networks. Unfortunately, these techniques are based on specialized training algorithms, are complex to implement, and expensive to run. We present a much simpler approach to training structured predictors by applying a boosting-like procedure to standard supervised training methods. The idea is to learn a local predictor using standard methods, such as logistic regression or support vector machines, but then achieve improved structured classification by "boosting" the influence of misclassified components after structured prediction, re-training the local predictor, and repeating. Further improvement in structured prediction accuracy can be achieved by incorporating "dynamic" features--i.e. an extension whereby the features for one predicted component can depend on the predictions already made for some other components. We apply our techniques to the problem of learning dependency parsers from annotated natural language corpora. By using logistic regression as an efficient base classifier (for predicting dependency links between word pairs), we are able to efficiently train a dependency parsing model, via structured boosting, that achieves state of the art results in English, and surpasses state of the art in Chinese.

#index 1275038
#* One class per named entity: exploiting unlabeled text for named entity recognition
#@ Yingchuan Wong;Hwee Tou Ng
#t 2007
#c 11
#% 226495
#% 252011
#% 709765
#% 817846
#% 817955
#% 842682
#% 855108
#% 855112
#% 855114
#% 939332
#! In this paper, we present a simple yet novel method of exploiting unlabeled text to further improve the accuracy of a high-performance state-of-the art named entity recognition (NER) system. The method utilizes the empirical property that many named entities occur in one name class only. Using only unlabeled text as the additional resource, our improved NER system achieves an F1 score of 87.13%, an improvement of 1.17% in F1 score and a 8.3% error reduction on the CoNLL 2003 English NER official test set. This accuracy places our NER system among the top 3 systems in the CoNLL 2003 English shared task.

#index 1275039
#* A privacy-sensitive approach to modeling multi-person conversations
#@ Danny Wyatt;Tanzeem Choudhury;Jeff Bilmes;Henry Kautz
#t 2007
#c 11
#% 528154
#% 575841
#% 575843
#% 716706
#% 1133506
#% 1289476
#% 1719327
#! In this paper we introduce a new dynamic Bayesian network that separates the speakers and their speaking turns in a multi-person conversation. We protect the speakers' privacy by using only features from which intelligible speech cannot be reconstructed. The model we present combines data from multiple audio streams, segments the streams into speech and silence, separates the different speakers, and detects when other nearby individuals who are not wearing microphones are speaking. No pre-trained speaker specific models are used, so the system can be easily applied in new and different environments. We show promising results in two very different datasets that vary in background noise, microphone placement and quality, and conversational dynamics.

#index 1275040
#* Multi-document summarization by maximizing informative content-words
#@ Wen-tau Yih;Joshua Goodman;Lucy Vanderwende;Hisami Suzuki
#t 2007
#c 11
#% 173758
#% 262112
#% 755863
#% 816173
#% 854191
#% 879636
#% 939777
#% 1265053
#% 1478826
#! We show that a simple procedure based on maximizing the number of informative content-words can produce some of the best reported results for multi-document summarization. We first assign a score to each term in the document cluster, using only frequency and position information, and then we find the set of sentences in the document cluster that maximizes the sum of these scores, subject to length constraints. Our overall results are the best reported on the DUC-2004 summarization task for the ROUGE-1 score, and are the best, but not statistically significantly different from the best system in MSE-2005. Our system is also substantially simpler than the previous best system.

#index 1275041
#* Ambiguous part-of-speech tagging for improving accuracy and domain portability of syntactic parsers
#@ Kazuhiro Yoshida;Yoshimasa Tsuruoka;Yusuke Miyao;Jun'ichi Tsujii
#t 2007
#c 11
#% 188076
#% 217059
#% 646547
#% 740916
#% 939353
#% 939689
#% 939912
#% 995512
#% 1299527
#% 1677208
#% 1712121
#% 1712133
#! We aim to improve the performance of a syntactic parser that uses a part-of-speech (POS) tagger as a preprocessor. Pipelined parsers consisting of POS taggers and syntactic parsers have several advantages, such as the capability of domain adaptation. However the performance of such systems on raw texts tends to be disappointing as they are affected by the errors of automatic POS tagging. We attempt to compensate for the decrease in accuracy caused by automatic taggers by allowing the taggers to output multiple answers when the tags cannot be determined reliably enough. We empirically verify the effectiveness of the method using an HPSG parser trained on the Penn Treebank. Our results show that ambiguous POS tagging improves parsing if outputs of taggers are weighted by probability values, and the results support previous studies with similar intentions. We also examine the effectiveness of our method for adapting the parser to the GENIA corpus and show that the use of ambiguous POS taggers can help development of portable parsers while keeping accuracy high.

#index 1275042
#* Automatic acquisition of context-specific lexical paraphrases
#@ Shiqi Zhao;Ting Liu;Xincheng Yuan;Sheng Li;Yu Zhang
#t 2007
#c 11
#% 348155
#% 465914
#% 747994
#% 815799
#% 815868
#% 854933
#% 854934
#% 939405
#% 939993
#% 995474
#% 1712200
#! Lexical paraphrasing aims at acquiring word-level paraphrases. It is critical for many Natural Language Processing (NLP) applications, such as Question Answering (QA), Information Extraction (IE), and Machine Translation (MT). Since the meaning and usage of a word can vary in distinct contexts, different paraphrases should be acquired according to the contexts. However, most of the existing researches focus on constructing paraphrase corpora, in which little contextual constraints for paraphrase application are imposed. This paper presents a method that automatically acquires context-specific lexical paraphrases. In this method, the obtained paraphrases of a word depend on the specific sentence the word occurs in. Two stages are included, i.e. candidate paraphrase extraction and paraphrase validation, both of which are mainly based on web mining. Evaluations are conducted on a news title corpus and the presented method is compared with a paraphrasing method that exploits a Chinese thesaurus of synonyms -- Tongyi Cilin (Extended) (CilinE for short). Results show that the f-measure of our method (0.4852) is significantly higher than that using CilinE (0.1127). In addition, over 85% of the correct paraphrases derived by our method cannot be found in CilinE, which suggests that our method is effective in acquiring out-of-thesaurus paraphrases.

#index 1275043
#* Learning question paraphrases for QA from Encarta logs
#@ Shiqi Zhao;Ming Zhou;Ting Liu
#t 2007
#c 11
#% 342961
#% 464612
#% 642978
#% 741891
#% 803037
#% 815303
#% 815799
#% 816156
#% 817434
#% 854668
#% 854929
#% 939405
#% 995474
#% 1712161
#! Question paraphrasing is critical in many Natural Language Processing (NLP) applications, especially for question reformulation in question answering (QA). However, choosing an appropriate data source and developing effective methods are challenging tasks. In this paper, we propose a method that exploits Encarta logs to automatically identify question paraphrases and extract templates. Questions from Encarta logs are partitioned into small clusters, within which a perceptron classier is used for identifying question paraphrases. Experiments are conducted and the results have shown: (1) Encarta log data is an eligible data source for question paraphrasing and the user clicks in the data are indicative clues for recognizing paraphrases; (2) the supervised method we present is effective, which can evidently outperform the unsupervised method. Besides, the features introduced to identify paraphrases are sound; (3) the obtained question paraphrase templates are quite effective in question reformulation, enhancing the MRR from 0.2761 to 0.4939 with the questions of TREC QA 2003.

#index 1275044
#* Detecting stochastically scheduled activities in video
#@ Massimiliano Albanese;Vincenzo Moscato;Antonio Picariello;V. S. Subrahmanian
#t 2007
#c 11
#% 313937
#% 313957
#% 632422
#% 706138
#% 775552
#% 780157
#% 784936
#% 1279396
#% 1502506
#% 1685191
#% 1858300
#! The ability to automatically detect activities in video is of increasing importance in applications such as bank security, airport tarmac security, baggage area security and building site surveillance. We present a stochastic activity model composed of atomic actions which are directly observable through image understanding primitives. We focus on answering two types of questions: (i) what are the minimal sub-videos in which a given action is identified with probability above a certain threshold and (ii) for a given video, can we decide which activity from a given set most likely occurred? We provide the MPS algorithm for the first problem, as well as two different algorithms (naive MPA and MPA) to solve the second. Our experimental results on a dataset consisting of staged bank robbery videos (described in [Vu et al., 2003]) show that our algorithms are both fast and provide high quality results when compared to human reviewers.

#index 1275045
#* A heuristic search approach to planning with temporally extended preferences
#@ Jorge A. Baier;Fahiem Bacchus;Sheila A. McIlraith
#t 2007
#c 11
#% 417597
#% 1250631
#% 1269556
#% 1271962
#% 1272017
#% 1275063
#! In this paper we propose a suite of techniques for planning with temporally extended preferences (TEPs). To this end, we propose a method for compiling TEP planning problems into simpler domains containing only final-state (simple) preferences and metric functions. With this simplified problem in hand, we propose a variety of heuristic functions for planning with final-state preferences, together with an incremental best-first planning algorithm. A key feature of the planning algorithm is its ability to prune the search space. We identify conditions under which our planning algorithm will generate optimal plans. We implemented our algorithm as an extension to the TLPLAN planning system and report on extensive testing performed to evaluate the effectiveness of our heuristics and algorithm. Our planner, HPLAN-P, competed in the 5th International Planning Competition, achieving distinguished performance in the qualitative preferences track.

#index 1275046
#* Waiting and relocation strategies in online stochastic vehicle routing
#@ Russell Bent;Pascal Van Hentenryck
#t 2007
#c 11
#% 35388
#% 534812
#% 573249
#% 794018
#% 959992
#% 1250198
#% 1279410
#% 1677418
#! This paper considers online stochastic multiple vehicle routing with time windows in which requests arrive dynamically and the goal is to maximize the number of serviced customers. Contrary to earlier algorithms which only move vehicles to known customers, this paper investigates waiting and relocation strategies in which vehicles may wait at their current location or relocate to arbitrary sites. Experimental results show that waiting and relocation strategies may dramatically improve customer service, especially for problems that are highly dynamic and contain many late requests. The decisions to wait and to relocate do not exploit any problem-specific features but rather are obtained by including choices in the online algorithm that are necessarily sub-optimal in an offline setting.

#index 1275047
#* Coalitions in action logic
#@ Stefano Borgo
#t 2007
#c 11
#% 567289
#% 819613
#% 890219
#% 1656530
#! If modal logics for coalitions need to be applied, one must know how to translate coalition power into agents' actions. To these days, the connection between coalition power and the actions of the agents has not been studied in the literature. This paper fills the gap by presenting a semantic translation from Pauly's Coalition Logic to a (fragment of an) action logic. The interpretation of the empty coalition in Pauly's system and the representation of the notion of ability are discussed.

#index 1275048
#* Fast planning with iterative macros
#@ Adi Botea;Martin Müller;Jonathan Schaeffer
#t 2007
#c 11
#% 1474
#% 243695
#% 337987
#% 449567
#% 691209
#% 1271962
#! Research on macro-operators has a long history in planning and other search applications. There has been a revival of interest in this topic, leading to systems that successfully combine macrooperators with current state-of-the-art planning approaches based on heuristic search. However, research is still necessary to make macros become a standard, widely-used enhancement of search algorithms. This article introduces sequences of macro-actions, called iterative macros. Iterative macros exhibit both the potential advantages (e.g., travel fast towards goal) and the potential limitations (e.g., utility problem) of classical macros, only on a much larger scale. A family of techniques are introduced to balance this trade-off in favor of faster planning. Experiments on a collection of planning benchmarks show that, when compared to low-level search and even to search with classical macro-operators, iterative macros can achieve an impressive speed-up in search.

#index 1275049
#* Planning for gene regulatory network intervention
#@ Daniel Bryce;Seungchan Kim
#t 2007
#c 11
#% 3873
#% 25470
#% 830858
#% 1269465
#! Modeling the dynamics of cellular processes has recently become a important research area of many disciplines. One of the most important reasons to model a cellular process is to enable highthroughput in-silico experiments that attempt to predict or intervene in the process. These experiments can help accelerate the design of therapies through their cheap replication and alteration. While some techniques exist for reasoning with cellular processes, few take advantage of the flexible and scalable algorithms popularized in AI research. In this domain, where scalability is crucial for feasible application, we apply AI planning based search techniques and demonstrate their advantage over existing enumerative methods.

#index 1275050
#* Long-distance mutual exclusion for propositional planning
#@ Yixin Chen;Zhao Xing;Weixiong Zhang
#t 2007
#c 11
#% 131357
#% 132022
#% 167629
#% 179938
#% 224480
#% 243695
#% 251783
#% 266388
#% 283220
#% 283422
#% 337980
#% 743416
#% 743463
#% 873954
#% 1271953
#% 1272016
#% 1272113
#% 1272116
#% 1272340
#% 1476298
#% 1698697
#! The use of mutual exclusion (mutex) has led to significant advances in propositional planning. However, previous mutex can only detect pairs of actions or facts that cannot be arranged at the same time step. In this paper, we introduce a new class of constraints that significantly generalizes mutex and can be efficiently computed. The proposed long-distance mutual exclusion (londex) can capture constraints over actions and facts not only at the same time step but also across multiple steps. Londex provides a powerful and general approach for improving planning efficiency. As an application, we have integrated londex into SATPLAN04, a leading optimal planner. Experimental results show that londex can effectively prune the search space and reduce the planning time. The resulting planner, MaxPlan, has won the First Place Award in the Optimal Track of the 5th International Planning Competition.

#index 1275051
#* Towards an integration of Golog and planning
#@ Jens Claßen;Patrick Eyerich;Gerhard Lakemeyer;Bernhard Nebel
#t 2007
#c 11
#% 100159
#% 229083
#% 290714
#% 326595
#% 342119
#% 762500
#% 1271962
#% 1272008
#% 1289429
#! The action language Golog has been applied successfully to the control of robots, among other things. Perhaps its greatest advantage is that a user can write programs which constrain the search for an executable plan in a flexible manner. However, when general planning is needed, Golog supports this only in principle, but does not measure up with state-of-the-art planners. In this paper we propose an integration of Golog and planning in the sense that planning problems, formulated as part of a Golog program, are solved by a modern planner during the execution of the program. Here we focus on the ADL subset of the plan language PDDL. First we show that the semantics of ADL can be understood as progression in the situation calculus, which underlies Golog, thus providing us with a correct embedding of ADL within Golog. We then show how Golog can be integrated with an existing ADL planner for closed-world initial databases and compare the performance of the resulting system with the original Golog.

#index 1275052
#* When is temporal planning really temporal?
#@ William Cushing;Subbarao Kambhampati; Mausam;Daniel S. Weld
#t 2007
#c 11
#% 79993
#% 179938
#% 345431
#% 495772
#% 1250645
#% 1271818
#% 1271962
#% 1272008
#% 1272013
#% 1272014
#% 1272015
#% 1272020
#% 1272099
#% 1272116
#% 1289204
#% 1478840
#! While even STRIPS planners must search for plans of unbounded length, temporal planners must also cope with the fact that actions may start at any point in time. Most temporal planners cope with this challenge by restricting action start times to a small set of decision epochs, because this enables search to be carried out in state-space and leverages powerful state-based reachability heuristics, originally developed for classical planning. Indeed, decision-epoch planners won the International Planning Competition's Temporal Planning Track in 2002, 2004 and 2006. However, decision-epoch planners have a largely unrecognized weakness: they are incomplete. In order to characterize the cause of incompleteness, we identify the notion of required concurrency, which separates expressive temporal action languages from simple ones. We show that decisionepoch planners are only complete for languages in the simpler class, and we prove that the simple class is 'equivalent' to STRIPS! Surprisingly, no problems with required concurrency have been included in the planning competitions. We conclude by designing a complete state-space temporal planning algorithm, which we hope will be able to achieve high performance by leveraging the heuristics that power decision epoch planners.

#index 1275053
#* Topological value iteration algorithm for Markov decision processes
#@ Peng Dai;Judy Goldsmith
#t 2007
#c 11
#% 181627
#% 337981
#% 363744
#% 410276
#% 578699
#% 578700
#% 578724
#% 644560
#% 1272002
#% 1279387
#% 1650297
#% 1650672
#% 1673002
#! Value Iteration is an inefficient algorithm for Markov decision processes (MDPs) because it puts the majority of its effort into backing up the entire state space, which turns out to be unnecessary in many cases. In order to overcome this problem, many approaches have been proposed. Among them, LAO, LRTDP and HDP are state-of-theart ones. All of these use reachability analysis and heuristics to avoid some unnecessary backups. However, none of these approaches fully exploit the graphical features of the MDPs or use these features to yield the best backup sequence of the state space. We introduce an algorithm named Topological Value Iteration (TVI) that can circumvent the problem of unnecessary backups by detecting the structure of MDPs and backing up states based on topological sequences. We prove that the backup sequence TVI applies is optimal. Our experimental results show that TVI outperforms VI, LAO, LRTDP and HDP on our benchmark MDPs.

#index 1275054
#* Automatic synthesis of new behaviors from a library of available behaviors
#@ Giuseppe De Giacomo;Sebastian Sardina
#t 2007
#c 11
#% 65904
#% 252183
#% 390685
#% 695783
#% 824702
#% 836542
#% 1650314
#! We consider the problem of synthesizing a fully controllable target behavior from a set of available partially controllable behaviors that are to execute within a shared partially predictable, but fully observable, environment. Behaviors are represented with a sort of nondeterministic transition systems, whose transitions are conditioned on the current state of the environment, also represented as a nondeterministic finite transition system. On the other hand, the target behavior is assumed to be fully deterministic and stands for the behavior that the system as a whole needs to guarantee. We formally define the problem within an abstract framework, characterize its computational complexity, and propose a solution by appealing to satisfiability in Propositional Dynamic Logic, which is indeed optimal with respect to computational complexity. We claim that this problem, while novel to the best of our knowledge, can be instantiated to multiple specific settings in different contexts and can thus be linked to different research areas of AI, including agent-oriented programming and cognitive robotics, control, multi-agent coordination, plan integration, and automatic web-service composition.

#index 1275055
#* Planning with goal utility dependencies
#@ Minh B. Do;J. Benton;Menkes Van Den Briel;Subbarao Kambhampati
#t 2007
#c 11
#% 167629
#% 224480
#% 496277
#% 1250208
#% 1271962
#% 1478840
#% 1650274
#% 1650628
#! Work in partial satisfaction planning (PSP) has hitherto assumed that goals are independent thus implying that they have additive utility values. In many real-world problems, we cannot make this assumption. In this paper, we motivate the need for handling various types of goal utility dependence in PSP. We provide a framework for representing them using the General Additive Independence model and investigate two different approaches to handle this problem: (1) compiling PSP with utility dependencies to Integer Programming; (2) extending forward heuristic search planning to handle PSP goal dependencies. To guide the forward planning search, we introduce a novel heuristic framework that combines costpropagation and Integer Programming to select beneficial goals to find an informative heuristic estimate. The two implemented planners, iPUD and SPUDS, using the approaches discussed above, are compared empirically on several benchmark domains. While iPUD is more readily amendable to handle goal utility dependencies and can provide bounded optimality guarantees, SPUDS scales much better.

#index 1275056
#* A decision-theoretic model of assistance
#@ Alan Fern;Sriraam Natarajan;Kshitij Judah;Prasad Tadepalli
#t 2007
#c 11
#% 159114
#% 160859
#% 393786
#% 495927
#% 567880
#% 578783
#% 823964
#% 848652
#% 1272002
#% 1272356
#% 1289556
#% 1650593
#! There is a growing interest in intelligent assistants for a variety of applications from organizing tasks for knowledge workers to helping people with dementia. In this paper, we present and evaluate a decision-theoretic framework that captures the general notion of assistance. The objective is to observe a goal-directed agent and to select assistive actions in order to minimize the overall cost. We model the problem as an assistant POMDP where the hidden state corresponds to the agent's unobserved goals. This formulation allows us to exploit domain models for both estimating the agent's goals and selecting assistive action. In addition, the formulation naturally handles uncertainty, varying action costs, and customization to specific agents via learning. We argue that in many domains myopic heuristics will be adequate for selecting actions in the assistant POMDP and present two such heuristics. We evaluate our approach in two domains where human subjects perform tasks in game-like computer environments. The results show that the assistant substantially reduces user effort with only a modest computational effort.

#index 1275057
#* Transferring learned control-knowledge between planners
#@ Susana Fernández;Ricardo Aler;Daniel Borrajo
#t 2007
#c 11
#% 229976
#% 449587
#% 451031
#% 495772
#% 732423
#% 823852
#% 890312
#! As any other problem solving task that employs search, AI Planning needs heuristics to efficiently guide the problem-space exploration. Machine learning (ML) provides several techniques for automatically acquiring those heuristics. Usually, a planner solves a problem, and a ML technique generates knowledge from the search episode in terms of complete plans (macro-operators or cases), or heuristics (also named control knowledge in planning). In this paper, we present a novel way of generating planning heuristics: we learn heuristics in one planner and transfer them to another planner. This approach is based on the fact that different planners employ different search bias. We want to extract knowledge from the search performed by one planner and use the learned knowledge on another planner that uses a different search bias. The goal is to improve the efficiency of the second planner by capturing regularities of the domain that it would not capture by itself due to its bias. We employ a deductive learning method (EBL) that is able to automatically acquire control knowledge by generating bounded explanations of the problem-solving episodes in a Graphplan-based planner. Then, we transform the learned knowledge so that it can be used by a bidirectional planner.

#index 1275058
#* Decidable reasoning in a modified situation calculus
#@ Yilan Gu;Mikhail Soutchanski
#t 2007
#c 11
#% 90860
#% 205398
#% 229083
#% 342119
#% 587425
#% 665856
#% 822575
#% 1250357
#% 1269448
#% 1289434
#% 1289445
#! We consider a modified version of the situation calculus built using a two-variable fragment of the first-order logic extended with counting quantifiers. We mention several additional groups of axioms that can be introduced to capture taxonomic reasoning. We show that the regression operator in this framework can be defined similarly to regression in the Reiter's version of the situation calculus. Using this new regression operator, we show that the projection and executability problems are decidable in the modified version even if an initial knowledge base is incomplete and open. For an incomplete knowledge base and for context-dependent actions, we consider a type of progression that is sound with respect to the classical progression. We show that the new knowledge base resulting after our progression is definable in our modified situation calculus if one allows actions with local effects only. We mention possible applications to formalization of Semantic Web services.

#index 1275059
#* Reducing accidental complexity in planning problems
#@ Patrik Haslum
#t 2007
#c 11
#% 172505
#% 175391
#% 251783
#% 337980
#% 337987
#% 544936
#% 875422
#% 1250634
#% 1272084
#% 1272116
#% 1290104
#! Although even propositional STRIPS planning is a hard problem in general, many instances of the problem, including many of those commonly used as benchmarks, are easy. In spite of this, they are often hard to solve for domain-independent planners, because the encoding of the problem into a general problem specification formalism such as STRIPS hides structure that needs to be exploited to solve problems easily. We investigate the use of automatic problem transformations to reduce this "accidental" problem complexity. The main tool is abstraction: we identify a new, weaker, condition under which abstraction is "safe", in the sense that any solution to the abstracted problem can be refined to a concrete solution (in polynomial time, for most cases) and also show how different kinds of problem reformulations can be applied to create greater opportunities for such safe abstraction.

#index 1275060
#* Planning via Petri net unfolding
#@ Sarah Hickmott;Jussi Rintanen;Sylvie Thiébaux;Lang White
#t 2007
#c 11
#% 224480
#% 337980
#% 338512
#% 424920
#% 445907
#% 542872
#% 543169
#% 544791
#% 939465
#% 1272379
#% 1344971
#! The factored state representation and concurrency semantics of Petri nets are closely related to those of concurrent planning domains, yet planning and Petri net analysis have developed independently, with minimal and usually unconvincing attempts at cross-fertilisation. In this paper, we investigate and exploit the relationship between the two areas, focusing on Petri net unfolding, which is an attractive reachability analysis method as it naturally enables the recognition and separate resolution of independent subproblems. On the one hand, based on unfolding, we develop a new forward search method for cost-optimal partial-order planning which can be exponentially more efficient than state space search. On the other hand, inspired by well-known planning heuristics, we investigate the automatic generation of heuristics to guide unfolding, resulting in a more efficient, directed reachability analysis tool for Petri nets.

#index 1275061
#* Detecting changes in unlabeled data streams using martingale
#@ Shen-Shyang Ho;Harry Wechsler
#t 2007
#c 11
#% 135968
#% 252011
#% 464466
#% 782126
#% 806981
#% 836814
#% 840875
#% 1289632
#% 1857658
#! The martingale framework for detecting changes in data stream, currently only applicable to labeled data, is extended here to unlabeled data using clustering concept. The one-pass incremental changedetection algorithm (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the clustering algorithm as data points are streaming, and (iii) works well for high-dimensional data streams. To enhance the performance of the martingale change detection method, the multiple martingale test method using multiple views is proposed. Experimental results show (i) the feasibility of the martingale method for detecting changes in unlabeled data streams, and (ii) the multiple-martingale test method compares favorably with alternative methods using the recall and precision measures for the video-shot change detection problem.

#index 1275062
#* SAT encodings of state-space reachability problems in numeric domains
#@ Jörg Hoffmann;Carla Gomes;Bart Selman;Henry Kautz
#t 2007
#c 11
#% 224480
#% 347808
#% 496111
#% 496277
#% 776161
#% 830717
#% 895017
#% 1272016
#% 1272017
#% 1272116
#% 1741982
#! Translation to Boolean satisfiability is an important approach for solving state-space reachability problems that arise in planning and verification. Many important problems, however, involve numeric variables; for example, C programs or planning with resources. Focussing on planning, we propose a method for translating such problems into propositional SAT, based on an approximation of reachable variable domains. We compare to a more direct translation into "SAT modulo theory" (SMT), that is, SAT extended with numeric variables and arithmetic constraints. Though translation to SAT generates much larger formulas, we show that it typically outperforms translation to SMT almost up to the point where the formulas don't fit into memory any longer. We also show that, even though our planner is optimal, it tends to outperform state-of-the-art sub-optimal heuristic planners in domains with tightly constrained resources. Finally we present encouraging initial results on applying the approach to model checking.

#index 1275063
#* Constraint partitioning for solving planning problems with trajectory constraints and goal preferences
#@ Chih-Wei Hsu;Benjamin W. Wah;Ruoyun Huang;Yixin Chen
#t 2007
#c 11
#% 844085
#% 873954
#% 1271962
#% 1272017
#% 1272047
#% 1272116
#! The PDDL3 specifications include soft goals and trajectory constraints for distinguishing highquality plans among the many feasible plans in a solution space. To reduce the complexity of solving a large PDDL3 planning problem, constraint partitioning can be used to decompose its constraints into subproblems of much lower complexity. However, constraint locality due to soft goals and trajectory constraints cannot be effectively exploited by existing subgoal-partitioning techniques developed for solving PDDL2.2 problems. In this paper, we present an improved partition-andresolve strategy for supporting the new features in PDDL3. We evaluate techniques for resolving violated global constraints, optimizing goal preferences, and achieving subgoals in a multivalued representation. Empirical results on the 5th International Planning Competition (IPC5) benchmarks show that our approach is effective and significantly outperforms other competing planners.

#index 1275064
#* Observation reduction for strong plans
#@ Wei Huang;Zhonghua Wen;Yunfei Jiang;Lihua Wu
#t 2007
#c 11
#% 266384
#% 544943
#% 572371
#% 578692
#% 578723
#% 655322
#% 873947
#% 1279364
#% 1289212
#% 1289213
#! Strong planning under full or partial observability has been addressed in the literature. But this research line is carried out under the hypothesis that the set of observation variables is fixed and compulsory. In most real world domains, however, observation variables are optional and many of them are useless in the execution of a plan; on the other side, information acquisition may require some kind of cost. So it is significant to find a minimal set of observation variables which are necessary for the execution of a plan, and to best of our knowledge, it is still an open problem. In this paper we present a first attempt to solve the problem, namely, we define an algorithmthat finds an approximateminimal set of observation variables which are necessary for the execution of a strong plan under full observability (i.e. a state-action table); and transforms the plan into a strong plan under partial observability (i.e. a conditional plan branching on the observations built on these observation variables).

#index 1275065
#* The role of macros in tractable planning over causal graphs
#@ Anders Jonsson
#t 2007
#c 11
#% 172505
#% 251783
#% 417604
#% 1250634
#% 1271885
#% 1271985
#% 1272113
#% 1279345
#% 1290106
#! The complexity of existing planners is bounded by the length of the resulting plan, a fact that limits planning to domains with relatively short solutions. We present a novel planning algorithm that uses the causal graph of a domain to decompose it into subproblems and stores subproblem plans in memory as macros. In many domains, the resulting plan can be expressed using relatively few macros, making it possible to generate exponential length plans in polynomial time. We show that our algorithm is complete, and that there exist special cases for which it is optimal and polynomial. Experimental results demonstrate the potential of using macros to solve planning domains with long solution plans.

#index 1275066
#* Factored planning using decomposition trees
#@ Elena Kelareva;Olivier Buffet;Jinbo Huang;Sylvie Thiébaux
#t 2007
#c 11
#% 98188
#% 131357
#% 329486
#% 336874
#% 1250634
#% 1279345
#% 1279378
#% 1290106
#! Improving AI planning algorithms relies on the ability to exploit the structure of the problem at hand. A promising direction is that of factored planning, where the domain is partitioned into subdomains with as little interaction as possible. Recent work in this field has led to an detailed theoretical analysis of such approaches and to a couple of high-level planning algorithms, but with no practical implementations or with limited experimentations. This paper presents dTreePlan, a new generic factored planning algorithm which uses a decomposition tree to efficiently partition the domain. We discuss some of its aspects, progressively describing a specific implementation before presenting experimental results. This prototype algorithm is a promising contribution--with major possible improvements--and helps enrich the picture of factored planning approaches.

#index 1275067
#* Property persistence in the situation calculus
#@ Ryan F. Kelly;Adrian R. Pearce
#t 2007
#c 11
#% 117869
#% 155825
#% 284106
#% 497779
#! We develop an algorithm for reducing universally quantified situation calculus queries to a form more amenable to automated reasoning. Universal quantification in the situation calculus requires a second-order induction axiom, making automated reasoning difficult for such queries. We show how to reduce queries about property persistence, a common family of universally-quantified query, to an equivalent form that does not quantify over situations. The algorithm for doing so utilizes only first-order reasoning. We give several examples of important reasoning tasks that are facilitated by our approach, including checking for goal impossibility and reasoning about knowledge with partial observability of actions.

#index 1275068
#* Fast (incremental) algorithms for useful classes of simple temporal problems with preferences
#@ T. K. Satish Kumar
#t 2007
#c 11
#% 54215
#% 66934
#% 107137
#% 122671
#% 266107
#% 1250129
#% 1289192
#! In this paper, we will provide a fast polynomialtime algorithm for solving simple temporal problems (STPs) with piecewise linear convex preference functions and a utilitarian objective function. Our algorithm is motivated by the study of the linear programming (LP)-dual of a given mincost circulation problem (MCCP). We will also show how this duality relationship between simple temporal problems with preferences (STPPs) and MCCPs leads to fast incremental algorithms for solving the former. Our algorithms bear important implications in planning, scheduling and execution monitoring scenarios where (partial) plans are subject to repeated changes, and the most preferred solutions to the underlying STPPs have to be computed and updated fast (incrementally).

#index 1275069
#* Handling alternative activities in resource-constrained project scheduling problems
#@ Jürgen Kuster;Dietmar Jannach;Gerhard Friedrich
#t 2007
#c 11
#% 200299
#% 314847
#% 777512
#% 1289379
#% 1777236
#! In the context of operative disruption management, decision support systems have to evaluate the typically manifold options of responding to disturbances: The temporal shift of activities and the allocation of alternative resources can be assessed by the application of generic scheduling frameworks such as the Resource-Constrained Project Scheduling Problem (RCPSP). However, switches from one process variant to another one are usually not supported by the corresponding models, even though they represent a common way of repairing broken schedules in many practical domains. In this paper, we thus show how the RCPSP can be extended by the concept of alternative activities, making it possible to model and search within alternative process execution paths. Beside a formal description of the conceptual extension, we show how such generalized rescheduling problems can be solved by a novel genetic algorithmand summarize the promising results of a detailed evaluation.

#index 1275070
#* Planning for temporally extended goals as propositional satisfiability
#@ Robert Mattmüller;Jussi Rintanen
#t 2007
#c 11
#% 101955
#% 131357
#% 296170
#% 937600
#% 1250631
#% 1290109
#% 1476298
#% 1476301
#! Planning for temporally extended goals (TEGs) expressed as formulae of Linear-time Temporal Logic (LTL) is a proper generalization of classical planning, not only allowing to specify properties of a goal state but of the whole plan execution. Additionally, LTL formulae can be used to represent domain-specific control knowledge to speed up planning. In this paper we extend SATbased planning for LTL goals (akin to bounded LTL model-checking in verification) to partially ordered plans, thus significantly increasing planning efficiency compared to purely sequential SAT planning. We consider a very relaxed notion of partial ordering and show how planning for LTL goals (without the next-time operator) can be translated into a SAT problem and solved very efficiently. The results extend the practical applicability of SATbased planning to a wider class of planning problems. In addition, they could be applied to solving problems in bounded LTL model-checking more efficiently.

#index 1275071
#* A hybridized planner for stochastic domains
#@  Mausam;Piergiorgio Bertoli;Daniel S. Weld
#t 2007
#c 11
#% 86465
#% 181627
#% 329487
#% 337981
#% 361730
#% 578724
#% 655322
#% 840906
#% 842579
#% 873947
#% 1250231
#% 1272092
#% 1272109
#% 1279358
#% 1289549
#% 1289551
#! Markov Decision Processes are a powerful framework for planning under uncertainty, but current algorithms have difficulties scaling to large problems. We present a novel probabilistic planner based on the notion of hybridizing two algorithms. In particular, we hybridize GPT, an exact MDP solver, with MBP, a planner that plans using a qualitative (nondeterministic) model of uncertainty. Whereas exact MDP solvers produce optimal solutions, qualitative planners sacrifice optimality to achieve speed and high scalability. Our hybridized planner, HYBPLAN, is able to obtain the best of both techniques -- speed, quality and scalability. Moreover, HYBPLAN has excellent anytime properties and makes effective use of available time and memory.

#index 1275072
#* Performance analysis of online anticipatory algorithms for large multistage stochastic integer programs
#@ Luc Mercier;Pascal Van Hentenryck
#t 2007
#c 11
#% 181627
#% 261358
#% 495927
#% 534812
#% 1250198
#% 1279410
#% 1713177
#% 1732435
#% 1826941
#! Despite significant algorithmic advances in recent years, finding optimal policies for large-scale, multistage stochastic combinatorial optimization problems remains far beyond the reach of existing methods. This paper studies a complementary approach, online anticipatory algorithms, that make decisions at each step by solving the anticipatory relaxation for a polynomial number of scenarios. Online anticipatory algorithms have exhibited surprisingly good results on a variety of applications and this paper aims at understanding their success. In particular, the paper derives sufficient conditions under which online anticipatory algorithms achieve good expected utility and studies the various types of errors arising in the algorithms including the anticipativity and sampling errors. The sampling error is shown to be negligible with a logarithmic number of scenarios. The anticipativity error is harder to bound and is shown to be low, both theoretically and experimentally, for the existing applications.

#index 1275073
#* Generalizing temporal controllability
#@ Michael D. Moffitt;Martha E. Pollack
#t 2007
#c 11
#% 107137
#% 266107
#% 722504
#% 1269549
#% 1289215
#% 1289683
#! In this paper, we focus on extending the expressive power of constraint-based temporal reasoning formalisms. We begin with the well-known Simple Temporal Problem with Uncertainty, and incorporate three extensions: prior observability, in which the values of uncontrollable events become known prior to their actual occurrence; partial shrinkage, in which an observation event triggers the reduction of a contingent temporal interval; and a generalization of partial shrinkage to requirement links, making it possible to express certain types of uncertainty that may arise even when the time points in a problem are themselves fully controllable. We describe levels of controllability in the resulting formalism, the Generalized STPU, and relate this formalism to related developments in disjunctive temporal reasoning. Throughout, we motivate our approach with simple, real-world examples that illustrate the limitations of existing formalisms and the flexibility of our proposed extensions.

#index 1275074
#* An extension to conformant planning using logic programming
#@ A. Ricardo Morales;Phan Huy Tu;Tran Cao Son
#t 2007
#c 11
#% 322911
#% 333237
#% 400987
#% 400992
#% 572371
#% 655323
#% 789560
#% 907265
#% 999271
#% 1269552
#% 1478800
#% 1656402
#! In this paper we extend the logic programming based conformant planner described in [Son et al., 2005a] to allow it to work on planning problems with more complex descriptions of the initial states. We also compare the extended planner with other concurrent conformant planners.

#index 1275075
#* Average-reward decentralized Markov decision processes
#@ Marek Petrik;Shlomo Zilberstein
#t 2007
#c 11
#% 137576
#% 203604
#% 223835
#% 363744
#% 528006
#% 711934
#% 1269437
#% 1272052
#% 1279314
#! Formal analysis of decentralized decision making has become a thriving research area in recent years, producing a number of multi-agent extensions of Markov decision processes. While much of the work has focused on optimizing discounted cumulative reward, optimizing average reward is sometimes a more suitable criterion. We formalize a class of such problems and analyze its characteristics, showing that it is NP complete and that optimal policies are deterministic. Our analysis lays the foundation for designing two optimal algorithms. Experimental results with a standard problem from the literature illustrate the applicability of these solution techniques.

#index 1275076
#* Graph decomposition for efficient multi-robot path planning
#@ Malcolm Ryan
#t 2007
#c 11
#% 123175
#% 580303
#% 934104
#! In my previous paper (Ryan, 2006) I introduced the concept of subgraph decomposition as a means of reducing the search space in multi-robot planning problems. I showed how partitioning a roadmap into subgraphs of known structure allows us to first plan at a level of abstraction and then resolve these plans into concrete paths without the need for further search so we can solve significantly harder planning tasks with the same resources. However the subgraph types I introduced in that paper, stacks and cliques, are not likely to occur often in realistic planning problems and so are of limited usefulness. In this paper I describe a new kind of subgraph called a hall, which can also be used for planning and which occurs much more commonly in real problems. I explain its formal properties as a planning component and demonstrate its use on a map of the Patrick's container yard at the Port of Brisbane in Queensland Australia.

#index 1275077
#* Memory-bounded dynamic programming for DEC-POMDPs
#@ Sven Seuken;Shlomo Zilberstein
#t 2007
#c 11
#% 528006
#% 643287
#% 773196
#% 1250230
#% 1250351
#% 1269512
#% 1271975
#% 1272052
#% 1272071
#% 1279314
#% 1289555
#! Decentralized decision making under uncertainty has been shown to be intractable when each agent has different partial information about the domain. Thus, improving the applicability and scalability of planning algorithms is an important challenge. We present the first memory-bounded dynamic programming algorithm for finite-horizon decentralized POMDPs. A set of heuristics is used to identify relevant points of the infinitely large belief space. Using these belief points, the algorithm successively selects the best joint policies for each horizon. The algorithm is extremely efficient, having linear time and space complexity with respect to the horizon length. Experimental results show that it can handle horizons that are multiple orders of magnitude larger than what was previously possible, while achieving the same or better solution quality. These results significantly increase the applicability of decentralized decision-making techniques.

#index 1275078
#* Domain independent approaches for finding diverse plans
#@ Biplav Srivastava;Tuan A. Nguyen;Alfonso Gerevini;Subbarao Kambhampati;Minh Binh Do;Ivan Serina
#t 2007
#c 11
#% 283218
#% 344878
#% 397133
#% 900811
#% 1269417
#% 1270132
#% 1272016
#! In many planning situations, a planner is required to return a diverse set of plans satisfying the same goals which will be used by the external systems collectively. We take a domain-independent approach to solving this problem. We propose different domain independent distance functions among plans that can provide meaningful insights about the diversity in the plan set. We then describe how two representative state-of-the-art domain independent planning approaches - one based on compilation to CSP, and the other based on heuristic local search - can be adapted to produce diverse plans. We present empirical evidence demonstrating the effectiveness of our approaches.

#index 1275079
#* Planning under risk and Knightian uncertainty
#@ Felipe W. Trevizan;Fábio G. Cozman;Leliane N. De Barros
#t 2007
#c 11
#% 3034
#% 63425
#% 267725
#% 318485
#% 361730
#% 604673
#% 644560
#% 1289544
#% 1289568
#% 1349518
#% 1673000
#% 1681780
#! Two noteworthy models of planning in AI are probabilistic planning (based on MDPs and its generalizations) and nondeterministic planning (mainly based on model checking). In this paper we: (1) show that probabilistic and nondeterministic planning are extremes of a rich continuum of problems that deal simultaneously with risk and (Knightian) uncertainty; (2) obtain a unifying model for these problems using imprecise MDPs; (3) derive a simplified Bellman's principle of optimality for our model; and (4) show how to adapt and analyze state-of-art algorithms such as (L)RTDP and LDFS in this unifying setup. We discuss examples and connections to various proposals for planning under (general) uncertainty.

#index 1275080
#* Progression of situation calculus action theories with incomplete information
#@ Stavros Vassos;Hector Levesque
#t 2007
#c 11
#% 7047
#% 229083
#% 284647
#% 322911
#% 340737
#% 342119
#% 572366
#% 643572
#% 815506
#% 998125
#% 1215046
#% 1279222
#% 1279223
#% 1289432
#% 1289434
#! In this paper, we propose a new progression mechanism for a restricted form of incomplete knowledge formulated as a basic action theory in the situation calculus. Specifically, we focus on functional fluents and deal directly with the possible values these fluents may have and how these values are affected by both physical and sensing actions. The method we propose is logically complete and can be calculated efficiently using database techniques under certain reasonable assumptions.

#index 1275081
#* Relational knowledge with predictive state representations
#@ David Wingate;Vishal Soni;Britton Wolfe;Satinder Singh
#t 2007
#c 11
#% 333786
#% 458377
#% 770781
#% 840956
#% 850430
#% 1289484
#% 1289565
#! Most work on Predictive Representations of State (PSRs) has focused on learning and planning in unstructured domains (for example, those represented by flat POMDPs). This paper extends PSRs to represent relational knowledge about domains, so that they can use policies that generalize across different tasks, capture knowledge that ignores irrelevant attributes of objects, and represent policies in a way that is independent of the size of the state space. Using a blocks world domain, we show how generalized predictions about the future can compactly capture relations between objects, which in turn can be used to naturally specify relational-style options and policies. Because our representation is expressed solely in terms of actions and observations, it has extensive semantics which are statistics about observable quantities.

#index 1275082
#* Discriminative learning of beam-search heuristics for planning
#@ Yuehua Xu;Alan Fern;Sungwook Yoon
#t 2007
#c 11
#% 322913
#% 345431
#% 464434
#% 544930
#% 722755
#% 840856
#% 854636
#% 1269553
#% 1271962
#% 1290042
#! We consider the problem of learning heuristics for controlling forward state-space beam search in AI planning domains. We draw on a recent framework for "structured output classification" (e.g. syntactic parsing) known as learning as search optimization (LaSO). The LaSO approach uses discriminative learning to optimize heuristic functions for search-based computation of structured outputs and has shown promising results in a number of domains. However, the search problems that arise in AI planning tend to be qualitatively very different from those considered in structured classification, which raises a number of potential difficulties in directly applying LaSO to planning. In this paper, we discuss these issues and describe a LaSO-based approach for discriminative learning of beam-search heuristics in AI planning domains. We give convergence results for this approach and present experiments in several benchmark domains. The results show that the discriminatively trained heuristic can outperform the one used by the planner FF and another recent non-discriminative learning approach.

#index 1275083
#* Using learned policies in heuristic-search planning
#@ SungWook Yoon;Alan Fern;Robert Givan
#t 2007
#c 11
#% 135539
#% 289949
#% 393786
#% 449559
#% 1269553
#% 1271962
#% 1272016
#% 1275306
#% 1650413
#! Many current state-of-the-art planners rely on forward heuristic search. The success of such search typically depends on heuristic distance-to-the-goal estimates derived from the plangraph. Such estimates are effective in guiding search for many domains, but there remain many other domains where current heuristics are inadequate to guide forward search effectively. In some of these domains, it is possible to learn reactive policies from example plans that solve many problems. However, due to the inductive nature of these learning techniques, the policies are often faulty, and fail to achieve high success rates. In this work, we consider how to effectively integrate imperfect learned policies with imperfect heuristics in order to improve over each alone. We propose a simple approach that uses the policy to augment the states expanded during each search step. In particular, during each search node expansion, we add not only its neighbors, but all the nodes along the trajectory followed by the policy from the node until some horizon. Empirical results show that our proposed approach benefits both of the leveraged automated techniques, learning and heuristic search, outperforming the state-of-the-art in most benchmark planning domains.

#index 1275084
#* Effective control knowledge transfer through learning skill and representation hierarchies
#@ Mehran Asadi;Manfred Huber
#t 2007
#c 11
#% 286423
#% 655326
#% 823852
#% 1271827
#% 1289475
#% 1650710
#! Learning capabilities of computer systems still lag far behind biological systems. One of the reasons can be seen in the inefficient re-use of control knowledge acquired over the lifetime of the artificial learning system. To address this deficiency, this paper presents a learning architecture which transfers control knowledge in the form of behavioral skills and corresponding representation concepts from one task to subsequent learning tasks. The presented system uses this knowledge to construct a more compact state space representation for learning while assuring bounded optimality of the learned task policy by utilizing a representation hierarchy. Experimental results show that the presented method can significantly outperform learning on a flat state space representation and the MAXQ method for hierarchical reinforcement learning.

#index 1275085
#* Image modeling using tree structured conditional random fields
#@ Pranjal Awasthi;Aakanksha Gagrani;Balaraman Ravindran
#t 2007
#c 11
#% 44876
#% 338741
#% 443972
#% 450888
#% 464434
#% 836836
#% 1502489
#% 1667638
#! In this paper we present a discriminative framework based on conditional random fields for stochastic modeling of images in a hierarchical fashion. The main advantage of the proposed framework is its ability to incorporate a rich set of interactions among the image sites. We achieve this by inducing a hierarchy of hidden variables over the given label field. The proposed tree like structure of our model eliminates the need for a huge parameter space and at the same time permits the use of exact and efficient inference procedures based on belief propagation. We demonstrate the generality of our approach by applying it to two important computer vision tasks, namely image labeling and object detection. The model parameters are trained using the contrastive divergence algorithm. We report the performance on real world images and compare it with the existing approaches.

#index 1275086
#* Visually tracking football games based on TV broadcasts
#@ Michael Beetz;Suat Gedikli;Jan Bandouch;Bernhard Kirchlechner;Nico V. Hoyningen-Huene;Alexander Perzylo
#t 2007
#c 11
#% 207004
#% 319464
#% 627603
#% 775696
#! This paper describes ASPOGAMO, a visual tracking system that determines the coordinates and trajectories of football players in camera view based on TV broadcasts. To do so, ASPOGAMO solves a complex probabilistic estimation problem that consists of three subproblems that interact in subtle ways: the estimation of the camera direction and zoom factor, the tracking and smoothing of player routes, and the disambiguation of tracked players after occlusions. The paper concentrates on system aspects that make it suitable for operating under unconstrained conditions and in (almost) realtime. We report on results obtained in a public demonstration at RoboCup 2006 where we conducted extensive experiments with real data from live coverage of World Cup 2006 games in Germany.

#index 1275087
#* Mediating between qualitative and quantitative representations for task-orientated human-robot interaction
#@ Michael Brenner;Nick Hawes;John Kelleher;Jeremy Wyatt
#t 2007
#c 11
#% 398947
#% 939594
#% 1271217
#% 1271962
#% 1272008
#% 1732930
#! In human-robot interaction (HRI) it is essential that the robot interprets and reacts to a human's utterances in a manner that reflects their intended meaning. In this paper we present a collection of novel techniques that allow a robot to interpret and execute spoken commands describing manipulation goals involving qualitative spatial constraints (e.g. "put the red ball near the blue cube"). The resulting implemented system integrates computer vision, potential field models of spatial relationships, and action planning to mediate between the continuous real world, and discrete, qualitative representations used for symbolic reasoning.

#index 1275088
#* Fast image alignment using anytime algorithms
#@ Rupert Brooks;Tal Arbel;Doina Precup
#t 2007
#c 11
#% 143454
#% 329485
#% 450949
#% 625125
#% 900210
#% 1250130
#% 1855116
#% 1855551
#! Image alignment refers to finding the best transformation from a fixed reference image to a new image of a scene. This process is often guided by similarity measures between images, computed based on the image data. However, in time-critical applications state-of-the-art methods for computing similarity are too slow. Instead of using all the image data to compute similarity, one can use a subset of pixels to improve the speed, but often this comes at the cost of reduced accuracy. This makes the problem of image alignment a natural application domain for deliberation control using anytime algorithms. However, almost no research has been done in this direction. In this paper, we present anytime versions for the computation of two common image similarity measures: mean squared difference and mutual information. Off-line, we learn a performance profile specific to each measure, which is then used on-line to select the appropriate amount of pixels to process at each optimization step. When tested against existing techniques, our method achieves comparable quality and robustness with significantly less computation.

#index 1275089
#* Learning to walk through imitation
#@ Rawichote Chalodhorn;David B. Grimes;Keith Grochow;Rajesh P. N. Rao
#t 2007
#c 11
#% 72533
#% 384911
#% 570015
#% 643107
#% 771053
#% 775627
#% 1051470
#! Programming a humanoid robot to walk is a challenging problem in robotics. Traditional approaches rely heavily on prior knowledge of the robot's physical parameters to devise sophisticated control algorithms for generating a stable gait. In this paper, we provide, to our knowledge, the first demonstration that a humanoid robot can learn to walk directly by imitating a human gait obtained from motion capture (mocap) data. Training using human motion capture is an intuitive and flexible approach to programming a robot but direct usage of mocap data usually results in dynamically unstable motion. Furthermore, optimization using mocap data in the humanoid full-body joint-space is typically intractable. We propose a new modelfree approach to tractable imitation-based learning in humanoids. We represent kinematic information from human motion capture in a low dimensional subspace and map motor commands in this lowdimensional space to sensory feedback to learn a predictive dynamic model. This model is used within an optimization framework to estimate optimal motor commands that satisfy the initial kinematic constraints as best as possible while at the same time generating dynamically stable motion. We demonstrate the viability of our approach by providing examples of dynamically stable walking learned from mocap data using both a simulator and a real humanoid robot.

#index 1275090
#* Dealing with perception errors in multi-robot system coordination
#@ Alessandro Farinelli;Daniele Nardi;Paul Scerri;Alberto Ingenito
#t 2007
#c 11
#% 823934
#% 1271975
#% 1673037
#! A prerequisite to efficient behavior by a multi-robot team is the ability to accurately perceive the environment. In this paper, we present an approach to deal with sensing uncertainty at the coordination level. Specifically, robots attach information regarding features that caused the initiation of a course of action, to any coordination message for that activity. Further information regarding such features, acquired by the team, are then combined and the expected utility of the started action is re-evaluated accordingly. Experiments show that the approach allows to coordinate a large group of robots, addressing sensing uncertainty in a tractable way.

#index 1275091
#* Team programming in Golog under partial observability
#@ Alessandro Farinelli;Alberto Finzi;Thomas Lukasiewicz
#t 2007
#c 11
#% 181622
#% 342119
#% 363744
#% 529345
#% 1272045
#% 1279314
#% 1279355
#% 1289241
#% 1289329
#% 1386436
#% 1650413
#! In this paper, we present the agent programming language TEAMGOLOG, which is a novel approach to programming a team of cooperative agents under partial observability. Every agent is associated with a partial control program in Golog, which is completed by the TEAMGOLOG interpreter in an optimal way by assuming a decision-theoretic semantics. The approach is based on the key concepts of a synchronization state and a communication state, which allow the agents to passively resp. actively coordinate their behavior, while keeping their belief states, observations, and activities invisible to the other agents. We show the usefulness of the approach in a rescue simulated domain.

#index 1275092
#* A new approach for stereo matching in autonomous mobile robot applications
#@ Pasquale Foggia;Jean-Michel Jolion;Alessandro Limongiello;Mario Vento
#t 2007
#c 11
#% 165464
#% 184523
#% 303490
#% 344568
#% 424094
#% 443841
#% 443963
#% 592037
#% 1854521
#! We propose a new approach for stereo matching in Autonomous Mobile Robot applications. In this framework an accurate but slow reconstruction of the 3D scene is not needed; rather, it is more important to have a fast localization of the obstacles to avoid them. All the methods in the literature are based on a punctual correspondence, but they are inefficient in realistic contexts for the presence of uniform patterns, or some perturbations between the two images of the stereo pair. Our idea is to face the stereo matching problem as a matching between homologous regions, instead of a point matching. The stereo images are represented as graphs and a graph matching is computed to find homologous regions. We present some results on a standard stereo database and also on a more realistic stereo sequence acquired from a robot moving in an indoor environment, and a performance comparison with other approaches in the literature is reported and discussed. Our method is strongly robust in case of some fluctuations of the stereo pair, homogeneous and repetitive regions, and is fast. The result is a semi-dense disparity map, leaving only a few regions in the scene unmatched.

#index 1275093
#* Voronoi random fields: extracting the topological structure of indoor environments via place labeling
#@ Stephen Friedman;Hanna Pasula;Dieter Fox
#t 2007
#c 11
#% 73441
#% 247930
#% 367254
#% 464434
#% 578682
#% 724344
#% 840913
#% 850430
#% 921068
#% 1289583
#% 1650318
#! The ability to build maps of indoor environments is extremely important for autonomous mobile robots. In this paper we introduce Voronoi random fields (VRFs), a novel technique for mapping the topological structure of indoor environments. Our maps describe environments in terms of their spatial layout along with information about the different places and their connectivity. To build these maps, we extract a Voronoi graph from an occupancy grid map generated with a laser range-finder, and then represent each point on the Voronoi graph as a node of a conditional random field, which is a discriminatively trained graphical model. The resulting VRF estimates the label of each node, integrating features from both the map and the Voronoi topology. The labels provide a segmentation of an environment, with the different segments corresponding to rooms, hallways, or doorways. Experiments using different maps show that our technique is able to label unknown environments based on parameters learned from other environments.

#index 1275094
#* Peripheral-foveal vision for real-time object recognition and tracking in video
#@ Stephen Gould;Joakim Arfvidsson;Adrian Kaehler;Benjamin Sapp;Marius Messner;Gary Bradski;Paul Baumstarck;Sukwon Chung;Andrew Y. Ng
#t 2007
#c 11
#% 268121
#% 315278
#% 318135
#% 334707
#% 736300
#% 838784
#% 1650568
#% 1712774
#! Human object recognition in a physical 3-d environment is still far superior to that of any robotic vision system. We believe that one reason (out of many) for this--one that has not heretofore been significantly exploited in the artificial vision literature--is that humans use a fovea to fixate on, or near an object, thus obtaining a very high resolution image of the object and rendering it easy to recognize. In this paper, we present a novel method for identifying and tracking objects in multiresolution digital video of partially cluttered environments. Our method is motivated by biological vision systems and uses a learned "attentive" interest map on a low resolution data stream to direct a high resolution "fovea." Objects that are recognized in the fovea can then be tracked using peripheral vision. Because object recognition is run only on a small foveal image, our system achieves performance in real-time object recognition and tracking that is well beyond simpler systems.

#index 1275095
#* Structure inference for Bayesian multisensory perception and tracking
#@ Timothy M. Hospedales;Joel J. Cartwright;Sethu Vijayakumar
#t 2007
#c 11
#% 246836
#% 387978
#% 641984
#% 739899
#% 761283
#% 855580
#! We investigate a solution to the problem of multisensor perception and tracking by formulating it in the framework of Bayesian model selection. Humans robustly associate multi-sensory data as appropriate, but previous theoretical work has focused largely on purely integrative cases, leaving segregation unaccounted for and unexploited by machine perception systems. We illustrate a unifying, Bayesian solution to multi-sensor perception and tracking which accounts for both integration and segregation by explicit probabilistic reasoning about data association in a temporal context. Unsupervised learning of such a model with EM is illustrated for a real world audio-visual application.

#index 1275096
#* Fast incremental square root information smoothing
#@ Michael Kaess;Ananth Ranganathan;Frank Dellaert
#t 2007
#c 11
#% 724286
#% 1279377
#% 1768660
#! We propose a novel approach to the problem of simultaneous localization and mapping (SLAM) based on incremental smoothing, that is suitable for real-time applications in large-scale environments. The main advantages over filter-based algorithms are that we solve the full SLAM problem without the need for any approximations, and that we do not suffer from linearization errors. We achieve efficiency by updating the square-root information matrix, a factored version of the naturally sparse smoothing information matrix. We can efficiently recover the exact trajectory and map at any given time by back-substitution. Furthermore, our approach allows access to the exact covariances, as it does not suffer from under-estimation of uncertainties, which is another problem inherent to filters. We present simulation-based results for the linear case, showing constant time updates for exploration tasks. We further evaluate the behavior in the presence of loops, and discuss how our approach extends to the non-linear case. Finally, we evaluate the overall non-linear algorithm on the standard Victoria Park data set.

#index 1275097
#* Optimal multi-sensor based multi target detection by moving sensors to the maximal clique in a covering graph
#@ Ganesh P. Kumar;K. Madhava Krishna
#t 2007
#c 11
#% 418831
#! Different methodologies have been employed to solve the multi-sensor multi-target detection problem in a variety of scenarios. In this paper, we devise a time-step optimal algorithm for this problem when all but a few parameters of the sensor/target system are unknown. Using the concept of covering graph, we find an optimum solution for a single sensor, which is extended to multiple sensors by a tagging operation. Both covering graph and tagging are novel concepts, developed in the context of the detection problem for the first time, and bring a mathematical elegance to its solution. Furthermore, an implementation of the resulting algorithm is found to perform better than other notable approaches. The strong theoretical foundation, combined with the practical efficacy of the algorithm, makes it a very attractive solution to the problem.

#index 1275098
#* Bayesian tensor inference for sketch-based facial photo hallucination
#@ Wei Liu;Xiaoou Tang;Jianzhuang Liu
#t 2007
#c 11
#% 316143
#% 323242
#% 443998
#% 457831
#% 724249
#% 812434
#% 812529
#% 815955
#% 1858130
#! This paper develops a statistical inference approach, Bayesian Tensor Inference, for style transformation between photo images and sketch images of human faces. Motivated by the rationale that image appearance is determined by two cooperative factors: image content and image style, we first model the interaction between these factors through learning a patch-based tensor model. Second, by introducing a common variation space, we capture the inherent connection between photo patch space and sketch patch space, thus building bidirectional mapping/inferring between the two spaces. Subsequently, we formulate a Bayesian approach accounting for the statistical inference from sketches to their corresponding photos in terms of the learned tensor model. Comparative experiments are conducted to contrast the proposed method with state-of-the-art algorithms for facial sketch synthesis in a novel face hallucination scenario: sketch-based facial photo hallucination. The encouraging results obtained convincingly validate the effectiveness of our method.

#index 1275099
#* Topological mapping through distributed, passive sensors
#@ Dimitri Marinakis;Gregory Dudek
#t 2007
#c 11
#% 495797
#% 741457
#% 879222
#% 1271848
#% 1502425
#% 1851033
#! In this paper we address the problem of inferring the topology, or inter-node navigability, of a sensor network given non-discriminating observations of activity in the environment. By exploiting motion present in the environment, our approach is able to recover a probabilistic model of the sensor network connectivity graph and the underlying traffic trends. We employ a reasoning system made up of a stochastic Expectation Maximization algorithm and a higher level search strategy employing the principle of Occam's Razor to look for the simplest solution explaining the data. The technique is assessed through numerical simulations and experiments conducted on a real sensor network.

#index 1275100
#* A distributed architecture for symbolic data fusion
#@ Fulvio Mastrogiovanni;Antonio Sgorbissa;Renato Zaccaria
#t 2007
#c 11
#% 85153
#% 570310
#% 1784775
#! This paper presents a distributed knowledge representation and data fusion system designed for highly integrated Ambient Intelligence applications. The architecture, based on the idea of an ecosystem of interacting artificial entities, is a framework for collaborating agents to perform an intelligent multi-sensor data fusion. In particular, we focus on the cognitive layers leading the overall data acquisition process. The approach has been thoroughly tested in simulation, and part of it has been already exploited in successful applications.

#index 1275101
#* Inferring long-term user properties based on users' location history
#@ Yutaka Matsuo;Naoaki Okazaki;Kiyoshi Izumi;Yoshiyuki Nakamura;Takuichi Nishimura;Kôiti Hasida;Hideyuki Nakashima
#t 2007
#c 11
#% 114573
#% 190581
#% 279755
#% 420181
#% 424016
#% 438456
#% 458379
#% 723186
#% 739767
#% 766436
#% 839751
#% 839755
#% 1279344
#% 1289473
#% 1289474
#% 1721315
#! Recent development of location technologies enables us to obtain the location history of users. This paper proposes a new method to infer users' longterm properties from their respective location histories. Counting the instances of sensor detection for every user, we can obtain a sensor-user matrix. After generating features from the matrix, a machine learning approach is taken to automatically classify users into different categories for each user property. Inspired by information retrieval research, the problem to infer user properties is reduced to a text categorization problem. We compare weightings of several features and also propose sensor weighting. Our algorithms are evaluated using experimental location data in an office environment.

#index 1275102
#* Co-localization from labeled and unlabeled data using graph Laplacian
#@ Jeffrey Junfeng Pan;Qiang Yang
#t 2007
#c 11
#% 313959
#% 337494
#% 339218
#% 342621
#% 593047
#% 613383
#% 797050
#% 819455
#% 1250661
#% 1269361
#% 1289567
#! This paper addresses the problem of recovering the locations of both mobile devices and access points from radio signals, a problem which we call colocalization, by exploiting both labeled and unlabeled data from mobile devices and access points. We first propose a solution using Latent Semantic Indexing to construct the relative locations of the mobile devices and access points when their absolute locations are unknown. We then propose a semi-supervised learning algorithm based on manifold to obtain the absolute locations of the devices. Both solutions are finally combined together in terms of graph Laplacian. Extensive experiments are conducted in wireless local-area networks, wireless sensor networks and radio frequency identification networks. The experimental results showthat we can achieve high accuracy with much less calibration effort as compared to several previous systems.

#index 1275103
#* Feature based occupancy grid maps for sonar based safe-mapping
#@ Amit Kumar Pandey;K. Madhava Krishna;Mainak Nath
#t 2007
#c 11
#% 403449
#% 696198
#% 719358
#% 1279373
#! This paper presents a methodology for integrating features within the occupancy grid (OG) framework. The OG maps provide a dense representation of the environment. In particular they give information for every range measurement projected onto a grid. However independence assumptions between cells during updates as well as not considering sonar models lead to inconsistent maps, which may also lead the robot to take some decisions which may be unsafe or which may introduce an unnecessary overhead of run-time collision avoidance behaviors. Feature based maps provide more consistent representation by implicitly considering correlation between cells. But they are sparse due to sparseness of features in a typical environment. This paper provides a method for integrating feature based representations within the standard Bayesian framework of OG and provides a dense, more accurate and safe representation than standard OG methods.

#index 1275104
#* Probabilistic mobile manipulation in dynamic environments, with application to opening doors
#@ Anna Petrovskaya;Andrew Y. Ng
#t 2007
#c 11
#% 283140
#% 746729
#% 1269570
#% 1650347
#! In recent years, probabilistic approaches have found many successful applications to mobile robot localization, and to object state estimation for manipulation. In this paper, we propose a unified approach to these two problems that dynamically models the objects to be manipulated and localizes the robot at the same time. Our approach applies in the common setting where only a lowresolution (10cm) grid-map of a building is available, but we also have a high-resolution (0.1cm) model of the object to be manipulated. Our method is based on defining a unifying probabilistic model over these two representations. The resulting algorithm works in real-time, and estimates the position of objects with sufficient precision for manipulation tasks. We apply our approach to the task of navigating from one office to another (including manipulating doors). Our approach, successfully tested on multiple doors, allows the robot to navigate through a hallway to an office door, grasp and turn the door handle, and continuously manipulate the door as it moves into the office.

#index 1275105
#* Efficient failure detection on mobile robots using particle filters with Gaussian process proposals
#@ Christian Plagemann;Dieter Fox;Wolfram Burgard
#t 2007
#c 11
#% 707413
#% 1279352
#% 1289566
#! The ability to detect failures and to analyze their causes is one of the preconditions of truly autonomous mobile robots. Especially online failure detection is a complex task, since the effects of failures are typically difficult to model and often resemble the noisy system behavior in a fault-free operational mode. The extremely low a priori likelihood of failures poses additional challenges for detection algorithms. In this paper, we present an approach that applies Gaussian process classification and regression techniques for learning highly effective proposal distributions of a particle filter that is applied to track the state of the system. As a result, the efficiency and robustness of the state estimation process is substantially improved. In practical experiments carried out with a real robot we demonstrate that our system is capable of detecting collisions with unseen obstacles while at the same time estimating the changing point of contact with the obstacle.

#index 1275106
#* Loopy SAM
#@ Ananth Ranganathan;Michael Kaess;Frank Dellaert
#t 2007
#c 11
#% 28541
#% 82083
#% 927528
#% 984708
#% 1279377
#% 1760836
#! Smoothing approaches to the Simultaneous Localization and Mapping (SLAM) problem in robotics are superior to the more common filtering approaches in being exact, better equipped to deal with non-linearities, and computing the entire robot trajectory. However, while filtering algorithms that perform map updates in constant time exist, no analogous smoothing method is available. We aim to rectify this situation by presenting a smoothingbased solution to SLAM using Loopy Belief Propagation (LBP) that can perform the trajectory and map updates in constant time except when a loop is closed in the environment. The SLAM problem is represented as a Gaussian Markov Random Field (GMRF) over which LBP is performed. We prove that LBP, in this case, is equivalent to Gauss-Seidel relaxation of a linear system. The inability to compute marginal covariances efficiently in a smoothing algorithm has previously been a stumbling block to their widespread use. LBP enables the efficient recovery of the marginal covariances, albeit approximately, of landmarks and poses. While the final covariances are overconfident, the ones obtained from a spanning tree of the GMRF are conservative, making them useful for data association. Experiments in simulation and using real data are presented.

#index 1275107
#* Depth estimation using monocular and stereo cues
#@ Ashutosh Saxena;Jamie Schulte;Andrew Y. Ng
#t 2007
#c 11
#% 282188
#% 409857
#% 424094
#% 443941
#% 464434
#% 634342
#% 724276
#% 836753
#% 840909
#% 883994
#% 1502489
#! Depth estimation in computer vision and robotics is most commonly done via stereo vision (stereopsis), in which images from two cameras are used to triangulate and estimate distances. However, there are also numerous monocular visual cues--such as texture variations and gradients, defocus, color/haze, etc. --that have heretofore been little exploited in such systems. Some of these cues apply even in regions without texture, where stereo would work poorly. In this paper, we apply a Markov Random Field (MRF) learning algorithm to capture some of these monocular cues, and incorporate them into a stereo system. We show that by adding monocular cues to stereo (triangulation) ones, we obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone. This holds true for a large variety of environments, including both indoor environments and unstructured outdoor environments containing trees/forests, buildings, etc. Our approach is general, and applies to incorporating monocular cues together with any off-the-shelf stereo system.

#index 1275108
#* Efficient planning of informative paths for multiple robots
#@ Amarjeet Singh;Andreas Krause;Carlos Guestrin;William Kaiser;Maxim Batalin
#t 2007
#c 11
#% 76270
#% 303075
#% 723908
#% 808255
#% 836516
#% 840868
#% 862540
#! In many sensing applications, including environmental monitoring, measurement systems must cover a large space with only limited sensing resources. One approach to achieve required sensing coverage is to use robots to convey sensors within this space. Planning the motion of these robots - coordinating their paths in order to maximize the amount of information collected while placing bounds on their resources (e.g., path length or energy capacity) - is aNP-hard problem. In this paper, we present an efficient path planning algorithm that coordinates multiple robots, each having a resource constraint, to maximize the "informativeness" of their visited locations. In particular, we use a Gaussian Process to model the underlying phenomenon, and use the mutual information between the visited locations and remainder of the space to characterize the amount of information collected. We provide strong theoretical approximation guarantees for our algorithm by exploiting the submodularity property of mutual information. In addition, we improve the efficiency of our approach by extending the algorithm using branch and bound and a region-based decomposition of the space. We provide an extensive empirical analysis of our algorithm, comparing with existing heuristics on datasets from several real world sensing applications.

#index 1275109
#* Color learning on a mobile robot: towards full autonomy under changing illumination
#@ Mohan Sridharan;Peter Stone
#t 2007
#c 11
#% 120270
#% 349208
#% 505094
#% 529827
#% 729437
#% 1269569
#! A central goal of robotics and AI is to be able to deploy an agent to act autonomously in the real world over an extended period of time. It is commonly asserted that in order to do so, the agent must be able to learn to deal with unexpected environmental conditions. However an ability to learn is not sufficient. For true extended autonomy, an agent must also be able to recognize when to abandon its current model in favor of learning a new one; and how to learn in its current situation. This paper presents a fully implemented example of such autonomy in the context of color map learning on a vision-based mobile robot for the purpose of image segmentation. Past research established the ability of a robot to learn a color map in a single fixed lighting condition when manually given a "curriculum," an action sequence designed to facilitate learning. This paper introduces algorithms that enable a robot to i) devise its own curriculum; and ii) recognize when the lighting conditions have changed sufficiently to warrant learning a new color map.

#index 1275110
#* Online speed adaptation using supervised learning for high-speed, off-road autonomous driving
#@ David Stavens;Gabriel Hoffmann;Sebastian Thrun
#t 2007
#c 11
#% 418658
#% 931347
#% 1768631
#% 1768760
#! The mobile robotics community has traditionally addressed motion planning and navigation in terms of steering decisions. However, selecting the best speed is also important - beyond its relationship to stopping distance and lateral maneuverability. Consider a high-speed (35 mph) autonomous vehicle driving off-road through challenging desert terrain. The vehicle should drive slowly on terrain that poses substantial risk. However, it should not dawdle on safe terrain. In this paper we address one aspect of risk - shock to the vehicle. We present an algorithm for trading-off shock and speed in realtime and without human intervention. The trade-off is optimized using supervised learning to match human driving. The learning process is essential due to the discontinuous and spatially correlated nature of the control problem - classical techniques do not directly apply. We evaluate performance over hundreds of miles of autonomous driving, including performance during the 2005 DARPA Grand Challenge. This approach was the deciding factor in our vehicle's speed for nearly 20% of the DARPA competition - more than any other constraint except the DARPA-imposed speed limits - and resulted in the fastest finishing time.

#index 1275111
#* Instance-based AMN classification for improved object recognition in 2D and 3D laser range data
#@ Rudolph Triebel;Richard Schmidt;Óscar Martínez Mozos;Wolfram Burgard
#t 2007
#c 11
#% 248810
#% 452113
#% 569156
#% 664407
#% 724347
#% 770866
#% 812487
#% 827631
#% 990072
#% 1289583
#% 1502409
#% 1650403
#! In this paper, we present an algorithm to identify different types of objects from 2D and 3D laser range data. Our method is a combination of an instance-based feature extraction similar to the Nearest-Neighbor classifier (NN) and a collective classification method that utilizes associative Markov networks (AMNs). Compared to previous approaches, we transform the feature vectors so that they are better separable by linear hyperplanes, which are learned by the AMN classifier. We present results of extensive experiments in which we evaluate the performance of our algorithm on several recorded indoor scenes and compare it to the standard AMN approach as well as the NN classifier. The classification rate obtained with our algorithm substantially exceeds those of the AMN and the NN.

#index 1275112
#* MESH-based active Monte Carlo recognition (MESH-AMCR)
#@ Felix V. Hundelshausen;H. J. Wünsche;M. Block;R. Kompass;R. Rojas
#t 2007
#c 11
#% 319464
#% 337494
#% 443975
#% 755467
#% 760805
#% 778279
#% 780859
#% 812301
#% 812600
#% 883810
#% 883971
#% 1386444
#% 1502463
#% 1730639
#! In this paper we extend Active Monte Carlo Recognition (AMCR), a recently proposed framework for object recognition. The approach is based on the analogy between mobile robot localization and object recognition. Up to now AMCR was only shown to work for shape recognition on binary images. In this paper, we significantly extend the approach to work on realistic images of real world objects. We accomplish recognition under similarity transforms and even severe non-rigid and non-affine deformations. We show that our approach works on databases with thousands of objects, that it can better discriminate between objects than state-of-the art approaches and that it has significant conceptual advantages over existing approaches: It allows iterative recognition with simultaneous tracking, iteratively guiding attention to discriminative parts, the inclusion of feedback loops, the simultaneous propagation of multiple hypotheses, multiple object recognition and simultaneous segmentation and recognition. While recognition takes place triangular meshes are constructed that precisely define the correspondence between input and prototype object, even in the case of strong non-rigid deformations.

#index 1275113
#* Common sense based joint training of human activity recognizers
#@ Shiaokai Wang;William Pentney;Ana-Maria Popescu;Tanzeem Choudhury;Matthai Philipose
#t 2007
#c 11
#% 44876
#% 754115
#% 788954
#% 812412
#% 843359
#% 1269362
#% 1270128
#% 1289473
#% 1650579
#! Given sensors to detect object use, commonsense priors of object usage in activities can reduce the need for labeled data in learning activity models. It is often useful, however, to understand how an object is being used, i.e., the action performed on it. We show how to add personal sensor data (e.g., accelerometers) to obtain this detail, with little labeling and feature selection overhead. By synchronizing the personal sensor data with object-use data, it is possible to use easily specified commonsense models to minimize labeling overhead. Further, combining a generative common sense model of activity with a discriminative model of actions can automate feature selection. On observed activity data, automatically trained action classifiers give 40/85% precision/recall on 10 actions. Adding actions to pure object-use improves precision/recall from 76/85% to 81/90% over 12 activities.

#index 1275114
#* Using a mobile robot for cognitive mapping
#@ Chee K. Wong;Jochen Schmidt;Wai K. Yeap
#t 2007
#c 11
#% 175013
#% 229084
#% 269561
#% 303954
#% 808837
#% 855580
#% 900190
#! When animals (including humans) first explore a new environment, what they remember is fragmentary knowledge about the places visited. Yet, they have to use such fragmentary knowledge to find their way home. Humans naturally use more powerful heuristics while lower animals have shown to develop a variety of methods that tend to utilize two key pieces of information, namely distance and orientation information. Their methods differ depending on how they sense their environment. Could a mobile robot be used to investigate the nature of such a process, commonly referred to in the psychological literature as cognitive mapping? What might be computed in the initial explorations and how is the resulting "cognitive map" be used to return home? In this paper, we presented a novel approach using a mobile robot to do cognitive mapping. Our robot computes a "cognitive map" and uses distance and orientation information to find its way home. The process developed provides interesting insights into the nature of cognitive mapping and encourages us to use a mobile robot to do cognitive mapping in the future, as opposed to its popular use in robot mapping.

#index 1275115
#* AWA*-a window constrained anytime heuristic search algorithm
#@ Sandip Aine;P. P. Chakrabarti;Rajeev Kumar
#t 2007
#c 11
#% 241
#% 93138
#% 266199
#% 578810
#% 620162
#% 677386
#! This work presents an iterative anytime heuristic search algorithm called Anytime Window A* (AWA*) where node expansion is localized within a sliding window comprising of levels of the search tree/graph. The search starts in depth-first mode and gradually proceeds towards A* by incrementing the window size. An analysis on a uniform tree model provides some very useful properties of this algorithm. A modification of AWA* is presented to guarantee bounded optimal solutions at each iteration. Experimental results on the 0/1 Knapsack problem and TSP demonstrate the efficacy of the proposed techniques over some existing anytime search methods.

#index 1275116
#* GUNSAT: a greedy local search algorithm for unsatisfiability
#@ Gilles Audemard;Laurent Simon
#t 2007
#c 11
#% 6068
#% 41220
#% 288165
#% 288366
#% 327779
#% 336874
#% 578747
#% 750050
#% 1250144
#% 1273681
#% 1289181
#% 1289197
#% 1674538
#% 1698697
#% 1698734
#% 1728045
#! Local search algorithms for satisfiability testing are still the best methods for a large number of problems, despite tremendous progresses observed on complete search algorithms over the last few years. However, their intrinsic limit does not allow them to address UNSAT problems. Ten years ago, this question challenged the community without any answer: was it possible to use local search algorithm for UNSAT formulae? We propose here a first approach addressing this issue, that can beat the best resolution-based completemethods. We define the landscape of the search by approximating the number of filtered clauses by resolution proof. Furthermore, we add high-level reasoning mechanism, based on Extended Resolution and Unit Propagation Look-Ahead to make this new and challenging approach possible. Our new algorithm also tends to be the first step on two other challenging problems: obtaining short proofs for UNSAT problems and build a real local-search algorithm for QBF.

#index 1275117
#* Symmetry breaking in quantified boolean formulae
#@ Gilles Audemard;Saïd Jabbour;Lakhdar Saïs
#t 2007
#c 11
#% 183640
#% 517569
#% 535315
#% 561731
#% 1718503
#! Many reasoning task and combinatorial problems exhibit symmetries. Exploiting such symmetries has been proved to be very important in reducing search efforts. Breaking symmetries using additional constraints is currently one of the most used approaches. Extending such symmetry breaking techniques to quantified boolean formulae (QBF) is a very challenging task. In this paper, an approach to break symmetries in quantified boolean formulae is proposed. It makes an original use of universally quantified auxiliary variables to generate new symmetry breaking predicates and a new ordering of the QBF prefix is then computed leading to a new equivalent QBF formula with respect to validity. Experimental evaluation of the state-of-the-art QBF solver SEMPROP shows significant improvements (up to several orders of magnitude) on many QBFs instances.

#index 1275118
#* Computational aspects of analyzing social network dynamics
#@ Chris Barrett;Harry B. Hunt;Madhav V. Marathe;S. S. Ravi;Daniel J. Rosenkrantz;Richard E. Stearns;Mayur Thakur
#t 2007
#c 11
#% 186987
#% 235072
#% 312126
#% 392811
#% 398375
#% 475714
#% 570647
#% 1017904
#% 1673248
#% 1676017
#! Motivated by applications such as the spread of epidemics and the propagation of influence in social networks, we propose a formal model for analyzing the dynamics of such networks. Our model is a stochastic version of discrete dynamical systems. Using this model, we formulate and study the computational complexity of two fundamental problems (called reachability and predecessor existence problems) which arise in the context of social networks. We also point out the implications of our results on other computational models such as Hopfield networks, communicating finite state machines and systolic arrays.

#index 1275119
#* A machine learning approach for statistical software testing
#@ Nicolas Baskiotis;Michèle Sebag;Marie-Claude Gaudel;Sandrine Gouraud
#t 2007
#c 11
#% 169726
#% 266208
#% 272259
#% 345851
#% 425053
#% 464268
#% 741139
#% 776158
#% 785695
#% 871302
#% 876083
#% 903341
#% 1269501
#% 1272051
#% 1665132
#% 1665148
#% 1722315
#! Some Statistical Software Testing approaches rely on sampling the feasible paths in the control flow graph of the program; the difficulty comes from the tiny ratio of feasible paths. This paper presents an adaptive sampling mechanismcalled EXIST for Exploration/ eXploitation Inference for Software Testing, able to retrieve distinct feasible paths with high probability. EXIST proceeds by alternatively exploiting and updating a distribution on the set of program paths. An original representation of paths, accommodating long-range dependencies and data sparsity and based on extended Parikh maps, is proposed. Experimental validation on real-world and artificial problems demonstrates dramatic improvements compared to the state of the art.

#index 1275120
#* Web page clustering using heuristic search in the web graph
#@ Ron Bekkerman;Shlomo Zilberstein;James Allan
#t 2007
#c 11
#% 241
#% 218992
#% 249110
#% 262045
#% 281209
#% 309145
#% 578762
#% 643069
#% 757155
#% 766433
#% 805885
#% 855119
#% 963669
#% 1394202
#% 1835183
#! Effective representation of Web search results remains an open problem in the Information Retrieval community. For ambiguous queries, a traditional approach is to organize search results into groups (clusters), one for each meaning of the query. These groups are usually constructed according to the topical similarity of the retrieved documents, but it is possible for documents to be totally dissimilar and still correspond to the same meaning of the query. To overcome this problem, we exploit the thematic locality of the Web--relevant Web pages are often located close to each other in the Web graph of hyperlinks. We estimate the level of relevance between each pair of retrieved pages by the length of a path between them. The path is constructed using multi-agent beam search: each agent starts with one Web page and attempts to meet as many other agents as possible with some bounded resources. We test the system on two types of queries: ambiguous English words and people names. The Web appears to be tightly connected; about 70% of the agents meet with each other after only three iterations of exhaustive breadth-first search. However, when heuristics are applied, the search becomes more focused and the obtained results are substantially more accurate. Combined with a content-driven Web page clustering technique, our heuristic search system significantly improves the clustering results.

#index 1275121
#* Information-theoretic approaches to branching in search
#@ Andrew Gilpin;Tuomas Sandholm
#t 2007
#c 11
#% 1722
#% 36698
#% 91752
#% 319789
#% 321639
#% 341672
#% 345429
#% 350388
#% 449588
#% 572734
#% 650287
#% 659864
#% 802590
#% 1835971
#! Deciding what question to branch on at each node is a key element of search algorithms. We introduce the information-theoretic paradigm for branching question selection. The idea is to drive the search to reduce uncertainty (entropy) in the current subproblem. We present four families of methods that fall within this paradigm. In the first, a variable to branch on is selected based on lookahead. This method performs comparably to strong branching on MIPLIB, and better than strong branching on hard real-world procurement optimization instances on which CPLEX's default strong branching outperforms CPLEX's default branching strategy. The second family combines this idea with strong branching. The third family does not use lookahead, but instead exploits the tie between indicator variables and the other variables they govern. This significantly outperforms the state-of-the-art branching strategies. The fourth family is about branching using carefully constructed linear inequality constraints over sets of variables.

#index 1275122
#* From sampling to model counting
#@ Carla P. Gomes;Joerg Hoffmann;Ashish Sabharwal;Bart Selman
#t 2007
#c 11
#% 8387
#% 205391
#% 420743
#% 529186
#% 1080900
#% 1250224
#% 1250317
#% 1250515
#% 1269433
#% 1478779
#% 1650391
#% 1698716
#! We introduce a new technique for counting models of Boolean satisfiability problems. Our approach incorporates information obtained from sampling the solution space. Unlike previous approaches, our method does not require uniform or near-uniform samples. It instead converts local search sampling without any guarantees into very good bounds on the model count with guarantees. We give a formal analysis and provide experimental results showing the effectiveness of our approach.

#index 1275123
#* Boosting a complete technique to find MSS and MUS thanks to a local search oracle
#@ Éric Grégoire;Bertrand Mazure;Cédric Piette
#t 2007
#c 11
#% 44930
#% 125529
#% 131559
#% 328590
#% 417618
#% 449487
#% 668322
#% 724938
#% 761106
#% 787559
#% 912973
#% 1223266
#% 1698705
#% 1698734
#% 1722417
#! In this paper, a new complete technique to compute Maximal Satisfiable Subsets (MSS) and Minimally Unsatisfiable Subformulas (MUS) of sets of Boolean clauses is introduced. The approach improves the currently most efficient complete technique in several ways. It makes use of the powerful concept of critical clause and of a computationally inexpensive local search oracle to boost an exhaustive algorithm proposed by Liffiton and Sakallah. These features can allow exponential efficiency gains to be obtained. Accordingly, experimental studies show that this new approach outperforms the best current existing exhaustive ones.

#index 1275124
#* Characterizing the NP-PSPACE gap in the satisfiability problem for modal logic
#@ Joseph Y. Halpern;Leandro Chaves Rêgo
#t 2007
#c 11
#% 36815
#% 67901
#% 116625
#% 760296
#% 830083
#! There has been a great deal of work on characterizing the complexity of the satisfiability and validity problem for modal logics. In particular, Ladner showed that the satisfiability problem for all logics between K and S4 is PSPACE-hard, while for S5 it is NP-complete. We show that it is negative introspection, the axiom ¬Kp ⇒ K¬Kp, that causes the gap: if we add this axiom to any modal logic between K and S4, then the satisfiability problem becomes NP-complete. Indeed, the satisfiability problem is NP-complete for any modal logic that includes the negative introspection axiom.

#index 1275125
#* Improving LRTA*(k)
#@ Carlos Hernández;Pedro Meseguer
#t 2007
#c 11
#% 68238
#% 398953
#% 655327
#% 773293
#% 890237
#% 1272096
#% 1289548
#! We identify some weak points of the LRTA*(k) algorithm in the propagation of heuristic changes. To solve them, we present a new algorithm, LRTA*LS(k), that is based on the selection and updating of the interior states of a local space around the current state. It keeps the good theoretical properties of LRTA*(k), while improving substantially its performance. It is related with a lookahead depth greater than 1. We provide experimental evidence of the benefits of the new algorithm on real-time benchmarks with respect to existing approaches.

#index 1275126
#* The effect of restarts on the efficiency of clause learning
#@ Jinbo Huang
#t 2007
#c 11
#% 155827
#% 220203
#% 266200
#% 327779
#% 336874
#% 427631
#% 496249
#% 578756
#% 655781
#% 1272049
#% 1273727
#% 1698734
#! Given the common use of restarts in today's clause learning SAT solvers, the task of choosing a good restart policy appears to have attracted remarkably little interest. On the other hand, results have been reported on the use of different restart policies for combinatorial search algorithms. Such results are not directly applicable to clause learning SAT solvers, as the latter are now understood as performing a form of resolution, something fundamentally different from search (in the sense of backtracking search for satisfying assignments). In this paper we provide strong evidence that a clause learning SAT solver could benefit substantially from a carefully designed restart policy (which may not yet be available). We begin by pointing out that the restart policy works together with other aspects of a SAT solver in determining the sequence of resolution steps performed by the solver, and hence its efficiency. In this spirit we implement a prototype clause learning SAT solver that facilitates restarts at arbitrary points, and conduct experiments on an extensive set of industrial benchmarks using various restart policies, including those used by well-known SAT solvers as well as a universal policy proposed in 1993 by Luby et al. The results indicate a substantial impact of the restart policy on the efficiency of the solver, and provide motivation for the design of better restart policies, particularly dynamic ones.

#index 1275127
#* Recent progress in heuristic search: a case study of the four-peg towers of Hanoi problem
#@ Richard E. Korf;Ariel Felner
#t 2007
#c 11
#% 2194
#% 160388
#% 189701
#% 348576
#% 829310
#% 873948
#% 1250219
#% 1250221
#% 1269579
#% 1272048
#% 1279478
#% 1478838
#! We integrate a number of new and recent advances in heuristic search, and apply them to the fourpeg Towers of Hanoi problem. These include frontier search, disk-based search, parallel processing, multiple, compressed, disjoint, and additive pattern database heuristics, and breadth-first heuristic search. New ideas include pattern database heuristics based on multiple goal states, a method to reduce coordination among multiple parallel threads, and a method for reducing the number of heuristic calculations. We perform the first complete breadth-first searches of the 21 and 22-disc fourpeg Towers of Hanoi problems, and extend the verification of "presumed optimal solutions" to this problem from 24 to 30 discs. Verification of the 31-disc problem is in progress.

#index 1275128
#* Adaptive genetic algorithm with mutation and crossover matrices
#@ Nga Lam Law;K. Y. Szeto
#t 2007
#c 11
#% 1704614
#% 1709922
#! A matrix formulation for an adaptive genetic algorithm is developed using mutation matrix and crossover matrix. Selection, mutation, and crossover are all parameter-free in the sense that the problem at a particular stage of evolution will choose the parameters automatically. This time dependent selection process was first developed in MOGA (mutation only genetic algorithm) [Szeto and Zhang, 2005] and now is extended to include crossover. The remaining parameters needed are population size and chromosome length. The adaptive behavior is based on locus statistics and fitness ranking of chromosomes. In crossover, two methods are introduced: Long Hamming Distance Crossover (LHDC) and Short Hamming Distance Crossover (SHDC). LHDC emphasizes exploration of solution space. SHDC emphasizes exploitation of local search process. The one-dimensional random coupling Ising Spin Glass problem, which is similar to a knapsack problem, is used as a benchmark test for the comparison of various realizations of the adaptive genetic algorithms. Our results show that LHDC is better than SHDC, but both are superior to MOGA, which has been shown to be better than many traditional methods.

#index 1275129
#* Exploiting inference rules to compute lower bounds for MAX-SAT solving
#@ Han Lin;Kaile Su
#t 2007
#c 11
#% 327779
#% 350387
#% 578757
#% 724941
#% 817633
#% 819612
#% 872870
#% 979219
#% 1250148
#% 1250517
#% 1250520
#% 1289381
#% 1289404
#% 1838890
#! In this paper we present a general logical framework for (weighted) MAX-SAT problem, and study properties of inference rules for branch and bound MAX-SAT solver. Several rules, which are not equivalent but Λ-equivalent, are proposed, and we show that Λ-equivalent rules are also sound. As an example, we show how to exploit inference rules to achieve a new lower bound function for a MAX-2-SAT solver. Our new function is admissible and consistently better than the well-known lower bound function. Based on the study of inference rules, we implement an efficient solver and the experimental results demonstrate that our solver outperforms the most efficient solver that has been implemented very recently [Heras and Larrosa, 2006], especially for large instances.

#index 1275130
#* A multiobjective frontier search algorithm
#@ L. Mandow;J. L. Pérez De la Cruz
#t 2007
#c 11
#% 2194
#% 102372
#% 137995
#% 206846
#% 418168
#% 590623
#% 829310
#% 1289385
#! The paper analyzes the extension of frontier search to the multiobjective framework. A frontier multiobjective A* search algorithm is developed, some formal properties are presented, and its performance is compared to those of other multiobjective search algorithms. The new algorithm is adequate for both monotone and non-monotone heuristics.

#index 1275131
#* A comparison of time-space schemes for graphical models
#@ Robert Mateescu;Rina Dechter
#t 2007
#c 11
#% 44876
#% 68183
#% 322912
#% 329486
#% 420720
#% 788050
#% 1289387
#% 1499510
#! We investigate three parameterized algorithmic schemes for graphical models that can accommodate trade-offs between time and space: 1) AND/OR Adaptive Caching (AOC(i)); 2) Variable Elimination and Conditioning (VEC(i)); and 3) Tree Decomposition with Conditioning (TDC(i)). We show that AOC(i) is better than the vanilla versions of both VEC(i) and TDC(i), and use the guiding principles of AOC(i) to improve the other two schemes. Finally, we show that the improved versions of VEC(i) and TDC(i) can be simulated by AOC(i), which emphasizes the unifying power of the AND/OR framework.

#index 1275132
#* State space search for risk-averse agents
#@ Patrice Perny;Olivier Spanjaard;Louis-Xavier Storme
#t 2007
#c 11
#% 241
#% 102372
#% 252183
#% 363744
#% 1289385
#% 1650688
#% 1650819
#% 1673034
#! We investigate search problems under risk in state-space graphs, with the aim of finding optimal paths for risk-averse agents. We consider problems where uncertainty is due to the existence of different scenarios of known probabilities, with different impacts on costs of solution-paths. We consider various non-linear decision criteria (EU, RDU, Yaari) to express risk averse preferences; then we provide a general optimization procedure for such criteria, based on a path-ranking algorithm applied on a scalarized valuation of the graph. We also consider partial preference models like second order stochastic dominance (SSD) and propose a multiobjective search algorithm to determine SSD-optimal paths. Finally, the numerical performance of our algorithms are presented and discussed.

#index 1275133
#* Building structure into local search for SAT
#@ Duc Nghia Pham;John Thornton;Abdul Sattar
#t 2007
#c 11
#% 349895
#% 427631
#% 531461
#% 535307
#% 535317
#% 578753
#% 1250149
#% 1269430
#% 1273681
#% 1476298
#% 1675296
#% 1698697
#! Local search procedures for solving satisfiability problems have attracted considerable attention since the development of GSAT in 1992. However, recentwork indicates that for many real-world problems, complete search methods have the advantage, because modern heuristics are able to effectively exploit problem structure. Indeed, to develop a local search technique that can effectively deal with variable dependencies has been an open challenge since 1997. In this paper we show that local search techniques can effectively exploit information about problem structure producing significant improvements in performance on structured problem instances. Building on the earlier work of Ostrowski et al. we describe how information about variable dependencies can be built into a local search, so that only independent variables are considered for flipping. The cost effect of a flip is then dynamically calculated using a dependency lattice that models dependent variables using gates (specifically and, or and equivalence gates). The experimental study on hard structured benchmark problems demonstrates that our new approach significantly outperforms the previously reported best local search techniques.

#index 1275134
#* Near-optimal anytime coalition structure generation
#@ Talal Rahwan;Sarvapali D. Ramchurn;Viet Dung Dang;Nicholas R. Jennings
#t 2007
#c 11
#% 4382
#% 243206
#% 252199
#% 267752
#% 284645
#% 773258
#% 1250607
#% 1269383
#! Forming effective coalitions is a major research challenge in the field of multi-agent systems. Central to this endeavour is the problem of determining the best set of agents that should participate in a given team. To this end, in this paper, we present a novel, anytime algorithm for coalition structure generation that is faster than previous anytime algorithms designed for this purpose. Our algorithm can generate solutions that either have a tight bound from the optimal or are optimal (depending on the objective) and works by partitioning the space in terms of a small set of elements that represent structures which contain coalitions of particular sizes. It then performs an online heuristic search that prunes the space and only considers valid and non-redundant coalition structures. We empirically show that we are able to find solutions that are, in the worst case, 99% efficient in 0.0043% of the time to find the optimal value by the state of the art dynamic programming (DP) algorithm (for 20 agents), using 66% less memory.

#index 1275135
#* Real-time heuristic search with a priority queue
#@ D. Chris Rayner;Katherine Davison;Vadim Bulitko;Kenneth Anderson;Jieshan Lu
#t 2007
#c 11
#% 68238
#% 160859
#% 181627
#% 398953
#% 497318
#% 578727
#% 581812
#% 655327
#% 773293
#% 890237
#% 1269574
#% 1272096
#% 1290111
#! Learning real-time search, which interleaves planning and acting, allows agents to learn from multiple trials and respond quickly. Such algorithms require no prior knowledge of the environment and can be deployed without pre-processing. We introduce Prioritized-LRTA* (P-LRTA*), a learning real-time search algorithm based on Prioritized Sweeping. P-LRTA* focuses learning on important areas of the search space, where the importance of a state is determined by the magnitude of the updates made to neighboring states. Empirical tests on path-planning in commercial game maps show a substantial learning speed-up over state-of-the-art real-time search algorithms.

#index 1275136
#* Best-first utility-guided search
#@ Wheeler Ruml;Minh B. Do
#t 2007
#c 11
#% 25470
#% 52789
#% 68238
#% 98073
#% 337980
#% 578810
#% 677386
#% 837649
#% 873948
#% 1271962
#% 1279388
#! In many shortest-path problems of practical interest, insufficient time is available to find a provably optimal solution. One can only hope to achieve a balance between search time and solution cost that respects the user's preferences, expressed as a utility function over time and cost. Current stateof-the-art approaches to this problem rely on anytime algorithms such as Anytime A* or ARA*. These algorithms require the use of extensive training data to compute a termination policy that respects the user's utility function. We propose a more direct approach, called BUGSY, that incorporates the utility function directly into the search, obviating the need for a separate termination policy. Experiments in several challenging problem domains, including sequence alignment and temporal planning, demonstrate that this direct approach can surpass anytime algorithms without requiring expensive performance profiling.

#index 1275137
#* Dynamic weighting A* search-based MAP algorithm for Bayesian networks
#@ Xiaoxun Sun;Marek J. Druzdzel;Changhe Yuan
#t 2007
#c 11
#% 241
#% 183497
#% 528175
#% 788111
#% 1650391
#% 1673033
#! In this paper we propose the Dynamic Weighting A* (DWA*) search algorithm for solving MAP problems in Bayesian networks. By exploiting asymmetries in the distribution of MAP variables, the algorithm is able to greatly reduce the search space and offer excellent performance both in terms of accuracy and efficiency.

#index 1275138
#* The fringe-saving A* search algorithm: a feasibility study
#@ Xiaoxun Sun;Sven Koenig
#t 2007
#c 11
#% 241
#% 70370
#% 443547
#% 757483
#% 772056
#% 1290111
#% 1768675
#! In this paper, we develop Fringe-Saving A* (FSA*), an incremental version of A* that repeatedly finds shortest paths in a known gridworld from a given start cell to a given goal cell while the traversability costs of cells increase or decrease. The first search of FSA* is the same as that of A*. However, FSA* is able to find shortest paths during the subsequent searches faster than A* because it reuses the beginning of the immediately preceeding A* search tree that is identical to the current A* search tree. FSA* does this by restoring the content of the OPEN list of A* at the point in time when an A* search for the current search problem could deviate from the A* search for the immediately preceeding search problem. We present first experimental results that demonstrate that FSA* can have a runtime advantage over A* and Lifelong Planning A* (LPA*), an alternative incremental version of A*.

#index 1275139
#* Using graph algebra to optimize neighborhood for isometric mapping
#@ Guihua Wen;Lijun Jiang;Nigel R. Shadbolt
#t 2007
#c 11
#% 571905
#% 577290
#% 593047
#% 726725
#% 770779
#% 774859
#% 824963
#% 848112
#% 1378289
#% 1378394
#% 1395256
#% 1667379
#% 1704781
#% 1710064
#% 1712814
#% 1781626
#! Most nonlinear dimensionality reduction approaches such as Isomap heavily depend on the neighborhood structure of manifold. They determine the neighborhood graph using Euclidean distance so that they often fail to nicely deal with sparsely sampled or noise contaminated data. This paper applies the graph algebra to optimize the neighborhood structure for Isomap. The improved Isomap outperforms the classic Isomap in visualization and time complexity, as it provides good neighborhood structure that can speed up the subsequent dimensionality reducing process. It also has stronger topological stability and less sensitive to parameters. This indicates that the more complicated or even time-consuming approaches can be applied to construct the better neighborhood structure whilst the whole time complexity will not raise. The conducted experiments on benchmark data sets have validated the proposed approach.

#index 1275140
#* Lambda depth-first proof number search and its application to go
#@ Kazuki Yoshizoe;Akihiro Kishimoto;Martin Müller
#t 2007
#c 11
#% 137995
#% 159245
#% 1269578
#% 1289397
#! Thomsen's λ search and Nagai's depth-first proof-number (DFPN) search are two powerful but very different AND/OR tree search algorithms. Lambda Depth-First Proof Number search (LDFPN) is a novel algorithm that combines ideas from both algorithms. λ search can dramatically reduce a search space by finding different levels of threat sequences. DFPN employs the notion of proof and disproof numbers to expand nodes expected to be easiest to prove or disprove. The method was shown to be effective for many games. Integrating λ order with proof and disproof numbers enables LDFPN to select moves more effectively, while preserving the efficiency of DFPN. LDFPN has been implemented for capturing problems in Go and is shown to be more efficient than DFPN and more robust than an algorithm based on classical λ search.

#index 1275141
#* Edge partitioning in external-memory graph search
#@ Rong Zhou;Eric A. Hansen
#t 2007
#c 11
#% 282771
#% 541474
#% 873948
#% 1250221
#% 1250226
#% 1250328
#% 1269579
#% 1269582
#! There is currently much interest in using external memory, such as disk storage, to scale up graph-search algorithms. Recent work shows that the local structure of a graph can be leveraged to substantially improve the efficiency of external-memory graph search. This paper introduces a technique, called edge partitioning, which exploits a form of local structure that has not been considered in previous work. The new technique improves the scalability of structured approaches to external-memory graph search, and also guarantees the applicability of these approaches to any graph-search problem. We show its effectiveness in an external-memory graph-search algorithm for domain-independent STRIPS planning.

#index 1275142
#* Solving POMDPs using quadratically constrained linear programs
#@ Christopher Amato;Daniel S. Bernstein;Shlomo Zilberstein
#t 2007
#c 11
#% 578724
#% 706380
#% 801616
#% 1269513
#% 1272075
#% 1289555
#% 1290038
#% 1650313
#% 1650588
#! Developing scalable algorithms for solving partially observable Markov decision processes (POMDPs) is an important challenge. One approach that effectively addresses the intractable memory requirements of POMDP algorithms is based on representing POMDP policies as finite-state controllers. In this paper, we illustrate some fundamental disadvantages of existing techniques that use controllers. We then propose a new approach that formulates the problem as a quadratically constrained linear program (QCLP), which defines an optimal controller of a desired size. This representation allows a wide range of powerful nonlinear programming algorithms to be used to solve POMDPs. Although QCLP optimization techniques guarantee only local optimality, the results we obtain using an existing optimization method show significant solution improvement over the state-of-the-art techniques. The results open up promising research directions for solving large POMDPs using nonlinear programming methods.

#index 1275143
#* On the compilation of stratified belief bases under linear and possibilistic logic policies
#@ Salem Benferhat;Safa Yahi;Habiba Drias
#t 2007
#c 11
#% 167544
#% 204396
#% 342378
#% 770539
#% 772064
#% 936786
#% 1223256
#% 1271987
#% 1272349
#% 1289554
#% 1290096
#% 1290097
#! Developing efficient approaches for reasoning under inconsistency is an important issue in many applications. Several methods have been proposed to compile, possibly inconsistent, weighted or stratified bases. This paper focuses on the well-known linear order and possibilistic logic strategies. It provides a way for compiling a stratified belief base in order to be able to process inference from it in polynomial time. The resulting extra compilation cost is very low. In particular, the number of additional variables, that are added to original stratified bases, corresponds exactly to the number of priority levels existing in the base. Moreover, our compilation approach allows an efficient computation of weighted possibilistic conclusions and possibilistic conditioning.

#index 1275144
#* Efficient and robust independence-based Markov network structure discovery
#@ Facundo Bromberg;Dimitris Margaritis
#t 2007
#c 11
#% 44876
#% 272520
#% 325348
#% 1269489
#% 1289266
#! In this paper we introduce a novel algorithm for the induction of the Markov network structure of a domain from the outcome of conditional independence tests on data. Such algorithms work by successively restricting the set of possible structures until there is only a single structure consistent with the conditional independence tests executed. Existing independence-based algorithms have wellknown shortcomings, such as rigidly ordering the sequence of tests they perform, resulting in potential inefficiencies in the number of tests required, and committing fully to the test outcomes, resulting in lack of robustness in case of unreliable tests. We address both problems through a Bayesian particle filtering approach, which uses a population of Markov network structures to maintain the posterior probability distribution over them, given the outcomes of the tests performed. Instead of a fixed ordering, our approach greedily selects, at each step, the optimally informative from a pool of candidate tests according to information gain. In addition, it maintains multiple candidate structures weighed by posterior probability, which makes it more robust to errors in the test outcomes. The result is an approximate algorithm (due to the use of particle filtering) that is useful in domains where independence tests are uncertain (such as applications where little data is available) or expensive (such as cases of very large data sets and/or distributed data).

#index 1275145
#* Using linear programming for Bayesian exploration in Markov decision processes
#@ Pablo Samuel Castro;Doina Precup
#t 2007
#c 11
#% 284108
#% 384911
#% 466075
#% 495927
#% 647111
#% 715337
#% 739715
#% 778078
#% 840942
#% 840955
#% 1289278
#% 1650283
#! A key problem in reinforcement learning is finding a good balance between the need to explore the environment and the need to gain rewards by exploiting existing knowledge. Much research has been devoted to this topic, and many of the proposed methods are aimed simply at ensuring that enough samples are gathered to estimate well the value function. In contrast, [Bellman and Kalaba, 1959] proposed constructing a representation in which the states of the original system are paired with knowledge about the current model. Hence, knowledge about the possible Markov models of the environment is represented and maintained explicitly. Unfortunately, this approach is intractable except for bandit problems (where it gives rise to Gittins indices, an optimal exploration method). In this paper, we explore ideas for making this method computationally tractable. We maintain a model of the environment as a Markov Decision Process. We sample finite-length trajectories from the infinite tree using ideas based on sparse sampling. Finding the values of the nodes of this sparse subtree can then be expressed as an optimization problem, which we solve using Linear Programming. We illustrate this approach on a few domains and compare it with other exploration algorithms.

#index 1275146
#* Compiling Bayesian networks using variable elimination
#@ Mark Chavira;Adnan Darwiche
#t 2007
#c 11
#% 233849
#% 528025
#% 571102
#% 771607
#% 1271984
#% 1272302
#% 1289558
#% 1289570
#% 1349569
#% 1650767
#% 1650778
#! Compiling Bayesian networks has proven an effective approach for inference that can utilize both global and local network structure. In this paper, we define a new method of compiling based on variable elimination (VE) and Algebraic Decision Diagrams (ADDs). The approach is important for the following reasons. First, it exploits local structure much more effectively than previous techniques based on VE. Second, the approach allows any of the many VE variants to compute answers to multiple queries simultaneously. Third, the approach makes a large body of research into more structured representations of factors relevant in many more circumstances than it has been previously. Finally, experimental results demonstrate that VE can exploit local structure as effectively as state-of-the-art algorithms based on conditioning on the networks considered, and can sometimes lead to much faster compilation times.

#index 1275147
#* Representing Kriegspiel states with metapositions
#@ Paolo Ciancarini;Gian Piero Favini
#t 2007
#c 11
#% 251781
#% 1289391
#% 1740206
#! We describe a novel approach to incomplete information board games, which is based on the concept of metaposition as the merging of a very large set of possible game states into a single entity which contains at least every state in the current information set. This merging operation allows an artificial player to apply traditional perfect information game theory tools such as the Minimax theorem. We apply this technique to the game of Kriegspiel, a variant of chess characterized by strongly incomplete information as players cannot see their opponent's pieces but can only try to guess their positions by listening to the messages of a referee. We provide a general representation of Kriegspiel states through metaposition trees and describe a weighed maximax algorithm for evaluating metapositions. We have tested our approach competing against both human and computer players.

#index 1275148
#* A conceptual graph approach to the generation of referring expressions
#@ Madalina Croitoru;Kees Van Deemter
#t 2007
#c 11
#% 2298
#% 448787
#% 465495
#% 579945
#% 744674
#% 1271976
#! This paper presents a Conceptual Graph (CG) framework to the Generation of Referring Expressions (GRE). Employing Conceptual Graphs as the underlying formalism allows a rigorous, semantically rich, approach to GRE. A number of advantages over existing work are discussed. The new framework is also used to revisit existing complexity results in a fully rigorous way, showing that the expressive power of CGs does not increase the theoretical complexity of GRE.

#index 1275149
#* Belief change based on global minimisation
#@ James P. Delgrande;Jérôme Lang;Torsten Schaub
#t 2007
#c 11
#% 36236
#% 736896
#% 834134
#% 1250169
#% 1271987
#! A general framework for minimisation-based belief change is presented. A problem instance is made up of an undirected graph, where a formula is associated with each vertex. For example, vertices may represent spatial locations, points in time, or some other notion of locality. Information is shared between vertices via a process of minimisation over the graph. We give equivalent semantic and syntactic characterisations of this minimisation. We also show that this approach is general enough to capture existing minimisation-based approaches to belief merging, belief revision, and (temporal) extrapolation operators. While we focus on a set-theoretic notion of minimisation, we also consider other approaches, such as cardinality-based and priority-based minimisation.

#index 1275150
#* ProbLog: a probabilistic prolog and its application in link discovery
#@ Luc De Raedt;Angelika Kimmig;Hannu Toivonen
#t 2007
#c 11
#% 3873
#% 147677
#% 162683
#% 171477
#% 292510
#% 472366
#% 850430
#% 1272388
#% 1692830
#! We introduce ProbLog, a probabilistic extension of Prolog. A ProbLog program defines a distribution over logic programs by specifying for each clause the probability that it belongs to a randomly sampled program, and these probabilities are mutually independent. The semantics of ProbLog is then defined by the success probability of a query, which corresponds to the probability that the query succeeds in a randomly sampled program. The key contribution of this paper is the introduction of an effective solver for computing success probabilities. It essentially combines SLD-resolution with methods for computing the probability of Boolean formulae. Our implementation further employs an approximation algorithm that combines iterative deepening with binary decision diagrams. We report on experiments in the context of discovering links in real biological networks, a demonstration of the practical usefulness of the approach.

#index 1275151
#* The value of observation for monitoring dynamic systems
#@ Eyal Even-Dar;Sham M. Kakade;Yishay Mansour
#t 2007
#c 11
#% 75936
#% 425074
#% 1650312
#% 1650389
#% 1650568
#! We consider the fundamental problem of monitoring (i.e. tracking) the belief state in a dynamic system, when the model is only approximately correct and when the initial belief state might be unknown. In this general setting where the model is (perhaps only slightly) mis-specified, monitoring (and consequently planning) may be impossible as errors might accumulate over time. We provide a new characterization, the value of observation, which allows us to bound the error accumulation. The value of observation is a parameter that governs how much information the observation provides. For instance, in Partially Observable MDPs when it is 1 the POMDP is an MDP while for an unobservable Markov Decision Process the parameter is 0. Thus, the new parameter characterizes a spectrum from MDPs to unobservable MDPs depending on the amount of information conveyed in the observations.

#index 1275152
#* WiFi-SLAM using Gaussian process latent variable models
#@ Brian Ferris;Dieter Fox;Neil Lawrence
#t 2007
#c 11
#% 777788
#% 891549
#% 916787
#% 1269361
#! WiFi localization, the task of determining the physical location of a mobile device from wireless signal strengths, has been shown to be an accurate method of indoor and outdoor localization and a powerful building block for location-aware applications. However, most localization techniques require a training set of signal strength readings labeled against a ground truth location map, which is prohibitive to collect and maintain as maps grow large. In this paper we propose a novel technique for solving the WiFi SLAM problem using the Gaussian Process Latent Variable Model (GPLVM) to determine the latent-space locations of unlabeled signal strength data. We show how GPLVM, in combination with an appropriate motion dynamics model, can be used to reconstruct a topological connectivity graph from a signal strength sequence which, in combination with the learned Gaussian Process signal strength model, can be used to perform efficient localization.

#index 1275153
#* Revisiting output coding for sequential supervised learning
#@ Guohua Hao;Alan Fern
#t 2007
#c 11
#% 464434
#% 770763
#% 770850
#% 840935
#% 854636
#% 938667
#% 939333
#% 1272365
#% 1705511
#! Markov models are commonly used for joint inference of label sequences. Unfortunately, inference scales quadratically in the number of labels, which is problematic for training methods where inference is repeatedly preformed and is the primary computational bottleneck for large label sets. Recent work has used output coding to address this issue by converting a problem with many labels to a set of problems with binary labels. Models were independently trained for each binary problem, at a much reduced computational cost, and then combined for joint inference over the original labels. Here we revisit this idea and show through experiments on synthetic and benchmark data sets that the approach can perform poorly when it is critical to explicitly capture the Markovian transition structure of the large-label problem. We then describe a simple cascade-training approach and show that it can improve performance on such problems with negligible computational overhead.

#index 1275154
#* Graph-based semi-supervised learning as a generative model
#@ Jingrui He;Jaime Carbonell;Yan Liu
#t 2007
#c 11
#% 443790
#% 466263
#% 565545
#% 780688
#% 840967
#% 842682
#% 939380
#! This paper proposes and develops a new graph-based semi-supervised learning method. Different from previous graph-based methods that are based on discriminative models, our method is essentially a generative model in that the class conditional probabilities are estimated by graph propagation and the class priors are estimated by linear regression. Experimental results on various datasets show that the proposed method is superior to existing graph-based semi-supervised learning methods, especially when the labeled subset alone proves insufficient to estimate meaningful class priors.

#index 1275155
#* An action description language for iterated belief change
#@ Aaron Hunter;James P. Delgrande
#t 2007
#c 11
#% 322911
#% 752887
#% 1289424
#! We are interested in the belief change that occurs due to a sequence of ontic actions and epistemic actions. In order to represent such problems, we extend an existing epistemic action language to allow erroneous initial beliefs. We define a non-Markovian semantics for our action language that explicitly respects the interaction between ontic actions and epistemic actions. Further, we illustrate how to solve epistemic projection problems in our new language by translating action descriptions into extended logic programs. We conclude with some remarks about a prototype implementation of our work.

#index 1275156
#* Using a hierarchical Bayesian model to handle high cardinality attributes with relevant interactions in a classification problem
#@ Jorge Jambeiro Filho;Jacques Wainer
#t 2007
#c 11
#% 44876
#% 246831
#% 246832
#% 290482
#% 1271973
#% 1650783
#% 1673044
#! We employed a multilevel hierarchical Bayesian model in the task of exploiting relevant interactions among high cardinality attributes in a classification problem without overfitting. With this model, we calculate posterior class probabilities for a pattern W combining the observations of W in the training set with prior class probabilities that are obtained recursively from the observations of patterns that are strictly more generic than W. The model achieved performance improvements over standard Bayesian network methods like Naive Bayes and Tree Augmented Naive Bayes, over Bayesian Networks where traditional conditional probability tables were substituted byNoisy-or gates, Default Tables, Decision Trees and Decision Graphs, and over Bayesian Networks constructed after a cardinality reduction preprocessing phase using the Agglomerative Information Bottleneck method.

#index 1275157
#* A factor graph model for software bug finding
#@ Ted Kremenek;Andrew Y. Ng;Dawson Engler
#t 2007
#c 11
#% 348853
#% 580307
#% 581053
#% 823198
#% 963635
#% 978401
#! Automatic tools for finding software errors require knowledge of the rules a program must obey, or "specifications," before they can identify bugs. We present a method that combines factor graphs and static program analysis to automatically infer specifications directly from programs. We illustrate the approach on inferring functions in C programs that allocate and release resources, and evaluate the approach on three codebases: SDL, OpenSSH, and the OS kernel for Mac OS X (XNU). The inferred specifications are highly accurate and with them we have discovered numerous bugs.

#index 1275158
#* Belief update revisited
#@ Jérôme Lang
#t 2007
#c 11
#% 90860
#% 131559
#% 250128
#% 291003
#% 303950
#% 495963
#% 763743
#% 819616
#% 906062
#% 1272393
#% 1279365
#% 1289163
#% 1289417
#% 1289424
#! Although many papers about belief update have been written, its precise scope still remains unclear. In this paper we aim at identifying this scope, and we show that belief update is a specific case of feedback-free action progression. This strong connection with the field of reasoning about action leads us to reconsider belief update and investigate new issues, especially reverse update, which is to regression what update is to progression.

#index 1275159
#* Dynamically weighted hidden Markov model for spam deobfuscation
#@ Seunghak Lee;Iryoung Jeong;Seungjin Choi
#t 2007
#c 11
#% 252472
#% 286550
#% 817758
#! Spam deobfuscation is a processing to detect obfuscated words appeared in spam emails and to convert them back to the original words for correct recognition. Lexicon tree hidden Markov model (LTHMM) was recently shown to be useful in spam deobfuscation. However, LT-HMM suffers from a huge number of states, which is not desirable for practical applications. In this paper we present a complexity-reduced HMM, referred to as dynamically weighted HMM (DW-HMM) where the states involving the same emission probability are grouped into super-states, while preserving state transition probabilities of the original HMM. DWHMM dramatically reduces the number of states and its state transition probabilities are determined in the decoding phase. We illustrate how we convert a LT-HMM to its associated DW-HMM. We confirm the useful behavior of DW-HMM in the task of spam deobfuscation, showing that it significantly reduces the number of states while maintaining the high accuracy.

#index 1275160
#* Training conditional random fields using virtual evidence boosting
#@ Lin Liao;Tanzeem Choudhury;Dieter Fox;Henry Kautz
#t 2007
#c 11
#% 44876
#% 235377
#% 464434
#% 736300
#% 770850
#% 1275093
#% 1673026
#% 1815596
#! While conditional random fields (CRFs) have been applied successfully in a variety of domains, their training remains a challenging task. In this paper, we introduce a novel training method for CRFs, called virtual evidence boosting, which simultaneously performs feature selection and parameter estimation. To achieve this, we extend standard boosting to handle virtual evidence, where an observation can be specified as a distribution rather than a single number. This extension allows us to develop a unified framework for learning both local and compatibility features in CRFs. In experiments on synthetic data as well as real activity classification problems, our new training algorithm outperforms other training approaches including maximum likelihood, maximum pseudo-likelihood, and the most recent boosted random fields.

#index 1275161
#* A fast analytical algorithm for solving Markov decision processes with real-valued resources
#@ Janusz Marecki;Sven Koenig;Milind Tambe
#t 2007
#c 11
#% 734920
#% 1250235
#% 1269516
#% 1269546
#% 1650355
#! Agents often have to construct plans that obey deadlines or, more generally, resource limits for real-valued resources whose consumption can only be characterized by probability distributions, such as execution time or battery power. These planning problems can be modeled with continuous state Markov decision processes (MDPs) but existing solution methods are either inefficient or provide no guarantee on the quality of the resulting policy. We therefore present CPH, a novel solution method that solves the planning problems by first approximating with any desired accuracy the probability distributions over the resource consumptions with phasetype distributions, which use exponential distributions as building blocks. It then uses value iteration to solve the resulting MDPs by exploiting properties of exponential distributions to calculate the necessary convolutions accurately and efficiently while providing strong guarantees on the quality of the resulting policy. Our experimental feasibility study in a Mars rover domain demonstrates a substantial speedup over Lazy Approximation, which is currently the leading algorithm for solving continuous state MDPs with quality guarantees.

#index 1275162
#* Hierarchical heuristic forward search in Stochastic domains
#@ Nicolas Meuleau;Ronen I. Brafman
#t 2007
#c 11
#% 25470
#% 75936
#% 159243
#% 181627
#% 286423
#% 337981
#% 363744
#% 393786
#% 578674
#% 1279345
#! Many MDPs exhibit an hierarchical structure where the agent needs to perform various subtasks that are coupled only by a small sub-set of variables containing, notably, shared resources. Previous work has shown how this hierarchical structure can be exploited by solving several sub-MDPs representing the different subtasks in different calling contexts, and a root MDP responsible for sequencing and synchronizing the subtasks, instead of a huge MDP representing the whole problem. Another important idea used by efficient algorithms for solving flat MDPs, such as (L)AO and (L)RTDP, is to exploit reachability information and an admissible heuristics in order to accelerate the search by pruning states that cannot be reached from a given starting state under an optimal policy. In this paper, we combine both ideas and develop a variant of the AO* algorithm for performing forward heuristic search in hierarchical models. This algorithm shows great performance improvements over hierarchical approaches using standard MDP solvers such as Value Iteration, as well as with respect to AO applied to a flat representation of the problem. Moreover, it presents a general new method for accelerating AO and other forward search algorithms. Substantial performance gains may be obtained in these algorithms by partitioning the set of search nodes, and solving a subset of nodes completely before propagating the results to other subsets.

#index 1275163
#* Compiling Bayesian networks by symbolic probability calculation based on zero-suppressed BDDs
#@ Shin-Ichi Minato;Ken Satoh;Taisuke Sato
#t 2007
#c 11
#% 3873
#% 147928
#% 329486
#% 528015
#% 571102
#% 1289558
#% 1289570
#! Compiling Bayesian networks (BNs) is a hot topic within probabilistic modeling and processing. In this paper, we propose a new method for compiling BNs into Multi-Linear Functions (MLFs) based on Zero-suppressed Binary Decision Diagrams (ZBDDs), which are a graph-based representation of combinatorial item sets. Our method differs from the original approach of Darwiche et al., which encodes BNs into Conjunctive Normal Forms (CNFs) and then translates CNFs into factored MLFs. Our approach directly translates a BN into a set of factored MLFs using a ZBDD-based symbolic probability calculation. The MLF may have exponential computational complexity, but our ZBDD-based data structure provides a compact factored form of the MLF, and arithmetic operations can be executed in a time almost linear with the ZBDD size. In our method, it is not necessary to generate the MLF for the whole network, as we can extract MLFs for only part of the network related to the query, avoiding unnecessary calculation of redundant MLF terms. We present experimental results for some typical benchmark examples. Although our algorithm is simply based on the mathematical definition of probability calculation, performance is competitive to existing state-of-the-art methods.

#index 1275164
#* Efficiently exploiting symmetries in real time dynamic programming
#@ Shravan Matthur Narayanamurthy;Balaraman Ravindran
#t 2007
#c 11
#% 181627
#% 212402
#% 464442
#% 477304
#% 655325
#% 1279356
#! Current approaches to solving Markov Decision Processes (MDPs) are sensitive to the size of the MDP. When applied to real world problems though, MDPs exhibit considerable implicit redundancy, especially in the form of symmetries. Existing model minimization methods do not exploit this redundancy due to symmetries well. In this work, given such symmetries, we present a time-efficient algorithm to construct a functionally equivalent reduced model of the MDP. Further, we present a Real Time Dynamic Programming (RTDP) algorithm which obviates an explicit construction of the reduced model by integrating the given symmetries into it. The RTDP algorithm solves the reduced model, while working with parameters of the original model and the given symmetries. As RTDP uses its experience to determine which states to backup, it focuses on parts of the reduced state set that are most relevant. This results in significantly faster learning and a reduced overall execution time. The algorithms proposed are particularly effective in the case of structured automorphisms even when the reduced model does not have fewer features. We demonstrate the results empirically on several domains.

#index 1275165
#* Hierarchical multi-channel hidden semi Markov models
#@ Pradeep Natarajan;Ramakant Nevatia
#t 2007
#c 11
#% 268080
#% 592062
#% 724317
#% 812412
#% 1250170
#! Many interesting human actions involve multiple interacting agents and also have typical durations. Further, there is an inherent hierarchical organization of these activities. In order to model these we introduce a new family of hidden Markov models (HMMs) that provide compositional state representations in both space and time and also a recursive hierarchical structure for inference at higher levels of abstraction. In particular, we focus on two possible 2-layer structures - the Hierarchical-Semi Parallel Hidden Markov Model (HSPaHMM) and the Hierarchical Parallel Hidden Semi-Markov Model (HPaHSMM). The lower layer of HSPaHMM consists of multiple HMMs for each agent while the top layer consists of a single HSMM. HPaHSMM on the other hand has multiple HSMMs at the lower layer and a Markov chain at the top layer. We present efficient learning and decoding algorithms for these models and then demonstrate them first on synthetic time series data and then in an application for sign language recognition.

#index 1275166
#* Iterated belief contraction from first principles
#@ Abhaya C. Nayak;Randy Goebel;Mehmet A. Orgun
#t 2007
#c 11
#% 224753
#% 581824
#% 1693261
#! Importance of contraction for belief change notwithstanding, literature on iterated belief change has by and large centered around the issue of iterated belief revision, ignoring the problem of iterated belief contraction. In this paper we examine iterated belief contraction in a principled way, starting with Qualified Insertion, a proposal by Hans Rott. We show that a judicious combination of Qualified Insertion with a well-known Factoring principle leads to what is arguably a pivotal principle of iterated belief contraction. We show that this principle is satisfied by the account of iterated belief contraction modelled by Lexicographic State Contraction, and outline its connection with Lexicographic Revision, Darwiche-Pearl's account of revision as well as Spohn's Ordinal ranking theory.

#index 1275167
#* An analysis of Laplacian methods for value function approximation in MDPs
#@ Marek Petrik
#t 2007
#c 11
#% 225253
#% 363744
#% 384911
#% 393786
#% 616105
#% 876020
#% 1250345
#% 1269517
#! Recently, a method based on Laplacian eigenfunctions was proposed to automatically construct a basis for value function approximation in MDPs. We show that its success may be explained by drawing a connection between the spectrum of the Laplacian and the value function of the MDP. This explanation helps us to identify more precisely the conditions that this method requires to achieve good performance. Based on this, we propose a modification of the Laplacian method for which we derive an analytical bound on the approximation error. Further, we show that the method is related the augmented Krylov methods, commonly used to solve sparse linear systems. Finally, we empirically demonstrate that in basis construction the augmented Krylov methods may significantly outperform the Laplacian methods in terms of both speed and quality.

#index 1275168
#* Global/local dynamic models
#@ Avi Pfeffer;Subrata Das;David Lawless;Brenda Ng
#t 2007
#c 11
#% 75936
#% 246836
#% 266616
#% 1650389
#% 1650568
#% 1650666
#! Many dynamic systems involve a number of entities that are largely independent of each other but interact with each other via a subset of state variables. We present global/local dynamic models (GLDMs) to capture these kinds of systems. In a GLDM, the state of an entity is decomposed into a globally influenced state that depends on other entities, and a locally influenced state that depends only on the entity itself. We present an inference algorithm for GLDMs called global/local particle filtering, that introduces the principle of reasoning globally about global dynamics and locally about local dynamics. We have applied GLDMs to an asymmetric urban warfare environment, in which enemy units form teams to attack important targets, and the task is to detect such teams as they form. Experimental results for this application show that global/local particle filtering outperforms ordinary particle filtering and factored particle filtering.

#index 1275169
#* Bayesian inverse reinforcement learning
#@ Deepak Ramachandran;Eyal Amir
#t 2007
#c 11
#% 38014
#% 91359
#% 252013
#% 266213
#% 384911
#% 465902
#% 466418
#% 770852
#% 806994
#% 1279315
#! Inverse Reinforcement Learning (IRL) is the problem of learning the reward function underlying a Markov Decision Process given the dynamics of the system and the behaviour of an expert. IRL is motivated by situations where knowledge of the rewards is a goal by itself (as in preference elicitation) and by the task of apprenticeship learning (learning policies from an expert). In this paper we show how to combine prior knowledge and evidence from the expert's actions to derive a probability distribution over the space of reward functions. We present efficient algorithms that find solutions for the reward learning and apprenticeship learning tasks that generalize well over these distributions. Experimental results show strong improvement for our methods over previous heuristic-based approaches.

#index 1275170
#* AEMS: an anytime online search algorithm for approximate policy refinement in large POMDPs
#@ Stéphane Ross;Brahim Chaib-Draa
#t 2007
#c 11
#% 25470
#% 30037
#% 283210
#% 337981
#% 544786
#% 703709
#% 788098
#% 823963
#% 827696
#% 842579
#% 1250227
#% 1272075
#% 1279358
#% 1650312
#% 1650702
#! Solving large Partially Observable Markov Decision Processes (POMDPs) is a complex task which is often intractable. A lot of effort has been made to develop approximate offline algorithms to solve ever larger POMDPs. However, even state-of-the-art approaches fail to solve large POMDPs in reasonable time. Recent developments in online POMDP search suggest that combining offline computations with online computations is often more efficient and can also considerably reduce the error made by approximate policies computed offline. In the same vein, we propose a new anytime online search algorithm which seeks to minimize, as efficiently as possible, the error made by an approximate value function computed offline. In addition, we show how previous online computations can be reused in following time steps in order to prevent redundant computations. Our preliminary results indicate that our approach is able to tackle large state space and observation space efficiently and under real-time constraints.

#index 1275171
#* Efficient Bayesian task-level transfer learning
#@ Daniel M. Roy;Leslie P. Kaelbling
#t 2007
#c 11
#% 116149
#% 236497
#% 288211
#% 464434
#% 729437
#% 770858
#% 840872
#% 1271814
#% 1279355
#! In this paper, we show how using the Dirichlet Process mixture model as a generative model of data sets provides a simple and effective method for transfer learning. In particular, we present a hierarchical extension of the classic Naive Bayes classifier that couples multiple Naive Bayes classifiers by placing a Dirichlet Process prior over their parameters and show how recent advances in approximate inference in the Dirichlet Process mixture model enable efficient inference. We evaluate the resulting model in a meeting domain, in which the system decides, based on a learned model of the user's behavior, whether to accept or reject the request on his or her behalf. The extended model outperforms the standard Naive Bayes model by using data from other users to influence its predictions.

#index 1275172
#* Inside-outside probability computation for belief propagation
#@ Taisuke Sato
#t 2007
#c 11
#% 225837
#% 363747
#% 380725
#% 668343
#% 788082
#% 1272388
#% 1289558
#% 1476311
#! In this paper we prove that the well-known correspondence between the forward-backward algorithm for hidden Markov models (HMMs) and belief propagation (BP) applied to HMMs can be generalized to one between BP for junction trees and the generalized inside-outside probability computation for probabilistic logic programs applied to junction trees.

#index 1275173
#* Logical circuit filtering
#@ Dafna Shahaf;Eyal Amir
#t 2007
#c 11
#% 90860
#% 117869
#% 121397
#% 229083
#% 278488
#% 347808
#% 349898
#% 1271828
#% 1279222
#% 1289211
#! Logical Filtering is the problem of tracking the possible states of a world (belief state) after a sequence of actions and observations. It is fundamental to applications in partially observable dynamic domains. This paper presents the first exact logical filtering algorithm that is tractable for all deterministic domains. Our tractability result is interesting because it contrasts sharply with intractability results for structured stochastic domains. The key to this advance lies in using logical circuits to represent belief states. We prove that both filtering time and representation size are linear in the sequence length and the input size. They are independent of the domain size if the actions have compact representations. The number of variables in the resulting formula is at most the number of state features. We also report on a reasoning algorithm (answering propositional questions) for our circuits, which can handle questions about past time steps (smoothing). We evaluate our algorithms extensively on AI planning domains. Our method outperforms competing methods, sometimes by orders of magnitude.

#index 1275174
#* Forward search value iteration for POMDPs
#@ Guy Shani;Ronen I. Brafman;Solomon E. Shimony
#t 2007
#c 11
#% 181627
#% 1272075
#% 1279358
#% 1289243
#! Recent scaling up of POMDP solvers towards realistic applications is largely due to point-based methods which quickly converge to an approximate solution formedium-sized problems. Of this family HSVI, which uses trial-based asynchronous value iteration, can handle the largest domains. In this paper we suggest a new algorithm, FSVI, that uses the underlying MDP to traverse the belief space towards rewards, finding sequences of useful backups, and show how it scales up better than HSVI on larger benchmarks.

#index 1275175
#* Dynamic interactions between goals and beliefs
#@ Steven Shapiro;Gerhard Brewka
#t 2007
#c 11
#% 68239
#% 314845
#% 342119
#% 521353
#% 1041674
#% 1289413
#% 1289444
#! Shapiro et al. [2005; 2006], presented a framework for representing goal change in the situation calculus. In that framework, agents adopt a goal when requested to do so (by some agent reqr), and they remain committed to the goal unless the request is cancelled by reqr. A common assumption in the agent theory literature, e.g., [Cohen and Levesque, 1990; Rao and Georgeff, 1991], is that achievement goals that are believed to be impossible to achieve should be dropped. In this paper, we incorporate this assumption into Shapiro et al.'s framework, however we go a step further. If an agent believes a goal is impossible to achieve, it is dropped. However, if the agent later believes that it was mistaken about the impossibility of achieving the goal, the agent might readopt the goal. In addition, we consider an agent's goals as a whole when making them compatible with their beliefs, rather than considering them individually.

#index 1275176
#* Inferring complex agent motions from partial trajectory observations
#@ Finnegan Southey;Wesley Loh;Dana Wilkinson
#t 2007
#c 11
#% 716892
#% 1250174
#% 1269581
#! Tracking the movements of a target based on limited observations plays a role in many interesting applications. Existing probabilistic tracking techniques have shown considerable success but the majority assume simplistic motion models suitable for short-term, local motion prediction. Agent movements are often governed by more sophisticated mechanisms such as a goal-directed path-planning algorithm. In such contexts we must go beyond estimating a target's current location to consider its future path and ultimate goal. We show how to use complex, "black box" motion models to infer distributions over a target's current position, origin, and destination, using only limited observations of the full path. Our approach accommodates motion models defined over a graph, including complex pathing algorithms such as A*. Robust and practical inference is achieved by using hidden semi-Markov models (HSMMs) and graph abstraction. The method has also been extended to effectively track multiple, indistinguishable agents via a greedy heuristic.

#index 1275177
#* Towards efficient computation of error bounded solutions in POMDPs: expected value approximation and dynamic disjunctive beliefs
#@ Pradeep Varakantham;Rajiv T. Maheswaran;Tapana Gupta;Milind Tambe
#t 2007
#c 11
#% 643148
#% 788053
#% 823964
#% 1250227
#% 1269513
#% 1271823
#% 1289243
#% 1650313
#% 1650702
#! While POMDPs (partially observable markov decision problems) are a popular computational model with wide-ranging applications, the computational cost for optimal policy generation is prohibitive. Researchers are investigating ever-more efficient algorithms, yet many applications demand such algorithms bound any loss in policy quality when chasing efficiency. To address this challenge, we present two new techniques. The first approximates in the value space to obtain solutions efficiently for a pre-specified error bound. Unlike existing techniques, our technique guarantees the resulting policy will meet this bound. Furthermore, it does not require costly computations to determine the quality loss of the policy. Our second technique prunes large tracts of belief space that are unreachable, allowing faster policy computation without any sacrifice in optimality. The combination of the two techniques, which are complementary to existing optimal policy generation algorithms, provides solutions with tight error bounds efficiently in domains where competing algorithms fail to provide such tight bounds.

#index 1275178
#* Distributed data mining: why do more than aggregating models
#@ Mohamed Aoun-Allah;Guy Mineau
#t 2007
#c 11
#% 73372
#% 179770
#% 209021
#% 232166
#% 442979
#% 703747
#% 803574
#% 1272179
#% 1272280
#% 1499476
#! In this paper we deal with the problem of mining large distributed databases. We show that the aggregation of models, i.e., sets of disjoint classification rules, each built over a subdatabase is quite enough to get an aggregated model that is both predictive and descriptive, that presents excellent prediction capability and that is conceptually much simpler than the comparable techniques. These results are made possible by lifting the disjoint cover constraint on the aggregated model and by the use of a confidence coefficient associated with each rule in a weighted majority vote.

#index 1275179
#* Stable biclustering of gene expression data with nonnegative matrix factorizations
#@ Liviu Badea;Doina Tilivea
#t 2007
#c 11
#% 374537
#% 400277
#% 469422
#% 1699576
#! Although clustering is probably the most frequently used tool for data mining gene expression data, existing clustering approaches face at least one of the following problems in this domain: a huge number of variables (genes) as compared to the number of samples, high noise levels, the inability to naturally deal with overlapping clusters, the instability of the resulting clusters w.r.t. the initialization of the algorithm as well as the difficulty in clustering genes and samples simultaneously. In this paper we show that all of these problems can be elegantly dealt with by using nonnegative matrix factorizations to cluster genes and samples simultaneously while allowing for bicluster overlaps and by employing Positive Tensor Factorization to perform a two-way meta-clustering of the biclusters produced in several different clustering runs (thereby addressing the above-mentioned instability). The application of our approach to a large lung cancer dataset proved computationally tractable and was able to recover the histological classification of the various cancer subtypes represented in the dataset.

#index 1275180
#* Determining expert profiles (with an application to expert finding)
#@ Krisztian Balog;Maarten De Rijke
#t 2007
#c 11
#% 10648
#% 387427
#% 426885
#% 737423
#% 768898
#% 857180
#% 879570
#! The profile of an individual is a record of the types and areas of skills of that individual ("topical profile") plus a description of her collaboration network ("social profile"). In this paper we define and formalize the task of automatically determining an expert profile of a person from a heterogeneous corpus made up of a large organization's intranet. We propose multiple models for addressing the topical profiling task. Our main methods build on ideas from information retrieval, while refinements bring in filtering (allowing an area into a person's profile only if she is among the top ranking experts in the area). An evaluation based on the W3C-corpus made available by TREC, shows significant improvements of the refined methods over the baseline. We apply our profiling algorithms to significantly enhance the performance of a state-ofthe-art expert finding algorithm and to help users of an operational expert search system find the person they would contact, given a specific problem, topic or information need. Finally, we address the task of determining a social profile for a given person, using graph-based methods.

#index 1275181
#* Learning "forgiving" hash functions: algorithms and large scale tests
#@ Shumeet Baluja;Michele Covell
#t 2007
#c 11
#% 90391
#% 209623
#% 404505
#% 457926
#% 479973
#% 812380
#% 917232
#% 983812
#! The problem of efficiently finding similar items in a large corpus of high-dimensional data points arises in many real-world tasks, such as music, image, and video retrieval. Beyond the scaling difficulties that arise with lookups in large data sets, the complexity in these domains is exacerbated by an imprecise definition of similarity. In this paper, we describe a method to learn a similarity function from only weakly labeled positive examples. Once learned, this similarity function is used as the basis of a hash function to severely constrain the number of points considered for each lookup. Tested on a large real-world audio dataset, only a tiny fraction of the points (∼0.27%) are ever considered for each lookup. To increase efficiency, no comparisons in the original high-dimensional space of points are required. The performance far surpasses, in terms of both efficiency and accuracy, a state-of-the-art Locality-Sensitive-Hashing based technique for the same problem and data set.

#index 1275182
#* Open information extraction from the web
#@ Michele Banko;Michael J. Cafarella;Stephen Soderland;Matt Broadhead;Oren Etzioni
#t 2007
#c 11
#% 301241
#% 312861
#% 342630
#% 504443
#% 706900
#% 786516
#% 815868
#% 816062
#% 817472
#% 830520
#% 938707
#% 938763
#% 939602
#% 939944
#% 940028
#% 940029
#% 983614
#% 1275192
#% 1289456
#% 1289516
#% 1476276
#! Traditionally, Information Extraction (IE) has focused on satisfying precise, narrow, pre-specified requests from small homogeneous corpora (e.g., extract the location and time of seminars from a set of announcements). Shifting to a new domain requires the user to name the target relations and to manually create new extraction rules or hand-tag new training examples. This manual labor scales linearly with the number of target relations. This paper introduces Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input. The paper also introduces TEXTRUNNER, a fully implemented, highly scalable OIE system where the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries. We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL, a state-of-the-art Web IE system. TEXTRUNNER achieves an error reduction of 33% on a comparable set of extractions. Furthermore, in the amount of time it takes KNOWITALL to perform extraction for a handful of pre-specified relations, TEXTRUNNER extracts a far broader set of facts reflecting orders of magnitude more relations, discovered on the fly. We report statistics on TEXTRUNNER's 11,000,000 highest probability tuples, and show that they contain over 1,000,000 concrete facts and over 6,500,000 more abstract assertions.

#index 1275183
#* Trust based recommender system for the semantic web
#@ Punam Bedi;Harmeet Kaur;Sudeep Marwaha
#t 2007
#c 11
#% 319705
#% 342687
#% 754098
#% 778641
#% 790459
#% 860127
#% 1561979
#! This paper proposes the design of a recommender system that uses knowledge stored in the form of ontologies. The interactions amongst the peer agents for generating recommendations are based on the trust network that exists between them. Recommendations about a product given by peer agents are in the form of Intuitionistic Fuzzy Sets specified using degree of membership, non membership and uncertainty. In literature, the recommender systems use databases to generate recommendations. The presented design uses ontologies, a knowledge representation technique for creating annotated content for Semantic Web. Seeing the potential and popularity of ontologies among researchers, we believe that ontologies will be build and maintained in numerous knowledge domains for the Semantic Web and future applications. The presented recommender system uses temporal ontologies that absorb the effect of changes in the ontologies due to the dynamic nature of domains, in addition to the benefits of ontologies. A case study of tourism recommender system is chosen to generate the recommendations for the selection of destination, travel agents and the flight schedule. A comparison of the generated recommendations with the manual recommendations by peers establishes the validity of the presented recommender system.

#index 1275184
#* Identifying expressions of opinion in context
#@ Eric Breck;Yejin Choi;Claire Cardie
#t 2007
#c 11
#% 198058
#% 464434
#% 577246
#% 577355
#% 723399
#% 742527
#% 746885
#% 854829
#% 855279
#% 939897
#% 939921
#% 943811
#% 1700552
#! While traditional information extraction systems have been built to answer questions about facts, subjective information extraction systems will answer questions about feelings and opinions. A crucial step towards this goal is identifying the words and phrases that express opinions in text. Indeed, although much previous work has relied on the identification of opinion expressions for a variety of sentiment-based NLP tasks, none has focused directly on this important supporting task. Moreover, none of the proposed methods for identification of opinion expressions has been evaluated at the task that they were designed to perform. We present an approach for identifying opinion expressions that uses conditional random fields and we evaluate the approach at the expression-level using a standard sentiment corpus. Our approach achieves expression-level performance within 5% of the human interannotator agreement.

#index 1275185
#* Detect and track latent factors with online nonnegative matrix factorization
#@ Bin Cao;Dou Shen;Jian-Tao Sun;Xuanhui Wang;Qiang Yang;Zheng Chen
#t 2007
#c 11
#% 310500
#% 679330
#% 729932
#% 766432
#% 793248
#% 823344
#% 1015261
#% 1650298
#% 1705459
#! Detecting and tracking latent factors from temporal data is an important task. Most existing algorithms for latent topic detection such as Nonnegative Matrix Factorization (NMF) have been designed for static data. These algorithms are unable to capture the dynamic nature of temporally changing data streams. In this paper, we put forward an online NMF (ONMF) algorithm to detect latent factors and track their evolution while the data evolve. By leveraging the already detected latent factors and the newly arriving data, the latent factors are automatically and incrementally updated to reflect the change of factors. Furthermore, by imposing orthogonality on the detected latent factors, we can not only guarantee the unique solution of NMF but also alleviate the partial-data problem, which may cause NMF to fail when the data are scarce or the distribution is incomplete. Experiments on both synthesized data and real data validate the efficiency and effectiveness of our ONMF algorithm.

#index 1275186
#* Learning semantic descriptions of web information sources
#@ Mark James Carman;Craig A. Knoblock
#t 2007
#c 11
#% 163547
#% 333988
#% 398263
#% 765433
#% 870896
#% 1016160
#% 1092030
#% 1250372
#% 1275347
#% 1722486
#! The Internet is full of information sources providing various types of data from weather forecasts to travel deals. These sources can be accessed via web-forms, Web Services or RSS feeds. In order to make automated use of these sources, one needs to first model them semantically. Writing semantic descriptions for web sources is both tedious and error prone. In this paper we investigate the problem of automatically generating such models. We introduce a framework for learning Datalog definitions for web sources, in which we actively invoke sources and compare the data they produce with that of known sources of information. We perform an inductive search through the space of plausible source definitions in order to learn the best possible semantic model for each new source. The paper includes an empirical evaluation demonstrating the effectiveness of our approach on real-world web sources.

#index 1275187
#* An improved probabilistic ant based clustering for distributed databases
#@ R. Chandrasekar;T. Srinivasan
#t 2007
#c 11
#% 36672
#% 103446
#% 171172
#% 294103
#% 296738
#% 311679
#% 338588
#% 361100
#% 375017
#% 762231
#% 846564
#! In this paper we present an improved version of the Probabilistic Ant based Clustering Algorithm for Distributed Databases (PACE). The most important feature of this algorithm is the formation of numerous zones in different sites based on corresponding user queries to the distributed database. Keywords, extracted out of the queries, are used to assign a range of values according to their corresponding probability of occurrence or hit ratio at each site. We propose the introduction of weights for individual or groups of data items in each zone according to their relevance to the queries along with the concept of familial pheromone trails as part of an Ant Odor Identification Model to bias the movements of different types of ants towards the members of their own family. Its performance is compared against PACE and other known clustering algorithms for different evaluation measures and an improvement is shown in terms of convergence speed and quality of solution obtained.

#index 1275188
#* Directed graph embedding
#@ Mo Chen;Qiong Yang;Xiaoou Tang
#t 2007
#c 11
#% 249143
#% 268079
#% 281209
#% 840965
#% 1269492
#! In this paper, we propose the Directed Graph Embedding (DGE) method that embeds vertices on a directed graph into a vector space by considering the link structure of graphs. The basic idea is to preserve the locality property of vertices on a directed graph in the embedded space. We use the transition probability together with the stationary distribution of Markov random walks to measure such locality property. It turns out that by exploring the directed links of the graph using random walks, we can get an optimal embedding on the vector space that preserves the local affinity which is inherent in the directed graph. Experiments on both synthetic data and real-world Web page data are considered. The application of our method to Web page classification problems gets a significant improvement comparing with state-of-art methods.

#index 1275189
#* Constructing career histories: a case study in disentangling the threads
#@ Paul R. Cohen
#t 2007
#c 11
#% 218978
#% 385946
#! We present an algorithm for organizing partially-ordered observations into multiple "threads," some of which may be concurrent., The algorithm is applied to the problem of constructing career histories for individual scientists from the abstracts of published papers. Because abstracts generally do not provide rich information about the contents of papers, we developed a novel relational method for judging the similarity of papers. We report four experiments that demonstrate the advantage of this method over the traditional Dice and Tanimoto coefficients, and that evaluate the quality of induced multi-thread career histories.

#index 1275190
#* Change of representation for statistical relational learning
#@ Jesse Davis;Irene Ong;Jan Struyf;Elizabeth Burnside;David Page;Vítor Santos Costa
#t 2007
#c 11
#% 246832
#% 420495
#% 458159
#% 496116
#% 727912
#% 769954
#% 840890
#% 850430
#% 1269484
#% 1289459
#% 1699582
#! Statistical relational learning (SRL) algorithms learn statistical models from relational data, such as that stored in a relational database. We previously introduced view learning for SRL, in which the view of a relational database can be automatically modified, yielding more accurate statistical models. The present paper presents SAYU-VISTA, an algorithm which advances beyond the initial view learning approach in three ways. First, it learns views that introduce new relational tables, rather than merely new fields for an existing table of the database. Second, new tables or new fields are not limited to being approximations to some target concept; instead, the new approach performs a type of predicate invention. The new approach avoids the classical problem with predicate invention, of learning many useless predicates, by keeping only new fields or tables (i.e., new predicates) that immediately improve the performance of the statistical model. Third, retained fields or tables can then be used in the definitions of further new fields or tables. We evaluate the new view learning approach on three relational classification tasks.

#index 1275191
#* Pseudo-aligned multilingual corpora
#@ Fernando Diaz;Donald Metzler
#t 2007
#c 11
#% 719598
#% 722927
#% 735134
#% 740901
#% 794860
#% 838528
#% 855563
#% 940273
#! In machine translation, document alignment refers to finding correspondences between documents which are exact translations of each other. We define pseudo-alignment as the task of finding topical--as opposed to exact--correspondences between documents in different languages. We apply semisupervised methods to pseudo-align multilingual corpora. Specifically, we construct a topic-based graph for each language. Then, given exact correspondences between a subset of documents, we project the unaligned documents into a shared lower-dimensional space. We demonstrate that close documents in this lower-dimensional space tend to share the same topic. This has applications in machine translation and cross-lingual information analysis. Experimental results show that pseudo-alignment of multilingual corpora is feasible and that the document alignments produced are qualitatively sound. Our technique requires no linguistic knowledge of the corpus. On average when 10% of the corpus consists of exact correspondences, an on-topic correspondence occurs within the top 5 foreign neighbors in the lower-dimensional space while the exact correspondence occurs within the top 10 foreign neighbors in this this space. We also show how to substantially improve these results with a novel method for incorporating language-independent information.

#index 1275192
#* Locating complex named entities in web text
#@ Doug Downey;Matthew Broadhead;Oren Etzioni
#t 2007
#c 11
#% 252011
#% 279755
#% 464434
#% 466892
#% 757350
#% 783484
#% 830520
#% 855108
#% 855119
#% 939332
#% 1269487
#! Named Entity Recognition (NER) is the task of locating and classifying names in text. In previous work, NER was limited to a small number of pre-defined entity classes (e.g., people, locations, and organizations). However, NER on the Web is a far more challenging problem. Complex names (e.g., film or book titles) can be very difficult to pick out precisely from text. Further, the Web contains a wide variety of entity classes, which are not known in advance. Thus, hand-tagging examples of each entity class is impractical. This paper investigates a novel approach to the first step in Web NER: locating complex named entities in Web text. Our key observation is that named entities can be viewed as a species of multiword units, which can be detected by accumulating n-gram statistics over the Web corpus. We show that this statistical method's F1 score is 50% higher than that of supervised techniques including Conditional Random Fields (CRFs) and Conditional Markov Models (CMMs) when applied to complex names. The method also outperforms CMMs and CRFs by 117% on entity classes absent from the training data. Finally, our method outperforms a semi-supervised CRF by 73%.

#index 1275193
#* Models of searching and browsing: languages, studies, and applications
#@ Doug Downey;Susan Dumais;Eric Horvitz
#t 2007
#c 11
#% 260005
#% 284796
#% 310567
#% 348155
#% 590523
#% 643057
#% 754059
#% 766447
#% 805200
#% 805877
#% 805878
#% 818259
#% 823348
#% 838547
#% 869501
#% 879565
#% 1264955
#! We describe the formulation, construction, and evaluation of predictive models of human information seeking from a large dataset of Web search activities. We first introduce an expressive language for describing searching and browsing behavior, and use this language to characterize several prior studies of search behavior. Then, we focus on the construction of predictive models from the data. We review several analyses, including an exploration of the properties of users, queries, and search sessions that are most predictive of future behavior. We also investigate the influence of temporal delay on user actions, and representational tradeoffs with varying the number of steps of user activity considered. Finally, we discuss applications of the predictive models, and focus on the example of performing principled prefetching of content.

#index 1275194
#* An adaptive context-based algorithm for term weighting: application to single-word question answering
#@ Marco Ernandes;Giovanni Angelini;Marco Gori;Leonardo Rigutini;Franco Scarselli
#t 2007
#c 11
#% 224113
#% 279755
#% 342398
#% 406493
#% 728350
#% 1269584
#! Term weighting systems are of crucial importance in Information Extraction and Information Retrieval applications. Common approaches to term weighting are based either on statistical or on natural language analysis. In this paper, we present a new algorithm that capitalizes from the advantages of both the strategies by adopting a machine learning approach. In the proposed method, the weights are computed by a parametric function, called Context Function, that models the semantic influence exercised amongst the terms of the same context. The Context Function is learned from examples, allowing the use of statistical and linguistic information at the same time. The novel algorithm was successfully tested on crossword clues, which represent a case of Single-Word Question Answering.

#index 1275195
#* Semi-supervised learning for multi-component data classification
#@ Akinori Fujino;Naonori Ueda;Kazumi Saito
#t 2007
#c 11
#% 211044
#% 248810
#% 311027
#% 413663
#% 466263
#% 1269479
#% 1676576
#! This paper presents a method for designing a semisupervised classifier for multi-component data such as web pages consisting of text and link information. The proposed method is based on a hybrid of generative and discriminative approaches to take advantage of both approaches. With our hybrid approach, for each component, we consider an individual generative model trained on labeled samples and a model introduced to reduce the effect of the bias that results when there are few labeled samples. Then, we construct a hybrid classifier by combining all the models based on the maximum entropy principle. In our experimental results using three test collections such as web pages and technical papers, we confirmed that our hybrid approach was effective in improving the generalization performance of multi-component data classification.

#index 1275196
#* Opinion sentence search engine on open-domain blog
#@ Osamu Furuse;Nobuaki Hiroshima;Setsuo Yamada;Ryoji Kataoka
#t 2007
#c 11
#% 529193
#% 577246
#% 577355
#% 723399
#% 769424
#% 815915
#% 816152
#% 855279
#% 943811
#% 1299644
#% 1700552
#! We have introduced a search engine that can extract opinion sentences relevant to an open-domain query from Japanese blog pages. The engine identifies opinions based not only on positive or negative measurements but also on neutral opinions, requests, advice, and thoughts. To retrieve a number of opinion sentences that a user could reasonably be expected to read, we attempted to extract only explicitly stated writer's opinions at the sentence-level and to exclude quoted or implicational opinions. In our search engine, opinion sentences are identified based on features such as opinion clue expressions, and then, the relevance to the query of each identified opinion sentence is checked. The experimental results for various topics, obtained by comparing the output of the proposed opinion search engine with that of human judgments as to whether the sentences were opinions, showed that the proposed engine has promise as a practical application.

#index 1275197
#* ItemRank: a random-walk based scoring algorithm for recommender engines
#@ Marco Gori;Augusto Pucci
#t 2007
#c 11
#% 202011
#% 330687
#% 348173
#% 420121
#% 420515
#% 577328
#% 577367
#% 616944
#% 729936
#% 832334
#% 1650569
#% 1728731
#! Recommender systems are an emerging technology that helps consumers to find interesting products. A recommender system makes personalized product suggestions by extracting knowledge from the previous users interactions. In this paper, we present "ItemRank", a random-walk based scoring algorithm, which can be used to rank products according to expected user preferences, in order to recommend top-rank items to potentially interested users. We tested our algorithm on a standard database, the MovieLens data set, which contains data collected from a popular recommender system on movies, that has been widely exploited as a benchmark for evaluating recently proposed approaches to recommender system (e.g. [Fouss et al., 2005; Sarwar et al., 2002]). We compared ItemRank with other state-of-the-art ranking techniques (in particular the algorithms described in [Fouss et al., 2005]). Our experiments show that ItemRank performs better than the other algorithms we compared to and, at the same time, it is less complex than other proposed algorithms with respect to memory usage and computational cost too.

#index 1275198
#* An analysis of the use of tags in a blog recommender system
#@ Conor Hayes;Paolo Avesani;Sriharsha Veeramachaneni
#t 2007
#c 11
#% 755463
#% 786843
#% 791728
#% 855601
#% 1374373
#! The Web is experiencing an exponential growth in the use of weblogs or blogs, websites containing dated journal-style entries. Blog entries are generally organised using informally defined labels known as tags. Increasingly, tags are being proposed as a 'grassroots' alternative to Semantic Web standards. We demonstrate that tags by themselves are weak at partitioning blog data. We then show how tags may contribute useful, discriminating information. Using content-based clustering, we observe that frequently occurring tags in each cluster are usually good meta-labels for the cluster concept. We then introduce the Tr score, a score based on the proportion of high-frequency tags in a cluster, and demonstrate that it is strongly correlated with cluster strength. We demonstrate how the Tr score enables the detection and removal of weak clusters. As such, the Tr score can be used as an independent means of verifying topic integrity in a cluster-based recommender system.

#index 1275199
#* Efficient calculation of personalized document rankings
#@ Claudia Hess;Klaus Stein
#t 2007
#c 11
#% 290830
#% 810734
#% 874420
#% 1016177
#% 1668087
#% 1734216
#! Social networks allow users getting personalized recommendations for interesting resources like websites or scientific papers by using reviews of users they trust. Search engines rank documents by using the reference structure to compute a visibility for each document with reference structure-based functions like PageRank. Personalized document visibilities can be computed by integrating both approaches. We present a framework for incorporating the information from both networks, and ranking algorithms using this information for personalized recommendations. Because the computation of document visibilities is costly and therefore cannot be done in runtime, i.e., when a user searches a document repository, we pay special attention to develop algorithms providing an efficient calculation of personalized visibilities at query time based on precalculated global visibilities. The presented ranking algorithms are evaluated by a simulation study.

#index 1275200
#* Computation of initial modes for K-modes clustering algorithm using evidence accumulation
#@ Shehroz S. Khan;Shri Kant
#t 2007
#c 11
#% 36672
#% 100220
#% 161496
#% 196334
#% 248790
#% 350935
#% 385538
#% 399587
#% 414554
#% 420081
#% 466083
#% 479863
#% 633220
#% 727903
#% 794265
#% 803762
#! Clustering accuracy of partitional clustering algorithm for categorical data primarily depends upon the choice of initial data points (modes) to instigate the clustering process. Traditionally initial modes are chosen randomly. As a consequence of that, the clustering results cannot be generated and repeated consistently. In this paper we present an approach to compute initial modes for K-mode clustering algorithm to cluster categorical data sets. Here, we utilize the idea of Evidence Accumulation for combining the results of multiple clusterings. Initially, n F - dimensional data is decomposed into a large number of compact clusters; the K-modes algorithm performs this decomposition, with several clusterings obtained by N random initializations of the K- modes algorithm. The modes thus obtained from every run of random initializations are stored in a Mode-Pool, PN. The objective is to investigate the contribution of those data objects/patterns that are less vulnerable to the choice of random selection of modes and to choose the most diverse set of modes from the available Mode-Pool that can be utilized as initial modes for the K-mode clustering algorithm. Experimentally we found that by this method we get initial modes that are very similar to the actual/desired modes and gives consistent and better clustering results with less variance of clustering error than the traditional method of choosing random modes.

#index 1275201
#* Logistic regression models for a fast CBIR method based on feature selection
#@ R. Ksantini;D. Ziou;B. Colin;F. Dubeau
#t 2007
#c 11
#% 334765
#% 424806
#% 589910
#% 658910
#% 775134
#% 803771
#% 1856015
#! Distance measures like the Euclidean distance have been the most widely used to measure similarities between feature vectors in the content-based image retrieval (CBIR) systems. However, in these similarity measures no assumption is made about the probability distributions and the local relevances of the feature vectors. Therefore, irrelevant features might hurt retrieval performance. Probabilistic approaches have proven to be an effective solution to this CBIR problem. In this paper, we use a Bayesian logistic regression model, in order to compute the weights of a pseudo-metric to improve its discriminatory capacity and then to increase image retrieval accuracy. The pseudo-metric weights were adjusted by the classical logistic regression model in [Ksantini et al., 2006]. The Bayesian logistic regression model was shown to be a significantly better tool than the classical logistic regression one to improve the retrieval performance. The retrieval method is fast and is based on feature selection. Experimental results are reported on the Zubud and WANG color image databases proposed by [Deselaers et al., 2004].

#index 1275202
#* Collapsed variational Dirichlet process mixture models
#@ Kenichi Kurihara;Max Welling;Yee Whye Teh
#t 2007
#c 11
#% 304932
#% 593926
#! Nonparametric Bayesian mixture models, in particular Dirichlet process (DP) mixture models, have shown great promise for density estimation and data clustering. Given the size of today's datasets, computational efficiency becomes an essential ingredient in the applicability of these techniques to real world data. We study and experimentally compare a number of variational Bayesian (VB) approximations to the DP mixture model. In particular we consider the standard VB approximation where parameters are assumed to be independent from cluster assignment variables, and a novel collapsed VB approximation where mixture weights are marginalized out. For both VB approximations we consider two different ways to approximate the DP, by truncating the stick-breaking construction, and by using a finite mixture model with a symmetric Dirichlet prior.

#index 1275203
#* Learning to identify unexpected instances in the test set
#@ Xiao-Li Li;Bing Liu;See-Kiong Ng
#t 2007
#c 11
#% 169717
#% 464641
#% 577235
#% 722811
#% 770821
#% 800568
#% 1279298
#! Traditional classification involves building a classifier using labeled training examples from a set of predefined classes and then applying the classifier to classify test instances into the same set of classes. In practice, this paradigm can be problematic because the test data may contain instances that do not belong to any of the previously defined classes. Detecting such unexpected instances in the test set is an important issue in practice. The problem can be formulated as learning from positive and unlabeled examples (PU learning). However, current PU learning algorithms require a large proportion of negative instances in the unlabeled set to be effective. This paper proposes a novel technique to solve this problem in the text classification domain. The technique first generates a single artificial negative document AN. The sets P and {AN} are then used to build a naïve Bayesian classifier. Our experiment results show that this method is significantly better than existing techniques.

#index 1275204
#* Feature mining and neuro-fuzzy inference system for steganalysis of LSB matching stegangoraphy in grayscale images
#@ Qingzhong Liu;Andrew H. Sung
#t 2007
#c 11
#% 302391
#% 425048
#% 426630
#% 431224
#% 539738
#% 539758
#% 900022
#% 927528
#% 1666724
#% 1677117
#% 1757302
#% 1788233
#% 1809759
#% 1855444
#% 1859304
#! In this paper, we present a scheme based on feature mining and neuro-fuzzy inference system for detecting LSB matching steganography in grayscale images, which is a very challenging problem in steganalysis. Four types of features are proposed, and a Dynamic Evolving Neural Fuzzy Inference System (DENFIS) based feature selection is proposed, as well as the use of Support Vector Machine Recursive Feature Elimination (SVM-RFE) to obtain better detection accuracy. In comparison with other well-known features, overall, our features perform the best. DENFIS outperforms some traditional learning classifiers. SVM-RFE and DENFIS based feature selection outperform statistical significance based feature selection such as t-test. Experimental results also indicate that it remains very challenging to steganalyze LSB matching steganography in grayscale images with high complexity.

#index 1275205
#* Improving activity discovery with automatic neighborhood estimation
#@ David Minnen;Thad Starner;Irfan Essa;Charles Isbell
#t 2007
#c 11
#% 70370
#% 268080
#% 629629
#% 662750
#% 729960
#% 769896
#% 799397
#% 905914
#! A fundamental problem for artificial intelligence is identifying perceptual primitives from raw sensory signals that are useful for higher-level reasoning. We equate these primitives with initially unknown recurring patterns called motifs. Autonomously learning the motifs is difficult because their number, location, length, and shape are all unknown. Furthermore, nonlinear temporal warping may be required to ensure the similarity of motif occurrences. In this paper, we extend a leading motif discovery algorithm by allowing it to operate on multidimensional sensor data, incorporating automatic parameter estimation, and providing for motif-specific similarity adaptation. We evaluate our algorithm on several data sets and show how our approach leads to faster real world discovery and more accurate motifs compared to other leading methods.

#index 1275206
#* Extracting keyphrases to represent relations in social networks from web
#@ Junichiro Mori;Mitsuru Ishizuka;Yutaka Matsuo
#t 2007
#c 11
#% 363038
#% 722926
#% 741083
#% 747738
#% 805872
#% 869502
#% 869503
#% 938705
#% 938706
#% 938763
#% 1250375
#% 1289476
#% 1289532
#% 1374378
#% 1655418
#% 1655423
#! Social networks have recently garnered considerable interest. With the intention of utilizing social networks for the Semantic Web, several studies have examined automatic extraction of social networks. However, most methods have addressed extraction of the strength of relations. Our goal is extracting the underlying relations between entities that are embedded in social networks. To this end, we propose a method that automatically extracts labels that describe relations among entities. Fundamentally, the method clusters similar entity pairs according to their collective contexts in Web documents. The descriptive labels for relations are obtained from results of clustering. The proposed method is entirely unsupervised and is easily incorporated with existing social network extraction methods. Our experiments conducted on entities in researcher social networks and political social networks achieved clustering with high precision and recall. The results showed that our method is able to extract appropriate relation labels to represent relations among entities in the social networks.

#index 1275207
#* Extracting and visualizing trust relationships from online auction feedback comments
#@ John O'Donovan;Barry Smyth;Vesile Evrim;Dennis McLeod
#t 2007
#c 11
#% 248218
#% 316798
#% 775921
#% 790459
#% 848659
#% 854646
#% 1708349
#! Buyers and sellers in online auctions are faced with the task of deciding who to entrust their business to based on a very limited amount of information. Current trust ratings on eBay average over 99% positive [13] and are presented as a single number on a user's profile. This paper presents a system capable of extracting valuable negative information from the wealth of feedback comments on eBay, computing personalized and feature-based trust and presenting this information graphically.

#index 1275208
#* What you seek is what you get: extraction of class attributes from query logs
#@ Marius Pasca;Benjamin Van Durme
#t 2007
#c 11
#% 301241
#% 309127
#% 312861
#% 815297
#% 816228
#% 938705
#% 939924
#% 995514
#% 1250378
#% 1712125
#! Within the larger area of automatic acquisition of knowledge from the Web, we introduce a method for extracting relevant attributes, or quantifiable properties, for various classes of objects. The method extracts attributes such as capital city and President for the class Country, or cost, manufacturer and side effects for the class Drug, without relying on any expensive language resources or complex processing tools. In a departure from previous approaches to large-scale information extraction, we explore the role of Web query logs, rather than Web documents, as an alternative source of class attributes. The quality of the extracted attributes recommends query logs as a valuable, albeit little explored, resource for information extraction.

#index 1275209
#* Semi-supervised learning of attribute-value pairs from product descriptions
#@ Katharina Probst;Rayid Ghani;Marko Krema;Andrew Fano;Yan Liu
#t 2007
#c 11
#% 196896
#% 252011
#% 316509
#% 805873
#% 939896
#! We describe an approach to extract attribute-value pairs from product descriptions. This allows us to represent products as sets of such attribute-value pairs to augment product databases. Such a representation is useful for a variety of tasks where treating a product as a set of attribute-value pairs is more useful than as an atomic entity. Examples of such applications include product recommendations, product comparison, and demand forecasting. We formulate the extraction as a classification problem and use a semi-supervised algorithm (co-EM) along with (Naïve Bayes). The extraction system requires very little initial user supervision: using unlabeled data, we automatically extract an initial seed list that serves as training data for the supervised and semi-supervised classification algorithms. Finally, the extracted attributes and values are linked to form pairs using dependency information and co-location scores. We present promising results on product descriptions in two categories of sporting goods.

#index 1275210
#* A fusion of stacking with dynamic integration
#@ Niall Rooney;David Patterson
#t 2007
#c 11
#% 132938
#% 208181
#% 209021
#% 229931
#% 256615
#% 290482
#% 481349
#% 629687
#% 738972
#% 1289491
#% 1860956
#! In this paper we present a novel method that fuses the ensemble meta-techniques of Stacking and Dynamic Integration (DI) for regression problems, without adding any major computational overhead. The intention of the technique is to benefit from the varying performance of Stacking and DI for different data sets, in order to provide a more robust technique. We detail an empirical analysis of the technique referred to as weighted Meta - Combiner (wMetaComb) and compare its performance to Stacking and the DI technique of Dynamic Weighting with Selection. The empirical analysis consisted of four sets of experiments where each experiment recorded the cross-fold evaluation of each technique for a large number of diverse data sets, where each base model is created using random feature selection and the same base learning algorithm. Each experiment differed in terms of the latter base learning algorithm used. We demonstrate that for each evaluation, wMeta-Comb was able to outperform DI and Stacking for each experiment and as such fuses the two underlying mechanisms successfully.

#index 1275211
#* Robust human-computer interaction system guiding a user by providing feedback
#@ M. S. Ryoo;J. K. Aggarwal
#t 2007
#c 11
#% 266223
#% 295955
#% 319244
#% 875495
#% 884073
#% 1272377
#! We introduce a human-computer interaction system which collaborates with a user by providing feed-back during user activities. The goal of the system is to help a user complete a high-level activity that has been represented hierarchically. While a user is performing the high-level activity, our system analyzes what sub-events a user has already completed and what sub-events are needed next in order for the user to finish the activity. The representations of human activities are constructed using a previously developed context-free grammar based representation scheme. We focus on a game named 'pentagram game' to illustrate our system. In the experiments, our system showsthe ability to guide the user to complete the 'pentagram game' by providing explicit feedback. The feedback not only contains atomic level instructions but also describes higher-level long-term goals of the composite activities.

#index 1275212
#* Combining learning and word sense disambiguation for intelligent user profiling
#@ Giovanni Semeraro;Marco Degemmis;Pasquale Lops;Pierpaolo Basile
#t 2007
#c 11
#% 187763
#% 234992
#% 279755
#% 301259
#% 344447
#% 445309
#% 532186
#% 976808
#! Understanding user interests from text documents can provide support to personalized information recommendation services. Typically, these services automatically infer the user profile, a structured model of the user interests, from documents that were already deemed relevant by the user. Traditional keyword-based approaches are unable to capture the semantics of the user interests. This work proposes the integration of linguistic knowledge in the process of learning semantic user profiles that capture concepts concerning user interests. The proposed strategy consists of two steps. The first one is based on a word sense disambiguation technique that exploits the lexical database WordNet to select, among all the possible meanings (senses) of a polysemous word, the correct one. In the second step, a naïve Bayes approach learns semantic sense-based user profiles as binary text classifiers (user-likes and user-dislikes) from disambiguated documents. Experiments have been conducted to compare the performance obtained by keyword-based profiles to that obtained by sense-based profiles. Both the classification accuracy and the effectiveness of the ranking imposed by the two different kinds of profile on the documents to be recommended have been considered. The main outcome is that the classification accuracy is increased with no improvement on the ranking. The conclusion is that the integration of linguistic knowledge in the learning process improves the classification of those documents whose classification score is close to the likes/dislikes threshold (the items for which the classification is highly uncertain).

#index 1275213
#* Document summarization using conditional random fields
#@ Dou Shen;Jian-Tao Sun;Hua Li;Qiang Yang;Zheng Chen
#t 2007
#c 11
#% 95730
#% 194251
#% 266370
#% 268079
#% 280835
#% 290830
#% 340884
#% 340971
#% 375017
#% 387791
#% 464434
#% 466892
#% 766437
#% 790703
#% 816173
#% 816181
#% 854813
#% 874707
#% 1269641
#! Many methods, including supervised and unsupervised algorithms, have been developed for extractive document summarization. Most supervised methods consider the summarization task as a two-class classification problem and classify each sentence individually without leveraging the relationship among sentences. The unsupervised methods use heuristic rules to select the most informative sentences into a summary directly, which are hard to generalize. In this paper, we present a Conditional Random Fields (CRF) based framework to keep the merits of the above two kinds of approaches while avoiding their disadvantages. What is more, the proposed framework can take the outcomes of previous methods as features and seamlessly integrate them. The key idea of our approach is to treat the summarization task as a sequence labeling problem. In this view, each document is a sequence of sentences and the summarization procedure labels the sentences by 1 and 0. The label of a sentence depends on the assignment of labels of others. We compared our proposed approach with eight existing methods on an open benchmark data set. The results show that our approach can improve the performance by more than 7.1% and 12.1% over the best supervised baseline and unsupervised baseline respectively in terms of two popular metrics F1 and ROUGE-2. Detailed analysis of the improvement is presented as well.

#index 1275214
#* Real-time detection of task switches of desktop users
#@ Jianqiang Shen;Lida Li;Thomas G. Dietterich
#t 2007
#c 11
#% 278106
#% 280408
#% 316546
#% 464434
#% 465754
#% 466892
#% 729980
#% 751792
#% 790446
#% 848639
#% 1289462
#! Desktop users commonly work on multiple tasks. The TaskTracer system provides a convenient, low-cost way for such users to define a hierarchy of tasks and to associate resources with those tasks. With this information, TaskTracer then supports the multi-tasking user by configuring the computer for the current task. To do this, it must detect when the user switches the task and identify the user's current task at all times. This problem of "task switch detection" is a special case of the general problem of change-point detection. It involves monitoring the behavior of the user and predicting in real time when the user moves from one task to another. We present a framework that analyzes a sequence of observations to detect task switches. First, a classifier is trained discriminatively to predict the current task based only on features extracted from the window in focus. Second, multiple single-window predictions (specifically, the class probability estimates) are combined to obtain more reliable predictions. This paper studies three such combination methods: (a) simple voting, (b) a likelihood ratio test that assesses the variability of the task probabilities over the sequence of windows, and (c) application of the Viterbi algorithm under an assumed task transition cost model. Experimental results show that all three methods improve over the single-window predictions and that the Viterbi approach gives the best results.

#index 1275215
#* Estimating the rate of web page updates
#@ Sanasam Ranbir Singh
#t 2007
#c 11
#% 309746
#% 374261
#% 640706
#% 841603
#! Estimating the rate of Web page updates helps in improving the Web crawler's scheduling policy. But, most of the Web sources are autonomous and updated independently. Clients like Web crawlers are not aware of when and how often the sources change. Unlike other studies, the process of Web page updates is modeled as nonhomogeneous Poisson process and focus on determining localized rate of updates. Then various rate estimators are discussed, showing experimentally how precise they are. This paper explores two classes of problems. Firstly the localized rate of updates is estimated by dividing the given sequence of independent and inconsistent update points into consistent windows. From various experimental comparisons, the proposed Weibull estimator outperforms Duane plot(another proposed estimator) and other estimators proposed by Cho et al. and Norman Matloff in 91.5%(90.6%) of the whole windows for synthetic(real Web) datasets. Secondly, the future update points are predicted based on most recent window and it is found that Weibull estimator has higher precision compared to other estimators.

#index 1275216
#* On the automatic scoring of handwritten essays
#@ Sargur Srihari;Rohini Srihari;Pavithra Babu;Harish Srinivasan
#t 2007
#c 11
#% 296534
#% 387427
#% 427293
#% 493484
#! Automating the task of scoring short handwritten student essays is considered. The goal is to assign scores which are comparable to those of human scorers by coupling two AI technologies: optical handwriting recognition and automated essay scoring. The test-bed is that of essays written by children in reading comprehension tests. The process involves several image-level operations: removal of pre-printed matter, segmentation of handwritten text lines and extraction of words. Recognition constraints are provided by the reading passage, the question and the answer rubric. Scoring is based on using a vector space model and machine learning of parameters from a set of human-scored samples. System performance is comparable to that of scoring based on perfect manual transcription.

#index 1275217
#* Layout analysis of tree-structured scene frames in comic images
#@ Takamasa Tanaka;Kenji Shoji;Fubito Toyama;Juichi Miyamichi
#t 2007
#c 11
#! Today, the demand of services for comic contents increases because paper magazines and books are bulky while digital contents can be read anytime and anywhere with cellular phones and PDAs. To convert existing print comic materials into digital format such that they can be read using the cellular phones and the PDAs with small screens, it is necessary to divide each page into scene frames and to determine reading order of the scene frames. The division of comic images into the scene frames can be considered as a type of document layout analysis. We analyzed layout of comic images using density gradient. The method can be applied to comics in which comic balloons or pictures are drawn over scene frames. In this research, a method for detecting the scene frame division in comic images using the density gradient after filling the quadrangle regions in each image with black is proposed. Experimental results show that 80 percent of 672 pages in four print comic booklets are successfully divided into scene frames by the proposed method.

#index 1275218
#* Face recognition via the overlapping energy histogram
#@ Ronny Tjahyadi;Wanquan Liu;Senjian An;Svetha Venkatesh
#t 2007
#c 11
#% 71174
#% 347836
#% 622068
#% 727684
#% 970036
#% 1010488
#% 1022958
#% 1180370
#! In this paper we investigate the face recognition problem via the overlapping energy histogram of the DCT coefficients. Particularly, we investigate some important issues relating to the recognition performance, such as the issue of selecting threshold and the number of bins. These selection methods utilise information obtained from the training dataset. Experimentation is conducted on the Yale face database and results indicate that the proposed parameter selection methods perform well in selecting the threshold and number of bins. Furthermore, we show that the proposed overlapping energy histogram approach outperforms the Eigenfaces, 2DPCA and energy histogram significantly.

#index 1275219
#* Semantic indexing of a competence map to support scientific collaboration in a research community
#@ Paola Velardi;Roberto Navigli;Michaël Petit
#t 2007
#c 11
#% 786523
#% 814007
#% 815295
#% 816189
#% 838514
#% 843739
#% 913796
#% 939847
#! This paper describes a methodology to semiautomatically acquire a taxonomy of terms and term definitions in a specific research domain. The taxonomy is then used for semantic search and indexing of a knowledge base of scientific competences, called Knowledge Map. The KMap is a system to support research collaborations and sharing of results within and beyond a European Network of Excellence. The methodology is general and can be applied to model any web community - starting from the documents shared and exchanged among the community members - and to use this model for improving accessibility of data and knowledge repositories.

#index 1275220
#* Manifold-ranking based topic-focused multi-document summarization
#@ Xiaojun Wan;Jianwu Yang;Jianguo Xiao
#t 2007
#c 11
#% 280835
#% 318409
#% 397138
#% 787502
#% 811320
#% 815920
#% 816173
#% 818227
#% 818266
#! Topic-focused multi-document summarization aims to produce a summary biased to a given topic or user profile. This paper presents a novel extractive approach based on manifold-ranking of sentences to this summarization task. The manifold-ranking process can naturally make full use of both the relationships among all the sentences in the documents and the relationships between the given topic and the sentences. The ranking score is obtained for each sentence in the manifold-ranking process to denote the biased information richness of the sentence. Then the greedy algorithm is employed to impose diversity penalty on each sentence. The summary is produced by choosing the sentences with both high biased information richness and high information novelty. Experiments on DUC2003 and DUC2005 are performed and the ROUGE evaluation results show that the proposed approach can significantly outperform existing approaches of the top performing systems in DUC tasks and baseline approaches.

#index 1275221
#* Dynamic mixture models for multiple time series
#@ Xing Wei;Jimeng Sun;Xuerui Wang
#t 2007
#c 11
#% 280819
#% 722904
#% 824709
#% 875959
#% 879587
#% 881498
#% 1016178
#! Traditional probabilistic mixture models such as Latent Dirichlet Allocation imply that data records (such as documents) are fully exchangeable. However, data are naturally collected along time, thus obey some order in time. In this paper, we present Dynamic Mixture Models (DMMs) for online pattern discovery in multiple time series. DMMs do not have the noticeable drawback of the SVD-based methods for data streams: negative values in hidden variables are often produced even with all non-negative inputs. We apply DMM models to two real-world datasets, and achieve significantly better results with intuitive interpretation.

#index 1275222
#* Automatic decision of piano fingering based on hidden Markov models
#@ Yuichiro Yonebayashi;Hirokazu Kameoka;Shigeki Sagayama
#t 2007
#c 11
#% 394014
#! This paper proposes a Hidden Markov Model (HMM)-based algorithm for automatic decision of piano fingering. We represent the positions and forms of hands and fingers as HMM states and model the resulted sequence of performed notes as emissions associated with HMM transitions. Optimal fingering decision is thus formulated as Viterbi search to find the most likely sequence of state transitions. The proposed algorithm models the required efforts in pressing a key with a finger followed by another key with another finger, and in two-dimensional positioning of fingers on the piano keyboard with diatonic and chromatic keys. Fundamental functionality of the algorithm was verified through experiments with real piano pieces. This framework can be extended to polyphonic music containing chords.

#index 1275223
#* Semantic smoothing of document models for agglomerative clustering
#@ Xiaohua Zhou;Xiaodan Zhang;Xiaohua Hu
#t 2007
#c 11
#% 280851
#% 340899
#% 340948
#% 397129
#% 740904
#% 818240
#% 826918
#% 832343
#% 879586
#! In this paper, we argue that the agglomerative clustering with vector cosine similarity measure performs poorly due to two reasons. First, the nearest neighbors of a document belong to different classes in many cases since any pair of documents shares lots of "general" words. Second, the sparsity of class-specific "core" words leads to grouping documents with the same class labels into different clusters. Both problems can be resolved by suitable smoothing of document model and using Kullback-Leibler divergence of two smoothed models as pairwise document distances. Inspired by the recent work in information retrieval, we propose a novel context-sensitive semantic smoothing method that can automatically identifies multiword phrases in a document and then statistically map phrases to individual document terms. We evaluate the new model-based similarity measure on three datasets using complete linkage criterion for agglomerative clustering and find out it significantly improves the clustering quality over the traditional vector cosine measure.

#index 1275224
#* Exploiting image contents in web search
#@ Zhi-Hua Zhou;Hong-Bin Dai
#t 2007
#c 11
#% 46803
#% 219047
#% 232710
#% 268079
#% 290830
#% 309104
#% 318785
#% 324984
#% 424287
#% 589742
#% 676177
#% 740763
#% 766464
#% 780873
#% 807299
#% 1250383
#! Web search is a challenging task. Previous research mainly exploits texts on the Web pages or link information between the pages, while multimedia information is largely ignored. This paper proposes a new framework for Web search, which exploits image contents to help improve the search performance. In this framework, candidate images are retrieved at first by considering their associated text information. Then, images related to the query are identified by analyzing the density of the visual feature space. After that, an image-based rank of the Web pages is generated, which is combined with the traditional keyword-based search result to produce the final search result. Experiments demonstrate the promise of the proposed framework.

#index 1275225
#* Mining complex patterns across sequences with gap requirements
#@ Xingquan Zhu;Xindong Wu
#t 2007
#c 11
#% 259993
#% 310542
#% 342666
#% 420063
#% 459006
#% 464996
#% 644560
#% 799764
#% 810060
#% 844359
#! The recurring appearance of sequential patterns, when confined by the predefined gap requirements, often implies strong temporal correlations or trends among pattern elements. In this paper, we study the problem of mining a set of gap constrained sequential patterns across multiple sequences. Given a set of sequences S1, S2,., SK constituting a single hypersequence S, we aim to find recurring patterns in S, say P, which may cross multiple sequences with all their matching characters in S bounded by the user specified gap constraints. Because of the combinatorial candidate explosion, traditional Apriori-based algorithms are computationally infeasible. Our research proposes a new mechanism to ensure pattern growing and pruning. When combining the pruning technique with our Gap Constrained Search (GCS) and map-based support prediction approaches, our method achieves a speed about 40 times faster than its other peers.

#index 1279211
#* Proceedings of the 18th international joint conference on Artificial intelligence
#@ 
#t 2003
#c 11

#index 1279212
#* Learning value predictors for the speculative execution of information gathering plans
#@ Greg Barish;Craig A. Knoblock
#t 2003
#c 11
#% 227883
#% 230578
#% 284823
#% 321332
#% 370528
#% 443654
#% 570880
#% 632068
#% 665553
#% 741066
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching is one approach that can be used to issue future predictions, but it scales poorly with large data sources and is unable to make intelligent predictions given previously unseen input data, even when there is an obvious relationship between past input and the output it generated. In this paper, we describe a novel way to combine classification and transduction for a more efficient and accurate value prediction strategy, one capable of issuing predictions about previously unseen hints. We show how our approach results in significant speedups for plans that query multiple sources or sources that require multi-page navigation.

#index 1279213
#* Logic programs for consistently querying data integration systems
#@ Loreto Bravo;Leopoldo Bertossi
#t 2003
#c 11
#% 171033
#% 248038
#% 273687
#% 300385
#% 333219
#% 333325
#% 378409
#% 384978
#% 460928
#% 464915
#% 488620
#% 707146
#% 752773
#% 1394993
#! We solve the problem of obtaining answers to queries posed to a mediated integration system under the local-as-view paradigm that are consistent wrt to certain global integrity constraints. For this, the query program is combined with logic programming specifications under the stable model semantics of the class of minimal global instances, and of the class of their repairs.

#index 1279214
#* Query rewriting and answering under constraints in data integration systems
#@ Andrea Cali;Domenico Lembo;Riccardo Rosati
#t 2003
#c 11
#% 101647
#% 237190
#% 273687
#% 300385
#% 378409
#% 384978
#% 416007
#% 464915
#% 465057
#% 488620
#% 576116
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279215
#* Integrating multiple internet directories by instance-based learning
#@ Ryutaro Ichise;Hiedeaki Takeda;Shinichi Honiden
#t 2003
#c 11
#% 191680
#% 220710
#% 330767
#% 348187
#% 376266
#% 465747
#% 479817
#% 529190
#% 1289178
#% 1393621
#! Finding desired information on the Internet is becoming increasingly difficult. Internet directories such as Yahoo!, which organize web pages into hierarchical categories, provide one solution to this problem; however, such directories are of limited use because some bias is applied both in the collection and categorization of pages. We propose a method for integrating multiple Internet directories by instance-based learning. Our method provides the mapping of categories in order to transfer documents from one directory to another, instead of simply merging two directories into one. We present herein an effective algorithm for determining similar categories between two directories via a statistical method called the k-statistic. In order to evaluate the proposed method, we conducted experiments using two actual Internet directories, Yahoo! and Google. The results show that the proposed method achieves extensive improvements relative to both the Naive Bayes and Enhanced Naive Bayes approaches, without any text analysis on documents.

#index 1279216
#* A semantic framework for multimedia document adaptation
#@ Jerome Euzenat;Nabil Layaida;Victor Dias
#t 2003
#c 11
#% 116335
#% 126395
#% 219844
#% 319244
#% 342449
#% 412522
#! With the proliferation of heterogeneous devices (desktop computers, personal digital assistants, phones), multimedia documents must be played under various constraints (small screens, low bandwidth). Taking these constraints into account with current document models is impossible. Hence, generic source documents must be transformed into documents compatible with the target contexts. Currently, the design of transformations is left to programmers. We propose here a semantic framework, which accounts for multimedia document adaptation in very general terms. A model of a multimedia document is a potential execution of this document and a context defines a particular class of models. The adaptation should then retain the source document models that belong to the class defined by the context if such models exist. Otherwise, the adaptation should produce a document whose models belong to this class and are "close" to those of the source documents. We focus on the temporal dimension of multimedia documents and show how adaptation can take advantage of temporal reasoning techniques. Several metrics are given for assessing the proximity of models.

#index 1279217
#* An ontology-based architecture for cooperative information agents
#@ Frederico L. G. Freitas;Guilherme Bittencourt
#t 2003
#c 11
#% 198058
#% 199979
#% 252750
#% 316533
#! In the Web, extractor agents process classes of pages (like 'call for papers' pages, researchers' pages, etc), neglecting the relevant fact that some of them are interrelated forming clusters (e.g., science). We propose here an architecture for cognitive multi-agent systems to retrieve and classify pages from these clusters, based on data extraction. To enable cooperation, two design requirements are crucial: (a) a Web vision coupling a vision for contents (classes and attributes to be extracted) to a functional vision (the role of pages in information presentation); (b) explicit representation of agents' knowledge and abilities in the form of ontologies, both about the cluster's domain and agents' tasks. Employing this Web vision and agents' cooperation can accelerate the retrieval of useful pages. We got encouraging results with two agents for the page classes of scientific events and articles. A comparison of results to similar systems comes up with two requirements for such systems: functional categorization and a thoroughly detailed ontology of the cluster.

#index 1279218
#* Web page cleaning for web mining through feature weighting
#@ Lan Yi;Bing Liu
#t 2003
#c 11
#% 144012
#% 269217
#% 271060
#% 278106
#% 282905
#% 310546
#% 340919
#% 348180
#% 387427
#% 406493
#% 413617
#% 458379
#% 465754
#% 577281
#% 746910
#% 786504
#% 786553
#! Unlike conventional data or text, Web pages typically contain a large amount of information that is not part of the main contents of the pages, e.g., banner ads, navigation bars, and copyright notices. Such irrelevant information (which we call Web page noise) in Web pages can seriously harm Web mining, e.g., clustering and classification. In this paper, we propose a novel feature weighting technique to deal with Web page noise to enhance Web mining. This method first builds a compressed structure tree to capture the common structure and comparable blocks in a set of Web pages. It then uses an information based measure to evaluate the importance of each node in the compressed structure tree. Based on the tree and its node importance values, our method assigns a weight to each word feature in its content block. The resulting weights are used in Web mining. We evaluated the proposed technique with two Web mining tasks, Web page clustering and Web page classification. Experimental results show that our weighting method is able to dramatically improve the mining results.

#index 1279219
#* A learning-based jam session system that imitates a player's personality model
#@ Masatoshi Hamanaka;Masataka Goto;Hideki Asoh;Nobuyuki Otsu
#t 2003
#c 11
#% 103743
#! This paper describes a jam session system that enables a human player to interplay with virtual players which can imitate the player personality models of various human players. Previous systems have parameters that allow some alteration in the way virtual players react, but these systems cannot imitate human personalities. Our system can obtain three kinds of player personality models from a MIDI recording of a session in which that player participated - a reaction model, a phrase model, and a groove model. The reaction model is the characteristic way that a player reacts to other players, and it can be statistically learned from the relationship between the MIDI data of music the player listens to and the MIDI data of music improvised by that player. The phrase model is a set of player's characteristic phrases; it can be acquired through musical segmentation of a MIDI session recording by using Voronoi diagrams on a piano-roll. The groove model is a model that generates onset time deviation; it can be acquired by using a hidden Markov model. Experimental results show that the personality models of any player participating in a guitar trio session can be derived from a MIDI recording of that session.

#index 1279220
#* Getting serious about the development of computational humor
#@ Oliviero Stock;Carlo Strapparava
#t 2003
#c 11
#% 81764
#% 292128
#% 349645
#% 398950
#% 741840
#% 757113
#% 1134812
#! Society needs humor, not just for entertainment. In the Web age, presentations become more and more flexible and personalized and they will require humor contributions for electronic commerce developments (e.g. product promotion, getting selective attention, help in memorizing names, etc...) more or less as it happened in the world of broadcasted advertisement. Even if deep modeling of humor in all of its facets is not something for the near future, there is something concrete that has been achieved and that can help in providing attention to the field. The paper refers to the results of HAHACRONYM, a project devoted to humorous acronym production, a circumscribed task that nonetheless requires various generic components. The project opens the way to developments for creative language, with applications in the world of advertisement.

#index 1279221
#* Automated generation of graphic sketches by example
#@ Michelle X. Zhou;Min Chen
#t 2003
#c 11
#% 18610
#% 136350
#% 144211
#% 145641
#% 172753
#% 239580
#% 284136
#% 349644
#% 376266
#% 496416
#% 641188
#% 1271868
#% 1306059
#! Hand-crafting effective visual presentations is time-consuming and requires design skills. Here we present a case-based graphic sketch generation algorithm, which uses a database of existing graphic examples (cases) to automatically create a sketch of a presentation for a new user request. As the first case-based learning approach to graphics generation, our work offers three unique contributions. First, we augment a similarity metric with a set of adequacy evaluation criteria to retrieve a case that is most similar to the request and is also usable in sketch synthesis. To facilitate the retrieval of case fragments, we develop a systematic approach to case/request decomposition when a usable case cannot be found. Second, we improve case retrieval speed by organizing cases into hierarchical clusters based on their similarity distances and by using dynamically selected cluster representatives. Third, we develop a general case composition method to synthesize a new sketch from multiple retrieved cases. Furthermore, we have implemented our casebased sketch generation algorithm in a user-system cooperative graphics design system called IMPROVISE, which helps users to generate creative and tailored presentations.

#index 1279222
#* Logical filtering
#@ Eyal Amir;Stuart Russell
#t 2003
#c 11
#% 90860
#% 101934
#% 229083
#% 322911
#% 529665
#% 1271828
#% 1289197
#% 1476265
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279223
#* A tractability result for reasoning with incomplete first-order knowledge bases
#@ Yongmei Liu;Hector J. Levesque
#t 2003
#c 11
#% 190254
#% 273683
#% 292675
#% 333865
#% 342119
#% 449224
#% 464727
#% 593756
#% 598376
#% 599549
#% 993437
#! In previous work, Levesque proposed an extension to classical databases that would allow for a certain form of incomplete first-order knowledge. Since this extension was sufficient to make full logical deduction undecidable, he also proposed an alternative reasoning scheme with desirable logical properties. He also claimed (without proof) that this reasoning could be implemented efficiently using database techniques such as projections and joins. In this paper, we substantiate this claim and show how to adapt a bottom-up database query evaluation algorithm for this purpose, thus obtaining a tractability result comparable to those that exist for databases.

#index 1279224
#* Practical partition-based theorem proving for large knowledge bases
#@ Bill MacCartney;Sheila McIlraith;Eyal Amir;Tomás E. Uribe
#t 2003
#c 11
#% 132176
#% 283118
#% 288529
#% 296756
#% 344361
#% 384112
#% 420643
#% 420720
#% 528171
#% 565127
#% 1289233
#% 1499555
#! Query answering over commonsense knowledge bases typically employs a first-order logic theorem prover. While first-order inference is intractable in general, provers can often be hand-tuned to answer queries with reasonable performance in practice. Appealing to previous theoretical work on partition-based reasoning, we propose resolution-based theorem proving strategies that exploit the structure of a KB to improve the efficiency of reasoning. We analyze and experimentally evaluate these strategies with a testbed based on the SNARK theorem prover. Exploiting graph-based partitioning algorithms, we show how to compute a partition-derived ordering for ordered resolution, with good experimental results, offering an automatic alternative to hand-crafted orderings. We further propose a new resolution strategy, MFS resolution, that combines partition-based message passing with focused sublanguage resolution. Our experiments show a significant reduction in the number of resolution steps when this strategy is used. Finally, we augment partition-based message passing, partition-derived ordering, and MFS by combining them with the set-of-support restriction. While these combinations are incomplete, they often produce dramatic improvements in practice. This work presents promising practical techniques for query answering with large and potentially distributed commonsense KBs.

#index 1279225
#* On the revision of probabilistic beliefs using uncertain evidence
#@ Hei Chan;Adnan Darwiche
#t 2003
#c 11
#% 44876
#% 224753
#% 351595
#% 417757
#% 578736
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279226
#* Quantifying information and contradiction in propositional logic through test actions
#@ Sebastien Konieczny;Jerome Lang;Pierre Marquis
#t 2003
#c 11
#% 38668
#% 42003
#% 447393
#% 503814
#% 578666
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279227
#* Minimal change and maximal coherence for epistemic logic program updates
#@ Yan Zhang
#t 2003
#c 11
#% 171033
#% 752792
#% 752887
#% 1289160
#% 1289236
#! We consider the problem of updating nonmonotonic knowledge bases represented by epistemic logic programs where disjunctive information and notions of knowledge and beliefs can be explicitly expressed. We propose a formulation for epistemic logic program updates based on a principle called minimal change and maximal coherence. The central feature of our approach is that during an update procedure, contradictory information is removed on a basis of minimal change under the semantics of epistemic logic programs and then coherent information is maximally retained in the update result. By using our approach, we can characterize an update result in both semantic and syntactic forms. We show that our approach handles update sequences and satisfies the consistency requirement. We also investigate important semantic properties of our update approach such as reduction, persistence and preservation.

#index 1279228
#* Increasing dialogue efficiency in case-based reasoning without loss of solution quality
#@ David McSherry
#t 2003
#c 11
#% 258186
#% 418152
#% 449588
#% 490786
#% 490944
#% 743911
#% 1289284
#! Increasing dialogue efficiency in case-based reasoning (CBR) must be balanced against the risk of commitment to a sub-optimal solution. Focusing on incremental query elicitation in recommender systems, we examine the limitations of naive strategies such as terminating the dialogue when the similarity of any case reaches a predefined threshold. We also identify necessary and sufficient conditions for recommendation dialogues to be terminated without loss of solution quality. Finally, we evaluate a number of attribute-selection strategies in terms of dialogue efficiency given the requirement that there must be no loss of solution quality.

#index 1279229
#* The power of suggestion
#@ Barry Smyth;Lorraine McGinty
#t 2003
#c 11
#% 202011
#% 220711
#% 490785
#% 490786
#% 1289344
#% 1389761
#! User feedback is vital in many recommender systems to help guide the search for good recommendations. Preference-based feedback (e.g. "Show me more like item A") is an inherently ambiguous form of feedback with a limited ability to guide the recommendation process, and for this reason it is usually avoided. Nevertheless we believe that certain domains demand the use of preference-based feedback. As such, we describe and evaluate a flexible recommendation strategy that has the potential to improve the performance of case-based recommenders that rely on preference-based feedback.

#index 1279230
#* A weighted polynomial information gain kernel for resolving prepositional phrase attachment ambiguities with support vector machines
#@ Bram Vanschoenwinkel;Bernard Manderick
#t 2003
#c 11
#% 92533
#% 140588
#% 190581
#% 309208
#% 376266
#% 706900
#% 740916
#% 818061
#% 854819
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279231
#* A logic for causal reasoning
#@ Alexander Bochman
#t 2003
#c 11
#% 77841
#% 224765
#% 243712
#% 289948
#% 340738
#% 366370
#% 763743
#% 1478800
#% 1499565
#! We introduce a logical formalism of irreflexive casual production relations that possesses both a standard monotonic semantics, and a natural nonmonotonic semantics. The formalism is shown to provide a complete characterization for the casual reasoning behind casual theories from [McCain and Turner, 1997]. It is shown also that any causal relation is reducible to its Horn sub-relation with respect to the nonmonotonic semantics. We describe also a general correspondence between casual relations and abductive systems, which shows, in effect, that casual relations allow to express abductive reasoning. The results of the study seem to suggest causal production relations as a viable general framework for nonmonotonic reasoning.

#index 1279232
#* Responsibility and blame: a structural-model approach
#@ Hana Chockler;Joseph Y. Halpern
#t 2003
#c 11
#% 289459
#% 297171
#% 449788
#% 528334
#% 1289151
#% 1650363
#! Causality is typically treated an all-or-nothing concept; either A is a cause of B or it is not. We extend the definition of causality introduced by Halpern and Pearl 2001a to take into account the degree of responsibility of A for B. For example, if someone wins an election 11-0, then each person who votes for him is less responsible for the victory than if he had won 6-5. We then define a notion of degree of blame, which takes into account an agent's epistemic state. Roughly speaking, the degree of blame of A for D is the expected degree of responsibility of A for B, taken over the epistemic state of an agent.

#index 1279233
#* Causes and explanations revisited
#@ James D. Park
#t 2003
#c 11
#% 528334
#% 1289151
#% 1650703
#! This paper reconsiders the notions of actual cause and explanation in functional causal models. We demonstrate that isomorphic causal models can generate intuitively different causal pronouncements. This occurs because psychological factors not represented in the model determine what criteria we use to determine causation. This partially explains the difficulty encountered in previous attempts to define actual cause. Freed from trying fit all examples to match intuition directly (which is not possible using only the information in causal models), we provide definitions for causation matching the different causal criteria we intuitively apply. This formulation avoids difficulties associated with previous definitions, and allows a more refined discussion of what constitutes a cause in a given situation. The definitions of actual cause also allow for more refined formulations of explanation.

#index 1279234
#* GHOST: experimenting conflicts countermeasures in the pilot's activity
#@ Frederic Dehais;Catherine Tessier;Laurent Chaudron
#t 2003
#c 11
#% 3460
#% 82810
#% 111485
#% 301131
#% 326221
#% 326248
#% 326250
#% 748582
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279235
#* Dynamic Bayesian modeling of the cerebral activity
#@ Vincent Labatut;Josette Pastor;Serge Ruff
#t 2003
#c 11
#% 44876
#% 380725
#% 1023097
#! Conventional methods used for the interpretation of activation data provided by functional neuroimaging techniques provide useful insights on what the networks of cerebral structures are, and when and how much they activate. However, they do not explain how the activation of these large-scale networks derives from the cerebral information processing mechanisms involved in cognitive functions. At this global level of representation, the human brain can be considered as a dynamic biological system. Dynamic Bayesian networks seem currently the most promising modeling paradigm. Our modeling approach is based on the anatomical connectivity of cerebral regions, the information processing within cerebral areas and the causal influences that connected regions exert on each other. The capabilities of the formalism's current version are illustrated by the modeling of a phonemic categorization process, explaining the different cerebral activations in normal and dyslexic subjects. The simulation data are compared to experimental results [Ruff et al, 2001].

#index 1279236
#* Body movement analysis of human-robot interaction
#@ Takayuki Kanda;Hiroshi Ishiguro;Michita Imai;Tetsuo Ono
#t 2003
#c 11
#% 418836
#% 495947
#% 1289342
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279237
#* Qualitative map learning based on co-visibility of objects
#@ Takehisa Yairi;Koichi Hori
#t 2003
#c 11
#% 89749
#% 124691
#% 201893
#% 263023
#% 266410
#% 329444
#% 352917
#% 1271848
#! This paper proposes a unique map learning method for mobile robots based on the co-visibility information of objects i.e., the information on whether two objects are visible at the same time or not from the current position. This method first estimates empirical distances among the objects using a simple heuristics - "a pair of objects observed at the same time more frequently is likely to be located more closely together". Then it computes all the coordinates of the objects by multidimensional scaling (MDS) technique. In the latter part of this paper, it is shown that the proposed method is able to learn qualitatively very accurate maps though it uses only such primitive information, and that it is robust against some kinds of object recognition errors.

#index 1279238
#* Propagate the right thing: how preferences can speed-up constraint solving
#@ Christian Bessiere;Anais Fabre;Ulrich Junker
#t 2003
#c 11
#% 160389
#% 267574
#% 578661
#% 729049
#% 1499497
#! We present an algorithm Pref-AC that limits arc consistency (AC) to the preferred choices of a tree search procedure and that makes constraint solving more efficient without changing the pruning and shape of the search tree. Arc consistency thus becomes more scalable and usable for many realworld constraint satisfaction problems such as configuration and scheduling. Moreover, Pref-AC directly computes a preferred solution for treelike constraint satisfaction problems.

#index 1279239
#* Amalgams of constraint satisfaction problems
#@ Andrei A. Bulatov;Eugeny S. Skvortsov
#t 2003
#c 11
#% 55926
#% 65348
#% 224751
#% 237054
#% 251197
#% 252213
#% 317107
#% 331899
#% 600496
#! Many of standard practical techniques of solving constraint satisfaction problems use various decomposition methods to represent a problem as a combination of smaller ones. We study a general method of decomposing constraint satisfaction problems in which every constraint is represented as a disjunction of two or more simpler constraints defined, possibly, on smaller sets of values. We call a problem an amalgam if it can be decomposed in this way. Some particular cases of this construction have been considered in [Cohen et al., 1997; 2000b; 2000a] including amalgams of problems with disjoint sets of values, and amalgams of independent problems. In this paper, we concentrate on constraint classes determined by relational clones, and study amalgams of such classes in the general case of arbitrary finite sets of values. We completely characterise amalgams of this form solvable in polynomial time and provide efficient algorithms.

#index 1279240
#* On a generalization of triangulated graphs for domains decomposition of CSPs
#@ Assef Chmeiss;Philippe Jegou;Lamia Keddar
#t 2003
#c 11
#% 451
#% 31482
#% 55926
#% 243560
#% 282846
#% 1478758
#! In [Jegou, 1993], a decomposition method has been introduced for improving search efficiency in the area of Constraint Satisfaction Problems. This method is based on properties of micro-structure of CSPs related to properties of triangulated graphs. This decomposition allows to transform an instance of CSP in a collection of sub-problems easier to solve, and then gives a natural and efficient way for a parallel implementation [Habbas et al, 2000]. In this paper, we present a generalization of this approach, which is based on a generalization of triangulated graphs. This generalization allows to define the level of decomposition which can be fixed by a graph parameter. The larger this parameter is, the more level of decomposition that is the number of sub-problems is. As a consequence, we can then define the level of decomposition, with respect to the nature of the parallel configuration used (the number of processors). First experiments reported here show that this extension increases significantly the advantage of the basic decomposition, already shown in [Habbas et al, 2000].

#index 1279241
#* A maximal tractable class of soft constraints
#@ David Cohen;Martin Cooper;Peter Jeavons;Andrei Krokhin
#t 2003
#c 11
#% 36698
#% 53085
#% 131561
#% 164166
#% 237054
#% 268708
#% 335852
#% 414936
#% 419951
#% 600496
#% 1289192
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279242
#* Reasoning about soft constraints and conditional preferences: complexity results and approximation techniques
#@ C. Domshlak;F. Rossi;K. B. Venable;T. Walsh
#t 2003
#c 11
#% 130133
#% 230551
#% 445247
#% 528176
#% 535473
#% 578698
#% 1275309
#! Many real life optimization problems contain both hard and soft constraints, as well as qualitative conditional preferences. However, there is no single formalism to specify all three kinds of information. We therefore propose a framework, based on both CP-nets and soft constraints, that handles both hard and soft constraints as well as conditional preferences efficiently and uniformly. We study the complexity of testing the consistency of preference statements, and show how soft constraints can faithfully approximate the semantics of conditional preference statements whilst improving the computational complexity.

#index 1279243
#* Multiset ordering constraints
#@ Alan Frisch;Ian Miguel;Zeynep Kiziltan;Brahim Hnich;Toby Walsh
#t 2003
#c 11
#% 160208
#% 477354
#% 534837
#% 535153
#% 535172
#% 1275309
#% 1499496
#! We identify a new and important global (or nonbinary) constraint which ensures that the values taken by two vectors of variables, when viewed as multisets, are ordered. This constraint is useful for a number of different applications including breaking symmetry and fuzzy constraint satisfaction. We propose and implement a linear time algorithm for enforcing generalised arc-consistency on such a multiset ordering constraint. Experimental results show considerable promise.

#index 1279244
#* Non-binary constraints and optimal dual-graph representations
#@ Gianluigi Greco;Francesco Scarcello
#t 2003
#c 11
#% 2028
#% 36814
#% 55926
#% 159244
#% 303886
#% 321058
#% 331899
#% 428357
#! We study the relationships among structural methods for identifying and solving tractable classes of Constraint Satisfaction Problems (CSPs). In particular, we first answer a long-standing question about the notion of biconnected components applied to an "optimal" reduct of the dual constraint-graph, by showing that this notion is in fact equivalent to the hinge decomposition method. Then, we give a precise characterization of the relationship between the treewidth notion applied to the hidden-variable encoding of a CSP and the same notion applied to some optimal reduct of the dual constraint-graph. Finally, we face the open problem of computing such an optimal reduct. We provide an algorithm that outputs an approximation of an optimal tree decomposition, and give a qualitative explanation of the difference between this graph-based method and more general hypergraph-based methods.

#index 1279245
#* Algorithms for identifying rigid subsystems in geometric constraint systems
#@ Christophe Jermann;Bertrand Neveu;Gilles Trombettoni
#t 2003
#c 11
#% 247931
#! The structural rigidity property, a generalization of Laman's theorem which characterizes rigid bar frameworks in 2D, is generally considered a good approximation of rigidity in geometric constraint satisfaction problems (GCSPs). However, it may fail even on simple GCSPs because it does not take geometric properties into account. In this paper, we question the flow-based algorithm used by Hoffmann et al to identify rigid subGCSPs. We show that this algorithm may fail because of the structural rigidity, but also by design. We introduce a new flow-based algorithm which uses Jermann et al.'S characterization of rigidity. We show that this algorithm is correct in 2D and 3D, and can be used to tackle the major issues related to rigidity: deciding whether a GCSP is rigid or not and identifying rigid (or over-rigid) subGCSPs.

#index 1279246
#* In the quest of the best form of local consistency for weighted CSP
#@ Javier Larrosa;Thomas Schiex
#t 2003
#c 11
#% 44876
#% 230551
#% 267576
#% 419942
#% 496250
#% 578663
#% 578951
#% 1275309
#% 1289190
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279247
#* A fast and simple algorithm for bounds consistency of the all different constraint
#@ Alejandro Lopez-Ortiz;Claude-Guy Quimper;John Tromp;Peter Van Beek
#t 2003
#c 11
#% 160208
#% 266132
#% 496276
#% 529344
#% 534510
#% 576134
#! In constraint programming one models a problem by stating constraints on acceptable solutions. The constraint model is then usually solved by interleaving backtracking search and constraint propagation. Previous studies have demonstrated that designing special purpose constraint propagators for commonly occurring constraints can significantly improve the efficiency of a constraint programming approach. In this paper we present a fast, simple algorithm for bounds consistency propagation of the alldifferent constraint. The algorithm has the same worst case behavior as the previous best algorithm but is much faster in practice. Using a variety of benchmark and random problems, we show that our algorithm outperforms existing bounds consistency algorithms and also outperforms--on problems with an easily identifiable property-state-ofthe-art commercial implementations of propagators for stronger forms of local consistency.

#index 1279248
#* Solving constraint optimization problems in anytime contexts
#@ Samir Loudni;Patrice Boizumault
#t 2003
#c 11
#% 159239
#% 249426
#% 267576
#% 329490
#% 419942
#% 419951
#% 534485
#% 1275306
#% 1275309
#! This paper presents a new hybrid method for solving constraint optimization problems in anytime contexts. Discrete optimization problems are modelled as Valued CSP. Our method (VNS/LDS+CP) combines a Variable Neighborhood Search and Limited Discrepancy Search with Constraint Propagation to efficiently guide the search. Experiments on the CELAR benchmarks demonstrate significant improvements over other competing methods. VNS/LDS+CP has been successfully applied to solve a real-life anytime resource allocation problem in computer networks.

#index 1279249
#* Scenario-based stochastic constraint programming
#@ Suresh Manandhar;Armagan Tarim;Toby Walsh
#t 2003
#c 11
#% 363744
#% 420743
#% 477354
#% 503496
#% 535473
#! To model combinatorial decision problems involving uncertainty and probability, we extend the stochastic constraint programming framework proposed in [Walsh, 2002] along a number of important dimensions (e.g. to multiple chance constraints and to a range of new objectives). We also provide a new (but equivalent) semantics based on scenarios. Using this semantics, we can compile stochastic constraint programs down into conventional (nonstochastic) constraint programs. This allows us to exploit the full power of existing constraint solvers. We have implemented this framework for decision making under uncertainty in stochastic OPL, a language which is based on the OPL constraint modelling language [Hentenryck et al., 1999]. To illustrate the potential of this framework, we model a wide range of problems in areas as diverse as finance, agriculture and production.

#index 1279250
#* Consistency and set intersection
#@ Yuanlin Zhang;Roland H. C. Yap
#t 2003
#c 11
#% 189747
#% 237055
#% 289332
#! We propose a new framework to study properties of consistency in a Constraint Network from the perspective of properties of set intersection. Our framework comes with a proof schema which gives a generic way of lifting a set intersection property to one on consistency. Various well known results can be derived with this framework. More importantly, we use the framework to obtain a number of new results. We identify a new class of tree convex constraints where local consistency ensures global consistency. Another result is that in a network of arbitrary constraints, local consistency implies global consistency whenever there arc certain m-tight constraints. The most interesting result is that when the constraint on every pair of variables is properly m-tight in an arbitrary network, global consistency can be achieved by enforcing relational m=1-consistency. These results significantly improve our understanding of convex and tight constraints. This demonstrates that our framework is a promising and powerful tool for studying consistency.

#index 1279251
#* Efficient symmetry breaking for boolean satisfiability
#@ Fadi A. Aloul;Karem A. Sakallah;Igor L. Markov
#t 2003
#c 11
#% 6068
#% 274131
#% 278488
#% 328866
#% 336401
#% 336874
#% 349895
#% 655781
#% 1837579
#! Identifying and breaking the symmetries of CNF formulae has been shown to lead to significant reductions in search times. In this paper we describe a more systematic and efficient construction of symmetry-breaking predicates (SBPs). In particular, we use the cycle structure of symmetry generators, which typically involve very few variables, to drastically reduce the size of SBPs. Furthermore, our new SBP construction grows linearly with the number of relevant variables as opposed to the previous quadratic constructions. Our empirical data suggest that these improvements reduce search run times by one to two orders of magnitude on a wide variety of benchmarks with symmetries.

#index 1279252
#* Tractable symmetry breaking for CSPs with interchangeable values
#@ P. Van Hentenryck;P. Flener;J. Pearson;M. Agren
#t 2003
#c 11
#% 1406
#% 337984
#% 497307
#% 534506
#% 534837
#% 534978
#% 535152
#% 535309
#% 574008
#! Symmetry breaking in CSPs has attracted considerable attention in recent years. Various general schemes have been proposed to eliminate symmetries during search. In general, these schemes may take exponential space or time to eliminate all symmetries. This paper studies classes of CSPs for which symmetry breaking is tractable. It identifies several CSP classes which feature various forms of value interchangeability and shows that symmetry breaking can be performed in constant time and space during search using dedicated search procedures. Experimental results also show the benefits of symmetry breaking on these CSPs, which encompass many practical applications.

#index 1279253
#* On the foundations of expected expected utility
#@ Craig Boutilier
#t 2003
#c 11
#% 528026
#% 528156
#% 528176
#% 529348
#% 578692
#% 1279257
#% 1650569
#% 1650573
#! Intelligent agents often need to assess user utility functions in order to make decisions on their behalf, or predict their behavior. When uncertainty exists over the precise nature of this utility function, one can model this uncertainty using a distribution over utility functions. This view lies at the core of games with incomplete information and, more recently, several proposals for incremental preference elicitation. In such cases, decisions (or predicted behavior) are based on computing the expected expected utility (EEU) of decisions with respect to the distribution over utility functions. Unfortunately, decisions made under EEU are sensitive to the precise representation of the utility function. We examine the conditions under which EEU provides for sensible decisions by appeal to the foundational axioms of decision theory. We also discuss the impact these conditions have on the enterprise of preference elicitation more broadly.

#index 1279254
#* Great expectations: part I: on the customizability of generalized expected utility
#@ Francis C. Chu;Joseph Y. Halpern
#t 2003
#c 11
#% 22494
#% 528313
#% 1279255
#% 1650648
#% 1650798
#! We propose a generalization of expected utility that we call generalized EU (GEU), where a decision maker's beliefs are represented by plausibility measures and the decision maker's tastes are represented by general (i.e., not necessarily realvalued) utility functions. We show that every agent, "rational" or not, can be modeled as a GEU maximizes We then show that we can customize GEU by selectively imposing just the constraints we want. In particular, by show how of Savage's postulates corresponds to constraints on GEU.

#index 1279255
#* Great expectations: part II: generalized expected utility as a universal decision rule
#@ Francis C. Chu;Joseph Y. Halpern
#t 2003
#c 11
#% 22494
#% 528313
#% 1650648
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279256
#* Qualitative decision under uncertainty: back to expected utility
#@ Helene Fargier;Regis Sabbadin
#t 2003
#c 11
#% 233138
#% 289953
#% 480204
#% 527528
#% 528024
#% 1290145
#% 1650292
#% 1650578
#% 1650690
#% 1650765
#! Different qualitative models have been proposed for decision under uncertainty in Artificial Intelligence, but they generally fail to satisfy the principle of strict Pareto dominance or principle of "efficiency", in contrast to the classical numerical criterion -- expected utility. In [Dubois and Prade, 1995] qualitative criteria based on possibility theory have been proposed, that are appealing but inefficient in the above sense. The question is whether it is possible to reconcile possibilistic criteria and efficiency. The present paper shows that the answer is yes, and that it leads to special kinds of expected utilities. It is also shown that although numerical, these expected utilities remain qualitative: they lead to two different decision procedures based on min, max and reverse operators only, generalizing the leximin and leximax orderings of vectors.

#index 1279257
#* Incremental utility elicitation with minimax regret decision criterion
#@ Tianhan Wang;Craig Boutilier
#t 2003
#c 11
#% 528176
#% 529348
#% 578692
#% 578734
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279258
#* Least common subsumers and most specific concepts in a description logic with existential restrictions and terminological cycles
#@ Franz Baader
#t 2003
#c 11
#% 496103
#% 539956
#% 593696
#% 1279259
#% 1414315
#! Computing least common subsumers (Ics) and most specific concepts (msc) are inference tasks that can support the bottom-up construction of knowledge bases in description logics. In description logics with existential restrictions, the most specific concept need not exist if one restricts the attention to concept descriptions or acyclic TBoxes. In this paper, we extend the notions les and msc to cyclic TBoxes. For the description logic EC (which allows for conjunctions, existential restrictions, and the top-concept), we show that the les and msc always exist and can be computed in polynomial time if we interpret cyclic definitions with greatest fixpoint semantics.

#index 1279259
#* Terminological cycles in a description logic with existential restrictions
#@ Franz Baader
#t 2003
#c 11
#% 79502
#% 101435
#% 269563
#% 496103
#% 593696
#% 1279258
#! Cyclic definitions in description logics have until now been investigated only for description logics allowing for value restrictions. Even for the most basic language FL0, which allows for conjunction and value restrictions only, deciding subsumption in the presence of terminological cycles is a PSPACE-complete problem. This paper investigates subsumption in the presence of terminological cycles for the language EL, Which allows for conjunction, existential restrictions, and the topconcept. In contrast to the results for FL0., subsumption in EL remains polynomial, independent of whether we use least fixpoint semantics, greatest fixpoint semantics, or descriptive semantics.

#index 1279260
#* On the undecidability of description and dynamic logics with recursion and counting
#@ Piero A. Bonatti
#t 2003
#c 11
#% 495988
#% 496108
#% 559320
#% 561701
#! The evolution of Description Logics (DLs) and Propositional Dynamic Logics produced a hierarchy of decidable logics with multiple maximal elements. It would be desirable to combine different maximal logics into one super-logic, but then inference may turn out to be undecidable. Then it is important to characterize the decidability threshold for these logics. In this perspective, an interesting open question pointed out by Sattler and Vardi [Sattler and Vardi, 1999] is whether inference in a hybrid µ-calculus with restricted forms of graded modalities is decidable, and which complexity class it belongs to. In this paper we prove that this calculus and the corresponding DL µALCIOf are undecidable. Second, we prove undecidability results for logics that support both a transitive closure operator over roles and number restrictions.

#index 1279261
#* Abductive matchmaking using description logics
#@ Tommaso Di Noia;Eugenio Di Sciascio;Francesco M. Donini;Marina Mongiello
#t 2003
#c 11
#% 6246
#% 58347
#% 70391
#% 108681
#% 181220
#% 213445
#% 348132
#% 431557
#% 480645
#% 519428
#% 665860
#% 728317
#% 1289174
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279262
#* Decidability of SHIQ with complex role inclusion axioms
#@ Ian Horrocks;Ulrike Sattler
#t 2003
#c 11
#% 100170
#% 101435
#% 405391
#% 517277
#% 561740
#% 569015
#! Motivated by medical terminology applications, we investigate the decidability of the well known expressive DL, SHIQ, extended with role inclusion axioms (RIAs) of the form Ro S ⊆ P. We show that this extension is undecidable even when RIAs are restricted to the forms RoS ⊆ R or SoR ⊆ R,k but that decidability can be regained by further restricting RIAs to be acyclic. We present a tableau algorithm for this DL and report on its implementation, which behaves well in practise and provides important additional functionality in a medical terminology application.

#index 1279263
#* Keys, nominate, and concrete domains
#@ Carsten Lutz;Carlos Areces;Ian Horrocks;Ulrike Sattler
#t 2003
#c 11
#% 459291
#% 465058
#% 539012
#% 578774
#% 778600
#% 1289174
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279264
#* Non-standard reasoning services for the debugging of description logic terminologies
#@ Stefan Schlobach;Ronald Cornet
#t 2003
#c 11
#% 21137
#% 70391
#% 517280
#% 561727
#% 561740
#% 703948
#% 935898
#! Current Description Logic reasoning systems provide only limited support for debugging logically erroneous knowledge bases. In this paper we propose new non-standard reasoning services which we designed and implemented to pinpoint logical contradictions when developing the medical terminology DICE. We provide complete algorithms for unfoldable ACC-TBoxes based on minimisation of axioms using Boolean methods for minimal unsatisfiability-presening sub-TBoxes, and an incomplete bottom-up method for generalised incoherence-preserving terminologies.

#index 1279265
#* Formal verification of diagnosability via symbolic model checking
#@ Alessandro Cimatti;Charles Pecheur;Roberto Cavada
#t 2003
#c 11
#% 3873
#% 101955
#% 262737
#% 297770
#% 336874
#% 365338
#% 514913
#% 1271828
#% 1476265
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279266
#* On the design of social diagnosis algorithms for multi-agent teams
#@ Meir Kalech;Gal A. Kaminka
#t 2003
#c 11
#% 75896
#% 189698
#% 215532
#% 263126
#% 677557
#% 1271813
#% 1272316
#% 1306049
#! Teamwork demands agreement among teammembers to collaborate and coordinate effectively. When a disagreement between teammates occurs (due to failures), team-members should ideally diagnose its causes, to resolve the disagreement. Such diagnosis of social failures can be expensive in communication and computation overhead, which previous work did not address. We present a novel design space of diagnosis algorithms, distinguishing several phases in the diagnosis process, and providing alternative algorithms for each phase. We then combine these algorithms in different ways to empirically explore specific design choices in a complex domain, on thousands of failure cases. The results show that centralizing the diagnosis disambiguation process is a key factor in reducing communications, while run-time is affected mainly by the amount of reasoning about other agents. These results contrast sharply with previous work in disagreement detection, in which distributed algorithms reduce communications.

#index 1279267
#* Model-based diagnosis of hybrid systems
#@ Sriram Narasimhan;Gautam Biswas
#t 2003
#c 11
#% 517996
#% 518897
#% 518899
#% 927441
#% 1784363
#! Recent years have seen a proliferation of embedded systems that combine a digital (discrete) supervisory controller with an analog (continuous) plant. Diagnosing faults in such hybrid systems, require techniques that are different from those used for discrete and continuous systems. In addition, these algorithms have to be deployed online to meet the real time requirements of embedded systems. This paper presents a methodology for online tracking and diagnosis of hybrid systems. We demonstrate the effectiveness of the approach with experiments conducted on the fuel transfer system of fighter aircraft.

#index 1279268
#* Automated qualitative domain abstraction
#@ Martin Sachenbacher;Peter Struss
#t 2003
#c 11
#% 6200
#% 36814
#% 82637
#% 109848
#% 125529
#% 175376
#% 231749
#% 243703
#% 243709
#% 331899
#% 936979
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279269
#* Coupling CSP decomposition methods and diagnosis algorithms for tree-structured systems
#@ Markus Stumptner;Franz Wotawa
#t 2003
#c 11
#% 2028
#% 21137
#% 21138
#% 55926
#% 159244
#% 273683
#% 331899
#% 334203
#% 1290122
#! Decomposition methods are used to convert general constraint satisfaction problems into an equivalent tree-structured problem that can be solved more effectively. Recently, diagnosis algorithms for treestructured systems have been introduced, but the prerequisites of coupling these algorithms to the outcome of decomposition methods have not been analyzed in detail, thus limiting their diagnostic applicability. In this paper we generalize the TREE* algorithm and show how to use hypertree decomposition outcomes as input to the algorithm to compute the diagnoses of a general diagnosis problem.

#index 1279270
#* Automatic abstraction in component-based diagnosis driven by system observability
#@ Gianluca Torta;Pietro Torasso
#t 2003
#c 11
#% 73374
#% 105619
#% 495790
#% 1272329
#% 1289226
#! The paper addresses the problem of automatic abstraction of component variables in the context of Model Based Diagnosis, in order to produce models capable of deriving fewer and more general diagnoses when the current observability of the system is reduced. The notion of indiscriminability among faults of a set of components is introduced and constitutes the basis for a formal definition of admissible abstractions which preserve all the distinctions that are relevant for diagnosis given the current observability of the system. The automatic synthesis of abstract models further restricts abstractions such that the behavior of abstract components is expressed in terms of a simple and intuitive combination of the behavior of their subcomponents. As a validation of our proposal, we present experimental results which show the reduction in the number of diagnoses returned by a diagnostic agent for a space robotic arm.

#index 1279271
#* Information extraction from web documents based on local unranked tree automaton inference
#@ Raymond Kosala;Maurice Bruynooghe;Jan Van Den Bussche;Hendrik Blocked
#t 2003
#c 11
#% 246837
#% 271065
#% 275915
#% 278109
#% 311037
#% 312860
#% 348146
#% 431536
#% 464425
#% 464926
#% 478629
#% 531458
#% 531459
#% 543990
#! Information extraction (IE) aims at extracting specific information from a collection of documents. A lot of previous work on 10 from semi-structured documents (in XML or HTML) uses learning techniques based on strings. Some recent work converts the document to a ranked tree and uses tree automaton induction. This paper introduces an algorithm that uses unranked trees to induce an automaton. Experiments show that this gives the best results obtained so far for IE from semi-structured documents based on learning.

#index 1279272
#* Intelligent multimedia indexing and retrieval through multi-source information extraction and merging
#@ Jan Kuper;Horacio Saggion;Hamish Cunningham;Thierry Declerck;Franciska De Jong;Dennis Reidsma;Yorick Wilks;Peter Wittenburg
#t 2003
#c 11
#% 437408
#% 478259
#% 741106
#% 757350
#% 1260447
#% 1857495
#! This paper reports work on automated meta-data creation for multimedia content. The approach results in the generation of a conceptual index of the content which may then be searched via semantic categories instead of keywords. The novelty of the work is to exploit multiple sources of information relating to video content (in this case the rich range of sources covering important sports events). News, commentaries and web reports covering international football games in multiple languages and multiple modalities is analysed and the resultant data merged. This merging process leads to increased accuracy relative to individual sources.

#index 1279273
#* Active learning with strong and weak views: a case study on wrapper induction
#@ Ion Muslea;Steven N. Minton;Craig A. Knoblock
#t 2003
#c 11
#% 116165
#% 169717
#% 170649
#% 252011
#% 283136
#% 312860
#% 431536
#% 464457
#% 464466
#% 466095
#% 529191
#% 529661
#% 529678
#% 732227
#! Multi-view learners reduce the need for labeled data by exploiting disjoint sub-sets of features (views), each of which is sufficient for learning. Such algorithms assume that each view is a strong view (i.e., perfect learning is possible in each view). We extend the multi-view framework by introducing a novel algorithm, Aggressive Co-Testing, that exploits both strong and weak views; in a weak view, one can learn a concept that is strictly more general or specific than the target concept. Aggressive Co-Testing uses the weak views both for detecting the most informative examples in the domain and for improving the accuracy of the predictions. In a case study on 33 wrapper induction tasks, our algorithm requires significantly fewer labeled examples than existing state-of-the-art approaches.

#index 1279274
#* Bayesian information extraction network
#@ Leonid Peshkin;Avi Pfeffer
#t 2003
#c 11
#% 217064
#% 278104
#% 278109
#% 283136
#% 431536
#% 466892
#% 646547
#% 709066
#% 716892
#% 740916
#% 815304
#% 1289318
#% 1289319
#% 1289321
#% 1650318
#% 1650579
#! Dynamic Bayesian networks (DBNs) offer an elegant way to integrate various aspects of language in one model. Many existing algorithms developed for learning and inference in DBNs are applicable to probabilistic language modeling. To demonstrate the potential of DBNs for natural language processing, we employ a DBN in an information extraction task. We show how to assemble wealth of emerging linguistic instruments for shallow parsing, syntactic and semantic tagging, morphological decomposition, named entity recognition etc. in order to incrementally build a robust information extraction system. Our method outperforms previously published results on an established benchmark domain.

#index 1279275
#* Hierarchical hidden Markov models for information extraction
#@ Marios Skounakis;Mark Craven;Soumya Ray
#t 2003
#c 11
#% 278107
#% 292235
#% 464434
#% 466892
#% 742230
#% 1289321
#! Information extraction can be defined as the task of automatically extracting instances of specified classes or relations from text. We consider the case of using machine learning methods to induce models for extracting relation instances from biomedical articles. We propose and evaluate an approach that is based on using hierarchical hidden Markov models to represent the grammatical structure of the sentences being processed. Our approach first uses a shallow parser to construct a multi-level representation of each sentence being processed. Then we train hierarchical HMMs to capture the regularities of the parses for both positive and negative sentences. We evaluate our method by inducing models to extract binary relations in three biomedical domains. Our experiments indicate that our approach results in more accurate models than several baseline HMM approaches.

#index 1279276
#* Coherent keyphrase extraction via web mining
#@ Peter D. Turney
#t 2003
#c 11
#% 229071
#% 246831
#% 260001
#% 279755
#% 281480
#% 303395
#% 337255
#% 375017
#% 401408
#% 420487
#% 495937
#% 740329
#% 748499
#! Keyphrases are useful for a variety of purposes, including summarizing, indexing, labeling, categorizing, clustering, highlighting, browsing, and searching. The task of automatic keyphrase extraction is to select keyphrases from within the text of a given document. Automatic keyphrase extraction makes it feasible to generate keyphrases for the huge number of documents that do not have manually assigned keyphrases. A limitation of previous keyphrase extraction algorithms is that the selected keyphrases are occasionally incoherent. That is, the majority of the output keyphrases may fit together well, but there may be a minority that appear to be outliers, with no clear semantic relation to the majority or to each other. This paper presents enhancements to the Kea keyphrase extraction algorithm that are designed to increase the coherence of the extracted keyphrases. The approach is to use the degree of statistical association among candidate keyphrases as evidence that they may be semantically related. The statistical association is measured using web mining. Experiments demonstrate that the enhancements improve the quality of the extracted keyphrases. Furthermore, the enhancements are not domain-specific: the algorithm generalizes well when it is trained on one domain (computer science documents) and tested on another (physics documents).

#index 1279277
#* From logic programming semantics to the consistency of syntactical treatments of knowledge and belief
#@ Thomas Bolander
#t 2003
#c 11
#% 1461
#% 53388
#% 73127
#% 197284
#% 267729
#% 431528
#% 495482
#% 1907872
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279278
#* Inverse circumscription
#@ Hubie Chen
#t 2003
#c 11
#% 126392
#% 130838
#% 181339
#% 216972
#% 235882
#% 268713
#% 311070
#% 335852
#% 600496
#! Inverse (or identification) problems involve deciding whether or not an explicitly given set of data points have an implicit description, for instance, in the form of a constraint network. Such problems provide insight into the relationships among various representations of knowledge, which may have differing computational properties. This paper formalizes and studies the inverse circumscription problem, which (roughly speaking) is to decide, given a set of models, if there exists a formula whose circumscription describes the input set.

#index 1279279
#* A theory of average-case compilability in knowledge representation
#@ Hubie Chen
#t 2003
#c 11
#% 10129
#% 27618
#% 42241
#% 98114
#% 181339
#% 216972
#% 216990
#% 235882
#% 256486
#% 291000
#% 492899
#% 571628
#% 590274
#% 616292
#% 1271822
#% 1275338
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279280
#* LADDER: a language to describe drawing, display, and editing in sketch recognition
#@ Tracy Hammond;Randall Davis
#t 2003
#c 11
#% 231306
#% 262249
#% 279107
#% 740157
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279281
#* Evaluating significance of inconsistencies
#@ Anthony Hunter
#t 2003
#c 11
#% 167544
#% 503814
#% 578666
#! Inconsistencies frequently occur in knowledge about the real-world. Some of these inconsistencies may be more significant than others, and some knowledgebases (sets of formulae) may contain more inconsistencies than others. This creates problems of deciding whether to act on these inconsistencies, and if so how. To address this, we provide a general characterization of inconsistency, based on quasi-classical logic (a form of paraconsistent logic with a more expressive semantics than Belnap's four-valued logic, and unlike other paraconsistent logics, allows the connectives to appear to behave as classical connectives). We analyse inconsistent knowledge by considering the conflicts arising in the minimal quasi-classical models for that knowledge. This is used for a measure of coherence for each knowledgebase, and for a measure of significance of inconsistencies in each knowledgebase. In this paper, we formalize this framework, and consider applications in managing heterogeneous sources of knowledge.

#index 1279282
#* Data clustering: principal components, Hopfield and self-aggregation networks
#@ Chris H. Q. Ding
#t 2003
#c 11
#% 60576
#% 74120
#% 266426
#% 313959
#% 342622
#% 342659
#% 356892
#% 466675
#% 478768
#! We present a coherent framework for data clustering. Starting with a Hopfield network, we show the solutions for several well-motivated clustering objective functions are principal components. For MinMaxCut objectives motivated for ensuring cluster balance, the solutions are the nonlinearly scaled principal components. Using scaled PC A, we generalize to multi-way clustering, constructing a self-aggregation network, where connection weights between different clusters are automatically suppressed while connection weights within same clusters are automatically enhanced.

#index 1279283
#* Distributed clustering based on sampling local density estimates
#@ Matthias Klusch;Stefano Lodi;Gianluca Moro
#t 2003
#c 11
#% 210173
#% 232102
#% 273890
#% 379340
#% 379492
#% 420144
#% 443082
#% 479658
#% 631984
#% 937189
#! Huge amounts of data are stored in autonomous, geographically distributed sources. The discovery of previously unknown, implicit and valuable knowledge is a key aspect of the exploitation of such sources. In recent years several approaches to knowledge discovery and data mining, and in particular to clustering, have been developed, but only a few of them are designed for distributed data sources. We propose a novel distributed clustering algorithm based on non-parametric kernel density estimation, which takes into account the issues of privacy and communication costs that arise in a distributed environment.

#index 1279284
#* When discriminative learning of Bayesian network parameters is easy
#@ Hannes Wettig;Peter Grunwald;Teemu Roos;Petri Myllymaki;Henry Tirri
#t 2003
#c 11
#% 44876
#% 246832
#% 528321
#% 578681
#% 1650722
#! Bayesian network models are widely used for discriminative prediction tasks such as classification. Usually their parameters are determined using 'unsupervised' methods such as maximization of the joint likelihood. The reason is often that it is unclear how to find the parameters maximizing the conditional (supervised) likelihood. We show how the discriminative learning problem can be solved efficiently for a large class of Bayesian network models, including the Naive Bayes (NB) and tree-augmented Naive Bayes (TAN) models. We do this by showing that under a certain general condition on the network structure, the discriminative learning problem is exactly equivalent to logistic regression with unconstrained convex parameter spaces. Hitherto this was known only for Naive Bayes models. Since logistic regression models have a concave log-likelihood surface, the global maximum can be easily found by local optimization methods.

#index 1279285
#* Monte Carlo theory as an explanation of bagging and boosting
#@ Roberto Esposito;Lorenza Saitta
#t 2003
#c 11
#% 36358
#% 132938
#% 198701
#% 209021
#% 235377
#% 424997
#% 425018
#% 562957
#% 562963
#% 1499573
#! In this paper we propose the framework of Monte Carlo algorithms as a useful one to analyze ensemble learning. In particular, this framework allows one to guess when bagging will be useful, explains why increasing the margin improves performances, and suggests a new way of performing ensemble learning and error estimation.

#index 1279286
#* Constructing diverse classifier ensembles using artificial training examples
#@ Prem Melville;Raymond J. Mooney
#t 2003
#c 11
#% 136350
#% 170649
#% 209021
#% 290482
#% 304515
#% 311027
#% 312728
#% 424997
#! Ensemble methods like bagging and boosting that combine the decisions of multiple hypotheses are some of the strongest existing machine learning methods. The diversity of the members of an ensemble is known to be an important factor in determining its generalization error. This paper presents a new method for generating ensembles that directly constructs diverse hypotheses using additional artificially-constructed training examples. The technique is a simple, general metalearner that can use any strong learner as a base classifier to build diverse committees. Experimental results using decision-tree induction as a base learner demonstrate that this approach consistently achieves higher predictive accuracy than both the base classifier and bagging (whereas boosting can occasionally decrease accuracy), and also obtains higher accuracy than boosting early in the learning curve when training data is limited.

#index 1279287
#* Evaluating classifiers by means of test data with noisy labels
#@ Chuck P. Lam;David G. Stork
#t 2003
#c 11
#% 115462
#% 219753
#% 252011
#% 311027
#% 466747
#% 729437
#% 742220
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279288
#* AUC: a statistically consistent and more discriminating measure than accuracy
#@ Charles X. Ling;Jin Huang;Harry Zhang
#t 2003
#c 11
#% 349550
#% 464606
#% 466086
#% 566871
#% 1272396
#% 1378224
#% 1389694
#! Predictive accuracy has been used as the main and often only evaluation criterion for the predictive performance of classification learning algorithms. In recent years, the area under the ROC (Receiver Operating Characteristics) curve, or simply AUC, has been proposed as an alternative single-number measure for evaluating learning algorithms. In this paper, we prove that AUC is a better measure than accuracy. More specifically, we present rigourous definitions on consistency and discriminancy in comparing two evaluation measures for learning algorithms. We then present empirical evaluations and a formal proof to establish that AUC is indeed statistically consistent and more discriminating than accuracy. Our result is quite significant since we formally prove that, for the first time, AUC is a better measure than accuracy in the evaluation of learning algorithms.

#index 1279289
#* Spaces of theories with ideal refinement operators
#@ Nicola Fanizzi;Stefano Ferilli;Nicola Di Mauro;Teresa M. A. Basile
#t 2003
#c 11
#% 26115
#% 44624
#% 277919
#% 289236
#% 302865
#% 382569
#% 449508
#% 498783
#% 939452
#% 1289264
#! Refinement operators for theories avoid the problems related to the myopia of many relational learning algorithms based on the operators that refine single clauses. However, the non-existence of ideal refinement operators has been proven for the standard clausal search spaces based on 0-subsumption or logical implication, which scales up to the spaces of theories. By adopting different generalization models constrained by the assumption of object identity, we extend the theoretical results on the existence of ideal refinement operators for spaces of clauses to the case of spaces of theories.

#index 1279290
#* Learning Minesweeper with multirelational learning
#@ Lourdes Pefia Castillo;Stefan Wrobel
#t 2003
#c 11
#% 170649
#% 183499
#% 252221
#% 458683
#% 497608
#% 550421
#% 1272328
#! Minesweeper is a one-person game which looks deceptively easy to play, but where average human performance is far from optimal. Playing the game requires logical, arithmetic and probabilistic reasoning based on spatial relationships on the board. Simply checking a board state for consistency is an NP-complete problem. Given the difficulty of hand-crafting strategies to play this and other games, AI researchers have always been interested in automatically learning such strategies from experience. In this paper, we show that when integrating certain techniques into a general purpose learning system (Mio), the resulting system is capable of inducing a Minesweeper playing strategy that beats the winning rate of average human players. In addition, we discuss the necessary background knowledge, present experimental results demonstrating the gain obtained with our techniques and show the strategy learned for the game.

#index 1279291
#* Multi-prototype support vector machine
#@ Fabio Aiolli;Alessandro Sperduti
#t 2003
#c 11
#% 191910
#% 400983
#% 562950
#% 722816
#% 857086
#! We extend multiclass SVM to multiple prototypes per class. For this framework, we give a compact constrained quadratic problem and we suggest an efficient algorithm for its optimization that guarantees a local minimum of the objective function. An annealed process is also proposed that helps to escape from local minima. Finally, we report experiments where the performance obtained using linear models is almost comparable to that obtained by state-of-art kernel-based methods but with a significant reduction (of one or two orders) in response time.

#index 1279292
#* Continuous nonlinear dimensionality reduction by kernel eigenmaps
#@ Matthew Brand
#t 2003
#c 11
#% 236651
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279293
#* Semi-supervised learning with explicit misclassification modeling
#@ Massih-Reza Amini;Patrick Gallinari
#t 2003
#c 11
#% 45106
#% 56503
#% 131258
#% 194251
#% 252011
#% 311027
#% 397136
#% 464287
#% 464466
#% 466263
#% 1051483
#! This paper investigates a new approach for training discriminant classifiers when only a small set of labeled data is available together with a large set of unlabeled data. This algorithm optimizes the classification maximum likelihood of a set of labeled-unlabeled data, using a variant form of the Classification Expectation Maximization (CEM) algorithm. Its originality is that it makes use of both unlabeled data and of a probabilistic misclassification model for these data. The parameters of the label-error model are learned together with the classifier parameters. We demonstrate the effectiveness of the approach on four data-sets and show the advantages of this method over a previously developed semi-supervised algorithm which does not consider imperfections in the labeling process.

#index 1279294
#* Spectral learning
#@ Sepandar D. Kamvar;Dan Klein;Christopher D. Manning
#t 2003
#c 11
#% 67565
#% 282905
#% 464608
#% 466890
#% 854651
#! We present a simple, easily implemented spectral learning algorithm which applies equally whether we have no supervisory information, pairwise link constraints, or labeled examples. In the unsupervised case, it performs consistently with other spectral clustering algorithms. In the supervised case, our approach achieves high accuracy on the categorization of thousands of documents given only a few dozen labeled training documents for the 20 Newsgroups data set. Furthermore, its classification accuracy increases with the addition of unlabeled documents, demonstrating effective use of unlabeled data. By using normalized affinity matrices which are both symmetric and stochastic, we also obtain both a probabilistic interpretation of our method and certain guarantees of performance.

#index 1279295
#* SVMC: single-class classification with support vector machines
#@ Hwanjo Yu
#t 2003
#c 11
#% 697
#% 420077
#% 464641
#% 466887
#% 577235
#% 722811
#% 722812
#% 855583
#! Single-Class Classification (SCC) seeks to distinguish one class of data from the universal set of multiple classes. We present a new SCC algorithm that efficiently computes an accurate boundary of the target class from positive and unlabeled data (without labeled negative data).

#index 1279296
#* A learning algorithm for web page scoring systems
#@ Michelangelo Diligenti;Marco Gori;Marco Maggini
#t 2003
#c 11
#% 80995
#% 319666
#% 348172
#% 348173
#% 480309
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279297
#* Does a new simple Gaussian weighting approach perform well in text categorization?
#@ Giorgio Maria Di Nunzio;Alessandro Micarelli
#t 2003
#c 11
#% 243728
#% 260001
#% 280817
#% 344447
#% 458369
#% 458379
#% 465754
#! A new approach to the Text Categorization problem is here presented. It is called Gaussian Weighting and it is a supervised learning algorithm that, during the training phase, estimates two very simple and easily computable statistics which are: the Presence P, how much a term is present in a category c in the Expressiveness E, how much is present outside c in the rest of the domain. Once the system has learned this information, a Gaussian function is shaped for each term of a category, in order to assign the term a weight that estimates the level of its importance for that particular category. We tested our learning method on the task of single-label classification using the Reuters-21578 benchmark. The outcome of the result was quite impressive: in different experimental setups, we reached a micro-averaged Fl-measure of 0.89, with a peak of 0.899. Moreover, a macro-averaged Recall and Precision was calculated: the former reported a 0.72, the latter a 0.79. These results reach most of the state-of-the-art techniques of machine learning applied to Text Categorization, demonstrating that this new weighting scheme does perform well on this particular task.

#index 1279298
#* Learning to classify texts using positive and unlabeled data
#@ Xiaoli Li;Bing Liu
#t 2003
#c 11
#% 169717
#% 169806
#% 190581
#% 252011
#% 264164
#% 269217
#% 280817
#% 311027
#% 406493
#% 464466
#% 464604
#% 464631
#% 464641
#% 466888
#% 577235
#! In traditional text classification, a classifier is built using labeled training documents of every class. This paper studies a different problem. Given a set P of documents of a particular class (called positive class) and a set U of unlabeled documents that contains documents from class P and also other types of documents (called negative class documents), we want to build a classifier to classify the documents in U into documents from P and documents not from P. The key feature of this problem is that there is no labeled negative document, which makes traditional text classification techniques inapplicable. In this paper, we propose an effective technique to solve the problem. It combines the Rocchio method and the SVM technique for classifier building. Experimental results show that the new method outperforms existing methods significantly.

#index 1279299
#* Inductive learning in less than one sequential data scan
#@ Wei Fan;Haixun Wang;Philip S. Yu;Shaw-Hwa Lo
#t 2003
#c 11
#% 209021
#% 227883
#% 235377
#% 273900
#% 479787
#% 481945
#% 629625
#% 703747
#! Most recent research of scalable inductive learning on very large dataset, decision tree construction in particular, focuses on eliminating memory constraints and reducing the number of sequential data scans. However, state-of-the-art decision tree construction algorithms still require multiple scans over the data set and use sophisticated control mechanisms and data structures. We first discuss a general inductive learning framework that scans the dataset exactly once. Then, we propose an extension based on Hoeffding's inequality that scans the dataset less than once. Our frameworks are applicable to a wide range of inductive learners.

#index 1279300
#* Skewing: an efficient alternative to lookahead for decision tree induction
#@ David Page;Soumya Ray
#t 2003
#c 11
#% 136350
#% 209021
#% 235377
#% 578676
#% 1650289
#! This paper presents a novel, promising approach that allows greedy decision tree induction algorithms to handle problematic functions such as parity functions. Lookahead is the standard approach to addressing difficult functions for greedy decision tree learners. Nevertheless, this approach is limited to very small problematic functions or subfunctions (2 or 3 variables), because the time complexity grows more than exponentially with the depth of lookahead. In contrast, the approach presented in this paper carries only a constant run-time penalty. Experiments indicate that the approach is effective with only modest amounts of data for problematic functions or subfunctions of up to six or seven variables, where the examples themselves may contain numerous other (irrelevant) variables as well.

#index 1279301
#* Complexity of determining nonemptiness of the core
#@ Vincent Conitzer;Thomas Sandholm
#t 2003
#c 11
#% 160153
#% 165011
#% 171142
#% 233135
#% 252199
#% 271034
#% 541503
#! Coalition formation is a key problem in automated negotiation among self-interested agents, and other multiagent applications. A coalition of agents can sometimes accomplish things that the individual agents cannot, or can do things more efficiently. However, motivating the agents to abide to a solution requires careful analysis: only some of the solutions are stable in the sense that no group of agents is motivated to break off and form a new coalition. This constraint has been studied extensively in cooperative game theory. However, the computational questions around this constraint have received less attention. When it comes to coalition formation among software agents (that represent real-world parties), these questions become increasingly explicit. In this paper we define a concise general representation for games in characteristic form that relies on superadditivity, and show that it allows for efficient checking of whether a given outcome is in the core. We then show that determining whether the core is nonempty is NP-complete both with and without transferable utility. We demonstrate that what makes the problem hard in both cases is determining the collaborative possibilities (the set of outcomes possible for the grand coalition), by showing that if these are given, the problem becomes tractable in both cases. However, we then demonstrate that for a hybrid version of the problem, where utility transfer is possible only within the grand coalition, the problem remains NP-complete even when the collaborative possibilities are given.

#index 1279302
#* An integrated multilevel learning approach to multiagent coalition formation
#@ Leen-Kiat Soh;Xin Li
#t 2003
#c 11
#% 271073
#% 284645
#% 557204
#% 1289302
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279303
#* Dynamics of coalition formation in combinatorial trading
#@ Yiming Ye;Yuhai Tu
#t 2003
#c 11
#% 267752
#% 275955
#% 301572
#% 314925
#% 496094
#% 496250
#% 529175
#% 659838
#% 704123
#! This paper studies the dynamics of agent mediated combinatorial trading at the macroscopic level. The combinatorial marketplace consists of a retailer who wishes to sell bundles of items, and a large number of agents with different purchasing goals. These agents dynamically form coalitions to exploit the benefits of grouping based on their complementary needs. A novel physics based dynamic equation is proposed to capture the essence of the movements of agents among different sized coalitions. Simulation experiments are performed to study the global behavior of the agents and the effectiveness of the agent mediated combinatorial trading.

#index 1279304
#* Biologically-inspired self-assembly of two-dimensional shapes using global-to-local compilation
#@ Attila Kondacs
#t 2003
#c 11
#% 160838
#% 167528
#% 297919
#% 709984
#% 714890
#% 715659
#! In this paper, we present a programming language approach for the assembly of arbitrary two-dimensional shapes by decentralized, identically-programmed agents. Our system compiles a predetermined global shape into a program that instructs these agents to grow the shape via replication and location-based control mechanisms. In the global-to-local compilation phase, an input shape is decomposed into a network of covering-discs. The disc network parameterizes the agent program, a biologically-inspired framework allowing agents to amorphously produce the shape using replication and local interaction. Our system is robust to random agent failure, and regenerates in the event of region death.

#index 1279305
#* Emergence of cooperation in a pursuit-evasion game
#@ Geoff Nitschke
#t 2003
#c 11
#% 92148
#% 267416
#% 280035
#% 470160
#% 496729
#% 679292
#! This research concerns the comparison of three different artificial evolution approaches to the design of cooperative behavior in a group of simulated mobile robots. The first and second approaches, termed: single pool and plasticity, are characterized by robots that share a single genotype, though the plasticity approach includes a learning mechanism. The third approach, termed: multiple pools, is characterized by robots that use different genotypes. The application domain implements a pursuit-evasion game in which teams of robots of various sizes, termed: predators, collectively work to capture either one or two others, termed: prey. These artificial evolution approaches are also compared with a static rule based cooperative pursuit strategy specified a priori. Results indicate that the multiple pools approach is superior comparative to the other approaches in terms of measures defined for prey-capture strategy performance. That is, this approach facilitated specialization of behavioral roles allowing it to be effective for all predator team sizes tested.

#index 1279306
#* When evolving populations is better than coevolving individuals: the blind mice problem
#@ Thomas Miconi
#t 2003
#c 11
#% 124074
#% 235332
#% 369236
#% 478831
#% 679292
#% 876142
#! This paper is about the evolutionary design of multi-agent systems. An important part of recent research in this domain has been focusing on collaborative revolutionary methods. We expose possible drawbacks of these methods, and show that for a non-trivial problem called the "blind mice" problem, a classical GA approach in which whole populations are evaluated, selected and crossed together (with a few tweaks) finds an elegant and non-intuitive solution more efficiently than cooperative coevolution. The difference in efficiency grows with the number of agents within the simulation. We propose an explanation for this poorer performance of cooperative coevolution, based on the intrinsic fragility of the evaluation process. This explanation is supported by theoretical and experimental arguments.

#index 1279307
#* Improving coevolutionary search for optimal multiagent behaviors
#@ Liviu Panait;R. Paul Wiegand;Sean Luke
#t 2003
#c 11
#% 242367
#% 266286
#% 466552
#% 466730
#% 506280
#% 964711
#% 1022849
#! Evolutionary computation is a useful technique for learning behaviors in multiagent systems. Among the several types of evolutionary computation, one natural and popular method is to coevolve multi-agent behaviors in multiple, cooperating populations. Recent research has suggested that revolutionary systems may favor stability rather than performance in some domains. In order to improve upon existing methods, this paper examines the idea of modifying traditional coevolution, biasing it to search for maximal rewards. We introduce a theoretical justification of the improved method and present experiments in three problem domains. We conclude that biasing can help coevolution find better results in some multiagent problem domains.

#index 1279308
#* Approximating game-theoretic optimal strategies for full-scale poker
#@ D. Billings;N. Burch;A. Davidson;R. Holte;J. Schaeffer;T. Schauenberg;D. Szafron
#t 2003
#c 11
#% 176299
#% 233137
#% 348584
#! The computation of the first complete approximations of game-theoretic optimal strategies for full-scale poker is addressed. Several abstraction techniques are combined to represent the game of 2-player Texas Hold'em, having size O(1018), using closely related models each having size O(1O7). Despite the reduction in size by a factor of 100 billion, the resulting models retain the key properties and structure of the real game. Linear programming solutions to the abstracted game are used to create substantially improved poker-playing programs, able to defeat strong human players and be competitive against world-class opponents.

#index 1279309
#* Last-branch and speculative pruning algorithms for max
#@ Nathan Sturtevant
#t 2003
#c 11
#% 101439
#% 529676
#% 731822
#% 1271963
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279310
#* Protocol conformance for logic-based agents
#@ Ulrich Endriss;Nicolas Maudet;Fariba Sadri;Francesca Toni
#t 2003
#c 11
#% 191653
#% 256538
#% 495999
#% 496274
#% 519519
#% 659863
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279311
#* Hidden uncertainty in the logical representation of desires
#@ Jerome Lang;Leendert Van Der Torre;Emil Weydert
#t 2003
#c 11
#% 68239
#% 109945
#% 233138
#% 348812
#% 1476312
#% 1650274
#% 1650578
#! In this paper we introduce and study a logic of desires. The semantics of our logic is defined by means of two ordering relations representing preference and normality as in Boutilier's logic QDT. However, the desires are interpreted in a different way: "in context A, I desire B" is interpreted as "the best among the most normal A Λ B worlds are preferred to the most normal A Λ ¬ B worlds". We study the formal properties of these desires, illustrate their expressive power on several classes of examples and position them with respect to previous work in qualitative decision theory.

#index 1279312
#* Constitutive rules for agent communication languages
#@ Jeremy Pitt
#t 2003
#c 11
#% 256538
#% 379154
#% 431508
#% 519516
#% 519518
#! We follow Searle's contention that speaking a (natural) language is to engage in a rule-governed form of behaviour, and that those rules are conventional (institutional) rather than natural or physical. We show how this analysis can also be used to specify rules of interaction for systems of electronic agents communicating with an artificial language. We conclude that using constitutive rules to define the semantics of an agent communication language not only distinguishes agent communication from method invocation, but also offers significant computational advantages over using intentional states.

#index 1279313
#* Simultaneous adversarial multi-robot learning
#@ Michael Bowling;Manuela Veloso
#t 2003
#c 11
#% 124687
#% 266286
#% 348821
#% 384911
#% 528018
#% 565539
#! Multi-robot learning faces all of the challenges of robot learning with all of the challenges of multiagent learning. There has been a great deal of recent research on multiagent reinforcement learning in stochastic games, which is the intuitive extension of MDPs to multiple agents. This recent work, although general, has only been applied to small games with at most hundreds of states. On the other hand robot tasks have continuous, and often complex, state and action spaces. Robot learning tasks demand approximation and generalization techniques, which have only received extensive attention in single-agent learning. In this paper we introduce GraWoLF, a general-purpose, scalable, multiagent learning algorithm. It combines gradient-based policy learning techniques with the WoLF ("Win or Learn Fast") variable learning rate. We apply this algorithm to an adversarial multi-robot task with simultaneous learning. We show results of learning both in simulation and on the real robots. These results demonstrate that GraWoLF can learn successful policies, overcoming the many challenges in multi-robot learning.

#index 1279314
#* Taming decentralized POMDPs: towards efficient policy computation for multiagent settings
#@ R. Nair;M. Tambe;M. Yokoo;D. Pynadath;S. Marsella
#t 2003
#c 11
#% 30037
#% 252183
#% 334662
#% 346451
#% 527987
#% 528006
#% 782311
#% 1271975
#% 1650702
#! The problem of deriving joint policies for a group of agents that maximize some joint reward function can be modeled as a decentralized partially observable Markov decision process (POMDP). Yet, despite the growing importance and applications of decentralized POMDP models in the multiagents arena, few algorithms have been developed for efficiently deriving joint policies for these models. This paper presents a new class of locally optimal algorithms called "Joint Equilibrium-based search for policies (JESP)". We first describe an exhaustive version of JESP and subsequently a novel dynamic programming approach to JESP. Our complexity analysis reveals the potential for exponential speedups due to the dynamic programming approach. These theoretical results are verified via empirical comparisons of the two JESP versions with each other and with a globally optimal brute-force search algorithm. Finally, we prove piece-wise linear and convexity (PWLC) properties, thus taking steps towards developing algorithms for continuous belief states.

#index 1279315
#* A Bayesian approach to imitation in reinforcement learning
#@ Bob Price;Craig Boutilier
#t 2003
#c 11
#% 126926
#% 135414
#% 160859
#% 305085
#% 465902
#% 465913
#% 466242
#% 466418
#% 570019
#% 1650283
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279316
#* Detecting & avoiding interference between goals in intelligent agents
#@ John Thangarajah;Lin Padgham;Michael Winikoff
#t 2003
#c 11
#% 271076
#% 283192
#% 326199
#% 334492
#% 396668
#% 444853
#% 557218
#% 643129
#% 1478841
#! Pro-active agents typically have multiple simultaneous goals. These may interact with each other both positively and negatively. In this paper we provide a mechanism allowing agents to detect and avoid a particular kind of negative interaction where the effects of one goal undo conditions that must be protected for successful pursuit of another goal. In order to detect such interactions we maintain summary information about the definite and potential conditional requirements and resulting effects of goals and their associated plans. We use these summaries to guard protected conditions by scheduling the execution of goals and plan steps. The algorithms and data structures developed allow agents to act rationally instead of blindly pursuing goals that will conflict.

#index 1279317
#* Behavior bounding: toward effective comparisons of agents & humans
#@ Scott A. Wallace;John E. Laird
#t 2003
#c 11
#% 44625
#% 179879
#% 212492
#% 262241
#! In this paper, we examine methods for comparing human and agent behavior. The results of such a comparison can be used to validate a computer model of human behavior, score a Turning test, or guide an intelligent tutoring system. We introduce behavior bounding, an automated model-based approach for behavior comparison. We identify how this approach can be used with both human and agent behavior. We demonstrate that it requires minimal human effort to use, and that it is efficient when working with complex agents. Finally, we show empirical results indicating that this approach is effective at identifying behavioral problems in certain types of agents and that it has superior performance when compared against two benchmarks.

#index 1279318
#* Characterization of strategy/false-name proof combinatorial auction protocols: price-oriented, rationing-free protocol
#@ Makoto Yokoo
#t 2003
#c 11
#% 283057
#% 341408
#% 413867
#% 529175
#% 578713
#% 635935
#% 643121
#% 739626
#! This paper introduces a new distinctive class of combinatorial auction protocols called price-oriented, rationing-free (PORF) protocols. The outline of a PORF protocol is as follows: (i) for each bidder, the price of each bundle of goods is determined independently of his/her own declaration (while it can depend on the declarations of other bidders), (ii) we allocate each bidder a bundle that maximizes his/her utility independently of the allocations of other bidders (i.e., rationing-free). Although a PORF protocol appears quite different from traditional protocol descriptions, surprisingly, it is a sufficient and necessary condition for a protocol to be strategy-proof. Furthermore, we show that a PORF protocol satisfying additional conditions is false-name-proof; at the same time, any false-name-proof protocol can be described as a PORF protocol that satisfies the additional conditions. A PORF protocol is an innovative characterization of strategy-proof protocols and the first attempt to characterize false-name-proof protocols. Such a characterization is not only theoretically significant but also useful in practice, since it can serve as a guideline for developing new strategy/false-name proof protocols. We present a new false-name-proof protocol based on the concept of a PORF protocol.

#index 1279319
#* On identifying and managing relationships in multi-agent systems
#@ Ronald Ashri;Michael Luck;Mark D'Inverno
#t 2003
#c 11
#% 115390
#% 296865
#% 338142
#% 379027
#% 503644
#% 558152
#! Multi-agent systems result from interactions between individual agents. Through these interactions different kinds of relationships are formed, which can impact substantially on the overall system performance. However, the behaviour of agents cannot always be anticipated, especially when dealing with open and complex systems. Open agent systems must incorporate relationship management mechanisms to constrain agent actions and allow only desirable interactions. In consequence, in this paper we tackle two important issues. Firstly, in addressing management, we identify the range of different control mechanisms that are required and when they should be applied. Secondly, in addressing relationships, we present a model for identifying and characterising relationships in a manner that is application-neutral and amenable to automation.

#index 1279320
#* ODISET: On-line distributed session tracing using agents
#@ Salvador Mandujano;Arturo Galvan
#t 2003
#c 11
#% 174161
#% 180949
#% 274912
#% 321550
#% 444166
#% 507559
#% 664537
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279321
#* A continuation method for Nash equilibria in structured games
#@ Ben Blum;Christian R. Shelton;Daphne Koller
#t 2003
#c 11
#% 416666
#% 527993
#% 567883
#% 578708
#% 1289289
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279322
#* Complexity results about Nash equilibria
#@ Vincent Conitzer;Tüomas Sandholm
#t 2003
#c 11
#% 289248
#% 338466
#% 349388
#% 567883
#% 580519
#% 598665
#% 600179
#% 1289289
#! Noncooperative game theory provides a normative framework for analyzing strategic interactions. However, for the toolbox to be operational, the solutions it defines will have to be computed. In this paper, we provide a single reduction that 1) demonstrates NP-hardness of determining whether Nash equilibria with certain natural properties exist, and 2) demonstrates the NP-hardness of counting Nash equilibria (or connected sets of Nash equilibria). We also show that 3) determining whether a purestrategy Bayes-Nash equilibrium exists is NP-hard, and that 4) determining whether a pure-strategy Nash equilibrium exists in a stochastic (Markov) game is PSP ACE-hard even if the game is invisible (this remains NP-hard if the game is finite). All of our hardness results hold even if there are only two players and the game is symmetric.

#index 1279323
#* Local-effect games
#@ Kevin Leyton-Brown;Moshe Tennenholtz
#t 2003
#c 11
#% 465913
#% 527993
#% 567883
#% 578708
#% 1279321
#% 1289289
#% 1650376
#! We present a new class of games, local-effect games (LEGs), which exploit structure in a different way from other compact game representations studied in AI. We show both theoretically and empirically that these games often (but not always) have pure-strategy Nash equilibria. Finding a potential function is a good technique for finding such equilibria. We give a complete characterization of which LEGs have potential functions and provide the functions in each case; we also show a general case where pure-strategy equilibria exist in the absence of potential functions. In experiments, we show that myopic best-response dynamics converge quickly to pure strategy equilibria in games not covered by our positive theoretical results.

#index 1279324
#* Universal voting protocol tweaks to make manipulation hard
#@ Vincent Conitzer;Tuomas Sandholm
#t 2003
#c 11
#% 2837
#% 529806
#% 578703
#% 578715
#! Voting is a general method for preference aggregation in multiagent settings, but seminal results have shown that all (nondictatorial) voting protocols are manipulable. One could try to avoid manipulation by using voting protocols where determining a beneficial manipulation is hard computationally. A number of recent papers study the complexity of manipulating existing protocols. This paper is the first work to take the next step of designing new protocols that are especially hard to manipulate. Rather than designing these new protocols from scratch, we instead show how to tweak existing protocols to make manipulation hard, while leaving much of the original nature of the protocol intact. The tweak studied consists of adding one elimination preround to the election. Surprisingly, this extremely simple and universal tweak makes typical protocols hard to manipulate! The protocols become NP-hard, NP-hard, or PSPACE-hard to manipulate, depending on whether the schedule of the preround is determined before the votes are collected, after the votes are collected, or the scheduling and the vote collecting are interleaved, respectively. We prove general sufficient conditions on the protocols for this tweak to introduce the hardness, and show that the most common voting protocols satisfy those conditions. These are the first results in voting settings where manipulation is in a higher complexity class than NP (presuming PSPACE ≠ NP).

#index 1279325
#* Probabilistically survivable MASs
#@ Sarit Kraus;V. S. Subrahmanian;N. Cihan Tas
#t 2003
#c 11
#% 1436
#% 70370
#% 232716
#% 279818
#% 379037
#% 639835
#% 659837
#% 673366
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279326
#* Minimally intrusive negotiating agents for resource sharing
#@ Fariba Sadri;Francesca Toni;Paolo Torroni
#t 2003
#c 11
#% 189700
#% 419972
#% 431523
#% 495999
#! We study the problem of agents negotiating periods of time during which they can have use of resources, thus allowing for the sharing of resources. We define a multi-stage negotiation framework where agents, in order to obtain resources, step through a sequence of stages, each characterised by an increased chance of a mutually agreeable deal but at the price of disclosing more and more information. In the sequence, the agents may agree to move to the next stage if the previous stage fails to produce a deal amongst them. In this paper, we concentrate on two early negotiation stages, characterised by minimal disclosure of information. Thus, the agents negotiating at these stages can be thought of as "minimally intrusive".

#index 1279327
#* Extended gloss overlaps as a measure of semantic relatedness
#@ Satanjeev Banerjee;Ted Pedersen
#t 2003
#c 11
#% 286069
#% 325502
#% 746871
#% 1275285
#! This paper presents a new measure of semantic relatedness between concepts that is based on the number of shared words (overlaps) in their definitions (glosses). This measure is unique in that it extends the glosses of the concepts under consideration to include the glosses of other concepts to which they are related according to a given concept hierarchy. We show that this new measure reasonably correlates to human judgments. We introduce a new method of word sense disambiguation based on extended gloss overlaps, and demonstrate that it fares well on the SENSEVAL-2 lexical sample data.

#index 1279328
#* Evaluating coverage for large symbolic NLG grammars
#@ Charles B. Callaway
#t 2003
#c 11
#% 217067
#% 447608
#% 740916
#% 742226
#% 742434
#% 747994
#% 755798
#% 995522
#! After many successes, statistical approaches that have been popular in the parsing community are now making headway into Natural Language Generation (NLG). These systems are aimed mainly at surface realization, and promise the same advantages that make statistics valuable for parsing: robustness, wide coverage and domain independence. A recent experiment aimed to empirically verify the linguistic coverage for such a statistical surface realization component by generating transformed sentences from the Penn TreeBank corpus. This article presents the empirical results of a similar experiment to evaluate the coverage of a purely symbolic surface realizer. We present the problems facing a symbolic approach on the same task, describe the results of its evaluation, and contrast them with the results of the statistical method to help quantitatively determine the level of coverage currently obtained by NLG surface realizers.

#index 1279329
#* Hierarchical semantic classification: word sense disambiguation with world knowledge
#@ Massimiliano Ciaramita;Thomas Hofmann;Mark Johnson
#t 2003
#c 11
#% 283180
#% 302390
#% 309141
#% 342669
#% 452983
#% 742218
#% 756964
#% 815924
#% 854572
#% 854641
#% 1910951
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279330
#* GRAEL: an agent-based evolutionary computing approach for natural language grammar development
#@ Guy De Pauw
#t 2003
#c 11
#% 197846
#% 466736
#% 477872
#% 496739
#% 706198
#% 708948
#% 716451
#% 740916
#% 742205
#% 742218
#% 755826
#% 815835
#% 1777152
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279331
#* Outlier detection using default logic
#@ Angiulli Fabrizio;Rachel Ben-Eliyahu-Zohary;Luigi Palopoli
#t 2003
#c 11
#% 20846
#% 95250
#% 107149
#% 181220
#% 224478
#% 408396
#% 428366
#% 780340
#! Default logic is used to describe regular behavior and normal properties. We suggest to exploit the framework of default logic for detecting outliers -- individuals who behave in an unexpected way or feature abnormal properties. The ability to locate outliers can help to maintain knowledge-base integrity and to single out irregular individuals. We first formally define the notion of an outlier and an outlier witness. We then show that finding outliers is quite complex. Indeed, we show that several versions of the outlier detection problem lie over the second level of the polynomial hierarchy. For example, the question of establishing if at least one outlier can be detected in a given propositional default theory is Σ3P-complete. Although outlier detection involves heavy computation, the queries involved can frequently be executed offline, thus somewhat alleviating the difficulty of the problem. In addition, we show that outlier detection can be done in polynomial time for both the class of acyclic normal unary defaults and the class of acyclic dual normal unary defaults.

#index 1279332
#* Ordering default theories
#@ Chiaki Sakama
#t 2003
#c 11
#% 101612
#% 304469
#% 340738
#% 382569
#! In first-order logic, a theory T1 is considered stronger than another theory T2 if every formula derived from T2 is also derived from T1. Such an order relation is useful to know relative value between different theories. In the context of default logic, a theory contains default information as well as definite information. To order default theories, it is necessary to assess the information content of a default theory. To this end, we introduce a multi-valued interpretation of default theories based on a nine-valued bilattice. It distinguishes definite and credulous/skeptical default information derived from a theory, and is used for ordering default theories based on their information contents. The technique is also applied to order nonmonotonic logic programs. The results of this paper provide a method for comparing different default theories and have important application to learning nonmonotonic theories.

#index 1279333
#* Aggregate functions in disjunctive logic programming: semantics, complexity, and implementation in DLV
#@ Tina Dell'Armi;Wolfgang Faber;Giuseppe Ielpa;Nicola Leone;Gerald Pfeifer
#t 2003
#c 11
#% 103704
#% 333219
#% 400992
#% 442702
#% 443230
#% 464918
#% 484342
#! Disjunctive Logic Programming (DLP) is a very expressive formalism: it allows to express every property of finite structures that is decidable in the complexity class ΣP2 (NPNP). Despite the high expressiveness of DLP, there are some simple properties, often arising in real-world applications, which cannot be encoded in a simple and natural manner. Among these, properties requiring to apply some arithmetic operators (like sum, times, count) on a set of elements satisfying some conditions, cannot be naturally expressed in DLP. To overcome this deficiency, in this paper we extend DLP by aggregate functions. We formally define the semantics of the new language, named DLPA. We show the usefulness of the new constructs on relevant knowledge-based problems. We analyze the computational complexity of DLPA, showing that the addition of aggregates does not bring a higher cost in that respect. We provide an implementation of the DLPA language in DLV- the state-of-the-art DLP system - and report on experiments which confirm the usefulness of the proposed extension also for the efficiency of the computation.

#index 1279334
#* On tight logic programs and yet another translation from normal logic programs to propositional logic
#@ Fangzhen Lin;Jicheng Zhao
#t 2003
#c 11
#% 244091
#% 417651
#% 534463
#% 578673
#! Fages showed that if a program is tight, then every propositional model of its completion is also its stable model. Recently, Babovich, Erdem, and Lifschitz generalized Fages' result, and showed that this is also true if the program is tight on the given model of the completion. As it turned out, this is quite a general result. Among the commonly known benchmark domains, only Niemelii's normal logic program encoding of the Hamiltonian Circuit (HC) problem does not have this property. In this paper, we propose a new normal logic program for solving the HC problem, and show that the program is tight on every model of its completion. Experimental results showed that for many graphs, this new encoding improves the performance of both SMODELS and ASSAT(Chaff2), especially of the latter system which is based on the SAT solver Chaff2. We also propose a notion of inherently tight logic programs and show that for any program, it is inherently tight iff all its completion models are stable models. We then propose a polynomial transformation from a logic programs to one that is inherently tight, thus providing a reduction of stable model semantics to program completion semantics and SAT.

#index 1279335
#* On the equivalence between answer sets and models of completion for nested logic programs
#@ Jia-Huai You;Li-Yan Yuan;Mingyi Zhang
#t 2003
#c 11
#% 101945
#% 288165
#% 417649
#% 465083
#% 578673
#% 752744
#! We present a sufficient as well as a necessary condition for the equivalence between answer sets and models of completion for logic programs with nested expressions in the bodies of rules. This condition is the weakest among all that we are aware of even for normal logic programs. To obtain this result, we present a polynomial time reduction from this class of nested logic programs to extended programs. Consequently, answer sets for these nested programs can be computed by an answer set generator for extended programs on the one hand, and characterized in terms of models of completion on the other.

#index 1279336
#* Answer set optimization
#@ Gerhard Brewka;Ilkka Niemela;Miroslaw Truszczynski
#t 2003
#c 11
#% 318601
#% 400987
#% 400992
#% 411814
#% 496141
#% 499512
#% 578671
#% 1289229
#! We investigate the combination of answer set programming and qualitative optimization techniques. Answer set optimization programs (ASO programs) have two parts. The generating program Pgen produces answer sets representing possible solutions. The preference program Ppref expresses user preferences. It induces a preference relation on the answer sets of Pgen based on the degree to which rules are satisfied. We discuss possible applications of ASO programming, give complexity results and propose implementation techniques. We also analyze the relationship between ASO programs and CP-networks.

#index 1279337
#* Weak conditional logics of normality
#@ James P. Delgrande
#t 2003
#c 11
#% 3035
#% 77841
#% 100158
#% 100178
#% 107155
#% 115327
#% 116294
#% 167538
#% 167544
#% 342379
#% 780340
#% 1478800
#! A default conditional α → β has most often been informally interpreted as a defeasible version of a classical conditional, usually the material conditional. That is, the intuition is that a default should behave (implicitly or explicitly) as its (say) material counterpart "by default" or unless explicitly overridden. In this paper, we develop an alternative interpretation, in which a default is regarded more like a rule, leading from premises to conclusion. To this end, a general semantic framework under a "rule-based" interpretation is developed, and a family of weak conditional logics is specified, along with associated proof theories. Nonmonotonic inference is defined very easily in these logics. One obtains a rich set of nonmonotonic inferences concerning the incorporation of irrelevant properties and of property inheritance. Moreover, this interpretation resolves problems that have been associated with previous approaches.

#index 1279338
#* Recycling computed answers in rewrite systems for abduction
#@ Fangzhen Lin;Jia-Huai You
#t 2003
#c 11
#% 77147
#% 101945
#% 1289237
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279339
#* What is artificial intelligence? psychometric AI as an answer
#@ Selmer Bringsjord;Bettina Schimanski
#t 2003
#c 11
#% 4704
#% 91441
#% 93207
#% 163579
#% 174161
#% 366275
#% 387249
#% 616111
#! We propose an answer to the "What is AI?" question, namely, that Al is really (or at least really ought in significant part to be) Psychometric AI (PAI). Along the way, we: set out and rebut five objections to PAI; describe PERI, a robot in our lab who exemplifies PAI; and briefly treat the future of Psychometric AI, first by pointing toward some promising PAI-based applications, and then by raising some of the "big" philosophical questions the success of Psychometric AI will raise.

#index 1279340
#* Tucking RCC in Cyc's ontological bed
#@ Pierre Grenon
#t 2003
#c 11
#% 100163
#% 221339
#% 318486
#% 344370
#% 405391
#% 495666
#! Formalisms and axiomatic theories are designed to support reasoning, they are often intended with a preferred interpretation and a targeted ontology. Questions of proper interpretations and of the possible challenge of an intended interpretation arise when integrating a particular theory in pre-existing formal and ontological settings. This paper reports on an instance of this general problem of ontological engineering. The case study is that of the integration of the Region Connection Calculus for spatial reasoning in the Cyc knowledge base. We show that given the assumptions on the Cyc ontology, RCC had to be interpreted within a substantivalist metaphysic of space as a Boolean algebra of spatial regions which are distinct from their occupants. The RCC literature suggests such an intended interpretation, and this paper intends to show that this was a necessary condition of integration in Cyc's ontology. This led to the enrichment of the Cyc knowledge base, rather than to a radical modification of the upper-level ontology.

#index 1279341
#* Integrity and change in modular ontologies
#@ Heiner Stuckenschmidt;Michel Klein
#t 2003
#c 11
#% 32903
#% 244095
#% 248026
#% 445512
#% 529498
#% 529653
#% 564210
#% 572311
#% 665856
#% 936786
#% 1289233
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279342
#* Where is . •.? learning and utilizing motion patterns of persons with mobile robots
#@ Grzegorz Cielniak;Maren Bennewitz;Wolfram Burgard
#t 2003
#c 11
#% 120270
#% 290714
#% 389693
#% 634255
#% 716892
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279343
#* An extension of the ICP algorithm for modeling nonrigid objects with mobile robots
#@ Dirk Hahnel;Sebastian Thrun;Wolfram Burgard
#t 2003
#c 11
#% 117665
#% 230467
#% 418645
#% 927528
#% 1650347
#! The iterative closest point (ICP) algorithm [2] is a popular method for modeling 3D objects from range data. The classical ICP algorithm rests on a rigid surface assumption. Building on recent work on nonrigid object models [5; 16; 9], this paper presents an ICP algorithm capable of modeling nonrigid objects, where individual scans may be subject to local deformations. We describe an integrated mathematical framework for simultaneously registering scans and recovering the surface configuration. To tackle the resulting high-dimensional optimization problems, we introduce a hierarchical method that first matches a coarse skeleton of scan points, then adapts local scan patches. The approach is implemented for a mobile robot capable of acquiring 3D models of objects.

#index 1279344
#* People tracking with anonymous and ID-sensors using Rao-Blackwellised particle filters
#@ Dirk Schulz;Dieter Fox;Jeffrey Hightower
#t 2003
#c 11
#% 114573
#% 207004
#% 309430
#% 438456
#% 528169
#% 643108
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279345
#* Factored planning
#@ Eyal Amir;Barbara Engelhardt
#t 2003
#c 11
#% 44876
#% 55926
#% 160202
#% 179879
#% 266383
#% 528171
#% 1271820
#% 1271828
#% 1271962
#% 1289233
#% 1290106
#% 1650763
#! We present a general-purpose method for dynamically factoring a planning domain, whose structure is then exploited by our generic planning method to find sound and complete plans. The planning algorithm's time complexity scales linearly with the size of the domain, and at worst exponentially with the size of the largest subdomain and interaction between subdomains. The factorization procedure divides a planning domain into subdomains that are organized in a tree structure such that interaction between neighboring subdomains in the tree is minimized. The combined planning algorithm is sound and complete, and we demonstrate it on a representative planning domain. The algorithm appears to scale to very large problems regardless of the black box planner used.

#index 1279346
#* A parametric hierarchical planner for experimenting abstraction techniques
#@ Giuliano Armano;Giancarlo Cherchi;Eloisa Vargiu
#t 2003
#c 11
#% 23012
#% 90954
#% 172505
#% 224480
#! This paper presents a parametric system, devised and implemented to perform hierarchical planning by delegating the actual search to an external planner (the "parameter") at any level of abstraction, including the ground one. Aimed at giving a better insight of whether or not the exploitation of abstract spaces can be used for solving complex planning problems, comparisons have been made between instances of the hierarchical planner and their non hierarchical counterparts. To improve the significance of the results, three different planners have been selected and used while performing experiments. To facilitate the setting of experimental environments, a novel semi-automatic technique, used to generate abstraction hierarchies starting from ground-level domain descriptions, is also described.

#index 1279347
#* On the application of least-commitment and heuristic search in temporal planning
#@ Antonio Garrido;Eva Onaindia
#t 2003
#c 11
#% 224480
#% 283223
#% 495772
#% 496243
#! Graphplan planning graphs are structures widely used in modern planners. The exclusion relations calculated in the planning graph extension provide very useful information, especially in temporal planning where actions have different duration. However, Graphplan backward search has some inefficiencies that impose limitations when dealing with large temporal problems. This paper presents a new search process for temporal planning to avoid these inefficiencies. This search uses the information of a planning graph and shows beneficial in the scalability of the planner. Moreover, our experiments show that a planner with this new search is competitive with other state-of-the-art planners w.r.t. the plan quality.

#index 1279348
#* Resource temporal networks: definition and complexity
#@ Philippe Laborie
#t 2003
#c 11
#% 21145
#% 122671
#% 179938
#% 220265
#% 408396
#% 453072
#% 535149
#% 750574
#% 1271925
#% 1272008
#! This paper introduces the concept of Resource Temporal Network (RTN), a constraint network that subsumes both classical attributes used in A.I. Planning and capacity resources traditionally handled in Scheduling. After giving a formal definition of RTNs, we analyze their expressive power and study complexities of several fragments of the RTN framework. We show that solving an RTN is in general NP-Complete - which is not surprising given the expressivity of the framework - whereas computing a Necessary Truth Criterion is polynomial. This last result opens the door for promising algorithms to solve RTNs.

#index 1279349
#* Generalizing GraphPlan by formulating planning as a CSP
#@ Adriana Lopez;Fahiem Bacchus
#t 2003
#c 11
#% 2028
#% 100159
#% 224480
#% 283220
#% 336874
#% 342119
#% 344878
#% 398249
#% 544766
#% 743462
#% 1289204
#% 1476298
#% 1478776
#! We examine the approach of encoding planning problems as CSPs more closely. First we present a simple CSP encoding for planning problems and then a set of transformations that can be used to eliminate variables and add new constraints to the encoding. We show that our transformations uncover additional structure in the planning problem, structure that subsumes the structure uncovered by GRAPHPLAN planning graphs. We solve the CSP encoded planning problem by using standard CSP algorithms. Empirical evidence is presented to validate the effectiveness of this approach to solving planning problems, and to show that even a prototype implementation is more effective than standard GRAPHPLAN. Our prototype is even competitive with far more optimized planning graph based implementations. We also demonstrate that this approach can be more easily lifted to more complex types of planning than can planning graphs. In particular, we show that the approach can be easily extended to planning with resources.

#index 1279350
#* In defense of PDDL axioms
#@ Sylvie Thiebaux;Jorg Hoffmann;Bernhard Nebel
#t 2003
#c 11
#% 53385
#% 289287
#% 342829
#% 364947
#% 495942
#% 544791
#% 598376
#% 1271818
#% 1271962
#% 1272008
#! There is controversy as to whether explicit support for PDDL-like axioms and derived predicates is needed for planners to handle real-world domains effectively. Many researchers have deplored the lack of precise semantics for such axioms, while others have argued that it might be best to compile them away. We propose an adequate semantics for PDDL axioms and show that they are an essential feature by proving that it is impossible to compile them away if we restrict the growth of plans and domain descriptions to be polynomial. These results suggest that adding a reasonable implementation to handle axioms inside the planner is beneficial for the performance. Our experiments confirm this suggestion.

#index 1279351
#* Optimal time-space tradeoff in probabilistic inference
#@ David Allen;Adnan Darwiche
#t 2003
#c 11
#% 322912
#% 329486
#! Recursive Conditioning, RC, is an any-space algorithm for exact inference in Bayesian networks, which can trade space for time in increments of the size of a floating point number. This smooth trade-off is possible by varying the algorithm's cache size. When RC is run with a constrained cache size, an important problem arises: Which specific results should be cached in order to minimize the running time of the algorithm? RC is driven by a structure known as a dtree, and many such dtrees exist for a given Bayesian network. In this paper, we examine the problem of searching for an optimal caching scheme for a given dtree, and present some optimal time-space tradeoff curves for given dtrees of several published Bayesian networks. We also compare these curves to the memory requirements of state-of-the-art algorithms based on join-trees. Our results show that the memory requirements of these networks can be significantly reduced with only a minimal cost in time, allowing for exact inference in situations previously impractical. They also show that probabilistic reasoning systems can be efficiently designed to run under varying amounts of memory.

#index 1279352
#* Variable resolution particle filter
#@ Vandi Verma;Sebastian Thrun;Reid Simmons
#t 2003
#c 11
#% 266616
#% 354155
#% 374580
#% 465918
#% 1757640
#! Particle filters are used extensively for tracking the state of non-linear dynamic systems. This paper presents a new particle filter that maintains samples in the state space at dynamically varying resolution for computational efficiency. Resolution within siatespace varies by region, depending on the belief that the true state lies within each region. Where belief is strong, resolution is fine. Where belief is low, resolution is coarse, abstracting multiple similar states together. The resolution of the statespace is dynamically updated as the belief changes. The proposed algorithm makes an explicit bias-variance tradeoff to select between maintaining samples in a biased generalization of a region of state space versus in a high variance specialization at fine resolution. Samples are maintained at a coarser resolution when the bias introduced by the generalization to a coarse resolution is outweighed by the gain in terms of reduction in variance, and at a finer resolution when it is not. Maintaining samples in abstraction prevents potential hypotheses from being eliminated prematurely for lack of a sufficient number of particles. Empirical results show that our variable resolution particle filter requires significantly lower computation for performance comparable to a classical particle filter.

#index 1279353
#* First-order probabilistic inference
#@ David Poole
#t 2003
#c 11
#% 44876
#% 89958
#% 90371
#% 147677
#% 266230
#% 288366
#% 296869
#% 384112
#% 1271984
#% 1272302
#% 1289247
#% 1650326
#! There have been many proposals for first-order belief networks (i.e., where we quantify over individuals) but these typically only let us reason about the individuals that we know about. There are many instances where we have to quantify over all of the individuals in a population. When we do this the population size often matters and we need to reason about all of the members of the population (but not necessarily individually). This paper presents an algorithm to reason about multiple individuals, where we may know particular facts about some of them, but want to treat the others as a group. Combining unification with variable elimination lets us reason about classes of individuals without needing to ground out the theory.

#index 1279354
#* Dynamic probabilistic relational models
#@ Sumit Sanghai;Pedro Domingos;Daniel Weld
#t 2003
#c 11
#% 75936
#% 115608
#% 265806
#% 464304
#% 496116
#% 577225
#% 578744
#% 1271962
#% 1272326
#% 1289241
#% 1289247
#% 1650389
#% 1650568
#% 1650767
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279355
#* Generalizing plans to new environments in relational MDPs
#@ Carlos Guestrin;Daphne Koller;Chris Gearhart;Neal Kanodia
#t 2003
#c 11
#% 266230
#% 289949
#% 384911
#% 578694
#% 735048
#% 778078
#% 1271827
#! A longstanding goal in planning research is the ability to generalize plans developed for some set of environments to a new but similar environment, with minimal or no replanning. Such generalization can both reduce planning time and allow us to tackle larger domains than the ones tractable for direct planning. In this paper, we present an approach to the generalization problem based on a new framework of relational Markov Decision Processes (RMDPs). An RMDP can model a set of similar environments by representing objects as instances of different classes. In order to generalize plans to multiple environments, we define an approximate value function specified in terms of classes of objects and, in a multiagent setting, by classes of agents. This class-based approximate value function is optimized relative to a sampled subset of environments, and computed using an efficient linear programming method. We prove that a polynomial number of sampled environments suffices to achieve performance close to the performance achievable when optimizing over the entire space. Our experimental results show that our method generalizes plans successfully to new, significantly larger, environments, with minimal loss of performance relative to environment-specific planning. We demonstrate our approach on a real strategic computer war game.

#index 1279356
#* SMDP homomorphisms: an algebraic approach to abstraction in semi-Markov decision processes
#@ Balaraman Ravindran;Andrew G. Barto
#t 2003
#c 11
#% 75936
#% 179939
#% 212402
#% 272662
#% 286423
#% 318485
#% 449567
#% 464442
#% 477304
#% 655325
#% 677517
#% 836038
#% 1271827
#% 1290041
#% 1478746
#! To operate effectively in complex environments learning agents require the ability to selectively ignore irrelevant details and form useful abstractions. In this article we consider the question of what constitutes a useful abstraction in a stochastic sequential decision problem modeled as a semi-Markov Decision Process (SMDPs). We introduce the notion of SMDP homomorphism and argue that it provides a useful tool for a rigorous study of abstraction for SMDPs. We present an SMDP minimization framework and an abstraction framework for factored MDPs based on SMDP homomorphisms. We also model different classes of abstractions that arise in hierarchical systems. Although we use the options framework for purposes of illustration, the ideas are more generally applicable. We also show that the conditions for abstraction we employ are a generalization of earlier work by Dietterich as applied to the options framework.

#index 1279357
#* Covariant policy search
#@ J. Andrew Bagnell;Jeff Schneider
#t 2003
#c 11
#% 393786
#% 720778
#! We investigate the problem of non-covariant behavior of policy gradient reinforcement learning algorithms. The policy gradient approach is amenable to analysis by information geometric methods. This leads us to propose a natural metric on controller parameterization that results from considering the manifold of probability distributions over paths induced by a stochastic controller. Investigation of this approach leads to a covariant gradient ascent rule. Interesting properties of this rule are discussed, including its relation with actor-critic style reinforcement learning algorithms. The algorithms discussed here are computationally quite efficient and on some interesting problems lead to dramatic performance improvement over noncovariant rules.

#index 1279358
#* Point-based value iteration: an anytime algorithm for POMDPs
#@ Joelle Pineau;Geoff Gordon;Sebastian Thrun
#t 2003
#c 11
#% 92301
#% 252183
#% 527859
#% 565539
#% 565547
#% 643108
#% 1271823
#% 1271954
#! This paper introduces the Point-Based Value Iteration (PBVI) algorithm for POMDP planning. PBVI approximates an exact value iteration solution by selecting a small set of representative belief points and then tracking the value and its derivative for those points only. By using stochastic trajectories to choose belief points, and by maintaining only one value hyper-plane per point, PBVI successfully solves large problems: we present results on a robotic laser tag problem as well as three test domains from the literature.

#index 1279359
#* New look at the semantics and optimization methods of CP-networks
#@ Ronen I. Brafman;Yannis Dimopoulos
#t 2003
#c 11
#% 44876
#% 268779
#% 428337
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279360
#* Categorizing classes of signals by means of fuzzy gradual rules
#@ Sylvie Galichet;Didier Dubois;Henri Prade
#t 2003
#c 11
#% 70356
#% 130919
#% 337734
#% 460919
#% 496430
#% 577221
#% 712691
#% 788670
#% 1776206
#% 1787926
#! This paper presents an approach to the approximate description of univariate real-valued functions in terms of precise or imprecise reference points and interpolation between these points. It is achieved by means of gradual rules which express that the closer the variable to the abscissa of a reference point, the closer the value of the function to the ordinate of this reference point. Gradual rules enable us to specify sophisticated gauges, under the form of connected areas, inside of which the function belonging to the class under consideration should remain. This provides a simple and efficient tool for categorizing signals. This tool can be further improved by making the gauge flexible by means of fuzzy gradual rules. This is illustrated on a benchmark example.

#index 1279361
#* Gaussian process models of spatial aggregation algorithms
#@ Naren Ramakrishnan;Chris Bailey-Kellogg
#t 2003
#c 11
#% 132697
#% 268069
#% 277396
#% 277516
#% 283151
#% 309208
#% 341407
#% 344587
#% 360691
#% 435614
#% 529503
#% 707413
#% 1272282
#% 1272294
#% 1289153
#% 1499542
#! Multi-level spatial aggregates are important for data mining in a variety of scientific and engineering applications, from analysis of weather data (aggregating temperature and pressure data into ridges and fronts) to performance analysis of wireless systems (aggregating simulation results into configuration space regions exhibiting particular performance characteristics). In many of these applications, data collection is expensive and time consuming, so effort must be focused on gathering samples at locations that will be most important for the analysis. This requires that we be able to functionally model a data mining algorithm in order to assess the impact of potential samples on the mining of suitable spatial aggregates. This paper describes a novel Gaussian process approach to modeling multi-layer spatial aggregation algorithms, and demonstrates the ability of the resulting models to capture the essential underlying qualitative behaviors of the algorithms. By helping cast classical spatial aggregation algorithms in a rigorous quantitative framework, the Gaussian process models support diverse uses such as directed sampling, characterizing the sensitivity of a mining algorithm to particular parameters, and understanding how variations in input data fields percolate up through a spatial aggregation hierarchy.

#index 1279362
#* Qualitatively faithful quantitative prediction
#@ Dorian Sue;Daniel Vladusic;Ivan Bratko
#t 2003
#c 11
#% 212219
#% 229931
#% 290482
#% 303945
#% 464471
#! In this paper we describe a case study in which we applied an approach to qualitative machine learning to induce, from system's behaviour data, a qualitative model of a complex, industrially relevant mechanical system (a car wheel suspension system). The induced qualitative model enables nice causal interpretation of the relations in the modelled system. Moreover, we also show that the qualitative model can be used to guide the quantitative modelling process leading to numerical predictions that may be considerably more accurate than those obtained by state-of-the-art numerical modelling methods. This idea of combining qualitative and quantitative machine learning for system identification is in this paper carried out in two stages: (1) induction of qualitative constraints from system's behaviour data, and (2) induction of a numerical regression function that both respects the qualitative constraints and fits the training data numerically. We call this approach Q2 learning, which stands for Qualitatively faithful Quantitative learning.

#index 1279363
#* Compiling control knowledge into preconditions for planning in the situation calculus
#@ Alfredo Gabaldon
#t 2003
#c 11
#% 44836
#% 99826
#% 117869
#% 284106
#% 296170
#% 342119
#% 417597
#% 417703
#% 578733
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279364
#* Action representation and partially observable planning using epistemic logic
#@ Andreas Herzig;Jerome Lang;Pierre Marquis
#t 2003
#c 11
#% 117869
#% 188086
#% 250142
#% 322911
#% 342119
#% 529166
#% 529811
#% 1289212
#% 1476290
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279365
#* Causal theories of action: a computational core
#@ Jerome Lang;Fangzhen Lin;Pierre Marquis
#t 2003
#c 11
#% 131559
#% 243712
#% 266241
#% 291003
#% 303950
#% 337497
#% 495996
#% 496284
#% 529166
#% 1271923
#% 1289165
#% 1290153
#% 1290154
#% 1290157
#% 1478800
#! We propose a framework for simple causal theories of action, and study the computational complexity in it of various reasoning tasks such as determinism, progression and regression under various assumptions. As it turned out, even the simplest one among them, one-step temporal projection with complete initial state, is intractable. We also briefly consider an extension of the framework to allow truly indeterministic actions, and find that this extension does not increase the complexity of any of the tasks considered here.

#index 1279366
#* Describing additive fluents in action language C+
#@ Joohyung Lee;Vladimir Lifschitz
#t 2003
#c 11
#% 266241
#% 763743
#! An additive fluent is a fluent with numerical values such that the effect of several concurrently executed actions on it can be computed by adding the effects of the individual actions. We propose a method for describing effects of actions on additive fluents in the declarative language C+. An implementation of this language, called the Causal Calculator, can be used for the automation of examples of commonsense reasoning involving additive fluents.

#index 1279367
#* The concurrent, continuous FLUX
#@ Yves Martin
#t 2003
#c 11
#% 174161
#% 284647
#% 529354
#% 539946
#% 1499560
#! FLUX belongs to the high-level programming languages for cognitive agents that have been developed in recent years. Based on the established, general action representation formalism of the Fluent Calculus, FLUX allows to implement complex strategies in a concise and modular fashion. In this paper, we extend the FLUX language to reason about domains involving continuous change and where actions occur concurrently. Using constraint logic programming, we show that this reasoning is performed in an efficient way.

#index 1279368
#* Reasoning about the interaction of knowlege, time and concurrent actions in the situation calculus
#@ Richard B. Scherl
#t 2003
#c 11
#% 117869
#% 181611
#% 188086
#% 198462
#% 342119
#% 572366
#% 701158
#% 752887
#% 1271891
#! A formal framework for specifying and developing agents/robots must handle not only knowledge and sensing actions, but also time and concurrency. Researchers have extended the situation calculus to handle knowledge and sensing actions. Other researchers have addressed the issue of adding time and concurrent actions. Here both of these features are combined into a united logical theory of knowledge, sensing, time, and concurrency. The result preserves the solution to the frame problem of previous work, maintains the distinction between indexical and objective knowledge of time, and is capable of representing the various ways in which concurrency interacts with time and knowledge. Furthermore, a method based on regression is developed for solving the projection problem for theories specified in this version of the situation calculus.

#index 1279369
#* Definition and complexity of some basic metareasoning problems
#@ Vincent Conitzer;Tuomas Sandholm
#t 2003
#c 11
#% 2837
#% 98073
#% 159239
#% 205385
#% 233135
#% 243725
#% 329490
#% 329491
#% 344879
#% 495761
#% 495928
#% 781210
#% 1272375
#! In most real-world settings, due to limited time or other resources, an agent cannot perform all potentially useful deliberation and information gathering actions. This leads to the metareasoning problem of selecting such actions. Decision-theoretic methods for metareasoning have been studied in AI, but there are few theoretical results on the complexity of metareasoning. We derive hardness results for three settings which most real metareasoning systems would have to encompass as special cases. In the first, the agent has to decide how to allocate its deliberation time across anytime algorithms running on different problem instances. We show this to be ATP-complete. In the second, the agent has to (dynamically) allocate its deliberation or information gathering resources across multiple actions that it has to choose among. We show this to be AfP-hard even when evaluating each individual action is extremely simple. In the third, the agent has to (dynamically) choose a limited number of deliberation or information gathering actions to disambiguate the state of the world. We show that this is AfP-hard under a natural restriction, and PSP ACE hard in general.

#index 1279370
#* Approximating optimal policies for agents with limited execution resources
#@ Dmitri A. Dolgov;Edmund H. Durfee
#t 2003
#c 11
#% 97542
#% 165469
#% 437280
#% 1272375
#! An agent with limited consumable execution resources needs policies that attempt to achieve good performance while respecting these limitations. Otherwise, an agent (such as a plane) might fail catastrophically (crash) when it runs out of resources (fuel) at the wrong time (in midair). We present a new approach to constructing policies for agents with limited execution resources that builds on principles of real-time AI, as well as research in constrained Markov decision processes. Specifically, we formulate, solve, and analyze the policy optimization problem where constraints are imposed on the probability of exceeding the resource limits. We describe and empirically evaluate our solution technique to show that it is computationally reasonable, and that it generates policies that sacrifice some potential reward in order to make the kinds of precise guarantees about the probability of resource overutilization that are crucial for mission-critical applications.

#index 1279371
#* Belief, awareness, and two-dimensional logic
#@ Hu Liu;Shier Ju
#t 2003
#c 11
#% 18326
#% 36815
#% 188086
#% 246317
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279372
#* Non-invasive brain-actuated control of a mobile robot
#@ Jose Del R. Millan;Frederic Renkens;Josep Mourino;Wulfram Gerstner
#t 2003
#c 11
#% 234978
#% 357083
#% 493287
#% 1860963
#! Recent experiments have indicated the possibility to use the brain electrical activity to directly control the movement of robotics or prosthetic devices. In this paper we report results with a portable non-invasive brain-computer interface that makes possible the continuous control of a mobile robot in a house-like environment. The interface uses 8 surface electrodes to measure electroencephalogram (EEG) signals from which a statistical classifier recognizes 3 different mental states. Until now, brain-actuated control of robots has relied on invasive approaches-requiring surgical implantation of electrodes-since EEG-based systems have been considered too slow for controlling rapid and complex sequences of movements. Here we show that, after a few days of training, two human subjects successfully moved a robot between several rooms by mental control only. Furthermore, mental control was only marginally worse than manual control on the same task.

#index 1279373
#* Exploring unknown environments with mobile robots using coverage maps
#@ Cyrill Stachniss;Wolfram Burgard
#t 2003
#c 11
#% 224006
#% 417745
#% 531449
#% 719358
#! In this paper we introduce coverage maps as a new way of representing the environment of a mobile robot. Coverage maps store for each cell of a given grid a posterior about the amount the corresponding cell is covered by an obstacle. Using this representation a mobile robot can more accurately reason about its uncertainty in the map of the environment than with standard occupancy grids. We present a model for proximity sensors designed to update coverage maps upon sensory input. We also describe how coverage maps can be used to formulate a decision-theoretic approach for mobile robot exploration. We present experiments carried out with real robots in which accurate maps are build from noisy ultrasound data. Finally, we present a comparison of different view-point selection strategies for mobile robot exploration.

#index 1279374
#* DP-SLAM: fast, robust simultaneous localization and mapping without predetermined landmarks
#@ Austin Eliazar;Ronald Parr
#t 2003
#c 11
#% 283140
#% 418645
#% 466255
#% 578744
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279375
#* Consistent, convergent, and constant-time SLAM
#@ J. Leonard;P. Newman
#t 2003
#c 11
#% 49737
#% 578682
#% 578744
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279376
#* FastSLAM 2.0: an improved particle filtering algorithm for simultaneous localization and mapping that provably converges
#@ Michael Montemerlo;Sebastian Thrun;Daphne Roller;Ben Wegbreit
#t 2003
#c 11
#% 28541
#% 32357
#% 39654
#% 578744
#% 674184
#% 857090
#% 1650666
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279377
#* Thin junction tree filters for simultaneous localization and mapping
#@ Mark A. Paskin
#t 2003
#c 11
#% 82083
#% 283131
#% 388024
#% 527121
#% 578744
#% 580300
#% 674184
#% 1650568
#% 1650642
#! Simultaneous Localization and Mapping (SLAM) is a fundamental problem in mobile robotics: while a robot navigates in an unknown environment, it must incrementally build a map of its surroundings and, at the same time, localize itself within that map. One popular solution is to treat SLAM as an estimation problem and apply the Kalman filter; this approach is elegant, but it does not scale well: the size of the belief state and the time complexity of the filter update both grow quadratically in the number of landmarks in the map. This paper presents a filtering technique that maintains a tractable approximation of the belief state as a thin junction tree. The junction tree grows under filter updates and is periodically "thinned" via efficient maximum likelihood projections so inference remains tractable. When applied to the SLAM problem, these thin junction tree filters have a linear-space belief state and a linear-time filtering operation. Further approximation yields a filtering operation that is often constant-time. Experiments on a suite of SLAM problems validate the approach.

#index 1279378
#* A structure-based variable ordering heuristic for SAT
#@ Jinbo Huang;Adnan Darwiche
#t 2003
#c 11
#% 220203
#% 288165
#% 327779
#% 329486
#% 336874
#% 427657
#% 529186
#% 578749
#! We propose a variable ordering heuristic for SAT, which is based on a structural analysis of the SAT problem. We show that when the heuristic is used by a Davis-Putnam SAT solver that employs conflict-directed backtracking, it produces a divide-and-conquer behavior in which the SAT problem is recursively decomposed into smaller problems that are solved independently. We discuss the implications of this divide-and-conquer behavior on our ability to provide structure-based guarantees on the complexity of Davis-Putnam SAT solvers. We also report on the integration of this heuristic with ZChaff- a state-of-the-art SAT solver--showing experimentally that it significantly improves performance on a range of benchmark problems that exhibit structure.

#index 1279379
#* Backdoors to typical case complexity
#@ Ryan Williams;Carla P. Gomes;Bart Selman
#t 2003
#c 11
#% 131357
#% 174161
#% 266200
#% 296170
#% 336874
#% 338397
#% 342829
#% 420713
#% 534807
#% 578834
#% 722505
#% 1273727
#% 1290109
#! There has been significant recent progress in reasoning and constraint processing methods. In areas such as planning and finite model-checking, current solution techniques can handle combinatorial problems with up to a million variables and five million constraints. The good scaling behavior of these methods appears to defy what one would expect based on a worst-case complexity analysis. In order to bridge this gap between theory and practice, we propose a new framework for studying the complexity of these techniques on practical problem instances. In particular, our approach incorporates general structural properties observed in practical problem instances into the formal complexity analysis. We introduce a notion of "backdoors", which are small sets of variables that capture the overall combinatorics of the problem instance. We provide empirical results showing the existence of such backdoors in real-world problems. We then present a series of complexity results that explain the good scaling behavior of current reasoning and constraint methods observed on practical problem instances.

#index 1279380
#* Backbone guided local search for maximum satisfiability
#@ Weixiong Zhang;Ananda Rangan;Moshe Looks
#t 2003
#c 11
#% 126386
#% 160270
#% 214188
#% 327779
#% 534971
#% 578753
#% 1279714
#% 1289181
#% 1478779
#! Maximum satisfiability (Max-SAT) is more general and more difficult to solve than satisfiability (SAT). In this paper, we first investigate the effectiveness of Walksat, one of the best local search algorithms designed for SAT, on Max-SAT. We show that Walksat is also effective on Max-SAT, while its effectiveness degrades as the problem is more constrained. We then develop a novel method that exploits the backbone information in the local minima from Walksat and applies the backbone information in different ways to improve the performance of the Walksat algorithm. We call our new algorithm backbone guided Walksat (BGWalksat). On large random SAT and Max-SAT problems as well as instances from the SATLIB, BGWalksat significantly improves Walksat's performance.

#index 1279381
#* Phase transitions of bounded satisfiability problems
#@ Delbert D. Bailey;Phokion G. Kolaitis
#t 2003
#c 11
#% 210193
#% 216995
#% 222822
#% 302719
#% 534971
#% 565017
#% 1081134
#! We investigate phase transitions for the family of bounded satisfiability problems 3SAT(b), recently introduced by Zhang, that ask: given a 3CNF- formula, is there a truth assignment that violates no more than b of its clauses. Zhang's results were experimental and for a fixed number of variables (n = 25), and suggested that the locations of the phase transitions for 3SAT(b) are separated and move significantly as b increases. Analysis of these locations was posed as an open question. We analytically show that the phase transitions of all 3SAT(6) problems must occur within a narrow region, regardless of how large the value of b is. Moreover, our experiments reveal that the phase transitions for these problems occur in a remarkable way. Specifically, unlike 3SAT, the probability curves for 3SAT(6) do not have a quasi-common intersection point about which they rotate as they become steeper with increasing n. Instead, they move rapidly to the left toward the narrow region that the analysis predicts.

#index 1279382
#* Understanding the power of clause learning
#@ Paul Beanie;Henry Kautz;Ashish Sabharwal
#t 2003
#c 11
#% 1120
#% 1121
#% 2119
#% 21138
#% 220203
#% 266200
#% 271262
#% 278488
#% 288165
#% 327779
#% 336401
#% 336874
#% 338404
#% 347232
#% 414979
#% 427631
#% 561083
#% 593951
#% 1273727
#% 1476298
#% 1478761
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279383
#* Phase transitions of the asymmetric traveling salesman
#@ Weixiong Zhang
#t 2003
#c 11
#% 191225
#% 197425
#% 216995
#% 297875
#% 325411
#% 378369
#% 534971
#% 1279714
#% 1289182
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279384
#* Contract algorithms and robots on rays: unifying two scheduling problems
#@ Daniel S. Bernstein;Lev Finkelstein;Shlomo Zilberstein
#t 2003
#c 11
#% 158402
#% 270684
#% 329491
#% 495928
#% 578760
#! We study two apparently different, but formally similar, scheduling problems. The first problem involves contract algorithms, which can trade off run time for solution quality, as long as the amount of available run time is known in advance. The problem is to schedule contract algorithms to run on parallel processors, under the condition that an interruption can occur at any time, and upon interruption a solution to any one of a number of problems can be requested. Schedules are compared in terms of acceleration ratio, which is a worst-case measure of efficiency. We provide a schedule and prove its optimality among a particular class of schedules. Our second problem involves multiple robots searching for a goal on one of multiple rays. Search strategics are compared in terms of time-competitive ratio, the ratio of the total search time to the time it would take for one robot to traverse directly to the goal. We demonstrate that search strategies and contract schedules are formally equivalent. In addition, for our class of schedules, we derive a formula relating the acceleration ratio of a schedule to the time-competitive ratio of the corresponding search strategy.

#index 1279385
#* Maximizing flexibility: a retraction heuristic for oversubscribed scheduling problems
#@ Laurence A. Kramer;Stephen F. Smith
#t 2003
#c 11
#% 111050
#% 126390
#% 160248
#% 266127
#% 535156
#% 709976
#% 1499506
#! In this paper we consider the solution of scheduling problems that are inherently over-subscribed. In such problems, there are always more tasks to execute within a given time frame than available resource capacity will allow, and hence decisions must be made about which tasks should be included in the schedule and which should be excluded. We adopt a controlled, iterative repair search approach, and focus on improving the results of an initial priority-driven solution generation procedure. Central to our approach is a new retraction heuristic, termed max-flexibility, which is responsible for identifying which tasks to (temporarily) retract from the schedule for reassignment in an effort to incorporate additional tasks into the schedule. The max-flexibility heuristic chooses those tasks that have maximum flexibility for assignment within their feasible windows. We empirically evaluate the performance of max-flexibility using problem data and the basic scheduling procedure from a fielded airlift mission scheduling application. We show that it produces better improvement results than two contention-based retraction heuristics, including a variant of min-conflicts L Minton et al., 1992, with significantly less search and computational cost.

#index 1279386
#* Distributed patient scheduling in hospitals
#@ T. O. Paulussen;N. R. Jennings;K. S. Decker;A. Heinzl
#t 2003
#c 11
#% 85236
#% 326788
#% 431521
#! Patient scheduling in hospitals is a highly complex task. Hospitals have a distributed organisational structure; being divided into several autonomous wards and ancillary units. Moreover, the treatment process is dynamic (information about the patients' diseases often varies during treatments, causing changes in the treatment process). Current approaches are insufficient because they either focus only on the single ancillary units, and therefore do not consider the entire treatment process of the patients, or they do not account for the distribution and dynamics of the patient scheduling problem. Therefore, we propose an agent based approach in which the patients and hospital resources are modelled as autonomous agents with their own goals, reflecting the decentralised structures in hospitals. In this multi-agent system, the patient agents compete over the scarce hospital resources. Moreover to improve the overall solution, the agents then negotiate with one another. To this end, a market mechanism is described, in which each self interested agent tries to improve its own situation. In particular we focus on how the agents can calculate demand and supply prices based upon their current schedule. Further, an evaluation of first results of the proposed method is given.

#index 1279387
#* Faster heuristic search algorithms for planning with uncertainty and full feedback
#@ Blai Bonet;Hector Geffner
#t 2003
#c 11
#% 179957
#% 181627
#% 211580
#% 337981
#% 361729
#% 363744
#% 527528
#% 644560
#% 1478838
#! Recent algorithms like RTDP and LAO* combine the strength of Heuristic Search (HS) and Dynamic Programming (DP) methods by exploiting knowledge of the initial state and an admissible heuristic function for producing optimal policies without evaluating the entire space. In this paper, we introduce and analyze three new HS/DP algorithms. A first general algorithm schema that is a simple loop in which 'inconsistent' reachable states (i.e., with residuals greater than a given c) are found and updated until no such states are found, and serves to make explicit the basic idea underlying HS/DP algorithms, leaving other commitments aside. A second algorithm, that builds on the first and adds a labeling mechanism for detecting solved states based on Tarjan's strongly-connected components procedure, which is very competitive with existing approaches. And a third algorithm, that approximates the latter by enforcing the consistency of the value function over the likely' reachable states only, and leads to great time and memory savings, with no much apparent loss in quality, when transitions have probabilities that differ greatly in value.

#index 1279388
#* Comparing best-first search and dynamic programming for optimal multiple sequence alignment
#@ Heath Hohwald;Ignacio Thayer;Richard E. Korf
#t 2003
#c 11
#% 2324
#% 66630
#% 102707
#% 244337
#% 321332
#% 496261
#% 529516
#% 578766
#! Sequence alignment is an important problem in computational biology. We compare two different approaches to the problem of optimally aligning two or more character strings: bounded dynamic programming (BDP), and divide-and-conquer frontier search (DCFS). The approaches are compared in terms of time and space requirements in 2 through 5 dimensions with sequences of varying similarity and length. While BDP performs better in two and three dimensions, it consumes more time and memory than DCFS for higher-dimensional problems.

#index 1279389
#* Factored A* search for models over sequences and trees
#@ Dan Klein;Christopher D. Manning
#t 2003
#c 11
#% 137618
#% 184881
#% 529508
#% 708948
#% 740902
#% 741066
#% 741115
#% 742218
#% 748561
#% 748722
#% 786566
#% 1478822
#! We investigate the calculation of A* bounds for sequence and tree models which are the explicit intersection of a set of simpler models or can be bounded by such an intersection. We provide a natural viewpoint which unifies various instances of factored A* models for trees and sequences, some previously known and others novel, including multiple sequence alignment, weighted finite-state transducer composition, and lexicalized statistical parsing. The specific case of parsing with a product of syntactic (PCFG) and semantic (lexical dependency) components is then considered in detail. We show that this factorization gives a modular lexicalized parser which is simpler than comparably accurate non-factored models, and which allows efficient exact inference with large treebank grammars.

#index 1279390
#* An improved algorithm for optimal bin packing
#@ Richard E. Korf
#t 2003
#c 11
#% 78107
#% 162150
#% 231316
#% 261223
#% 408396
#% 421208
#% 573089
#% 578765
#! Given a set of numbers, and a set of bins of fixed capacity, the NP-complete problem of bin packing is to find the minimum number of bins needed to contain the numbers, such that the sum of the numbers assigned to each bin does not exceed the bin capacity. We present two improvements to our previous bin-completion algorithm. The first speeds up the constant factor per node generation, and the second prunes redundant parts of the search tree. The resulting algorithm appears to be asymptotically faster than our original algorithm. On problems with 90 elements, it runs over 14 times faster. Furthermore, the ratios of node generations and running times both increase with increasing problem size.

#index 1279391
#* Sparse-memory graph search
#@ Rong Zhou;Eric A. Hansen
#t 2003
#c 11
#% 2194
#% 137995
#% 266203
#% 268042
#% 321332
#% 443807
#% 496261
#% 529508
#% 529516
#% 578766
#! We describe a framework for reducing the space complexity of graph search algorithms such as A* that use Open and Closed lists to keep track of the frontier and interior nodes of the search space. We propose a sparse representation of the Closed list in which only a fraction of already expanded nodes need to be stored to perform the two functions of the Closed List - preventing duplicate search effort and allowing solution extraction. Our proposal is related to earlier work on search algorithms that do not use a Closed list at all [Korf and Zhang, 2000]. However, the approach we describe has several advantages that make it effective for a wider variety of problems.

#index 1279392
#* Layered mereotopology
#@ Maureen Donnelly
#t 2003
#c 11
#% 221339
#% 344370
#% 344379
#% 344380
#% 1275336
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279393
#* Reasoning about distances
#@ Frank Wolter;Michael Zakharyaschev
#t 2003
#c 11
#% 67565
#% 270714
#% 287466
#% 294634
#% 346656
#% 382974
#% 393812
#% 410958
#% 447960
#% 517441
#% 665856
#% 1271965
#% 1898684
#! The paper presents a novel expressive logic-based formalism intended for reasoning about numerical distances. We investigate its computational properties (in particular, show that it is EXPTIME-complete) and devise a tableau-based satisfiability-checking algorithm. To be able to express knowledge about implicit or unknown distances, we then extend the language with variables ranging over distances and prove that the resulting logic is decidable as well.

#index 1279394
#* Incremental tractable reasoning about qualitative temporal constraints
#@ Alfonso Gerevini
#t 2003
#c 11
#% 70370
#% 106116
#% 126395
#% 181229
#% 319244
#% 657751
#% 1271925
#% 1499522
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279395
#* Tractable Pareto optimization of temporal preferences
#@ Lina Khatib;Paul Morris;Robert Morris;Kristen Brent Venable
#t 2003
#c 11
#% 70370
#% 107137
#% 230551
#% 1650628
#! This paper focuses on temporal constraint problems where the objective is to optimize a set of local preferences for when events occur. In previous work, a subclass of these problems has been formalized as a generalization of Temporal CSPs, and a tractable strategy for optimization has been proposed, where global optimality is defined as maximizing the minimum of the component preference values. This criterion for optimality, which we call "Weakest Link Optimization" (WLO), is known to have limited practical usefulness because solutions are compared only on the basis of their worst value; thus, there is no requirement to improve the other values. To address this limitation, we introduce a new algorithm that rc-applies WLO iteratively in a way that leads to improvement of all the values. We show the value of this strategy by proving that, with suitable preference functions, the resulting solutions are Pareto Optimal.

#index 1279396
#* Automatic video interpretation: a novel algorithm for temporal scenario recognition
#@ Van-Thinh Vu;Francois Bremond;Monique Thonnat
#t 2003
#c 11
#! This paper presents a new scenario recognition algorithm for Video Interpretation. We represent a scenario model by specifying the characters involved in the scenario, the sub-scenarios composing the scenario and the constraints combining the sub-scenarios. Various types of constraints can be used including spatio-temporal and logical constraints. In this paper, we focus on the performance of the recognition algorithm. Our goal is to propose an efficient algorithm for processing temporal constraints and combining several actors defined within the scenario. By efficient we mean that the recognition process is linear in function of the number of sub-scenarios and in most of the cases in function of the number of characters. To validate this algorithm in term of correctness, robustness and processing time in function of scenario and scene properties (e.g. number of persons in the scene), we have tested the algorithm on several videos of a bank branch and of an office, in on-line and off-line mode and on simulated data. We conclude by comparing our algorithm with the state of the art and showing how the definition of scenario models can influence the results of the real-time scenario recognition.

#index 1279397
#* Corpus-based, statistical goal recognition
#@ Nate Blaylock;James Allen
#t 2003
#c 11
#% 103865
#% 147680
#% 279755
#% 284787
#% 328961
#% 368080
#% 423981
#% 527858
#% 706640
#% 741112
#% 741913
#% 1272376
#% 1650293
#% 1650681
#! Goal recognition for dialogue systems needs to be fast, make early predictions, and be portable. We present initial work which shows that using statistical, corpus-based methods to build goal recognizers may be a viable way to meet those needs. Our goal recognizer is trained on data from apian corpus and then used to determine the agent's most likely goal based on that data. The algorithm is linear in the number of goals, and performs very well in terms of accuracy and early prediction. In addition, it is more easily portable to new domains as does not require a hand-crafted plan library.

#index 1279398
#* A general model for online probabilistic plan recognition
#@ Hung H. Bui
#t 2003
#c 11
#% 147680
#% 180201
#% 292235
#% 380725
#% 423981
#% 528169
#% 529347
#% 567880
#% 706874
#% 709172
#% 1272356
#% 1650293
#% 1650681
#% 1650767
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279399
#* Use of off-line dynamic programming for efficient image interpretation
#@ Ramana Isukapalli;Russell Greiner
#t 2003
#c 11
#% 376266
#% 384911
#% 1022958
#! An interpretation system finds the likely mappings from portions of an image to real-world objects. An interpretation policy specifies when to apply which imaging operator, to which portion of the image, during every stage of interpretation. Earlier results compared a number of policies, and demonstrated that policies that select operators which maximize the information gain per cost, worked most effectively. However, those policies are myopic -- they rank the operators based only on their immediate rewards. This can lead to inferior overall results: it may be better to use a relatively expensive operator first, if that operator provides information that will significantly reduce the cost of the subsequent operators. This suggests using some lookahead process to compute the quality for operators non-myopically. Unfortunately, this is prohibitively expensive for most domains, especially for domains that have a large number of complex states. We therefore use ideas from reinforcement learning to compute the utility of each operator sequence. In particular, our system first uses dynamic programming, over abstract simplifications of interpretation states, to precompute the utility of each relevant sequence. It does this off-line, over a training sample of images. At run time, our interpretation system uses these estimates to decide when to use which imaging operator. Our empirical results, in the challenging real-world domain of face recognition, demonstrate that this approach works more effectively than myopic approaches.

#index 1279400
#* Switching hypothesized measurements: a dynamic model with applications to occlusion adaptive joint tracking
#@ Yang Wang;Tele Tan;Kia-Fock Loe
#t 2003
#c 11
#% 32357
#% 165466
#% 207004
#% 261320
#% 336055
#% 344669
#% 457558
#% 625130
#% 718442
#% 857094
#! This paper proposes a dynamic model supporting multimodal state space probability distributions and presents the application of the model in dealing with visual occlusions when tracking multiple objects jointly. For a set of hypotheses, multiple measurements are acquired at each time instant. The model switches among a set of hypothesized measurements during the propagation. Two computationally efficient filtering algorithms are derived for online joint tracking. Both the occlusion relationship and state of the objects are recursively estimated from the history of measurement data. The switching hypothesized measurements (SHM) model is generally applicable to describe various dynamic processes with multiple alternative measurement methods.

#index 1279401
#* Active probing strategies for problem diagnosis in distributed systems
#@ Mark Brodie;Irina Rish;Sheng Ma;Natalia Odintsova
#t 2003
#c 11
#% 408396
#% 578739
#! We address the task of problem determination in a distributed system using probes, or test transactions, which gather information about system components. Effective probing requires minimizing the cost of probing while maximizing the diagnostic accuracy of the probe set. We show that pre-planning an optimal probe set is NP-hard and present polynomial-time approximation algorithms that perform well. We then implement an active probing strategy which selects probes dynamically and show that it yields a significant reduction in probe set size in both simulation and a real system environment.

#index 1279402
#* A resolution theorem for algebraic domains
#@ Pascal Hitzler
#t 2003
#c 11
#% 197233
#% 288366
#% 345064
#% 723170
#! W. C. Rounds and G.-Q. Zhang have recently proposed to study a form of resolution on algebraic domains [Rounds and Zhang, 2001]. This framework allows reasoning with knowledge which is hierarchically structured and forms a (suitable) domain, more precisely, a coherent algebraic cpo as studied in domain theory. In this paper, we give conditions under which a resolution theorem -- in a form underlying resolution-based logic programming systems -- can be obtained. The investigations bear potential for engineering new knowledge representation and reasoning systems on a firm domain-theoretic background.

#index 1279403
#* A novel framework for integrating discrete event system control and diagnosis
#@ Gregory Provan
#t 2003
#c 11
#% 1272329

#index 1279404
#* Assertion application in theorem proving and proof planning
#@ Quoc Bao Vo;Christoph Benzmiiller;Serge Autexier
#t 2003
#c 11
#% 291002
#% 333458
#% 484329
#% 559315
#% 560582

#index 1279405
#* Case base adaptation using solution-space metrics
#@ Brian Knight;Fei Ling Woon
#t 2003
#c 11
#% 376266
#% 606569
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279406
#* Coverage-optimized retrieval
#@ David McSherry
#t 2003
#c 11
#% 494599
#% 494604
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279407
#* Explicit vs implicit profiling: a case-study in electronic programme guides
#@ Derry O'Sullivan;Barry Smyth;David Wilson
#t 2003
#c 11
#% 124010
#% 169803
#% 173879
#% 220709
#% 220711
#% 283169
#% 320432
#% 490917
#% 516633
#! In this paper, we evaluate the use of implicit interest indicators as the basis for user profiling in the Digital TV domain. Research in more traditional domains, such as Web browsing or Usenet News, indicates that some implicit interest indicators (e.g., read-time and mouse movements) are capable of serving as alternative to explicit profile information such as user ratings. Consequently, the key question we wish to answer relates to the type of implicit indicators that can be identified within the DTV domain and the extent to which they can accurately reflect a user's true preferences.

#index 1279408
#* A simulated annealing approach to the travelling tournament problem
#@ A. Anagnostopoulos;L. Michel;P. Van Hentenryck;Y. Vergados
#t 2003
#c 11
#% 244909
#% 383492
#% 534810
#! Automating the scheduling of sport leagues has received considerable attention in recent years. This paper considers the traveling tournament problem (TTP) proposed in [8; 4] to abstract the salient features of major league baseball (MLB) in the United States. It proposes a simulated annealing algorithm (TTSA) for the TTP that produces significant improvements over previous approaches.

#index 1279409
#* Grid-based sensorDCSP
#@ R. Bejar;C. Domshlak;C. Fernandez;C. Gomes;B. Selman;M. Vails
#t 2003
#c 11
#% 160245
#% 337838
#% 535157
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279410
#* Dynamic vehicle routing with stochastic requests
#@ Russell Bent;Pascal Van Hentenryck
#t 2003
#c 11
#% 573249
#% 794018
#% 959996
#! This paper considers vehicle routing problems (VRP) where customer locations and service times are random variables that are realized dynamically during plan execution. It proposes a multiple scenario approach (MSA) that continuously generates plans consistent with past decisions and anticipating future requests. The approach, which combines AI and OR techniques in novel ways, is compared with the best available heuristics that model long-distance courier mail services [Larsen et al, 2002]. Experimental results shows that MSA may significantly decrease travel times and is robust wrt reasonably noisy distributions.

#index 1279411
#* Solving finite domain constraint hierarchies by local consistency and tree search
#@ Stefano Bistarelli;Philippe Codognet;H. K. C. Hui;J. H. M. Lee
#t 2003
#c 11
#% 144558
#% 344105
#! We provide a reformulation of the constraint hierarchies (CHs) framework based on the notion of error indicators. Adapting the generalized view of local consistency in semiring-based constraint satisfaction problems (SCSPs), we define constraint hierarchy k-consistency (CH-k-C) and give a CH- 2-C enforcement algorithm. We demonstrate how the CH-2-C algorithm can be seamlessly integrated into the ordinary branch-and-bound algorithm to make it a finite domain CH solver. Experimentation confirms the efficiency and robustness of our proposed solver prototype. Unlike other finite domain CH solvers, our proposed method works for both local and global comparators. In addition, our solver can support arbitrary error functions.

#index 1279412
#* Splitting the atom: a new approach to neighbourhood interchangeability in constraint satisfaction problems
#@ James Bowen;Chavalit Likitvivatanavong
#t 2003
#c 11
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279413
#* Efficient representation of adhoc constraints
#@ Kenil C. K. Cheng;Jimmy H. M. Lee;Peter J. Stuckey
#t 2003
#c 11
#% 535306
#% 564858

#index 1279414
#* Propagation redundancy for permutation channels
#@ C. W. Choi;J. H. M. Lee;P. J. Stuckey
#t 2003
#c 11
#% 419950
#% 576134
#% 778289

#index 1279415
#* Channeling constraints and value ordering in the quasigroup completion problem
#@ Ivan Dotti;Alvaro Del Val;Manuel Cebrian
#t 2003
#c 11

#index 1279416
#* Making the breakout algorithm complete using systematic search
#@ Carlos Eisenberg;Boi Faltings
#t 2003
#c 11
#% 126390
#% 535164
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279417
#* Sampling combinatorial spaces using biased random walks
#@ Jordan Erenrich;Bart Selman
#t 2003
#c 11
#% 160270
#% 205391
#% 529186
#% 1478779
#! For probabilistic reasoning, one often needs to sample from a combinatorial space. For example, one may need to sample uniformly from the space of all satisfying assignments. Can state-of-the-art search procedures for SAT be used to sample effectively from the space of all solutions? And, if so, how uniformly do they sample? Our initial results find that on the positive side, one can find all solutions to a given instance. Nevertheless, sampling can be highly biased. This research provides a starting point for the development of more balanced procedures.

#index 1279418
#* Finite domain constraint solver learning
#@ Arnaud Lallouet;Thi-Bich-Hanh Dao;Andrei Legtchenko;AbdelAli Ed-Dbali
#t 2003
#c 11
#% 278105
#% 535306
#% 564858
#% 744223
#! In this paper, we present an abstract framework for learning a finite domain constraint solver modeled by a set of operators enforcing a consistency. The behavior of the consistency to be learned is taken as the set of examples on which the learning process is applied. The best possible expression of this operator in a given language is then searched. We instantiate this framework to the learning of bound-consistency in the indexical language of Gnu-Prolog.

#index 1279419
#* Applying interchangeability techniques to the distributed breakout algorithm
#@ Adrian Petcu;Boi Faltings
#t 2003
#c 11
#% 266119
#% 443227
#% 535157
#! This paper presents two methods for improving the performance of the Distributed Breakout Algorithm using the notion of interchangeability. In particular, we use neighborhood partial and full interchangeability techniques to keep conflicts localized and avoid spreading them to neighboring areas. Our experiments on distributed sensor networks show that such techniques can significantly reduce the number of cycles required to solve the problems (therefore also reduce communication and time requirements), especially on difficult problems. Moreover, the improved algorithms are able to solve a higher proportion of the test problems.

#index 1279420
#* EVOC: a music generating system using genetic algorithms
#@ Timothy Weale;Jennifer Seitzer
#t 2003
#c 11
#% 68171
#! In this work, we present a Genetic Algorithm (GA) system "Evolutionary Counterpoint" (EVOC) that generates contrapuntal music. Counterpoint is the construction of a musical piece by superimposing multiple melodies, indirectly forming an underlying harmonic structure. Here, we include a description of the underlying algorithm, fitness function, and overall system modules.

#index 1279421
#* Temporal reasoning with preferences and uncertainty
#@ N. Yorke-Smith;K. B. Venable;F. Rossi
#t 2003
#c 11
#% 107137
#% 535154
#% 1289215
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279422
#* BDIO: obligations and the specification of agent behavior
#@ Jan Broersen;Mehdi Dastani;Leendert Van Der Torre
#t 2003
#c 11
#% 431526

#index 1279423
#* Prolegomenon to a theory of conservative belief revision
#@ James P. Delgrande;Abhaya C. Nayak;Maurice Pagnucco
#t 2003
#c 11
#% 90860
#% 296028
#% 326595
#! A standard intuition underlying traditional accounts of belief change is the principle of minimal change. In this paper we introduce a novel account of belief change in which the agent's belief state is modified minimally to incorporate exactly the new information. Thus a revision by p ∧ q will result in a new belief state in which p ∧ q is believed, but a stronger proposition (such as p Λ q) is not, regardless of the initial form of the belief state.

#index 1279424
#* Extending DTGOLOG with options
#@ A. Ferrein;Ch. Fritz;G. Lakemeyer
#t 2003
#c 11
#% 286423
#% 363744
#% 529345

#index 1279425
#* Indirect and conditional sensing in the event calculus
#@ Jeremy Forth
#t 2003
#c 11
#% 90829
#! Controlling the sensing of an environment by an agent has been accepted as necessary for it's effective operation. Usually, however, agents operate in partially observable domains where not all parameters of interest are accessible for direct sensing. Sensing actions must then be chosen for what they will reveal indirectly, through an axiomatized model of the domain causal structure. This indirect form of sensing has received somewhat less attention in the literature. This article shows how sensing can be chosen so as to acquire and use indirectly obtained information to meet goals not otherwise possible. Event Calculus is extended with a knowledge formalism, and used to show how inferring unknown information about a domain leads to conditional sensing actions.

#index 1279426
#* Proactive dialogue for interactive knowledge capture
#@ Jihie Kim;Yolanda Gil
#t 2003
#c 11
#% 553942
#! Current tools for interactive knowledge capture have little or no learning aptitude. They are mostly oblivious to the process or strategy that the user may be following in entering new knowledge, unaware of their progress during a session, and ignorant of typical skills expected from a good student. We present an approach to make acquisition interfaces more proactive by extending them with: 1) goals that represent what remains to be learned, 2) strategies to achieve these goals and acquire further knowledge, and 3) awareness of the current status of the body of knowledge learned. The resulting interaction shows that the system is aware of its progress towards acquiring the new knowledge, and moves forward by understanding what acquisition goals and strategies to pursue.

#index 1279427
#* Coherence of laws
#@ Rex Kwok;Norman Y. Foo;Abhaya C. Nayak
#t 2003
#c 11
#% 520716
#! The core of scientific theories are laws. These laws often make use of theoretical terms, linguistic entities which do not directly refer to observables. There is therefore no direct way of determining which theoretical assertions are true. This suggests that multiple theories may exist which are incompatible with each other but compatible with all possible observations. Since such theories make the same empirical claims, empirical tests cannot be used to differentiate or rank such theories. One property that has been suggested for evaluating rival theories is coherence. This was only understood qualitatively until we [Kwok, et.al. 98] introduced a coherence measure based on the average use of formulas in support sets for observations. The idea was to identify highly coherent theories with those whose formulas that are tightly coupled to account for observations, while low coherence theories contain many disjointed and isolated statements. Our current approach generalizes that insight to accommodate fundamental ideas from the philosophy of science and better mirrors scientific practice. Moreover, this new approach is neutral with respect to the philosophy and practice of science, and is able to explain notions like modularization using coherence.

#index 1279428
#* An epistemic logic for arbitration
#@ Churn-Jung Liau
#t 2003
#c 11
#% 137868
#% 188086

#index 1279429
#* Constructing utility models from observed negotiation actions
#@ Angelo Restificar;Peter Haddawy
#t 2003
#c 11
#% 257048
#! We propose a novel method for constructing utility models by learning from observed negotiation actions. In particular, we show how offers and counter-offers in negotiation can be transformed into gamble questions providing the basis for eliciting utility functions. Results of experiments and evaluation are briefly described.

#index 1279430
#* Engineering a complex ontology with time
#@ Jorge Santos;Steffen Staab
#t 2003
#c 11
#% 310424
#% 514884
#% 529190
#% 572314

#index 1279431
#* A logic-based algorithm for image sequence interpretation and anchoring
#@ Paulo Santos;Murray Shanahan
#t 2003
#c 11
#% 529673
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279432
#* Learning consumer photo categories for semantic retrieval
#@ Joo-Hwee Lim;Jesse S. Jin
#t 2003
#c 11
#% 316199
#% 1855132
#! In this paper, we develop a computational learning framework to build a hierarchy of 11 consumer photo categories for semantic retrieval. Two levels of visual semantics are learned for image content and image category statistically. We evaluate the average precisions at top retrieved photos on 2400 heterogeneous consumer photos with very good result.

#index 1279433
#* Intelligent multimodal stream processing
#@ Mark Maybury
#t 2003
#c 11
#% 293974
#! This poster describes methods to enable intelligent access to multimodal information streams. We illustrate these methods in two integrated systems: the Broadcast News Editor (BNE) which incorporates image, speech, and language processing and the Broadcast News Navigator (BNN) which provides search, visualization and personalized access to broadcast news video. BNN enables users to perform keyword and named entity search, temporally and geospatially visualize entities and stories, cluster stories, discover entity relations, and obtain personalized multimedia summaries. By transforming access from sequential to direct search and providing hierarchical hyperlinked summaries, BNE and BNN enable users to access topics and entity news clusters nearly three times as fast as direct search of video.

#index 1279434
#* Collaborative web search
#@ Barry Smyth;Evelyn Balfe;Peter Briggs;Maurice Coyle;Jill Freyne
#t 2003
#c 11
#% 230432
#% 262084
#% 292151
#% 341964
#% 348173
#% 433674
#! Web search engines struggle to satisfy the needs of Web users. Users are notoriously poor at representing their needs in the form of a query, and search engines are poor at responding to vague queries. However progress has been made by introducing context into the search process. In this paper we describe and evaluate a novel approach to using context in Web search that adapts a generic search engine for the needs of a specialist community of users. This collaborative search method enjoys significant performance benefits and avoids the privacy and security concerns that are commonly associated with related personalization research.

#index 1279435
#* A statistical model for flexible string similarity
#@ Atsuhiro Takasu
#t 2003
#c 11
#% 438103
#% 627852
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279436
#* Mining video associations for efficient database management
#@ Xingquan Zhu;Xindong Wu
#t 2003
#c 11
#% 207198
#% 248865
#% 316709
#% 351784
#% 413596
#% 463903
#% 481290
#! To support more efficient video database management, this paper explores the concept of video association mining, with which the association patterns are characterized by sequentially associated video shots and their cluster information. Given a continuous video sequence V, the video shot segmentation mechanism is first introduced to parse it into discrete shots. We then cluster shots into visually distinct groups and construct a shot cluster sequence by using the class label of each shot. An association mining scheme is designed to mine sequentially associated clusters from the sequence. Those detected associations will convey valuable knowledge for video database management. The experimental results demonstrate the effectiveness of our design.

#index 1279437
#* A learning algorithm for localizing people based on wireless signal strength that uses labeled and unlabeled data
#@ Mary Berna;Brennan Sellner;Brad Lisien;Sebastian Thrun;Geoffrey Gordon;Frank Pfenning
#t 2003
#c 11
#% 311027
#% 337494
#! This paper summarizes a probabilistic approach for localizing people through the signal strengths of a wireless IEEE 802.1 lb network. Our approach uses data labeled by ground truth position to learn a probabilistic mapping from locations to wireless signals, represented by piecewise linear Gaussians. It then uses sequences of wireless signal data (without position labels) to acquire motion models of individual people, which further improves the localization accuracy. The approach has been implemented and evaluated in an office environment.

#index 1279438
#* Learning to compete in heterogeneous web search environments
#@ Rinat Khoussainov;Nicholas Kushmerick
#t 2003
#c 11
#% 194246
#% 527987
#% 1499474

#index 1279439
#* Approximate policy iteration using large-margin classifiers
#@ Michail G. Lagoudakis;Ronald Parr
#t 2003
#c 11
#% 393786
#% 466230
#% 565532
#% 722757
#% 1650413
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279440
#* Active learning with ensembles for image classification
#@ H. Liu;A. Mandvikar;P. Foschi;K. Torkkola
#t 2003
#c 11
#% 290482
#% 481290
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279441
#* Item selection strategies for collaborative filtering
#@ Rachael Rafter;Barry Smyth
#t 2003
#c 11
#% 173879
#% 220711
#% 280852
#% 345045
#% 1650569

#index 1279442
#* Modular self-organization for a long-living autonomous agent
#@ Bruno Scherrer
#t 2003
#c 11
#% 384911
#% 494216
#% 496684
#% 1650589
#% 1650672
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279443
#* Towards a theoretical framework for ensemble classification
#@ Alexander K. Seewald
#t 2003
#c 11
#% 132938
#% 209021
#% 464452
#% 464782
#% 549438
#% 1272397
#! Ensemble learning schemes such as AdaBoost and Bagging enhance the performance of a single classifier by combining predictions from multiple classifiers of the same type. The predictions from an ensemble of diverse classifiers can be combined in related ways, e.g. by voting or simply by selecting the best classifier via cross-validation - a technique widely used in machine learning. However, since no ensemble scheme is always the best choice, a deeper insight into the structure of meaningful approaches to combine predictions is needed to achieve further progress. In this paper we offer an operational reformulation of common ensemble learning schemes - Voting, Selection by Crossvalidation (X-Val), Grading and Bagging - as a Stacking scheme with appropriate parameter settings. Thus, from a theoretical point of view all these schemes can be reduced to Stacking with an appropriate combination method. This result is an important step towards a general theoretical framework for the field of ensemble learning.

#index 1279444
#* Multiple-goal reinforcement learning with modular Sarsa(O)
#@ Nathan Sprague;Dana Ballard
#t 2003
#c 11
#% 203602
#% 240248
#% 272665
#% 307102
#! We present a new algorithm, GM-Sarsa(O), for finding approximate solutions to multiple-goal reinforcement learning problems that are modeled as composite Markov decision processes. According to our formulation different sub-goals are modeled as MDPs that are coupled by the requirement that they share actions. Existing reinforcement learning algorithms address similar problem formulations by first finding optimal policies for the component MDPs, and then merging these into a policy for the composite task. The problem with such methods is that policies that are optimized separately may or may not perform well when they are merged into a composite solution. Instead of searching for optimal policies for the component MDPs in isolation, our approach finds good policies in the context of the composite task.

#index 1279445
#* Integrating background knowledge into text classification
#@ Sarah Zelikovitz;Haym Hirsh
#t 2003
#c 11
#% 169717
#% 248801
#% 252011
#% 304876
#% 311027
#% 342670
#% 466263
#% 466580
#% 466888
#% 490929
#! We present a description of three different algorithms that use background knowledge to improve text classifiers. One uses the background knowledge as an index into the set of training examples. The second method uses background knowledge to reexpress the training examples. The last method treats pieces of background knowledge as unlabeled examples, and actually classifies them. The choice of background knowledge affects each method's performance and we discuss which type of background knowledge is most useful for each specific method.

#index 1279446
#* Parametric distance metric learning with label information
#@ Zhihua Zhang;James T. Kwok;Dit-Yan Yeung
#t 2003
#c 11
#% 656804
#% 1010442
#! Distance-based methods in pattern recognition and machine learning have to rely on a similarity or dissimilarity measure between patterns in the input space. For many applications, Euclidean distance in the input space is not a good choice and hence more complicated distance metrics have to be used. In this paper, we propose a parametric method for metric learning based on class label information. We first define a dissimilarity measure that can be proved to be metric. It has the favorable property that between-class dissimilarity is always larger than within-class dissimilarity. We then perform parametric learning to find a regression mapping from the input space to a feature space, such that the dissimilarity between patterns in the input space is approximated by the Euclidean distance between points in the feature space. Parametric learning is performed using the iterative majorization algorithm. Experimental results on real-world benchmark data sets show that this approach is promising.

#index 1279447
#* Network meta-reasoning for information assurance in mobile agent systems
#@ Donovan Artz;Max Peysakhov;William Regli
#t 2003
#c 11
#% 334662
#% 437181
#% 557552

#index 1279448
#* Towards cooperative negotiation for decentralized resource allocation in autonomic computing systems
#@ Craig Boutilier;Rajarshi Das;Jeffrey O. Kephart;William E. Walsh
#t 2003
#c 11
#% 452359
#% 578692
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279449
#* A formalization of equilibria for multiagent planning
#@ Michael Bowling;Rune Jensen;Manuela Veloso
#t 2003
#c 11
#% 1271826

#index 1279450
#* Bidding marginal utility in simultaneous auctions
#@ Amy Greenwald
#t 2003
#c 11
#% 341923
#% 558918
#% 578793

#index 1279451
#* NoA: a normative agent architecture
#@ Martin J. Kollingbaum;Timothy J. Norman
#t 2003
#c 11
#% 214197
#% 271076
#% 378938
#! NoA is an agent architecture that supports the development of agents motivated by norms: obligations, permissions and prohibitions. Obligations motivate a normative agent to act: a motive to achieve a state of affairs or to perform some action. Prohibitions restrict an agent's behaviour, whereas permissions allow an agent to pursue certain activities. To test the architecture, NoA agents arc applied to automated business transaction scenarios where the correct execution of contracts is paramount to create a situation of trust.

#index 1279452
#* A heuristic model for concurrent bi-lateral negotiations in incomplete information settings
#@ Thuc Duong Nguyen;Nicholas R. Jennings
#t 2003
#c 11
#% 721233
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279453
#* Imitation learning of team-play in multiagent system based on hidden Markov modeling
#@ Itsuki Noda
#t 2003
#c 11
#% 246836
#% 272376
#% 303620
#% 313955
#! This paper addresses agents' intentions as building blocks of imitation learning that abstract local situations of the agent, and proposes a hierarchical hidden Markov model (HMM) to represent cooperative behaviors of teamworks. The key of the proposed model is introduction of gate probabilities that restrict transition among agents' intentions according to others' intentions. Using these probabilities, the framework can control transitions flexibly among basic behaviors in a cooperative behavior.

#index 1279454
#* Virtual world as interface for human-robot interaction
#@ Eric Normand;Sheila Tejada
#t 2003
#c 11
#% 352917
#! This article describes preliminary work on a research environment called Virtual Synergy to represent a shared virtual map of an area for multiple autonomous robots by modifying the GameBots 3D multi-agent system. The use of GameBots will allow multiple users to interact with robots and agents at different levels of adjustable or dynamic autonomy. By interacting with the robots as another team member, the users take on different roles to suit the situation: supervisor, peer, mechanic, teleoperator, and spectator.

#index 1279455
#* Learning algorithms for software agents in uncertain and untrusted market environments
#@ Thomas Tran;Robin Cohen
#t 2003
#c 11

#index 1279456
#* A multi-agent computational linguistic approach to speech recognition
#@ Michael Walsh;Robert Kelly;Gregory M. P. O'Hare;Julie Carson-Berndsen;Tarek Abu-Amer
#t 2003
#c 11
#% 317964
#% 355911
#% 357518
#! This paper illustrates how a multi-agent system implements and governs a computational linguistic model of phonology for syllable recognition. We describe how the Time Map model can be recast as a multi-agent architecture and discuss how constraint relaxation, output extrapolation, parse-tree pruning, clever task allocation, and distributed processing are all achieved in this new architcture.

#index 1279457
#* The knowledge required to interpret noun compounds
#@ James Fan;Ken Barker;Bruce Porter
#t 2003
#c 11
#% 341640
#% 341641
#% 708351
#% 740917
#% 756183
#% 757333
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279458
#* Improving word sense disambiguation in lexical chaining
#@ Michel Galley;Kathleen McKeown
#t 2003
#c 11
#% 268075
#% 817846
#! Previous algorithms to compute lexical chains suffer either from a lack of accuracy in word sense disambiguation (WSD) or from computational inefficiency. In this paper, we present a new linear-time algorithm for lexical chaining that adopts the assumption of one sense per discourse. Our results show an improvement over previous algorithms when evaluated on a WSD task.

#index 1279459
#* A revised algorithm for latent semantic analysis
#@ Xiangen Hu;Zhiqiang Cai;Max Louwerse;Andrew Olney;Phanni Penumatsa;Art Graesser
#t 2003
#c 11
#% 272325
#% 1837435
#! The intelligent tutoring system AutoTutor uses latent semantic analysis to evaluate student answers to the tutor's questions. By comparing a student's answer to a set of expected answers, the system determines how much information is covered and how to continue the tutorial. Despite the success of LSA in tutoring conversations, the system sometimes has difficulties determining at an early stage whether or not an expectation is covered. A new LSA algorithm significantly improves the precision of AutoTutor's natural language understanding and can be applied to other natural language understanding applications.

#index 1279460
#* Identifying synonyms among distributionally similar words
#@ Dekang Lin;Shaojun Zhao;Lijuan Qin;Ming Zhou
#t 2003
#c 11
#% 746885
#% 747738
#% 748465
#% 748691
#% 815915
#! There have been many proposals to compute similarities between words based on their distributions in contexts. However, these approaches do not distinguish between synonyms and antonyms. We present two methods for identifying synonyms among distributionally similar words.

#index 1279461
#* A logic prover for text processing
#@ Dan Moldovan;Christine Clark
#t 2003
#c 11
#% 45220
#% 145393
#% 815843
#% 815867
#% 816175
#! This paper demonstrates the applicability of automated reasoning to text processing, specifically to Question Answering. It is shown that the approach is feasible, effective, and scalable. A Logic Prover has been implemented and integrated into a state-of-the-art Question Answering System.

#index 1279462
#* Inducing criteria for lexicalization parts of speech using the Cyc KB
#@ Tom O'Hara;Michael Witbrock;Bjern Aldag;Stefano Bertolo;Nancy Salay;Jon Curtis;Kathy Panton
#t 2003
#c 11
#% 136350
#% 196896
#% 198055
#% 290482
#% 742091
#! We present an approach for learning part-of-speech distinctions by induction over the lexicon of the Cyc knowledge base. This produces good results (74.6%) using a decision tree that incorporates both semantic features and syntactic features. Accurate results (90.5%) are achieved for the special case of deciding whether lexical mappings should use count noun or mass noun headwords. Comparable results are also obtained using OpenCyc, the publicly available version of Cyc.

#index 1279463
#* Neural executive attentional control in robots
#@ Jason Garforth;Sue Mcliale;Anthony Meehan
#t 2003
#c 11
#% 281065
#% 297157
#! We have developed a robot controller based upon a neural implementation of Norman and Shallice's model of executive attentional control in humans. A simulation illustrates how attentional control leads to the suppression of action selection errors in neurally controlled robots. A related demonstration illustrates how lesioning of the control architecture leads to behavioural pathologies that resemble those seen in human patients with damage to the prefrontal cortex.

#index 1279464
#* Boosting face identification in airports
#@ Liu Jiang Jimmy;Kia-Fock Loe
#t 2003
#c 11
#% 276506
#% 312727
#% 331916
#% 565543
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279465
#* Action selection for single- and multi-robot tasks using cooperative extended Kohonen maps
#@ Kian Hsiang Low;Wee Kheng Leow;Marcelo H. Ang
#t 2003
#c 11
#% 378931
#! This paper presents an action selection framework based on an assemblage of self-organizing neural networks called Cooperative Extended Kohonen Maps. This framework encapsulates two features that significantly enhance a robot's action selection capability: self-organization in the continuous state and action spaces to provide smooth, efficient and fine motion control; action selection via the cooperation and competition of Extended Kohonen Maps to achieve more complex motion tasks. Qualitative and quantitative comparisons for single- and multi-robot tasks show our framework can provide better action selection than do potential fields method.

#index 1279466
#* Artificial neural network for sequence learning
#@ Sorin Moga;Philippe Gaussier
#t 2003
#c 11
#% 169108
#% 1784515
#! This poster shows an artificial neural network capable of learning a temporal sequence. Directly inspired from a hippocampus model [Banquet et al, 1998], this architecture allows an autonomous robot to learn how to imitate a sequence of movements with the correct timing.

#index 1279467
#* Comparison of different grid abstractions for pathfinding on maps
#@ Yngvi Bjornsson;Markus Enzenberger;Robert Holte;Jonathan Schaejfer;Peter Yap
#t 2003
#c 11
#% 443807
#% 534450
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279468
#* Multiagent planning with partially ordered temporal plans
#@ Michael Brenner
#t 2003
#c 11
#% 107137
#% 224480
#% 398248
#% 431523
#% 1271962
#! This paper discusses the specifics of planning in multiagent environments. It presents the formal framework MAPL ("maple") for describing multiagent planning domains. MAPL allows to describe both qualitative and quantitative temporal relations among events, thus subsuming the temporal models of both PDDL 2.1 and POP. Other features are different levels of control over actions, modeling of agents' ignorance of facts, and plan synchronization with communicative actions. For single-agent planning in multi-agent domains, we present a novel forward-search algorithm synthesizing MAPL's partially ordered temporal plans. Finally, we present a general distributed algorithm scheme for solving MAPL problems with several coordinating planners. These different contributions are intended as as step towards a simple, yet expressive standard for the description of multiagent planning domains and algorithms. Such a standard could in the future allow cross-evaluation of Multi-agent Planning algorithms on standardized benchmarks.

#index 1279469
#* Recognizing plan/goal abandonment
#@ Christopher W. Geib;Robert P. Goldman
#t 2003
#c 11
#% 101231
#% 527832
#% 1650293
#! The ability to recognize when an agent abandons a plan is an open problem in the plan recognition literature and is a significant problem if these methods are to be applied in real systems. This paper presents an explicit, formal, and implemented solution to the problem of recognizing when an agent has abandoned one of its goals based on a theory of probabilistic model revision.

#index 1279470
#* Automated generation of understandable contingency plans
#@ Max Horstmann;Shlomo Zilberstein
#t 2003
#c 11
#% 337981
#% 578724
#% 1272331
#% 1650355
#! Markov Decision Processes (MDPs) and contingency planning (CP) are two widely used approaches to planning under uncertainty. MDPs are attractive because the model is extremely general and because many algorithms exist for deriving optimal plans. In contrast, CP is normally performed using heuristic techniques that do not guarantee optimality, but the resulting plans are more compact and more understandable. The inability to present MDP policies in a clear, intuitive way has limited their applicability in some important domains. We introduce an anytime algorithm for deriving contingency plans that combines the advantages of the two approaches.

#index 1279471
#* A planning algorithm for predictive state representations
#@ Masoumeh T. Izadi;Doina Precup
#t 2003
#c 11
#% 179940
#% 703709
#% 1290039
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279472
#* Parallelizing state space plans online
#@ Romeo Sanchez Nigenda;Subbarao Kambhampati
#t 2003
#c 11
#% 224480
#% 345431
#% 1476298
#! Searching for parallel solutions in state space planners is a challenging problem, because it would require the planners to branch on all possible subsets of parallel actions, exponentially increasing their branching factor. We introduce a variant of our heuristic state search planner AltAlt, which generates parallel plans by using greedy online parallelization of partial plans. Empirical results show that our online approach outperforms post-processing (offline) techniques in terms of the quality of the solutions returned.

#index 1279473
#* A lookahead strategy for solving large planning problems
#@ Vincent Vidal
#t 2003
#c 11
#% 224480
#% 1271962
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279474
#* Using available memory to transform Graphplan's search
#@ Terry Zimmerman;Subbarao Kambhampati
#t 2003
#c 11
#% 224480
#% 283223
#% 529525
#% 544930
#! We present a major variant of the Graphplan algorithm that employs available memory to transform the depth-first nature of Graphplan's search into an iterative state space view in which heuristics can be used to traverse the search space. When the planner, PEGG, is set to conduct exhaustive search, it produces guaranteed optimal parallel plans 2 to 90 times faster than a version of Graphplan enhanced with CSP speedup methods. By heuristically pruning this search space PEGG produces plans comparable to Graphplan's in makespan, at speeds approaching state-of-the-art heuristic serial planners.

#index 1279475
#* Lookahead pathologies for single agent search
#@ Vadim Bulitko;Lihong Li;Russ Greiner;Ilya Levner
#t 2003
#c 11
#% 2194
#% 20950
#% 68238
#% 98073
#% 181627
#% 451046
#% 477285
#% 605676
#% 692887
#% 1476299
#! Admissible and consistent heuristic functions are usually preferred in single-agent heuristic search as they guarantee optimal solutions with complete search methods such as A* and IDA*. Larger problems, however, frequently make a complete search intractable due to space and/or time limitations. In particular, a path-planning agent in a real-time strategy game may need to take an action before its complete search has the time to finish. In such cases, incomplete search techniques (such as RTA*, SRTA*, RTDP, DTA*) can be used. Such algorithms conduct a limited ply lookahead and then evaluate the states envisioned using a heuristic function. The action selected on the basis of such evaluations can be suboptimal due to the incompleteness of search and inaccuracies in the heuristic. It is usually believed that deeper lookahead increases the chances of taking the optimal action. In this paper, we demonstrate that this is not necessarily the case, even when admissible and consistent heuristic functions are used.

#index 1279476
#* Real-time strategy gaines: a new AI research challenge
#@ Michael Buro
#t 2003
#c 11
#% 438443
#% 445551
#! This poster motivates AI research in the area of real-time strategy (RTS) games and describes the current status of a project whose goals are to implement an RTS game programming environment and to build AIs that eventually can outperform human experts in this challenging and popular domain.

#index 1279477
#* Multiple agents moving target search
#@ Mark Goldenberg;Alexander Kovarsky;Xiaomeng Wu;Jonathan Schaeffer
#t 2003
#c 11
#% 68238
#% 443874
#% 578727
#% 1290111
#! Traditional single-agent search algorithms usually make simplifying assumptions (single search agent, stationary target, complete knowledge of the state, and sufficient time). There are algorithms for relaxing one or two of these constraints; in this paper we want to relax all four. The application domain is to have multiple search agents cooperate to pursue and capture a moving target. Agents are allowed to communicate with each other. For solving Multiple Agents Moving Target (MAMT) applications, we present a framework for specifying a family of suitable search algorithms. This paper investigates several effective approaches for solving problem instances in this domain.

#index 1279478
#* Delayed duplicate detection: extended abstract
#@ Richard E. Korf
#t 2003
#c 11
#% 2194
#% 121359
#% 387508
#% 496261
#% 529516
#! Best-first search is limited by the memory needed to store nodes in order to detect duplicates. Disks can greatly expand the amount of storage available, but randomly accessing a disk is impractical. Rather than checking newly-generated nodes as soon as they are generated, we append them to a disk file, then sort the file, and finally scan the sorted file in one pass to detect and remove duplicate nodes. This also speeds up such searches that fit entirely in memory, by improving cache performance. We implement this idea for breadth-first search, performing the first complete searches of the 2×7 sliding-tile puzzle, and the 18-disk, 4-peg Towers of Hanoi puzzle.

#index 1279479
#* A portfolio approach to algorithm select
#@ Kevin Leyton-Brown;Eugene Nudelman;Galen Andrew;Jim McFadden;Yoav Shoham
#t 2003
#c 11
#% 73372
#% 314925
#% 329487
#% 466598
#% 496094
#% 528307
#% 535163

#index 1279480
#* A new node Centroid algorithm for bandwidth minimization
#@ Andrew Lim;Brian Rodrigues;Fei Xiao
#t 2003
#c 11
#% 602040
#! We propose a Node Centroid method with Hill-Climbing to solve the well-known matrix bandwidth minimization problem, which is to permute rows and columns of the matrix to minimize its bandwidth. Many heuristics have been developed for this NP-complete problem including the Cuthill-McKee (CM) and the Gibbs, Poole and Stockmeyer (GPS) algorithms. Recently, heuristics such as Simulated Annealing, Tabu Search and GRASP have been used, where Tabu Search and the GRASP with Path Relinking have achieved significantly better solution quality than the CM and GPS algorithms. Experimentation shows that the Node Centroid method achieves the best solution quality when compared with these while being much faster than the newly-developed algorithms.

#index 1279481
#* Combining two local search approaches to hypergraph partitioning
#@ Arathi Ramani;Igor Markov
#t 2003
#c 11
#% 160270
#% 239588
#% 247169
#% 605157
#% 1478771
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279482
#* A new content based image retrieval method based on a sketch-driven interpretation of line segments
#@ Marco Anelli;Alessandro Micarelli;Enver Sangineto
#t 2003
#c 11
#% 391298
#! We present a new method for image retrieval by shape similarity able to deal with real images with not uniform background and possible touching/ occluding objects. First of all we perform a sketch-driven segmentation of the scene by means of a Deformation Tolerant version of the Generalized Hough Transform (DTGHT). Using the DTGHT we select in the image some candidate segments to be matched with the user sketch. The candidate segments are then matched with the sketch checking the consistency of the corresponding shapes.

#index 1279483
#* Towards pervasive robotics
#@ Artur M. Arsenio
#t 2003
#c 11
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279484
#* A visual-sensor model for mobile robot localisation
#@ Matthias Fichtner;Axel Grofimann
#t 2003
#c 11
#% 344594

#index 1279485
#* Improving speech recognition on a mobile robot platform through the use of top-down visual queues
#@ Robert J. Ross;R. P. S. O'Donoghue;G. M. P. O'Hare
#t 2003
#c 11
#% 283225
#% 529528
#% 711814
#% 1775138
#! In many real-world environments, Automatic Speech Recognition (ASR) technologies fail to provide adequate performance for applications such as human robot dialog. Despite substantial evidence that speech recognition in humans is performed in a top-down as well as bottom-up manner, ASR systems typically fail to capitalize on this, instead relying on a purely statistical, bottom up methodology. In this paper we advocate the use of a knowledge based approach to improving ASR in domains such as mobile robotics. A simple implementation is presented, which uses the visual recognition of objects in a robot's environment to increase the probability that words and sentences related to these objects will be recognized.

#index 1279486
#* Comparing image-based localization methods
#@ Robert Sim;Gregory Dudek
#t 2003
#c 11
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279487
#* Quantum computation and image processing: new trends in artificial intelligence
#@ S. E. Venegas-Andraca;S. Bose
#t 2003
#c 11
#% 378462
#% 392851
#% 1081278
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279488
#* Corpus-based knowledge representation
#@ Alon Y. Halevy;Jayant Madhavan
#t 2003
#c 11
#% 127670
#% 179974
#% 266237
#% 330616
#% 333990
#% 348163
#% 348187
#% 378409
#% 397351
#% 397379
#% 428249
#% 480645
#% 509695
#% 572311
#% 572314
#% 578668
#% 578767
#% 993982
#% 1478822
#! A corpus-based knowledge representation system consists of a large collection of disparate knowledge fragments or schemas, and a rich set of statistics computed over the corpus. We argue that by collecting such a corpus and computing the appropriate statistics, corpus-based representation offers an alternative to traditional knowledge representation for a broad class of applications. The key advantage of corpus-based representation is that we avoid the laborious process of building a (often brittle) knowledge base. We describe the basic building blocks of a corpus-based representation system and a set of applications for which such a paradigm is appropriate, including one application where the approach is already showing promising results.

#index 1279489
#* Challenges in web search engines
#@ Monika R. Henzinger;Rajeev Motwani;Craig Silverstein
#t 2003
#c 11
#% 201935
#% 248809
#% 268079
#% 281214
#% 282905
#% 296646
#% 300176
#% 319876
#% 330676
#% 340919
#% 340928
#% 446932
#% 590524
#% 616528
#! This article presents a high-level discussion of some problems that are unique to web search engines. The goal is to raise awareness and stimulate research in these areas.

#index 1279490
#* Deploying information agents on the web
#@ Craig A. Knoblock
#t 2003
#c 11
#% 159113
#% 229828
#% 241037
#% 266102
#% 275915
#% 312858
#% 312863
#% 314740
#% 350103
#% 398263
#% 400440
#% 424302
#% 431536
#% 445444
#% 461618
#% 480824
#% 519432
#% 529191
#% 531452
#% 570880
#% 577238
#% 577247
#% 578783
#% 705442
#% 707146
#% 720479
#% 732227
#% 1271981
#% 1272382
#% 1279273
#% 1476317
#! The information resources on the Web are vast, but much of the Web is based on a browsing paradigm that requires someone to actively seek information. Instead, one would like to have information agents that continuously attend to one's personal information needs. Such agents need to be able to extract the relevant information from web sources, integrate data across sites, and execute efficiently in a networked environment. In this paper I describe the technologies we have developed to rapidly construct and deploy information agents on the Web. This includes wrapper learning to convert online sources into agent-friendly resources, query planning and record linkage to integrate data across different sites, and streaming dataflow execution to efficiently execute agent plans. I also describe how we applied this work within the Electric Elves project to deploy a set of agents for continuous monitoring of travel itineraries.

#index 1279491
#* Constraint satisfaction, databases, and logic
#@ Phokion G. Kolaitis
#t 2003
#c 11
#% 36683
#% 39265
#% 55926
#% 115329
#% 150115
#% 150197
#% 190340
#% 237054
#% 251197
#% 252213
#% 288946
#% 289947
#% 321058
#% 408396
#% 460791
#% 529338
#% 535150
#% 587604
#% 599549
#% 600496
#% 927017

#index 1279492
#* Web intelligence (WI): what makes wisdom web?
#@ Jiming Liu
#t 2003
#c 11
#% 241382
#% 341071
#% 345044
#% 349152
#% 433988
#% 438669
#% 438670
#% 482338
#% 483345
#% 579442
#% 744790
#% 766057
#! Web Intelligence (WI) sheds new light on directions for scientific research and development which explores the fundamental roles as well as practical impacts of Artificial Intelligence (AI) and advanced Information Technology (IT) on the next generation of Web-empowered products, systems, services, and activities. This paper gives new perspectives on the future WI research and highlights some of the research challenges and initiatives.

#index 1279493
#* Self-reconfiguring robots: successes and challenges
#@ Daniela Rus
#t 2003
#c 11
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279494
#* Automated verification: graphs, logic, and automata
#@ Moshe Y. Vardi
#t 2003
#c 11
#% 2991
#% 131357
#% 145228
#% 158068
#% 172932
#% 175122
#% 215675
#% 218112
#% 234819
#% 239406
#% 278488
#% 285967
#% 296170
#% 297770
#% 417597
#% 502751
#% 502889
#% 529740
#% 543359
#% 544938
#% 1068329
#% 1271828
#! Automated verification is one of the most successful applications of automated reasoning in computer science. In automated verification one uses algorithmic techniques to establish the correctness of the design with respect to a given property. Automated verification is based on a small number of key algorithmic ideas, tying together graph theory, automata theory, and logic. In this self-contained talk I will describe how this "holy trinity" gave rise to automated-verification tools, and mention some applications to planning.

#index 1279495
#* Automated reasoning: past story and new trends
#@ Andrei Voronkov
#t 2003
#c 11
#% 212204
#% 288366
#% 289443
#% 318185
#% 360463
#% 420630
#% 420631
#% 420636
#% 420643
#% 420648
#% 420762
#% 472395
#% 495957
#% 505471
#% 559340
#% 560570
#% 560750
#% 560931
#% 561548
#% 561561
#% 561575
#% 561576
#% 569100
#% 579729
#% 579731
#% 585627
#% 653688
#% 653695
#% 717201
#% 938538
#! We overview the development of first-order automated reasoning systems starting from their early years. Based on the analysis of current and potential applications of such systems, we also try to predict new trends in first-order automated reasoning. Our presentation will be centered around two main motives: efficiency and usefulness for existing and future potential applications.

#index 1279496
#* Automatically personalizing user interfaces
#@ Daniel S. Weld;Corin Anderson;Pedro Domingos;Oren Etzioni;Krzysztof Gajos;Tessa Lau;Steve Wolfman
#t 2003
#c 11
#% 96282
#% 150994
#% 152191
#% 159113
#% 224758
#% 260105
#% 272793
#% 312874
#% 320689
#% 320869
#% 338308
#% 343122
#% 402090
#% 428249
#% 428254
#% 440571
#% 466590
#% 491105
#% 496116
#% 1279354
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279497
#* Intelligent systems in travel and tourism
#@ Hannes Werthner
#t 2003
#c 11
#% 312860
#% 545713
#! Travel and tourism is the leading application field in the b2c e-commerce, it represents nearly 50% of the total b2c turnover. Already in the past travel applications were at the forefront of Information Technology, i.e., the airline Computerized Reservation Systems in the early 60s. The industry and its product have rather specific features which explain this circumstance: the product is a confidence good, consumer decisions are solely based on information beforehand; and the industry is highly networked, based on world-wide cooperation of very different types of stakeholders. Consequently, this industry depends on advanced IT applications. As such travel and tourism may serve as an example of what happens and will happen in the emerging e-markets, pointing at structural changes as well as challenging application scenarios. The paper provides an overview about the industry, describes ongoing structural changes, outlines domain-specific requirements and discusses achievements and challenges in the field, following an AI and e-commerce point of view. It finishes with considerations regarding a future IT scenario.

#index 1279498
#* Writer's Aid: using a planner in a collaborative interface
#@ Tamara Babaian;Barbara J. Grosz;Stuart M. Shieber
#t 2003
#c 11
#% 312871
#% 342752
#% 531452
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279499
#* Sensible agent technology improving coordination and communication in biosurveillance domains
#@ K. S. Barber;D. Faith;K. Fuilam;T. Graser;D. C. Han;J. Jeong;J. Kim;D. Lam;R. McKay;M. Pal;J. Park;M. Vanzin
#t 2003
#c 11
#% 334234
#% 334629

#index 1279500
#* GSTP: a temporal reasoning system supporting multi-granularity temporal constraints
#@ Claudio Bettini;Sergio Mascetti;Vincenzo Pupiilo
#t 2003
#c 11
#% 1145
#% 107137
#% 160389
#% 225003
#% 417598
#% 428360

#index 1279501
#* Comparing different cognitive paradigms with a virtual laboratory
#@ Carlos Gershenson
#t 2003
#c 11
#! A public virtual laboratory is presented, where animats are controlled by mechanisms from different cognitive paradigms. A brief description of the characteristics of the laboratory and the uses it has had is given. Mainly, it has been used to contrast philosophical ideas related with the notion of cognition, and to elucidate debates on "proper" paradigms in AI and cognitive science.

#index 1279502
#* Towards domain-independent, task-oriented, conversational adequacy
#@ Darsana P. Josyula;Michael L. Anderson;Don Perlis
#t 2003
#c 11
#% 80631
#% 264439

#index 1279503
#* Broadcast news navigator (BNN) demonstration
#@ Mark Maybury
#t 2003
#c 11
#% 293974
#% 815336
#! The Broadcast News Navigator (BNN) is a fully implemented system that incorporates image, speech, and language processing together with visualization and user preference modeling to support intelligent, personalized access to broadcast news video. The demonstration will illustrate the use of the system's underlying machine learning enabled story segmentation and processing, called the Broadcast News Editor (BNE). A live, scenario-based demonstration will illustrate the use of named entity search, temporal visualization of entities, story clustering and geospatial story visualization, discovery of entity relations, and personalized multimedia summary generation. By transforming access from sequential to direct search and providing hierarchical hyperlinked summaries, we will demonstrate how users can access topics and entity specific news clusters nearly three times as fast as direct search of digital video. In short, we will demonstrate intelligent news on demand enabled by a suite of AI technologies.

#index 1279504
#* Demonstration: liaison agents for distributed space operations
#@ D. Schreckenghost;P. Bonasso;D. Kortenkamp;C. Martin;T. Milam;C. Thronesbery
#t 2003
#c 11
#% 445527
#% 445564
#% 579927
#! Future manned space operations are expected to include a greater use of automation [Cooke and Hine, 2002] This automation will function without human intervention most of the time. However, humans will be required to supervise the automation, and they must be on-call to respond to anomalies or to perform related tasks that are not easily automated. In such an environment, humans perform other tasks most of the time, and their interaction with the automation may be remote and asynchronous. As automation becomes more prevalent, better support for such interaction is needed. The Distributed Collaboration and Interaction (DCI) environment, being developed at NASA, investigates the use of software agents to assist humans in this type of remote, distributed space operations. The DCI approach has been applied for use by control engineers at the Johnson Space Center (JSC) who are investigating advanced technology for life support such as the water recovery system, or WRS [Schreckenghost, et al, 2002]. The WRS recycles wastewater through biological and chemical processes to remove impurities and produce potable water. Managed by an autonomous control program called 3T [Bonasso, et al, 1997], the WRS ran unattended in a continuous 24/7 integrated test from January 2001 through April 2002 [Bonasso, et al., 2002]. WRS control engineers periodically monitored for network, hardware, or power failures from remote locations, while spending the majority of their time carrying out their daily tasks on unrelated projects. The current prototype of the DCI environment uses a simulation of the WRS 3T system for both demonstration and continuing development. The DCI implementation creates an environment in which humans and the 3T control automation together form an integrated team to ensure efficient, effective operation of the WRS.

#index 1279505
#* Interactive spoken simulation control and conversational tutoring
#@ Karl Schultz;Brady Clark;Elizabeth Owen Bratt;Stanley Peters;Heather Pon-Barry;Pucktada Treeratpituk;Zack Thomsen-Gray;David C. Willdns;David M. Fried;Eugene Grois
#t 2003
#c 11
#% 398947
#% 817918

#index 1279506
#* TAGA: travel market framework in Agentcities
#@ Youyong Zou;Tim Finin;Li Ding;Harry Chen;Rong Pan
#t 2003
#c 11
#% 331379
#% 519432
#% 578793
#! Speculative execution of information gathering plans can dramatically reduce the effect of source I/O latencies on overall performance. However, the utility of speculation is closely tied to how accurately data values are predicted at runtime. Caching ...

#index 1279507
#* Making markets and democracy work: a story of incentives and computing
#@ Thomas Sandholm
#t 2003
#c 11
#% 82813
#% 267752
#% 282989
#% 283035
#% 302061
#% 306530
#% 314918
#% 314919
#% 314920
#% 314925
#% 314944
#% 314946
#% 341943
#% 344879
#% 378898
#% 378910
#% 379486
#% 413867
#% 420435
#% 431519
#% 431523
#% 452545
#% 496094
#% 496250
#% 529336
#% 529496
#% 529651
#% 529664
#% 558907
#% 558908
#% 566719
#% 571115
#% 578703
#% 578707
#% 578710
#% 578711
#% 578713
#% 578715
#% 580533
#% 580554
#% 580557
#% 631051
#% 635936
#% 636336
#% 643113
#% 643243
#% 659840
#% 659849
#% 659857
#% 659864
#% 704123
#% 781210
#% 912341
#% 1013352
#% 1275317
#% 1279324
#% 1289299
#% 1289305
#% 1289313
#% 1385383
#% 1650358
#! Collective choice settings are the heart of society. Game theory provides a basis for engineering the incentives into the interaction mechanism (e.g., rules of an election or auction) so that a desirable system-wide outcome (e.g., president, resource allocation, or task allocation) is chosen even though every agent acts based on self-interest. However, there are a host of computer science issues not traditionally addressed in game theory that have to be addressed in order to make mechanisms work in the real world. Those computing, communication, and privacy issues are deeply intertwined with the economic incentive issues. For example, the fact that agents have limited computational capabilities to determine their own (and others') preferences ruins the incentive properties of established auction mechanisms, and gives rise to new issues. On the positive side, computational complexity can be used as a barrier to strategic behavior in settings where economic mechanism design falls short. Novel computational approaches also enable new economic institutions. For example, market clearing technology with specialized search algorithms is enabling a form of interaction that I call expressive competition. As another example, selective incremental preference elicitation can determine the optimal outcome while requiring the agents to determine and reveal only a small portion of their preferences. Furthermore, automated mechanism design can yield better mechanisms than the best known to date.

#index 1289147
#* Proceedings of the 17th international joint conference on Artificial intelligence - Volume 1
#@ 
#t 2001
#c 11

#index 1289148
#* A logical account of causal and topological maps
#@ Emilio Remolina;Benjamin Kuipers
#t 2001
#c 11
#% 108
#% 36780
#% 167541
#% 181628
#% 184795
#% 303954
#% 499512
#% 679455
#% 1476284
#% 1478753
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this paper we take the Spatial Semantic Hierarchy as the agent's target spatial representation, and use a circumscriptive theory to specify the minimal models associated with this representation. We provide a logic program to calculate the models of the proposed theory. We also illustrate how the different levels of the representation assume different spatial properties about both the environment and the actions performed by the agent. These spatial properties play the role of "filters" the agent applies in order to distinguish the different environment states it has visited.

#index 1289149
#* On-line execution of cc-Golog plans
#@ Henrik Grosskreutz;Gerhard Lakemeyer
#t 2001
#c 11
#% 245664
#% 314845
#% 495950
#% 529354
#% 539639
#! Previously, the plan language cc-Golog was introduced for the purpose of specifying event-driven behavior typically found in robot controllers. So far, however, cc-Golog is usable only for projecting the outcome of a plan and it is unclear how to actually execute plans on-line on a robot. In this paper, we provide such an execution model for cc-Golog and, in addition, show how to interleave execution with a new kind of time-bounded projection. Along the way we also demonstrate how a typical robot control architecture where a high-level controller communicates with low-level processes via messages can be directly modelled in cc-Golog.

#index 1289150
#* An on-line decision-theoretic Golog interpreter
#@ Mikhail Soutchanski
#t 2001
#c 11
#% 284106
#% 290714
#% 301094
#% 495950
#% 1290146
#% 1476290
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289151
#* Causes and explanations: a structural-model approach-part II: explanations
#@ Joseph Y. Halpern;Judea Pearl
#t 2001
#c 11
#% 243717
#% 297171
#% 370075
#% 564806
#% 1650703
#! We propose a new definition of (causal) explanation, using structural equations to model counterfactuals. The definition is based on the notion of actual cause, as defined and motivated in a companion paper. Essentially, an explanation is a fact that is not known for certain but, if found to be true, would constitute an actual cause of the fact to be explained, regardless of the agent's initial uncertainty. We show that the definition handles well a number of problematic examples from the literature.

#index 1289152
#* Complexity results for structure-based causality
#@ Thomas Eiter;Thomas Lukasiewicz
#t 2001
#c 11
#% 103725
#% 160190
#% 205391
#% 243717
#% 289948
#% 297171
#% 366370
#% 496256
#% 1271819
#% 1289151
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289153
#* Ambiguity-directed sampling for qualitative analysis of sparse data from spatially-distributed physical systems
#@ Chris Bailey-Kellogg;Naren Ramakrishnan
#t 2001
#c 11
#% 164368
#% 173235
#% 243703
#% 283151
#% 469555
#% 529503
#% 592143
#% 722755
#% 1272294
#% 1499542
#! A number of important scientific and engineering applications, such as fluid dynamics simulation and aircraft design, require analysis of spatially-distributed data from expensive experiments and complex simulations. In such data-scarce applications, it is advantageous to use models of given sparse data to identify promising regions for additional data collection. This paper presents a principled mechanism for applying domain-specific knowledge to design focused sampling strategies. In particular, our approach uses ambiguities identified in a multi-level qualitative analysis of sparse data to guide iterative data collection. Two case studies demonstrate that this approach leads to highly effective sampling decisions that are also explainable in terms of problem structures and domain knowledge.

#index 1289154
#* A spatial odyssey of the interval algebra: 1. directed intervals
#@ Jochen Renz
#t 2001
#c 11
#% 158920
#% 181229
#% 267770
#% 270714
#% 319244
#% 417552
#! Allen's well-known Interval Algebra has been developed for temporal representation and reasoning, but there are also interesting spatial applications where intervals can be used. A prototypical example are traffic scenarios where cars and their regions of influence can be represented as intervals on a road as the underlying line. There are several differences of temporal and spatial intervals which have to be considered when developing a spatial interval algebra. In this paper we analyze the first important difference: as opposed to temporal intervals, spatial intervals can have an intrinsic direction with respect to the underlying line. We develop an algebra for qualitative spatial representation and reasoning about directed intervals, identify tractable subsets, and show that path-consistency is sufficient for deciding consistency for a particular subset which contains all base relations.

#index 1289155
#* From images to bodies: modelling and exploiting spatial occlusion and motion parallax
#@ David Randell;Mark Witkowski;Murray Shanahan
#t 2001
#c 11
#% 89749
#% 98395
#% 184523
#% 210842
#% 539600
#! This paper describes the Region Occlusion Calculus (ROC-20), that can be used to model spatial occlusion and the effects of motion parallax of arbitrary shaped objects. ROC-20 assumes the region based ontology of RCC-8 and extends Galton's Lines of Sight Calculus by allowing concave shaped objects into the modelled domain. This extension is used to describe the effects of mutually occluding bodies. The inclusion of van Benthem's axiomatisation of comparative nearness facilitates reasoning about relative distances between occluding bodies. Further, an envisionment table is developed to model sequences of occlusion events enabling reasoning about objects and their images formed in a changing visual field.

#index 1289156
#* Qualitative simulation of genetic regulatory networks: method and application
#@ Hidde De Jong;Michel Page;Cane Hernandez;Johannes Geiselmann
#t 2001
#c 11
#% 1116
#! Computer modeling and simulation are indispensable for understanding the functioning of an organism on a molecular level. We present an implemented method for the qualitative simulation of large and complex genetic regulatory networks. The method allows a broad range of regulatory interactions between genes to be represented and has been applied to the analysis of a real network of biological interest, the network controlling the inititation of sporulation in the bacterium B. subtilis.

#index 1289157
#* Discrimination of semi-quantitative models by experiment selection: method and application in population biology
#@ Ivayla Vatcheva;Olivier Bernard;Hidde De Jong;Jean-Luc Gouza;Nicolaas J. I. Mars
#t 2001
#c 11
#% 95580
#% 243703
#% 496404
#! Modeling an experimental system often results in a number of alternative models that are justified equally well by the experimental data. In order to discriminate between these models, additional experiments are needed. We present a method for the discrimination of models in the form of semiquantitative differential equations. The method is a generalization of previous work in model discrimination. It is based on an entropy criterion for the selection of the most informative experiment which can handle cases where the models predict multiple qualitative behaviors. The applicability of the method is demonstrated on a real-life example, the discrimination of a set of competing models of the growth of phytoplankton in a bioreactor.

#index 1289158
#* A complete classification of complexity in Allen's algebra in the presence of a non-trivial basic relation
#@ Andrei Krokhin;Peter Jeavons;Peter Jonsson
#t 2001
#c 11
#% 82720
#% 101015
#% 121993
#% 152555
#% 158920
#% 181229
#% 207779
#% 216976
#% 231751
#% 267770
#% 312121
#% 319244
#% 408396
#% 419928
#% 1272313
#! We study fragments of Allen's algebra that contain a basic relation distinct from the equality relation. We prove that such a fragment is either NP-complete or else contained in some already known tractable subalgebra. We obtain this result by giving a new uniform description of known maximal tractable subalgebras and then systematically using an algebraic technique for description of maximal subalgebras with a given property. This approach avoids the need for extensive computerassisted search.

#index 1289159
#* Interval-based temporal reasoning with general TBoxes
#@ Carsten Lutz
#t 2001
#c 11
#% 6246
#% 70391
#% 264856
#% 319244
#% 561700
#% 671276
#% 1272342
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289160
#* On the semantics of knowledge update
#@ Chitta Baral;Yan Zhang
#t 2001
#c 11
#% 188086
#% 305422
#% 322911
#% 1272323
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289161
#* Resource-bounded inference from inconsistent belief bases
#@ Pierre Marquis;Nadège Porquet
#t 2001
#c 11
#% 57927
#% 100134
#% 184793
#% 204396
#% 207484
#% 266113
#% 417601
#% 420659
#% 496096
#% 1290085
#! A family of resource-bounded paraconsistent inference relations is introduced. These relations are based on S -- 3 entailment, an inference relation logically weaker than classical entailment and parametrized by a set S of variables. Their properties are investigated, especially from the computational complexity point of view. Among the strong features of our framework is the fact that tractability is ensured each time |S| is bounded and that binary connectives behave in a classical manner. Moreover, our family is large enough to include both S -- 3 inference, the standard inference relations based on the selection of consistent subbases and some additional forms of paraconsistent reasoning as specific cases.

#index 1289162
#* Weakening conflicting information for iterated revision and knowledge integration
#@ Salem Benferhat;Souhila Kaci;Daniel Le Berre;Mary-Anne Williams
#t 2001
#c 11
#% 167544
#% 521221
#% 661262
#! The ability to handle exceptions, to perform iterated belief revision and to integrate information from multiple sources are essential skills for an intelligent agent. These important skills are related in the sense that they all rely on resolving inconsistent information. We develop a novel and useful strategy for conflict resolution, and compare and contrast it with existing strategies. Ideally the process of conflict resolution should conform with the principle of Minimal Change and should result in the minimal loss of information. Our approach to minimizing the loss of information is to weaken information involved in conflicts rather than completely removing it. We implemented and tested the relative performance of our new strategy in three different ways. We show that it retains more information than the existing Maxi-Adjustment strategy at no extra computational cost. Surprisingly, we are able to demonstrate that it provides a computationally effective compilation of the lexicographical strategy, a strategy which is known to have desirable theoretical properties.

#index 1289163
#* Updates, actions, and planning
#@ Andreas Herzig;Jérôme Lang;Pierre Marquis;Thomas Polacsek
#t 2001
#c 11
#% 109945
#% 266241
#% 291003
#% 303950
#% 495764
#% 503813
#% 529665
#% 529811
#% 544773
#% 544923
#% 1272399
#% 1476295
#% 1478845
#! A general framework for update-based planning is presented. We first give a new family of dependence-based update operators that are wellsuited to the representation of simple actions and we identify the complexity of query entailment from an updated belief base. Then we introduce conditional, nondeterministic and concurrent updates so as to encode the corresponding types of action effects. Plan verification and existence are expressed in this update-based framework.

#index 1289164
#* Causality and minimal change demystified
#@ Maurice Pagnucco;Pavlos Peppas
#t 2001
#c 11
#% 89961
#% 183459
#% 224765
#% 496257
#% 1290152
#% 1478800
#! The Principle of Minimal Change is prevalent in various guises throughout the development of areas such as reasoning about action, belief change and nonmonotonic reasoning. Recent literature has witnessed the proposal of several theories of action that adopt an explicit representation of causality. It is claimed that an explicit notion of causality is able to deal with the frame problem in a manner not possible with traditional approaches based on minimal change. However, such claims remain untested by all but representative examples. It is our purpose here to objectively test these claims in an abstract sense; to determine whether an explicit representation of causality is capable of providing something that the Principle of Minimal Change is unable to capture. Working towards this end, we provide a precise characterisation of the limit of applicability of minimal change.

#index 1289165
#* EPDL: a logic for causal reasoning
#@ Dongmo Zhang;Norman Foo
#t 2001
#c 11
#% 19974
#% 36236
#% 77841
#% 224765
#% 243707
#% 289948
#% 366370
#% 374945
#% 421937
#% 558551
#% 1290152
#% 1290153
#% 1478800
#! This paper presents an extended system EPDL of propositional dynamic logic by allowing a proposition as a modality for representing and specifying direct and indirect effects of actions in a unified logical structure. A set of causal logics based on the framework are proposed to model causal propagations through logical relevancy and iterated effects of causation. It is shown that these logics capture the basic properties of causal reasoning.

#index 1289166
#* A circumscriptive formalization of the qualification problem
#@ G. Neelakantan Kartha
#t 2001
#c 11
#% 3035
#% 38668
#% 107123
#% 167541
#% 183459
#% 184795
#% 224765
#% 243707
#% 296169
#% 1290151
#% 1290152
#! The qualification problem refers to the difficulty that arises in formalizing actions, because it is difficult or impossible to specify in advance all the preconditions that should hold before an action can be executed. We study the qualification problem in the setting of the situation calculus and give a simple formalization using nested abnormality theories, a formalism based on circumscription. The formalization that we present allows us to combine a solution to the frame problem with a solution to the qualification problem.

#index 1289167
#* Computing strongest necessary and weakest sufficient conditions of first-order formulas
#@ Patrick Doherty;Witold Łukaszewicz;Andrzej Szałas
#t 2001
#c 11
#% 204396
#% 222065
#% 229083
#% 270252
#% 361471
#% 384051
#% 384978
#% 420607
#! A technique is proposed for computing the weakest sufficient (wsc) and strongest necessary (snc) conditions for formulas in an expressive fragment of first-order logic using quantifier elimination techniques. The efficacy of the approach is demonstrated by using the techniques to compute snc's and wsc's for use in agent communication applications, theory approximation and generation of abductive hypotheses. Additionally, we generalize recent results involving the generation of successor state axioms in the propositional situation calculus via snc's to the first-order case. Subsumption results for existing approaches to this problem and a re-interpretation of the concept of forgetting as a process of quantifier elimination are also provided.

#index 1289168
#* Identification constraints and functional dependencies in description logics
#@ Diego Calvanese;Giuseppe De Giacomo;Maurizio Lenzerini
#t 2001
#c 11
#% 248026
#% 384978
#% 442977
#% 459240
#% 459291
#% 1271815
#! DLR is an expressive Description Logic (DL) with n-ary relations, particularly suited for modeling database schemas. Although DLR has constituted one of the crucial steps for applying DL technology to data management, there is one important aspect of database schemas that DLs, including DLR, do not capture yet, namely the notion of identification constraints and functional dependencies. In this paper we introduce a DL which extends DLR and fully captures the semantics of such constraints, and we address the problem of reasoning in such a logic. We show that, verifying knowledge base satisfiability and logical implication in the presence of identification constraints and nonunary functional dependencies can be done in EXPTIME, thus with the same worst-case computational complexity as for plain DLR. We also show that adding just unary functional dependencies to DLR leads to undecidability.

#index 1289169
#* High performance reasoning with very large knowledge bases: a practical case study
#@ Volker Haarslev;Ralf Möller
#t 2001
#c 11
#% 445332
#% 496099
#% 517558
#% 517564
#% 561709
#! We present an empirical analysis of optimization techniques devised to speed up the so-called TBox classification supported by description logic systems which have to deal with very large knowledge bases (e.g. containing more than 100,000 concept introduction axioms). These techniques are integrated into the RACE architecture which implements a TBox and ABox reasoner for the description logic ALCNHR+. The described techniques consist of adaptions of previously known as well as new optimization techniques for efficiently coping with these kinds of very large knowledge bases. The empirical results presented in this paper are based on experiences with an ontology for the Unified Medical Language System and demonstrate a considerable runtime improvement. They also indicate that appropriate description logic systems based on sound and complete algorithms can be particularly useful for very large knowledge bases.

#index 1289170
#* Complexity of nested circumscription and abnormality theories
#@ Marco Cadoli;Thomas Eiter;Georg Gottlob
#t 2001
#c 11
#% 61221
#% 95643
#% 136678
#% 167541
#% 184795
#% 263132
#% 318489
#% 495922
#% 499508
#% 1275338
#% 1393768
#! We propose LCirc, an extension of circumscription by allowing propositional combinations and nesting of circumscriptive theories. As shown, Lifschitzs nested abnormality theories (NATs, introduced in AIJ, 1995) are naturally embedded into this language. We analyze the complexity of LCirc and NATs, and in particular the effect of nesting. The latter is found a source of complexity, as both formalisms are proved to be PSPACE-complete. We identify cases of lower complexity, including a tractable case. Our results give insight into the cost of using LCirc resp. NATs as a host language for expressing other formalisms, such as narratives.

#index 1289171
#* A perspective on knowledge compilation
#@ Adnan Darwiche;Pierre Marquis
#t 2001
#c 11
#% 3873
#% 204396
#% 239245
#% 291003
#% 442363
#% 495784
#% 600823
#% 936786
#% 1273692
#% 1275335
#% 1275338
#% 1499541
#! We provide a perspective on knowledge compilation which calls for analyzing different compilation approaches according to two key dimensions: the succinctness of the target compilation language, and the class of queries and transformations that the language supports in polytime. We argue that such analysis is necessary for placing new compilation approaches within the context of existing ones. We also go beyond classical, flat target compilation languages based on CNF and DNF, and consider a richer, nested class based on directed acyclic graphs, which we show to include a relatively large number of target compilation languages.

#index 1289172
#* Phase transitions of PP-complete satisfiability problems
#@ Delbert D. Bailey;Víctor Dalmau;Phokion G. Kolaitis
#t 2001
#c 11
#% 17298
#% 77847
#% 167629
#% 205391
#% 210193
#% 222822
#% 283229
#% 283232
#% 300063
#% 314121
#% 420743
#% 529186
#% 558706
#% 593982
#% 686847
#% 1080900
#% 1081134
#% 1272331
#% 1272404
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289173
#* Decision Procedures for Expressive Description Logics with Intersection, Composition, Converse of Roles and Role Identity
#@ Fabio Massacci
#t 2001
#c 11
#% 6246
#% 101435
#% 205398
#% 248026
#% 251634
#% 283011
#% 319931
#% 420690
#% 420765
#% 587516
#% 665856
#% 939417
#% 1275330
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289174
#* Ontology reasoning in the SHOQ(D) description logic
#@ Ian Horrocks;Ulrike Sattler
#t 2001
#c 11
#% 170059
#% 225467
#% 433879
#% 517441
#% 517563
#% 1271815
#! Ontologies are set to play a key rôle in the "Semantic Web" by providing a source of shared and precisely defined terms that can be used in descriptions of web resources. Reasoning over such descriptions will be essential if web resources are to be more accessible to automated processes. SHOQ(D) is an expressive description logic equipped with named individuals and concrete datatypes which has almost exactly the same expressive power as the latest web ontology languages (e.g., OIL and DAML). We present sound and complete reasoning services for this logic.

#index 1289175
#* The SG family: extensions of simple conceptual graphs
#@ Jean-François Baget;Marie-Laure Mugnier
#t 2001
#c 11
#% 2298
#% 465492
#% 465656
#% 465805
#% 465819
#% 465829
#% 517248
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289176
#* Matching under side conditions in description logics
#@ Franz Baader;Sebastian Brandt;Ralf Küsters
#t 2001
#c 11
#% 244095
#% 671246
#% 703948
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289177
#* Computing least common subsumers in ALEN
#@ Ralf Küsters;Ralf Molitor
#t 2001
#c 11
#% 466006
#% 496103
#% 539635
#! Computing the least common subsumer (lcs) has proved to be useful in a variety of different applications. Previous work on the lcs has concentrated on description logics that either allow for number restrictions or for existential restrictions. Many applications, however, require to combine these constructors. In this work, we present an lcs algorithm for the description logic ALEN, which allows for both constructors, thereby correcting previous algorithms proposed in the literature.

#index 1289178
#* FCA-MERGE: bottom-up merging of ontologies
#@ Gerd Stumme;Alexander Maedche
#t 2001
#c 11
#% 189739
#% 384416
#% 511913
#% 529190
#% 742426
#! Ontologies have been established for knowledge sharing and are widely used as a means for conceptually structuring domains of interest. With the growing usage of ontologies, the problem of overlapping knowledge in a common domain becomes critical. We propose the new method FCA-MERGE for merging ontologies following a bottom-up approach which offers a structural description of the merging process. The method is guided by application-specific instances of the given source ontologies, that are to be merged. We apply techniques from natural language processing and formal concept analysis to derive a lattice of concepts as a structural result of FCA-MERGE. The generated result is then explored and transformed into the merged ontology with human interaction.

#index 1289179
#* Incomplete tree search using adaptive probing
#@ Wheeler Ruml
#t 2001
#c 11
#% 90867
#% 95673
#% 179960
#% 265781
#% 266127
#% 266208
#% 266290
#% 674446
#% 709863
#% 1271914
#% 1271915
#% 1275261
#% 1275306
#% 1499506
#% 1499508
#% 1777042
#% 1860015
#! When not enough time is available to fully explore a search tree, different algorithms will visit different leaves. Depth-first search and depth-bounded discrepancy search, for example, make opposite assumptions about the distribution of good leaves. Unfortunately, it is rarely clear a priori which algorithm will be most appropriate for a particular problem. Rather than fixing strong assumptions in advance, we propose an approach in which an algorithm attempts to adjust to the distribution of leaf costs in the tree while exploring it. By sacrificing completeness, such flexible algorithms can exploit information gathered during the search using only weak assumptions. As an example, we show how a simple depth-based additive cost model of the tree can be learned on-line. Empirical analysis using a generic tree search problem shows that adaptive probing is competitive with systematic algorithms on a variety of hard trees and outperforms them when the node-ordering heuristic makes many mistakes. Results on boolean satisfiability and two different representations of number partitioning confirm these observations. Adaptive probing combines the flexibility and robustness of local search with the ability to take advantage of constructive heuristics.

#index 1289180
#* Heuristic search in infinite state spaces guided by Lyapunov analysis
#@ Theodore J. Perkins;Andrew G. Barto
#t 2001
#c 11
#% 68238
#% 174161
#% 369763
#% 380351
#% 388161
#% 421205
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289181
#* A backbone-search heuristic for efficient solving of hard 3-SAT formulae
#@ Olivier Dubois;Gilles Dequen
#t 2001
#c 11
#% 267602
#% 294983
#% 327779
#% 337577
#% 408396
#% 561083
#% 1273681
#% 1478761
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289182
#* Backbones in optimization and approximation
#@ John Slaney;Toby Walsh
#t 2001
#c 11
#% 233698
#% 319789
#% 337577
#% 341488
#% 529517
#% 1271817
#% 1275261
#% 1476300
#% 1478782
#! We study the impact of backbones in optimization and approximation problems. We show that some optimization problems like graph coloring resemble decision problems, with problem hardness positively correlated with backbone size. For other optimization problems like blocks world planning and traveling salesperson problems, problem hardness is weakly and negatively correlated with backbone size, while the cost of finding optimal and approximate solutions is positively correlated with backbone size. A third class of optimization problems like number partitioning have regions of both types of behavior. We find that to observe the impact of backbone size on problem hardness, it is necessary to eliminate some symmetries, perform trivial reductions and factor out the effective problem size.

#index 1289183
#* Cooperative search and nogood recording
#@ Cyril Terrioux
#t 2001
#c 11
#% 160272
#! Within the framework of constraint satisfaction problem, we propose a new scheme of cooperative parallel search. The cooperation is realized by exchanging nogoods (instantiations which can't be extended to a solution). We associate a process with each solver and we introduce a manager of no-goods, in order to regulate exchanges of nogoods. Each solver runs the algorithm Forward-Checking with Nogood Recording. We add to algorithm a phase of interpretation, which limits the size of the search tree according to the received nogoods. Solvers differ from each other in ordering variables and/or values by using different heuristics. The interest of our approach is shown experimentally. In particular, we obtain linear or superlinear speed-up for consistent problems, like for inconsistent ones, up to about ten solvers.

#index 1289184
#* Search on high degree graphs
#@ Toby Walsh
#t 2001
#c 11
#% 283230
#% 319789
#% 341488
#% 496249
#% 529517
#% 1478782
#! We show that nodes of high degree tend to occur infrequently in random graphs but frequently in a wide variety of graphs associated with real world search problems. We then study some alternative models for randomly generating graphs which have been proposed to give more realistic topologies. For example, we show that Watts and Strogatz's small world model has a narrow distribution of node degree. On the other hand, Barabási and Albert's power law model, gives graphs with both nodes of high degree and a small world topology. These graphs may therefore be useful for benchmarking. We then measure the impact of nodes of high degree and a small world topology on the cost of coloring graphs. The long tail in search costs observed with small world graphs disappears when these graphs are also constructed to contain nodes of high degree. We conjecture that this is a result of the small size of their "backbone", pairs of edges that are frozen to be the same color.

#index 1289185
#* Backjumping for quantified Boolean logic satisfiability
#@ Enrico Giunchiglia;Massimo Narizzano;Armando Tacchella
#t 2001
#c 11
#% 68183
#% 183640
#% 266109
#% 283229
#% 327779
#% 420766
#% 495922
#% 529173
#% 529515
#% 561731
#% 561734
#% 1272399
#% 1478761
#! The implementation of effective reasoning tools for deciding the satisfiability of Quantified Boolean Formulas (QBFs) is an important research issue in Artificial Intelligence. Many decision procedures have been proposed in the last few years, most of them based on the Davis, Logemann, Loveland procedure (DLL) for propositional satisfiability (SAT). In this paper we show how it is possible to extend the conflict-directed backjumping schema for SAT to QBF: when applicable, it allows to jump over existentially quantified literals while backtracking. We introduce solution-directed backjumping, which allows the same for universally quantified literals. Then, we show how it is possible to incorporate both conflict-directed and solution-directed backjumping in a DLL-based decision procedure for QBF satisfiability. We also implement and test the procedure: The experimental analysis shows that, because of backjumping, significant speed-ups can be obtained. While there have been several proposals for backjumping in SAT, this is the first time - as far as we know - this idea has been proposed, implemented and experimented for QBFs.

#index 1289186
#* Solving non-Boolean satisfiability problems with stochastic local search
#@ Alan M. Frisch;Timothy J. Peugniez
#t 2001
#c 11
#% 126390
#% 131357
#% 160270
#% 496245
#% 496258
#% 1271884
#% 1476298
#% 1478771
#! Much excitement has been generated by the recent success of stochastic local search procedures at finding satisfying assignments to large formulas. Many of the problems on which these methods have been effective are non-Boolean in that they are most naturally formulated in terms of variables with domain sizes greater than two. To tackle such a problem with a Boolean procedure the problem is first reformulated as an equivalent Boolean problem. This paper introduces and studies the alternative of extending a Boolean stochastic local search procedure to operate directly on non-Boolean problems. It then compares the non-Boolean representation to three Boolean representations and presents experimental evidence that the non-Boolean method is often superior for problems with large domain sizes.

#index 1289187
#* Backtracking through biconnected components of a constraint graph
#@ Jean-François Baget;Yannic S. Tognetti
#t 2001
#c 11
#% 1145
#% 36814
#% 68183
#% 289332
#% 566718
#! The algorithm presented here, BCC, is an enhancement of the well known Backtrack used to solve constraint satisfaction problems. Though most backtrack improvements rely on propagation of local informations, BCC uses global knowledge of the constraint graph structure (and in particular its biconnected components) to reduce search space, permanently removing values and compiling partial solutions during exploration. This algorithm performs well by itself, without any filtering, when the biconnected components are small, achieving optimal time complexity in case of a tree. Otherwise, it remains compatible with most existing techniques, adding only a negligible overhead cost.

#index 1289188
#* A constraint satisfaction approach to parametric differential equations
#@ Micha Janssen;Pascal Van Hentenryck;Yves Deville
#t 2001
#c 11
#% 137234
#% 534490
#% 837629
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289189
#* Improved bounds on the complexity of kB-consistency
#@ Lucas Bordeaux;Eric Monfroy;Frédéric Benhamou
#t 2001
#c 11
#% 1145
#% 21144
#% 224751
#% 278105
#% 320265
#% 422159
#! kB-consistencies form the class of strong consistencies used in interval constraint programming. We survey, prove, and give theoretical motivations to some technical improvements to a naive kB- consistency algorithm. Our contribution is twofold: on the one hand, we introduce an optimal 3B- consistency algorithm whose time-complexity of O(md2n) improves the known bound by a factor n (m is the number of constraints, n is the number of variables, and d is the maximal size of the intervals of the box). On the other hand, we prove that improved bounds on time complexity can effectively be reached for higher values of k. These results are obtained with very affordable overheads in terms of space complexity.

#index 1289190
#* Refining the basic constraint propagation algorithm
#@ Christian Bessière;Jean-Charles Régin
#t 2001
#c 11
#% 3463
#% 131561
#% 160389
#% 267574
#% 419942
#% 477221
#% 1275304
#! Propagating constraints is the main feature of any constraint solver. This is thus of prime importance to manage constraint propagation as efficiently as possible, justifying the use of the best algorithms. But the ease of integration is also one of the concerns when implementing an algorithm in a constraint solver. This paper focuses on AC-3, which is the simplest arc consistency algorithm known so far. We propose two refinements that preserve as much as possible the ease of integration into a solver (no heavy data structure to be maintained during search), while giving some noticeable improvements in efficiency. One of the proposed refinements is analytically compared to AC-6, showing interesting properties, such as optimality of its worst-case time complexity.

#index 1289191
#* Making AC-3 an optimal algorithm
#@ Yuanlin Zhang;Roland H. C. Yap
#t 2001
#c 11
#% 1145
#% 3463
#% 131561
#% 160389
#% 267574
#% 419942
#% 1499494
#! The AC-3 algorithm is a basic and widely used arc consistency enforcing algorithm in Constraint Satisfaction Problems (CSP). Its strength lies in that it is simple, empirically efficient and extensible. However its worst case time complexity was not considered optimal since the first complexity result for AC-3 [Mackworth and Freuder, 1985] with the bound O(ed3), where e is the number of constraints and d the size of the largest domain. In this paper, we show suprisingly that AC-3 achieves the optimal worst case time complexity with O(ed2). The result is applied to obtain a path consistency algorithm which has the same time and space complexity as the best known theoretical results. Our experimental results show that the new approach to AC-3 is comparable to the traditional AC-3 implementation for simpler problems where AC-3 is more efficient than other algorithms and significantly faster on hard instances.

#index 1289192
#* Temporal constraint reasoning with preferences
#@ Lina Khatib;Paul Morris;Robert Morris;Francesca Rossi
#t 2001
#c 11
#% 70370
#% 107137
#% 126386
#% 189747
#% 230551
#% 1275309
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289193
#* A hybrid approach for the 0-1 multidimensional knapsack problem
#@ Michel Vasquez;Jin-Kao Hao
#t 2001
#c 11
#% 40202
#% 143595
#% 383492
#% 421213
#! We present a hybrid approach for the 0-1 multidimensional knapsack problem. The proposed approach combines linear programming and Tabu Search. The resulting algorithm improves significantly on the best known results of a set of more than 150 benchmark instances.

#index 1289194
#* The exponentiated subgradient algorithm for heuristic Boolean programming
#@ Dale Schuurmans;Finnegan Southey;Robert C. Holte
#t 2001
#c 11
#% 160239
#% 160270
#% 227736
#% 283088
#% 283198
#% 283231
#% 314925
#% 420726
#% 495768
#% 496094
#% 496250
#% 529167
#% 529172
#% 529507
#% 529822
#% 534508
#% 564832
#% 659864
#% 1476298
#% 1478779
#% 1499519
#! Boolean linear programs (BLPs) are ubiquitous in AI. Satisfiability testing, planning with resource constraints, and winner determination in combinatorial auctions are all examples of this type of problem. Although increasingly well-informed by work in OR, current AI research has tended to focus on specialized algorithms for each type of BLP task and has only loosely patterned new algorithms on effective methods from other tasks. In this paper we introduce a single general-purpose local search procedure that can be simultaneously applied to the entire range of BLP problems, without modification. Although one might suspect that a general-purpose algorithm might not perform as well as specialized algorithms, we find that this is not the case here. Our experiments show that our generic algorithm simultaneously achieves performance comparable with the state of the art in satisfiability search and winner determination in combinatorial auctions-- two very different BLP problems. Our algorithm is simple, and combines an old idea from OR with recent ideas from AI.

#index 1289195
#* A new method for the three dimensional container packing problem
#@ Andrew Lim;Wang Ying
#t 2001
#c 11
#! A new algorithm for solving the three dimensional container packing problem is proposed in this paper. This new algorithm deviates from the traditional approach of wall building and layering. It uses the concept of "building growing" from multiple sides of the container. We tested our method using all 760 test cases from the OR-Library. Experimental results indicate that the new algorithm is able to achieve an average packing utilization of more than 87%. This is better than the results reported in the literature.

#index 1289196
#* Balance and filtering in structured satisfiable problems
#@ Henry Kautz;Yongshao Ruan;Dimitris Achlioptas;Carla Gomes;Bart Selman;Mark Stickel
#t 2001
#c 11
#% 63780
#% 160208
#% 210191
#% 420719
#% 496276
#% 529517
#% 561083
#% 1273727
#! New methods to generate hard random problem instances have driven progress on algorithms for deduction and constraint satisfaction. Recently Achlioptas et al. (AAAI 2000) introduced a new generator based on Latin squares that creates only satisfiable problems, and so can be used to accurately test incomplete (one sided) solvers. We investigate how this and other generators are biased away from the uniform distribution of satisfiable problems and show how they can be improved by imposing a balance condition. More generally, we show that the generator is one member of a family of related models that generate distributions ranging from ones that are everywhere tractable to ones that exhibit a sharp hardness threshold. We also discuss the critical role of the problem encoding in the performance of both systematic and local search solvers.

#index 1289197
#* Efficient consequence finding
#@ Laurent Simon
#t 2001
#c 11
#% 3460
#% 69150
#% 121397
#% 132173
#% 132176
#% 147928
#% 204396
#% 205390
#% 283118
#% 288165
#% 529332
#% 529333
#% 569112
#% 661260
#% 936786
#% 1275334
#% 1290122
#% 1393567
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289198
#* Formalizing artistic techniques and scientific visualization for painted renditions of complex information spaces
#@ Christopher G. Healey
#t 2001
#c 11
#% 2740
#% 80352
#% 181348
#% 434539
#% 435730
#% 619534
#! This paper describes a new method for visualizing complex information spaces as painted images. Scientific visualization converts data into pictures that allow viewers to "see" trends, relationships, and patterns. We introduce a formal definition of the correspondence between traditional visualization techniques and painterly styles from the Impressionist art movement. This correspondence allows us to apply perceptual guidelines from visualization to control the presentation of information in a computer-generated painting. The result is an image that is visually engaging, but that also allows viewers to rapidly and accurately explore and analyze the underlying data values. We conclude by applying our technique to a collection of environmental and weather readings, to demonstrate its viability in a practical, real-world visualization environment.

#index 1289199
#* Visual analogy in problem solving
#@ Jim Davies;Ashok K. Goel
#t 2001
#c 11
#% 65345
#% 162824
#% 1273717
#! Computational models of analogical problem solving have traditionally described source and target domains in terms of their causal structure. But psychological research shows that visual reasoning plays a part for many kinds of analogies. This paper describes a model that transfers a solution from a source analog to a new target problem using only visual knowledge represented symbolically. The knowledge representation is based on a language of primitive visual elements and transformations. We found that visual knowledge is sufficient for transfer, but that causal knowledge is needed to determine if the transferred solution is appropriate.

#index 1289200
#* Reasoning about categories in conceptual spaces
#@ Peter Gärdenfors;Mary-Anne Williams
#t 2001
#c 11
#% 19385
#% 64553
#% 103743
#% 270714
#% 353872
#% 421040
#% 539433
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289201
#* Simulating the formation of color categories
#@ Tony Belpaeme
#t 2001
#c 11
#% 200798
#! This paper investigates the formation of color categories and color naming in a population of agents. The agents perceive and categorize color stimuli, and try to communicate about these perceived stimuli. While doing so they adapt their internal representations to be more successful at conveying color meaning in future interactions. The agents have no access to global information or to the representations of other agents; they only exchange word forms. The factors driving the population coherence are the shared environment and the interactions. The experiments show how agents can form a coherent lexicon of color terms and -- particularly -- how a coherent color categorization emerges through these linguistic interactions. The results are interpreted in the light of theories describing and explaining universal tendencies in human color categorization and color naming. At the same time the experiments confirm the view that certain aspects of language act as a complex dynamic system, arising from self-organization and cultural interactions.

#index 1289202
#* Grounded models as a basis for intuitive reasoning
#@ Josefina Sierra-Santibáñez
#t 2001
#c 11
#% 3035
#% 262742
#! This paper introduces grounded models and compares them to axiomatic models of mathematics. Grounded models differ from axiomatic theories in establishing explicit connections between language and reality that are learnt through language games. They are constructed and updated by autonomous agents connected to their environment through sensors and actuators using some conceptualization mechanisms and language games described in [Steels, 1999]. They are based on conceptualization and support a form of intuitive reasoning, which can be done sometimes by constraint satisfaction and it is argued to be the basis of some axiomatizations. This is illustrated with a simple example of spatial reasoning.

#index 1289203
#* Perceptual anchoring of symbols for action
#@ Silvia Coradeschi;Alessandro Saffiotti
#t 2001
#c 11
#% 85153
#% 194658
#% 418727
#% 529673
#% 539352
#% 1271929
#% 1289206
#! Anchoring is the process of creating and maintaining the correspondence between symbols and percepts that refer to the same physical objects. Although this process must necessarily be present in any symbolic reasoning system embedded in a physical environment (e.g., an autonomous robot), the systematic study of anchoring as a clearly separated problem is just in its initial phase. In this paper we focus on the use of symbols in actions and plans and the consequences this has for anchoring. In particular we introduce action properties and partial matching of objects descriptions. We also consider the use of indefinite references in the context of action. The use of our formalism is exemplified in a mobile robotic domain.

#index 1289204
#* Planning with resources and concurrency a forward chaining approach
#@ Fahiem Bacchus;Michael Ady
#t 2001
#c 11
#% 100159
#% 296170
#% 398248
#% 398249
#% 417597
#% 495772
#% 496277
#% 618579
#! Recently tremendous advances have been made in the performance of AI planning systems. However increased performance is only one of the prerequisites for bringing planning into the realm of real applications; advances in the scope of problems that can be represented and solved must also be made. In this paper we address two important representational features, concurrently executable actions with varying durations, and metric quantities like resources, both essential for modeling real applications. We show how the forward chaining approach to planning can be extended to allow it to solve planning problems with these two features. Forward chaining using heuristics or domain specific information to guide search has shown itself to be a very promising approach to planning, and it is sensible to try to build on this success. In our experiments we utilize the TLPLAN approach to planning, in which declaratively represented control knowledge is used to guide search. We show that this extra knowledge can be intuitive and easy to obtain, and that with it impressive planning performance can be achieved.

#index 1289205
#* Total-order planning with partially ordered subtasks
#@ Dana Nau;Héctor Muñoz-Avila;Yue Cao;Amnon Lotem;Steven Mitchell
#t 2001
#c 11
#% 25470
#% 103050
#% 109935
#% 296170
#% 495942
#% 496111
#% 544766
#! One of the more controversial recent planning algorithms is the SHOP algorithm, an HTN planning algorithm that plans for tasks in the same order that they are to be executed. SHOP can use domaindependent knowledge to generate plans very quickly, but it can be difficult to write good knowledge bases for SHOP. Our hypothesis is that this difficulty is because SHOP's total-ordering requirement for the subtasks of its methods is more restrictive than it needs to be. To examine this hypothesis, we have developed a new HTN planning algorithm called SHOP2. Like SHOP, SHOP2 is sound and complete, and it constructs plans in the same order that they will later be executed. But unlike SHOP, SHOP2 allows the subtasks of each method to be partially ordered. Our experimental results suggest that in some problem domains, the difficulty of writing SHOP knowledge bases derives from SHOP's total-ordering requirement--and that in such cases, SHOP2 can plan as efficiently as SHOP using knowledge bases simpler than those needed by SHOP.

#index 1289206
#* Conditional progressive planning under uncertainty
#@ Lars Karlsson
#t 2001
#c 11
#% 101955
#% 215878
#% 252183
#% 266387
#% 283215
#% 283219
#% 296170
#% 478255
#% 496418
#% 1289203
#% 1290109
#% 1476294
#% 1478833
#! In this article, we describe a possibilistic/ probabilistic conditional planner called PTLplan. Being inspired by Bacchus and Kabanza's TLplan, PTLplan is a progressive planner that uses strategic knowledge encoded in a temporal logic to reduce its search space. Actions effects and sensing can be context dependent and uncertain, and the information the planning agent has at each point in time is represented as a set of situations with associated possibilities or probabilities. Besides presenting the planner itself -- its representation of actions and plans, and its algorithm -- we also provide some promising data from performance tests.

#index 1289207
#* One action is enough to plan
#@ Emmanuel Guéré;Rachid Alami
#t 2001
#c 11
#% 224480
#% 266388
#% 496243
#% 496418
#% 544766
#% 544930
#% 618579
#% 1272340
#! We describe a new practical domain independent task planner, called ShaPer, specially designed to deal efficiently with large problems. ShaPer performs in two steps. In the first step, executed off-line for a given domain subclass, ShaPer explores and builds a compact representation of the state space called the shape graph. The main contribution of ShaPer is its ability to "resist" to combinatorial explosion thanks to the manipulation of sets of similar state descriptions called shapes. The shape graph is then used by ShaPer to answer very efficiently to planning requests. A first version of the planner has been implemented. It has been tested on several well known benchmark domains. The results are very promising when compared with themost efficient planners from AIPS-2000 competition.

#index 1289208
#* Hybrid STAN: Identifying and managing combinatorial optimisation sub-problems in planning
#@ Maria Fox;Derek Long
#t 2001
#c 11
#% 327432
#% 495942
#% 544930
#% 544937
#% 618579
#% 1272340
#% 1478840
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289209
#* Local search topology in planning benchmarks: an empirical analysis
#@ Jörg Hoffmann
#t 2001
#c 11
#% 167629
#% 337980
#% 544791
#% 1271820
#% 1272321
#% 1478840
#! Many state-of-the-art heuristic planners derive their heuristic function by relaxing the planning task at hand, where the relaxation is to assume that all delete lists are empty. Looking at a collection of planning benchmarks, we measure topological properties of state spaces with respect to that relaxation. The results suggest that, given the heuristic based on the relaxation, many planning benchmarks are simple in structure. This sheds light on the recent success of heuristic planners employing local search.

#index 1289210
#* Reviving partial order planning
#@ XuanLong Nguyen;Subbarao Kambhampati
#t 2001
#c 11
#% 179935
#% 224480
#% 266388
#% 275214
#% 345431
#% 495772
#% 529525
#% 544930
#% 743461
#% 1271809
#% 1272297
#% 1272333
#% 1272340
#% 1272392
#% 1476298
#% 1477346
#% 1478667
#% 1478837
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289211
#* Heuristic search + symbolic model checking = efficient conformant planning
#@ Piergiorgio Bertoli;Alessandro Cimatti;Marco Roveri
#t 2001
#c 11
#% 121397
#% 134017
#% 148016
#% 243697
#% 266386
#% 266387
#% 365338
#% 404742
#% 500121
#% 529322
#% 529665
#% 544788
#% 1271828
#% 1272287
#% 1272399
#% 1289212
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289212
#* Planning in nondeterministic domains under partial observability via symbolic model checking
#@ Piergiorgio Bertoli;Alessandro Cimatti;Marco Roveri;Paolo Traverso
#t 2001
#c 11
#% 121397
#% 179940
#% 243697
#% 266196
#% 266384
#% 266386
#% 266387
#% 365338
#% 495922
#% 528003
#% 529511
#% 1271828
#% 1272287
#% 1272331
#% 1272399
#% 1289211
#% 1289213
#! Planning under partial observability is one of the most significant and challenging planning problems. It has been shown to be hard, both theoretically and experimentally. In this paper, we present a novel approach to the problem of planning under partial observability in non-deterministic domains. We propose an algorithm that searches through a (possibly cyclic) and-or graph induced by the domain. The algorithm generates conditional plans that are guaranteed to achieve the goal despite of the uncertainty in the initial condition, the uncertain effects of actions, and the partial observability of the domain. We implement the algorithm by means of BDD-based, symbolic model checking techniques, in order to tackle in practice the exponential blow up of the search space. We show experimentally that our approach is practical by evaluating the planner with a set of problems taken from the literature and comparing it with other state of the art planners for partially observable domains.

#index 1289213
#* Planning as model checking for extended goals in non-deterministic domains
#@ Marco Pistore;Paolo Traverso
#t 2001
#c 11
#% 101955
#% 145228
#% 243697
#% 266384
#% 417597
#% 518136
#% 544938
#% 544943
#% 1289212
#! Recent research has addressed the problem of planning in non-deterministic domains. Classical planning has also been extended to the case of goals that can express temporal properties. However, the combination of these two aspects is not trivial. In non-deterministic domains, goals should take into account the fact that a plan may result in many possible different executions and that some requirements can be enforced on all the possible executions, while others may be enforced only on some executions. In this paper we address this problem. We define a planning algorithm that generates automatically plans for extended goals in nondeterministic domains. We also provide preliminary experimental results based on an implementation of the planning algorithm that uses symbolic model checking techniques.

#index 1289214
#* Executing reactive, model-based programs through graph-based temporal planning
#@ Phil Kim;Brian C. Williams;Mark Abramson
#t 2001
#c 11
#% 70370
#% 107137
#% 122671
#% 131859
#% 179879
#% 224480
#% 229241
#% 252826
#% 262737
#% 266108
#% 365440
#% 495772
#% 1289227
#% 1290110
#! In the future, webs of unmanned air and space vehicles will act together to robustly perform elaborate missions in uncertain environments. We coordinate these systems by introducing a reactive model-based programming language (RMPL) that combines within a single unified representation the flexibility of embedded programming and reactive execution languages, and the deliberative reasoning power of temporal planners. The KIRK planning system takes as input a problem expressed as a RMPL program, and compiles it into a temporal plan network (TPN), similar to those used by temporal planners, but extended for symbolic constraints and decisions. This intermediate representation clarifies the relation between temporal planning and causal-link planning, and permits a single task model to be used for planning and execution. Such a unified model has been described as a holy grail for autonomous agents by the designers of the Remote Agent[Muscettola et al., 1998b].

#index 1289215
#* Dynamic control of plans with temporal uncertainty
#@ Paul Morris;Nicola Muscettola;Thierry Vidal
#t 2001
#c 11
#% 70370
#% 107137
#% 262737
#% 496406
#% 529337
#! Certain planning systems that deal with quantitative time constraints have used an underlying Simple Temporal Problem solver to ensure temporal consistency of plans. However, many applications involve processes of uncertain duration whose timing cannot be controlled by the execution agent. These cases require more complex notions of temporal feasibility. In previous work, various "controllability" properties such as Weak, Strong, and Dynamic Controllability have been defined. The most interesting and useful Controllability property, the Dynamic one, has ironically proved to be the most difficult to analyze. In this paper, we resolve the complexity issue for Dynamic Controllability. Unexpectedly, the problem turns out to be tractable. We also show how to efficiently execute networks whose status has been verified.

#index 1289216
#* Complexity of probabilistic planning under average rewards
#@ Jussi Rintanen
#t 2001
#c 11
#% 18
#% 7827
#% 30037
#% 42241
#% 77386
#% 167629
#% 187079
#% 217506
#% 283210
#% 310835
#% 363744
#% 836122
#% 1080992
#% 1272331
#% 1290040
#% 1478845
#% 1650308
#% 1650313
#% 1650588
#! A general and expressive model of sequential decision making under uncertainty is provided by the Markov decision processes (MDPs) framework. Complex applications with very large state spaces are best modelled implicitly (instead of explicitly by enumerating the state space), for example as precondition-effect operators, the representation used in AI planning. This kind of representations are very powerful, and they make the construction of policies/plans computationally very complex. In many applications, average rewards over unit time is the relevant rationality criterion, as opposed to the more widely used discounted reward criterion, and for providing a solid basis for the development of efficient planning algorithms, the computational complexity of the decision problems related to average rewards has to be analyzed. We investigate the complexity of the policy/plan existence problem for MDPs under the average reward criterion, with MDPs represented in terms of conditional probabilistic precondition-effect operators. We consider policies with and without memory, and with different degrees of sensing/observability. The unrestricted policy existence problem for the partially observable cases was earlier known to be undecidable. The results place the remaining computational problems to the complexity classes EXP and NEXP (deterministic and nondeterministic exponential time.)

#index 1289217
#* Computational complexity of planning with temporal goals
#@ Chitta Baral;Vladik Kreinovich;Raúl A. Trejo
#t 2001
#c 11
#% 101955
#% 167629
#% 168262
#% 194648
#% 318489
#% 417597
#% 1478845
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289218
#* A simplifier for propositional formulas with many binary clauses
#@ Ronen I. Brafman
#t 2001
#c 11
#% 160270
#% 266200
#% 327779
#% 496111
#% 496409
#% 541925
#% 601159
#% 1271884
#% 1273727
#% 1476298
#% 1478761
#! Deciding whether a propositional formula in conjunctive normal form is satisfiable (SAT) is an NP-complete problem. The problem becomes linear when the formula contains binary clauses only. Interestingly, the reduction to SAT of a number of well-known and important problems - such as classical AI planning and automatic test pattern generation for circuits - yields formulas containing many binary clauses. In this paper we introduce and experiment with 2-SIMPLIFY, a formula simplifier targeted at such problems. 2-SIMPLIFY constructs the implication graph corresponding to the binary clauses in the formula and uses this graph to deduce new unit literals. The deduced literals are used to simplify the formula and update the graph, and so on, until stabilization. Finally, we use the graph to construct an equivalent, simpler set of binary clauses. Experimental evaluation of this simplifier on a number of bench-mark formulas produced by encoding AI planning problems prove 2-SIMPLIFY to be fast and effective.

#index 1289219
#* Iterative widening
#@ Tristan Cazenave
#t 2001
#c 11
#% 2194
#% 60140
#% 120809
#% 180122
#% 291205
#! We propose a method to gradually expand the moves to consider at the nodes of game search trees. The algorithm is an extension of Abstract Proof Search, an algorithm that solves more problem than basic Alpha-Beta search in less time and which is more reliable. Unlike other related algorithms, iterative winding adapts to the game via genearal game definition functions. In the game of Go, it can solve more problems than the original non windening algorithm in approximately half of the time, as shown by the experimental results.

#index 1289220
#* Temporal difference learning applied to a high-performance game-playing program
#@ Jonathan Schaeffer;Markian Hlynka;Vili Jussila
#t 2001
#c 11
#% 68273
#% 126860
#% 183499
#% 235559
#% 314787
#% 384911
#% 465917
#% 697616
#% 1272176
#! The temporal difference (TD) learning algorithm offers the hope that the arduous task of manually tuning the evaluation function weights of game-playing programs can be automated. With one exception (TD-Gammon), TD learning has not been demonstrated to be effictive in a high-performance, world Class game-palying program. Further, there has been doubt expressed by game-program developers that learned weights could compete with the best hand-tuned weights. Chinook is the World Man-Machine tuned over 5 years. This paper shows that TD learinng is capable of competing with the best human effort.

#index 1289221
#* Satisficing and learning cooperation in the prisoner's dilemma
#@ Jeff L. Stimpson;Michael A. Goodrich;Lawrence C. Walters
#t 2001
#c 11
#% 164502
#% 465913
#! The prisoner's dilemma is a useful model for studying the balance between self-interest and group-interest in multi-agent systems. Although many stratergies have been developed that perform well, most of these stratergies make strong assumptions about the information available to the agent. It is in this context that we describe a satisficing learning stratergy for the prisoner's dilemma and present evidance that stable outcomes other than the Nash equilibrium are possible. In addition, we offer emperical evidence that under typical circumstances, mutual cooperation is the most likely outcome and identify conditions under which two satisficing agents will learn to cooperate.

#index 1289222
#* Temporal decision trees or the lazy ECU vindicated
#@ Luca Console;Claudia Picardi;Daniele Theseider Dupré
#t 2001
#c 11
#% 257696
#% 449588
#% 496408
#% 936862
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289223
#* Model-based diagnosability and sensor placement application to a frame 6 gas turbine subsystem
#@ Louise Travé-Massuyès;Teresa Escobet;Robert Milne
#t 2001
#c 11
#% 163717
#% 220153
#% 445130
#! This paper presents a methodology for: assessing the degree of diagnosability of a system, i.e. given a set of sensors, which faults can be discriminated? and; characterising and determining the minimal additional sensors which guarantee a specified degree of diagnosability. This method has been applied to several subsystems of a Ge neral Electric Frame 6 gas turbine owned by a major UK utility.

#index 1289224
#* Distributed monitoring of hybrid systems: a model-directed approach
#@ Feng Zhao;Xenofon Koutsoukos;Horst Haussecker;James Reich;Patrick Cheung;Claudia Picardi
#t 2001
#c 11
#% 32357
#% 420214
#% 529185
#% 529667
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289225
#* Causal interaction: from a high-level representation to an operational event-based representation
#@ Irène Grosclaude;Marie-Odile Cordier;René Quiniou
#t 2001
#c 11
#% 7047
#% 183459
#% 266241
#% 558545
#% 558691
#% 1478841
#! We propose to extend the temporal causal graph formalisms used in model-based diagnosis in order to deal with non trivial interactions like (partial) cancellation of fault effects. A high-level causal language is defined in which properties such as the persistence of effects and the triggering or sustaining properties of causes can be expressed. Various interaction phenomena are associated with these features. Instead of proposing an ad hoc reasoning mechanism to process this extended formalism, the specifications in this language are automatically translated into an event calculus based language having well-established semantics. Our approach improves the way fault interaction and intermittent faults are coped with in temporal abductive diagnosis.

#index 1289226
#* Hierarchical diagnosis guided by observations
#@ Luca Chittaro;Roberto Ranon
#t 2001
#c 11
#% 1121
#% 109854
#% 125585
#% 125588
#% 132173
#! We propose a technique to improve the performance of hierarchical model-based diagnosis, based on structural abstraction. Given a hierarchical representation and the set of currently available observations, the technique is able to dynamically derive a tailored hierarchical representation to diagnose the current situation. We implement our strategy as an extension to the well-known Mozetic's approach [Mozetic, 1992], and illustrate the obtained performance improvements. Our approach is more efficient than Mozetic's one when, due to abstraction, fewer observations are available at the coarsest hierarchical levels.

#index 1289227
#* Mode estimation of model-based programs: monitoring systems with complex behavior
#@ Brian C. Williams;Seung Chung;Vineet Gupta
#t 2001
#c 11
#% 21138
#% 29439
#% 131859
#% 229241
#% 529667
#% 1476265
#! Deductive mode-estimation has become an essential component of robotic space systems, like NASA's deep space probes. Future robots will serve as components of large robotic networks. Monitoring these networks will require modeling languages and estimators that handle the sophisticated behaviors of robotic components. This paper introduces RMPL, a rich modeling language that combines reactive programming constructs with probabilistic, constraint-based modeling, and that offers a simple semantics in terms of hidden Markov models (HMMs). To support efficient realtime deduction, we translate RMPL models into a compact encoding of HMMs called probabilistic hierarchical constraint automata (PHCA). Finally, we use these models to track a system's most likely states by extending traditional HMM belief update.

#index 1289228
#* A-system: problem solving through abduction
#@ Antonis C. Kakas;Bert Van Nuffelen;Marc Denecker
#t 2001
#c 11
#% 103705
#% 266741
#% 305415
#% 417653
#% 443070
#% 544930
#% 1275253
#! This paper presents a new system, called the A- System, performing abductive reasoning within the framework of Abductive Logic Programming. It is based on a hybrid computational model that implements the abductive search in terms of two tightly coupled processes: a reduction process of the highlevel logical representation to a lower-level constraint store and a lower-level constraint solving process. A set of initial "proof of principle" experiments demonstrate the versatility of the approach stemming from its declarative representation of problems and the good underlying computational behaviour of the system. The approach offers a general methodology of declarative problem solving in AI where an incremental and modular refinement of the high-level representation with extra domain knowledge can improve and scale the computational performance of the framework.

#index 1289229
#* A comparative study of logic programs with preference
#@ Torsten Schaub;Kewen Wang
#t 2001
#c 11
#% 154317
#% 244354
#% 275032
#% 473192
#% 485071
#% 529161
#% 1290088
#! We are interested in semantical underpinnings for existing approaches to preference handling in extended logic programming (within the framework of answer set programming). As a starting point, we explore three different approaches that have been recently proposed in the literature. Because these approaches use rather different formal means, we furnish a series of uniform characterizations that allow us to gain insights into the relationships among these approaches. To be more precise, we provide different characterizations in terms of (i) fixpoints, (ii) order preservation, and (iii) translations into standard logic programs. While the two former provide semantics for logic programming with preference information, the latter furnishes implementation techniques for these approaches.

#index 1289230
#* Reasoning with infinite stable models
#@ Piero A. Bonatti
#t 2001
#c 11
#% 877
#% 68240
#% 125134
#% 169181
#% 171033
#% 190336
#% 517131
#% 708186
#! The existing proof-theoretic and software tools for nonmonotonic reasoning can only handle finite domains. In this paper we introduce a class of normal logic programs, called finitary programs, whose domain may be infinite, and such that credulous and skeptical entailment under the stable model semantics are computable. Finitary programs-- that are characterized by two conditions on their dependency graph--are computationally complete (they can simulate arbitrary Turing machines). Further results include a compactness theorem and the proof that the two conditions defining finitary programs are, in some sense, "minimal". The existing methods for automated nonmonotonic reasoning are either complete for finitary programs, or can be easily extended to cover them.

#index 1289231
#* Splitting without backtracking
#@ Alexandre Riazanov;Andrei Voronkov
#t 2001
#c 11
#% 289022
#% 420643
#% 561712
#% 579728
#% 585627
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289232
#* UNSEARCHMO: eliminating redundant search space on backtracking for forward chaining theorem proving
#@ Lifeng He
#t 2001
#c 11
#% 107547
#% 259449
#% 288366
#% 288555
#% 420698
#% 420741
#% 560057
#! This paper introduces how to eliminate redundant search space for forward chaining theorem proving as much as possible. We consider how to keep on minimal useful consequent atom sets for necessary branches in a proof tree. In the most cases, an unnecessary non-Horn clause used for forward chaining will be split only once. The increase of the search space by invoking unnecessary forward chaining clauses will be nearly linear, not exponential anymore. In a certain sense, we "unsearch" more than necessary. We explain the principle of our method, and provide an example to show that our approach is powerful for forward chaining theorem proving.

#index 1289233
#* Theorem proving with structured theories
#@ Sheila McIlraith;Eyal Amir
#t 2001
#c 11
#% 132176
#% 250847
#% 283118
#% 288366
#% 288692
#% 318185
#% 420720
#% 497327
#% 684874
#% 1499555
#! Motivated by the problem of query answering over multiple structured commonsense theories, we exploit graph-based techniques to improve the efficiency of theorem proving for structured theories. Theories are organized into subtheories that are minimally connected by the literals they share. We presentmessage-passing algorithms that reason over these theories using consequence finding, specializing our algorithms for the case of first-order resolution, and for batch and concurrent theorem proving. We provide an algorithm that restricts the interaction between subtheories by exploiting the polarity of literals. We attempt to minimize the reasoning within each individual partition by exploiting existing algorithms for focused incremental and general consequence finding. Finally, we propose an algorithm that compiles each subtheory into one in a reduced sublanguage. We have proven the soundness and completeness of all of these algorithms.

#index 1289234
#* Experimenting with heuristics for answer set programming
#@ Wolfgang Faber;Nicola Leone;Gerald Pfeifer
#t 2001
#c 11
#% 198885
#% 210195
#% 235018
#% 244091
#% 305343
#% 333219
#% 417651
#% 443134
#% 499656
#% 529173
#% 1273727
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289235
#* Graph theoretical characterization and computation of answer sets
#@ Thomas Linke
#t 2001
#c 11
#% 77167
#% 95339
#% 167641
#% 217007
#% 318419
#% 417651
#% 499509
#% 499512
#% 499927
#% 529173
#% 544776
#! We give a graph theoretical characterization of answer sets of normal logic programs. We show that there is a one-to-one correspondence between answer sets and a special, non-standard graph coloring of so-called block graphs of logic programs. This leads us to an alternative implementation paradigm to compute answer sets, by computing non-standard graph colorings. Our approach is rule-based and not atom-based like most of the currently known methods. We present an implementation for computing answer sets which works on polynomial space.

#index 1289236
#* A framework for declarative update specifications in logic programs
#@ Thomas Eiter;Michael Fink;Giuliana Sabbatini;Hans Tompits
#t 2001
#c 11
#% 247421
#% 283126
#% 305347
#% 389834
#% 553834
#! Recently, several approaches for updating knowledge bases represented as logic programs have been proposed. In this paper, we present a generic framework for declarative specifications of update policies, which is built upon such approaches. It extends the LUPS language for update specifications and incorporates the notion of events into the framework. An update policy allows an agent to flexibly react upon new information, arriving as an event, and perform suitable changes of its knowledge base. The framework compiles update policies to logic programs by means of generic translations, and can be instantiated in terms of different concrete update approaches. It thus provides a flexible tool for designing adaptive reasoning agents.

#index 1289237
#* Abduction in logic programming: a new definition and an abductive procedure based on rewriting
#@ Fangzhen Lin;Jia-Huai You
#t 2001
#c 11
#% 60502
#% 77147
#% 90824
#% 101945
#% 116296
#% 125134
#% 417651
#% 529166
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289238
#* Context-specific sign-propagation in qualitative probabilistic networks
#@ Silja Renooij;Simon Parsons;Linda C. Van Der Gaag
#t 2001
#c 11
#% 89748
#% 496082
#% 1650328
#% 1650644
#% 1650767
#! Qualitative probabilistic networks represent probabilistic influences between variables. Due to the level of representation detail provided, knowledge about influences that hold only in specific contexts cannot be expressed. The results computed from a qualitative network, as a consequence, can be quite weak and uninformative. We extend the basic formalism of qualitative probabilistic networks by providing for the inclusion of context-specific information about influences and show that exploiting this information upon inference has the ability to forestall unnecessarily weak results.

#index 1289239
#* Max-norm projections for factored MDPs
#@ Carlos Guestrin;Daphne Koller;Ronald Parr
#t 2001
#c 11
#% 75936
#% 203598
#% 214028
#% 224762
#% 289947
#% 363744
#% 408680
#% 496267
#% 527994
#! Markov Decision Processes (MDPs) provide a coherent mathematical framework for planning under uncertainty. However, exact MDP solution algorithms require the manipulation of a value function, which specifies a value for each state in the system. Most real-world MDPs are too large for such a representation to be feasible, preventing the use of exact MDP algorithms. Various approximate solution algorithms have been proposed, many of which use a linear combination of basis functions as a compact approximation to the value function. Almost all of these algorithms use an approximation based on the (weighted) L2-norm (Euclidean distance); this approach prevents the application of standard convergence results for MDP algorithms, all of which are based on max-norm. This paper makes two contributions. First, it presents the first approximate MDP solution algorithms - both value and policy iteration - that use max-norm projection, thereby directly optimizing the quantity required to obtain the best error bounds. Second, it shows how these algorithms can be applied efficiently in the context of factored MDPs, where the transition model is specified using a dynamic Bayesian network.

#index 1289240
#* Solving factored MDPs via non-homogeneous partitioning
#@ Kee-Eung Kim;Thomas Dean
#t 2001
#c 11
#% 75936
#% 178906
#% 203598
#% 318485
#% 393786
#% 496114
#% 496267
#% 713306
#% 1290041
#% 1650297
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289241
#* Symbolic dynamic programming for first-order MDPs
#@ Craig Boutilier;Ray Reiter;Bob Price
#t 2001
#c 11
#% 117869
#% 233132
#% 284106
#% 314843
#% 342119
#% 363744
#% 393786
#% 529345
#% 644560
#% 1290146
#% 1650297
#! We present a dynamic programming approach for the solution of first-order Markov decisions processes. This technique uses an MDP whose dynamics is represented in a variant of the situation calculus allowing for stochastic actions. It produces a logical description of the optimal value function and policy by constructing a set of first-order formulae that minimally partition state space according to distinctions made by the value function and policy. This is achieved through the use of an operation known as decision-theoretic regression. In effect, our algorithm performs value iteration without explicit enumeration of either the state or action spaces of the MDP. This allows problems involving relational fluents and quantification to be solved without requiring explicit state space enumeration or conversion to propositional form.

#index 1289242
#* Adaptive control of acyclic progressive processing task structures
#@ Stéphane Cardon;Abdel-Illah Mouaddib;Shlomo Zilberstein;Richard Washington
#t 2001
#c 11
#% 91210
#% 495761
#% 1271888
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289243
#* An improved grid-based approximation algorithm for POMDPs
#@ Rong Zhou;Eric A. Hansen
#t 2001
#c 11
#% 92301
#% 496114
#% 544786
#% 1271823
#% 1478842
#% 1478843
#% 1650344
#% 1650588
#% 1650702
#! Although a partially observable Markov decision process (POMDP) provides an appealing model for problems of planning under uncertainty, exact algorithms for POMDPs are intractable. This motivates work on approximation algorithms, and grid-based approximation is a widely-used approach. We describe a novel approach to grid-based approximation that uses a variable-resolution regular grid, and show that it outperforms previous grid-based approaches to approximation.

#index 1289244
#* Weakening the commensurability hypothesis in possibilistic qualitative decision theory
#@ Adriana Zapico
#t 2001
#c 11
#% 315415
#% 418172
#% 496101
#% 1478741
#% 1650287
#% 1650578
#! Models for Qualitative Decision under Uncertainty assuming that uncertainty is of possibilistic nature have been proposed in 1990's. In them, as in the classical approach of Expected Utility Theory, two alternatives emerge: à la Von Neumann and Morgenstern (VNM) or à la Savage. In the first one, uncertainty and preferences on consequences are measured on finite scales. Decisions are ranked in terms of the ranking induced, on their associated possibility distributions on consequences, by qualitative utility functions. To define these utilities, an hypothesis of commensurability, i.e. the existence of an onto order-preserving mapping h linking both scales of uncertainty and preference, is assumed. This hypothesis forces us to restrict to decision problems where the cardinality of the uncertainty values set is greater than or equal to the cardinality of the preference set. This point has been attacked in the possibilistic à la Savage approach, but as far as we know, it is an open question in the qualitative VNM approach. As a first step to weaken the commensurability hypothesis in this model, the preference orderings resulting of applying the qualitative criteria without requiring h to be onto are characterized. These orderings may be not continuous, but they satisfy a relaxed continuity axiom.

#index 1289245
#* A fuzzy modal logic for belief functions
#@ Lluís Godo;Petr Hájek;Francesc Esteva
#t 2001
#c 11
#% 3034
#% 73571
#% 90371
#% 110373
#% 128607
#% 167544
#% 1650654
#! In this paper we introduce a new logical approach to reason explicitly about Dempster-Shafer belief functions. We adopt the following view: one just starts with Boolean formulas φ and a belief function on them; the belief of φ is taken to be the truth degree of the (fuzzy) proposition Bφ standing for "φ is believed" For our complete axiomatization (Hylbert-style) we use one of the possible definitions of belief, namely as probability of (modal) necessity. This enables us to define a logical system combining the modal logic S5 with an already proposed fuzzy logic approach to reason about probabilities. In particular, our fuzzy logic is the logic ŁΠ1/2 which puts Lukasiewicz and Product logics together.

#index 1289246
#* IBAL: a probabilistic rational programming language
#@ Avi Pfeffer
#t 2001
#c 11
#% 529345
#% 1478844
#% 1650326
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289247
#* Approximate inference for first-order probabilistic languages
#@ Hanna Pasula;Stuart Russell
#t 2001
#c 11
#% 44876
#% 89958
#% 98073
#% 217824
#% 266230
#% 495797
#% 529159
#% 711139
#% 1271907
#% 1272302
#% 1650326
#! A new, general approach is described for approximate inference in first-order probabilistic languages, using Markov chain Monte Carlo (MCMC) techniques in the space of concrete possible worlds underlying any given knowledge base. The simplicity of the approach and its lazy construction of possible worlds make it possible to consider quite expressive languages. In particular, we consider two extensions to the basic relational probability models (RPMs) defined by Koller and Pfeffer, both of which have caused difficulties for exact algorithms. The first extension deals with uncertainty about relations among objects, where MCMC samples over relational structures. The second extension deals with uncertainty about the identity of individuals, where MCMC samples over sets of equivalence classes of objects. In both cases, we identify types of probability distributions that allow local decomposition of inference while encoding possible domains in a plausible way. We apply our algorithms to simple examples and show that the MCMC approach scales well.

#index 1289248
#* Knowledge processing under information fidelity
#@ Wilhelm Rödder
#t 2001
#c 11
#% 44876
#% 73239
#% 250115
#% 295783
#% 403535
#% 443633
#% 1650809
#! XSPIRIT is a professional expert system-shell for knowledge acquisition, inference and response using conditional logic and probability. Composed conditionals on propositional variables with finite domain are the communication tool between the user and the knowledge base, making the process of acquisition, inference and query comfortable and intelligible. XSPIRIT allows partial rather than complete information about the knowledge domain and supplements missing parts by the principle of information fidelity. By virtue of evident temporary information, knowledge undergoes a well-defined adaptation process, respecting this principle again. The construction and transformation of probability distributions as developed here, allow acquired knowledge, remaining uncertainty and strength of inference to be measured in the information units [bit]. XSPIRIT allows large-scale applications with hundreds of composed conditionals and umpteen variables.

#index 1289249
#* Constraints as data: a new perspective on inferring probabilities
#@ Manfred Jaeger
#t 2001
#c 11
#% 73239
#% 1650595
#% 1650644
#% 1650809
#! We consider the problem of how an agent creates a discrete spatial representation from its continuous interactions with the environment. Such representation will be the minimal one that explains the experiences of the agent in the environment. In this ...

#index 1289251
#* Proceedings of the 17th international joint conference on Artificial intelligence - Volume 2
#@ 
#t 2001
#c 11

#index 1289252
#* Knowledge extraction from local function networks
#@ Kenneth McGarry;Stefan Wermter;John MacIntyre
#t 2001
#c 11
#% 170665
#% 252404
#% 361100
#% 637856
#% 1042868
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute to any output class. To address this we have developed an algorithm called LREX (for Local Rule EXtraction) which tackles these issues by extracting rules at two levels: hREX extracts rules by examining the hidden unit to class assignments while mREX extracts rules based on the input space to output space mappings. The rules extracted by our algorithm are compared and contrasted against a competing local rule extraction system. The central claim of this paper is that local function networks such as radial basis function (RBF) networks have a suitable architecture based on Gaussian functions that is amenable to rule extraction.

#index 1289253
#* Violation-guided learning for constrained formulations in neural-network time-series predictions
#@ Benjamin W. Wah;Minglun Qian
#t 2001
#c 11
#% 174773
#% 534482
#% 534488
#% 661307
#% 1860422
#! Time-series predictions by artificial neural networks (ANNs) are traditionally formulated as unconstrained optimization problems. As an unconstrained formulation provides little guidance on search directions when a search gets stuck in a poor local minimum, we have proposed recently to use a constrained formulation in order to use constraint violations to provide additional guidance. In this paper, we formulate ANN learning with cross-validations for time-series predictions as a non-differentiable nonlinear constrained optimization problem. Based on our theory of Lagrange multipliers for discrete constrained optimization, we propose an efficient learning algorithm, called violation guided back-propagation (VGBP), that computes an approximate gradient using back-propagation (BP), that introduces annealing to avoid blind acceptance of trial points, and that applies a relax-and-tighten (R&T) strategy to achieve faster convergence. Extensive experimental results on well-known benchmarks, when compared to previous work, show one to two orders-of-magnitude improvement in prediction quality, while using less weights.

#index 1289254
#* Mobile robot learning of delayed response tasks through event extraction: a solution to the road sign problem and beyond
#@ Fredrik Linåker;Henrik Jacobsson
#t 2001
#c 11
#% 103423
#% 270023
#% 321578
#% 633874
#! We show how event extraction can be used for handling delayed response tasks with arbitrary delay periods between the stimulus and the cue for response. Our approach is based on a number of information processing levels, where the lowest level works on raw time-stepped based sensory data. This data is classified using an unsupervised clustering mechanism. The second level works on this classified data, but still on the individual time-step basis. An event extraction mechanism detects and signals transitions between classes; this forms the basis for the third level. As this level only is updated when events occur, it is independent of the time-scale of the lower level interaction. We also sketch how an event filtering mechanism could be constructed which discards irrelevant data from the event stream. Such a mechanism would output a fourth level representation which could be used for delayed response tasks where irrelevant, or distracting, events could occur during the delay.

#index 1289255
#* NORN finance forecaster: a neural oscillatory-based recurrent network for finance prediction
#@ Raymond S. T. Lee;James N. K. Liu
#t 2001
#c 11
#% 204714
#% 360500
#% 449561
#% 1860660
#! Financial prediction is so far the most important applications in contemporary scientific study. In this paper, we present a fully integrated stock prediction system - NORN Finance Forecaster - A Neural Oscillatory-based Recurrent Network for finance prediction system to provide both a) Long-term trend prediction, and b) Short-term stock price prediction. One of the major characteristics of the proposed system is the automation of the conventional financial technical analysis technique such as market pattern analysis via NOEGM (Neural Oscillatory-based Elastic Graph Matching) model and its integration with the Time-difference recurrent neural network model. This will provide a fully integrated and automated tool for analytic and investigation of stock investment. From the implementation point of view, the stock pricing information of 33 major Hong Kong stocks in the period of 1990 to 1999 are being adopted for system training and evaluation. As compared with contemporary neural prediction model, the proposed system has achieved challenging results in terms of efficiency and accuracy.

#index 1289256
#* A general updating rule for discrete hopfield-type neural network with delay
#@ Shenshan Qiu;Eric C. C. Tsang;Daniel S. Yeung;Xizhao Wang
#t 2001
#c 11
#% 36792
#% 204712
#% 219714
#% 474885
#% 1860232
#% 1860537
#! In this paper, the Hopfield neural network with delay (HNND) is studied from the standpoint of regarding it as an optimized computational model. Two general updating rules for network with delay (GURD) are given based on Hopfield-type neural networks with delay for optimization problems and characterized dynamic thresholds. It is proved that in any sequence of updating rule modes, the GURD monotonously converges to a stable state of the network. The diagonal elements of the connection matrix are shown to have an important influence on the convergence process, and they represent the relationship of the local maximum value of the energy function with the stable states of the networks. All ordinary DHNN algorithms are instances of GURD. It can be shown that the convergence conditions of GURD may be relaxed in the context of applications, for instance, the condition of nonnegative diagonal elements of the connection matrix can be removed from the original convergence theorem. New updating rule mode and restrictive conditions can guarantee the network to achieve a local maximum of the energy function.

#index 1289257
#* Genetic algorithm based selective neural network ensemble
#@ Zhi-Hua Zhou;Jian-Xin Wu;Yuan Jiang;Shi-Fu Chen
#t 2001
#c 11
#% 136350
#% 209021
#% 304515
#% 369236
#% 386907
#% 443616
#% 593646
#% 1756595
#% 1780765
#! Neural network ensemble is a learning paradigm where several neural networks are jointly used to solve a problem. In this paper, the relationship between the generalization ability of the neural network ensemble and the correlation of the individual neural networks is analyzed, which reveals that ensembling a selective subset of individual networks is superior to ensembling all the individual networks in some cases. Therefore an approach named GASEN is proposed, which trains several individual neural networks and then employs genetic algorithm to select an optimum subset of individual networks to constitute an ensemble. Experimental results show that, comparing with a popular ensemble approach, i.e. averaging all, and a theoretically optimum selective ensemble approach, i.e. enumerating, GASEN has preferable performance in generating ensembles with strong generalization ability in relatively small computational cost.

#index 1289258
#* Neural logic network learning using genetic programming
#@ Chew Lim Tan;Henry Wai Kit Chia
#t 2001
#c 11
#% 49557
#% 124073
#% 160857
#% 167411
#% 167670
#% 204433
#% 204434
#% 362240
#% 385564
#% 1248873
#% 1860145
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289259
#* Sensitivity analysis of multilayer perceptron
#@ Daniel S. Yeung;Xuequan Sun;Xiaoqin Zeng
#t 2001
#c 11
#% 111338
#% 1776265
#% 1862550
#! Sensitivity analysis of neural network is useful for network design. Piché used a stochastic model to describe the Multilayer Perceptron (MLP), but it doesn't match the true MLP closely, and too severe limitations are imposed on both input and weight perturbations. This paper attempts to generalize Piché's stochastic model of MLP, and derive an universal expression of MLP's sensitivity for all sigmoidal activation functions, without any restriction on input and output perturbations. The effects of network design parameters such as the number of layer, the number of neuron per layer and the chosen activation function are analyzed, and they provide useful information for network design decision-making. Furthermore, we use our sensitivity expression to design MLP for a given application. It can help to design the network structure, as well as the training of MLP.

#index 1289260
#* Reinforcement learning in distributed domains: beyond team games
#@ David H. Wolpert;Joseph Sill;Kagan Tumer
#t 2001
#c 11
#% 9240
#% 53981
#% 214188
#% 265781
#% 266286
#% 302091
#% 305072
#% 305088
#% 384911
#% 465913
#% 529342
#% 798509
#% 1272286
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289261
#* Fast concurrent reinforcement learners
#@ Bikramjit Banerjee;Sandip Sen;Jing Peng
#t 2001
#c 11
#% 203613
#% 271764
#% 304312
#% 384911
#% 465913
#% 496735
#% 1150919
#! When several agents learn concurrently, the payoff received by an agent is dependent on the behavior of the other agents. As the other agents learn, the reward of one agent becomes non-stationary. This makes learning in multiagent systemsmore difficult than single-agent learning. A few methods, how-ever, are known to guarantee convergence to equilibrium in the limit in such systems. In this paper we experimentally study one such technique, the minimax-Q, in a competitive domain and prove its equivalence with another well-known method for competitive domains. We study the rate of convergence of minimax-Q and investigate possible ways for increasing the same. We also present a variant of the algorithm, minimax-SARSA, and prove its convergence to minimax-Q values under appropriate conditions. Finally we show that this new algorithm performs better than simple minimax-Q in a general-sum domain as well.

#index 1289262
#* Multi-agent systems by incremental gradient reinforcement learning
#@ Alain Dutech;Olivier Buffet;François Charpillet
#t 2001
#c 11
#% 213480
#% 271043
#% 334075
#% 355911
#% 384911
#% 418632
#% 418731
#% 465913
#% 528006
#% 659873
#% 782311
#! A new reinforcement learning (RL) methodology is proposed to design multi-agent systems. In the realistic setting of situated agents with local perception, the task of automatically building a coordinated system is of crucial importance. We use simple reactive agents which learn their own behavior in a decentralized way. To cope with the difficulties inherent to RL used in that framework, we have developed an incremental learning algorithm where agents face more and more complex tasks. We illustrate this general framework on a computer experiment where agents have to coordinate to reach a global goal.

#index 1289263
#* Robot weightlifting by direct policy search
#@ Michael T. Rosenstein;Andrew G. Barto
#t 2001
#c 11
#% 28142
#% 124691
#% 201257
#% 286423
#% 305081
#% 314843
#% 449561
#% 565539
#! This paper describes a method for structuring a robot motor learning task. By designing a suitably parameterized policy, we show that a simple search algorithm, along with biologically motivated constraints, offers an effective means for motor skill acquisition. The framework makes use of the robot counterparts to several elements found in human motor learning: imitation, equilibrium-point control, motor programs, and synergies. We demonstrate that through learning, coordinated behavior emerges from initial, crude knowledge about a difficult robot weightlifting task.

#index 1289264
#* OI-implication: soundness and refutation completeness
#@ Floriana Esposito;Nicola Fanizzi;Stefano Ferilli;Giovanni Semeraro
#t 2001
#c 11
#% 877
#% 26115
#% 45241
#% 67540
#% 136362
#% 288366
#% 289236
#% 302388
#% 382569
#% 384112
#% 466579
#% 1272180
#! Weakening implication by assuming the object identity bias allows for both a model-theoretical and a proof-theoretical definition of a novel and more manageable ordering relationship over clausal spaces. In this paper, we give two important results, namely the soundness and the refutation completeness (through a subsumption theorem) of the underlying derivation procedure, that make this relationship particularly appealing for inducing a generalization model for clausal search spaces.

#index 1289265
#* The levelwise version space algorithm and its application to molecular fragment finding
#@ Luc De Raedt;Stefan Kramer
#t 2001
#c 11
#% 109952
#% 152934
#% 178515
#% 216508
#% 248785
#% 248791
#% 280409
#% 300120
#% 420062
#% 420076
#% 420087
#% 438134
#% 464289
#% 464714
#% 496247
#% 558264
#! A tight integration of Mitchell's version space algorithm with Agrawal et al.'s Apriori algorithm is presented. The algorithm can be used to generate patterns that satisfy a variety of constraints on data. Constraints that can be imposed on patterns include the generality relation among patterns and imposing a minimum or a maximum frequency on data sets of interest. The theoretical framework is applied to an important application in chemo-informatics, i.e. that of finding fragments of interest within a given set of compounds. Fragments are linearly connected substructures of compounds. An implementation as well as preliminary experiments within the application are presented.

#index 1289266
#* Active learning for structure in Bayesian networks
#@ Simon Tong;Daphne Koller
#t 2001
#c 11
#% 44876
#% 101213
#% 197387
#% 297171
#% 528004
#% 1650279
#% 1650289
#! The task of causal structure discovery from empirical data is a fundamental problem in many areas. Experimental data is crucial for accomplishing this task. However, experiments are typically expensive, and must be selected with great care. This paper uses active learning to determine the experiments that are most informative towards uncovering the underlying structure. We formalize the causal learning task as that of learning the structure of a causal Bayesian network. We consider an active learner that is allowed to conduct experiments, where it intervenes in the domain by setting the values of certain variables. We provide a theoretical framework for the active learning problem, and an algorithm that actively chooses the experiments to perform based on the model learned so far. Experimental results show that active learning can substantially reduce the number of observations required to determine the structure of a domain.

#index 1289267
#* Probabilistic classification and clustering in relational data
#@ Ben Taskar;Eran Segal;Daphne Koller
#t 2001
#c 11
#% 44876
#% 232117
#% 266230
#% 282905
#% 420495
#% 466896
#% 495929
#% 496116
#% 568786
#% 729437
#% 1650318
#% 1650579
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289268
#* Adaptive web navigation for wireless devices
#@ Corin R. Anderson;Pedro Domingos;Daniel S. Weld
#t 2001
#c 11
#% 209662
#% 268082
#% 271129
#% 272821
#% 292169
#% 310543
#% 312874
#% 338308
#% 713666
#% 1273676
#% 1393581
#! Visitors who browse the web from wireless PDAs, cell phones, and pagers are frequently stymied by web interfaces optimized for desktop PCs. Simply replacing graphics with text and reformatting tables does not solve the problem, because deep link structures can still require minutes to traverse. In this paper we develop an algorithm, MINPATH, that automatically improves wireless web navigation by suggesting useful shortcut links in real time. MINPATH finds shortcuts by using a learned model of web visitor behavior to estimate the savings of shortcut links, and suggests only the few best links. We explore a variety of predictive models, including Naïve Bayes mixture models and mixtures of Markov models, and report empirical evidence that MINPATH finds useful shortcuts that save substantial navigational effort.

#index 1289269
#* Using text classifiers for numerical classification
#@ Sofus A. Macskassy;Haym Hirsh;Arunava Banerjee;Aynur A. Dayanik
#t 2001
#c 11
#% 136350
#% 165111
#% 262085
#% 318412
#% 376266
#% 458174
#% 465895
#% 466234
#% 1290045
#% 1499571
#! _cf_loadingtexthtml="";_cf_contextpath="";_cf_ajaxscriptsrc="/CFIDE/scripts/ajax";_cf_jsonprefix='//';_cf_clientid='3559BF9AB369D6AFD572F79412A5BBE8';Using text classifiers for numerical classification function settab() { var mytabs = ColdFusion.Layout.getTabLayout('citationdetails'); mytabs.on('tabchange', function(tabpanel,activetab) { document.cookie = 'picked=' + '1642212' + ',' + activetab.id; }) }function letemknow(){ ColdFusion.Window.show('letemknow');}function testthis(){alert('test');}function loadalert(){ alert("I am in the load alert"); }function loadalert2(){ alert("I am in the load alert2"); } google.load('visualization', '1', {packages:['orgchart']}); google.setOnLoadCallback(drawChart); function drawChart() { var data = new google.visualization.DataTable(); data.addColumn('string', 'Name'); data.addColumn('string', 'Manager'); data.addColumn('string', 'ToolTip'); data.addRows([ [{v:'0', f:'CCS for this Article

#index 1289270
#* Faster association rules for multiple relations
#@ Siegfried Nijssen;Joost Kok
#t 2001
#c 11
#% 232136
#% 550412
#! Several algorithms have already been implemented which combine association rules with first order logic formulas. Although this resulted in several usable algorithms, little attention was payed until recently to the efficiency of these algorithms. In this paper we present some new ideas to turn one important intermediate step in the process of discovering such rules, i.e. the discovery of frequent item sets, more efficient. Using an implementation that we coined FARMER, we show that indeed a speed-up is obtained and that, using these ideas, the performance is much more comparable to original association rule algorithms.

#index 1289271
#* A simple feature selection method for text classification
#@ Pascal Soucy;Guy W. Mineau
#t 2001
#c 11
#% 67565
#% 246831
#% 449588
#% 458379
#% 465754
#% 466101
#% 515676
#! In text classification most techniques use bag-of-words to represent documents. The main problem is to identify what words are best suited to classify the documents in such a way as to discriminate between them. Feature selection techniques are then needed to identify these words. The feature selection method presented in this paper is rather simple and computationally efficient. It combines a well known feature selection criterion, the information gain, and a new algorithm that selects and adds a feature to a bag-of-words if it does not occur too often with the features already in a small set composed of the best features selected so far for their high information gain. In brief, it tries to avoid considering features whose discrimination capability is sufficiently covered by already selected features, reducing in size the set of the features used to characterize the document set. This paper presents this feature selection method and its results, and how we have predetermined some of its parameters through experimentation.

#index 1289272
#* Link analysis, eigenvectors and stability
#@ Andrew Y. Ng;Alice X. Zheng;Michael I. Jordan
#t 2001
#c 11
#% 262061
#% 268079
#% 282905
#% 340932
#% 420495
#% 466574
#! The HITS and the PageRank algorithms are eigenvector methods for identifying "authoritative" or "influential" articles, given hyperlink or citation information. That such algorithms should give consistent answers is surely a desideratum, and in this paper, we address the question of when they can be expected to give stable rankings under small perturbations to the hyperlink patterns. Using tools from matrix perturbation theory and Markov chain theory, we provide conditions under which these methods are stable, and give specific examples of instability when these conditions are violated. We also briefly describe a modification to HITS that improves its stability.

#index 1289273
#* Active learning for class probability estimation and ranking
#@ Maytal Saar-Tsechansky;Foster Provost
#t 2001
#c 11
#% 697
#% 116165
#% 136350
#% 169717
#% 170649
#% 283138
#% 310503
#% 424997
#% 450951
#% 451056
#% 466086
#% 466095
#% 682135
#% 1272282
#% 1378224
#! For many supervised learning tasks it is very costly to produce training data with class labels. Active learning acquires data incrementally, at each stage using the model learned so far to help identify especially useful additional data for labeling. Existing empirical active learning approaches have focused on learning classifiers. However, many applications require estimations of the probability of class membership, or scores that can be used to rank new cases. We present a new active learning method for class probability estimation (CPE) and ranking. BOOTSTRAP-LV selects new data for labeling based on the variance in probability estimates, as determined by learning multiple models from bootstrap samples of the existing labeled data. We show empirically that the method reduces the number of data items that must be labeled, across a wide variety of data sets. We also compare BOOTSTRAP-LV with UNCERTAINTY SAMPLING, an existing active learning method designed to maximize classification accuracy. The results show that BOOTSTRAP-LV dominates for CPE. Surprisingly it also often is preferable for accelerating simple accuracy maximization.

#index 1289274
#* Learning on the phase transition edge
#@ Alessandro Serra;Attilio Giordana;Lorenza Saitta
#t 2001
#c 11
#% 36358
#% 175367
#% 376266
#% 425004
#% 449508
#% 466063
#% 496106
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289275
#* A simple additive re-weighting strategy for improving margins
#@ Fabio Aiolli;Alessandro Sperduti
#t 2001
#c 11
#% 476717
#% 857086
#% 1809314
#! We present a sample re-weighting scheme inspired by recent results in margin theory. The basic idea is to add to the training set replicas of samples which are not classified with a sufficient margin. We prove the convergence of the input distribution obtained in this way. As study case, we consider an instance of the scheme involving a 1-NN classifier implementing a Vector Quantization algorithm that accommodates tangent distance models. The tangent distance models created in this way have shown a significant improvement in generalization power with respect to the standard tangent models. More-over, the obtained models were able to outperform state of the art algorithms, such as SVM.

#index 1289276
#* Knowledge analysis on process models
#@ Jihie Kim;Yolanda Gil
#t 2001
#c 11
#% 35075
#% 44836
#% 79993
#% 194651
#% 262699
#% 283115
#% 529176
#% 1272173
#% 1478786
#! Helping end users build and check process models is a challenge for many science and engineering fields. Many AI researchers have investigated useful ways of verifying and validating knowledge bases for ontologies and rules, but it is not easy to directly apply them to checking process models. Other techniques developed for checking and refining planning knowledge tend to focus on automated plan generation rather than helping users author process information. In this paper, we propose a complementary approach which helps users author and check process models. Our system, called KANAL, relates pieces of information in process models among themselves and to the existing KB, analyzing how different pieces of input are put together to achieve some effect. It builds interdependency models from this analysis and uses them to find errors and propose fixes. Our initial evaluation shows that KANAL was able to find most of the errors in the process models and suggest useful fixes including the fixes that directly point to the sources of the errors.

#index 1289277
#* Integrating expectations from different sources to help end users acquire procedural knowledge
#@ Jim Blythe
#t 2001
#c 11
#% 55936
#% 134110
#% 134111
#% 197428
#% 283115
#% 283116
#% 320415
#% 1499535
#! Role-limiting approaches using explicit theories of problem-solving have been successful for acquiring knowledge from domain experts. However most systems using this approach do not support acquiring procedural knowledge, only instance and type information. Approaches using interdependencies among different pieces of knowledge have been successful for acquiring procedural knowledge, but these approaches usually do not provide all the support that domain experts require. We show how the two approaches can be combined in such a way that each benefits from information provided by the other. We extend the role-limiting approach with a knowledge acquisition tool that dynamically generates questions for the user based on the problem solving method. This allows a more flexible interaction pattern. When users add knowledge, this tool generates expectations for the procedural knowledge that is to be added. When these procedures are refined, new expectations are created from interdependencymodels that in turn refine the information used by the system. The implemented KA tool provides broader support than previously implemented systems. Preliminary evaluations in a travel planning domain show that users who are not programmers can, with little training, specify executable procedural knowledge to customize an intelligent system.

#index 1289278
#* R-MAX: a general polynomial time algorithm for near-optimal reinforcement learning
#@ Ronen I. Brafman;Moshe Tennenholtz
#t 2001
#c 11
#% 90041
#% 135414
#% 160859
#% 251784
#% 314841
#% 384911
#% 465913
#% 466075
#% 495933
#% 1272286
#% 1272320
#! R-MAX is a simple model-based reinforcement learning algorithm which can attain near-optimal average reward in polynomial time. In R-MAX, the agent always maintains a complete, but possibly inaccurate model of its environment and acts based on the optimal policy derived from this model. The model is initialized in an optimistic fashion: all actions in all states return the maximal possible reward (hence the name). During execution, the model is updated based on the agent's observations. R-MAX improves upon several previous algorithms: (1) It is simpler and more general than Kearns and Singh's E3 algorithm, covering zerosum stochastic games. (2) It has a built-in mechanism for resolving the exploration vs. exploitation dilemma. (3) It formally justifies the "optimism under uncertainty" bias used in many RL algorithms. (4) It is much simpler and more general than Brafman and Tennenholtz's LSG algorithmfor learning in single controller stochastic games. (5) It generalizes the algorithm by Monderer and Tennenholtz for learning in repeated games. (6) It is the only algorithm for near-optimal learning in repeated games known to be polynomial, providing a much simpler and more efficient alternative to previous algorithms by Banos and by Megiddo.

#index 1289279
#* From Q(λ) to average Q-learning: efficient implementation of an asymptotic approximation
#@ Frédérick Garcia;Florent Serre
#t 2001
#c 11
#% 83929
#% 203602
#% 226878
#% 271764
#% 292228
#% 299643
#% 363744
#% 393786
#% 449561
#% 465923
#% 562959
#% 1272366
#! Q(λ) is a reinforcement learning algorithm that combines Q-learning and TD(λ). Online implementations of Q(λ) that use eligibility traces have been shown to speed basic Q-learning. In this paper we present an asymptotic analysis of Watkins' Q(λ) with accumulative eligibility traces. We first introduce an asymptotic approximation of Q(λ) that appears to be a gain matrix variant of basic Q-learning. Using the ODE method, we then determine an optimal gain matrix for Q-learning that maximizes its rate of convergence toward the optimal value function Q*. The similarity between this optimal gain and the asymptotic gain of Q(λ) explains the relative efficiency of the latter for (λ) 0. Furthermore, by minimizing the difference between these two gains, optimal values for the λ parameter and the decreasing learning rates can be determined. This optimal λ strongly depends on the exploration policy during learning. A robust approximation of these learning parameters leads to the definition of a new efficient algorithm called AQ-learning (Average Q-learning), that shows a close resemblance to Schwartz' R-learning. Our results have been demonstrated through numerical simulations.

#index 1289280
#* Exploiting multiple secondary reinforcers in policy gradient reinforcement learning
#@ Greg Grudic;Lyle Ungar
#t 2001
#c 11
#% 36160
#% 124687
#% 195263
#% 305081
#% 384911
#% 393786
#% 466399
#% 527987
#% 531445
#% 565539
#% 1272286
#! Most formulations of Reinforcement Learning depend on a single reinforcement reward value to guide the search for the optimal policy solution. If observation of this reward is rare or expensive, converging to a solution can be impractically slow. One way to exploit additional domain knowledge is to use more readily available, but related quantities as secondary reinforcers to guide the search through the space of all policies. We propose a method to augment Policy Gradient Reinforcement Learning algorithms by using prior domain knowledge to estimate desired relative levels of a set of secondary reinforcement quantities. RL can then be applied to determine a policy which will establish these levels. The primary reinforcement reward is then sampled to calculate a gradient for each secondary reinforcer, in the direction of increased primary reward. These gradients are used to improve the estimate of relative secondary values, and the process iterates until reward is maximized. We prove that the algorithm converges to a local optimum in secondary reward space, and that the rate of convergence of the performance gradient estimate in secondary reward space is independent of the size of the state space. Experimental results demonstrate that the algorithm can converge many orders of magnitude faster than standard policy gradient formulations.

#index 1289281
#* The foundations of cost-sensitive learning
#@ Charles Elkan
#t 2001
#c 11
#% 191910
#% 214236
#% 424997
#% 458361
#% 464280
#% 466760
#% 682135
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289282
#* Mining soft-matching rules from textual data
#@ Un Yong Nahm;Raymond J. Mooney
#t 2001
#c 11
#% 67565
#% 136350
#% 209023
#% 248857
#% 280436
#% 288885
#% 318412
#% 481290
#% 529678
#% 584888
#% 786497
#! Text mining concerns the discovery of knowledge from unstructured textual data. One important task is the discovery of rules that relate specific words and phrases. Although existing methods for this task learn traditional logical rules, soft-matching methods that utilize word-frequency information generally work better for textual data. This paper presents a rule induction system, TEXTRISE, that allows for partial matching of text-valued features by combining rule-based and instance-based learning. We present initial experiments applying TEXTRISE to corpora of book descriptions and patent documents retrieved from the web and compare its results to those of traditional rule and instance based methods.

#index 1289283
#* Bridging the lesson distribution gap
#@ David W. Aha;Rosina Weber;Héctor Muñoz-Avila;Leonard A. Breslow;Kalyan Moy Gupta
#t 2001
#c 11
#% 126842
#% 283308
#% 421389
#% 426885
#! Many organizations employ lessons learned (LL) processes to collect, analyze, store, and distribute, validated experiential knowledge (lessons) of their members that, when reused, can substantially improve organizational decision processes. Unfortunately, deployed LL systems do not facilitate lesson reuse and fail to bring lessons to the attention of the users when and where they are needed and applicable (i.e., they fail to bridge the lesson distribution gap). Our approach for solving this problem, named monitored distribution, tightly integrates lesson distribution with these decision processes. We describe a case-based implementation of monitored distribution (ALDS) in a plan authoring tool suite (HICAP). We evaluate its utility in a simulated military planning domain. Our results show that monitored distribution can significantly improve plan evaluation measures for this domain.

#index 1289284
#* minimizing dialog length in interactive case-based reasoning
#@ David McSherry
#t 2001
#c 11
#% 90157
#% 136350
#% 258186
#% 418155
#% 449588
#% 490294
#% 490619
#% 494593
#% 742781
#% 743911
#! Decision trees induced from stored cases are increasingly used to guide case retrieval in case-based reasoning (CBR) systems for fault diagnosis and product recommendation. In this paper, we refer to such a decision tree as an identification tree when, as often in practice, each of the faults to be identified, or available products, is represented by a single case in the case library. We evaluate common splitting criteria for decision trees in the special case of identification trees. We present simplified versions of those that are most effective in reducing the average path length of an identification tree, or equivalently, the average number of questions asked when the tree is used for problem solving. We also identify conditions in which no such reduction is possible with any splitting criterion.

#index 1289285
#* SiN: integrating case-based reasoning with task decomposition
#@ Héctor Muñoz-Avila;David W. Aha;Dana S. Nau;Rosina Weber;Len Breslow;Fusun Yamal
#t 2001
#c 11
#% 55921
#% 179879
#% 179932
#% 362441
#% 494428
#% 495942
#% 1272167
#% 1289205
#% 1478935
#% 1478941
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289286
#* A distributed case-based query rewriting
#@ Maurizio Panti;Luca Spalazzi;Loris Penserini
#t 2001
#c 11
#% 116303
#% 229827
#% 237189
#% 457172
#% 464717
#% 480150
#% 588691
#! In literature, the mediator architecture has been proposed for taking information from distributed, heterogeneous, and often dynamic sources and making them work together as a whole. In this paper we propose a distributed case-based approach for the main problem of a mediator, i.e. rewriting queries according to mediator's schema. According to this approach we use a case memory as mediator's schema. Therefore, such a schema is not static (as in other systems) but is dynamically updated through the cooperation with information sources and other mediators, strongly influenced by the queries submitted by a consumer. From the analysis of different cooperation strategies arises that it is more efficient and effective for a mediator to directly cooperate with information sources, when the sources are few. Otherwise, it is more efficient to cooperate with other mediators.

#index 1289287
#* Using case-base data to learn adaptation knowledge for design
#@ Jacek Jarmulak;Susan Craw;Ray Rowe
#t 2001
#c 11
#% 103914
#% 131984
#% 490457
#% 490468
#% 494443
#% 1499567
#! One advantage of Case-Based Reasoning (CBR) is the relative ease of constructing and maintaining CBR systems, especially as a number of commercial CBR tools are available. However, there are areas of CBR that current tools have not yet addressed. One of these is easing or automating the acquisition of adaptation knowledge. Since tasks like design or planning typically require a significant amount of adaptation, CBR systems for these tasks still do not fully benefit from CBR's promise of reducing the development effort. To address this, we have developed several "knowledge-light" methods for learning adaptation knowledge from the cases in the case-base. These methods perform substitutional adaptation, for both nominal and numerical values, and are suitable for decomposable design problems, in particular formulation and configuration. Tests performed on a tablet formulation domain show promising results. The automatic adaptation methods we present can easily be incorporated in general-purpose CBR tools, thus further contributing to reducing the cost of CBR systems.

#index 1289288
#* Rational and convergent learning in stochastic games
#@ Michael Bowling;Manuela Veloso
#t 2001
#c 11
#% 240768
#% 266286
#% 305081
#% 307102
#% 384911
#% 418731
#% 464281
#% 465913
#% 528018
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289289
#* Multi-agent influence diagrams for representing and solving games
#@ Daphne Koller;Brian Milch
#t 2001
#c 11
#% 34262
#% 70370
#% 138515
#% 176299
#% 284811
#% 527993
#% 527999
#% 528021
#% 1650620
#% 1650767
#! The traditional representations of games using the extensive form or the strategic (normal) form obscure much of the structure that is present in real-world games. In this paper, we propose a new representation language for general multiplayer games--multi-agent influence diagrams (MAIDs). This representation extends graphical models for probability distributions to a multi-agent decision-making context. MAIDs explicitly encode structure involving the dependence relationships among variables. As a consequence, we can define a notion of strategic relevance of one decision variable to another: D′ is strategically relevant to D if, to optimize the decision rule at D, the decision maker needs to take into consideration the decision rule at D′. We provide a sound and complete graphical criterion for determining strategic relevance. We then show how strategic relevance can be used to detect structure in games, allowing a large game to be broken up into a set of interacting smaller games, which can be solved in sequence. We show that this decomposition can lead to substantial savings in the computational cost of finding Nash equilibria in these games.

#index 1289290
#* Multiagent coordination by stochastic cellular automata
#@ T. D. Barfoot;G. M. T. D'Eleuterio
#t 2001
#c 11
#% 76731
#% 154041
#% 466692
#% 840585
#! A coordination mechanism for a system of sparsely communicating agents is described. The mechanism is based on a stochastic version of cellular automata. A parameter similar to a temperature can be tuned to change the behaviour of the system. It is found that the best coordination occurs near a phase transition between order and chaos. Coordination does not rely on any particular structure of the connections between agents, thus it may be applicable to a large array of sparsely communicating mobile robots.

#index 1289291
#* Identifying the scope of modeling for time-critical multiagent decision-making
#@ Sanguk Noh;Piotr J. Gmytrasiewicz
#t 2001
#c 11
#% 107169
#% 205385
#% 271052
#% 423984
#% 431493
#% 431527
#% 496268
#! Decision-making in multiagent settings requires significant computational resources. Agents need to model each other to decide how to coordinate - this sometimes may require solving nested models of many other agents and may be impractical to perform in an acceptable time. In this paper, we investigate ways in which the agents can be equipped with flexible decision-making procedures to allow multiagent decision-making under time pressure. One of the techniques we implemented uses iterative deepening algorithm guided by performance profiles generated offline. When the interaction involves many agents, the algorithm iteratively enhances the quality of coordinated decision-making by incrementally adding the levels of nesting considered, but with the additional penalty of increased running time. To identify the appropriate scope of modeling online we use the concept of urgency which represents cost of delaying decisions. We validate our framework with experiments in a simulated anti-air defense domain. The contribution of our framework is that it endows our autonomous agents with flexibility to cope with time pressure in complex multiagent settings.

#index 1289292
#* A layered brain architecture for synthetic creatures
#@ Damian Isla;Robert Burke;Marc Downie;Bruce Blumberg
#t 2001
#c 11
#% 31686
#% 97619
#% 100336
#% 124584
#% 173183
#% 196930
#% 213566
#% 245218
#% 279823
#% 302076
#% 395698
#% 436429
#% 702594
#! This paper describes a new layered brain architecture for simulated autonomous and semi-autonomous creatures that inhabit graphical worlds. The main feature of the brain is its division into distinct systems, which communicate through common access to an internal mental blackboard. The brain was designed to encourage experimentation with various systems and architectures. It has so far proven flexible enough to accommodate research advancing in a number of different directions by a small team of researchers.

#index 1289293
#* Behavior planning for a reflexive agent
#@ Berardina De Carolis;Catherine Pelachaud;Isabella Poggi;Fiorella de Rosis
#t 2001
#c 11
#% 173276
#% 238395
#% 272909
#% 330273
#% 330277
#% 330278
#% 332673
#% 740937
#% 936987
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289294
#* Rational competitive analysis
#@ Moshe Tennenholtz
#t 2001
#c 11
#% 106121
#% 131240
#% 189575
#% 261358
#% 301796
#! Much work in computer science has adopted competitive analysis as a tool for decision making under uncertainty. In this work we extend competitive analysis to the context of multi-agent systems. Unlike classical competitive analysis where the behavior of an agent's environment is taken to be arbitrary, we consider the case where an agent's environment consists of other agents. These agents will usually obey some (minimal) rationality constraints. This leads to the definition of rational competitive analysis. We introduce the concept of rational competitive analysis, and initiate the study of competitive analysis for multi-agent systems. We also discuss the application of rational competitive analysis to the context of bidding games, as well as to the classical oneway trading problem.

#index 1289295
#* Learning procedural knowledge to better coordinate
#@ Andrew Garland;Richard Alterman
#t 2001
#c 11
#% 156189
#% 168280
#% 215532
#% 257043
#% 275427
#% 275432
#% 431505
#% 449586
#% 451052
#% 711208
#% 1272316
#% 1275276
#! A fundamental difficulty faced by groups of agents that work together is how to efficiently coordinate their efforts. This paper presents techniques that allow heterogeneous agents to more efficiently solve coordination problems by acquiring procedural knowledge. In particular, each agent autonomously learns coordinated procedures that reflect her contributions towards successful past joint behavior. Empirical results validate the significant benefits of coordinated procedures.

#index 1289296
#* Fair imposition
#@ Yoav Shoham;Moshe Tennenholtz
#t 2001
#c 11
#% 92695
#% 122889
#% 181622
#% 233131
#% 233134
#% 495925
#% 496094
#% 496250
#% 529664
#! We introduce a new notion, related to auctions and mechanism design, called fair imposition. In this setting a center wishes to fairly and efficiently allocate tasks among a set of agents, not knowing their cost structure. As in the study of auctions, the main abstacle to overcome is the self-interest of the agents, which will in general cause them to hide their true costs. Unlike the auction setting, however, here the center has the power to impose arbitrary behavior on the agents, and furthermore wishes to distribute the cost as fairly as possible among them. We define the problem precisely, present solution criteria for these problems (the central of which is called k-efficiency), and present both positive results (in the form of concrete protocols) and negative results (in the form of impossibility theorems) concerning these criteria.

#index 1289297
#* Robust multi-unit auction protocol against false-name bids
#@ Makoto Yokoo;Yuko Sakurai;Shigeo Matsubara
#t 2001
#c 11
#% 283057
#% 301572
#% 496094
#% 496250
#% 529175
#% 635935
#% 660248
#% 978268
#! This paper presents a new multi-unit auction protocol (IR protocol) that is robust against false-name bids. Internet auctions have become an integral part of Electronic Commerce and a promising field for applying agent and Artificial Intelligence technologies. Although the Internet provides an excellent infrastructure for executing auctions, the possibility of a new type of cheating called false-name bids has been pointed out. A false-name bid is a bid submitted under a fictitious name. A protocol called LDS has been developed for combinatorial auctions of multiple different items and has proven to be robust against false-name bids. Although we can modify the LDS protocol to handle multi-unit auctions, in which multiple units of an identical item are auctioned, the protocol is complicated and requires the auctioneer to carefully predetermine the combination of bundles to obtain a high social surplus or revenue. For the auctioneer, our newly developed IR protocol is easier to use than the LDS, since the combination of bundles is automatically determined in a flexible manner according to the declared evaluation values of agents. The evaluation results show that the IR protocol can obtain a better social surplus than that obtained by the LDS protocol.

#index 1289298
#* Bundle design in robust combinatorial auction protocol against false-name bids
#@ Makoto Yokoo;Yuko Sakurai;Shigeo Matsubara
#t 2001
#c 11
#% 252811
#% 265785
#% 283057
#% 301572
#% 314921
#% 314925
#% 496094
#% 496250
#% 529175
#% 635935
#% 660248
#% 978268
#! This paper presents a method for designing bundles in a combinatorial auction protocol that is robust against false-name bids. Internet auctions have become an integral part of Electronic Commerce and a promising field for applying AI technologies. However, the possibility of a new type of cheating called a false-name bid, i.e., a bid submitted under a fictitious name, has been pointed out. A protocol called Leveled Division Set (LDS) protocol that is robust against false-name bids has been developed. However, this protocol requires the auctioneer to define a leveled division set. A leveled division set is a series of division sets, where a division set is a set of divisions and a division is a combination of bundles of goods. We need to solve a very complicated optimization problem to construct a leveled division set in order to obtain a good social surplus. We have developed a heuristic method for overcoming this problem. In this method, we first find a good division with a winner determination algorithm, and then construct a leveled division set by using this division as a seed. Through a simulation, we showthat our method can obtain a social surplus that is very close to optimal.

#index 1289299
#* CABOB: a fast optimal algorithm for combinatorial auctions
#@ Tuomas Sandholm;Subhash Suri;Andrew Gilpin;David Levine
#t 2001
#c 11
#% 155827
#% 266200
#% 267752
#% 301572
#% 302061
#% 314918
#% 314925
#% 378898
#% 496094
#% 496250
#% 529167
#% 529336
#% 659864
#! Combinatorial auctions where bidders can bid on bundles of items can lead to more economical allocations, but determining the winners is NP-complete and inapproximable. We present CABOB, a sophisticated search algorithm for the problem. It uses decomposition techniques, upper and lower bounding (also across components), elaborate and dynamically chosen bid ordering heuristics, and a host of structural observations. Experiments against CPLEX 7.0 show that CABOB is usually faster, never drastically slower, and in many cases drastically faster. We also uncover interesting aspects of the problem itself. First, the problems with short bids that were hard for the first-generation of specialized algorithms are easy. Second, almost all of the CATS distributions are easy, and become easier with more bids. Third, we test a number of random restart strategies, and show that they do not help on this problem because the run-time distribution does not have a heavy tail (at least not for CABOB).

#index 1289300
#* A software architecture for dynamically generated adaptive web stores
#@ Liliana Ardissono;Anna Goy;Giovanna Petrone;Marino Segnan
#t 2001
#c 11
#% 271063
#% 301650
#% 301889
#% 424007
#% 431490
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289301
#* Modularity and design in reactive intelligence
#@ Joanna J. Bryson;Lynn Andrea Stein
#t 2001
#c 11
#% 21145
#% 97619
#% 239778
#% 263023
#% 263059
#% 457023
#% 557220
#% 557222
#% 708759
#% 1051405
#! Software design is the hardest part of creating intelligent agents. Therefore agent architectures should be optimized as design tools. This paper presents an architectural synthesis between the three-layer architectures which dominate autonomous robotics and virtual reality, and a more agent-oriented approach to viewing behavior modules. We provide an approach, Behavior Oriented Design (BOD), for rapid, maintainable development. We demonstrate our approach by modeling primate learning.

#index 1289302
#* Reflective negotiating agents for real-time multisensor target tracking
#@ Leen-Kiat Soh;Costas Tsatsoulis
#t 2001
#c 11
#% 37906
#% 179004
#% 189700
#% 215525
#% 257048
#% 263126
#% 417563
#% 615048
#% 636344
#! In this paper we describe a multiagent system in which agents negotiate to allocate resources and satisfy constraints in a real-time environment of multisensor target tracking. The agents attempt to optimize the use of their own consumable resources while adhering to the global goal, i.e., accurate and effective multisensor target tracking. Agents negotiate based on different strategies which are selected and instantiated using case-based reasoning (CBR). Agents are also fully reflective in that they are aware of all their resources including system-level ones such as CPU allocation, and this allows them to achieve real-time behavior. We focus our discussion on multisensor target racking, case-based negotiation, and real-time behavior, and present experimental results comparing our methodology to ones using either no negotiation or using a static negotiation protocol.

#index 1289303
#* Stable strategies for sharing information among agents
#@ Rina Azoulay-Schwartz;Sarit Kraus
#t 2001
#c 11
#% 543219
#% 593736
#% 1272372
#% 1499474
#! Information sharing is important for different goals, such as sharing reputations of sellers among potential buyers, load balancing, solving technical problems, etc. In the short run, providing information as a response to queries is often unbeneficial. In the long run, mechanisms that enable beneficial stable strategies for information exchange can be found. This paper presents such mechanisms and specifies under which conditions it is beneficial to the agents to answer queries. We analyze a model of repeated encounters in which two agents ask each other queriesover time. We present different strategies that enable information exchange, and compare them according to the expected utility for the agents, and the conditions required for the cooperative equilibrium to exist.

#index 1289304
#* CAST: collaborative agents for simulating teamwork
#@ John Yen;Jianwen Yin;Thomas R. Ioerger;Michael S. Miller;Dianxiang Xu;Richard A. Volz
#t 2001
#c 11
#% 68239
#% 116625
#% 174161
#% 189698
#% 215532
#% 280042
#% 284267
#% 285540
#% 302099
#% 418058
#% 1272316
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289305
#* Market clearability
#@ Tuomas Sandholm;Subhash Suri
#t 2001
#c 11
#% 252811
#% 302061
#% 496094
#% 496250
#% 529336
#% 529664
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289306
#* On market-inspired approaches to propositional satisfiability
#@ William E. Walsh;Makoto Yokoo;Katsutoshi Hirayama;Michael P. Wellman
#t 2001
#c 11
#% 274891
#% 337838
#% 431523
#% 529187
#% 529517
#% 636335
#% 636338
#! We describe two market-inspired approaches to propositional satisfiability. Whereas a previous market-inspired approach exhibited extremely slow performance, we find that variations on the pricing method with a simplified market structure can improve performance significantly. We compare the performance of the new protocols with the previous market protocol and with the distributed breakout algorithm on benchmark 3-SAT problems. We identify a tradeoff between performance and economic realism in the new market protocols, and a tradeoff between performance and the degree of decentralization between the new market protocols and distributed breakout. We also conduct informal and experimental analyses to gain insight into the operation of price-guided search.

#index 1289307
#* Achieving budget-balance with Vickrey-based payment schemes in exchanges
#@ David C. Parkes;Jayant Kalagnanam;Marta Eso
#t 2001
#c 11
#% 267752
#% 274891
#% 314946
#% 420435
#% 496250
#! Generalized Vickrey mechanisms have received wide attention in the literature because they are efficient and strategy-proof, i.e. truthful bidding is optimal whatever the bids of other agents. However it is well-known that it is impossible for an exchange, with multiple buyers and sellers, to be efficient and budget-balanced, even putting strategy-proofness to one side. A market-maker in an efficient exchange must make more payments than it collects. We enforce budget-balance as a hard constraint, and explore payment rules to distribute surplus after an exchange clears to minimize distance to Vickrey payments. Different rules lead to different levels of truth-revelation and efficiency. Experimental and theoretical analysis suggest a simple Threshold scheme, which gives surplus to agents with payments further than a certain threshold value from their Vickrey payments. The scheme appears able to exploit agent uncertainty about bids from other agents to reduce manipulation and boost allocative efficiency in comparison with other simple rules.

#index 1289308
#* Agent-human interactions in the continuous double auction
#@ Rajarshi Das;James E. Hanson;Jeffrey O. Kephart;Gerald Tesauro
#t 2001
#c 11
#% 260307
#% 310459
#% 433914
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289309
#* Usability guidelines for interactive search in direct manipulation systems
#@ Robert St. Amant;Christopher G. Healey
#t 2001
#c 11
#% 34537
#% 115181
#% 159108
#% 240805
#% 248127
#% 272793
#% 284910
#% 298151
#% 302114
#% 311171
#% 434539
#% 529644
#% 1134810
#% 1275346
#% 1478774
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289310
#* Leveraging data about users in general in the learning of individual user models
#@ Anthony Jameson;Frank Wittig
#t 2001
#c 11
#% 44876
#% 130114
#% 234992
#% 246832
#% 271083
#% 280852
#% 443025
#% 742228
#% 1650719
#! Models of computer users that are learned on the basis of data can make use of two types of information: data about users in general and data about the current individual user. Focusing on user models that take the form of Bayesian networks, we compare four types of model that represent different ways of combining these two types of data. Models of the four types are applied to the data of an experiment, and they are evaluated according to theoretical, empirical, and practical criteria. One of the model types is a new variant of the AHUGIN method for adapting the probabilities of a Bayesian network while it is being used: Differential adaptation is a principled way of determining the speed with which each aspect of a network is adapted to an individual user.

#index 1289311
#* An agent architecture for multi-attribute negotiation
#@ Catholijn M. Jonker;Jan Treur
#t 2001
#c 11
#% 162305
#% 543221
#% 543234
#% 557217
#! A component-based generic agent architecture for multi-attribute (integrative) negotiation is introduced and its application is described in a prototype system for negotiation about cars, developed in co-operation with, among others, Dutch Telecom KPN. The approach can be characterised as co-operative one-to-one multi-criteria negotiation in which the privacy of both parties is protected as much as possible.

#index 1289312
#* A multiagent system for helping urban traffic management
#@ Luis A. García;F. Toledo
#t 2001
#c 11
#% 368175
#% 515963
#! This paper describes the MASHGREEN DM prototype following three goals: 1) The identification and implementation of the tasks related to urban traffic control that use deep reasoning mechanisms as main tools for their resolution. The chosen model for explaining urban traffic behaviour is a qualitative model, which includes among its main features their low temporal and spatial computational costs. 2) The definition of a functional architecture with soft real time constraints that integrates the developed tasks. A specilized component named agent, composed by four functional modules executes every task. These modules are the following ones: communication protocols, methods (agent specilization), data space and control. This architecture verifies that the execution performances of every agent are not compromised by the inclusion of new agents in the system, or by the interactions due to the active system agents. 3) The implementation of a prototype in a high performance computational architecture, a Beowulf computer system.

#index 1289313
#* Bidding languages for combinatorial auctions
#@ Craig Boutilier;Holger H. Hoos
#t 2001
#c 11
#% 29844
#% 267752
#% 302061
#% 314918
#% 496094
#% 496250
#% 529167
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289314
#* Partitioning activities for agents
#@ Fatma Özcan;V. S. Subrahmanian
#t 2001
#c 11
#% 25470
#% 159113
#% 169337
#% 210176
#% 227886
#% 519677
#% 557216
#% 591562
#! There are now numerous agent applications that track interests of thousands of users in situations where changes occur continuously. [Shim et al., 1994] suggested that such agents can be made efficient by merging commonalities in their activities. However, past algorithms cannot merge more than 10 or 20 concurrent activities. We develop techniques so that a large number of concurrent activities (typically over 1000) can be partitioned into components (groups of activities) of small size (e.g. 10 to 50) so that each component's activities can be merged using previously developed algorithms (e.g. [Shim et al., 1994]). We first formalize the problem and show that finding optimal partitions is NP-hard. We then develop three algorithms - Greedy, A*-based and BAB (branch and bound). A*-based and BAB are both guaranteed to compute optimal solutions. Greedy on the other hand uses heuristics and typically finds suboptimal solutions. We implemented all three algorithms. We experimentally show that the greedy algorithm finds partitions whose costs are at most 14% worse than that found by A*-based and BAB--however, Greedy is able to handle over thousand concurrent requests very fast while the other two methods are much slower and able to handle only 10-20 requests. Hence, Greedy appears to be the best.

#index 1289315
#* Title generation for machine-translated documents
#@ Rong Jin;Alexander G. Hauptmann
#t 2001
#c 11
#% 46803
#% 81669
#% 165111
#% 198296
#% 230530
#% 280835
#% 280909
#% 283177
#% 301267
#% 375017
#% 840583
#! In this paper, we present and compare automatically generated titles for machine-translated documents using several different statistics-based methods. A Naïve Bayesian, a K-Nearest Neighbour, a TF-IDF and an iterative Expectation-Maximization method for title generation were applied to 1000 original English news documents and again to the same documents translated from English into Portuguese, French or German and back to English using SYSTRAN. The AutoSummarization function of Microsoft Word was used as a base line. Results on several metrics show that the statistics-based methods of title generation for machine-translated documents are fairly language independent and title generation is possible at a level approaching the accuracy of titles generated for the original English documents.

#index 1289316
#* Dealing with dependencies between content planning and surface realisation in a pipeline generation architecture
#@ Kalina Bontcheva;Yorick Wilks
#t 2001
#c 11
#% 9197
#% 19925
#% 91528
#% 177915
#% 217067
#% 297158
#% 354421
#% 365052
#% 370475
#% 404608
#% 555589
#% 740396
#% 757379
#! The majority of existing language generation systems have a pipeline architecture which offers efficient sequential execution of modules, but does not allow decisions about text content to be revised in later stages. However, as exemplified in this paper, in some cases choosing appropriate content can depend on text length and formatting, which in a pipeline architecture are determined after content planning is completed. Unlike pipelines, interleaved and revision-based architectures can deal with such dependencies but tend to be more expensive computationally. Since our system needs to generate acceptable hypertext explanations reliably and quickly, the pipeline architecture was modified instead to allow additional content to be requested in later stages of the generation process if necessary.

#index 1289317
#* Narrative prose generation
#@ Charles B. Callaway;James C. Lester
#t 2001
#c 11
#% 145399
#% 175130
#% 199036
#% 241721
#% 423966
#% 491736
#% 555587
#% 704144
#% 711027
#% 741059
#% 741105
#% 747810
#% 854278
#% 1271852
#% 1476281
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289318
#* Adaptive information extraction from text by rule induction and generalisation
#@ Fabio Ciravegna
#t 2001
#c 11
#% 266216
#% 278109
#% 478258
#% 707780
#% 757422
#! (LP)2 is a covering algorithm for adaptive Information Extraction from text (IE). It induces symbolic rules that insert SGML tags into texts by learning from examples found in a user-defined tagged corpus. Training is performed in two steps: initially a set of tagging rules is learned; then additional rules are induced to correct mistakes and imprecision in tagging. Induction is performed by bottom-up generalization of examples in the training corpus. Shallow knowledge about Natural Language Processing (NLP) is used in the generalization process. The algorithm has a considerable success story. From a scientific point of view, experiments report excellent results with respect to the current state of the art on two publicly available corpora. From an application point of view, a successful industrial IE tool has been based on (LP)2. Real world applications have been developed and licenses have been released to external companies for building other applications. This paper presents (LP)2, experimental results and applications, and discusses the role of shallow NLP in rule induction.

#index 1289319
#* Relational learning via propositional algorithms: an information extraction case study
#@ Dan Roth;Wen-tau Yih
#t 2001
#c 11
#% 33376
#% 99406
#% 163545
#% 266368
#% 278102
#% 278109
#% 283136
#% 311037
#% 333797
#% 449508
#% 451055
#% 495943
#% 550250
#% 550407
#% 1272374
#! This paper develops a new paradigm for relational learning which allows for the representation and learning of relational information using propositional means. This paradigm suggests different tradeoffs than those in the traditional approach to this problem - the ILP approach - and as a result it enjoys several significant advantages over it. In particular, the new paradigm is more flexible and allows the use of any propositional algorithm, including probabilistic algorithms, within it. We evaluate the new approach on an important and relation-intensive task - Information Extraction - and show that it outperforms existing methods while being orders of magnitude more efficient.

#index 1289320
#* Deriving a multi-domain information extraction system from a rough ontology
#@ Thierry Poibeau
#t 2001
#c 11
#% 55490
#% 194267
#% 207536
#% 286069
#% 461626
#% 748549
#% 757276
#% 762178
#% 1275285
#! This paper presents a multi-domain information extraction system. In order to decrease the time spent on the elaboration of resources for the IE system and guide the end-user in a new domain, we suggest to use a machine learning system that helps defining new templates and associated resources. This knowledge is automatically derived from the text collection, in interaction with the end-user to rapidly develop a local ontology giving an accurate image of the content of the text. The system is finally evaluated using classical indicators.

#index 1289321
#* Representing sentence structure in hidden Markov models for information extraction
#@ Soumya Ray;Mark Craven
#t 2001
#c 11
#% 217064
#% 466892
#% 531459
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289322
#* Sequentially finding the N-best list in hidden Markov models
#@ Dennis Nilsson;Jacob Goldberger
#t 2001
#c 11
#% 99638
#% 424793
#% 898726
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289323
#* NLP-driven IR: evaluating performances over a text classification task
#@ Roberto Basili;Alessandro Moschitti;Maria Teresa Pazienza
#t 2001
#c 11
#% 46803
#% 165110
#% 219052
#% 219053
#% 232653
#% 280817
#% 318412
#% 449588
#% 458379
#% 465754
#% 466263
#% 478262
#! Although several attempts have been made to introduce Natural Language Processing (NLP) techniques in Information Retrieval, most ones failed to prove their effectiveness in increasing performances. In this paper Text Classification (TC) has been taken as the IR task and the effect of linguistic capabilities of the underlying system have been studied. A novel model for TC, extending a well know statistical model (i.e. Rocchio's formula [Ittner et al., 1995]) and applied to linguistic features has been defined and experimented. The proposed model represents an effective feature selection methodology. All the experiments result in a significant improvement with respect to other purely statistical methods (e.g. [Yang, 1999]), thus stressing the relevance of the available linguistic information. Moreover, the derived classifier reachs the performance (about 85%) of the best known models (i.e. Support Vector Machines (SVM) and K -Nearest Neighbour (KNN)) characterized by an higher computational complexity for training and processing.

#index 1289324
#* Dialog-driven adaptation of explanations of proofs
#@ Armin Fiedler
#t 2001
#c 11
#% 91525
#% 110352
#% 145399
#% 145400
#% 423966
#% 1271854
#! In order to generate high quality explanations in mathematical domains, the presentation must be adapted to the knowledge of the intended audience. Most proof presentation systems only communicate proofs on a fixed degree of abstraction independently of the addressee's knowledge. In this paper, we shall present the proof explanation system P.rex. Based on assumptions about the addressee's knowledge, its dialog planner chooses a degree of abstraction for each proof step to be explained. In reaction to the user's interactions, which are allowed at any time, it enters clarification dialogs to revise its user model and to adapt the explanation.

#index 1289325
#* Generating tailored examples to support learning via self-explanation
#@ Cristina Conati;Giuseppe Carenini
#t 2001
#c 11
#% 220130
#% 292074
#% 320666
#% 423966
#% 552940
#% 742069
#! We describe a framework that helps students learn from examples by generating example problem solutions whose level of detail is tailored to the students' domain knowledge. The framework uses natural language generation techniques and a probabilistic student model to selectively introduce gaps in the example solution, so that the student can practice applying rules learned from previous examples in problem solving episodes of difficulty adequate to her knowledge. Filling in solution gaps is part of the meta-cognitive skill known as self-explanation (generate explanations to oneself to clarify an example solution), which is crucial to effectively learn from examples. In this paper, we describe how examples with tailored solution gaps are generated and how they are used to support students in learning through gap-filling self-explanation.

#index 1289326
#* An empirical study of the influence of user tailoring on evaluative argument effectiveness
#@ Giuseppe Carenini;Johanna D. Moore
#t 2001
#c 11
#% 172355
#% 713511
#% 741064
#% 854257
#% 854262
#% 1290140
#! The ability to generate effective evaluative arguments is critical for systems intended to advise and persuade their users. We have developed a system that generates evaluative arguments that are tailored to the user, properly arranged and concise. We have also devised an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users. This paper presents the results of a formal experiment we performed in our framework to verify the influence of user tailoring on argument effectiveness.

#index 1289327
#* Refining the structure of a stochastic context-free grammar
#@ Joseph Bockhorst;Mark Craven
#t 2001
#c 11
#% 124708
#% 161241
#% 175368
#% 197387
#% 200195
#% 214314
#% 1650771
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289328
#* Automatically extracting and comparing lexicalized grammars for different languages
#@ Fei Xia;Chung-hye Han;Martha Palmer;Aravind Joshi
#t 2001
#c 11
#% 137144
#% 241161
#% 740916
#% 816079
#% 853849
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289329
#* Combining probabilities, failures and safety in robot control
#@ Alberto Finzi;Fiora Pirri
#t 2001
#c 11
#% 89958
#% 90371
#% 145167
#% 157172
#% 284106
#% 284644
#% 334327
#% 418654
#% 515386
#% 529322
#% 529345
#! We present a formal framework for treating both incomplete information in the initial database and possible failures during an agent's execution of a course of actions. These two aspects of uncertainty are formalized by two different notions of probability. We introduce also a concept of expected probability, which is obtained by combining the two previous notions. Expected probability accounts for the probability of a sentence on the hypothesis that the sequence of actions needed to make it true might have failed. Expected probability leads to the possibility of comparing courses of actions and verifying which is more safe.

#index 1289330
#* Heterogeneity in the coevolved behaviors of mobile robots: the emergence of specialists
#@ Mitchell A. Potter;Lisa Meeden;Alan C. Schultz
#t 2001
#c 11
#% 374560
#% 418626
#% 512120
#% 708124
#% 846520
#% 1022780
#! Many mobile robot tasks can be most efficiently solved when a group of robots is utilized. The type of organization, and the level of coordination and communication within a team of robots affects the type of tasks that can be solved. This paper examines the tradeoff of homogeneity versus heterogeneity in the control systems by allowing a team of robots to coevolve their high-level controllers given different levels of difficulty of the task. Our hypothesis is that simply increasing the difficulty of a task is not enough to induce a team of robots to create specialists. The key factor is not difficulty per se, but the number of skill sets necessary to successfully solve the task. As the number of skills needed increases, the more beneficial and necessary heterogeneity becomes. We demonstrate this in the task domain of herding, where one or more robots must herd another robot into a confined space.

#index 1289331
#* Agent-based control for object manipulation with modular self-reconfigurable robots
#@ Jeremy Kubica;Arancha Casal;Tad Hogg
#t 2001
#c 11
#% 121115
#% 169112
#% 199416
#% 269147
#% 435330
#% 455258
#% 586606
#% 659835
#! We demonstrate multiagent control of modular self-reconfigurable (MSR) robots for object manipulation tasks and show how it provides a useful programming abstraction. Such robots consist of many modules that can move relative to each other and change their connectivity, thereby changing the robot's overall shape to suit different tasks. We illustrate this approach through simulation experiments of the TeleCube MSR robot system.

#index 1289332
#* Learning iterative image reconstruction
#@ Sven Behnke
#t 2001
#c 11
#% 92636
#% 272540
#% 635753
#% 1042867
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289333
#* A hierarchy of boundary-based shape descriptors
#@ Richard Meathrel;Antony Galton
#t 2001
#c 11
#% 36778
#% 495923
#! In this paper we extend previous work on the boundary-based approach to describing shape, by deriving an unbounded hierarchy of "atomic" shape descriptors (called tokens) based on tangent bearing and its successive derivatives, and incorporating angle and cusp curve features. Both open and closed curves have token-string descriptions at all levels in the hierarchy. We provide a pair of compatibility matrices for generating transition tables for any level, from which level-specific token ordering graphs that encode basic string syntax can be systematically constructed.

#index 1289334
#* Resolving ambiguities to create a natural computer-based sketching environment
#@ Christine Alvarado;Randall Davis
#t 2001
#c 11
#% 109079
#% 213434
#% 263139
#% 297589
#% 438383
#% 445225
#% 625187
#! Current computer-based design tools for mechanical engineers are not tailored to the early stages of design. Most designs start as pencil and paper sketches, and are entered into CAD systems only when nearly complete. Our goal is to create a kind of "magic paper" capable of bridging the gap between these two stages. We want to create a computer-based sketching environment that feels as natural as sketching on paper, but unlike paper, understands a mechanical engineer's sketch as it is drawn. One important step toward realizing this goal is resolving ambiguities in the sketch-determining, for example, whether a circle is intended to indicate a wheel or a pin joint-and doing this as the user draws, so that it doesn't interfere with the design process. We present a method and an implemented program that does this for freehand sketches of simple 2-D mechanical devices.

#index 1289335
#* VAMBAM: view and motion -based aspect models for distributed omnidirectional vision systems
#@ Hiroshi Ishiguro;Takuichi Nishimura
#t 2001
#c 11
#% 117660
#% 245502
#% 336211
#% 612548
#% 835105
#% 1273679
#! This paper proposes a new model for gesture recognition. The model, called view and motion -based aspect models (VAMBAM), is an omnidirectional view-based aspect model based on motion-based segmentation. This model realizes location-free and rotation-free gesture recognition with a distributed omnidirectional vision system (DOVS). The distributed vision system consisting of multiple omnidirectional cameras is a prototype of a perceptual information infrastructure for monitoring and recognizing the real world. In addition to the concept of VABAM, this paper shows how the model realizes robust and real-time visual recognition of the DOVS.

#index 1289336
#* Efficient interpretation policies
#@ Ramana Isukapalli;Russell Greiner
#t 2001
#c 11
#% 58384
#% 196761
#% 240254
#% 262739
#% 376266
#% 527672
#% 1022958
#% 1650686
#! Many imaging systems seek a good interpretation of the scene presented - i.e., a plausible (perhaps optimal) mapping from aspects of the scene to real-world objects. This paper addresses the issue of finding such likely mappings efficiently. In general, an "(interpretation) policy" specifies when to apply which "imaging operators", which can range from low-level edge-detectors and region-growers through highlevel token-combination-rules and expectation-driven object-detectors. Given the costs of these operators and the distribution of possible images, we can determine both the expected cost and expected accuracy of any such policy. Our task is to find a maximally effective policy - typically one with sufficient accuracy, whose cost is minimal. We explore this framework in several contexts, including the eigenface approach to face recognition. Our results show, in particular, that policies which select the operators that maximize information gain per unit cost work more effectively than other policies, including ones that, at each stage, simply try to establish the putative most-likely interpretation.

#index 1289337
#* Perceptual texture space improves perceptual consistency of computational features
#@ Huizhong Long;Wee Kheng Leow
#t 2001
#c 11
#% 42413
#% 187271
#% 208708
#% 284557
#% 592183
#% 726267
#! Perceptual consistency is important in many computer vision applications. Unfortunately, except for color, computational features and similarity measurements for other visual features are not necessarily consistent with human's perception. This paper addresses three critical issues regarding perceptually consistent texture analysis: (1) development of perceptual texture space, (2) assessment of how consistent computational features are to human perception, and (3) mapping computational features to perceptual space. It demonstrates the construction of a reliable perceptual texture space, which can be used as a yardstick for assessing the perceptual consistency of computational features and similarity measurements. Moreover, it is found that commonly used computational texture features are not very consistent with human perception, and mapping them to the perceptual space improves their perceptual consistency.

#index 1289338
#* Fuzzy conceptual graphs for matching images of natural scenes
#@ Philippe Mulhem;Wee Kheng Leow;Yoong Keok Lee
#t 2001
#c 11
#% 2298
#% 251403
#% 262095
#% 285540
#% 443133
#% 465324
#% 465339
#% 465637
#% 563749
#! Conceptual graphs are very useful for representing structured knowledge. However, existing formulations of fuzzy conceptual graphs are not suitable for matching images of natural scenes. This paper presents a new variation of fuzzy conceptual graphs that is more suited to image matching. This variant differentiates between a model graph that describes a known scene and an image graph which describes an input image. A new measurement is defined to measure how well a model graph matches an image graph. A fuzzy graph matching algorithm is developed based on error-tolerant subgraph isomorphism. Test results show that the matching algorithm gives very good results for matching images to predefined scene models.

#index 1289339
#* Discriminating animate from inanimate visual stimuli
#@ Brian Scassellati
#t 2001
#c 11
#% 207004
#% 268121
#% 445391
#% 495947
#! From as early as 6 months of age, human children distinguish between motion patterns generated by animate objects from patterns generated by moving inanimate objects, even when the only stimulus that the child observes is a single point of light moving against a blank background. The mechanisms by which the animate/inanimate distinction are made are unknown, but have been shown to rely only upon the spatial and temporal properties of the movement. In this paper, I present both a multiagent architecture that performs this classification as well as detailed comparisons of the individual agent contributions against human baselines.

#index 1289340
#* An hybrid approach to solve the global localization problem for indoor mobile robots considering sensor's perceptual limitations
#@ Leonardo Romero;Eduardo Morales;Enrique Sucar
#t 2001
#c 11
#% 18547
#% 194039
#% 232117
#% 247930
#% 251262
#% 263035
#% 380686
#% 389645
#! Global localization is the problem of determining the position of a robot under global uncertainty. This problem can be divided in two phases: 1) from the sensor data (or sensor view), determine the set of locations where the robot can be; and 2) devise a strategy by which the robot can correctly eliminate all but the right location. The approach proposed in this paper is based on Markov localization. It applies the principal component method to get rotation invariant features for each location of the map, a Bayesian classification system to cluster the features, and polar correlations between the sensor view and the local map views to determine the locations where the robot can be. In order to solve efficiently the localization problem, as well as to consider the perceptual limitation of the sensors, the possible locations of the robot are restricted to be in a roadmap that keep the robot close to obstacles, and correlations between the possible local map views are pre-computed. The hypotheses are clustered and a greedy search determine the robot movements to reduce the number of clusters of hypotheses. This approach is tested using a simulated and a real mobile robot with promising results.

#index 1289341
#* Multimodal integration: a biological view
#@ Michael H. Coen
#t 2001
#c 11
#% 219232
#% 235356
#% 266223
#% 266402
#% 445393
#% 592404
#% 593443
#% 593652
#% 742400
#% 1775074
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289342
#* Real-time auditory and visual multiple-object tracking for humanoids
#@ Kazuhiro Nakadai;Ken-ichi Hidai;Hiroshi Mizoguchi;Hiroshi G. Okuno;Hiroaki Kitano
#t 2001
#c 11
#% 257158
#% 266402
#% 266406
#% 283262
#% 495947
#% 531462
#% 633525
#% 1022958
#% 1271842
#! This paper presents a real-time auditory and visual tracking of multiple objects for humanoid under real-world environments. Real-time processing is crucial for sensorimotor tasks in tracking, and multiple-object tracking is crucial for real-world applications. Multiple sound source tracking needs perception of a mixture of sounds and cancellation of motor noises caused by body movements. However its real-time processing has not been reported yet. Real-time tracking is attained by fusing information obtained by sound source localization, multiple face recognition, speaker tracking, focus of attention control, and motor control. Auditory streams with sound source direction are extracted by active audition system with motor noise cancellation capability from 48KHz sampling sounds. Visual streams with face ID and 3D-position are extracted by combining skincolor extraction, correlation-based matching, and multiple-scale image generation from a single camera. These auditory and visual streams are associated by comparing the spatial location, and associated streams are used to control focus of attention. Auditory, visual, and association processing are performed asynchronously on different PC's connected by TCP/IP network. The resulting system implemented on an upper-torso humanoid can track multiple objects with the delay of 200 msec, which is forced by visual tracking and network latency.

#index 1289343
#* A web-based intelligent system for the Daya Bay contingency plan in Hong Kong
#@ James Liu;Raymond Lee;Jane You
#t 2001
#c 11
#% 40619
#% 181390
#% 376904
#% 395537
#% 444697
#% 496264
#% 496417
#% 520589
#% 1271882
#! Decision making is particularly important for emergency managers as they often need to make quick and high quality decisions under stress based on scratch and inadequate information; and to follow expert knowledge or past experience. The potential release of radioactive material from the Guangdong Nuclear Power Station (GNPS) at Daya Bay, though is highly unlikely, could perhaps be the most dreaded disaster which would cause drastic damages to lives and properties. The Government of the Hong Kong Special Administrative Region Government (HKSAR) has therefore in 1990 completed the Daya Bay Contingency Plan (DBCP) to prepare for such disasters. To supplement the experts in assisting disaster managers with a useful tool to make better quality decisions based on well-structured, accurate, sufficient expert knowledge, a prototype expert system has been developed to cover two major areas of the plan, namely: (A) Determination of activation level of the DBCP and provision of an action checklist and (B) recommendation on counter-measures.

#index 1289344
#* ExpertClerk: navigating shoppers' buying process with the combination of asking and proposing
#@ Hideo Shimazu
#t 2001
#c 11
#% 168280
#% 283297
#% 406493
#% 418153
#% 445152
#% 449588
#% 490619
#% 494593
#% 494599
#% 496105
#% 756992
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289345
#* Preference-based configuration of web page content
#@ Carmel Domshlak;Ronen I. Brafman;Solomon E. Shimony
#t 2001
#c 11
#% 262265
#% 582013
#% 758040
#% 1650274
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289346
#* Keyword spices: a new method for building domain-specific web search engines
#@ Satoshi Oyama;Takashi Kokubo;Toru Ishida;Teruhiro Yamada;Yasuhiko Kitamura
#t 2001
#c 11
#% 136350
#% 226099
#% 252834
#% 255161
#% 266215
#% 376266
#% 387427
#% 449588
#% 495944
#% 1476317
#! This paper presents a new method for building domain-specific web search engines. Previous methods eliminate irrelevant documents from the pages accessed using heuristics based on human knowledge about the domain in question. Accordingly, they are hard to build and can not be applied to other domains. The keyword spice method, in contrast, improves search performance by adding domain-specific keywords, called keyword spices, to the user's input query; the modified query is then forwarded to a general-purpose search engine. Keyword spices can be effectively discovered automatically from web documents allowing us to build high quality domain-specific search engines in various domains without requiring the collection of heuristic knowledge. We describe a machine learning algorithm, which is a type of decision-tree learning algorithm, that can extract keyword spices. To demonstrate the value of the proposed approach, we conduct experiments in the domain of cooking. The results confirm the excellent performance of our method in terms of both precision and recall.

#index 1289347
#* Multimodal interaction: a new focal area for AI
#@ Philip R. Cohen
#t 2001
#c 11
#% 58870
#% 117568
#% 127465
#% 185856
#% 201997
#% 239643
#% 256532
#% 272922
#% 272924
#% 295952
#% 296728
#% 302109
#% 311973
#% 316401
#% 320850
#% 742107
#% 746898
#% 747980
#% 1134782
#% 1134821
#! AI research has often been driven by popular visions - HAL 2001, Asimov's Robot, Star Trek - and by critical application areas - medical expert systems, spoken dialogue systems, etc. These visions and applications serve to inspire and guide researchers, posing challenges, illustrating technical weaknesses, and generally channeling creative energy. Without doubt, the widely held vision of the autonomous robot, has exerted a substantial integrative force, such that numerous disciplines, ranging from mechanical engineering to cognitive science, can see how their intellectual endeavors can contribute to the overall endeavor. In this brief position paper, and in the accompanying talk, I would like to propose that the next generation of intelligent multimodal user interfaces can offer a similar intellectual focus for AI researchers. After providing a brief overview of our work in this area and two examples, I would like to suggest the potential impact that such interfaces could have in the relatively near-term.

#index 1289348
#* Plausibility measures: a general approach for representing uncertainty
#@ Joseph Y. Halpern
#t 2001
#c 11
#% 36534
#% 44876
#% 74868
#% 77841
#% 100178
#% 115327
#% 116624
#% 187571
#% 211580
#% 243704
#% 265802
#% 320132
#% 527990
#% 729449
#% 1272393
#% 1476313
#% 1650648
#% 1650784

#index 1289349
#* Robust translation of spontaneous speech: a multi-engine approach
#@ Wolfgang Wahlster
#t 2001
#c 11
#% 629370
#! Extracting rules from RBFs is not a trivial task because of nonlinear functions or high input dimensionality. In such cases, some of the hidden units of the RBF network have a tendency to be "shared" across several output classes or even may not contribute ...

#index 1289350
#* Proceedings of the 19th international joint conference on Artificial intelligence
#@ 
#t 2005
#c 11

#index 1289351
#* Cho-k-NN: a method for combining interacting pieces of evidence in case-based learning
#@ Eyke Hüllermeier
#t 2005
#c 11
#% 92533
#% 168280
#% 229954
#% 229972
#% 246243
#% 252233
#% 283141
#% 405727
#% 451032
#% 490785
#! The case-based learning paradigm relies upon memorizing cases in the form of successful problem solving experience, such as e.g. a pattern along with its classification in pattern recognition or a problem along with a solution in case-based reasoning. When it comes to solving a new problem, each of these cases serves as an individual piece of evidence that gives an indication of the solution to that problem. In this paper, we elaborate on issues concerning the proper combination (aggregation) of such pieces of evidence. Particularly, we argue that cases retrieved from a case library must not be considered as independent information sources, as implicitly done by most case-based learning methods. Focusing on the problem of prediction as a performance task, we propose a new inference principle that combines potentially interacting pieces of evidence by means of the so-called (discrete) Choquet-integral. Our method, called Cho-k-NN, takes interdependencies between the stored cases into account and can be seen as a generalization of weighted nearest neighbor estimation.

#index 1289352
#* Automating the discovery of recommendation knowledge
#@ David McSherry;Christopher Stretch
#t 2005
#c 11
#% 319705
#% 418152
#% 428440
#% 1279228
#% 1289284
#! In case-based reasoning (CBR) systems for product recommendation, the retrieval of acceptable products based on limited information is an important and challenging problem. As we show in this paper, basic retrieval strategies such as nearest neighbor are potentially unreliable when applied to incomplete queries. To address this issue, we present techniques for automating the discovery of recommendation rules that are provably reliable and non-conflicting while requiring minimal information for their application in a rule-based approach to the retrieval of recommended cases.

#index 1289353
#* Sophia: a novel approach for textual case-based reasoning
#@ David Patterson;Niall Rooney;Vladimir Dobrynin;Mykola Galushka
#t 2005
#c 11
#% 344447
#% 387427
#% 490929
#% 1650298
#! In this paper we present a novel methodology for textual case-based reasoning. This technique is unique in that it automatically discovers case and similarity knowledge, is language independent, is scaleable and facilitates semantic similarity between cases to be carried out inherently without the need for domain knowledge. In addition it provides an insight into the thematical content of the case-base as a whole, which enables users to better structure queries. We present an analysis of the competency of the system by assessing the quality of the similarity knowledge discovered and show how it is ideally suited to case-based retrieval (querying by example).

#index 1289354
#* Partial and vague knowledge for similarity measures
#@ Timo Steffens
#t 2005
#c 11
#% 89782
#% 92555
#% 120634
#% 126860
#% 126894
#% 129212
#% 169659
#% 229968
#% 229972
#% 490263
#% 490274
#% 494577
#! This paper proposes to enhance similarity-based classification by virtual attributes from imperfect domain theories. We analyze how properties of the domain theory, such as partialness and vagueness, influence classification accuracy. Experiments in a simple domain suggest that partial knowledge is more useful than vague knowledge. However, for data sets from the UCI Machine Learning Repository, we show that vague domain knowledge that in isolation performs at chance level can substantially increase classification accuracy when being incorporated into similarity-based classification.

#index 1289355
#* A flexible and robust similarity measure based on contextual probability
#@ Hui Wang;Werner Dubitzky
#t 2005
#c 11
#% 5182
#% 94876
#% 168280
#% 496092
#% 1272304
#! Arguably, analogy is one of the most important aspects of intelligent reasoning. It has been hypothesized that, given suitable background knowledge, analogy can be viewed as a logical inference process. This study follows another school of thought that argues that similarity can provide a probabilistic basis for inference and analogy. Most similarity measures (which are frequently viewed as being conceptually equivalent to distance measures) are restricted to either nominal or ordinal attributes, and some are confined to classification tasks. This paper proposes a flexible similarity measure that is task-independent and applies to both nominal and ordinal data in a conceptually uniform way. The proposed similarity measure is derived from a probability function and corresponds to the intuition that if we consider all neighborhoods around a data point, the data points closer to this point should be included in more of these neighborhoods than more distant points. Experiments we have conducted to demonstrate the usefulness of this measure indicate that it fares very competitively with commonly used similarity measures.

#index 1289356
#* Propagating logical combinations of constraints
#@ Fahiem Bacchus;Toby Walsh
#t 2005
#c 11
#% 427161
#% 534497
#% 535153
#% 539444
#% 1250136
#! Many constraint toolkits provide logical connectives like disjunction, negation and implication. These permit complex constraint expressions to be built from primitive constraints. However, the propagation of such complex constraint expressions is typically limited. We therefore present a simple and light weight method for propagating complex constraint expressions. We provide a precise characterization of when this method enforces generalized arc-consistency. In addition, we demonstrate that with our method many different global constraints can be easily implemented.

#index 1289357
#* Improved knowledge acquisition for high-performance heuristic search
#@ J. P. Bekmann;Achim Hoffmann
#t 2005
#c 11
#% 81272
#% 114994
#% 334126
#% 409585
#% 410954
#% 465863
#% 486001
#% 789998
#! We present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. The approach addresses the known difficulty of tuning probabilistic search algorithms, such as genetic algorithms or simulated annealing, for a given search problem by the introduction of domain knowledge. We show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of VLSI detailed routing. In this paper we present advanced techniques for improving our knowledge acquisition approach. We also present a novel method that uses domain knowledge for the prioritisation of mutation operators, increasing the GA's efficiency noticeably.

#index 1289358
#* Extracting certificates from quantified boolean formulas
#@ Marco Benedetti
#t 2005
#c 11
#% 3873
#% 600179
#% 1272399
#% 1675277
#! A certificate of satisfiability for a quantified boolean formula is a compact representation of one of its models which is used to provide solver-independent evidence of satisfiability. In addition, it can be inspected to gather explicit information about the semantics of the formula. Due to the intrinsic nature of quantified formulas, such certificates demand much care to be efficiently extracted, compactly represented, and easily queried. We show how to solve all these problems.

#index 1289359
#* Optimal and suboptimal singleton arc consistency algorithms
#@ Christian Bessiere;Romuald Debruyne
#t 2005
#c 11
#% 160389
#% 198885
#% 320265
#% 589700
#% 1271960
#% 1273727
#% 1289190
#% 1289191
#! Singleton arc consistency (SAC) enhances the pruning capability of arc consistency by ensuring that the network cannot become arc inconsistent after the assignment of a value to a variable. Algorithms have already been proposed to enforce SAC, but they are far from optimal time complexity. We give a lower bound to the time complexity of enforcing SAC, and we propose an algorithm that achieves this complexity, thus being optimal. However, it can be costly in space on large problems. We then propose another SAC algorithm that trades time optimality for a better space complexity. Nevertheless, this last algorithm has a better worst-case time complexity than previously published SAC algorithms. An experimental study shows the good performance of the new algorithms.

#index 1289360
#* The range and roots constraints: specifying counting and occurrence problems
#@ Christian Bessiere;Emmanuel Hebrard;Brahim Hnich;Zeynep Kiziltan;Toby Walsh
#t 2005
#c 11
#% 160208
#% 419950
#% 495762
#% 534497
#% 534993
#% 1250136
#% 1499496
#! We propose a simple declarative language for specifying a wide range of counting and occurrence constraints. This specification language is executable since it immediately provides a polynomial propagation algorithm. To illustrate the capabilities of this language, we specify a dozen global constraints taken from the literature. We observe one of three outcomes: we achieve generalized arc-consistency; we do not achieve generalized arc-consistency, but achieving generalized arc-consistency is NP-hard; we do not achieve generalized arc-consistency, but specialized propagation algorithms can do so in polynomial time. Experiments demonstrate that this specification language is both efficient and effective in practice.

#index 1289361
#* A model for generating random quantified boolean formulas
#@ Hubie Chen;Yannet Interian
#t 2005
#c 11
#% 41220
#% 283229
#% 302719
#% 561731
#! The quantified boolean formula (QBF) problem is a powerful generalization of the boolean satisfiability (SAT) problem where variables can be both universally and existentially quantified. Inspired by the fruitfulness of the established model for generating random SAT instances, we define and study a general model for generating random QBF instances. We exhibit experimental results showing that our model bears certain desirable similarities to the random SAT model, as well as a number of theoretical results concerning our model.

#index 1289362
#* A unified theory of structural tractability for constraint satisfaction and spread cut decomposition
#@ David Cohen;Peter Jeavons;Marc Gyssens
#t 2005
#c 11
#% 2028
#% 36814
#% 55926
#% 159244
#% 289424
#% 321058
#% 331899
#% 643572
#% 644201
#% 1069810
#! In this paper we introduce a generic form of structural decomposition for the constraint satisfaction problem, which we call a guarded decomposition. We show that many existing decomposition methods can be characterized in terms of finding guarded decompositions satisfying certain specified additional conditions. Using the guarded decomposition framework we are also able to define a new form of decomposition, which we call a spread cut. We show that discovery of width k spread-cut decompositions is tractable for each k, and that the spread cut decomposition strongly generalize all existing decompositions except hypertrees. Finally we exhibit a family of hypergraphs Hn, for n = 1, 2, 3 ..., where the width of the best hypertree decomposition of each Hn is at least 3n, but the width of the best spreadcut decomposition is at most 2n.

#index 1289363
#* Phase transitions of dominating clique problem and their implications to heuristics in satisfiability search
#@ Joseph Culberson;Yong Gao;Calin Anton
#t 2005
#c 11
#% 283230
#% 420713
#% 449862
#% 496249
#% 1272336
#! We study a monotone NP decision problem, the dominating clique problem, whose phase transition occurs at a very dense stage of the random graph evolution process. We establish the exact threshold of the phase transition and propose an efficient search algorithm that runs in super-polynomial time with high probability. Our empirical studies reveal two even more intriguing phenomena in its typical-case complexity: (1) the problem is "uniformly hard" with a tiny runtime variance on negative instances. (2) Our algorithm and its CNF-tailored implementation, outperform several SAT solvers by a huge margin on dominating cliques and some other SAT problems with similar structures.

#index 1289364
#* Existential arc consistency: getting closer to full arc consistency in weighted CSPs
#@ Simon de Givry;Matthias Zytnicki;Federico Heras;Javier Larrosa
#t 2005
#c 11
#% 751442
#% 789556
#% 1275309
#% 1279246
#% 1289190
#! The weighted CSP framework is a soft constraint framework with a wide range of applications. Most current state-of-the-art complete solvers can be described as a basic depth-first branch and bound search that maintain some form of arc consistency during the search. In this paper we introduce a new stronger form of arc consistency, that we call existential directional arc consistency and we provide an algorithm to enforce it. The efficiency of the algorithm is empirically demonstrated in a variety of domains.

#index 1289365
#* A uniform integration of higher-order reasoning and external evaluations in answer-set programming
#@ Thomas Eiter;Giovambattista Ianni;Roman Schindlauer;Hans Tompits
#t 2005
#c 11
#% 42003
#% 189739
#% 270718
#% 342829
#% 400992
#% 519557
#% 880394
#! We introduce HEX programs, which are nonmonotonic logic programs admitting higher-order atoms as well as external atoms, and we extend the well-known answer-set semantics to this class of programs. Higher-order features are widely acknowledged as useful for performing meta-reasoning, among other tasks. Furthermore, the possibility to exchange knowledge with external sources in a fully declarative framework such as Answer-Set Programming (ASP) is nowadays important, in particular in view of applications in the Semantic Web area. Through external atoms, HEX programs can model some important extensions to ASP, and are a useful KR tool for expressing various applications. Finally, complexity and implementation issues for a preliminary prototype are discussed.

#index 1289366
#* On solution correspondences in answer-set programming
#@ Thomas Eiter;Hans Tompits;Stefan Woltran
#t 2005
#c 11
#% 340738
#% 400986
#% 752748
#! We introduce a general framework for specifying program correspondence under the answer-set semantics. The framework allows to define different kinds of equivalence notions, including previously defined notions like strong and uniform equivalence, in which programs are extended with rules from a given context, and correspondence is determined by means of a binary relation. In particular, refined equivalence notions based on projected answer sets can be defined within this framework, where not all parts of an answer set are of relevance. We study general characterizations of inclusion and equivalence problems, introducing novel semantical structures. Furthermore, we deal with the issue of determining counterexamples for a given correspondence problem, and we analyze the computational complexity of correspondence checking.

#index 1289367
#* Dual lookups in pattern databases
#@ Ariel Felner;Uzi Zahavi;Jonathan Schaeffer;Robert C. Holte
#t 2005
#c 11
#% 208
#% 2194
#% 348576
#% 1272048
#% 1478838
#% 1499544
#! A pattern database (PDB) is a heuristic function stored as a lookup table. Symmetries of a state space are often used to enable multiple values to be looked up in a PDB for a given state. This paper introduces an additional PDB lookup, called the dual PDB lookup. A dual PDB lookup is always admissible but can return inconsistent values. The paper also presents an extension of the well-known pathmax method so that inconsistencies in heuristic values are propagated in both directions (child-to-parent, and parent-to-child) in the search tree. Experiments show that the addition of dual lookups and bidirectional pathmax propagation can reduce the number of nodes generated by IDA* by over one order of magnitude in the TopSpin puzzle and Rubik's Cube, and by about a factor of two for the sliding tile puzzles.

#index 1289368
#* The rules of constraint modelling
#@ Alan M. Frisch;Chris Jefferson;Bernadette Martínez Hernández;Ian Miguel
#t 2005
#c 11
#% 181043
#% 269391
#% 419950
#% 419988
#% 535172
#% 923608
#% 1797049
#! Many and diverse combinatorial problems have been solved successfully using finite-domain constraint programming. However, to apply constraint programming to a particular domain, the problem must first be modelled as a constraint satisfaction or optimisation problem. Since constraints provide a rich language, typically many alternative models exist. Formulating a good model therefore requires a great deal of expertise. This paper describes CONJURE, a system that refines a specification of a problem in the abstract constraint specification language ESSENCE into a set of alternative constraint models. Refinement is compositional: alternative constraint models are generated by composing refinements of the components of the specification. Experimental results demonstrate that CONJURE is able to generate a variety of models for practical problems from their ESSENCE specifications.

#index 1289369
#* Bin-completion algorithms for multicontainer packing and covering problems
#@ Alex S. FukunagaRichard;Richard E. Korf
#t 2005
#c 11
#% 86465
#% 231316
#% 266200
#% 408396
#% 534837
#% 534978
#% 578765
#% 1279390
#% 1844998
#! Bin-completion, a bin-oriented branch-and-bound approach, was recently shown to be promising for the bin packing problem. We propose several improvements to bin-completion that significantly improves search efficiency. We also show the generality of bin-completion for packing and covering problems involving multiple containers, and present bin-completion algorithms for the multiple knapsack, bin covering, and min-cost covering (liquid loading) problems that significantly outperform the previous state of the art. However, we show that for the bin packing problem, bin-completion is not competitive with the state of the art solver.

#index 1289370
#* Limited discrepancy beam search
#@ David Furcy;Sven Koenig
#t 2005
#c 11
#% 241
#% 64788
#% 68238
#% 130194
#% 137995
#% 180004
#% 180114
#% 266199
#% 516650
#% 590541
#% 677386
#% 827731
#% 1250219
#% 1271915
#% 1275306
#% 1289595
#% 1476299
#% 1478838
#! Beam search reduces the memory consumption of best-first search at the cost of finding longer paths but its memory consumption can still exceed the given memory capacity quickly. We therefore develop BULB (Beam search Using Limited discrepancy Backtracking), a complete memory-bounded search method that is able to solve more problem instances of large search problems than beam search and does so with a reasonable runtime. At the same time, BULB tends to find shorter paths than beam search because it is able to use larger beam widths without running out of memory. We demonstrate these properties of BULB experimentally for three standard benchmark domains.

#index 1289371
#* Generalized amazons is PSPACE-complete
#@ Timothy Furtak;Masashi Kiyomi;Takeaki Uno;Michael Buro
#t 2005
#c 11
#% 289248
#% 866766
#! Amazons is a perfect information board game with simple rules and large branching factors. Two players alternately move chess queen-like pieces and block squares on a 10×10 playing field. The player who makes the last move wins. Amazons endgames usually decompose into independent subgames. Therefore, the game is a natural testbed for combinatorial game theory. It was known that determining the winner of simple generalized Amazons endgames is NP-equivalent. This paper presents two proofs for the PSPACE-completeness of the generalized version of the full game.

#index 1289372
#* QCSP-solve: a solver for quantified constraint satisfaction problems
#@ Ian P. Gent;Peter Nightingale;Kostas Stergiou
#t 2005
#c 11
#% 345806
#% 420766
#% 535134
#% 1289185
#! The Quantified Constraint Satisfaction Problem (QCSP) is a generalization of the CSP in which some variables are universally quantified. It has been shown that a solver based on an encoding of QCSP into QBF can outperform the existing direct QCSP approaches by several orders of magnitude. In this paper we introduce an efficient QCSP solver. We show how knowledge learned from the successful encoding of QCSP into QBF can be utilized to enhance the existing QCSP techniques and speed up search by orders of magnitude. We also show how the performance of the solver can be further enhanced by incorporating advanced look-back techniques such as CBJ and solution-directed pruning. Experiments demonstrate that our solver is several orders of magnitude faster than existing direct approaches to QCSP solving, and significantly outperforms approaches based on encoding QCSPs as QBFs.

#index 1289373
#* The computational complexity of dominance and consistency in CP-nets
#@ Judy Goldsmith;Jérôme Lang;Miroslaw Truszczynski;Nic Wilson
#t 2005
#c 11
#% 167629
#% 767712
#% 1250234
#% 1271985
#% 1272026
#% 1279242
#% 1650274
#% 1650354
#! We investigate the computational complexity of testing dominance and consistency in CP-nets. Up until now, the complexity of dominance has been determined only for restricted classes in which the dependency graph of the CP-net is acyclic. However, there are preferences of interest that define cyclic dependency graphs; these are modeled with general CP-nets. We show here that both dominance and consistency testing for general CP-nets are PSPACE-complete. The reductions used in the proofs are from STRIPS planning, and thus establish strong connections between both areas.

#index 1289374
#* The complexity of quantified constraint satisfaction problems under structural restrictions
#@ Georg Gottlob;Gianluigi Greco;Francesco Scarcello
#t 2005
#c 11
#% 183640
#% 237054
#% 321058
#% 331899
#% 335852
#% 339937
#% 600496
#% 643572
#% 644201
#% 1250143
#! We give a clear picture of the tractability/intractability frontier for quantified constraint satisfaction problems (QCSPs) under structural restrictions. On the negative side, we prove that checking QCSP satisfiability remains PSPACE-hard for all known structural properties more general than bounded treewidth and for the incomparable hypergraph acyclicity. Moreover, if the domain is not fixed, the problem is PSPACE-hard even for tree-shaped constraint scopes. On the positive side, we identify relevant tractable classes, including QCSPs with prefix Æ having bounded hypertree width, and QCSPs with a bounded number of guards. The latter are solvable in polynomial time without any bound on domains or quantifier alternations.

#index 1289375
#* DPLL with a trace: from SAT to knowledge compilation
#@ Jinbo Huang;Adnan Darwiche
#t 2005
#c 11
#% 3873
#% 204396
#% 266400
#% 327779
#% 336874
#% 342378
#% 427657
#% 442363
#% 529186
#% 578749
#% 723877
#% 788050
#% 936786
#% 1272349
#% 1275335
#% 1675285
#! We show that the trace of an exhaustive DPLL search can be viewed as a compilation of the propositional theory. With different constraints imposed or lifted on the DPLL algorithm, this compilation will belong to the language of d-DNNF, FBDD, and OBDD, respectively. These languages are decreasingly succinct, yet increasingly tractable, supporting such polynomial-time queries as model counting and equivalence testing. Our contribution is thus twofold. First, we provide a uniform framework, supported by empirical evaluations, for compiling knowledge into various languages of interest. Second, we show that given a particular variant of DPLL, by identifying the language membership of its traces, one gains a fundamental understanding of the intrinsic complexity and computational power of the search algorithm itself. As interesting examples, we unveil the "hidden power" of several recent model counters, point to one of their potential limitations, and identify a key limitation of DPLL-based procedures in general.

#index 1289376
#* Optimal refutations for constraint satisfaction problems
#@ Tudor Hulubei;Barry O’Sullivan
#t 2005
#c 11
#% 249315
#% 319789
#% 419942
#% 419990
#% 420713
#% 496249
#% 1279379
#% 1289181
#% 1289184
#% 1738923
#! Variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. In this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble (sub)problem. We employ the notion of an optimal refutation of an insoluble (sub)problem and describe an algorithm for obtaining it. We propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. It is clear from our analysis that the standard variable orderings used to solve CSPs behave very differently on real-world problems than on random problems of comparable size. Our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.

#index 1289377
#* Efficient stochastic local search for MPE solving
#@ Frank Hutter;Holger H. Hoos;Thomas Stützle
#t 2005
#c 11
#% 44876
#% 289947
#% 344568
#% 388024
#% 448887
#% 578739
#% 578757
#% 724276
#% 750050
#% 1272398
#% 1673025
#! Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-the-art branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.

#index 1289378
#* The backbone of the travelling salesperson
#@ Philip Kilby;John Slaney;Toby Walsh
#t 2005
#c 11
#% 160270
#% 408396
#% 420713
#% 534971
#% 578761
#% 1272034
#% 1289181
#% 1289182
#% 1478782
#! We study the backbone of the travelling salesperson optimization problem. We prove that it is intractable to approximate the backbone with any performance guarantee, assuming that P≠NP and there is a limit on the number of edges falsely returned. Nevertheless, in practice, it appears that much of the backbone is present in close to optimal solutions. We can therefore often find much of the backbone using approximation methods based on good heuristics. We demonstrate that such backbone information can be used to guide the search for an optimal solution. However, the variance in runtimes when using a backbone guided heuristic is large. This suggests that we may need to combine such heuristics with randomization and restarts. In addition, though backbone guided heuristics are useful for finding optimal solutions, they are less help in proving optimality.

#index 1289379
#* Complete MCS-based search: application to resource constrained project scheduling
#@ Philippe Laborie
#t 2005
#c 11
#% 244899
#% 453072
#% 955847
#% 1290110
#! This paper describes a simple complete search for cumulative scheduling based on the detection and resolution of minimal critical sets (MCS). The heuristic for selecting MCSs relies on an estimation of the related reduction of the search space. An extension of the search procedure using self-adapting shaving is proposed. The approach was implemented on top of classical constraint propagation algorithms and tested on resource constrained project scheduling problems (RCPSP). We were able to close more than 15% of the previously open problems of the PSPLIB [Kolisch and Sprecher, 1996] and improve more than 31% of the best known lower bounds on those heavily studied problems. Other new results on open-shop and cumulative job-shop scheduling are reported.

#index 1289380
#* Three truth values for the SAT and Max-SAT problems
#@ Frédéric Lardeux;Frédéric Saubion;Jin-Kao Hao
#t 2005
#c 11
#% 160270
#% 327779
#% 383492
#% 408396
#% 417606
#% 535158
#% 1289181
#% 1478773
#! The aim of this paper is to propose a new resolution framework for the SAT and MAX-SAT problems which introduces a third truth value undefined in order to improve the resolution efficiency. Using this framework, we have adapted the classic algorithms Tabu Search andWalksat. Promising results are obtained and show the interest of our approach.

#index 1289381
#* Resolution in Max-SAT and its relation to local consistency in weighted CSPs
#@ Javier Larrosa;Federico Heras
#t 2005
#c 11
#% 95582
#% 288366
#% 289947
#% 327779
#% 419951
#% 420720
#% 578747
#% 578951
#% 789556
#% 1250148
#% 1279246
#% 1289364
#% 1499515
#! Max-SAT is an optimization version of the well-known SAT problem. It is of great importance from both a theoretical and a practical point of view. In recent years, there has been considerable interest in finding efficient solving techniques [Alsinet et al., 2003; Xing and Zhang, 2004; Shen and Zhang, 2004; de Givry et al., 2003]. Most of this work focus on the computation of good quality lower bounds to be used within a branch and bound algorithm. Unfortunately, lower bounds are described in a procedural way. Because of that, it is difficult to realize the logic that is behind. In this paper we introduce a logical framework for Max-SAT solving. Using this framework, we introduce an extension of the Davis-Putnam algorithm (that we call Max-DPLL) and the resolution rule. Our framework has the advantage of nicely integrating branch and bound concepts such as the lower and upper bound, as well as hiding away implementation details. We show that Max-DPLL augmented with a restricted form of resolution at each branching point is an effective solving strategy. We also show that the resulting algorithm is closely related with some local consistency properties developed for weighted constraint satisfaction problems.

#index 1289382
#* A greedy approach to establish singleton arc consistency
#@ Christophe Lecoutre;Stéphane Cardon
#t 2005
#c 11
#% 217501
#% 477221
#% 644201
#% 661274
#% 1289359
#! In this paper, we propose a new approach to establish Singleton Arc Consistency (SAC) on constraint networks. While the principle of existing SAC algorithms involves performing a breadth-first search up to a depth equal to 1, the principle of the two algorithms introduced in this paper involves performing several runs of a greedy search (where at each step, arc consistency is maintained). It is then an original illustration of applying inference (i.e. establishing singleton arc consistency) by search. Using a greedy search allows benefiting from the incrementality of arc consistency, learning relevant information from conflicts and, potentially finding solution(s) during the inference process. Further-more, both space and time complexities are quite competitive.

#index 1289383
#* Identifying conflicts in overconstrained temporal problems
#@ Mark H. Liffiton;Michael D. Moffitt;Martha E. Pollack;Karem A. Sakallah
#t 2005
#c 11
#% 107137
#% 266107
#% 404719
#% 544940
#% 736897
#% 761106
#% 1698705
#% 1722417
#! We describe a strong connection between maximally satisfiable and minimally unsatisfiable subsets of constraint systems. Using this relationship, we develop a two-phase algorithm, employing powerful constraint satisfaction techniques, for the identification of conflicting sets of constraints in infeasible constraint systems. We apply this technique to overconstrained instances of the Disjunctive Temporal Problem (DTP), an expressive form of temporal constraint satisfaction problems. Using randomly-generated benchmarks, we provide experimental results that demonstrate how the algorithm scales with problem size and constraint density.

#index 1289384
#* Why minimax works: an alternative explanation
#@ Mitja Luštrek;Matjaž Gams;Ivan Bratko
#t 2005
#c 11
#% 248775
#% 688748
#% 692887
#! In game-playing programs relying on the minimax principle, deeper searches generally produce better evaluations. Theoretical analyses, however, suggest that in many cases minimaxing amplifies the noise introduced by the heuristic function used to evaluate the leaves of the game tree, leading to what is known as pathological behavior, where deeper searches produce worse evaluations. In most of the previous research, positions were evaluated as losses or wins. Dependence between the values of positions close to each other was identified as the property of realistic game trees that eliminates the pathology and explains why minimax is successful in practice. In this paper we present an alternative explanation that does not rely on value dependence. We show that if real numbers are used for position values, position values tend to be further apart at lower levels of the game tree, which leads to a larger proportion of more extreme positions, where error is less probable. Decreased probability of error in searches to greater depths is sufficient to eliminate the pathology and no additional properties of game trees are required.

#index 1289385
#* A new approach to multiobjective A* search
#@ J. L. P´erez De la Cruz;J. L. P´erez De la Cruz;L. Mandow;L. Mandow
#t 2005
#c 11
#% 1722
#% 102372
#% 289148
#% 319222
#% 578768
#! The paper presents a new algorithm for multiobjective heuristic graph search problems. The algorithm presents some nice properties that are easily proven. Additionally, empirical tests show that substantial savings in memory can be achieved over previous proposals.

#index 1289386
#* AND/OR branch-and-bound for graphical models
#@ Radu Marinescu;Rina Dechter
#t 2005
#c 11
#% 44876
#% 52784
#% 230551
#% 267576
#% 289947
#% 337983
#% 419942
#% 448887
#% 788050
#% 1275299
#% 1279246
#! The paper presents and evaluates the power of a new framework for optimization in graphical models, based on AND/OR search spaces. The virtue of the AND/OR representation of the search space is that its size may be far smaller than that of a traditional OR representation. We develop our work on Constraint Optimization Problems (COP) and introduce a new generation of depth-first Branch-and-Bound algorithms that explore an AND/OR search space and use static and dynamic mini-bucket heuristics to guide the search. We focus on two optimization problems, solvingWeighted CSPs (WCSP) and finding theMost Probable Explanation (MPE) in belief networks. We show that the new AND/OR approach improves considerably over the classic OR space, on a variety of benchmarks including random and real-world problems. We also demonstrate the impact of different lower bounding heuristics on Branch-and-Bound exploring AND/OR spaces.

#index 1289387
#* AND/OR cutset conditioning
#@ Robert Mateescu;Rina Dechter
#t 2005
#c 11
#% 44876
#% 68183
#% 289947
#% 329486
#% 420720
#% 788041
#% 788050
#% 1389692
#% 1499510
#! Cutset conditioning is one of the methods of solving reasoning tasks for graphical models, especially when space restrictions make inference (e.g., jointree-clustering) algorithms infeasible. The w-cutset is a natural extension of the method to a hybrid algorithm that performs search on the conditioning variables and inference on the remaining problems of induced width bounded by w. This paper takes a fresh look at these methods through the spectrum of AND/OR search spaces for graphical models. The resulting AND/OR cutset method is a strict improvement over the traditional one, often by exponential amounts.

#index 1289388
#* Reducing checks and revisions in coarse-grained MAC algorithms
#@ D. Mehta;M. R. C. Van Dongen
#t 2005
#c 11
#% 3463
#% 419990
#% 529517
#% 769573
#% 1289190
#! Arc consistency algorithms are widely used to prune the search space of Constraint Satisfaction Problems (CSPs). Coarse-grained arc consistency algorithms like AC-3, AC-3d and AC-2001 are efficient when it comes to transforming a CSP to its arc-consistent equivalent. These algorithms repeatedly carry out revisions. Revisions require support checks for identifying and deleting all unsupported values from the domain of a variable. In revisions for difficult problems most values have some support. Indeed, most revisions are ineffective, i.e. they cannot delete any value and consume a lot of checks and time. We propose two solutions to overcome these problems. First we introduce the notion of a Support Condition (SC) which guarantees that a value has some support. SCs reduce support checks while maintaining arc consistency during search. Second we introduce the notion of a Revision Condition (RC) which guarantees that all values have support. A RC avoids a candidate revision and queue maintenance overhead. For random problems, SCs reduce the checks required by MAC-3 (MAC-2001) up to 90% (72%). RCs avoid at least 50% of the total revisions. Combining the two results in reducing 50% of the solution time.

#index 1289389
#* Applying local search to disjunctive temporal problems
#@ Michael D. Moffitt;Martha E. Pollack
#t 2005
#c 11
#% 3463
#% 107137
#% 126390
#% 144332
#% 266107
#% 383492
#% 544940
#% 736897
#% 750050
#% 1250232
#% 1279395
#% 1478839
#% 1675274
#! We present a method for applying local search to overconstrained instances of the Disjunctive Temporal Problem (DTP). Our objective is to generate high quality solutions (i.e., solutions that violate few constraints) in as little time as possible. The technique presented here differs markedly from previous work on DTPs, as it operates within the total assignment space of the underlying CSP rather than the partial assignment space of the related meta-CSP. We provide experimental results demonstrating that the use of local search leads to substantially improved performance over systematic methods.

#index 1289390
#* Possibilistic stable models
#@ Pascal Nicolas;Laurent Garcia;Igor Stéphan
#t 2005
#c 11
#% 167544
#% 228810
#% 275032
#% 499512
#% 503490
#% 528155
#% 1705584
#! In this work, we define a new framework in order to improve the knowledge representation power of Answer Set Programming paradigm. Our proposal is to use notions from possibility theory to extend the stable model semantics by taking into account a certainty level, expressed in terms of necessity measure, on each rule of a normal logic program. First of all, we introduce possibilistic definite logic programs and show how to compute the conclusions of such programs both in syntactic and semantic ways. The syntactic handling is done by help of a fix-point operator, the semantic part relies on a possibility distribution on all sets of atoms and we show that the two approaches are equivalent. In a second part, we define what is a possibilistic stable model for a normal logic program, with default negation. Again, we define a possibility distribution allowing to determine the stable models.

#index 1289391
#* Game-tree search with combinatorially large belief states
#@ Austin Parker;Dana Nau;V. S. Subrahmanian
#t 2005
#c 11
#% 251781
#% 348585
#% 495931
#% 1279308
#% 1740206
#! In games such as kriegspiel chess (a chess variant where players have no direct knowledge of the opponent's pieces' locations) the belief state's sizes dwarf those of other partial information games like bridge, scrabble, and poker-and there is no easy way to generate states satisfying the given observations. We show that statistical sampling approaches can be developed to do well in such games. We show that it is not necessary for the random sample to consist only of game boards that satisfy each and every one of a player's observations. In fact, we win 24% more often by beginning with such completely consistent boards and gradually switching (as the game progressed) to boards that are merely consistent with the latest observation. This surprising result is explained by noting that as the game progresses, a board that is consistent with the last move becomes more and more likely to be consistent with the entire set of observations, even if we have no idea what sequence of moves might have actually generated this board.

#index 1289392
#* Counting solutions of CSPs: a structural approach
#@ Gilles Pesant
#t 2005
#c 11
#% 3463
#% 77847
#% 205391
#% 528016
#% 534161
#% 723932
#% 766230
#% 1272404
#! Determining the number of solutions of a CSP has several applications in AI, in statistical physics, and in guiding backtrack search heuristics. It is a #P-complete problem for which some exact and approximate algorithms have been designed. Successful CSP models often use high-arity, global constraints to capture the structure of a problem. This paper exploits such structure and derives polytime evaluations of the number of solutions of individual constraints. These may be combined to approximate the total number of solutions or used to guide search heuristics. We give algorithms for several of the main families of constraints and discuss the possible uses of such solution counts.

#index 1289393
#* A scalable method for multiagent constraint optimization
#@ Adrian Petcu;Boi Faltings
#t 2005
#c 11
#% 1675
#% 2028
#% 224082
#% 322912
#% 443227
#% 529162
#% 643099
#% 644201
#% 773217
#% 855912
#% 1275299
#% 1810385
#! We present in this paper a new, complete method for distributed constraint optimization, based on dynamic programming. It is a utility propagation method, inspired by the sum-product algorithm, which is correct only for tree-shaped constraint networks. In this paper, we show how to extend that algorithm to arbitrary topologies using a pseudotree arrangement of the problem graph. Our algorithm requires a linear number of messages, whose maximal size depends on the induced width along the particular pseudotree chosen. We compare our algorithm with backtracking algorithms, and present experimental results. For some problem types we report orders of magnitude fewer messages, and the ability to deal with arbitrarily large problems. Our algorithm is formulated for optimization problems, but can be easily applied to satisfaction problems as well.

#index 1289394
#* Breaking symmetries in all different problems
#@ Jean-François Puget
#t 2005
#c 11
#% 379093
#% 497307
#% 535172
#% 741333
#! Adding symmetry breaking constraints is one of the oldest ways of breaking variable symmetries for CSPs. For instance, it is well known that all the symmetries for the pigeon hole problem can be removed by ordering the variables. We have generalized this result to all CSPs where the variables are subject to an all different constraint. In such case it is possible to remove all variable symmetries with a partial ordering of the variables. We show how this partial ordering can be automatically computed using computational group theory (CGT). We further show that partial orders can be safely used together with the GE-tree method of [Roney-Dougal et al., 2004]. Experiments show the efficiency of our method.

#index 1289395
#* Efficient belief-state AND-OR search, with application to Kriegspiel
#@ Stuart Russell;Jason Wolfe
#t 2005
#c 11
#% 117886
#% 174161
#% 233137
#% 495931
#% 1289212
#% 1289391
#% 1740206
#! The paper reports on new algorithms for solving partially observable games. Whereas existing algorithms apply AND-OR search to a tree of blackbox belief states, our "incremental" versions treat uncertainty as a new search dimension, examining the physical states within a belief state to construct solution trees incrementally. On a newly created database of checkmate problems for Kriegspiel (a partially observable form of chess), incrementalization yields speedups of two or more orders of magnitude on hard instances.

#index 1289396
#* Bounded search and symbolic inference for constraint optimization
#@ Martin Sachenbacher;Brian C. Williams
#t 2005
#c 11
#% 3873
#% 233849
#% 331899
#% 578755
#% 581814
#% 751442
#% 1275309
#% 1650297
#! Constraint optimization underlies many problems in AI. We present a novel algorithm for finite domain constraint optimization that generalizes branch-and-bound search by reasoning about sets of assignments rather than individual assignments. Because in many practical cases, sets of assignments can be represented implicitly and compactly using symbolic techniques such as decision diagrams, the set-based algorithm can compute bounds faster than explicitly searching over individual assignments, while memory explosion can be avoided by limiting the size of the sets. Varying the size of the sets yields a family of algorithms that includes known search and inference algorithms as special cases. Furthermore, experiments on random problems indicate that the approach can lead to significant performance improvements.

#index 1289397
#* Solving checkers
#@ J. Schaeffer;Y. Björnsson;N. Burch;A. Kishimoto;M. M¨ uller;R. Lake;P. Lu;S. Sutphen
#t 2005
#c 11
#% 39261
#% 1112725
#% 1250220
#! AI has had notable success in building high-performance game-playing programs to complete against the best human players. However, the availability of fast and plentiful machines with large memories and disks creates the possibility of solving a game. This has been done before for simple or relatively small games. In this paper, we present new ideas and algorithms for solving the game of checkers. Checkers is a popular game of skill with a search space of 1020 possible positions. This paper reports on our first result. One of the most challenging checkers openings has been solved-the White Doctor opening is a draw. Solving roughly 50 more openings will result in the game-theoretic value of checkers being determined.

#index 1289398
#* Structural symmetry breaking
#@ Meinolf Sellmann;Pascal Van Hentenryck
#t 2005
#c 11
#% 484962
#% 534837
#% 534978
#% 535152
#% 535172
#% 535309
#% 1279252
#! Symmetry breaking has been shown to be an important method to speed up the search in constraint satisfaction problems that contain symmetry. When breaking symmetry by dominance detection, a computationally efficient symmetry breaking scheme can be achieved if we can solve the dominance detection problem in polynomial time. We study the complexity of dominance detection when value and variable symmetry appear simultaneously in constraint satisfaction problems (CSPs) with single-valued variables and set-CSPs. We devise an efficient dominance detection algorithm for CSPs with single-valued variables that yields symmetry-free search trees and that is based on the abstraction to the actual, intuitive structure of a symmetric CSP.

#index 1289399
#* Decentralized search in networks using homophily and degree disparity
#@ O¨ zgu¨r Simsek;David Jensen
#t 2005
#c 11
#% 281251
#% 300078
#% 480309
#! We propose a new algorithm for finding a target node in a network whose topology is known only locally. We formulate this task as a problem of decision making under uncertainty and use the statistical properties of the graph to guide this decision. This formulation uses the homophily and degree structure of the network simultaneously, differentiating our algorithm from those previously proposed in the literature. Because homophily and degree disparity are characteristics frequently observed in real-world networks, the algorithm we propose is applicable to a wide variety of networks, including two families that have received much recent attention: small-world and scale-free networks.

#index 1289400
#* Value ordering for finding all solutions
#@ Barbara M. Smith;Paula Sturdy
#t 2005
#c 11
#% 130208
#% 131561
#% 529344
#% 1272031
#% 1275301
#! In finding all solutions to a constraint satisfaction problem, or proving that there are none, with a search algorithm that backtracks chronologically and forms k-way branches, the order in which the values are assigned is immaterial. However, we show that if the values of a variable are assigned instead via a sequence of binary choice points, and the removal of the value just tried from the domain of the variable is propagated before another value is selected, the value ordering can affect the search effort. We show that this depends on the problem constraints; for some types of constraints, we show that the savings in search effort can be significant, given a good value ordering.

#index 1289401
#* Leaf-value tables for pruning non-zero-sum games
#@ Nathan Sturtevant
#t 2005
#c 11
#% 101439
#% 174161
#% 529676
#% 1279309
#% 1499483
#! Algorithms for pruning game trees generally rely on a game being zero-sum, in the case of alpha-beta pruning, or constant-sum, in the case of multi-player pruning algorithms such as speculative pruning. While existing algorithms can prune non-zero-sum games, pruning is much less effective than in constant-sum games. We introduce the idea of leaf-value tables, which store an enumeration of the possible leaf values in a game tree. Using these tables we are can make perfect decisions about whether or not it is possible to prune a given node in a tree. Leaf-value tables also make it easier to incorporate monotonic heuristics for increased pruning. In the 3-player perfect-information variant of Spades we are able to reduce node expansions by two orders of magnitude over the previous best zero-sum and non-zero-sum pruning techniques.

#index 1289402
#* Choosing between heuristics and strategies: an enhanced model for decision-making
#@ Shavit Talman;Rotem Toister;Sarit Kraus
#t 2005
#c 11
#% 307212
#% 543561
#% 657345
#% 773284
#% 823892
#! Often an agent that has to solve a problem must choose which heuristic or strategy will help it the most in achieving its objectives. Sometimes the agent wishes to obtain additional units of information on the possible heuristics and strategies in order to choose between them, but it may be costly. As a result, the agent's goal is to acquire enough units of information in order to make a decision while incurring minimal cost. We focus on situations where the agent must decide in advance how many units it would like to obtain. We present an algorithm for choosing between two options, and then formulate three methods for the general case where there are k 2 options to choose from. We investigate the 2-option algorithm and the general k-option methods effectiveness in two domains: the 3-SAT domain, and the CT computer game. In both domains we present the experimental performance of our models. Results will show that applying the 2-option algorithm is beneficial and provides the agent a substantial gain. In addition, applying the k-option method in the domains investigated results in a moderate gain.

#index 1289403
#* Decision diagrams for the computation of semiring valuations
#@ Nic Wilson
#t 2005
#c 11
#% 3873
#% 44876
#% 203055
#% 230551
#% 289947
#% 345434
#% 408680
#% 419951
#% 460588
#% 567872
#% 644560
#% 788050
#% 788082
#% 1650767
#% 1675291
#! This paper describes a new approach to computation in a semiring-based system, which includes semiring-based CSPs (in particular weighted CSPs, fuzzy CSPs and standard CSPs) as well as Bayesian networks. The approach to computation is based on what we call semiring-labelled decision diagrams (SLDDs). These can be generated in a similar way to a standard search tree (decision tree) for solving a CSP, but some nodes are merged, creating a more compact representation; for certain classes of CSPs, the number of nodes in the resulting network will be a tiny fraction of the number of nodes in the corresponding search tree. A method is given for generating an SLDD that represents e.g., a particular instance of a semiring-based CSP; it is shown how this can be used to perform various computations of interest, such as solving a semiring-based CSP, finding optimal solutions, determining the possible values of each variable and counting solutions of a CSP.

#index 1289404
#* A simple model to generate hard satisfiable instances
#@ Ke Xu;Fr´ed´eric Boussemart;Fred Hemery;Christophe Lecoutre
#t 2005
#c 11
#% 63780
#% 334082
#% 341489
#% 419990
#% 529517
#% 535171
#% 1250139
#% 1271812
#% 1675288
#! In this paper, we try to further demonstrate that the models of random CSP instances proposed by [Xu and Li, 2000; 2003] are of theoretical and practical interest. Indeed, these models, called RB and RD, present several nice features. First, it is quite easy to generate random instances of any arity since no particular structure has to be integrated, or property enforced, in such instances. Then, the existence of an asymptotic phase transition can be guaranteed while applying a limited restriction on domain size and on constraint tightness. In that case, a threshold point can be precisely located and all instances have the guarantee to be hard at the threshold, i.e., to have an exponential tree-resolution complexity. Next, a formal analysis shows that it is possible to generate forced satisfiable instances whose hardness is similar to unforced satisfiable ones. This analysis is supported by some representative results taken from an intensive experimentation that we have carried out, using complete and incomplete search methods.

#index 1289405
#* A novel local search algorithm for the traveling salesman problem that exploits backbones
#@ Weixiong Zhang;Moshe Looks
#t 2005
#c 11
#% 160270
#% 210191
#% 214188
#% 739628
#% 782010
#% 1289181
#! We present and investigate a new method for the Traveling Salesman Problem (TSP) that incorporates backbone information into the well known and widely applied Lin-Kernighan (LK) local search family of algorithms for the problem. We consider how heuristic backbone information can be obtained and develop methods to make biased local perturbations in the LK algorithm and its variants by exploiting heuristic backbone information to improve their efficacy. We present extensive experimental results, using large instances from the TSP Challenge suite and real-world instances in TSPLIB, showing the significant improvement that the new method can provide over the original algorithms.

#index 1289406
#* Scalability study of peer-to-peer consequence finding
#@ P. Adjiman;P. Chatalic;F. Goasdou´e;M.-C. Rousset;L. Simon
#t 2005
#c 11
#% 82819
#% 132176
#% 283118
#% 303639
#% 340175
#% 348182
#% 384112
#% 577359
#% 743023
#% 765446
#! In peer-to-peer inference systems, each peer can reason locally but also solicit some of its acquaintances, sharing part of its vocabulary. This paper studies both theoretically and experimentally the problem of computing proper prime implicates for propositional peer-to-peer systems, the global theory (union of all peer theories) of which is not known (as opposed to partition-based reasoning).

#index 1289407
#* Identifiability of path-specific effects
#@ Chen Avin;Ilya Shpitser;Judea Pearl
#t 2005
#c 11
#% 89958
#% 297171
#% 528178
#% 1271819
#% 1650649
#! Counterfactual quantities representing path-specific effects arise in cases where we are interested in computing the effect of one variable on another only along certain causal paths in the graph (in other words by excluding a set of edges from consideration). A recent paper [Pearl, 2001] details a method by which such an exclusion can be specified formally by fixing the value of the parent node of each excluded edge. In this paper we derive simple, graphical conditions for experimental identifiability of path-specific effects, namely, conditions under which path-specific effects can be estimated consistently from data obtained from controlled experiments.

#index 1289408
#* Pushing the EL envelope
#@ Franz Baader;Sebastian Brandt;Carsten Lutz
#t 2005
#c 11
#% 36782
#% 70391
#% 179613
#% 561740
#% 778600
#% 821581
#% 826035
#% 1279262
#! Recently, it has been shown that the small description logic (DL) EL, which allows for conjunction and existential restrictions, has better algorithmic properties than its counterpart FL0, which allows for conjunction and value restrictions. Whereas the subsumption problem in FL0 becomes already intractable in the presence of acyclic TBoxes, it remains tractable in EL even with general concept inclusion axioms (GCIs). On the one hand, we extend the positive result for EL by identifying a set of expressive means that can be added to EL without sacrificing tractability. On the other hand, we show that basically all other additions of typical DL constructors to EL with GCIs make subsumption intractable, and in most cases even EXPTIME-complete. In addition, we show that subsumption in FL0 with GCIs is EXPTIME-complete.

#index 1289409
#* Analysis and verification of qualitative models of genetic regulatory networks: a model-checking approach
#@ Gr´egory Batt;Delphine Ropers;Hidde De Jong;Johannes Geiselmann;Radu Mateescu;Michel Page;Dominique Schneider
#t 2005
#c 11
#% 159945
#% 166232
#% 229082
#% 297770
#% 417599
#% 452108
#% 542265
#% 557450
#% 790576
#% 1718654
#! Methods developed for the qualitative simulation of dynamical systems have turned out to be powerful tools for studying genetic regulatory networks. A bottleneck in the application of these methods is the analysis of the simulation results. In this paper, we propose a combination of qualitative simulation and model-checking techniques to perform this task systematically and efficiently. We apply our approach to the analysis of the complex network controlling the nutritional stress response in the bacterium Escherichia coli.

#index 1289410
#* Revision of partially ordered information: axiomatization, semantics and iteration
#@ Salem Benferhat;Sylvain Lagrue;Odile Papini
#t 2005
#c 11
#% 109945
#% 224753
#% 421961
#% 1290096
#! This paper deals with iterated revision of partially ordered information. The first part of this paper concerns the Katsuno-Mendelzon's postulates: we first point out that these postulates are not fully satisfactory since only a class of partially ordered information can be revised. We then propose a suitable definition of faithful assignment, followed by a new set of postulates and a representation theorem. The second part of this paper investigates additional postulates dedicated to iterated revision operators of partially ordered information. Three extensions of well-known iterated belief revision operations for dealing with partially ordered information are briefly presented.

#index 1289411
#* Computational ontologies of parthood, componenthood, and containment
#@ Thomas Bittner;Maureen Donnelly
#t 2005
#c 11
#% 100170
#% 305945
#% 917555
#% 935898
#! Parthood, componenthood, and containment relations are commonly assumed in biomedical ontologies and terminology systems, but are not usually clearly distinguished from another. This paper contributes towards a unified theory of parthood, componenthood, and containment relations. Our goal in this is to clarify distinctions between these relations as well as principles governing their interrelations. We first develop a theory of these relations in first order predicate logic and then discuss how description logics can be used to capture some important aspects of the first order theory.

#index 1289412
#* Propositional argumentation and causal reasoning
#@ Alexander Bochman
#t 2005
#c 11
#% 160188
#% 198464
#% 231742
#% 330290
#% 366370
#% 763743
#% 917556
#% 1279231
#% 1478800
#! The paper introduces a number of propositional argumentation systems obtained by gradually extending the underlying language and associated monotonic logics. An assumption-based argumentation framework [Bondarenko et al., 1997] will constitute a special case of this construction. In addition, a stronger argumentation system in a full classical language will be shown to be equivalent to a system of causal reasoning [Giunchiglia et al., 2004]. The implications of this correspondence for the respective nonmonotonic theories of argumentation and causal reasoning are discussed.

#index 1289413
#* Reconstructing an agent's epistemic state from observations
#@ Richard Booth;Alexander Nittka
#t 2005
#c 11
#% 115327
#% 116294
#% 224753
#% 233138
#% 581824
#% 741458
#% 1272393
#% 1290096
#% 1738769
#! We look at the problem in belief revision of trying to make inferences about what an agent believed - or will believe - at a given moment, based on an observation of how the agent has responded to some sequence of previous belief revision inputs over time. We adopt a "reverse engineering" approach to this problem. Assuming a framework for iterated belief revision which is based on sequences, we construct a model of the agent that "best explains" the observation. Further considerations on this best-explaining model then allow inferences about the agent's epistemic behaviour to be made. We also provide an algorithm which computes this best explanation.

#index 1289414
#* Scale-based monotonicity analysis in qualitative modelling with flat segments
#@ Martin Brooks;Yuhong Yan;Daniel Lemire
#t 2005
#c 11
#% 1116
#% 6200
#% 151284
#% 303945
#% 466506
#! Qualitative models are often more suitable than classical quantitative models in tasks such as Model-based Diagnosis (MBD), explaining system behavior, and designing novel devices from first principles. Monotonicity is an important feature to leverage when constructing qualitative models. Detecting monotonic pieces robustly and efficiently from sensor or simulation data remains an open problem. This paper presents scale-based monotonicity: the notion that monotonicity can be defined relative to a scale. Real-valued functions defined on a finite set of reals e.g. sensor data or simulation results, can be partitioned into quasimonotonic segments, i.e. segments monotonic with respect to a scale, in linear time. A novel segmentation algorithm is introduced along with a scalebased definition of "flatness".

#index 1289415
#* Declarative and computational properties of logic programs with aggregates
#@ Francesco Calimeri;Wolfgang Fabery;Nicola Leone;Simona Perri
#t 2005
#c 11
#% 103705
#% 123070
#% 190336
#% 231786
#% 296153
#% 400992
#% 411814
#% 464918
#% 484342
#% 736900
#% 1289431
#! We investigate the properties of logic programs with aggregates. We mainly focus on programs with monotone and antimonotone aggregates (LPm,aA programs). We define a new notion of unfounded set for (LPm,aA programs, and prove that it is a sound generalization of the standard notion of unfounded set for aggregate-free programs. We show that the answer sets of an LPm,aA program are precisely its unfounded-free models. We define a well-founded operator WP for LPm,aA programs; we prove that its total fixpoints are precisely the answer sets of P, and its least fixpoint WPw(0) is contained in the intersection of all answer sets (if P admits an answer set). WPW(0) is efficiently computable, and for aggregate-free programs it coincides with the well-founded model. We carry out an in-depth complexity analysis in the general framework, including also nonmonotone aggregates. We prove that monotone and anti-monotone aggregates do not increase the complexity of cautious reasoning, which remains in co-NP. Nonmonotone aggregates, instead, do increase the complexity by one level in the polynomial hierarchy. Our results allow also to generalize and speed-up ASP systems with aggregates.

#index 1289416
#* Parameterized compilability
#@ Hubie Chen
#t 2005
#c 11
#% 42241
#% 216990
#% 235882
#% 291000
#% 307262
#% 344152
#% 529652
#% 571628
#% 1271822
#% 1275338
#! Compilability is a measure of how effectively compilation (or preprocessing) can be applied to knowledge bases specified in a particular knowledge representation formalism; the aim of compilation is to allow for efficient, on-line query processing. A theory of compilability has been established for organizing knowledge representation formalisms according to a scheme of "compilability classes", and bears strong analogies to the classical theory of complexity, which permits the organization of computational problems according to complexity classes. We develop a novel theory of compilability, called parameterized compilability, which incorporates the notion of parameterization as used in parameterized complexity and permits for refined analysis of compilability.

#index 1289417
#* Updating action domain descriptions
#@ Thomas Eiter;Esra Erdem;Michael Fink;Ján Senko
#t 2005
#c 11
#% 90860
#% 266241
#% 520879
#% 752737
#% 752792
#% 1499547
#! How can an intelligent agent update her knowledge base about an action domain, relative to some conditions (possibly obtained from earlier observations)? We study this question in a formal framework for reasoning about actions and change, in which the meaning of an action domain description can be represented by a directed graph whose nodes correspond to states and whose edges correspond to action occurrences. We define the update of an action domain description in this framework, and show among other results that a solution to this problem can be obtained by a divide-and-conquer approach in some cases. We also introduce methods to compute a solution and an approximate solution to this problem, and analyze the computational complexity of these problems. Finally, we discuss techniques to improve the quality of solutions.

#index 1289418
#* Quota and Gmin merging operators
#@ Patricia Everaere;Sébastien Konieczny;Pierre Marquis
#t 2005
#c 11
#% 442755
#% 443185
#! In this paper, two families of merging operators are considered: quota operators and Gmin operators. Quota operators rely on a simple idea: any possible world is viewed as a model of the result of the merging when it satisfies "sufficiently many" bases from the given profile (a multi-set of bases). Different interpretations of the "sufficiently many" give rise to specific operators. Each Gmin operator is parameterized by a pseudo-distance and each of them is intended to refine the quota operators (i.e., to preserve more information). Quota and Gmin operators are evaluated and compared along four dimensions: rationality, computational complexity, strategy-proofness, and discriminating power. Those two families are shown as interesting alternatives to the formula-based merging operators (which selects some formulas in the union of the bases).

#index 1289419
#* Strong equivalence for logic programs with preferences
#@ Wolfgang Faber;Kathrin Konczak
#t 2005
#c 11
#% 275032
#% 340738
#% 517309
#% 752747
#% 752748
#% 752754
#! Recently, strong equivalence for Answer Set Programming has been studied intensively, and was shown to be beneficial for modular programming and automated optimization. In this paper we define the novel notion of strong equivalence for logic programs with preferences. Based on this definition we give, for several semantics for preference handling, necessary and sufficient conditions for programs to be strongly equivalent. These results provide a clear picture of the relationship of these semantics with respect to strong equivalence, which differs considerably from their relationship with respect to answer sets. Finally, based on these results, we present for the first time simplification methods for logic programs with preferences.

#index 1289420
#* Representing flexible temporal behaviors in the situation calculus
#@ Alberto Finzi;Fiora Pirri
#t 2005
#c 11
#% 107137
#% 216976
#% 262737
#% 314845
#% 319244
#% 342119
#% 741448
#% 743461
#% 835732
#% 1250133
#% 1271810
#! In this paper we present an approach to representing and managing temporally-flexible behaviors in the Situation Calculus based on a model of time and concurrent situations. We define a new hybrid framework combining temporal constraint reasoning and reasoning about actions. We show that the Constraint Based Interval Planning approach can be imported into the Situation Calculus by defining a temporal and concurrent extension of the basic action theory. Finally, we provide a version of the Golog interpreter suitable for managing flexible plans on multiple timelines.

#index 1289421
#* Cohesion, coupling and the meta-theory of actions
#@ Andreas Herzig;Ivan Varzinczak
#t 2005
#c 11
#% 31900
#% 39262
#% 115188
#% 236024
#% 284106
#% 520879
#% 531443
#% 1279365
#% 1290152
#% 1290153
#% 1290154
#! In this work we recast some design principles commonly used in software engineering and adapt them to the design and analysis of domain descriptions in reasoning about actions. We show how the informal requirements of cohesion and coupling can be turned into consistency tests of several different arrangements of modules. This gives us new criteria for domain description evaluation and clarifies the link between software and knowledge engineering in what concerns the meta-theory of actions.

#index 1289422
#* A tableaux decision procedure for SHOIQ
#@ Ian Horrocks;Ulrike Sattler
#t 2005
#c 11
#% 170059
#% 445250
#% 517267
#% 561419
#% 561740
#% 587425
#% 1271815
#% 1289174
#! This paper presents a tableaux decision procedure for SHOIQ, the DL underlying OWL DL. To the best of our knowledge, this is the first goal-directed decision procedure for SHOIQ.

#index 1289423
#* Reasoning with inconsistent ontologies
#@ Zhisheng Huang;Frank Van Harmelen;Annette Ten Teije
#t 2005
#c 11
#% 184793
#% 665860
#% 722844
#! In this paper we present a framework of reasoning with inconsistent ontologies, in which pre-defined selection functions are used to deal with concept relevance. We examine how the notion of "concept relevance" can be used for reasoning with inconsistent ontologies. We have implemented a prototype called PION (Processing Inconsistent ONtologies), which is based on a syntactic relevance-based selection function. In this paper, we also report the experiments with PION.

#index 1289424
#* Iterated belief change: a transition system approach
#@ Aaron Hunter;James P. Delgrande
#t 2005
#c 11
#% 224753
#% 422076
#% 1290098
#! We use a transition system approach to reason about the evolution of an agent's beliefs as actions are executed. Some actions cause an agent to perform belief revision and some actions cause an agent to perform belief update, but the interaction between revision and update can be non-elementary. We present a set of basic postulates describing the interaction of revision and update, and we introduce a new belief evolution operator that gives a plausible interpretation to alternating sequences of revisions and updates.

#index 1289425
#* Data complexity of reasoning in very expressive description logics
#@ Ullrich Hustadt;Boris Motik;Ulrike Sattler
#t 2005
#c 11
#% 190266
#% 191611
#% 198529
#% 342829
#% 935898
#! Data complexity of reasoning in description logics (DLs) estimates the performance of reasoning algorithms measured in the size of the ABox only. We show that, even for the very expressive DL SHIQ, satisfiability checking is data complete for NP. For applications with large ABoxes, this can be a more accurate estimate than the usually considered combined complexity, which is EXPTIME-complete. Furthermore, we identify an expressive fragment, Horn-SHIQ, which is data complete for P, thus being very appealing for practical usage.

#index 1289426
#* Equivalence in abductive logic
#@ Katsumi Inoue;Chiaki Sakama
#t 2005
#c 11
#% 21137
#% 42003
#% 130489
#% 181220
#% 205390
#% 243831
#% 340738
#% 417577
#% 1275253
#! We consider the problem of identifying equivalence of two knowledge bases which are capable of abductive reasoning. Here, a knowledge base is written in either first-order logic or nonmonotonic logic programming. In this work, we will give two definitions of abductive equivalence. The first one, explainable equivalence, requires that two abductive programs have the same explainability for any observation. Another one, explanatory equivalence, guarantees that any observation has exactly the same explanations in each abductive framework. Explanatory equivalence is a stronger notion than explainable equivalence. In first-order abduction, explainable equivalence can be verified by the notion of extensional equivalence in default theories. In nonmonotonic logic programs, explanatory equivalence can be checked by means of the notion of relative strong equivalence. We also show the complexity results for abductive equivalence.

#index 1289427
#* Iterated belief revision, revised
#@ Yi Jin;Michael Thielscher
#t 2005
#c 11
#% 109945
#% 150427
#% 224753
#% 480182
#% 555519
#% 581824
#% 781173
#% 782308
#% 782324
#% 1290096
#% 1290097
#! The AGM postulates for belief revision, augmented by the DP postulates for iterated belief revision, provide generally accepted criteria for the design of operators by which intelligent agents adapt their beliefs incrementally to new information. These postulates alone, however, are too permissive: They support operators by which all newly acquired information is canceled as soon as an agent learns a fact that contradicts some of its current beliefs. In this paper, we present a formal analysis of the deficiency of the DP postulates, and we show how to solve the problem by an additional postulate of independence. We give a representation theorem for this postulate and prove that it is compatible with AGM and DP.

#index 1289428
#* Reasoning under inconsistency: the forgotten connective
#@ Sébastien Konieczny;Jérôme Lang;Pierre Marquis
#t 2005
#c 11
#% 42003
#% 235882
#% 416007
#% 417601
#% 503248
#% 503676
#! In many frameworks for reasoning under inconsistency, it is implicitly assumed that the formulae from the belief base are connected using a weak form of conjunction. When it is consistent, a belief base B = {φ1..., φn}, where the φi are propositional formulae, is logically equivalent to the base {φ1 Λ ... Λ φn}. However, when it is not consistent, both bases typically lead to different conclusions. This illustrates the fact that the comma used in base B has to be considered as an additional, genuine connective, and not as a simple conjunction. In this work we define and investigate a propositional framework with such a "comma connective". We give it a semantics and show how it generalizes several approaches for reasoning from inconsistent beliefs.

#index 1289429
#* Semantics for a useful fragment of the situation calculus
#@ Gerhard Lakemeyer;Hector J. Levesque
#t 2005
#c 11
#% 7047
#% 92771
#% 117869
#% 183459
#% 284647
#% 326595
#% 340735
#% 342119
#% 529811
#% 572366
#% 1068305
#! In a recent paper, we presented a new logic called ES for reasoning about the knowledge, action, and perception of an agent. Although formulated using modal operators, we argued that the language was in fact a dialect of the situation calculus but with the situation terms suppressed. This allowed us to develop a clean and workable semantics for the language without piggybacking on the generic Tarski semantics for first-order logic. In this paper, we reconsider the relation between ES and the situation calculus and show how to map sentences of ES into the situation calculus. We argue that the fragment of the situation calculus represented by ES is rich enough to handle the basic action theories defined by Reiter as well as Golog. Finally, we show that in the full second-order version of ES, almost all of the situation calculus can be accommodated.

#index 1289430
#* From knowledge-based programs to graded belief-based programs, part II: off-line reasoning
#@ Noël Laverny;Jérôme Lang
#t 2005
#c 11
#% 188086
#% 250128
#% 265802
#% 284644
#% 326595
#% 342119
#% 790640
#! Belief-based programs generalize knowledgebased programs [Fagin et al., 1995] by allowing for incorrect beliefs, unreliable observations, and branching conditions that refer to implicit graded beliefs, such as in "while my belief about the direction to the railway station is not strong enough do ask someone". We show how to reason off-line about the possible executions of a belief-based program, which calls for introducing second-order uncertainty in the model.

#index 1289431
#* A model-theoretic counterpart of loop formulas
#@ Joohyung Lee
#t 2005
#c 11
#% 53385
#% 58574
#% 103705
#% 231786
#% 268779
#% 417649
#% 752744
#% 772065
#% 865743
#% 1250128
#! In an important recent paper, Lin and Zhao introduced the concept of a loop formula, and showed that the answer sets for a logic program are exactly the models of Clark's completion of the program that satisfy the loop formulas. Just as supported sets are a model-theoretic account of completion, "externally supported" sets, defined in this paper, are a model-theoretic counterpart of loop formulas. This reformulation of loop formulas shows that they are related to assumption sets (Saccá and Zaniolo) and to unfounded sets (Van Gelder, Ross and Schlipf; Leone, Rullo and Scarcello), invented many years earlier. Other contributions of this paper includes a simplification of the definition of a loop, extending it to programs with classical negation and infinite programs, and a generalization of the definition of a loop formula.

#index 1289432
#* Planning with loops
#@ Hector J. Levesque
#t 2005
#c 11
#% 252203
#% 296170
#% 318195
#% 342119
#% 655322
#% 762500
#% 1476290
#! Unlike the case for sequential and conditional planning, much of the work on iterative planning (planning where loops may be needed) leans heavily on theorem-proving. This paper does the following: it proposes a different approach where generating plans is decoupled from verifying them; describes the implementation of an iterative planner based on the situation calculus; presents a few examples illustrating the sorts of plans that can be generated; shows some of the strengths and weaknesses of the approach; and finally sketches the beginnings of a theory, where validation of plans is done offline.

#index 1289433
#* Discovering classes of strongly equivalent logic programs
#@ Fangzhen Lin;Yin Chen
#t 2005
#c 11
#% 340738
#% 417651
#% 517309
#% 801768
#! We report on a successful experiment of computeraided theorem discovery in the area of logic programming with answer set semantics. Specifically, with the help of computers, we discovered exact conditions that capture the strong equivalence between a set of a rule and the empty set, a set of a rule and another set of a rule, a set S of two rules and a subset of S with one rule, a set of two rules and a set of another rule, and a set S of three rules and a subset of S with two rules. We prove some general theorems that can help us verify the correctness of these conditions, and discuss the usefulness of our results in program simplification.

#index 1289434
#* Tractable reasoning with incomplete first-order knowledge in dynamic systems with context-dependent actions
#@ Yongmei Liu;Hector J. Levesque
#t 2005
#c 11
#% 229083
#% 322911
#% 342119
#% 495950
#% 1250157
#% 1271828
#% 1279222
#% 1279223
#! A basic reasoning problem in dynamic systems is the projection problem: determine if a formula holds after a sequence of actions has been performed. In this paper, we propose a tractable solution to the projection problem in the presence of incomplete first-order knowledge and contextdependent actions. Our solution is based on a type of progression, that is, we progress the initial knowledge base (KB) wrt the action sequence and answer the query against the resulting KB. The form of reasoning we propose is always logically sound and is also logically complete when the query is in a certain normal form and the agent has complete knowledge about the context of any context-dependent actions.

#index 1289435
#* Cognitive modelling of event ordering reasoning in imagistic domains
#@ Laura S. Mastella;Mara Abel;Luís C. Lamb;Luiz F. De Ros
#t 2005
#c 11
#% 156337
#% 189917
#% 261694
#% 319244
#% 454253
#% 719454
#% 763742
#% 1272294
#! The inference of temporal information from past event occurences in imagistic domains is relevant in several applications in knowledge engineering. In such applications, the order in which events have happened is imprinted in the domain as visual-spatial relations among its elements. Therefore, the interpretation of the relative ordering in which those events have occured is essential for understanding the domain evolution. We propose a cognitive model for event ordering reasoning within domains whose elements have been modified by past events. From the analysis of cognitive abilities of experts we propose new ontology constructs for knowledge modelling associated to Problem-Solving Methods. We illustrate the effectiveness of the model by means of an applications to an imagistic domain.

#index 1289436
#* Propositional abduction is almost always hard
#@ Gustav Nordh;Bruno Zanuttini
#t 2005
#c 11
#% 107135
#% 145393
#% 181220
#% 288946
#% 296176
#% 334203
#% 335852
#% 345434
#% 350221
#% 408396
#% 502365
#% 529332
#% 578665
#% 600496
#% 601159
#% 1271990
#! Abduction is a fundamental form of nonmonotonic reasoning that aims at finding explanations for observed manifestations. Applications of this process range from car configuration to medical diagnosis. We study here its computational complexity in the case where the application domain is described by a propositional theory built upon a fixed constraint language and the hypotheses and manifestations are described by sets of literals. We show that depending on the language the problem is either polynomial-time solvable, NP-complete, or ΣP2-complete. In particular, we show that under the assumption P≠NP, only languages that are affine of width 2 have a polynomial algorithm, and we exhibit very weak conditions for NP-hardness.

#index 1289437
#* Inverse resolution as belief change
#@ Maurice Pagnucco;David Rajaratnam
#t 2005
#c 11
#% 77841
#% 90029
#% 160378
#% 161241
#% 782324
#! Belief change is concerned with modelling the way in which a rational reasoner maintains its beliefs as it acquires new information. Of particular interest is the way in which new beliefs are acquired and determined and old beliefs are retained or discarded. A parallel can be drawn to symbolic machine learning approaches where examples to be categorised are presented to the learning system and a theory is subsequently derived, usually over a number of iterations. It is therefore not surprising that the term 'theory revision' is used to describe this process [Ourston and Mooney, 1994]. Viewing a machine learning system as a rational reasoner allows us to begin seeing these seemingly disparate mechanisms in a similar light. In this paper we are concerned with characterising the well known inverse resolution operations [Muggleton, 1987; 1992] (and more recently, inverse entailment [Muggleton, 1995]) as AGM-style belief change operations. In particular, our account is based on the abductive expansion operation [Pagnucco et al., 1994; Pagnucco, 1996] and characterised by using the notion of epistemic entrenchment [Gärdenfors and Makinson, 1988] extended for this operation. This work provides a basis for reconciling work in symbolic machine learning and belief revision. Moreover, it allows machine learning techniques to be understood as forms of nonmonotonic reasoning.

#index 1289438
#* Building the semantic web tower from RDF straw
#@ Peter F. Patel-Schneider
#t 2005
#c 11
#% 577304
#% 665856
#! A same-syntax extension of RDF to first-order logic results in a collapse of the model theory due to logical paradoxes resulting from diagonalization. RDF is thus the wrong material for building the Semantic Web tower.

#index 1289439
#* Measuring conflict and agreement between two prioritized belief bases
#@ Guilin Qi;Weiru Liu;David A. Bell
#t 2005
#c 11
#% 167544
#% 417813
#% 578666
#% 936786
#% 1250161
#% 1279226
#! In this paper, we investigate the relationship between two prioritized knowledge bases by measuring both the conflict and the agreement between them. First of all, a quantity of conflict and two quantities of agreement are defined. The former is shown to be a generalization of the Dalal distance. The latter are, respectively, a quantity of strong agreement which measures the amount of information on which two belief bases "totally" agree, and a quantity of weak agreement which measures the amount of information that is believed by one source but is unknown to the other. All three quantity measures are based on the weighted prime implicant, which represents beliefs in a prioritized belief base. We then define a degree of conflict and two degrees of agreement based on our quantity of conflict and the quantities of agreement. We also consider the impact of these measures on belief merging and information source ordering.

#index 1289440
#* Minimal and absent information in contexts
#@ Floris Roelofsen;Luciano Serafini
#t 2005
#c 11
#% 28185
#% 93766
#% 103705
#% 160385
#% 334493
#% 757481
#! Multi-context systems (MCS) represent contextual information flow. We show that the semantics of an MCS is completely determined by the information that is obtained when simulating the MCS, in such a way that a minimal amount of information is deduced at each step of the simulation. In MCS, the acquisition of new information is based on the presence of other information only. We give a generalized account to model situations in which information can be obtained as a result of the absence of other information as well.

#index 1289441
#* Supervaluation semantics for an inland water feature ontology
#@ Paulo Santos;Brandon Bennett;Georgios Sakellariou
#t 2005
#c 11
#% 489424
#% 496922
#% 592212
#! This paper describes an ontology for inland water features built using formal concept analysis and supervaluation semantics. The first is used to generate a complete lattice of the water domain, whereas supervaluation semantics is used to model the variability of the concepts in terms of threshold parameters. We also present an algorithm for a mechanism of individuation and classification of water features, from snapshots of river networks, according to the proposed ontology.

#index 1289442
#* Aspects of distributed and modular ontology reasoning
#@ Luciano Serafini;Alex Borgida;Andrei Tamilin
#t 2005
#c 11
#% 334493
#% 801692
#% 935898
#% 1279341
#% 1374385
#! We investigate a formalism for reasoning with multiple local ontologies, connected by directional semantic mappings. We propose: (1) a relatively small change of semantics which localizes inconsistency (thereby making unnecessary global satisfiability checks), and preserves directionality of "knowledge import"; (2) a characterization of inferences using a fixed-point operator, which can form the basis of a cache-based implementation for local reasoners; (3) a truly distributed tableaux algorithm for cases when the local reasoners use subsets of SHIQ. Throughout, we indicate the applicability of the results to several recent proposals for knowledge representation and reasoning that support modularity, scalability and distributed reasoning.

#index 1289443
#* A formal investigation of mapping language for terminological knowledge
#@ Luciano Serafini;Heiner Stuckenschmidt;Holger Wache
#t 2005
#c 11
#% 205398
#% 334493
#% 464717
#% 484323
#% 763751
#% 1374385
#! The need to represent mappings between different ontologies has been recognized as a result of the fact that different ontologies may partially overlap, or even represent the same domain from different points of view. Unlike ontology languages, work on languages to represent ontology mappings has not yet reached a state where a common understanding of the basic principles exists. In this paper we propose a formal comparison of existing mapping languages by translating them into distributed first order logic. This allows us to analyze underlying assumptions and differences in the interpretation of ontology mappings.

#index 1289444
#* Goal change
#@ Steven Shapiro;Yves Lespérance;Hector J. Levesque
#t 2005
#c 11
#% 68239
#% 314845
#% 342119
#% 484915
#% 572366
#! Although there has been much discussion of belief change (e.g., [Gärdenfors, 1988; Spohn, 1988]), goal change has not received much attention. In this paper, we propose a method for goal change in the framework of Reiter's [2001] theory of action in the situation calculus [McCarthy and Hayes, 1969; Levesque et al., 1998], and investigate its properties. We extend the framework developed by Shapiro et al. [1998] and Shapiro and Lespérance [2001], where goals and goal expansion were modelled, but goal contraction was not.

#index 1289445
#* First-order logical filtering
#@ Afsaneh Shirazi;Eyal Amir
#t 2005
#c 11
#% 90860
#% 131559
#% 229083
#% 1279222
#% 1650568
#! Logical filtering is the process of updating a belief state (set of possible world states) after a sequence of executed actions and perceived observations. In general, it is intractable in dynamic domains that include many objects and relationships. Still, potential applications for such domains (e.g., semantic web, autonomous agents, and partial-knowledge games) encourage research beyond immediate intractability results. In this paper we present polynomial-time algorithms for filtering belief states that are encoded as First-Order Logic (FOL) formulae. We sidestep previous discouraging results, and show that our algorithms are exact in many cases of interest. These algorithms accept belief states in full FOL, which allows natural representation with explicit references to unidentified objects, and partially known relationships. Our algorithms keep the encoding compact for important classes of actions, such as STRIPS actions. These results apply to most expressive modeling languages, such as partial databases and belief revision in FOL.

#index 1289446
#* Combining learning constraints and numerical regression
#@ Dorian Šuc;Ivan Bratko
#t 2005
#c 11
#% 132583
#% 132938
#% 166232
#% 229931
#% 328946
#% 431101
#% 464471
#% 466401
#% 783959
#! Usual numerical learning methods are primarily concerned with finding a good numerical fit to data and often make predictions that do not correspond to qualitative laws in the domain of modelling or expert intuition. In contrast, the idea of Q2 learning is to induce qualitative constraints from training data, and use the constraints to guide numerical regression. The resulting numerical predictions are consistent with a learned qualitative model which is beneficial in terms of explanation of phenomena in the modelled domain, and can also improve numerical accuracy. This paper proposes a method for combining the learning of qualitative constraints with an arbitrary numerical learner and explores the accuracy and explanation benefits of learning monotonic qualitative constraints in a number of domains. We show that Q2 learning can correct for errors caused by the bias of the learning algorithm and discuss the potentials of similar hierarchical learning schemes.

#index 1289447
#* On the interaction between inverse features and path-functional dependencies in description logics
#@ David Toman;Grant Weddell
#t 2005
#c 11
#% 535512
#% 826035
#% 1279263
#% 1289168
#! We investigate how inverse features can be added to a boolean complete description logic with path-functional dependencies in ways that avoid undecidability of the associated logical implication problem. In particular, we present two conditions that ensure the problem remains EXPTIME-complete. The first is syntactic in nature and limits the form that dependencies may have in argument terminologies. The second is a coherence condition on terminologies that is sufficiently weak to allow the transfer of relational and emerging object-oriented normalization techniques.

#index 1289448
#* Ordering heuristics for description logic reasoning
#@ Dmitry Tsarkov;Ian Horrocks
#t 2005
#c 11
#% 101435
#% 198885
#% 248026
#% 445250
#% 459487
#% 935898
#! We present a new architecture for Description Logic implementations, a range of new optimisation techniques and an empirical analysis of their effectiveness.

#index 1289449
#* Going far, logically
#@ Fusun Yaman;Dana Nau;V. S. Subrahmanian
#t 2005
#c 11
#% 52985
#% 181340
#% 421073
#% 1391867
#! There are numerous applications where we need to ensure that multiple moving objects are sufficiently far apart. Furthermore, in many moving object domains, there is positional indeterminacy--we are not 100% sure exactly when a given moving object will be at a given location. [Yaman et al., 2004] provided a logic of motion but did not provide algorithms to ensure that moving objects are kept sufficiently far apart. In this paper, we extend their logic to include a "far" predicate. We develop the CheckFar algorithm that checks if any given two objects will always be sufficiently far apart at during a time interval. We have run a set of experiments showing that our CheckFar algorithm scales very well.

#index 1289450
#* A motion closed world asumption
#@ Fusun Yaman;Dana Nau;V. S. Subrahmanian
#t 2005
#c 11
#% 556918
#% 592056
#% 939431
#% 1391867
#! Yaman et. al. [Yaman et al., 2004] introduce "go theories" to reason about moving objects. In this paper, we show that this logic often does not allow us to infer that an object is not present at a given place or region, even though common sense would dictate that this is a reasonable inference to make. We define a class of models of go-theories called coherent models. We use this concept to define a motion closed world assumption (MCWA) and develop a notion of MCWA-entailment. We show that checking if a go-theory has a coherent model is NP-complete. An in atom checks if a given object is present in a given region sometime in a given time interval. We provide sound and complete algorithms to check if a ground in literal (positive or negative in atom) can be inferred from a go-theory using the MCWA. In our experiments our algorithms answer such queries in less than 1 second when there are up to 1,000 go-atoms per object.

#index 1289451
#* Solving logic program conflict through strong and weak forgettings
#@ Yan Zhang;Norman Foo;Kewen Wang
#t 2005
#c 11
#% 337497
#% 340738
#% 752792
#% 1271987
#! We consider how to forget a set of atoms in a logic program. Intuitively, when a set of atoms is forgotten from a logic program, all atoms in the set should be eliminated from this program in some way, and other atoms related to them in the program might also be affected. We define notions of strong and weak forgettings in logic programs to capture such intuition and reveal their close connections to the notion of forgetting in classical propositional theories. Based on these notions, we then propose a framework for conflict solving in logic programs, which is general enough to represent many important conflict solving problems. We also study some essential semantic and computational properties in relation to strong and weak forgettings and conflict solving in our framework.

#index 1289452
#* Ranking cases with decision trees: a geometric method that preserves intelligibility
#@ Isabelle Alvarez;Stephan Bernard
#t 2005
#c 11
#% 136350
#% 227510
#% 290482
#% 420084
#% 464280
#% 580510
#! This paper proposes a new method to rank the cases classified by a decision tree. The method applies a posteriori without modification of the tree and doesn't use additional training cases. It consists in computing the distance of the cases to the decision boundary induced by the decision tree, and to rank them according to this geometric score. When the data are numeric it is very easy to implement and efficient. The distance-based score is a global assess, contrary to other methods that evaluate the score at the level of the leaf. The distance-based score gives good results even with pruned tree, so if the tree is intelligible this property is preserved with an improved ranking ability. The main reason for the efficacity of the geometric method is that in most cases when the classifier is sufficiently accurate, errors are located near the decision boundary.

#index 1289453
#* Exploiting informative priors for Bayesian classification and regression trees
#@ Nicos Angelopoulos;James Cussens
#t 2005
#c 11
#% 195016
#% 528014
#% 528326
#! A general method for defining informative priors on statistical models is presented and applied specifically to the space of classification and regression trees. A Bayesian approach to learning such models from data is taken, with the Metropolis-Hastings algorithm being used to approximately sample from the posterior. By only using proposal distributions closely tied to the prior, acceptance probabilities are easily computable via marginal likelihood ratios, whatever the prior used. Our approach is empirically tested by varying (i) the data, (ii) the prior and (iii) the proposal distribution. A comparison with related work is given.

#index 1289454
#* Exploiting background knowledge for knowledge-intensive subgroup discovery
#@ Martin Atzmueller;Frank Puppe;Hans-Peter Buscher
#t 2005
#c 11
#% 270817
#% 307386
#% 477497
#% 490919
#% 579586
#! In general, knowledge-intensive data mining methods exploit background knowledge to improve the quality of their results. Then, in knowledge-rich domains often the interestingness of the mined patterns can be increased significantly. In this paper we categorize several classes of background knowledge for subgroup discovery, and present how the necessary knowledge elements can be modelled. Furthermore, we show how subgroup discovery methods benefit from the utilization of background knowledge, and discuss its application in an incremental process-model. The context of our work is to identify interesting diagnostic patterns to supplement a medical documentation and consultation system. We provide a case study in the medical domain, using a case base from a realworld application.

#index 1289455
#* Fast and complete symbolic plan recognition
#@ Dorit Avrahami-Zilberbrand;Gal A. Kaminka
#t 2005
#c 11
#% 136350
#% 424017
#% 567880
#% 1271813
#% 1279398
#! Recent applications of plan recognition face several open challenges: (i) matching observations to the plan library is costly, especially with complex multi-featured observations; (ii) computing recognition hypotheses is expensive. We present techniques for addressing these challenges. First, we show a novel application of machine-learning decision-tree to efficiently map multi-featured observations to matching plan steps. Second, we provide efficient lazy-commitment recognition algorithms that avoid enumerating hypotheses with every observation, instead only carrying out bookkeeping incrementally. The algorithms answer queries as to the current state of the agent, as well as its history of selected states. We provide empirical results demonstrating their efficiency and capabilities.

#index 1289456
#* Unsupervised learning of semantic relations between concepts of a molecular biology ontology
#@ Massimiliano Ciaramita;Aldo Gangemi;Esther Ratsch;Jasmin Šaric;Isabel Rojas
#t 2005
#c 11
#% 226545
#% 342630
#% 452983
#% 471758
#% 731208
#% 740900
#% 742218
#% 786515
#% 854173
#% 938677
#% 938707
#% 995512
#! In this paper we present an unsupervised model for learning arbitrary relations between concepts of a molecular biology ontology for the purpose of supporting text mining and manual ontology building. Relations between named-entities are learned from the GENIA corpus by means of several standard natural language processing techniques. An in-depth analysis of the output of the system shows that the model is accurate and has good potentials for text mining and ontology building applications.

#index 1289457
#* Feature selection based on the Shapley value
#@ Shay Cohen;Eytan Ruppin;Gideon Dror
#t 2005
#c 11
#% 269217
#% 400847
#% 722937
#% 776586
#! We present and study the Contribution-Selection algorithm (CSA), a novel algorithm for feature selection. The algorithm is based on the Multiperturbation Shapley Analysis, a framework which relies on game theory to estimate usefulness. The algorithm iteratively estimates the usefulness of features and selects them accordingly, using either forward selection or backward elimination. Empirical comparison with several other existing feature selection methods shows that the backward eliminati-nation variant of CSA leads to the most accurate classification results on an array of datasets.

#index 1289458
#* Stacked sequential learning
#@ William W. Cohen;Vitor R. Carvalho
#t 2005
#c 11
#% 132938
#% 211044
#% 252034
#% 278104
#% 464434
#% 466892
#% 479726
#% 741122
#% 741169
#% 770850
#% 816186
#% 854636
#% 854637
#! We describe a new sequential learning scheme called "stacked sequential learning". Stacked sequential learning is a meta-learning algorithm, in which an arbitrary base learner is augmented so as to make it aware of the labels of nearby examples. We evaluate the method on several "sequential partitioning problems", which are characterized by long runs of identical labels. We demonstrate that on these problems, sequential stacking consistently improves the performance of nonsequential base learners; that sequential stacking often improves performance of learners (such as CRFs) that are designed specifically for sequential tasks; and that a sequentially stacked maximum-entropy learner generally outperforms CRFs.

#index 1289459
#* View learning for statistical relational learning: with an application to mammography
#@ Jesse Davis;Elizabeth Burnside;Inês Dutra;David Page;Raghu Ramakrishnan;Vitor Santos Costa;Jude Shavlik
#t 2005
#c 11
#% 92776
#% 128623
#% 246832
#% 379345
#% 390132
#% 496116
#% 550390
#% 727912
#% 729926
#% 729982
#% 1650289
#% 1673040
#! Statistical relational learning (SRL) constructs probabilistic models from relational databases. A key capability of SRL is the learning of arcs (in the Bayes net sense) connecting entries in different rows of a relational table, or in different tables. Nevertheless, SRL approaches currently are constrained to use the existing database schema. For many database applications, users find it profitable to define alternative "views" of the database, in effect defining new fields or tables. Such new fields or tables can also be highly useful in learning. We provide SRL with the capability of learning new views.

#index 1289460
#* Learning web page scores by error back-propagation
#@ Michelangelo Diligenti;Marco Gori;Marco Maggini
#t 2005
#c 11
#% 348172
#% 464615
#% 466891
#% 480309
#% 577338
#% 729437
#% 1279296
#! In this paper we present a novel algorithm to learn a score distribution over the nodes of a labeled graph (directed or undirected). Markov Chain theory is used to define the model of a random walker that converges to a score distribution which depends both on the graph connectivity and on the node labels. A supervised learning task is defined on the given graph by assigning a target score for some nodes and a training algorithm based on error backpropagation through the graph is devised to learn the model parameters. The trained model can assign scores to the graph nodes generalizing the criteria provided by the supervisor in the examples. The proposed algorithm has been applied to learn a ranking function for Web pages. The experimental results show the effectiveness of the proposed technique in reorganizing the rank accordingly to the examples provided in the training set.

#index 1289461
#* Reinforcement learning in POMDPs without resets
#@ Eyal Even-Dar;Sham M. Kakade;Yishay Mansour
#t 2005
#c 11
#% 92301
#% 102136
#% 160327
#% 466075
#% 527987
#% 706380
#% 1271956
#% 1290039
#% 1478842
#% 1650312
#% 1650568
#! We consider the most realistic reinforcement learning setting in which an agent starts in an unknown environment (the POMDP) and must follow one continuous and uninterrupted chain of experience with no access to "resets" or "offline" simulation. We provide algorithms for general connected POMDPs that obtain near optimal average reward. One algorithm we present has a convergence rate which depends exponentially on a certain horizon time of an optimal policy, but has no dependence on the number of (unobservable) states. The main building block of our algorithms is an implementation of an approximate reset strategy, which we show always exists in every POMDP. An interesting aspect of our algorithms is how they use this strategy when balancing exploration and exploitation.

#index 1289462
#* A simple-transition model for relational sequences
#@ Alan Fern
#t 2005
#c 11
#% 28072
#% 226437
#% 289947
#% 464434
#% 709996
#% 716892
#% 731606
#% 736898
#% 770842
#% 827613
#% 854636
#% 1272377
#% 1279354
#% 1650403
#! We use "nearly sound" logical constraints to infer hidden states of relational processes. We introduce a simple-transition cost model, which is parameterized by weighted constraints and a statetransition cost. Inference for this model, i.e. finding a minimum-cost state sequence, reduces to a single-state minimization (SSM) problem. For relational Horn constraints, we give a practical approach to SSM based on logical reasoning and bounded search. We present a learning method that discovers relational constraints using CLAUDIEN [De Raedt and Dehaspe, 1997] and then tunes their weights using perceptron updates. Experiments in relational video interpretation show that our learned models improve on a variety of competitors.

#index 1289463
#* Repairing concavities in ROC curves
#@ Peter A. Flach;Shaomin Wu
#t 2005
#c 11
#% 107456
#% 209021
#% 331909
#% 349550
#% 464606
#% 482502
#% 580510
#% 1042787
#% 1784199
#! In this paper we investigate methods to detect and repair concavities in ROC curves by manipulating model predictions. The basic idea is that, if a point or a set of points lies below the line spanned by two other points in ROC space, we can use this information to repair the concavity. This effectively builds a hybrid model combining the two better models with an inversion of the poorer models; in the case of ranking classifiers, it means that certain intervals of the scores are identified as unreliable and candidates for inversion. We report very encouraging results on 23 UCI data sets, particularly for naive Bayes where the use of two validation folds yielded significant improvements on more than half of them, with only one loss.

#index 1289464
#* Inferring useful heuristics from the dynamics of iterative relational classifiers
#@ Aram Galstyan;Paul R. Cohen
#t 2005
#c 11
#% 290830
#% 420495
#% 466896
#% 496116
#% 748024
#% 769896
#% 891284
#! In this paper we consider dynamical properties of simple iterative relational classifiers. We conjecture that for a class of algorithms that use label-propagation the iterative procedure can lead to nontrivial dynamics in the number of newly classified instances. The underlaying reason for this nontriviality is that in relational networks true class labels are likely to propagate faster than false ones. We suggest that this phenomenon, which we call two-tiered dynamics for binary classifiers, can be used for establishing a self-consistent classification threshold and a criterion for stopping iteration. We demonstrate this effect for two unrelated binary classification problems using a variation of a iterative relational neighbor classifier. We also study analytically the dynamical properties of the suggested classifier, and compare its results to the numerical experiments on synthetic data.

#index 1289465
#* Learning coordination classifiers
#@ Yuhong Guo;Russell Greiner;Dale Schuurmans
#t 2005
#c 11
#% 136350
#% 235377
#% 246832
#% 360691
#% 387653
#% 464434
#% 578681
#% 722914
#% 763697
#% 1650318
#% 1650403
#! We present a new approach to ensemble classification that requires learning only a single base classifier. The idea is to learn a classifier that simultaneously predicts pairs of test labels--as opposed to learning multiple predictors for single test labels-- then coordinating the assignment of individual labels by propagating beliefs on a graph over the data. We argue that the approach is statistically well motivated, even for independent identically distributed (iid) data. In fact, we present experimental results that show improvements in classification accuracy over single-example classifiers, across a range of iid data sets and over a set of base classifiers. Like boosting, the technique increases representational capacity while controlling variance through a principled form of classifier combination.

#index 1289466
#* Generalization bounds for weighted binary classification with applications to statistical verification
#@ Vu Ha;Tariq Samad
#t 2005
#c 11
#% 66937
#% 137603
#% 179818
#% 190581
#% 359194
#% 425059
#% 1810542
#! We describe an approach to statistically verifying complex controllers. This approach is based on deriving practical Vapnik-Chervonenkis-style (VC) generalization bounds for binary classifiers with weighted loss. An important case is deriving bounds on the probability of false positive. We show how existing methods to derive bounds on classification error can be extended to derive similar bounds on the probability of false positive, as well as bounds in a decision-theoretic setting that allows tradeoffs between false negatives and false positives. We describe experiments using these bounds in statistically verifying computational properties of an iterative controller for an Organic Air Vehicle (OAV).

#index 1289467
#* The COMPSET algorithm for subset selection
#@ Yaniv Hamo;Shaul Markovitch
#t 2005
#c 11
#% 149628
#% 170667
#% 546966
#% 750050
#% 1272321
#! Subset selection problems are relevant in many domains. Unfortunately, their combinatorial nature prohibits solving them optimally in most cases. Local search algorithms have been applied to subset selection with varying degrees of success. This work presents COMPSET, a general algorithm for subset selection that invokes an existing local search algorithm from a random subset and its complementary set, exchanging information between the two runs to help identify wrong moves. Preliminary results on complex SAT, Max Clique, 0/1 Multidimensional Knapsack and Vertex Cover problems show that COMPSET improves the efficient stochastic hill climbing and tabu search algorithms by up to two orders of magnitudes.

#index 1289468
#* Combining memory and landmarks with predictive state representations
#@ Michael R. James;Britton Wolfe;Satinder Singh
#t 2005
#c 11
#% 770781
#% 770863
#% 788097
#! It has recently been proposed that it is advantageous to have models of dynamical systems be based solely on observable quantities. Predictive state representations (PSRs) are a type of model that uses predictions about future observations to capture the state of a dynamical system. However, PSRs do not use memory of past observations. We propose a model called memory-PSRs that uses both memories of the past, and predictions of the future. We show that the use of memories provides a number of potential advantages. It can reduce the size of the model (in comparison to a PSR model). In addition many dynamical systems have memories that can serve as landmarks that completely determine the current state. The detection and recognition of landmarks is advantageous because they can serve to reset a model that has gotten off-track, as often happens when the model is learned from samples. This paper develops both memory-PSRs and the use and detection of landmarks.

#index 1289469
#* Learning with labeled sessions
#@ Rong Jin;Huan Liu
#t 2005
#c 11
#% 136350
#% 190541
#% 224755
#% 235377
#% 272527
#% 312727
#% 464436
#% 565537
#% 578794
#% 770827
#! Traditional supervised learning deals with labeled instances. In many applications such as physiological data modeling and speaker identification, however, training examples are often labeled objects and each of the labeled objects consists of multiple unlabeled instances. When classifying a new object, its class is determined by the majority of its instance classes. As a consequence of this decision rule, one challenge to learning with labeled objects (or sessions) is to determine during training which subset of the instances inside an object should belong to the class of the object. We call this type of learning 'session-based learning' to distinguish it from the traditional supervised learning. In this paper, we introduce session-based learning problems, give a formal description of session-based learning in the context of related work, and propose an approach that is particularly designed for session-based learning. Empirical studies with UCI datasets and real-world data show that the proposed approach is effective for session-based learning.

#index 1289470
#* A novel approach to model generation for heterogeneous data classification
#@ Rong Jin;Huan Liu
#t 2005
#c 11
#% 33917
#% 131258
#% 132938
#% 136350
#% 290482
#% 302391
#% 313959
#% 420077
#% 424997
#% 1272365
#! Ensemble methods such as bagging and boosting have been successfully applied to classification problems. Two important issues associated with an ensemble approach are: how to generate models to construct an ensemble, and how to combine them for classification. In this paper, we focus on the problem of model generation for heterogeneous data classification. If we could partition heterogeneous data into a number of homogeneous partitions, we will likely generate reliable and accurate classification models over the homogeneous partitions. We examine different ways of forming homogeneous subsets and propose a novel method that allows a data point to be assigned multiple times in order to generate homogeneous partitions for ensemble learning. We present the details of the new algorithm and empirical studies over the UCI benchmark datasets and datasets of image classification, and show that the proposed approach is effective for heterogeneous data classification.

#index 1289471
#* State abstraction discovery from irrelevant state variables
#@ Nicholas K. Jong;Peter Stone
#t 2005
#c 11
#% 286423
#% 384911
#% 466731
#% 702594
#% 770775
#% 770777
#% 1271827
#% 1279356
#% 1478746
#% 1650283
#! Abstraction is a powerful form of domain knowledge that allows reinforcement-learning agents to cope with complex environments, but in most cases a human must supply this knowledge. In the absence of such prior knowledge or a given model, we propose an algorithm for the automatic discovery of state abstraction from policies learned in one domain for use in other domains that have similar structure. To this end, we introduce a novel condition for state abstraction in terms of the relevance of state features to optimal behavior, and we exhibit statistical methods that detect this condition robustly. Finally, we show how to apply temporal abstraction to benefit safely from even partial state abstraction in the presence of generalization error.

#index 1289472
#* Signal-to-score music transcription using graphical models
#@ Emir Kapanci;Avi Pfeffer
#t 2005
#c 11
#% 400984
#% 1271978
#% 1289247
#% 1775270
#! We present a transcription system that takes a music signal as input and returns its musical score. Two stages of processing are used. The first employs a fundamental frequency detector and an onset detector to transform input signals into a sequence of sound events. The onset detection is inherently noisy. This paper focuses on the second stage, going from sound events to a notated score. We use a family of graphical models for this task. We allow the results of onset detection to be noisy, necessitating a search over possible segmentations of the sound events. We use a large corpus of monophonic vocal music to evaluate our system. Our results show that our approach is well-suited to the problem of music transcription. The initial onset detection reduces the number of observations and makes the system less instrument specific. The search over segmentations corrects the errors in the onset detection. Without such reasoning, these errors are magnified in subsequent rhythm transcription.

#index 1289473
#* A hybrid discriminative/generative approach for modeling human activities
#@ Jonathan Lester;Tanzeem Choudhury;Nicky Kern;Gaetano Borriello;Blake Hannaford
#t 2005
#c 11
#% 277314
#% 304917
#% 496419
#% 549315
#% 632422
#% 970043
#% 1502497
#! Accurate recognition and tracking of human activities is an important goal of ubiquitous computing. Recent advances in the development of multi-modal wearable sensors enable us to gather rich datasets of human activities. However, the problem of automatically identifying the most useful features for modeling such activities remains largely unsolved. In this paper we present a hybrid approach to recognizing activities, which combines boosting to discriminatively select useful features and learn an ensemble of static classifiers to recognize different activities, with hidden Markov models (HMMs) to capture the temporal regularities and smoothness of activities. We tested the activity recognition system using over 12 hours of wearable-sensor data collected by volunteers in natural unconstrained environments. The models succeeded in identifying a small set of maximally informative features, and were able identify ten different human activities with an accuracy of 95%.

#index 1289474
#* Location-based activity recognition using relational Markov networks
#@ Lin Liao;Dieter Fox;Henry Kautz
#t 2005
#c 11
#% 464434
#% 723186
#% 724344
#% 788954
#% 816181
#% 1250174
#% 1650403
#% 1719312
#! In this paper we define a general framework for activity recognition by building upon and extending Relational Markov Networks. Using the example of activity recognition from location data, we show that our model can represent a variety of features including temporal information such as time of day, spatial information extracted from geographic databases, and global constraints such as the number of homes or workplaces of a person. We develop an efficient inference and learning technique based on MCMC. Using GPS location data collected by multiple people we show that the technique can accurately label a person's activity locations. Furthermore, we show that it is possible to learn good models from less data by using priors extracted from other people's data.

#index 1289475
#* Concurrent hierarchical reinforcement learning
#@ Bhaskara Marthi;Stuart Russell;David Latham;Carlos Guestrin
#t 2005
#c 11
#% 272662
#% 272663
#% 289947
#% 466230
#% 565550
#% 578674
#% 746859
#% 1271827
#% 1279355
#! We consider applying hierarchical reinforcement learning techniques to problems in which an agent has several effectors to control simultaneously. We argue that the kind of prior knowledge one typically has about such problems is best expressed using a multithreaded partial program, and present concurrent ALisp, a language for specifying such partial programs. We describe algorithms for learning and acting with concurrent ALisp that can be efficient even when there are exponentially many joint choices at each decision point. Finally, we show results of applying these methods to a complex computer game domain.

#index 1289476
#* Topic and role discovery in social networks
#@ Andrew McCallum;Andrés Corrada-Emmanuel;Xuerui Wang
#t 2005
#c 11
#% 722904
#% 769906
#! Previous work in social network analysis (SNA) has modeled the existence of links from one entity to another, but not the language content or topics on those links. We present the Author-Recipient-Topic (ART) model for social network analysis, which learns topic distributions based on the direction-sensitive messages sent between entities. The model builds on Latent Dirichlet Allocation (LDA) and the Author-Topic (AT) model, adding the key attribute that distribution over topics is conditioned distinctly on both the sender and recipient--steering the discovery of topics according to the relationships between people. We give results on both the Enron email corpus and a researcher's email archive, providing evidence not only that clearly relevant topics are discovered, but that the ART model better predicts people's roles.

#index 1289477
#* Training without data: knowledge insertion into RBF neural networks
#@ Ken McGarry;Stefan Wermter
#t 2005
#c 11
#% 143056
#% 171879
#% 229812
#% 332956
#% 1042868
#% 1289252
#% 1762961
#% 1780538
#% 1860031
#% 1860366
#% 1860667
#! A major problem when developing neural networks or machine diagnostics situations is that no data or very little data is available for training on fault conditions. However, the domain expert often has a good idea of what to expect in terms of input and output parameter values. If the expert can express these relationships in the form of rules, this would provide a resource too valuable to ignore. Fuzzy logic is used to handle the imprecision and vagueness of natural language and provides this additional advantage to a system. This paper investigates the development of a novel knowledge insertion algorithm that explores the benefits of prestructuring RBF neural networks by using prior fuzzy domain knowledge and previous training experiences. Pre-structuring is accomplished by using fuzzy rules gained from a domain expert and using them to modify existing Radial Basis Function (RBF) networks. The benefits and novel achievements of this work enable RBF neural networks to be trained without actual data but to rely on input to output mappings defined through expert knowledge.

#index 1289478
#* Unsupervised dimensionality estimation and manifold learning in high-dimensional spaces by tensor voting
#@ Philippos Mordohai;Gérard Medioni
#t 2005
#c 11
#% 251418
#% 266426
#% 341444
#% 389472
#% 593047
#% 723241
#% 1502529
#% 1759699
#! We address dimensionality estimation and nonlinear manifold inference starting from point inputs in high dimensional spaces using tensor voting. The proposed method operates locally in neighborhoods and does not involve any global computations. It is based on information propagation among neighboring points implemented as a voting process. Unlike other local approaches for manifold learning, the quantity propagated from one point to another is not a scalar, but is in the form of a tensor that provides considerably richer information. The accumulation of votes at each point provides a reliable estimate of local dimensionality, as well as of the orientation of a potential manifold going through the point. Reliable dimensionality estimation at the point level is a major advantage over competing methods. Moreover, the absence of global operations allows us to process significantly larger datasets. We demonstrate the effectiveness of our method on a variety of challenging datasets.

#index 1289479
#* Generalization error of linear neural networks in an empirical bayes approach
#@ Shinichi Nakajima;Sumio Watanabe
#t 2005
#c 11
#% 151214
#% 593036
#% 735504
#% 908664
#% 1650268
#% 1862599
#! It is well known that in unidentifiable models, the Bayes estimation has the advantage of generalization performance to the maximum likelihood estimation. However, accurate approximation of the posterior distribution requires huge computational costs. In this paper, we consider an empirical Bayes approach where a part of the parameters are regarded as hyperparameters, which we call a subspace Bayes approach, and theoretically analyze the generalization error of three-layer linear neural networks. We show that a subspace Bayes approach is asymptotically equivalent to a positivepart James-Stein type shrinkage estimation, and behaves similarly to the Bayes estimation in typical cases.

#index 1289480
#* Phase transitions within grammatical inference
#@ Nicolas Pernot;Antoine Cornuéjols;Michèle Sebag
#t 2005
#c 11
#% 190581
#% 210191
#% 238555
#% 425004
#% 464401
#% 466853
#% 542161
#% 723257
#! It is now well-known that the feasibility of inductive learning is ruled by statistical properties linking the empirical risk minimization principle and the "capacity" of the hypothesis space. The discovery, a few years ago, of a phase transition phenomenon in inductive logic programming proves that other fundamental characteristics of the learning problems may similarly affect the very possibility of learning under very general conditions. Our work examines the case of grammatical inference. We show that while there is no phase transition when considering the whole hypothesis space, there is a much more severe "gap" phenomenon affecting the effective search space of standard grammatical induction algorithms for deterministic finite automata (DFA). Focusing on the search heuristics of the RPNI and RED-BLUE algorithms, we show that they overcome this problem to some extent, but that they are subject to overgeneralization. The paper last suggests some directions for new generalization operators, suited to this Phase Transition phenomenon.

#index 1289481
#* Learning against opponents with bounded memory
#@ Rob Powers;Yoav Shoham
#t 2005
#c 11
#% 124691
#% 176293
#% 266286
#% 348821
#% 464437
#% 466739
#% 557575
#% 773295
#% 1279479
#! Recently, a number of authors have proposed criteria for evaluating learning algorithms in multiagent systems. While well-justified, each of these has generally given little attention to one of the main challenges of a multi-agent setting: the capability of the other agents to adapt and learn as well. We propose extending existing criteria to apply to a class of adaptive opponents with bounded memory. We then show an algorithm that provably achieves an o-best response against this richer class of opponents while simultaneously guaranteeing a minimum payoff against any opponent and performing well in self-play. This new algorithm also demonstrates strong performance in empirical tests against a variety of opponents in a wide range of environments.

#index 1289482
#* ROCCER: an algorithm for rule learning based on ROC analysis
#@ Ronaldo C. Prati;Peter A. Flach
#t 2005
#c 11
#% 136350
#% 209023
#% 277919
#% 283138
#% 331909
#% 449566
#% 458178
#% 466744
#% 580510
#% 717537
#% 763701
#% 770817
#% 799042
#! We introduce a rule selection algorithm called ROCCER, which operates by selecting classification rules from a larger set of rules - for instance found by Apriori - using ROC analysis. Experimental comparison with rule induction algorithms shows that ROCCER tends to produce considerably smaller rule sets with compatible Area Under the ROC Curve (AUC) values. The individual rules that compose the rule set also have higher support and stronger association indexes.

#index 1289483
#* Stepwise nearest neighbor discriminant analysis
#@ Xipeng Qiu;Lide Wu
#t 2005
#c 11
#% 80995
#% 209623
#% 235342
#% 723024
#% 729437
#% 1022958
#! Linear Discriminant Analysis (LDA) is a popular feature extraction technique in statistical pattern recognition. However, it often suffers from the small sample size problem when dealing with the high dimensional data. Moreover, while LDA is guaranteed to find the best directions when each class has a Gaussian density with a common covariance matrix, it can fail if the class densities are more general. In this paper, a new nonparametric feature extraction method, stepwise nearest neighbor discriminant analysis(SNNDA), is proposed from the point of view of the nearest neighbor classification. SNNDA finds the important discriminant directions without assuming the class densities belong to any particular parametric family. It does not depend on the nonsingularity of the within-class scatter matrix either. Our experimental results demonstrate that SNNDA outperforms the existing variant LDA methods and the other state-of-art face recognition approaches on three datasets from ATT and FERET face databases.

#index 1289484
#* Using predictive representations to improve generalization in reinforcement learning
#@ Eddie J. Rafols;Mark B. Ring;Richard S. Sutton;Brian Tanner
#t 2005
#c 11
#% 158924
#% 199975
#% 384911
#% 702594
#% 1279471
#! The predictive representations hypothesis holds that particularly good generalization will result from representing the state of the world in terms of predictions about possible future experience. This hypothesis has been a central motivation behind recent research in, for example, PSRs and TD networks. In this paper we present the first explicit investigation of this hypothesis. We show in a reinforcement-learning example (a grid-world navigation task) that a predictive representation in tabular form can learn much faster than both the tabular explicit-state representation and a tabular history-based method.

#index 1289485
#* InterActive feature selection
#@ Hema Raghavan;Omid Madani;Rosie Jones
#t 2005
#c 11
#% 86528
#% 115521
#% 124708
#% 170649
#% 344447
#% 464465
#% 722797
#% 769908
#% 799753
#% 836019
#% 938686
#! We study the effects of feature selection and human feedback on features in active learning settings. Our experiments on a variety of text categorization tasks indicate that there is significant potential in improving classifier performance by feature reweighting, beyond that achieved via selective sampling alone (standard active learning) if we have access to an oracle that can point to the important (most predictive) features. Consistent with previous findings, we find that feature selection based on the labeled training set has little effect. But our experiments on human subjects indicate that human feedback on feature relevance can identify a sufficient proportion (65%) of the most relevant features. Furthermore, these experiments show that feature labeling takes much less (about 1/5th) time than document labeling. We propose an algorithm that interleaves labeling features and documents which significantly accelerates active learning.

#index 1289486
#* Generative modeling with failure in PRISM
#@ Taisuke Sato;Yoshitaka Kameya;Neng-Fa Zhou
#t 2005
#c 11
#% 68077
#% 103705
#% 228812
#% 233132
#% 363747
#% 379345
#% 399653
#% 741139
#% 769801
#% 1271907
#% 1272388
#! PRISM is a logic-based Turing-complete symbolic-statistical modeling language with a built-in parameter learning routine. In this paper,we enhance the modeling power of PRISM by allowing general PRISM programs to fail in the generation process of observable events. Introducing failure extends the class of definable distributions but needs a generalization of the semantics of PRISM programs. We propose a three valued probabilistic semantics and show how failure enables us to pursue constraint-based modeling of complex statistical phenomena.

#index 1289487
#* Evolino: hybrid neuroevolution / optimal linear search for sequence learning
#@ Jürgen Schmidhuber;Daan Wierstra;Faustino Gomez
#t 2005
#c 11
#% 190581
#% 203594
#% 495781
#% 959478
#% 1042867
#% 1860873
#! Current Neural Network learning algorithms are limited in their ability to model non-linear dynamical systems. Most supervised gradient-based recurrent neural networks (RNNs) suffer from a vanishing error signal that prevents learning from inputs far in the past. Those that do not, still have problems when there are numerous local minima. We introduce a general framework for sequence learning, EVOlution of recurrent systems with LINear outputs (Evolino). Evolino uses evolution to discover good RNN hidden node weights, while using methods such as linear regression or quadratic programming to compute optimal linear mappings from hidden state to output. Using the Long Short-Term Memory RNN Architecture, the method is tested in three very different problem domains: 1) context-sensitive languages, 2) multiple superimposed sine waves, and 3) the Mackey-Glass system. Evolino performs exceptionally well across all tasks, where other methods show notable deficiencies in some.

#index 1289488
#* A multi-objective multi-modal optimization approach for mining stable spatio-temporal patterns
#@ Michèle Sebag;Nicolas Tarrisson;Olivier Teytaud;Julien Lefevre;Sylvain Baillet
#t 2005
#c 11
#% 218098
#% 310577
#% 392343
#% 409585
#% 443515
#% 449997
#% 449999
#% 729917
#% 755055
#% 769691
#% 783479
#! This paper, motivated by functional brain imaging applications, is interested in the discovery of stable spatio-temporal patterns. This problem is formalized as a multi-objective multi-modal optimization problem: on one hand, the target patterns must show a good stability in a wide spatio-temporal region (antagonistic objectives); on the other hand, experts are interested in finding all such patterns (global and local optima). The proposed algorithm, termed 4D-Miner, is empirically validated on artificial and real-world datasets; it shows good performances and scalability, detecting target spatiotemporal patterns within minutes from 400+ Mo datasets.

#index 1289489
#* Temporal-difference networks with history
#@ Brian Tanner;Richard S. Sutton
#t 2005
#c 11
#% 651665
#% 770863
#% 788097
#! Temporal-difference (TD) networks are a formalism for expressing and learning grounded world knowledge in a predictive form [Sutton and Tanner, 2005]. However, not all partially observable Markov decision processes can be efficiently learned with TD networks. In this paper, we extend TD networks by allowing the network-update process (answer network) to depend on the recent history of previous actions and observations rather than only on the most recent action and observation. We show that this extension enables the solution of a larger class of problems than can be solved by the original TD networks or by history-based methods alone. In addition, we apply TD networks to a problem that, while still simple, is significantly larger than has previously been considered. We show that history-extended TD networks can learn much of the common-sense knowledge of an egocentric gridworld domain with a single bit of perception.

#index 1289490
#* Learning to play like the great pianists
#@ Asmir Tobudic;Gerhard Widmer
#t 2005
#c 11
#% 731215
#% 883331
#! An application of relational instance-based learning to the complex task of expressive music performance is presented. We investigate to what extent a machine can automatically build 'expressive profiles' of famous pianists using only minimal performance information extracted from audio CD recordings by pianists and the printed score of the played music. It turns out that the machine-generated expressive performances on unseen pieces are substantially closer to the real performances of the 'trainer' pianist than those of all others. Two other interesting applications of the work are discussed: recognizing pianists from their style of playing, and automatic style replication.

#index 1289491
#* Sequential genetic search for ensemble feature selection
#@ Alexey Tsymbal;Mykola Pechenizkiy;Pádraig Cunningham
#t 2005
#c 11
#% 142546
#% 160862
#% 246831
#% 256615
#% 283145
#% 342639
#% 424997
#% 637522
#% 1777136
#! Ensemble learning constitutes one of the main directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. One technique, which proved to be effective for constructing an ensemble of diverse classifiers, is the use of feature subsets. Among different approaches to ensemble feature selection, genetic search was shown to perform best in many domains. In this paper, a new strategy GAS-SEFS, Genetic Algorithmbased Sequential Search for Ensemble Feature Selection, is introduced. Instead of one genetic process, it employs a series of processes, the goal of each of which is to build one base classifier. Experiments on 21 data sets are conducted, comparing the new strategy with a previously considered genetic strategy for different ensemble sizes and for five different ensemble integration methods. The experiments show that GAS-SEFS, although being more time-consuming, often builds better ensembles, especially on data sets with larger numbers of features.

#index 1289492
#* Stereotype extraction with default clustering
#@ Julien Velcin;Jean-Gabriel Ganascia
#t 2005
#c 11
#% 383492
#% 451052
#% 697024
#% 717497
#! The concept of stereotype seems to be really adapted when wishing to extract meaningful descriptions from data, especially when there is a high rate of missing values. This paper proposes a logical framework called default clustering based on default reasoning and local search techniques. The first experiment deals with the rediscovering of initial descriptions from artificial data sets, the second one extracts stereotypes of politicians in a real case generated from newspaper articles. It is shown that default clustering is more adapted in this context than the three classical clusterers considered.

#index 1289493
#* Learning subjective representations for planning
#@ Dana Wilkinson;Michael Bowling;Ali Ghodsi
#t 2005
#c 11
#% 157736
#% 363744
#% 770781
#% 770863
#% 857087
#% 1502529
#! Planning involves using a model of an agent's actions to find a sequence of decisions which achieve a desired goal. It is usually assumed that the models are given, and such models often require expert knowledge of the domain. This paper explores subjective representations for planning that are learned directly from agent observations and actions (requiring no initial domain knowledge). A non-linear embedding technique called Action Respecting Embedding is used to construct such a representation. It is then shown how to extract the effects of the agent's actions as operators in this learned representation. Finally, the learned representation and operators are combined with search to find sequences of actions that achieve given goals. The efficacy of this technique is demonstrated in a challenging robot-vision-inspired image domain.

#index 1289494
#* Maximum a posteriori path estimation with input trace perturbation: algorithms and application to credible rating of human routines
#@ Daniel H. Wilson;Matthai Philipose
#t 2005
#c 11
#% 788954
#% 1264970
#! Rating how well a routine activity is performed can be valuable in a variety of domains. Making the rating inexpensive and credible is a key aspect of the problem. We formalize the problem as MAP estimation in HMMs where the incoming trace needs repair. We present polynomial time algorithms for computing minimal repairs with maximal likelihood for HMMs, Hidden Semi-Markov Models (HSMMs) and a form of HMMs constrained with a fragment of the temporal logic LTL. We present some results to show the promise of our approach.

#index 1289495
#* Mining spatial object associations for scientific data
#@ Hui Yang;Srinivasan Parthasarathy;Sameep Mehta
#t 2005
#c 11
#% 259704
#% 280417
#% 342604
#% 342635
#% 413199
#% 527021
#% 527188
#% 629708
#% 678196
#% 727910
#% 769914
#% 786307
#! In this paper, we present efficient algorithms to discover spatial associations among features extracted from scientific datasets. In contrast to previous work in this area, features are modeled as geometric objects rather than points. We define multiple distance metrics that take into account objects' extent. We have developed algorithms to discover two types of spatial association patterns in scientific data. We present experimental results to demonstrate the efficacy of our approach on real datasets drawn from the bioinformatic domain. We also highlight the importance of the discovered patterns by integrating the underlying domain knowledge.

#index 1289496
#* Semi-supervised regression with co-training
#@ Zhi-Hua Zhou;Ming Li
#t 2005
#c 11
#% 252011
#% 311027
#% 316509
#% 400985
#% 466263
#% 466888
#% 565545
#% 811376
#% 816079
#! In many practical machine learning and data mining applications, unlabeled training examples are readily available but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. Previous research mainly focuses on semi-supervised classification. In this paper, a co-training style semi-supervised regression algorithm, i.e. COREG, is proposed. This algorithm uses two k-nearest neighbor regressors with different distance metrics, each of which labels the unlabeled data for the other regressor where the labeling confidence is estimated through consulting the influence of the labeling of unlabeled examples on the labeled ones. Experiments show that COREG can effectively exploit unlabeled data to improve regression estimates.

#index 1289497
#* On the axiomatic foundations of ranking systems
#@ Alon Altman;Moshe Tennenholtz
#t 2005
#c 11
#% 100137
#% 316798
#% 480348
#% 782310
#% 788101
#% 808358
#% 1272026
#% 1650358
#! Reasoning about agent preferences on a set of alternatives, and the aggregation of such preferences into some social ranking is a fundamental issue in reasoning about multi-agent systems. When the set of agents and the set of alternatives coincide, we get the ranking systems setting. A famous type of ranking systems are page ranking systems in the context of search engines. In this paper we present an extensive axiomatic study of ranking systems. In particular, we consider two fundamental axioms: Transitivity, and Ranked Independence of Irrelevant Alternatives. Surprisingly, we find that there is no general social ranking rule that satisfies both requirements. Furthermore, we show that our impossibility result holds under various restrictions on the class of ranking problems considered. Each of these axioms can be individually satisfied. Moreover, we show a complete axiomatization of approval voting using one of these axioms.

#index 1289498
#* Sequential-simultaneous information elicitation in multi-agent systems
#@ Gal Bahar;Moshe Tennenholtz
#t 2005
#c 11
#% 580548
#% 631039
#% 765317
#% 788099
#% 1672988
#! We introduce a general setting for information elicitation in multi-agent systems, where agents may be approached both sequentially and simultaneously in order to compute a function that depends on their private secrets. We consider oblivious mechanisms for sequential-simultaneous information elicitation. In such mechanisms the ordering of agents to be approached is fixed in advance. Surprisingly, we show that these mechanisms, which are easy to represent and implement are sufficient for very general settings, such as for the classical uniform model, where agents' secret bits are uniformly distributed, and for the computation of the majority function and other classical threshold functions. Moreover, we provide efficient algorithms for the verification of the existence of the desired elicitation mechanisms, and for synthesizing such mechanisms.

#index 1289499
#* Regret-based utility elicitation in constraint-based decision problems
#@ Craig Boutilier;Relu Patrascu;Pascal Poupart;Dale Schuurmans
#t 2005
#c 11
#% 230551
#% 341926
#% 445247
#% 528176
#% 529348
#% 578692
#% 1250151
#% 1275309
#% 1279257
#% 1650628
#% 1784525
#! We propose new methods of preference elicitation for constraint-based optimization problems based on the use of minimax regret. Specifically, we assume a constraintbased optimization problem (e.g., product configuration) in which the objective function (e.g., consumer preferences) are unknown or imprecisely specified. Assuming a graphical utility model, we describe several elicitation strategies that require the user to answer only binary (bound) queries on the utility model parameters. While a theoretically motivated algorithm can provably reduce regret quickly (in terms of number of queries), we demonstrate that, in practice, heuristic strategies perform much better, and are able to find optimal (or near-optimal) configurations with far fewer queries.

#index 1289500
#* Efficiency and envy-freeness in fair division of indivisible goods
#@ Sylvain Bouveret;Jérôme Lang
#t 2005
#c 11
#% 754147
#% 767712
#% 819611
#% 824064
#! We study fair division of indivisible goods among agents from the point of view of compact representation and computational complexity. We identify the complexity of several problems, including that of deciding whether there exists an efficient and envy-free allocation when preferences are represented in a succinct way. We also draw connections to nonmonotonic reasoning.

#index 1289501
#* On maximal classes of utility functions for efficient one-to-one negotiation
#@ Yann Chevaleyre;Ulle Endriss;Nicolas Maudet
#t 2005
#c 11
#% 36698
#% 392811
#% 643101
#% 818584
#% 819611
#% 823882
#% 1013352
#! We investigate the properties of an abstract negotiation framework where agents autonomously negotiate over allocations of discrete resources. In this framework, reaching an optimal allocation potentially requires very complex multilateral deals. Therefore, we are interested in identifying classes of utility functions such that any negotiation conducted by means of deals involving only a single resource at at time is bound to converge to an optimal allocation whenever all agents model their preferences using these functions. We show that the class of modular utility functions is not only sufficient but also maximal in this sense.

#index 1289502
#* Two-sided bandits and the dating market
#@ Sanmay Das;Emir Kamenica
#t 2005
#c 11
#% 348821
#% 384911
#% 416988
#! We study the decision problems facing agents in repeated matching environments with learning, or two-sided bandit problems, and examine the dating market, in which men and women repeatedly go out on dates and learn about each other, as an example. We consider three natural matching mechanisms and empirically examine properties of these mechanisms, focusing on the asymptotic stability of the resulting matchings when the agents use a simple learning rule coupled with an ε-greedy exploration policy. Matchings tend to be more stable when agents are patient in two different ways -- if they are more likely to explore early or if they are more optimistic. However, the two forms of patience do not interact well in terms of increasing the probability of stable outcomes. We also define a notion of regret for the two-sided problem and study the distribution of regrets under the different matching mechanisms.

#index 1289503
#* Multi-agent coordination using local search
#@ Boi Faltings;Quang-Huy Nguyen
#t 2005
#c 11
#% 160270
#% 314944
#% 1279324
#! We consider the problem of coordinating the behavior of multiple self-interested agents. It involves constraint optimization problems that often can only be solved by local search algorithms. Using local search poses problems of incentivecompatibility and individual rationality. We thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. We observe that in real life, manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. We show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.

#index 1289504
#* More on the power of demand queries in combinatorial auctions: learning atomic languages and handling incentives
#@ Sébastien Lahaie;Florin Constantin;David C. Parkes
#t 2005
#c 11
#% 314918
#% 341943
#% 382586
#% 558906
#% 578711
#% 754153
#% 763719
#! Query learning models from computational learning theory (CLT) can be adopted to perform elicitation in combinatorial auctions. Indeed, a recent elicitation framework demonstrated that the equivalence queries of CLT can be usefully simulated with price-based demand queries. In this paper, we validate the flexibility of this framework by defining a learning algorithm for atomic bidding languages, a class that includes XOR and OR. We also handle incentives, characterizing the communication requirements of the Vickrey-Clarke-Groves outcome rule. This motivates an extension to the earlier learning framework that brings truthful responses to queries into an equilibrium.

#index 1289505
#* The role of clustering on the emergence of efficient social conventions
#@ Josep M. Pujol;Jordi Delgado;Ramon Sangüesa;Andreas Flache
#t 2005
#c 11
#% 233136
#% 428342
#! Multiagent models of the emergence of social conventions have demonstrated that global conventions can arise from local coordination processes without a central authority. We further develop and extend previous work to address how and under what conditions emerging conventions are also socially efficient, i.e. better for all agents than potential alternative conventions. We show with computational experiments that the clustering coefficient of the networks within which agents interact is an important condition for efficiency. We also develop an analytical approximation of the simulation model that sheds some light to the original model behavior. Finally, we combine two decision mechanisms, local optimization and imitation, to study the competition between efficient and attractive actions. Our main result is that in clustered networks a society converges to an efficient convention and is stable against invasion of sub-optimal conventions under a much larger range of conditions than in a non-clustered network. On the contrary, in non-clustered networks the convention finally established heavily depends on its initial support.

#index 1289506
#* Distributive and collective readings in group protocols
#@ Silvia Rossi;Sanjeev Kumar;Philip R. Cohen
#t 2005
#c 11
#% 326788
#% 529170
#% 748668
#% 822359
#! Collaborative applications require protocols that specify how distributed entities interact with one another in order to achieve a specified behavior. Many different kinds of relationships can be established between these entities as a result of such interactions. Distributive and Collective readings are two important ways to characterize group interaction. Starting from an attempt-based semantics of group communicative acts, we distinguish between these two concepts and evaluate group protocols with respect to formation of different types of teams during the interaction.

#index 1289507
#* Learning payoff functions in infinite games
#@ Yevgeniy Vorobeychik;Michael P. Wellman;Satinder Singh
#t 2005
#c 11
#% 190581
#% 229931
#% 269217
#% 789557
#% 806741
#% 1271991
#! We consider a class of games with real-valued strategies and payoff information available only in the form of data from a given sample of strategy profiles. Solving such games with respect to the underlying strategy space requires generalizing from the data to a complete payoff-function representation. We address payoff-function learning as a standard regression problem, with provision for capturing known structure (symmetry) in the multiagent environment. To measure learning performance, we consider the relative utility of prescribed strategies, rather than the accuracy of payoff functions per se. We demonstrate our approach and evaluate its effectiveness on two examples: a two-player version of the first-price sealed-bid auction (with known analytical form), and a five-player marketbased scheduling game (with no known solution).

#index 1289508
#* A logical model of Nash bargaining solution
#@ Dongmo Zhang
#t 2005
#c 11
#% 263126
#% 557217
#% 781207
#% 819412
#% 1250165
#% 1250169
#! This paper presents a logical extension of Nash's Cooperative Bargaining Theory. We introduce a concept of entrenchment measurement, which maps propositions to real numbers, as a vehicle to represent agent's belief states and attitudes towards bargaining situations. We show that Nash's bargaining solution can be restated in terms of bargainers belief states. Negotiable items, bargaining outcomes and conflicting arguments can then be explicitly expressed in propositional logic meanwhile Nash's numerical solution to bargaining problem is still applicable.

#index 1289509
#* A two-stage method for active learning of statistical grammars
#@ Markus Becker;Miles Osborne
#t 2005
#c 11
#% 99686
#% 116165
#% 169717
#% 209021
#% 466231
#% 565531
#% 713324
#% 740916
#% 742092
#% 742205
#% 742218
#% 746865
#% 748465
#% 815878
#% 843647
#% 853848
#! Active learning reduces the amount of manually annotated sentences necessary when training state-of-the-art statistical parsers. One popular method, uncertainty sampling, selects sentences for which the parser exhibits low certainty. However, this method does not quantify confidence about the current statistical model itself. In particular, we should be less confident about selection decisions based on low frequency events. We present a novel two-stage method which first targets sentences which cannot be reliably selected using uncertainty sampling, and then applies standard uncertainty sampling to the remaining sentences. An evaluation shows that this method performs better than pure uncertainty sampling, and better than an ensemble method based on bagged ensemble members only.

#index 1289510
#* TimeML-compliant text analysis for temporal reasoning
#@ Branimir Boguraev;Rie Kubota Ando
#t 2005
#c 11
#% 309124
#% 722822
#% 757292
#% 772012
#% 772013
#% 816210
#% 817550
#% 938754
#! Reasoning with time needs more than just a list of temporal expressions. TimeML--an emerging standard for temporal annotation as a language capturing properties and relationships among timedenoting expressions and events in text--is a good starting point for bridging the gap between temporal analysis of documents and reasoning with the information derived from them. Hard as TimeML-compliant analysis is, the small size of the only currently available annotated corpus makes it even harder. We address this problem with a hybrid TimeML annotator, which uses cascaded finite-state grammars (for temporal expression analysis, shallow syntactic parsing, and feature generation) together with a machine learning component capable of effectively using large amounts of unannotated data.

#index 1289511
#* Viewing referring expression generation as search
#@ Bernd Bohnet;Robert Dale
#t 2005
#c 11
#% 174161
#% 375503
#% 448787
#% 579945
#% 689870
#% 744674
#% 746889
#% 748498
#% 756920
#% 786524
#% 854271
#! Almost all natural language generation (NLG) systems are faced with the problem of the generation of referring expressions (GRE): given a symbol corresponding to an intended referent, how do we work out the semantic content of a referring expression that uniquely identifies the entity in question? This is now one of the most widely explored problems in NLG: over the last 15 years, a number of algorithms have been proposed for addressing different aspects of this problem, but the different approaches taken make it very difficult to compare and contrast the algorithms provided in any meaningful way. In this paper, we show how viewing the problem of referring expression generation as a search problem allows us to recast existing algorithms in a way that makes their similarities and differences clear.

#index 1289512
#* Word sense disambiguation with distribution estimation
#@ Yee Seng Chan;Hwee Tou Ng
#t 2005
#c 11
#% 450870
#% 817476
#% 817596
#% 853864
#% 854641
#% 938688
#% 939825
#% 1250278
#% 1910924
#% 1910925
#! A word sense disambiguation (WSD) system trained on one domain and applied to a different domain will show a decrease in performance. One major reason is the different sense distributions between different domains. This paper presents novel application of two distribution estimation algorithms to provide estimates of the sense distribution of the new domain data set. Even though our training examples are automatically gathered from parallel corpora, the sense distributions estimated are good enough to achieve a relative improvement of 56% when incorporated into our WSD system.

#index 1289513
#* A probabilistic learning method for XML annotation of documents
#@ Boris Chidlovskii;Jérôme Fuselier
#t 2005
#c 11
#% 211044
#% 299944
#% 427027
#% 464434
#% 466892
#% 659925
#% 718609
#% 854813
#% 1279275
#! We consider the problem of semantic annotation of semi-structured documents according to a target XML schema. The task is to annotate a document in a tree-like manner where the annotation tree is an instance of a tree class defined by DTD or W3C XML Schema descriptions. In the probabilistic setting, we cope with the tree annotation problem as a generalized probabilistic context-free parsing of an observation sequence where each observation comes with a probability distribution over terminals supplied by a probabilistic classifier associated with the content of documents. We determine the most probable tree annotation by maximizing the joint probability of selecting a terminal sequence for the observation sequence and the most probable parse for the selected terminal sequence.

#index 1289514
#* Maps for verbs: the relation between interaction dynamics and verb use
#@ Paul R. Cohen;Clayton T. Morrison;Erin Cannon
#t 2005
#c 11
#% 188076
#% 266285
#% 283197
#% 329443
#% 642923
#% 1272377
#! We report a study of word meaning that tests whether dynamical aspects of movies predict word use. The movies were based on a novel representation of verb semantics called maps for verbs. We asked preschool-school-age children to describe the movies, and demonstrated that their distributions of words could be predicted by the dynamical aspects of the movies. These results lend support to the empiricist position that word meanings are learned associatively.

#index 1289515
#* Learning to understand web site update requests
#@ William W. Cohen;Einat Minkov;Anthony Tomasic
#t 2005
#c 11
#% 196896
#% 252034
#% 340903
#% 452991
#% 571396
#% 748705
#% 854636
#! Although Natural Language Processing (NLP) for requests for information has been well-studied, there has been little prior work on understanding requests to update information. In this paper, we propose an intelligent system that can process natural language website update requests semi-automatically. In particular, this system can analyze requests, posted via email, to update the factual content of individual tuples in a database-backed website. Users' messages are processed using a scheme decomposing their requests into a sequence of entity recognition and text classification tasks. Using a corpus generated by human-subject experiments, we experimentally evaluate the performance of this system, as well as its robustness in handling request types not seen in training, or user-specific language styles not seen in training.

#index 1289516
#* A probabilistic model of redundancy in information extraction
#@ Doug Downey;Oren Etzioni;Stephen Soderland
#t 2005
#c 11
#% 283180
#% 301241
#% 754068
#% 815916
#% 830520
#% 1264970
#! Unsupervised Information Extraction (UIE) is the task of extracting knowledge from text without using hand-tagged training examples. A fundamental problem for both UIE and supervised IE is assessing the probability that extracted information is correct. In massive corpora such as the Web, the same extraction is found repeatedly in different documents. How does this redundancy impact the probability of correctness? This paper introduces a combinatorial "balls-andurns" model that computes the impact of sample size, redundancy, and corroboration from multiple distinct extraction rules on the probability that an extraction is correct. We describe methods for estimating the model's parameters in practice and demonstrate experimentally that for UIE the model's log likelihoods are 15 times better, on average, than those obtained by Pointwise Mutual Information (PMI) and the noisy-or model used in previous work. For supervised IE, the model's performance is comparable to that of Support Vector Machines, and Logistic Regression.

#index 1289517
#* A probabilistic framework for recognizing intention in information graphics
#@ Stephanie Elzer;Sandra Carberry;Ingrid Zukerman;Daniel Chester;Nancy Green;Seniz Demir
#t 2005
#c 11
#% 147680
#% 180201
#% 205882
#% 292187
#% 740962
#% 780433
#% 939359
#% 1133833
#! This paper extends language understanding and plan inference to information graphics. We identify the kinds of communicative signals that appear in information graphics, describe how we utilize them in a Bayesian network that hypothesizes the graphic's intended message, and discuss the performance of our implemented system. This work is part of a larger project aimed at making information graphics accessible to individuals with sight impairments.

#index 1289518
#* Feature generation for text categorization using world knowledge
#@ Evgeniy Gabrilovich;Shaul Markovitch
#t 2005
#c 11
#% 86531
#% 90262
#% 147065
#% 260001
#% 266284
#% 280817
#% 344447
#% 413955
#% 425047
#% 458379
#% 466573
#% 763708
#% 766444
#% 770810
#% 854646
#! We enhance machine learning algorithms for text categorization with generated features based on domain-specific and common-sense knowledge. This knowledge is represented using publicly available ontologies that contain hundreds of thousands of concepts, such as the Open Directory; these ontologies are further enriched by several orders of magnitude through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts, which in turn induce a set of generated features that augment the standard bag of words. Feature generation is accomplished through contextual analysis of document text, implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses the two main problems of natural language processing--synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the documents alone. Experimental results confirm improved performance, breaking through the plateau previously reached in the field.

#index 1289519
#* Learning strategies for open-domain natural language question answering
#@ Eugene Grois;David C. Wilkins
#t 2005
#c 11
#% 172505
#% 196896
#% 280088
#% 495943
#% 741888
#% 742217
#% 786549
#% 853665
#% 853667
#% 1272286
#% 1272292
#! We present an approach to automatically learning strategies for natural language question answering from examples composed of textual sources, questions, and answers. Our approach formulates QA as a problem of first order inference over a suitably expressive, learned representation. This framework draws on prior work in learning action and problem-solving strategies, as well as relational learning methods. We describe the design of a system implementing this model in the framework of natural language question answering for story comprehension. Finally, we compare our approach to three prior systems, and present experimental results demonstrating the efficacy of our model.

#index 1289520
#* Shallow semantics for relation extraction
#@ Sanda Harabagiu;Cosmin Adrian Bejan;Paul Morarescu
#t 2005
#c 11
#% 452991
#% 817420
#% 818065
#% 823311
#% 854645
#% 938670
#% 938706
#! This paper presents a new method for extracting meaningful relations from unstructured natural language sources. The method is based on information made available by shallow semantic parsers. Semantic information was used (1) to enhance a dependency tree kernel; and (2) to build semantic dependency structures used for enhanced relation extraction for several semantic classifiers. In our experiments the quality of the extracted relations surpassed the results of kernel-based models employing only semantic class information.

#index 1289521
#* Semantic argument classification exploiting argument interdependence
#@ Zheng Ping Jiang;Jia Li;Hwee Tou Ng
#t 2005
#c 11
#% 747891
#% 816081
#% 817605
#% 823311
#% 855272
#% 939827
#% 939845
#! This paper describes our research on automatic semantic argument classification, using the PropBank data [Kingsbury et al., 2002]. Previous research employed features that were based either on a full parse or shallow parse of a sentence. These features were mostly based on an individual semantic argument and the relation between the predicate and a semantic argument, but they did not capture the interdependence among all arguments of a predicate. In this paper, we propose the use of the neighboring semantic arguments of a predicate as additional features in determining the class of the current semantic argument. Our experimental results show significant improvement in the accuracy of semantic argument classification after exploiting argument interdependence. Argument classification accuracy on the standard Section 23 test set improves to 90.50%, representing a relative error reduction of 18%.

#index 1289522
#* Automatic text-to-scene conversion in the traffic accident domain
#@ Richard Johansson;Anders Berglund;Magnus Danielsson;Pierre Nugues
#t 2005
#c 11
#% 136350
#% 292467
#% 340405
#% 341657
#% 452991
#% 740995
#% 817420
#% 854241
#% 1277326
#! In this paper, we describe a system that automatically converts narratives into 3D scenes. The texts, written in Swedish, describe road accidents. One of the program's key features is that it animates the generated scene using temporal relations between the events. We believe that this system is the first text-to-scene converter that is not restricted to invented narratives. The system consists of three modules: natural language interpretation based on information extraction (IE) methods, a planning module that produces a geometric description of the accident, and finally a visualization module that renders the geometric description as animated graphics. An evaluation of the system was carried out in two steps: First, we used standard IE scoring methods to evaluate the language interpretation. The results are on the same level as for similar systems tested previously. Secondly, we performed a small user study to evaluate the quality of the visualization. The results validate our choice of methods, and since this is the first evaluation of a text-to-scene conversion system, they also provide a baseline for further studies.

#index 1289523
#* Redundancy-free island parsing of word graphs
#@ Bernd Kiefer
#t 2005
#c 11
#% 19901
#% 167627
#% 741092
#! Island parsing is a bidirectional parsing strategy mostly used in speech analysis, as well as in applications where robustness is highly relevant and/or processing resources are limited. Although there exists an efficient redundancy-free island parsing algorithm for string input, it has not yet been applied to word graph input, an application which is central for speech analysis systems. This paper describes how the established algorithm can be generalized from string input to word graphs, increasing its flexibility by integrating the selection of island seeds into the search process inherent to parsing.

#index 1289524
#* Automatic evaluation of text coherence: models and representations
#@ Mirella Lapata;Regina Barzilay
#t 2005
#c 11
#% 90661
#% 190444
#% 200694
#% 286069
#% 465914
#% 708948
#% 740329
#% 741809
#% 815902
#% 816173
#% 854256
#% 1275285
#! This paper investigates the automatic evaluation of text coherence for machine-generated texts. We introduce a fully-automatic, linguistically rich model of local coherence that correlates with human judgments. Our modeling approach relies on shallow text properties and is relatively inexpensive. We present experimental results that assess the predictive power of various discourse representations proposed in the linguistic literature. Our results demonstrate that certain models capture complementary aspects of coherence and thus can be combined to improve performance.

#index 1289525
#* Semantic annotation of unstructured and ungrammatical text
#@ Matthew Michelson;Craig A. Knoblock
#t 2005
#c 11
#% 269217
#% 278109
#% 314740
#% 333943
#% 431536
#% 445444
#% 459484
#% 459490
#% 654467
#% 729913
#% 754104
#% 769877
#% 769884
#% 770763
#% 788107
#% 830525
#% 1289318
#! There are vast amounts of free text on the internet that are neither grammatical nor formally structured, such as item descriptions on Ebay or internet classifieds like Craig's list. These sources of data, called "posts," are full of useful information for agents scouring the Semantic Web, but they lack the semantic annotation to make them searchable. Annotating these posts is difficult since the text generally exhibits little formal grammar and the structure of the posts varies. However, by leveraging collections of known entities and their common attributes, called "reference sets," we can annotate these posts despite their lack of grammar and structure. To use this reference data, we align a post to a member of the reference set, and then exploit this matched member during information extraction. We compare this extraction approach to more traditional information extraction methods that rely on structural and grammatical characteristics, and we show that our approach outperforms traditional methods on this type of data.

#index 1289526
#* Temporal context representation and reasoning
#@ Dan Moldovan;Christine Clark;Sanda Harabagiu
#t 2005
#c 11
#% 45220
#% 344361
#% 740902
#% 815320
#% 816081
#% 816175
#% 817550
#% 854252
#! This paper demonstrates how a model for temporal context reasoning can be implemented. The approach is to detect temporally related events in natural language text and convert the events into an enriched logical representation. Reasoning is provided by a first order logic theorem prover adapted to text. Results show that temporal context reasoning boosts the performance of a Question Answering system.

#index 1289527
#* A machine learning approach to identification and resolution of one-anaphora
#@ Hwee Tou Ng;Yu Zhou;Robert Dale;Mary Gardiner
#t 2005
#c 11
#% 130058
#% 136350
#% 184073
#% 740418
#% 740995
#% 741195
#% 742218
#% 757292
#% 815876
#! We present a machine learning approach to identifying and resolving one-anaphora. In this approach, the system first learns to distinguish different uses of instances of the word one; in the second stage, the antecedents of those instances of one that are classified as anaphoric are then determined. We evaluated our approach on written texts drawn from the informative domains of the British National Corpus (BNC), and achieved encouraging results. To our knowledge, this is the first learning-based system for the identification and resolution of one-anaphora.

#index 1289528
#* Robust ontology acquisition from machine-readable dictionaries
#@ Eric Nichols;Francis Bond;Daniel Flickinger
#t 2005
#c 11
#% 756083
#% 817554
#% 854711
#% 939759
#% 939833
#% 939841
#% 1344600
#! In this paper, we outline the development of a system that automatically constructs ontologies by extracting knowledge from dictionary definition sentences using Robust Minimal Recursion Semantics (RMRS), a semantic formalism that permits underspecification. We show that by combining deep and shallow parsing resources through the common formalism of RMRS, we can extract ontological relations in greater quality and quantity. Our approach also has the advantages of requiring a very small amount of rules and being easily adaptable to any language with RMRS resources.

#index 1289529
#* The necessity of syntactic parsing for semantic role labeling
#@ Vasin Punyakanok;Dan Roth;Wen-tau Yih
#t 2005
#c 11
#% 266368
#% 302390
#% 329558
#% 708948
#% 722822
#% 727824
#% 815304
#% 815808
#% 815893
#% 817420
#% 843647
#% 853874
#% 855271
#% 855273
#% 939845
#! We provide an experimental study of the role of syntactic parsing in semantic role labeling. Our conclusions demonstrate that syntactic parse information is clearly most relevant in the very first stage - the pruning stage. In addition, the quality of the pruning stage cannot be determined solely based on its recall and precision. Instead it depends on the characteristics of the output candidates that make downstream problems easier or harder. Motivated by this observation, we suggest an effective and simple approach of combining different semantic role labeling systems through joint inference, which significantly improves the performance.

#index 1289530
#* Learning and inference over constrained output
#@ Vasin Punyakanok;Dan Roth;Wen-tau Yih;Dav Zimak
#t 2005
#c 11
#% 387653
#% 464434
#% 466892
#% 740916
#% 854636
#% 939845
#! We study learning structured output in a discriminative framework where values of the output variables are estimated by local classifiers. In this framework, complex dependencies among the output variables are captured by constraints and dictate which global labels can be inferred. We compare two strategies, learning independent classifiers and inference based training, by observing their behaviors in different conditions. Experiments and theoretical justification lead to the conclusion that using inference based learning is superior when the local classifiers are difficult to learn but may require many examples before any discernible difference can be observed.

#index 1289531
#* Beyond TFIDF weighting for text categorization in the vector space model
#@ Pascal Soucy;Guy W. Mineau
#t 2005
#c 11
#% 219052
#% 260001
#% 280817
#% 321635
#% 458379
#% 710542
#% 728350
#! KNN and SVM are two machine learning approaches to Text Categorization (TC) based on the Vector Space Model. In this model, borrowed from Information Retrieval, documents are represented as a vector where each component is associated with a particular word from the vocabulary. Traditionally, each component value is assigned using the information retrieval TFIDF measure. While this weighting method seems very appropriate for IR, it is not clear that it is the best choice for TC problems. Actually, this weighting method does not leverage the information implicitly contained in the categorization task to represent documents. In this paper, we introduce a new weighting method based on statistical estimation of the importance of a word for a specific categorization problem. This method also has the benefit to make feature selection implicit, since useless features for the categorization problem considered get a very small weight. Extensive experiments reported in the paper shows that this new weighting method improves significantly the classification accuracy as measured on many categorization tasks.

#index 1289532
#* Measuring semantic similarity by latent relational analysis
#@ Peter D. Turney
#t 2005
#c 11
#% 99690
#% 224113
#% 274488
#% 286069
#% 406493
#% 747738
#% 815799
#% 823312
#% 1279327
#! This paper introduces Latent Relational Analysis (LRA), a method for measuring semantic similarity. LRA measures similarity in the semantic relations between two pairs of words. When two pairs have a high degree of relational similarity, they are analogous. For example, the pair cat:meow is analogous to the pair dog:bark. There is evidence from cognitive science that relational similarity is fundamental to many cognitive and linguistic tasks (e.g., analogical reasoning). In the Vector Space Model (VSM) approach to measuring relational similarity, the similarity between two pairs is calculated by the cosine of the angle between the vectors that represent the two pairs. The elements in the vectors are based on the frequencies of manually constructed patterns in a large corpus. LRA extends the VSM approach in three ways: (1) patterns are derived automatically from the corpus, (2) Singular Value Decomposition is used to smooth the frequency data, and (3) synonyms are used to reformulate word pairs. This paper describes the LRA algorithm and experimentally compares LRA to VSM on two tasks, answering college-level multiple-choice word analogy questions and classifying semantic relations in noun-modifier expressions. LRA achieves state-of-the-art results, reaching human-level performance on the analogy questions and significantly exceeding VSM performance on both tasks.

#index 1289533
#* Theory of alignment generators and applications to statistical machine translation
#@ Raghavendra U. Udupa;Hemanta K. Maji
#t 2005
#c 11
#% 740915
#% 741368
#% 746909
#% 747832
#% 751440
#% 757409
#% 854068
#% 854653
#% 939739
#! Viterbi Alignment and Decoding are two fundamental search problems in Statistical Machine Translation. Both the problems are known to be NP-hard and therefore, it is unlikely that there exists an optimal polynomial time algorithm for either of these search problems. In this paper we characterize exponentially large subspaces in the solution space of Viterbi Alignment and Decoding. Each of these subspaces admits polynomial time optimal search algorithms. We propose a local search heuristic using a neighbourhood relation on these subspaces. Experimental results show that our algorithms produce better solutions taking substantially less time than the previously known algorithms for these problems.

#index 1289534
#* Analogy generation with HowNet
#@ Tony Veale
#t 2005
#c 11
#% 65345
#% 198058
#% 367473
#% 1273708
#! Analogy is a powerful boundary-transcending process that exploits a conceptual system's ability to perform controlled generalization in one domain and re-specialization into another. The result of this semantic leap is the transference of meaning from one concept to another from which metaphor derives its name (literally: to carry over). Such generalization and respecialization can be achieved using a variety of representations and techniques, most notably abstraction via a taxonomic backbone, or selective projection via structure-mapping on propositional content. In this paper we explore the extent to which a bilingual lexical ontology for English and Chinese, called HowNet, can support both approaches to analogy.

#index 1289535
#* Meaning development versus predefined meanings in language evolution models
#@ Paul Vogt
#t 2005
#c 11
#% 401687
#% 844542
#% 938654
#! This paper investigates the effect of predefining semantics in modelling the evolution of compositional languages versus allowing agents to develop these semantics in parallel with the development of language. The study is done using a multi-agent model of language evolution that is based on the Talking Heads experiment. The experiments show that when allowing a co-evolution of semantics with language, compositional languages develop faster than when the semantics are predefined, but compositionality appears more stable in the latter case. The paper concludes that conclusions drawn from simulations with predefined meanings, which most studies use, may need revision.

#index 1289536
#* Automatic semantic role labeling for Chinese verbs
#@ Nianwen Xue;Martha Palmer
#t 2005
#c 11
#% 452991
#% 747891
#% 808936
#% 815893
#% 855170
#% 855182
#% 855290
#% 858036
#! Recent years have seen a revived interest in semantic parsing by applying statistical and machine-learning methods to semantically annotated corpora such as the FrameNet and the Proposition Bank. So far much of the research has been focused on English due to the lack of semantically annotated resources in other languages. In this paper, we report first results on semantic role labeling using a pre-release version of the Chinese Proposition Bank. Since the Chinese Proposition Bank is superimposed on top of the Chinese Tree-bank, i.e., the semantic role labels are assigned to constituents in a treebank parse tree, we start by reporting results on experiments using the handcrafted parses in the treebank. This will give us a measure of the extent to which the semantic role labels can be bootstrapped from the syntactic annotation in the treebank. We will then report experiments using a fully automatic Chinese parser that integrates word segmentation, POS-tagging and parsing. This will gauge how successful semantic role labeling can be done for Chinese in realistic situations. We show that our results using hand-crafted parses are slightly higher than the results reported for the state-of-the-art semantic role labeling systems for English using the Penn English Proposition Bank data, even though the Chinese Proposition Bank is smaller in size. When an automatic parser is used, however, the accuracy of our system is much lower than the English state-of-the-art. This reveals an interesting cross-linguistic difference between the two languages, which we attempt to explain. We also describe a method to induce verb classes from the Proposition Bank "frame files" that can be used to improve semantic role labeling.

#index 1289537
#* Extraction of hierarchies based on inclusion of co-occurring words with frequency information
#@ Eiko Yamamoto;Kyoko Kanzaki;Hitoshi Isahara
#t 2005
#c 11
#% 493311
#% 756964
#% 786515
#% 786523
#% 938756
#% 939813
#! In this paper, we propose a method of automatically extracting word hierarchies based on the inclusion relations of word appearance patterns in corpora. We applied the complementary similarity measure (CSM) to determine a hierarchical structure of word meanings. The CSM is a similarity measure developed for recognizing degraded machine-printed text. There are CSMs for both binary and gray-scale images. The CSM for binary images has been applied to estimate one-to-many relations, such as superordinate-subordinate relations, and to extract word hierarchies. However, the CSM for gray-scale images has not been applied to natural language processing. Here, we apply the latter to extract word hierarchies from corpora. To do this, we used frequency information for co-occurring words, which is not considered when using the CSM for binary images. We compared our hierarchies with those obtained using the CSM for binary images, and evaluated them by measuring their degree of agreement with the EDR electronic dictionary.

#index 1289538
#* Attribution of knowledge to artificial agents and their principals
#@ Samir Chopra;Laurence White
#t 2005
#c 11
#% 552968
#% 644021
#! We consider the problem of attribution of knowledge to artificial agents and their legal principals. When can we say that an artificial agent X knows p and that its principal can be attributed the knowledge of p? We offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.

#index 1289539
#* PsychSim: modeling theory of mind with decision-theoretic agents
#@ David V. Pynadath;Stacy C. Marsella
#t 2005
#c 11
#% 251942
#% 302046
#% 379063
#% 773345
#! Agent-based modeling of human social behavior is an increasingly important research area. A key factor in human social interaction is our beliefs about others, a theory of mind. Whether we believe a message depends not only on its content but also on our model of the communicator. How we act depends not only on the immediate effect but also on how we believe others will react. In this paper, we discuss PsychSim, an implemented multiagent-based simulation tool for modeling interactions and influence. While typical approaches to such modeling have used first-order logic, Psych-Sim agents have their own decision-theoretic model of the world, including beliefs about its environment and recursive models of other agents. Using these quantitative models of uncertainty and preferences, we have translated existing psychological theories into a decision-theoretic semantics that allow the agents to reason about degrees of believability in a novel way. We discuss PsychSim's underlying architecture and describe its application to a school violence scenario for illustration.

#index 1289540
#* The altricial-precocial spectrum for robots
#@ Aaron Sloman;Jackie Chappell
#t 2005
#c 11
#% 85153
#% 90714
#% 317125
#% 375400
#% 714724
#% 722460
#% 920864
#! Several high level methodological debates among AI researchers, linguists, psychologists and philosophers, appear to be endless, e.g. about the need for and nature of representations, about the role of symbolic processes, about embodiment, about situatedness, about whether symbol-grounding is needed, and about whether a robot needs any knowledge at birth or can start simply with a powerful learning mechanism. Consideration of the variety of capabilities and development patterns on the precocial-altricial spectrum in biological organisms will help us to see these debates in a new light.

#index 1289541
#* Model compilation for real-time planning and diagnosis with feedback
#@ Anthony Barrett
#t 2005
#c 11
#% 179955
#% 544935
#% 578749
#% 1271885
#% 1272329
#% 1272349
#% 1476265
#! This paper describes MEXEC, an implemented micro executive that compiles a device model that can have feedback into a structure for subsequent evaluation. This system computes both the most likely current device mode from n sets of sensor measurements and the n-1 step reconfiguration plan that is most likely to result in reaching a target mode - if such a plan exists. A user tunes the system by increasing n to improve system capability at the cost of real-time performance.

#index 1289542
#* Proactive algorithms for scheduling with probabilistic durations
#@ J. Christopher Beck;Nic Wilson
#t 2005
#c 11
#% 230332
#% 295780
#% 408396
#% 453072
#% 574248
#! Proactive scheduling seeks to generate high quality solutions despite execution time uncertainty. Building on work in [Beck and Wilson, 2004], we conduct an empirical study of a number of algorithms for the job shop scheduling problem with probabilistic durations. The main contributions of this paper are: the introduction and empirical analysis of a novel constraint-based search technique that can be applied beyond probabilistic scheduling problems, the introduction and empirical analysis of a number of deterministic filtering algorithms for probabilistic job shop scheduling, and the identification of a number of problem characteristics that contribute to algorithm performance.

#index 1289543
#* Over-subscription planning with numeric goals
#@ J. Benton;Minh B. Do;Subbarao Kambhampati
#t 2005
#c 11
#% 224480
#% 728052
#% 1250208
#% 1272014
#% 1272017
#! By relaxing the hard-goal constraints from classical planning and associating them with reward values, over-subscription planning allows users to concentrate on presenting what they want and leaves the task of deciding the best goals to achieve to the planner. In this paper, we extend the over-subscription planning problem and its limited goal specification to allow numeric goals with continuous utility values and goals with mixed hard and soft constraints. Together they considerably extend the modeling power of goal specification and allow the user to express goal constraints that were not possible before. To handle these new goal constraints, we extend the Sapaps planner's planning graph based techniques to help it choose the best beneficial subset of goals that can include both hard or soft logical and numeric goals. We also provide empirical results in several benchmark domains to demonstrate that our technique helps return quality plans.

#index 1289544
#* Robust planning with (L)RTDP
#@ Olivier Buffet;Douglas Aberdeen
#t 2005
#c 11
#% 181627
#% 277782
#% 318485
#% 333525
#% 384911
#% 393786
#% 785489
#! Stochastic Shortest Path problems (SSPs), a subclass of Markov Decision Problems (MDPs), can be efficiently dealt with using Real-Time Dynamic Programming (RTDP). Yet, MDP models are often uncertain (obtained through statistics or guessing). The usual approach is robust planning: searching for the best policy under the worst model. This paper shows how RTDP can be made robust in the common case where transition probabilities are known to lie in a given interval.

#index 1289545
#* Abstraction-based action ordering in planning
#@ Maria Fox;Derek Long;Julie Porteous
#t 2005
#c 11
#% 212398
#% 496243
#% 559334
#% 1271962
#% 1272008
#% 1272340
#% 1478760
#! Many planning problems contain collections of symmetric objects, actions and structures which render them difficult to solve efficiently. It has been shown that the detection and exploitation of symmetric structure in planning problems can dramatically reduce the size of the search space and the time taken to find a solution. We present the idea of using an abstraction of the problem domain to reveal symmetric structure and guide the navigation of the search space. We show that this is effective even in domains in which there is little accessible symmetric structure available for pruning. Proactive exploitation represents a flexible and powerful alternative to the symmetry-breaking strategies exploited in earlier work in planning and CSPs. The notion of almost symmetry is defined and results are presented showing that proactive exploitation of almost symmetry can improve the performance of a heuristic forward search planner.

#index 1289546
#* Integrating planning and temporal reasoning for domains with durations and time windows
#@ Alfonso Gerevini;Alessandro Saetti;Ivan Serina
#t 2005
#c 11
#% 107137
#% 224480
#% 307179
#% 736897
#% 1272008
#% 1272016
#% 1290110
#! The treatment of exogenous events in planning is practically important in many domains. In this paper we focus on planning with exogenous events that happen at known times, and affect the plan actions by imposing that the execution of certain plan actions must be during some time windows. When actions have durations, handling such constraints adds an extra difficulty to planning, which we address by integrating temporal reasoning into planning. We propose a new approach to planning in domains with durations and time windows, combining graph-based planning and disjunctive constraint-based temporal reasoning. Our techniques are implemented in a planner that took part in the 4th International Planning Competition showing very good performance in many benchmark problems.

#index 1289547
#* Real-time path planning for humanoid robot navigation
#@ Jens-Steffen Gutmann;Masaki Fukuchi;Masahiro Fujita
#t 2005
#c 11
#% 367254
#% 418822
#! We present a data structure and an algorithm for real-time path planning of a humanoid robot. Due to the many degrees of freedom, the robots shape and available actions are approximated for finding solutions efficiently. The resulting 3 dimensional configuration space is searched by the A* algorithm finding solutions in tenths of a second on lowperformance, embedded hardware. Experimental results demonstrate our solution for a robot in a world containing obstacles with different heights, stairs and a higher-level platform.

#index 1289548
#* LRTA*(k)
#@ Carlos Hernández;Pedro Meseguer
#t 2005
#c 11
#% 68238
#% 398953
#% 529808
#% 581812
#% 773293
#% 1279477
#! LRTA* is a real-time heuristic search algorithm widely used. In each iteration it updates the heuristic estimate of the current state. Here we present LRTA*(k), a new LRTA*-based algorithm that is able to update the heuristic estimates of up to k states, not necessarily distinct. Based on bounded propagation, this updating strategy maintains heuristic admissibility, so the new algorithm keeps the good theoretical properties of LRTA*. Experimentally, we show that LRTA*(k) produces better solutions in the first trial and converges faster when compared with other state-of-the-art algorithms on benchmarks for real-time search.

#index 1289549
#* Planning with continuous resources in stochastic domains
#@  Mausam;Emmanuel Benazera;Ronen Brafman;Nicolas Meuleau;Eric A. Hansen
#t 2005
#c 11
#% 241
#% 317313
#% 337981
#% 788054
#% 788064
#% 1250208
#% 1250235
#% 1650355
#! We consider the problem of optimal planning in stochastic domains with resource constraints, where resources are continuous and the choice of action at each step may depend on the current resource level. Our principal contribution is the HAO* algorithm, a generalization of the AO* algorithm that performs search in a hybrid state space that is modeled using both discrete and continuous state variables. The search algorithm leverages knowledge of the starting state to focus computational effort on the relevant parts of the state space. We claim that this approach is especially effective when resource limitations contribute to reachability constraints. Experimental results show its effectiveness in the domain that motivates our research - automated planning for planetary exploration rovers.

#index 1289550
#* Automated composition of web services by planning at the knowledge level
#@ M. Pistore;A. Marconi;P. Bertoli;P. Traverso
#t 2005
#c 11
#% 348131
#% 576091
#% 754120
#% 1289550
#! In this paper, we address the problem of the automated composition of web services by planning on their "knowledge level" models. We start from descriptions of web services in standard process modeling and execution languages, like BPEL4WS, and automatically translate them into a planning domain that models the interactions among services at the knowledge level. This allows us to avoid the explosion of the search space due to the usually large and possibly infinite ranges of data values that are exchanged among services, and thus to scale up the applicability of state-of-the-art techniques for the automated composition of web services. We present the theoretical framework, implement it, and provide an experimental evaluation that shows the practical advantage of our approach w.r.t. techniques that are not based on a knowledgelevel representation.

#index 1289551
#* Conditional planning in the discrete belief space
#@ Jussi Rintanen
#t 2005
#c 11
#% 252183
#% 266387
#% 283210
#% 310835
#% 363744
#% 1250202
#% 1289212
#! Probabilistic planning with observability restrictions, as formalized for example as partially observable Markov decision processes (POMDP), has a wide range of applications, but it is computationally extremely difficult. For POMDPs, the most general decision problems about existence of policies satisfying certain properties are undecidable. We consider a computationally easier form of planning that ignores exact probabilities, and give an algorithm for a class of planning problems with partial observability. We show that the basic backup step in the algorithm is NP-complete. Then we proceed to give an algorithm for the backup step, and demonstrate how it can be used as a basis of an efficient algorithm for constructing plans.

#index 1289552
#* Probabilistic reasoning for plan robustness
#@ Steve R. Schaffer;Bradley J. Clement;Steve A. Chien
#t 2005
#c 11
#% 363744
#% 379005
#% 393786
#% 398953
#% 466575
#% 1650355
#! A planning system must reason about the uncertainty of continuous variables in order to accurately project the possible system state over time. A method is devised for directly reasoning about the uncertainty in continuous activity duration and resource usage for planning problems. By representing random variables as parametric distributions, computing projected system state can be simplified. Common approximations and novel methods are compared for over-constrained and lightly constrained domains within an iterative repair planner. Results show improvements in robustness over the conventional non-probabilistic representation by reducing the number of constraint violations during execution. The improvement is more significant for larger problems and those with higher resource subscription levels but diminishes as the system is allowed to accept higher risk levels.

#index 1289553
#* Optimized execution of action chains using learned performance models of abstract actions
#@ Freek Stulp;Michael Beetz
#t 2005
#c 11
#% 103309
#% 194658
#% 431471
#% 466071
#% 532950
#% 715981
#% 747147
#! Many plan-based autonomous robot controllers generate chains of abstract actions in order to achieve complex, dynamically changing, and possibly interacting goals. The execution of these action chains often results in robot behavior that shows abrupt transitions between subsequent actions, causing suboptimal performance. The resulting motion patterns are so characteristic for robots that people imitating robotic behavior will do so by making abrupt movements between actions. In this paper we propose a novel computation model for the execution of abstract action chains. In this computation model a robot first learns situation-specific performance models of abstract actions. It then uses these models to automatically specialize the abstract actions for their execution in a given action chain. This specialization results in refined chains that are optimized for performance. As a side effect this behavior optimization also appears to produce action chains with seamless transitions between actions.

#index 1289554
#* Encoding formulas with partially constrained weights in a possibilistic-like many-sorted propositional logic
#@ Salem Benferhat;Henri Prade
#t 2005
#c 11
#% 167544
#% 772064
#% 1271987
#% 1272312
#! Possibilistic logic offers a convenient tool for handling uncertain or prioritized formulas and coping with inconsistency. Propositional logic formulas are thus associated with weights belonging to a linearly ordered scale. However, especially in case of multiple source information, only partial knowledge may be available about the relative ordering between weights of formulas. In order to cope with this problem, a two-sorted counterpart of possibilistic logic is introduced. Pieces of information are encoded as clauses where special literals refer to the weights. Constraints between weights translate into logical formulas of the corresponding sort and are gathered in a distinct auxiliary knowledge base. An inference relation, which is sound and complete with respect to preferential model semantics, enables us to draw plausible conclusions from the two knowledge bases. The inference process is characterized by using "forgetting variables" for handling the symbolic weights, and hence an inference process is obtained by means of a DNF compilation of the two knowledge bases.

#index 1289555
#* Bounded policy iteration for decentralized POMDPs
#@ Daniel S. Bernstein;Eric A. Hansen;Shlomo Zilberstein
#t 2005
#c 11
#% 450852
#% 527987
#% 773196
#% 788053
#% 1250230
#% 1650313
#% 1650588
#% 1650702
#! We present a bounded policy iteration algorithm for infinite-horizon decentralized POMDPs. Policies are represented as joint stochastic finite-state controllers, which consist of a local controller for each agent. We also let a joint controller include a correlation device that allows the agents to correlate their behavior without exchanging information during execution, and show that this leads to improved performance. The algorithm uses a fixed amount of memory, and each iteration is guaranteed to produce a controller with value at least as high as the previous one for all possible initial state distributions. For the case of a single agent, the algorithm reduces to Poupart and Boutilier's bounded policy iteration for POMDPs.

#index 1289556
#* A decision-theoretic approach to task assistance for persons with dementia
#@ Jennifer Boger;Pascal Poupart;Jesse Hoey;Craig Boutilier;Geoff Fernie;Alex Mihailidis
#t 2005
#c 11
#% 102136
#% 317099
#% 466418
#% 528308
#% 842579
#% 1289562
#% 1650297
#% 1778706
#! Cognitive assistive technologies that aid people with dementia (such as Alzheimer's disease) hold the promise to provide such people with an increased level of independence. However, to realize this promise, such systems must account for the specific needs and preferences of individuals. We argue that this form of customization requires a sequential, decision-theoretic model of interaction. We describe both fully and partially observable Markov decision process (POMDP) models of a handwashing task, and show that, despite the potential computational complexity, these can be effectively solved and produce policies that are evaluated as useful by professional caregivers.

#index 1289557
#* Sensitivity analysis in Markov networks
#@ Hei Chan;Adnan Darwiche
#t 2005
#c 11
#% 44876
#% 351595
#% 528027
#% 571102
#% 788044
#% 1272350
#% 1349540
#% 1784188
#! This paper explores the topic of sensitivity analysis in Markov networks, by tackling questions similar to those arising in the context of Bayesian networks: the tuning of parameters to satisfy query constraints, and the bounding of query changes when perturbing network parameters. Even though the distribution induced by a Markov network corresponds to ratios of multi-linear functions, whereas the distribution induced by a Bayesian network corresponds to multi-linear functions, the results we obtain for Markov networks are as effective computationally as those obtained for Bayesian networks. This similarity is due to the fact that conditional probabilities have the same functional form in both Bayesian and Markov networks, which turns out to be the more influential factor. The major difference we found, however, is in how changes in parameter values should be quantified, as such parameters are interpreted differently in Bayesian networks and Markov networks.

#index 1289558
#* Compiling Bayesian networks with local structure
#@ Mark Chavira;Adnan Darwiche
#t 2005
#c 11
#% 327779
#% 329486
#% 342378
#% 571102
#% 723877
#% 1271984
#% 1650767
#! Recent work on compiling Bayesian networks has reduced the problem to that of factoring CNF encodings of these networks, providing an expressive framework for exploiting local structure. For networks that have local structure, large CPTs, yet no excessive determinism, the quality of the CNF encodings and the amount of local structure they capture can have a significant effect on both the offline compile time and online inference time. We examine the encoding of such Bayesian networks in this paper and report on new findings that allow us to significantly scale this compilation approach. In particular, we obtain order-of-magnitude improvements in compile time, compile some networks successfully for the first time, and obtain ordersof-magnitude improvements in online inference for some networks with local structure, as compared to baseline jointree inference, which does not exploit local structure.

#index 1289559
#* The inferential complexity of Bayesian and credal networks
#@ Cassio Polpo De Campos;Fabio Gagliardi Cozman
#t 2005
#c 11
#% 44876
#% 172544
#% 205391
#% 212217
#% 267725
#% 319172
#% 420743
#% 528010
#% 788048
#% 1272025
#% 1289172
#% 1650391
#% 1650396
#% 1650778
#! This paper presents new results on the complexity of graph-theoretical models that represent probabilities (Bayesian networks) and that represent interval and set valued probabilities (credal networks). We define a new class of networks with bounded width, and introduce a new decision problem for Bayesian networks, the maximin a posteriori. We present new links between the Bayesian and credal networks, and present new results both for Bayesian networks (most probable explanation with observations, maximin a posteriori) and for credal networks (bounds on probabilities a posteriori, most probable explanation with and without observations, maximum a posteriori).

#index 1289560
#* Lifted first-order probabilistic inference
#@ Rodrigo De Salvo Braz;Eyal Amir;Dan Roth
#t 2005
#c 11
#% 56471
#% 144840
#% 147677
#% 484593
#% 496116
#% 529159
#% 577225
#% 1279353
#% 1650326
#% 1650727
#! Most probabilistic inference algorithms are specified and processed on a propositional level. In the last decade, many proposals for algorithms accepting first-order specifications have been presented, but in the inference stage they still operate on a mostly propositional representation level. [Poole, 2003] presented a method to perform inference directly on the first-order level, but this method is limited to special cases. In this paperwe present the first exact inference algorithm that operates directly on a first-order level, and that can be applied to any first-order model (specified in a language that generalizes undirected graphical models). Our experiments show superior performance in comparison with propositional exact inference.

#index 1289561
#* Stationary deterministic policies for constrained MDPs with multiple rewards, costs, and discount factors
#@ Dmitri Dolgov;Edmund Durfee
#t 2005
#c 11
#% 163914
#% 163920
#% 188153
#% 221770
#% 313593
#% 644560
#% 773262
#! We consider the problem of policy optimization for a resource-limited agent with multiple time-dependent objectives, represented as an MDP with multiple discount factors in the objective function and constraints. We show that limiting search to stationary deterministic policies, coupled with a novel problem reduction to mixed integer programming, yields an algorithm for finding such policies that is computationally feasible, where no such algorithm has heretofore been identified. In the simpler case where the constrained MDP has a single discount factor, our technique provides a new way for finding an optimal deterministic policy, where previous methods could only find randomized policies. We analyze the properties of our approach and describe implementation results.

#index 1289562
#* Solving POMDPs with continuous or large discrete observation spaces
#@ Jesse Hoey;Pascal Poupart
#t 2005
#c 11
#% 179940
#% 252183
#% 393786
#% 464448
#% 527859
#% 578743
#% 627197
#% 695957
#% 817553
#% 1271954
#% 1279358
#% 1289556
#% 1650314
#% 1778706
#! We describe methods to solve partially observable Markov decision processes (POMDPs) with continuous or large discrete observation spaces. Realistic problems often have rich observation spaces, posing significant problems for standard POMDP algorithms that require explicit enumeration of the observations. This problem is usually approached by imposing an a priori discretisation on the observation space, which can be sub-optimal for the decision making task. However, since only those observations that would change the policy need to be distinguished, the decision problem itself induces a lossless partitioning of the observation space. This paper demonstrates how to find this partition while computing a policy, and how the resulting discretisation of the observation space reveals the relevant features of the application domain. The algorithms are demonstrated on a toy example and on a realistic assisted living task.

#index 1289563
#* Optimal nonmyopic value of information in graphical models: efficient algorithms and theoretical limits
#@ Andreas Krause;Carlos Guestrin
#t 2005
#c 11
#% 443640
#% 449588
#% 528327
#% 629619
#% 788039
#% 1016178
#% 1272025
#% 1272282
#% 1272331
#% 1272369
#% 1650712
#! Many real-world decision making tasks require us to choose among several expensive observations. In a sensor network, for example, it is important to select the subset of sensors that is expected to provide the strongest reduction in uncertainty. It has been general practice to use heuristic-guided procedures for selecting observations. In this paper, we present the first efficient optimal algorithms for selecting observations for a class of graphical models containing Hidden Markov Models (HMMs). We provide results for both selecting the optimal subset of observations, and for obtaining an optimal conditional observation plan. For both problems, we present algorithms for the filtering case, where only observations made in the past are taken into account, and the smoothing case, where all observations are utilized. Furthermore we prove a surprising result: In most graphical models tasks, if one designs an efficient algorithm for chain graphs, such as HMMs, this procedure can be generalized to polytrees. We prove that the value of information problem is NPPP-hard even for discrete polytrees. It also follows from our results that even computing conditional entropies, which are widely used to measure value of information, is a #P-complete problem on polytrees. Finally, we demonstrate the effectiveness of our approach on several real-world datasets.

#index 1289564
#* An MCMC approach to solving hybrid factored MDPs
#@ Branislav Kveton;Milos Hauskrecht
#t 2005
#c 11
#% 75936
#% 363744
#% 382586
#% 393786
#% 644560
#% 739715
#% 778078
#% 788054
#% 788064
#% 788111
#% 1272002
#% 1289239
#% 1290041
#! Hybrid approximate linear programming (HALP) has recently emerged as a promising framework for solving large factored Markov decision processes (MDPs) with discrete and continuous state and action variables. Our work addresses its major computational bottleneck - constraint satisfaction in large structured domains of discrete and continuous variables. We analyze this problem and propose a novelMarkov chainMonte Carlo (MCMC) method for finding the most violated constraint of a relaxed HALP. This method does not require the discretization of continuous variables, searches the space of constraints intelligently based on the structure of factored MDPs, and its space complexity is linear in the number of variables. We test the method on a set of large control problems and demonstrate improvements over alternative approaches.

#index 1289565
#* BLOG: probabilistic models with unknown objects
#@ Brian Milch;Bhaskara Marthi;Stuart Russell;David Sontag;Daniel L. Ong;Andrey Kolobov
#t 2005
#c 11
#% 44876
#% 89958
#% 144840
#% 147677
#% 147680
#% 266230
#% 417753
#% 464304
#% 496116
#% 1272388
#% 1289246
#! This paper introduces and illustrates BLOG, a formal language for defining probability models over worlds with unknown objects and identity uncertainty. BLOG unifies and extends several existing approaches. Subject to certain acyclicity constraints, every BLOG model specifies a unique probability distribution over first-order model structures that can contain varying and unbounded numbers of objects. Furthermore, complete inference algorithms exist for a large fragment of the language. We also introduce a probabilistic form of Skolemization for handling evidence.

#index 1289566
#* Continuous time particle filtering
#@ Brenda Ng;Avi Pfeffer;Richard Dearden
#t 2005
#c 11
#% 119941
#% 424819
#% 528169
#% 1476265
#% 1650389
#% 1650390
#% 1673032
#! We present the continuous-time particle filter (CTPF) - an extension of the discrete-time particle filter for monitoring continuous-time dynamic systems. Our methods apply to hybrid systems containing both discrete and continuous variables. The dynamics of the discrete state system are governed by a Markov jump process. Observations of the discrete process are intermittent and irregular. Whenever the discrete process is observed, CTPF samples a trajectory of the underlying Markov jump process. This trajectory is then used to estimate the continuous variables using the system dynamics determined by the discrete state in the trajectory. We use the unscented Kalman-Bucy filter to handle nonlinearities and continuous time. We present results showing that CTPF is more stable in its performance than discrete-time particle filtering, even when the discrete-time algorithm is allowed to update many more times than CTPF. We also present a method for online learning of the Markov jump process model that governs the discrete states.

#index 1289567
#* Accurate and low-cost location estimation using kernels
#@ Jeffery Junfeng Pan;James T. Kwok;Qiang Yang;Yiqiang Chen
#t 2005
#c 11
#% 401172
#% 433320
#% 613334
#% 613383
#% 746038
#% 797049
#% 797050
#% 855563
#% 917779
#% 1250174
#% 1272356
#% 1769642
#! We present a novel method for indoor-location estimation using a vector-space model based on signals received from a wireless client. Our aim is to obtain an accurate mapping between the signal space and the physical space without incurring too much human calibration effort. This problem has traditionally been tackled through probabilistic models trained on manually labeled data, which are expensive to obtain. In this paper, we present a novel approach to building a mapping between the signalvector space and the physical location space using kernel canonical correlation analysis (KCCA). Its training requires much less human labor. Moreover, unlike traditional location-estimation systems that treat grid points as independent and discrete target classes during training, we use the physical location as a continuous feedback to build a similarity mapping using KCCA. We test our algorithm in a 802.11 wireless LAN environment, and demonstrate the advantage of our method in both accuracy and its ability to utilize a much smaller set of labeled training data than previous methods.

#index 1289568
#* Algebraic Markov decision processes
#@ Patrice Perny;Olivier Spanjaard;Paul Weng
#t 2005
#c 11
#% 252183
#% 363744
#% 528313
#% 578661
#% 1275308
#% 1279254
#% 1279255
#% 1290145
#% 1650329
#% 1650353
#% 1650648
#% 1650690
#! In this paper, we provide an algebraic approach to Markov Decision Processes (MDPs), which allows a unified treatment of MDPs and includes many existing models (quantitative or qualitative) as particular cases. In algebraic MDPs, rewards are expressed in a semiring structure, uncertainty is represented by a decomposable plausibility measure valued on a second semiring structure, and preferences over policies are represented by Generalized Expected Utility. We recast the problem of finding an optimal policy at a finite horizon as an algebraic path problem in a decision rule graph where arcs are valued by functions, which justifies the use of the Jacobi algorithm to solve algebraic Bellman equations. In order to show the potential of this general approach, we exhibit new variations of MDPs, admitting complete or partial preference structures, as well as probabilistic or possibilistic representation of uncertainty.

#index 1289569
#* Asymptotic conditional probability in modal logic: a probabilistic reconstruction of nonmonotonic logic
#@ Riccardo Rosati;Georg Gottlob
#t 2005
#c 11
#% 1146
#% 73579
#% 89976
#% 155815
#% 175359
#% 205808
#% 383293
#% 472995
#% 587465
#! We analyze the asymptotic conditional validity of modal formulas, i.e., the probability that a formula ψ is valid in the finite Kripke structures in which a given modal formula φ is valid, when the size of these Kripke structures grows to infinity. We characterize the formulas ψ that are almost surely valid (i.e., with probability 1) in case φ is a flat, S5- consistent formula, and show that these formulas ψ are exactly those which follow from φ according to the nonmonotonic modal logic S5G. Our results provide - for the first time - a probabilistic semantics to a well-known nonmonotonic modal logic, establishing a new bridge between nonmonotonic and probabilistic reasoning, and give a computational account of the asymptotic conditional validity problem in Kripke structures.

#index 1289570
#* Affine algebraic decision diagrams (AADDs) and their application to structured probabilistic inference
#@ Scott Sanner;David McAllester
#t 2005
#c 11
#% 3873
#% 233825
#% 233849
#% 644560
#% 1289239
#% 1650297
#% 1650767
#! We propose an affine extension to ADDs (AADD) capable of compactly representing context-specific, additive, and multiplicative structure. We show that the AADD has worst-case time and space performance within a multiplicative constant of that of ADDs, but that it can be linear in the number of variables in cases where ADDs are exponential in the number of variables. We provide an empirical comparison of tabular, ADD, and AADD representations used in standard Bayes net and MDP inference algorithms and conclude that the AADD performs at least as well as the other two representations, and often yields an exponential performance improvement over both when additive or multiplicative structure can be exploited. These results suggest that the AADD is likely to yield exponential time and space improvements for a variety of probabilistic inference algorithms that currently use tables or ADDs.

#index 1289571
#* Probabilistic reasoning with hierarchically structured variables
#@ Rita Sharma;David Poole
#t 2005
#c 11
#% 1858
#% 3513
#% 44876
#% 266230
#% 527687
#% 1650767
#! Many practical problems have random variables with a large number of values that can be hierarchically structured into an abstraction tree of classes. This paper considers how to represent and exploit hierarchical structure in probabilistic reasoning. We represent the distribution for such variables by specifying, for each class, the probability distribution over its immediate subclasses. We represent the conditional probability distribution of any variable conditioned on hierarchical variables using inheritance. We present an approach for reasoning in Bayesian networks with hierarchically structured variables that dynamically constructs a flat Bayesian network, given some evidence and a query, by collapsing the hierarchies to include only those values necessary to answer the query. This can be done with a single pass over the network. We can answer the query from the flat Bayesian network using any standard probabilistic inference algorithm such as variable elimination or stochastic simulation. The domain size of the variables in the flat Bayesian network is independent of the size of the hierarchies; it depends on how many of the classes in the hierarchies are directly associated with the evidence and query. Thus, the representation is applicable even when the hierarchy is conceptually infinite.

#index 1289572
#* Self adaptive particle filter
#@ Alvaro Soto
#t 2005
#c 11
#% 283140
#% 465918
#% 529194
#! The particle filter has emerged as a useful tool for problems requiring dynamic state estimation. The efficiency and accuracy of the filter depend mostly on the number of particles used in the estimation and on the propagation function used to reallocate these particles at each iteration. Both features are specified beforehand and are kept fixed in the regular implementation of the filter. In practice this may be highly inappropriate since it ignores errors in the models and the varying dynamics of the processes. This work presents a self adaptive version of the particle filter that uses statistical methods to adapt the number of particles and the propagation function at each iteration. Furthermore, our method presents similar computational load than the standard particle filter. We show the advantages of the self adaptive filter by applying it to a synthetic example and to the visual tracking of targets in a real video sequence.

#index 1289573
#* Dynamically constructed Bayes nets for multi-domain sketch understanding
#@ Christine Alvarado;Randall Davis
#t 2005
#c 11
#% 496116
#% 503673
#% 625272
#% 669227
#% 782260
#% 782261
#% 828003
#% 1250190
#% 1279280
#% 1650731
#% 1650734
#% 1650767
#% 1775074
#! This paper presents a novel form of dynamically constructed Bayes net, developed for multidomain sketch recognition. Our sketch recognition engine integrates shape information and domain knowledge to improve recognition accuracy across a variety of domains using an extendible, hierarchical approach. Our Bayes net framework integrates the influence of stroke data and domain-specific context in recognition, enabling our recognition engine to handle noisy input. We illustrate this behavior with qualitative and quantitative results in two domains: hand-drawn family trees and circuits.

#index 1289574
#* You are wrong!: automatic detection of interaction errors from brain waves
#@ Pierre W. Ferrez;José Del R. Millán
#t 2005
#c 11
#% 234978
#% 789563
#% 1279372
#! Brain-computer interfaces, as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject's intent. In this paper we exploit a unique feature of the "brain channel", namely that it carries information about cognitive states that are crucial for a purposeful interaction. One of these states is the awareness of erroneous responses. Different physiological studies have shown the presence of error-related potentials (ErrP) in the EEG recorded right after people get aware they have made an error. However, for human-computer interaction, the central question is whether ErrP are also elicited when the error is made by the interface during the recognition of the subject's intent and no longer by errors of the subject himself. In this paper we report experimental results with three volunteer subjects during a simple human-robot interaction (i.e., bringing the robot to either the left or right side of a room) that seem to reveal a new kind of ErrP, which is satisfactorily recognized in single trials. These recognition rates significantly improve the performance of the brain interface.

#index 1289575
#* A live-user evaluation of collaborative web search
#@ Barry Smyth;Evelyn Balfe;Oisin Boydell;Keith Bradley;Peter Briggs;Maurice Coyle;Jill Freyne
#t 2005
#c 11
#% 27049
#% 162459
#% 194299
#% 232713
#% 268079
#% 290830
#% 320839
#% 342961
#% 433674
#% 563963
#% 769569
#% 803556
#% 1279434
#% 1715615
#! Collaborative Web search exploits repetition and regularity within the query-space of a community of like-minded individuals in order to improve the quality of search results. In short, search results that have been judged to be relevant for past queries are promoted in response to similar queries that occur in the future. In this paper we present the results of a large-scale evaluation of this approach, in a corporate Web search scenario, which shows that significant benefits are available to its users.

#index 1289576
#* Clinical-reasoning skill acquisition through intelligent group tutoring
#@ Siriwan Suebnukarn;Peter Haddawy
#t 2005
#c 11
#% 185079
#% 414515
#% 734951
#! This paper describes COMET, a collaborative intelligent tutoring system for medical problembased learning. COMET uses Bayesian networks to model individual student knowledge and activity, as well as that of the group. Generic domainindependent tutoring algorithms use the models to generate tutoring hints. We present an overview of the system and then the results of two evaluation studies. The validity of the modeling approach is evaluated in the areas of head injury, stroke and heart attack. Receiver operating characteristic (ROC) curve analysis indicates that, the models are accurate in predicting individual student actions. Comparison of learning outcomes shows that student clinical reasoning gains from our system are significantly higher than those obtained from human tutored sessions (Mann-Whitney, p = 0.011).

#index 1289577
#* Learning partially observable deterministic action models
#@ Eyal Amir
#t 2005
#c 11
#% 3035
#% 131559
#% 246836
#% 252183
#% 289947
#% 304882
#% 703709
#% 716892
#% 1279222
#% 1499593
#% 1650276
#! We present the first tractable, exact solution for the problem of identifying actions' effects in partially observable STRIPS domains. Our algorithms resemble Version Spaces and Logical Filtering, and they identify all the models that are consistent with observations. They apply in other deterministic domains (e.g., with conditional effects), but are inexact (may return false positives) or inefficient (we could not bound the representation size). Our experiments verify the theoretical guarantees, and show that we learn STRIPS actions efficiently, with time that is significantly better than approaches for HMMs and Reinforcement Learning (which are inexact). Our results are especially surprising because of the inherent intractability of the general deterministic case. These results have been applied to an autonomous agent in a virtual world, facilitating decision making, diagnosis, and exploration.

#index 1289578
#* Learning forward models for robots
#@ Anthony Dearden;Yiannis Demiris
#t 2005
#c 11
#% 44876
#% 465762
#% 1289266
#! Forward models enable a robot to predict the effects of its actions on its own motor system and its environment. This is a vital aspect of intelligent behaviour, as the robot can use predictions to decide the best set of actions to achieve a goal. The ability to learn forward models enables robots to be more adaptable and autonomous; this paper describes a system whereby they can be learnt and represented as a Bayesian network. The robot's motor system is controlled and explored using 'motor babbling'. Feedback about its motor system comes from computer vision techniques requiring no prior information to perform tracking. The learnt forward model can be used by the robot to imitate human movement.

#index 1289579
#* Inferring image templates from classification decisions
#@ Arnab Dhua;Florin Cutzu
#t 2005
#c 11
#% 209623
#% 270997
#% 272991
#% 296513
#% 1012881
#! Assuming human image classification decisions are based on estimating the degree of match between a small number of stored internal templates and certain regions of the input images, we present an algorithm which infers observers classification templates from their classification decisions on a set of test images. The problem is formulated as learning prototypes from labeled data under an adjustable, prototype-specific elliptical metric. The matrix of the elliptical metric indicates the pixels that the template responds to. The model was applied to human psychophysical data collected in a simple image classification experiment.

#index 1289580
#* Combining structural descriptions and image-based representations for image, object, and scene recognition
#@ Nicolas Do Huu;Williams Paquier;Raja Chatila
#t 2005
#c 11
#% 279804
#% 279805
#% 450880
#% 1502411
#! Object and scene learning and recognition is a major issue in computer vision, in robotics and in cognitive sciences. This paper presents the principles and results of an approach which extracts structured view-based representations for multi-purpose recognition. The structures are hierarchical and distributed and provide for generalization and categorization. A tracking process enables to bind views over time and to link consecutive views. Scenes can also be recognized using objects as components. Illustrative results are presented.

#index 1289581
#* Compound effects of top-down and bottom-up influences on visual attention during action recognition
#@ Bassam Khadhouri;Yiannis Demiris
#t 2005
#c 11
#% 245759
#% 268121
#% 400716
#% 495947
#! The limited visual and computational resources available during the perception of a human action makes a visual attention mechanism essential. In this paper we propose an attention mechanism that combines the saliency of top-down (or goal-directed) elements, based on multiple hypotheses about the demonstrated action, with the saliency of bottom-up (or stimulus-driven) components. Furthermore, we use the bottom-up part to initialise the top-down, hence resulting in a selection of the behaviours that rightly require the limited computational resources. This attention mechanism is then combined with an action understanding model and implemented on a robot, where we examine its performance during the observation of object-directed human actions.

#index 1289582
#* Collective AI: context awareness via communication
#@ S. Kornienko;O. Kornienko;P. Levi
#t 2005
#c 11
#% 218123
#% 294103
#% 418811
#% 634138
#! Communication among participants (agents, robots) is central to an appearance of Collective AI. In this work we deal with the development of local communication mechanisms for real microrobotic swarms. We demonstrate that despite of very limited capabilities of the microrobot, the specific construction of communication hardware and software allows very extended collective capabilities of the whole swarm. We propose mechanisms providing information content and context for collective navigation, coordination and spatial perception in a group of microrobots.

#index 1289583
#* Relational object maps for mobile robots
#@ Benson Limketkai;Lin Liao;Dieter Fox
#t 2005
#c 11
#% 303954
#% 464434
#% 724344
#% 1279374
#% 1289474
#% 1650347
#% 1650403
#! Mobile robot map building is the task of generating a model of an environment from sensor data. Most existing approaches to mobile robot mapping either build topological representations or generate accurate, metric maps of an environment. In this paper we introduce relational object maps, a novel approach to building metric maps that represent individual objects such as doors or walls. We show how to extend relational Markov networks in order to reason about a hierarchy of objects and the spatial relationships between them. Markov chain Monte Carlo is used for efficient inference and to learn the parameters of the model. We show that the spatial constraints modeled by our mapping technique yield drastic improvements for labeling line segments extracted from laser range-finders.

#index 1289584
#* Maintaining coherent perceptual information using anchoring
#@ Amy Loutfi;Silvia Coradeschi;Alessandro Saffiotti
#t 2005
#c 11
#% 194658
#% 478255
#% 529673
#! The purpose of this paper is to address the problem of maintaining coherent perceptual information in a mobile robotic system working over extended periods of time, interacting with a user and using multiple sensing modalities to gather information about the environment and specific objects. We present a system which is able to use spatial and olfactory sensors to patrol a corridor and execute user requested tasks. To cope with perceptual maintenance we present an extension of the anchoring framework capable of maintaining the correspondence between sensor data and the symbolic descriptions referring to objects. It is also capable of tracking and acquiring information from observations derived from sensor-data as well as information from a priori symbolic concepts. The general system is described and an experimental validation on a mobile robot is presented.

#index 1289585
#* 2D shape classification and retrieval
#@ Graham McNeill;Sethu Vijayakumar
#t 2005
#c 11
#% 111369
#% 443975
#% 721824
#% 743670
#! We present a novel correspondence-based technique for efficient shape classification and retrieval. Shape boundaries are described by a set of (ad hoc) equally spaced points - avoiding the need to extract "landmark points". By formulating the correspondence problem in terms of a simple generative model, we are able to efficiently compute matches that incorporate scale, translation, rotation and reflection invariance. A hierarchical scheme with likelihood cut-off provides additional speed-up. In contrast to many shape descriptors, the concept of a mean (prototype) shape follows naturally in this setting. This enables model based classification, greatly reducing the cost of the testing phase. Equal spacing of points can be defined in terms of either perimeter distance or radial angle. It is shown that combining the two leads to improved classification/ retrieval performance.

#index 1289586
#* Efficient distributed "hormone" graph gradients
#@ Esben Hallundbæk Østergaard
#t 2005
#c 11
#% 297919
#% 659835
#! Several researchers have attempted extract the principles behind hormone gradients found in biological system, and apply them to control physically manifested distributed systems. This paper presents an efficient implementation of a graph-based version of hormone gradient mechanisms. The algorithm is based on hop-counting of the topological distance between any given vertex and the hormone emitting vertex, and can deal with dynamic changes to the topology of the system. Performance of the described algorithm is documented through a number of experiments. The algorithm was developed for use in self-reconfigurable robotics, but might very well be useful for many other applications. The use of the algorithm to provide a common coordinate system for a collection of self-recon figurable robot modules is described, that provides pose relative to the emitting module for all modules affected by the hormone.

#index 1289587
#* Building patterned structures with robot swarms
#@ Justin Werfel;Yaneer Bar-Yam;Radhika Nagpal
#t 2005
#c 11
#% 336865
#% 642929
#! We describe a system in which simple, identical, autonomous robots assemble two-dimensional structures using prefabricated modules as building blocks. Modules are capable of some information processing, enabling them to share longrange structural information and communicate it to robots. This communication allows arbitrary solid structures to be rapidly built using a few fixed, local robot behaviors. Modules are identical in shape but may be functionally distinct, with constraints governing the location of different classes. We present algorithms for assembly of solid structures of any shape, both when the layout of module classes is fully specified in advance, and when functional constraints are satisfied during the building process, allowing for adaptive structures. This approach demonstrates a decentralized, autonomous, flexible, simple, and adaptive approach to construction.

#index 1289588
#* Motivated agents
#@ Kathryn Kasmarik;William Uther;Mary-Lou Maher
#t 2005
#c 11
#% 384911
#% 458377
#% 1271827

#index 1289589
#* Using AI and simulations to design and control space habitats
#@ David Kortenkamp;Scott Bell
#t 2005
#c 11
#% 579927
#! This paper describes a dynamic simulation of a space habitat. The simulation is configurable and controllable via external programs. Several groups have been using the simulation to study the impact of artificial intelligence tools on space habitat design and control. We outline some of the AI challenges and invite the AI community to use our simulation to further NASA's exploration goals.

#index 1289590
#* A universal measure of intelligence for artificial agents
#@ Shane Legg;Marcus Hutter
#t 2005
#c 11
#% 422028
#% 563271
#% 787659

#index 1289591
#* It's about time
#@ Neil Madden;Brian Logan
#t 2005
#c 11
#% 136370
#% 1134790

#index 1289592
#* Automation intelligence for the smart environment
#@ G. Michael Youngblood;Edwin O. Heierman;Lawrence B. Holder;Diane J. Cook
#t 2005
#c 11
#% 964204
#! Scaling AI algorithms to large problems requires that these algorithms work together to harness their respective strengths. We introduce a method of automatically constructing HHMMs using the output of a sequential data-mining algorithm and sequential prediction algorithm. We present the theory of this technique and demonstrate results using the MavHome intelligent environment.

#index 1289593
#* Allocation and scheduling for MPSoCs via decomposition and no-good generation
#@ Luca Benini;Davide Bertozzi;Alessio Guerri;Michela Milano
#t 2005
#c 11
#% 573790
#% 761139

#index 1289594
#* Minimizing a makespan under uncertainty
#@ Jérôme Fortin;Paweł Zielinski;Didier Dubois;Hélène Fargier
#t 2005
#c 11
#% 107137
#% 1289192
#% 1289215
#% 1781148
#! This paper reconsiders the most basic scheduling problem, that of minimizing the makespan of a partially ordered set of activities, in the context of incomplete knowledge. After positioning this paper in the scope of temporal networks under uncertainty, we provide a complete solution to the problem of finding floats of activities, and of locating surely critical ones, as they are often isolated. The minimal float problem is NP-hard while the maximal float problem is polynomial. New complexity results and efficient algorithms are provided for the interval-valued makespan minimization problem.

#index 1289595
#* Scaling up WA* with commitment and diversity
#@ David Furcy;Sven Koenig
#t 2005
#c 11
#% 590541
#% 827731
#! Weighted A* (WA*) is a popular search technique that scales up A* while sacrificing solution quality. Recently, researchers have proposed two variants of WA*: KWA* adds diversity to WA*, and MSC-WA* adds commitment to WA*. In this paper, we demonstrate that there is benefit in combining them. The resulting MSC-KWA* scales up to larger domains than WA*, KWA* and MSC-WA*, which is rather surprising since diversity and commitment at first glance seem to be opposing concepts.

#index 1289596
#* A covering problem for hypercubes
#@ Jörg Hoffmann;Sebastian Kupferschmid
#t 2005
#c 11
#% 289947
#% 336874
#! We introduce a new NP-complete problem asking if a "query" hypercube is (not) covered by a set of other "evidence" hypercubes. This comes down to a form of constraint reasoning asking for the satisfiability of a CNF formula where the logical atoms are inequalities over single variables, with possibly infinite variable domains. We empirically investigate the location of the phase transition regions in two random distributions of problem instances. We introduce a solution method that iteratively constructs a representation of the non-covered part of the query cube. In particular, the method is not based on backtracking. Our experiments show that the method is, in a significant range of instances, superior to the backtracking method that results from translation to SAT, and application of a state-of-the-art DP-based SAT solver.

#index 1289597
#* Predicate-oriented isomorphism elimination in model finding
#@ Xiangxue Jia;Jian Zhang
#t 2005
#c 11
#% 1275265
#% 1838919
#! Finding models of logical formulas is a challenging problem. For first-order formulas, a finite model can be found by exhaustive search. For many structured problem instances, there is much isomorphism in the search space. This paper proposes general-purpose techniques for eliminating isomorphic subspaces, which can be helpful when the formulas have many predicates. The techniques are based on inherent symmetries in first-order clauses.

#index 1289598
#* Maintaining arc consistency using adaptive domain ordering
#@ Chavalit Likitvivatanavong;Yuanlin Zhang;James Bowen;Eugene C. Freuder
#t 2005
#c 11
#% 288952
#% 1289191

#index 1289599
#* Combination of local search strategies for rotating workforce scheduling problem
#@ Nysret Musliu
#t 2005
#c 11
#% 126390
#% 413490
#! Rotating workforce scheduling is a typical constraint satisfaction problem which appears in a broad range of work places (e.g. industrial plants). Solving this problem is of a high practical relevance. In this paper we propose the combination of tabu search with random walk and min conflicts strategy to solve this problem. Computational results for benchmark examples in literature and other real life examples show that combination of tabu search with random walk and min conflicts strategy improves the performance of tabu search for this problem. The methods proposed in this paper improve performance of the state of art commercial system for generation of rotating workforce schedules.

#index 1289600
#* Corrective explanation for interactive constraint satisfaction
#@ Barry O’Sullivan;Barry O'Callaghan;Eugene C. Freuder
#t 2005
#c 11
#% 21137
#% 345434
#% 1250145
#! Interactive tasks such as online configuration can be modeled as constraint satisfaction problems. These can be solved interactively by a user assigning values to variables. Explanations for failure in constraint programming tend to focus on conflict. However, what is often desirable is an explanation that is corrective in the sense that it provides the basis for moving forward in the problem-solving process. This paper defines this notion of corrective explanation and demonstrates that a greedy search approach performs very well on a large real-world configuration problem.

#index 1289601
#* CSP search with responsibility sets and kernels
#@ Igor Razgon;Amnon Meisels
#t 2005
#c 11
#! We introduce data structures called responsibility set and kernel. We present an algorithm FCRK, which is a modification of FC that maintains these structures and uses them for pruning of the search space. According to our experimental evaluation, FC-RK outperforms FC-CBJ on constraint networks encoding graph k-coloring instances and on non-dense random binary constraint networks.

#index 1289602
#* Hypertree-decomposition via branch-decomposition
#@ Marko Samer
#t 2005
#c 11
#% 14511
#% 98188
#% 331899
#% 739628
#! Hypertree-decomposition is the most general approach in the literature for identifying tractable computation problems encoded as hypergraphs. We show how the heuristic branch-decomposition approach for ordinary graphs of [Cook and Seymour, 2003] can be used for the heuristic construction of hypertree-decompositions.

#index 1289603
#* Improving tree decomposition methods with function filtering
#@ Martí Sánchez;Javier Larrosa;Pedro Meseguer
#t 2005
#c 11
#% 55926
#% 578663
#% 644201
#! Tree decomposition can solve weighted CSP, but with a high spatial complexity. To improve its practical usage, we present function filtering, a strategy to decrease memory consumption. Function filtering dtects and removes some tuples that appear to be consistent but that will become inconsistent when extended to other variables. We show empirically the benefits of our approach.

#index 1289604
#* Streamlining local search for spatially balanced Latin squares
#@ Casey Smith;Carla Gomes;Cesar Fernandez
#t 2005
#c 11
#! Streamlined constrained reasoning powerfully boosts the performance of backtrack search methods for finding hard combinatorial objects. We use so-called spatially balanced Latin squares to show how streamlining can also be very effective for local search: Our approach is much faster and generates considerably larger spatially balanced Latin squares than previously reported approaches (up to order 35; the previous best results could only generate solutions up to order 18). We also provide a detailed characterization of our streamliner and solution topology for small orders. We believe that streamlined local search is a general technique suitable for solving a wide range of hard combinatorial design problems.

#index 1289605
#* Abduction with hypotheses confirmation
#@ Marco Alberti;Marco Gavanelli;Evelina Lamma;Paola Mello;Paolo Torroni
#t 2005
#c 11

#index 1289606
#* A language for functional interpretation of model based simulation
#@ Jonathan Bell;Neal Snooke;Chris Price
#t 2005
#c 11
#! Functional modeling is in use for the interpretation of the results of model based simulation of engineered systems for design analysis, enabling the automatic generation of a textual design analysis report that expresses the results of the simulation in terms of the system's purpose. We present a novel functional description language that increases the expressiveness of this approach, allowing a system function to be decomposed in terms of subsidiary functions as well as required effects, increasing the range both of systems and design analysis tasks for which the approach can be used.

#index 1289607
#* A non-monotonic logic for specifying and querying preferences
#@ Guido Boella;Leendert Van Der Torre
#t 2005
#c 11
#% 163720
#% 555435

#index 1289608
#* A multidimensional semantic framework for adaptive hypermedia systems
#@ Francesca Carmagnola;Federica Cena;Cristina Gena;Ilaria Torre
#t 2005
#c 11
#% 424010
#% 536219
#% 743023
#! This paper introduces a multidimensional semantic framework for adaptive systems. Different planes allow us to represent ontologies of user, her actions, context, device, domain, while the intersection between planes allow us to represent the semantic rules for inferring new user features or adaptation strategies. The adoption of ontology-based framework aims at creating a server for user modeling and adaptation strategy.

#index 1289609
#* Explaining search results
#@ Maurice Coyle;Barry Smyth
#t 2005
#c 11
#% 201992
#% 268079
#% 272821
#% 342660
#% 803556
#% 1279434
#% 1715636
#! In this paper we argue that it may be possible to help searchers to better understand the relevance of search results by generating explanations that highlight how other users have interacted with such results under similar search conditions in the past. We propose the use of the search histories of a community of online users as a source of these explanations. We describe the results of a recent study to examine the use of such explanation-based techniques to help Web searchers better appreciate the relevancy of search results. We highlight shortcomings of this approach in its current form and offer suggestions as to how it may be improved in future work.

#index 1289610
#* A cognitive model of visual analogical problem-solving transfer
#@ Jim Davies;Ashok K. Goel;Nancy J. Nersessian
#t 2005
#c 11
#% 1289199
#! Complex problem solving typically involves the generation of a procedure consisting of an ordered sequence of steps. Analogical reasoning is one strategy for solving complex problems, and visual reasoning is another. Visual analogies pertain to analogies based only on visual knowledge. In this paper, we describe the use of Galatea, a computational model of visual analogies in problem solving, to model the problem solving of a human subject (L14). L14 was a given the task of solving a complex problem using analogy in a domain that contained both visual and non-visual knowledge, and was encouraged to use visual analogy. We describe how Galatea models L14's use of visual analogy in problem solving.

#index 1289611
#* An architecture for proof planning systems
#@ Louise A. Dennis
#t 2005
#c 11
#% 559900
#! This paper presents a generic architecture for proof planning systems in terms of an interaction between a customisable proof module and search module. These refer to both global and local information contained in reasoning states.

#index 1289612
#* Explaining preferences with argument positions
#@ Sylvie Doutre;Trevor Bench-Capon;Paul E. Dunne
#t 2005
#c 11
#% 198464
#% 733126
#! When deciding what to do agents must choose among alternative actions and different agents may make different choices according to what they wish to achieve in the light of their preferences and values. It cannot be assumed, however, that agents have a conscious understanding of their value preferences independent of the reasoning situations in which they engage. In this paper we consider an extension to a generic framework for reasoning about arguments justifying actions in terms of values in which the preferences amongst values emerge from the reasoning process.

#index 1289613
#* Heuristics for hard ASP programs
#@ Wolfgang Faber;Nicola Leone;Francesco Ricca
#t 2005
#c 11
#% 235018
#% 283229
#% 305343
#% 411814
#% 517569
#% 535315
#% 736900
#% 880394
#% 1289234
#% 1675277
#! We define a new heuristic hDS for ASP, and implement it in the (disjunctive) ASP system DLV. The new heuristic improves the evaluation of Σ2P/Π2P - hard ASP programs while maintaining the benign behaviour of the well-assessed heuristic of DLV on NP problems. We experiment with the new heuristic on QBFs. hDS significantly outperforms the heuristic of DLV on hard 2QBF problems. We compare also the DLV system (with the new heuristic hDS) to three prominent QBF solvers. The results of the comparison, performed on instances used in the last QBF competition, indicate that ASP systems can be faster than QBF systems on Σ2P/Π2P-hard problems.

#index 1289614
#* Incremental diagnosis of discrete-event systems
#@ Alban Grastien;Marie-Odile Cordier;Christine Largouët
#t 2005
#c 11

#index 1289615
#* Reflection patterns for interactive knowledge capture
#@ Jihie Kim
#t 2005
#c 11
#% 529176
#! Current knowledge acquisition tools have limited understanding of how users enter knowledge and how acquired knowledge is used, and provide limited assistance in organizing various knowledge authoring tasks. In this paper, we present a novel extension to existing knowledge acquisition tools where the system 1) captures the episodes of knowledge acquisition and knowledge use through a set of declarative reflection patterns 2) performs assessment on how to improve the future knowledge acquisition and knowledge use based on captured episodes, and 3) provides assistance to the users by combining the assessment results.

#index 1289616
#* A unified framework of propositional knowledge base revision and update based on state transition models
#@ Yasuo Kudo;Tetsuya Murai
#t 2005
#c 11
#% 109945
#% 212220
#! Belief revision and belief update are two of the most basic types of belief change operations. We need to select either revision or update when we accept new information into the current belief, however, such decision making has not been considered. In this paper, we propose a unified framework of revision and update based on state transition models that enable us to do such decision making. This framework provides a hybrid operation of revision and update, called acceptance.

#index 1289617
#* Redesign support framework based on hierarchical multiple models
#@ I. López-Arévalo;A. Rodríguez-Martínez;A. Aldea;R. Bañares-Alcántara;L. Jiménez
#t 2005
#c 11
#% 206965
#! A redesign support framework for complex technical processes is described in this paper. This framework employs a multi-model hierarchical representation of the process to be redesigned together with a case-based reasoning engine that helps us to decide the elements of the process that should be modified. This framework has been tested in the chemical engineering domain.

#index 1289618
#* Knowledge based approach for mechanically verifying security protocols
#@ Xiaoqi Ma;Xiaochun Cheng;Rachel McCrindle
#t 2005
#c 11
#% 198189
#% 320267
#% 592688
#! A new knowledge-based security protocol verification approach is proposed in this paper. A number of predicates, functions, assumptions and rules are used to infer the knowledge of participating principals. These items are implemented with Isabelle, which enables mechanical proving. This approach can prove protocols concerning interleaving protocol sessions and can prove the correctness of a mediumsized security protocol in a couple of seconds. The mechanical proofs of a number of important secure properties and then of the correctness of the Needham-Schroeder-Lowe protocol are given as examples to show the effectiveness of this method.

#index 1289619
#* Capturing and reusing case-based context for image retrieval
#@ Dympna O’Sullivan;Eoin McLoughlin;Michela Bertolotto;David C. Wilson
#t 2005
#c 11
#% 320432
#% 568104
#% 721163
#% 789897
#! Like many other application areas, task-based domains that employ digital imagery are faced with the problem of information overload. Modeling the relationship between images and the tasks being performed is an important step in addressing this problem. We have developed an interactive approach for the capture and reuse of image context information that leverages a measure of a user's intentions with regard to tasks that they address. We analyze aspects of human-computer interaction information that enables us to infer why image contents are important in a particular context and how specific images have been used to address particular domain goals.

#index 1289620
#* Dependency calculus reasoning in a general point relation algebra
#@ Marco Ragni;Alexander Scivos
#t 2005
#c 11
#% 270714
#! The point algebra is a fundamental formal calculus for spatial and temporal reasoning. We present a new generalization that meets all requirements to describe dependencies on networks. Applications range from traffic networks to medical diagnostics. We investigate satisfaction problems, tractable subclassses, embeddings into other relation algebras, and the associated interval algebra.

#index 1289621
#* Compact propositional encodings of first-order theories
#@ Deepak Ramachandran;Eyal Amir
#t 2005
#c 11
#% 336874
#% 355076
#% 528171
#% 822227
#% 1476298

#index 1289622
#* Computationally grounded model of BDI-agents
#@ Kaile Su;Abdul Sattar;Kewen Wang;Guido Governatori
#t 2005
#c 11
#% 68239
#% 188086
#% 214197
#% 659831
#% 1250134

#index 1289623
#* The ontology revision
#@ Yu Sun;Yuefei Sui
#t 2005
#c 11
#% 22296
#% 156337
#% 224753
#% 1393692
#! An ontology consists of a set of concepts, a set of constraints imposing on instances of concepts, and the subsumption relation. It is assumed that an ontology is a tree under the subsumption relation between concepts. To preserve structural properties of ontologies, the ontology revision is not only contracting ontologies by discarding statements inconsistent with a revising statement, but also extracting statements consistent with the revising statement and adding some other statements. In the ontology revision, the consistency of a revising statement with the theory of the logical closure of the ontology under the closed world assumption is discussed. The basic postulates of the ontology revision are proposed and a concrete ontology revision is given based on the consistence or inconsistence of an ontology and a revising statement.

#index 1289624
#* A CLP-based, diagnosticity-driven system for concept combinations
#@ Georgios Tagalakis;Daniela Ferrari;Mark T. Keane
#t 2005
#c 11
#% 375017
#! Diagnosticity operates as an important selection criterion for several computational models of concept combination. Unfortunately, it has not been clear how the diagnosticity of property and relational predicates of the concepts combined can be formalized and quantified. Using an information retrieval method we compute, in a uniform manner, diagnosticity values of concepts predicates. We go on to present a reasoning system that attempts to create meaningful interpretations of novel noun noun combinations. The system is based solely on diagnostic predicates values and a set of constraint satisfaction rules. We show the effectiveness and plausibility of our methods and discuss their potential.

#index 1289625
#* Proof general/eclipse: a generic interface for interactive proof
#@ Daniel Winterstein;David Aspinall;Christoph Lüth
#t 2005
#c 11
#% 251206

#index 1289626
#* Using learned browsing behavior models to recommend relevant web pages
#@ Tingshao Zhu;Russ Greiner;Gerald Häubl;Kevin Jewell;Bob Price
#t 2005
#c 11
#% 230532
#% 284794
#% 325198
#% 463903
#% 1275346
#! We introduce our research on learning browsing behavior models for inferring a user's information need (corresponding to a set of words) based on the actions he has taken during his current web session. This information is then used to find relevant pages, from essentially anywhere on the web. The models, learned from over one hundred users during a fiveweek user study, are session-specific but independent of both the user and website. Our empirical results suggest that these models can identify and satisfy the current information needs of users, even if they browse previously unseen pages containing unfamiliar words.

#index 1289627
#* A study of selection noise in collaborative web search
#@ Oisín Boydell;Barry Smyth;Cathal Gurrin;Alan F. Smeaton
#t 2005
#c 11
#% 27049
#% 194299
#% 268079
#% 320839
#% 342961
#% 433674
#% 803556
#% 1706000
#% 1715615
#! Collaborative Web search uses the past search behaviour (queries and selections) of a community of users to promote search results that are relevant to the community. The extent to which these promotions are likely to be relevant depends on how reliably past search behaviour can be captured. We consider this issue by analysing the results of collaborative Web search in circumstances where the behaviour of searchers is unreliable.

#index 1289628
#* Image retrieval and disambiguation for encyclopedic web search
#@ Atsushi Fujii;Tetsuya Ishikawa
#t 2005
#c 11
#% 219036
#% 815817
#! To produce multimedia encyclopedic content, we propose a method to search the Web for images associated with a specific word sense. We use text in an HTML file which links to an image as a pseudocaption for the image and perform text-based indexing and retrieval. We use term descriptions in a Web search site called "CYCLONE" as queries and correspond images and texts based on word senses.

#index 1289629
#* Learning complex event descriptions by abstraction
#@ Ugo Galassi;Attilio Giordana;Lorenza Saitta;Marco Botta
#t 2005
#c 11
#% 84444
#% 164953
#% 292235
#% 423630
#! The presence of long gaps dramatically increases the difficulty of detecting and characterizing complex events hidden in long sequences. In order to cope with this problem, a learning algorithm based on an abstraction mechanism is proposed: it can infer a Hierarchical Hidden Markov Model, from a learning set of sequences. The induction algorithm proceeds bottom-up, progressively coarsening the sequence granularity, and letting correlations between subsequences, separated by long gaps, naturally emerge. As a case study, the method is evaluated on an application of user profiling. The results show that the proposed algorithm is suitable for developing real applications in network security and monitoring.

#index 1289630
#* Conditional visuomotor learning and viability theory
#@ Fadila Hadj-Bouziane;Hélène Frankowska;Martine Meunier;Driss Boussaoud
#t 2005
#c 11
#% 107410
#! In conditional visuomotor learning, several arbitrary associations between visual cues and motor responses have to be learned by trial and error at the same time. Monkeys, as humans, do not achieve this task by randomly trying each possible association. Rather, they use a strategy that organizes sequentially the acquisition of individual stimulus-response associations. Accordingly, neuronal recordings in the monkey striatum, the main basal ganglia structure, reveals two forms of plasticity during learning, a transient one that could constitute the neuronal correlate of the strategy, and a long-lasting one that could reflect the slow neuronal implementation of individual associations. Existing models of basal ganglia function based on reinforcement learning cannot account for this dual process. Hence, we developed a mathematical model of conditional visuomotor learning, inspired from viability theory, which implements both the formation of individual associations and the use of strategies to organize learning.

#index 1289631
#* fMRI analysis via one-class machine learning techniques
#@ David R. Hardoon;Larry M. Manevitz
#t 2005
#c 11
#% 722811
#% 768668
#! We show how one-class compression Neural Networks and one-class SVM can be applied to fMRI data to learn the classification of brain activity associated with a specific motor activity. For comparison purposes, we use two labeled data and see what degree of classification ability is lost compared with the usual two-class SVM.

#index 1289632
#* Adaptive support vector machine for time-varying data streams using martingale
#@ Shen-Shyang Ho;Harry Wechsler
#t 2005
#c 11
#% 342600
#% 1042825
#! A martingale framework is proposed to enable support vector machine (SVM) to adapt to timevarying data streams. The adaptive SVM is a onepass incremental algorithm that (i) does not require a sliding window on the data stream, (ii) does not require monitoring the performance of the classifier as data points are streaming, and (iii) works well for high dimensional, multi-class data streams. Our experiments show that the novel adaptive SVM is effective at handling time-varying data streams simulated using both a synthetic dataset and a multiclass real dataset.

#index 1289633
#* Automatic hypertext keyphrase detection
#@ Daniel Kelleher;Saturnino Luz
#t 2005
#c 11
#% 55490
#% 281480
#% 495937
#% 1650665
#! This paper describes initial experiments in applying knowledge derived from hypertext structure to domain-specific automatic keyphrase extraction. It is found that hyperlink information can improve the effectiveness of automatic keyphrase extraction by 50%. However, the primary goal of this project is to apply similar techniques to information retrieval tasks such as web searching. These initial results show promise for the applicability of these techniques to more far-reaching tasks.

#index 1289634
#* Relational learning for email task management
#@ Rinat Khoussainov;Nicholas Kushmerick
#t 2005
#c 11
#% 340394

#index 1289635
#* A fast normalized maximum likelihood algorithm for multinomial data
#@ Petri Kontkanen;Petri Myllymäki
#t 2005
#c 11
#% 424807
#% 490612
#% 934581
#% 998771
#% 1650585
#% 1808676
#% 1809511
#% 1809531
#% 1809999
#% 1810528
#! Stochastic complexity of a data set is defined as the shortest possible code length for the data obtainable by using some fixed set of models. This measure is of great theoretical and practical importance as a tool for tasks such as model selection or data clustering. In the case of multinomial data, computing the modern version of stochastic complexity, defined as the Normalized Maximum Likelihood (NML) criterion, requires computing a sum with an exponential number of terms. Furthermore, in order to apply NML in practice, one often needs to compute a whole table of these exponential sums. In our previous work, we were able to compute this table by a recursive algorithm. The purpose of this paper is to significantly improve the time complexity of this algorithm. The techniques used here are based on the discrete Fourier transformand the convolution theorem.

#index 1289636
#* Using neutral examples for learning polarity
#@ Moshe Koppel;Jonathan Schler
#t 2005
#c 11
#% 132938
#% 272518
#% 290482
#% 577355
#% 819213
#% 854646
#! Sentiment analysis is an example of polarity learning. Most research on learning to identify sentiment ignores "neutral" examples and instead performs training and testing using only examples of significant polarity. We show that it is crucial to use neutral examples in learning polarity for a variety of reasons and show how neutral examples help us obtain superior classification results in two sentiment analysis test-beds.

#index 1289637
#* Transfer in learning by doing
#@ Bill Krueger;Tim Oates;Tom Armstrong;Paul Cohen;Carole Beal
#t 2005
#c 11
#% 200195
#! We develop two related themes, learning procedures and knowledge transfer. This paper introduces two methods for learning procedures and one for transferring previously-learned knowledge to a slightly different task. We demonstrate by experiment that transfer accelerates learning.

#index 1289638
#* Supervised local tangent space alignment for classification
#@ Hongyu Li;Wenbin Chen;I-Fan Shen
#t 2005
#c 11
#% 790049
#! Supervised local tangent space alignment (SLTSA) is an extension of local tangent space alignment (LTSA) to supervised feature extraction. Two algorithmic improvements are made upon LTSA for classification. First a simple technique is proposed to map new data to the embedded low-dimensional space and make LTSA suitable in a changing, dynamic environment. Then SLTSA is introduced to deal with data sets containing multiple classes with class membership information.

#index 1289639
#* Active cost-sensitive learning
#@ Dragos D. Margineantu
#t 2005
#c 11
#% 170649
#% 447606
#% 458681
#% 464280
#% 466568
#% 580510
#% 1289273
#% 1289281
#! For many classification tasks a large number of instances available for training are unlabeled and the cost associated with the labeling process varies over the input space. Meanwhile, virtually all these problems require classifiers that minimize a nonuniform loss function associated with the classification decisions (rather than the accuracy or number of errors). For example, to train pattern classification models for a network intrusion detection task, experts need to analyze network events and assign them labels. This can be a very costly procedure if the instances to be labeled are selected at random. In the meantime, the loss associated with mislabeling an intrusion is much higher than the loss associated with the opposite error (i.e., labeling a legal event as being an intrusion). As a result, to address these types of tasks, practitioners need tools that minimize the total cost computed as a sum of the cost of labeling and the loss associated with the decisions. This paper describes an approach for addressing this problem.

#index 1289640
#* Automatic learning of domain model for personalized hypermedia applications
#@ Hermine Njike;Thierry Artières;Patrick Gallinari;Julien Blanchard;Guillaume Letellier
#t 2005
#c 11
#% 102726
#% 280849
#% 342739
#% 424010
#% 536212
#% 679849
#% 741058
#! This paper deals with the automatic building of personalized hypermedia. We build upon ideas developed for educational hypermedia; the definition of a domain model and the use of overlay user models. Since much work has been done on learning user models and adapting hypermedia based on such models, we tackle the core problem: the automatic definition of a domain model for a static hypermedia.

#index 1289641
#* Kernels on prolog ground terms
#@ Andrea Passerini;Paolo Frasconi
#t 2005
#c 11
#% 418121
#% 731606
#% 731607
#% 743284
#% 771944
#! We describe a family of kernels over untyped and typed Prolog ground terms and show that they can be applied for learning in structured domains, presenting experimental results in a QSPR task.

#index 1289642
#* A learning scheme for generating expressive music performances of jazz standards
#@ Rafael Ramirez;Amaury Hazan
#t 2005
#c 11
#% 543942
#% 571112
#! We describe our approach for generating expressive music performances of monophonic Jazz melodies. It consists of three components: (a) a melodic transcription component which extracts a set of acoustic features from monophonic recordings, (b) a machine learning component which induces an expressive transformation model from the set of extracted acoustic features, and (c) a melody synthesis component which generates expressive monophonic output (MIDI or audio) from inexpressive melody descriptions using the induced expressive transformation model. In this paper we concentrate on the machine learning component, in particular, on the learning scheme we use for generating expressive audio from a score.

#index 1289643
#* Incorporating a folding rule into inductive logic programming
#@ David A. Rosenblueth
#t 2005
#c 11
#% 519278
#% 945021
#! Many inductive logic programming systems have operators reorganizing the program so far inferred, such as the intra-construction operator of CIGOL. At the same time, there is a similar reorganizing operator, called the "folding rule," developed in program transformation. We argue that there are advantages in using an extended folding rule as a reorganizing operator for inductive-inference systems. Such an extended folding rule allows an inductive-inference system not only to recognize already-learned concepts, but also to increase the efficiently of execution of inferred programs.

#index 1289644
#* Development of new techniques to improve web search
#@ David Sánchez;Antonio Moreno
#t 2005
#c 11
#% 280849
#% 741080
#% 762332
#! Web search engines are a great help for accessing web sites but they present several problems regarding semantic ambiguity. In order to solve them, we propose new methods for polysemy disambiguation of web resources and discovery of lexicalizations and synonyms of search queries.

#index 1289645
#* Intimate learning: a novel approach for combining labelled and unlabelled data
#@ Zhongmin Shi;Anoop Sarkar
#t 2005
#c 11
#% 252011
#% 1650352
#! This paper introduces a new bootstrapping method closely related to co-training and scoped-learning. The method is tested on a Web information extraction task of learning course names from web pages in which we use very few labelled items as seed data (10 web pages) and combine with an unlabelled set (174 web pages). The overall performance improved the precision/recall from 3.11%/0.31% for a baseline EM-based method to 44.7%/44.1% for intimate learning.

#index 1289646
#* Collective object identification
#@ Parag Singla;Pedro Domingos
#t 2005
#c 11
#% 464434
#% 854636

#index 1289647
#* Question classification by structure induction
#@ Menno Van Zaanen;Luiz Augusto Pizzato;Diego Mollá
#t 2005
#c 11
#% 282723
#% 742368
#% 853907
#! In this article we introduce a new approach (and several implementations) to the task of question classification. The approach extracts structural information using machine learning techniques and the patterns found are used to classify the questions. The approach fits in between the machine learning and handcrafting of regular expressions (as it was done in the past) and combines the best of both: classifiers can be generated automatically and the output can be investigated and manually optimised if needed.

#index 1289648
#* An inductive database for mining temporal patterns in event sequences
#@ Alexandre Vautier;Marie-Odile Cordier;René Quiniou
#t 2005
#c 11
#% 216508
#% 420063
#% 496087
#% 1289265

#index 1289649
#* Discovering time differential law equations containing hidden state variables and chaotic dynamics
#@ Takashi Washio;Fuminori Adachi;Hiroshi Motoda
#t 2005
#c 11
#% 24538
#% 351347
#% 417617
#% 424819
#% 451038
#% 465896
#% 495954
#! This paper proposes a novel approach to discover simultaneous time differential law equations having high plausibility to represent first principles underlying objective processes. The approach has the power to identify law equations containing hidden state variables and/or representing chaotic dynamics without using any detailed domain knowledge.

#index 1289650
#* Learning global models based on distributed data abstractions
#@ Xiaofeng Zhang;William K. Cheung
#t 2005
#c 11
#% 361100
#% 727929
#! Due to the increasing demand of massive and distributed data analysis, achieving highly accurate global data analysis results with local data privacy preserved becomes an increasingly important research issue. In this paper, we propose to adopt a model-based method (Gaussian mixture model) for local data abstraction and aggregate the local model parameters for learning global models. To support global model learning based on solely local GMM parameters instead of virtual data generated from the aggregated local model, a novel EM-like algorithm is derived. Experiments have been performed using synthetic datasets and the proposed method was demonstrated to be able to achieve the global model accuracy comparable to that of using the data regeneration approach at a much lower computational cost.

#index 1289651
#* Language learning in multi-agent systems
#@ Martin Allen;Claudia V. Goldman;Shlomo Zilberstein
#t 2005
#c 11
#% 450852
#% 496272
#% 773310
#% 1272045
#! We present the problem of learning to communicate in decentralized and stochastic environments, analyzing it formally in a decision-theoretic context and illustrating the concept experimentally. Our approach allows agents to converge upon coordinated communication and action over time.

#index 1289652
#* On the evolution of memory size in the minority game
#@ Ricardo M. Araújo;Luis C. Lamb
#t 2005
#c 11
#% 785571

#index 1289653
#* Achieving allocatively-efficient and strongly budget-balanced mechanisms in the network flow domain for bounded-rational agents
#@ Yoram Bachrach;Jeffrey S. Rosenschein
#t 2005
#c 11
#! Vickrey-Clarke-Groves (VCG) mechanisms are a framework for finding a solution to a distributed optimization problem in systems of self-interested agents. VCG mechanisms have received wide attention in the AI community because they are efficient and strategy-proof; a special case of the Groves family of mechanisms, VCG mechanisms are the only direct-revelation mechanisms that are allocatively efficient and strategy-proof. Unfortunately, they are only weakly budget-balanced. We consider self-interested agents in a network flow domain, and show that in this domain, it is possible to design a mechanism that is both allocatively-efficient and almost completely budget-balanced. This is done by choosing a mechanism that is not strategy-proof but rather strategy-resistant. Instead of using the VCG mechanism, we propose a mechanism in which finding a beneficial manipulation is an NP-complete problem, and the payments from the agents to the mechanism may be minimized as much as desired.

#index 1289654
#* The evolution of artificial social systems
#@ Guido Boella;Leendert Van Der Torre
#t 2005
#c 11
#% 181622
#% 233136
#% 257694
#% 823929

#index 1289655
#* Fast convergence to satisfying distributions
#@ Teddy Candale;Sandip Sen
#t 2005
#c 11
#% 257045
#% 496084
#! We investigate an environment where self-interested agents have to find high-quality service resources. Agents have common knowledge about resources which are able to provide these services. The performance of resources is measured by the satisfaction obtained by agents using them. The performance of a resource depends on its intrinsic capability and its current load. We use a satisfying rather than an optimizing framework, where agents are content to receive service quality above a threshold. We introduce a formal framework to characterize the convergence of agents to a state where each agent is satisfied with the performance of the service it is currently using. We analyzed the convergence behavior of such a system and identified a mechanism to speed up convergence.

#index 1289656
#* A rule language for modelling and monitoring social expectations in multi-agent systems
#@ Stephen Cranefield
#t 2005
#c 11
#% 205239
#% 417597
#% 643145
#! This paper proposes a rule language for defining social expectations based on a metric interval temporal logic with past and future modalities and a current-time binding operator. An algorithm for run-timemonitoring compliance of rules in this language based on formula progression is also outlined.

#index 1289657
#* A framework for communication planning on mobile devices
#@ Joseph B. Kopena;William C. Regli
#t 2005
#c 11
#% 188086
#% 398515
#% 731212
#% 1830870
#! In mobile computing, communicative acts are not free. Costs such as power and bandwidth consumption are prominent issues. In addition, resources vary widely across hardware and operating context. Agents in these settings must account for these costs and adapt to available capabilities. This poster presents a planning optimization formalization of this problem, enabling service-based agents to reason about and conduct communication using local and network accessible resources.

#index 1289658
#* Trust no one: evaluating trust-based filtering for recommenders
#@ John O'Donovan;Barry Smyth
#t 2005
#c 11
#% 173879
#% 458691
#% 490917
#% 563963
#% 790459
#% 1650569
#! To be successful recommender systems must gain the trust of users. To do this they must demonstrate their ability to make reliable predictions. We argue that collaborative filtering recommendation algorithms can benefit from explicit models of trust to inform their predictions. We present one such model of trust along with a cost-benefit analysis that focuses on the classical trade-off that exists between recommendation coverage and prediction accuracy.

#index 1289659
#* Inter-agent communication: a cost-reduction approach using an autonomous mobile mailbox
#@ Armin Stranjak;Igor Cavrak;Mario Zagar
#t 2005
#c 11
#% 632778
#% 636022
#! In this paper, we consider a mobile mailbox communication scheme to reduce inter-agent communication costs. We employ a mailbox mobility strategy based on the ability of the mailbox to predict variations in inbound message rates and to migrate, if necessary, to a potentially better position in the network.

#index 1289660
#* Coalitional games in open anonymous environments
#@ Makoto Yokoo;Vincent Conitzer;Tuomas Sandholm;Naoki Ohta;Atsushi Iwasaki
#t 2005
#c 11
#% 171142
#% 252199

#index 1289661
#* Value-centric trust model with improved familiarity measurement
#@ Jie Zhang;Ali A. Ghorbani
#t 2005
#c 11
#% 950065
#! Formalization of familiarity contributes to formalization of trust through a value-centric trust model. However, familiarity was assumed to be the similarity of values (fixed for two agents), and stability of the trust model was relatively low. To increase the stability, we propose an improved familiarity measurement. Experiments are carried out to compare the stability of the trust model with the improved familiarity measurement and with the fixed familiarity value. It is observed that the stability is increased by 33.47% through the improved familiarity measurement.

#index 1289662
#* Towards more intelligent mobile search
#@ Karen Church;Mark T. Keane;Barry Smyth
#t 2005
#c 11
#% 475237
#% 739771
#% 803556
#% 1279434
#% 1715637
#! As the mobile Internet continues to grow there is an increasing need to provide users with effective search facilities. In this paper we argue that the standard Web search approach of providing snippet text alongside each result is not appropriate given the interface limitations of mobile devices. Instead we evaluate an alternative approach involving the use of related queries in place of snippet text for result gisting.

#index 1289663
#* An inference model for semantic entailment in natural language
#@ Rodrigo De Salvo Braz;Roxana Girju;Vasin Punyakanok;Dan Roth;Mark Sammons
#t 2005
#c 11
#! Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. We present a principled approach to this problem that builds on inducing re-representations of text snippets into a hierarchical knowledge representation along with a sound inferential mechanism that makes use of it to prove semantic entailment.

#index 1289664
#* Discovering inconsistency through examination dialogues
#@ Paul E. Dunne;Sylvie Doutre;Trevor Bench-Capon
#t 2005
#c 11
#% 198464
#! In this paper we introduce examination dialogues, an addition to the dialogue typology of Walton and Krabbe. In educational settings the purpose of dialogue is often to elicit the position of a student, e.g. to test understanding. In other settings, a frequently adopted tactic is to attack an opponent's stance by exposing internal inconsistencies in their argument. In real debate such inconsistencies will often be rather more subtle than elementary logical fallacies since they arise from contradictions apparent in the opponent's value system. Protagonists will be better positioned to judge the applicability of this tactic as more information is determined concerning the exact nature of their opponent's case, e.g. the arguments favoured and values endorsed. One obstacle, however, is that following a request to state a view, the challenged party may refuse to comment. In this paper we present an approach to modelling the evolution of examination dialogues based on the concept of value-based argument frameworks and outline some algorithmic issues regarding argument selection.

#index 1289665
#* A probabilistic lexical approach to textual entailment
#@ Oren Glickman;Ido Dagan;Moshe Koppel
#t 2005
#c 11
#! The textual entailment problem is to determine if a given text entails a given hypothesis. This paper describes first a general generative probabilistic setting for textual entailment. We then focus on the sub-task of recognizing whether the lexical concepts present in the hypothesis are entailed from the text. This problem is recast as one of text categorization in which the classes are the vocabulary words. We make novel use of Naïve Bayes to model the problem in an entirely unsupervised fashion. Empirical tests suggest that the method is effective and compares favorably with state-of-the-art heuristic scoring approaches.

#index 1289666
#* Structural representation and matching of articulatory speech structures based on the evolving transformation system (ETS) formalism
#@ Alexander Gutkin;David Gay
#t 2005
#c 11
#% 252472
#! A formal structural representation of speech is presented in this paper. The representation is developed within the Evolving Transformation System (ETS) formalism and encapsulates speech processes at the articulatory level. We show how the class structure of several consonantal phonemes of English can be expressed via articulatory gestures. Elements of these classes can be detected in a corresponding structural representation of continuous speech. Our experimental results on the MOCHA articulatory corpus support the hypothesis that the proposed articulatory representation captures sufficient information for the accurate structural identification of phonemic classes.

#index 1289667
#* Sentence extraction for legal text summarisation
#@ Ben Hachey;Claire Grover
#t 2005
#c 11
#% 194251
#% 449747
#% 854813
#% 938701
#% 1650665
#! We describe a system for generating extractive summaries of texts in the legal domain, focusing on the relevance classifier, which determines which sentences are abstract-worthy. We experiment with naïve Bayes and maximum entropy estimation toolkits and explore methods for selecting abstract-worthy sentences in rank order. Evaluation using standard accuracy measures and using correlation confirm the utility of our approach, but suggest different optimal configurations.

#index 1289668
#* Fault-tolerant context-based interpretation of mathematical formulas
#@ Helmut Horacek;Magdalena Wolska
#t 2005
#c 11
#% 559315
#% 938656
#! We present a fault-tolerant formula interpreter that aims at finding plausibly intended, formally correct and contextually meaningful specifications from user statements containing formal inaccuracies.

#index 1289669
#* MDL-based acquisition of substitutability relationships between discourse connectives
#@ Ben Hutchinson
#t 2005
#c 11
#% 92535
#% 939350
#! Knowledge of which lexical items convey the same meaning in a given context is important for many Natural Language Processing tasks. This paper concerns the substitutability of discourse connectives in particular. This paper proposes a datadriven method based on a Minimum Description Length (MDL) criterion for automatically learning substitutability of connectives. The method is shown to outperform two baseline classifiers.

#index 1289670
#* Can we assign attitudes to a computer based on its beeps?: toward an effective method for making humans empathize with artificial agents
#@ Takanori Komatsu
#t 2005
#c 11
#% 571522
#% 752995
#! Can we assign attitudes to a computer based on its beeps? If so, which kinds of beeps are perceived as specific attitudes, such as "disagreement", "hesitation" or "agreement"? To examine this issue, I carried out an experiment to observe how participants perceive or assign an attitude to a computer according to beeps of different durations and F0 contour's slopes. The results revealed that 1) beeps with increasing intonation regardless of duration were perceived by participants as "disagreement", 2) flat sounds with longer duration were interpreted as "hesitation", and 3) decreasing intonations with shorter duration were as "agreement."

#index 1289671
#* Correspondence-guided synchronous parsing of parallel corpora
#@ Jonas Kuhn
#t 2005
#c 11
#% 288575
#% 741071
#% 816174
#! We present an efficient dynamic programming algorithm for synchronous parsing of sentence pairs from a parallel corpus with a given word alignment. Unless there is a large proportion of words without a correspondence in the other language, the worstcase complexity is significantly reduced over standard synchronous parsing. The theoretical complexity results are corroborated by a quantitative experimental evaluation.

#index 1289672
#* Naturalness of an utterance based on the automatically retrieved commonsense
#@ Rafal Rzepka;Yali Ge;Kenji Araki
#t 2005
#c 11
#% 375339
#% 377987
#! In this research we investigated user's behavior while facing a system coping with common knowledge about keywords and compared it with not only classic word-spotting method but also with random text-mining. We show how even a simple implementation of our idea can enrich the conversation and increase the naturalness of computer's utterances. Our results show that even very commonsensical utterances are more natural than classic approaches and also methods we developed to make a conversation more interesting. For arousing opinion exchange during the session, we will also briefly introduce our idea of combining latest NLP achievements into one holistic system where the main engine we want to base on commonsense processing and affective computing.

#index 1289673
#* Induction of syntactic collocation patterns from generic syntactic relations
#@ Violeta Seretan
#t 2005
#c 11
#% 740904
#% 855201
#! Syntactic configurations used in collocation extraction are highly divergent from one system to another, this questioning the validity of results and making comparative evaluation difficult. We describe a corpus-driven approach for inferring an exhaustive set of configurations from actual data by finding, with a parser, all the productive syntactic associations, then by appealing to human expertise for relevance judgements.

#index 1289674
#* Evaluating an NLG system using post-editing
#@ Somayajulu G. Sripada;Ehud Reiter;Lezan Hawizy
#t 2005
#c 11
#% 449752
#% 854837
#! Computer-generated texts, whether from Natural Language Generation (NLG) or Machine Translation (MT) systems, are often post-edited by humans before being released to users. The frequency and type of post-edits is a measure of how well the system works, and can be used for evaluation. We describe how we have used post-edit data to evaluate SUMTIME-MOUSAM, an NLG system that produces weather forecasts.

#index 1289675
#* Online support system for mediator education
#@ Takahiro Tanaka;Yoshiaki Yasumura;Daisuke Katagami;Katsumi Nitta
#t 2005
#c 11
#% 98223
#% 392069
#! To settle the disputation, ADR (Alternative Disputation Resolution) has been becoming popular instead of the trial. However, to educate the mediation skill, much training is needed. In this paper, we introduce the overview of the online mediator education system. This system navigates the users by providing materials for decision making by referring to old cases. Users can communicate with each other by using avatars, and they can see the status of disputation in the form of several diagrams.

#index 1289676
#* Appropriate microplanning choices for low-skilled readers
#@ Sandra Williams;Ehud Reiter
#t 2005
#c 11
#% 51055
#% 91524
#% 297158
#% 757379
#% 854106
#! We have developed a set of microplanning choice rules which are intended to enable Natural Language Generation (NLG) systems to generate appropriate texts for readers with below-average literacy, focusing in particular on choices related to how discourse structure is expressed (cue phrases, ordering, sentence structure). Evaluation experiments suggest that our rules do enhance the readability of texts for low-skilled readers, although there is still room for improvement.

#index 1289677
#* Mixed-initiative activity planning for Mars rovers
#@ John Bresina;Ari Jónsson;Paul Morris;Kanna Rajan
#t 2005
#c 11
#! One of the ground tools used to operate the Mars Exploration Rovers is a mixed-initiative planning system called MAPGEN. The role of the system is to assist operators building daily plans for each of the rovers, maximizing science return, while maintaining rover safety and abiding by science and engineering constraints. In this paper, we describe the MAPGEN system, focusing on the mixed-initiative planning aspect. We note important challenges, both in terms of human interaction and in terms of automated reasoning requirements. We then describe the approaches taken in MAPGEN, focusing on the novel methods developed by our team.

#index 1289678
#* Planning with graded fluents and actions
#@ Marta Cialdea;Carla Limongelli;Andrea Orlandini;Valentina Poggioni
#t 2005
#c 11
#% 763743
#% 1272008
#% 1279366
#% 1279387
#! This work can be seen as a first approach to a new planning model that takes into account the possibility to express actions and fluents with nonboolean values. According to this model, a planning problem is defned using both graded (multi-valued) and classical (boolean) fluents. Moreover, actions that can have different application degrees can be defined. In this work a PDDL extension allowing to describe such new problems is proposed and a planning algorithm for such problems is presented.

#index 1289679
#* Automated adaptive support for task and information prioritizing
#@ Tjerk De Greef;Peter-Paul Van Maanen
#t 2005
#c 11
#% 266391
#% 840577
#! This paper discusses a means for automatically supporting humans in information and task prioritizing. A new generic method based on the Competitive Task Model is described. Its implementation is able to calculate priorities of competing information entities, which provides a way of allocating tasks to the process operator. Due to a combination of dynamic states and information entities, it is usable as an adaptive control mechanism for attention and task allocation.

#index 1289680
#* Planning for weakly-coupled partially observable stochastic games
#@ AnYuan Guo;Victor Lesser
#t 2005
#c 11
#% 450852
#% 773196
#% 1279314

#index 1289681
#* Multi-agent assumption-based planning
#@ Damien Pellier;Humbert Fiorino
#t 2005
#c 11
#! The purpose of this poster is to introduce a dialectical theory for plan synthesis based on a multiagent approach. This approach is a promising way to devise systems able to take into account partial knowledge and heterogeneous skills of agents. We propose to consider the planning problem as a defeasible reasoning where agents exchange proposals and counter-proposals and are able to conjecture i.e., formulate plan steps based on hypothetical states of the world.

#index 1289682
#* Open-world planning for story generation
#@ Mark O. Riedl;R. Michael Young
#t 2005
#c 11
#% 773208
#! The ability to generate narrative is of importance to computer systems that wish to use story effectively for entertainment, training, or education. One way to generate narrative is to use planning. However, story planners are limited by the fact that they can only operate on the story world provided, which impacts the ability of the planner to find a solution story plan and the quality and structure of the story plan if one is found. We present a planning algorithm for story generation that can nondeterministically make decisions about the description of the initial story world state in a least-commitment fashion.

#index 1289683
#* Disjunctive temporal planning with uncertainty
#@ K. Brent Venable;Neil Yorke-Smith
#t 2005
#c 11
#% 107137
#% 307179
#% 736897
#% 1250232
#% 1289215
#! Driven by planning problems with both disjunctive constraints and contingency, we define the Disjunctive Temporal Problem with Uncertainty (DTPU), an extension of the DTP that includes contingent events. Generalizing existing work on Simple Temporal Problems with Uncertainty, we divide the time-points into controllable and uncontrollable classes, and propose varying notions of controllability to replace the notion of consistency.

#index 1289684
#* Talking robots: a fully autonomous implementation of the talking heads
#@ Jean-Christophe Baillie;Matthieu Nottale
#t 2005
#c 11
#% 85153
#% 179859
#% 530127
#! The "Talking Robots" experiment, inspried by the "Talking Heads" experiment from Sony, explores possibilities on how to ground symbols into perception using language, with two autonomous Aibo robots in an unconstained environment. We present here the first results of this experiment and outline in the conclusion a planned extension to social behaviors grounding.

#index 1289685
#* An on-line time warping algorithm for tracking musical performances
#@ Simon Dixon
#t 2005
#c 11
#! Dynamic time warping is not suitable for on-line applications because it requires complete knowledge of both series before the alignment of the first elements can be computed. We present a novel online time warping algorithm which has linear time and space costs, and performs incremental alignment of two series as one is received in real time. This algorithm is applied to the alignment of audio signals in order to track musical performances.

#index 1289686
#* Path-planning for autonomous training on robot manipulators in space
#@ Froduald Kabanza;Roger Nkambou;Khaled Belghith
#t 2005
#c 11
#! This paper describes the integration of robot path-planning and spatial task modeling into a software system that teaches the operation of a robot manipulator deployed on International Space Station (ISS). The system addresses the complexity of the manipulator, the limited direct view of the ISS exterior and the unpredictability of lighting conditions in the workspace. Robot path planning is used not for controlling the manipulator, but for automatically checking errors of a student learning to operate the manipulator and for automatically producing illustrations of good and bad motions in training.

#index 1289687
#* Growth of motor coordination in early robot learning
#@ M. H. Lee;Q. Meng
#t 2005
#c 11
#% 178014
#! We present an implementation of a model of very early sensory-motor development, guided by results from developmental psychology. Behavioral acquisition and growth is demonstrated through constraint-lifting mechanisms initiated by global state variables. The results show how staged competence can be shaped by qualitative behavior changes produced by anatomical, computational and maturational constraints.

#index 1289688
#* Measuring the cost of robotic communication
#@ Avi Rosenfeld;Gal A. Kaminka;Sarit Kraus
#t 2005
#c 11
#% 164502

#index 1289689
#* An heuristic search based approach for moving objects tracking
#@ Elena Sánchez-Nielsen;Mario Hernández-Tejera
#t 2005
#c 11
#% 241
#% 115608
#! Fast and accurate tracking of moving objects in video streams is a critical process in computer vision. This problem can be formulated as exploration problems and thus can be expressed as a search into a state space based representation approach. However, these search problems are hard to solve because they involve search through a high dimensional space. In this paper, we describe an A* heuristic search for computing efficient search through a space of transformations corresponding to the 2D motion of the object, where most promising search alternatives are computed by means of integrating target dynamics into the search process, and ideas from information theory are used to guide the search. The paper includes evaluations with video streams that illustrate the efficiency and suitability for real-time vision tasks on general purpose hardware. Moreover, the computational cost to carry out the tracking task is smaller than real time requirements (40 ms).

#index 1289690
#* 3-D interpretation of single line drawings
#@ Kenji Shoji;Fubito Toyama;Juichi Miyamichi
#t 2005
#c 11
#! The human visual system can interpret two dimensional (2-D) line drawings like the Necker cube as three dimensional (3-D) wire frames. We focus attention on a principle to minimize the entropy of angle distribution between line segments in a 3-D wire frame as a concrete definition of the law of pragnanz in Gestalt Psychology. And we implement the principle with the perceptual preference of planarity to the loops of wire frames using a genetic algorithm. Experimental results show the good coincidence with human perception.

#index 1289691
#* SVM-based obstacles recognition for road vehicle applications
#@ M. A. Sotelo;J. Nuevo;D. Fernandez;I. Parra;L. M. Bergasa;M. Ocana;R. Flores
#t 2005
#c 11
#% 116149
#% 316998
#% 335194
#! This paper describes an obstacle Recognition System based on SVM and vision. The basic components of the detected objects are first located in the image and then combined with a SVM-based classifier. A distributed learning approach is proposed in order to better deal with objects variability, illumination conditions, partial occlusions and rotations. A large database containing thousands of object examples extracted from real road images has been created for learning purposes. We present and discuss the results achieved up to date.

#index 1289692
#* Detecting and locating faults in the control software of autonomous mobile robots
#@ Gerald Steinbauer;Franz Wotawa
#t 2005
#c 11
#% 21137
#% 262737
#% 284640

#index 1289693
#* Learning discontinuities for switching between local models
#@ Marc Toussaint;Sethu Vijayakumar
#t 2005
#c 11
#% 272374
#% 418819

#index 1289694
#* Model minimization by linear PSR
#@ Masoumeh T. Izadi;Doina Precup
#t 2005
#c 11
#% 788097
#! Predictive state representation (PSR), proposed by [Littman et al., 2002; Singh et al., 2004], are a general representation for controlled dynamical systems. We present a sufficient condition under which a linear PSR compresses a POMDP representation.

#index 1289695
#* Using core beliefs for point-based value iteration
#@ Masoumeh T. Izadi;Ajit V. Rajwade;Doina Precup
#t 2005
#c 11
#% 252183
#% 788098
#% 1279358
#! Recent research on point-based approximation algorithms for POMDPs demonstrated that good solutions to POMDP problems can be obtained without considering the entire belief simplex. For instance, the Point Based Value Iteration (PBVI) algorithm [Pineau et al., 2003] computes the value function only for a small set of belief states and iteratively adds more points to the set as needed. A key component of the algorithm is the strategy for selecting belief points, such that the space of reachable beliefs is well covered. This paper presents a new method for selecting an initial set of representative belief points, which relies on finding first the basis for the reachable belief simplex. Our approach has better worst-case performance than the original PBVI heuristic, and performs well in several standard POMDP tasks.

#index 1289696
#* Approximating pseudo-Boolean functions on non-uniform domains
#@ R. F. Lax;Guoli Ding;Peter P. Chen;J. Chen
#t 2005
#c 11
#% 697
#% 313166
#% 749383
#% 789993
#! In Machine Learning (ML) and Evolutionary Computation (EC), it is often beneficial to approximate a complicated function by a simpler one, such as a linear or quadratic function, for computational efficiency or feasibility reasons (cf. [Jin, 2005]). A complicated function (the target function in ML or the fitness function in EC) may require an exponential amount of computation to learn/evaluate, and thus approximations by simpler functions are needed. We consider the problem of approximating pseudo-Boolean functions by simpler (e.g., linear) functions when the instance space is associated with a probability distribution. We consider {0, 1}n as a sample space with a (possibly nonuniform) probability measure on it, thus making pseudo-Boolean functions into random variables. This is also in the spirit of the PAC learning framework of Valiant [Valiant, 1984] where the instance space has a probability distribution on it. The best approximation to a target function f is then defined as the function g (from all possible approximating functions of the simpler form) that minimizes the expected distance to f. In an example, we use methods from linear algebra to find, in this more general setting, the best approximation to a given pseudo-Boolean function by a linear function.

#index 1289697
#* A modal logic for reasoning about possibilistic belief fusion
#@ Churn-Jung Liau;Tuan-Fang Fan
#t 2005
#c 11
#% 188086
#% 552832
#% 791176

#index 1289698
#* Networked distributed POMDPs: a synergy of distributed constraint optimization and POMDPs
#@ Ranjit Nair;Pradeep Varakantham;Milind Tambe;Makoto Yokoo
#t 2005
#c 11
#% 636335
#% 719917
#% 1250230
#% 1272045
#% 1272052
#% 1279314
#! In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent's limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present a distributed policy generation algorithm that performs local search.

#index 1289699
#* Coping with exceptions in multiclass ILP problems using possibilistic logic
#@ Mathieu Serrurier;Henri Prade
#t 2005
#c 11
#% 167544
#% 1272165
#% 1393859
#! The handling of exceptions in multiclass problems is a tricky issue in inductive logic programming (ILP). In this paper we propose a new formalization of the ILP problem which accounts for default reasoning, and is encoded with first-order possibilistic logic. We show that this formalization allows us to handle rules with exceptions, and to prevent an example to be classified in more than one class. The possibilistic logic view of ILP problem, can be easily handled at the algorithmic level as an optimization problem.

#index 1289700
#* What kind of a graphical model is the brain?
#@ Geoffrey E. Hinton
#t 2005
#c 11
#% 44876
#% 92146
#% 130878
#% 198701
#% 269195
#% 277467
#% 344590
#% 450888
#% 792896
#% 812582
#% 1051494
#! If neurons are treated as latent variables, our visual systems are non-linear, densely-connected graphical models containing billions of variables and thousands of billions of parameters. Current algorithms would have difficulty learning a graphical model of this scale. Starting with an algorithm that has difficulty learning more than a few thousand parameters, I describe a series of progressively better learning algorithms all of which are designed to run on neuron-like hardware. The latest member of this series can learn deep, multi-layer belief nets quite rapidly. It turns a generic network with three hidden layers and 1:7 million connections into a very good generative model of handwritten digits. After learning, the model gives classification performance that is comparable to the best discriminative methods.

#index 1305247
#* Local search: is brute-force avoidable?
#@ Michael R. Fellows;Frances A. Rosamond;Fedor V. Fomin;Daniel Lokshtanov;Saket Saurabh;Yngve Villanger
#t 2009
#c 11
#% 5804
#% 25998
#% 44934
#% 261150
#% 263371
#% 268714
#% 307700
#% 382908
#% 429983
#% 442065
#% 448483
#% 501419
#% 613122
#% 683672
#% 683674
#% 725766
#% 749534
#% 770724
#% 796416
#% 819513
#% 826827
#% 840418
#% 878715
#% 932939
#% 944324
#% 1078544
#% 1105387
#% 1827061
#% 1839433
#% 1972413
#! Many local search algorithms are based on searching in the k-exchange neighborhood. This is the set of solutions that can be obtained from the current solution by exchanging at most k elements. As a rule of thumb, the larger k is, the better are the chances of finding an improved solution. However, for inputs of size n, a naïve brute-force search of the k-exchange neighborhood requires nO(k) time, which is not practical even for very small values of k. We show that for several classes of sparse graphs, like planar graphs, graphs of bounded vertex degree and graphs excluding some fixed graph as a minor, an improved solution in the k-exchange neighborhood for many problems can be found much more efficiently. Our algorithms run in time O(τ (k) ċ nc), where τ is a function depending on k only and c is a constant independent of k. We demonstrate the applicability of this approach on different problems like r-CENTER, VERTEX COVER, ODD CYCLE TRANSVERSAL, MAX-CUT, and MIN-BISECTION. In particular, on planar graphs, all our algorithms searching for a k- local improvement run in time O(2O(k) ċ n2), which is polynomial for k = O(log n). We also complement the algorithms with complexity results indicating that--brute force search is unavoidable--in more general classes of sparse graphs.

#index 1305290
#* Proceedings of the 21st international jont conference on Artifical intelligence
#@ Hiroaki Kitano
#t 2009
#c 11

#index 1305291
#* Intelligent tutoring systems: new challenges and directions
#@ Cristina Conati
#t 2009
#c 11
#% 414515
#% 553939
#% 641790
#% 988199
#% 1006310
#% 1035633
#% 1127655
#% 1219588
#% 1220520
#% 1220540
#% 1225218
#% 1274829
#% 1289325
#! Intelligent Tutoring Systems (ITS) is the interdisciplinary field that investigates how to devise educational systems that provide instruction tailored to the needs of individual learners, as many good teachers do. Research in this field has successfully delivered techniques and systems that provide adaptive support for student problem solving in a variety of domains. There are, however, other educational activities that can benefit from individualized computer-based support, such as studying examples, exploring interactive simulations and playing educational games. Providing individualized support for these activities poses unique challenges, because it requires an ITS that can model and adapt to student behaviors, skills and mental states often not as structured and welldefined as those involved in traditional problem solving. This paper presents a variety of projects that illustrate some of these challenges, our proposed solutions, and future opportunities.

#index 1305292
#* Machine learning in ecosystem informatics and sustainability
#@ Thomas G. Dietterich
#t 2009
#c 11
#% 46803
#% 235377
#% 350323
#% 400847
#% 457842
#% 760805
#% 836905
#% 1035698
#% 1074346
#% 1211846
#! Ecosystem Informatics brings together mathematical and computational tools to address scientific and policy challenges in the ecosystem sciences. These challenges include novel sensors for collecting data, algorithms for automated data cleaning, learning methods for building statistical models from data and for fitting mechanistic models to data, and algorithms for designing optimal policies for biosphere management. This presentation discusses these challenges and then describes recent work on the first two of these--new methods for automated arthropod population counting and linear Gaussian DBNs for automated cleaning of sensor network data.

#index 1305293
#* How experience of the body shapes language about space
#@ Luc Steels;Michael Spranger
#t 2009
#c 11
#% 211883
#% 382676
#% 445479
#% 1135065
#% 1728838
#! Open-ended language communication remains an enormous challenge for autonomous robots. This paper argues that the notion of a language strategy is the appropriate vehicle for addressing this challenge. A language strategy packages all the procedures that are necessary for playing a language game. We present a specific example of a language strategy for playing an Action Game in which one robot asks another robot to take on a body posture (such as stand or sit), and show how it effectively allows a population of agents to self-organise a perceptually grounded ontology and a lexicon from scratch, without any human intervention. Next, we show how a new language strategy can arise by exaptation from an existing one, concretely, how the body posture strategy can be exapted to a strategy for playing language games about the spatial position of objects (as in "the bottle stands on the table").

#index 1305294
#* Activity recognition: linking low-level sensors to high-level intelligence
#@ Qiang Yang
#t 2009
#c 11
#% 236497
#% 743353
#% 797049
#% 850430
#% 944137
#% 946811
#% 1024911
#% 1034531
#% 1055696
#% 1072103
#% 1089792
#% 1114487
#% 1250174
#% 1250210
#% 1250661
#% 1269847
#% 1270305
#% 1270308
#% 1270314
#% 1270315
#% 1272008
#% 1275152
#% 1290117
#% 1305579
#% 1476298
#% 1668045
#! Sensors provide computer systems with a window to the outside world. Activity recognition "sees" what is in the window to predict the locations, trajectories, actions, goals and plans of humans and objects. Building an activity recognition system requires a full range of interaction from statistical inference on lower level sensor data to symbolic AI at higher levels, where prediction results and acquired knowledge are passed up each level to form a knowledge food chain. In this article, I will give an overview of some of the current activity recognition research works and explore a life-cycle of learning and inference that allows the lowest-level radio-frequency signals to be transformed into symbolic logical representations for AI planning, which in turn controls the robots or guides human users through a sensor network, thus completing a full life cycle of knowledge.

#index 1305295
#* Nonmanipulable selections from a tournament
#@ Alon Altman;Ariel D. Procaccia;Moshe Tennenholtz
#t 2009
#c 11
#% 198464
#% 951820
#% 953322
#% 992253
#% 1083990
#% 1084425
#% 1270025
#% 1272142
#! A tournament is a binary dominance relation on a set of alternatives. Tournaments arise in many contexts that are relevant to AI, most notably in voting (as a method to aggregate the preferences of agents). There are many works that deal with choice rules that select a desirable alternative from a tournament, but very few of them deal directly with incentive issues, despite the fact that game-theoretic considerations are crucial with respect to systems populated by selfish agents. We deal with the problem of the manipulation of choice rules by considering two types of manipulation. We say that a choice rule is monotonic if an alternative cannot get itself selected by losing on purpose, and pairwise nonmanipulable if a pair of alternatives cannot make one of them the winner by reversing the outcome of the match between them. Our main result is a combinatorial construction of a choice rule that is monotonic, pairwise nonmanipulable, and onto the set of alternatives, for any number of alternatives besides three.

#index 1305296
#* Using reasoning patterns to help humans solve complex games
#@ Dimitrios Antos;Avi Pfeffer
#t 2009
#c 11
#% 773284
#% 1269685
#! We propose a novel method for helping humans make good decisions in complex games, for which common equilibrium solutions may be too difficult to compute or not relevant. Our method leverages and augments humans' natural use of arguments in the decision making process. We believe that, if computers were capable of generating similar arguments from the mathematical description of a game, and presented those to a human decision maker, the synergies would result in better performance overall. The theory of reasoning patterns naturally lends itself to such a use. We use reasoning patterns to derive localized evaluation functions for each decision in a game, then present their output to humans. We have implemented this approach in a repeated principal-agent game, and used it to generate advice given to subjects. Experimental results show that humans who received advice performed better than those who did not.

#index 1305297
#* UCT for tactical assault planning in real-time strategy games
#@ Radha-Krishna Balla;Alan Fern
#t 2009
#c 11
#% 425053
#% 425074
#% 983838
#% 1665148
#% 1713137
#! We consider the problem of tactical assault planning in real-time strategy games where a team of friendly agents must launch an assault on an enemy. This problem offers many challenges including a highly dynamic and uncertain environment, multiple agents, durative actions, numeric attributes, and different optimization objectives. While the dynamics of this problem are quite complex, it is often possible to provide or learn a coarse simulation-based model of a tactical domain, which makes Monte-Carlo planning an attractive approach. In this paper, we investigate the use of UCT, a recent Monte-Carlo planning algorithm for this problem. UCT has recently shown impressive successes in the area of games, particularly Go, but has not yet been considered in the context of multiagent tactical planning. We discuss the challenges of adapting UCT to our domain and an implementation which allows for the optimization of user specified objective functions. We present an evaluation of our approach on a range of tactical assault problems with different objectives in the RTS game Wargus. The results indicate that our planner is able to generate superior plans compared to several baselines and a human player.

#index 1305298
#* Methodology for designing reasonably expressive mechanisms with application to ad auctions
#@ Michael Benisch;Norman Sadeh;Tuomas Sandholm
#t 2009
#c 11
#% 1206663
#% 1270022
#% 1270024
#% 1270036
#% 1407360
#% 1407362
#! Mechanisms (especially on the Internet) have begun allowing people or organizations to express richer preferences in order to provide for greater levels of overall satisfaction. In this paper, we develop an operational methodology for quantifying the expected gains in economic efficiency associated with different forms of expressiveness. We begin by proving that the sponsored search mechanism (GSP) used by Google, Yahoo!, MSN, etc. can be arbitrarily inefficient. We then experimentally compare its efficiency to a slightly more expressive variant (PGSP), which solicits an extra bid for a premium class of positions. We generate random preference distributions based on published industry knowledge. We determine ideal strategies for the agents using a custom tree search technique, and we also benchmark using straightforward heuristic bidding strategies. The GSP's efficiency loss is greatest in the practical case where some advertisers ("brand advertisers") prefer top positions while others ("value advertisers") prefer middle positions, and that loss can be dramatic. It is also worst when agents have small profit margins. While the PGSP is only slightly more expressive (and thus not much more cumbersome), it removes almost all of the efficiency loss in all of the settings we study.

#index 1305299
#* A multivariate complexity analysis of determining possible winners given incomplete votes
#@ Nadja Betzler;Susanne Hemmann;Rolf Niedermeier
#t 2009
#c 11
#% 408396
#% 951820
#% 1083984
#% 1269671
#% 1269785
#% 1270050
#% 1274974
#% 1274989
#! The POSSIBLE WINNER problem asks whether some distinguished candidate may become the winner of an election when the given incomplete votes are extended into complete ones in a favorable way. POSSIBLE WINNER is NP-complete for common voting rules such as Borda, many other positional scoring rules, Bucklin, Copeland etc. We investigate how three different parameterizations influence the computational complexity of POSSIBLE WINNER for a number of voting rules. We show fixed-parameter tractability results with respect to the parameter "number of candidates" but intractability results with respect to the parameter "number of votes". Finally, we derive fixed-parameter tractability results with respect to the parameter "total number of undetermined candidate pairs" and identify an interesting polynomial-time solvable special case for Borda.

#index 1305300
#* Algorithms and complexity results for pursuit-evasion problems
#@ Richard Borie;Craig Tovey;Sven Koenig
#t 2009
#c 11
#% 17278
#% 36176
#% 93657
#% 93660
#% 135538
#% 139753
#% 408396
#% 1039317
#% 1084017
#% 1084332
#! We study pursuit-evasion problems where a number of pursuers have to clear a given graph. We study when polynomial-time algorithms exist to determine how many pursuers are needed to clear a given graph and how a given number of pursuers should move on the graph to clear it with either a minimum sum of their travel distances or minimum task-completion time. We generalize prior work to both unit-width arbitrary-length and unit-length arbitrary-width graphs and derive both algorithms and complexity results for a variety of graph topologies. In this context, we describe a polynomial-time algorithm, called CLEARTHETREE, that is much shorter and algorithmically simpler than the state-of-the-art algorithm for the minimum pursuer problem on trees. Our theoretical research lays a firm theoretical foundation for pursuit evasion on graphs and informs practitioners about which problems are easy and which ones are hard.

#index 1305301
#* Conditional importance networks: a graphical language for representing ordinal, monotonic preferences over sets of goods
#@ Sylvain Bouveret;Ulle Endriss;Jérôme Lang
#t 2009
#c 11
#% 1250234
#% 1250331
#% 1272026
#% 1272103
#% 1272227
#% 1272249
#! While there are several languages for representing combinatorial preferences over sets of alternatives, none of these are well-suited to the representation of ordinal preferences over sets of goods (which are typically required to be monotonic). We propose such a language, taking inspiration from previous work on graphical languages for preference representation, specifically CP-nets, and introduce conditional importance networks (CI-nets). A CI-net includes statements of the form "if I have a set A of goods, and I do not have any of the goods from some other set B, then I prefer the set of goods C over the set of goods D." We investigate expressivity and complexity issues for CI-nets. Then we show that CI-nets are well-suited to the description of fair division problems.

#index 1305302
#* Planning games
#@ Ronen I. Brafman;Carmel Domshlak;Yagil Engel;Moshe Tennenholtz
#t 2009
#c 11
#% 217918
#% 567883
#% 808378
#% 1279323
#% 1279449
#! We introduce planning games, a study of interactions of self-motivated agents in automated planning settings. Planning games extend STRIPS-like models of single-agent planning to systems of multiple self-interested agents, providing a rich class of structured games that capture subtle forms of local interactions. We consider two basic models of planning games and adapt game-theoretic solution concepts to these models. In both models, agents may need to cooperate in order to achieve their goals, but are assumed to do so only in order to increase their net benefit. For each model we study the computational problem of finding a stable solution and provide efficient algorithms for systems exhibiting acyclic interaction structure.

#index 1305303
#* Coalitional affinity games and the stability gap
#@ Simina Brânzei;Kate Larson
#t 2009
#c 11
#% 165011
#% 1000451
#% 1083989
#% 1275134
#! We present and analyze coalitional affinity games, a family of hedonic games that explicitly model the value that an agent receives from being associated with other agents. We provide a characterization of the social-welfare maximizing coalition structures, and study the stability properties of affinity games, using the core solution concept. Interestingly, we observe that members of the core do not necessarily maximize social welfare. We introduce a new measure, the stability-gap to capture this difference. Using the stability gap, we show that for an interesting class of coalitional affinity games, the difference between the social welfare of a stable coalition structure and a social welfare maximizing coalition structure is bounded by a factor of two, and that this bound is tight.

#index 1305304
#* Simple coalitional games with beliefs
#@ Georgios Chalkiadakis;Edith Elkind;Nicholas R. Jennings
#t 2009
#c 11
#% 165011
#% 404719
#% 773332
#% 1024740
#% 1024930
#% 1223514
#% 1269784
#% 1270030
#% 1270034
#! We introduce coalitional games with beliefs (CGBs), a natural generalization of coalitional games to environments where agents possess private beliefs regarding the capabilities (or types) of others. We put forward a model to capture such agent-type uncertainty, and study coalitional stability in this setting. Specifically, we introduce a notion of the core for CGBs, both with and without coalition structures. For simple games without coalition structures, we then provide a characterization of the core that matches the one for the full information case, and use it to derive a polynomial-time algorithm to check core nonemptiness. In contrast, we demonstrate that in games with coalition structures allowing beliefs increases the computational complexity of stability-related problems. In doing so, we introduce and analyze weighted voting games with beliefs, which may be of independent interest. Finally, we discuss connections between our model and other classes of coalitional games.

#index 1305305
#* Commitment tracking via the reactive event calculus
#@ Federico Chesani;Paola Mello;Marco Montali;Paolo Torroni
#t 2009
#c 11
#% 7047
#% 378993
#% 417715
#% 438021
#% 719162
#% 1066581
#% 1425500
#! Runtime commitment verification is an important, open issue in multiagent research. To address it, we build on Yolum and Singh's formalization of commitment operations, on Chittaro and Montanari's cached event calculus, and on the SCIFF abductive logic programming proof-procedure. We propose a framework consisting of a declarative and compact language to express the domain knowledge, and a reactive and complete procedure to track the status of commitments effectively, producing provably sound and irrevocable answers.

#index 1305306
#* Compiling the votes of a subelectorate
#@ Yann Chevaleyre;Jérôme Lang;Nicolas Maudet;Guillaume Ravilly-Abadie
#t 2009
#c 11
#% 238182
#% 571628
#% 578715
#% 808366
#% 1083982
#% 1270050
#% 1272349
#% 1274989
#! In many practical contexts where a number of agents have to find a common decision, the votes do not come all together at the same time. In such situations, we may want to preprocess the information given by the subelectorate (consisting of the voters who have expressed their votes) so as to "compile" the known votes for the time when the latecomers have expressed their votes. We study the amount of space necessary for such a compilation, as a function of the voting rule, the number of candidates, and the number of votes already known. We relate our results to existing work, especially on communication complexity.

#index 1305307
#* How hard is it to control sequential elections via the agenda?
#@ Vincent Conitzer;Jérôme Lang;Lirong Xia
#t 2009
#c 11
#% 953322
#% 1021271
#% 1269785
#% 1270051
#% 1272026
#% 1272243
#% 1274964
#% 1274973
#! Voting on multiple related issues is an important and difficult problem. The key difficulty is that the number of alternatives is exponential in the number of issues, and hence it is infeasible for the agents to rank all the alternatives. A simple approach is to vote on the issues one at a time, in sequence; however, a drawback is that the outcome may depend on the order in which the issues are voted upon and decided, which gives the chairperson some control over the outcome of the election because she can strategically determine the order. While this is undeniably a negative feature of sequential voting, in this paper we temper this judgment by showing that the chairperson's control problem is, in most cases, computationally hard.

#index 1305308
#* Preference functions that score rankings and maximum likelihood estimation
#@ Vincent Conitzer;Matthew Rognlie;Lirong Xia
#t 2009
#c 11
#% 464451
#% 892736
#% 1071501
#% 1250605
#% 1305343
#% 1799949
#! In social choice, a preference function (PF) takes a set of votes (linear orders over a set of alternatives) as input, and produces one or more rankings (also linear orders over the alternatives) as output. Such functions have many applications, for example, aggregating the preferences of multiple agents, or merging rankings (of, say, webpages) into a single ranking. The key issue is choosing a PF to use. One natural and previously studied approach is to assume that there is an unobserved "correct" ranking, and the votes are noisy estimates of this. Then, we can use the PF that always chooses the maximum likelihood estimate (MLE) of the correct ranking. In this paper, we define simple ranking scoring functions (SRSFs) and show that the class of neutral SRSFs is exactly the class of neutral PFs that are MLEs for some noise model. We also define composite ranking scoring functions (CRSFs) and show a condition under which these coincide with SRSFs. We study key properties such as consistency and continuity, and consider some example PFs. In particular, we study Single Transferable Vote (STV), a commonly used PF, showing that it is a CRSF but not an SRSF, thereby clarifying the extent to which it is an MLE function. This also gives a new perspective on how ties should be broken under STV. We leave some open questions.

#index 1305309
#* Learning graphical game models
#@ Quang Duong;Yevgeniy Vorobeychik;Satinder Singh;Michael P. Wellman
#t 2009
#c 11
#% 197387
#% 567883
#% 773295
#% 951944
#% 1269873
#! Graphical games provide compact representation of a multiagent interaction when agents' payoffs depend only on actions of agents in their local neighborhood. We formally describe the problem of learning a graphical game model from limited observation of the payoff function, define three performance metrics for evaluating learned games, and investigate several learning algorithms based on minimizing empirical loss. Our first algorithm is a branch-and-bound search, which takes advantage of the structure of the empirical loss function to derive upper and lower bounds on loss at every node of the search tree. We also examine a greedy heuristic and local search algorithms. Our experiments with directed graphical games show that (i) when only a small sample of profile payoffs is available, branch-and-bound significantly outperforms other methods, and has competitive running time, but (ii) when many profiles are observed, greedy is nearly optimal and considerably better than other methods, at a fraction of branch-and-bound's running time. The results are comparable for undirected graphical games and when payoffs are sampled with noise.

#index 1305310
#* Preference aggregation over restricted ballot languages: sincerity and strategy-proofness
#@ Ulle Endriss;Maria Silvia Pini;Francesca Rossi;K. Brent Venable
#t 2009
#c 11
#% 392811
#% 1021253
#% 1274989
#! Voting theory can provide useful insights for multiagent preference aggregation. However, the standard setting assumes voters with preferences that are total orders, as well as a ballot language that coincides with the preference language. In typical AI scenarios, these assumptions do not hold: certain alternatives may be incomparable for some agents, and others may have their preferences encoded in a format that is different from how the preference aggregation mechanism wants them. We study the consequences of dropping these assumptions. In particular, we investigate the consequences for the important notion of strategy-proofness. While strategy-proofness cannot be guaranteed in the classical setting, we are able to show that there are situations in our more general framework where this is possible. We also consider computational aspects of the problem.

#index 1305311
#* Multimode control attacks on elections
#@ Piotr Faliszewski;Edith Hemaspaandra;Lane A. Hemaspaandra
#t 2009
#c 11
#% 408396
#% 953322
#% 1071500
#% 1071501
#% 1141527
#% 1250606
#% 1250608
#% 1270053
#% 1272243
#% 1274964
#! In 1992, Bartholdi, Tovey, and Trick [1992] opened the study of control attacks on elections--attempts to improve the election outcome by such actions as adding/deleting candidates or voters. That work has led to many results on how algorithms can be used to find attacks on elections and how complexity-theoretic hardness results can be used as shields against attacks. However, all the work in this line has assumed that the attacker employs just a single type of attack. In this paper, we model and study the case in which the attacker launches a multipronged (i.e., multimode) attack. We do so to more realistically capture the richness of reallife settings. For example, an attacker might simultaneously try to suppress some voters, attract new voters into the election, and introduce a spoiler candidate. Our model provides a unified framework for such varied attacks, and by constructing polynomial-time multiprong attack algorithms we prove that for various election systems even such concerted, flexible attacks can be perfectly planned in deterministic polynomial time.

#index 1305312
#* Charting the tractability frontier of mixed multi-unit combinatorial auctions
#@ Valeria Fionda;Gianluigi Greco
#t 2009
#c 11
#% 798967
#% 963346
#% 1038058
#% 1084438
#% 1250152
#% 1272004
#% 1274950
#! Mixed multi-unit combinatorial auctions (MMUCAs) are extensions of classical combinatorial auctions (CAs) where bidders trade transformations of goods rather than just sets of goods. Solving MMUCAs, i.e., determining the sequences of bids to be accepted by the auctioneer, is computationally intractable in general. However, differently from CAs, little was known about whether polynomial-time solvable classes of MMUCAs can be singled out based on constraining their characteristics. The paper precisely fills this gap, by depicting a clear picture of the "tractability frontier" for MMUCA instances under both structural and qualitative restrictions, which characterize interactions among bidders and types of bids involved in the various transformations, respectively. By analyzing these restrictions, a sharp frontier is charted based on various dichotomy results. In particular, tractability islands resulting from the investigation generalize on MMUCAs the largest class of tractable CAs emerging from the literature.

#index 1305313
#* Computing equilibria in multiplayer stochastic games of imperfect information
#@ Sam Ganzfried;Tuomas Sandholm
#t 2009
#c 11
#% 363744
#% 464283
#% 528153
#% 734918
#% 850011
#% 898290
#% 1024867
#% 1083975
#% 1083976
#% 1250316
#% 1271991
#! Computing a Nash equilibrium in multiplayer stochastic games is a notoriously difficult problem. Prior algorithms have been proven to converge in extremely limited settings and have only been tested on small problems. In contrast, we recently presented an algorithm for computing approximate jam/fold equilibrium strategies in a three-player nolimit Texas hold'em tournament--a very large real-world stochastic game of imperfect information [5]. In this paper we show that it is possible for that algorithm to converge to a non-equilibrium strategy profile. However, we develop an ex post procedure that determines exactly how much each player can gain by deviating from his strategy and confirm that the strategies computed in that paper actually do constitute an ε-equilibrium for a very small ε (0.5% of the tournament entry fee). Next, we develop several new algorithms for computing a Nash equilibrium in multiplayer stochastic games (with perfect or imperfect information) which can provably never converge to a non-equilibrium. Experiments show that one of these algorithms outperforms the original algorithm on the same poker tournament. In short, we present the first algorithms for provably computing an ε-equilibrium of a large stochastic game for small ε. Finally, we present an efficient algorithm that minimizes external regret in both the perfect and imperfect information cases.

#index 1305314
#* On the complexity of compact coalitional games
#@ Gianluigi Greco;Enrico Malizia;Luigi Palopoli;Francesco Scarcello
#t 2009
#c 11
#% 8913
#% 93660
#% 101944
#% 165011
#% 808378
#% 873944
#% 1269784
#! A significantly complete account of the complexity underlying the computation of relevant solution concepts in compact coalitional games is provided. The starting investigation point is the setting of graph games, about which various long-standing open problems were stated in the literature. The paper gives an answer to most of them, and in addition provides new insights on this setting, by stating a number of complexity results about some relevant generalizations and specializations. The presented results also pave the way towards precisely carving the tractability frontier characterizing computation problems on compact coalitional games.

#index 1305315
#* Iterated regret minimization: a new solution concept
#@ Joseph Y. Halpern;Rafael Pass
#t 2009
#c 11
#% 265907
#% 788068
#! For some well-known games, such as the Traveler's Dilemma or the Centipede Game, traditional game-theoretic solution concepts--most notably Nash equilibrium--predict outcomes that are not consistent with empirical observations. We introduce a new solution concept, iterated regret minimization, which exhibits the same qualitative behavior as that observed in experiments in many games of interest, including Traveler's Dilemma, the Centipede Game, Nash bargaining, and Bertrand competition. As the name suggests, iterated regret minimization involves the iterated deletion of strategies that do not minimize regret.

#index 1305316
#* Multi-step multi-sensor hider-seeker games
#@ Erik Halvorson;Vincent Conitzer;Ronald Parr
#t 2009
#c 11
#% 36176
#% 160600
#% 382586
#% 739590
#% 749559
#! We study a multi-step hider-seeker game where the hider is moving on a graph and, in each step, the seeker is able to search c subsets of the graph nodes. We model this game as a zero-sum Bayesian game, which can be solved in weakly polynomial time in the players' action spaces. The seeker's action space is exponential in c, and both players' action spaces are exponential in the game horizon. To manage this intractability, we use a column/constraint generation approach for both players. This approach requires an oracle to determine best responses for each player. However, we show that computing a best response for the seeker is NP-hard, even for a single-step game when c is part of the input, and that computing a best response is NP-hard for both players for the multi-step game, even if c = 1. An integer programming formulation of the best response for the hider is practical for moderate horizons, but computing an exact seeker best response is impractical due to the exponential dependence on both c and the horizon. We therefore develop an approximate best response oracle with bounded suboptimality for the seeker. We prove performance bounds on the strategy that results when column/constraint generation with approximate best responses converges, and we measure the performance of our algorithm in simulations. In our experimental results, column/constraint generation converges to near-minimax strategies for both players fairly quickly.

#index 1305317
#* Collaborative multi agent physical search with Probabilistic knowledge
#@ Noam Hazon;Yonatan Aumann;Sarit Kraus
#t 2009
#c 11
#% 417744
#% 493873
#% 546171
#% 1084018
#% 1269384
#% 1270021
#! This paper considers the setting wherein a group of agents (e.g., robots) is seeking to obtain a given tangible good, potentially available at different locations in a physical environment. Traveling between locations, as well as acquiring the good at any given location consumes from the resources available to the agents (e.g., battery charge). The availability of the good at any given location, as well as the exact cost of acquiring the good at the location is not fully known in advance, and observed only upon physically arriving at the location. However, apriori probabilities on the availability and potential cost are provided. Given such as setting, the problem is to find a strategy/plan that maximizes the probability of acquiring the good while minimizing resource consumption. Sample applications include agents in exploration and patrol missions, e.g., rovers on Mars seeking to mine a specific mineral. Although this model captures many real world scenarios, it has not been investigated so far. We focus on the case where locations are aligned along a path, and study several variants of the problem, analyzing the effects of communication and coordination. For the case that agents can communicate, we present a polynomial algorithm that works for any fixed number of agents. For noncommunicating agents, we present a polynomial algorithm that is suitable for any number of agents. Finally, we analyze the difference between homogeneous and heterogeneous agents, both with respect to their allotted resources and with respect to their capabilities.

#index 1305318
#* Strengthening schedules through uncertainty analysis
#@ Laura M. Hiatt;Terry L. Zimmerman;Stephen F. Smith;Reid Simmons
#t 2009
#c 11
#% 215489
#% 266386
#% 565111
#% 883360
#% 1024750
#% 1053972
#% 1250235
#% 1250638
#% 1250645
#% 1272093
#% 1272143
#% 1289215
#! In this paper, we describe an approach to scheduling under uncertainty that achieves scalability through a coupling of deterministic and probabilistic reasoning. Our specific focus is a class of oversubscribed scheduling problems where the goal is to maximize the reward earned by a team of agents in a distributed execution environment. There is uncertainty in both the duration and outcomes of executed activities. To ensure scalability, our solution approach takes as its starting point an initial deterministic schedule for the agents, computed using expected duration reasoning. This initial agent schedule is probabilistically analyzed to find likely points of failure, and then selectively strengthened based on this analysis. For each scheduled activity, the probability of failing and the impact that failure would have on the schedule's overall reward are calculated and used to focus schedule strengthening actions. Such actions generally entail fundamental trade-offs; for example, modifications that increase the certainty that a high-reward activity succeeds may decrease the schedule slack available to accommodate uncertainty during execution. We describe a principled approach to handling these trade-offs based on the schedule's "expected reward," using it as a metric to ensure that all schedule modifications are ultimately beneficial. Finally, we present experimental results obtained using a multi-agent simulation environment, which confirm that executing schedules strengthened in this way result in significantly higher rewards than are achieved by executing the corresponding initial schedules.

#index 1305319
#* DCOPs meet the realworld: exploring unknown reward matrices with applications to mobile sensor networks
#@ Manish Jain;Matthew Taylor;Milind Tambe;Makoto Yokoo
#t 2009
#c 11
#% 384911
#% 643102
#% 719917
#% 773232
#% 823945
#% 855913
#% 933448
#% 1083942
#% 1269368
#% 1274986
#% 1289393
#! Buoyed by recent successes in the area of distributed constraint optimization problems (DCOPs), this paper addresses challenges faced when applying DCOPs to real-world domains. Three fundamental challenges must be addressed for a class of real-world domains, requiring novel DCOP algorithms. First, agents may not know the payoff matrix and must explore the environment to determine rewards associated with variable settings. Second, agents may need to maximize total accumulated reward rather than instantaneous final reward. Third, limited time horizons disallow exhaustive exploration of the environment. We propose and implement a set of novel algorithms that combine decision-theoretic exploration approaches with DCOP-mandated coordination. In addition to simulation results, we implement these algorithms on robots, deploying DCOPs on a distributed mobile sensor network.

#index 1305320
#* Collaboration and shared plans in the open world: studies of ridesharing
#@ Ece Kamar;Eric Horvitz
#t 2009
#c 11
#% 806737
#% 1083997
#% 1272153
#% 1650372
#% 1704259
#% 1707163
#% 1728806
#! We develop and test computational methods for guiding collaboration that demonstrate how shared plans can be created in real-world settings, where agents can be expected to have diverse and varying goals, preferences, and availabilities. The methods are motivated and evaluated in the realm of ridesharing, using GPS logs of commuting data. We consider challenges with coordination among self-interested people aimed at minimizing the cost of transportation and the impact of travel on the environment. We present planning, optimization, and payment mechanisms that provide fair and efficient solutions to the rideshare collaboration challenge. We evaluate different VCG-based payment schemes in terms of their computational efficiency, budget balance, incentive compatibility, and strategy proofness. We present the behavior and analyses provided by the ABC ridesharing prototype system. The system learns about destinations and preferences from GPS traces and calendars, and considers time, fuel, environmental, and cognitive costs. We review how ABC generates rideshare plans from hundreds of real-life GPS traces collected from a community of commuters and reflect about the promise of employing the ABC methods to reduce the number of vehicles on the road, thus reducing CO2 emissions and fuel expenditures.

#index 1305321
#* Exchanging reputation information between communities: a payment-function approach
#@ Georgia Kastidou;Kate Larson;Robin Cohen
#t 2009
#c 11
#% 341929
#% 856790
#% 959133
#% 963351
#% 1093384
#% 1250347
#! We introduce a framework so that communities can exchange reputation information about agents in environments where agents are migrating between communities. We view the acquisition of the reputation information as a purchase and focus on the design of a payment function to facilitate the payment for information in a way that motivates communities to truthfully report reputation information for agents. We prove that in our proposed framework, honesty is the optimal policy and demonstrate the value of using a payment-function approach for the exchange of reputation information about agents between communities in multiagent environments. Using our payment function, each community is strengthened: it is able to reason more effectively about which agents to accept and can enjoy agents that are motivated to contribute strongly to the benefit of the community.

#index 1305322
#* Event-detecting multi-agent MDPs: complexity and constant-factor approximation
#@ Akshat Kumar;Shlomo Zilberstein
#t 2009
#c 11
#% 289947
#% 450852
#% 496272
#% 719917
#% 980074
#% 989613
#% 1215581
#% 1269380
#% 1289393
#! Planning under uncertainty for multiple agents has grown rapidly with the development of formal models such as multi-agent MDPs and decentralized MDPs. But despite their richness, the applicability of these models remains limited due to their computational complexity. We present the class of event-detecting multi-agent MDPs (eMMDPs), designed to detect multiple mobile targets by a team of sensor agents. We show that eMMDPs are NP-Hard and present a scalable 2-approximation algorithm for solving them using matroid theory and constraint optimization. The complexity of the algorithm is linear in the state-space and number of agents, quadratic in the horizon, and exponential only in a small parameter that depends on the interaction among the agents. Despite the worst-case approximation ratio of 2, experimental results show that the algorithm produces near-optimal policies for a range of test problems.

#index 1305323
#* A kernel method for market clearing
#@ Sébastien Lahaie
#t 2009
#c 11
#% 314918
#% 314925
#% 743284
#% 754153
#% 959291
#! The problem of market clearing in an economy is that of finding prices such that supply meets demand. In this work, we propose a kernel method to compute nonlinear clearing prices for instances where linear prices do not suffice. We first present a procedure that, given a sample of values and costs for a set of bundles, implicitly computes nonlinear clearing prices by solving an appropriately formulated quadratic program. We then use this as a subroutine in an elicitation procedure that queries demand and supply incrementally over rounds, only as much as needed to reach clearing prices. An empirical evaluation demonstrates that, with a proper choice of kernel function, the method is able to find sparse nonlinear clearing prices with much less than full revelation of values and costs. When the kernel function is not suitable to clear the market, the method can be tuned to achieve approximate clearing.

#index 1305324
#* Balancing utility and deal probability for auction-based negotiations in highly nonlinear utility spaces
#@ Ivan Marsa-Maestre;Miguel A. Lopez-Carmona;Juan R. Velasco;Takayuki Ito;Mark Klein;Katsuhide Fujita
#t 2009
#c 11
#% 338265
#% 659832
#% 823880
#% 890265
#% 1274970
#% 1725546
#% 1817034
#! Negotiation scenarios involving nonlinear utility functions are specially challenging, because traditional negotiation mechanisms cannot be applied. Even mechanisms designed and proven useful for nonlinear utility spaces may fail if the utility space is highly nonlinear. For example, although both contract sampling and constraint sampling have been successfully used in auction based negotiations with constraint-based utility spaces, they tend to fail in highly nonlinear utility scenarios. In this paper, we will show that the performance of these approaches decrease drastically in highly nonlinear utility scenarios, and propose a mechanism which balances utility and deal probability for the bidding and deal identification processes. The experiments show that the proposed mechanisms yield better results than the previous approaches in highly nonlinear negotiation scenarios.

#index 1305325
#* Strategyproof classification with shared inputs
#@ Reshef Meir;Ariel D. Procaccia;Jeffrey S. Rosenschein
#t 2009
#c 11
#% 180945
#% 432397
#% 769885
#% 1039674
#% 1222638
#% 1270039
#! Strategy proof classification deals with a setting where a decision-maker must classify a set of input points with binary labels, while minimizing the expected error. The labels of the input points are reported by self-interested agents, who might lie in order to obtain a classifier that more closely matches their own labels, thus creating a bias in the data; this motivates the design of truthful mechanisms that discourage false reports. Previous work [Meir et al., 2008] investigated both decision-theoretic and learning-theoretic variations of the setting, but only considered classifiers that belong to a degenerate class. In this paper we assume that the agents are interested in a shared set of input points. We show that this plausible assumption leads to powerful results. In particular, we demonstrate that variations of a truthful random dictator mechanism can guarantee approximately optimal outcomes with respect to any class of classifiers.

#index 1305326
#* Argumentation system with changes of an agent's knowledge base
#@ Kenichi Okuno;Kazuko Takahashi
#t 2009
#c 11
#% 198464
#% 263126
#% 330290
#% 428335
#% 431089
#% 733126
#% 752766
#% 773286
#% 1024834
#% 1221670
#% 1270040
#% 1274796
#% 1675013
#! This paper discusses a process of argumentation. We propose an algorithm for dynamic treatment of argumentation in which all lines of argumentation are executed in succession, and the agent's knowledge base can change during argumentation. We show that there exists a case in which an agent dynamically loses argumentation that would be considered won by a static analysis. We also show that the algorithm terminates, and describe acceptable arguments that are obtained after the argumentation.

#index 1305327
#* How pervasive is the Myerson-Satterthwaite impossibility?
#@ Abraham Othman;Tuomas Sandholm
#t 2009
#c 11
#% 890339
#% 963331
#% 1141527
#% 1272144
#! The Myerson-Satterthwaite theorem is a foundational impossibility result in mechanism design which states that no mechanism can be Bayes-Nash incentive compatible, individually rational, and not run a deficit. It holds universally for priors that are continuous, gapless, and overlapping. Using automated mechanism design, we investigate how often the impossibility occurs over discrete valuation domains. While the impossibility appears to hold generally for settings with large numbers of possible valuations (approaching the continuous case), domains with realistic valuation structure circumvent the impossibility with surprising frequency. Even if the impossibility applies, the amount of subsidy required to achieve individual rationality and incentive compatibility is relatively small, even over large unstructured domains.

#index 1305328
#* Thou shalt covet thy neighbor's cake
#@ Ariel D. Procaccia
#t 2009
#c 11
#% 70370
#% 847066
#% 1835907
#! The problem of fairly dividing a cake (as a metaphor for a heterogeneous divisible good) has been the subject of much interest since the 1940's, and is of importance in multiagent resource allocation. Two fairness criteria are usually considered: proportionality, in the sense that each of the n agents receives at least 1/n of the cake; and the stronger property of envy-freeness, namely that each agent prefers its own piece of cake to the others' pieces. For proportional division, there are algorithms that require O(n log n) steps, and recent lower bounds imply that one cannot do better. In stark contrast, known (discrete) algorithms for envy-free division require an unbounded number of steps, even when there are only four agents. In this paper, we give an Ω(n2) lower bound for the number of steps required by envy-free cake-cutting algorithms. This result provides, for the first time, a true separation between envy-free and proportional division, thus giving a partial explanation for the notorious difficulty of the former problem.

#index 1305329
#* Generalised fictitious play for a continuum of anonymous players
#@ Zinovi Rabinovich;Enrico Gerding;Maria Polukarov;Nicholas R. Jennings
#t 2009
#c 11
#% 788092
#% 1024729
#% 1029083
#% 1083993
#% 1083994
#% 1084432
#! Recently, efficient approximation algorithms for finding Nash equilibria have been developed for the interesting class of anonymous games, where a player's utility does not depend on the identity of its opponents. In this paper, we tackle the problem of computing equilibria in such games with continuous player types, extending the framework to encompass settings with imperfect information. In particular, given the existence result for pure Bayes-Nash equilibiria in these games, we generalise the fictitious play algorithm by developing a novel procedure for finding a best response strategy, which is specifically designed to deal with continuous and, therefore, infinite type spaces. We then combine the best response computation with the general fictitious play structure to obtain an equilibrium. To illustrate the power of this approach, we apply our algorithm to the domain of simultaneous auctions with continuous private values and discrete bids, in which the algorithm shows quick convergence.

#index 1305330
#* A characterisation of strategy-proofness for grounded argumentation semantics
#@ Iyad Rahwan;Kate Larson;Fernando Tohmé
#t 2009
#c 11
#% 198464
#% 992249
#% 992251
#% 1083990
#! Recently, Argumentation Mechanism Design (ArgMD) was introduced as a new paradigm for studying argumentation among self-interested agents using game-theoretic techniques. Preliminary results showed a condition under which a direct mechanism based on Dung's grounded semantics is strategy-proof (i.e. truth enforcing). But these early results dealt with a highly restricted form of agent preferences, and assumed agents can only hide, but not lie about, arguments. In this paper, we characterise strategy-proofness under grounded semantics for a more realistic preference class (namely, focal arguments). We also provide the first analysis of the case where agents can lie.

#index 1305331
#* Coalition structure generation in multi-agent systems with positive and negative externalities
#@ Talal Rahwan;Tomasz Michalak;Nicholas R. Jennings;Michael Wooldridge;Peter McBurney
#t 2009
#c 11
#% 252199
#% 284645
#% 773258
#% 1223513
#% 1270044
#% 1272269
#! Coalition structure generation has received considerable attention in recent research. Several algorithms have been proposed to solve this problem in Characteristic Function Games (CFGs), where every coalition is assumed to perform equally well in any coalition structure containing it. In contrast, very little attention has been given to the more general Partition Function Games (PFGs), where a coalition's effectiveness may change from one coalition structure to another. In this paper, we deal with PFGs with positive and negative externalities. In this context, we identify the minimum search that is required in order to establish a bound on the quality of the best coalition structure found. We then develop an anytime algorithm that improves this bound with further search, and show that it out-performs the existing state-of-the-art algorithms by orders of magnitude.

#index 1305332
#* Modeling agents through bounded rationality theories
#@ Avi Rosenfeld;Sarit Kraus
#t 2009
#c 11
#% 198113
#% 265892
#% 576214
#% 586853
#% 1084006
#% 1084436
#% 1269379
#% 1271975
#! Effectively modeling an agent's cognitive model is an important problem in many domains. In this paper, we explore the agents people wrote to operate within optimization problems. We claim that the overwhelming majority of these agents used strategies based on bounded rationality, even when optimal solutions could have been implemented. Particularly, we believe that many elements from Aspiration Adaptation Theory (AAT) are useful in quantifying these strategies. To support these claims, we present extensive empirical results from over a hundred agents programmed to perform in optimization problems involving solving for one and two variables.

#index 1305333
#* Towards con-resistant trust models for distributed agent systems
#@ Amirali Salehi-Abari;Tony White
#t 2009
#c 11
#% 378941
#% 543383
#% 608769
#% 643088
#% 803395
#% 804916
#% 823908
#% 823966
#% 878367
#% 1084410
#! Artificial societies - distributed systems of autonomous agents - are becoming increasingly important in e-commerce. Agents base their decisions on trust and reputation in ways analogous to human societies. Many different definitions for trust and reputation have been proposed that incorporate many sources of information; however, system designs have tended to focus much of their attention on direct interactions. Furthermore, trust updating schemes for direct interactions have tended to uncouple updates for positive and negative feedback. Consequently, behaviour in which cycles of positive feedback followed by a single negative feedback results in untrustworthy agents remaining undetected. This con-man style of behaviour is formally described and desirable characteristics of con-resistant trust schemes proposed. A conresistant scheme is proposed and compared with FIRE, Regret and Yu and Singh's model [Yu and Singh, 2000]. Simulation experiments demonstrate the utility of the con-resistant scheme.

#index 1305334
#* Probabilistic state translation in extensive games with large action sets
#@ David Schnizlein;Michael Bowling;Duane Szafron
#t 2009
#c 11
#% 348584
#% 1083975
#% 1215607
#% 1407337
#! Equilibrium or near-equilibrium solutions to very large extensive form games are often computed by using abstractions to reduce the game size. A common abstraction technique for games with a large number of available actions is to restrict the number of legal actions in every state. This method has been used to discover equilibrium solutions for the game of no-limit heads-up Texas Hold'em. When using a solution to an abstracted game to play one side in the un-abstracted (real) game, the real opponent actions may not correspond to actions in the abstracted game. The most popular method for handling this situation is to translate opponent actions in the real game to the closest legal actions in the abstracted game. We show that this approach can result in a very exploitable player and propose an alternative solution. We use probabilistic mapping to translate a real action into a probability distribution over actions, whose weights are determined by a similarity metric. We show that this approach significantly reduces the exploitability when using an abstract solution in the real game.

#index 1305335
#* Investigations of continual computation
#@ Dafna Shahaf;Eric Horvitz
#t 2009
#c 11
#% 288942
#% 314843
#% 329491
#% 528307
#% 566716
#% 593734
#% 989613
#% 1068349
#% 1183221
#% 1272002
#% 1845813
#! Autonomous agents that sense, reason, and act in real-world environments for extended periods often need to solve streams of incoming problems. Traditionally, effort is applied only to problems that have already arrived and have been noted. We examine continual computation methods that allow agents to ideally allocate time to solving current as well as potential future problems under uncertainty. We first review prior work on continual computation. Then, we present new directions and results, including the consideration of shared subtasks and multiple tasks. We present results on the computational complexity of the continual-computation problem and provide approximations for arbitrary models of computational performance. Finally, we review special formulations for addressing uncertainty about the best algorithm to apply, learning about performance, and considering costs associated with delayed use of results.

#index 1305336
#* Flexible procurement of services with uncertain durations using redundancy
#@ Sebastian Stein;Enrico Gerding;Alex Rogers;Kate Larson;Nicholas R. Jennings
#t 2009
#c 11
#% 252751
#% 342279
#% 1023420
#% 1084041
#% 1090846
#% 1093384
#! Emerging service-oriented technologies allow software agents to automatically procure distributed services to complete complex tasks. However, in many application scenarios, service providers demand financial remuneration, execution times are uncertain and consumers have deadlines for their tasks. In this paper, we address these issues by developing a novel approach that dynamically procures multiple, redundant services over time, in order to ensure success by the deadline. Specifically, we first present an algorithm for finding optimal procurement solutions, as well as a heuristic algorithm that achieves over 99% of the optimal and is capable of handling thousands of providers. Using experiments, we show that these algorithms achieve an improvement of up to 130% over current strategies that procure only single services. Finally, we consider settings where service costs are not known to the consumer, and introduce several mechanisms that incentivise providers to reveal their costs truthfully and that still achieve up to 95% efficiency.

#index 1305337
#* Decentralised coordination of mobile sensors using the max-sum algorithm
#@ Ruben Stranders;Alessandro Farinelli;Alex Rogers;Nicholas R. Jennings
#t 2009
#c 11
#% 840868
#% 891549
#% 1060234
#% 1083942
#% 1269765
#% 1275108
#% 1289393
#% 1809993
#! In this paper, we introduce an on-line, decentralised coordination algorithm for monitoring and predicting the state of spatial phenomena by a team of mobile sensors. These sensors have their application domain in disaster response, where strict time constraints prohibit path planning in advance. The algorithm enables sensors to coordinate their movements with their direct neighbours to maximise the collective information gain, while predicting measurements at unobserved locations using a Gaussian process. It builds upon the max-sum message passing algorithm for decentralised coordination, for which we present two new generic pruning techniques that result in speed-up of up to 92% for 5 sensors. We empirically evaluate our algorithm against several on-line adaptive coordination mechanisms, and report a reduction in root mean squared error up to 50% compared to a greedy strategy.

#index 1305338
#* Dynamic configuration of agent organizations
#@ Evan A. Sultanik;Robert N. Lass;William C. Regli
#t 2009
#c 11
#% 1675
#% 159514
#% 252199
#% 360802
#% 445079
#% 534174
#% 789896
#% 824063
#% 873077
#% 975059
#% 1026745
#% 1270327
#! It is useful to impose organizational structure over multiagent coalitions. Hierarchies, for instance, allow for compartmentalization of tasks: if organized correctly, tasks in disjoint subtrees of the hierarchy may be performed in parallel. Given a notion of the way in which a group of agents need to interact, the Dynamic Distributed Multiagent Hierarchy Generation (DynDisMHG) problem is to determine the best hierarchy that might expedite the process of coordination. This paper introduces a distributed algorithm, called Mobed, for both constructing and maintaining organizational agent hierarchies, enabling exploitation of parallelism in distributed problem solving. The algorithm is proved correct and it is shown that individual additions of agents to the hierarchy will run in an amortized linear number of rounds. The hierarchies resulting after perturbations to the agent coalition have constant-bounded edit distance, making Mobed very well suited to highly dynamic problems.

#index 1305339
#* Discovering theorems in game theory: two-person games with unique pure nash equilibrium payoffs
#@ Pingzhong Tang;Fangzhen Lin
#t 2009
#c 11
#% 1065101
#% 1210219
#% 1272149
#! In this paper we provide a logical framework for using computers to discover theorems in two-person finite games in strategic form, and apply it to discover classes of games that have unique pure Nash equilibrium payoffs. We consider all possible classes of games that can be expressed by a conjunction of two binary clauses, and our program rediscovered Kats and Thisse's class of weakly unilaterally competitive two-person games, and came up with several other classes of games that have unique pure Nash equilibrium payoffs. It also came up with new classes of strict games that have unique pure Nash equilibria, where a game is strict if for both player different profiles have different payoffs.

#index 1305340
#* Acquiring agent-based models of conflict from event data
#@ Glenn Taylor;Michael Quist;Allen Hicken
#t 2009
#c 11
#! Building and using agent-based models is often impractical, in part due to the cost of including expensive subject matter experts (SMEs) in the development process. In this paper, we describe a method for "bootstrapping" model building to lower the cost of overall model development. The models we are interested in here capture dynamic phenomena related to international and subnational conflict. The method of acquiring these models begins with event data drawn from news reports about a conflict region, and infers model characteristics particular to a conflict modeling framework called the Power Structure Toolkit (PSTK). We describe the toolkit and how it has been used prior to this work. We then describe the current problem of modeling conflict and the empirical data available to learn models, and extensions to the PSTK for model generation from this data. We also describe a formative evaluation of the system that compares the performance and costs of models built entirely by an SME against models built with an SME aided by the automated model generation process. Early results indicate at least equivalent prediction rates with significant savings in model generation costs.

#index 1305341
#* Where are the really hard manipulation problems? the phase transition in manipulating the veto rule
#@ Toby Walsh
#t 2009
#c 11
#% 216995
#% 261584
#% 534165
#% 709975
#% 951820
#% 984002
#% 1024781
#% 1071500
#% 1071501
#% 1083982
#% 1141527
#% 1250606
#% 1269671
#% 1272142
#% 1272336
#% 1274974
#% 1274989
#! Voting is a simple mechanism to aggregate the preferences of agents. Many voting rules have been shown to be NP-hard to manipulate. However, a number of recent theoretical results suggest that this complexity may only be in the worst-case since manipulation is often easy in practice. In this paper, we show that empirical studies are useful in improving our understanding of this issue. We demonstrate that there is a smooth transition in the probability that a coalition can elect a desired candidate using the veto rule as the size of the manipulating coalition increases. We show that a rescaled probability curve displays a simple and universal form independent of the size of the problem. We argue that manipulation of the veto rule is asymptotically easy for many independent and identically distributed votes even when the coalition of manipulators is critical in size. Based on this argument, we identify a situation in which manipulation is computationally hard. This is when votes are highly correlated and the election is "hung". We show, however, that even a single uncorrelated voter is enough to make manipulation easy again.

#index 1305342
#* Eliciting honest reputation feedback in a Markov setting
#@ Jens Witkowski
#t 2009
#c 11
#% 713046
#% 868465
#% 959133
#% 963351
#% 1650358
#% 1684491
#! Recently, online reputation mechanisms have been proposed that reward agents for honest feedback about products and services with fixed quality. Many real-world settings, however, are inherently dynamic. As an example, consider a web service that wishes to publish the expected download speed of a file mirrored on different server sites. In contrast to the models of Miller, Resnick and Zeckhauser and of Jurca and Faltings, the quality of the service (e. g., a server's available bandwidth) changes over time and future agents are solely interested in the present quality levels. We show that hidden Markov models (HMM) provide natural generalizations of these static models and design a payment scheme that elicits honest reports from the agents after they have experienced the quality of the service.

#index 1305343
#* Finite local consistency characterizes generalized scoring rules
#@ Lirong Xia;Vincent Conitzer
#t 2009
#c 11
#% 940734
#% 951820
#% 1024781
#% 1071501
#% 1083984
#% 1150431
#% 1250606
#% 1272142
#% 1279324
#% 1305306
#% 1305341
#% 1305345
#% 1698228
#! An important problem in computational social choice concerns whether it is possible to prevent manipulation of voting rules by making it computationally intractable. To answer this, a key question is how frequently voting rules are manipulable. We [Xia and Conitzer, 2008] recently defined the class of generalized scoring rules (GSRs) and characterized the frequency of manipulability for such rules. We showed, by examples, that most common rules seem to fall into this class. However, no natural axiomatic characterization of the class was given, leaving the possibility that there are natural rules to which these results do not apply. In this paper, we characterize the class of GSRs based on two natural properties: it is equal to the class of rules that are anonymous and finitely locally consistent. Generalized scoring rules also have other uses in computational social choice. For these uses, the order of the GSR (the dimension of its score vector) is important. Our characterization result implies that the order of a GSR is related to the minimum number of locally consistent components of the rule. We proceed to bound the minimum number of locally consistent components for some common rules.

#index 1305344
#* A dichotomy theorem on the existence of efficient or neutral sequential voting correspondences
#@ Lirong Xia;Jérôme Lang
#t 2009
#c 11
#% 1021271
#% 1250233
#% 1269793
#% 1270051
#% 1270252
#% 1272026
#% 1274973
#! Sequential voting rules and correspondences provide a way for agents to make group decisions when the set of available options has a multiissue structure. One important question about sequential voting rules (correspondences) is whether they satisfy two crucial criteria, namely neutrality and efficiency. Recently, Benoit and Kornhauser established an important result about seat-by-seat voting rules (which are a special case of sequential voting rules): they proved that if the multi-issue domain satisfies some properties, then the only seat-by-seat rules being either efficient or neutral are dictatorships. However, there are still some cases not covered by their results, including a very important and interesting case--voting correspondences. In this paper, we extend the impossibility theorems by Benoit and Kornhauser to voting correspondences, and obtain a dichotomy theorem on the existence of efficient or neutral sequential (seat-by-seat) voting rules and correspondences. Therefore, the question of whether sequential (seat-by-seat) voting rules (correspondences) can be efficient or neutral is now completely answered.

#index 1305345
#* Complexity of unweighted coalitional manipulation under some common voting rules
#@ Lirong Xia;Michael Zuckerman;Ariel D. Procaccia;Vincent Conitzer;Jeffrey S. Rosenschein
#t 2009
#c 11
#% 940734
#% 951820
#% 1024781
#% 1039608
#% 1071500
#% 1071501
#% 1083984
#% 1141527
#% 1250606
#% 1272142
#% 1279324
#% 1698228
#! Understanding the computational complexity of manipulation in elections is arguably the most central agenda in Computational Social Choice. One of the influential variations of the the problem involves a coalition of manipulators trying to make a favorite candidate win the election. Although the complexity of the problem is well-studied under the assumption that the voters are weighted, there were very few successful attempts to abandon this strong assumption. In this paper, we study the complexity of the unweighted coalitional manipulation problem (UCM) under several prominent voting rules. Our main result is that UCM is NP-complete under the maximin rule; this resolves an enigmatic open question. We then show that UCM is NP-complete under the ranked pairs rule, even with respect to a single manipulator. Furthermore, we provide an extreme hardness-of-approximation result for an optimization version of UCM under ranked pairs. Finally, we show that UCM under the Bucklin rule is in P.

#index 1305346
#* Trading off solution quality for faster computation in DCOP search algorithms
#@ William Yeoh;Xiaoxun Sun;Sven Koenig
#t 2009
#c 11
#% 337838
#% 428357
#% 773217
#% 823971
#% 855910
#% 855913
#% 1083936
#% 1083937
#% 1083938
#% 1223335
#% 1274986
#% 1289386
#! Distributed Constraint Optimization (DCOP) is a key technique for solving agent coordination problems. Because finding cost-minimal DCOP solutions is NP-hard, it is important to develop mechanisms for DCOP search algorithms that trade off their solution costs for smaller runtimes. However, existing tradeoff mechanisms do not provide relative error bounds. In this paper, we introduce three tradeoff mechanisms that provide such bounds, namely the Relative Error Mechanism, the Uniformly Weighted Heuristics Mechanism and the Non-Uniformly Weighted Heuristics Mechanism, for two DCOP algorithms, namely ADOPT and BnB-ADOPT. Our experimental results show that the Relative Error Mechanism generally dominates the other two tradeoff mechanisms for ADOPT and the UniformlyWeighted Heuristics Mechanism generally dominates the other two trade-off mechanisms for BnB-ADOPT.

#index 1305347
#* A multi-agent learning approach to online distributed resource allocation
#@ Chongjie Zhang;Victor Lesser;Prashant Shenoy
#t 2009
#c 11
#% 66336
#% 266286
#% 303737
#% 307102
#% 495958
#% 729612
#% 1269499
#% 1272372
#! Resource allocation in computing clusters is traditionally centralized, which limits the cluster scale. Effective resource allocation in a network of computing clusters may enable building larger computing infrastructures. We consider this problem as a novel application for multiagent learning (MAL). We propose a MAL algorithm and apply it for optimizing online resource allocation in cluster networks. The learning is distributed to each cluster, using local information only and without access to the global system reward. Experimental results are encouraging: our multiagent learning approach performs reasonably well, compared to an optimal solution, and better than a centralized myopic allocation approach in some cases.

#index 1305348
#* Axiomatic characterization of task oriented negotiation
#@ Dongmo Zhang
#t 2009
#c 11
#% 162305
#% 263126
#% 1272056
#! This paper presents an axiomatic analysis of negotiation problems within task-oriented domains (TOD). We start by applying three classical bargaining solutions of Nash, Kalai-Smorodinsky and Egalitarian to the domains of problems with a preprocess of randomization on possible agreements. We find out that these three solutions coincide within any TOD and can be characterized by the same set of axioms, which specify a solution of task oriented negotiation as an outcome of dual-process of maximizing cost reduction and minimizing workload imbalance. This axiomatic characterization is then used to produce an approximate solution to the domain of problems without randomization on possible agreements.

#index 1305349
#* K-swaps: cooperative negotiation for solving task-allocation problems
#@ Xiaoming Zheng;Sven Koenig
#t 2009
#c 11
#% 282989
#% 1270035
#% 1274972
#! In this paper, we study distributed algorithms for cooperative agents that allow them to exchange their assigned tasks in order to reduce their team cost. We define a new type of contract, called K-swaps, that describes multiple task exchanges among multiple agents at a time, which generalizes the concept of single task exchanges. We design a distributed algorithm that constructs all possible K-swaps that reduce the team cost of a given task allocation and show that each agent typically only needs to communicate a small part of its local computation results to the other agents. We then demonstrate empirically that K-swaps can reduce the team costs of several existing task-allocation algorithms significantly even if K is small.

#index 1305350
#* Interruptible algorithms for multi-problem solving
#@ Spyros Angelopoulos;Alejandro López-Ortiz
#t 2009
#c 11
#% 329487
#% 331356
#% 495928
#% 578760
#% 590544
#% 1250644
#% 1270226
#% 1279384
#! In this paper we address the problem of designing an interruptible system in a setting in which n problem instances, all equally important, must be solved. The system involves scheduling executions of contract algorithms (which offer a trade-off between allowable computation time and quality of the solution) in m identical parallel processors. When an interruption occurs, the system must report a solution to each of the n problem instances. The quality of this output is then compared to the best-possible algorithm that has foreknowledge of the interruption time and must, likewise, produce solutions to all n problem instances. This extends the well-studied setting in which only one problem instance is queried at interruption time. We propose a schedule which we prove is optimal for the case of a single processor. For multiple processors, we show that the quality of the schedule is within a small factor from optimal.

#index 1305351
#* Towards industrial-like random SAT instances
#@ Carlos Ansótegui;Maria Luisa Bonet;Jordi Levy
#t 2009
#c 11
#% 644201
#% 895016
#% 1270054
#% 1273681
#% 1279379
#% 1289181
#% 1406883
#! We focus on the random generation of SAT instances that have computational properties that are similar to real-world instances. It is known that industrial instances, even with a great number of variables, can be solved by a clever solver in a reasonable amount of time. This is not possible, in general, with classical randomly generated instances. We provide different generation models of SAT instances, extending the uniform and regular 3-CNF models. They are based on the use of non-uniform probability distributions to select variables. Our last model also uses a mechanism to produce clauses of different lengths as in industrial instances. We show the existence of the phase transition phenomena for our models and we study the hardness of the generated instances as a function of the parameters of the probability distributions. We prove that, with these parameters we can adjust the difficulty of the problems in the phase transition point. We measure hardness in terms of the performance of different solvers. We show how these models will allow us to generate random instances similar to industrial instances, of interest for testing purposes.

#index 1305352
#* On solving Boolean multilevel optimization problems
#@ Josep Argelich;Inês Lynce;Joao Marques-Silva
#t 2009
#c 11
#% 132376
#% 576844
#% 637526
#% 735861
#% 897179
#% 961375
#% 1269828
#% 1270074
#% 1272026
#% 1272198
#% 1350692
#% 1396042
#% 1846124
#! Many combinatorial optimization problems entail a number of hierarchically dependent optimization problems. An often used solution is to associate a suitably large cost with each individual optimization problem, such that the solution of the resulting aggregated optimization problem solves the original set of optimization problems. This paper starts by studying the package upgradeability problem in software distributions. Straightforward solutions based on Maximum Satisfiability (MaxSAT) and pseudo-Boolean (PB) optimization are shown to be ineffective, and unlikely to scale for large problem instances. Afterwards, the package upgradeability problem is related to multilevel optimization. The paper then develops new algorithms for Boolean Multilevel Optimization (BMO) and highlights a number of potential applications. The experimental results indicate that algorithms for BMO allow solving optimization problems that existing MaxSAT and PB solvers would otherwise be unable to solve.

#index 1305353
#* Predicting learnt clauses quality in modern SAT solvers
#@ Gilles Audemard;Laurent Simon
#t 2009
#c 11
#% 336874
#% 420713
#% 427631
#% 1273681
#% 1275126
#% 1396061
#% 1413487
#% 1664973
#% 1698697
#! Beside impressive progresses made by SAT solvers over the last ten years, only few works tried to understand why Conflict Directed Clause Learning algorithms (CDCL) are so strong and efficient on most industrial applications. We report in this work a key observation of CDCL solvers behavior on this family of benchmarks and explain it by an unsuspected side effect of their particular Clause Learning scheme. This new paradigm allows us to solve an important, still open, question: How to designing a fast, static, accurate, and predictive measure of new learnt clauses pertinence. Our paper is followed by empirical evidences that show how our new learning scheme improves state-of-the art results by an order of magnitude on both SAT and UNSAT industrial problems.

#index 1305354
#* Online stochastic optimization in the large: application to kidney exchange
#@ Pranjal Awasthi;Tuomas Sandholm
#t 2009
#c 11
#% 737809
#% 765296
#% 963362
#% 1250198
#% 1270024
#% 1275046
#% 1275072
#% 1450355
#% 1699381
#% 1732435
#! Kidneys are the most prevalent organ transplants, but demand dwarfs supply. Kidney exchanges enable willing but incompatible donor-patient pairs to swap donors. These swaps can include cycles longer than two pairs as well, and chains triggered by altruistic donors. Current kidney exchanges address clearing (deciding who gets kidneys from whom) as an offline problem: they optimize the current batch. In reality, clearing is an online problem where patient-donor pairs and altruistic donors appear and expire over time. In this paper, we study trajectory-based online stochastic optimization algorithms (which use a recent scalable optimal offline solver as a subroutine) for this. We identify tradeoffs in these algorithms between different parameters. We also uncover the need to set the batch size that the algorithms consider an atomic unit. We develop an experimental methodology for setting these parameters, and conduct experiments on real and generated data. We adapt the REGRETS algorithm of Bent and van Hentenryck for the setting. We then develop a better algorithm. We also show that the AMSAA algorithm of Mercier and van Hentenryck does not scale to the nationwide level. Our best online algorithm saves significantly more lives than the current practice of solving each batch separately.

#index 1305355
#* Circuit complexity and decompositions of global constraints
#@ Christian Bessiere;George Katsirelos;Nina Narodytska;Toby Walsh
#t 2009
#c 11
#% 25998
#% 160208
#% 198885
#% 408396
#% 835213
#% 976748
#% 1223221
#% 1223531
#% 1270353
#% 1272349
#% 1289360
#% 1305356
#% 1399069
#% 1399074
#% 1399099
#% 1411194
#% 1664964
#% 1665000
#% 1665020
#% 1732424
#! We show that tools from circuit complexity can be used to study decompositions of global constraints. In particular, we study decompositions of global constraints into conjunctive normal form with the property that unit propagation on the decomposition enforces the same level of consistency as a specialized propagation algorithm. We prove that a constraint propagator has a a polynomial size decomposition if and only if it can be computed by a polynomial size monotone Boolean circuit. Lower bounds on the size of monotone Boolean circuits thus translate to lower bounds on the size of decompositions of global constraints. For instance, we prove that there is no polynomial sized decomposition of the domain consistency propagator for the ALLDIFFERENT constraint.

#index 1305356
#* Decompositions of all different, global cardinality and related constraints
#@ Christian Bessiere;George Katsirelos;Nina Narodytska;Claude-Guy Quimper;Toby Walsh
#t 2009
#c 11
#% 160208
#% 266132
#% 496276
#% 804969
#% 835213
#% 1223221
#% 1223531
#% 1270353
#% 1279247
#% 1289360
#% 1305355
#% 1399074
#% 1399096
#% 1399099
#% 1411194
#% 1499496
#% 1664964
#% 1665020
#% 1732424
#! We show that some common and important global constraints like ALL-DIFFERENT and GCC can be decomposed into simple arithmetic constraints on which we achieve bound or range consistency, and in some cases even greater pruning. These decompositions can be easily added to new solvers. They also provide other constraints with access to the state of the propagator by sharing of variables. Such sharing can be used to improve propagation between constraints. We report experiments with our decomposition in a pseudo-Boolean solver.

#index 1305357
#* Making bound consistency as effective as arc consistency
#@ Christian Bessiere;Thierry Petit;Bruno Zanuttini
#t 2009
#c 11
#% 160208
#% 189747
#% 252213
#% 266132
#% 275221
#% 317107
#% 809802
#% 911010
#% 1046048
#% 1086127
#% 1845643
#! We study under what conditions bound consistency (BC) and arc consistency (AC), two forms of propagation used in constraint solvers, are equivalent to each other. We show that they prune exactly the same values when the propagated constraint is connected row convex / closed under median and its complement is row convex. This characterization is exact for binary constraints. Since row convexity depends on the order of the values in the domains, we give polynomial algorithms for computing orders under which BC and AC are equivalent, if any.

#index 1305358
#* TBA*: time-bounded A*
#@ Yngvi Björnsson;Vadim Bulitko;Nathan Sturtevant
#t 2009
#c 11
#% 2194
#% 68238
#% 323695
#% 773293
#% 1269581
#% 1272182
#% 1272224
#% 1275135
#% 1290111
#! Real-time heuristic search algorithms are used for planning by agents in situations where a constant-bounded amount of deliberation time is required for each action regardless of the problem size. Such algorithms interleave their planning and execution to ensure real-time response. Furthermore, to guarantee completeness, they typically store improved heuristic estimates for previously expanded states. Although subsequent planning steps can benefit from updated heuristic estimates, many of the same states are expanded over and over again. Here we propose a variant of the A* algorithm, Time-Bounded A* (TBA*), that guarantees real-time response. In the domain of path-finding on videogame maps TBA* expands an order of magnitude fewer states than traditional real-time search algorithms, while finding paths of comparable quality. It reaches the same level of performance as recent state-of-the-art real-time search algorithms but, unlike these, requires neither state-space abstractions nor pre-computed pattern databases.

#index 1305359
#* Canadian traveler problem with remote sensing
#@ Zahy Bnaya;Ariel Felner;Solomon Eyal Shimony
#t 2009
#c 11
#% 101144
#% 113707
#% 121114
#% 408396
#% 578727
#% 655327
#% 1250642
#% 1269867
#% 1270242
#% 1272039
#% 1665157
#! The Canadian Traveler Problem (CTP) is a navigation problem where a graph is initially known, but some edges may be blocked with a known probability. The task is to minimize travel effort of reaching the goal. We generalize CTP to allow for remote sensing actions, now requiring minimization of the sum of the travel cost and the remote sensing cost. Finding optimal policies for both versions is intractable. We provide optimal solutions for special case graphs. We then develop a framework that utilizes heuristics to determine when and where to sense the environment in order to minimize total costs. Several such heuristics, based on the expected total cost are introduced. Empirical evaluations show the benefits of our heuristics and support some of the theoretical results.

#index 1305360
#* Experiments with massively parallel constraint solving
#@ Lucas Bordeaux;Youssef Hamadi;Horst Samulowitz
#t 2009
#c 11
#% 17890
#% 95577
#% 329487
#% 534502
#% 785485
#% 1231251
#% 1250515
#% 1272228
#! The computing industry is currently facing a major architectural shift. Extra computing power is not coming anymore from higher processor frequencies, but from a growing number of computing cores and processors. For AI, and constraint solving in particular, this raises the question of how to scale current solving techniques to massively parallel architectures. While prior work focusses mostly on small scale parallel constraint solving, we conduct the first study on scalability of constraint solving on 100 processors and beyond in this paper. We propose techniques that are simple to apply and show empirically that they scale surprisingly well. These techniques establish a performance baseline for parallel constraint solving technologies against which more sophisticated parallel algorithms need to compete in the future.

#index 1305361
#* Best-first heuristic search for multi-core machines
#@ Ethan Burns;Seth Lemons;Rong Zhou;Wheeler Ruml
#t 2009
#c 11
#% 94784
#% 192215
#% 409460
#% 567949
#% 590541
#% 873948
#% 1250226
#% 1250328
#% 1269864
#% 1272145
#! To harness modern multi-core processors, it is imperative to develop parallel versions of fundamental algorithms. In this paper, we present a general approach to best-first heuristic search in a shared-memory setting. Each thread attempts to expand the most promising open nodes. By using abstraction to partition the state space, we detect duplicate states without requiring frequent locking. We allow speculative expansions when necessary to keep threads busy. We identify and fix potential livelock conditions in our approach, verifying its correctness using temporal logic. In an empirical comparison on STRIPS planning, grid pathfinding, and sliding tile puzzle problems using an 8-core machine, we show that A* implemented in our framework yields faster search than improved versions of previous parallel search proposals. Our approach extends easily to other best-first searches, such as Anytime weighted A*.

#index 1305362
#* Nested Monte-Carlo search
#@ Tristan Cazenave
#t 2009
#c 11
#% 866837
#% 983838
#! Many problems have a huge state space and no good heuristic to order moves so as to guide the search toward the best positions. Random games can be used to score positions and evaluate their interest. Random games can also be improved using random games to choose a move to try at each step of a game. Nested Monte-Carlo Search addresses the problem of guiding the search toward better states when there is no available heuristic. It uses nested levels of random games in order to guide the search. The algorithm is studied theoretically on simple abstract problems and applied successfully to three different games: Morpion Solitaire, SameGame and 16×16 Sudoku.

#index 1305363
#* Reasoning with lines in the Euclidean space
#@ Khalil Challita
#t 2009
#c 11
#% 1145
#% 250113
#% 319244
#% 741444
#% 741459
#% 939431
#% 1272059
#% 1274836
#! The main result of this paper is to show that the problem of instantiating a finite and path-consistent constraint network of lines in the Euclidean space is NP-complete. Indeed, we already know that reasoning with lines in the Euclidean space is NP-hard. In order to prove that this problem is NP-complete, we first establish that a particular instance of this problem can be solved by a nondeterministic polynomial-time algorithm, and then we show that solving any finite and path-consistent constraint network of lines in the Euclidean space is at most as difficult as solving that instance.

#index 1305364
#* Search strategies for an anytime usage of the branch and prune algorithm
#@ Raphael Chenouard;Alexandre Goldsztejn;Christophe Jermann
#t 2009
#c 11
#% 181030
#% 225336
#% 410561
#% 1271914
#% 1399061
#! When applied to numerical CSPs, the branch and prune algorithm (BPA) computes a sharp covering of the solution set. The BPA is therefore impractical when the solution set is large, typically when it has a dimension larger than four or five which is often met in underconstrained problems. The purpose of this paper is to present a new search tree exploration strategy for BPA that hybridizes depth-first and breadth-first searches. This search strategy allows the BPA discovering potential solutions in different areas of the search space in early stages of the exploration, hence allowing an anytime usage of the BPA. The merits of the proposed search strategy are experimentally evaluated.

#index 1305365
#* Monte Carlo tree search techniques in the game of Kriegspiel
#@ Paolo Ciancarini;Gian Piero Favini
#t 2009
#c 11
#% 117886
#% 1250646
#% 1275147
#% 1289391
#% 1289395
#% 1665148
#% 1733899
#! Monte Carlo tree search has brought significant improvements to the level of computer players in games such as Go, but so far it has not been used very extensively in games of strongly imperfect information with a dynamic board and an emphasis on risk management and decision making under uncertainty. In this paper we explore its application to the game of Kriegspiel (invisible chess), providing three Monte Carlo methods of increasing strength for playing the game with little specific knowledge. We compare these Monte Carlo agents to the strongest known minimax-based Kriegspiel player, obtaining significantly better results with a considerably simpler logic and less domain-specific knowledge.

#index 1305366
#* Duplicate avoidance in depth-first search with applications to treewidth
#@ P. Alex Dow;Richard E. Korf
#t 2009
#c 11
#% 2194
#% 31482
#% 528338
#% 788060
#% 1269853
#% 1700197
#% 1916535
#! Depth-first search is effective at solving hard combinatorial problems, but if the problem space has a graph structure the same nodes may be searched many times. This can increase the size of the search exponentially. We explore two techniques that prevent this: duplicate detection and duplicate avoidance. We illustrate these techniques on the treewidth problem, a combinatorial optimization problem with applications to a variety of research areas. The bottleneck for previous treewidth algorithms is a large memory requirement. We develop a duplicate avoidance technique for treewidth and demonstrate that it significantly outperforms other algorithms when memory is limited. Additionally, we are able to find, for the first time, the treewidth of several hard benchmark graphs.

#index 1305367
#* Local search: is brute-force avoidable?
#@ Michael R. Fellows;Frances A. Rosamond;Fedor V. Fomin;Daniel Lokshtanov;Saket Saurabh;Yngve Villanger
#t 2009
#c 11
#% 5804
#% 25998
#% 44934
#% 263371
#% 268714
#% 382908
#% 448483
#% 725766
#% 749534
#% 819513
#% 840418
#% 932939
#% 1105387
#% 1827061
#% 1972413
#! Many local search algorithms are based on searching in the k-exchange neighborhood. This is the set of solutions that can be obtained from the current solution by exchanging at most k elements. As a rule of thumb, the larger k is, the better are the chances of finding an improved solution. However, for inputs of size n, a naïve brute-force search of the k-exchange neighborhood requires nO(k) time, which is not practical even for very small values of k. We show that for several classes of sparse graphs, like planar graphs, graphs of bounded vertex degree and graphs excluding some fixed graph as a minor, an improved solution in the k-exchange neighborhood for many problems can be found much more efficiently. Our algorithms run in time O(τ (k) ċ nc), where τ is a function depending on k only and c is a constant independent of k. We demonstrate the applicability of this approach on different problems like r-CENTER, VERTEX COVER, ODD CYCLE TRANSVERSAL, MAX-CUT, and MIN-BISECTION. In particular, on planar graphs, all our algorithms searching for a k- local improvement run in time O(2O(k) ċ n2), which is polynomial for k = O(log n). We also complement the algorithms with complexity results indicating that--brute force search is unavoidable--in more general classes of sparse graphs.

#index 1305368
#* Minimum proof graphs and fastest-cut-first search heuristics
#@ Timothy Furtak;Michael Buro
#t 2009
#c 11
#% 216974
#% 248775
#% 1305515
#% 1499500
#% 1665148
#! Alpha-Beta is the most common game tree search algorithm, due to its high-performance and straightforward implementation. In practice one must find the best trade-off between heuristic evaluation time and bringing the subset of nodes explored closer to a minimum proof graph. In this paper we present a series of structural properties of minimum proof graphs that help us to prove that finding such graphs is NP-hard for arbitrary DAG inputs, but can be done in linear time for trees. We then introduce the class of fastest-cut-first search heuristics that aim to approximate minimum proof graphs by sorting moves based on approximations of sub-DAG values and sizes. To explore how various aspects of the game tree (such as branching factor and distribution of move values) affect the performance of Alpha-Beta we introduce the class of "Prefix Value Game Trees" that allows us to label interior nodes with true minimax values on the fly without search. Using these trees we show that by explicitly attempting to approximate a minimum game tree we are able to achieve performance gains over Alpha-Beta with common extensions.

#index 1305369
#* Control-based clause sharing in parallel SAT solving
#@ Youssef Hamadi;Said Jabbour;Lakhdar Sais
#t 2009
#c 11
#% 45094
#% 61309
#% 220203
#% 266200
#% 327779
#% 336874
#% 657874
#% 1020605
#% 1413487
#! Conflict driven clause learning, one of the most important component of modern SAT solvers, is also recognized as very important in parallel SAT solving. Indeed, it allows clause sharing between multiple processing units working on related (sub) problems. However, without limitation, sharing clauses might lead to an exponential blow up in communication or to the sharing of irrelevant clauses. This paper, proposes two innovative policies to dynamically adjust the size of shared clauses between any pair of processing units. The first approach controls the overall number of exchanged clauses whereas the second additionally exploits the relevance quality of shared clauses. Experimental results show important improvements of the state-of the-art parallel SAT solver.

#index 1305370
#* Solving 8&times8 Hex
#@ Philip Henderson;Broderick Arneson;Ryan B. Hayward
#t 2009
#c 11
#% 348580
#% 348586
#% 866760
#% 1406890
#! Using efficient methods that reduce the search space, we design an algorithm strong enough to solve all 8×8 Hex openings.

#index 1305371
#* New improvements in optimal rectangle packing
#@ Eric Huang;Richard E. Korf
#t 2009
#c 11
#% 1411167
#! The rectangle packing problem consists of finding an enclosing rectangle of smallest area that can contain a given set of rectangles without overlap. Our algorithm picks the x-coordinates of all the rectangles before picking any of the y-coordinates. For the x-coordinates, we present a dynamic variable ordering heuristic and an adaptation of a pruning algorithm used in previous solvers. We then transform the rectangle packing problem into a perfect packing problem that has no empty space, and present inference rules to reduce the instance size. For the y-coordinates we search a space that models empty positions as variables and rectangles as values. Our solver is over 19 times faster than the previous state-of-the-art on the largest problem solved to date, allowing us to extend the known solutions for a consecutive-square packing benchmark from N=27 to N=32.

#index 1305372
#* SATenstein: automatically building local search SAT solvers from components
#@ Ashiqur R. KhudaBukhsh;Lin Xu;Holger H. Hoos;Kevin Leyton-Brown
#t 2009
#c 11
#% 160270
#% 283230
#% 329487
#% 535307
#% 578751
#% 578753
#% 743415
#% 846606
#% 945273
#% 1029063
#% 1250149
#% 1269854
#% 1272228
#% 1396048
#% 1398387
#% 1478764
#% 1478779
#% 1698697
#% 1698704
#% 1698707
#! Designing high-performance algorithms for computationally hard problems is a difficult and often time-consuming task. In this work, we demonstrate that this task can be automated in the context of stochastic local search (SLS) solvers for the propositional satisfiability problem (SAT). We first introduce a generalised, highly parameterised solver framework, dubbed SATenstein, that includes components gleaned from or inspired by existing high-performance SLS algorithms for SAT. The parameters of SATenstein control the selection of components used in any specific instantiation and the behaviour of these components. SATenstein can be configured to instantiate a broad range of existing high-performance SLS-based SAT solvers, and also billions of novel algorithms. We used an automated algorithm configuration procedure to find instantiations of SATenstein that perform well on several well-known, challenging distributions of SAT instances. Overall, we consistently obtained significant improvements over the previously best-performing SLS algorithms, despite expending minimal manual effort.

#index 1305373
#* Exploiting decomposition on constraint problems with high tree-width
#@ Matthew Kitching;Fahiem Bacchus
#t 2009
#c 11
#% 329486
#% 419942
#% 419954
#% 448887
#% 1250510
#% 1271902
#% 1272266
#% 1274762
#% 1274770
#% 1279246
#% 1289386
#! Decomposition is an effective technique for solving discrete Constraint Optimization Problems (COPs) with low tree-width. On problems with high tree-width, however, existing decomposition algorithms offer little advantage over branch and bound search (B&B). In this paper we propose a method for exploiting decomposition on problems with high treewidth. Our technique involves modifying B&B to detect and exploit decomposition on a selected subset of the problem's objectives. Decompositions over this subset, generated during search, are exploited to compute tighter bounds allowing B&B to prune more of its search space. We present a heuristic for selecting an appropriate subset of objectives--one that readily decomposes during search and yet can still provide good bounds. We demonstrate empirically that our approach can significantly improve B&B's performance and outperform standard decomposition algorithms on a variety of high tree-width problems.

#index 1305374
#* Set branching in constraint optimization
#@ Matthew Kitching;Fahiem Bacchus
#t 2009
#c 11
#% 419942
#% 534480
#% 1058686
#% 1270059
#% 1279246
#! Branch and bound is an effective technique for solving constraint optimization problems (COP's). However, its search space expands very rapidly as the domain sizes of the problem variables grow. In this paper, we present an algorithm that clusters the values of a variable's domain into sets. Branch and bound can then branch on these sets of values rather than on individual values, thereby reducing the branching factor of its search space. The aim of our clustering algorithm is to construct a collection of sets such that branching on these sets will still allow effective bounding. In conjunction with the reduced branching factor, the size of the explored search space is thus significantly reduced. We test our method and show empirically that it can yield significant performance gains over existing state-of-the-art techniques.

#index 1305375
#* Multi-way number partitioning
#@ Richard E. Korf
#t 2009
#c 11
#% 267769
#% 408396
#% 674446
#% 1275261
#! The number partitioning problem is to divide a given set of integers into a collection of subsets, so that the sum of the numbers in each subset are as nearly equal as possible. While a very efficient algorithm exists for optimal two-way partitioning, it is not nearly as effective for multi-way partitioning. We develop two new linear-space algorithms for multi-way partitioning, and demonstrate their performance on three, four, and five-way partitioning. In each case, our algorithms outperform the previous state of the art by orders of magnitude, in one case by over six orders of magnitude. Empirical analysis of the running times of our algorithms strongly suggest that their asymptotic growth is less than that of previous algorithms. The key insight behind both our new algorithms is that if an optimal k-way partition includes a particular subset, then optimally partitioning the numbers not in that set k-1 ways results in an optimal k-way partition.

#index 1305376
#* Integrating systematic and local search paradigms: a new strategy for MaxSAT
#@ Lukas Kroc;Ashish Sabharwal;Carla P. Gomes;Bart Selman
#t 2009
#c 11
#% 288165
#% 327779
#% 417606
#% 535307
#% 750050
#% 787562
#% 1209770
#% 1272189
#% 1275123
#% 1389682
#% 1396047
#% 1396048
#% 1399081
#% 1413505
#! Systematic search and local search paradigms for combinatorial problems are generally believed to have complementary strengths. Nevertheless, attempts to combine the power of the two paradigms have had limited success, due in part to the expensive information communication overhead involved. We propose a hybrid strategy based on shared memory, ideally suited for multi-core processor architectures. This method enables continuous information exchange between two solvers without slowing down either of the two. Such a hybrid search strategy is surprisingly effective, leading to substantially better quality solutions to many challenging Maximum Satisfiability (MaxSAT) instances than what the current best exact or heuristic methods yield, and it often achieves this within seconds. This hybrid approach is naturally best suited to MaxSAT instances for which proving unsatisfiability is already hard; otherwise the method falls back to pure local search.

#index 1305377
#* Variety reasoning for multiset constraint propagation
#@ Y. C. Law;J. H. M. Lee;M. H. C. Woo
#t 2009
#c 11
#% 976748
#% 1272073
#! Set variables in constraint satisfaction problems (CSPs) are typically propagated by enforcing set bounds consistency together with cardinality reasoning, which uses some inference rules involving the cardinality of a set variable to produce more prunings than set bounds propagation alone. Multiset variables are a generalization of set variables by allowing the elements to have repetitions. In this paper, we generalize cardinality reasoning for multiset variables. In addition, we propose to exploit the variety of a multiset--the number of distinct elements in it--to improve modeling expressiveness and further enhance constraint propagation. We derive a number of inference rules involving the varieties of multiset variables. The rules interact varieties with the traditional components of multiset variables (such as cardinalities) to obtain stronger propagation. We also demonstrate how to apply the rules to perform variety reasoning on some common multiset constraints. Experimental results show that performing variety reasoning on top of cardinality reasoning can effectively reduce more search space and achieve better runtime in solving multiset CSPs

#index 1305378
#* Towards efficient consistency enforcement for global constraints in weighted constraint satisfaction
#@ J. H. M. Lee;K. L. Leung
#t 2009
#c 11
#% 122671
#% 420010
#% 568145
#% 751442
#% 789556
#% 866428
#% 874125
#% 1058686
#% 1275309
#% 1279246
#! Powerful consistency techniques, such as AC* and FDAC*, have been developed for Weighted Constraint Satisfaction Problems (WCSPs) to reduce the space in solution search, but are restricted to only unary and binary constraints. On the other hand, van Hoeve et al. developed efficient graph-based algorithms for handling soft constraints as classical constraint optimization problems. We prove that naively incorporating van Hoeve's method into the WCSP framework can enforce a strong form of Ø-Inverse Consistency, which can prune infeasible values and deduce good lower bound estimates. We further show how Van Hoeve's method can be modified so as to handle cost projection and extension to maintain the stronger AC* and FDAC* generalized for non-binary constraints. Using the soft allDifferent constraint as a testbed, preliminary results demonstrate that our proposal gives improvements up to an order of magnitude both in terms of time and pruning.

#index 1305379
#* A soft global precedence constraint
#@ David Lesaint;Deepak Mehta;Barry O'Sullivan;Luis Quesada;Nic Wilson
#t 2009
#c 11
#% 408396
#% 875483
#% 928731
#% 1145166
#! Hard and soft precedence constraints play a key role in many application domains. In telecommunications, one application is the configuration of callcontrol feature subscriptions where the task is to sequence a set of user-selected features subject to a set of hard (catalogue) precedence constraints and a set of soft (user-selected) precedence constraints. When no such consistent sequence exists, the task is to find an optimal relaxation by discarding some features or user precedences. For this purpose, we present the global constraint SOFTPREC. Enforcing Generalized Arc Consistency (GAC) on SOFTPREC is NP-complete. Therefore, we approximate GAC based on domain pruning rules that follow from the semantics of SOFTPREC; this pruning is polynomial. Empirical results demonstrate that the search effort required by SOFTPREC is up to one order of magnitude less than the previously known best CP approach for the feature subscription problem. SOFTPREC is also applicable to other problem domains including minimum cutset problems for which initial experiments confirm the interest.

#index 1305380
#* A divide-and-conquer approach for solving interval algebra networks
#@ Jason Jingshi Li;Jinbo Huang;Jochen Renz
#t 2009
#c 11
#% 84513
#% 121993
#% 181229
#% 319244
#% 1090848
#% 1223539
#% 1399115
#! Deciding consistency of constraint networks is a fundamental problem in qualitative spatial and temporal reasoning. In this paper we introduce a divide-and-conquer method that recursively partitions a given problem into smaller sub-problems in deciding consistency. We identify a key theoretical property of a qualitative calculus that ensures the soundness and completeness of this method, and show that it is satisfied by the Interval Algebra (IA) and the Point Algebra (PA). We develop a new encoding scheme for IA networks based on a combination of our divide-and-conquer method with an existing encoding of IA networks into SAT. We empirically show that our new encoding scheme scales to much larger problems and exhibits a consistent and significant improvement in efficiency over state-of-the-art solvers on the most difficult instances.

#index 1305381
#* Open contractible global constraints
#@ Michael J. Maher
#t 2009
#c 11
#% 70370
#% 160208
#% 464907
#% 535153
#% 644201
#% 855914
#% 928731
#% 1223531
#% 1399074
#% 1499496
#% 1664994
#% 1665020
#% 1728036
#% 1732437
#! Open forms of global constraints allow the addition of new variables to an argument during the execution of a constraint program. Such forms are needed for difficult constraint programming problems where problem construction and problem solving are interleaved. However, in general, filtering that is sound for a global constraint can be unsound when the constraint is open. This paper provides a simple characterization, called contractibility, of the constraints where filtering remains sound when the constraint is open. With this characterization we can easily determine whether a constraint is contractible or not. In the latter case, we can use it to derive the strongest contractible approximation to the constraint. We demonstrate how specific algorithms for some closed contractible constraints are easily adapted to open constraints.

#index 1305382
#* Evaluating strategies for running from the cops
#@ Carsten Moldenhauer;Nathan R. Sturtevant
#t 2009
#c 11
#% 443874
#% 1024864
#% 1215714
#% 1269581
#! Moving target search (MTS) or the game of cops and robbers has a broad field of application reaching from law enforcement to computer games. Within the recent years research has focused on computing move policies for one or multiple pursuers (cops). The present work motivates to extend this perspective to both sides, thus developing algorithms for the target (robber). We investigate the game with perfect information for both players and propose two new methods, named TrailMax and Dynamic Abstract Trailmax, to compute move policies for the target. Experiments are conducted by simulating games on 20 maps of the commercial computer game Baldur's Gate and measuring survival time and computational complexity. We test seven algorithms: Cover, Dynamic Abstract Minimax, minimax, hill climbing with distance heuristic, a random beacon algorithm, TrailMax and DATrailMax. Analysis shows that our methods outperform all the other algorithms in quality, achieving up to 98% optimality, while meeting modern computer game computation time constraints.

#index 1305383
#* A new d-DNNF-based bound computation algorithm for functional E-MAJSAT
#@ Knot Pipatsrisawat;Adnan Darwiche
#t 2009
#c 11
#% 194652
#% 283232
#% 327779
#% 420743
#% 527988
#% 696997
#% 1250337
#% 1272025
#% 1272331
#% 1272349
#% 1650391
#% 1650778
#% 1673033
#! We present a new algorithm for computing upper bounds for an optimization version of the EMAJSAT problem called functional E-MAJSAT. The algorithm utilizes the compilation language d-DNNF which underlies several state-of-the-art algorithms for solving related problems. This bound computation can be used in a branch-and-bound solver for solving functional E-MAJSAT. We then present a technique for pruning values from the branch-and-bound search tree based on the information available after each bound computation. We evaluated the proposed techniques in a MAP solver and a probabilistic conformant planner. In both cases, our experiments showed that the new techniques improved the efficiency of state-of-the-art solvers by orders of magnitude.

#index 1305384
#* A structural approach to reasoning with quantified Boolean formulas
#@ Luca Pulina;Armando Tacchella
#t 2009
#c 11
#% 183640
#% 219474
#% 266109
#% 331899
#% 420720
#% 717227
#% 856497
#% 888016
#% 1272117
#% 1289374
#% 1675277
#% 1698697
#% 1718503
#% 1720783
#% 1728050
#! In this paper we approach the problem of reasoning with quantified Boolean formulas (QBFs) by combining search and resolution, and by switching between them according to structural properties of QBFs. We provide empirical evidence that QBFs which cannot be solved by search or resolution alone, can be solved by combining them, and that our approach makes a proof-of-concept implementation competitive with current QBF solvers.

#index 1305385
#* Russian Doll search with tree decomposition
#@ M. Sanchez;D. Allouche;S. De Givry;T. Schiex
#t 2009
#c 11
#% 329486
#% 419942
#% 581814
#% 751442
#% 789556
#% 906041
#% 1058686
#% 1223214
#% 1250346
#% 1250510
#% 1275309
#% 1289364
#% 1399084
#% 1499492
#! Optimization in graphical models is an important problem which has been studied in many AI frameworks such as weighted CSP, maximum satisfiability or probabilistic networks. By identifying conditionally independent subproblems, which are solved independently and whose optimum is cached, recent Branch and Bound algorithms offer better asymptotic time complexity. But the locality of bounds induced by decomposition often hampers the practical effects of this result because subproblems are often uselessly solved to optimality. Following the Russian Doll Search (RDS) algorithm, a possible approach to overcome this weakness is to (inductively) solve a relaxation of each subproblem to strengthen bounds. The algorithm obtained generalizes both RDS and tree-decomposition based algorithms such as BTD or AND-OR Branch and Bound. We study its efficiency on different problems, closing a very hard frequency assignment instance which has been open for more than 10 years.

#index 1305386
#* Memory-based heuristics for explicit state spaces
#@ Nathan R. Sturtevant;Ariel Felner;Max Barrer;Jonathan Schaeffer;Neil Burch
#t 2009
#c 11
#% 939032
#% 1269581
#% 1270073
#% 1272186
#% 1272224
#% 1289367
#! In many scenarios, quickly solving a relatively small search problem with an arbitrary start and arbitrary goal state is important (e.g., GPS navigation). In order to speed this process, we introduce a new class of memory-based heuristics, called true distance heuristics, that store true distances between some pairs of states in the original state space can be used for a heuristic between any pair of states. We provide a number of techniques for using and improving true distance heuristics such that most of the benefits of the all-pairs shortest-path computation can be gained with less than 1% of the memory. Experimental results on a number of domains show a 6- 14 fold improvement in search speed compared to traditional heuristics.

#index 1305387
#* Efficient incremental search for moving target search
#@ Xiaoxun Sun;William Yeoh;Sven Koenig
#t 2009
#c 11
#% 241
#% 443547
#% 772056
#% 1024864
#% 1084068
#% 1272096
#% 1290111
#% 1768675
#! Incremental search algorithms reuse information from previous searches to speed up the current search and are thus often able to find shortest paths for series of similar search problems faster than by solving each search problem independently from scratch. However, they do poorly on moving target search problems, where both the start and goal cells change over time. In this paper, we thus develop Fringe-Retrieving A* (FRA*), an incremental version of A* that repeatedly finds shortest paths for moving target search in known gridworlds. We demonstrate experimentally that it runs up to one order of magnitude faster than a variety of state-of-the-art incremental search algorithms applied to moving target search in known gridworlds.

#index 1305388
#* Solving dynamic constraint satisfaction problems by identifying stable features
#@ Richard J. Wallace;Diarmuid Grimes;Eugene C. Freuder
#t 2009
#c 11
#% 126390
#% 160248
#% 419990
#% 816232
#! This paper presents a new analysis of dynamic constraint satisfaction problems (DCSPs) with finite domans and a new approach to solving them. We first show that even very small changes in a CSP, in the form of addition of constraints or changes in constraint relations, can have profound effects on search performance. These effects are reflected in the amenability of the problem to different forms of heuristic action as well as overall quality of search. In addition, classical DCSP methods perform poorly on these problems because there are sometimes no solutions similar to the original one found. We then show that the same changes do not markedly affect the locations of the major sources of contention in the problem. A technique for iterated sampling that performs a careful assessment of this property and uses the information during subsequent search, performs well even when it only uses information based on the original problem in the DCSP sequence. The result is a new approach to solving DCSPs that is based on a robust strategy for ordering variables rather than on robust solutions.

#index 1305389
#* Qualitative CSP, finite CSP, and SAT: comparing methods for qualitative constraint-based reasoning
#@ Matthias Westphal;Stefan Wölfl
#t 2009
#c 11
#% 319244
#% 417552
#% 1223214
#% 1272384
#% 1399115
#% 1499522
#% 1664968
#% 1664987
#! Qualitative Spatial and Temporal Reasoning (QSR) is concerned with constraint-based formalisms for representing, and reasoning with, spatial and temporal information over infinite domains. Within the QSR community it has been a widely accepted assumption that genuine qualitative reasoning methods outperform other reasoning methods that are applicable to encodings of qualitative CSP instances. Recently this assumption has been tackled by several authors, who proposed to encode qualitative CSP instances as finite CSP or SAT instances. In this paper we report on the results of a broad empirical study in which we compared the performance of several reasoners on instances from different qualitative formalisms. Our results show that for small-sized qualitative calculi (e.g., Allen's interval algebra and RCC-8) a state-of-theart implementation of QSR methods currently gives the most efficient performance. However, on recently suggested large-size calculi, e.g., OPRA4, finite CSP encodings provide a considerable performance gain. These results confirm a conjecture by Bessière stating that support-based constraint propagation algorithms provide better performance for large-sized qualitative calculi.

#index 1305390
#* A* search with inconsistent heuristics
#@ Zhifu Zhang;Nathan R. Sturtevant;Robert Holte;Jonathan Schaeffer;Ariel Felner
#t 2009
#c 11
#% 208
#% 241
#% 289395
#% 802590
#% 1269863
#% 1289367
#% 1305386
#! Early research in heuristic search discovered that using inconsistent heuristics with A* could result in an exponential increase in the number of node expansions. As a result, the use of inconsistent heuristics has largely disappeared from practice. Recently, inconsistent heuristics have been shown to be effective in IDA*, especially when applying the bidirectional pathmax (BPMX) enhancement. This paper presents new worst-case complexity analysis of A*'s behavior with inconsistent heuristics, discusses how BPMX can be used with A*, and gives experimental results justifying the use of inconsistent heuristics in A* searches.

#index 1305391
#* Combining breadth-first and depth-first strategies in searching for treewidth
#@ Rong Zhou;Eric A. Hansen
#t 2009
#c 11
#% 31482
#% 289947
#% 329486
#% 728026
#% 788060
#% 829310
#% 873948
#% 985940
#% 1250226
#% 1269853
#! Breadth-first and depth-first search are basic search strategies upon which many other search algorithms are built. In this paper, we describe an approach to integrating these two strategies in a single algorithm that combines the complementary strengths of both. We show the benefits of this approach using the treewidth problem as an example.

#index 1305392
#* Mixing search strategies for multi-player games
#@ Inon Zuckerman;Ariel Felner;Sarit Kraus
#t 2009
#c 11
#% 101439
#% 529676
#% 1271963
#% 1733906
#! There are two basic approaches to generalize the propagation mechanism of the two-player Minimax search algorithm to multi-player (3 or more) games: the MaxN algorithm and the Paranoid algorithm. The main shortcoming of these approaches is that their strategy is fixed. In this paper we suggest a new approach (called MP-Mix) that dynamically changes the propagation strategy based on the players' relative strengths between MaxN, Paranoid and a newly presented offensive strategy. In addition, we introduce the Opponent Impact factor for multi-player games, which measures the players' ability to impact their opponents' score, and show its relation to the relative performance of our new MP-Mix strategy. Experimental results show that MP-Mix outperforms all other approaches under most circumstances.

#index 1305393
#* A new bayesian approach to multiple intermittent fault diagnosis
#@ Rui Abreu;Peter Zoeteweij;Arjan J. C. Van Gemund
#t 2009
#c 11
#% 21138
#% 132173
#% 840516
#% 979225
#% 1009872
#% 1083577
#% 1270233
#% 1270296
#% 1289949
#! Logic reasoning approaches to fault diagnosis account for the fact that a component cj may fail intermittently by introducing a parameter gj that expresses the probability the component exhibits correct behavior. This component parameter gj, in conjunction with a priori fault probability, is used in a Bayesian framework to compute the posterior fault candidate probabilities. Usually, information on gj is not known a priori. While proper estimation of gj can have a great impact on the diagnostic accuracy, at present, only approximations have been proposed. We present a novel framework, BARINEL, that computes exact estimations of gj as integral part of the posterior candidate probability computation. BARINEL's diagnostic performance is evaluated for both synthetic and real software systems. Our results show that our approach is superior to approaches based on classical persistent fault models as well as previously proposed intermittent fault models.

#index 1305394
#* A logic for coalitions with bounded resources
#@ Natasha Alechina;Brian Logan;Nguyen Hoang Nga;Abdur Rakib
#t 2009
#c 11
#% 413871
#% 781217
#% 879715
#% 1083954
#% 1269672
#! Recent work on Alternating-Time Temporal Logic and Coalition Logic has allowed the expression of many interesting properties of coalitions and strategies. However there is no natural way of expressing resource requirements in these logics. This paper presents a Resource-Bounded Coalition Logic (RBCL) which has explicit representation of resource bounds in the language, and gives a complete and sound axiomatisation of RBCL.

#index 1305395
#* Repairing preference-based argumentation frameworks
#@ Leila Amgoud;Srdjan Vesic
#t 2009
#c 11
#% 116292
#% 198464
#% 417812
#% 431089
#% 470198
#% 992251
#% 1060767
#% 1168543
#% 1193569
#! Argumentation is a reasoning model based on the construction and evaluation of arguments. Dung has proposed an abstract argumentation framework in which arguments are assumed to have the same strength. This assumption is unfortunately not realistic. Consequently, three main extensions of the framework have been proposed in the literature. The basic idea is that if an argument is stronger than its attacker, the attack fails. The aim of the paper is twofold: First, it shows that the three extensions of Dung framework may lead to unintended results. Second, it proposes a new approach that takes into account the strengths of arguments, and that ensures sound results. We start by presenting two minimal requirements that any preference-based argumentation framework should satisfy, namely the conflict-freeness of arguments extensions and the generalization of Dung's framework. Inspired from works on handling inconsistency in knowledge bases, the proposed approach defines a binary relation on the powerset of arguments. The maximal elements of this relation represent the extensions of the new framework.

#index 1305396
#* Which semantics for neighbourhood semantics?
#@ Carlos Areces;Diego Figueira
#t 2009
#c 11
#% 67901
#% 188086
#% 338753
#% 782395
#! In this article we discuss two alternative proposals for neighbourhood semantics (which we call strict and loose neighbourhood semantics, N= and N⊆ respectively) that have been previously introduced in the literature. Our main tools are suitable notions of bisimulation. While an elegant notion of bisimulation exists for N⊆, the required bisimulation for N= is rather involved. We propose a simple extension of N= with a universal modality that we call N=(E), which comes together with a natural notion of bisimulation. We also investigate the complexity of the satisfiability problem for N⊆ and N=(E).

#index 1305397
#* Extending decidable cases for rules with existential variables
#@ Jean-François Baget;Michel Leclère;Marie-Laure Mugnier;Êric Salvat
#t 2009
#c 11
#% 2298
#% 384978
#% 465053
#% 465057
#% 465511
#% 893166
#% 935898
#% 992962
#% 1063724
#% 1271976
#! In ∀∃-rules, the conclusion may contain existentially quantified variables, which makes reasoning tasks (as deduction) non-decidable. These rules have the same logical form as TGD (tuple-generating dependencies) in databases and as conceptual graph rules. We extend known decidable cases by combining backward and forward chaining schemes, in association with a graph that captures exactly the notion of dependency between rules. Finally, we draw a map of known decidable cases, including an extension obtained by combining our approach with very recent results on TGD.

#index 1305398
#* Computational properties of resolution-based grounded semantics
#@ Pietro Baroni;Paul E. Dunne;Massimiliano Giacomin
#t 2009
#c 11
#% 198464
#% 217007
#% 428343
#% 867893
#% 992251
#% 1222427
#! In the context of Dung's theory of abstract argumentation frameworks, the recently introduced resolution-based grounded semantics features the unique property of fully complying with a set of general requirements, only partially satisfied by previous literature proposals. This paper contributes to the investigation of resolution-based grounded semantics by analyzing its computational properties with reference to a standard set of decision problems for abstract argumentation semantics: (a) checking the property of being an extension for a set of arguments; (b) checking agreement with traditional grounded semantics; (c) checking the existence of a non-empty extension; (d) checking credulous acceptance of an argument; (e) checking skeptical acceptance of an argument. It is shown that problems (a)-(c) admit polynomial time decision processes, while (d) is NP-complete and (e) coNP-complete.

#index 1305399
#* An argumentation-based interpreter for Golog programs
#@ Michelle L. Blom;Adrian R. Pearce
#t 2009
#c 11
#% 314845
#% 529345
#% 904771
#% 1041670
#% 1696326
#! This paper presents an argumentation-based interpreter for Golog programs. Traditional Golog interpreters are not designed to find the most preferred executions of a program from the perspective of an agent. Existing techniques developed to discover these executions are limited in terms of how the preferences of an agent can be expressed, and the variety of preference types that can be used to guide search for a solution. The presented work combines the use of argumentation to compare executions relative to a set of general comparison principles, and the theory behind best first search to reduce the cost of the search process. To the best of our knowledge this is the first work to integrate argumentation and the interpretation of Golog programs, and to use argumentation as a tool for best first search.

#index 1305400
#* Defeasible inclusions in low-complexity DLs: preliminary notes
#@ P. A. Bonatti;M. Faella;L. Sauro
#t 2009
#c 11
#% 107262
#% 251786
#% 344506
#% 613819
#% 719465
#% 778645
#% 960435
#% 1269453
#% 1273694
#% 1289408
#! We analyze the complexity of reasoning with circumscribed low-complexity DLs such as DL-lite and the EL family, under suitable restrictions on the use of abnormality predicates. We prove that in circumscribed DL-liteR complexity drops from NExpNP to the second level of the polynomial hierarchy. In EL, reasoning remains ExpTime-hard, in general. However, by restricting the possible occurrences of existential restrictions, we obtain membership in Σ2p and Π2p for an extension of EL.

#index 1305401
#* Next steps in propositional horn contraction
#@ Richard Booth;Thomas Meyer;Ivan José Varzinczak
#t 2009
#c 11
#% 131559
#% 307262
#% 351545
#% 1270093
#% 1279259
#% 1279264
#! Standard belief contraction assumes an underlying logic containing full classical propositional logic, but there are good reasons for considering contraction in less expressive logics. In this paper we focus on Horn logic. In addition to being of interest in its own right, our choice is motivated by the use of Horn logic in several areas, including ontology reasoning in description logics. We consider three versions of contraction: entailment-based and inconsistency-based contraction (e-contraction and i-contraction, resp.), introduced by Delgrande for Horn logic, and package contraction (p-contraction), studied by Fuhrmann and Hansson for the classical case. We show that the standard basic form of contraction, partial meet, is too strong in the Horn case. We define more appropriate notions of basic contraction for all three types above, and provide associated representation results in terms of postulates. Our results stand in contrast to Delgrande's conjectures that orderly maxichoice is the appropriate contraction for both e- and i-contraction. Our interest in p-contraction stems from its relationship with an important reasoning task in ontological reasoning: repairing the subsumption hierarchy in EL. This is closely related to p-contraction with sets of basic Horn clauses (Horn clauses of the form p → q). We show that this restricted version of p-contraction can also be represented as i-contraction.

#index 1305402
#* Euclidean and mereological qualitative spaces: a study of SCC and DCC
#@ Stefano Borgo
#t 2009
#c 11
#% 424578
#% 549078
#% 1386447
#! We determine the implicit assumptions and the structure of the Single and Double Cross Calculi within Euclidean geometry, and use these results to guide the construction of analogous calculi in mereogeometry. The systems thus obtained have strong semantic and deductive similarities with the Euclidean-based Cross Calculi although they rely on a different geometry. This fact suggests that putting too much emphasis on usual classification of qualitative spaces may hide important commonalities among spaces living in different classes.

#index 1305403
#* Regular path queries in expressive description logics with nominals
#@ Diego Calvanese;Thomas Eiter;Magdalena Ortiz
#t 2009
#c 11
#% 561701
#% 665856
#% 1072656
#% 1136066
#% 1269731
#% 1271815
#! Reasoning over complex queries in the DLs underlying OWL 2 is of importance in several application domains. We provide decidability and (tight) upper bounds for the problem of checking entailment and containment of positive regular path queries under various combinations of constructs used in such expressive DLs; specifically: regular expressions and (safe) Booleans over roles, and allowing for the combination of any two constructs among inverse roles, qualified number restrictions, and nominals. Our results carry over also to the DLs of the SR family, and thus have a direct impact on OWL 2.

#index 1305404
#* A symmetry reduction technique for model checking temporal-epistemic logic
#@ Mika Cohen;Mads Dam;Alessio Lomuscio;Hongyang Qu
#t 2009
#c 11
#% 46786
#% 167468
#% 188086
#% 212400
#% 212402
#% 379079
#% 543514
#% 555219
#% 643130
#% 659831
#% 766972
#% 947931
#% 982397
#% 1215628
#! We introduce a symmetry reduction technique for model checking temporal-epistemic properties of multi-agent systems defined in the mainstream interpreted systems framework. The technique, based on counterpart semantics, aims to reduce the set of initial states that need to be considered in a model. We present theoretical results establishing that there are neither false positives nor false negatives in the reduced model. We evaluate the technique by presenting the results of an implementation tested against two well known applications of epistemic logic, the muddy children and the dining cryptographers. The experimental results obtained confirm that the reduction in model checking time can be dramatic, thereby allowing for the verification of hitherto intractable systems.

#index 1305405
#* Import-by-query: ontology reasoning under access limitations
#@ Bernardo Cuenca Grau;Boris Motik;Yevgeny Kazakov
#t 2009
#c 11
#% 378409
#% 665856
#% 822575
#% 992962
#% 1271965
#% 1272206
#% 1274824
#% 1289408
#% 1289425
#! To enable ontology reuse, the Web Ontology Language (OWL) allows an ontology κv to import an ontology κh. To reason with such a κv, a reasoner needs physical access to the axioms of κh. For copyright and/or privacy reasons, however, the authors of κh might not want to publish the axioms of κh; instead, they might prefer to provide an oracle that can answer a (limited) set of queries over κh, thus allowing κv to import κh "by query." In this paper, we study import-by-query algorithms, which can answer questions about κv ∪ κh by accessing only κv and the oracle. We show that no such algorithm exists in general, and present restrictions under which importing by query becomes feasible.

#index 1305406
#* Diagnosing multiple persistent and intermittent faults
#@ Johan De Kleer
#t 2009
#c 11
#% 21138
#% 132173
#% 546669
#% 741452
#% 1013030
#! Almost all approaches to model-based diagnosis presume that the system being diagnosed behaves non-intermittently and analyze behavior over a small number (often only one) of time instants. In this paper we show how existing approaches to model-based diagnosis can be extended to diagnose intermittent failures as they manifest themselves over time. In addition, we show where to insert probe points to best distinguish among the intermittent faults those that best explain the symptoms and isolate the fault in minimum expected cost.

#index 1305407
#* A tableaux-based method for computing least common subsumers for expressive description logics
#@ Francesco M. Donini;Simona Colucci;Tommaso Di Noia;Eugenio Di Sciascio
#t 2009
#c 11
#% 328312
#% 496103
#% 539635
#% 564919
#% 800007
#% 935898
#% 1130889
#! Least Common Subsumers (LCS) have been proposed in Description Logics (DL) to capture the commonalities between two or more concepts. Since its introduction in 1992, LCS have been successfully employed as a logical tool for a variety of applications, spanning from inductive learning, to bottom-up construction of knowledge bases, information retrieval, to name a few. The best known algorithm for computing LCS uses structural comparison on normal forms, and the most expressive DL it is applied to is ALEN. We provide a general tableau-based calculus for computing LCS, via substitutions on concept terms containing concept variables. We show the applicability of our method to an expressive DL (but without disjunction and full negation), discuss complexity issues, and show the generality of our proposal.

#index 1305408
#* A unified framework for representation and development of dialectical proof procedures in argumentation
#@ P. M. Dung;P. M. Thang
#t 2009
#c 11
#% 198464
#% 231742
#% 290540
#% 733126
#% 873958
#% 908926
#% 992250
#% 1221648
#% 1274852
#! We present an unified methodology for representation and development of dialectical proof procedures in abstract argumentation based on the notions of legal environments and dispute derivations. A legal environment specifies the legal moves of the dispute parties while a dispute derivation describes the procedure structure. A key insight of this paper is that the opponent moves determine the soundness of a dispute while the completeness of a dispute procedure depends on the proponent moves.

#index 1305409
#* Decomposition of declarative knowledge bases with external functions
#@ Thomas Eiter;Michael Fink;Thomas Krennwallner
#t 2009
#c 11
#% 171033
#% 384978
#% 389834
#% 852150
#% 1065897
#% 1667778
#! We present a method to decompose a declarative knowledge base, given by a logic program under Answer Set Semantics with access to external sources. It overcomes the ineffectiveness of current methods due to a lack of structural information about these sources, viewed as black boxes, by exploiting independency information in accesses to them. To this end, we develop a generic notion of domain independence that allows to restrict the evaluation domain and, as a consequence, to prune unnecessary dependency assumptions between atoms. This leads to increased decomposability; we demonstrate this by an evaluation method for HEX-programs based on program rewriting, which may yield large performance gains. While developed for a particular formalism, the notions and ideas of this paper might be adapted to related formalisms as well.

#index 1305410
#* Query answering in description logics with transitive roles
#@ Thomas Eiter;Carsten Lutz;Magdalena Ortiz;Mantas Šimkus
#t 2009
#c 11
#% 289287
#% 1068400
#% 1072656
#% 1269731
#% 1270099
#% 1272202
#! We study the computational complexity of conjunctive query answering w.r.t. ontologies formulated in fragments of the description logic SHIQ. Our main result is the identification of two new sources of complexity: the combination of transitive roles and role hierarchies which results in 2-EXPTIME-hardness, and transitive roles alone which result in CO-NEXPTIME-hardness. These bounds complement the existing result that inverse roles make query answering in SHIQ 2-EXPTIME-hard. We also show that conjunctive query answering with transitive roles, but without inverse roles and role hierarchies, remains in EXPTIME if the ABox is tree-shaped.

#index 1305411
#* Bidirectional answer set programs with function symbols
#@ Thomas Eiter;Mantas Šimkus
#t 2009
#c 11
#% 53383
#% 101943
#% 135873
#% 411814
#% 494344
#% 763752
#% 1404453
#% 1405533
#! Current Answer Set Programming (ASP) solvers largely build on logic programming without function symbols. This limitation makes ASP decidable, but greatly complicates the modeling of indefinite time, recursive data structures (e.g., lists), and infinite processes and objects in general. Recent research thus aims at finding decidable fragments of ASP with function symbols and studying their complexity. We identify bidirectional ASP programs as an expressive such fragment that is useful, e.g., for reasoning about actions involving both the future and the past. We tightly characterize the computational complexity of bidirectional programs and of some of their subclasses, addressing the main reasoning tasks. Our results also imply that the recently introduced FDNC programs can be extended by inverse predicates while retaining decidability, but computational costs are unavoidably higher.

#index 1305412
#* Knowledge compilation properties of trees-of-BDDs, revisited
#@ Hélène Fargier;Pierre Marquis
#t 2009
#c 11
#% 204396
#% 342378
#% 936786
#% 1223442
#% 1250513
#% 1269749
#% 1270089
#% 1270101
#% 1272349
#% 1275338
#! Recent results have shown the interest of trees-of-BDDs [Subbarayan et al., 2007] as a suitable target language for propositional knowledge compilation from the practical side. In the present paper, the concept of tree-of-BDDs is extended to additional classes of data structures C thus leading to trees-of-C representations (ToC). We provide a number of generic results enabling one to determine the queries/transformations satisfied by ToC depending on those satisfied by C. We also present some results about the spatial efficiency of the ToC languages. Focusing on the ToOBDD language (and other related languages), we address a number of issues that remained open in [Subbarayan et al., 2007]. We show that beyond CO and VA, the ToOBDD fragment satisfies IM and ME but satisfies neither CD nor any query among CE, SE unless P = NP. Among other results, we prove that ToOBDD is not comparable w.r.t. succinctness with any of CNF, DNF, DNNF unless the polynomial hierarchy collapses. This contributes to the explanation of some empirical results reported in [Subbarayan et al., 2007].

#index 1305413
#* FRACTAL: efficient fault isolation using active testing
#@ Alexander Feldman;Gregory Provan;Arjan Van Gemund
#t 2009
#c 11
#% 21138
#% 160260
#% 203169
#% 256685
#% 1217777
#% 1269936
#% 1274806
#% 1274845
#% 1279401
#% 1784305
#% 1784632
#% 1785024
#% 1837579
#! Model-Based Diagnosis (MBD) approaches often yield a large number of diagnoses, severely limiting their practical utility. This paper presents a novel active testing approach based on MBD techniques, called FRACTAL (FRamework for ACtive Testing ALgorithms), which, given a system description, computes a sequence of control settings for reducing the number of diagnoses. The approach complements probing, sequential diagnosis, and ATPG, and applies to systems where additional tests are restricted to setting a subset of the existing system inputs while observing the existing outputs. This paper evaluates the optimality of FRACTAL, both theoretically and empirically. FRACTAL generates test vectors using a greedy, next-best strategy and a low-cost approximation of diagnostic information entropy. Further, the approximate sequence computed by FRACTAL's greedy approach is optimal over all poly-time approximation algorithms, a fact which we confirm empirically. Extensive experimentation with ISCAS85 combinational circuits shows that FRACTAL reduces the number of remaining diagnoses according to a steep geometric decay function, even when only a fraction of inputs are available for active testing.

#index 1305414
#* Solving strong-fault diagnostic models by model relaxation
#@ Alexander Feldman;Gregory Provan;Arjan Van Gemund
#t 2009
#c 11
#% 21137
#% 21138
#% 107135
#% 110365
#% 132173
#% 154456
#% 204396
#% 529332
#% 757484
#% 979225
#% 1053890
#% 1274845
#% 1411197
#! In Model-Based Diagnosis (MBD), the problem of computing a diagnosis in a strong-fault model (SFM) is computationally much harder than in a weak-fault model (WFM). For example, in propositional Horn models, computing the first minimal diagnosis in a weak-fault model (WFM) is in P but is NP-hard for strong-fault models. As a result, SFM problems of practical significance have not been studied in great depth within the MBD community. In this paper we describe an algorithm that renders the problem of computing a diagnosis in several important SFM subclasses no harder than a similar computation in a WFM. We propose an approach for efficiently computing minimal diagnoses for these subclasses of SFM that extends existing conflict-based algorithms like GDE (Sherlock) and CDA*. Experiments on ISCAS85 combinational circuits show (1) inference speedups with CDA*of up to a factor of 8, and (2) an average of 28% reduction in the average conflict size, at the price of an extra low-polynomial-time consistency check for a candidate diagnosis.

#index 1305415
#* Plausible repairs for inconsistent requirements
#@ Alexander Felfernig;Gerhard Friedrich;Monika Schubert;Monika Mandl;Markus Mairitsch;Erich Teppan
#t 2009
#c 11
#% 21137
#% 132173
#% 220711
#% 234992
#% 741461
#% 1250145
#% 1269720
#% 1270137
#% 1272304
#% 1389762
#% 1655399
#! Knowledge-based recommenders support users in the identification of interesting items from large and potentially complex assortments. In cases where no recommendation could be found for a given set of requirements, such systems propose explanations that indicate minimal sets of faulty requirements. Unfortunately, such explanations are not personalized and do not include repair proposals which triggers a low degree of satisfaction and frequent cancellations of recommendation sessions. In this paper we present a personalized repair approach that integrates the calculation of explanations with collaborative problem solving techniques. In order to demonstrate the applicability of our approach, we present the results of an empirical study that show significant improvements in the accuracy of predictions for interesting repairs.

#index 1305416
#* Symmetric splitting in the general theory of stable models
#@ Paolo Ferraris;Joohyung Lee;Vladimir Lifschitz;Ravi Palla
#t 2009
#c 11
#% 171033
#% 236024
#% 400992
#% 417651
#% 772065
#% 906658
#% 1184237
#% 1270094
#% 1270359
#% 1274811
#% 1388132
#% 1503511
#! Splitting a logic program allows us to reduce the task of computing its stable models to similar tasks for smaller programs. This idea is extended here to the general theory of stable models that replaces traditional logic programs by arbitrary first-order sentences and distinguishes between intensional and extensional predicates. We discuss two kinds of splitting: a set of intensional predicates can be split into subsets, and a formula can be split into its conjunctive terms.

#index 1305417
#* On the accrual of arguments in defeasible logic programming
#@ Mauro J. Gómez Lucero;Carlos I. Chesñevar;Guillermo R. Simari
#t 2009
#c 11
#% 159242
#% 198464
#% 752766
#% 894061
#% 943879
#! Recently, the notion of accrual of arguments has received some attention from the argumentation community. Three principles for argument accrual have been identified as necessary to hold in argumentation frameworks. In this paper we propose an approach to model the accrual of arguments in the context of Defeasible Logic Programming, a logic programming approach to argumentation which has proven to be successful for many real-world applications. We will analyze the above mentioned principles in the context of our proposal, studying other interesting properties.

#index 1305418
#* Evaluating abductive hypotheses using an EM algorithm on BDDs
#@ Katsumi Inoue;Taisuke Sato;Masakazu Ishihata;Yoshitaka Kameya;Hidetomo Nabeshima
#t 2009
#c 11
#% 3873
#% 132176
#% 147677
#% 578665
#% 883336
#% 905825
#% 1011655
#% 1089646
#% 1269704
#% 1272388
#% 1275150
#% 1289197
#% 1405134
#! Abductive inference is an important AI reasoning technique to find explanations of observations, and has recently been applied to scientific discovery. To find best hypotheses among many logically possible hypotheses, we need to evaluate hypotheses obtained from the process of hypothesis generation. We propose an abductive inference architecture combined with an EM algorithm working on binary decision diagrams (BDDs). This work opens a way of applying BDDs to compress multiple hypotheses and to select most probable ones from them. An implemented system has been applied to inference of inhibition in metabolic pathways in the domain of systems biology.

#index 1305419
#* Answer-set programming with bounded treewidth
#@ Michael Jakl;Reinhard Pichler;Stefan Woltran
#t 2009
#c 11
#% 66112
#% 101944
#% 219474
#% 262723
#% 303886
#% 331899
#% 411814
#% 417651
#% 906658
#% 1077372
#% 1250131
#% 1250546
#% 1388119
#% 1405531
#! In this paper, we present a novel approach to the evaluation of propositional answer-set programs. In particular, for programs with bounded treewidth, our algorithm is capable of (i) computing the number of answer sets in linear time and (ii) enumerating all answer sets with linear delay. Our algorithm relies on dynamic programming. Therefore, our approach significantly differs from standard ASP systems which implement techniques stemming from SAT or CSP, and thus usually do not exploit fixed parameter properties of the programs. We provide first experimental results which underline that, for programs with low treewidth, even a prototypical implementation is competitive compared to state-of-the-art systems.

#index 1305420
#* Circumscriptive event calculus as answer set programming
#@ Tae-Won Kim;Joohyung Lee;Ravi Palla
#t 2009
#c 11
#% 3035
#% 7047
#% 167541
#% 198462
#% 236024
#% 417649
#% 417651
#% 834130
#% 834131
#% 934828
#% 1250163
#% 1270094
#% 1270359
#% 1274811
#% 1274822
#% 1425500
#% 1503511
#! Recently, Ferraris, Lee and Lifschitz presented a general definition of a stable model that is similar to the definition of circumscription, and can even be characterized in terms of circumscription. In this paper, we show the opposite direction, which is, how to turn circumscription into the general stable model semantics, and based on this, how to turn circumscriptive event calculus into answer set programs. The reformulation of the event calculus in answer set programming allows answer set solvers to be applied to event calculus reasoning, handling more expressive reasoning tasks than the current SAT-based approach. Our experiments also show clear computational advantages of the answer set programming approach.

#index 1305421
#* Forgetting and uniform interpolation in large-scale description logic terminologies
#@ Boris Konev;Dirk Walther;Frank Wolter
#t 2009
#c 11
#% 941445
#% 956566
#% 961683
#% 1076645
#% 1223443
#% 1271987
#% 1274824
#% 1297721
#! We develop a framework for forgetting concepts and roles (aka uniform interpolation) in terminologies in the lightweight description logic ƐL extended with role inclusions and domain and range restrictions. Three different notions of forgetting, preserving, respectively, concept inclusions, concept instances, and answers to conjunctive queries, with corresponding languages for uniform interpolants are investigated. Experiments based on SNOMED CT (Systematised Nomenclature of Medicine Clinical Terms) and NCI (National Cancer Institute Ontology) demonstrate that forgetting is often feasible in practice for large-scale terminologies.

#index 1305422
#* Minimal module extraction from DL-lite ontologies using QBF solvers
#@ R. Kontchakov;L. Pulina;U. Sattler;T. Schneider;P. Selmer;F. Wolter;M. Zakharyaschev
#t 2009
#c 11
#% 869464
#% 1166735
#% 1223443
#% 1269453
#% 1269726
#% 1272117
#% 1272206
#% 1409382
#% 1718503
#% 1728050
#! We present a formal framework for (minimal) module extraction based on an abstract notion of inseparability w.r.t. a signature between ontologies. Two instances of this framework are discussed in detail for DL-Lite ontologies: concept inseparability, when ontologies imply the same complex concept inclusions over the signature, and query inseparability, when they give the same answers to existential queries for any instance data over the signature. We demonstrate that different types of corresponding minimal modules for these inseparability relations can be automatically extracted from large-scale DL-Lite ontologies by composing the tractable syntactic locality-based module extraction algorithm with intractable extraction algorithms using the multi-engine QBF solver AQME. The extracted minimal modules are compared with those obtained using non-logic-based approaches.

#index 1305423
#* A semantical account of progression in the presence of defaults
#@ Gerhard Lakemeyer;Hector J. Levesque
#t 2009
#c 11
#% 1146
#% 7047
#% 68240
#% 117869
#% 229083
#% 284647
#% 326595
#% 342119
#% 431514
#% 529811
#% 558551
#% 572366
#% 1223595
#% 1250548
#% 1275051
#% 1275080
#% 1289429
#% 1289434
#! In previous work, we proposed a modal fragment of the situation calculus called ƐS, which fully captures Reiter's basic action theories. ƐS also has epistemic features, including only-knowing, which refers to all that an agent knows in the sense of having a knowledge base. While our model of only-knowing has appealing properties in the static case, it appears to be problematic when actions come into play. First of all, its utility seems to be restricted to an agent's initial knowledge base. Second, while it has been shown that only-knowing correctly captures default inferences, this was only in the static case, and undesirable properties appear to arise in the presence of actions. In this paper, we remedy both of these shortcomings and propose a new dynamic semantics of only-knowing, which is closely related to Lin and Reiter's notion of progression when actions are performed and where defaults behave properly.

#index 1305424
#* The complexity of learning separable ceteris paribus preferences
#@ Jérôme Lang;Jérôme Mengin
#t 2009
#c 11
#% 499542
#% 945225
#% 961136
#% 1074022
#% 1093383
#% 1250234
#% 1272026
#% 1272103
#% 1272133
#% 1272396
#% 1305598
#% 1650721
#! We address the problem of learning preference relations on multi-attribute (or combinatorial) domains. We do so by making a very simple hypothesis about the dependence structure between attributes that the preference relation enjoys, namely separability (no preferential dependencies between attributes). Given a set of examples consisting of comparisons between alternatives, we want to output a separable CP-net, consisting of local preferences on each of the attributes, that fits the examples. We consider three forms of compatibility between a CP-net and a set of examples, and for each of them we give useful characterizations as well as complexity results.

#index 1305425
#* Combining RCC-8 with qualitative direction calculi: algorithms and complexity
#@ Weiming Liu;Sanjiang Li;Jochen Renz
#t 2009
#c 11
#% 319244
#% 400979
#% 495793
#% 527331
#% 806735
#% 862119
#% 1270080
#% 1274821
#! Increasing the expressiveness of qualitative spatial calculi is an essential step towards meeting the requirements of applications. This can be achieved by combining existing calculi in a way that we can express spatial information using relations from both calculi. The great challenge is to develop reasoning algorithms that are correct and complete when reasoning over the combined information. Previous work has mainly studied cases where the interaction between the combined calculi was small, or where one of the two calculi was very simple. In this paper we tackle the important combination of topological and directional information for extended spatial objects. We combine some of the best known calculi in qualitative spatial reasoning (QSR), the RCC8 algebra for representing topological information, and the Rectangle Algebra (RA) and the Cardinal Direction Calculus (CDC) for directional information. Although CDC is more expressive than RA, reasoning with CDC is of the same order as reasoning with RA. We show that reasoning with basic RCC8 and basic RA relations is in P, but reasoning with basic RCC8 and basic CDC relations is NP-Complete.

#index 1305426
#* On first-order definability and computability of progression for local-effect actions and beyond
#@ Yongmei Liu;Gerhard Lakemeyer
#t 2009
#c 11
#% 229083
#% 342119
#% 1269459
#% 1270247
#! In a seminal paper, Lin and Reiter introduced the notion of progression for basic action theories in the situation calculus. Unfortunately, progression is not first-order definable in general. Recently, Vassos, Lakemeyer, and Levesque showed that in case actions have only local effects, progression is first-order representable. However, they could show computability of the first-order representation only for a restricted class. Also, their proofs were quite involved. In this paper, we present a result stronger than theirs that for local-effect actions, progression is always first-order definable and computable. We give a very simple proof for this via the concept of forgetting. We also show first-order definability and computability results for a class of knowledge bases and actions with non-local effects. Moreover, for a certain class of local-effect actions and knowledge bases for representing disjunctive information, we show that progression is not only first-order definable but also efficiently computable.

#index 1305427
#* A logic for reasoning about counterfactual emotions
#@ Emiliano Lorini;François Schwarzentruber
#t 2009
#c 11
#% 68239
#% 116625
#% 238395
#% 289946
#% 413871
#% 431524
#% 867249
#% 908967
#% 1269691
#! The aim of this work is to propose a logical framework for the specification of cognitive emotions that are based on counterfactual reasoning about agents' choices. An example of this kind of emotions is regret. In order to meet this objective, we exploit the well-known STIT logic [Belnap et al., 2001; Horty, 2001]. STIT logic has been proposed in the domain of formal philosophy in the nineties and, more recently, it has been imported into the field of theoretical computer science where its formal relationships with other logics for multi-agent systems such as ATL and Coalition Logic (CL) have been studied. STIT is a very suitable formalism to reason about choices and capabilities of agents and groups of agents. Unfortunately, the version of STIT with agents and groups has been recently proved to be undecidable. In this work we study a decidable fragment of STIT with agents and groups which is sufficiently expressive for our purpose of formalizing counterfactual emotions.

#index 1305428
#* Labellings and games for extended argumentation frameworks
#@ Sanjay Modgil
#t 2009
#c 11
#% 198464
#% 417812
#% 908926
#% 992249
#% 1193569
#% 1221648
#% 1221668
#% 1222446
#% 1274852
#! Dung's abstract theory of argumentation has become established as a general framework for various species of non-monotonic reasoning, and reasoning in the presence of conflict. A Dung framework consists of arguments related by attacks, and the extensions of a framework, and so the status of arguments, are defined under different semantics. Developments of Dung's work have also defined argument labellings as an alternative way of characterising extensions, and dialectical argument game proof theories for establishing the status of individual arguments. Recently, Extended Argumentation Frameworks extend Dung's theory so that arguments not only attack arguments, but attacks themselves. In this way, the extended theory provides an abstract framework for principled integration of meta-level argumentation about defeasible preferences applied to resolve conflicts between object level arguments. In this paper we formalise labellings and argument games for a selection of Dung's semantics defined for the extended frameworks.

#index 1305429
#* A fixed-parameter tractable algorithm for spatio-temporal calendar management
#@ Bernhard Nebel;Jochen Renz
#t 2009
#c 11
#% 319244
#% 816393
#% 857282
#% 1144829
#% 1250276
#! Calendar management tools assist users with coordinating their daily life. Different tasks have to be scheduled according to the user preferences. In many cases, tasks are at different locations and travel times have to be considered. Therefore, these kinds of calendar management problems can be regarded as spatio-temporal optimisation problems and are often variants of traveling salesman problems (TSP) or vehicle routing problems. While standard TSPs require a solution to include all tasks, prize-collecting TSPs are more suited for calendar management problems as they require a solution that optimises the total sum of "prizes" we assigned to tasks at different locations. If we now add time windows that limit when tasks can occur, these prize-collecting TSPs with time windows (TW-TSP) are excellent abstractions of spatio-temporal optimisation problems such as calendar management. Due to the inherent complexity of TW-TSPs, the existing literature considers mainly approximation algorithms or special cases. We present a novel algorithm for TW-TSPs that enables us to find the optimal solution to TW-TSP problems occurring in real-world calendar management applications efficiently. Our algorithm is a fixed-parameter tractable algorithm that depends on the maximal number of tasks that can be revisited from some other task, a parameter which is small in the application scenario we consider.

#index 1305430
#* Reasoning with knowledge, action and time in dynamic and uncertain domains
#@ Theodore Patkos;Dimitris Plexousakis
#t 2009
#c 11
#% 167541
#% 322911
#% 484341
#% 572366
#% 752887
#% 934828
#% 1275080
#% 1279222
#% 1279368
#% 1289434
#! We propose a new framework for reasoning about knowledge, action and time for domains that include actions with non-deterministic and context-dependent effects. The axiomatization is based on the Event Calculus and combines the expressiveness of possible worlds semantics with the efficiency of approaches that dispense the use of the accessibility relation. The framework is proved logically sound and, when restricted to deterministic domains, is also logically complete. To prove correctness of the approach, we construct a knowledge theory based on a branching version of the Event Calculus and study their correlation.

#index 1305431
#* Model-based revision operators for terminologies in description logics
#@ Guilin Qi;Jianfeng Du
#t 2009
#c 11
#% 42986
#% 109945
#% 665856
#% 992961
#% 992962
#% 1217753
#% 1250361
#% 1269460
#% 1269733
#% 1413143
#% 1655398
#% 1655407
#% 1664546
#% 1702407
#! The problem of revising an ontology consistently is closely related to the problem of belief revision which has been widely discussed in the literature. Some syntax-based belief revision operators have been adapted to revise ontologies in Description Logics (DLs). However, these operators remove the whole axioms to resolve logical contradictions and thus are not fine-grained. In this paper, we propose three model-based revision operators to revise terminologies in DLs. We show that one of them is more rational than others by comparing their logical properties. Therefore, we focus on this revision operator. We also consider the problem of computing the result of revision by our operator with the help of the notion of concept forgetting. Finally, we analyze the computational complexity of our revision operator.

#index 1305432
#* Dialectical abstract argumentation: a characterization of the marking criterion
#@ Nicolás D. Rotstein;Martín O. Moguillansky;Guillermo R. Simari
#t 2009
#c 11
#% 752766
#% 992251
#% 1222454
#% 1270040
#% 1274796
#% 1274826
#% 1274852
#! This article falls within the field of abstract argumentation frameworks. In particular, we focus on the study of frameworks using a proof procedure based on dialectical trees. These trees rely on a marking procedure to determine the warrant status of their root argument. Thus, our objective is to formulate rationality postulates to characterize the marking criterion over dialectical trees. The behavior of the marking procedure is closely tied to the alteration of trees, which is the keystone of any model of change based on dialectical argumentation. Hence, the results achieved in this work will benefit research on dynamics in argumentation.

#index 1305433
#* Composition of ConGolog programs
#@ Sebastian Sardina;Giuseppe De Giacomo
#t 2009
#c 11
#% 284106
#% 314845
#% 342119
#% 762500
#% 824702
#% 1275054
#% 1275067
#! We look at composition of (possibly nonterminating) high-level programs over situation calculus action theories. Specifically the problem we look at is as follows: given a library of available ConGolog programs and a target program not in the library, verify whether the target program executions be realized by composing fragments of the executions of the available programs; and, if so, synthesize a controller that does the composition automatically. This kind of composition problems have been investigated in the CS and AI literature, but always assuming finite states settings. Here, instead, we investigate the issue in the context of infinite domains that may go through an infinite number of states as a result of actions. Obviously in this context the problem is undecidable. Nonetheless, by exploiting recent results in the AI literature, we devise a sound and well characterized technique to actually solve the problem.

#index 1305434
#* Automated theorem proving for general game playing
#@ Stephan Schiffel;Michael Thielscher
#t 2009
#c 11
#% 7690
#% 33376
#% 53385
#% 1250387
#% 1269851
#% 1269860
#% 1270060
#! A general game player is a system that understands the rules of an unknown game and learns to play this game well without human intervention. To succeed in this endeavor, systems need to be able to extract and prove game-specific knowledge from the mere game rules. We present a practical approach to this challenge with the help of Answer Set Programming. The key idea is to reduce the automated theorem proving task to a simple proof of an induction step and its base case. We prove correctness of this method and report on experiments with an off-the-shelf Answer Set Programming system in combination with a successful general game player.

#index 1305435
#* Nominals for everyone
#@ Lutz Schröoder;Dirk Pattinson;Clemens Kupke
#t 2009
#c 11
#% 104387
#% 717501
#% 717506
#% 935898
#% 960848
#% 1036397
#% 1066375
#% 1134163
#% 1136065
#% 1271815
#% 1916560
#! It has been recognised that the expressivity of description logics benefits from the introduction of non-standard modal operators beyond existential and number restrictions. Such operators support notions such as uncertainty, defaults, agency, obligation, or evidence, whose semantics often lies outside the realm of relational structures. Coalgebraic hybrid logic serves as a unified setting for logics that combine non-standard modal operators and nominals, which allow reasoning about individuals. In this framework, we prove a generic EXPTIME upper bound for concept satisfiability over general TBoxes, which instantiates to novel upper bounds for many individual logics including probabilistic logic with nominals.

#index 1305436
#* Effective query rewriting with ontologies over DBoxes
#@ Inanç Seylan;Enrico Franconi;Jos De Bruijn
#t 2009
#c 11
#% 224758
#% 248038
#% 809238
#% 935898
#% 976986
#% 1043800
#% 1661430
#! We consider query answering on Description Logic (DL) ontologies with DBoxes, where a DBox is a set of assertions on individuals involving atomic concepts and roles called DBox predicates. The extension of a DBox predicate is exactly defined in every interpretation by the contents of the DBox, i.e., a DBox faithfully represents a database whose table names are the DBox predicates and the tuples are the DBox assertions. Our goals are (i) to find out whether the answers to a given query are solely determined by the DBox predicates and, if so, (ii) to find a rewriting of the query in terms of them. The resulting query can then be efficiently evaluated using standard database technology. We have that (i) can be reduced to entailment checking and (ii) can be reduced to finding an interpolant. We present a procedure for computing interpolants in the DL ALC with general TBoxes. We extend the procedure with standard tableau optimisations, and we discuss abduction as a technique for amending ontologies to gain definability of queries of interest.

#index 1305437
#* Negotiation using logic programming with consistency restoring rules
#@ Tran Cao Son;Chiaki Sakama
#t 2009
#c 11
#% 400986
#% 411814
#% 495999
#% 782765
#% 890255
#% 1024834
#% 1024918
#% 1250165
#% 1388120
#! We formalize negotiations using logic programming with consistency restoring rules (or CR-Prolog) [Balduccini and Gelfond, 2003]. Our formulation deals with incomplete information, preferences, and changing goals. We assume that each agent is equipped with a knowledge base for negotiation which consists of a CR-program, a set of possible assumptions, and a set of ordered goals. We use the notion of an answer set as a means to formalize the basic notions of negotiation such as proposal, response, negotiation, negotiation tree (protocol), etc. and discuss their properties.

#index 1305438
#* Realising deterministic behavior from multiple non-deterministic behaviors
#@ Thomas Ströder;Maurice Pagnucco
#t 2009
#c 11
#% 900890
#% 1269840
#% 1275054
#! This paper considers the problem of composing or scheduling several (non-deterministic) behaviors so as to conform to a specified target behavior as well as satisfying constraints imposed by the environment in which the behaviors are to be performed. This problem has already been considered by several works in the literature and applied to areas such as web service composition, the composition of robot behaviors and co-ordination of distributed devices. We develop a sound and complete algorithm for determining such a composition which has a number of significant advantages over previous proposals: a) our algorithm is different from previous proposals which resort to dynamic logic or simulation relations, b) we realized an implementation in Java as opposed to other approaches for which there are no known implementations, c) our algorithm determines all possible schedulers at once, and d) we can use our framework to define a notion of approximation when the target behavior cannot be realized.

#index 1305439
#* Declarative programming of search problems with built-in arithmetic
#@ Eugenia Ternovska;David G. Mitchell
#t 2009
#c 11
#% 257866
#% 333865
#% 778122
#% 879186
#% 1036569
#% 1077573
#% 1269426
#% 1274777
#% 1712427
#! We address the problem of providing a logical formalization of arithmetic in declarative modelling languages for NP search problems. The challenge is to simultaneously allow quantification over an infinite domain such as the natural numbers, provide natural modelling facilities, and control expressive power of the language. To address the problem, we introduce an extension of the model expansion (MX) based framework to finite structures embedded in an infinite secondary structure, together with "double-guarded" logics for representing MX specifications for these structures. The logics also contain multi-set functions (aggregate operations). Our main result is that these logics capture the complexity class NP on "small-cost" arithmetical structures.

#index 1305440
#* Applications and extensions of PTIME description logics with functional constraints
#@ David Toman;Grant Weddell
#t 2009
#c 11
#% 175746
#% 248026
#% 408495
#% 459291
#% 826035
#% 992962
#% 1289408
#% 1289447
#% 1703740
#! We review and extend earlier work on the logic CFD, a description logic that allows terminological cycles with universal restrictions over functional roles. In particular, we consider the problem of reasoning about concept subsumption and the problem of computing certain answers for a family of attribute-connected conjunctive queries, showing that both problems are in PTIME. We then consider the effect on the complexity of these problems after adding a concept constructor that expresses concept union, or after adding a concept constructor for the bottom class. Finally, we show that adding both constructors makes both problems EXPTIME-complete.

#index 1305441
#* Knowing more: from global to local correspondence
#@ Hans Van Ditmarsch;Wiebe Van Der Hoek;Barteld Kooi
#t 2009
#c 11
#% 188086
#% 338753
#% 380578
#% 390685
#% 1197380
#% 1274943
#! Modal correspondence theory is a powerful and effective way to guarantee that adding specific syntactic axioms to a modal logic is mirrored by requiring 'corresponding' properties of the underlying Kripke models. However, such axioms not only quantify over all formulas, but they are also global in the sense that the corresponding semantic property is assumed to hold for all states. However, in for instance epistemic logic one would like to have the flexibility to say that certain properties (like 'agent b knows at least what agent a knows') are true locally in a specific state, but not necessarily globally, in all states. This would enable one to say 'currently, b knows at least what a knows, but this is not common knowledge', or '... but this is not always true', or '... but this could be changed by action α'. We offer a logic for 'knowing at least as', where the (global) axiom scheme KaΦ → KbΦ is replaced by a (local) inference rule. We give a complete modal system, and discuss some consequences of the axiom in an epistemic setting. Our completeness proof also suggests how achieving such local properties can be generalized to other axioms schemes and modal logics.

#index 1305442
#* Efficient inference for expressive comparative preference languages
#@ Nic Wilson
#t 2009
#c 11
#% 528176
#% 767712
#% 1023517
#% 1223283
#% 1250234
#% 1272026
#% 1272103
#% 1279242
#% 1289373
#% 1650274
#% 1650354
#! A fundamental task for reasoning with preferences is the following: given input preference information from a user, and outcomes α and β, should we infer that the user will prefer α to β? For CP-nets and related comparative preference formalisms, inferring a preference of α over β using the standard definition of derived preference appears to be extremely hard, and has been proved to be PSPACE-complete in general for CP-nets. Such inference is also rather conservative, only making the assumption of transitivity. This paper defines a less conservative approach to inference which can be applied for very general forms of input. It is shown to be efficient for expressive comparative preference languages, allowing comparisons between arbitrary partial tuples (including complete assignments), and with the preferences being ceteris paribus or not.

#index 1305443
#* On combinations of binary qualitative constraint calculi
#@ Stefan Wölfl;Matthias Westphal
#t 2009
#c 11
#% 1145
#% 82720
#% 319244
#% 400979
#% 417552
#! Qualitative constraint calculi are representation formalisms that allow for efficient reasoning about spatial and temporal information. Many of the calculi discussed in the field of Qualitative Spatial and Temporal Reasoning can be defined as combinations of other, simpler and more compact formalisms. On the other hand, existing calculi can be combined to a new formalism in which one can represent, and reason about, different aspects of a domain at the same time. For example, Gerevini and Renz presented a loose combination of the region connection calculus RCC-8 and the point algebra: the resulting formalism integrates topological and qualitative size relations between spatially extended objects. In this paper we compare the approach by Gerevini and Renz to a method that generates a new qualitative calculus by exploiting the semantic interdependencies between the component calculi. We will compare these two methods and analyze some formal relationships between a combined calculus and its components. The paper is completed by an empirical case study in which the reasoning performance of the suggested methods is compared on random test instances.

#index 1305444
#* Exponential family hybrid semi-supervised learning
#@ Arvind Agarwal;Hal Daumé
#t 2009
#c 11
#% 304917
#% 311027
#% 883830
#% 948913
#% 989599
#% 1031854
#% 1250575
#! We present an approach to semi-supervised learning based on an exponential family characterization. Our approach generalizes previous work on coupled priors for hybrid generative/discriminative models. Our model is more flexible and natural than previous approaches. Experimental results on several data sets show that our approach also performs better in practice.

#index 1305445
#* Active policy iteration: efficient exploration through active learning for value function approximation in reinforcement learning
#@ Takayuki Akiyama;Hirotaka Hachiya;Masashi Sugiyama
#t 2009
#c 11
#% 384911
#% 466751
#% 734920
#% 961139
#% 1270303
#% 1272282
#! Appropriately designing sampling policies is highly important for obtaining better control policies in reinforcement learning. In this paper, we first show that the least-squares policy iteration (LSPI) framework allows us to employ statistical active learning methods for linear regression. Then we propose a design method of good sampling policies for efficient exploration, which is particularly useful when the sampling cost of immediate rewards is high. We demonstrate the usefulness of the proposed method, named active policy iteration (API), through simulations with a batting robot.

#index 1305446
#* Relational random forests based on random relational rules
#@ Grant Anderson;Bernhard Pfahringer
#t 2009
#c 11
#% 224755
#% 398847
#% 398848
#% 400847
#% 550387
#% 550398
#% 723257
#% 883329
#% 1250568
#% 1415860
#! Random Forests have been shown to perform very well in propositional learning. FORF is an upgrade of Random Forests for relational data. In this paper we investigate shortcomings of FORF and propose an alternative algorithm, R4F, for generating Random Forests over relational data. R4F employs randomly generated relational rules as fully self-contained Boolean tests inside each node in a tree and thus can be viewed as an instance of dynamic propositionalization. The implementation of R4F allows for the simultaneous or parallel growth of all the branches of all the trees in the ensemble in an efficient shared, but still single-threaded way. Experiments favorably compare R4F to both FORF and the combination of static propositionalization together with standard Random Forests. Various strategies for tree initialization and splitting of nodes, as well as resulting ensemble size, diversity, and computational complexity of R4F are also investigated.

#index 1305447
#* Adaptive cluster ensemble selection
#@ Javad Azimi;Xiaoli Fern
#t 2009
#c 11
#% 212986
#% 722902
#% 726725
#% 727903
#% 770836
#% 940282
#% 1137063
#! Cluster ensembles generate a large number of different clustering solutions and combine them into a more robust and accurate consensus clustering. On forming the ensembles, the literature has suggested that higher diversity among ensemble members produces higher performance gain. In contrast, some studies also indicated that medium diversity leads to the best performing ensembles. Such contradicting observations suggest that different data, with varying characteristics, may require different treatments. We empirically investigate this issue by examining the behavior of cluster ensembles on benchmark data sets. This leads to a novel framework that selects ensemble members for each data set based on its own characteristics. Our framework first generates a diverse set of solutions and combines them into a consensus partition P*. Based on the diversity between the ensemble members and P*, a subset of ensemble members is selected and combined to obtain the final output. We evaluate the proposed method on benchmark data sets and the results show that the proposed method can significantly improve the clustering performance, often by a substantial margin. In some cases, we were able to produce final solutions that significantly outperform even the best ensemble members.

#index 1305448
#* Self-managing associative memory for dynamic acquisition of expertise in high-level domains
#@ Jacob Beal
#t 2009
#c 11
#% 60576
#% 63672
#% 391311
#% 1727836
#! Self-organizing maps can be used to implement an associative memory for an intelligent system that dynamically learns about new high-level domains over time. SOMs are an attractive option for implementing associative memory: they are fast, easily parallelized, and digest a stream of incoming data into a topographically organized collection of models where more frequent classes of data are represented by higher-resolution collections of models. Typically, the distribution of models in an SOM, once developed, remains fairly stable, but developing expertise in a new high-level domain requires altering the allocation of models. We use a mixture of analysis and empirical studies to characterize the behavior of SOMs for high-level associative memory, finding that new high-resolution collections of models develop quickly. High-resolution areas of the SOM decay rapidly unless actively refreshed, but in a large SOM, the ratio between growth rate and decay rate may be high enough to support both fast learning and long-term memory.

#index 1305449
#* Angluin-style learning of NFA
#@ Benedikt Bollig;Peter Habermehl;Carsten Kern;Martin Leucker
#t 2009
#c 11
#% 31215
#% 116138
#% 183668
#% 202295
#% 749136
#% 939982
#% 1378363
#% 1404044
#% 1703518
#! We introduce NL*, a learning algorithm for inferring non-deterministic finite-state automata using membership and equivalence queries. More specifically, residual finite-state automata (RFSA) are learned similarly as in Angluin's popular L* algorithm, which, however, learns deterministic finite-state automata (DFA). Like in a DFA, the states of an RFSA represent residual languages. Unlike a DFA, an RFSA restricts to prime residual languages, which cannot be described as the union of other residual languages. In doing so, RFSA can be exponentially more succinct than DFA. They are, therefore, the preferable choice for many learning applications. The implementation of our algorithm is applied to a collection of examples and confirms the expected advantage of NL* over L*.

#index 1305450
#* Locality preserving nonnegative matrix factorization
#@ Deng Cai;Xiaofei He;Xuanhui Wang;Hujun Bao;Jiawei Han
#t 2009
#c 11
#% 313959
#% 643008
#% 729437
#% 837604
#% 876918
#% 961218
#% 1176865
#% 1176946
#! Matrix factorization techniques have been frequently applied in information processing tasks. Among them, Non-negative Matrix Factorization (NMF) have received considerable attentions due to its psychological and physiological interpretation of naturally occurring data whose representation may be parts-based in human brain. On the other hand, from geometric perspective the data is usually sampled from a low dimensional manifold embedded in high dimensional ambient space. One hopes then to find a compact representation which uncovers the hidden topics and simultaneously respects the intrinsic geometric structure. In this paper, we propose a novel algorithm, called Locality Preserving Non-negative Matrix Factorization (LPNMF), for this purpose. For two data points, we use KL-divergence to evaluate their similarity on the hidden topics. The optimal maps are obtained such that the feature values on hidden topics are restricted to be non-negative and vary smoothly along the geodesics of the data manifold. Our empirical study shows the encouraging results of the proposed algorithm in comparisons to the state-of-the-art algorithms on two large high-dimensional databases.

#index 1305451
#* Selecting informative universum sample for semi-supervised learning
#@ Shuo Chen;Changshui Zhang
#t 2009
#c 11
#% 466263
#% 876071
#% 983899
#% 1073897
#! The Universum sample, which is defined as the sample that doesn't belong to any of the classes the learning task concerns, has been proved to be helpful in both supervised and semi-supervised settings. The former works treat the Universum samples equally. Our research found that not all the Universum samples are helpful, and we propose a method to pick the informative ones, i.e., in-between Universum samples. We also set up a new semi-supervised framework to incorporate the in-between Universum samples. Empirical experiments show that our method outperforms the former ones.

#index 1305452
#* Bayesian extreme components analysis
#@ Yutian Chen;Max Welling
#t 2009
#c 11
#% 251155
#% 272536
#% 278040
#% 304879
#% 450266
#! Extreme Components Analysis (XCA) is a statistical method based on a single eigenvalue decomposition to recover the optimal combination of principal and minor components in the data. Unfortunately, minor components are notoriously sensitive to overfitting when the number of data items is small relative to the number of attributes. We present a Bayesian extension of XCA by introducing a conjugate prior for the parameters of the XCA model. This Bayesian-XCA is shown to outperform plain vanilla XCA as well as Bayesian-PCA and XCA based on a frequentist correction to the sample spectrum. Moreover, we show that minor components are only picked when they represent genuine constraints in the data, even for very small sample sizes. An extension to mixtures of Bayesian XCA models is also explored.

#index 1305453
#* Inverse reinforcement learning in partially observable environments
#@ Jaedeug Choi;Kee-Eung Kim
#t 2009
#c 11
#% 179940
#% 252013
#% 252183
#% 466230
#% 466418
#% 707796
#% 770852
#% 940817
#% 1269868
#% 1270316
#% 1275169
#! Inverse reinforcement learning (IRL) is the problem of recovering the underlying reward function from the behaviour of an expert. Most of the existing algorithms for IRL assume that the expert's environment is modeled as a Markov decision process (MDP), although they should be able to handle partially observable settings in order to widen the applicability to more realistic scenarios. In this paper, we present an extension of the classical IRL algorithm by Ng and Russell to partially observable environments. We discuss technical issues and challenges, and present the experimental results on some of the benchmark partially observable domains.

#index 1305454
#* Knowledge driven dimension reduction for clustering
#@ Ian Davidson
#t 2009
#c 11
#% 376266
#% 464291
#% 829025
#% 948091
#% 1073891
#! As A.I. algorithms are applied to more complex domains that involve high dimensional data sets there is a need to more saliently represent the data. However, most dimension reduction approaches are driven by objective functions that may not or only partially suit the end users requirements. In this work, we show how to incorporate general-purpose domain expertise encoded as a graph into dimension reduction in way that lends itself to an elegant generalized eigenvalue problem. We call our approach Graph-Driven Constrained Dimension Reduction via Linear Projection (GCDR-LP) and show that it has several desirable properties.

#index 1305455
#* Search techniques for Fourier-based learning
#@ Adam Drake;Dan Ventura
#t 2009
#c 11
#% 148216
#% 156699
#% 243163
#% 312083
#% 840858
#! Fourier-based learning algorithms rely on being able to efficiently find the large coefficients of a function's spectral representation. In this paper, we introduce and analyze techniques for finding large coefficients. We show how a previously introduced search technique can be generalized from the Boolean case to the real-valued case, and we apply it in branch-and-bound and beam search algorithms that have significant advantages over the best-first algorithm in which the technique was originally introduced.

#index 1305456
#* Local learning regularized nonnegative matrix factorization
#@ Quanquan Gu;Jie Zhou
#t 2009
#c 11
#% 143194
#% 313959
#% 593047
#% 643008
#% 732522
#% 757953
#% 793248
#% 881468
#% 1176865
#% 1327693
#% 1861693
#! Nonnegative Matrix Factorization (NMF) has been widely used in machine learning and data mining. It aims to find two nonnegative matrices whose product can well approximate the nonnegative data matrix, which naturally lead to parts-based representation. In this paper, we present a local learning regularized nonnegative matrix factorization (LLNMF) for clustering. It imposes an additional constraint on NMF that the cluster label of each point can be predicted by the points in its neighborhood. This constraint encodes both the discriminative information and the geometric structure, and is good at clustering data on manifold. An iterative multiplicative updating algorithm is proposed to optimize the objective, and its convergence is guaranteed theoretically. Experiments on many benchmark data sets demonstrate that the proposed method outperforms NMF as well as many state of the art clustering methods.

#index 1305457
#* Learning optimal subsets with implicit user preferences
#@ Yunsong Guo;Carla Gomes
#t 2009
#c 11
#% 734915
#% 829043
#% 840882
#% 875979
#% 1074025
#% 1250331
#% 1269444
#% 1269456
#% 1269866
#% 1272103
#! We study the problem of learning an optimal subset from a larger ground set of items, where the optimality criterion is defined by an unknown preference function. We model the problem as a discriminative structural learning problem and solve it using a Structural Support Vector Machine (SSVM) that optimizes a "set accuracy" performance measure representing set similarities. Our approach departs from previous approaches since we do not explicitly learn a pre-defined preference function. Experimental results on both a synthetic problem domain and a real-world face image subset selection problem show that our method significantly outperforms previous learning approaches for such problems.

#index 1305458
#* Ranking structured documents: a large margin based approach for patent prior art search
#@ Yunsong Guo;Carla Gomes
#t 2009
#c 11
#% 169777
#% 309095
#% 340948
#% 466229
#% 577224
#% 766414
#% 770788
#% 840846
#% 840853
#% 879588
#% 879655
#% 961191
#% 983905
#% 987226
#! We propose an approach for automatically ranking structured documents applied to patent prior art search. Our model, SVM Patent Ranking (SVMPR) incorporates margin constraints that directly capture the specificities of patent citation ranking. Our approach combines patent domain knowledge features with meta-score features from several different general Information Retrieval methods. The training algorithm is an extension of the Pegasos algorithm with performance guarantees, effectively handling hundreds of thousands of patent-pair judgements in a high dimensional feature space. Experiments on a homogeneous essential wireless patent dataset show that SVMPR performs on average 30%-40% better than many other state-of-the-art general-purpose Information Retrieval methods in terms of the NDCG measure at different cut-off positions.

#index 1305459
#* Graph embedding with constraints
#@ Xiaofei He;Ming Ji;Hujun Bao
#t 2009
#c 11
#% 235342
#% 310667
#% 317525
#% 729437
#% 732522
#% 791402
#% 812580
#% 836827
#% 961279
#% 1022958
#% 1279292
#% 1781954
#! Recently graph based dimensionality reduction has received a lot of interests in many fields of information processing. Central to it is a graph structure which models the geometrical and discriminant structure of the data manifold. When label information is available, it is usually incorporated into the graph structure by modifying the weights between data points. In this paper, we propose a novel dimensionality reduction algorithm, called Constrained Graph Embedding, which considers the label information as additional constraints. Specifically, we constrain the space of the solutions that we explore only to contain embedding results that are consistent with the labels. Experimental results on two real life data sets illustrate the effectiveness of our proposed method.

#index 1305460
#* Bootstrap voting experts
#@ Daniel Hewlett;Paul Cohen
#t 2009
#c 11
#% 278101
#% 549452
#% 741035
#% 796737
#% 815804
#% 939800
#% 1056091
#% 1272315
#% 1656720
#! BOOTSTRAP VOTING EXPERTS (BVE) is an extension to the VOTING EXPERTS algorithm for unsupervised chunking of sequences. BVE generates a series of segmentations, each of which incorporates knowledge gained from the previous segmentation. We show that this method of bootstrapping improves the performance of VOTING EXPERTS in a variety of unsupervised word segmentation scenarios, and generally improves both precision and recall of the algorithm. We also show that Minimum Description Length (MDL) can be used to choose nearly optimal parameters for VOTING EXPERTS in an unsupervised manner.

#index 1305461
#* Linear dimensionality reduction for multi-label classification
#@ Shuiwang Ji;Jieping Ye
#t 2009
#c 11
#% 80995
#% 176588
#% 763697
#% 763699
#% 916788
#% 961154
#% 961246
#% 983806
#% 1074000
#% 1128929
#% 1270338
#! Dimensionality reduction is an essential step in high-dimensional data analysis. Many dimensionality reduction algorithms have been applied successfully to multi-class and multi-label problems. They are commonly applied as a separate data preprocessing step before classification algorithms. In this paper, we study a joint learning framework in which we perform dimensionality reduction and multi-label classification simultaneously. We show that when the least squares loss is used in classification, this joint learning decouples into two separate components, i.e., dimensionality reduction followed by multi-label classification. This analysis partially justifies the current practice of a separate application of dimensionality reduction for classification problems. We extend our analysis using other loss functions, including the hinge loss and the squared hinge loss. We further extend the formulation to the more general case where the input data for different class labels may differ, overcoming the limitation of traditional dimensionality reduction algorithms. Experiments on benchmark data sets have been conducted to evaluate the proposed joint formulations.

#index 1305462
#* Semi-supervised classification on evolutionary data
#@ Yangqing Jia;Shuicheng Yan;Changshui Zhang
#t 2009
#c 11
#% 260001
#% 406493
#% 829014
#% 881514
#% 961218
#% 989586
#% 1705533
#! In this paper, we consider semi-supervised classification on evolutionary data, where the distribution of the data and the underlying concept that we aim to learn change over time due to short-term noises and long-term drifting, making a single aggregated classifier inapplicable for long-term classification. The drift is smooth if we take a localized view over the time dimension, which enables us to impose temporal smoothness assumption for the learning algorithm. We first discuss how to carry out such assumption using temporal regularizers defined in a structural way with respect to the Hilbert space, and then derive the online algorithm that efficiently finds the closed-form solution to the classification functions. Experimental results on real-world evolutionary mailing list data demonstrate that our algorithm outperforms classical semi-supervised learning algorithms in both algorithmic stability and classification accuracy.

#index 1305463
#* gRegress: extracting features from graph transactions for regression
#@ Nikhil S. Ketkar;Lawrence B. Holder;Diane J. Cook
#t 2009
#c 11
#% 309208
#% 629708
#% 731608
#% 742493
#% 768632
#% 798044
#% 813990
#% 989610
#% 1083688
#% 1673586
#! In this work we propose gRegress, a new algorithm which given set a of labeled graphs and a real value associated with each graph extracts the complete set of subgraphs such that a) each subgraph in this set has correlation with the real value above a user-specified threshold and b) each subgraph in this set has correlation with any other subgraph in the set below a user-specified threshold. gRegress incorporates novel pruning mechanisms based on correlation of a subgraph feature with the output and correlation with other subgraph features. These pruning mechanisms lead to significant speedup. Experimental results indicate that in terms of run-time, gRegress substantially outperforms gSpan, often by an order of magnitude while the regression models produced by both approaches have comparable accuracy.

#index 1305464
#* Local query mining in a probabilistic prolog
#@ Angelika Kimmig;Luc De Raedt
#t 2009
#c 11
#% 232136
#% 248784
#% 248785
#% 292510
#% 299985
#% 420062
#% 420087
#% 466579
#% 1016201
#% 1063531
#% 1272388
#% 1275150
#% 1393138
#% 1692830
#! Local pattern mining is concerned with finding the set of patterns that satisfy a constraint in a database. We study local pattern mining in the context of ProbLog, a probabilistic Prolog system, and introduce an approach for finding correlated patterns in the form of queries in such a Prolog system. The approach combines principles of inductive logic programming, data mining and statistical relational learning. Experiments on a challenging biological network mining task provide evidence for the interestingness of the approach.

#index 1305465
#* Unsupervised rank aggregation with domain-specific expertise
#@ Alexandre Klementiev;Dan Roth;Kevin Small;Ivan Titov
#t 2009
#c 11
#% 137599
#% 266477
#% 330769
#% 450535
#% 464451
#% 728195
#% 956542
#% 983818
#% 1073931
#% 1074065
#% 1275654
#! Consider the setting where a panel of judges is repeatedly asked to (partially) rank sets of objects according to given criteria, and assume that the judges' expertise depends on the objects' domain. Learning to aggregate their rankings with the goal of producing a better joint ranking is a fundamental problem in many areas of Information Retrieval and Natural Language Processing, amongst others. However, supervised ranking data is generally difficult to obtain, especially if coming from multiple domains. Therefore, we propose a framework for learning to aggregate votes of constituent rankers with domain specific expertise without supervision. We apply the learning framework to the settings of aggregating full rankings and aggregating top-k lists, demonstrating significant improvements over a domain-agnostic baseline in both cases.

#index 1305466
#* Efficient skill learning using abstraction selection
#@ George Konidaris;Andrew Barto
#t 2009
#c 11
#% 286423
#% 384911
#% 431471
#% 464636
#% 466070
#% 466235
#% 840937
#% 891559
#% 1271827
#! We present an algorithm for selecting an appropriate abstraction when learning a new skill. We show empirically that it can consistently select an appropriate abstraction using very little sample data, and that it significantly improves skill learning performance in a reasonably large real-valued reinforcement learning domain.

#index 1305467
#* Exponential family sparse coding with applications to self-taught learning
#@ Honglak Lee;Rajat Raina;Alex Teichman;Andrew Y. Ng
#t 2009
#c 11
#% 272711
#% 722904
#% 757953
#% 770857
#% 876071
#% 983808
#% 983899
#% 1014657
#% 1074024
#% 1250570
#% 1861282
#! Sparse coding is an unsupervised learning algorithm for finding concise, slightly higher-level representations of inputs, and has been successfully applied to self-taught learning, where the goal is to use unlabeled data to help on a supervised learning task, even if the unlabeled data cannot be associated with the labels of the supervised task [Raina et al., 2007]. However, sparse coding uses a Gaussian noise model and a quadratic loss function, and thus performs poorly if applied to binary valued, integer valued, or other non-Gaussian data, such as text. Drawing on ideas from generalized linear models (GLMs), we present a generalization of sparse coding to learning with data drawn from any exponential family distribution (such as Bernoulli, Poisson, etc). This gives a method that we argue is much better suited to model other data types than Gaussian. We present an algorithm for solving the L1- regularized optimization problem defined by this model, and show that it is especially efficient when the optimal solution is sparse. We also show that the new model results in significantly improved self-taught learning performance when applied to text classification and to a robotic perception task.

#index 1305468
#* Exploiting multi-modal interactions: a unified framework
#@ Ming Li;Xiao-Bing Xue;Zhi-Hua Zhou
#t 2009
#c 11
#% 318785
#% 340899
#% 387427
#% 457912
#% 642989
#% 642990
#% 721163
#% 722927
#% 784963
#% 884074
#% 905280
#% 989605
#! Given an imagebase with tagged images, four types of tasks can be executed, i.e., content-based image retrieval, image annotation, text-based image retrieval, and query expansion. For any of these tasks the similarity on the concerned type of objects is essential. In this paper, we propose a framework to tackle these four tasks from a unified view. The essence of the framework is to estimate similarities by exploiting the interactions between objects of different modality. Experiments show that the proposed method can improve similarity estimation, and based on the improved similarity estimation, some simple methods can achieve better performances than some state-of-the-art techniques.

#index 1305469
#* Relation regularized matrix factorization
#@ Wu-Jun Li;Dit-Yan Yeung
#t 2009
#c 11
#% 266215
#% 420495
#% 647057
#% 818241
#% 840924
#% 840965
#% 987253
#! In many applications, the data, such as web pages and research papers, contain relation (link) structure among entities in addition to textual content information. Matrix factorization (MF) methods, such as latent semantic indexing (LSI), have been successfully used to map either content information or relation information into a lower-dimensional latent space for subsequent processing. However, how to simultaneously model both the relation information and the content information effectively with an MF framework is still an open research problem. In this paper, we propose a novel MF method called relation regularized matrix factorization (RRMF) for relational data analysis. By using relation information to regularize the content MF procedure, RRMF seamlessly integrates both the relation information and the content information into a principled framework. We propose a linear-time learning algorithm with convergence guarantee to learn the parameters of RRMF. Extensive experiments on real data sets show that RRMF can achieve state-of-the-art performance.

#index 1305470
#* Boosting constrained mutual subspace method for robust image-set based object recognition
#@ Xi Li;Kazuhiro Fukui;Nanning Zheng
#t 2009
#c 11
#% 458001
#% 593505
#% 732522
#% 734914
#% 778279
#% 884029
#% 940372
#% 1274872
#% 1685173
#! Object recognition using image-set or video sequence as input tends to be more robust since image-set or video sequence provides much more information than single snap-shot about the variability in the appearance of the target subject. Constrained Mutual Subspace Method (CMSM) is one of the state-of-the-art algorithms for imageset based object recognition by first projecting the image-set patterns onto the so-called generalized difference subspace then classifying based on the principal angle based mutual subspace distance. By treating the subspace bases for each image-set patterns as basic elements in the grassmann manifold, this paper presents a framework for robust image-set based recognition by CMSM-based ensemble learning in a boosting way. The proposed Boosting Constrained Mutual Subspace Method(BCMSM) improves the original CMSM in the following ways: a) The proposed BCMSM algorithm is insensitive to the dimension of the generalized differnce subspace while the performance of the original CMSM algorithm is quite dependent on the dimension and the selecting of optimum choice is quite empirical and case-dependent; b) By taking advantage of both boosting and CMSM techniques, the generalization ability is improved and much higher classification performance can be achieved. Extensive experiments on real-life data sets (two face recognition tasks and one 3D object category classification task) show that the proposed method outperforms the previous state-of-the-art algorithms greatly in terms of classification accuracy.

#index 1305471
#* Probabilistic models for concurrent chatting activity recognition
#@ Chia-Chun Lian;Jane Yung-jen Hsu
#t 2009
#c 11
#% 335067
#% 464434
#% 580307
#% 592062
#% 716706
#% 828825
#% 863022
#% 876066
#% 961269
#% 1275039
#% 1815596
#! Recognition of chatting activities in social interactions is useful for constructing human social networks. However, the existence of multiple people involved in multiple dialogues presents special challenges. To model the conversational dynamics of concurrent chatting behaviors, this paper advocates Factorial Conditional Random Fields (FCRFs) as a model to accommodate co-temporal relationships among multiple activity states. In addition, to avoid the use of inefficient Loopy Belief Propagation (LBP) algorithm, we propose using Iterative Classification Algorithm (ICA) as the inference method for FCRFs. We designed experiments to compare our FCRFs model with two dynamic probabilistic models, Parallel Condition Random Fields (PCRFs) and Hidden Markov Models (HMMs), in learning and decoding based on auditory data. The experimental results show that FCRFs outperform PCRFs and HMM-like models. We also discover that FCRFs using the ICA inference approach not only improves the recognition accuracy but also takes significantly less time than the LBP inference method.

#index 1305472
#* Learning the optimal neighborhood kernel for classification
#@ Jun Liu;Jianhui Chen;Songcan Chen;Jieping Ye
#t 2009
#c 11
#% 425040
#% 757953
#% 763697
#% 770846
#% 832903
#% 876008
#% 894263
#% 961190
#% 989644
#! Kernel methods have been applied successfully in many applications. The kernel matrix plays an important role in kernel-based learning methods, but the "ideal" kernel matrix is usually unknown in practice and needs to be estimated. In this paper, we propose to directly learn the "ideal" kernel matrix (called the optimal neighborhood kernel matrix) from a pre-specified kernel matrix for improved classification performance. We assume that the prespecified kernel matrix generated from the specific application is a noisy observation of the ideal one. The resulting optimal neighborhood kernel matrix is shown to be the summation of the pre-specified kernel matrix and a rank-one matrix. We formulate the problem of learning the optimal neighborhood kernel as a constrained quartic problem, and propose to solve it using two methods: level method and constrained gradient descent. Empirical results on several benchmark data sets demonstrate the efficiency and effectiveness of the proposed algorithms.

#index 1305473
#* Spectral kernel learning for semi-supervised classification
#@ Wei Liu;Buyue Qian;Jingyu Cui;Jianzhuang Liu
#t 2009
#c 11
#% 393059
#% 464615
#% 757953
#% 763697
#% 840938
#% 881474
#% 961218
#% 1455666
#! Typical graph-theoretic approaches for semi-supervised classification infer labels of unlabeled instances with the help of graph Laplacians. Founded on the spectral decomposition of the graph Laplacian, this paper learns a kernel matrix via minimizing the leave-one-out classification error on the labeled instances. To this end, an efficient algorithm is presented based on linear programming, resulting in a transductive spectral kernel. The idea of our algorithm stems from regularization methodology and also has a nice interpretation in terms of spectral clustering. A simple classifier can be readily built upon the learned kernel, which suffices to give prediction for any data point aside from those in the available dataset. Besides this usage, the spectral kernel can be effectively used in tandem with conventional kernel machines such as SVMs. We demonstrate the efficacy of the proposed algorithm through experiments carried out on challenging classification tasks.

#index 1305474
#* Large margin Boltzmann machines
#@ Xu Miao;Rajesh P. N. Rao
#t 2009
#c 11
#% 464434
#% 722816
#% 722909
#% 770763
#% 850430
#% 854636
#% 905168
#% 1073910
#% 1073923
#% 1264133
#% 1815596
#% 1815597
#% 1815753
#! Boltzmann Machines are a powerful class of undirected graphical models. Originally proposed as artificial neural networks, they can be regarded as a type of Markov Random Field in which the connection weights between nodes are symmetric and learned from data. They are also closely related to recent models such as Markov logic networks and Conditional Random Fields. A major challenge for Boltzmann machines (as well as other graphical models) is speeding up learning for large-scale problems. The heart of the problem lies in efficiently and effectively approximating the partition function. In this paper, we propose a new efficient learning algorithm for Boltzmann machines that allows them to be applied to problems with large numbers of random variables. We introduce a new large-margin variational approximation to the partition function that allows Boltzmann machines to be trained using a support vector machine (SVM) style learning algorithm. For discriminative learning tasks, these large margin Boltzmann machines provide an alternative approach to structural SVMs. We show that these machines have low sample complexity and derive a generalization bound. Our results demonstrate that on multilabel classification problems, large margin Boltzmann machines achieve orders of magnitude faster performance than structural SVMs and also outperform structural SVMs on problems with large numbers of labels.

#index 1305475
#* Transfer learning from minimal target data by mapping across relational domains
#@ Lilyana Mihalkova;Raymond J. Mooney
#t 2009
#c 11
#% 568785
#% 840890
#% 850430
#% 876034
#% 983882
#% 1000502
#% 1250579
#% 1269766
#% 1415877
#! A central goal of transfer learning is to enable learning when training data from the domain of interest is limited. Yet, work on transfer across relational domains has so far focused on the case where there is a significant amount of target data. This paper bridges this gap by studying transfer when the amount of target data is minimal and consists of information about just a handful of entities. In the extreme case, only a single entity is known. We present the SR2LR algorithm that finds an effective mapping of predicates from a source model to the target domain in this setting and thus renders pre-existing knowledge useful to the target task. We demonstrate SR2LR's effectiveness in three benchmark relational domains on social interactions and study its behavior as information about an increasing number of entities becomes available.

#index 1305476
#* Semi-supervised learning of visual classifiers from web images and text
#@ Nicholas Morsillo;Christopher Pal;Randal Nelson
#t 2009
#c 11
#% 316148
#% 635689
#% 722904
#% 836904
#% 883830
#% 884041
#% 989599
#% 1250575
#% 1667698
#% 1857498
#! The web holds tremendous potential as a source of training data for visual classification. However, web images must be correctly indexed and labeled before this potential can be realized. Accordingly, there has been considerable recent interest in collecting imagery from the web using image search engines to build databases for object and scene recognition research. While search engines can provide rough sets of image data, results are noisy and this leads to problems when training classifiers. In this paper we propose a semi-supervised model for automatically collecting clean example imagery from the web. Our approach includes both visual and textual web data in a unified framework. Minimal supervision is enabled by the selective use of generative and discriminative elements in a probabilistic model and a novel learning algorithm. We show through experiments that our model discovers good training images from the web with minimal manual work. Classifiers trained using our method significantly outperform analogous baseline approaches on the Caltech-256 dataset.

#index 1305477
#* Autonomously learning an action hierarchy using a learned qualitative state representation
#@ Jonathan Mugan;Benjamin Kuipers
#t 2009
#c 11
#% 100336
#% 286423
#% 384911
#% 464303
#% 466066
#% 642923
#% 840937
#% 875977
#% 961214
#% 1269772
#% 1272161
#% 1290041
#! There has been intense interest in hierarchical reinforcement learning as a way to make Markov decision process planning more tractable, but there has been relatively little work on autonomously learning the hierarchy, especially in continuous domains. In this paper we present a method for learning a hierarchy of actions in a continuous environment. Our approach is to learn a qualitative representation of the continuous environment and then to define actions to reach qualitative states. Our method learns one or more options to perform each action. Each option is learned by first learning a dynamic Bayesian network (DBN). We approach this problem from a developmental robotics perspective. The agent receives no extrinsic reward and has no external direction for what to learn. We evaluate our work using a simulation with realistic physics that consists of a robot playing with blocks at a table.

#index 1305478
#* Spectral embedded clustering
#@ Feiping Nie;Dong Xu;Ivor W. Tsang;Changshui Zhang
#t 2009
#c 11
#% 36672
#% 313959
#% 629648
#% 724227
#% 766434
#% 829010
#% 837604
#% 875975
#% 983869
#% 983940
#% 983944
#% 1269774
#! In this paper, we propose a new spectral clustering method, referred to as Spectral Embedded Clustering (SEC), to minimize the normalized cut criterion in spectral clustering as well as control the mismatch between the cluster assignment matrix and the low dimensional embedded representation of the data. SEC is based on the observation that the cluster assignment matrix of high dimensional data can be represented by a low dimensional linear mapping of data. We also discover the connection between SEC and other clustering methods, such as spectral clustering, Clustering with local and global regularization, K-means and Discriminative K-means. The experiments on many real-world data sets show that SEC significantly out-performs the existing spectral clustering methods as well as K-means clustering related methods.

#index 1305479
#* Domain adaptation via transfer component analysis
#@ Sinno Jialin Pan;Ivor W. Tsang;James T. Kwok;Qiang Yang
#t 2009
#c 11
#% 266426
#% 311027
#% 652071
#% 722798
#% 906248
#% 939332
#% 1034531
#% 1073879
#% 1261539
#% 1270196
#! Domain adaptation solves a learning problem in a target domain by utilizing the training data in a different but related source domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a Reproducing Kernel Hilbert Space (RKHS) using Maximum Mean Discrepancy (MMD). In the subspace spanned by these transfer components, data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. The main contribution of our work is that we propose a novel feature representation in which to perform domain adaptation via a new parametric kernel using feature extraction methods, which can dramatically minimize the distance between domain distributions by projecting data onto the learned transfer components. Furthermore, our approach can handle large datsets and naturally lead to out-of-sample generalization. The effectiveness and efficiency of our approach in are verified by experiments on two real-world applications: cross-domain indoor WiFi localization and cross-domain text classification.

#index 1305480
#* Semi-supervised classification using sparse Gaussian process regression
#@ Amrish Patel;S. Sundararajan;Shirish Shevade
#t 2009
#c 11
#% 304876
#% 891549
#% 983944
#% 1274924
#% 1711511
#! Gaussian Processes (GPs) are promising Bayesian methods for classification and regression problems. They have also been used for semi-supervised learning tasks. In this paper, we propose a new algorithm for solving semi-supervised binary classification problem using sparse GP regression (GPR) models. It is closely related to semi-supervised learning based on support vector regression (SVR) and maximum margin clustering. The proposed algorithm is simple and easy to implement. It gives a sparse solution directly unlike the SVR based algorithm. Also, the hyperparameters are estimated easily without resorting to expensive cross-validation technique. Use of sparse GPR model helps in making the proposed algorithm scalable. Preliminary results on synthetic and real-world data sets demonstrate the efficacy of the new algorithm.

#index 1305481
#* Expanding domain sentiment lexicon through double propagation
#@ Guang Qiu;Bing Liu;Jiajun Bu;Chun Chen
#t 2009
#c 11
#% 464434
#% 529193
#% 722308
#% 746885
#% 769892
#% 815915
#% 838521
#% 854646
#% 855282
#% 939348
#% 939848
#% 1261566
#% 1275184
#! In most sentiment analysis applications, the sentiment lexicon plays a key role. However, it is hard, if not impossible, to collect and maintain a universal sentiment lexicon for all application domains because different words may be used in different domains. The main existing technique extracts such sentiment words from a large domain corpus based on different conjunctions and the idea of sentiment coherency in a sentence. In this paper, we propose a novel propagation approach that exploits the relations between sentiment words and topics or product features that the sentiment words modify, and also sentiment words and product features themselves to extract new sentiment words. As the method propagates information through both sentiment words and features, we call it double propagation. The extraction rules are designed based on relations described in dependency trees. A new method is also proposed to assign polarities to newly discovered sentiment words in a domain. Experimental results show that our approach is able to extract a large number of new sentiment words. The polarity assignment method is also effective.

#index 1305482
#* Goal-driven learning in the GILA integrated intelligence architecture
#@ Jainarayan Radhakrishnan;Santiago Ontañón;Ashwin Ram
#t 2009
#c 11
#% 108741
#% 176887
#% 286419
#% 376266
#% 490454
#% 1275004
#! Goal Driven Learning (GDL) focuses on systems that determine by themselves what has to be learnt and how to learn it. Typically GDL systems use meta-reasoning capabilities over a base reasoner, identifying learning goals and devising strategies. In this paper we present a novel GDL technique to deal with complex AI systems where the meta-reasoning module has to analyze the reasoning trace of multiple components with potentially different learning paradigms. Our approach works by distributing the generation of learning strategies among the different modules instead of centralizing it in the meta-reasoner. We implemented our technique in the GILA system, that works in the airspace task orders domain, showing an increase in performance.

#index 1305483
#* Streamed learning: one-pass SVMs
#@ Piyush Rai;Hal Daumé;Suresh Venkatasubramanian
#t 2009
#c 11
#% 269218
#% 309208
#% 578388
#% 729940
#% 757953
#% 766228
#% 770754
#% 803575
#% 894646
#% 916781
#% 983905
#% 983918
#% 1073905
#% 1274887
#! We present a streaming model for large-scale classification (in the context of l2-SVM) by leveraging connections between learning and computational geometry. The streaming model imposes the constraint that only a single pass over the data is allowed. The l2-SVM is known to have an equivalent formulation in terms of the minimum enclosing ball (MEB) problem, and an efficient algorithm based on the idea of core sets exists (CVM) [Tsang et al., 2005]. CVM learns a (1+Ɛ)-approximate MEB for a set of points and yields an approximate solution to corresponding SVM instance. However CVM works in batch mode requiring multiple passes over the data. This paper presents a single-pass SVM which is based on the minimum enclosing ball of streaming data. We show that the MEB updates for the streaming case can be easily adapted to learn the SVM weight vector in a way similar to using online stochastic gradient updates. Our algorithm performs polylogarithmic computation at each example, and requires very small and constant storage. Experimental results show that, even in such restrictive settings, we can learn efficiently in just one pass and get accuracies comparable to other state-of-the-art SVM solvers (batch and online). We also give an analysis of the algorithm, and discuss some open issues and possible extensions.

#index 1305484
#* Semi-supervised metric learning using pairwise constraints
#@ Mahdieh Soleymani Baghshah;Saeed Bagheri Shouraki
#t 2009
#c 11
#% 209623
#% 464608
#% 829025
#% 884027
#% 940128
#% 940258
#% 940276
#% 1038720
#% 1086226
#% 1274937
#% 1279446
#% 1861871
#! Distance metric has an important role in many machine learning algorithms. Recently, metric learning for semi-supervised algorithms has received much attention. For semi-supervised clustering, usually a set of pairwise similarity and dissimilarity constraints is provided as supervisory information. Until now, various metric learning methods utilizing pairwise constraints have been proposed. The existing methods that can consider both positive (must-link) and negative (cannot-link) constraints find linear transformations or equivalently global Mahalanobis metrics. Additionally, they find metrics only according to the data points appearing in constraints (without considering other data points). In this paper, we consider the topological structure of data along with both positive and negative constraints. We propose a kernel-based metric learning method that provides a non-linear transformation. Experimental results on synthetic and real-world data sets show the effectiveness of our metric learning method.

#index 1305485
#* Predictive projections
#@ Nathan Sprague
#t 2009
#c 11
#% 734920
#% 840843
#% 876001
#% 1014677
#% 1073966
#! This paper addresses the problem of learning control policies in very high dimensional state spaces. We propose a linear dimensionality reduction algorithm that discovers predictive projections: projections in which accurate predictions of future states can be made using simple nearest neighbor style learning. The goal of this work is to extend the reach of existing reinforcement learning algorithms to domains where they would otherwise be inapplicable without extensive engineering of features. The approach is demonstrated on a synthetic pendulum balancing domain, as well as on a robot domain requiring visually guided control.

#index 1305486
#* On the equivalence between canonical correlation analysis and orthonormalized partial least squares
#@ Liang Sun;Shuiwang Ji;Shipeng Yu;Jieping Ye
#t 2009
#c 11
#% 393059
#% 722887
#% 743284
#% 855563
#% 1074000
#% 1742155
#! Canonical correlation analysis (CCA) and partial least squares (PLS) are well-known techniques for feature extraction from two sets of multi-dimensional variables. The fundamental difference between CCA and PLS is that CCA maximizes the correlation while PLS maximizes the covariance. Although both CCA and PLS have been applied successfully in various applications, the intrinsic relationship between them remains unclear. In this paper, we attempt to address this issue by showing the equivalence relationship between CCA and orthonormalized partial least squares (OPLS), a variant of PLS. We further extend the equivalence relationship to the case when regularization is employed for both sets of variables. In addition, we show that the CCA projection for one set of variables is independent of the regularization on the other set of variables. We have performed experimental studies using both synthetic and real data sets and our results confirm the established equivalence relationship. The presented analysis provides novel insights into the connection between these two existing algorithms as well as the effect of the regularization.

#index 1305487
#* Latent variable perceptron algorithm for structured classification
#@ Xu Sun;Takuya Matsuzaki;Daisuke Okanohara;Jun'ichi Tsujii
#t 2009
#c 11
#% 274189
#% 302390
#% 816081
#% 816181
#% 853697
#% 854636
#% 939559
#% 1223727
#% 1223731
#% 1223735
#% 1251691
#! We propose a perceptron-style algorithm for fast discriminative training of structured latent variable model, and analyzed its convergence properties. Our method extends the perceptron algorithm for the learning task with latent dependencies, which may not be captured by traditional models. It relies on Viterbi decoding over latent variables, combined with simple additive updates. Compared to existing probabilistic models of latent variables, our method lowers the training cost significantly yet with comparable or even superior classification accuracy.

#index 1305488
#* Succinct approximate counting of skewed data
#@ David Talbot
#t 2009
#c 11
#% 190611
#% 214073
#% 320240
#% 322884
#% 600478
#% 654461
#% 816392
#! Practical data analysis relies on the ability to count observations of objects succinctly and efficiently. Unfortunately the space usage of an exact estimator grows with the size of the a priori set from which objects are drawn while the time required to maintain such an estimator grows with the size of the data set. We present static and on-line approximation schemes that avoid these limitations when approximate frequency estimates are acceptable. Our Log-Frequency Sketch extends the approximate counting algorithm of Morris [1978] to estimate frequencies with bounded relative error via a single pass over a data set. It uses constant space per object when the frequencies follow a power law and can be maintained in constant time per observation. We give an (ε, δ)-approximation scheme which we verify empirically on a large natural language data set where, for instance, 95 percent of frequencies are estimated with relative error less than 0.25 using fewer than 11 bits per object in the static case and 15 bits per object on-line.

#index 1305489
#* Maintaining predictions over time without a model
#@ Erik Talvitie;Satinder Singh
#t 2009
#c 11
#% 528325
#% 707796
#% 875961
#% 875996
#% 1350944
#! A common approach to the control problem in partially observable environments is to perform a direct search in policy space, as defined over some set of features of history. In this paper we consider predictive features, whose values are conditional probabilities of future events, given history. Since predictive features provide direct information about the agent's future, they have a number of advantages for control. However, unlike more typical features defined directly over past observations, it is not clear how to maintain the values of predictive features over time. A model could be used, since a model can make any prediction about the future, but in many cases learning a model is infeasible. In this paper we demonstrate that in some cases it is possible to learn to maintain the values of a set of predictive features even when a learning a model is infeasible, and that natural predictive features can be useful for policy-search methods.

#index 1305490
#* On multiple kernel learning with multiple labels
#@ Lei Tang;Jianhui Chen;Jieping Ye
#t 2009
#c 11
#% 763697
#% 763699
#% 770846
#% 770848
#% 833012
#% 961190
#% 983901
#% 983953
#! For classification with multiple labels, a common approach is to learn a classifier for each label. With a kernel-based classifier, there are two options to set up kernels: select a specific kernel for each label or the same kernel for all labels. In this work, we present a unified framework for multi-label multiple kernel learning, in which the above two approaches can be considered as two extreme cases. Moreover, our framework allows the kernels shared partially among multiple labels, enabling flexible degrees of label commonality. We systematically study how the sharing of kernels among multiple labels affects the performance based on extensive experiments on various benchmark data including images and microarray data. Interesting findings concerning efficacy and efficiency are reported.

#index 1305491
#* Toward unsupervised activity discovery using multi-dimensional motif detection in time series
#@ Alireza Vahdatpour;Navid Amini;Majid Sarrafzadeh
#t 2009
#c 11
#% 328321
#% 662750
#% 729960
#% 799397
#% 989656
#% 1117067
#% 1132586
#% 1180749
#% 1275205
#% 1778807
#! This paper addresses the problem of activity and event discovery in multi dimensional time series data by proposing a novel method for locating multi dimensional motifs in time series. While recent work has been done in finding single dimensional and multi dimensional motifs in time series, we address motifs in general case, where the elements of multi dimensional motifs have temporal, length, and frequency variations. The proposed method is validated by synthetic data, and empirical evaluation has been done on several wearable systems that are used by real subjects.

#index 1305492
#* Multi-class classifiers and their underlying shared structure
#@ Volkan Vural;Glenn Fung;Romer Rosales;Jennifer G. Dy
#t 2009
#c 11
#% 283859
#% 342598
#% 722756
#% 722816
#% 735256
#% 770831
#% 829043
#% 983806
#% 983815
#! Multi-class problems have a richer structure than binary classification problems. Thus, they can potentially improve their performance by exploiting the relationship among class labels. While for the purposes of providing an automated classification result this class structure does not need to be explicitly unveiled, for human level analysis or interpretation this is valuable. We develop a multi-class large margin classifier that extracts and takes advantage of class relationships. We provide a bi-convex formulation that explicitly learns a matrix that captures these class relationships and is decoupled from the feature weights. Our representation can take advantage of the class structure to compress themodel by reducing the number of classifiers employed, maintaining high accuracy even with large compression. In addition, we present an efficient formulation in terms of speed and memory.

#index 1305493
#* Manifold alignment without correspondence
#@ Chang Wang;Sridhar Mahadevan
#t 2009
#c 11
#% 593047
#% 1074012
#% 1275191
#% 1305545
#! Manifold alignment has been found to be useful in many areas of machine learning and data mining. In this paper we introduce a novel manifold alignment approach, which differs from "semi-supervised alignment" and "Procrustes alignment" in that it does not require predetermining correspondences. Our approach learns a projection that maps data instances (from two different spaces) to a lower dimensional space simultaneously matching the local geometry and preserving the neighborhood relationship within each set. This approach also builds connections between spaces defined by different features and makes direct knowledge transfer possible. The performance of our algorithm is demonstrated and validated in a series of carefully designed experiments in information retrieval and bioinformatics.

#index 1305494
#* Generalized cluster aggregation
#@ Fei Wang;Xin Wang;Tao Li
#t 2009
#c 11
#% 209021
#% 252836
#% 722902
#% 724227
#% 744117
#% 765518
#% 769881
#% 770836
#% 879689
#% 1085668
#% 1117063
#! Clustering aggregation has emerged as an important extension of the classical clustering problem. It refers to the situation in which a number of different (input) clusterings have been obtained for a particular data set and it is desired to aggregate those clustering results to get a better clustering solution. In this paper, we propose a unified framework to solve the clustering aggregation problem, where the aggregated clustering result is obtained by minimizing the (weighted) sum of the Bregman divergence between it and all the input clusterings. Moreover, under our algorithm framework, we also propose a novel cluster aggregation problem where some must-link and cannot-link constraints are given in addition to the input clusterings. Finally the experimental results on some real world data sets are presented to show the effectiveness of our method.

#index 1305495
#* Preference learning with extreme examples
#@ Fei Wang;Bin Zhang;Ta-Hsin Li;Wen Jun Yin;Jin Dong;Tao Li
#t 2009
#c 11
#% 528330
#% 643029
#% 766456
#% 823360
#% 829028
#% 840852
#% 842682
#% 881457
#% 902508
#% 959870
#% 961218
#% 987228
#% 1455666
#! In this paper, we consider a general problem of semi-supervised preference learning, in which we assume that we have the information of the extreme cases and some ordered constraints, our goal is to learn the unknown preferences of the other places. Taking the potential housing place selection problem as an example, we have many candidate places together with their associated information (e.g., position, environment), and we know some extreme examples (i.e. several places are perfect for building a house, and several places are the worst that cannot build a house there), and we know some partially ordered constraints (i.e. for two places, which place is better), then how can we judge the preference of one potential place whose preference is unknown beforehand? We propose a Bayesian framework based on Gaussian process to tackle this problem, from which we not only solve for the unknown preferences, but also the hyperparameters contained in our model.

#index 1305496
#* Knowledge transfer on hybrid graph
#@ Zheng Wang;Yangqiu Song;Changshui Zhang
#t 2009
#c 11
#% 236497
#% 313959
#% 329562
#% 342621
#% 466263
#% 724227
#% 729918
#% 826918
#% 876018
#% 961218
#% 989592
#% 989618
#% 1074038
#% 1083678
#% 1279294
#! In machine learning problems, labeled data are often in short supply. One of the feasible solution for this problem is transfer learning. It can make use of the labeled data from other domain to discriminate those unlabeled data in the target domain. In this paper, we propose a transfer learning framework based on similarity matrix approximation to tackle such problems. Two practical algorithms are proposed, which are the label propagation and the similarity propagation. In these methods, we build a hybrid graph based on all available data. Then the information is transferred cross domains through alternatively constructing the similarity matrix for different part of the graph. Among all related methods, similarity propagation approach can make maximum use of all available similarity information across domains. This leads to more efficient transfer and better learning result. The experiment on real world text mining applications demonstrates the promise and effectiveness of our algorithms.

#index 1305497
#* Early prediction on time series: a nearest neighbor approach
#@ Zhengzheng Xing;Jian Pei;Philip S. Yu
#t 2009
#c 11
#% 280488
#% 577221
#% 737337
#% 876074
#% 881545
#% 1673559
#! In this paper, we formulate the problem of early classification of time series data, which is important in some time-sensitive applications such as health-informatics. We introduce a novel concept of MPL (Minimum Prediction Length) and develop ECTS (Early Classification on Time Series), an effective 1-nearest neighbor classification method. ECTS makes early predictions and at the same time retains the accuracy comparable to that of a 1NN classifier using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where 1NN classification is effective.

#index 1305498
#* Discriminative semi-supervised feature selection via manifold regularization
#@ Zenglin Xu;Rong Jin;Michael R. Lyu;Irwin King
#t 2009
#c 11
#% 310498
#% 361100
#% 425048
#% 722929
#% 722943
#% 763697
#% 771842
#% 961190
#% 961218
#% 1074378
#% 1411129
#! We consider the problem of semi-supervised feature selection, where we are given a small amount of labeled examples and a large amount of unlabeled examples. Since a small number of labeled samples are usually insufficient for identifying the relevant features, the critical problem arising from semi-supervised feature selection is how to take advantage of the information underneath the unlabeled data. To address this problem, we propose a novel discriminative semi-supervised feature selection method based on the idea of manifold regularization. The proposed method selects features through maximizing the classification margin between different classes and simultaneously exploiting the geometry of the probability distribution that generates both labeled and unlabeled data. We formulate the proposed feature selection method into a convex-concave optimization problem, where the saddle point corresponds to the optimal solution. To find the optimal solution, the level method, a fairly recent optimization method, is employed. We also present a theoretic proof of the convergence rate for the application of the level method to our problem. Empirical evaluation on several benchmark data sets demonstrates the effectiveness of the proposed semi-supervised feature selection method.

#index 1305499
#* Multi-relational learning with Gaussian processes
#@ Zhao Xu;Kristian Kersting;Volker Tresp
#t 2009
#c 11
#% 314933
#% 715096
#% 891549
#% 916787
#% 923861
#% 1000502
#% 1074083
#% 1083696
#% 1250567
#! Due to their flexible nonparametric nature, Gaussian process models are very effective at solving hard machine learning problems. While existing Gaussian process models focus on modeling one single relation, we present a generalized GP model, named multi-relational Gaussian process model, that is able to deal with an arbitrary number of relations in a domain of interest. The proposed model is analyzed in the context of bipartite, directed, and undirected univariate relations. Experimental results on real-world datasets show that exploiting the correlations among different entity types and relations can indeed improve prediction performance.

#index 1305500
#* Transfer learning using task-level features with application to information retrieval
#@ Rong Yan;Jian Zhang
#t 2009
#c 11
#% 236497
#% 267027
#% 466750
#% 723239
#% 780805
#% 829014
#% 840962
#% 961246
#% 1389537
#! We propose a probabilistic transfer learning model that uses task-level features to control the task mixture selection in a hierarchical Bayesian model. These task-level features, although rarely used in existing approaches, can provide additional information to model complex task distributions and allow effective transfer to new tasks especially when only limited number of data are available. To estimate the model parameters, we develop an empirical Bayes method based on variational approximation techniques. Our experiments on information retrieval show that the proposed model achieves significantly better performance compared with other transfer learning methods.

#index 1305501
#* Spatio-temporal event detection using dynamic conditional random fields
#@ Jie Yin;Derek Hao Hu;Qiang Yang
#t 2009
#c 11
#% 464434
#% 770844
#% 824715
#% 836906
#% 837279
#% 874982
#% 981606
#% 1394366
#% 1410618
#% 1758321
#! Event detection is a critical task in sensor networks for a variety of real-world applications. Many real-world events often exhibit complex spatio-temporal patterns whereby they manifest themselves via observations over time and space proximities. These spatio-temporal events cannot be handled well by many of the previous approaches. In this paper, we propose a new Spatio-Temporal Event Detection (STED) algorithm in sensor networks based on a dynamic conditional random field (DCRF) model. Our STED method handles the uncertainty of sensor data explicitly and permits neighborhood interactions in both observations and event labels. Experiments on both real data and synthetic data demonstrate that our STED method can provide accurate event detection in near real time even for large-scale sensor networks.

#index 1305502
#* Robust distance metric learning with auxiliary knowledge
#@ Zheng-Jun Zha;Tao Mei;Meng Wang;Zengfu Wang;Xian-Sheng Hua
#t 2009
#c 11
#% 235342
#% 336073
#% 732522
#% 829025
#% 884027
#% 983812
#% 983830
#% 1270183
#% 1270196
#% 1270222
#% 1274925
#% 1274937
#! Most of the existing metric learning methods are accomplished by exploiting pairwise constraints over the labeled data and frequently suffer from the insufficiency of training examples. To learn a robust distance metric from few labeled examples, prior knowledge from unlabeled examples as well as the metrics previously derived from auxiliary data sets can be useful. In this paper, we propose to leverage such auxiliary knowledge to assist distance metric learning, which is formulated following the regularized loss minimization principle. Two algorithms are derived on the basis of manifold regularization and log-determinant divergence regularization technique, respectively, which can simultaneously exploit label information (i.e., the pairwise constraints over labeled data), unlabeled examples, and the metrics derived from auxiliary data sets. The proposed methods directly manipulate the auxiliary metrics and require no raw examples from the auxiliary data sets, which make them efficient and flexible. We conduct extensive evaluations to compare our approaches with a number of competing approaches on face recognition task. The experimental results show that our approaches can derive reliable distance metrics from limited training examples and thus are superior in terms of accuracy and labeling efforts.

#index 1305503
#* Fast active tabu search and its application to image retrieval
#@ Chao Zhang;Hongyu Li;Qiyong Guo;Jinyuan Jia;I-Fan Shen
#t 2009
#c 11
#% 11720
#% 780689
#% 905155
#% 987346
#% 996148
#% 1119135
#! This paper proposes a novel framework for image retrieval. The retrieval is treated as searching for an ordered cycle in an image database. The optimal cycle can be found by minimizing the geometric manifold entropy of images. The minimization is solved by the proposed method, fast active tabu search. Experimental results demonstrate the framework for image retrieval is feasible and quite promising.

#index 1305504
#* M3IC: maximum margin multiple instance clustering
#@ Dan Zhang;Fei Wang;Luo Si;Tao Li
#t 2009
#c 11
#% 36672
#% 565537
#% 876033
#% 881477
#% 1074028
#% 1225272
#! Clustering, classification, and regression, are three major research topics in machine learning. So far, much work has been conducted in solving multiple instance classification and multiple instance regression problems, where supervised training patterns are given as bags and each bag consists of some instances. But the research on unsupervised multiple instance clustering is still limited. This paper formulates a novel Maximum Margin Multiple Instance Clustering (M3IC) problem for the multiple instance clustering task. To avoid solving a nonconvex optimization problem directly, M3IC is further relaxed, which enables an efficient optimization solution with a combination of Constrained Concave-Convex Procedure (CCCP) and the Cutting Plane method. Furthermore, this paper analyzes some important properties of the proposed method and the relationship between the proposed method and some other related ones. An extensive set of empirical results demonstrate the advantages of the proposed method against existing research for both effectiveness and efficiency.

#index 1305505
#* An efficient nonnegative matrix factorization approach in flexible kernel space
#@ Daoqiang Zhang;Wanquan Liu
#t 2009
#c 11
#% 743284
#% 793248
#% 848114
#% 995168
#% 1387650
#% 1861693
#% 1862143
#! In this paper, we propose a general formulation for kernel nonnegative matrix factorization with flexible kernels. Specifically, we propose the Gaussian nonnegative matrix factorization (GNMF) algorithm by using the Gaussian kernel in the framework. Different from a recently developed polynomial NMF (PNMF), GNMF finds basis vectors in the kernel-induced feature space and the computational cost is independent of input dimensions. Furthermore, we prove the convergence and nonnegativity of decomposition of our method. Extensive experiments compared with PNMF and other NMF algorithms on several face databases, validate the effectiveness of the proposed method.

#index 1305506
#* Smart PCA
#@ Yi Zhang
#t 2009
#c 11
#% 272536
#% 304879
#% 983857
#! PCA can be smarter and makes more sensible projections. In this paper, we propose smart PCA, an extension to standard PCA to regularize and incorporate external knowledge into model estimation. Based on the probabilistic interpretation of PCA, the inverse Wishart distribution can be used as the informative conjugate prior for the population covariance, and useful knowledge is carried by the prior hyperparameters. We design the hyperparameters to smoothly combine the information from both the domain knowledge and the data itself. The Bayesian point estimation of principal components is in closed form. In empirical studies, smart PCA shows clear improvement on three different criteria: image reconstruction errors, the perceptual quality of the reconstructed images, and the pattern recognition performance.

#index 1305507
#* Non-metric label propagation
#@ Yin Zhang;Zhi-Hua Zhou
#t 2009
#c 11
#% 284557
#% 304899
#% 316780
#% 464615
#% 640416
#% 722813
#% 732531
#% 732546
#% 771840
#% 839915
#% 883842
#% 983949
#% 1275195
#% 1296836
#! In many applications non-metric distances are better than metric distances in reflecting the perceptual distances of human beings. Previous studies on non-metric distances mainly focused on supervised setting and did not consider the usefulness of unlabeled data. In this paper, we present probably the first study of label propagation on graphs induced from non-metric distances. The challenge here lies in the fact that the triangular inequality does not hold for non-metric distances and therefore, a direct application of existing label propagation methods will lead to inconsistency and conflict. We show that by applying spectrum transformation, non-metric distances can be converted into metric ones, and thus label propagation can be executed. Such methods, however, suffer from the change of original semantic relations. As a main result of this paper, we prove that any nonmetric distance matrix can be decomposed into two metric distance matrices containing different information of the data. Based on this recognition, our proposed NMLP method derives two graphs from the original non-metric distance and performs a joint label propagation on the joint graph. Experiments validate the effectiveness of the proposed NMLP method.

#index 1305508
#* Multiclass probabilistic kernel discriminant analysis
#@ Zheng Zhao;Liang Sun;Shipeng Yu;Huan Liu;Jieping Ye
#t 2009
#c 11
#% 190581
#% 235342
#% 299012
#% 581716
#% 763697
#% 857421
#% 891549
#% 961149
#% 983940
#% 1074363
#% 1377410
#% 1667701
#! Kernel discriminant analysis (KDA) is an effective approach for supervised nonlinear dimensionality reduction. Probabilistic models can be used with KDA to improve its robustness. However, the state of the art of such models could only handle binary class problems, which confines their application in many real world problems. To overcome this limitation, we propose a novel nonparametric probabilistic model based on Gaussian Process for KDA to handle multiclass problems. The model provides a novel Bayesian interpretation for KDA, which allows its parameters to be automatically tuned through the optimization of the marginal log-likelihood of the data. Empirical study demonstrates the efficacy of the proposed model.

#index 1305509
#* Multiple information sources cooperative learning
#@ Xingquan Zhu;Ruoming Jin
#t 2009
#c 11
#% 136350
#% 236497
#% 252011
#% 267036
#% 314740
#% 577258
#% 729437
#% 926881
#% 989596
#% 989618
#% 1117687
#% 1289267
#! Many applications are facing the problem of learning from an objective dataset, whereas information from other auxiliary sources may be beneficial but cannot be integrated into the objective dataset for learning. In this paper, we propose an omni-view learning approach to enable learning from multiple data collections. The theme is to organize heterogeneous data sources into a unified table with global data view. To achieve the omni-view learning goal, we consider that the objective dataset and the auxiliary datasets share some instance-level dependency structures. We then propose a relational k-means to cluster instances in each auxiliary dataset, such that clusters can help build new features to capture correlations between the objective and auxiliary datasets. Experimental results demonstrate that omni-view learning can help build models which outperform the ones learned from the objective dataset only. Comparisons with the co-training algorithm further assert that omni-view learning provides an alternative, yet effective, way for semi-supervised learning.

#index 1305510
#* Analysis of a winning computational billiards player
#@ Christopher Archibald;Alon Altman;Yoav Shoham
#t 2009
#c 11
#% 85135
#% 348584
#% 367254
#% 1000506
#% 1014783
#% 1198817
#! We discuss CUECARD, the program that won the 2008 Computer Olympiad computational pool tournament. Beside addressing intrinsic interest in a complex competitive environment with unique features, our goal is to isolate the factors that contributed to the performance so that the lessons can be transferred to other, similar domains. Specifically, we distinguish among pure engineering factors (such as using a computer cluster), domain-specific factors (such as optimized break shots), and domain-independent factors (such as state clustering). Our conclusion is that each type of factor contributed to the performance of the program.

#index 1305511
#* Generalized clustergrams for overlapping biclusters
#@ Liviu Badea
#t 2009
#c 11
#% 400277
#% 469422
#% 906484
#% 1275179
#% 1699576
#! Many real-life datasets, such as those produced by gene expression studies, exhibit complex substructures at various levels of granularity and thus do not have unique well-defined numbers of clusters. In such cases, it is important to be able to trace the evolution of the individual clusters as the number of dimensions of the clustering is varied. While the dendrograms produced by bottom-up clustering methods such as hierarchical clustering are very useful for this purpose, the approach is known to produce unreliable clusters due to its instability w.r.t. resampling. Moreover, hierarchical clustering does not apply to overlapping (bi)clusters, such as those obtained in gene expression studies. On the other hand, the instability w.r.t. the initialization of top-down methods, such as k-means, prevents the comparison between clusters obtained at different dimensionalities. In this paper, we present a method for constructing generalized dendrograms for overlapping biclusters, which depict the evolution of the biclusters as their number is varied. An essential ingredient is a stable biclustering method based on positive tensor factorization of a number of nonnegative matrix factorization runs. We apply our approach to a large colon cancer dataset, which shows several distinct subclasses whose dimensional evolution must be carefully analyzed to enable a more meaningful biological interpretation and sub-classification.

#index 1305512
#* Semi-supervised regression for evaluating convenience store location
#@ Xinxin Bai;Gang Chen;Qiming Tian;Wenjun Yin;Jin Dong
#t 2009
#c 11
#% 190581
#% 393059
#% 448023
#% 458379
#% 1119062
#! Location plays a very important role in the retail business due to its huge and long-term investment. In this paper, we propose a novel semisupervised regression model for evaluating convenience store location based on spatial data analysis. First, the input features for each convenience store can be extracted by analyzing the elements around it based on a geographic information system, and the turnover is used to evaluate its performance. Second, considering the practical application scenario, a manifold regularization model with one semi-supervised performance information constraint is provided. The promising experimental results in the real-world dataset demonstrate the effectiveness of the proposed approach in performance prediction of certain candidate locations for new convenience store opening.

#index 1305513
#* Using entropy to distinguish shape versus text in hand-drawn diagrams
#@ Akshay Bhat;Tracy Hammond
#t 2009
#c 11
#% 109079
#% 179866
#% 201990
#% 213434
#% 297616
#% 658749
#% 668966
#% 782261
#% 785793
#% 1069974
#% 1270373
#% 1279280
#% 1297972
#% 1910103
#! Most sketch recognition systems are accurate in recognizing either text or shape (graphic) ink strokes, but not both. Distinguishing between shape and text strokes is, therefore, a critical task in recognizing hand-drawn digital ink diagrams that contain text labels and annotations. We have found the 'entropy rate' to be an accurate criterion of classification. We found that the entropy rate is significantly higher for text strokes compared to shape strokes and can serve as a distinguishing factor between the two. Using a single feature -- zero-order entropy rate -- our system produced a correct classification rate of 92.06% on test data belonging to diagrammatic domain for which the threshold was trained on. It also performed favorably on an unseen domain for which no training examples were supplied.

#index 1305514
#* Combining speech and sketch to interpret unconstrained descriptions of mechanical devices
#@ David Bischel;Thomas Stahovich;Eric Peterson;Randall Davis;Aaron Adler
#t 2009
#c 11
#% 109079
#% 232927
#% 239643
#% 785793
#% 815910
#% 1069968
#% 1069974
#% 1297969
#% 1297974
#% 1471741
#! Mechanical design tools would be considerably more useful if we could interact with them in the way that human designers communicate design ideas to one another, i.e., using crude sketches and informal speech. Those crude sketches frequently contain pen strokes of two different sorts, one type portraying device structure, the other denoting gestures, such as arrows used to indicate motion. We report here on techniques we developed that use information from both sketch and speech to distinguish gesture strokes from non-gestures -- a critical first step in understanding a sketch of a device. We collected and analyzed unconstrained device descriptions, which revealed six common types of gestures. Guided by this knowledge, we developed a classifier that uses both sketch and speech features to distinguish gesture strokes from nongestures. Experiments with our techniques indicate that the sketch and speech modalities alone produce equivalent classification accuracy, but combining them produces higher accuracy.

#index 1305515
#* Improving state evaluation, inference, and search in trick-based card games
#@ Michael Buro;Jeffrey R. Long;Timothy Furtak;Nathan Sturtevant
#t 2009
#c 11
#% 169359
#% 1271963
#% 1274992
#% 1305368
#% 1404139
#% 1404140
#% 1665148
#! Skat is Germany's national card game played by millions of players around the world. In this paper, we present the world's first computer skat player that plays at the level of human experts. This performance is achieved by improving state evaluations using game data produced by human players and by using these state evaluations to perform inference on the unobserved hands of opposing players. Our results demonstrate the gains from adding inference to an imperfect information game player and show that training on data from average human players can result in expert-level playing strength.

#index 1305516
#* Suggesting email view filters for triage and search
#@ Mark Dredze;Bill N. Schilit;Peter Norvig
#t 2009
#c 11
#% 642983
#% 722924
#% 801383
#% 818221
#% 857482
#% 860036
#% 905333
#% 910807
#% 1250379
#% 1351261
#% 1392483
#% 1696323
#! Growing email volumes cause flooded inboxes and swelled email archives, making search and new email processing difficult. While emails have rich metadata, such as recipients and folders, suitable for creating filtered views, it is often difficult to choose appropriate filters for new inbox messages without first examining messages. In this work, we consider a system that automatically suggests relevant view filters to the user for the currently viewed messages. We propose several ranking algorithms for suggesting useful filters. Our work suggests that such systems quickly filter groups of inbox messages and find messages more easily during search.

#index 1305517
#* Sensing and predicting the pulse of the city through shared bicycling
#@ Jon Froehlich;Joachim Neumann;Nuria Oliver
#t 2009
#c 11
#% 729437
#% 987205
#% 1090047
#% 1147435
#! City-wide urban infrastructures are increasingly reliant on network technology to improve and expand their services. As a side effect of this digitalization, large amounts of data can be sensed and analyzed to uncover patterns of human behavior. In this paper, we focus on the digital footprints from one type of emerging urban infrastructure: shared bicycling systems. We provide a spatiotemporal analysis of 13 weeks of bicycle station usage from Barcelona's shared bicycling system, called Bicing. We apply clustering techniques to identify shared behaviors across stations and show how these behaviors relate to location, neighborhood, and time of day. We then compare experimental results from four predictive models of near-term station usage. Finally, we analyze the impact of factors such as time of day and station activity in the prediction capabilities of the algorithms.

#index 1305518
#* Topic tracking model for analyzing consumer purchase behavior
#@ Tomoharu Iwata;Shinji Watanabe;Takeshi Yamada;Naonori Ueda
#t 2009
#c 11
#% 677787
#% 722904
#% 769895
#% 824709
#% 875959
#% 876067
#% 881498
#% 956521
#% 1275221
#% 1650298
#! We propose a new topic model for tracking timevarying consumer purchase behavior, in which consumer interests and item trends change over time. The proposed model can adaptively track changes in interests and trends based on current purchase logs and previously estimated interests and trends. The online nature of the proposed method means we do not need to store past data for current inferences and so we can considerably reduce the computational cost and the memory requirement. We use real purchase logs to demonstrate the effectiveness of the proposed method in terms of the prediction accuracy of purchase behavior and the computational cost of the inference.

#index 1305519
#* Interpreting written how-to instructions
#@ Tessa Lau;Clemens Drews;Jeffrey Nichols
#t 2009
#c 11
#% 571396
#% 734963
#% 801424
#% 848638
#% 854636
#% 860034
#% 894557
#% 955006
#% 1047347
#% 1047498
#% 1269911
#! Written instructions are a common way of teaching people how to accomplish tasks on the web. However, studies have shown that written instructions are difficult to follow, even for experienced users. A system that understands human-written instructions could guide users through the process of following the directions, improving completion rates and enhancing the user experience. While general natural language understanding is extremely difficult, we believe that in the limited domain of howto instructions it should be possible to understand enough to provide guided help in a mixed-initiative environment. Based on a qualitative analysis of instructions gathered for 43 web-based tasks, we have formalized the problem of understanding and interpreting how-to instructions. We compare three different approaches to interpreting instructions: a keyword-based interpreter, a grammar-based interpreter, and an interpreter based on machine learning and information extraction. Our empirical results demonstrate the feasibility of automated how-to instruction understanding.

#index 1305520
#* Is it enough to get the behaviour right?
#@ Hector J. Levesque
#t 2009
#c 11
#% 92733
#% 157686
#% 325050
#% 571698
#% 743359
#% 1274839
#! This paper deals with the relationship between intelligent behaviour, on the one hand, and the mental qualities needed to produce it, on the other. We consider two well-known opposing positions on this issue: one due to Alan Turing and one due to John Searle (via the Chinese Room). In particular, we argue against Searle, showing that his answer to the so-called System Reply does not work. The argument takes a novel form: we shift the debate to a different and more plausible room where the required conversational behaviour is much easier to characterize and to analyze. Despite being much simpler than the Chinese Room, we show that the behaviour there is still complex enough that it cannot be produced without appropriate mental qualities.

#index 1305521
#* Drosophila gene expression pattern annotation through multi-instance multi-label learning
#@ Ying-Xin Li;Shuiwang Ji;Sudhir Kumar;Jieping Ye;Zhi-Hua Zhou
#t 2009
#c 11
#% 311034
#% 464633
#% 669214
#% 760805
#% 824956
#% 950267
#% 1126371
#! The Berkeley Drosophila Genome Project (BDGP) has produced a large number of gene expression patterns, many of which have been annotated textually with anatomical and developmental terms. These terms spatially correspond to local regions of the images; however, they are attached collectively to groups of images, such that it is unknown which term is assigned to which region of which image in the group. This poses a challenge to the development of the computational method to automate the textual description of expression patterns contained in each image. In this paper, we show that the underlying nature of this task matches well with a new machine learning framework, Multi-Instance Multi-Label learning (MIML). We propose a new MIML support vector machine to solve the problems that beset the annotation task. Empirical study shows that the proposed method outperforms the state-of-the-art Drosophila gene expression pattern annotation methods.

#index 1305522
#* Expressive power-based resource allocation for data centers
#@ Benjamin Lubin;Jeffrey O. Kephart;Rajarshi Das;David C. Parkes
#t 2009
#c 11
#% 323504
#% 342368
#% 808533
#% 818584
#% 890392
#% 894342
#% 968294
#! As data-center energy consumption continues to rise, efficient power management is becoming increasingly important. In this work, we examine the use of a novel market mechanism for finding the right balance between power and performance. The market enables a separation between a 'buyer side' that strives to maximize performance and a 'seller side' that strives to minimize power and other costs. A concise and scalable description language is defined for agent preferences that admits a mixedinteger program for computing optimal allocations. Experimental results demonstrate the robustness, flexibility, practicality and scalability of the architecture.

#index 1305523
#* Efficient online learning and prediction of users' desktop actions
#@ Omid Madani;Hung Bui;Eric Yeh
#t 2009
#c 11
#% 272793
#% 466564
#% 529804
#% 722924
#% 790446
#% 817498
#% 848639
#% 848651
#% 1083681
#! We investigate prediction of users' desktop activities in the Unix domain. The learning techniques we explore do not require explicit user teaching. We show that simple efficient many-class learning can perform well for action prediction, significantly improving over previously published results and baselines. This finding is promising for various human-computer interaction scenarios where a rich set of potentially predictive features is available, where there can be many different actions to predict, and where there can be considerable nonstationarity.

#index 1305524
#* A visual approach to sketched symbol recognition
#@ Tom Y. Ouyang;Randall Davis
#t 2009
#c 11
#% 190892
#% 493347
#% 640416
#% 774901
#% 775622
#% 782261
#% 785771
#% 785864
#% 909376
#% 1045304
#% 1269804
#! There is increasing interest in building systems that can automatically interpret hand-drawn sketches. However, many challenges remain in terms of recognition accuracy, robustness to different drawing styles, and ability to generalize across multiple domains. To address these challenges, we propose a new approach to sketched symbol recognition that focuses on the visual appearance of the symbols. This allows us to better handle the range of visual and stroke-level variations found in freehand drawings. We also present a new symbol classifier that is computationally efficient and invariant to rotation and local deformations. We show that our method exceeds state-of-the-art performance on all three domains we evaluated, including handwritten digits, PowerPoint shapes, and electrical circuit symbols.

#index 1305525
#* Towards context aware emotional intelligence in machines: computing contextual appropriateness of affective states
#@ Michal Ptaszynski;Pawel Dybala;Wenhan Shi;Rafal Rzepka;Kenji Araki
#t 2009
#c 11
#% 238395
#% 344556
#% 1155894
#% 1251696
#% 1264757
#! This paper presents a novel approach to the estimation of user's affective states in Human-Computer Interaction. Most of the present approaches divide emotions strictly between positive or negative. However, recent discoveries in the field of Emotional Intelligence show that emotions should be rather perceived as context-sensitive engagements with the world. This leads to a need to specify whether the emotions conveyed in a conversation are appropriate for a situation they are expressed in. In the proposed method we use a system for affect analysis on textual input to recognize users emotions and a Web mining technique to verify the contextual appropriateness of those emotions. On this basis a conversational agent can choose to either sympathize with the user or help them manage their emotions. Finally, the results of evaluation of the proposed method with two different conversational agents are discussed, and perspectives for further development of the method are proposed.

#index 1305526
#* Representation and synthesis of melodic expression
#@ Christopher Raphael
#t 2009
#c 11
#% 207193
#! A method for expressive melody synthesis is presented seeking to capture the prosodic (stress and directional) element of musical interpretation. An expressive performance is represented as a notelevel annotation, classifying each note according to a small alphabet of symbols describing the role of the note within a larger context. An audio performance of the melody is represented in terms of two time-varying functions describing the evolving frequency and intensity. A method is presented that transforms the expressive annotation into the frequency and intensity functions, thus giving the audio performance. The problem of expressive rendering is then cast as estimation of the most likely sequence of hidden variables corresponding to the prosodic annotation. Examples are presented on a dataset of around 50 folk-like melodies, realized both from hand-marked and estimated annotations.

#index 1305527
#* Simultaneous discovery of conservation laws and hidden particles with Smith matrix decomposition
#@ Oliver Schulte
#t 2009
#c 11
#% 24538
#% 178517
#! Particle physics experiments, like the Large Hadron Collider in Geneva, can generate thousands of data points listing detected particle reactions. An important learning task is to analyze the reaction data for evidence of conserved quantities and hidden particles. This task involves latent structure in two ways: first, hypothesizing hidden quantities whose conservation determines which reactions occur, and second, hypothesizing the presence of hidden particles. We model this problem in the classic linear algebra framework of automated scientific discovery due to Valdés-Pérez, Zytkow and Simon, where both reaction data and conservation laws are represented as matrices. We introduce a new criterion for selecting a matrix model for reaction data: find hidden particles and conserved quantities that rule out as many interactions among the nonhidden particles as possible. A polynomial-time algorithm for optimizing this criterion is based on the new theorem that hidden particles are required if and only if the Smith Normal Form of the reaction matrix R contains entries other than 0 or 1. To our knowledge this is the first application of Smith matrix decomposition to a problem in AI. Using data from particle accelerators, we compare our algorithm to the main model of particles in physics, known as the Standard Model: our algorithm discovers conservation laws that are equivalent to those in the Standard Model, and indicates the presence of a hidden particle (the electron antineutrino) in accordance with the Standard Model.

#index 1305528
#* Learning to follow navigational route instructions
#@ Nobuyuki Shimizu;Andrew Haas
#t 2009
#c 11
#% 375503
#% 464434
#% 769884
#% 816181
#% 850007
#% 853697
#% 854636
#% 1215404
#% 1776525
#! We have developed a simulation model that accepts instructions in unconstrained natural language, and then guides a robot to the correct destination. The instructions are segmented on the basis of the actions to be taken, and each segment is labeled with the required action. This flat formulation reduces the problem to a sequential labeling task, to which machine learning methods are applied. We propose an innovative machine learning method for explicitly modeling the actions described in instructions and integrating learning and inference about the physical environment. We obtained a corpus of 840 route instructions that experimenters verified as follow-able, given by people in building navigation situations. Using the four-fold cross validation, our experiments showed that the simulated robot reached the correct destination 88% of the time.

#index 1305529
#* Efficient dominant point algorithms for the multiple longest common subsequence (MLCS) problem
#@ Qingguo Wang;Dmitry Korkin;Yi Shang
#t 2009
#c 11
#% 93316
#% 121230
#% 288976
#% 289101
#% 319601
#% 444539
#% 675379
#% 718261
#% 1117441
#% 1717044
#! Finding the longest common subsequence of multiple strings is a classical computer science problem and has many applications in the areas of bioinformatics and computational genomics. In this paper, we present a new sequential algorithm for the general case of MLCS problem, and its parallel realization. The algorithm is based on the dominant point approach and employs a fast divide-and-conquer technique to compute the dominant points. When applied to find a MLCS of 3 strings, our general algorithm is shown to exhibit the same performance as the best existing MLCS algorithm by Hakata and Imai, designed specifically for the case of 3 strings. Moreover, we show that for a general case of more than 3 strings, the algorithm is significantly faster than the best existing sequential approaches, reaching up to 2-3 orders of magnitude faster on the large-size problems. Finally, we propose a parallel implementation of the algorithm. Evaluating the parallel algorithm on a benchmark set of both random and biological sequences reveals a near-linear speed-up with respect to the sequential algorithm.

#index 1305530
#* Knowledge-based WSD on specific domains: performing better than generic supervised WSD
#@ Eneko Agirre;Oier Lopez De Lacalle;Aitor Soroa
#t 2009
#c 11
#% 268079
#% 348173
#% 747738
#% 817962
#% 853864
#% 939906
#% 1008096
#% 1251588
#% 1260668
#% 1260669
#% 1271271
#% 1275025
#! This paper explores the application of knowledge-based Word Sense Disambiguation systems to specific domains, based on our state-of-the-art graph-based WSD system that uses the information in WordNet. Evaluation was performed over a publicly available domain-specific dataset of 41 words related to Sports and Finance, comprising examples drawn from three corpora: one balanced corpus (BNC), and two domain-specific corpora (news related to Sports and Finance). The results show that in all three corpora our knowledge-based WSD algorithm improves over previous results, and also over two state-of-the-art supervised WSD systems trained on SemCor, the largest publicly available annotated corpus. We also show that using related words as context, instead of the actual occurrence contexts, yields better results on the domain datasets, but not on the general one. Interestingly, the results are higher for domain-specific corpus than for the general corpus, raising prospects for improving current WSD systems when applied to specific domains.

#index 1305531
#* Web-scale N-gram models for lexical disambiguation
#@ Shane Bergsma;Dekang Lin;Randy Goebel
#t 2009
#c 11
#% 266368
#% 278102
#% 461622
#% 748594
#% 770763
#% 786527
#% 815796
#% 817693
#% 958458
#% 1251694
#% 1271260
#% 1299633
#% 1299636
#% 1411896
#! Web-scale data has been used in a diverse range of language research. Most of this research has used web counts for only short, fixed spans of context. We present a unified view of using web counts for lexical disambiguation. Unlike previous approaches, our supervised and unsupervised systems combine information from multiple and overlapping segments of context. On the tasks of preposition selection and context-sensitive spelling correction, the supervised system reduces disambiguation error by 20-24% over the current state-of-the-art.

#index 1305532
#* Explicit versus latent concept models for cross-language information retrieval
#@ Philipp Cimiano;Antje Schultz;Sergej Sizov;Philipp Sorg;Steffen Staab
#t 2009
#c 11
#% 27049
#% 280819
#% 722904
#% 727861
#% 807750
#% 811358
#% 1275012
#% 1415756
#! The field of information retrieval and text manipulation (classification, clustering) still strives for models allowing semantic information to be folded in to improve performance with respect to standard bag-of-word based models. Many approaches aim at a concept-based retrieval, but differ in the nature of the concepts, which range from linguistic concepts as defined in lexical resources such as WordNet, latent topics derived from the data itself - as in Latent Semantic Indexing (LSI) or (Latent Dirichlet Allocation (LDA) - to Wikipedia articles as proxies for concepts, as in the recently proposed Explicit Semantic Analysis (ESA) model. A crucial question which has not been answered so far is whether models based on explicitly given concepts (as in the ESA model for instance) perform inherently better than retrieval models based on "latent" concepts (as in LSI and/or LDA). In this paper we investigate this question closer in the context of a cross-language setting, which inherently requires concept-based retrieval bridging between different languages. In particular, we compare the recently proposed ESA model with two latent models (LSI and LDA) showing that the former is clearly superior to the both. From a general perspective, our results contribute to clarifying the role of explicit vs. implicitly derived or latent concepts in (cross-language) information retrieval research.

#index 1305533
#* Detection of imperative and declarative question-answer pairs in email conversations
#@ Helen Kwong;Neil Yorke-Smith
#t 2009
#c 11
#% 905347
#% 939776
#% 939909
#% 956502
#% 1074109
#% 1137778
#% 1270293
#% 1499571
#! Question-answer pairs extracted from email threads can help construct summaries of the thread, as well as inform semantic-based assistance with email. Previous work dedicated to email threads extracts only questions in interrogative form. We extend the scope of question and answer detection and pairing to encompass also questions in imperative and declarative forms, and to operate at sentence-level fidelity. Building on prior work, our methods are based on learned models over a set of features that include the content, context, and structure of email threads. For two large email corpora, we show that our methods balance precision and recall in extracting question-answer pairs, while maintaining a modest computation time.

#index 1305534
#* Reading between the lines
#@ Loizos Michael
#t 2009
#c 11
#% 697
#% 66937
#% 198055
#% 296858
#% 551723
#% 1139045
#% 1250397
#% 1250405
#% 1274909
#% 1289319
#! Reading involves, among others, identifying what is implied but not expressed in text. This task, known as textual entailment, offers a natural abstraction for many NLP tasks, and has been recognized as a central tool for the new area of Machine Reading. Important in the study of textual entailment is making precise the sense in which something is implied by text. The operational definition often employed is a subjective one: something is implied if humans are more likely to believe it given the truth of the text, than otherwise. In this work we propose a natural objective definition for textual entailment. Our approach is to view text as a partial depiction of some underlying hidden reality. Reality is mapped into text through a possibly stochastic process, the author of the text. Textual entailment is then formalized as the task of accurately, in a defined sense, recovering information about this hidden reality. We show how existing machine learning work can be applied to this information recovery setting, and discuss the implications for the construction of machines that autonomously engage in textual entailment. We then investigate the role of using multiple inference rules for this task. We establish that such rules cannot be learned and applied in parallel, but that layered learning and reasoning are necessary.

#index 1305535
#* Improving morphology induction by learning spelling rules
#@ Jason Naradowsky;Sharon Goldwater
#t 2009
#c 11
#% 397158
#% 740916
#% 741043
#% 905493
#% 939938
#% 1271755
#% 1271757
#% 1344866
#! Unsupervised learning of morphology is an important task for human learners and in natural language processing systems. Previous systems focus on segmenting words into substrings (taking ⇒ tak.ing), but sometimes a segmentation-only analysis is insufficient (e.g., taking may be more appropriately analyzed as take+ing, with a spelling rule accounting for the deletion of the stem-final e). In this paper, we develop a Bayesian model for simultaneously inducing both morphology and spelling rules. We show that the addition of spelling rules improves performance over the baseline morphology-only model.

#index 1305536
#* Improving a virtual human using a model of degrees of grounding
#@ Antonio Roque;David Traum
#t 2009
#c 11
#% 199215
#% 527858
#% 838123
#% 902090
#% 939882
#% 1271679
#! We describe the Degrees of Grounding model, which tracks the extent to which material has reached mutual belief in a dialogue, and conduct experiments in which the model is used to manage grounding behavior in spoken dialogues with a virtual human. We show that the model produces improvements in virtual human performance as measured by post-session questionnaires.

#index 1305537
#* On the tip of my thought: playing the Guillotine game
#@ Giovanni Semeraro;Pasquale Lops;Pierpaolo Basile;Marco De Gemmis
#t 2009
#c 11
#% 252328
#% 348577
#% 902301
#% 1082191
#% 1269584
#% 1413165
#! In this paper we propose a system to solve a language game, called Guillotine, which requires a player with a strong cultural and linguistic background knowledge. The player observes a set of five words, generally unrelated to each other, and in one minute she has to provide a sixth word, semantically connected to the others. Several knowledge sources, such as a dictionary and a set of proverbs, have been modeled and integrated in order to realize a knowledge infusion process into the system. The main motivation for designing an artificial player for Guillotine is the challenge of providing the machine with the cultural and linguistic background knowledge which makes it similar to a human being, with the ability of interpreting natural language documents and reasoning on their content. Experiments carried out showed promising results, and both the knowledge source modeling and the reasoning mechanisms (implementing a spreading activation algorithm to find out the solution) seem to be appropriate. We are convinced that the approach has a great potential for other more practical applications besides solving a language game, such as semantic search.

#index 1305538
#* Introspection and adaptable model integration for dialogue-based question answering
#@ Daniel Sonntag
#t 2009
#c 11
#% 124652
#% 742201
#% 793419
#% 807028
#% 923088
#% 958453
#% 996378
#% 1271821
#% 1274830
#% 1406713
#% 1501197
#! Dialogue-based Question Answering (QA) is a highly complex task that brings together a QA system including various natural language processing components (i.e., components for question classification, information extraction, and retrieval) with dialogue systems for effective and natural communication. The dialogue-based access is difficult to establish when the QA system in use is complex and combines many different answer services with different quality and access characteristics. For example, some questions are processed by opendomain QA services with a broad coverage. Others should be processed by using a domain-specific instance ontology for more reliable answers. Different answer services may change their characteristics over time and the dialogue reaction models have to be updated according to that. To solve this problem, we developed introspective methods to integrate adaptable models of the answer services. We evaluated the impact of the learned models on the dialogue performance, i.e., whether the adaptable models can be used for a more convenient dialogue formulation process. We show significant effectiveness improvements in the resulting dialogues when using the machine learning (ML) models. Examples are provided in the context of the generation of system-initiative feedback to user questions and answers, as provided by heterogeneous information services.

#index 1305539
#* Context-based approach for pivot translation services
#@ Rie Tanaka;Yohei Murakami;Toru Ishida
#t 2009
#c 11
#% 282421
#% 756790
#% 849488
#% 900826
#% 905358
#% 1145300
#% 1163727
#% 1183144
#% 1241140
#% 1397568
#% 1696293
#! Machine translation services available on the Web are becoming increasingly popular. However, a pivot translation service is required to realize translations between non-English languages by cascading different translation services via English. As a result, the meaning of words often drifts due to the inconsistency, asymmetry and intransitivity of word selections among translation services. In this paper, we propose context-based coordination to maintain the consistency of word meanings during pivot translation services. First, we propose a method to automatically generate multilingual equivalent terms based on bilingual dictionaries and use generated terms to propagate context among combined translation services. Second, we show a multiagent architecture as one way of implementation, wherein a coordinator agent gathers and propagates context from/to a translation agent. We generated trilingual equivalent noun terms and implemented a Japanese-to-German-and-back translation, cascading into four translation services. The evaluation results showed that the generated terms can cover over 58% of all nouns. The translation quality was improved by 40% for all sentences, and the quality rating for all sentences increased by an average of 0.47 points on a five-point scale. These results indicate that we can realize consistent pivot translation services through context-based coordination based on existing services.

#index 1305540
#* Online graph planarisation for synchronous parsing of semantic and syntactic dependencies
#@ Ivan Titov;James Henderson;Paola Merlo;Gabriele Musillo
#t 2009
#c 11
#% 939344
#% 939919
#% 983915
#% 1249464
#% 1249475
#% 1249502
#% 1249503
#% 1249504
#% 1249505
#% 1249508
#% 1249515
#% 1249519
#% 1251680
#% 1260718
#% 1271213
#% 1299521
#! This paper investigates a generative history-based parsing model that synchronises the derivation of non-planar graphs representing semantic dependencies with the derivation of dependency trees representing syntactic structures. To process non-planarity online, the semantic transition-based parser uses a new technique to dynamically reorder nodes during the derivation. While the synchronised derivations allow different structures to be built for the semantic non-planar graphs and syntactic dependency trees, useful statistical dependencies between these structures are modeled using latent variables. The resulting synchronous parser achieves competitive performance on the CoNLL- 2008 shared task, achieving relative error reduction of 12% in semantic F score over previously proposed synchronous models that cannot process non-planarity online.

#index 1305541
#* Computational semantics of noun compounds in a semantic space model
#@ Akira Utsumi
#t 2009
#c 11
#% 979654
#% 983541
#% 1269813
#% 1289532
#% 1294844
#% 1712197
#! This study examines the ability of a semantic space model to represent themeaning of noun compounds such as "information gathering" or "weather forecast". A new algorithm, comparison, is proposed for computing compound vectors from constituent word vectors, and compared with other algorithms (i.e., predication and centroid) in terms of accuracy of multiple-choice synonym test and similarity judgment test. The result of both tests is that the comparison algorithm is, on the whole, superior to other algorithms, and in particular achieves the best performance when noun compounds have emergent meanings. Furthermore, the comparison algorithm also works for novel noun compounds that do not occur in the corpus. These findings indicate that a semantic space model in general and the comparison algorithm in particular has sufficient ability to compute the meaning of noun compounds.

#index 1305542
#* Probabilistic counting with randomized storage
#@ Benjamin Van Durme;Ashwin Lall
#t 2009
#c 11
#% 1682
#% 320240
#% 322884
#% 654461
#% 993960
#% 1215290
#% 1270706
#! Previous work by Talbot and Osborne [2007] explored the use of randomized storage mechanisms in language modeling. These structures trade a small amount of error for significant space savings, enabling the use of larger language models on relatively modest hardware. Going beyond space efficient count storage, here we present the Talbot Osborne Morris Bloom (TOMB) Counter, an extended model for performing space efficient counting over streams of finite length. Theoretical and experimental results are given, showing the promise of approximate counting over large vocabularies in the context of limited space.

#index 1305543
#* Context-sensitive semantic smoothing using semantically relatable sequences
#@ Kamaljeet S. Verma;Pushpak Bhattacharyya
#t 2009
#c 11
#% 248218
#% 262096
#% 280819
#% 280851
#% 340899
#% 340948
#% 375017
#% 397129
#% 740904
#% 742218
#% 818115
#% 818239
#% 879586
#% 1112744
#! We propose a novel approach to context sensitive semantic smoothing by making use of an intermediate, "semantically light" representation for sentences, called Semantically Relatable Sequences (SRS). SRSs of a sentence are tuples of words appearing in the semantic graph of the sentence as linked nodes depicting dependency relations. In contrast to patterns based on consecutive words, SRSs make use of groupings of nonconsecutive but semantically related words. Our experiments on TREC AP89 collection show that the mixture model of SRS translation model and Two Stage Language Model (TSLM) of Lafferty and Zhai achieves MAP scores better than the mixture model of MultiWord Expression (MWE) translation model and TSLM. Furthermore, a system, which for each test query selects either the SRS or the MWE mixture model based on better query MAP score, shows significant improvements over the individual mixture models.

#index 1305544
#* Graph-based multi-modality learning for topic-focused multi-document summarization
#@ Xiaojun Wan;Jianguo Xiao
#t 2009
#c 11
#% 280835
#% 397138
#% 787502
#% 815920
#% 816173
#% 818227
#% 840000
#% 939539
#% 1019065
#% 1074086
#% 1074088
#% 1074089
#% 1130898
#% 1215306
#% 1251709
#% 1264797
#% 1275213
#% 1275220
#! Graph-based manifold-ranking methods have been successfully applied to topic-focused multi-document summarization. This paper further proposes to use the multi-modality manifold-ranking algorithm for extracting topic-focused summary from multiple documents by considering the within-document sentence relationships and the cross-document sentence relationships as two separate modalities (graphs). Three different fusion schemes, namely linear form, sequential form and score combination form, are exploited in the algorithm. Experimental results on the DUC benchmark datasets demonstrate the effectiveness of the proposed multi-modality learning algorithms with all the three fusion schemes.

#index 1305545
#* Multiscale analysis of document corpora based on diffusion models
#@ Chang Wang;Sridhar Mahadevan
#t 2009
#c 11
#% 722904
#% 876020
#! We introduce a nonparametric approach to multiscale analysis of document corpora using a hierarchical matrix analysis framework called diffusion wavelets. In contrast to eigenvector methods, diffusion wavelets construct multiscale basis functions. In this framework, a hierarchy is automatically constructed by an iterative series of dilation and orthogonalization steps beginning with an initial set of orthogonal basis functions, such as the unitvector bases. Each set of basis functions at a given level is constructed from the bases at the lower level by dilation using the dyadic powers of a diffusion operator. A novel aspect of our work is that the diffusion analysis is conducted on the space of variables (words), instead of instances (documents). This approach can automatically and efficiently determine the number of levels of the topical hierarchy, as well as the topics at each level. Multiscale analysis of document corpora is achieved by using the projections of the documents onto the spaces spanned by basis functions at different levels. Further, when the input term-term matrix is a "local" diffusion operator, the algorithm runs in time approximately linear in the number of non-zero elements of the matrix. The approach is illustrated on various data sets including NIPS conference papers, 20 Newsgroups and TDT2 data.

#index 1305546
#* Wikispeedia: an online game for inferring semantic distances between concepts
#@ Robert West;Joelle Pineau;Doina Precup
#t 2009
#c 11
#% 268079
#% 801375
#% 860015
#% 975019
#% 1002276
#% 1148765
#% 1250381
#% 1264744
#% 1275012
#! Computing the semantic distance between realworld concepts is crucial for many intelligent applications. We present a novel method that leverages data from 'Wikispeedia', an online game played on Wikipedia; players have to reach an article from another, unrelated article, only by clicking links in the articles encountered. In order to automatically infer semantic distances between everyday concepts, our method effectively extracts the common sense displayed by humans during play, and is thus more desirable, from a cognitive point of view, than purely corpus-based methods. We show that our method significantly outperforms Latent Semantic Analysis in a psychometric evaluation of the quality of learned semantic distances.

#index 1305547
#* Situated resolution and generation of spatial referring expressions for robotic assistants
#@ Hendrik Zender;Geert-Jan M. Kruijff;Ivana Kruijff-Korbayová
#t 2009
#c 11
#% 579945
#% 742338
#% 744674
#% 746889
#% 939431
#% 939631
#% 979656
#% 1041886
#% 1063859
#% 1223564
#% 1275148
#! In this paper we present an approach to the task of generating and resolving referring expressions (REs) for conversational mobile robots. It is based on a spatial knowledge base encompassing both robot- and human-centric representations. Existing algorithms for the generation of referring expressions (GRE) try to find a description that uniquely identifies the referent with respect to other entities that are in the current context. Mobile robots, however, act in large-scale space, that is environments that are larger than what can be perceived at a glance, e.g. an office building with different floors, each containing several rooms and objects. One challenge when referring to elsewhere is thus to include enough information so that the interlocutors can extend their context appropriately. We address this challenge with a method for context construction that can be used for both generating and resolving REs - two previously disjoint aspects. Our approach is embedded in a bi-directional framework for natural language processing for robots.

#index 1305548
#* On-line evolutionary exponential family mixture
#@ Jianwen Zhang;Yangqiu Song;Gang Chen;Changshui Zhang
#t 2009
#c 11
#% 190581
#% 232768
#% 718437
#% 881514
#% 916785
#% 989586
#% 1083699
#% 1269933
#! This paper deals with evolutionary clustering, which refers to the problem of clustering data with distribution drifting along time. Starting from a density estimation view to clustering problems, we propose two general on-line frameworks. In the first framework, i.e., historical data dependent (HDD), current model distribution is designed to approximate both current and historical data distributions. In the second framework, i.e., historical model dependent (HMD), current model distribution is designed to approximate both current data distribution and historical model distribution. Both frameworks are based on the general exponential family mixture (EFM) model. As a result, all conventional clustering algorithms based on EFMs can be extended to evolutionary setting under the two frameworks. Empirical results validate the two frameworks.

#index 1305549
#* Word sense disambiguation for all words without hard labor
#@ Zhi Zhong;Hwee Tou Ng
#t 2009
#c 11
#% 740916
#% 747738
#% 815895
#% 817476
#% 817596
#% 818059
#% 854641
#% 939922
#% 1265022
#% 1269524
#% 1271271
#% 1271309
#% 1910925
#! While the most accurate word sense disambiguation systems are built using supervised learning from sense-tagged data, scaling them up to all words of a language has proved elusive, since preparing a sense-tagged corpus for all words of a language is time-consuming and human labor intensive. In this paper, we propose and implement a completely automatic approach to scale up word sense disambiguation to all words of English. Our approach relies on English-Chinese parallel corpora, English-Chinese bilingual dictionaries, and automatic methods of finding synonyms of Chinese words. No additional human sense annotations or word translations are needed. We conducted a large-scale empirical evaluation on more than 29,000 noun tokens in English texts annotated in OntoNotes 2.0, based on its coarsegrained sense inventory. The evaluation results show that our approach is able to achieve high accuracy, outperforming the first-sense baseline and coming close to a prior reported approach that requires manual human efforts to provide Chinese translations of English senses.

#index 1305550
#* A translation-based approach to contingent planning
#@ Alexandre Albore;Héctor Palacios;Héctor Geffner
#t 2009
#c 11
#% 124601
#% 544923
#% 873947
#% 1271962
#% 1272109
#% 1272287
#! The problem of planning in the presence of sensing has been addressed in recent years as a nondeterministic search problem in belief space. In this work, we use ideas advanced recently for compiling conformant problems into classical ones for introducing a different approach where contingent problems P are mapped into non-deterministic problems X(P) in state space. We also identify a contingent width parameter, and show that for problems P with bounded contingent width, the translation is sound, polynomial, and complete. We then solve X(P) by using a relaxation X+(P) that is a classical planning problem. The formulation is tested experimentally over contingent benchmarks where it is shown to yield a planner that scales up better than existing contingent planners.

#index 1305551
#* Translating HTNs to PDDL: a small amount of domain knowledge can go a long way
#@ Ron Alford;Ugur Kuter;Dana Nau
#t 2009
#c 11
#% 44836
#% 109935
#% 243697
#% 266385
#% 296170
#% 345431
#% 417703
#% 495942
#% 544793
#% 544930
#% 743353
#% 1223551
#% 1271962
#% 1272016
#% 1272019
#% 1272113
#% 1272116
#! We show how to translate HTN domain descriptions (if they satisfy certain restrictions) into PDDL so that they can be used by classical planners. We provide correctness results for our translation algorithm, and show that it runs in linear time and space. We also show that even small and incomplete amounts of HTN knowledge, when translated into PDDL using our algorithm, can greatly improve a classical planner's performance. In experiments on several thousand randomly generated problems in three different planning domains, such knowledge speeded up the well-known Fast-Forward planner by several orders of magnitude, and enabled it to solve much larger problems than it could otherwise solve.

#index 1305552
#* Goal recognition with variable-order Markov models
#@ Marcelo G. Armentano;Analía Amandi
#t 2009
#c 11
#% 103865
#% 147680
#% 159108
#% 222437
#% 398946
#% 496119
#% 528007
#% 632422
#% 706640
#% 788954
#% 812594
#% 900235
#% 953324
#% 1279398
#% 1650593
#! The recognition of the goal a user is pursing when interacting with a software application is a crucial task for an interface agent as it serves as a context for making opportune interventions to provide assistance to the user. The prediction of the user goal must be fast and a goal recognizer must be able to make early predictions with few observations of the user actions. In this work we propose an approach to automatically build an intention model from a plan corpus using Variable Order Markov models. We claim that following our approach, an interface agent will be capable of accurately ranking the most probable user goals in a time linear to the number of goals modeled.

#index 1305553
#* Solving POMDPs: RTDP-bel vs. point-based algorithms
#@ Blai Bonet;Héctor Geffner
#t 2009
#c 11
#% 68238
#% 181627
#% 252183
#% 361729
#% 384911
#% 393786
#% 465931
#% 565547
#% 1271823
#% 1272075
#% 1272129
#% 1275174
#! Point-based algorithms and RTDP-Bel are approximate methods for solving POMDPs that replace the full updates of parallel value iteration by faster and more effective updates at selected beliefs. An important difference between the two methods is that the former adopt Sondik's representation of the value function, while the latter uses a tabular representation and a discretization function. The algorithms, however, have not been compared up to now, because they target different POMDPs: discounted POMDPs on the one hand, and Goal POMDPs on the other. In this paper, we bridge this representational gap, showing how to transform discounted POMDPs into Goal POMDPs, and use the transformation to compare RTDP-Bel with point-based algorithms over the existing discounted benchmarks. The results appear to contradict the conventional wisdom in the area showing that RTDP-Bel is competitive, and sometimes superior to point-based algorithms in both quality and time.

#index 1305554
#* Incremental heuristic search for planning with temporally extended goals and uncontrollable events
#@ Adi Botea;André A. Ciré
#t 2009
#c 11
#% 296170
#% 445247
#% 1223552
#% 1271962
#% 1275045
#% 1275066
#% 1279345
#! Planning with temporally extended goals and uncontrollable events has recently been introduced as a formal model for system reconfiguration problems. An important application is to automatically reconfigure a real-life system in such a way that its subsequent internal evolution is consistent with a temporal goal formula. In this paper we introduce an incremental search algorithm and a search-guidance heuristic, two generic planning enhancements. An initial problem is decomposed into a series of subproblems, providing two main ways of speeding up a search. Firstly, a subproblem focuses on a part of the initial goal. Secondly, a notion of action relevance allows to explore with higher priority actions that are heuristically considered to be more relevant to the subproblem at hand. Even though our techniques are more generally applicable, we restrict our attention to planning with temporally extended goals and uncontrollable events. Our ideas are implemented on top of a successful previous system that performs online learning to better guide planning and to safely avoid potentially expensive searches. In experiments, the system speed performance is further improved by a convincing margin.

#index 1305555
#* Equivalence relations in fully and partially observable Markov decision processes
#@ Pablo Samuel Castro;Prakash Panangaden;Doina Precup
#t 2009
#c 11
#% 104387
#% 135428
#% 252183
#% 374130
#% 655325
#% 788055
#% 827696
#% 1478746
#! We explore equivalence relations between states in Markov Decision Processes and Partially Observable Markov Decision Processes. We focus on two different equivalence notions: bisimulation [Givan et al., 2003] and a notion of trace equivalence, under which states are considered equivalent if they generate the same conditional probability distributions over observation sequences (where the conditioning is on action sequences). We show that the relationship between these two equivalence notions changes depending on the amount and nature of the partial observability. We also present an alternate characterization of bisimulation based on trajectory equivalence.

#index 1305556
#* Completeness and optimality preserving reduction for planning
#@ Yixin Chen;Guohui Yao
#t 2009
#c 11
#% 172505
#% 251783
#% 337980
#% 496243
#% 535059
#% 1250634
#% 1270238
#% 1272113
#% 1275066
#% 1279345
#! Traditional AI search methods search in a state space typically modelled as a directed graph. Prohibitively large sizes of state space graphs make complete or optimal search expensive. A key observation, as exemplified by the SAS+ formalism for planning, is that most commonly a state-space graph can be decomposed into subgraphs, linked by constraints. We propose a novel space reduction algorithm that exploits such structure. The result reveals that standard search algorithms may explore many redundant paths. Our method provides an automatic way to remove such redundancy. At each state, we expand only the subgraphs within a dependency closure satisfying certain sufficient conditions instead of all the subgraphs. Theoretically we prove that the proposed algorithm is completeness-preserving as well as optimality-preserving. We show that our reduction method can significantly reduce the search cost on a collection of planning domains.

#index 1305557
#* Stratified planning
#@ Yixin Chen;You Xu;Guohui Yao
#t 2009
#c 11
#% 172505
#% 1250634
#% 1270238
#% 1272113
#% 1275066
#% 1279345
#! Most planning problems have strong structures. They can be decomposed into subdomains with causal dependencies. The idea of exploiting the domain decomposition has motivated previous work such as hierarchical planning and factored planing. However, these algorithms require extensive backtracking and lead to few efficient general-purpose planners. On the other hand, heuristic search has been a successful approach to automated planning. The domain decomposition of planning problems, unfortunately, is not directly and fully exploited by heuristic search. We propose a novel and general framework to exploit domain decomposition. Based on a structure analysis on the SAS+ planning formalism, we stratify the sub-domains of a planning problem into dependency layers. By recognizing the stratification of a planning structure, we propose a space reduction method that expands only a subset of executable actions at each state. This reduction method can be combined with state-space search, allowing us to simultaneously employ the strength of domain decomposition and high-quality heuristics. We prove that the reduction preserves completeness and optimality of search and experimentally verify its effectiveness in space reduction.

#index 1305558
#* Temporal planning in domains with linear processes
#@ Amanda Coles;Andrew Coles;Maria Fox;Derek Long
#t 2009
#c 11
#% 179938
#% 495772
#% 830717
#% 1269377
#% 1270230
#% 1272008
#% 1272015
#% 1272017
#% 1272098
#% 1272127
#% 1275052
#! We consider the problem of planning in domains with continuous linear numeric change. Such change cannot always be adequately modelled by discretisation and is a key facet of many interesting problems. We show how a forward-chaining temporal planner can be extended to reason with actions with continuous linear effects. We extend a temporal planner to handle numeric values using linear programming. We show how linear continuous change can be integrated into the same linear program and we discuss how a temporal-numeric heuristic can be used to provide the search guidance necessary to underpin continuous planning. We present results to show that the approach can effectively handle duration-dependent change and numeric variables subject to continuous linear change.

#index 1305559
#* Domain-independent, automatic partitioning for probabilistic planning
#@ Peng Dai; Mausam;Daniel S. Weld
#t 2009
#c 11
#% 181627
#% 201257
#% 337981
#% 425080
#% 466402
#% 544936
#% 644560
#% 829022
#% 1250328
#% 1270231
#% 1279478
#% 1650355
#% 1650672
#% 1650710
#! Recent progress on external-memory MDP solvers, in particular PEMVI [Dai et al., 2008], has enabled optimal solutions to large probabilistic planning problems. However, PEMVI requires a human to manually partition the MDP before the planning algorithm can be applied -- putting an added burden on the domain designer and detracting from the vision of automated planning. This paper presents a novel partitioning scheme, which automatically subdivides the state space into blocks that respect the memory constraints. Our algorithm first applies static domain analysis to identify candidates for partitioning, and then uses heuristic search to generate a 'good' partition. We evaluate the usefulness of our method in the context of PEMVI across many benchmark domains, showing that it can successfully solve extremely large problems in each domain. We also compare the performance of automatic partitioning with previously reported results using human-designed partitions. Experiments show that our algorithm generates significantly superior partitions, which speed MDP solving and also yield vast memory savings.

#index 1305560
#* Topological order planner for POMDPs
#@ Jilles S. Dibangoye;Guy Shani;Brahim Chaib-Draa;Abdel-Illah Mouaddib
#t 2009
#c 11
#% 92301
#% 829022
#% 1269875
#% 1272075
#% 1275053
#% 1275174
#% 1279358
#% 1279387
#% 1650702
#% 1665157
#% 1673035
#% 1845990
#! Over the past few years, point-based POMDP solvers scaled up to produce approximate solutions to mid-sized domains. However, to solve real world problems, solvers must exploit the structure of the domain. In this paper we focus on the topological structure of the problem, where the state space contains layers of states. We present here the Topological Order Planner (TOP) that utilizes the topological structure of the domain to compute belief space trajectories. TOP rapidly produces trajectories focused on the solveable regions of the belief space, thus reducing the number of redundant backups considerably. We demonstrate TOP to produce good quality policies faster than any other pointbased algorithm on domains with sufficient structure.

#index 1305561
#* Optimal symbolic planning with action costs and preferences
#@ Stefan Edelkamp;Peter Kissmann
#t 2009
#c 11
#% 3873
#% 68114
#% 160388
#% 323695
#% 477286
#% 539774
#% 544788
#% 544936
#% 850323
#% 1023519
#% 1178631
#% 1223405
#% 1250208
#% 1398234
#% 1414232
#% 1476298
#! This paper studies the solving of finite-domain action planning problems with discrete action costs and soft constraints. For sequential optimal planning, a symbolic perimeter database heuristic is addressed in a bucket implementation of A*. For computing net-benefits, we propose symbolic branch-and-bound search together with some search refinements. The net-benefit we optimize is the total benefit of satisfying the goals, minus the total action cost to achieve them. This results in an objective function to be minimized that is a linear expression over the violation of the preferences added to the action cost total.

#index 1305562
#* Activity recognition with intended actions
#@ Alfredo Gabaldon
#t 2009
#c 11
#% 77167
#% 379067
#% 398251
#% 411814
#% 499512
#% 567880
#% 1250632
#% 1269467
#% 1272356
#% 1289455
#! The following activity recognition problem is considered: a description of the action capabilities of an agent being observed is given. This includes the preconditions and effects of atomic actions and of the activities (sequences of actions) the agent may execute. Given this description and a set of propositions, called history, about action occurrences, intended actions and properties of the world all at various points in time, the problem is to complete the picture as much as possible and determine what has already happened, what the intentions of the agent are, and what may happen as a result of the agent acting on those intentions. We present a framework to solve these activity recognition problems based on a formal language for reasoning about actions that includes a notion of intended actions, and a corresponding formalization in answer set programming.

#index 1305563
#* Delaying commitment in plan recognition using combinatory categorial grammars
#@ Christopher W. Geib
#t 2009
#c 11
#% 103865
#% 297229
#% 368080
#% 567880
#% 743353
#% 938666
#% 1250199
#% 1272356
#% 1289455
#! This paper presents a new algorithm for plan recognition called ELEXIR (Engine for LEXicalized Intent Recognition). ELEXIR represents the plans to be recognized with a grammatical formalism called Combinatory Categorial Grammar(CCG). We show that representing plans with CCGs can allow us to prevent early commitment to plan goals and thereby reduce runtime.

#index 1305564
#* Learning hierarchical task networks for nondeterministic planning domains
#@ Chad Hogg;Ugur Kuter;Héctor Muñoz-Avila
#t 2009
#c 11
#% 384911
#% 465761
#% 655322
#% 743353
#% 840877
#% 876028
#% 961150
#% 1178632
#% 1250200
#% 1269396
#% 1270239
#% 1289206
#! This paper describes how to learn Hierarchical Task Networks (HTNs) in nondeterministic planning domains, where actions may have multiple possible outcomes. We discuss several desired properties that guarantee that the resulting HTNs will correctly handle the nondeterminism in the domain. We developed a new learning algorithm, called HTN-MAKERND, that exploits these properties. We implemented HTN-MAKERND in the recently-proposed HTN-MAKER system, a goal-regression based HTN learning approach. In our theoretical study, we show that HTN-MAKERND soundly produces HTN planning knowledge in low-order polynomial times, despite the nondeterminism. In our experiments with two nondeterministic planning domains, ND-SHOP2, a well-known HTN planning algorithm for nondeterministic domains, significantly outperformed (in some cases, by about 3 orders of magnitude) the well-known planner MBP using the learned HTNs.

#index 1305565
#* Abnormal activity recognition based on HDP-HMM models
#@ Derek Hao Hu;Xian-Xing Zhang;Jie Yin;Vincent Wenchen Zheng;Qiang Yang
#t 2009
#c 11
#% 304917
#% 812382
#% 812412
#% 946811
#% 1024911
#% 1114487
#% 1250303
#% 1279398
#% 1289473
#% 1378224
#% 1668045
#! Detecting abnormal activities from sensor readings is an important research problem in activity recognition. A number of different algorithms have been proposed in the past to tackle this problem. Many of the previous state-based approaches suffer from the problem of failing to decide the appropriate number of states, which are difficult to find through a trial-and-error approach, in real-world applications. In this paper, we propose an accurate and flexible framework for abnormal activity recognition from sensor readings that involves less human tuning of model parameters. Our approach first applies a Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM), which supports an infinite number of states, to automatically find an appropriate number of states. We incorporate a Fisher Kernel into the One-Class Support Vector Machine (OCSVM) model to filter out the activities that are likely to be normal. Finally, we derive an abnormal activity model from the normal activity models to reduce false positive rate in an unsupervised manner. Our main contribution is that our proposed HDP-HMM models can decide the appropriate number of states automatically, and that by incorporating a Fisher Kernel into the OCSVM model, we can combine the advantages from generative model and discriminative model. We demonstrate the effectiveness of our approach by using several real-world datasets to test our algorithm's performance.

#index 1305566
#* Structured plans and observation reduction for plans with contexts
#@ Wei Huang;Zhonghua Wen;Yunfei Jiang;Hong Peng
#t 2009
#c 11
#% 252183
#% 578723
#% 655322
#% 873947
#% 1275064
#% 1289212
#% 1289213
#! In many real world planning domains, some observation information is optional and useless to the execution of a plan; on the other hand, information acquisition may require some kind of cost. The problem of observation reduction for strong plans has been addressed in the literature. However, observation reduction for plans with contexts (which are more general and useful than strong plans in robotics) is still a open problem. In this paper, we present an attempt to solve the problem. Our first contribution is the definition of structured plans, which can encode sequential, conditional and iterative behaviors, and is expressive enough for dealing with incomplete observation information and internal states of the agent. A second contribution is an observation reduction algorithm for plans with contexts, which can transform a plan with contexts into a structured plan that only branches on necessary observation information.

#index 1305567
#* Cost-optimal planning with landmarks
#@ Erez Karpas;Carmel Domshlak
#t 2009
#c 11
#% 1722
#% 337980
#% 873956
#% 1178627
#% 1270243
#% 1272047
#% 1272113
#! Planning landmarks are facts that must be true at some point in every solution plan. Previous work has very successfully exploited planning landmarks in satisficing (non-optimal) planning. We propose a methodology for deriving admissible heuristic estimates for cost-optimal planning from a set of planning landmarks. The resulting heuristics fall into a novel class of multi-path dependent heuristics, and we present a simple best-first search procedure exploiting such heuristics. Our empirical evaluation shows that this framework favorably competes with the state-of-the-art of cost-optimal heuristic search.

#index 1305568
#* Trees of shortest paths vs. Steiner trees: understanding and improving delete relaxation heuristics
#@ Emil Keyder;Héctor Geffner
#t 2009
#c 11
#% 70370
#% 167629
#% 299247
#% 303076
#% 337980
#% 1223554
#% 1271962
#% 1272113
#! Heuristic search using heuristics extracted from the delete relaxation is one of the most effective methods in planning. Since finding the optimal solution of the delete relaxation is intractable, various heuristics introduce independence assumptions, the implications of which are not yet fully understood. Here we use concepts from graph theory to show that in problems with unary action preconditions, the delete relaxation is closely related to the Steiner Tree problem, and that the independence assumption for the set of goals results in a tree-of-shortest-paths approximation. We analyze the limitations of this approximation and develop an alternative method for computing relaxed plans that addresses them. The method is used to guide a greedy best-first search, where it is shown to improve plan quality and coverage over several benchmark domains.

#index 1305569
#* Efficient abstraction and refinement for behavioral description based web service composition
#@ Hyunyoung Kil;Wonhong Nam;Dongwon Lee
#t 2009
#c 11
#% 167468
#% 873947
#% 900869
#% 1145174
#% 1175720
#% 1275064
#% 1279346
#% 1289550
#! The Web Service Composition (WSC) problem with respect to behavioral descriptions deals with the automatic synthesis of a coordinator web service, c, that controls a set of web services to reach a goal state. Despite its importance, however, solving the WSC problem for a general case (when c has only partial observations) remains to be doubly exponential in the number of variables in web service descriptions, rendering any attempts to compute an exact solution for modest size impractical. Toward this challenge, in this paper, we propose two novel (signature preserving and subsuming) approximation-based approaches using abstraction and refinement. We empirically validate that our proposals can solve realistic problems efficiently.

#index 1305570
#* ReTrASE: integrating paradigms for approximate probabilistic planning
#@ Andrey Kolobov; Mausam;Daniel S. Weld
#t 2009
#c 11
#% 181627
#% 393786
#% 578724
#% 644560
#% 788062
#% 876001
#% 1270248
#% 1271962
#% 1272002
#% 1272092
#% 1279355
#% 1289549
#% 1650297
#! Past approaches for solving MDPs have several weaknesses: 1) Decision-theoretic computation over the state space can yield optimal results but scales poorly. 2) Value-function approximation typically requires human-specified basis functions and has not been shown successful on nominal ("discrete") domains such as those in the ICAPS planning competitions. 3) Replanning by applying a classical planner to a determinized domain model can generate approximate policies for very large problems but has trouble handling probabilistic subtlety [Little and Thiebaux, 2007]. This paper presents RETRASE, a novel MDP solver, which combines decision theory, function approximation and classical planning in a new way. RETRASE uses classical planning to create basis functions for value-function approximation and applies expected-utility analysis to this compact space. Our algorithm is memory-efficient and fast (due to its compact, approximate representation), returns high-quality solutions (due to the decision-theoretic framework) and does not require additional knowledge from domain engineers (since we apply classical planning to automatically construct the basis functions). Experiments demonstrate that RETRASE outperforms winners from the past three probabilistic-planning competitions on many hard problems.

#index 1305571
#* Learning probabilistic hierarchical task networks to capture user preferences
#@ Nan Li;Subbarao Kambhampati;Sungwook Yoon
#t 2009
#c 11
#% 179965
#% 266385
#% 742218
#% 746865
#% 1250389
#% 1270239
#% 1275013
#! While much work on learning in planning focused on learning domain physics (i.e., action models), and search control knowledge, little attention has been paid towards learning user preferences on desirable plans. Hierarchical task networks (HTN) are known to provide an effective way to encode user prescriptions about what constitute good plans. However, manual construction of these methods is complex and error prone. In this paper, we propose a novel approach to learning probabilistic hierarchical task networks that capture user preferences by examining user-produced plans given no prior information about the methods (in contrast, most prior work on learning within the HTN framework focused on learning "method preconditions"--i.e., domain physics--assuming that the structure of the methods is given as input). We will show that this problem has close parallels to the problem of probabilistic grammar induction, and describe how grammar induction methods can be adapted to learn task networks. We will empirically demonstrate the effectiveness of our approach by showing that task networks we learn are able to generate plans with a distribution close to the distribution of the user-preferred plans.

#index 1305572
#* A distributed control loop for autonomous recovery in a multi-agent plan
#@ Roberto Micalizio
#t 2009
#c 11
#% 334633
#% 431521
#% 823945
#% 977571
#% 1173783
#% 1223517
#% 1271826
#% 1271828
#! This paper considers the execution of a Multi-Agent Plan in a partially observable environment, and faces the problem of recovering from action failures. The paper formalizes a local plan repair strategy, where each agent in the system is responsible for controlling (monitoring and diagnosing) the actions it executes, and for autonomously repairing its own plan when an action failure is detected. The paper describes also how to mitigate the impact of an action failure on the plans of other agents when the local recovery strategy fails.

#index 1305573
#* Monte-Carlo exploration for deterministic planning
#@ Hootan Nakhost;Martin Müller
#t 2009
#c 11
#% 60140
#% 593734
#% 750050
#% 934104
#% 1270060
#% 1270346
#% 1271962
#% 1272113
#% 1272116
#% 1272141
#% 1665148
#! Search methods based on Monte-Carlo simulation have recently led to breakthrough performance improvements in difficult game-playing domains such as Go and General Game Playing. Monte-Carlo Random Walk (MRW) planning applies Monte-Carlo ideas to deterministic classical planning. In the forward chaining planner ARVAND, Monte-Carlo random walks are used to explore the local neighborhood of a search state for action selection. In contrast to the stochastic local search approach used in the recent planner Identidem, random walks yield a larger and unbiased sample of the search neighborhood, and require state evaluations only at the endpoints of each walk. On IPC-4 competition problems, the performance of ARVAND is competitive with state of the art systems.

#index 1305574
#* Planning with partial preference models
#@ Tuan A. Nguyen;Minh B. Do;Subbarao Kambhampati;Biplav Srivastava
#t 2009
#c 11
#% 590623
#% 794918
#% 1046055
#% 1269925
#% 1272014
#% 1275078
#! In many real-world planning scenarios, the users are interested in optimizing multiple objectives (such as makespan and execution cost), but are unable to express their exact tradeoff between those objectives. When a planner encounters such partial preference models, rather than look for a single optimal plan, it needs to present the pareto set of plans and let the user choose from them. This idea of presenting the full pareto set is fraught with both computational and user-interface challenges. To make it practical, we propose the approach of finding a representative subset of the pareto set. We measure the quality of this representative set using the Integrated Convex Preference (ICP) model, originally developed in the OR community. We implement several heuristic approaches based on the Metric-LPG planner to find a good solution set according to this measure. We present empirical results demonstrating the promise of our approach.

#index 1305575
#* Plan recognition as planning
#@ Miquel Ramírez;Hector Geffner
#t 2009
#c 11
#% 147680
#% 1223554
#% 1250649
#% 1271962
#% 1272113
#% 1289455
#% 1290117
#% 1650293
#! In this work we aim to narrow the gap between plan recognition and planning by exploiting the power and generality of recent planning algorithms for recognizing the set G* of goals G that explain a sequence of observations given a domain theory. After providing a crisp definition of this set, we show by means of a suitable problem transformation that a goal G belongs to G* if there is an action sequence π that is an optimal plan for both the goal G and the goal G extended with extra goals representing the observations. Exploiting this result, we show how the set G* can be computed exactly and approximately by minor modifications of existing optimal and suboptimal planning algorithms, and existing polynomial heuristics. Experiments over several domains show that the suboptimal planning algorithms and the polynomial heuristics provide good approximations of the optimal goal set G* while scaling up as well as state-of-the-art planning algorithms and heuristics.

#index 1305576
#* Bayesian real-time dynamic programming
#@ Scott Sanner;Robby Goetschalckx;Kurt Driessens;Guy Shani
#t 2009
#c 11
#% 107169
#% 266287
#% 337981
#% 363744
#% 677083
#% 840906
#% 1250350
#% 1279387
#% 1650653
#! Real-time dynamic programming (RTDP) solves Markov decision processes (MDPs) when the initial state is restricted, by focusing dynamic programming on the envelope of states reachable from an initial state set. RTDP often provides performance guarantees without visiting the entire state space. Building on RTDP, recent work has sought to improve its efficiency through various optimizations, including maintaining upper and lower bounds to both govern trial termination and prioritize state exploration. In this work, we take a Bayesian perspective on these upper and lower bounds and use a value of perfect information (VPI) analysis to govern trial termination and exploration in a novel algorithm we call VPI-RTDP. VPI-RTDP leads to an improvement over state-of-the-art RTDP methods, empirically yielding up to a three-fold reduction in the amount of time and number of visited states required to achieve comparable policy performance.

#index 1305577
#* HTN planning with preferences
#@ Shirin Sohrabi;Jorge A. Baier;Sheila A. McIlraith
#t 2009
#c 11
#% 266385
#% 342119
#% 417597
#% 1178630
#% 1178631
#% 1272019
#% 1275063
#% 1413169
#! In this paper we address the problem of generating preferred plans by combining the procedural control knowledge specified by Hierarchical Task Networks (HTNs) with rich user preferences. To this end, we extend the popular Planning Domain Definition Language, PDDL3, to support specification of simple and temporally extended preferences over HTN constructs. To compute preferred HTN plans, we propose a branch-and-bound algorithm, together with a set of heuristics that, leveraging HTN structure, measure progress towards satisfaction of preferences. Our preference-based planner, HTNPLAN-P, is implemented as an extension of the SHOP2 planner. We compared our planner with SGPlan5 and HPLAN-P- the top performers in the 2006 International Planning Competition preference tracks. HTNPLAN-P generated plans that in all but a few cases equalled or exceeded the quality of plans returned by HPLAN-P and SGPlan5. While our implementation builds on SHOP2, the language and techniques proposed here are relevant to a broad range of HTN planners.

#index 1305578
#* A context driven approach for workflow mining
#@ Fusun Yaman;Tim Oates;Mark Burstein
#t 2009
#c 11
#% 203029
#% 258498
#% 259602
#% 289372
#% 459021
#% 589166
#% 772836
#% 1169592
#% 1709197
#! Existing work on workflow mining ignores the dataflow aspect of the problem. This is not acceptable for service-oriented applications that use Web services with typed inputs and outputs. We propose a novel algorithm WIT (Workflow Inference from Traces) which identifies the context similarities of the observed actions based on the dataflow and uses model merging techniques to generalize the control flow and the dataflow simultaneously. We identify the class of workflows that WIT can learn correctly. We implemented WIT and tested it on a real world medical scheduling domain where WIT was able to find a good approximation of the target workflow.

#index 1305579
#* Learning HTN method preconditions and action models from partial observations
#@ Hankz Hankui Zhuo;Derek Hao Hu;Chad Hogg;Qiang Yang;Hector Munoz-Avila
#t 2009
#c 11
#% 320415
#% 465761
#% 803704
#% 840877
#% 876028
#% 944137
#% 1250313
#% 1269396
#% 1270239
#% 1289577
#! To apply hierarchical task network (HTN) planning to real-world planning problems, one needs to encode the HTN schemata and action models beforehand. However, acquiring such domain knowledge is difficult and time-consuming because the HTN domain definition involves a significant knowledge-engineering effort. A system that can learn the HTN planning domain knowledge automatically would save time and allow HTN planning to be used in domains where such knowledgeengineering effort is not feasible. In this paper, we present a formal framework and algorithms to acquire HTN planning domain knowledge, by learning the preconditions and effects of actions and preconditions of methods. Our algorithm, HTN-learner, first builds constraints from given observed decomposition trees to build action models and method preconditions. It then solves these constraints using a weighted MAX-SAT solver. The solution can be converted to action models and method preconditions. Unlike prior work on HTN learning, we do not depend on complete action models or state information. We test the algorithm on several domains, and show that our HTN-learner algorithm is both effective and efficient.

#index 1305580
#* Adversarial uncertainty in multi-robot patrol
#@ Noa Agmon;Sarit Kraus;Gal A. Kaminka;Vladimir Sadov
#t 2009
#c 11
#% 774295
#% 890236
#% 1024857
#% 1084017
#% 1084018
#% 1155821
#% 1215557
#! We study the problem of multi-robot perimeter patrol in adversarial environments, under uncertainty of adversarial behavior. The robots patrol around a closed area using a nondeterministic patrol algorithm. The adversary's choice of penetration point depends on the knowledge it obtained on the patrolling algorithm and its weakness points. Previous work investigated full knowledge and zero knowledge adversaries, and the impact of their knowledge on the optimal algorithm for the robots. However, realistically the knowledge obtained by the adversary is neither zero nor full, and therefore it will have uncertainty in its choice of penetration points. This paper considers these cases, and offers several approaches to bounding the level of uncertainty of the adversary, and its influence on the optimal patrol algorithm. We provide theoretical results that justify these approaches, and empirical results that show the performance of the derived algorithms used by simulated robots working against humans playing the role of the adversary is several different settings.

#index 1305581
#* Evaluating description and reference strategies in a cooperative human-robot dialogue system
#@ Mary Ellen Foster;Manuel Giuliani;Amy Isard;Colin Matheson;Jon Oberlander;Alois Knoll
#t 2009
#c 11
#% 398946
#% 741919
#% 746897
#% 939631
#% 1041913
#% 1126206
#% 1215304
#% 1223313
#% 1330536
#% 1392237
#! We present a human-robot dialogue system that enables a robot to work together with a human user to build wooden construction toys. We then describe a study which assessed the responses of naïve users to output that varied along two dimensions: the method of describing an assembly plan (preorder or post-order), and the method of referring to objects in the world (basic and full). Varying both of these factors produced significant results: subjects using the system that employed a preorder description strategy asked for instructions to be repeated significantly less often than those who experienced the post-order strategy, while the subjects who heard references generated by the full reference strategy judged the robot's instructions to be significantly more understandable than did those who heard the output of the basic strategy.

#index 1305582
#* Incremental Phi*: incremental any-angle path planning on grids
#@ Alex Nash;Sven Koenig;Maxim Likhachev
#t 2009
#c 11
#% 443547
#% 578727
#% 655327
#% 1269574
#% 1269858
#% 1290111
#! We study path planning on grids with blocked and unblocked cells. Any-angle path-planning algorithms find short paths fast because they propagate information along grid edges without constraining the resulting paths to grid edges. Incremental pathplanning algorithms solve a series of similar pathplanning problems faster than repeated single-shot searches because they reuse information from the previous search to speed up the next one. In this paper, we combine these ideas by making the anyangle path-planning algorithm Basic Theta* incremental. This is non-trivial because Basic Theta* does not fit the standard assumption that the parent of a vertex in the search tree must also be its neighbor. We present Incremental Phi* and show experimentally that it can speed up Basic Theta* by about one order of magnitude for path planning with the freespace assumption.

#index 1305583
#* Information-lookahead planning for AUV mapping
#@ Zeyn A. Saigol;Richard W. Dearden;Jeremy L. Wyatt;Bramley J. Murton
#t 2009
#c 11
#% 788054
#% 823963
#% 1270306
#% 1272231
#% 1650355
#! Exploration for robotic mapping is typically handled using greedy entropy reduction. Here we show how to apply information lookahead planning to a challenging instance of this problem in which an Autonomous Underwater Vehicle (AUV) maps hydrothermal vents. Given a simulation of vent behaviour we derive an observation function to turn the planning for mapping problem into a POMDP. We test a variety of information state MDP algorithms against greedy, systematic and reactive search strategies. We show that directly rewarding the AUV for visiting vents induces effective mapping strategies. We evaluate the algorithms in simulation and show that our information lookahead method outperforms the others.

#index 1305584
#* Self-supervised aerial image analysis for extracting parking lot structure
#@ Young-Woo Seo;Nathan Ratliff;Chris Urmson
#t 2009
#c 11
#% 78784
#% 191603
#% 622091
#% 891559
#% 1022958
#% 1066983
#% 1077644
#! Road network information simplifies autonomous driving by providing strong priors about environments. It informs a robotic vehicle with where it can drive, models of what can be expected, and contextual cues that influence driving behaviors. Currently, however, road network information is manually generated using a combination of GPS survey and aerial imagery. These manual techniques are labor intensive and error prone. To fully exploit the benefits of digital imagery, these processes should be automated. As a step toward this goal, we present an algorithm that extracts the structure of a parking lot visible from a given aerial image. To minimize human intervention in the use of aerial imagery, we devise a self-supervised learning algorithm that automatically generates a set of parking spot templates to learn the appearance of a parking lot and estimates the structure of the parking lot from the learned model. The data set extracted from a single image alone is too small to sufficiently learn an accurate parking spot model. However, strong priors trained using large data sets collected across multiple images dramatically improve performance. Our self-supervised approach outperforms the prior alone by adapting the distribution of examples toward that found in the current image. A thorough empirical analysis compares leading state-of-the-art learning techniques on this problem.

#index 1305585
#* Nonmyopic adaptive informative path planning for multiple robots
#@ Amarjeet Singh;Andreas Krause;William J. Kaiser
#t 2009
#c 11
#% 723894
#% 757953
#% 836516
#% 840868
#% 862540
#% 983860
#% 1039650
#% 1074346
#% 1269765
#% 1272055
#% 1275108
#! Many robotic path planning applications, such as search and rescue, involve uncertain environments with complex dynamics that can be only partially observed. When selecting the best subset of observation locations subject to constrained resources (such as limited time or battery capacity) it is an important problem to trade off exploration (gathering information about the environment) and exploitation (using the current knowledge about the environment most effectively) for efficiently observing these environments. Even the nonadaptive setting, where paths are planned before observations are made, is NP-hard, and has been subject to much research. In this paper, we present a novel approach to adaptive informative path planning that addresses this exploration-exploitation tradeoff. Our approach is nonmyopic, i.e. it plans ahead for possible observations that can be made in the future. We quantify the benefit of exploration through the "adaptivity gap" between an adaptive and a nonadaptive algorithm in terms of the uncertainty in the environment. Exploiting the submodularity (a diminishing returns property) and locality properties of the objective function, we develop an algorithm that performs provably near-optimally in settings where the adaptivity gap is small. In case of large gap, we use an objective function that simultaneously optimizes paths for exploration and exploitation. We also provide an algorithm to extend any single robot algorithm for adaptive informative path planning to the multi robot setting while approximately preserving the theoretical guarantee of the single robot algorithm. We extensively evaluate our approach on a search and rescue domain and a scientific monitoring problem using a real robotic system.

#index 1305586
#* Learning kinematic models for articulated objects
#@ Jürgen Sturm;Vijay Pradeep;Cyrill Stachniss;Christian Plagemann;Kurt Konolige;Wolfram Burgard
#t 2009
#c 11
#% 784819
#% 883815
#% 891549
#% 909790
#% 1148291
#% 1289578
#! Robots operating in home environments must be able to interact with articulated objects such as doors or drawers. Ideally, robots are able to autonomously infer articulation models by observation. In this paper, we present an approach to learn kinematic models by inferring the connectivity of rigid parts and the articulation models for the corresponding links. Our method uses a mixture of parameterized and parameter-free (Gaussian process) representations and finds low-dimensional manifolds that provide the best explanation of the given observations. Our approach has been implemented and evaluated using real data obtained in various realistic home environment settings.

#index 1305587
#* A computational model for the alignment of hierarchical scene representations in human-robot interaction
#@ Agnes Swadzba;Sven Wachsmuth;Constanze Vorwerg;Gert Rickheit
#t 2009
#c 11
#% 449015
#% 578701
#% 578743
#% 724234
#% 736300
#% 760805
#% 828841
#% 900206
#% 954817
#% 1063859
#% 1275087
#% 1407860
#! The ultimate goal of human-robot interaction is to enable the robot to seamlessly communicate with a human in a natural human-like fashion. Most work in this field concentrates on the speech interpretation and gesture recognition side assuming that a propositional scene representation is available. Less work was dedicated to the extraction of relevant scene structures that underlies these propositions. As a consequence, most approaches are restricted to place recognition or simple table top settings and do not generalize to more complex room setups. In this paper, we propose a hierarchical spatial model that is empirically motivated from psycholinguistic studies. Using this model the robot is able to extract scene structures from a time-of-flight depth sensor and adjust its spatial scene representation by taking verbal statements about partial scene aspects into account. Without assuming any pre-known model of the specific room, we show that the system aligns its sensor-based room representation to a semantically meaningful representation typically used by the human descriptor.

#index 1305588
#* Domain-guided novelty detection for autonomous exploration
#@ David R. Thompson
#t 2009
#c 11
#% 731721
#% 781774
#% 855602
#% 924022
#% 954340
#% 1164193
#% 1730641
#! In this work, novelty detection identifies salient image features to guide autonomous robotic exploration. There is little advance knowledge of the features in the scene or the proportion that should count as outliers. A new algorithm addresses this ambiguity by modeling novel data in advance and characterizing regular data at run time. Detection thresholds adapt dynamically to reduce misclassification risk while accommodating homogeneous and heterogeneous scenes. Experiments demonstrate the technique on a representative set of navigation images from the Mars Exploration Rover "Opportunity." An efficient image analysis procedure filters each image using the integral transform. Pixel-level features are aggregated into covariance descriptors that represent larger regions. Finally, a distance metric derived from generalized eigenvalues permits novelty detection with kernel density estimation. Results suggest that exploiting training examples of novel data can improve performance in this domain.

#index 1305589
#* Tractable multi-agent path planning on grid maps
#@ Ko-Hsin Cindy Wang;Adi Botea
#t 2009
#c 11
#% 6451
#% 367254
#% 1084390
#% 1272212
#! Multi-agent path planning on grid maps is a challenging problem and has numerous real-life applications. Running a centralized, systematic search such as A* is complete and cost-optimal but scales up poorly in practice, since both the search space and the branching factor grow exponentially in the number of mobile units. Decentralized approaches, which decompose a problem into several subproblems, can be faster and can work for larger problems. However, existing decentralized methods offer no guarantees with respect to completeness, running time, and solution quality. To address such limitations, we introduce MAPP, a tractable algorithm for multi-agent path planning on grid maps. We show that MAPP has low-polynomial worst-case upper bounds for the running time, the memory requirements, and the length of solutions. As it runs in low-polynomial time, MAPP is incomplete in the general case. We identify a class of problems for which our algorithm is complete. We believe that this is the first study that formalises restrictions to obtain a tractable class of multi-agent path planning problems.

#index 1305590
#* Human activity encoding and recognition using low-level visual features
#@ Zheshen Wang;Baoxin Li
#t 2009
#c 11
#% 58593
#% 179696
#% 309208
#% 722925
#% 732531
#% 775269
#% 830744
#% 1066707
#% 1270302
#% 1272356
#% 1289474
#! Automatic recognition of human activities is among the key capabilities of many intelligent systems with vision/perception. Most existing approaches to this problem require sophisticated feature extraction before classification can be performed. This paper presents a novel approach for human action recognition using only simple low-level visual features: motion captured from direct frame differencing. A codebook of key poses is first created from the training data through unsupervised clustering. Videos of actions are then coded as sequences of super-frames, defined as the key poses augmented with discriminative attributes. A weighted-sequence distance is proposed for comparing two super-frame sequences, which is further wrapped as a kernel embedded in a SVM classifier for the final classification. Compared with conventional methods, our approach provides a flexible non-parametric sequential structure with a corresponding distance measure for human action representation and classification without requiring complex feature extraction. The effectiveness of our approach is demonstrated with the widely-used KTH human activity dataset, for which the proposed method outperforms the existing state-of-the-art.

#index 1305591
#* Markov network based ontology matching
#@ Sivan Albagli;Rachel Ben-Eliyahu-Zohary;Solomon E. Shimony
#t 2009
#c 11
#% 44876
#% 288885
#% 348187
#% 529190
#% 551850
#% 660001
#% 924747
#% 1655419
#% 1810385
#! iMatch is a probabilistic scheme for ontology matching based on Markov networks, which has several advantages over other probabilistic schemes. First, it uses undirected networks, which better supports the non-causal nature of the dependencies. Second, it handles the high computational complexity by doing approximate reasoning, rather then by ad-hoc pruning. Third, the probabilities that it uses are learned from matched data. Finally, iMatch naturally supports interactive semi-automatic matches. Experiments using the standard benchmark tests that compare our approach with the most promising existing systems show that iMatch is one of the top performers.

#index 1305592
#* Ceteris Paribus preference elicitation with predictive guarantees
#@ Yannis Dimopoulos;Loizos Michael;Fani Athienitou
#t 2009
#c 11
#% 697
#% 180945
#% 1223287
#% 1272026
#% 1272103
#% 1272396
#! CP-networks have been proposed as a simple and intuitive graphical tool for representing conditional ceteris paribus preference statements over the values of a set of variables. While the problem of reasoning with CP-networks has been receiving some attention, there are very few works that address the problem of learning CP-networks. In this work we investigate the task of learning CP-networks, given access to a set of pairwise comparisons. We first prove that the learning problem is intractable, even under several simplifying assumptions. We then present an algorithm that, under certain assumptions about the observed pairwise comparisons, identifies a CP-network that entails these comparisons. We finally show that the proposed algorithm is a PAC-learner, and, thus, that the CP-networks it induces accurately predict the user's preferences on previously unseen situations.

#index 1305593
#* Fast recommendations using GAI models
#@ Jean-Philippe Dubus;Christophe Gonzales;Patrice Perny
#t 2009
#c 11
#% 289951
#% 380725
#% 388024
#% 424793
#% 495627
#% 528176
#% 540381
#% 1272026
#% 1272103
#% 1650628
#! This paper deals with Decision-Making in the context of multiattribute utility theory and, more precisely, with the problem of efficiently determining the best alternative w.r.t. an agent's preferences (choice problem). We assume that alternatives are elements of a product set of attributes and that the agent's preferences are represented by a generalized additive decomposable (GAI) utility on this set. Such a function allows an efficient representation of interactions between attributes while preserving some decomposability of the model. GAI utilities can be compiled into graphical structures called GAI networks that can be exploited to solve choice problems using collect/distribute schemes essentially similar to those used in Bayesian networks. In this paper, rather than directly using this scheme on the GAI network for determining the most preferred alternative, we propose to work with another GAI function, acting as an upper-bound on utility values and enhancing the model's decomposability. This method still provides the exact optimal solution but speeds up significantly the search. It proves to be particularly useful when dealing with choice and ranking under constraints and within collective Decision-Making, where GAI nets tend to have a large size. We present an efficient algorithm for determining this new GAI function and provide experimental results highlighting the practical efficiency of our procedure.

#index 1305594
#* Multiobjective optimization using GAI models
#@ Jean-Philippe Dubus;Christophe Gonzales;Patrice Perny
#t 2009
#c 11
#% 102372
#% 380725
#% 388024
#% 449999
#% 528176
#% 593993
#% 857276
#% 1223534
#% 1269708
#% 1404848
#% 1650628
#! This paper deals with multiobjective optimization in the context of multiattribute utility theory. The alternatives (feasible solutions) are seen as elements of a product set of attributes and preferences over solutions are represented by generalized additive decomposable (GAI) utility functions modeling individual preferences or criteria. Due to decomposability, utility vectors attached to solutions can be compiled into a graphical structure closely related to junction trees, the so-called GAI net. We first show how the structure of the GAI net can be used to determine efficiently the exact set of Pareto-optimal solutions in a product set and provide numerical tests on random instances. Since the exact determination of the Pareto set is intractable in worst case, we propose a near admissible algorithm with performance guarantee, exploiting the GAI structure to approximate the set of Pareto optimal solutions. We present numerical experimentations, showing that both utility decomposition and approximation significantly improve resolution times in multiobjective search problems.

#index 1305595
#* Greedy algorithms for sequential sensing decisions
#@ Hannaneh Hajishirzi;Afsaneh Shirazi;Jaesik Choi;Eyal Amir
#t 2009
#c 11
#% 179940
#% 252183
#% 329488
#% 329490
#% 576214
#% 703709
#% 715251
#% 731406
#% 842579
#% 1016159
#% 1272075
#% 1289461
#! In many real-world situations we are charged with detecting change as soon as possible. Important examples include detecting medical conditions, detecting security breaches, and updating caches of distributed databases. In those situations, sensing can be expensive, but it is also important to detect change in a timely manner. In this paper we present tractable greedy algorithms and prove that they solve this decision problem either optimally or approximate the optimal solution in many cases. Our problem model is a POMDP that includes a cost for sensing, a cost for delayed detection, a reward for successful detection, and no-cost partial observations. Making optimal decisions is difficult in general. We show that our tractable greedy approach finds optimal policies for sensing both a single variable and multiple correlated variables. Further, we provide approximations for the optimal solution to multiple hidden or observed variables per step. Our algorithms outperform previous algorithms in experiments over simulated data and live Wikipedia WWW pages.

#index 1305596
#* Generalized first order decision diagrams for first order Markov decision processes
#@ Saket Joshi;Kristian Kersting;Roni Khardon
#t 2009
#c 11
#% 33376
#% 233849
#% 363744
#% 770823
#% 1178635
#% 1272131
#% 1272210
#% 1289241
#% 1650297
#! First order decision diagrams (FODD) were recently introduced as a compact knowledge representation expressing functions over relational structures. FODDs represent numerical functions that, when constrained to the Boolean range, use only existential quantification. Previous work developed a set of operations over FODDs, showed how they can be used to solve relational Markov decision processes (RMDP) using dynamic programming algorithms, and demonstrated their success in solving stochastic planning problems from the International Planning Competition in the system FODD-Planner. A crucial ingredient of this scheme is a set of operations to remove redundancy in decision diagrams, thus keeping them compact. This paper makes three contributions. First, we introduce Generalized FODDs (GFODD) and combination algorithms for them, generalizing FODDs to arbitrary quantification. Second, we show how GFODDs can be used in principle to solve RMDPs with arbitrary quantification, and develop a particularly promising case where an arbitrary number of existential quantifiers is followed by an arbitrary number of universal quantifiers. Third, we develop a new approach to reduce FODDs and GFODDs using model checking. This yields a reduction that is complete for FODDs and provides a sound reduction procedure for GFODDs.

#index 1305597
#* Lifted aggregation in directed first-order probabilistic models
#@ Jacek Kisynski;David Poole
#t 2009
#c 11
#% 6199
#% 529159
#% 983845
#% 1000502
#% 1270256
#% 1272302
#% 1279353
#% 1349569
#% 1416197
#% 1416205
#% 1650731
#! As exact inference for first-order probabilistic graphical models at the propositional level can be formidably expensive, there is an ongoing effort to design efficient lifted inference algorithms for such models. This paper discusses directed first-order models that require an aggregation operator when a parent random variable is parameterized by logical variables that are not present in a child random variable. We introduce a new data structure, aggregation parfactors, to describe aggregation in directed first-order models. We show how to extend Milch et al.'s C-FOVE algorithm to perform lifted inference in the presence of aggregation parfactors. We also show that there are cases where the polynomial time complexity (in the domain size of logical variables) of the C-FOVE algorithm can be reduced to logarithmic time complexity using aggregation parfactors.

#index 1305598
#* Learning conditional preference networks with queries
#@ Frédéric Koriche;Bruno Zanuttini
#t 2009
#c 11
#% 73369
#% 131685
#% 198240
#% 222440
#% 450951
#% 451055
#% 451056
#% 770816
#% 1132535
#% 1272026
#% 1289345
#% 1305424
#! We investigate the problem of eliciting CP-nets in the well-known model of exact learning with equivalence and membership queries. The goal is to identify a preference ordering with a binary-valued CP-net by guiding the user through a sequence of queries. Each example is a dominance test on some pair of outcomes. In this setting, we show that acyclic CP-nets are not learnable with equivalence queries alone, while they are learnable with the help of membership queries if the supplied examples are restricted to swaps. A similar property holds for tree CP-nets with arbitrary examples. In fact, membership queries allow us to provide attribute-efficient algorithms for which the query complexity is only logarithmic in the number of attributes. Such results highlight the utility of this model for eliciting CP-nets in large multi-attribute domains.

#index 1305599
#* A sparse covariance function for exact Gaussian process inference in large datasets
#@ Arman Melkumyan;Fabio Ramos
#t 2009
#c 11
#% 891549
#% 916792
#! Despite the success of Gaussian processes (GPs) in modelling spatial stochastic processes, dealing with large datasets is still challenging. The problem arises by the need to invert a potentially large covariance matrix during inference. In this paper we address the complexity problem by constructing a new stationary covariance function (Mercer kernel) that naturally provides a sparse covariance matrix. The sparseness of the matrix is defined by hyperparameters optimised during learning. The new covariance function enables exact GP inference and performs comparatively to the squared-exponential one, at a lower computational cost. This allows the application of GPs to large-scale problems such as ore grade prediction in mining or 3D surface modelling. Experiments show that using the proposed covariance function, very sparse covariance matrices are normally obtained which can be effectively used for faster inference and less memory usage.

#index 1305600
#* CTPPL: a continuous time probabilistic programming language
#@ Avi Pfeffer
#t 2009
#c 11
#% 997869
#% 1269463
#% 1269514
#% 1271978
#% 1289566
#! Probabilistic programming languages allow a modeler to build probabilistic models using complex data structures with all the power of a programming language. We present CTPPL, an expressive probabilistic programming language for dynamic processes that models processes using continuous time. Time is a first class element in our language; the amount of time taken by a subprocess can be specified using the full power of the language. We show through examples that CTPPL can easily represent existing continuous time frameworks and makes it easy to represent new ones. We present semantics for CTPPL in terms of a probability measure over trajectories. We present a particle filtering algorithm for the language that works for a large and useful class of CTPPL programs.

#index 1305601
#* Speeding up inference in Markov logic networks by preprocessing to reduce the size of the resulting grounded network
#@ Jude Shavlik;Sriraam Natarajan
#t 2009
#c 11
#% 271128
#% 576214
#% 729913
#% 1000502
#% 1127415
#% 1269815
#% 1270256
#% 1270258
#% 1270261
#% 1289560
#% 1349569
#% 1467732
#! Statistical-relational reasoning has received much attention due to its ability to robustly model complex relationships. A key challenge is tractable inference, especially in domains involving many objects, due to the combinatorics involved. One can accelerate inference by using approximation techniques, "lazy" algorithms, etc. We consider Markov Logic Networks (MLNs), which involve counting how often logical formulae are satisfied. We propose a preprocessing algorithm that can substantially reduce the effective size of MLNs by rapidly counting how often the evidence satisfies each formula, regardless of the truth values of the query literals. This is a general preprocessing method that loses no information and can be used for any MLN inference algorithm. We evaluate our algorithm empirically in three real-world domains, greatly reducing the work needed during subsequent inference. Such reduction might even allow exact inference to be performed when sampling methods would be otherwise necessary.

#index 1305602
#* Testing edges by truncations
#@ Ilya Shpitser;Thomas S. Richardson;James M. Robins
#t 2009
#c 11
#% 44876
#% 129987
#% 297171
#% 578740
#% 1250349
#% 1270259
#% 1650407
#% 1650678
#! We consider the problem of testing whether two variables should be adjacent (either due to a direct effect between them, or due to a hidden common cause) given an observational distribution, and a set of causal assumptions encoded as a causal diagram. In other words, given a set of edges in the diagram known to be true, we are interested in testing whether another edge ought to be in the diagram. In fully observable faithful models this problem can be easily solved with conditional independence tests. Latent variables make the problem significantly harder since they can imply certain non-adjacent variable pairs, namely those connected by so called inducing paths, are not independent conditioned on any set of variables. We characterize which variable pairs can be determined to be non-adjacent by a class of constraints due to dormant independence, that is conditional independence in identifiable interventional distributions. Furthermore, we show that particular operations on joint distributions, which we call truncations are sufficient for exhibiting these non-adjacencies.This suggests a causal discovery procedure taking advantage of these constraints in the latent variable case can restrict itself to truncations.

#index 1305603
#* Variable and value ordering for MPE search
#@ Sajjad Siddiqi;Jinbo Huang
#t 2009
#c 11
#% 448887
#% 1269433
#% 1289558
#% 1673025
#! In Bayesian networks, a most probable explanation (MPE) is a most likely instantiation of all network variables given a piece of evidence. Recent work proposed a branch-and-bound search algorithm that finds exact solutions to MPE queries, where bounds are computed on a relaxed network obtained by a technique known as node splitting. In this work we study the impact of variable and value ordering on such a search algorithm. We study several heuristics based on the entropies of variables and on the notion of nogoods, and propose a new meta-heuristic that combines their strengths. Experiments indicate that search efficiency is significantly improved, allowing many hard problems to be solved for the first time.

#index 1305604
#* Parameter identification in a class of linear structural equation models
#@ Jin Tian
#t 2009
#c 11
#% 70370
#% 297171
#% 375029
#% 578735
#% 1250135
#% 1269413
#% 1269874
#% 1650356
#! Linear causal models known as structural equation models (SEMs) are widely used for data analysis in the social sciences, economics, and artificial intelligence, in which random variables are assumed to be continuous and normally distributed. This paper deals with one fundamental problem in the applications of SEMs - parameter identification. The paper uses the graphical models approach and provides a procedure for solving the identification problem in a special class of SEMs.

#index 1305605
#* Learning a value analysis tool for agent evaluation
#@ Martha White;Michael Bowling
#t 2009
#c 11
#% 1250598
#! Evaluating an agent's performance in a stochastic setting is necessary for agent development, scientific evaluation, and competitions. Traditionally, evaluation is done using Monte Carlo estimation; the magnitude of the stochasticity in the domain or the high cost of sampling, however, can often prevent the approach from resulting in statistically significant conclusions. Recently, an advantage sum technique has been proposed for constructing unbiased, low variance estimates of agent performance. The technique requires an expert to define a value function over states of the system, essentially a guess of the state's unknown value. In this work, we propose learning this value function from past interactions between agents in some target population. Our learned value functions have two key advantages: they can be applied in domains where no expert value function is available and they can result in tuned evaluation for a specific population of agents (e.g., novice versus advanced agents). We demonstrate these two advantages in the domain of poker. We show that we can reduce variance over state-of-the-art estimators for a specific population of limit poker players as well as construct the first variance reducing estimators for no-limit poker and multi-player limit poker.

#index 1305606
#* Efficient computation of jointree bounds for systematic MAP search
#@ Changhe Yuan;Eric A. Hansen
#t 2009
#c 11
#% 172544
#% 205391
#% 283314
#% 302413
#% 448887
#% 528175
#% 788111
#% 1250337
#% 1275137
#% 1289558
#% 1650391
#% 1673033
#! The MAP (maximum a posteriori assignment) problem in Bayesian networks is the problem of finding the most probable instantiation of a set of variables given partial evidence for the remaining variables. The state-of-the-art exact solution method is depth-first branch-and-bound search using dynamic variable ordering and a jointree upper bound proposed by Park and Darwiche [2003]. Since almost all search time is spent computing the jointree bounds, we introduce an efficient method for computing these bounds incrementally. We point out that, using a static variable ordering, it is only necessary to compute relevant upper bounds at each search step, and it is also possible to cache potentials of the jointree for efficient backtracking. Since the jointree computation typically produces bounds for joint configurations of groups of variables, our method also instantiates multiple variables at each search step, instead of a single variable, in order to reduce the number of times that upper bounds need to be computed. Experiments show that this approach leads to orders of magnitude reduction in search time.

#index 1305607
#* A syntax-based framework for merging imprecise probabilistic logic programs
#@ Anbu Yue;Weiru Liu
#t 2009
#c 11
#% 137467
#% 191854
#% 336009
#% 772063
#% 808364
#% 808860
#% 943104
#% 946596
#! In this paper, we address the problem of merging multiple imprecise probabilistic beliefs represented as Probabilistic Logic Programs (PLPs) obtained from multiple sources. Beliefs in each PLP are modeled as conditional events attached with probability bounds. The major task of syntax-based merging is to obtain the most rational probability bound for each conditional event from the original PLPs to form a new PLP. We require the minimal change principle to be followed so that each source gives up its beliefs as little as possible. Some instantiated merging operators are derived from our merging framework. Furthermore, we propose a set of postulates for merging PLPs, some of which extend the postulates for merging classical knowledge bases, whilst others are specific to the merging of probabilistic beliefs.

#index 1305608
#* Speeding up exact solutions of interactive dynamic influence diagrams using action equivalence
#@ Yifeng Zeng;Prashant Doshi
#t 2009
#c 11
#% 252183
#% 643112
#% 890362
#% 1171119
#% 1269836
#% 1272071
#% 1272129
#% 1279314
#% 1289289
#! Interactive dynamic influence diagrams (I-DIDs) are graphical models for sequential decision making in partially observable settings shared by other agents. Algorithms for solving I-DIDs face the challenge of an exponentially growing space of candidate models ascribed to other agents, over time. Previous approach for exactly solving I-DIDs groups together models having similar solutions into behaviorally equivalent classes and updates these classes. We present a new method that, in addition to aggregating behaviorally equivalent models, further groups models that prescribe identical actions at a single time step. We show how to update these augmented classes and prove that our method is exact. The new approach enables us to bound the aggregated model space by the cardinality of other agents' actions. We evaluate its performance and provide empirical results in support.

#index 1305609
#* A general approach to environment design with one agent
#@ Haoqi Zhang;Yiling Chen;David Parkes
#t 2009
#c 11
#% 573678
#% 580515
#% 766225
#% 1222651
#% 1270052
#! The problem of environment design considers a setting in which an interested party aims to influence an agent's decisions by making limited changes to the agent's environment. Zhang and Parkes [2008] first introduced the environment design concept for a specific problem in the Markov Decision Process setting. In this paper, we present a general framework for the formulation and solution of environment design problems with one agent. We consider both the case in which the agent's local decision model is known and partially unknown to the interested party, and illustrate the framework and results on a linear programming setting. For the latter problem, we formulate an active, indirect elicitation method and provide conditions for convergence and logarithmic convergence. We relate to the problem of inverse optimization and also offer a game-theoretic interpretation of our methods.

#index 1305610
#* DL-LITER in the light of propositional logic for decentralized data management
#@ N. Abdallah;F. Goasdoué;M.-C. Rousset
#t 2009
#c 11
#% 572307
#% 572311
#% 992962
#% 1016250
#% 1058254
#% 1272100
#% 1289442
#% 1396154
#% 1405506
#! This paper provides a decentralized data model and associated algorithms for peer data management systems (PDMS) based on the DL-LITER description logic. Our approach relies on reducing query reformulation and consistency checking for DL-LITER into reasoning in propositional logic. This enables a straightforward deployment of DL-LITER PDMSs on top of Some Where, a scalable propositional peer-to-peer inference system. We also show how to use the state-of-the-art Minicon algorithm for rewriting queries using views in DL-LITER in the centralized and decentralized cases.

#index 1305611
#* Sketching techniques for collaborative filtering
#@ Yoram Bachrach;Ely Porat;Jeffrey S. Rosenschein
#t 2009
#c 11
#% 124010
#% 173879
#% 202011
#% 311808
#% 329790
#% 419377
#% 479973
#% 548654
#% 578389
#% 643568
#% 1023422
#% 1215859
#! Recommender systems attempt to highlight items that a target user is likely to find interesting. A common technique is to use collaborative filtering (CF), where multiple users share information so as to provide each with effective recommendations. A key aspect of CF systems is finding users whose tastes accurately reflect the tastes of some target user. Typically, the system looks for other agents who have had experience with many of the items the target user has examined, and whose classification of these items has a strong correlation with the classifications of the target user. Since the universe of items may be enormous and huge data sets are involved, sophisticated methods must be used to quickly locate appropriate other agents. We present a method for quickly determining the proportional intersection between the items that each of two users has examined, by sending and maintaining extremely concise "sketches" of the list of items. These sketches enable the approximation of the proportional intersection within a distance of ε, with a high probability of 1 - δ. Our sketching techniques are based on random min-wise independent hash functions, and use very little space and time, so they are well-suited for use in large-scale collaborative filtering systems.

#index 1305612
#* Spatial processes for recommender systems
#@ Fabian Bohnert;Daniel F. Schmidt;Ingrid Zukerman
#t 2009
#c 11
#% 220706
#% 280852
#% 330687
#% 414514
#% 876081
#% 945224
#% 1132541
#% 1650569
#! Spatial processes are typically used to analyse and predict geographic data. This paper adapts such models to predicting a user's interests (i. e., implicit item ratings) within a recommender system in the museum domain. We present the theoretical framework for a model based on Gaussian spatial processes, and discuss efficient algorithms for parameter estimation. Our model was evaluated with a real-world dataset collected by tracking visitors in a museum, attaining a higher predictive accuracy than state-of-the-art collaborative filters.

#index 1305613
#* Dynamic selection of ontological alignments: a space reduction mechanism
#@ Paul Doran;Valentina Tamma;Terry R. Payne;Ignazio Palmisano
#t 2009
#c 11
#% 869464
#% 924747
#% 1019063
#% 1024904
#% 1083965
#% 1092060
#% 1272206
#% 1274824
#% 1413139
#! Effective communication in open environments relies on the ability of agents to reach a mutual understanding of the exchanged message by reconciling the vocabulary (ontology) used. Various approaches have considered how mutually acceptable mappings between corresponding concepts in the agents' own ontologies may be determined dynamically through argumentation-based negotiation (such as Meaning-based Argumentation). However, the complexity of this process is high, approaching Π2(p)-complete in some cases. As reducing this complexity is non-trivial, we propose the use of ontology modularization as a means of reducing the space over which possible concepts are negotiated. The suitability of different modularization approaches as filtering mechanisms for reducing the negotiation search space is investigated, and a framework that integrates modularization with Meaning-based Argumentation is proposed. We empirically demonstrate that some modularization approaches not only reduce the number of alignments required to reach consensus, but also predict those cases where a service provider is unable to satisfy a request, without the need for negotiation.

#index 1305614
#* Improving search in social networks by agent based mining
#@ Anil Gürsel;Sandip Sen
#t 2009
#c 11
#% 220708
#% 268079
#% 301590
#% 643087
#% 883616
#% 961567
#! The popularity of social networks have burgeoned in recent years. Users share and access large volumes of information on social networking sites like Facebook, Flickr, del.icio.us, etc. Whereas a few of these sites have generic, impersonal searching mechanisms, we have developed an agent-based framework that mines the social network of a user to improve search results. Our Social Network-based Item Search (SNIS) system uses agents that utilize the connections of a user in the social network to facilitate the search for items of interest. Our approach generates targeted search results that can improve the precision of the result returned from a user's query. We have implemented the SNIS agent-based framework in Flickr, a photo-sharing social network, for searching for photos by using tag lists as search queries. We discuss the architecture of SNIS, motivate the searching scheme used, and demonstrate the effectiveness of the SNIS approach by presenting results. We also show how SNIS can be utilized for expertise location.

#index 1305615
#* Consequence-driven reasoning for horn SHIQ ontologies
#@ Yevgeny Kazakov
#t 2009
#c 11
#% 935898
#% 992964
#% 1289408
#! We present a novel reasoning procedure for Horn SHIQ ontologies--SHIQ ontologies that can be translated to the Horn fragment of first-order logic. In contrast to traditional reasoning procedures for ontologies, our procedure does not build models or model representations, but works by deriving new consequent axioms. The procedure is closely related to the so-called completion-based procedure for EL++ ontologies, and can be regarded as an extension thereof. In fact, our procedure is theoretically optimal for Horn SHIQ ontologies as well as for the common fragment of EL++ and SHIQ. A preliminary empirical evaluation of our procedure on large medical ontologies demonstrates a dramatic improvement over existing ontology reasoners. Specifically, our implementation allows the classification of the largest available OWL version of Galen. To the best of our knowledge no other reasoner is able to classify this ontology.

#index 1305616
#* Efficient estimation of influence functions for SIS model on social networks
#@ Masahiro Kimura;Kazumi Saito;Hiroshi Motoda
#t 2009
#c 11
#% 342596
#% 577217
#% 729923
#% 754107
#% 832271
#% 989613
#% 1092318
#% 1179993
#% 1269888
#! We address the problem of efficiently estimating the influence function of initially activated nodes in a social network under the susceptible/ infected/susceptible (SIS) model, a diffusion model where nodes are allowed to be activated multiple times. The computational complexity drastically increases because of this multiple activation property. We solve this problem by constructing a layered graph from the original social network with each layer added on top as the time proceeds, and applying the bond percolation with a pruning strategy. We show that the computational complexity of the proposed method is much smaller than the conventional naive probabilistic simulation method by a theoretical analysis and confirm this by applying the proposed method to two real world networks.

#index 1305617
#* Can movies and books collaborate?: cross-domain collaborative filtering for sparsity reduction
#@ Bin Li;Qiang Yang;Xiangyang Xue
#t 2009
#c 11
#% 173879
#% 330687
#% 495929
#% 818216
#% 844369
#% 881468
#% 983899
#% 1030863
#! The sparsity problem in collaborative filtering (CF) is a major bottleneck for most CF methods. In this paper, we consider a novel approach for alleviating the sparsity problem in CF by transferring useritem rating patterns from a dense auxiliary rating matrix in other domains (e.g., a popular movie rating website) to a sparse rating matrix in a target domain (e.g., a new book rating website). We do not require that the users and items in the two domains be identical or even overlap. Based on the limited ratings in the target matrix, we establish a bridge between the two rating matrices at a cluster-level of user-item rating patterns in order to transfer more useful knowledge from the auxiliary task domain. We first compress the ratings in the auxiliary rating matrix into an informative and yet compact cluster-level rating pattern representation referred to as a codebook. Then, we propose an efficient algorithm for reconstructing the target rating matrix by expanding the codebook. We perform extensive empirical tests to show that our method is effective in addressing the data sparsity problem by transferring the useful knowledge from the auxiliary tasks, as compared to many state-of-the-art CF methods.

#index 1305618
#* Using web photos for measuring video frame interestingness
#@ Feng Liu;Yuzhen Niu;Michael Gleicher
#t 2009
#c 11
#% 264161
#% 319464
#% 332007
#% 451652
#% 760805
#% 860092
#% 919709
#% 999537
#% 1074107
#% 1131865
#% 1149153
#! In this paper, we present a method that uses web photos for measuring frame interestingness of a travel video. Web photo collections, such as those on Flickr, tend to contain interesting images because their images are more carefully taken, composed, and selected. Because these photos have already been chosen as subjectively interesting, they serve as evidence that similar images are also interesting. Our idea is to leverage these web photos to measure the interestingness of video frames. Specifically, we measure the interestingness of each video frame according to its similarity to web photos. The similarity is defined based on the scene content and composition. We characterize the scene content using scale invariant local features, specifically SIFT keypoints. We characterize composition by feature distribution. Accordingly, we measure the similarity between a web photo and a video frame based on the co-occurrence of the SIFT features, and the similarity between their spatial distribution. Interestingness of a video frame is measured by considering how many photos it is similar to, and how similar it is to them. Our experiments on measuring frame interestingness of videos from YouTube using photos from Flickr show the initial success of our method.

#index 1305619
#* A content-based method to enhance tag recommendation
#@ Yu-Ta Lu;Shoou-I Yu;Tsung-Chieh Chang;Jane Yung-jen Hsu
#t 2009
#c 11
#% 152934
#% 280819
#% 406493
#% 813966
#% 855601
#% 881054
#% 956544
#% 1035588
#% 1074117
#% 1130827
#% 1130829
#% 1655418
#! Tagging has become a primary tool for users to organize and share digital content on many social media sites. In addition, tag information has been shown to enhance capabilities of existing search engines. However, many resources on the web still lack tag information. This paper proposes a content-based approach to tag recommendation which can be applied to webpages with or without prior tag information. While social bookmarking service such as Delicious enables users to share annotated bookmarks, tag recommendation is available only for pages with tags specified by other users. Our proposed approach is motivated by the observation that similar webpages tend to have the same tags. Each webpage can therefore share the tags they own with similar webpages. The propagation of a tag depends on its weight in the originating webpage and the similarity between the sending and receiving webpages. The similarity metric between two webpages is defined as a linear combination of four cosine similarities, taking into account both tag information and page content. Experiments using data crawled from Delicious show that the proposed method is effective in populating untagged webpages with the correct tags.

#index 1305620
#* Conjunctive query answering in the description logic EL using a relational database system
#@ Carsten Lutz;David Toman;Frank Wolter
#t 2009
#c 11
#% 162224
#% 941445
#% 992962
#% 1206804
#% 1274795
#% 1289408
#% 1405521
#% 1409925
#% 1409961
#! Conjunctive queries (CQ) are fundamental for accessing description logic (DL) knowledge bases. We study CQ answering in (extensions of) the DL EL, which is popular for large-scale ontologies and underlies the designated OWL2-EL profile of OWL2. Our main contribution is a novel approach to CQ answering that enables the use of standard relational database systems as the basis for query execution. We evaluate our approach using the IBM DB2 system, with encouraging results.

#index 1305621
#* Exploiting background knowledge to build reference sets for information extraction
#@ Matthew Michelson;Craig A. Knoblock
#t 2009
#c 11
#% 280849
#% 464434
#% 939924
#% 1022353
#% 1026925
#% 1250378
#% 1261583
#% 1272078
#% 1272213
#% 1289318
#% 1682424
#! Previous work on information extraction from unstructured, ungrammatical text (e.g. classified ads) showed that exploiting a set of background knowledge, called a "reference set," greatly improves the precision and recall of the extractions. However, finding a source for this reference set is often difficult, if not impossible. Further, even if a source is found, it might not overlap well with the text for extraction. In this paper we present an approach to building the reference set directly from the text itself. Our approach eliminates the need to find the source for the reference set, and ensures better overlap between the text and reference set. Starting with a small amount of background knowledge, our technique constructs tuples representing the entities in the text to form a reference set. Our results show that our method outperforms manually constructed reference sets, since hand built reference sets may not overlap with the entities in the unstructured, ungrammatical text. We also ran experiments comparing our method to the supervised approach of Conditional Random Fields (CRFs) using simple, generic features. These results show our method achieves an improvement in F1-measure for 6/9 attributes and is competitive in performance on the others, and this is without training data.

#index 1305622
#* Large-scale taxonomy mapping for restructuring and integrating wikipedia
#@ Simone Paolo Ponzetto;Roberto Navigli
#t 2009
#c 11
#% 207677
#% 405391
#% 817472
#% 843739
#% 939601
#% 956564
#% 1055735
#% 1130858
#% 1131827
#% 1250402
#% 1269899
#% 1270281
#% 1413152
#% 1707940
#! We present a knowledge-rich methodology for disambiguating Wikipedia categories with WordNet synsets and using this semantic information to restructure a taxonomy automatically generated from the Wikipedia system of categories. We evaluate against a manual gold standard and show that both category disambiguation and taxonomy restructuring perform with high accuracy. Besides, we assess these methods on automatically generated datasets and show that we are able to effectively enrich WordNet with a large number of instances from Wikipedia. Our approach produces an integrated resource, thus bringing together the fine-grained classification of instances in Wikipedia and a well-structured top-level taxonomy from WordNet.

#index 1305623
#* Towards ontology learning from folksonomies
#@ Jie Tang;Ho-fung Leung;Qiong Luo;Dewei Chen;Jibin Gong
#t 2009
#c 11
#% 406493
#% 445448
#% 722904
#% 726213
#% 840967
#% 855601
#% 956589
#% 1055681
#% 1409951
#! A folksonomy refers to a collection of user-defined tags with which users describe contents published on the Web. With the flourish of Web 2.0, folksonomies have become an important mean to develop the Semantic Web. Because tags in folksonomies are authored freely, there is a need to understand the structure and semantics of these tags in various applications. In this paper, we propose a learning approach to create an ontology that captures the hierarchical semantic structure of folksonomies. Our experimental results on two different genres of real world data sets show that our method can effectively learn the ontology structure from the folksonomies.

#index 1305624
#* Streamlining attacks on CAPTCHAs with a computer game
#@ Jeff Yan;Su-Yang Yu
#t 2009
#c 11
#% 718774
#% 729661
#% 736253
#% 751818
#% 1128869
#% 1128870
#! CAPTCHA has been widely deployed by commercial web sites as a security technology for purposes such as anti-spam. A common approach to evaluating the robustness of CAPTCHA is the use of machine learning techniques. Critical to this approach is the acquisition of an adequate set of labeled samples, on which the learning techniques are trained. However, such a sample labeling task is difficult for computers, since the strength of CAPTCHAs stems exactly from the difficulty computers have in recognizing either distorted texts or image contents. Therefore, until now, researchers have to manually label their samples, which is tedious and expensive. In this paper, we present Magic Bullet, a computer game that for the first time turns such sample labeling into a fun experience, and that achieves a labeling accuracy of as high as 98% for free. The game leverages human computation to address a task that cannot be easily automated, and it effectively streamlines the evaluation of CAPTCHAs. The game can also be used for other constructive purposes such as 1) developing better machine learning algorithms for handwriting recognition, and 2) training people's typing skills.

#index 1305625
#* Incorporating user behaviors in new word detection
#@ Yabin Zheng;Zhiyuan Liu;Maosong Sun;Liyun Ru;Yang Zhang
#t 2009
#c 11
#% 428272
#% 452563
#% 465906
#% 577220
#% 643007
#% 722935
#% 734594
#% 766409
#% 813966
#% 854783
#% 855182
#% 939729
#% 1650569
#% 1677212
#! In this paper, we proposed a novel method to detect new words in domain-specific fields based on user behaviors. First, we select the most representative words from domain-specific lexicon. Then combining with user behaviors, we try to discover the potential experts in this field who use those terminologies frequently. Finally, we make further efforts to identify new words from behaviors of those experts. Words used much more frequently in this community than others are most probably new words. In brief, our method follows a collaborative filtering way: first from words to find professional experts, then from experts to discover new words, which is different from the traditional new word detection methods. Our method achieves up to 0.86 in accuracy on a computer science related data set. Moreover, the proposed method can be easily extended to related words retrieval task. We compare our method with Google Sets and Bayesian Sets. Experiments show that our method and Bayesian Sets gives better results than Google Sets.

#index 1305627
#* Learning a value analysis tool for agent evaluation
#@ Martha White;Michael Bowling
#t 2009
#c 11
#% 1250598
#! Evaluating an agent's performance in a stochastic setting is necessary for agent development, scientific evaluation, and competitions. Traditionally, evaluation is done using Monte Carlo estimation; the magnitude of the stochasticity in the domain or the high cost of sampling, however, can often prevent the approach from resulting in statistically significant conclusions. Recently, an advantage sum technique has been proposed for constructing unbiased, low variance estimates of agent performance. The technique requires an expert to define a value function over states of the system, essentially a guess of the state's unknown value. In this work, we propose learning this value function from past interactions between agents in some target population. Our learned value functions have two key advantages: they can be applied in domains where no expert value function is available and they can result in tuned evaluation for a specific population of agents (e.g., novice versus advanced agents). We demonstrate these two advantages in the domain of poker. We show that we can reduce variance over state-of-the-art estimators for a specific population of limit poker players as well as construct the first variance reducing estimators for no-limit poker and multi-player limit poker.

#index 1501183
#* Proceedings of the ICMI 2006 and IJCAI 2007 international conference on Artifical intelligence for human computing
#@ Thomas S. Huang;Anton Nijholt;Maja Pantic;Alex Pentland
#t 2007
#c 11

#index 1501184
#* Foundations of human computing: facial expression and emotion
#@ Jeffrey F. Cohn
#t 2007
#c 11
#% 318793
#% 593601
#% 632406
#% 839970
#% 861206
#% 861253
#% 905410
#% 1548469
#% 1781690
#! Many people believe that emotions and subjective feelings are one and the same and that a goal of human-centered computing is emotion recognition. The first belief is outdated; the second mistaken. For human-centered computing to succeed, a different way of thinking is needed. Emotions are species-typical patterns that evolved because of their value in addressing fundamental life tasks. Emotions consist of multiple components, of which subjective feelings may be one. They are not directly observable, but inferred from expressive behavior, self-report, physiological indicators, and context. I focus on expressive facial behavior because of its coherence with other indicators and research. Among the topics included are measurement, timing, individual differences, dyadic interaction, and inference. I propose that design and implementation of perceptual user interfaces may be better informed by considering the complexity of emotion, its various indicators, measurement, individual differences, dyadic interaction, and problems of inference.

#index 1501185
#* Instinctive computing
#@ Yang Cai
#t 2007
#c 11
#% 68009
#% 136370
#% 181147
#% 191316
#% 214028
#% 238395
#% 260105
#% 292205
#% 294103
#% 325050
#% 375339
#% 457672
#% 616104
#% 622032
#% 630995
#% 655283
#% 752250
#% 840585
#% 855159
#% 858102
#% 905420
#% 945494
#% 945498
#% 948774
#% 1391490
#% 1678827
#% 1729947
#% 1729948
#% 1729950
#% 1730262
#% 1730264
#! Instinctive computing is a computational simulation of biological and cognitive instincts. It is a meta-program of life, just like universal gravity in nature. It profoundly influences how we look, feel, think, and act. If we want a computer to be genuinely intelligent and to interact naturally with us, we must give computers the ability to recognize, understand, even to have primitive instincts. In this paper, we will review the recent work in this area, the building blocks for the instinctive operating system, and potential applications. The paper proposes a 'bottom-up' approach that is focused on human basic instincts: forage, vigilance, reproduction, intuition and learning. They are the machine codes in human operating systems, where high-level programs, such as social functions can override the low-level instinct. However, instinctive computing has been always a default operation. Instinctive computing is the foundation of Ambient Intelligence as well as Empathic Computing. It is an essential part of Human Computing.

#index 1501186
#* Human computing and machine understanding of human behavior: a survey
#@ Maja Pantic;Alex Pentland;Anton Nijholt;Thomas S. Huang
#t 2007
#c 11
#% 27049
#% 266616
#% 344667
#% 440391
#% 592391
#% 643498
#% 729344
#% 733330
#% 733333
#% 733336
#% 736300
#% 752260
#% 769027
#% 775494
#% 775563
#% 784970
#% 795250
#% 802909
#% 802976
#% 803660
#% 806973
#% 814121
#% 814137
#% 860822
#% 861253
#% 883985
#% 884266
#% 889149
#% 905407
#% 905410
#% 905411
#% 905412
#% 905419
#% 975115
#% 975130
#% 1134895
#% 1295035
#% 1295115
#% 1501188
#% 1501190
#% 1501192
#% 1502533
#% 1548464
#% 1562511
#% 1781690
#! A widely accepted prediction is that computing will move to the background, weaving itself into the fabric of our everyday living spaces and projecting the human user into the foreground. If this prediction is to come true, then next generation computing should be about anticipatory user interfaces that should be human-centered, built for humans based on human models. They should transcend the traditional keyboard and mouse to include natural, humanlike interactive functions including understanding and emulating certain human behaviors such as affecti0ve and social signaling. This article discusses how far are we from enabling computers to understand human behavior.

#index 1501187
#* Audio-visual spontaneous emotion recognition
#@ Zhihong Zeng;Yuxiao Hu;Glenn I. Roisman;Zhen Wen;Yun Fu;Thomas S. Huang
#t 2007
#c 11
#% 235352
#% 238395
#% 324263
#% 575848
#% 593514
#% 593601
#% 593659
#% 625115
#% 625116
#% 711133
#% 724236
#% 724314
#% 726466
#% 736300
#% 781041
#% 812541
#% 812596
#% 839970
#% 839971
#% 861262
#% 881599
#% 881600
#% 881601
#% 881603
#% 905111
#% 905408
#% 905410
#% 905411
#% 905420
#% 938697
#% 969782
#% 1502533
#% 1548533
#% 1672334
#% 1775586
#% 1781690
#% 1860069
#! Automatic multimodal recognition of spontaneous emotional expressions is a largely unexplored and challenging problem. In this paper, we explore audio-visual emotion recognition in a realistic human conversation setting--the Adult Attachment Interview (AAI). Based on the assumption that facial expression and vocal expression are at the same coarse affective states, positive and negative emotion sequences are labeled according to Facial Action Coding System. Facial texture in visual channel and prosody in audio channel are integrated in the framework of Adaboost multi-stream hidden Markov model (AdaMHMM) in which the Adaboost learning scheme is used to build component HMM fusion. Our approach is evaluated in AAI spontaneous emotion recognition experiments.

#index 1501188
#* Modeling naturalistic affective states via facial, vocal, and bodily expressions recognition
#@ Kostas Karpouzis;George Caridakis;Loic Kessous;Noam Amir;Amaryllis Raouzaiou;Lori Malatesta;Stefanos Kollias
#t 2007
#c 11
#% 238395
#% 318793
#% 325050
#% 344556
#% 344667
#% 376589
#% 444046
#% 589652
#% 593659
#% 643498
#% 706929
#% 711133
#% 724331
#% 768293
#% 798871
#% 803660
#% 839970
#% 848062
#% 881602
#% 990972
#% 1378214
#% 1562579
#% 1672334
#% 1700099
#! Affective and human-centered computing have attracted a lot of attention during the past years, mainly due to the abundance of devices and environments able to exploit multimodal input from the part of the users and adapt their functionality to their preferences or individual habits. In the quest to receive feedback from the users in an unobtrusive manner, the combination of facial and hand gestures with prosody information allows us to infer the users' emotional state, relying on the best performing modality in cases where one modality suffers from noise or bad sensing conditions. In this paper, we describe a multi-cue, dynamic approach to detect emotion in naturalistic video sequences. Contrary to strictly controlled recording conditions of audiovisual material, the proposed approach focuses on sequences taken from nearly real world situations. Recognition is performed via a 'Simple Recurrent Network' which lends itself well to modeling dynamic events in both user's facial expressions and speech. Moreover this approach differs from existing work in that it models user expressivity using a dimensional representation of activation and valence, instead of detecting discrete 'universal emotions', which are scarce in everyday human-machine interaction. The algorithm is deployed on an audiovisual database which was recorded simulating human-human discourse and, therefore, contains less extreme expressivity and subtle variations of a number of emotion labels.

#index 1501189
#* Emotion and reinforcement: affective facial expressions facilitate robot learning
#@ Joost Broekens
#t 2007
#c 11
#% 151769
#% 238395
#% 318793
#% 334536
#% 384911
#% 430535
#% 539795
#% 723246
#% 783636
#% 858685
#% 905420
#% 1250663
#% 1272286
#% 1664271
#! Computer models can be used to investigate the role of emotion in learning. Here we present EARL, our framework for the systematic study of the relation between emotion, adaptation and reinforcement learning (RL). EARL enables the study of, among other things, communicated affect as reinforcement to the robot; the focus of this chapter. In humans, emotions are crucial to learning. For example, a parent--observing a child--uses emotional expression to encourage or discourage specific behaviors. Emotional expression can therefore be a reinforcement signal to a child. We hypothesize that affective facial expressions facilitate robot learning, and compare a social setting with a non-social one to test this. The non-social setting consists of a simulated robot that learns to solve a typical RL task in a continuous grid-world environment. The social setting additionally consists of a human (parent) observing the simulated robot (child). The human's emotional expressions are analyzed in real time and converted to an additional reinforcement signal used by the robot; positive expressions result in reward, negative expressions in punishment. We quantitatively show that the "social robot" indeed learns to solve its task significantly faster than its "non-social sibling". We conclude that this presents strong evidence for the potential benefit of affective communication with humans in the reinforcement learning loop.

#index 1501190
#* Trajectory-based representation of human actions
#@ Antonios Oikonomopoulos;Ioannis Patras;Maja Pantic;Nikos Paragios
#t 2007
#c 11
#% 32357
#% 260293
#% 266616
#% 277314
#% 280790
#% 403085
#% 424150
#% 457703
#% 458100
#% 578409
#% 592224
#% 635685
#% 641982
#% 659971
#% 723871
#% 724258
#% 724270
#% 775138
#% 800191
#% 812331
#% 812376
#% 812455
#% 836696
#% 836851
#% 861270
#% 861308
#% 883864
#% 889149
#% 905420
#% 1548464
#% 1548519
#% 1548541
#% 1548558
#% 1548574
#% 1781690
#% 1781714
#% 1828393
#% 1828415
#! This work addresses the problem of human action recognition by introducing a representation of a human action as a collection of short trajectories that are extracted in areas of the scene with significant amount of visual activity. The trajectories are extracted by an auxiliary particle filtering tracking scheme that is initialized at points that are considered salient both in space and time. The spatiotemporal salient points are detected by measuring the variations in the information content of pixel neighborhoods in space and time. We implement an online background estimation algorithm in order to deal with inadequate localization of the salient points on the moving parts in the scene, and to improve the overall performance of the particle filter tracking scheme.We use a variant of the Longest Common Subsequence algorithm (LCSS) in order to compare different sets of trajectories corresponding to different actions. We use Relevance Vector Machines (RVM) in order to address the classification problem. We propose new kernels for use by the RVM, which are specifically tailored to the proposed representation of short trajectories. The basis of these kernels is the modified LCSS distance of the previous step. We present results on real image sequences from a small database depicting people performing 12 aerobic exercises.

#index 1501191
#* Modelling the communication atmosphere: a human centered multimedia approach to evaluate communicative situations
#@ Tomasz M. Rutkowski;Danilo P. Mandic
#t 2007
#c 11
#% 190581
#% 318793
#% 730219
#% 880091
#% 905420
#% 1860941
#! This chapter addresses the problem of multimodal analysis of human face-to-face communication. This is imporant since in the near future, smart environments equipped with multiple sensory systems will be able to sense the presence of humans and assess recognize their behaviours, actions, and emotional states. The main goal of the presented study is to develop models of communicative/interactive events in multi-media (audio and video), suitable for the analysis and subsequent incorporation within virtual reality environments. Interactive, environmental, and emotional characteristics of the communicators are estimated in order to define the communication event as one entity. This is achieved by putting together results obtained in social sciences and multimedia signal processing under one umbrella - the communication atmosphere analysis. Experiments based on real life recordings support the approach.

#index 1501192
#* Modeling influence between experts
#@ Wen Dong;Alex Pentland
#t 2007
#c 11
#% 313955
#% 813847
#% 858102
#% 902359
#% 905420
#! A common problem of ubiquitous sensor-network computing is combining evidence between multiple agents or experts. We demonstrate that the latent structure influence model, our novel formulation for combining evidence from multiple dynamic classification processes ("experts"), can achieve greater accuracy, efficiency, and robustness to data corruption than standard methods such as HMMs. It accomplishes this by simultaneously modeling the structure of interaction and the latent states.

#index 1501193
#* Social intelligence design and human computing
#@ Toyoaki Nishida
#t 2007
#c 11
#% 212994
#% 474168
#% 474309
#% 474331
#% 474337
#% 794847
#% 794849
#% 794853
#% 853318
#% 853323
#% 853325
#% 908751
#% 936935
#% 1000532
#% 1000535
#% 1000542
#% 1085141
#% 1085146
#% 1397610
#% 1695929
#% 1709753
#! The central concern of Social Intelligence Design is the understanding and augmentation of social intelligence that might be attributed to both an individual and a group. Social Intelligence Design addresses understanding and augmentation of social intelligence resulting from bilateral interaction of intelligence attributed to an individual to coordinate her/his behavior with others in a society and that attributed to a collection of individuals to achieve goals as a whole and learn from experiences. Social intelligence can be addressed from multiple perspectives. In this chapter, I will focus on three aspects. First, I highlight interaction from the social discourse perspective in which social intelligence manifests in rapid interaction in a small group. Second, I look at the community media and social interaction in the large, where slow and massive interaction takes place in a large collection of people. Third, I survey work on social artifacts that embody social intelligence. Finally, I attempt to provide a structured view of the field.

#index 1501194
#* Feedback loops in communication and human computing
#@ Rieks op den Akker;Dirk Heylen
#t 2007
#c 11
#% 379041
#% 817488
#% 1137742
#% 1672215
#! Building systems that are able to analyse communicative behaviours or take part in conversations requires a sound methodology in which the complex organisation of conversations is understood and tested on real-life samples. The data-driven approaches to human computing not only have a value for the engineering of systems, but can also provide feedback to the study of conversations between humans and between human and machines.

#index 1501195
#* Evaluating the future of HCI: challenges for the evaluation of emerging applications
#@ Ronald Poppe;Rutger Rienks;Betsy van Dijk
#t 2007
#c 11
#% 54239
#% 137614
#% 157698
#% 193650
#% 207671
#% 211607
#% 237131
#% 266223
#% 297564
#% 308616
#% 343154
#% 349622
#% 349623
#% 350507
#% 364906
#% 394790
#% 407891
#% 433332
#% 575404
#% 608995
#% 733334
#% 750348
#% 752107
#% 752260
#% 769203
#% 789828
#% 795243
#% 795250
#% 802977
#% 837514
#% 845411
#% 861183
#% 872199
#% 905259
#% 924078
#% 936365
#% 995915
#% 1134816
#% 1138444
#% 1501186
#% 1665927
#% 1669368
#% 1746784
#! Current evaluation methods are inappropriate for emerging HCI applications. In this paper, we give three examples of these applications and show that traditional evaluation methods fail. We identify trends in HCI development and discuss the issues that arise with evaluation.We aim at achieving increased awareness that evaluation too has to evolve in order to support the emerging trends in HCI systems.

#index 1501196
#* Gaze-X: adaptive, affective, multimodal interface for single-user office scenarios
#@ Ludo Maat;Maja Pantic
#t 2007
#c 11
#% 58872
#% 182976
#% 211471
#% 219232
#% 238395
#% 292193
#% 295950
#% 296383
#% 297914
#% 297920
#% 322204
#% 336078
#% 424032
#% 424033
#% 445993
#% 451582
#% 530374
#% 603592
#% 643490
#% 733329
#% 733333
#% 733334
#% 733335
#% 733336
#% 764089
#% 784970
#% 823439
#% 839970
#% 839971
#% 871715
#% 905407
#% 905408
#% 905411
#% 905420
#% 1134895
#% 1548466
#% 1699591
#% 1699775
#! This paper describes an intelligent system that we developed to support affective multimodal human-computer interaction (AMM-HCI) where the user's actions and emotions are modeled and then used to adapt the interaction and support the user in his or her activity. The proposed system, which we named Gaze-X, is based on sensing and interpretation of the human part of the computer's context, known as W5+ (who, where, what, when, why, how). It integrates a number of natural human communicative modalities including speech, eye gaze direction, face and facial expression, and a number of standard HCI modalities like keystrokes, mouse movements, and active software identification, which, in turn, are fed into processes that provide decision making and adapt the HCI to support the user in his or her activity according to his or her preferences. A usability study conducted in an office scenario with a number of users indicates that Gaze-X is perceived as effective, easy to use, useful, and affectively qualitative.

#index 1501197
#* SmartWeb handheld: multimodal interaction with ontological knowledge bases and semantic web services
#@ Daniel Sonntag;Ralf Engel;Gerd Herzog;Alexander Pfalzgraf;Norbert Pfleger;Massimo Romanelli;Norbert Reithinger
#t 2007
#c 11
#% 105
#% 117568
#% 286679
#% 344361
#% 431539
#% 459487
#% 575404
#% 741913
#% 741919
#% 742201
#% 743353
#% 768885
#% 782757
#% 782760
#% 815146
#% 828842
#% 857181
#% 898635
#% 903266
#% 905420
#% 913484
#% 969426
#% 1271967
#% 1501195
#% 1713587
#! SMARTWEB aims to provide intuitive multimodal access to a rich selection of Web-based information services. We report on the current prototype with a smartphone client interface to the Semantic Web. An advanced ontology-based representation of facts and media structures serves as the central description for rich media content. Underlying content is accessed through conventional web service middleware to connect the ontological knowledge base and an intelligent web service composition module for external web services, which is able to translate between ordinary XML-based data structures and explicit semantic representations for user queries and system responses. The presentation module renders the media content and the results generated from the services and provides a detailed description of the content and its layout to the fusion module. The user is then able to employ multiple modalities, like speech and gestures, to interact with the presented multimedia material in a multimodal way.

#index 1501198
#* A learning-based high-level human computer interface for face modeling and animation
#@ Volker Blanz
#t 2007
#c 11
#% 87
#% 224727
#% 235349
#% 252914
#% 279841
#% 279889
#% 308454
#% 443668
#% 721161
#% 729437
#% 815955
#% 815965
#% 910403
#! This paper describes a system for animation and modeling of faces in images or in 3D. It provides high-level control of facial appearance to users, due to a learning-based approach that extracts class-specific information from a database of 3D scans. The modification tools include changes of facial attributes, such as body weight, masculine or feminine look, or overall head shape. Facial expressions are learned from examples and can be applied to new individuals. The system is intrinsically based on 3D face shapes and surface colors, but it can be applied to existing images as well, using a 3D shape reconstruction algorithm that operates on single images. After reconstruction, faces can be modified and drawn back into the original image, so the users can manipulate, animate and exchange faces in images at any given pose and illumination. The system can be used to create face models or images from a vague description or mental image, for example based on the recollection of eyewitnesses in forensic applications. For this specific problem, we present a software tool and a user study with a forensic artist. Our model-based approach may be considered a prototype implementation of a high-level user interface to control meaningful attributes in human faces.

#index 1501199
#* Challenges for virtual humans in human computing
#@ Dennis Reidsma;Zsófia Ruttkay;Anton Nijholt
#t 2007
#c 11
#% 172747
#% 212994
#% 232905
#% 250441
#% 301528
#% 305116
#% 314376
#% 330286
#% 334511
#% 334512
#% 379206
#% 431497
#% 445555
#% 451513
#% 452620
#% 536860
#% 589646
#% 704833
#% 750260
#% 755108
#% 779603
#% 814279
#% 823959
#% 823978
#% 838149
#% 871715
#% 871717
#% 874665
#% 905412
#% 935329
#% 959876
#% 994502
#% 1000541
#% 1501184
#% 1501186
#% 1664240
#% 1664254
#% 1664257
#% 1664263
#% 1664269
#% 1665926
#% 1665927
#% 1665929
#% 1669451

#index 1501200
#* Affect detection and an automated improvisational AI actor in E-drama
#@ Li Zhang;Marco Gillies;John A. Barnden;Robert J. Hendley;Mark G. Lee;Alan M. Wallington
#t 2007
#c 11
#% 207677
#% 238395
#% 252807
#% 325006
#% 325050
#% 777407
#% 905420
#% 1260627
#% 1299645
#% 1501184
#% 1837240
#! Enabling machines to understand emotions and feelings of the human users in their natural language textual input during interaction is a challenging issue in Human Computing. Our work presented here has tried to make our contribution toward such machine automation. We report work on adding affect-detection to an existing e-drama program, a text-based software system for dramatic improvisation in simple virtual scenarios, for use primarily in learning contexts. The system allows a human director to monitor improvisations and make interventions, for instance in reaction to excessive, insufficient or inappropriate emotions in the characters' speeches. Within an endeavour to partially automate directors' functions, and to allow for automated affective bit-part characters, we have developed an affect-detection module. It is aimed at detecting affective aspects (concerning emotions, moods, value judgments, etc.) of human-controlled characters' textual "speeches". The work also accompanies basic research into how affect is conveyed linguistically. A distinctive feature of the project is a focus on the metaphorical ways in which affect is conveyed. Moreover, we have also introduced how the detected affective states activate the animation engine to produce gestures for human-controlled characters. The description of our approach in this paper is taken in part from our previous publications [1, 2] with new contributions mainly on metaphorical language processing (practically and theoretically), 3D emotional animation generation and user testing evaluation. Finally, Our work on affect detection in open-ended improvisational text contributes to the development of automatic understanding of human language and emotion. The generation of emotional believable animations based on detected affective states and the production of appropriate responses for the automated affective bit-part character based on the detection of affect contribute greatly to the ease and innovative user interface in e-drama, which leads to high-level user engagement and enjoyment.

#index 1604126
#* Proceedings of the AI for an Intelligent Planet
#@ Biplav Srivastava;Carla Gomes;Anand Ranganathan
#t 2011
#c 11
#! AI has long lead the march towards intelligent behavior in computer systems. This has lead to emergence of techniques in perceiving the world (e.g., web-based systems, vision, speech, NLP), manipulating internal representations (e.g., knowledge representation, logic, uncertainty, utility, constraints), analyzing information (e.g., search, learning, planning, scheduling) and altering the world (e.g., robotics, multi-agent systems). They have resulted in many applications with profound impact to our daily lives and remarkable commercial successes. The time has come for AI to address even more challenging problems. One such problem is sustenance and improvement of quality of life for global citizens despite over-population and limited resources. As the world's population increases and it puts increasing demands on the planet's limited resources due to shifting life-styles, we not only need to monitor how we consume resources but also optimize resource usage. Some examples of planet's resources citizens consume are water; energy sources --- hydrocarbons, electricity; air --- conversely, green-houses gases emitted; and food sources --- plants and animals. Everyone (individuals, enterprises, governments) can do something in their realm for reducing resource footprint to alleviate the worsening situation. This is both an ethically good thing to do as well as makes a lot of economic sense. Championing this cause, industry has started using the prefix "smarter" to cyber-physical systems, which involve sensing the data through physical instruments, interconnecting and integrating them from multiple sources and analyzing them for intelligent patterns. There are multiple domains, all converging on a broader "Smarter Planet" theme. Consider a city. The city management, citizens and businesses may be interested in optimizing their usage of energy and water, while providing efficient infrastructure, transportation and public safety to all participants. The trend towards optimized cyber-physical systems, however, is not new to AI and in fact a subset of what has been pursued as intelligent behavior, but on a much larger scale of people and resources involved. We believe that AI has a big role to play in making all the stakeholders in the scope under consideration (individuals, building, campus, city, leading to the planet), and hence the planet, intelligent.

#index 1826064
#* Proceedings of the Twenty-Second international joint conference on Artificial Intelligence - Volume Volume One
#@ Toby Walsh
#t 2011
#c 11

#index 1826065
#* Open information extraction: the second generation
#@ Oren Etzioni;Anthony Fader;Janara Christensen;Stephen Soderland;Mausam Mausam
#t 2011
#c 11
#% 278109
#% 744495
#% 940029
#% 1190065
#% 1250397
#% 1264291
#% 1272263
#% 1275182
#% 1301004
#% 1330550
#% 1355026
#% 1471191
#% 1471208
#% 1471222
#% 1476276
#% 1481641
#% 1481658
#% 1591983
#% 1591990
#! How do we scale information extraction to the massive size and unprecedented heterogeneity of the Web corpus? Beginning in 2003, our KnowItAll project has sought to extract high-quality knowledge from the Web. In 2007, we introduced the Open Information Extraction (Open IE) paradigm which eschews hand-labeled training examples, and avoids domain-specific verbs and nouns, to develop unlexicalized, domain-independent extractors that scale to the Web corpus. Open IE systems have extracted billions of assertions as the basis for both common-sense knowledge and novel question-answering systems. This paper describes the second generation of Open IE systems, which rely on a novel model of how relations and their arguments are expressed in English sentences to double precision/recall compared with previous systems such as TEXTRUNNER and WOE.

#index 1826066
#* Artificial intelligence and human thinking
#@ Robert Kowalski
#t 2011
#c 11
#% 233132
#% 288985
#% 374912
#% 1383858
#% 1620482
#! Research in AI has built upon the tools and techniques of many different disciplines, including formal logic, probability theory, decision theory, management science, linguistics and philosophy. However, the application of these disciplines in AI has necessitated the development of many enhancements and extensions. Among the most powerful of these are the methods of computational logic. I will argue that computational logic, embedded in an agent cycle, combines and improves upon both traditional logic and classical decision theory. I will also argue that many of its methods can be used, not only in AI, but also in ordinary life, to help people improve their own human intelligence without the assistance of computers.

#index 1826067
#* Aggregating dependency graphs into voting agendas in multi-issue elections
#@ Stéphane Airiau;Ulle Endriss;Umberto Grandi;Daniele Porello;Joel Uckelman
#t 2011
#c 11
#% 271246
#% 1208130
#% 1250233
#% 1272026
#% 1305310
#% 1453103
#% 1473273
#! Many collective decision making problems have a combinatorial structure: the agents involved must decide on multiple issues and their preferences over one issue may depend on the choices adopted for some of the others. Voting is an attractive method for making collective decisions, but conducting a multi-issue election is challenging. On the one hand, requiring agents to vote by expressing their preferences over all combinations of issues is computationally infeasible; on the other, decomposing the problem into several elections on smaller sets of issues can lead to paradoxical outcomes. Any pragmatic method for running a multi-issue election will have to balance these two concerns. We identify and analyse the problem of generating an agenda for a given election, specifying which issues to vote on together in local elections and in which order to schedule those local elections.

#index 1826068
#* Using emotions to enhance decision-making
#@ Dimitrios Antos;Avi Pfeffer
#t 2011
#c 11
#% 283976
#% 516793
#% 811390
#% 1221188
#% 1225218
#% 1263782
#% 1481056
#% 1837395
#! We present a novel methodology for decision-making by computer agents that leverages a computational concept of emotions. It is believed that emotions help living organisms perform well in complex environments. Can we use them to improve the decision-making performance of computer agents? We explore this possibility by formulating emotions as mathematical operators that serve to update the relative priorities of the agent's goals. The agent uses rudimentary domain knowledge to monitor the expectation that its goals are going to be accomplished in the future, and reacts to changes in this expectation by "experiencing emotions." The end result is a projection of the agent's long-run utility function, which might be too complex to optimize or even represent, to a time-varying valuation function that is being myopically maximized by selecting appropriate actions. Our methodology provides a systematic way to incorporate emotion into a decision-theoretic framework, and also provides a principled, domain-independent methodology for generating heuristics in novel situations. We test our agents in simulation in two domains: restless bandits and a simple foraging environment. Our results indicate that emotion-based agents outperform other reasonable heuristics for such difficult domains, and closely approach computationally expensive near-optimal solutions, whenever these are computable, yet requiring only a fraction of the cost.

#index 1826069
#* Hustling in repeated zero-sum games with imperfect execution
#@ Christopher Archibald;Yoav Shoham
#t 2011
#c 11
#% 1083974
#% 1152376
#% 1453183
#! We study repeated games in which players have imperfect execution skill and one player's true skill is not common knowledge. In these settings the possibility arises of a player "hustling", or pretending to have lower execution skill than they actually have. Focusing on repeated zero-sum games, we provide a hustle-proof strategy; this strategy maximizes a player's payoff, regardless of the true skill level of the other player.

#index 1826070
#* Dynamics of profit-sharing games
#@ John Augustine;Ning Chen;Edith Elkind;Angelo Fanelli;Nick Gravin;Dmitry Shiryaev
#t 2011
#c 11
#% 91060
#% 165011
#% 233135
#% 765315
#% 773332
#% 991138
#% 1061617
#% 1071518
#% 1105398
#% 1128419
#% 1215742
#% 1426648
#% 1530768
#% 1615227
#! An important task in the analysis of multiagent systems is to understand how groups of selfish players can form coalitions, i.e., work together in teams. In this paper, we study the dynamics of coalition formation under bounded rationality. We consider settings where each team's profit is given by a concave function, and propose three profit-sharing schemes, each of which is based on the concept of marginal utility. The agents are assumed to be myopic, i.e., they keep changing teams as long as they can increase their payoff by doing so. We study the properties (such as closeness to Nash equilibrium or total profit) of the states that result after a polynomial number of such moves, and prove bounds on the price of anarchy and the price of stability of the corresponding games.

#index 1826071
#* Optimal partitions in additively separable hedonic games
#@ Haris Aziz;Felix Brandt;Hans Georg Seedig
#t 2011
#c 11
#% 165011
#% 284645
#% 408396
#% 754147
#% 765548
#% 1215749
#% 1272227
#% 1332277
#% 1698321
#% 1845354
#! We conduct a computational analysis of fair and optimal partitions in additively separable hedonic games. We show that, for strict preferences, a Pareto optimal partition can be found in polynomial time while verifying whether a given partition is Pareto optimal is coNP-complete, even when preferences are symmetric and strict. Moreover, computing a partition with maximum egalitarian or utilitarian social welfare or one which is both Pareto optimal and individually rational is NP-hard. We also prove that checking whether there exists a partition which is both Pareto optimal and envy-free is Σ2p-complete. Even though an envy-free partition and a Nash stable partition are both guaranteed to exist for symmetric preferences, checking whether there exists a partition which is both envy-free and Nash stable is NP-complete.

#index 1826072
#* Coalitional voting manipulation: a game-theoretic perspective
#@ Yoram Bachrach;Edith Elkind;Piotr Faliszewski
#t 2011
#c 11
#% 940734
#% 951820
#% 1288655
#% 1305341
#% 1305345
#% 1366625
#% 1426673
#% 1426682
#% 1453102
#% 1530771
#! Computational social choice literature has successfully studied the complexity of manipulation in various voting systems. However, the existing models of coalitional manipulation view the manipulating coalition as an exogenous input, ignoring the question of the coalition formation process. While such analysis is useful as a first approximation, a richer framework is required to model voting manipulation in the real world more accurately, and, in particular, to explain how a manipulating coalition arises and chooses its action. In this paper, we apply tools from cooperative game theory to develop a model that considers the coalition formation process and determines which coalitions are likely to form and what actions they are likely to take. We explore the computational complexity of several standard coalitional game theory solution concepts in our setting, and study the relationship between our model and the classic coalitional manipulation problem as well as the now-standard bribery model.

#index 1826073
#* Unweighted coalitional manipulation under the Borda rule Is NP-hard
#@ Nadja Betzler;Rolf Niedermeier;Gerhard J. Woeginger
#t 2011
#c 11
#% 769579
#% 940734
#% 951820
#% 1071501
#% 1150431
#% 1272142
#% 1305299
#% 1426673
#% 1454257
#% 1500258
#! The Borda voting rule is a positional scoring rule where, for m candidates, for every vote the first candidate receives m- 1 points, the second m- 2 points and so on. A Borda winner is a candidate with highest total score. It has been a prominent open problem to determine the computational complexity of UNWEIGHTED COALITIONAL MANIPULATION UNDER BORDA: Can one add a certain number of additional votes (called manipulators) to an election such that a distinguished candidate becomes a winner? We settle this open problem by showing NP-hardness even for two manipulators and three input votes. Moreover, we discuss extensions and limitations of this hardness result.

#index 1826074
#* Simulating the emergence of grammatical agreement in multi-agent language games
#@ Katrien Beuls;Sebastian Höfer
#t 2011
#c 11
#% 938654
#% 1125480
#% 1310701
#! Grammatical agreement is present in many of the world's languages today and has become an essential feature that guides linguistic processing. When two words in a sentence are said to "agree", this means that they share certain features such as "gender", "number", "person" or others. The primary hypothesis of this paper is that marking agreement within one linguistic phrase reduces processing effort as phrasal constituents can more easily be recognized. The drive to reduce processing effort introduces the rise of agreement marking in a population of multiple agents by means of an incrementally aligned mapping between the most discriminatory features of a particular linguistic unit and their associative markers. A series of experiments compare feature selection methods for one-to-one agreement mappings, and show how an agreement system can be bootstrapped.

#index 1826075
#* Approximately strategy-proof voting
#@ Eleanor Birrell;Rafael Pass
#t 2011
#c 11
#% 287981
#% 1029084
#% 1080863
#% 1141527
#% 1250606
#% 1521681
#% 1740518
#! The classic Gibbard-Satterthwaite Theorem establishes that only dictatorial voting rules are strategy-proof; under any other voting rule, players have an incentive to lie about their true preferences. We consider a new approach for circumventing this result: we consider randomized voting rules that only approximate a deterministic voting rule and only are approximately strategy-proof. We show that any deterministic voting rule can be approximated by an approximately strategy-proof randomized voting rule, and we provide asymptotically tight lower bounds on the parameters required by such voting rules.

#index 1826076
#* A general elicitation-free protocol for allocating indivisible goods
#@ Sylvain Bouveret;Jérôme Lang
#t 2011
#c 11
#% 1350758
#! We consider the following sequential allocation process. A benevolent central authority has to allocate a set of indivisible goods to a set of agents whose preferences it is totally ignorant of. We consider the process of allocating objects one after the other by designating an agent and asking her to pick one of the objects among those that remain. The problem consists in choosing the "best" sequence of agents, according to some optimality criterion. We assume that agents have additive preferences over objects. The choice of an optimality criterion depends on three parameters: how utilities of objects are related to their ranking in an agent's preference relation; how the preferences of different agents are correlated; and how social welfare is defined from the agents' utilities. We address the computation of a sequence maximizing expected social welfare under several assumptions. We also address strategical issues.

#index 1826077
#* Group-strategyproof irresolute social choice functions
#@ Felix Brandt
#t 2011
#c 11
#% 1250606
#% 1305341
#% 1521681
#! An important problem in voting is that agents may misrepresent their preferences in order to obtain a more preferred outcome. Unfortunately, this phenomenon has been shown to be inevitable in the case of resolute, i.e., single-valued, social choice functions. In this paper, we introduce a variant of Maskin-monotonicity that completely characterizes the class of pairwise irresolute social choice functions that are group-strategyproof according to Kelly's preference extension. The class is narrow but contains a number of appealing Condorcet extensions such as the minimal covering set and the bipartisan set, thereby answering a question raised independently by Barberà (1977) and Kelly (1977). These functions furthermore encourage participation and thus do not suffer from the no-show paradox (under Kelly's extension).

#index 1826078
#* On the fixed-parameter tractability of composition-consistent tournament solutions
#@ Felix Brandt;Markus Brill;Hans Georg Seedig
#t 2011
#c 11
#% 181845
#% 858155
#% 992253
#% 1250604
#% 1343551
#! Tournament solutions, i.e., functions that associate with each complete and asymmetric relation on a set of alternatives a non-empty subset of the alternatives, play an important role within social choice theory and the mathematical social sciences at large. Laffond et al. have shown that various tournament solutions satisfy composition-consistency, a structural invariance property based on the similarity of alternatives. We define the decomposition degree of a tournament as a parameter that reflects its decomposability and show that computing any composition-consistent tournament solution is fixed-parameter tractable with respect to the decomposition degree. Furthermore, we experimentally investigate the decomposition degree of two natural distributions of tournaments and its impact on the running time of computing the tournament equilibrium set.

#index 1826079
#* Social distance games
#@ Simina Brânzei;Kate Larson
#t 2011
#c 11
#% 300078
#% 1000451
#% 1227295
#% 1305303
#% 1348055
#% 1425621
#% 1540202
#! In this paper we introduce and analyze social distance games, a family of non-transferable utility coalitional games where an agent's utility is a measure of closeness to the other members of the coalition. We study both social welfare maximisation and stability in these games using a graph theoretic perspective. We use the stability gap to investigate the welfare of stable coalition structures, and propose two new solution concepts with improved welfare guarantees. We argue that social distance games are both interesting in themselves, as well as in the context of social networks.

#index 1826080
#* Modeling the emergence and convergence of norms
#@ Logan Brooks;Wayne Iba;Sandip Sen
#t 2011
#c 11
#% 160038
#% 233136
#% 430239
#% 737084
#% 1215570
#% 1274996
#! In many multi-agent systems, the emergence of norms is the primary factor that determines over-all behavior and utility. Agent simulations can be used to predict and study the development of these norms. However, a large number of simulations is usually required to provide an accurate depiction of the agents' behavior, and some rare contingencies may still be overlooked completely. The cost and risk involved with agent simulations can be reduced by analyzing a system theoretically and producing models of its behavior. We use such a theoretical approach to examine the dynamics of a population of agents playing a coordination game to determine all the norms to which the society can converge, and develop a system of linear recurrence relations that predict how frequently each of these norms will be reached, as well as the average convergence time. This analysis produces certain guarantees about system behavior that canot be provided by a purely empirical approach, and can be used to make predictions about the emergence of norms that numerically match those obtained through large-scale simulations.

#index 1826081
#* Verifying normative behaviour via normative mechanism design
#@ Nils Bulling;Mehdi Dastani
#t 2011
#c 11
#% 181622
#% 191653
#% 408396
#% 413871
#% 631052
#% 773202
#% 1024805
#% 1068329
#% 1197940
#% 1332458
#% 1478501
#% 1503917
#! The environment is an essential component of multi-agent systems and is often used to coordinate the behaviour of individual agents. Recently many languages have been proposed to specify and implement multi-agent environments in terms of social and normative concepts. In this paper, we first introduce a formal setting of multi-agent environment which abstracts from concrete specification languages. We extend this formal setting with norms and sanctions and show how concepts from mechanism design can be used to formally analyse and verify whether specific normative behaviours can be enforced (or implemented) if agents follow their subjective preferences. We also consider complexity issues of associated problems.

#index 1826082
#* Alternating epistemic Mu-calculus
#@ Nils Bulling;Wojciech Jamroga
#t 2011
#c 11
#% 297770
#% 413871
#% 944865
#% 1453179
#! Alternating-time temporal logic (ATL) is a well-known logic for reasoning about strategic abilities of agents. An important feature that distinguishes variants of ATL for imperfect information scenarios is that the standard fixed point characterizations of temporal modalities do not hold anymore. In this paper, we show that adding explicit fixed point operators to the "next-time" fragment of ATL already allows to capture abilities that could not be expressed in ATL. We also illustrate that the new language allows to specify important kinds of abilities, namely ones where the agents can always recompute their strategy while executing it. Thus, the agents are not assumed to remember their strategy by definition, like in the existing variants of ATL. Last but not least, we show that verification of such abilities can be cheaper than for all the variants of "ATL with imperfect information" considered so far.

#index 1826083
#* Trust decision-making in multi-agent systems
#@ Chris Burnett;Timothy J. Norman;Katia Sycara
#t 2011
#c 11
#% 803395
#% 856790
#% 878367
#% 882441
#% 1453084
#% 1453087
#% 1668082
#! Trust is crucial in dynamic multi-agent systems, where agents may frequently join and leave, and the structure of the society may often change. In these environments, it may be difficult for agents to form stable trust relationships necessary for confident interactions. Societies may break down when trust between agents is too low to motivate interactions. In such settings, agents should make decisions about who to interact with, given their degree of trust in the available partners. We propose a decision-theoretic model of trust decision making allows controls to be used, as well as trust, to increase confidence in initial interactions. We consider explicit incentives, monitoring and reputation as examples of such controls. We evaluate our approach within a simulated, highly-dynamic multi-agent environment, and show how this model supports the making of delegation decisions when trust is low.

#index 1826084
#* Manipulation in group argument evaluation
#@ Martin Caminada;Gabriella Pigozzi;Mikołaj Podlaszewski
#t 2011
#c 11
#% 198464
#% 992252
#% 1453108
#% 1538164
#% 1664525
#! Given an argumentation framework and a group of agents, the individuals may have divergent opinions on the status of the arguments. If the group needs to reach a common position on the argumentation framework, the question is how the individual evaluations can be mapped into a collective one. This problem has been recently investigated by Caminada and Pigozzi. In this paper, we investigate the behaviour of two of such operators from a social choice-theoretic point of view. In particular, we study under which conditions these operators are Pareto optimal and whether they are manipulable.

#index 1826085
#* Towards more expressive cake cutting
#@ Ioannis Caragiannis;John K. Lai;Ariel D. Procaccia
#t 2011
#c 11
#% 847066
#% 1270022
#% 1305328
#! Cake cutting is a playful name for the problem of fairly dividing a heterogeneous divisible good among a set of agents. The agent valuations for different pieces of cake are typically assumed to be additive. However, in certain practical settings this assumption is invalid because agents may not have positive value for arbitrarily small "crumbs" of cake. In this paper, we propose a new, more expressive model of agent valuations that captures this feature. We present an approximately proportional algorithm for any number of agents that have such expressive valuations. The algorithm is optimal in the sense that no other algorithm can guarantee a greater worst-case degree of proportionality. We also design an optimal approximately proportional and fully envy-free algorithm for two agents

#index 1826086
#* Efficient mechanisms with risky participation
#@ Ruggiero Cavallo
#t 2011
#c 11
#% 1426657
#! There is a fundamental incompatibility between efficiency, interim individual rationality, and budget-balance in mechanism design, even for extremely simple settings. Yet it is possible to specify efficient mechanisms that satisfy participation and budget-balance constraints in expectation, prior to types being realized. We do so here, in fact deriving mechanisms that are individually rational for each agent even ex post of other agents' type realizations. However, participation must still bear some risk of loss. For agents that are risk neutral, we show how the center can extract the entire surplus in expectation, or alternatively provide an equal expected share of the surplus for each participant, without violating dominant strategy incentive compatibility, efficiency, or ex ante budget-balance. We compare these solutions to a third efficient mechanism we design explicitly to address risk aversion in trade settings: payments are defined to minimize the odds of loss, satisfying ex ante participation constraints for agents with attitudes toward risk ranging from neutrality to high loss-aversion.

#index 1826087
#* Using incentive mechanisms for an adaptive regulation of open multi-agent systems
#@ Roberto Centeno;Holger Billhardt
#t 2011
#c 11
#% 486821
#% 776276
#% 823842
#% 1192290
#% 1192291
#% 1280789
#% 1289499
#% 1453184
#% 1698053
#! In this paper we propose a mechanism that encourages agents, participating in an open MAS, to follow a desirable behaviour, by introducing modifications in the environment. This mechanism is deployed by using an infrastructure based on institutional agents called incentivators. Each external agent is assigned to an incentivator that is able to discover its preferences, and to learn the suitable modifications in the environment, in order to improve the global utility of a system in response to inadequate design or changes in the population of participating agents. The mechanism is evaluated in a p2p scenario.

#index 1826088
#* AstonCAT-plus: an efficient specialist for the TAC market design tournament
#@ Meng Chang;Minghua He;Xudong Luo
#t 2011
#c 11
#% 274891
#% 727658
#% 1223521
#% 1442594
#% 1777187
#! This paper describes the strategies used by AstonCAT-Plus, the post-tournament version of the specialist designed for the TAC Market Design Tournament 2010. It details how AstonCAT-Plus accepts shouts, clears market, sets transaction prices and charges fees. Through empirical evaluation, we show that AstonCAT-Plus not only outperforms AstonCAT (tournament version) significantly but also achieves the second best overall score against some top entrants of the competition. In particular, it achieves the highest allocative efficiency, transaction success rate and average trader profit among all the specialists in our controlled experiments.

#index 1826089
#* A market clearing solution for social lending
#@ Ning Chen;Arpita Ghosh
#t 2011
#c 11
#% 59697
#% 490060
#% 1222655
#% 1426654
#! The social lending market, with over a billion dollars in loans, is a two-sided matching market where borrowers specify demands and lenders specify total budgets and their desired interest rates from each acceptable borrower. Because different borrowers correspond to different risk-return profiles, lenders have preferences over acceptable borrowers; a borrower prefers lenders in order of the interest rates they offer to her. We investigate the question of what is a computationally feasible, 'good', allocation to clear this market. We design a strongly polynomial time algorithm for computing a Pareto-efficient stable outcome in a two-sided many-to-many matching market with indifferences, and use this to compute an allocation for the social lending market that satisfies the properties of stability -- a standard notion of fairness in two-sided matching markets -- and Pareto efficiency; and additionally addresses envy-freeness amongst similar borrowers and risk diversification for lenders.

#index 1826090
#* Hypercubewise preference aggregation in multi-issue domains
#@ Vincent Conitzer;Jérôme Lang;Lirong Xia
#t 2011
#c 11
#% 322544
#% 866430
#% 892736
#% 1250233
#% 1270051
#% 1272026
#% 1473273
#% 1615239
#! We consider a framework for preference aggregation on multiple binary issues, where agents' preferences are represented by (possibly cyclic) CP-nets. We focus on the majority aggregation of the individual CP-nets, which is the CP-net where the direction of each edge of the hypercube is decided according to the majority rule. First we focus on hypercube Condorcet winners (HCWs); in particular, we show that, assuming a uniform distribution for the CP-nets, the probability that there exists at least one HCWis at least 1-1/e, and the expected number of HCWs is 1. Our experimental results confirm these results. We also show experimental results under the Impartial Culture assumption. We then generalize a few tournament solutions to select winners from (weighted) majoritarian CP-nets, namely Copeland, maximin, and Kemeny. For each of these, we address some social choice theoretic and computational issues.

#index 1826091
#* Changing one's mind: erase or rewind? possibilistic belief revision with fuzzy argumentation based on trust
#@ Célia Da Costa Pereira;Andrea G. B. Tettamanzi;Serena Villata
#t 2011
#c 11
#% 198464
#% 277058
#% 337502
#% 569060
#% 723626
#% 735151
#% 1111200
#% 1134201
#% 1184032
#% 1453195
#% 1498838
#% 1664525
#! We address the issue, in cognitive agents, of possible loss of previous information, which later might turn out to be correct when new information becomes available. To this aim, we propose a framework for changing the agent's mind without erasing forever previous information, thus allowing its recovery in case the change turns out to be wrong. In this new framework, a piece of information is represented as an argument which can be more or less accepted depending on the trustworthiness of the agent who proposes it. We adopt possibility theory to represent uncertainty about the information, and to model the fact that information sources can be only partially trusted. The originality of the proposed framework lies in the following two points: (i) argument reinstatement is mirrored in belief reinstatement in order to avoid the loss of previous information; (ii) new incoming information is represented under the form of arguments and it is associated with a plausibility degree depending on the trustworthiness of the information source.

#index 1826092
#* Multi-agent soft constraint aggregation via sequential voting
#@ Giorgio Dalla Pozza;Maria Silvia Pini;Francesca Rossi;K. Brent Venable
#t 2011
#c 11
#% 951820
#% 1083984
#% 1270252
#% 1272026
#% 1650628
#! We consider scenarios where several agents must aggregate their preferences over a large set of candidates with a combinatorial structure. That is, each candidate is an element of the Cartesian product of the domains of some variables. We assume agents compactly express their preferences over the candidates via soft constraints. We consider a sequential procedure that chooses one candidate by asking the agents to vote on one variable at a time. While some properties of this procedure have been already studied, here we focus on independence of irrelevant alternatives, non-dictatorship, and strategy-proofness. Also, we perform an experimental study that shows that the proposed sequential procedure yields a considerable saving in time with respect to a non-sequential approach, while the winners satisfy the agents just as well, independently of the variable ordering and of the presence of coalitions of agents.

#index 1826093
#* Human-agent auction interactions: adaptive-aggressive agents dominate
#@ Marco De Luca;Dave Cliff
#t 2011
#c 11
#% 341935
#% 379009
#% 1076647
#% 1289308
#% 1776629
#! We report on results from experiments where human traders interact with software-agent traders in a real-time asynchronous continuous double auction (CDA) experimental economics system. Our experiments are inspired by the seminal work reported by IBM at IJCAI 2001 [Das et al., 2001], where it was demonstrated that software-agent traders could consistently outperform human traders in real-time CDA markets. IBM tested two trading-agent strategies, ZIP and a modified version of GD, and in a subsequent paper they reported on a new strategy called GDX that was demonstrated to outperform GD and ZIP in agent vs. agent CDA competitions, on which basis it was claimed that GDX "... may offer the best performance of any published CDA bidding strategy." [Tesauro and Bredin, 2002]. In this paper, we employ experiment methods similar to those pioneered by IBM to test the performance of "Adaptive Aggressive" (AA) algorithmic traders [Vytelingum, 2006]. The results presented here confirm Vytelingum's claim that AA outperforms ZIP, GD, and GDX in agent vs. agent experiments. We then present the first results from testing AA against human traders in human vs. agent CDA experiments, and demonstrate that AA's performance against human traders is superior to that of ZIP, GD, and GDX. We therefore claim that, on the basis of the available evidence, AA may offer the best performance of any published bidding strategy.

#index 1826094
#* Choosing collectively optimal sets of alternatives based on the condorcet criterion
#@ Edith Elkind;Jérôme Lang;Abdallah Saffidine
#t 2011
#c 11
#% 49762
#! In elections, an alternative is said to be a Condorcet winner if it is preferred to any other alternative by a majority of voters. While this is a very attractive solution concept, many elections do not have a Condorcet winner. In this paper, we propose a setvalued relaxation of this concept, which we call a Condorcet winning set: such sets consist of alternatives that collectively dominate any other alternative. We also consider a more general version of this concept, where instead of domination by a majority of voters we require domination by a given fraction Θ of voters; we refer to this concept as Θ-winning set. We explore social choice-theoretic and algorithmic aspects of these solution concepts, both theoretically and empirically.

#index 1826095
#* Action selection via learning behavior patterns in multi-robot domains
#@ Can Erdogan;Manuela Veloso
#t 2011
#c 11
#% 98255
#% 577276
#% 659971
#% 883355
#% 1250388
#% 1270313
#! The RoboCup robot soccer Small Size League has been running since 1997 with many teams successfully competing and very effectively playing the games. Teams of five robots, with a combined autonomous centralized perception and control, and distributed actuation, move at high speeds in the field space, actuating a golf ball by passing and shooting it to aim at scoring goals. Most teams run their own pre-defined team strategies, unknown to the other teams, with flexible game-state dependent assignment of robot roles and positioning. However, in this fast-paced noisy real robot league, recognizing the opponent team strategies and accordingly adapting one's own play has proven to be a considerable challenge. In this work, we analyze logged data of real games gathered by the CMDragons team, and contribute several results in learning and responding to opponent strategies. We define episodes as segments of interest in the logged data, and introduce a representation that captures the spatial and temporal data of the multi-robot system as instances of geometrical trajectory curves. We then learn a model of the team strategies through a variant of agglomerative hierarchical clustering. Using the learned cluster model, we are able to classify a team behavior incrementally as it occurs. Finally, we define an algorithm that autonomously generates counter tactics, in a simulation based on the real logs, showing that it can recognize and respond to opponent strategies.

#index 1826096
#* Assumption-based argumentation dialogues
#@ Xiuyi Fan;Francesca Toni
#t 2011
#c 11
#% 231742
#% 894431
#% 908926
#% 1201957
#% 1291393
#% 1305330
#% 1422689
#% 1473089
#! We propose a formal model for argumentation-based dialogues between agents, using assumption-based argumentation (ABA). The model is given in terms of ABA-specific utterances, trees drawn from dialogues and legal-move and outcome functions. We prove a formal connection between these dialogues and argumentation semantics. We illustrate persuasion as an application of the dialogue model.

#index 1826097
#* Binary aggregation with integrity constraints
#@ Umberto Grandi;Ulle Endriss
#t 2011
#c 11
#% 767712
#% 1274973
#% 1453101
#! Binary aggregation studies problems in which individuals express yes/no choices over a number of possibly correlated issues, and these individual choices need to be aggregated into a collective choice. We show how several classical frameworks of Social Choice Theory, particularly preference and judgment aggregation, can be viewed as binary aggregation problems by designing an appropriate set of integrity constraints for each specific setting. We explore the generality of this framework, showing that it makes available useful techniques both to prove theoretical results, such as a new impossibility theorem in preference aggregation, and to analyse practical problems, such as the characterisation of safe agendas in judgment aggregation in a syntactic way. The framework also allows us to formulate a general definition of paradox that is independent of the domain under consideration, which gives rise to the study of the class of aggregation procedures of generalised dictatorships

#index 1826098
#* Manipulating boolean games through communication
#@ John Grant;Sarit Kraus;Michael Wooldridge;Inon Zuckerman
#t 2011
#c 11
#% 729449
#% 781219
#% 1083988
#% 1197380
#% 1202783
#% 1223241
#% 1272023
#% 1272080
#% 1305302
#% 1332425
#% 1614153
#! We address the issue of manipulating games through communication. In the specific setting we consider (a variation of Boolean games), we assume there is some set of environment variables, the value of which is not directly accessible to players; each player has their own beliefs about these variables, and makes decisions about what actions to perform based on these beliefs. The communication we consider takes the form of (truthful) announcements about the value of some environment variables; the effect of an announcement about some variable is to modify the beliefs of the players who hear the announcement so that they accurately reflect the value of the announced variables. By choosing announcements appropriately, it is possible to perturb the game away from certain rational outcomes and towards others. We specifically focus on the issue of stabilisation: making announcements that transform a game from having no stable states to one that has stable configurations.

#index 1826099
#* On the complexity of the core over coalition structures
#@ Gianluigi Greco;Enrico Malizia;Luigi Palopoli;Francesco Scarcello
#t 2011
#c 11
#% 165011
#% 808378
#% 1223514
#% 1274979
#% 1291457
#% 1305314
#% 1332425
#% 1366625
#% 1530782
#! The computational complexity of relevant core-related questions for coalitional games is addressed from the coalition structure viewpoint, i.e., without assuming that the grand-coalition necessarily forms. In the analysis, games are assumed to be in "compact" form, i.e., their worth functions are implicitly given as polynomial-time computable functions over succinct game encodings provided as input. Within this setting, a complete picture of the complexity issues arising with the core, as well as with the related stability concepts of least core and cost of stability, is depicted. In particular, the special cases of superadditive games and of games whose sets of feasible coalitions are restricted over tree-like interaction graphs are also studied.

#index 1826100
#* Max-Prob: an unbiased rational decision making procedure for multiple-adversary environments
#@ Anat Hashavit;Shaul Markovitch
#t 2011
#c 11
#% 241
#% 1697
#% 101439
#% 243725
#% 347813
#% 529676
#% 890311
#% 1250324
#% 1291446
#% 1305392
#! In binary-utility games, an agent can have only two possible utility values for final states, 1 (win) and 0 (lose). An adversarial binary-utility game is one where for each final state there must be at least one winning and one losing agent. We define an unbiased rational agent as one that seeks to maximize its utility value, but is equally likely to choose between states with the same utility value. This induces a probability distribution over the outcomes of the game, from which an agent can infer its probability to win. A single adversary binary game is one where there are only two possible outcomes, so that the winning probabilities remain binary values. In this case, the rational action for an agent is to play minimax. In this work we focus on the more complex, multiple-adversary environment. We propose a new algorithmic framework where agents try to maximize their winning probabilities. We begin by theoretically analyzing why an unbiased rational agent should take our approach in an unbounded environment and not that of the existing Paranoid or MaxN algorithms. We then expand our framework to a resource-bounded environment, where winning probabilities are estimated, and show empirical results supporting our claims.

#index 1826101
#* A dynamic logic of normative systems
#@ Andreas Herzig;Emiliano Lorini;Frédéric Moisan;Nicolas Troquard
#t 2011
#c 11
#% 224765
#% 342119
#% 390685
#% 908969
#% 1274943
#% 1291402
#% 1309981
#% 1473941
#! We propose a logical framework to represent and reason about agent interactions in normative systems. Our starting point is a dynamic logic of propositional assignments whose satisfiability problem is PSPACE-complete. We show that it embeds Coalition Logic of Propositional Control CL-PC and that various notions of ability and capability can be captured in it. We illustrate it on a water resource management case study. Finally, we show how the logic can be easily extended in order to represent constitutive rules which are also an essential component of the modelling of social reality.

#index 1826102
#* Considerate equilibrium
#@ Martin Hoefer;Michal Penn;Maria Polukarov;Alexander Skopalik;Berthold Vöcking
#t 2011
#c 11
#% 866689
#% 1069081
#% 1171615
#% 1231955
#% 1250603
#% 1332419
#% 1530757
#! We study the existence and computational complexity of coalitional stability concepts based on social networks. Our concepts represent a natural and rich combinatorial generalization of a recent notion termed partition equilibrium [5]. We assume that players in a strategic game are embedded in a social (or, communication) network, and there are coordination constraints defining the set of coalitions that can jointly deviate in the game. A main feature of our approach is that players act in a "considerate" fashion to ignore potentially profitable (group) deviations if the change in their strategy may cause a decrease of utility to their neighbors in the network. We explore the properties of such considerate equilibria in application to the celebrated class of resource selection games (RSGs). Our main result proves existence of a super-strong considerate equilibrium in all symmetric RSGs with strictly increasing delays, for any social network among the players and feasible coalitions represented by the set of cliques. The existence proof is constructive and yields an efficient algorithm. In fact, the computed considerate equilibrium is a Nash equilibrium for a standard RSG, thus showing that there exists a state that is stable against selfish and considerate behavior simultaneously. Furthermore, we provide results on convergence of considerate dynamics.

#index 1826103
#* Model checking knowledge in pursuit evasion games
#@ Xiaowei Huang;Patrick Maupin;Ron Van Der Meyden
#t 2011
#c 11
#% 36176
#% 183299
#% 188086
#% 195739
#% 239239
#% 250339
#% 297770
#% 574043
#% 739590
#% 788674
#% 795925
#% 1041626
#% 1230304
#! In a pursuit-evasion game, one or more pursuers aim to discover the existence of, and then capture, an evader. The paper studies pursuit-evasion games in which players may have incomplete information concerning the game state. A methodology is presented for the application of a model checker for the logic of knowledge and time to verify epistemic properties in such games. Experimental results are provided from a number of case studies that validate the feasibility of the approach.

#index 1826104
#* The complexity of safe manipulation under scoring rules
#@ Egor Ianovski;Lan Yu;Edith Elkind;Mark C. Wilson
#t 2011
#c 11
#% 417561
#% 1083984
#% 1150431
#% 1305345
#% 1426673
#% 1453102
#% 1530771
#! [Slinko and White, 2008] have recently introduced a new model of coalitional manipulation of voting rules under limited communication, which they call safe strategic voting. The computational aspects of this model were first studied by [Hazon and Elkind, 2010], who provide polynomial-time algorithms for finding a safe strategic vote under k- approval and the Bucklin rule. In this paper, we answer an open question of [Hazon and Elkind, 2010] by presenting a polynomial-time algorithm for finding a safe strategic vote under the Borda rule. Our results for Borda generalize to several interesting classes of scoring rules.

#index 1826105
#* Comparing variants of strategic ability
#@ Wojciech Jamroga;Nils Bulling
#t 2011
#c 11
#% 413871
#% 504415
#% 875611
#% 890221
#% 944865
#% 1021241
#% 1036059
#% 1105437
#% 1137921
#% 1269736
#! We show that different semantics of ability in ATL give rise to different validity sets. As a consequence, different notions of ability induce different strategic logics and different general properties of games. Moreover, the study can be seen as the first systematic step towards satisfiability-checking algorithms for ATL with imperfect information.

#index 1826106
#* Accelerating best response calculation in large extensive games
#@ Michael Johanson;Kevin Waugh;Michael Bowling;Martin Zinkevich
#t 2011
#c 11
#% 1215607
#% 1269678
#% 1451414
#! One fundamental evaluation criteria of an AI technique is its performance in the worst-case. For static strategies in extensive games, this can be computed using a best response computation. Conventionally, this requires a full game tree traversal. For very large games, such as poker, that traversal is infeasible to perform on modern hardware. In this paper, we detail a general technique for best response computations that can often avoid a full game tree traversal. Additionally, our method is specifically well-suited for parallel environments. We apply this approach to computing the worst-case performance of a number of strategies in heads-up limit Texas hold'em, which, prior to this work, was not possible. We explore these results thoroughly as they provide insight into the effects of abstraction on worst-case performance in large imperfect information games. This is a topic that has received much attention, but could not previously be examined outside of toy domains.

#index 1826107
#* A mechanism for dynamic ride sharing based on parallel auctions
#@ Alexander Kleiner;Bernhard Nebel;Vittorio Amos Ziparo
#t 2011
#c 11
#% 102123
#% 835024
#% 1305320
#% 1777042
#! Car pollution is one of the major causes of greenhouse emissions, and traffic congestion is rapidly becoming a social plague. Dynamic Ride Sharing (DRS) systems have the potential to mitigate this problem by computing plans for car drivers, e.g. commuters, allowing them to share their rides. Existing efforts in DRS are suffering from the problem that participants are abandoning the system after repeatedly failing to get a shared ride. In this paper we present an incentive compatible DRS solution based on auctions. While existing DRS systems are mainly focusing on fixed assignments that minimize the totally travelled distance, the presented approach is adaptive to individual preferences of the participants. Furthermore, our system allows to tradeoff the minimization of Vehicle Kilometers Travelled (VKT) with the overall probability of successful ride-shares, which is an important feature when bootstrapping the system. To the best of our knowledge, we are the first to present a DRS solution based on auctions using a sealed-bid second price scheme.

#index 1826108
#* Security games with multiple attacker resources
#@ Dmytro Korzhyk;Vincent Conitzer;Ronald Parr
#t 2011
#c 11
#% 868454
#% 898290
#% 1083973
#% 1215597
#% 1453189
#% 1617544
#! Algorithms for finding game-theoretic solutions are now used in several real-world security applications. This work has generally assumed a Stackelberg model where the defender commits to a mixed strategy first. In general two-player normal-form games, Stackelberg strategies are easier to compute than Nash equilibria, though it has recently been shown that in many security games, Stackelberg strategies are also Nash strategies for the defender. However, the work on security games so far assumes that the attacker attacks only a single target. In this paper, we generalize to the case where the attacker attacks multiple targets simultaneously. Here, Stackelberg and Nash strategies for the defender can be truly different. We provide a polynomial-time algorithm for finding a Nash equilibrium. The algorithm gradually increases the number of defender resources and maintains an equilibrium throughout this process. Moreover, we prove that Nash equilibria in security games with multiple attackers satisfy the interchange property, which resolves the problem of equilibrium selection in such games. On the other hand, we show that Stackelberg strategies are actually NP-hard to compute in this context. Finally, we provide experimental results.

#index 1826110
#* Robust approximation and incremental elicitation in voting protocols
#@ Tyler Lu;Craig Boutilier
#t 2011
#c 11
#% 578715
#% 808366
#% 844381
#% 1083982
#% 1208130
#% 1250151
#% 1270050
#% 1274968
#% 1274973
#% 1291488
#% 1426666
#% 1538167
#! While voting schemes provide an effective means for aggregating preferences, methods for the effective elicitation of voter preferences have received little attention. We address this problem by first considering approximate winner determination when incomplete voter preferences are provided. Exploiting natural scoring metrics, we use max regret to measure the quality or robustness of proposed winners, and develop polynomial time algorithms for computing the alternative with minimax regret for several popular voting rules. We then show how minimax regret can be used to effectively drive incremental preference/vote elicitation and devise several heuristics for this process. Despite worst-case theoretical results showing that most voting protocols require nearly complete voter preferences to determine winners, we demonstrate the practical effectiveness of regret-based elicitation for determining both approximate and exact winners on several real-world data sets.

#index 1826111
#* Push and swap: fast cooperative path-finding with completeness guarantees
#@ Ryan Luna;Kostas E. Bekris
#t 2011
#c 11
#% 1275076
#% 1305589
#% 1769058
#! Cooperative path-finding can be abstracted as computing non-colliding paths for multiple agents between their start and goal locations on a graph. This paper proposes a fast algorithm that can provide completeness guarantees for a general class of problems without any assumptions about the graph's topology. Specifically, the approach can address any solvable instance where there are at most n-2 agents in a graph of size n. The algorithm employs two primitives: a "push" operation where agents move towards their goals up to the point that no progress can be made, and a "swap" operation that allows two agents to swap positions without altering the configuration of other agents. Simulated experiments are provided on hard instances of cooperative path-finding, including comparisons against alternative methods. The results are favorable for the proposed algorithm and show that the technique scales to problems that require high levels of coordination, involving hundreds of agents.

#index 1826112
#* Subsidies, stability, and restricted cooperation in coalitional games
#@ Reshef Meir;Jeffrey S. Rosenschein;Enrico Malizia
#t 2011
#c 11
#% 813768
#% 1250607
#% 1266919
#% 1274979
#% 1291457
#% 1332425
#% 1339859
#% 1453185
#% 1530782
#! Cooperation among automated agents is becoming increasingly important in various artificial intelligence applications. Coalitional (i.e., cooperative) game theory supplies conceptual and mathematical tools useful in the analysis of such interactions, and in particular in the achievement of stable outcomes among self-interested agents. Here, we study the minimal external subsidy required to stabilize the core of a coalitional game. Following the Cost of Stability (CoS) model introduced by Bachrach et al. [2009a], we give tight bounds on the required subsidy under various restrictions on the social structure of the game. We then compare the extended core induced by subsidies with the least core of the game, proving tight bounds on the ratio between the minimal subsidy and the minimal demand relaxation that each lead to stability.

#index 1826113
#* Using experience to generate new regulations
#@ Javier Morales;Maite López-Sánchez;Marc Esteva
#t 2011
#c 11
#% 176887
#% 181622
#% 1192290
#% 1215531
#% 1215604
#% 1229848
#% 1272214
#% 1414421
#% 1453132
#% 1453152
#% 1603955
#% 1776838
#! Humans have developed jurisprudence as a mechanism to solve conflictive situations by using past experiences. Following this principle, we propose an approach to enhance a multi-agent system by adding an authority which is able to generate new regulations whenever conflicts arise. Regulations are generated by learning from previous similar situations, using a machine learning technique (based on Case-Based Reasoning) that solves new problems using previous experiences. This approach requires: to be able to gather and evaluate experiences; and to be described in such a way that similar social situations require similar regulations. As a scenario to evaluate our proposal, we use a simplified version of a traffic scenario, where agents are traveling cars. Our goals are to avoid collisions between cars and to avoid heavy traffic. These situations, when happen, lead to the synthesis of new regulations. At each simulation step, applicable regulations are evaluated in terms of their effectiveness and necessity. Overtime the system generates a set of regulations that, if followed, improve system performance (i.e. goal achievement).

#index 1826114
#* Agents, actions and goals in dynamic environments
#@ Peter Novák;Wojciech Jamroga
#t 2011
#c 11
#% 101955
#% 543524
#% 1068329
#% 1215524
#! In agent-oriented programming and planning, agents' actions are typically specified in terms of postconditions, and the model of execution assumes that the environment carries the actions out exactly as specified. That is, it is assumed that the state of the environment after an action has been executed will satisfy its postcondition. In reality, however, such environments are rare: the actual execution of an action may fail, and the envisaged outcome is not met. We provide a conceptual framework for reasoning about success and failure of agents' behaviours. In particular, we propose a measure that reflects how "good" an environment is with respect to agent's capabilities and a given goal it might pursue. We also discuss which types of goals are worth pursuing, depending on the type of environment the agent is acting in.

#index 1826115
#* On the complexity of voting manipulation under randomized tie-breaking
#@ Svetlana Obraztsova;Edith Elkind
#t 2011
#c 11
#% 408396
#% 417561
#% 1083981
#% 1083984
#% 1150431
#% 1305308
#% 1305345
#% 1426682
#% 1614152
#! Computational complexity of voting manipulation is one of the most actively studied topics in the area of computational social choice, starting with the groundbreaking work of [Bartholdi et al., 1989]. Most of the existing work in this area, including that of [Bartholdi et al., 1989], implicitly assumes that whenever several candidates receive the top score with respect to the given voting rule, the resulting tie is broken according to a lexicographic ordering over the candidates. However, till recently, an equally appealing method of tie-breaking, namely, selecting the winner uniformly at random among all tied candidates, has not been considered in the computational social choice literature. The first paper to analyze the complexity of voting manipulation under randomized tiebreaking is [Obraztsova et al., 2011], where the authors provide polynomial-time algorithms for this problem under scoring rules and--under an additional assumption on the manipulator's utilities-- for Maximin. In this paper, we extend the results of [Obraztsova et al., 2011] by showing that finding an optimal vote under randomized tie-breaking is computationally hard for Copeland and Maximin (with general utilities), as well as for STV and Ranked Pairs, but easy for the Bucklin rule and Plurality with Runoff.

#index 1826116
#* Efficient planning for factored infinite-horizon DEC-POMDPs
#@ Joni Pajarinen;Jaakko Peltonen
#t 2011
#c 11
#% 283131
#% 716892
#% 1084074
#% 1289555
#% 1453204
#% 1496771
#% 1650568
#% 1699607
#! Decentralized partially observable Markov decision processes (DEC-POMDPs) are used to plan policies for multiple agents that must maximize a joint reward function but do not communicate with each other. The agents act under uncertainty about each other and the environment. This planning task arises in optimization of wireless networks, and other scenarios where communication between agents is restricted by costs or physical limits. DEC-POMDPs are a promising solution, but optimizing policies quickly becomes computationally intractable when problem size grows. Factored DEC-POMDPs allow large problems to be described in compact form, but have the same worst case complexity as non-factored DEC-POMDPs. We propose an efficient optimization algorithm for large factored infinite-horizon DEC-POMDPs. We formulate expectation-maximization based optimization into a new form, where complexity can be kept tractable by factored approximations. Our method performs well, and it can solve problems with more agents and larger state spaces than state of the art DEC-POMDP methods. We give results for factored infinite-horizon DEC-POMDP problems with up to 10 agents.

#index 1826117
#* An interaction-oriented model for multi-scale simulation
#@ Sébastien Picault;Philippe Mathieu
#t 2011
#c 11
#% 215020
#% 446652
#% 1223512
#% 1453123
#% 1453298
#% 1595608
#% 1618820
#% 1697892
#! The design of multiagent simulations devoted to complex systems, addresses the issue of modeling behaviors that are involved at different space, time, behavior scales, each one being relevant so as to represent a feature of the phenomenon. We propose here a generic formalismintended to represent multiple environments, endowed with their own spatiotemporal scales and with behavioral rules for the agents they contain. An environment can be nested inside any agent, which itself is situated in one or more environments. This leads to a lattice decomposition of the global system, which appears to be necessary for an accurate design of multi-scale systems. This uniform representation of entities and behaviors at each abstraction level relies upon an interaction-oriented approach for the design of agent simulations, which clearly separates agents from interactions, from the modeling to the code. We also explain the implementation of our formalism within an existing interaction-based platform.

#index 1826118
#* Minimum search to establish worst-case guarantees in coalition structure generation
#@ Talal Rahwan;Tomasz Michalak;Nicholas R. Jennings
#t 2011
#c 11
#% 233135
#% 284645
#% 302018
#% 404719
#% 659853
#% 773258
#% 1250607
#% 1272269
#% 1290268
#% 1305331
#% 1412978
#! Coalition formation is a fundamental research topic in multi-agent systems. In this context, while it is desirable to generate a coalition structure that maximizes the sum of the values of the coalitions, the space of possible solutions is often too large to allow exhaustive search. Thus, a fundamental open question in this area is the following: Can we search through only a subset of coalition structures, and be guaranteed to find a solution that is within a desirable bound β from optimum? If so, what is the minimum such subset?. To date, the above question has only been partially answered by Sandholm et al. in their seminal work on anytime coalition structure generation [Sandholm et al., 1999]. More specifically, they identified minimum subsets to be searched for two particular bounds: β = n and β = ⌈n/2⌉. Nevertheless, the question remained open for other values of β. In this paper, we provide the complete answer to this question.

#index 1826119
#* On combining decisions from multiple expert imitators for performance
#@ Jonathan Rubin;Ian Watson
#t 2011
#c 11
#% 168280
#% 425053
#% 428413
#% 551723
#% 1073890
#% 1252995
#% 1333072
#% 1737344
#! One approach for artificially intelligent agents wishing to maximise some performance metric in a given domain is to learn from a collection of training data that consists of actions or decisions made by some expert, in an attempt to imitate that expert's style. We refer to this type of agent as an expert imitator. In this paper we investigate whether performance can be improved by combining decisions from multiple expert imitators. In particular, we investigate two existing approaches for combining decisions. The first approach combines decisions by employing ensemble voting between multiple expert imitators. The second approach dynamically selects the best imitator to use at runtime given the performance of the imitators in the current environment. We investigate these approaches in the domain of computer poker. In particular, we create expert imitators for limit and no limit Texas Hold'em and determine whether their performance can be improved by combining their decisions using the two approaches listed above.

#index 1826120
#* An empirical study of seeding manipulations and their prevention
#@ Tyrel Russell;Peter Van Beek
#t 2011
#c 11
#% 736538
#% 958702
#% 1215539
#% 1274974
#% 1442446
#% 1454257
#% 1473250
#! It is well known that cheating occurs in sports. In cup competitions, a common type of sports competition, one method of cheating is in manipulating the seeding to unfairly advantage a particular team. Previous empirical and theoretical studies of seeding manipulation have focused on competitions with unrestricted seeding. However, real cup competitions often place restrictions on seedings to ensure fairness, wide geographic interest, and so on. In this paper, we perform an extensive empirical study of seeding manipulation under comprehensive and realistic sets of restrictions. A generalized random model of competition problems is proposed. This model creates a realistic range of problem instances that are used to identify the sets of seeding restrictions that are hard to manipulate in practice. We end with a discussion of the implications of this work and recommendations for organizing competitions so as to prevent or reduce the opportunities for manipulating the seeding.

#index 1826121
#* Rigging tournament brackets for weaker players
#@ Isabelle Stanton;Virginia Vassilevska Williams
#t 2011
#c 11
#% 785100
#% 847120
#% 858155
#% 1039607
#% 1068448
#% 1096055
#% 1222621
#% 1274974
#% 1332271
#% 1453314
#% 1619125
#! Consider the following problem in game manipulation. A tournament designer who has full knowledge of the match outcomes between any possible pair of players would like to create a bracket for a balanced single-elimination tournament so that their favorite player will win. Although this problem has been studied in the areas of voting and tournament manipulation, it is still unknown whether it can be solved in polynomial time. We focus on identifying several general cases for which the tournament can always be rigged efficiently so that the given player wins. We give constructive proofs that, under some natural assumptions, if a player is ranked among the top K players, then one can efficiently rig the tournament for the given player, even when K is as large as 19% of the players.

#index 1826122
#* Learning where you are going and from whence you came: h- and g-cost learning in real-time heuristic search
#@ Nathan R. Sturtevant;Vadim Bulitko
#t 2011
#c 11
#% 2194
#% 68238
#% 398953
#% 529808
#% 581812
#% 1171114
#% 1272096
#% 1453098
#! Real-time agent-centric algorithms have been used for learning and solving problems since the introduction of the LRTA* algorithm in 1990. In this time period, numerous variants have been produced, however, they have generally followed the same approach in varying parameters to learn a heuristic which estimates the remaining cost to arrive at a goal state. Recently, a different approach, RIBS, was suggested which, instead of learning costs to the goal, learns costs from the start state. RIBS can solve some problems faster, but in other problems has poor performance. We present a new algorithm, f-cost Learning Real-Time A* (f-LRTA*), which combines both approaches, simultaneously learning distances from the start and heuristics to the goal. An empirical evaluation demonstrates that f-LRTA* outperforms both RIBS and LRTA*-style approaches in a range of scenarios.

#index 1826123
#* Emergence and stability of social conventions in conflict situations
#@ Toshiharu Sugawara
#t 2011
#c 11
#% 233136
#% 1083959
#% 1084419
#% 1274996
#% 1289505
#% 1478501
#! We investigate the emergence and stability of social conventions for efficiently resolving conflicts through reinforcement learning. Facilitation of coordination and conflict resolution is an important issue in multi-agent systems. However, exhibiting coordinated and negotiation activities is computationally expensive. In this paper, we first describe a conflict situation using a Markov game which is iterated if the agents fail to resolve their conflicts, where the repeated failures result in an inefficient society. Using this game, we show that social conventions for resolving conflicts emerge, but their stability and social efficiency depend on the payoff matrices that characterize the agents. We also examine how unbalanced populations and small heterogeneous agents affect efficiency and stability of the resulting conventions. Our results show that (a) a type of indecisive agent that is generous for adverse results leads to unstable societies, and (b) selfish agents that have an explicit order of benefits make societies stable and efficient.

#index 1826124
#* Approximating optimal combinatorial auctions for complements using restricted welfare maximization
#@ Pingzhong Tang;Tuomas Sandholm
#t 2011
#c 11
#% 754148
#% 813836
#% 1000451
#% 1222643
#% 1250155
#% 1269401
#% 1272153
#! The VCG mechanism is the gold standard for combinatorial auctions (CAs), and it maximizes social welfare. In contrast, the revenue-maximizing (aka optimal) CA is unknown, and designing one is NP-hard. Therefore, research on optimal CAs has progressed into special settings. Notably, Levin [1997] derived the optimal CA for complements when each agent's private type is one-dimensional. (This does not fall inside the well-studied "single-parameter environment".) We introduce a new research avenue for increasing revenue where we poke holes in the allocation space--based on the bids--and then use a welfare-maximizing allocation rule within the remaining allocation set. In this paper, the first step down this avenue, we introduce a new form of "reserve pricing" into CAs. We show that Levin's optimal revenue can be 2-approximated by using "monopoly reserve prices" to curtail the allocation set, followed by welfare-maximizing allocation and Levin's payment rule. A key lemma of potential independent interest is that the expected revenue from any truthful allocation-monotonic mechanism equals the expected virtual valuation; this generalizes Myerson's lemma [1981] from the single-parameter environment. Our mechanism is close to the gold standard and thus easier to adopt than Levin's. It also requires less information about the prior over the bidders' types, and is always more efficient. Finally, we show that the optimal revenue can be 6- approximated even if the "reserve pricing" is required to be symmetric across bidders.

#index 1826125
#* Generalizing envy-freeness toward group of agents
#@ Taiki Todo;Runcong Li;Xuemei Hu;Takayuki Mouri;Atsushi Iwasaki;Makoto Yokoo
#t 2011
#c 11
#% 723935
#% 1269400
#% 1279318
#% 1332279
#% 1453128
#! Envy-freeness is a well-known fairness concept for analyzing mechanisms. Its traditional definition requires that no individual envies another individual. However, an individual (or a group of agents) may envy another group, even if she (or they) does not envy another individual. In mechanisms with monetary transfer, such as combinatorial auctions, considering such fairness requirements, which are refinements of traditional envy-freeness, is meaningful and brings up a new interesting research direction in mechanism design. In this paper, we introduce two new concepts of fairness called envy-freeness of an individual toward a group, and envy-freeness of a group toward a group. They are natural extensions of traditional envy-freeness. We discuss combinatorial auction mechanisms that satisfy these concepts. First, we characterize such mechanisms by focusing on their allocation rules. Then we clarify the connections between these concepts and three other properties: the core, strategy-proofness, and false-name-proofness.

#index 1826126
#* Concise characteristic function representations in coalitional games based on agent types
#@ Suguru Ueda;Makoto Kitaki;Atsushi Iwasaki;Makoto Yokoo
#t 2011
#c 11
#% 165011
#% 284645
#% 529664
#% 808378
#% 1083983
#% 1083986
#% 1083989
#% 1084394
#% 1164854
#% 1229367
#% 1291437
#% 1291457
#% 1305304
#% 1412978
#% 1453143
#! Forming effective coalitions is a major research challenge in AI and multi-agent systems (MAS). Thus, coalitional games, including Coalition Structure Generation (CSG), have been attracting considerable attention from the AI research community. Traditionally, the input of a coalitional game is a black-box function called a characteristic function. A range of previous studies have found that many problems in coalitional games tend to be computationally intractable when the input is a black-box function. Recently, several concise representation schemes for a characteristic function have been proposed. Although these schemes are effective for reducing the representation size, most problems remain computationally intractable. In this paper, we develop a new concise representation scheme based on the idea of agent types. Intuitively, a type represents a set of agents, which are recognized as having the same contribution. This representation can be exponentially more concise than existing concise representation schemes. Furthermore, this idea can be used in conjunction with existing schemes to further reduce the representation size. Moreover, we show that most of the problems in coalitional games, including CSG, can be solved in polynomial time in the number of agents, assuming the number of possible types is fixed.

#index 1826127
#* Facing openness with socio-cognitive trust and categories
#@ Matteo Venanzi;Michele Piunti;Rino Falcone;Cristiano Castelfranchi
#t 2011
#c 11
#% 336984
#% 378941
#% 878367
#% 881719
#% 1024840
#% 1127877
#% 1453087
#% 1485634
#% 1693047
#! Typical solutions for agents assessing trust relies on the circulation of information on the individual level, i.e. reputational images, subjective experiences, statistical analysis, etc. This work presents an alternative approach, inspired to the cognitive heuristics enabling humans to reason at a categorial level. The approach is envisaged as a crucial ability for agents in order to: (1) estimate trustworthiness of unknown trustees based on an ascribed membership to categories; (2) learn a series of emergent relations between trustees observable properties and their effective abilities to fulfill tasks in situated conditions. On such a basis, categorization is provided to recognize signs (Manifesta) through which hidden capabilities (Kripta) can be inferred. Learning is provided to refine reasoning attitudes needed to ascribe tasks to categories. A series of architectures combining categorization abilities, individual experiences and context awareness are evaluated and compared in simulated experiments.

#index 1826128
#* Attack semantics for abstract argumentation
#@ Serena Villata;Guido Boella;Leendert Van Der Torre
#t 2011
#c 11
#% 198464
#% 992251
#% 1222446
#% 1291495
#% 1496577
#% 1664525
#% 1706869
#! In this paper we conceptualize abstract argumentation in terms of successful and unsuccessful attacks, such that arguments are accepted when there are no successful attacks on them. We characterize the relation between attack semantics and Dung's approach, and we define an SCC recursive algorithm for attack semantics using attack labelings.

#index 1826129
#* Dynamic sanctioning for robust and cost-efficient norm compliance
#@ Daniel Villatoro;Giulia Andrighetto;Jordi Sabater-Mir;Rosaria Conte
#t 2011
#c 11
#% 1096159
#% 1503913
#! As explained by Axelrod in his seminal work An Evolutionary Approach to Norms, punishment is a key mechanism to achieve the necessary social control and to impose social norms in a self-regulated society. In this paper, we distinguish between two enforcing mechanisms. i.e. punishment and sanction, focusing on the specific ways in which they favor the emergence and maintenance of cooperation. The key research question is to find more stable and cheaper mechanisms for norm compliance in hybrid social environments (populated by humans and computational agents). To achieve this task, we have developed a normative agent able to punish and sanction defectors and to dynamically choose the right amount of punishment and sanction to impose on them (Dynamic Adaptation Heuristic). The results obtained through agent-based simulation show us that sanction is more effective and less costly than punishment in the achievement and maintenance of cooperation and it makes the population more resilient to sudden changes than if it were enforced only by mere punishment.

#index 1826130
#* Social instruments for robust convention emergence
#@ Daniel Villatoro;Jordi Sabater-Mir;Sandip Sen
#t 2011
#c 11
#% 233136
#% 428342
#% 737084
#% 870884
#% 1083959
#% 1274996
#% 1280825
#% 1453088
#! We present the notion of Social Instruments as mechanisms that facilitate the emergence of conventions from repeated interactions between members of a society. Specifically, we focus on two social instruments: rewiring and observation. Our main goal is to provide agents with tools that allow them to leverage their social network of interactions when effectively addressing coordination and learning problems, paying special attention to dissolving metastable subconventions. Our initial experiments throw some light on how Self-Reinforcing Substructures (SRS) in the network prevent full convergence to society-wide conventions, resulting in reduced convergence rates. The use of an effective composed social instrument, observation + rewiring, allow agents to achieve convergence by eliminating the subconventions that otherwise remained meta-stable.

#index 1826131
#* Reasoning about preferences in intelligent agent systems
#@ Simeon Visser;John Thangarajah;James Harland
#t 2011
#c 11
#% 341652
#% 643129
#% 890321
#% 1587998
#! Agent systems based on the BDI paradigm need to make decisions about which plans are used to achieve their goals. Usually the choice of which plan to use to achieve a particular goal is left up to the system to determine. In this paper we show how preferences, which can be set by the user of the system, can be incorporated into the BDI execution process and used to guide the choices made.

#index 1826132
#* Using Gaussian processes to optimise concession in complex negotiations against unknown opponents
#@ Colin R. Williams;Valentin Robu;Enrico H. Gerding;Nicholas R. Jennings
#t 2011
#c 11
#% 799159
#% 823880
#% 891549
#% 916479
#% 1024832
#% 1024869
#% 1036396
#% 1084051
#% 1215788
#% 1453328
#! In multi-issue automated negotiation against unknown opponents, a key part of effective negotiation is the choice of concession strategy. In this paper, we develop a principled concession strategy, based on Gaussian processes predicting the opponent's future behaviour. We then use this to set the agent's concession rate dynamically during a single negotiation session. We analyse the performance of our strategy and show that it outperforms the state-of-the-art negotiating agents from the 2010 Automated Negotiating Agents Competition, in both a tournament setting and in self-play, across a variety of negotiation domains.

#index 1826133
#* Online planning for ad hoc autonomous agent teams
#@ Feng Wu;Shlomo Zilberstein;Xiaoping Chen
#t 2011
#c 11
#% 425053
#% 782311
#% 983838
#% 1084054
#% 1090422
#% 1151182
#% 1273798
#% 1291064
#% 1453072
#% 1526847
#% 1615228
#% 1650420
#% 1665148
#! We propose a novel online planning algorithm for ad hoc team settings--challenging situations in which an agent must collaborate with unknown teammates without prior coordination. Our approach is based on constructing and solving a series of stage games, and then using biased adaptive play to choose actions. The utility function in each stage game is estimated via Monte-Carlo tree search using the UCT algorithm. We establish analytically the convergence of the algorithm and show that it performs well in a variety of ad hoc team domains.

#index 1826134
#* A maximum likelihood approach towards aggregating partial orders
#@ Lirong Xia;Vincent Conitzer
#t 2011
#c 11
#% 1071501
#% 1208130
#% 1250233
#% 1269671
#% 1270050
#% 1272026
#% 1305299
#% 1305308
#% 1453106
#% 1464590
#! In many of the possible applications as well as the theoretical models of computational social choice, the agents' preferences are represented as partial orders. In this paper, we extend the maximum likelihood approach for defining "optimal" voting rules to this setting. We consider distributions in which the pairwise comparisons/incomparabilities between alternatives are drawn i.i.d. We call such models pairwise-independent models and show that they correspond to a class of voting rules that we call pairwise scoring rules. This generalizes rules such as Kemeny and Borda. Moreover, we show that Borda is the only pairwise scoring rule that satisfies neutrality, when the outcome space is the set of all alternatives. We then study which voting rules defined for linear orders can be extended to partial orders via our MLE model. We show that any weakly neutral outcome scoring rule (including any ranking/candidate scoring rule) based on the weighted majority graph can be represented as the MLE of a weakly neutral pairwise-independent model. Therefore, all such rules admit natural extensions to profiles of partial orders. Finally, we propose a specific MLE model πk for generating a set of k winning alternatives, and study the computational complexity of winner determination for the MLE of πk.

#index 1826135
#* An efficient Monte-Carlo algorithm for pricing combinatorial prediction markets for tournaments
#@ Lirong Xia;David M. Pennock
#t 2011
#c 11
#% 44876
#% 58608
#% 341672
#% 431455
#% 578658
#% 1036395
#% 1061612
#% 1071510
#% 1250224
#% 1269433
#% 1270062
#% 1339861
#% 1426662
#! Computing the marketmaker price of a security in a combinatorial prediction market is #P-hard. We devise a fully polynomial randomized approximation scheme (FPRAS) that computes the price of any security in disjunctive normal form (DNF) within an ε multiplicative error factor in time polynomial in 1/ε and the size of the input, with high probability and under reasonable assumptions. Our algorithm is a Monte-Carlo technique based on importance sampling. The algorithm can also approximately price securities represented in conjunctive normal form (CNF) with additive error bounds. To illustrate the applicability of our algorithm, we show that many securities in Yahoo!'s popular combinatorial prediction market game called Predictalot can be represented by DNF formulas of polynomial size.

#index 1826136
#* Improving resource allocation strategy against human adversaries in security games
#@ Rong Yang;Christopher Kiekintveld;Fernando Ordonez;Milind Tambe;Richard John
#t 2011
#c 11
#% 1084332
#% 1215597
#% 1456452
#! Recent real-world deployments of Stackelberg security games make it critical that we address human adversaries' bounded rationality in computing optimal strategies. To that end, this paper provides three key contributions: (i) new efficient algorithms for computing optimal strategic solutions using Prospect Theory and Quantal Response Equilibrium; (ii) the most comprehensive experiment to date studying the effectiveness of different models against human subjects for security games; and (iii) new techniques for generating representative payoff structures for behavioral experiments in generic classes of games. Our results with human subjects show that our new techniques outperform the leading contender for modeling human behavior in security games.

#index 1826137
#* Continuous time planning for multiagent teams with temporal constraints
#@ Zhengyu Yin;Milind Tambe
#t 2011
#c 11
#% 450852
#% 643084
#% 823962
#% 1024895
#% 1084075
#% 1099892
#% 1171119
#% 1215646
#% 1269380
#% 1269546
#% 1272052
#% 1275161
#% 1453037
#% 1453203
#% 1453204
#! Continuous state DEC-MDPs are critical for agent teams in domains involving resources such as time, but scaling them up is a significant challenge. To meet this challenge, we first introduce a novel continuous-time DEC-MDP model that exploits transition independence in domains with temporal constraints. More importantly, we present a new locally optimal algorithm called SPAC. Compared to the best previous algorithm, SPAC finds solutions of comparable quality substantially faster; SPAC also scales to larger teams of agents.

#index 1826138
#* Mechanism design for double auctions with temporal constraints
#@ Dengji Zhao;Dongmo Zhang;Laurent Perrussel
#t 2011
#c 11
#% 1451
#% 3938
#% 107971
#% 274891
#% 907719
#% 1272184
#% 1279507
#! This paper examines an extended double auction model where market clearing is restricted by temporal constraints. It is found that the allocation problem in this model can be effectively transformed into a weighted bipartite matching in graph theory. By using the augmentation technique, we propose a Vickrey-Clarke-Groves (VCG) mechanism in this model and demonstrate the advantages of the payment compared with the classical VCG payment (the Clarke pivot payment). We also show that the algorithms for both allocation and payment calculation run in polynomial time. It is expected that the method and results provided in this paper can be applied to the design and analysis of dynamic double auctions and futures markets.

#index 1826139
#* Generalized reaction functions for solving complex-task allocation problems
#@ Xiaoming Zheng;Sven Koenig
#t 2011
#c 11
#% 1083932
#% 1274972
#! We study distributed task-allocation problems where cooperative agents need to perform some tasks simultaneously. Examples are multi-agent routing problems where several agents need to visit some targets simultaneously, for example, to move obstacles out of the way cooperatively. In this paper, we first generalize the concept of reaction functions proposed in the literature to characterize the agent costs of performing multiple complex tasks. Second, we show how agents can construct and approximate reaction functions in a distributed way. Third, we show how reaction functions can be used by an auctionlike algorithm to allocate tasks to agents. Finally, we show empirically that the team costs of our algorithms are substantially smaller than those of an existing state-of-the-art allocation algorithm for complex tasks.

#index 1826140
#* Multi-agent plan recognition with partial team traces and plan libraries
#@ Hankz Hankui Zhuo;Lei Li
#t 2011
#c 11
#% 1210222
#% 1230643
#% 1270246
#% 1279398
#% 1305575
#! Multi-Agent Plan Recognition (MAPR) seeks to identify the dynamic team structures and team behaviors from the observed activity sequences (team traces) of a set of intelligent agents, based on a library of known team activity sequences (team plans). Previous MAPR systems require that team traces and team plans are fully observed. In this paper we relax this constraint, i.e., team traces and team plans are allowed to be partial. This is an important task in applying MAPR to real-world domains, since in many applications it is often difficult to collect full team traces or team plans due to environment limitations, e.g., military operation. This is also a hard problem since the information available is limited. We propose a novel approach to recognizing team plans from partial team traces and team plans. We encode the MAPR problem as a satisfaction problem and solve the problem using a state-of-the-art weighted MAX-SAT solver. We empirically show that our algorithm is both effective and efficient.

#index 1826141
#* The Shapley value as a function of the quota in weighted voting games
#@ Yair Zick;Alexander Skopalik;Edith Elkind
#t 2011
#c 11
#% 80804
#% 165011
#% 341523
#% 1076646
#% 1151713
#% 1270053
#% 1350761
#% 1602936
#! In weighted voting games, each agent has a weight, and a coalition of players is deemed to be winning if its weight meets or exceeds the given quota. An agent's power in such games is usually measured by her Shapley value, which depends both on the agent's weight and the quota. [Zuckerman et al., 2008] show that one can alter a player's power significantly by modifying the quota, and investigate some of the related algorithmic issues. In this paper, we answer a number of questions that were left open by [Zuckerman et al., 2008]: we show that, even though deciding whether a quota maximizes or minimizes an agent's Shapley value is coNP-hard, finding a Shapley value-maximizing quota is easy. Minimizing a player's power appears to be more difficult. However, we propose and evaluate a heuristic for this problem, which takes into account the voter's rank and the overall weight distribution. We also explore a number of other algorithmic issues related to quota manipulation.

#index 1826142
#* Tackling the partner units configuration problem
#@ Markus Aschinger;Conrad Drescher;Georg Gottlob;Peter Jeavons;Evgenij Thorstensen
#t 2011
#c 11
#% 288711
#% 1091908
#% 1273489
#% 1274765
#% 1598168
#! The Partner Units Problem is a specific type of configuration problem with important applications in the area of surveillance and security. In this work we show that a special case of the problem, that is of great interest to our partners in industry, can directly be tackled via a structural problem decompostion method. Combining these theoretical insights with general purpose AI techniques such as constraint satisfaction and SAT solving proves to be particularly effective in practice.

#index 1826143
#* Depth-driven circuit-level stochastic local search for SAT
#@ Anton Belov;Matti Järvisalo;Zbigniev Stachniak
#t 2011
#c 11
#% 283231
#% 979219
#% 1153330
#% 1223543
#% 1230625
#% 1268742
#% 1275133
#% 1387621
#% 1413508
#% 1726943
#% 1785804
#! We develop a novel circuit-level stochastic local search (SLS) method D-CRSat for Boolean satisfiability by integrating a structure-based heuristic into the recent CRSat algorithm. D-CRSat significantly improves on CRSat on real-world application benchmarks on which other current CNF and circuit-level SLS methods tend to perform weakly. We also give an intricate proof of probabilistically approximate completeness for D-CRSat, highlighting key features of the method.

#index 1826144
#* Tractable set constraints
#@ Manuel Bodirsky;Martin Hils;Alex Krimkevich
#t 2011
#c 11
#% 212216
#% 257699
#% 317107
#% 344008
#% 428361
#% 448093
#% 477202
#% 587604
#% 600496
#% 806096
#% 836017
#% 856318
#% 866593
#% 911175
#% 944139
#% 982409
#% 1099417
#% 1289408
#% 1310060
#% 1379602
#% 1826144
#! Many fundamental problems in artificial intelligence, knowledge representation, and verification involve reasoning about sets and relations between sets and can be modeled as set constraint satisfaction problems (set CSPs). Such problems are frequently intractable, but there are several important set CSPs that are known to be polynomial-time tractable. We introduce a large class of set CSPs that can be solved in quadratic time. Our class, which we call EI, contains all previously known tractable set CSPs, but also some new ones that are of crucial importance for example in description logics. The class of EI set constraints has an elegant universal-algebraic characterization, which we use to show that every set constraint language that properly contains all EI set constraints already has a finite sublanguage with an NP-hard constraint satisfaction problem.

#index 1826145
#* Symmetries and lazy clause generation
#@ Geoffrey Chu;Peter J. Stuckey;Maria Garcia De la Banda;Chris Mears
#t 2011
#c 11
#% 534506
#% 534837
#% 534978
#% 535172
#% 1211661
#% 1399088
#% 1412987
#! Lazy clause generation is a powerful approach to reducing search in constraint programming. This is achieved by recording sets of domain restrictions that previously led to failure as new clausal propagators. Symmetry breaking approaches are also powerful methods for reducing search by recognizing that parts of the search tree are symmetric and do not need to be explored. In this paper we show how we can successfully combine symmetry breaking methods with lazy clause generation. Further, we show that the more precise nogoods generated by a lazy clause solver allow our combined approach to exploit redundancies that cannot be exploited via any previous symmetry breaking method, be it static or dynamic.

#index 1826146
#* Constraint satisfaction problems: convexity makes all different constraints tractable
#@ Michael Fellows;Tobias Friedrich;Danny Hermelin;Nina Narodytska;Frances Rosamond
#t 2011
#c 11
#% 2028
#% 55926
#% 122318
#% 160208
#% 237054
#% 266132
#% 400988
#% 408396
#% 460791
#% 560657
#% 600496
#% 857282
#% 1029092
#% 1061976
#% 1105314
#% 1125934
#% 1223531
#% 1223533
#% 1229544
#% 1277481
#% 1304482
#% 1332833
#% 1373433
#% 1412967
#% 1426325
#% 1697783
#% 1698002
#% 1972413
#! We examine the complexity of constraint satisfaction problems that consist of a set of AllDiff constraints. Such CSPs naturally model a wide range of real-world and combinatorial problems, like scheduling, frequency allocations and graph coloring problems. As this problem is known to be NP-complete, we investigate under which further assumptions it becomes tractable. We observe that a crucial property seems to be the convexity of the variable domains and constraints. Our main contribution is an extensive study of the complexity of Multiple AllDiff CSPs for a set of natural parameters, like maximum domain size and maximum size of the constraint scopes. We show that, depending on the parameter, convexity can make the problem tractable while it is provably intractable in general

#index 1826147
#* Probabilistic satisfiability: logic-based algorithms and phase transition
#@ Marcelo Finger;Glauber De Bona
#t 2011
#c 11
#% 3034
#% 15262
#% 42485
#% 271832
#% 336874
#% 417766
#% 601159
#% 1279714
#% 1290137
#! In this paper, we study algorithms for probabilistic satisfiability (PSAT), an NP-complete problem, and their empiric complexity distribution. We define a PSAT normal form, based on which we propose two logic-based algorithms: a reduction of normal form PSAT instances to SAT, and a linearalgebraic algorithmwith a logic-based column generation strategy. We conclude that both algorithms present a phase transition behaviour and that the latter has a much better performance.

#index 1826148
#* Using payoff-similarity to speed up search
#@ Timothy Furtak;Michael Buro
#t 2011
#c 11
#% 1305515
#% 1499499
#! Transposition tables are a powerful tool in search domains for avoiding duplicate effort and for guiding node expansions. Traditionally, however, they have only been applicable when the current state is exactly the same as a previously explored state. We consider a generalized transposition table, whereby a similarity metric that exploits local structure is used to compare the current state with a neighbourhood of previously seen states. We illustrate this concept and forward pruning based on function approximation in the domain of Skat, and show that we can achieve speedups of 16+ over standard methods.

#index 1826149
#* Kernels for global constraints
#@ Serge Gaspers;Stefan Szeider
#t 2011
#c 11
#% 534497
#% 534993
#% 911010
#% 928731
#% 949713
#% 1061595
#% 1250136
#% 1270056
#% 1277481
#% 1499496
#% 1541730
#% 1725694
#% 1726575
#% 1972413
#! Bessière et al. (AAAI'08) showed that several intractable global constraints can be efficiently propagated when certain natural problem parameters are small. In particular, the complete propagation of a global constraint is fixed-parameter tractable in k - the number of holes in domains - whenever bound consistency can be enforced in polynomial time; this applies to the global constraints ATMOST-NVALUE and EXTENDED GLOBAL CARDINALITY (EGC). In this paper we extend this line of research and introduce the concept of reduction to a problem kernel, a key concept of parameterized complexity, to the field of global constraints. In particular, we show that the consistency problem for ATMOST-NVALUE constraints admits a linear time reduction to an equivalent instance on O(k2) variables and domain values. This small kernel can be used to speed up the complete propagation of NVALUE constraints. We contrast this result by showing that the consistency problem for EGC constraints does not admit a reduction to a polynomial problem kernel unless the polynomial hierarchy collapses.

#index 1826150
#* A uniform approach for generating proofs and strategies for both true and false QBF formulas
#@ Alexandra Goultiaeva;Allen Van Gelder;Fahiem Bacchus
#t 2011
#c 11
#% 4599
#% 183640
#% 500082
#% 576843
#% 746744
#% 1022415
#% 1230638
#% 1269837
#% 1289358
#% 1305422
#% 1306288
#% 1396054
#% 1396067
#% 1675281
#% 1698713
#% 1726939
#! Many important problems can be compactly represented as quantified boolean formulas (QBF) and solved by general QBF solvers. To date QBF solvers have mainly focused on determining whether or not the input QBF is true or false. However, additional important information about an application can be gathered from its QBF formulation. In this paper we demonstrate that a circuitbased QBF solver can be exploited to obtain a QResolution proof of the truth or the falsity of a QBF. QBFs have a natural interpretation as a two person game and our main result is to show how, via a simple computation, the moves for the winning player can be computed directly from these proofs. This result shows that the proof is a representation of the winning strategy. In previous approaches the winning strategy has often been represented in a way that makes it hard to verify. In our approach the correctness of the strategy follows directly from the correctness of the proof, which is relatively easy to verify.

#index 1826151
#* Generalizing ADOPT and BnB-ADOPT
#@ Patricia Gutierrez;Pedro Meseguer;William Yeoh
#t 2011
#c 11
#% 773217
#% 823971
#% 1083942
#% 1289393
#% 1291421
#% 1498839
#! ADOPT and BnB-ADOPT are two optimal DCOP search algorithms that are similar except for their search strategies: the former uses best-first search and the latter uses depth-first branch-and-bound search. In this paper, we present a new algorithm, called ADOPT(k), that generalizes them. Its behavior depends on the k parameter. It behaves like ADOPT when k = 1, like BnB-ADOPT when k = ∞ and like a hybrid of ADOPT and BnB-ADOPT when 1 k k) is a correct and complete algorithm and experimentally show that ADOPT(k) outperforms ADOPT and BnB-ADOPT on several benchmarks across several metrics.

#index 1826152
#* Dynamic SAT with decision change costs: formalization and solutions
#@ Daisuke Hatano;Katsutoshi Hirayama
#t 2011
#c 11
#% 160248
#% 266125
#% 534478
#% 816232
#% 945275
#% 1269417
#% 1272189
#% 1389681
#% 1451385
#% 1477281
#% 1477282
#% 1499491
#! We address a dynamic decision problem in which decision makers must pay some costs when they change their decisions along the way. We formalize this problem as Dynamic SAT (DynSAT) with decision change costs, whose goal is to find a sequence of models that minimize the aggregation of the costs for changing variables. We provide two solutions to solve a specific case of this problem. The first uses a Weighted Partial MaxSAT solver after we encode the entire problem as a Weighted Partial MaxSAT problem. The second solution, which we believe is novel, uses the Lagrangian decomposition technique that divides the entire problem into sub-problems, each of which can be separately solved by an exact Weighted Partial MaxSAT solver, and produces both lower and upper bounds on the optimal in an anytime manner. To compare the performance of these solvers, we experimented on the random problem and the target tracking problem. The experimental results show that a solver based on Lagrangian decomposition performs better for the random problem and competitively for the target tracking problem.

#index 1826153
#* Minimization for generalized Boolean formulas
#@ Edith Hemaspaandra;Henning Schnoor
#t 2011
#c 11
#% 237054
#% 288946
#% 335852
#% 400370
#% 414998
#% 442984
#% 545243
#% 600496
#% 776187
#% 856318
#% 1041689
#% 1113937
#% 1172180
#% 1172182
#% 1172187
#% 1182881
#% 1272100
#% 1428631
#% 1496529
#% 1839809
#! The minimization problem for propositional formulas is an important optimization problem in the second level of the polynomial hierarchy. In general, the problem is Σ2p-complete under Turing reductions, but restricted versions are tractable. We study the complexity of minimization for formulas in two established frameworks for restricted propositional logic: The Post framework allowing arbitrarily nested formulas over a set of Boolean connectors, and the constraint setting, allowing generalizations of CNF formulas. In the Post case, we obtain a dichotomy result: Minimization is solvable in polynomial time or coNP-hard. This result also applies to Boolean circuits. For CNF formulas, we obtain new minimization algorithms for a large class of formulas, and give strong evidence that we have covered all polynomial-time cases.

#index 1826154
#* Read-once resolution for unsatisfiability-based Max-SAT algorithms
#@ Federico Heras;Joao Marques-Silva
#t 2011
#c 11
#% 616280
#% 776979
#% 977574
#% 1023522
#% 1084834
#% 1230639
#% 1230645
#% 1272049
#% 1272189
#% 1272198
#% 1383595
#% 1396047
#% 1413497
#% 1457061
#% 1728042
#! This paper proposes the integration of the resolution rule for Max-SAT with unsatisfiability-based Max-SAT solvers. First, we show that the resolution rule for Max-SAT can be safely applied as dictated by the resolution proof associated with an unsatisfiable core when such proof is read-once, that is, each clause is used at most once in the resolution process. Second, we study how this property can be integrated in an unsatisfiability-based solver. In particular, the resolution rule for Max-SAT is applied to read-once proofs or to read-once subparts of a general proof. Finally, we perform an empirical investigation on structured instances from recent Max-SAT evaluations. Preliminary results show that the use of read-once resolution substantially improves the performance of the solver.

#index 1826155
#* Real-time heuristic search with depression avoidance
#@ Carlos Hernández;Jorge A. Baier
#t 2011
#c 11
#% 68238
#% 398953
#% 655327
#% 890237
#% 1171114
#% 1272096
#% 1275125
#% 1289548
#% 1305358
#% 1478539
#% 1545556
#% 1617648
#! Heuristics used for solving hard real-time search problems have regions with depressions. Such regions are bounded areas of the search space in which the heuristic function is exceedingly low compared to the actual cost to reach a solution. Real-time search algorithms easily become trapped in those regions since the heuristic values of states in them may need to be updated multiple times, which results in costly solutions. State-of-theart real-time search algorithms like LSS-LRTA*, LRTA*(k), etc., improve LRTA*'s mechanism to update the heuristic, resulting in improved performance. Those algorithms, however, do not guide search towards avoiding or escaping depressed regions. This paper presents depression avoidance, a simple real-time search principle to guide search towards avoiding states that have been marked as part of a heuristic depression. We apply the principle to LSS-LRTA* producing aLSS-LRTA*, a new real-time search algorithm whose search is guided towards exiting regions with heuristic depressions. We show our algorithm outperforms LSS-LRTA* in standard real-time benchmarks. In addition we prove aLSS-LRTA* has most of the good theoretical properties of LSS-LRTA*.

#index 1826156
#* Evaluations of hash distributed A* in optimal sequence alignment
#@ Yoshikazu Kobayashi;Akihiro Kishimoto;Osamu Watanabe
#t 2011
#c 11
#% 2194
#% 54206
#% 167926
#% 192215
#% 235670
#% 268042
#% 398803
#% 829310
#% 1250321
#% 1250328
#% 1279391
#% 1279478
#% 1545566
#! Hash Distributed A* (HDA*) is a parallel A* algorithm that is proven to be effective in optimal sequential planning with unit edge costs. HDA* leverages the Zobrist function to almost uniformly distribute and schedule work among processors. This paper evaluates the performance of HDA* in optimal sequence alignment. We observe that with a large number of CPU cores HDA* suffers from an increase of search overhead caused by reexpansions of states in the closed list due to nonuniform edge costs in this domain. We therefore present a new work distribution strategy limiting processors to distribute work, thus increasing the possibility of detecting such duplicate search effort. We evaluate the performance of this approach on a cluster of multi-core machines and show that the approach scales well up to 384 CPU cores.

#index 1826157
#* A hybrid recursive multi-way number partitioning algorithm
#@ Richard E. Korf
#t 2011
#c 11
#% 267769
#% 288896
#% 408396
#% 674446
#% 1305341
#% 1305375
#! The number partitioning problem is to divide a given set of n positive integers into k subsets, so that the sum of the numbers in each subset are as nearly equal as possible. While effective algorithms for two-way partitioning exist, multiway partitioning is much more challenging. We introduce an improved algorithm for optimal multiway partitioning, by combining several existing algorithms with some new extensions. We test our algorithm for partitioning 31-bit integers from three to ten ways, and demonstrate orders of magnitude speedup over the previous state of the art.

#index 1826158
#* Constraint programming on infinite data streams
#@ A. Lallouet;Y. C. Law;J. H. M. Lee;C. F. K. Siu
#t 2011
#c 11
#% 1768
#% 101943
#% 283220
#% 419898
#% 644201
#% 794991
#% 803071
#% 816232
#% 1412955
#% 1664961
#! Classical constraint satisfaction problems (CSPs) are commonly defined on finite domains. In real life, constrained variables can evolve over time. A variable can actually take an infinite sequence of values over discrete time points. In this paper, we propose constraint programming on infinite data streams, which provides a natural way to model constrained time-varying problems. In our framework, variable domains are specified by ω-regular languages. We introduce special stream operators as basis to form stream expressions and constraints. Stream CSPs have infinite search space. We propose a search procedure that can recognize and avoid infinite search over duplicate search space. The solution set of a stream CSP can be represented by a Büchi automaton allowing stream values to be non-periodic. Consistency notions are defined to reduce the search space early. We illustrate the feasibility of the framework by examples and experiments.

#index 1826159
#* Minimum satisfiability and its applications
#@ Chu-Min Li;Zhu Zhu;Felip Manyà;Laurent Simon
#t 2011
#c 11
#% 160600
#% 206864
#% 314925
#% 806575
#% 1270074
#% 1272189
#% 1273727
#% 1273808
#% 1383595
#% 1457061
#% 1520671
#% 1726952
#! We define solving techniques for the Minimum Satisfiability Problem (MinSAT), propose an efficient branch-and-bound algorithm to solve the Weighted Partial MinSAT problem, and report on an empirical evaluation of the algorithm on Min-3SAT, Max-Clique, and combinatorial auction problems. Techniques solving MinSAT are substantially different from those for the Maximum Satisfiability Problem (MaxSAT). Our results provide empirical evidence that solving combinatorial optimization problems by reducing them to MinSAT may be substantially faster than reducing them to MaxSAT, and even competitive with specific algorithms. We also use MinSAT to study an interesting correlation between the minimum number and the maximum number of satisfied clauses of a SAT instance.

#index 1826160
#* Large hinge width on sparse random hypergraphs
#@ Tian Liu;Xiaxiang Lin;Chaoyi Wang;Kaile Su;Ke Xu
#t 2011
#c 11
#% 159244
#% 210193
#% 331899
#% 339937
#% 644201
#% 872870
#% 977568
#% 1061964
#% 1269694
#% 1270054
#% 1271812
#% 1272151
#% 1279714
#% 1378500
#% 1424371
#% 1478529
#% 1673009
#! Consider random hypergraphs on n vertices, where each k-element subset of vertices is selected with probability p independently and randomly as a hyperedge. By sparse we mean that the total number of hyperedges is O(n) or O(n ln n). When k = 2, these are exactly the classical Erdös-Rényi random graphs G(n, p). We prove that with high probability, hinge width on these sparse random hypergraphs can grow linearly with the expected number of hyperedges. Some random constraint satisfaction problems such as Model RB and Model RD have satisfiability thresholds on these sparse constraint hypergraphs, thus the large hinge width results provide some theoretical evidence for random instances around satisfiability thresholds to be hard for a standard hinge-decomposition based algorithm. We also conduct experiments on these and other kinds of random graphs with several hundreds vertices, including regular random graphs and power law random graphs. The experimental results also show that hinge width can grow linearly with the number of edges on these different random graphs. These results may be of further interests.

#index 1826161
#* Real-time opponent modelling in trick-taking card games
#@ Jeffrey Long;Michael Buro
#t 2011
#c 11
#% 348584
#% 868462
#% 1271963
#% 1274992
#% 1305515
#! As adversarial environments become more complex, it is increasingly crucial for agents to exploit the mistakes of weaker opponents, particularly in the context of winning tournaments and competitions. In this work, we present a simple post processing technique, which we call Perfect Information Post-Mortem Analysis (PIPMA), that can quickly assess the playing strength of an opponent in certain classes of game environments. We apply this technique to skat, a popular German card game, and show that we can achieve substantial performance gains against not only players weaker than our program, but against stronger players as well. Most importantly, PIPMA can model the opponent after only a handful of games. To our knowledge, this makes our work the first successful example of an opponent modelling technique that can adapt its play to a particular opponent in real time in a complex game setting.

#index 1826162
#* Exploiting short supports for generalised arc consistency for arbitrary constraints
#@ Peter Nightingale;Ian P. Gent;Chris Jefferson;Ian Miguel
#t 2011
#c 11
#% 3463
#% 534983
#% 535153
#% 1108481
#% 1223207
#% 1269699
#% 1272481
#% 1291374
#% 1399085
#% 1412971
#% 1493587
#% 1499496
#% 1664971
#! Special-purpose constraint propagation algorithms (such as those for the element constraint) frequently make implicit use of short supports - by examining a subset of the variables, they can infer support for all other variables and values and save substantial work. However, to date general purpose propagation algorithms (such as GAC-Schema) rely upon supports involving all variables. We demonstrate how to employ short supports in a new general purpose propagation algorithm called SHORTGAC. This works when provided with either an explicit list of allowed short tuples, or a function to calculate the next supporting short tuple. Empirical analyses demonstrate the efficiency of SHORTGAC compared to other general-purpose propagation algorithms. In some cases SHORTGAC even exhibits similar performance to special-purpose propagators.

#index 1826163
#* The multi-inter-distance constraint
#@ Pierre Ouellet;Claude-Guy Quimper
#t 2011
#c 11
#% 160208
#% 410276
#% 1191531
#% 1250526
#% 1412991
#% 1499496
#! We introduce the MULTI-INTER-DISTANCE constraint that ensures no more than m variables are assigned to values lying in a window of p consecutive values. This constraint is useful for modeling scheduling problems where tasks of processing time p compete for m identical resources. We present a propagator that achieves bounds consistency in cubic time. Experiments show that this new constraint offers a much stronger filtering than an edge-finder and that it allows to solve larger instances of the runway scheduling problem.

#index 1826164
#* Finite-length Markov processes with constraints
#@ François Pachet;Pierre Roy;Gabriele Barbieri
#t 2011
#c 11
#% 150703
#% 160208
#% 267574
#% 289332
#% 788050
#% 1098490
#% 1112718
#% 1187872
#% 1275304
#% 1565564
#% 1736693
#! Many systems use Markov models to generate finite-length sequences that imitate a given style. These systems often need to enforce specific control constraints on the sequences to generate. Unfortunately, control constraints are not compatible with Markov models, as they induce long-range dependencies that violate the Markov hypothesis of limited memory. Attempts to solve this issue using heuristic search do not give any guarantee on the nature and probability of the sequences generated. We propose a novel and efficient approach to controlled Markov generation for a specific class of control constraints that 1) guarantees that generated sequences satisfy control constraints and 2) follow the statistical distribution of the initial Markov model. Revisiting Markov generation in the framework of constraint satisfaction, we show how constraints can be compiled into a nonhomogeneous Markov model, using arc-consistency techniques and renormalization. We illustrate the approach on a melody generation problem and sketch some realtime applications in which control constraints are given by gesture controllers.

#index 1826165
#* A generalized arc-consistency algorithm for a class of counting constraints
#@ Thierry Petit;Nicolas Beldiceanu;Xavier Lorca
#t 2011
#c 11
#% 131561
#% 534497
#% 534973
#% 911011
#% 1223531
#% 1737834
#! This paper introduces the SEQ BIN meta-constraint with a polytime algorithm achieving generalized arc-consistency. SEQ BIN can be used for encoding counting constraints such as CHANGE, SMOOTH, or INCREASING NVALUE. For all of them the time and space complexity is linear in the sum of domain sizes, which improves or equals the best known results of the literature.

#index 1826166
#* Nested rollout policy adaptation for Monte Carlo tree search
#@ Christopher D. Rosin
#t 2011
#c 11
#% 392766
#% 866837
#% 983838
#% 1211781
#% 1211808
#% 1305362
#% 1305573
#% 1477102
#% 1536218
#% 1536257
#% 1597142
#% 1602937
#! Monte Carlo tree search (MCTS) methods have had recent success in games, planning, and optimization. MCTS uses results from rollouts to guide search; a rollout is a path that descends the tree with a randomized decision at each ply until reaching a leaf. MCTS results can be strongly influenced by the choice of appropriate policy to bias the rollouts. Most previous work on MCTS uses static uniform random or domain-specific policies. We describe a new MCTS method that dynamically adapts the rollout policy during search, in deterministic optimization problems. Our starting point is Cazenave's original Nested Monte Carlo Search (NMCS), but rather than navigating the tree directly we instead use gradient ascent on the rollout policy at each level of the nested search. We benchmark this new Nested Rollout Policy Adaptation (NRPA) algorithm and examine its behavior. Our test problems are instances of Crossword Puzzle Construction and Morpion Solitaire. Over moderate time scales NRPA can substantially improve search efficiency compared to NMCS, and over longer time scales NRPA improves upon all previous published solutions for the test problems. Results include a new Morpion Solitaire solution that improves upon the previous human-generated record that had stood for over 30 years.

#index 1826167
#* Real-time solving of quantified CSPs based on Monte-Carlo game tree search
#@ Baba Satomi;Yongjoon Joe;Atsushi Iwasaki;Makoto Yokoo
#t 2011
#c 11
#% 425053
#% 443227
#% 535134
#% 795601
#% 1270060
#% 1289372
#% 1399070
#% 1404135
#% 1412989
#% 1453146
#% 1665148
#! We develop a real-time algorithm based on a Monte-Carlo game tree search for solving a quantified constraint satisfaction problem (QCSP), which is a CSP where some variables are universally quantified. A universally quantified variable represents a choice of nature or an adversary. The goal of a QCSP is to make a robust plan against an adversary. However, obtaining a complete plan off-line is intractable when the size of the problem becomes large. Thus, we need to develop a realtime algorithmthat sequentially selects a promising value at each deadline. Such a problem has been considered in the field of game tree search. In a standard game tree search algorithm, developing a good static evaluation function is crucial. However, developing a good static evaluation function for a QCSP is very difficult since it must estimate the possibility that a partially assigned QCSP is solvable. Thus, we apply a Monte-Carlo game tree search technique called UCT. However, the simple application of the UCT algorithm does not work since the player and the adversary are asymmetric, i.e., finding a game sequence where the player wins is very rare. We overcome this difficulty by introducing constraint propagation techniques. We experimentally compare the winning probability of our UCT-based algorithm and the state-of-the-art alpha-beta search algorithm. Our results show that our algorithm outperforms the state-of-the-art algorithm in large-scale problems.

#index 1826168
#* The increasing cost tree search for optimal multi-agent pathfinding
#@ Guni Sharon;Roni Stern;Meir Goldenberg;Ariel Felner
#t 2011
#c 11
#% 1272212
#% 1272214
#! We address the problem of optimal path finding for multiple agents where agents must not collide and their total travel cost should be minimized. Previous work used traditional single-agent search variants of the A* algorithm. We present a novel formalization for this problem which includes a search tree called the increasing cost tree (ICT) and a corresponding search algorithm that finds optimal solutions. We analyze this new formalization and compare it to the previous state-of-the-art A*-based approach. Experimental results on various domains show the benefits and drawbacks of this approach. A speedup of up to 3 orders of magnitude was obtained in a number of cases.

#index 1826169
#* Complete algorithms for cooperative pathfinding problems
#@ Trevor Standley;Richard Korf
#t 2011
#c 11
#% 2194
#% 773254
#% 873563
#% 1084390
#% 1272212
#% 1321584
#! Problems that require multiple agents to follow non-interfering paths from their current states to their respective goal states are called cooperative pathfinding problems. We present the first complete algorithm for finding these paths that is sufficiently fast for real-time applications. Furthermore, our algorithm offers a trade-off between running time and solution quality. We then refine our algorithm into an anytime algorithm that first quickly finds a solution, and then uses any remaining time to incrementally improve that solution until it is optimal or the algorithm is terminated. We compare our algorithms to those in the literature and show that in addition to completeness, our algorithms offer improved solution quality as well as competitive running time.

#index 1826170
#* Bounded suboptimal search: a direct approach using inadmissible estimates
#@ Jordan T. Thayer;Wheeler Ruml
#t 2011
#c 11
#% 743353
#% 1273092
#% 1273212
#% 1274276
#% 1313373
#% 1632825
#! Bounded suboptimal search algorithms offer shorter solving times by sacrificing optimality and instead guaranteeing solution costs within a desired factor of optimal. Typically these algorithms use a single admissible heuristic both for guiding search and bounding solution cost. In this paper, we present a new approach to bounded suboptimal search, Explicit Estimation Search, that separates these roles, consulting potentially inadmissible information to determine search order and using admissible information to guarantee the cost bound. Unlike previous proposals, it successfully combines estimates of solution length and solution cost to predict which node will lead most quickly to a solution within the suboptimality bound. An empirical evaluation across six diverse benchmark domains shows that Explicit Estimation Search is competitive with the previous state of the art in domains with unit-cost actions and substantially outperforms previously proposed techniques for domains in which solution cost and length can differ.

#index 1826171
#* Rational deployment of CSP heuristics
#@ David Tolpin;Shimony Eyal Shimony
#t 2011
#c 11
#% 36814
#% 98073
#% 130208
#% 1269701
#% 1271812
#% 1478757
#% 1650449
#! Heuristics are crucial tools in decreasing search effort in varied fields of AI. In order to be effective, a heuristic must be efficient to compute, as well as provide useful information to the search algorithm. However, some well-known heuristics which do well in reducing backtracking are so heavy that the gain of deploying them in a search algorithm might be outweighed by their overhead. We propose a rational metareasoning approach to decide when to deploy heuristics, using CSP backtracking search as a case study. In particular, a value of information approach is taken to adaptive deployment of solution-count estimation heuristics for value ordering. Empirical results show that indeed the proposed mechanism successfully balances the tradeoff between decreasing backtracking and heuristic computational overhead, resulting in a significant overall search time reduction.

#index 1826172
#* Symmetry breaking via LexLeader feasibility checkers
#@ Justin Yip;Pascal Van Hentenryck
#t 2011
#c 11
#% 535172
#% 873069
#% 1026511
#% 1250136
#% 1412936
#% 1412961
#% 1412992
#% 1493589
#% 1498844
#! This paper considers matrix models, a class of CSPs which generally exhibit significant symmetries. It proposed the idea of LexLeader feasibility checkers that verify, during search, whether the current partial assignment can be extended into a canonical solution. The feasibility checkers are based on a novel result by [Katsirelos et al., 2010] on how to check efficiently whether a solution is canonical. The paper generalizes this result to partial assignments, various variable orderings, and value symmetries. Empirical results on 5 standard benchmarks shows that feasibility checkers may bring significant performance gains, when jointly used with DOUBLELEX or SNAKELEX.

#index 1826173
#* Heuristic algorithms for balanced multi-way number partitioning
#@ Jilian Zhang;Kyriakos Mouratidis;HweeHwa Pang
#t 2011
#c 11
#% 196277
#% 214520
#% 267769
#% 408396
#% 504545
#% 1305375
#! Balanced multi-way number partitioning (BMNP) seeks to split a collection of numbers into subsets with (roughly) the same cardinality and subset sum. The problem is NP-hard, and there are several exact and approximate algorithms for it. However, existing exact algorithms solve only the simpler, balanced two-way number partitioning variant, whereas the most effective approximate algorithm, BLDM, may produce widely varying subset sums. In this paper, we introduce the LRM algorithm that lowers the expected spread in subset sums to one third that of BLDM for uniformly distributed numbers and odd subset cardinalities. We also propose Meld, a novel strategy for skewed number distributions. A combination of LRM and Meld leads to a heuristic technique that consistently achieves a narrower spread of subset sums than BLDM.

#index 1826174
#* Space defragmentation heuristic for 2D and 3D bin packing problems
#@ Zhaoyi Zhang;Songshan Guo;Wenbin Zhu;Wee-Chong Oon;Andrew Lim
#t 2011
#c 11
#% 260514
#% 573088
#% 573444
#% 739629
#% 958639
#% 1191549
#! One of main difficulties of multi-dimensional packing problems is the fragmentation of free space into several unusable small parts after a few items are packed. This study proposes a defragmentation technique to combine the fragmented space into a continuous usable space, which potentially allows the packing of additional items. We illustrate the effectiveness of this technique on the two-and three-dimensional Bin Packing Problems. In conjunction with a bin shuffling strategy for incremental improvement, our resultant algorithm outperforms all leading meta-heuristic approaches.

#index 1826175
#* Proceedings of the Twenty-Second international joint conference on Artificial Intelligence - Volume Volume Two
#@ Toby Walsh
#t 2011
#c 11

#index 1826176
#* What is an ideal logic for reasoning with inconsistency?
#@ Ofer Arieli;Arnon Avron;Anna Zamansky
#t 2011
#c 11
#% 57927
#% 101612
#% 106862
#% 257698
#% 490487
#% 1511891
#% 1557902
#! Many AI applications are based on some underlying logic that tolerates inconsistent information in a non-trivial way. However, it is not always clear what should be the exact nature of such a logic, and how to choose one for a specific application. In this paper, we formulate a list of desirable properties of "ideal" logics for reasoning with inconsistency, identify a variety of logics that have these properties, and provide a systematic way of constructing, for every n 2, a family of such n-valued logics.

#index 1826177
#* Walking the complexity lines for generalized guarded existential rules
#@ Jean-François Baget;Marie-Laure Mugnier;Sebastian Rudolph;Michaël Thomazo
#t 2011
#c 11
#% 71306
#% 342829
#% 490909
#% 598678
#% 826032
#% 1130756
#% 1217122
#% 1269741
#% 1305397
#% 1511857
#% 1511884
#! We establish complexities of the conjunctive query entailment problem for classes of existential rules (i.e. Tuple-Generating Dependencies or Datalog+/- rules). Our contribution is twofold. First, we introduce the class of greedy bounded treewidth sets (gbts), which covers guarded rules, and their known generalizations, namely (weakly) frontier-guarded rules. We provide a generic algorithm for query entailment with gbts, which is worst-case optimal for combined complexity with bounded predicate arity, as well as for data complexity. Second, we classify several gbts classes, whose complexity was unknown, namely frontier-one, frontier-guarded and weakly frontier-guarded rules, with respect to combined complexity (with bounded and unbounded predicate arity) and data complexity.

#index 1826178
#* Query reasoning on trees with types, interleaving, and counting
#@ Everardo Bárcenas;Pierre Genevès;Nabil Layaïda;Alan Schmitt
#t 2011
#c 11
#% 494344
#% 717498
#% 734789
#% 799999
#% 821610
#% 963218
#% 1266687
#% 1292479
#% 1428486
#! A major challenge of query language design is the combination of expressivity with effective static analyses such as query containment. In the setting of XML, documents are seen as finite trees, whose structure may additionally be constrained by type constraints such as those described by an XML schema. We consider the problem of query containment in the presence of type constraints for a class of regular path queries extended with counting and interleaving operators. The counting operator restricts the number of occurrences of children nodes satisfying a given logical property. The interleaving operator provides a succinct notation for describing the absence of order between nodes satisfying a logical property. We provide a logic-based framework supporting these operators, which can be used to solve common query reasoning problems such as satisfiability and containment of queries in exponential time.

#index 1826179
#* First-order extension of the FLP stable model semantics via modified circumscription
#@ Michael Bartholomew;Joohyung Lee;Yunsong Meng
#t 2011
#c 11
#% 340738
#% 501041
#% 752732
#% 1257219
#% 1263092
#% 1263126
#% 1274811
#% 1289365
#% 1305420
#% 1472761
#% 1503511
#% 1503513
#% 1577210
#% 1656398
#! We provide reformulations and generalizations of both the semantics of logic programs by Faber, Leone and Pfeifer and its extension to arbitrary propositional formulas by Truszczynski. Unlike the previous definitions, our generalizations refer neither to grounding nor to fixpoints, and apply to first-order formulas containing aggregate expressions. In the same spirit as the first-order stable model semantics proposed by Ferraris, Lee and Lifschitz, the semantics proposed here are based on syntactic transformations that are similar to circumscription. The reformulations provide useful insights into the FLP semantics and its relationship to circumscription and the first-order stable model semantics.

#index 1826180
#* A theory of meta-diagnosis: reasoning about diagnostic systems
#@ Nuno Belard;Yannick Pencolé;Michel Combacau
#t 2011
#c 11
#% 1120
#% 21137
#% 21138
#% 132173
#% 154456
#% 400981
#% 669370
#% 1273476
#! In Model-Based Diagnosis, a diagnostic algorithm is typically used to compute diagnoses using a model of a real-world system and some observations. Contrary to classical hypothesis, in real-world applications it is sometimes the case that either the model, the observations or the diagnostic algorithm are abnormal with respect to some required properties; with possibly huge economical consequences. Determining which abnormalities exist constitutes a meta-diagnostic problem. We contribute, first, with a general theory of meta-diagnosis with clear semantics to handle this problem. Second, we propose a series of typically required properties and relate them between themselves. Finally, using our meta-diagnostic framework and the studied properties and relations, we model and solve some common meta-diagnostic problems.

#index 1826181
#* A computationally-grounded semantics for artifact-centric systems and abstraction results
#@ Francesco Belardinelli;Alessio Lomuscio;Fabio Patrizi
#t 2011
#c 11
#% 145228
#% 167468
#% 188086
#% 348920
#% 659831
#% 824702
#% 1180017
#% 1193571
#% 1215628
#% 1561977
#! We present a formal investigation of artifact-based systems, a relatively novel framework in service oriented computing, aimed at laying the foundations for verifying these systems through model checking. We present an infinite-state, computationally grounded semantics for these systems that allows us to reason about temporal-epistemic specifications. We present abstraction techniques for the semantics that guarantee transfer of satisfaction from the abstract system to the concrete one.

#index 1826182
#* On progression and query evaluation in first-order knowledge bases with function symbols
#@ Vaishak Belle;Gerhard Lakemeyer
#t 2011
#c 11
#% 131357
#% 229083
#% 288165
#% 326595
#% 342119
#% 984354
#% 1232188
#% 1289167
#% 1305426
#! In a seminal paper, Lin and Reiter introduced the notion of progression of basic action theories. Unfortunately, progression is second-order in general. Recently, Liu and Lakemeyer improve on earlier results and show that for the local-effect and normal actions case, progression is computable but may lead to an exponential blow-up. Nevertheless, they show that for certain kinds of expressive first-order knowledge bases with disjunctive information, called proper, it is efficient. However, answering queries about the resulting state is still undecidable. In this paper, we continue this line of research and extend proper KBs to include functions. We prove that their progression wrt local-effect, normal actions, and range-restricted theories, is first-order definable and efficiently computable. We then provide a new logically sound and complete decision procedure for certain kinds of queries.

#index 1826183
#* Interval-based possibilistic logic
#@ Salem Benferhat;Julien Hué;Sylvain Lagrue;Julien Rossit
#t 2011
#c 11
#% 144547
#% 167544
#% 1223256
#! Possibilistic logic is a well-known framework for dealing with uncertainty and reasoning under inconsistent knowledge bases. Standard possibilistic logic expressions are propositional logic formulas associated with positive real degrees belonging to [0,1]. However, in practice it may be difficult for an expert to provide exact degrees associated with formulas of a knowledge base. This paper proposes a flexible representation of uncertain information where the weights associated with formulas are in the form of intervals. We first study a framework for reasoning with interval-based possibilistic knowledge bases by extending main concepts of possibilistic logic such as the ones of necessity and possibility measures. We then provide a characterization of an interval-based possibilistic logic base by means of a concept of compatible standard possibilistic logic bases. We show that interval-based possibilistic logic extends possibilistic logic in the case where all intervals are singletons. Lastly, we provide computational complexity results of deriving plausible conclusions from interval-based possibilistic bases and we show that the flexibility in representing uncertain information is handled without extra computational costs.

#index 1826184
#* RCC8 is polynomial on networks of bounded treewidth
#@ Manuel Bodirsky;Stefan Wölfl
#t 2011
#c 11
#% 236025
#% 318486
#% 419932
#% 483796
#% 526851
#% 560268
#% 731291
#% 939431
#% 1223539
#% 1304482
#% 1305380
#% 1405060
#% 1414318
#% 1669590
#% 1916545
#! We construct an homogeneous (and ω-categorical) representation of the relation algebra RCC8, which is one of the fundamental formalisms for spatial reasoning. As a consequence we obtain that the network consistency problem for RCC8 can be solved in polynomial time for networks of bounded treewidth.

#index 1826185
#* On the complexity of EL with defeasible inclusions
#@ Piero A. Bonatti;Marco Faella;Luigi Sauro
#t 2011
#c 11
#% 107262
#% 344506
#% 613819
#% 665856
#% 778645
#% 960435
#% 1263113
#% 1269453
#% 1273631
#% 1273694
#% 1274593
#% 1288661
#% 1289408
#% 1305400
#% 1495917
#% 1540296
#! We analyze the complexity of reasoning in EL with defeasible inclusions and extensions thereof. The results by Bonatti et al., 2009a are extended by proving tight lower complexity bounds and by relaxing the syntactic restrictions adopted there. We further extend the old framework by supporting arbitrary priority relations.

#index 1826186
#* Description logics over lattices with multi-valued ontologies
#@ Stefan Borgwardt;Rafael Peñaloza
#t 2011
#c 11
#% 665856
#% 1090749
#% 1136065
#% 1228623
#% 1271958
#% 1272188
#% 1274841
#% 1279735
#% 1288039
#% 1376134
#% 1547250
#! Uncertainty is unavoidable when modeling most application domains. In medicine, for example, symptoms (such as pain, dizziness, or nausea) are always subjective, and hence imprecise and incomparable. Additionally, concepts and their relationships may be inexpressible in a crisp, clear-cut manner. We extend the description logic ALC with multi-valued semantics based on lattices that can handle uncertainty on concepts as well as on the axioms of the ontology. We introduce reasoning methods for this logic w.r.t. general concept inclusions and show that the complexity of reasoning is not increased by this new semantics.

#index 1826187
#* Finite-valued Lukasiewicz modal logic Is PSPACE-complete
#@ Félix Bou;Marco Cerami;Francesc Esteva
#t 2011
#c 11
#% 338753
#% 665856
#% 1279734
#% 1346815
#% 1410990
#% 1640907
#! It is well-known that satisfiability (and hence validity) in the minimal classical modal logic is a PSPACE-complete problem. In this paper we consider the satisfiability and validity problems (here they are not dual, although mutually reducible) for the minimal modal logic over a finite Lukasiewicz chain, and show that they also are PSPACE-complete. This result is also true when adding either the Delta operator or truth constants in the language, i.e. in all these cases it is PSPACE-complete.

#index 1826188
#* Relating the semantics of abstract dialectical frameworks and standard AFs
#@ Gerd Brewka;Paul E. Dunne;Stefan Woltran
#t 2011
#c 11
#% 44878
#% 198464
#% 772065
#% 992259
#% 1086512
#% 1473073
#% 1705582
#! One criticism often advanced against abstract argumentation frameworks (AFs), is that these consider only one form of interaction between atomic arguments: specifically that an argument attacks another. Attempts to broaden the class of relationships include bipolar frameworks, where arguments support others, and abstract dialectical frameworks (ADFs). The latter, allow "acceptance" of an argument, x, to be predicated on a given propositional function, Cx, dependent on the corresponding acceptance of its parents, i.e. those y for which 〈y, x〉 occurs. Although offering a richly expressive formalism subsuming both standard and bipolar AFs, an issue that arises with ADFs is whether this expressiveness is achieved in a manner that would be infeasible within standard AFs. Can the semantics used in ADFs be mapped to some AF semantics? How many arguments are needed in an AF to "simulate" an ADF? We show that (in a formally defined sense) any ADF can be simulated by an AF of similar size and that this translation can be realised by a polynomial time algorithm.

#index 1826189
#* Managed multi-context systems
#@ Gerhard Brewka;Thomas Eiter;Michael Fink;Antonius Weinzierl
#t 2011
#c 11
#% 160385
#% 198464
#% 400989
#% 778288
#% 1153205
#% 1215046
#% 1263082
#% 1269730
#% 1388121
#! Multi-context systems (MCS) are a powerful framework for interlinking heterogeneous knowledge sources. They model the flow of information among different reasoning components (called contexts) in a declarative way, using so-called bridge rules, where contexts and bridge rules may be nonmonotonic. We considerably generalize MCS to managed MCS (mMCS): while the original bridge rules can only add information to contexts, our generalization allows arbitrary operations on context knowledge bases to be freely defined, e.g., deletion or revision operators. The paper motivates and introduces the generalized framework and presents several interesting instances. Furthermore, we consider inconsistency management in mMCS and complexity issues.

#index 1826190
#* Modeling attempt and action failure in probabilistic stit logic
#@ Jan Broersen
#t 2011
#c 11
#% 101955
#% 338753
#% 413871
#% 908967
#% 1021249
#% 1083949
#% 1727197
#! We define an extension of stit logic that encompasses subjective probabilities representing beliefs about simultaneous choice exertion of other agents. The formalism enables us to express the notion of 'attempt' as a choice exertion that maximizes the chance of success with respect to an action effect. The notion of attempt (or effort) is central in philosophical and legal discussions on responsibility and liability.

#index 1826191
#* A practical automata-based technique for reasoning in expressive description logics
#@ Diego Calvanese;Domenico Carbotta;Magdalena Ortiz
#t 2011
#c 11
#% 179613
#% 327779
#% 330229
#% 494344
#% 561573
#% 935898
#% 1050476
#% 1269731
#% 1369577
#% 1703714
#! In this work we describe the theoretical foundations and the implementation of a new automata-based technique for reasoning over expressive Description Logics that is worst-case optimal and lends itself to an efficient implementation. In order to show the feasibility of the approach, we have realized a working prototype of a reasoner based upon these techniques. An experimental evaluation of this prototype shows encouraging results.

#index 1826192
#* Containment of regular path queries under description logic constraints
#@ Diego Calvanese;Magdalena Ortiz;Mantas Šimkus
#t 2011
#c 11
#% 53400
#% 140410
#% 248026
#% 384978
#% 494344
#% 599549
#% 731485
#% 935898
#% 1108111
#% 1224353
#% 1270103
#% 1272202
#% 1290269
#% 1305403
#% 1305410
#% 1426443
#! Query containment has been studied extensively in KR and databases, for different kinds of query languages and domain constraints. We address the longstanding open problem of containment under expressive description logic (DL) constraints for two-way regular path queries (2RPQs) and their conjunctions, which generalize conjunctive queries with the ability to express regular navigation. We show that, surprisingly, functionality constraints alone make containment of 2RPQs already EXPTIME-hard. By employing automata-theoretic techniques, we also provide a matching upper bound that extends to very expressive DL constraints. For conjunctive 2RPQs we prove a further exponential jump in complexity, and provide again a matching upper bound for expressive DLs. Our techniques provide also a solution to the problem of query entailment over DL knowledge bases in which individuals in the ABox may be related through regular role-paths.

#index 1826193
#* Defeasible inheritance-based description logics
#@ Giovanni Casini;Umberto Straccia
#t 2011
#c 11
#% 115327
#% 167537
#% 167538
#% 344506
#% 935898
#% 1263113
#% 1273630
#% 1273631
#% 1274593
#% 1288661
#% 1332526
#% 1477165
#% 1483051
#% 1495917
#! Defeasible inheritance networks are a nonmonotonic framework that deals with hierarchical knowledge. On the other hand, rational closure is acknowledged as a landmark of the preferential approach. We will combine these two approaches and define a new non-monotonic closure operation for propositional knowledge bases that combines the advantages of both. Then we redefine such a procedure for Description Logics, a family of logics well-suited to model structured information. In both cases we will provide a simple reasoning method that is build on top of the classical entailment relation.

#index 1826194
#* SDD: a new canonical representation of propositional knowledge bases
#@ Adnan Darwiche
#t 2011
#c 11
#% 3873
#% 263371
#% 342378
#% 386158
#% 427657
#% 442363
#% 543491
#% 1036395
#% 1270101
#% 1272349
#% 1473201
#% 1674531
#! We identify a new representation of propositional knowledge bases, the Sentential Decision Diagram (SDD), which is interesting for a number of reasons. First, it is canonical in the presence of additional properties that resemble reduction rules of OBDDs. Second, SDDs can be combined using any Boolean operator in polytime. Third, CNFs with n variables and treewidth w have canonical SDDs of size O(n2w), which is tighter than the bound on OBDDs based on pathwidth. Finally, every OBDD is an SDD. Hence, working with the latter does not preclude the former.

#index 1826195
#* Efficient reasoning in proper knowledge bases with unknown individuals
#@ Giuseppe De Giacomo;Yves Lespérance;Hector J. Levesque
#t 2011
#c 11
#% 663
#% 2984
#% 6711
#% 191611
#% 264858
#% 378409
#% 464717
#% 599549
#% 647506
#% 809239
#% 866986
#% 917146
#% 1272205
#% 1279223
#% 1291118
#% 1416180
#% 1481057
#% 1523891
#! This work develops an approach to efficient reasoning in first-order knowledge bases with incomplete information. We build on Levesque's proper knowledge bases approach, which supports limited incomplete knowledge in the form of a possibly infinite set of positive or negative ground facts. We propose a generalization which allows these facts to involve unknown individuals, as in the work on labeled null values in databases. Dealing with such unknown individuals has been shown to be a key feature in the database literature on data integration and data exchange. In this way, we obtain one of the most expressive first-order open-world settings for which reasoning can still be done efficiently by evaluation, as in relational databases. We show the soundness of the reasoning procedure and its completeness for queries in a certain normal form.

#index 1826196
#* Revising by an inconsistent set of formulas
#@ James Delgrande
#t 2011
#c 11
#% 109945
#% 224753
#% 421961
#% 581824
#% 834117
#% 942467
#% 1270087
#% 1273688
#% 1289428
#! This paper presents an approach to belief revision in which revision is a function from a belief state and a finite set of formulas to a new belief state. In the interesting case, the set for revision S may be inconsistent but individual members of S are consistent. We argue that S will still contain interesting information regarding revision; in particular, maximum consistent subsets of S will determine candidate formulas for the revision process, and the agent's associated faithful ranking will determine the plausibility of such candidate formulas. Postulates and semantic conditions characterizing this approach are given, and representation results are provided. As a consequence of this approach, we argue that revision by a sequence of formulas, usually considered as a problem of iterated revision, is more appropriately regarded as revision by the possibly-inconsistent set of these formulas. Hence we suggest that revision by a sequence of formulas is foremost a problem of (uniterated) set revision.

#index 1826197
#* Revising horn theories
#@ James P. Delgrande;Pavlos Peppas
#t 2011
#c 11
#% 109945
#% 131559
#% 307262
#% 1152348
#% 1221612
#% 1270093
#% 1305401
#% 1495937
#! This paper investigates belief revision where the underlying logic is that governing Horn clauses. It proves to be the case that classical (AGM) belief revision doesn't immediately generalise to the Horn case. In particular, a standard construction based on a total preorder over possible worlds may violate the accepted (AGM) postulates. Conversely, Horn revision functions in the obvious extension to the AGM approach are not captured by total preorders over possible worlds. We address these difficulties by first restricting the semantic construction to "well behaved" orderings; and second, by augmenting the revision postulates by an additional postulate. This additional postulate is redundant in the AGM approach but not in the Horn case. In a representation result we show that these two approaches coincide. Arguably this work is interesting for several reasons. It extends AGM revision to inferentially-weaker Horn theories; hence it sheds light on the theoretical underpinnings of belief change, as well as generalising the AGM paradigm. Thus, this work is relevant to revision in areas that employ Horn clauses, such as deductive databases and logic programming, as well as areas in which inference is weaker than classical logic, such as in description logic.

#index 1826198
#* Expressiveness of the interval logics of Allen's relations on the class of all linear orders: complete classification
#@ Dario Della Monica;Valentin Goranko;Angelo Montanari;Guido Sciavicco
#t 2011
#c 11
#% 102358
#% 319244
#% 338753
#% 742780
#% 948060
#% 1111183
#% 1375440
#% 1392300
#% 1489403
#! We compare the expressiveness of the fragments of Halpern and Shoham's interval logic (HS), i.e., of all interval logics with modal operators associated with Allen's relations between intervals in linear orders. We establish a complete set of inter-definability equations between these modal operators, and thus obtain a complete classification of the family of 212 fragments of HS with respect to their expressiveness. Using that result and a computer program, we have found that there are 1347 expressively different such interval logics over the class of all linear orders.

#index 1826199
#* Parametric properties of ideal semantics
#@ Wolfgang Dvořák;Paul E. Dunne;Stefan Woltran
#t 2011
#c 11
#% 147604
#% 198464
#% 217007
#% 420659
#% 428343
#% 844093
#% 992250
#% 992251
#% 992253
#% 1193569
#% 1221649
#% 1292077
#% 1422064
#% 1496577
#% 1531971
#% 1650979
#! The concept of "ideal semantics" has been promoted as an alternative basis for skeptical reasoning within abstract argumentation settings. Informally, ideal acceptance not only requires an argument to be skeptically accepted in the traditional sense but further insists that the argument is in an admissible set all of whose arguments are also skeptically accepted. The original proposal was couched in terms of the so-called preferred semantics for abstract argumentation. We argue, in this paper, that the notion of "ideal acceptability" is applicable to arbitrary semantics and justify this claim by showing that standard properties of classical ideal semantics, e.g. unique status, continue to hold in any "reasonable" extension-based semantics. We categorise the relationship between the divers concepts of "ideal extension wrt semantics σ" that arise and we present a comprehensive analysis of algorithmic and complexity-theoretic issues.

#index 1826200
#* Tangled modal logic for spatial reasoning
#@ David Fernández Duque
#t 2011
#c 11
#% 298024
#% 491563
#% 821609
#% 1619181
#! We consider an extension of the propositional modal logic S4 which allows ⋄ to act not only on isolated formulas, but also on sets of formulas. The interpretation of ⋄Γ is then given by the tangled closure of the valuations of formulas in Γ, which over finite transitive, reflexive models indicates the existence of a cluster satisfying Γ. This extension has been shown to be more expressive than the basic modal language: for example, it is equivalent to the bisimulation-invariant fragment of FOL over finite S4 models, whereas the basic modal language is weaker. However, previous analyses of this logic have been entirely semantic, and no proof system was available. In this paper we present a sound proof system for the polyadic S4 and prove that it is complete. The axiomatization is fairly standard, adding only the fixpoint axioms of the tangled closure to the usual S4 axioms. The proof proceeds by explicitly constructing a finite model from a consistent set of formulas.

#index 1826201
#* Backdoors to tractable answer-set programming
#@ Johannes Klaus Fichte;Stefan Szeider
#t 2011
#c 11
#% 103704
#% 400988
#% 417651
#% 495981
#% 541796
#% 729052
#% 1023276
#% 1086245
#% 1091265
#% 1105378
#% 1171090
#% 1250131
#% 1270076
#% 1272295
#% 1279334
#% 1279379
#% 1305419
#% 1611311
#% 1703584
#% 1826228
#% 1972413
#% 1985061
#! We present a unifying approach to the efficient evaluation of propositional answer-set programs. Our approach is based on backdoors which are small sets of atoms that represent "clever reasoning shortcuts" through the search space. The concept of backdoors is widely used in the areas of propositional satisfiability and constraint satisfaction. We show how this concept can be adapted to the nonmonotonic setting and how it allows to augment various known tractable subproblems, such as the evaluation of Horn and acyclic programs. In order to use backdoors we need to find them first. We utilize recent advances in fixed-parameter algorithmics to detect small backdoors. This implies fixed-parameter tractability of the evaluation of propositional answer-set programs, parameterized by the size of backdoors. Hence backdoor size provides a structural parameter similar to the treewidth parameter previously considered. We show that backdoor size and treewidth are incomparable, hence there are instances that are hard for one and easy for the other parameter. We complement our theoretical results with first empirical results.

#index 1826202
#* Refutation in dummett logic using a sign to express the truth at the next possible world
#@ Guido Fiorino
#t 2011
#c 11
#% 93805
#% 420742
#% 517276
#% 948064
#% 948065
#% 1131468
#% 1452756
#! In this paper we use the Kripke semantics characterization of Dummett logic to introduce a new way of handling non-forced formulas in tableau proof systems. We pursue the aim of reducing the search space by strictly increasing the number of forced propositional variables after the application of noninvertible rules. The focus of the paper is on a new tableau system for Dummett logic, for which we have an implementation.

#index 1826203
#* Fixpoints in temporal description logics
#@ Enrico Franconi;David Toman
#t 2011
#c 11
#% 64284
#% 473034
#% 491563
#% 496125
#% 1116024
#% 1273742
#! We study a decidable fixpoint extension of temporal description logics. To this end we employ and extend decidability results obtained for various temporally first-order monodic extensions of (firstorder) description logics. Using these techniques we obtain decidability and tight complexity results for various fixpoint extensions of temporal description logics.

#index 1826204
#* Succinctness of epistemic languages
#@ Tim French;Wiebe Van Der Hoek;Petar Iliev;Barteld Kooi
#t 2011
#c 11
#% 188086
#% 380578
#% 575378
#% 890213
#! Proving that one language is more succinct than another becomes harder when the underlying semantics is stronger. We propose to use Formula-Size Games (as put forward by Adler and Immerman, 2003), games that are played on two sets of models, and that directly link the length of play with the size of the formula. Using FSGs, we prove three succinctness results for m-dimensional modal logic: (1) In system Km, a notion of 'everybody knows' makes the resulting language exponentially more succinct for m 1 (2) In S5m, the same language becomes more succinct for m 3 and (3) Public Announcement Logic is exponentially more succinct than S5m, if m 3. The latter settles an open problem raised by Lutz, 2006.

#index 1826205
#* Repairing incorrect knowledge with model formulation and metareasoning
#@ Scott E. Friedman;Kenneth D. Forbus
#t 2011
#c 11
#% 1116
#% 23011
#% 109848
#% 109945
#% 231749
#% 365331
#% 668799
#% 1245895
#! Learning concepts via instruction and expository texts is an important problem for modeling human learning and for making autonomous AI systems. This paper describes a computational model of the self-explanation effect, whereby conceptual knowledge is repaired by integrating and explaining new material. Our model represents conceptual knowledge with compositional model fragments, which are used to explain new material via model formulation. Preferences are computed over explanations and conceptual knowledge, along several dimensions. These preferences guide knowledge integration and question-answering. Our simulation learns about the human circulatory system, using facts from a circulatory system passage used in a previous cognitive psychology experiment. We analyze the simulation's performance, showing that individual differences in sequences of models learned by students can be explained by different parameter settings in our model.

#index 1826206
#* Reasoning about typicality in low complexity DLs: the logics EL⊥Tmin and DL-LitecTmin
#@ Laura Giordano;Valentina Gliozzi;Nicola Olivetti;Gian Luca Pozzato
#t 2011
#c 11
#% 77841
#% 344506
#% 992962
#% 1111193
#% 1263113
#% 1273631
#% 1289408
#% 1305400
#% 1369844
#% 1495917
#% 1540296
#% 1613552
#! We propose a nonmonotonic extension of low complexity Description Logics EL⊥ and DL-Litecore for reasoning about typicality and defeasible properties. The resulting logics are called EL⊥Tmin and DL-LitecTmin. Concerning DL-LitecTmin, we prove that entailment is in Π2p. With regard to EL⊥Tmin, we first show that entailment remains EXPTIME-hard. Next we consider the known fragment of Left Local EL⊥Tmin and we prove that the complexity of entailment drops to Π2p.

#index 1826207
#* Belief management for high-level robot programs
#@ Stephan Gspandl;Ingo Pill;Michael Reip;Gerald Steinbauer;Alexander Ferrein
#t 2011
#c 11
#% 21138
#% 342119
#% 448092
#% 1269717
#% 1415583
#! The robot programming and plan language IndiGolog allows for on-line execution of actions and offline projections of programs in dynamic and partly unknown environments. Basic assumptions are that the outcomes of primitive and sensing actions are correctly modeled, and that the agent is informed about all exogenous events beyond its control. In real-world applications, however, such assumptions do not hold. In fact, an action's outcome is error-prone and sensing results are noisy. In this paper, we present a belief management system in IndiGolog that is able to detect inconsistencies between a robot's modeled belief and what happened in reality. The system furthermore derives explanations and maintains a consistent belief. Our main contributions are (1) a belief management system following a history-based diagnosis approach that allows an agent to actively cope with faulty actions and the occurrence of exogenous events; and (2) an implementation in IndiGolog and experimental results from a delivery domain.

#index 1826208
#* Multidimensional mereotopology with betweenness
#@ Torsten Hahmann;Michael Grüninger
#t 2011
#c 11
#% 526995
#% 539613
#% 549078
#% 836183
#% 866143
#% 939431
#! Qualitative reasoning about commonsense space often involves entities of different dimensions. We present a weak axiomatization of multidimensional qualitative space based on 'relative dimension' and dimension-independent 'containment' which suffice to define basic dimension-dependent mereotopological relations. We show the relationships to other meoreotopologies and to incidence geometry. The extension with betweenness, a primitive of relative position, results in a first-order theory that qualitatively abstracts ordered incidence geometry.

#index 1826209
#* Generalising the interaction rules in probabilistic logic
#@ Arjen Hommersom;Peter J. F. Lucas
#t 2011
#c 11
#% 44876
#% 147677
#% 224478
#% 233132
#% 457137
#% 655266
#% 850430
#% 1184229
#% 1272302
#% 1568280
#% 1607843
#! The last two decades has seen the emergence of many different probabilistic logics that use logical languages to specify, and sometimes reason, with probability distributions. Probabilistic logics that support reasoning with probability distributions, such as ProbLog, use an implicit definition of an interaction rule to combine probabilistic evidence about atoms. In this paper, we show that this interaction rule is an example of a more general class of interactions that can be described by nonmonotonic logics. We furthermore show that such local interactions about the probability of an atom can be described by convolution. The resulting extended probabilistic logic supports nonmonotonic reasoning with probabilistic information.

#index 1826210
#* Generalized planning: synthesizing plans that work for multiple environments
#@ Yuxiao Hu;Giuseppe De Giacomo
#t 2011
#c 11
#% 65904
#% 167629
#% 408396
#% 417597
#% 544923
#% 544938
#% 743353
#% 1270245
#% 1288659
#% 1289432
#% 1473332
#% 1526852
#! We give a formal definition of generalized planning that is independent of any representation formalism. We assume that our generalized plans must work on a set of deterministic environments, which are essentially unrelated to each other. We prove that generalized planning for a finite set of environments is always decidable and EXPSPACE-complete. Our proof is constructive and gives us a sound, complete and complexity-wise optimal technique. We also consider infinite sets of environments, and show that generalized planning for the infinite "one-dimensional problems," known in the literature to be recursively enumerable when restricted to finite-state plans, is EXPSPACE-decidable without sequence functions, and solvable by generalized planning for finite sets.

#index 1826211
#* Logic programming for Boolean networks
#@ Katsumi Inoue
#t 2011
#c 11
#% 53385
#% 121630
#% 157418
#% 173127
#% 400992
#% 499644
#% 558857
#% 642873
#% 772065
#% 1041019
#% 1126345
#% 1126354
#% 1171768
#% 1197943
#% 1315629
#% 1428655
#% 1601001
#% 1746508
#! The Boolean network is a mathematical model of biological systems, and has attracted much attention as a qualitative tool for analyzing the regulatory system. The stable states and dynamics of Boolean networks are characterized by their attractors, whose properties have been analyzed computationally, yet not much work has been done from the viewpoint of logical inference systems. In this paper, we show direct translations of Boolean networks into logic programs, and propose new methods to compute their trajectories and attractors based on inference on such logic programs. In particular, point attractors of both synchronous and asynchronous Boolean networks are characterized as supported models of logic programs so that SAT techniques can be applied to compute them. Investigation of these relationships suggests us to view Boolean networks as logic programs and vice versa.

#index 1826212
#* Discrete-time temporal reasoning with horn DLRs
#@ Peter Jonsson;Tomas Lööw
#t 2011
#c 11
#% 13742
#% 107137
#% 216976
#% 251197
#% 257699
#% 288469
#% 317107
#% 417598
#% 512017
#% 736615
#% 798723
#% 1035471
#% 1184092
#% 1310060
#! Temporal reasoning problems arise in many areas of AI, including planning, natural language understanding, and reasoning about physical systems. The computational complexity of continuous-time temporal constraint reasoning is fairly well understood. There are, however, many different cases where discrete time must be considered; various scheduling problems and reasoning about sampled physical systems are two examples. Here, the complexity of temporal reasoning is not as well-studied nor as well-understood. In order to get a better understanding, we consider the powerful Horn DLR formalism adapted for discrete time and study its computational complexity. We show that the full formalism is NP-hard and identify several maximal tractable subclasses. We also 'lift' the maximality results to obtain hardness results for other families of constraints. Finally, we discuss how the results and techniques presented in this paper can be used for studying even more expressive classes of temporal constraints.

#index 1826213
#* A constructive approach to independent and evidence retaining belief revision by general information sets
#@ Gabriele Kern-Isberner;Patrick Krümpelmann
#t 2011
#c 11
#% 109945
#% 211580
#% 224753
#% 723774
#% 942467
#% 1270087
#% 1400952
#! Recent years have seen a lot of work towards extending the established AGM belief revision theory with respect to iterating revision, preserving conditional beliefs, and handling sets of propositions as new information. In particular, novel postulates like independence and evidence retainment have been brought forth as new standards for revising epistemic states by (sets of) propositional information. In this paper, we propose a constructive approach for revising epistemic states by sets of (propositional and conditional) beliefs that combines ideas from nonmonotonic reasoning with conditional belief revision. We also propose a novel principle called enforcement that covers both independence and evidence retainment, and we show our revision operator to comply with major postulates from the literature. Moreover, we point out the relevance of our approach for default reasoning.

#index 1826214
#* A logic for causal inference in time series with discrete and continuous variables
#@ Samantha Kleinberg
#t 2011
#c 11
#% 297171
#% 716892
#% 1134494
#% 1417087
#% 1477302
#% 1486627
#% 1566460
#% 1650317
#% 1650530
#! Many applications of causal inference, such as finding the relationship between stock prices and news reports, involve both discrete and continuous variables observed over time. Inference with these complex sets of temporal data, though, has remained difficult and required a number of simplifications. We show that recent approaches for inferring temporal relationships (represented as logical formulas) can be adapted for inference with continuous valued effects. Building on advances in logic, PCTLc (an extension of PCTL with numerical constraints) is introduced here to allow representation and inference of relationships with a mixture of discrete and continuous components. Then, finding significant relationships in the continuous case can be done using the conditional expectation of an effect, rather than its conditional probability. We evaluate this approach on both synthetically generated and actual financial market data, demonstrating that it can allow us to answer different questions than the discrete approach can.

#index 1826215
#* Belief base rationalization for propositional merging
#@ Sébastien Konieczny;Pierre Marquis;Nicolas Schwind
#t 2011
#c 11
#% 109945
#% 207782
#% 443185
#% 772063
#% 1228596
#! Existing belief merging operators take advantage of all the models from the bases, including those contradicting the integrity constraints. In this paper, we show that this is not suited to every merging scenario. We study the case when the bases are "rationalized" with respect to the integrity constraints during the merging process. We define in formal terms several independence conditions for merging operators and show how they interact with the standard IC postulates for belief merging. Especially, we give an independence-based axiomatic characterization of a distance-based operator.

#index 1826216
#* On the decidability of connectedness constraints in 2D and 3D Euclidean spaces
#@ Roman Kontchakov;Yavor Nenov;Ian Pratt-Hartmann;Michael Zakharyaschev
#t 2011
#c 11
#% 734681
#% 1272384
#% 1826216
#! We investigate (quantifier-free) spatial constraint languages with equality, contact and connectedness predicates, as well as Boolean operations on regions, interpreted over low-dimensional Euclidean spaces. We show that the complexity of reasoning varies dramatically depending on the dimension of the space and on the type of regions considered. For example, the logic with the interior-connectedness predicate (and without contact) is undecidable over polygons or regular closed sets in R2, EXPTIME-complete over polyhedra in R3, and NP-complete over regular closed sets in R3.

#index 1826217
#* Extending decidable existential rules by joining acyclicity and guardedness
#@ Markus Krötzsch;Sebastian Rudolph
#t 2011
#c 11
#% 71306
#% 287339
#% 289287
#% 416034
#% 465053
#% 490909
#% 598678
#% 826032
#% 992962
#% 1020896
#% 1217115
#% 1217122
#% 1305397
#% 1500877
#% 1523844
#% 1826177
#! Existential rules, i.e. Datalog extended with existential quantifiers in rule heads, are currently studied under a variety of names such as Datalog+/-, ∀∃-rules, and tuple-generating dependencies. The renewed interest in this formalism is fuelled by a wealth of recently discovered language fragments for which query answering is decidable. This paper extends and consolidates two of the main approaches in this field - acyclicity and guardedness - by providing (1) complexity-preserving generalisations of weakly acyclic and weakly (frontier-) guarded rules, and (2) a novel formalism of glut-(frontier-) guarded rules that subsumes both. This builds on an insight that acyclicity can be used to extend any existential rule language while retaining decidability. Besides decidability, combined query complexities are established in all cases.

#index 1826218
#* Context-sensitive diagnosis of discrete-event systems
#@ Gianfranco Lamperti;Marina Zanella
#t 2011
#c 11
#% 275962
#% 289415
#% 420238
#% 903261
#% 926913
#% 1291403
#% 1784884
#! Since the seminal work of Sampath et al. in 1996, despite the subsequent flourishing of techniques on diagnosis of discrete-event systems (DESs), the basic notions of fault and diagnosis have been remaining conceptually unchanged. Faults are defined at component level and diagnoses incorporate the occurrences of component faults within system evolutions: diagnosis is context-free. As this approach may be unsatisfactory for a complex DES, whose topology is organized in a hierarchy of abstractions, we propose to define different diagnosis rules for different subsystems in the hierarchy. Relevant fault patterns are specified as regular expressions on patterns of lower-level subsystems. Separation of concerns is achieved and the expressive power of diagnosis is enhanced: each subsystem has its proper set of diagnosis rules, which may or may not depend on the rules of other subsystems. Diagnosis is no longer anchored to components: it becomes context-sensitive. The approach yields seemingly contradictory but nonetheless possible scenarios: a subsystem can be normal despite the faulty behavior of a number of its components (positive paradox); also, it can be faulty despite the normal behavior of all its components (negative paradox).

#index 1826219
#* On the progression of knowledge in the situation calculus
#@ Yongmei Liu;Ximing Wen
#t 2011
#c 11
#% 229083
#% 342119
#% 572366
#% 1261232
#% 1270247
#% 1305426
#% 1702994
#! In a seminal paper, Lin and Reiter introduced the notion of progression for basic action theories in the situation calculus. Earlier works by Moore, Scherl and Levesque extended the situation calculus to account for knowledge. In this paper, we study progression of knowledge in the situation calculus. We first adapt the concept of bisimulation from modal logic and extend Lin and Reiter's notion of progression to accommodate knowledge. We show that for physical actions, progression of knowledge reduces to forgetting predicates in first-order modal logic. We identify a class of first-order modal formulas for which forgetting an atom is definable in first-order modal logic. This class of formulas goes beyond formulas without quantifyingin. We also identify a simple case where forgetting a predicate reduces to forgetting a finite number of atoms. Thus we are able to show that for local-effect physical actions, when the initial KB is a formula in this class, progression of knowledge is definable in first-order modal logic. Finally, we extend our results to the multi-agent case.

#index 1826220
#* Description logic TBoxes: model-theoretic characterizations and rewritability
#@ Carsten Lutz;Robert Piro;Frank Wolter
#t 2011
#c 11
#% 205398
#% 784055
#% 935898
#% 1152354
#% 1269453
#% 1290243
#% 1369574
#% 1493527
#! We characterize the expressive power of description logic (DL) TBoxes, both for expressive DLs such as ALC and ALCQIO and lightweight DLs such as DL-Lite and EL. Our characterizations are relative to first-order logic, based on a wide range of semantic notions such as bisimulation, equisimulation, disjoint union, and direct product. We exemplify the use of the characterizations by a first study of the following novel family of decision problems: given a TBox T formulated in a DL L, decide whether T can be equivalently rewritten as a TBox in the fragment L′ of L.

#index 1826221
#* Foundations for uniform interpolation and forgetting in expressive description logics
#@ Carsten Lutz;Frank Wolter
#t 2011
#c 11
#% 935898
#% 961683
#% 1111195
#% 1271987
#% 1305421
#% 1333470
#% 1334684
#% 1456451
#% 1473209
#! We study uniform interpolation and forgetting in the description logic ALC. Our main results are model-theoretic characterizations of uniform interpolants and their existence in terms of bisimulations, tight complexity bounds for deciding the existence of uniform interpolants, an approach to computing interpolants when they exist, and tight bounds on their size. We use a mix of model-theoretic and automata-theoretic methods that, as a by-product, also provides characterizations of and decision procedures for conservative extensions.

#index 1826222
#* Existential closures for knowledge compilation
#@ Pierre Marquis
#t 2011
#c 11
#% 204396
#% 342378
#% 529171
#% 600496
#% 936786
#% 1223442
#% 1250513
#% 1269749
#% 1270076
#% 1270089
#% 1270101
#% 1272251
#% 1272349
#% 1273692
#% 1275338
#% 1305412
#% 1473201
#% 1499541
#! We study the existential closures of several propositional languages L considered recently as target languages for knowledge compilation (KC), namely the incomplete fragments KROM-C, HORN-C, K/H-C, renH-C, AFF, and the corresponding disjunction closures KROM-C[V], HORN-C[V], K/H-C[V], renH-C[V], and AFF[V]. We analyze the queries, transformations, expressiveness and succinctness of the resulting languages L[∃] in order to locate them in the KC map. As a by-product, we also address several issues concerning disjunction closures that were left open so far. From our investigation, the language HORN - C[V, ∃] (where disjunctions and existential quantifications can be applied to Horn CNF formulae) appears as an interesting target language for the KC purpose, challenging the influential DNNF languages.

#index 1826223
#* Lost in translation: language independence in propositional logic-application to belief revision and belief merging
#@ Pierre Marquis;Nicolas Schwind
#t 2011
#c 11
#% 109945
#% 265352
#% 428338
#% 772063
#% 1046053
#% 1271987
#% 1273683
#! Despite the importance of propositional logic in artificial intelligence, the notion of language independence in the propositional setting (not to be confound with syntax independence) has not received much attention so far. In this paper, we define language independence for a propositional operator as robustness w.r.t. symbol translation. We provide a number of characterizations results for such translations. We motivate the need to focus on symbol translations of restricted types, and identify several families of interest. We identify the computational complexity of recognizing symbol translations from those families. Finally, as a case study, we investigate the robustness of belief revision/ merging operators w.r.t. translations of different types. It turns out that rational belief revision/ merging operators are not guaranteed to offer the most basic (yet non-trivial) form of language independence; operators based on the Hamming distance do not suffer from this drawback but are less robust than operators based on the drastic distance.

#index 1826224
#* Reasoning about fuzzy belief and common belief: with emphasis on incomparable beliefs
#@ Yoshihiro Maruyama
#t 2011
#c 11
#% 144550
#% 157172
#% 188086
#% 472650
#% 752487
#% 1152376
#% 1172353
#% 1640907
#% 1881546
#! We formalize reasoning about fuzzy belief and fuzzy common belief, especially incomparable beliefs, in multi-agent systems by using a logical system based on Fitting's many-valued modal logic, where incomparable beliefs mean beliefs whose degrees are not totally ordered. Completeness and decidability results for the logic of fuzzy belief and common belief are established while implicitly exploiting the duality-theoretic perspective on Fitting's logic that builds upon the author's previous work. A conceptually novel feature is that incomparable beliefs and qualitative fuzziness can be formalized in the developed system, whereas they cannot be formalized in previously proposed systems for reasoning about fuzzy belief. We believe that belief degrees can ultimately be reduced to truth degrees, and we call this "the reduction thesis about belief degrees", which is assumed in the present paper and motivates an axiom of our system. We finally argue that fuzzy reasoning sheds new light on old epistemic issues such as coordinated attack problem.

#index 1826225
#* Causal learnability
#@ Loizos Michael
#t 2011
#c 11
#% 697
#% 180945
#% 188334
#% 207558
#% 243163
#% 243727
#% 264164
#% 449559
#% 450951
#% 451056
#% 484341
#% 1272248
#% 1305592
#% 1427868
#% 1503504
#% 1718457
#% 1718464
#! The ability to predict, or at least recognize, the state of the world that an action brings about, is a central feature of autonomous agents. We propose, herein, a formal framework within which we investigate whether this ability can be autonomously learned. The framework makes explicit certain premises that we contend are central in such a learning task: (i) slow sensors may prevent the sensing of an action's direct effects during learning; (ii) predictions need to be made reliably in future and novel situations. We initiate in this work a thorough investigation of the conditions under which learning is or is not feasible. Despite the very strong negative learnability results that we obtain, we also identify interesting special cases where learning is feasible and useful.

#index 1826226
#* Revisiting preferences and argumentation
#@ Sanjay Modgil;Henry Prakken
#t 2011
#c 11
#% 198464
#% 231742
#% 417812
#% 953323
#% 1060767
#% 1193569
#% 1268408
#% 1290084
#% 1305395
#% 1473077
#% 1473099
#! The ASPIC+ framework is intermediate in abstraction between Dung's argumentation framework and concrete instantiating logics. This paper generalises ASPIC+ to accommodate classical logic instantiations, and adopts a new proposal for evaluating extensions: attacks are used to define the notion of conflict-free sets, while the defeats obtained by applying preferences to attacks, are exclusively used to determine the acceptability of arguments. Key properties and rationality postulates are then shown to hold for the new framework.

#index 1826227
#* Reasoning-supported interactive revision of knowledge bases
#@ Nadeschda Nikitina;Sebastian Rudolph;Birte Glimm
#t 2011
#c 11
#% 1218638
#% 1270280
#% 1333464
#% 1473453
#! Quality control is an essential task within ontology development projects, especially when the knowledge formalization is partially automatized. We propose a method for integrating newly acquired, possibly low-quality axioms into an existing ontology after their manual inspection; based on the decision whether the axiom is desired or not, several of the yet unevaluated axioms are evaluated automatically. Since the evaluation order can significantly increase the amount of automatization, we further propose the notion of axiom impact. Finally, we introduce decision spaces as structures to efficiently compute the axiom impact and the implicit evaluation decisions. Compared to a naïve implementation, this reduces the number of costly reasoning operations on average by 75%.

#index 1826228
#* Augmenting tractable fragments of abstract argumentation
#@ Sebastian Ordyniak;Stefan Szeider
#t 2011
#c 11
#% 121990
#% 198464
#% 217007
#% 231742
#% 408396
#% 428343
#% 857282
#% 992249
#% 992253
#% 1060767
#% 1091265
#% 1171090
#% 1247945
#% 1279379
#% 1473092
#% 1705577
#% 1826201
#% 1845833
#% 1972413
#% 1985061
#! We present a new and compelling approach to the efficient solution of important computational problems that arise in the context of abstract argumentation. Our approach makes known algorithms defined for restricted fragments generally applicable, at a computational cost that scales with the distance from the fragment. Thus, in a certain sense, we gradually augment tractable fragments. Surprisingly, it turns out that some tractable fragments admit such an augmentation and that others do not. More specifically, we show that the problems of credulous and skeptical acceptance are fixed-parameter tractable when parameterized by the distance from the fragment of acyclic argumentation frameworks. Other tractable fragments such as the fragments of symmetrical and bipartite frameworks seem to prohibit an augmentation: the acceptance problems are already intractable for frameworks at distance 1 from the fragments. For our study we use a broad setting and consider several different semantics. For the algorithmic results we utilize recent advances in fixed-parameter tractability.

#index 1826229
#* Query answering in the horn fragments of the description logics SHOIQ and SROIQ
#@ Magdalena Ortiz;Sebastian Rudolph;Mantas Šimkus
#t 2011
#c 11
#% 494344
#% 1108111
#% 1111191
#% 1269741
#% 1271815
#% 1289425
#% 1305410
#% 1545560
#! The high computational complexity of the expressive Description Logics (DLs) that underlie the OWL standard has motivated the study of their Horn fragments, which are usually tractable in data complexity and can also have lower combined complexity, particularly for query answering. In this paper we provide algorithms for answering conjunctive 2-way regular path queries (2CRPQs), a non-trivial generalization of plain conjunctive queries, in the Horn fragments of the DLs SHOIQ and SROIQ underlying OWL 1 and OWL 2. We show that the combined complexity of the problem is ExpTime-complete for Horn-SHOIQ and 2ExpTime- complete for the more expressive Horn-SROIQ, but is PTime-complete in data complexity for both. In contrast, even decidability of plain conjunctive queries is still open for full SHOIQ and SROIQ. These are the first completeness results for query answering in DLs with inverses, nominals, and counting, and show that for the considered logics the problem is not more expensive than standard reasoning.

#index 1826230
#* An approach to minimal belief via objective belief
#@ David Pearce;Levan Uridia
#t 2011
#c 11
#% 89976
#% 123223
#% 155815
#% 175359
#% 780339
#% 1272967
#% 1274577
#% 1495932
#! As a doxastic counterpart to epistemic logic based on S5 we study the modal logic KSD that can be viewed as an approach to modelling a kind of objective and fair belief. We apply KSD to the problem of minimal belief and develop an alternative approach to nonmonotonic modal logic using a weaker concept of expansion. This corresponds to a certain minimal kind of KSD model and yields a new type of nonmonotonic doxastic reasoning.

#index 1826231
#* An assertion retrieval algebra for object queries over knowledge bases
#@ Jeffrey Pound;David Toman;Grant Weddell;Jiewen Wu
#t 2011
#c 11
#% 874876
#% 960234
#% 1180013
#% 1223443
#% 1711122
#! We consider a generalization of instance retrieval over knowledge bases that provides users with assertions in which descriptions of qualifying objects are given in addition to their identifiers. Notably, this involves a transfer of basic database paradigms involving caching and query rewriting in the context of an assertion retrieval algebra. We present an optimization framework for this algebra, with a focus on finding plans that avoid any need for general knowledge base reasoning at query execution time when sufficient cached results of earlier requests exist.

#index 1826232
#* On the complexity of dealing with inconsistency in description logic ontologies
#@ Riccardo Rosati
#t 2011
#c 11
#% 131559
#% 181400
#% 342829
#% 665856
#% 1272202
#% 1289408
#% 1305431
#% 1500885
#% 1661426
#! We study the problem of dealing with inconsistency in Description Logic (DL) ontologies. We consider inconsistency-tolerant semantics recently proposed in the literature, called AR-semantics and CAR-semantics, which are based on repairing (i.e., modifying) in a minimal way the extensional knowledge (ABox) while keeping the intensional knowledge (TBox) untouched. We study instance checking and conjunctive query entailment under the above inconsistency-tolerant semantics for a wide spectrum of DLs, ranging from tractable ones (EL) to very expressive ones (SHIQ), showing that reasoning under the above semantics is inherently intractable, even for very simple DLs. To the aim of overcoming such a high computational complexity of reasoning, we study sound approximations of the above semantics. Surprisingly, our computational analysis shows that reasoning under the approximated semantics is intractable even for tractable DLs. Finally, we identify suitable language restrictions of such DLs allowing for tractable reasoning under inconsistency-tolerant semantics.

#index 1826233
#* Dishonest reasoning by abduction
#@ Chiaki Sakama
#t 2011
#c 11
#% 243831
#% 442958
#% 752737
#% 1275253
#% 1279698
#% 1495933
#% 1675024
#! This paper studies a computational logic for dishonest reasoning. We introduce logic programs with disinformation to represent and reason with dishonesty. We then consider two different cases of dishonesty: deductive dishonesty and abductive dishonesty. The former misleads another agent to deduce wrong conclusions, while the latter interrupts another agent to abduce correct explanations. In deductive or abductive dishonesty, an agent can perform different types of dishonest reasoning such as lying, bullshitting, and withholding information. We show that these different types of dishonest reasoning are characterized by extended abduction, and address their computational methods using abductive logic programming.

#index 1826234
#* A logical formulation for negotiation among dishonest agents
#@ Chiaki Sakama;Tran Cao Son;Enrico Pontelli
#t 2011
#c 11
#% 318601
#% 495999
#% 890255
#% 1024834
#% 1279698
#% 1305437
#% 1598608
#! The paper introduces a logical framework for negotiation among dishonest agents. The framework relies on the use of abductive logic programming as a knowledge representation language for agents to deal with incomplete information and preferences. The paper shows how intentionally false or inaccurate information of agents could be encoded in the agents' knowledge bases. Such disinformation can be effectively used in the process of negotiation to have desired outcomes by agents. The negotiation processes are formulated under the answer set semantics of abductive logic programming and enable the exploration of various strategies that agents can employ in their negotiation.

#index 1826235
#* Description logics and fuzzy probability
#@ Lutz Schröder;Dirk Pattinson
#t 2011
#c 11
#% 21146
#% 54223
#% 89958
#% 157172
#% 259392
#% 565833
#% 752494
#% 998297
#% 1036397
#% 1100696
#% 1136065
#% 1195102
#% 1268417
#% 1268424
#% 1271958
#% 1272188
#% 1346815
#% 1503331
#! Uncertainty and vagueness are pervasive phenomena in real-life knowledge. They are supported in extended description logics that adapt classical description logics to deal with numerical probabilities or fuzzy truth degrees. While the two concepts are distinguished for good reasons, they combine in the notion of probably, which is ultimately a fuzzy qualification of probabilities. Here, we develop existing propositional logics of fuzzy probability into a full-blown description logic, and we show decidability of several variants of this logic under Łukasiewicz semantics. We obtain these results in a novel generic framework of fuzzy coalgebraic logic; this enables us to extend our results to logics that combine crisp ingredients including standard crisp roles and crisp numerical probabilities with fuzzy roles and fuzzy probabilities.

#index 1826236
#* Well-supported semantics for description logic programs
#@ Yi-Dong Shen
#t 2011
#c 11
#% 665856
#% 772065
#% 1065897
#% 1109406
#% 1272162
#% 1289365
#% 1384952
#% 1466301
#% 1513035
#! [Fages, 1994] introduces the notion of well-supportedness as a key requirement for the semantics of normal logic programs and characterizes the standard answer set semantics in terms of the well-supportedness condition. With the property of well-supportedness, answer sets are guaranteed to be free of circular justifications. In this paper, we extend Fages' work to description logic programs (or DL-programs). We introduce two forms of well-supportedness for DL-programs. The first one defines weakly well-supported models that are free of circular justifications caused by positive literals in rule bodies. The second one defines strongly well-supported models that are free of circular justifications caused by either positive or negative literals. We then define two new answer set semantics for DL-programs and characterize them in terms of the weakly and strongly well-supported models, respectively. The first semantics is based on an extended Gelfond-Lifschitz transformation and defines weakly well-supported answer sets that are free of circular justifications for the class of DL-programs without negative dlatoms. The second semantics defines strongly well-supported answer sets which are free of circular justifications for all DL-programs. We show that the existing answer set semantics for DL-programs, such as the weak answer set semantics, the strong answer set semantics, and the FLP-based answer set semantics, satisfy neither the weak nor the strong well-supportedness condition, even for DL-programs without negative dl-atoms. This explains why their answer sets incur circular justifications.

#index 1826237
#* Computing minimum-cardinality diagnoses by model relaxation
#@ Sajjad Siddiqi
#t 2011
#c 11
#% 21137
#% 342378
#% 571102
#% 1274845
#% 1305603
#% 1406884
#! We propose a new approach based on model relaxation to compute minimum-cardinality diagnoses of a (faulty) system: We obtain a relaxed model of the system by splitting nodes in the system and compile the abstraction of the relaxed model into DNNF. Abstraction is obtained by treating self-contained sub-systems called cones as single components. We then use a novel branch-and-bound search algorithm and compute the abstract minimum-cardinality diagnoses of the system, which are later refined hierarchically, in a careful manner, to get all minimum-cardinality diagnoses of the system. Experiments on ISCAS-85 benchmark circuits show that the new approach is faster than the previous state-of-the-art hierarchical approach, and scales to all circuits in the suite for the first time.

#index 1826238
#* Consequence-based reasoning beyond horn ontologies
#@ František Simančík;Yevgeny Kazakov;Ian Horrocks
#t 2011
#c 11
#% 935898
#% 1050476
#% 1099359
#% 1136066
#% 1289408
#% 1305615
#! Consequence-based ontology reasoning procedures have so far been known only for Horn ontology languages. A difficulty in extending such procedures is that non-Horn axioms seem to require reasoning by case, which causes non-determinism in tableau-based procedures. In this paper we present a consequence-based procedure for ALCH that overcomes this difficulty by using rules similar to ordered resolution to deal with disjunctive axioms in a deterministic way; it retains all the favourable attributes of existing consequence-based procedures, such as goal-directed "one pass" classification, optimal worst-case complexity, and "pay-as-you-go" behaviour. Our preliminary empirical evaluation suggests that the procedure scales well to non-Horn ontologies.

#index 1826239
#* Beth definability in expressive description logics
#@ Balder Ten Cate;Enrico Franconi;İnanç Seylan
#t 2011
#c 11
#% 207489
#% 575382
#% 579726
#% 665856
#% 798349
#% 890213
#% 1046053
#% 1272069
#% 1305436
#% 1426418
#! The Beth definability property, a well-known property from classical logic, is investigated in the context of description logics (DLs): if a general LTBox implicitly defines an L-concept in terms of a given signature, where L is a DL, then does there always exist over this signature an explicit definition in L for the concept? This property has been studied before and used to optimize reasoning in DLs. In this paper a complete classification of Beth definability is provided for extensions of the basic DL ALC with transitive roles, inverse roles, role hierarchies, and/or functionality restrictions, both on arbitrary and on finite structures. Moreover, we present a tableau-based algorithm which computes explicit definitions of at most double exponential size. This algorithm is optimal because it is also shown that the smallest explicit definition of an implicitly defined concept may be double exponentially long in the size of the input TBox. Finally, if explicit definitions are allowed to be expressed in first-order logic then we show how to compute them in EXPTIME.

#index 1826240
#* The general game playing description language is universal
#@ Michael Thielscher
#t 2011
#c 11
#% 7690
#% 53385
#% 233137
#% 1134243
#% 1269851
#% 1269860
#% 1271826
#% 1650455
#! The Game Description Language is a high-level, rule-based formalisms for communicating the rules of arbitrary games to general game-playing systems, whose challenging task is to learn to play previously unknown games without human intervention. Originally designed for deterministic games with complete information about the game state, the language was recently extended to include randomness and imperfect information. However, determining the extent to which this enhancement allows to describe truly arbitrary games was left as an open problem. We provide a positive answer to this question by relating the extended Game Description Language to the universal, mathematical concept of extensive-form games, proving that indeed just any such game can be described faithfully.

#index 1826241
#* Relating Carneades with abstract argumentation
#@ Bas Van Gijzel;Henry Prakken
#t 2011
#c 11
#% 198464
#% 992251
#% 992259
#% 1473073
#% 1826188
#! Carneades is a recently proposed formalism for structured argumentation with varying proof standards. An open question is its relation with Dung's seminal abstract approach to argumentation. In this paper the two formalisms are formally related by translating Carneades into ASPIC+, another recently proposed formalism for structured argumentation. Since ASPIC+ is defined to generate Dungstyle abstract argumentation frameworks, this in effect translates Carneades graphs into abstract argumentation frameworks. It is proven that Carneades always induces a unique Dung extension, which is the same in all of Dung's semantics.

#index 1826242
#* On qualitative route descriptions: representation and computational complexity
#@ Matthias Westphal;Stefan Wölfl;Bernhard Nebel;Jochen Renz
#t 2011
#c 11
#% 47708
#% 303954
#% 647499
#% 1110700
#% 1405079
#% 1407871
#% 1425765
#% 1473450
#% 1738809
#! The generation of route descriptions is a fundamental task of navigation systems. A particular problem in this context is to identify routes that can easily be described and processed by users. In this work, we present a framework for representing route networks with the qualitative information necessary to evaluate and optimize route descriptions with regard to ambiguities in them. We identify different agent models that differ in how agents are assumed to process route descriptions while navigating through route networks. Further, we analyze the computational complexity of matching route descriptions and paths in route networks in dependency of the agent model. Finally we empirically evaluate the influence of the agent model on the optimization and the processing of route instructions.

#index 1826243
#* Translating first-order theories into logic programs
#@ Heng Zhang;Yan Zhang;Mingsheng Ying;Yi Zhou
#t 2011
#c 11
#% 116627
#% 235018
#% 1263126
#% 1274639
#% 1305416
#% 1305420
#% 1503511
#% 1503512
#% 1676835
#! This paper focuses on computing first-order theories under either stable model semantics or circumscription. A reduction from first-order theories to logic programs under stable model semantics over finite structures is proposed, and an embedding of circumscription into stable model semantics is also given. Having such reduction and embedding, reasoning problems represented by first-order theories under these two semantics can then be handled by using existing answer set solvers. The effectiveness of this approach in computing hard problems beyond NP is demonstrated by some experiments.

#index 1826244
#* Transitively relational partial meet horn contraction
#@ Zhiqiang Zhuang;Maurice Pagnucco
#t 2011
#c 11
#% 109945
#% 782324
#% 1305401
#% 1495937
#! Following the recent trend of studying the theory of belief revision under the Horn fragment of propositional logic this paper develops a fully characterised Horn contraction which is analogous to the traditional transitively relational partial meet contraction [Alchourrón et al., 1985]. This Horn contraction extends the partial meet Horn contraction studied in [Delgrande and Wassermann, 2010] so that it is guided by a transitive relation that models the ordering of plausibility over sets of beliefs.

#index 1826245
#* Discerning linkage-based algorithms among hierarchical clustering methods
#@ Margareta Ackerman;Shai Ben-David
#t 2011
#c 11
#% 1417126
#! Selecting a clustering algorithm is a perplexing task. Yet since different algorithms may yield dramatically different outputs on the same data, the choice of algorithm is crucial. When selecting a clustering algorithm, users tend to focus on cost-related considerations (software purchasing costs, running times, etc). Differences concerning the output of the algorithms are not usually considered. Recently, a formal approach for selecting a clustering algorithm has been proposed [2]. The approach involves distilling abstract properties of the input-output behavior of different clustering paradigms and classifying algorithms based on these properties. In this paper, we extend the approach in [2] into the hierarchical setting. The class of linkage-based algorithms is perhaps the most popular class of hierarchical algorithms. We identify two properties of hierarchical algorithms, and prove that linkage-based algorithms are the only ones that satisfy both of these properties. Our characterization clearly delineates the difference between linkage-based algorithms and other hierarchical algorithms. We formulate an intuitive notion of locality of a hierarchical algorithm that distinguishes between linkage-based and "global" hierarchical algorithms like bisecting k-means, and prove that popular divisive hierarchical algorithms produce clusterings that cannot be produced by any linkage-based algorithm.

#index 1826246
#* A competitive strategy for function approximation in Q-learning
#@ Alejandro Agostini;Enric Celaya
#t 2011
#c 11
#% 384911
#% 647069
#% 840860
#% 857462
#% 1044118
#% 1182603
#% 1342670
#! In this work we propose an approach for generalization in continuous domain Reinforcement Learning that, instead of using a single function approximator, tries many different function approximators in parallel, each one defined in a different region of the domain. Associated with each approximator is a relevance function that locally quantifies the quality of its approximation, so that, at each input point, the approximator with highest relevance can be selected. The relevance function is defined using parametric estimations of the variance of the q-values and the density of samples in the input space, which are used to quantify the accuracy and the confidence in the approximation, respectively. These parametric estimations are obtained from a probability density distribution represented as a Gaussian Mixture Model embedded in the input-output space of each approximator. In our experiments, the proposed approach required a lesser number of experiences for learning and produced more stable convergence profiles than when using a single function approximator.

#index 1826247
#* Multi-evidence lifted message passing, with application to PageRank and the Kalman filter
#@ Babak Ahmadi;Kristian Kersting;Scott Sanner
#t 2011
#c 11
#% 44876
#% 268079
#% 850430
#% 856762
#% 1000502
#% 1008889
#% 1270256
#% 1270261
#% 1279353
#% 1289560
#% 1417084
#% 1417109
#! Lifted message passing algorithms exploit repeated structure within a given graphical model to answer queries efficiently. Given evidence, they construct a lifted network of supernodes and superpotentials corresponding to sets of nodes and potentials that are indistinguishable given the evidence. Recently, efficient algorithms were presented for updating the structure of an existing lifted network with incremental changes to the evidence. In the inference stage, however, current algorithms need to construct a separate lifted network for each evidence case and run a modified message passing algorithm on each lifted network separately. Consequently, symmetries across the inference tasks are not exploited. In this paper, we present a novel lifted message passing technique that exploits symmetries across multiple evidence cases. The benefits of this multi-evidence lifted inference are shown for several important AI tasks such as computing personalized PageRanks and Kalman filters via multievidence lifted Gaussian belief propagation.

#index 1826248
#* An efficient framework for constructing generalized locally-induced text metrics
#@ Saeed Amizadeh;Shuguang Wang;Milos Hauskrecht
#t 2011
#c 11
#% 218978
#% 406493
#% 464615
#% 466574
#% 837604
#% 838532
#% 852092
#% 1073875
#% 1074081
#% 1074187
#% 1450893
#! In this paper, we propose a new framework for constructing text metrics which can be used to compare and support inferences among terms and sets of terms. Our metric is derived from data-driven kernels on graphs that let us capture global relations among terms and sets of terms, regardless of their complexity and size. To compute the metric efficiently for any two subsets of terms, we develop an approximation technique that relies on the precompiled term-term similarities. To scale-up the approach to problems with huge number of terms, we develop and experiment with a solution that subsamples the term space. We demonstrate the benefits of the whole framework on two text inference tasks: prediction of terms in the article from its abstract and query expansion in information retrieval.

#index 1826249
#* Semi-supervised learning from a translation model between data distributions
#@ Henry Anaya-Sánchez;José Martínez-Sotoca;Adolfo Martínez-Usó
#t 2011
#c 11
#% 280851
#% 340899
#% 563885
#% 722904
#% 1073989
#% 1209696
#% 1354495
#% 1949288
#! In this paper, we introduce a probabilistic classification model to address the task of semi-supervised learning. The major novelty of our proposal stems from measuring distributional relationships between the labeled and unlabeled data. This is achieved from a stochastic translation model between data distributions that is estimated from a mixture model. The proposed classifier is defined from the combination of both the translation model and a kernel logistic regression on labeled data. Experimental results obtained over synthetic and real-world data sets validate the usefulness of our proposal.

#index 1826250
#* A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic
#@ David Andrzejewski;Xiaojin Zhu;Mark Craven;Benjamin Recht
#t 2011
#c 11
#% 227736
#% 722904
#% 850430
#% 938687
#% 1100044
#% 1117688
#% 1152447
#% 1211693
#% 1250579
#% 1261563
#% 1268069
#% 1270261
#% 1270263
#% 1305601
#% 1338553
#% 1417084
#% 1467732
#% 1591954
#% 1695067
#% 1845612
#! Topic models have been used successfully for a variety of problems, often in the form of application-specific extensions of the basic Latent Dirichlet Allocation (LDA) model. Because deriving these new models in order to encode domain knowledge can be difficult and time-consuming, we propose the Foldċall model, which allows the user to specify general domain knowledge in First-Order Logic (FOL). However, combining topic modeling with FOL can result in inference problems beyond the capabilities of existing techniques. We have therefore developed a scalable inference technique using stochastic gradient descent which may also be useful to the Markov Logic Network (MLN) research community. Experiments demonstrate the expressive power of Foldċall, as well as the scalability of our proposed inference method.

#index 1826251
#* Improving performance of topic models by variable grouping
#@ Evgeniy Bart
#t 2011
#c 11
#% 722904
#% 724203
#% 724246
#% 836717
#% 836755
#% 891559
#% 1073915
#% 1083687
#% 1117695
#% 1214715
#% 1270334
#! Topic models have a wide range of applications, including modeling of text documents, images, user preferences, product rankings, and many others. However, learning optimal models may be difficult, especially for large problems. The reason is that inference techniques such as Gibbs sampling often converge to suboptimal models due to the abundance of local minima in large datasets. In this paper, we propose a general method of improving the performance of topic models. The method, called 'grouping transform', works by introducing auxiliary variables which represent assignments of the original model tokens to groups. Using these auxiliary variables, it becomes possible to resample an entire group of tokens at a time. This allows the sampler to make larger state space moves. As a result, better models are learned and performance is improved. The proposed ideas are illustrated on several topic models and several text and image datasets. We show that the grouping transform significantly improves performance over standard models.

#index 1826252
#* Learning a distance metric by empirical loss minimization
#@ Wei Bian;Dacheng Tao
#t 2011
#c 11
#% 457926
#% 983830
#% 1305502
#% 1560063
#% 1742166
#! In this paper, we study the problem of learning a metric and propose a loss function based metric learning framework, in which the metric is estimated by minimizing an empirical risk over a training set. With mild conditions on the instance distribution and the used loss function, we prove that the empirical risk converges to its expected counterpart at rate of root-n. In addition, with the assumption that the best metric that minimizes the expected risk is bounded, we prove that the learned metric is consistent. Two example algorithms are presented by using the proposed loss function based metric learning framework, each of which uses a log loss function and a smoothed hinge loss function, respectively. Experimental results suggest the effectiveness of the proposed algorithms.

#index 1826253
#* A hidden Markov model variant for sequence classification
#@ Sam Blasiak;Huzefa Rangwala
#t 2011
#c 11
#% 280819
#% 304917
#% 722816
#% 722904
#% 771841
#% 773682
#% 830744
#% 905796
#! Sequence classification is central to many practical problems within machine learning. Distances metrics between arbitrary pairs of sequences can be hard to define because sequences can vary in length and the information contained in the order of sequence elements is lost when standard metrics such as Euclidean distance are applied. We present a scheme that employs a Hidden Markov Model variant to produce a set of fixed-length description vectors from a set of sequences. We then define three inference algorithms, a Baum-Welch variant, a Gibbs Sampling algorithm, and a variational algorithm, to infer model parameters. Finally, we show experimentally that the fixed length representation produced by these inference methods is useful for classifying sequences of amino acids into structural classes.

#index 1826254
#* Approximation-guided evolutionary multi-objective optimization
#@ Karl Bringmann;Tobias Friedrich;Frank Neumann;Markus Wagner
#t 2011
#c 11
#% 392343
#% 449999
#% 593993
#% 857276
#% 958590
#% 1084576
#% 1411380
#% 1447241
#% 1484144
#% 1492770
#% 1504029
#% 1703898
#% 1777103
#% 1777209
#! Multi-objective optimization problems arise frequently in applications but can often only be solved approximately by heuristic approaches. Evolutionary algorithms have been widely used to tackle multi-objective problems. These algorithms use different measures to ensure diversity in the objective space but are not guided by a formal notion of approximation. We present a new framework of an evolutionary algorithm for multi-objective optimization that allows to work with a formal notion of approximation. Our experimental results show that our approach outperforms state-of-the-art evolutionary algorithms in terms of the quality of the approximation that is obtained in particular for problems with many objectives.

#index 1826255
#* Distance metric learning under covariate shift
#@ Bin Cao;Xiaochuan Ni;Jian-Tao Sun;Gang Wang;Qiang Yang
#t 2011
#c 11
#% 190581
#% 643008
#% 770847
#% 876008
#% 983814
#% 983830
#% 1074017
#% 1270308
#% 1272110
#% 1861871
#! Learning distance metrics is a fundamental problem in machine learning. Previous distance-metric learning research assumes that the training and test data are drawn from the same distribution, which may be violated in practical applications. When the distributions differ, a situation referred to as covariate shift, the metric learned from training data may not work well on the test data. In this case the metric is said to be inconsistent. In this paper, we address this problem by proposing a novel metric learning framework known as consistent distance metric learning (CDML), which solves the problem under covariate shift situations. We theoretically analyze the conditions when the metrics learned under covariate shift are consistent. Based on the analysis, a convex optimization problem is proposed to deal with the CDML problem. An importance sampling method is proposed for metric learning and two importance weighting strategies are proposed and compared in this work. Experiments are carried out on synthetic and real world datasets to show the effectiveness of the proposed method.

#index 1826256
#* Using cases as heuristics in reinforcement learning: a transfer learning application
#@ Luiz A. Celiberto, Jr.;Jackson P. Matsuura;Ramon Lopez De Mantaras;Reinaldo A. C. Bianchi
#t 2011
#c 11
#% 384911
#% 719138
#% 866959
#% 890312
#% 1046445
#% 1073940
#% 1108911
#% 1109929
#% 1193572
#% 1250585
#% 1252987
#% 1252990
#% 1271966
#% 1274860
#% 1274921
#% 1385963
#% 1699609
#% 1706010
#! In this paper we propose to combine three AI techniques to speed up a Reinforcement Learning algorithm in a Transfer Learning problem: Case-based Reasoning, Heuristically Accelerated Reinforcement Learning and Neural Networks. To do so, we propose a new algorithm, called L3, which works in 3 stages: in the first stage, it uses Reinforcement Learning to learn how to perform one task, and stores the optimal policy for this problem as a case-base; in the second stage, it uses a Neural Network to map actions from one domain to actions in the other domain and; in the third stage, it uses the case-base learned in the first stage as heuristics to speed up the learning performance in a related, but different, task. The RL algorithm used in the first phase is the Q-learning and in the third phase is the recently proposed Case-based Heuristically Accelerated Q-learning. A set of empirical evaluations were conducted in transferring the learning between two domains, the Acrobot and the Robocup 3D: the policy learned during the solution of the Acrobot Problem is transferred and used to speed up the learning of stability policies for a humanoid robot in the Robocup 3D simulator. The results show that the use of this algorithm can lead to a significant improvement in the performance of the agent.

#index 1826257
#* Increasing the scalability of the fitting of generalised block models for social networks
#@ Jeffrey Chan;Samantha Lam;Conor Hayes
#t 2011
#c 11
#% 95673
#% 207252
#% 442537
#% 848218
#% 1117695
#% 1233311
#% 1438370
#! In recent years, the summarisation and decomposition of social networks has become increasingly popular, from community finding to role equivalence. However, these approaches concentrate on one type of model only. Generalised blockmodelling decomposes a network into independent, interpretable, labeled blocks, where the block labels summarise the relationship between two sets of users. Existing algorithms for fitting generalised blockmodels do not scale beyond networks of 100 vertices. In this paper, we introduce two new algorithms, one based on genetic algorithms and the other on simulated annealing, that is at least two orders of magnitude faster than existing algorithms and obtaining similar accuracy. Using synthetic and real datasets, we demonstrate their efficiency and accuracy and show how generalised block-modelling and our new approaches enable tractable network summarisation and modelling of medium sized networks.

#index 1826258
#* Concept labeling: building text classifiers with minimal supervision
#@ Vijil Chenthamarakshan;Prem Melville;Vikas Sindhwani;Richard D. Lawrence
#t 2011
#c 11
#% 466263
#% 840965
#% 1031858
#% 1074125
#% 1083703
#% 1120999
#% 1250362
#% 1270222
#% 1385982
#% 1451182
#% 1455666
#% 1482395
#! The rapid construction of supervised text classification models is becoming a pervasive need across many modern applications. To reduce human-labeling bottlenecks, many new statistical paradigms (e.g., active, semi-supervised, transfer and multi-task learning) have been vigorously pursued in recent literature with varying degrees of empirical success. Concurrently, the emergence of Web 2.0 platforms in the last decade has enabled a world-wide, collaborative human effort to construct a massive ontology of concepts with very rich, detailed and accurate descriptions. In this paper we propose a new framework to extract supervisory information from such ontologies and complement it with a shift in human effort from direct labeling of examples in the domain of interest to the much more efficient identification of concept-class associations. Through empirical studies on text categorization problems using the Wikipedia ontology, we show that this shift allows very high-quality models to be immediately induced at virtually no cost.

#index 1826259
#* Unsupervised learning of patterns in data streams using compression and edit distance
#@ Sook-Ling Chua;Stephen Marsland;Hans W. Guesgen
#t 2011
#c 11
#% 299038
#% 817577
#% 891559
#% 914226
#% 937081
#% 1018413
#% 1227294
#% 1334698
#% 1815525
#! Many unsupervised learning methods for recognising patterns in data streams are based on fixed length data sequences, which makes them unsuitable for applications where the data sequences are of variable length such as in speech recognition, behaviour recognition and text classification. In order to use these methods on variable length data sequences, a pre-processing step is required to manually segment the data and select the appropriate features, which is often not practical in real-world applications. In this paper we suggest an unsupervised learning method that handles variable length data sequences by identifying structure in the data stream using text compression and the edit distance between 'words'. We demonstrate that using this method we can automatically cluster unlabelled data in a data stream and perform segmentation. We evaluate the effectiveness of our proposed method using both fixed length and variable length benchmark datasets, comparing it to the Self-Organising Map in the first case. The results show a promising improvement over baseline recognition systems.

#index 1826260
#* Flexible, high performance convolutional neural networks for image classification
#@ Dan C. Cireşan;Ueli Meier;Jonathan Masci;Luca M. Gambardella;Jürgen Schmidhuber
#t 2011
#c 11
#% 718774
#% 812600
#% 933160
#% 1051441
#% 1089696
#% 1421047
#% 1493946
#% 1502411
#% 1542726
#! We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs, respectively.

#index 1826261
#* Automatic state abstraction from demonstration
#@ Luis C. Cobo;Peng Zang;Charles L. Isbell, Jr.;Andrea L. Thomaz
#t 2011
#c 11
#% 543750
#% 770852
#% 876001
#% 950571
#% 983896
#% 1083647
#% 1187663
#% 1211755
#% 1211842
#% 1289471
#! Learning from Demonstration (LfD) is a popular technique for building decision-making agents from human help. Traditional LfD methods use demonstrations as training examples for supervised learning, but complex tasks can require more examples than is practical to obtain. We present Abstraction from Demonstration (AfD), a novel form of LfD that uses demonstrations to infer state abstractions and reinforcement learning (RL) methods in those abstract state spaces to build a policy. Empirical results show that AfD is greater than an order of magnitude more sample efficient than just using demonstrations as training examples, and exponentially faster than RL alone.

#index 1826262
#* Generative structure learning for Markov logic networks based on graph of predicates
#@ Quang-Thang Dinh;Matthieu Exbrayat;Christel Vrain
#t 2011
#c 11
#% 44876
#% 496116
#% 577225
#% 785353
#% 816181
#% 850430
#% 875974
#% 983882
#% 1073924
#% 1108078
#% 1211753
#% 1223507
#% 1271907
#% 1478466
#% 1540529
#% 1546616
#! In this paper we present a new algorithm for generatively learning the structure of Markov Logic Networks. This algorithm relies on a graph of predicates, which summarizes the links existing between predicates and on relational information between ground atoms in the training database. Candidate clauses are produced by means of a heuristical variabilization technique. According to our first experiments, this approach appears to be promising.

#index 1826263
#* Learning decision rules from data streams
#@ João Gama;Petr Kosina
#t 2011
#c 11
#% 136350
#% 204531
#% 209023
#% 252533
#% 342639
#% 449559
#% 449566
#% 451036
#% 465922
#% 727880
#% 729932
#% 729965
#% 751439
#% 953970
#% 1214654
#% 1451181
#! Decision rules, which can provide good interpretability and flexibility for data mining tasks, have received very little attention in the stream mining community so far. In this work we introduce a new algorithm to learn rule sets, designed for open-ended data streams. The proposed algorithm is able to continuously learn compact ordered and unordered rule sets. The experimental evaluation shows competitive results in comparison with VFDT and C4.5rules.

#index 1826264
#* Constituent grammatical evolution
#@ Loukas Georgiou;William J. Teahan
#t 2011
#c 11
#% 124073
#% 165144
#% 431244
#% 644331
#% 1261971
#% 1287993
#% 1577708
#% 1669378
#% 1669713
#% 1777172
#! We present Constituent Grammatical Evolution (CGE), a new evolutionary automatic programming algorithm that extends the standard Grammatical Evolution algorithm by incorporating the concepts of constituent genes and conditional behaviour-switching. CGE builds from elementary and more complex building blocks a control program which dictates the behaviour of an agent and it is applicable to the class of problems where the subject of search is the behaviour of an agent in a given environment. It takes advantage of the powerful Grammatical Evolution feature of using a BNF grammar definition as a plug-in component to describe the output language to be produced by the system. The main benchmark problem in which CGE is evaluated is the Santa Fe Trail problem using a BNF grammar definition which defines a search space semantically equivalent with that of the original definition of the problem by Koza. Furthermore, CGE is evaluated on two additional problems, the Loss Altos Hills and the Hampton Court Maze. The experimental results demonstrate that Constituent Grammatical Evolution outperforms the standard Grammatical Evolution algorithm in these problems, in terms of both efficiency (percent of solutions found) and effectiveness (number of required steps of solutions found).

#index 1826265
#* Continuous correlated beta processes
#@ Robby Goetschalckx;Pascal Poupart;Jesse Hoey
#t 2011
#c 11
#% 925382
#! In this paper we consider a (possibly continuous) space of Bernoulli experiments. We assume that the Bernoulli distributions are correlated. All evidence data comes in the form of successful or failed experiments at different points. Current state-of-the-art methods for expressing a distribution over a continuum of Bernoulli distributions use logistic Gaussian processes or Gaussian copula processes. However, both of these require computationally expensive matrix operations (cubic in the general case). We introduce a more intuitive approach, directly correlating beta distributions by sharing evidence between them according to a kernel function, an approach which has linear time complexity. The approach can easily be extended to multiple outcomes, giving a continuous correlated Dirichlet process, and can be used for both classification and learning the actual probabilities of the Bernoulli distributions. We show results for a number of data sets, as well as a case-study where a mixture of continuous beta processes is used as part of an automated stroke rehabilitation system.

#index 1826266
#* A fast dual projected Newton method for l1-regularized least squares
#@ Pinghua Gong;Changshui Zhang
#t 2011
#c 11
#% 757953
#% 891559
#% 1100067
#% 1298490
#% 1302843
#% 1302853
#% 1386006
#! L1-regularized least squares, with the ability of discovering sparse representations, is quite prevalent in the field of machine learning, statistics and signal processing. In this paper, we propose a novel algorithm called Dual Projected Newton Method (DPNM) to solve the l1-regularized least squares problem. In DPNM, we first derive a new dual problem as a box constrained quadratic programming. Then, a projected Newton method is utilized to solve the dual problem, achieving a quadratic convergence rate. Moreover, we propose to utilize some practical techniques, thus it greatly reduces the computational cost and makes DPNM more efficient. Experimental results on six real-world data sets indicate that DPNM is very efficient for solving the l1-regularized least squares problem, by comparing it with state of the art methods.

#index 1826267
#* Kernel-based selective ensemble learning for streams of trees
#@ Valerio Grossi;Alessandro Sperduti
#t 2011
#c 11
#% 310500
#% 342600
#% 342639
#% 629617
#% 729932
#% 815896
#% 824795
#% 874178
#% 915360
#% 998561
#% 1074047
#% 1083627
#% 1090541
#% 1214635
#% 1268042
#% 1411055
#% 1716028
#! Learning from streaming data represents an important and challenging task. Maintaining an accurate model, while the stream goes by, requires a smart way for tracking data changes through time, originating concept drift. One way to treat this kind of problem is to resort to ensemble-based techniques. In this context, the advent of new technologies related to web and ubiquitous services call for the need of new learning approaches able to deal with structured-complex information, such as trees. Kernel methods enable the modeling of structured data in learning algorithms, however they are computationally demanding. The contribute of this work is to show how an effective ensemble-based approach can be deviced for streams of trees by optimizing the kernel-based model representation. Both efficacy and efficiency of the proposed approach are assessed for different models by using data sets exhibiting different levels and types of concept drift.

#index 1826268
#* On trivial solution and scale transfer problems in graph regularized NMF
#@ Quanquan Gu;Chris Ding;Jiawei Han
#t 2011
#c 11
#% 313959
#% 643008
#% 729918
#% 757953
#% 837604
#% 881468
#% 891559
#% 915294
#% 961218
#% 1176865
#% 1214657
#% 1327693
#! Combining graph regularization with nonnegative matrix (tri-)factorization (NMF) has shown great performance improvement compared with traditional nonnegative matrix (tri-)factorization models due to its ability to utilize the geometric structure of the documents and words. In this paper, we show that these models are not well-defined and suffering from trivial solution and scale transfer problems. In order to solve these common problems, we propose two models for graph regularized non-negative matrix (tri-)factorization, which can be applied for document clustering and co-clustering respectively. In the proposed models, a Normalized Cut-like constraint is imposed on the cluster assignment matrix to make the optimization problem well-defined. We derive a multiplicative updating algorithm for the proposed models, and prove its convergence. Experiments of clustering and coclustering on benchmark text data sets demonstrate that the proposed models outperform the original models as well as many other state-of-the-art clustering methods.

#index 1826269
#* Joint feature selection and subspace learning
#@ Quanquan Gu;Zhenhui Li;Jiawei Han
#t 2011
#c 11
#% 224113
#% 235342
#% 722929
#% 732522
#% 757953
#% 836827
#% 876025
#% 913838
#% 1117001
#% 1128929
#% 1379069
#! Dimensionality reduction is a very important topic in machine learning. It can be generally classified into two categories: feature selection and subspace learning. In the past decades, many methods have been proposed for dimensionality reduction. However, most of these works study feature selection and subspace learning independently. In this paper, we present a framework for joint feature selection and subspace learning. We reformulate the subspace learning problem and use L2,1-norm on the projection matrix to achieve row-sparsity, which leads to selecting relevant features and learning transformation simultaneously. We discuss two situations of the proposed framework, and present their optimization algorithms. Experiments on benchmark face recognition data sets illustrate that the proposed framework outperforms the state of the art methods overwhelmingly.

#index 1826270
#* Multi-label classification using conditional dependency networks
#@ Yuhong Guo;Suicheng Gu
#t 2011
#c 11
#% 172544
#% 311034
#% 325348
#% 722754
#% 763708
#% 838412
#% 1117464
#% 1134224
#% 1264044
#% 1570399
#! In this paper, we tackle the challenges of multilabel classification by developing a general conditional dependency network model. The proposed model is a cyclic directed graphical model, which provides an intuitive representation for the dependencies among multiple label variables, and a well integrated framework for efficient model training using binary classifiers and label predictions using Gibbs sampling inference. Our experiments show the proposed conditional model can effectively exploit the label dependency to improve multilabel classification performance.

#index 1826271
#* Extracting temporal patterns from interval-based sequences
#@ Thomas Guyet;René Quiniou
#t 2011
#c 11
#% 319244
#% 329537
#% 459006
#% 464996
#% 487661
#% 874164
#% 949146
#% 975048
#% 1062748
#% 1069597
#% 1136707
#% 1159274
#% 1273818
#% 1318790
#! Most of the sequential patterns extraction methods proposed so far deal with patterns composed of events linked by temporal relationships based on simple precedence between instants. In many real situations, some quantitative information about event duration or inter-event delay is necessary to discriminate phenomena. We propose the algorithm QTIPrefixSpan for extracting temporal patterns composed of events to which temporal intervals describing their position in time and their duration are associated. It extends algorithm PrefixSpan with a multi-dimensional interval clustering step for extracting the representative temporal intervals associated to events in patterns. Experiments on simulated data show that our algorithm is efficient for extracting precise patterns even in noisy contexts and that it improves the performance of a former algorithm which used a clustering method based on the EM algorithm.

#index 1826272
#* Fast approximate nearest-neighbor search with k-nearest neighbor graph
#@ Kiana Hajebi;Yasin Abbasi-Yadkori;Hossein Shahbazi;Hong Zhang
#t 2011
#c 11
#% 61589
#% 249321
#% 309135
#% 317313
#% 319601
#% 592073
#% 760805
#% 1061636
#% 1164853
#% 1385976
#% 1446731
#% 1739422
#! We introduce a new nearest neighbor search algorithm. The algorithm builds a nearest neighbor graph in an offline phase and when queried with a new point, performs hill-climbing starting from a randomly sampled node of the graph. We provide theoretical guarantees for the accuracy and the computational complexity and empirically show the effectiveness of this algorithm.

#index 1826273
#* Gaussianity measures for detecting the direction of causal time series
#@ José Miguel Hernández-Lobato;Pablo Morales-Mombiela;Alberto Suárez
#t 2011
#c 11
#% 13453
#% 1100645
#% 1211790
#% 1267791
#% 1472280
#! We conjecture that the distribution of the time-reversed residuals of a causal linear process is closer to a Gaussian than the distribution of the noise used to generate the process in the forward direction. This property is demonstrated for causal AR(1) processes assuming that all the cumulants of the distribution of the noise are defined. Based on this observation, it is possible to design a decision rule for detecting the direction of time series that can be described as linear processes: The correct direction (forward in time) is the one in which the residuals from a linear fit to the time series are less Gaussian. A series of experiments with simulated and real-world data illustrate the superior results of the proposed rule when compared with other state-of-the-art methods based on independence tests.

#index 1826274
#* Feature selection via joint embedding learning and sparse regression
#@ Chenping Hou;Feiping Nie;Dongyun Yi;Yi Wu
#t 2011
#c 11
#% 593047
#% 629628
#% 771842
#% 983948
#% 1270195
#% 1451172
#% 1474964
#! The problem of feature selection has aroused considerable research interests in the past few years. Traditional learning based feature selection methods separate embedding learning and feature ranking. In this paper, we introduce a novel unsupervised feature selection approach via Joint Embedding Learning and Sparse Regression (JELSR). Instead of simply employing the graph laplacian for embedding learning and then regression, we use the weight via locally linear approximation to construct graph and unify embedding learning and sparse regression to perform feature selection. By adding the l2,1-norm regularization, we can learn a sparse matrix for feature ranking. We also provide an effective method to solve the proposed problem. Compared with traditional unsupervised feature selection methods, our approach could integrate the merits of embedding learning and sparse regression simultaneously. Plenty of experimental results are provided to show the validity.

#index 1826275
#* Heuristic rule-based regression via dynamic reduction to classification
#@ Frederik Janssen;Johannes Fürnkranz
#t 2011
#c 11
#% 226438
#% 277919
#% 449566
#% 477579
#% 478279
#% 486623
#% 550575
#% 768632
#% 799042
#% 961134
#% 1104086
#% 1272177
#% 1350668
#% 1742013
#! In this paper, we propose a novel approach for learning regression rules by transforming the regression problem into a classification problem. Unlike previous approaches to regression by classification, in our approach the discretization of the class variable is tightly integrated into the rule learning algorithm. The key idea is to dynamically define a region around the target value predicted by the rule, and considering all examples within that region as positive and all examples outside that region as negative. In this way, conventional rule learning heuristics may be used for inducing regression rules. Our results show that our heuristic algorithm outperforms approaches that use a static discretization of the target variable, and performs en par with other comparable rule-based approaches, albeit without reaching the performance of statistical approaches.

#index 1826276
#* Adaptation of a mixture of multivariate Bernoulli distributions
#@ Ankur Kamthe;Miguel Á. Carreira-Perpinñán;Alberto E. Cerpa
#t 2011
#c 11
#% 118893
#% 267027
#% 857458
#% 1290944
#% 1831092
#! The mixture of multivariate Bernoulli distributions (MMB) is a statistical model for high-dimensional binary data in widespread use. Recently, the MMB has been used to model the sequence of packet receptions and losses of wireless links in sensor networks. Given an MMB trained on long data traces recorded from links of a deployed network, one can then use samples from the MMB to test different routing algorithms for as long as desired. However, learning an accurate model for a new link requires collecting from it long traces over periods of hours, a costly process in practice (e.g. limited battery life). We propose an algorithm that can adapt a preexisting MMB trained with extensive data to a new link from which very limited data is available. Our approach constrains the new MMB's parameters through a nonlinear transformation of the existing MMB's parameters. The transformation has a small number of parameters that are estimated using a generalized EM algorithm with an inner loop of BFGS iterations. We demonstrate the efficacy of the approach using the MNIST dataset of handwritten digits, and wireless link data from a sensor network. We show we can learn accurate models from data traces of about 1 minute, about 10 times shorter than needed if training an MMB from scratch.

#index 1826277
#* Revisiting numerical pattern mining with formal concept analysis
#@ Mehdi Kaytoue;Sergei O. Kuznetsov;Amedeo Napoli
#t 2011
#c 11
#% 210160
#% 338594
#% 429873
#% 565484
#% 1250571
#% 1388769
#% 1549710
#! We investigate the problem of mining numerical data with Formal Concept Analysis. The usual way is to use a scaling procedure -transforming numerical attributes into binary ones- leading either to a loss of information or of efficiency, in particular w.r.t. the volume of extracted patterns. By contrast, we propose to directlywork on numerical data in a more precise and efficient way. For that, the notions of closed patterns, generators and equivalent classes are revisited in the numerical context. Moreover, two algorithms are proposed and tested in an evaluation involving real-world data, showing the quality of the present approach.

#index 1826278
#* Activity recognition with finite state machines
#@ Wesley Kerr;Anh Tran;Paul Cohen
#t 2011
#c 11
#% 296534
#% 319244
#% 481290
#% 481611
#% 661873
#% 737988
#% 871048
#% 903616
#% 980988
#% 992857
#% 1063499
#% 1310498
#% 1605608
#! This paper shows how to learn general, Finite State Machine representations of activities that function as recognizers of previously unseen instances of activities. The central problem is to tell which differences between instances of activities are unimportant and may be safely ignored for the purpose of learning generalized representations of activities. We develop a novel way to find the "essential parts" of activities by a greedy kind of multiple sequence alignment, and a method to transform the resulting alignments into Finite State Machine that will accept novel instances of activities with high accuracy.

#index 1826279
#* Incremental slow feature analysis
#@ Varun Raj Kompella;Matthew Luciw;Jürgen Schmidhuber
#t 2011
#c 11
#% 131085
#% 348544
#% 450248
#% 719278
#% 994432
#! The Slow Feature Analysis (SFA) unsupervised learning framework extracts features representing the underlying causes of the changes within a temporally coherent high-dimensional raw sensory input signal. We develop the first online version of SFA, via a combination of incremental Principal Components Analysis and Minor Components Analysis. Unlike standard batch-based SFA, online SFA adapts along with non-stationary environments, which makes it a generally useful unsupervised preprocessor for autonomous learning agents. We compare online SFA to batch SFA in several experiments and show that it indeed learns without a teacher to encode the input stream by informative slow features representing meaningful abstract environmental properties. We extend online SFA to deep networks in hierarchical fashion, and use them to successfully extract abstract object position information from high-dimensional video.

#index 1826280
#* Learning hash functions for cross-view similarity search
#@ Shaishav Kumar;Raghavendra Udupa
#t 2011
#c 11
#% 228351
#% 264161
#% 312072
#% 347225
#% 855563
#% 898309
#% 1019136
#% 1040539
#% 1077150
#% 1181094
#% 1215859
#% 1338683
#% 1470635
#% 1481560
#% 1481657
#! Many applications in Multilingual and Multimodal Information Access involve searching large databases of high dimensional data objects with multiple (conditionally independent) views. In this work we consider the problem of learning hash functions for similarity search across the views for such applications. We propose a principled method for learning a hash function for each view given a set of multiview training data objects. The hash functions map similar objects to similar codes across the views thus enabling cross-view similarity search. We present results from an extensive empirical study of the proposed approach which demonstrate its effectiveness on Japanese language People Search and Multilingual People Search problems.

#index 1826281
#* Modular community detection in networks
#@ Wenye Li;Dale Schuurmans
#t 2011
#c 11
#% 296738
#% 313959
#% 868089
#% 881685
#% 1399996
#% 1425621
#! Network community detection--the problem of dividing a network of interest into clusters for intelligent analysis--has recently attracted significant attention in diverse fields of research. To discover intrinsic community structure a quantitative measure called modularity has been widely adopted as an optimization objective. Unfortunately, modularity is inherently NP-hard to optimize and approximate solutions must be sought if tractability is to be ensured. In practice, a spectral relaxationmethod is most often adopted, after which a community partition is recovered from relaxed fractional values by a rounding process. In this paper, we propose an iterative rounding strategy for identifying the partition decisions that is coupled with a fast constrained power method that sequentially achieves tighter spectral relaxations. Extensive evaluation with this coupled relaxation-rounding method demonstrates consistent and sometimes dramatic improvements in the modularity of the communities discovered.

#index 1826282
#* Probit classifiers with a generalized Gaussian scale mixture prior
#@ Guoqing Liu;Jianxin Wu;Suiping Zhou
#t 2011
#c 11
#% 331916
#% 721164
#% 722760
#% 957325
#% 1073883
#% 1302141
#! Most of the existing probit classifiers are based on sparsity-oriented modeling. However, we show that sparsity is not always desirable in practice, and only an appropriate degree of sparsity is profitable. In this work, we propose a flexible probabilistic model using a generalized Gaussian scale mixture prior that can promote an appropriate degree of sparsity for its model parameters, and yield either sparse or non-sparse estimates according to the intrinsic sparsity of features in a dataset. Model learning is carried out by an efficient modified maximum a posteriori (MAP) estimate. We also show relationships of the proposed model to existing probit classifiers as well as iteratively re-weighted l1 and l2 minimizations. Experiments demonstrate that the proposed method has better or comparable performances in feature selection for linear classifiers as well as in kernel-based classification.

#index 1826283
#* Locality-constrained concept factorization
#@ Haifeng Liu;Zheng Yang;Zhaohui Wu
#t 2011
#c 11
#% 766432
#% 791402
#% 793248
#% 1573152
#! Matrix factorization based techniques, such as non-negative matrix factorization (NMF) and concept factorization (CF), have attracted great attention in dimension reduction and data clustering. Both of them are linear learning problems and lead to a sparse representation of the data. However, the sparsity obtained by these methods does not always satisfy locality conditions, thus the obtained data representation is not the best. This paper introduces a locality-constrained concept factorization method which imposes a locality constraint onto the traditional concept factorization. By requiring the concepts (basis vectors) to be as close to the original data points as possible, each data can be represented by a linear combination of only a few basis concepts. Thus our method is able to achieve sparsity and locality at the same time. We demonstrate the effectiveness of this novel algorithm through a set of evaluations on real world applications.

#index 1826284
#* Cluster indicator decomposition for efficient matrix factorization
#@ Dijun Luo;Chris Ding;Heng Huang
#t 2011
#c 11
#% 345848
#% 453490
#% 732552
#% 784995
#% 789800
#% 840839
#% 881468
#% 1074026
#% 1318664
#! We propose a new clustering based low-rank matrix approximation method, Cluster Indicator Decomposition (CID), which yields more accurate low-rank approximations than previous commonly used singular value decomposition and other Nyström style decompositions. Our model utilizes the intrinsic structures of data and theoretically be more compact and accurate than the traditional low rank approximation approaches. The reconstruction in CID is extremely fast leading to a desirable advantage of our method in large-scale kernel machines (like Support Vector Machines) in which the reconstruction of the kernels needs to be frequently computed. Experimental results indicate that our approach compress images much more efficiently than other factorization based methods. We show that combining our method with Support Vector Machines obtains more accurate approximation and more accurate prediction while consuming much less computation resources.

#index 1826285
#* Ball ranking machines for content-based multimedia retrieval
#@ Dijun Luo;Heng Huang
#t 2011
#c 11
#% 57484
#% 190581
#% 269217
#% 269218
#% 309095
#% 345848
#% 577224
#% 579234
#% 734915
#% 803575
#% 840846
#% 983918
#% 1037922
#% 1269502
#! In this paper, we propose the new Ball Ranking Machines (BRMs) to address the supervised ranking problems. In previous work, supervised ranking methods have been successfully applied in various information retrieval tasks. Among these methodologies, the Ranking Support Vector Machines (Rank SVMs) are well investigated. However, one major fact limiting their applications is that Ranking SVMs need optimize a margin-based objective function over all possible document pairs within all queries on the training set. In consequence, Ranking SVMs need select a large number of support vectors among a huge number of support vector candidates. This paper introduces a new model of of Ranking SVMs and develops an efficient approximation algorithm, which decreases the training time and generates much fewer support vectors. Empirical studies on synthetic data and content-based image/video retrieval data show that our method is comparable to Ranking SVMs in accuracy, but use much fewer ranking support vectors and significantly less training time.

#index 1826286
#* Combining supervised and unsupervised models via unconstrained probabilistic embedding
#@ Xudong Ma;Ping Luo;Fuzhen Zhuang;Qing He;Zhongzhi Shi;Zhiyong Shen
#t 2011
#c 11
#% 73441
#% 420495
#% 722902
#% 770836
#% 1083664
#! Ensemble learning with output from multiple supervised and unsupervised models aims to improve the classification accuracy of supervised model ensemble by jointly considering the grouping results from unsupervised models. In this paper we cast this ensemble task as an unconstrained probabilistic embedding problem. Specifically, we assume both objects and classes/clusters have latent coordinates without constraints in a D-dimensional Euclidean space, and consider the mapping from the embedded space into the space of results from supervised and unsupervised models as a probabilistic generative process. The prediction of an object is then determined by the distances between the object and the classes in the embedded space. A solution of this embedding can be obtained using the quasi-Newton method, resulting in the objects and classes/clusters with high co-occurrence weights being embedded close. We demonstrate the benefits of this unconstrained embedding method by three real applications.

#index 1826287
#* Agent-oriented incremental team and activity recognition
#@ Daniele Masato;Timothy J. Norman;Wamberto W. Vasconcelos;Katia Sycara
#t 2011
#c 11
#% 251365
#% 270134
#% 464434
#% 890297
#% 946811
#% 953324
#% 1024911
#% 1031851
#% 1270313
#% 1305471
#% 1305501
#! Monitoring team activity is beneficial when human teams cooperate in the enactment of a joint plan. Monitoring allows teams to maintain awareness of each other's progress within the plan and it enables anticipation of information needs. Humans find this difficult, particularly in time-stressed and uncertain environments. In this paper we introduce a probabilistic model, based on Conditional Random Fields, to automatically recognise the composition of teams and the team activities in relation to a plan. The team composition and activities are recognised incrementally by interpreting a stream of spatio-temporal observations.

#index 1826288
#* Multi-kernel Gaussian processes
#@ Arman Melkumyan;Fabio Ramos
#t 2011
#c 11
#% 236497
#% 829014
#% 891549
#% 1305599
#! Multi-task learning remains a difficult yet important problem in machine learning. In Gaussian processes the main challenge is the definition of valid kernels (covariance functions) able to capture the relationships between different tasks. This paper presents a novel methodology to construct valid multi-task covariance functions (Mercer kernels) for Gaussian processes allowing for a combination of kernels with different forms. The method is based on Fourier analysis and is general for arbitrary stationary covariance functions. Analytical solutions for cross covariance terms between popular forms are provided including Matérn, squared exponential and sparse covariance functions. Experiments are conducted with both artificial and real datasets demonstrating the benefits of the approach.

#index 1826289
#* Imitation learning in relational domains: a functional-gradient boosting approach
#@ Sriraam Natarajan;Saket Joshi;Prasad Tadepalli;Kristian Kersting;Jude Shavlik
#t 2011
#c 11
#% 126926
#% 289949
#% 295957
#% 370528
#% 464296
#% 466418
#% 770823
#% 770850
#% 770852
#% 788062
#% 875974
#% 876036
#% 936866
#% 1000502
#% 1073929
#% 1176872
#% 1187663
#% 1225134
#% 1272089
#% 1289241
#% 1415877
#% 1417310
#% 1469430
#% 1650413
#% 1665139
#% 1693530
#! Imitation learning refers to the problem of learning how to behave by observing a teacher in action. We consider imitation learning in relational domains, in which there is a varying number of objects and relations among them. In prior work, simple relational policies are learned by viewing imitation learning as supervised learning of a function from states to actions. For propositional worlds, functional gradient methods have been proved to be beneficial. They are simpler to implement than most existing methods, more efficient, more naturally satisfy common constraints on the cost function, and better represent our prior beliefs about the form of the function. Building on recent generalizations of functional gradient boosting to relational representations, we implement a functional gradient boosting approach to imitation learning in relational domains. In particular, given a set of traces from the human teacher, our system learns a policy in the form of a set of relational regression trees that additively approximate the functional gradients. The use of multiple additive trees combined with relational representation allows for learning more expressive policies than what has been done before. We demonstrate the usefulness of our approach in several different domains.

#index 1826290
#* Positive unlabeled learning for time series classification
#@ Minh Nhut Nguyen;Xiao-Li Li;See-Kiong Ng
#t 2011
#c 11
#% 443984
#% 464641
#% 564957
#% 643518
#% 715296
#% 821868
#% 837604
#% 876074
#% 881545
#% 972280
#% 1000760
#% 1275203
#% 1279298
#% 1455666
#% 1707850
#! In many real-world applications of the time series classification problem, not only could the negative training instances be missing, the number of positive instances available for learning may also be rather limited. This has motivated the development of new classification algorithms that can learn from a small set P of labeled seed positive instances augmented with a set U of unlabeled instances (i.e. PU learning algorithms). However, existing PU learning algorithms for time series classification have less than satisfactory performance as they are unable to identify the class boundary between positive and negative instances accurately. In this paper, we propose a novel PU learning algorithm LCLC (Learning from Common Local Clusters) for time series classification. LCLC is designed to effectively identify the ground truths' positive and negative boundaries, resulting in more accurate classifiers than those constructed using existing methods. We have applied LCLC to classify time series data from different application domains; the experimental results demonstrate that LCLC out-performs existing methods significantly.

#index 1826291
#* Distribution-aware online classifiers
#@ Tam T. Nguyen;Kuiyu Chang;Siu Cheung Hui
#t 2011
#c 11
#% 197394
#% 801566
#% 961152
#% 983815
#% 1073905
#% 1073927
#% 1108844
#% 1338580
#% 1535408
#% 1699617
#! We propose a family of Passive-Aggressive Mahalanobis (PAM) algorithms, which are incremental (online) binary classifiers that consider the distribution of data. PAM is in fact a generalization of the Passive-Aggressive (PA) algorithms to handle data distributions that can be represented by a covariance matrix. The update equations for PAM are derived and theoretical error loss bounds computed. We benchmarked PAM against the original PA-I, PA-II, and ConfidenceWeighted (CW) learning. Although PAM somewhat resembles CWin its update equations, PA minimizes differences in the weights while CWminimizes differences in weight distributions. Results on 8 classification datasets, which include a real-lifemicro-blog sentiment classification task, show that PAM consistently outperformed its competitors, most notably CW. This shows that a simple approach like PAM is more practical in real-life classification tasks, compared to more sophisticated approaches like CW.

#index 1826292
#* Robust principal component analysis with non-greedy l1-norm maximization
#@ Feiping Nie;Heng Huang;Chris Ding;Dijun Luo;Hua Wang
#t 2011
#c 11
#% 30518
#% 266426
#% 444001
#% 576580
#% 757953
#% 812400
#% 875980
#% 1086226
#% 1116396
#% 1279799
#% 1373023
#% 1474237
#% 1474964
#% 1815965
#% 1858998
#! Principal Component Analysis (PCA) is one of the most important methods to handle high-dimensional data. However, the high computational complexity makes it hard to apply to the large scale data with high dimensionality, and the used l2-norm makes it sensitive to outliers. A recent work proposed principal component analysis based on l1-normmaximization, which is efficient and robust to outliers. In that work, a greedy strategy was applied due to the difficulty of directly solving the l1-norm maximization problem, which is easy to get stuck in local solution. In this paper, we first propose an efficient optimization algorithmto solve a general l1-norm maximization problem, and then propose a robust principal component analysis with non-greedy l1-norm maximization. Experimental results on real world datasets show that the nongreedy method always obtains much better solution than that of the greedy method.

#index 1826293
#* Biclustering-driven ensemble of Bayesian belief network classifiers for underdetermined problems
#@ Tatdow Pansombut;William Hendrix;Zekai J. Gao;Brent E. Harrison;Nagiza F. Samatova
#t 2011
#c 11
#% 73372
#% 129987
#% 209021
#% 256615
#% 397632
#% 424997
#% 469422
#% 716892
#% 729932
#% 830651
#% 832775
#% 871052
#% 906512
#% 1095860
#% 1250171
#% 1270209
#% 1279286
#% 1314713
#% 1345852
#% 1360167
#% 1777496
#! In this paper, we present BENCH (Biclustering-driven ENsemble of Classifiers), an algorithm to construct an ensemble of classifiers through concurrent feature and data point selection guided by unsupervised knowledge obtained from biclustering. BENCH is designed for underdetermined problems. In our experiments, we use Bayesian Belief Network (BBN) classifiers as base classifiers in the ensemble; however, BENCH can be applied to other classification models as well. We show that BENCH is able to increase prediction accuracy of a single classifier and traditional ensemble of classifiers by up to 15% on three microarray datasets using various weighting schemes for combining individual predictions in the ensemble.

#index 1826294
#* Strategy learning for autonomous agents in smart grid markets
#@ Prashant P. Reddy;Manuela M. Veloso
#t 2011
#c 11
#% 124691
#% 1130330
#! Distributed electricity producers, such as small wind farms and solar installations, pose several technical and economic challenges in Smart Grid design. One approach to addressing these challenges is through Broker Agents who buy electricity from distributed producers, and also sell electricity to consumers, via a Tariff Market-a new market mechanism where Broker Agents publish concurrent bid and ask prices. We investigate the learning of pricing strategies for an autonomous Broker Agent to profitably participate in a Tariff Market. We employ Markov Decision Processes (MDPs) and reinforcement learning. An important concern with this method is that even simple representations of the problem domain result in very large numbers of states in the MDP formulation because market prices can take nearly arbitrary real values. In this paper, we present the use of derived state space features, computed using statistics on Tariff Market prices and Broker Agent customer portfolios, to obtain a scalable state representation. We also contribute a set of pricing tactics that form building blocks in the learned Broker Agent strategy. We further present a Tariff Market simulation model based on real-world data and anticipated market dynamics. We use this model to obtain experimental results that show the learned strategy performing vastly better than a random strategy and significantly better than two other non-learning strategies.

#index 1826295
#* Q-error as a selection mechanism in modular reinforcement-learning systems
#@ Mark Ring;Tom Schaul
#t 2011
#c 11
#% 124694
#% 154030
#% 252330
#% 272374
#% 286423
#% 384911
#% 449447
#% 449561
#% 465704
#% 466235
#% 476730
#% 734920
#% 735500
#% 1022821
#% 1271827
#% 1271833
#! This paper introduces a novel multimodular method for reinforcement learning. A multimodular system is one that partitions the learning task among a set of experts (modules), where each expert is incapable of solving the entire task by itself. There are many advantages to splitting up large tasks in this way, but existing methods face difficulties when choosing which module(s) should contribute to the agent's actions at any particular moment. We introduce a novel selection mechanism where every module, besides calculating a set of action values, also estimates its own error for the current input. The selection mechanism combines each module's estimate of long-term reward and self-error to produce a score by which the next module is chosen. As a result, the modules can use their resources effectively and efficiently divide up the task. The system is shown to learn complex tasks even when the individual modules use only linear function approximators.

#index 1826296
#* Domain adaptation with ensemble of feature groups
#@ Rajhans Samdani;Wen-Tau Yih
#t 2011
#c 11
#% 823397
#% 854646
#% 940000
#% 983828
#% 1083634
#% 1261539
#% 1270716
#% 1377382
#% 1385982
#% 1481610
#! We present a novel approach for domain adaptation based on feature grouping and re-weighting. Our algorithm operates by creating an ensemble of multiple classifiers, where each classifier is trained on one particular feature group. Faced with the distribution change involved in domain change, different feature groups exhibit different cross-domain prediction abilities. Herein, ensemble models provide us the flexibility of tuning the weights of corresponding classifiers in order to adapt to the new domain. Our approach is supported by a solid theoretical analysis based on the expressiveness of ensemble classifiers, which allows trading-off errors across source and target domains. Moreover, experimental results on sentiment classification and spam detection show that our approach not only outperforms the baseline method, but is also superior to other state-of-the-art methods.

#index 1826297
#* Discovering deformable motifs in continuous time series data
#@ Suchi Saria;Andrew Duchi;Daphne Koller
#t 2011
#c 11
#% 287568
#% 629629
#% 729960
#% 844297
#% 1226596
#% 1269767
#% 1584083
#! Continuous time series data often comprise or contain repeated motifs -- patterns that have similar shape, and yet exhibit nontrivial variability. Identifying these motifs, even in the presence of variation, is an important subtask in both unsupervised knowledge discovery and constructing useful features for discriminative tasks. This paper addresses this task using a probabilistic framework that models generation of data as switching between a random walk state and states that generate motifs. A motif is generated from a continuous shape template that can undergo non-linear transformations such as temporal warping and additive noise. We propose an unsupervised algorithm that simultaneously discovers both the set of canonical shape templates and a template-specific model of variability manifested in the data. Experimental results on three real-world data sets demonstrate that our model is able to recover templates in data where repeated instances show large variability. The recovered templates provide higher classification accuracy and coverage when compared to those from alternatives such as random projection based methods and simpler generative models that do not model variability. Moreover, in analyzing physiological signals from infants in the ICU, we discover both known signatures as well as novel physiomarkers.

#index 1826298
#* A general MCMC method for Bayesian inference in logic-based probabilistic modeling
#@ Taisuke Sato
#t 2011
#c 11
#% 424830
#% 1000502
#% 1225211
#% 1269504
#% 1271907
#% 1272388
#% 1289565
#% 1416198
#% 1607839
#! We propose a generalMCMC method for Bayesian inference in logic-based probabilistic modeling. It covers a broad class of generativemodels including Bayesian networks and PCFGs. The idea is to generalize an MCMC method for PCFGs to the one for a Turing-complete probabilistic modeling language PRISM in the context of statistical abduction where parse trees are replaced with explanations. We describe how to estimate the marginal probability of data from MCMC samples and how to perform Bayesian Viterbi inference using an example of Naive Bayesmodel augmentedwith a hidden variable.

#index 1826299
#* Classification of emerging extreme event tracks in multivariate spatio-temporal physical systems using dynamic network structures: application to hurricane track prediction
#@ Huseyin Sencan;Zhengzhang Chen;William Hendrix;Tatdow Pansombut;Frederick Semazzi;Alok Choudhary;Vipin Kumar;Anatoli V. Melechko;Nagiza F. Samatova
#t 2011
#c 11
#% 136350
#% 197394
#% 256615
#% 400847
#% 425048
#% 466644
#% 478274
#% 629708
#% 830651
#! Understanding extreme events, such as hurricanes or forest fires, is of paramount importance because of their adverse impacts on human beings. Such events often propagate in space and time. Predicting--even a few days in advance--what locations will get affected by the event tracks could benefit our society in many ways. Arguably, simulations from first principles, where underlying physics-based models are described by a system of equations, provide least reliable predictions for variables characterizing the dynamics of these extreme events. Data-driven model building has been recently emerging as a complementary approach that could learn the relationships between historically observed or simulated multiple, spatio-temporal ancillary variables and the dynamic behavior of extreme events of interest. While promising, the methodology for predictive learning from such complex data is still in its infancy. In this paper, we propose a dynamic networks-based methodology for in-advance prediction of the dynamic tracks of emerging extreme events. By associating a network model of the system with the known tracks, our method is capable of learning the recurrent network motifs that could be used as discriminatory signatures for the event's behavioral class. When applied to classifying the behavior of the hurricane tracks at their early formation stages inWestern Africa region, our method is able to predict whether hurricane tracks will hit the land of the North Atlantic region at least 10-15 days lead lag time in advance with more than 90% accuracy using 10-fold cross-validation. To the best of our knowledge, no comparable methodology exists for solving this problem using data-driven models

#index 1826300
#* Active surveying: a probabilistic approach for identifying key opinion leaders
#@ Hossam Sharara;Lise Getoor;Myra Norton
#t 2011
#c 11
#% 169717
#% 341269
#% 466231
#% 729923
#% 735358
#! Opinion leaders play an important role in influencing people's beliefs, actions and behaviors. Although a number of methods have been proposed for identifying influentials using secondary sources of information, the use of primary sources, such as surveys, is still favored in many domains. In this work we present a new surveying method which combines secondary data with partial knowledge from primary sources to guide the information gathering process. We apply our proposed active surveying method to the problem of identifying key opinion leaders in the medical field, and show how we are able to accurately identify the opinion leaders while minimizing the amount of primary data required, which results in significant cost reduction in data acquisition without sacrificing its integrity.

#index 1826301
#* Consistency measures for feature selection: a formal definition, relative sensitivity comparison and a fast algorithm
#@ Kilho Shin;Danny Fernandes;Seiya Miyazaki
#t 2011
#c 11
#% 169659
#% 366687
#% 458371
#% 466410
#% 629619
#% 926881
#% 1058802
#% 1274940
#% 1331668
#! Consistency-based feature selection is an important category of feature selection research yet is defined only intuitively in the literature. First, we formally define a consistency measure, and then using this definition, evaluate 19 feature selection measures from the literature. While only 5 of these were labeled as consistency measures by their original authors, by our definition, an additional 9 measures should be classified as consistency measures. To compare these 14 consistency measures in terms of sensitivity, we introduce the concept of quasi-linear compatibility order, and partially determine the order among the measures. Next, we propose a new fast algorithm for consistency-based feature selection. We ran experiments using eleven large datasets to compare the performance of our algorithm against INTERACT and LCC, the only two instances of consistency-based algorithms with potential real world application. Our algorithm shows vast improvement in time efficiency, while its performance in accuracy is comparable with that of INTERACT and LCC.

#index 1826302
#* Active online classification via information maximization
#@ Noam Slonim;Elad Yom-Tov;Koby Crammer
#t 2011
#c 11
#% 169717
#% 236729
#% 302390
#% 350859
#% 375017
#% 397139
#% 729437
#% 763708
#% 789855
#% 878207
#% 961152
#% 961177
#% 1073905
#% 1338580
#! We propose an online classification approach for co-occurrence data which is based on a simple information theoretic principle. We further show how to properly estimate the uncertainty associated with each prediction of our scheme and demonstrate how to exploit these uncertainty estimates. First, in order to abstain highly uncertain predictions. And second, within an active learning framework, in order to preserve classification accuracy while substantially reducing training set size. Our method is highly efficient in terms of run-time and memory footprint requirements. Experimental results in the domain of text classification demonstrate that the classification accuracy of our method is superior or comparable to other state-of-the-art online classification algorithms.

#index 1826303
#* Angular decomposition
#@ Dengdi Sun;Chris Ding;Bin Luo;Jin Tang
#t 2011
#c 11
#% 593047
#% 722818
#% 729437
#% 770830
#% 790049
#% 913838
#% 1318664
#% 1495503
#! Dimensionality reduction plays a vital role in pattern recognition. However, for normalized vector data, existing methods do not utilize the fact that the data is normalized. In this paper, we propose to employ an Angular Decomposition of the normalized vector data which corresponds to embedding them on a unit surface. On graph data for similarity/ kernel matrices with constant diagonal elements, we propose the Angular Decomposition of the similarity matrices which corresponds to embedding objects on a unit sphere. In these angular embeddings, the Euclidean distance is equivalent to the cosine similarity. Thus data structures best described in the cosine similarity and data structures best captured by the Euclidean distance can both be effectively detected in our angular embedding. We provide the theoretical analysis, derive the computational algorithm, and evaluate the angular embedding on several datasets. Experiments on data clustering demonstrate that our method can provide a more discriminative subspace.

#index 1826304
#* Fast anomaly detection for streaming data
#@ Swee Chuan Tan;Kai Ming Ting;Tony Fei Liu
#t 2011
#c 11
#% 310500
#% 342600
#% 349550
#% 400847
#% 574604
#% 729912
#% 866326
#% 881506
#% 889260
#% 893104
#% 1000334
#% 1176944
#% 1202160
#% 1210659
#% 1214635
#% 1451239
#! This paper introduces Streaming Half-Space-Trees (HS-Trees), a fast one-class anomaly detector for evolving data streams. It requires only normal data for training and works well when anomalous data are rare. The model features an ensemble of random HS-Trees, and the tree structure is constructed without any data. This makes the method highly efficient because it requires no model restructuring when adapting to evolving data streams. Our analysis shows that Streaming HS-Trees has constant amortised time complexity and constant memory requirement. When compared with a state-of-the-art method, our method performs favourably in terms of detection accuracy and runtime performance. Our experimental results also show that the detection performance of Streaming HS-Trees is not sensitive to its parameter settings.

#index 1826305
#* Utility-based fraud detection
#@ Luis Torgo;Elsa Lopes
#t 2011
#c 11
#% 300136
#% 311027
#% 420064
#% 1550123
#! Fraud detection is a key activity with serious socio-economical impact. Inspection activities associated with this task are usually constrained by limited available resources. Data analysis methods can provide help in the task of deciding where to allocate these limited resources in order to optimise the outcome of the inspection activities. This paper presents a multi-strategy learning method to address the question of which cases to inspect first. The proposed methodology is based on the utility theory and provides a ranking ordered by decreasing expected outcome of inspecting the candidate cases. This outcome is a function not only of the probability of the case being fraudulent but also of the inspection costs and expected payoff if the case is confirmed as a fraud. The proposed methodology is general and can be useful on fraud detection activities with limited inspection resources. We experimentally evaluate our proposal on both an artificial domain and on a real world task.

#index 1826306
#* On the utility of curricula in unsupervised learning of probabilistic grammars
#@ Kewei Tu;Vasant Honavar
#t 2011
#c 11
#% 279755
#% 938713
#% 1211695
#% 1470678
#! We examine the utility of a curriculum (a means of presenting training samples in a meaningful order) in unsupervised learning of probabilistic grammars. We introduce the incremental construction hypothesis that explains the benefits of a curriculum in learning grammars and offers some useful insights into the design of curricula as well as learning algorithms. We present results of experiments with (a) carefully crafted synthetic data that provide support for our hypothesis and (b) natural language corpus that demonstrate the utility of curricula in unsupervised learning of probabilistic grammars.

#index 1826307
#* Learning driving behavior by timed syntactic pattern recognition
#@ Sicco Verwer;Mathijs De Weerdt;Cees Witteveen
#t 2011
#c 11
#% 162493
#% 331001
#% 359443
#% 443515
#% 891559
#% 1195435
#% 1354495
#% 1378363
#% 1493804
#! We advocate the use of an explicit time representation in syntactic pattern recognition because it can result in more succinct models and easier learning problems. We apply this approach to the real-world problem of learning models for the driving behavior of truck drivers. We discretize the values of onboard sensors into simple events. Instead of the common syntactic pattern recognition approach of sampling the signal values at a fixed rate, we model the time constraints using timed models. We learn these models using the RTI+ algorithm from grammatical inference, and show how to use computational mechanics and a form of semi-supervised classification to construct a real-time automaton classifier for driving behavior. Promising results are shown using this new approach.

#index 1826308
#* Bi-weighting domain adaptation for cross-language text classification
#@ Chang Wan;Rong Pan;Jiefei Li
#t 2011
#c 11
#% 115608
#% 466263
#% 832331
#% 983803
#% 983828
#% 983899
#% 1055769
#% 1074012
#% 1214639
#% 1305479
#% 1558464
#! Text classification is widely used in many real-world applications. To obtain satisfied classification performance, most traditional data mining methods require lots of labeled data, which can be costly in terms of both time and human efforts. In reality, there are plenty of such resources in English since it has the largest population in the Internet world, which is not true in many other languages. In this paper, we present a novel transfer learning approach to tackle the cross-language text classification problems. We first align the feature spaces in both domains utilizing some on-line translation service, which makes the two feature spaces under the same coordinate. Although the feature sets in both domains are the same, the distributions of the instances in both domains are different, which violates the i.i.d. assumption in most traditional machine learning methods. For this issue, we propose an iterative feature and instance weighting (Bi-Weighting) method for domain adaptation. We empirically evaluate the effectiveness and efficiency of our approach. The experimental results show that our approach outperforms some baselines including four transfer learning algorithms.

#index 1826309
#* Heterogeneous domain adaptation using manifold alignment
#@ Chang Wang;Sridhar Mahadevan
#t 2011
#c 11
#% 961218
#% 1211726
#% 1227635
#% 1261539
#% 1272110
#% 1456843
#% 1464068
#! We propose a manifold alignment based approach for heterogeneous domain adaptation. A key aspect of this approach is to construct mappings to link different feature spaces in order to transfer knowledge across domains. The new approach can reuse labeled data from multiple source domains in a target domain even in the case when the input domains do not share any common features or instances. As a pre-processing step, our approach can also be combined with existing domain adaptation approaches to learn a common feature space for all input domains. This paper extends existing manifold alignment approaches by making use of labels rather than correspondences to align the manifolds. This extension significantly broadens the application scope of manifold alignment, since the correspondence relationship required by existing alignment approaches is hard to obtain in many applications.

#index 1826310
#* Jointly learning data-dependent label and locality-preserving projections
#@ Chang Wang;Sridhar Mahadevan
#t 2011
#c 11
#% 80995
#% 593047
#% 961218
#! This paper describes a novel framework to jointly learn data-dependent label and locality-preserving projections. Given a set of data instances from multiple classes, the proposed approach can automatically learn which classes are more similar to each other, and construct discriminative features using both labeled and unlabeled data to map similar classes to similar locations in a lower dimensional space. In contrast to linear discriminant analysis (LDA) and its variants, which can only return c-1 features for a problem with c classes, the proposed approach can generate d features, where d is bounded only by the number of the input features. We describe and evaluate the new approach both theoretically and experimentally, and compare its performance with other state of the art methods.

#index 1826311
#* Fast nonnegative matrix tri-factorization for large-scale data co-clustering
#@ Hua Wang;Feiping Nie;Heng Huang;Fillia Makedon
#t 2011
#c 11
#% 342621
#% 770830
#% 881468
#% 881487
#% 1176865
#% 1214657
#% 1305478
#% 1327693
#% 1537112
#! Nonnegative Matrix Factorization (NMF) based coclustering methods have attracted increasing attention in recent years because of their mathematical elegance and encouraging empirical results. However, the algorithms to solve NMF problems usually involve intensive matrix multiplications, which make them computationally inefficient. In this paper, instead of constraining the factor matrices of NMF to be nonnegative as existing methods, we propose a novel Fast Nonnegative Matrix Trifactorization (FNMTF) approach to constrain them to be cluster indicator matrices, a special type of nonnegative matrices. As a result, the optimization problem of our approach can be decoupled, which results in much smaller size subproblems requiring much less matrix multiplications, such that our approach works well for large-scale input data. Moreover, the resulted factor matrices can directly assign cluster labels to data points and features due to the nature of indicator matrices. In addition, through exploiting the manifold structures in both data and feature spaces, we further introduce the Locality Preserved FNMTF (LP-FNMTF) approach, by which the clustering performance is improved. The promising results in extensive experimental evaluations validate the effectiveness of the proposed methods.

#index 1826312
#* Local and structural consistency for multi-manifold clustering
#@ Yong Wang;Yuan Jiang;Yi Wu;Zhi-Hua Zhou
#t 2011
#c 11
#% 278040
#% 308899
#% 313959
#% 723241
#% 790049
#% 836752
#% 837622
#% 1156158
#% 1492077
#% 1667668
#! Data sets containing multi-manifold structures are ubiquitous in real-world tasks, and effective grouping of such data is an important yet challenging problem. Though there were many studies on this problem, it is not clear on how to design principled methods for the grouping of multiple hybrid manifolds. In this paper, we show that spectral methods are potentially helpful for hybrid manifold clustering when the neighborhood graph is constructed to connect the neighboring samples from the same manifold. However, traditional algorithms which identify neighbors according to Euclidean distance will easily connect samples belonging to different manifolds. To handle this drawback, we propose a new criterion, i.e., local and structural consistency criterion, which considers the neighboring information as well as the structural information implied by the samples. Based on this criterion, we develop a simple yet effective algorithm, named Local and Structural Consistency (LSC), for clustering with multiple hybrid manifolds. Experiments show that LSC achieves promising performance.

#index 1826313
#* Bayesian policy search with policy priors
#@ David Wingate;Noah D. Goodman;Daniel M. Roy;Leslie P. Kaelbling;Joshua B. Tenenbaum
#t 2011
#c 11
#% 124687
#% 458377
#% 739673
#% 1270346
#% 1290265
#! We consider the problem of learning to act in partially observable, continuous-state-and-action worlds where we have abstract prior knowledge about the structure of the optimal policy in the form of a distribution over policies. Using ideas from planning-as-inference reductions and Bayesian unsupervised learning, we cast Markov Chain Monte Carlo as a stochastic, hill-climbing policy search algorithm. Importantly, this algorithm's search bias is directly tied to the prior and its MCMC proposal kernels, which means we can draw on the full Bayesian toolbox to express the search bias, including nonparametric priors and structured, recursive processes like grammars over action sequences. Furthermore, we can reason about uncertainty in the search bias itself by constructing a hierarchical prior and reasoning about latent variables that determine the abstract structure of the policy. This yields an adaptive search algorithm--our algorithm learns to learn a structured policy efficiently. We show how inference over the latent variables in these policy priors enables intra- and intertask transfer of abstract knowledge. We demonstrate the flexibility of this approach by learning meta search biases, by constructing a nonparametric finite state controller to model memory, by discovering motor primitives using a simple grammar over primitive actions, and by combining all three.

#index 1826314
#* Learning to rank under multiple annotators
#@ Ou Wu;Weiming Hu;Jun Gao
#t 2011
#c 11
#% 464451
#% 983820
#% 1073931
#% 1074021
#% 1083692
#% 1472273
#! Learning to rank has received great attention in recent years as it plays a crucial role in information retrieval. The existing concept of learning to rank assumes that each training sample is associated with an instance and a reliable label. However, in practice, this assumption does not necessarily hold true. This study focuses on the learning to rank when each training instance is labeled by multiple annotators that may be unreliable. In such a scenario, no accurate labels can be obtained. This study proposes two learning approaches. One is to simply estimate the ground truth first and then to learn a ranking model with it. The second approach is a maximum likelihood learning approach which estimates the ground truth and learns the ranking model iteratively. The two approaches have been tested on both synthetic and real-world data. The results reveal that the maximum likelihood approach outperforms the first approach significantly and is comparable of achieving results with the learning model considering reliable labels. Further more, both the approaches have been applied for ranking the Web visual clutter.

#index 1826315
#* Similarity-based approach for positive and unlabelled learning
#@ Yanshan Xiao;Bo Liu;Jie Yin;Longbing Cao;Chengqi Zhang;Zhifeng Hao
#t 2011
#c 11
#% 169806
#% 344447
#% 464641
#% 727883
#% 729621
#% 843873
#% 855602
#% 1100060
#% 1279298
#% 1326695
#! Positive and unlabelled learning (PU learning) has been investigated to deal with the situation where only the positive examples and the unlabelled examples are available. Most of the previous works focus on identifying some negative examples from the unlabelled data, so that the supervised learning methods can be applied to build a classifier. However, for the remaining unlabelled data, which can not be explicitly identified as positive or negative (we call them ambiguous examples), they either exclude them from the training phase or simply enforce them to either class. Consequently, their performance may be constrained. This paper proposes a novel approach, called similarity-based PU learning (SPUL) method, by associating the ambiguous examples with two similarity weights, which indicate the similarity of an ambiguous example towards the positive class and the negative class, respectively. The local similarity-based and global similarity-based mechanisms are proposed to generate the similarity weights. The ambiguous examples and their similarity-weights are thereafter incorporated into an SVM-based learning phase to build a more accurate classifier. Extensive experiments on real-world datasets have shown that SPUL outperforms state-of-the-art PU learning methods.

#index 1826316
#* Dealing with concept drift and class imbalance in multi-label stream classification
#@ Eleftherios Spyromitros Xioufis;Myra Spiliopoulou;Grigorios Tsoumakas;Ioannis Vlahavas
#t 2011
#c 11
#% 310500
#% 466408
#% 763708
#% 915314
#% 915345
#% 1214654
#% 1267771
#% 1333068
#! Streams of objects that are associated with one or more labels at the same time appear in many applications. However, stream classification of multi-label data is largely unexplored. Existing approaches try to tackle the problem by transferring traditional single-label stream classification practices to the multi-label domain. Nevertheless, they fail to consider some of the unique properties of the problem such as within and between class imbalance and multiple concept drift. To deal with these challenges, this paper proposes a novel multilabel stream classification approach that employs two windows for each label, one for positive and one for negative examples. Instance-sharing is exploited for space efficiency, while a time-efficient instantiation based on the k-Nearest Neighbor algorithm is also proposed. Finally, a batch-incremental thresholding technique is proposed to further deal with the class imbalance problem. Results of an empirical comparison against two other methods on three real world datasets are in favor of the proposed approach.

#index 1826317
#* l2,1-norm regularized discriminative feature selection for unsupervised learning
#@ Yi Yang;Heng Tao Shen;Zhigang Ma;Zi Huang;Xiaofang Zhou
#t 2011
#c 11
#% 80995
#% 336073
#% 443790
#% 722902
#% 729437
#% 789025
#% 876058
#% 983948
#% 1128929
#% 1270195
#% 1417091
#% 1451172
#% 1481247
#% 1750621
#! Compared with supervised learning for feature selection, it is much more difficult to select the discriminative features in unsupervised learning due to the lack of label information. Traditional unsupervised feature selection algorithms usually select the features which best preserve the data distribution, e.g., manifold structure, of the whole feature set. Under the assumption that the class label of input data can be predicted by a linear classifier, we incorporate discriminative analysis and l2,1-norm minimization into a joint framework for unsupervised feature selection. Different from existing unsupervised feature selection algorithms, our algorithm selects the most discriminative feature subset from the whole feature set in batch mode. Extensive experiment on different data types demonstrates the effectiveness of our algorithm.

#index 1826318
#* Matrix co-factorization on compressed sensing
#@ Jiho Yoo;Seungjin Choi
#t 2011
#c 11
#% 135331
#% 643008
#% 818234
#% 987253
#% 1083696
#% 1152754
#% 1260273
#% 1333074
#% 1448345
#% 1815965
#% 1816485
#! In this paper we address the problem of matrix factorization on compressively-sampled measurements which are obtained by random projections. While this approach improves the scalability of matrix factorization, its performance is not satisfactory. We present a matrix co-factorization method where compressed measurements and a small number of uncompressed measurements are jointly decomposed, sharing a factor matrix. We evaluate the performance of three matrix factorization methods in terms of Cramér-Rao bounds, including: (1) matrix factorization on uncompressed data (MF); (2) matrix factorization on compressed data (CS-MF); (3) matrix co-factorization on compressed and uncompressed data (CS-MCF). Numerical experiments demonstrate that CS-MCF improves the performance of CS-MF, emphasizing the useful behavior of exploiting side information (a small number of uncompressed measurements).

#index 1826319
#* Diversity regularized machine
#@ Yang Yu;Yu-Feng Li;Zhi-Hua Zhou
#t 2011
#c 11
#% 697
#% 131165
#% 190581
#% 209021
#% 235377
#% 256615
#% 312727
#% 314785
#% 387653
#% 400847
#% 722806
#% 757953
#% 872759
#% 1229199
#% 1558464
#% 1736158
#% 1781594
#% 1809314
#! Ensemble methods, which train multiple learners for a task, are among the state-of-the-art learning approaches. The diversity of the component learners has been recognized as a key to a good ensemble, and existing ensemble methods try different ways to encourage diversity, mostly by heuristics. In this paper, we propose the diversity regularized machine (DRM) in a mathematical programming framework, which efficiently generates an ensemble of diverse support vector machines (SVMs). Theoretical analysis discloses that the diversity constraint used in DRM can lead to an effective reduction on its hypothesis space complexity, implying that the diversity control in ensemble methods indeed plays a role of regularization as in popular statistical learning approaches. Experiments show that DRM can significantly improve generalization ability and is superior to some state-of-the-art SVM ensemble methods.

#index 1826320
#* LIFT: multi-label learning with label-specific features
#@ Min-Ling Zhang
#t 2011
#c 11
#% 296738
#% 311034
#% 818236
#% 838412
#% 889101
#% 950571
#% 961134
#% 989655
#% 1083666
#% 1095861
#% 1100077
#% 1264044
#% 1267771
#% 1451240
#% 1558464
#! Multi-label learning deals with the problem where each training example is represented by a single instance while associated with a set of class labels. For an unseen example, existing approaches choose to determine the membership of each possible class label to it based on identical feature set, i.e. the very instance representation of the unseen example is employed in the discrimination processes of all labels. However, this commonly-used strategy might be suboptimal as different class labels usually carry specific characteristics of their own, and it could be beneficial to exploit different feature sets for the discrimination of different labels. Based on the above reflection, we propose a new strategy to multi-label learning by leveraging label-specific features, where a simple yet effective algorithm named LIFT is presented. Briefly, LIFT constructs features specific to each label by conducting clustering analysis on its positive and negative instances, and then performs training and testing by querying the clustering results. Extensive experiments across sixteen diversified data sets clearly validate the superiority of LIFT against other well-established multi-label learning algorithms.

#index 1826321
#* Multi-kernel multi-label learning with max-margin concept network
#@ Wei Zhang;Xiangyang Xue;Jianping Fan;Xiaojing Huang;Bin Wu;Mingjie Liu
#t 2011
#c 11
#% 260001
#% 564285
#% 770763
#% 770846
#% 770848
#% 838412
#% 950571
#% 961190
#% 983901
#% 989655
#% 997067
#% 1305472
#% 1305490
#% 1305521
#% 1434058
#% 1454143
#% 1927565
#! In this paper, a novel method is developed for enabling Multi-Kernel Multi-Label Learning. Interlabel dependency and similarity diversity are simultaneously leveraged in the proposed method. A concept network is constructed to capture the inter-label correlations for classifier training. Maximal margin approach is used to effectively formulate the feature-label associations and the labellabel correlations. Specific kernels are learned not only for each label but also for each pair of the inter-related labels. By learning the eigenfunctions of the kernels, the similarity between a new data point and the training samples can be computed in the online mode. Our experimental results on real datasets (web pages, images, music, and bioinformatics) have demonstrated the effectiveness of our method.

#index 1826322
#* Pattern field classification with style normalized transformation
#@ Xu-Yao Zhang;Kaizhu Huang;Cheng-Lin Liu
#t 2011
#c 11
#% 23974
#% 209623
#% 236497
#% 784526
#% 784532
#% 857076
#% 975179
#% 1464068
#% 1645244
#! Field classification is an extension of the traditional classification framework, by breaking the i.i.d. assumption. In field classification, patterns occur as groups (fields) of homogeneous styles. By utilizing style consistency, classifying groups of patterns is often more accurate than classifying single patterns. In this paper, we extend the Bayes decision theory, and develop the Field Bayesian Model (FBM) to deal with field classification. Specifically, we propose to learn a Style Normalized Transformation (SNT) for each field. Via the SNTs, the data of different fields are transformed to a uniform style space (i.i.d. space). The proposed model is a general and systematic framework, under which many probabilistic models can be easily extended for field classification. To transfer the model to unseen styles, we propose a transductive model called Transfer Bayesian Rule (TBR) based on self-training. We conducted extensive experiments on face, speech and a large-scale handwriting dataset, and got significant error rate reduction compared to the state-of-the-art methods.

#index 1826323
#* Finding "unexplained" activities in video
#@ Massimiliano Albanese;Cristian Molinaro;Fabio Persia;Antonio Picariello;V. S. Subrahmanian
#t 2011
#c 11
#% 284558
#% 632422
#% 790610
#% 1275044
#% 1502506
#% 1855842
#% 1856612
#! Consider a video surveillance application that monitors some location. The application knows a set of activity models (that are either normal or abnormal or both), but in addition, the application wants to find video segments that are unexplained by any of the known activity models -- these unexplained video segments may correspond to activities for which no previous activity model existed. In this paper, we formally define what it means for a given video segment to be unexplained (totally or partially) w.r.t. a given set of activity models and a probability threshold. We develop two algorithms - FindTUA and FindPUA - to identify Totally and Partially Unexplained Activities respectively, and show that both algorithms use important pruning methods. We report on experiments with a prototype implementation showing that the algorithms both run efficiently and are accurate.

#index 1826324
#* Explaining genetic knock-out effects using cost-based abduction
#@ Emad A. M. Andrews;Anthony J. Bonner
#t 2011
#c 11
#% 160384
#% 161246
#% 172544
#% 217505
#% 229098
#% 257695
#% 263146
#% 720857
#% 748611
#% 856292
#% 908984
#% 1096520
#% 1336554
#% 1416197
#% 1477086
#! Cost-Based Abduction (CBA) is an AI model for reasoning under uncertainty. In CBA, evidence to be explained is treated as a goal which is true and must be proven. Each proof of the goal is viewed as a feasible explanation and has a cost equal to the sum of the costs of all hypotheses that are assumed to complete the proof. The aim is to find the Least Cost Proof. This paper uses CBA to develop a novel method for modeling Genetic Regulatory Networks (GRN) and explaining genetic knock-out effects. Constructing GRN using multiple data sources is a fundamental problem in computational biology. We show that CBA is a powerful formalism for modeling GRN that can easily and effectively integrate multiple sources of biological data. In this paper, we use three different biological data sources: Protein-DNA, Protein-Protein and gene knock-out data. Using this data, we first create an un-annotated graph; CBA then annotates the graph by assigning a sign and a direction to each edge. Our biological results are promising; however, this manuscript focuses on the mathematical modeling of the application. The advantages of CBA and its relation to Bayesian inference are also presented.

#index 1826325
#* Just an artifact: why machines are perceived as moral agents
#@ Joanna J. Bryson;Philip P. Kime
#t 2011
#c 11
#% 122293
#% 426646
#% 643940
#% 934067
#% 1307841
#% 1310749
#! How obliged can we be to AI, and how much danger does it pose us? A surprising proportion of our society holds exaggerated fears or hopes for AI, such as the fear of robot world conquest, or the hope that AI will indefinitely perpetuate our culture. These misapprehensions are symptomatic of a larger problem--a confusion about the nature and origins of ethics and its role in society. While AI technologies do pose promises and threats, these are not qualitatively different from those posed by other artifacts of our culture which are largely ignored: from factories to advertising, weapons to political systems. Ethical systems are based on notions of identity, and the exaggerated hopes and fears of AI derive from our cultures having not yet accommodated the fact that language and reasoning are no longer uniquely human. The experience of AI may improve our ethical intuitions and self-understanding, potentially helping our societies make better-informed decisions on serious ethical dilemmas.

#index 1826326
#* A hierarchical architecture for adaptive brain-computer interfacing
#@ Mike Chung;Willy Cheung;Reinhold Scherer;Rajesh P. N. Rao
#t 2011
#c 11
#% 891549
#% 1401684
#! Brain-computer interfaces (BCIs) allow a user to directly control devices such as cursors and robots using brain signals. Non-invasive BCIs, e.g., those based on electroencephalographic (EEG) signals recorded from the scalp, suffer from low signal-to-noise ratio which limits the bandwidth of control. Invasive BCIs allow fine-grained control but can leave users exhausted since control is typically exerted on a moment-by-moment basis. In this paper, we address these problems by proposing a new adaptive hierarchical architecture for brain-computer interfacing. The approach allows a user to teach the BCI new skills on-the-fly; these learned skills are later invoked directly as high-level commands, relieving the user of tedious low-level control. We report results from four subjects who used a hierarchical EEG-based BCI to successfully train and control a humanoid robot in a virtual home environment. Gaussian processes were used for learning high-level commands, allowing a BCI to switch between autonomous and user-guided modes based on the current estimate of uncertainty. We also report the first instance of multi-tasking in a BCI, involving simultaneous control of two different devices by a single user. Our results suggest that hierarchical BCIs can provide a flexible and robust way of controlling complex robotic devices in real-world environments.

#index 1826327
#* A neural-symbolic cognitive agent for online learning and reasoning
#@ H. L. H. De Penning;A. S. D'Avila Garcez;Luís C. Lamb;John-Jules C. Meyer
#t 2011
#c 11
#% 92145
#% 198461
#% 427296
#% 450888
#% 492814
#% 1148749
#% 1269801
#% 1335273
#% 1442191
#% 1781663
#! In real-world applications, the effective integration of learning and reasoning in a cognitive agent model is a difficult task. However, such integration may lead to a better understanding, use and construction of more realistic models. Unfortunately, existing models are either oversimplified or require much processing time, which is unsuitable for online learning and reasoning. Currently, controlled environments like training simulators do not effectively integrate learning and reasoning. In particular, higher-order concepts and cognitive abilities have many unknown temporal relations with the data, making it impossible to represent such relationships by hand. We introduce a novel cognitive agent model and architecture for online learning and reasoning that seeks to effectively represent, learn and reason in complex training environments. The agent architecture of the model combines neural learning with symbolic knowledge representation. It is capable of learning new hypotheses from observed data, and infer new beliefs based on these hypotheses. Furthermore, it deals with uncertainty and errors in the data using a Bayesian inference model. The validation of the model on real-time simulations and the results presented here indicate the promise of the approach when performing online learning and reasoning in real-world scenarios, with possible applications in a range of areas.

#index 1826328
#* Verifying fault tolerance and self-diagnosability of an autonomous underwater vehicle
#@ Jonathan Ezekiel;Alessio Lomuscio;Levente Molnar;Sandor Veres;Miles Pebody
#t 2011
#c 11
#% 188086
#% 297770
#% 541757
#% 901632
#% 946510
#% 1230304
#% 1326199
#% 1505028
#% 1539963
#! We report the results obtained during the verification of Autosub6000, an autonomous underwater vehicle used for deep oceanic exploration. Our starting point is the Simulink/Matlab engineering model of the submarine, which is discretised by a compiler into a representation suitable for model checking. We assess the ability of the vehicle to function under degraded conditions by injecting faults automatically into the discretised model. The resulting system is analysed by means of the model checker MCMAS, and conclusions are drawn on the system's ability to withstand faults and to perform self-diagnosis and recovery. We present lessons learnt from this and suggest a general method for verifying autonomous vehicles.

#index 1826329
#* OCS-14: you can get occluded in fourteen ways
#@ Prithwijit Guha;Amitabha Mukerjee;K. S. Venkatesh
#t 2011
#c 11
#% 903394
#% 1289155
#! Occlusions are a central phenomenon in multiobject computer vision. However, formal analyses (LOS14, ROC20) proposed in the spatial reasoning literature ignore many distinctions crucial to computer vision, as a result of which these algebras have been largely ignored in vision applications. Two distinctions of relevance to visual computation are (a) whether the occluder is a moving object or part of the static background, and (b) whether the visible part of an object is a connected blob or fragmented. In this work, we develop a formal model of occlusion states that combines these criteria with overlap distinctions modeled in spatial reasoning to come up with a comprehensive set of fourteen occlusion states, which we define as OCS14. Transitions between these occlusion states are an important source of information on visual activity (e.g. splits and merges). We show that the resulting formalism is representationally complete in the sense that these states constitute a partition of all possible occlusion situations based on these criteria. Finally, we show results from implementations of this approach in a test application involving static camera based scene analysis, where occlusion state analysis and multiple object tracking can be used for two tasks - (a) identifying static occluders, and (b) modeling a class of interactions represented as transitions of occlusion states. Thus, the formalism is shown to have direct relevance to actual vision applications.

#index 1826330
#* Effective and efficient microprocessor design space exploration using unlabeled design configurations
#@ Qi Guo;Tianshi Chen;Yunji Chen;Zhi-Hua Zhou;Weiwu Hu;Zhiwei Xu
#t 2011
#c 11
#% 252011
#% 438538
#% 644169
#% 870993
#% 896772
#% 961145
#% 1100081
#% 1113093
#% 1185788
#% 1209575
#% 1269479
#% 1269502
#% 1289496
#% 1326643
#% 1473497
#! During the design of a microprocessor, Design Space Exploration (DSE) is a critical step which determines the appropriate design configuration of the microprocessor. In the computer architecture community, supervised learning techniques have been applied to DSE to build models for predicting the qualities of design configurations. For supervised learning, however, considerable simulation costs are required for attaining the labeled design configurations. Given limited resources, it is difficult to achieve high accuracy. In this paper, inspired by recent advances in semi-supervised learning, we propose the COMT approach which can exploit unlabeled design configurations to improve the models. In addition to an improved predictive accuracy, COMT is able to guide the design of microprocessors, owing to the use of comprehensible model trees. Empirical study demonstrates that COMT significantly outperforms state-of-the-art DSE technique through reducing mean squared error by 30% to 84%, and thus, promising architectures can be attained more efficiently.

#index 1826331
#* Visual task inference using hidden Markov models
#@ Amin Haji Abolhassani;James J. Clark
#t 2011
#c 11
#% 95730
#% 219740
#% 988440
#% 1134825
#% 1270538
#! It has been known for a long time that visual task, such as reading, counting and searching, greatly influences eye movement patterns. Perhaps the best known demonstration of this is the celebrated study of Yarbus showing that different eye movement trajectories emerge depending on the visual task that the viewers are given. The objective of this paper is to develop an inverse Yarbus process whereby we can infer the visual task by observing the measurements of a viewer's eye movements while executing the visual task. The method we are proposing is to use Hidden Markov Models (HMMs) to create a probabilistic framework to infer the viewer's task from eye movements.

#index 1826332
#* The role of intention recognition in the evolution of cooperative behavior
#@ The Anh Han;Luís Moniz Pereira;Francisco C. Santos
#t 2011
#c 11
#% 147680
#% 1210222
#% 1279397
#% 1305552
#% 1491518
#! Given its ubiquity, scale and complexity, few problems have created the combined interest of so many unrelated areas as the evolution of cooperation. Using the tools of evolutionary game theory, here we address, for the first time, the role played by intention recognition in the final outcome of cooperation in large populations of self-regarding individuals. By equipping individuals with the capacity of assessing intentions of others in the course of repeated Prisoner's Dilemma interactions, we show how intention recognition opens a window of opportunity for cooperation to thrive, as it precludes the invasion of pure cooperators by random drift while remaining robust against defective strategies. Intention recognizers are able to assign an intention to the action of their opponents based on an acquired corpus of possible intentions. We show how intention recognizers can prevail against most famous strategies of repeated dilemmas of cooperation, even in the presence of errors. Our approach invites the adoption of other classification and pattern recognition mechanisms common among Humans, to unveil the evolution of complex cognitive processes in the context of social dilemmas.

#index 1826333
#* Multi-select faceted navigation based on minimum description length principle
#@ Chao He;Xueqi Cheng;Jiafeng Guo;Huawei Shen
#t 2011
#c 11
#% 300120
#% 452641
#% 810015
#% 857478
#% 857482
#% 955762
#% 960283
#% 1055719
#% 1063501
#% 1130808
#% 1183211
#% 1206746
#% 1399998
#% 1400029
#% 1482250
#! Faceted navigation can effectively reduce user efforts of reaching targeted resources in databases, by suggesting dynamic facet values for iterative query refinement. A key issue is minimizing the navigation cost in a user query session. Conventional navigation scheme assumes that at each step, users select only one suggested value to figure out resources containing it. To make faceted navigation more flexible and effective, this paper introduces a multi-select scheme where multiple suggested values can be selected at one step, and a selected value can be used to either retain or exclude the resources containing it. Previous algorithms for cost-driven value suggestion can hardly work well under our navigation scheme. Therefore, we propose to optimize the navigation cost using the Minimum Description Length principle, which can well balance the number of navigation steps and the number of suggested values per step under our new scheme. An emperical study demonstrates that our approach is more cost-saving and efficient than state-of-the-art approaches.

#index 1826334
#* Modeling situation awareness in human-like agents using mental models
#@ Mark Hoogendoorn;Rianne M. Van Lambalgen;Jan Treur
#t 2011
#c 11
#% 33677
#% 229439
#% 243704
#% 774264
#% 889281
#% 1279677
#% 1383858
#! In order for agents to be able to act intelligently in an environment, a first necessary step is to become aware of the current situation in the environment. Forming such awareness is not a trivial matter. Appropriate observations should be selected by the agent, and the observation results should be interpreted and combined into one coherent picture. Humans use dedicated mental models which represent the relationships between various observations and the formation of beliefs about the environment, which then again direct the further observations to be performed. In this paper, a generic agent model for situation awareness is proposed that is able to take a mental model as input, and utilize this model to create a picture of the current situation. In order to show the suitability of the approach, it has been applied within the domain of F-16 fighter pilot training for which a dedicated mental model has been specified, and simulations experiments have been conducted.

#index 1826335
#* Generalized latent factor models for social network analysis
#@ Wu-Jun Li;Dit-Yan Yeung;Zhihua Zhang
#t 2011
#c 11
#% 280819
#% 313959
#% 466574
#% 771841
#% 987253
#% 1117695
#% 1214714
#% 1250567
#% 1305469
#% 1312988
#% 1369424
#% 1417123
#! Homophily and stochastic equivalence are two primary features of interest in social networks. Recently, the multiplicative latent factor model (MLFM) is proposed to model social networks with directed links. Although MLFM can capture stochastic equivalence, it cannot model well homophily in networks. However, many real-world networks exhibit homophily or both homophily and stochastic equivalence, and hence the network structure of these networks cannot be modeled well by MLFM. In this paper, we propose a novel model, called generalized latent factor model (GLFM), for social network analysis by enhancing homophily modeling in MLFM. We devise a minorization-maximization (MM) algorithm with linear-time complexity and convergence guarantee to learn the model parameters. Extensive experiments on some real-world networks show that GLFM can effectively model homophily to dramatically outperform state-of-the-art methods.

#index 1826336
#* Modeling multivariate spatio-temporal remote sensing data with large gaps
#@ Qiang Lou;Zoran Obradovic
#t 2011
#c 11
#% 891559
#% 1214672
#% 1267862
#! Prediction models for multivariate spatio-temporal functions in geosciences are typically developed using supervised learning from attributes collected by remote sensing instruments collocated with the outcome variable provided at sparsely located sites. In such collocated data there are often large temporal gaps due to missing attribute values at sites where outcome labels are available. Our objective is to develop more accurate spatio-temporal predictors by using enlarged collocated data obtained by imputing missing attributes at time and locations where outcome labels are available. The proposed method for large gaps estimation in space and time (called LarGEST) exploits temporal correlation of attributes, correlations among multiple attributes collected at the same time and space, and spatial correlations among attributes from multiple sites. LarGEST outperformed alternative methods in imputing up to 80% of randomly missing observations at a synthetic spatio-temporal signal and at a model of fluoride content in a water distribution system. LarGEST was also applied for imputing 80% of nonrandom missing values in data from one of the most challenging Earth science problems related to aerosol properties. Using such enlarged data a predictor of aerosol optical depth is developed that was much more accurate than predictors based on alternative imputation methods when tested rigorously over entire continental US in year 2005.

#index 1826337
#* On the role of domain knowledge in analogy-based story generation
#@ Santiago Ontañón;Jichen Zhu
#t 2011
#c 11
#% 55937
#% 65345
#% 149460
#% 197254
#% 199539
#% 387249
#% 490445
#% 687715
#% 705161
#% 1109936
#% 1402709
#! Computational narrative is a complex and interesting domain for exploring AI techniques that algorithmically analyze, understand, and most importantly, generate stories. This paper studies the importance of domain knowledge in story generation, and particularly in analogy-based story generation (ASG). Based on the construct of knowledge container in case-based reasoning, we present a theoretical framework for incorporating domain knowledge in ASG. We complement the framework with empirical results in our existing system Riu.

#index 1826338
#* Using multiple models to understand data
#@ Kayur Patel;Steven M. Drucker;James Fogarty;Ashish Kapoor;Desney S. Tan
#t 2011
#c 11
#% 209021
#% 251145
#% 342618
#% 881575
#% 884039
#% 926881
#% 1047372
#% 1183210
#% 1289485
#% 1384243
#% 1477557
#! A human's ability to diagnose errors, gather data, and generate features in order to build better models is largely untapped. We hypothesize that analyzing results from multiple models can help people diagnose errors by understanding relationships among data, features, and algorithms. These relationships might otherwise be masked by the bias inherent to any individual model. We demonstrate this approach in our Prospect system, show how multiple models can be used to detect label noise and aid in generating new features, and validate our methods in a pair of experiments.

#index 1826339
#* Feature learning for activity recognition in ubiquitous computing
#@ Thomas Plötz;Nils Y. Hammerla;Patrick Olivier
#t 2011
#c 11
#% 845413
#% 891060
#% 1089790
#% 1278815
#% 1334217
#% 1410614
#% 1483514
#! Feature extraction for activity recognition in context-aware ubiquitous computing applications is usually a heuristic process, informed by underlying domain knowledge. Relying on such explicit knowledge is problematic when aiming to generalize across different application domains. We investigate the potential of recent machine learning methods for discovering universal features for context-aware applications of activity recognition. We also describe an alternative data representation based on the empirical cumulative distribution function of the raw data, which effectively abstracts from absolute values. Experiments on accelerometer data from four publicly available activity recognition datasets demonstrate the significant potential of our approach to address both contemporary activity recognition tasks and next generation problems such as skill assessment and the detection of novel activities.

#index 1826340
#* A cognitive agent model displaying and regulating different social response patterns
#@ Jan Treur
#t 2011
#c 11
#% 518789
#% 752160
#% 1084031
#% 1184361
#% 1523328
#% 1546709
#% 1610179
#% 1837390
#! Differences in social responses of individuals can often be related to differences in functioning of neurological mechanisms. This paper presents a cognitive agent model capable of showing different types of social response patterns based on such mechanisms, adopted from theories on mirror neuron systems, emotion regulation, empathy, and autism spectrum disorders. The presented agent model provides a basis for human-like social response patterns of virtual agents in the context of simulation-based training (e.g., for training of therapists), gaming, or for agent-based generation of virtual stories.

#index 1826341
#* A cognitive agent model incorporating prior and retrospective ownership states for actions
#@ Jan Treur
#t 2011
#c 11
#% 892985
#% 1610178
#% 1610196
#! The cognitive agent model presented in this paper generates prior and retrospective ownership states for an action based on principles from recent neurological theories. A prior ownership state is affected by prediction of the effects of a prepared action, and exerts control by strengthening or suppressing actual execution of the action. A retrospective ownership state depends on whether the sensed consequences co-occur with the predicted consequences, and is the basis for acknowledging authorship of actions, for example, in social context. It is shown how poor action effect prediction capabilities can lead to reduced retrospective ownership states, as in persons suffering from schizophrenia.

#index 1826342
#* Active graph reachability reduction for network security and software engineering
#@ Alice X. Zheng;John Dunagan;Ashish Kapoor
#t 2011
#c 11
#% 68119
#% 616945
#% 765247
#% 963811
#% 1005044
#% 1013898
#% 1278394
#% 1650536
#! Motivated by applications from computer network security and software engineering, we study the problem of reducing reachability on a graph with unknown edge costs. When the costs are known, reachability reduction can be solved using a linear relaxation of sparsest cut. Problems arise, however, when edge costs are unknown. In this case, blindly applying sparsest cut with incorrect edge costs can result in suboptimal or infeasible solutions. Instead, we propose to solve the problem via edge classification using feedback on individual edges. We show that this approach outperforms competing approaches in accuracy and efficiency on our target applications.

#index 1826343
#* Proceedings of the Twenty-Second international joint conference on Artificial Intelligence - Volume Volume Three
#@ Toby Walsh
#t 2011
#c 11

#index 1826344
#* Learning cause identifiers from annotator rationales
#@ Muhammad Arshad Ul Abedin;Vincent Ng;Latifur Rahman Khan
#t 2011
#c 11
#% 269217
#% 1149091
#% 1498851
#! In the aviation safety research domain, cause identification refers to the task of identifying the possible causes responsible for the incident described in an aviation safety incident report. This task presents a number of challenges, including the scarcity of labeled data and the difficulties in finding the relevant portions of the text. We investigate the use of annotator rationales to overcome these challenges, proposing several new ways of utilizing rationales and showing that through judicious use of the rationales, it is possible to achieve significant improvement over a unigram SVM baseline.

#index 1826345
#* Learning bilingual lexicons using the visual similarity of labeled web images
#@ Shane Bergsma;Benjamin Van Durme
#t 2011
#c 11
#% 722927
#% 747947
#% 751818
#% 760805
#% 786574
#% 836904
#% 854571
#% 854821
#% 939601
#% 940001
#% 1041734
#% 1470687
#% 1471382
#% 1481485
#! Speakers of many different languages use the Internet. A common activity among these users is uploading images and associating these images with words (in their own language) as captions, filenames, or surrounding text. We use these explicit, monolingual, image-to-word connections to successfully learn implicit, bilingual, word-to-word translations. Bilingual pairs of words are proposed as translations if their corresponding images have similar visual features. We generate bilingual lexicons in 15 language pairs, focusing on words that have been automatically identified as physical objects. The use of visual similarity substantially improves performance over standard approaches based on string similarity: for generated lexicons with 1000 translations, including visual information leads to an absolute improvement in accuracy of 8-12% over string edit distance alone.

#index 1826346
#* Semantic relationship discovery with wikipedia structure
#@ Fan Bu;Yu Hao;Xiaoyan Zhu
#t 2011
#c 11
#% 290830
#% 868096
#% 1190102
#% 1250381
#% 1269897
#% 1275012
#% 1650569
#! Thanks to the idea of social collaboration, Wikipedia has accumulated vast amount of semi-structured knowledge in which the link structure reflects human's cognition on semantic relationship to some extent. In this paper, we proposed a novel method RCRank to jointly compute concept-concept relatedness and concept-category relatedness base on the assumption that information carried in concept-concept links and concept-category links can mutually reinforce each other. Different from previous work, RCRank can not only find semantically related concepts but also interpret their relations by categories. Experimental results on concept recommendation and relation interpretation show that our method substantially outperforms classical methods.

#index 1826347
#* Short text classification improved by learning multi-granularity topics
#@ Mengen Chen;Xiaoming Jin;Dou Shen
#t 2011
#c 11
#% 169659
#% 722904
#% 869500
#% 894253
#% 956570
#% 1055680
#% 1074073
#% 1214660
#% 1250381
#% 1269907
#% 1275012
#% 1292559
#! Understanding the rapidly growing short text is very important. Short text is different from traditional documents in its shortness and sparsity, which hinders the application of conventional machine learning and text mining algorithms. Two major approaches have been exploited to enrich the representation of short text. One is to fetch contextual information of a short text to directly add more text; the other is to derive latent topics from existing large corpus, which are used as features to enrich the representation of short text. The latter approach is elegant and efficient in most cases. The major trend along this direction is to derive latent topics of certain granularity through well-known topic models such as latent Dirichlet allocation (LDA). However, topics of certain granularity are usually not sufficient to set up effective feature spaces. In this paper, we move forward along this direction by proposing an method to leverage topics at multiple granularity, which can model the short text more precisely. Taking short text classification as an example, we compared our proposed method with the state-of-the-art baseline over one open data set. Our method reduced the classification error by 20.25% and 16.68% respectively on two classifiers.

#index 1826348
#* Online latent structure training for language acquisition
#@ Michael Connor;Cynthia Fisher;Dan Roth
#t 2011
#c 11
#% 815893
#% 854636
#% 1084594
#% 1211836
#% 1249492
#% 1249502
#% 1249534
#% 1249551
#% 1470628
#% 1471279
#% 1478822
#% 1481555
#! A fundamental step in sentence comprehension involves assigning semantic roles to sentence constituents. To accomplish this, the listener must parse the sentence, find constituents that are candidate arguments, and assign semantic roles to those constituents. Where do children learning their first languages begin in solving this problem? Even assuming children can derive a rough meaning for the sentence from the situation, how do they begin to map this meaning to the structure and the structure to the form of the sentence? In this paper we use feedback from a semantic role labeling (SRL) task to improve the intermediate syntactic representations that feed the SRL. We accomplish this by training an intermediate classifier using signals derived from latent structure optimization techniques. By using a separate classifier to predict internal structure we see benefits due to knowledge embedded in the classifier's feature representation. This extra structure allows the system to begin to learn using weaker, more plausible semantic feedback.

#index 1826349
#* Predicting globally-coherent temporal structures from texts via endpoint inference and graph decomposition
#@ Pascal Denis;Philippe Muller
#t 2011
#c 11
#% 129430
#% 319244
#% 939595
#% 1008044
#% 1251693
#% 1261547
#% 1264790
#% 1328349
#% 1472106
#! An elegant approach to learning temporal orderings from texts is to formulate this problem as a constraint optimization problem, which can be then given an exact solution using Integer Linear Programming. This works well for cases where the number of possible relations between temporal entities is restricted to the mere precedence relation [Bramsen et al., 2006; Chambers and Jurafsky, 2008], but becomes impractical when considering all possible interval relations. This paper proposes two innovations, inspired from work on temporal reasoning, that control this combinatorial blow-up, therefore rendering an exact ILP inference viable in the general case. First, we translate our network of constraints from temporal intervals to their endpoints, to handle a drastically smaller set of constraints, while preserving the same temporal information. Second, we show that additional efficiency is gained by enforcing coherence on particular subsets of the entire temporal graphs. We evaluate these innovations through various experiments on TimeBank 1.2, and compare our ILP formulations with various baselines and oracle systems.

#index 1826350
#* Learning from natural instructions
#@ Dan Goldwasser;Dan Roth
#t 2011
#c 11
#% 853859
#% 883357
#% 939615
#% 1073888
#% 1250663
#% 1250666
#% 1328312
#% 1328313
#% 1328342
#% 1330547
#% 1338628
#% 1476277
#% 1481468
#! Machine learning is traditionally formalized and researched as the study of learning concepts and decision functions from labeled examples, requiring a representation that encodes information about the domain of the decision function to be learned. We are interested in providing a way for a human teacher to interact with an automated learner using natural instructions, thus allowing the teacher to communicate the relevant domain expertise to the learner without necessarily knowing anything about the internal representations used in the learning process. In this paper we suggest to view the process of learning a decision function as a natural language lesson interpretation problem instead of learning from labeled examples. This interpretation of machine learning is motivated by human learning processes, in which the learner is given a lesson describing the target concept directly, and a few instances exemplifying it. We introduce a learning algorithm for the lesson interpretation problem that gets feedback from its performance on the final task, while learning jointly (1) how to interpret the lesson and (2) how to use this interpretation to do well on the final task. This approach alleviates the supervision burden of traditional machine learning by focusing on supplying the learner with only human-level task expertise for learning. We evaluate our approach by applying it to the rules of the Freecell solitaire card game. We show that our learning approach can eventually use natural language instructions to learn the target concept and play the game legally. Furthermore, we show that the learned semantic interpreter also generalizes to previously unseen instructions.

#index 1826351
#* Automatic discovery of fuzzy synsets from dictionary definitions
#@ Hugo Gonçalo Oliveira;Paulo Gomes
#t 2011
#c 11
#% 374537
#% 458630
#% 564000
#% 748241
#% 756171
#% 815297
#% 1270651
#% 1338748
#% 1389716
#% 1428962
#% 1540540
#% 1697526
#! In order to deal with ambiguity in natural language, it is common to organise words, according to their senses, in synsets, which are groups of synonymous words that can be seen as concepts. The manual creation of a broad-coverage synset base is a time-consuming task, so we take advantage of dictionary definitions for extracting synonymy pairs and clustering for identifying synsets. Since word senses are not discrete, we create fuzzy synsets, where each word has a membership degree. We report on the results of the creation of a fuzzy synset base for Portuguese, from three electronic dictionaries. The resulting resource is larger than existing hancrafted Portuguese thesauri.

#index 1826352
#* Unsupervised modeling of dialog acts in asynchronous conversations
#@ Shafiq Joty;Giuseppe Carenini;Chin-Yew Lin
#t 2011
#c 11
#% 313959
#% 722925
#% 740409
#% 891559
#% 939504
#% 939526
#% 939712
#% 940037
#% 1220562
#% 1269911
#% 1338562
#% 1338659
#% 1470582
#% 1481573
#% 1481619
#% 1484214
#% 1549086
#! We present unsupervised approaches to the problem of modeling dialog acts in asynchronous conversations; i.e., conversations where participants collaborate with each other at different times. In particular, we investigate a graph-theoretic deterministic framework and two probabilistic conversation models (i.e., HMM and HMM+Mix) for modeling dialog acts in emails and forums. We train and test our conversation models on (a) temporal order and (b) graph-structural order of the datasets. Empirical evaluation suggests (i) the graph-theoretic framework that relies on lexical and structural similarity metrics is not the right model for this task, (ii) conversation models perform better on the graph-structural order than the temporal order of the datasets and (iii) HMM+Mix is a better conversation model than the simple HMM model.

#index 1826353
#* Improve tree kernel-based event pronoun resolution with competitive information
#@ Fang Kong;Guodong Zhou
#t 2011
#c 11
#% 740995
#% 815329
#% 815873
#% 815876
#% 938669
#% 938695
#% 939506
#% 1008106
#% 1124447
#% 1270713
#% 1481620
#% 1484308
#! Event anaphora resolution plays a critical role in discourse analysis. This paper proposes a tree kernel-based framework for event pronoun resolution. In particular, a new tree expansion scheme is introduced to automatically determine a proper parse tree structure for event pronoun resolution by considering various kinds of competitive information related with the anaphor and the antecedent candidate. Evaluation on the OntoNotes English corpus shows the appropriateness of the tree kernel-based framework and the effectiveness of competitive information for event pronoun resolution.

#index 1826354
#* Incorporating reviewer and product information for review rating prediction
#@ Fangtao Li;Nathan Liu;Hongwei Jin;Kai Zhao;Qiang Yang;Xiaoyan Zhu
#t 2011
#c 11
#% 578684
#% 939346
#% 1127964
#% 1260273
#% 1305481
#% 1471448
#% 1484343
#% 1715226
#! Traditional sentiment analysis mainly considers binary classifications of reviews, but in many real-world sentiment classification problems, non-binary review ratings are more useful. This is especially true when consumers wish to compare two products, both of which are not negative. Previous work has addressed this problem by extracting various features from the review text for learning a predictor. Since the same word may have different sentiment effects when used by different reviewers on different products, we argue that it is necessary to model such reviewer and product dependent effects in order to predict review ratings more accurately. In this paper, we propose a novel learning framework to incorporate reviewer and product information into the text based learner for rating prediction. The reviewer, product and text features are modeled as a three-dimension tensor. Tensor factorization techniques can then be employed to reduce the data sparsity problems. We perform extensive experiments to demonstrate the effectiveness of our model, which has a significant improvement compared to state of the art methods, especially for reviews with unpopular products and inactive reviewers.

#index 1826355
#* Semi-supervised learning for imbalanced sentiment classification
#@ Shoushan Li;Zhongqing Wang;Guodong Zhou;Sophia Yat Mei Lee
#t 2011
#c 11
#% 252011
#% 256615
#% 748550
#% 765519
#% 765522
#% 805873
#% 815915
#% 843876
#% 854646
#% 998622
#% 1166290
#% 1176920
#% 1246173
#% 1250356
#% 1270809
#% 1271973
#% 1301405
#% 1328329
#% 1328330
#% 1330516
#% 1471221
#! Various semi-supervised learning methods have been proposed recently to solve the long-standing shortage problem of manually labeled data in sentiment classification. However, most existing studies assume the balance between negative and positive samples in both the labeled and unlabeled data, which may not be true in reality. In this paper, we investigate a more common case of semi-supervised learning for imbalanced sentiment classification. In particular, various random subspaces are dynamically generated to deal with the imbalanced class distribution problem. Evaluation across four domains shows the effectiveness of our approach.

#index 1826356
#* Collective semantic role labeling for tweets with clustering
#@ Xiaohua Liu;Kuan Li;Ming Zhou;Zhongyang Xiong
#t 2011
#c 11
#% 452991
#% 816186
#% 817825
#% 850430
#% 939404
#% 1084591
#% 1084594
#% 1249482
#% 1249502
#% 1249521
#% 1265033
#% 1270666
#% 1298864
#% 1344869
#% 1344871
#% 1344874
#% 1344877
#% 1399966
#% 1471259
#% 1471277
#% 1484319
#% 1544087
#! As tweets have become a comprehensive repository of fresh information, Semantic Role Labeling (SRL) for tweets has aroused great research interests because of its central role in a wide range of tweet related studies such as fine-grained information extraction, sentiment analysis and summarization. However, the fact that a tweet is often too short and informal to provide sufficient information poses a major challenge. To tackle this challenge, we propose a new method to collectively label similar tweets. The underlying idea is to exploit similar tweets to make up for the lack of information in a tweet. Specifically, similar tweets are first grouped together by clustering. Then for each cluster a two-stage labeling is conducted: One labeler conducts SRL to get statistical information, such as the predicate/argument/role triples that occur frequently, from its highly confidently labeled results; then in the second stage, another labeler performs SRL with such statistical information to refine the results. Experimental results on a human annotated dataset show that our approach remarkably improves SRL by 3.1% F1.

#index 1826357
#* SMT versus AI redux: how semantic fames evaluate MT more accurately
#@ Chi-Kiu Lo;Dekai Wu
#t 2011
#c 11
#% 747891
#% 815902
#% 858036
#% 995522
#% 1270728
#% 1275640
#% 1275669
#% 1275692
#% 1289536
#% 1338533
#% 1480000
#% 1591951
#! We argue for an alternative paradigm in evaluating machine translation quality that is strongly empirical but more accurately reflects the utility of translations, by returning to a representational foundation based on AI oriented lexical semantics, rather than the superficial flat n-gram and string representations recently dominating the field. Driven by such metrics as BLEU and WER, current SMT frequently produces unusable translations where the semantic event structure is mistranslated: who did what to whom, when, where, why, and how? We argue that it is time for a new generation of more intelligent automatic and semi-automatic metrics, based clearly on getting the structure right at the lexical semantics level. We show empirically that it is possible to use simple PropBank style semantic frame representations to surpass all currently widespread metrics' correlation to human adequacy judgments, including even HTER. We also show that replacing human annotators with automatic semantic role labeling still yields much of the advantage of the approach. We combine the best of both worlds: from an SMT perspective, we provide superior yet low-cost quantitative objective functions for translation quality; and yet from an AI perspective, we regain the representational transparency and clear reflection of semantic utility of structural frame-based knowledge representations.

#index 1826358
#* Constraint optimization approach to context based word selection
#@ Jun Matsuno;Toru Ishida
#t 2011
#c 11
#% 230551
#% 849488
#% 905358
#% 939379
#% 1251626
#% 1264727
#% 1275012
#% 1305539
#% 1338535
#! Consistent word selection in machine translation is currently realized by resolving word sense ambiguity through the context of a single sentence or neighboring sentences. However, consistent word selection over the whole article has yet to be achieved. Consistency over the whole article is extremely important when applying machine translation to collectively developed documents like Wikipedia. In this paper, we propose to consider constraints between words in the whole article based on their semantic relatedness and contextual distance. The proposed method is successfully implemented in both statistical and rule-based translators. We evaluate those systems by translating 100 articles in the EnglishWikipedia into Japanese. The results show that the ratio of appropriate word selection for common nouns increased to around 75% with our method, while it was around 55% without our method.

#index 1826359
#* An approach to answer selection in question-answering based on semantic relations
#@ Ana Cristina Mendes;Luísa Coheur
#t 2011
#c 11
#% 340953
#% 342398
#% 741889
#% 815303
#% 816157
#% 1288643
#% 1558164
#! A usual strategy to select the final answer in factoid Question-Answering (QA) relies on redundancy. A score is given to each candidate answer as a function of its frequency of occurrence, and the final answer is selected from the set of candidates sorted in decreasing order of score. For that purpose, systems often try to group together semantically equivalent answers. However, they hold several other semantic relations, such as inclusion, which are not considered, and candidates are mostly seen independently, as competitors. Our hypothesis is that not just equivalence, but other relations between candidate answers have impact on the performance of a redundancy-based QA system. In this paper, we describe experimental studies to back up this hypothesis. Our findings show that, with relatively simple techniques to recognize relations, systems' accuracy can be improved for answers of categories NUMBER, DATE and ENTITY.

#index 1826360
#* Learning for deep language understanding
#@ Smaranda Muresan
#t 2011
#c 11
#% 163545
#% 241161
#% 466853
#% 757809
#% 815905
#% 818038
#% 980270
#% 995021
#% 1022764
#% 1249483
#% 1276571
#% 1338528
#% 1344851
#% 1481654
#% 1544106
#! The paper addresses the problem of learning to parse sentences to logical representations of their underlying meaning, by inducing a syntactic-semantic grammar. The approach uses a class of grammars which has been proven to be learnable from representative examples. In this paper, we introduce tractable learning algorithms for learning this class of grammars, comparing them in terms of a-priori knowledge needed by the learner, hypothesis space and algorithm complexity. We present experimental results on learning tense, aspect, modality and negation of verbal constructions.

#index 1826361
#* Improving topic evaluation using conceptual knowledge
#@ Claudiu Cristian Musat;Julien Velcin;Stefan Trausan-Matu;Marian-Andrei Rizoiu
#t 2011
#c 11
#% 198058
#% 280819
#% 722904
#% 881498
#% 956510
#% 989620
#% 1117083
#% 1211693
#% 1211828
#% 1214638
#% 1470574
#! The growing number of statistical topic models led to the need to better evaluate their output. Traditional evaluation means estimate the model's fitness to unseen data. It has recently been proven than the output of human judgment can greatly differ from these measures. Thus the need for methods that better emulate human judgment is stringent. In this paper we present a system that computes the conceptual relevance of individual topics from a given model on the basis of information drawn from a given concept hierarchy, in this case WordNet. The notion of conceptual relevance is regarded as the ability to attribute a concept to each topic and separate words related to the topic from the unrelated ones based on that concept. In multiple experiments we prove the correlation between the automatic evaluation method and the answers received from human evaluators, for various corpora and difficulty levels. By changing the evaluation focus from a statistical one to a conceptual one we were able to detect which topics are conceptually meaningful and rank them accordingly.

#index 1826362
#* A graph-based algorithm for inducing lexical taxonomies from scratch
#@ Roberto Navigli;Paola Velardi;Stefano Faralli
#t 2011
#c 11
#% 756964
#% 786515
#% 815267
#% 816164
#% 939601
#% 979654
#% 1131827
#% 1182835
#% 1328333
#% 1428692
#% 1471209
#% 1471312
#% 1481643
#! In this paper we present a graph-based approach aimed at learning a lexical taxonomy automatically starting from a domain corpus and the Web. Unlike many taxonomy learning approaches in the literature, our novel algorithm learns both concepts and relations entirely from scratch via the automated extraction of terms, definitions and hypernyms. This results in a very dense, cyclic and possibly disconnected hypernym graph. The algorithm then induces a taxonomy from the graph. Our experiments show that we obtain high-quality results, both when building brand-new taxonomies and when reconstructing WordNet sub-hierarchies.

#index 1826363
#* Sample efficient on-line learning of optimal dialogue policies with kalman temporal differences
#@ Olivier Pietquin;Matthieu Geist;Senthilkumar Chandramohan
#t 2011
#c 11
#% 384911
#% 734920
#% 741919
#% 746897
#% 894433
#% 940817
#% 1149089
#% 1260606
#% 1543977
#% 1545561
#% 1562993
#% 1767526
#! Designing dialog policies for voice-enabled interfaces is a tailoring job that is most often left to natural language processing experts. This job is generally redone for every new dialog task because cross-domain transfer is not possible. For this reason, machine learning methods for dialog policy optimization have been investigated during the last 15 years. Especially, reinforcement learning (RL) is now part of the state of the art in this domain. Standard RL methods require to test more or less random changes in the policy on users to assess them as improvements or degradations. This is called on policy learning. Nevertheless, it can result in system behaviors that are not acceptable by users. Learning algorithms should ideally infer an optimal strategy by observing interactions generated by a non-optimal but acceptable strategy, that is learning off-policy. In this contribution, a sample-efficient, online and off-policy reinforcement learning algorithm is proposed to learn an optimal policy from few hundreds of dialogues generated with a very simple handcrafted policy.

#index 1826364
#* Ensemble-based coreference resolution
#@ Altaf Rahman;Vincent Ng
#t 2011
#c 11
#% 577224
#% 740995
#% 747890
#% 748541
#% 815876
#% 816176
#% 938670
#% 938782
#% 939351
#% 939376
#% 939921
#% 1264748
#% 1264786
#% 1270797
#% 1290034
#% 1330511
#% 1470623
#% 1602946
#! We investigate new methods for creating and applying ensembles for coreference resolution. While existing ensembles for coreference resolution are typically created using different learning algorithms, clustering algorithms or training sets, we harness recent advances in coreference modeling and propose to create our ensemble from a variety of supervised coreference models. However, the presence of pairwise and non-pairwise coreference models in our ensemble presents a challenge to its application: it is not immediately clear how to combine the coreference decisions made by these models. We investigate different methods for applying a model-heterogeneous ensemble for coreference resolution. Empirical results on the ACE data sets demonstrate the promise of ensemble approaches: all ensemble-based systems significantly outperform the best member of the ensemble.

#index 1826365
#* Unsupervised lexicon acquisition for HPSG-based relation extraction
#@ Benjamin Rozenfeld;Ronen Feldman
#t 2011
#c 11
#% 763708
#% 853697
#% 855119
#% 940029
#% 983614
#% 1019100
#% 1292703
#% 1673571
#! The paper describes a method of relation extraction, which is based on parsing the input text using a combination of a generic HPSG-based grammar and a highly focused domain-and relation-specific lexicon. We also show a method of unsupervised acquisition of such a lexicon from a large unlabeled corpus. Together, the methods introduce a novel approach to the "Open IE" task, which is superior in accuracy and in quality of relation identification to the existing approaches.

#index 1826366
#* Interfacing virtual agents with collaborative knowledge: open domain question answering using wikipedia-based topic models
#@ Ulli Waltinger;Alexa Breuing;Ipke Wachsmuth
#t 2011
#c 11
#% 474645
#% 838146
#% 854158
#% 995494
#% 1026891
#% 1108106
#% 1210603
#% 1221010
#% 1275012
#% 1280710
#% 1288161
#% 1305538
#% 1517796
#% 1547224
#% 1605069
#! This paper is concerned with the use of conversational agents as an interaction paradigm for accessing open domain encyclopedic knowledge by means of Wikipedia. More precisely, we describe a dialog-based question answering system for German which utilizes Wikipedia-based topic models as a reference point for context detection and answer prediction. We investigate two different perspectives to the task of interfacing virtual agents with collaborative knowledge. First, we exploit the use of Wikipedia categories as a basis for identifying the broader topic of a spoken utterance. Second, we describe how to enhance the conversational behavior of the virtual agent by means of a Wikipedia-based question answering component which incorporates the question topic. At large, our approach identifies topic-related focus terms of a user's question, which are subsequently mapped onto a category taxonomy. Thus, we utilize the taxonomy as a reference point to derive topic labels for a user's question. The employed topic model is thereby based on explicitly given concepts as represented by the document and category structure of the Wikipedia knowledge base. Identified topic categories are subsequently combined with different linguistic filtering methods to improve answer candidate retrieval and reranking. Results show that the topic model approach contributes to an enhancement of the conversational behavior of virtual agents.

#index 1826367
#* Affect sensing in metaphorical phenomena and dramatic interaction context
#@ Li Zhang
#t 2011
#c 11
#% 3708
#% 783633
#% 870824
#% 1100471
#% 1111006
#% 1181945
#% 1305525
#% 1488239
#% 1507902
#! Metaphorical interpretation and affect detection using context profiles from open-ended text input are challenging in affective language processing field. In this paper, we explore recognition of a few typical affective metaphorical phenomena and context-based affect sensing using the modeling of speakers' improvisational mood and other participants' emotional influence to the speaking character under the improvisation of loose scenarios. The overall updated affect detection module is embedded in an AI agent. The new developments have enabled the AI agent to perform generally better in affect sensing tasks. The work emphasizes the conference themes on affective dialogue processing, human-agent interaction and intelligent user interfaces.

#index 1826368
#* Entity linking with effective acronym expansion, instance selection and topic modeling
#@ Wei Zhang;Yan Chuan Sim;Jian Su;Chew Lim Tan
#t 2011
#c 11
#% 190581
#% 269217
#% 301261
#% 390723
#% 722904
#% 938727
#% 1470634
#% 1484272
#% 1484385
#% 1713162
#! Entity linking maps name mentions in the documents to entries in a knowledge base through resolving the name variations and ambiguities. In this paper, we propose three advancements for entity linking. Firstly, expanding acronyms can effectively reduce the ambiguity of the acronym mentions. However, only rule-based approaches relying heavily on the presence of text markers have been used for entity linking. In this paper, we propose a supervised learning algorithm to expand more complicated acronyms encountered, which leads to 15.1% accuracy improvement over state-of-the-art acronym expansion methods. Secondly, as entity linking annotation is expensive and labor intensive, to automate the annotation process without compromise of accuracy, we propose an instance selection strategy to effectively utilize the automatically generated annotation. In our selection strategy, an informative and diverse set of instances are selected for effective disambiguation. Lastly, topic modeling is used to model the semantic topics of the articles. These advancements give statistical significant improvement to entity linking individually. Collectively they lead the highest performance on KBP-2010 task.

#index 1826369
#* Learning inter-related statistical query translation models for English-Chinese bi-directional CLIR
#@ Yuejie Zhang;Lei Cen;Cheng Jin;Xiangyang Xue;Jianping Fan
#t 2011
#c 11
#% 313959
#% 464434
#% 818268
#% 827631
#% 879589
#% 879590
#% 939510
#% 1015007
#% 1174575
#% 1856603
#! To support more precise query translation for English-Chinese Bi-Directional Cross-Language Information Retrieval (CLIR), we have developed a novel framework by integrating a semantic network to characterize the correlations between multiple inter-related text terms of interest and learn their inter-related statistical query translation models. First, a semantic network is automatically generated from large-scale English-Chinese bilingual parallel corpora to characterize the correlations between a large number of text terms of interest. Second, the semantic network is exploited to learn the statistical query translation models for such text terms of interest. Finally, these inter-related query translation models are used to translate the queries more precisely and achieve more effective CLIR. Our experiments on a large number of official public data have obtained very positive results.

#index 1826370
#* Fusion of multiple features and supervised learning for Chinese OOV term detection and POS guessing
#@ Yuejie Zhang;Lei Cen;Wei Wu;Cheng Jin;Xiangyang Xue
#t 2011
#c 11
#% 466892
#% 855168
#% 855184
#% 939589
#% 1024911
#% 1277962
#! In this paper, to support more precise Chinese Out-of-Vocabulary (OOV) term detection and Part-of-Speech (POS) guessing, a unified mechanism is proposed and formulated based on the fusion of multiple features and supervised learning. Besides all the traditional features, the new features for statistical information and global contexts are introduced, as well as some constraints and heuristic rules, which reveal the relationships among OOV term candidates. Our experiments on the Chinese corpora from both People's Daily and SIGHAN 2005 have achieved the consistent results, which are better than those acquired by pure rule-based or statistics-based models. From the experimental results for combining our model with Chinese monolingual retrieval on the data sets of TREC-9, it is found that the obvious improvement for the retrieval performance can also be obtained.

#index 1826371
#* DetH: approximate hierarchical solution of large Markov decision processes
#@ Jennifer L. Barry;Leslie Pack Kaelbling;Tomás Lozano-Pérez
#t 2011
#c 11
#% 393786
#% 466066
#% 1073953
#% 1275053
#% 1289570
#% 1305553
#% 1453208
#% 1650297
#! This paper presents an algorithm for finding approximately optimal policies in very large Markov decision processes by constructing a hierarchical model and then solving it approximately. It exploits factored representations to achieve compactness and efficiency and to discover connectivity properties of the domain. We provide a bound on the quality of the solutions and give asymptotic analysis of the runtimes; in addition we demonstrate performance on a collection of very large domains. Results show that the quality of resulting policies is very good and the total running times, for both creating and solving the hierarchy, are significantly less than for an optimal factored MDP solver.

#index 1826372
#* Planning under partial observability by classical replanning: theory and experiments
#@ Blai Bonet;Hector Geffner
#t 2011
#c 11
#% 425075
#% 655327
#% 789560
#% 1178627
#% 1178633
#% 1271962
#% 1272109
#% 1272340
#% 1288659
#% 1290265
#% 1291064
#% 1305550
#! Planning with partial observability can be formulated as a non-deterministic search problem in belief space. The problem is harder than classical planning as keeping track of beliefs is harder than keeping track of states, and searching for action policies is harder than searching for action sequences. In this work, we develop a framework for partial observability that avoids these limitations and leads to a planner that scales up to larger problems. For this, the class of problems is restricted to those in which 1) the non-unary clauses representing the uncertainty about the initial situation are invariant, and 2) variables that are hidden in the initial situation do not appear in the body of conditional effects, which are all assumed to be deterministic. We show that such problems can be translated in linear time into equivalent fully observable non-deterministic planning problems, and that an slight extension of this translation renders the problem solvable by means of classical planners. The whole approach is sound and complete provided that in addition, the state-space is connected. Experiments are also reported.

#index 1826373
#* Risk-sensitive policies for sustainable renewable resource allocation
#@ Stefano Ermon;Jon Conrad;Carla Gomes;Bart Selman
#t 2011
#c 11
#% 361730
#% 384911
#% 757953
#! Markov Decision Processes arise as a natural model for many renewable resources allocation problems. In many such problems, high stakes decisions with potentially catastrophic outcomes (such as the collapse of an entire ecosystem) need to be taken by carefully balancing social, economic, and ecologic goals. We introduce a broad class of such MDP models with a risk averse attitude of the decision maker, in order to obtain policies that are more balanced with respect to the welfare of future generations. We prove that they admit a closed form solution that can be efficiently computed. We show an application of the proposed framework to the Pacific Halibut marine fishery, obtaining new and more cautious policies. Our results strengthen findings of related policies from the literature by providing new evidence that a policy based on periodic closures of the fishery should be employed, in place of the one traditionally used that harvests a constant proportion of the stock every year.

#index 1826374
#* Simple and fast strong cyclic planning for fully-observable nondeterministic planning problems
#@ Jicheng Fu;Vincent Ng;Farokh B. Bastani;I-Ling Yen
#t 2011
#c 11
#% 337981
#% 655322
#% 1250200
#% 1271962
#% 1289432
#% 1432470
#! We address a difficult, yet under-investigated class of planning problems: fully-observable nondeterministic (FOND) planning problems with strong cyclic solutions. The difficulty of these strong cyclic FOND planning problems stems from the large size of the state space. Hence, to achieve efficient planning, a planner has to cope with the explosion in the size of the state space by planning along the directions that allow the goal to be reached quickly. A major challenge is: how would one know which states and search directions are relevant before the search for a solution has even begun? We first describe an NDP-motivated strong cyclic algorithm that, without addressing the above challenge, can already outperform state-of-the-art FOND planners, and then extend this NDP-motivated planner with a novel heuristic that addresses the challenge.

#index 1826375
#* On the decidability of HTN planning with task insertion
#@ Thomas Geier;Pascal Bercher
#t 2011
#c 11
#% 194648
#% 266385
#% 390964
#% 544793
#% 1223551
#% 1386453
#! The field of deterministic AI planning can roughly be divided into two approaches -- classical state-based planning and hierarchical task network (HTN) planning. The plan existence problem of the former is known to be decidable while it has been proved undecidable for the latter. When extending HTN planning by allowing the unrestricted insertion of tasks and ordering constraints, one obtains a form of planning which is often referred to as "hybrid planning". We present a simplified formalization of HTN planning with and without task insertion. We show that the plan existence problem is undecidable for the HTN setting without task insertion and that it becomes decidable when allowing task insertion. In the course of the proof, we obtain an upper complexity bound of EXPSPACE for the plan existence problem for propositional HTN planning with task insertion.

#index 1826376
#* Transfer learning for activity recognition via sensor mapping
#@ Derek Hao Hu;Qiang Yang
#t 2011
#c 11
#% 310545
#% 843360
#% 879581
#% 975019
#% 1024911
#% 1089789
#% 1269362
#% 1270540
#% 1328303
#% 1385963
#% 1464068
#% 1496686
#% 1496687
#% 1496688
#% 1588825
#% 1668045
#% 1729100
#! Activity recognition aims to identify and predict human activities based on a series of sensor readings. In recent years, machine learning methods have become popular in solving activity recognition problems. A special difficulty for adopting machine learning methods is the workload to annotate a large number of sensor readings as training data. Labeling sensor readings for their corresponding activities is a time-consuming task. In practice, we often have a set of labeled training instances ready for an activity recognition task. If we can transfer such knowledge to a new activity recognition scenario that is different from, but related to, the source domain, it will ease our effort to perform manual labeling of training data for the new scenario. In this paper, we propose a transfer learning framework based on automatically learning a correspondence between different sets of sensors to solve this transfer-learning in activity recognition problem. We validate our framework on two different datasets and compare it against previous approaches of activity recognition, and demonstrate its effectiveness.

#index 1826377
#* Point-based value iteration for constrained POMDPs
#@ Dongho Kim;Jaesong Lee;Kee-Eung Kim;Pascal Poupart
#t 2011
#c 11
#% 97542
#% 940817
#% 1270065
#% 1271823
#% 1272129
#% 1272257
#% 1290265
#% 1650702
#% 1845540
#% 1851733
#! Constrained partially observable Markov decision processes (CPOMDPs) extend the standard POMDPs by allowing the specification of constraints on some aspects of the policy in addition to the optimality objective for the value function. CPOMDPs have many practical advantages over standard POMDPs since they naturally model problems involving limited resource or multiple objectives. In this paper, we show that the optimal policies in CPOMDPs can be randomized, and present exact and approximate dynamic programming methods for computing randomized optimal policies. While the exact method requires solving a minimax quadratically constrained program (QCP) in each dynamic programming update, the approximate method utilizes the point-based value update with a linear program (LP). We show that the randomized policies are significantly better than the deterministic ones. We also demonstrate that the approximate point-based method is scalable to solve large problems.

#index 1826378
#* Monitoring the execution of partial-order plans via regression
#@ Christian Muise;Sheila A. McIlraith;J. Christopher Beck
#t 2011
#c 11
#% 163714
#% 430722
#% 788062
#% 1271962
#% 1272333
#% 1290041
#% 1305570
#! Partial-order plans (POPs) have the capacity to compactly represent numerous distinct plan linearizations and as a consequence are inherently robust. We exploit this robustness to do effective execution monitoring. We characterize the conditions under which a POP remains viable as the regression of the goal through the structure of a POP. We then develop a method for POP execution monitoring via a structured policy, expressed as an ordered algebraic decision diagram. The policy encompasses both state evaluation and action selection, enabling an agent to seamlessly switch between POP linearizations to accommodate unexpected changes during execution. We demonstrate the effectiveness of our approach by comparing it empirically and analytically to a standard technique for execution monitoring of sequential plans. On standard benchmark planning domains, our approach is 2 to 17 times faster and up to 2.5 times more robust than comparable monitoring of a sequential plan. On POPs that have few ordering constraints among actions, our approach is significantly more robust, with the ability to continue executing in up to an exponential number of additional states.

#index 1826379
#* Computing perfect heuristics in polynomial time: on bisimulation and merge-and-shrink abstraction in optimal planning
#@ Raz Nissim;Jörg Hoffmann;Malte Helmert
#t 2011
#c 11
#% 101958
#% 1270237
#% 1741981
#! A* with admissible heuristics is a very successful approach to optimal planning. But how to derive such heuristics automatically? Merge-and-shrink abstraction (M&S) is a general approach to heuristic design whose key advantage is its capability to make very fine-grained choices in defining abstractions. However, little is known about how to actually make these choices. We address this via the well-known notion of bisimulation. When aggregating only bisimilar states, M&S yields a perfect heuristic. Alas, bisimulations are exponentially large even in trivial domains. We show how to apply label reduction - not distinguishing between certain groups of operators - without incurring any information loss, while potentially reducing bisimulation size exponentially. In several benchmark domains, the resulting algorithm computes perfect heuristics in polynomial time. Empirically, we show that approximating variants of this algorithm improve the state of the art in M&S heuristics. In particular, a simple hybrid of two such variants is competitive with the leading heuristic LM-cut.

#index 1826380
#* Iterative flattening search for the flexible job shop scheduling problem
#@ Angelo Oddi;Riccardo Rasconi;Amedeo Cesta;Stephen F. Smith
#t 2011
#c 11
#% 107137
#% 408396
#% 529677
#% 957089
#% 1036687
#% 1053972
#% 1425385
#% 1478777
#% 1486339
#! This paper presents a meta-heuristic algorithm for solving the Flexible Job Shop Scheduling Problem (FJSSP). This strategy, known as Iterative Flattening Search (IFS), iteratively applies a relaxation-step, in which a subset of scheduling decisions are randomly retracted from the current solution; and a solving-step, in which a new solution is incrementally recomputed from this partial schedule. This work contributes two separate results: (1) it proposes a constraint-based procedure extending an existing approach previously used for classical Job Shop Scheduling Problem; (2) it proposes an original relaxation strategy on feasible FJSSP solutions based on the idea of randomly breaking the execution orders of the activities on the machines and opening the resource options for some activities selected at random. The efficacy of the overall heuristic optimization algorithm is demonstrated on a set of well-known benchmarks.

#index 1826381
#* Large neighborhood search and adaptive randomized decompositions for flexible jobshop scheduling
#@ Dario Pacino;Pascal Van Hentenryck
#t 2011
#c 11
#% 95594
#% 143606
#% 529677
#% 1036687
#% 1042104
#% 1478767
#% 1493574
#! This paper considers a constraint-based scheduling approach to the flexible jobshop, a generalization of the traditional jobshop scheduling where activities have a choice of machines. It studies both large neighborhood (LNS) and adaptive randomized decomposition (ARD) schemes, using random, temporal, and machine decompositions. Empirical results on standard benchmarks show that, within 5 minutes, both LNS and ARD produce many new best solutions and are about 0.5% in average from the best-known solutions. Moreover, over longer runtimes, they improve 60% of the best-known solutions and match the remaining ones. The empirical results also show the importance of hybrid decompositions in LNS and ARD.

#index 1826382
#* Computing infinite plans for LTL goals using a classical planner
#@ Fabio Patrizi;Nir Lipoveztky;Giuseppe De Giacomo;Hector Geffner
#t 2011
#c 11
#% 101943
#% 172932
#% 215675
#% 417597
#% 542265
#% 544791
#% 544938
#% 767935
#% 1068329
#% 1178630
#% 1250631
#% 1271962
#% 1395211
#% 1433891
#% 1473370
#! Classical planning has been notably successful in synthesizing finite plans to achieve states where propositional goals hold. In the last few years, classical planning has also been extended to incorporate temporally extended goals, expressed in temporal logics such as LTL, to impose restrictions on the state sequences generated by finite plans. In this work, we take the next step and consider the computation of infinite plans for achieving arbitrary LTL goals. We show that infinite plans can also be obtained efficiently by calling a classical planner once over a classical planning encoding that represents and extends the composition of the planning domain and the Büchi automaton representing the goal. This compilation scheme has been implemented and a number of experiments are reported.

#index 1826383
#* Goal recognition over POMDPs: inferring the intention of a POMDP agent
#@ Miquel Ramírez;Hector Geffner
#t 2011
#c 11
#% 247892
#% 889273
#% 953324
#% 1210222
#% 1279398
#% 1289455
#% 1290265
#% 1291498
#% 1305294
#% 1305553
#% 1305575
#! Plan recognition is the problem of inferring the goals and plans of an agent from partial observations of her behavior. Recently, it has been shown that the problem can be formulated and solved using planners, reducing plan recognition to plan generation. In this work, we extend this model-based approach to plan recognition to the POMDP setting, where actions are stochastic and states are partially observable. The task is to infer a probability distribution over the possible goals of an agent whose behavior results from a POMDP model. The POMDP model is shared between agent and observer except for the true goal of the agent that is hidden to the observer. The observations are action sequences O that may contain gaps as some or even most of the actions done by the agent may not be observed. We show that the posterior goal distribution P(G|O) can be computed from the value function VG(b) over beliefs b generated by the POMDP planner for each possible goal G. Some extensions of the basic framework are discussed, and a number of experiments are reported.

#index 1826384
#* Planning with SAT, admissible heuristics and A*
#@ Jussi Rintanen
#t 2011
#c 11
#% 2194
#% 131357
#% 327779
#% 337980
#% 1271953
#% 1272049
#% 1412980
#% 1493597
#! We study the relationship between optimal planning algorithms, in the form of (iterative deepening) A* with (forward) state-space search, and the reduction of the problem to SAT. Our results establish a strict dominance relation between the two approaches: any iterative deepening A* search can be efficiently simulated in the SAT framework, assuming that the heuristic has been encoded in the SAT problem, but the opposite is not possible as A* and IDA* searches sometimes take exponentially longer.

#index 1826385
#* Replanning in domains with partial information and sensing actions
#@ Guy Shani;Ronen I. Brafman
#t 2011
#c 11
#% 342119
#% 425075
#% 1270248
#% 1271828
#% 1271962
#% 1288659
#% 1291454
#% 1305550
#! Replanning via determinization is a recent, popular approach for online planning in MDPs. In this paper we adapt this idea to classical, nonstochastic domains with partial information and sensing actions. At each step we generate a candidate plan which solves a classical planning problem induced by the original problem. We execute this plan as long as it is safe to do so. When this is no longer the case, we replan. The classical planning problem we generate is based on the T0 translation, in which the classical state captures the knowledge state of the agent. We overcome the non-determinism in sensing actions, and the large domain size introduced by T0 by using state sampling. Our planner also employs a novel, lazy, regression-based method for querying the belief state.

#index 1826386
#* Scaling up optimal heuristic search in Dec-POMDPs via incremental expansion
#@ Matthijs T. J. Spaan;Frans A. Oliehoek;Christopher Amato
#t 2011
#c 11
#% 643287
#% 773196
#% 1090422
#% 1215583
#% 1269779
#% 1272221
#% 1275077
#% 1453186
#% 1453204
#% 1526847
#! Planning under uncertainty for multiagent systems can be formalized as a decentralized partially observable Markov decision process. We advance the state of the art for optimal solution of this model, building on the Multiagent A* heuristic search method. A key insight is that we can avoid the full expansion of a search node that generates a number of children that is doubly exponential in the node's depth. Instead, we incrementally expand the children only when a next child might have the highest heuristic value. We target a subsequent bottleneck by introducing a more memory-efficient representation for our heuristic functions. Proof is given that the resulting algorithm is correct and experiments demonstrate a significant speedup over the state of the art, allowing for optimal solutions over longer horizons for many benchmark problems.

#index 1826387
#* On the effectiveness of CNF and DNF representations in contingent planning
#@ Son Thanh To;Enrico Pontelli;Tran Cao Son
#t 2011
#c 11
#% 121397
#% 124601
#% 318489
#% 1272109
#% 1291462
#% 1305550
#! This paper investigates the effectiveness of two state representations, CNF and DNF, in contingent planning. To this end, we developed a new contingent planner, called CNFct, using the AND/OR forward search algorithm PrAO [To et al., 2011] and an extension of the CNF representation of [To et al., 2010] for conformant planning to handle nondeterministic and sensing actions for contingent planning. The study uses CNFct and DNFct [To et al., 2011] and proposes a new heuristic function for both planners. The experiments demonstrate that both CNFct and DNFct offer very competitive performance in a large range of benchmarks but neither of the two representations is a clear winner over the other. The paper identifies properties of the representation schemes that can affect their performance on different problems.

#index 1826388
#* Bounded intention planning
#@ Jason Wolfe;Stuart Russell
#t 2011
#c 11
#% 172505
#% 251783
#% 543289
#% 1270229
#% 1270238
#% 1271985
#% 1272113
#% 1273866
#% 1275059
#% 1305556
#% 1305557
#% 1369584
#% 1473387
#% 1477346
#% 1545553
#! We propose a novel approach for solving unary SAS+ planning problems. This approach extends an SAS+ instance with new state variables representing intentions about how each original state variable will be used or changed next, and splits the original actions into several stages of intention followed by eventual execution. The result is a new SAS+ instance with the same basic solutions as the original. While the transformed problem is larger, it has additional structure that can be exploited to reduce the branching factor, leading to reachable state spaces that are many orders of magnitude smaller (and hence much faster planning) in several test domains with acyclic causal graphs.

#index 1826389
#* Probabilistic goal Markov decision processes
#@ Huan Xu;Shie Mannor
#t 2011
#c 11
#% 29939
#% 361730
#% 810882
#% 959522
#% 997711
#% 1269516
#% 1358092
#! The Markov decision process model is a powerful tool in planing tasks and sequential decision making problems. The randomness of state transitions and rewards implies that the performance of a policy is often stochastic. In contrast to the standard approach that studies the expected performance, we consider the policy that maximizes the probability of achieving a pre-determined target performance, a criterion we term probabilistic goal Markov decision processes. We show that this problem is NP-hard, but can be solved using a pseudo-polynomial algorithm. We further consider a variant dubbed "chance-constraint Markov decision problems," that treats the probability of achieving target performance as a constraint instead of the maximizing objective. This variant is NP-hard, but can be solved in pseudo-polynomial time.

#index 1826390
#* Capturing an evader in a polygonal environment with obstacles
#@ Deepak Bhadauria;Volkan Isler
#t 2011
#c 11
#% 126316
#% 338087
#% 1768730
#! We study a pursuit-evasion game in which one or more cops try to capture a robber by moving onto the robber's current location. All players have equal maximum velocities. They can observe each other at all times. We show that three cops can capture the robber in any polygonal environment (which can contain any finite number of holes).

#index 1826391
#* Aesthetic guideline driven photography by robots
#@ Raghudeep Gadde;Kamalakar Karlapalem
#t 2011
#c 11
#% 444003
#% 742913
#% 883919
#% 1148278
#% 1677518
#! Robots depend on captured images for perceiving the environment. A robot can replace a human in capturing quality photographs for publishing. In this paper, we employ an iterative photo capture by robots (by repositioning itself) to capture good quality photographs. Our image quality assessment approach is based on few high level features of the image combined with some of the aesthetic guidelines of professional photography. Our system can also be used in web image search applications to rank images. We test our quality assessment approach on a large and diversified dataset and our system is able to achieve a classification accuracy of 79%. We assess the aesthetic error in the captured image and estimate the change required in orientation of the robot to retake an aesthetically better photograph. Our experiments are conducted on NAO robot with no stereo vision. The results demonstrate that our system can be used to capture professional photographs which are in accord with the human professional photography.

#index 1826392
#* Accommodating human variability in human-robot teams through theory of mind
#@ Laura M. Hiatt;Anthony M. Harrison;J. Gregory Trafton
#t 2011
#c 11
#% 1083414
#% 1192713
#% 1797184
#! The variability of human behavior during plan execution poses a difficult challenge for human-robot teams. In this paper, we use the concepts of theory of mind to enable robots to account for two sources of human variability during team operation. When faced with an unexpected action by a human teammate, a robot uses a simulation analysis of different hypothetical cognitive models of the human to identify the most likely cause for the human's behavior. This allows the cognitive robot to account for variances due to both different knowledge and beliefs about the world, as well as different possible paths the human could take with a given set of knowledge and beliefs. An experiment showed that cognitive robots equipped with this functionality are viewed as both more natural and intelligent teammates, compared to both robots who either say nothing when presented with human variability, and robots who simply point out any discrepancies between the human's expected, and actual, behavior. Overall, this analysis leads to an effective, general approach for determining what thought process is leading to a human's actions.

#index 1826393
#* Robotic object detection: learning to improve the classifiers using sparse graphs for path planning
#@ Zhaoyin Jia;Ashutosh Saxena;Tsuhan Chen
#t 2011
#c 11
#% 344587
#% 635689
#% 775282
#% 812418
#% 867753
#% 934104
#% 1038792
#% 1041906
#% 1063860
#% 1074346
#% 1077401
#% 1270311
#! Object detection is a basic skill for a robot to perform tasks in human environments. In order to build a good object classifier, a large training set of labeled images is required; this is typically collected and labeled (often painstakingly) by a human. This method is not scalable and therefore limits the robot's detection performance. We propose an algorithm for a robot to collect more data in the environment during its training phase so that in the future it could detect objects more reliably. The first step is to plan a path for collecting additional training images, which is hard because a previously visited location affects the decision for the future locations. One key component of our work is path planning by building a sparse graph that captures these dependencies. The other key component is our learning algorithm that weighs the errors made in robot's data collection process while updating the classifier. In our experiments, we show that our algorithms enable the robot to improve its object classifiers significantly.

#index 1826394
#* Conics with a common axis of symmetry: properties and applications to camera calibration
#@ Zijian Zhao
#t 2011
#c 11
#% 272714
#% 318135
#% 321583
#% 444059
#% 643698
#% 658444
#% 796242
#% 883938
#% 1402331
#% 1667630
#! We focus on recovering the 2D Euclidean structure in one view from the projections of N parallel conics in this paper. This work denotes that the conic dual to the absolute points is the general form of the conic dual to the circular points, but it does not encode the Euclidean structure. Therefore, we have to recover the circular point-envelope to find out some useful information about the Euclidean structure, which relies on the fact that the line at infinity and the symmetric axis can be recovered. We provide a solution to recover the two lines and deduce the constraints for recovering the conic dual to the circular points, then apply them on the camera calibration. Our work relaxes the problem conditions and gives a more general framework than the past. Experiments with simulated and real data are carried out to show the validity of the proposed algorithm. Especially, our method is applied in the endoscope operation to calibrate the camera for tracking the surgical tools, that is the main interest-point we pay attention to.

#index 1826395
#* User-dependent aspect model for collaborative activity recognition
#@ Vincent W. Zheng;Qiang Yang
#t 2011
#c 11
#% 31919
#% 754115
#% 843360
#% 946811
#% 1024911
#% 1089790
#% 1131951
#% 1250210
#% 1269362
#% 1273828
#% 1275013
#% 1279398
#% 1289473
#% 1305471
#% 1334223
#! Activity recognition aims to discover one or more users' actions and goals based on sensor readings. In the real world, a single user's data are often insufficient for training an activity recognition model due to the data sparsity problem. This is especially true when we are interested in obtaining a personalized model. In this paper, we study how to collaboratively use different users' sensor data to train a model that can provide personalized activity recognition for each user. We propose a user-dependent aspect model for this collaborative activity recognition task. Our model introduces user aspect variables to capture the user grouping information, so that a target user can also benefit from her similar users in the same group to train the recognition model. In this way, we can greatly reduce the need for much valuable and expensive labeled data required in training the recognition model for each user. Our model is also capable of incorporating time information and handling new user in activity recognition. We evaluate our model on a real-world WiFi data set obtained from an indoor environment, and show that the proposed model can outperform several state-of-art baseline algorithms.

#index 1826396
#* Lifted relational Kalman filtering
#@ Jaesik Choi;Abner Guzman-Rivera;Eyal Amir
#t 2011
#c 11
#% 277455
#% 278011
#% 496116
#% 798540
#% 850430
#% 1183091
#% 1246431
#% 1270256
#% 1270263
#% 1272104
#% 1279353
#% 1289560
#% 1289583
#% 1400031
#! Kalman Filtering is a computational tool with widespread applications in robotics, financial and weather forecasting, environmental engineering and defense. Given observation and state transition models, the Kalman Filter (KF) recursively estimates the state variables of a dynamic system. However, the KF requires a cubic time matrix inversion operation at every timestep which prevents its application in domains with large numbers of state variables. We propose Relational Gaussian Models to represent and model dynamic systems with large numbers of variables efficiently. Furthermore, we devise an exact lifted Kalman Filtering algorithm which takes only linear time in the number of random variables at every timestep. We prove that our algorithm takes linear time in the number of state variables even when individual observations apply to each variable. To our knowledge, this is the first lifted (linear time) algorithm for filtering with continuous dynamic relational models.

#index 1826397
#* New complexity results for MAP in Bayesian networks
#@ Cassio P. De Campos
#t 2011
#c 11
#% 44876
#% 150115
#% 341672
#% 408396
#% 593993
#% 1196918
#% 1272025
#% 1650812
#! This paper presents new results for the (partial) maximum a posteriori (MAP) problem in Bayesian networks, which is the problem of querying the most probable state configuration of some of the network variables given evidence. It is demonstrated that the problem remains hard even in networks with very simple topology, such as binary polytrees and simple trees (including the Naive Bayes structure), which extends previous complexity results. Furthermore, a Fully Polynomial Time Approximation Scheme for MAP in networks with bounded treewidth and bounded number of states per variable is developed. Approximation schemes were thought to be impossible, but here it is shown otherwise under the assumptions just mentioned, which are adopted in most applications.

#index 1826398
#* Inference with multinomial data: why to weaken the prior strength
#@ Cassio P. De Campos;Alessio Benavoli
#t 2011
#c 11
#% 263784
#% 340948
#% 1228569
#% 1417383
#! This paper considers inference from multinomial data and addresses the problem of choosing the strength of the Dirichlet prior under a mean-squared error criterion. We compare the Maximum Likelihood Estimator (MLE) and the most commonly used Bayesian estimators obtained by assuming a prior Dirichlet distribution with "noninformative" prior parameters, that is, the parameters of the Dirichlet are equal and altogether sum up to the so called strength of the prior. Under this criterion, MLE becomes more preferable than the Bayesian estimators at the increase of the number of categories k of the multinomial, because non-informative Bayesian estimators induce a region where they are dominant that quickly shrinks with the increase of k. This can be avoided if the strength of the prior is not kept constant but decreased with the number of categories. We argue that the strength should decrease at least k times faster than usual estimators do.

#index 1826399
#* Motor simulation via coupled internal models using sequential Monte Carlo
#@ Haris Dindo;Daniele Zambuto;Giovanni Pezzulo
#t 2011
#c 11
#% 222070
#% 244830
#% 272374
#% 424819
#% 716892
#% 856763
#% 880977
#% 880981
#% 891559
#% 1289578
#% 1781569
#! We describe a generative Bayesian model for action understanding in which inverse-forward internal model pairs are considered 'hypotheses' of plausible action goals that are explored in parallel via an approximate inference mechanism based on sequential Monte Carlo methods. The reenactment of internal model pairs can be considered a form of motor simulation, which supports both perceptual prediction and action understanding at the goal level. However, this procedure is generally considered to be computationally inefficient. We present a model that dynamically reallocates computational resources to more accurate internal models depending on both the available prior information and the prediction error of the inverse-forward models, and which leads to successful action recognition. We present experimental results that test the robustness and efficiency of our model in real-world scenarios.

#index 1826400
#* Resolute choice in sequential decision problems with multiple priors
#@ Hélène Fargier;Gildas Jeantet;Olivier Spanjaard
#t 2011
#c 11
#% 1332298
#% 1565907
#! This paper is devoted to sequential decision making under uncertainty, in the multi-prior framework of Gilboa and Schmeidler [1989]. In this setting, a set of probability measures (priors) is defined instead of a single one, and the decision maker selects a strategy that maximizes the minimum possible value of expected utility over this set of priors. We are interested here in the resolute choice approach, where one initially commits to a complete strategy and never deviates from it later. Given a decision tree representation with multiple priors, we study the problem of determining an optimal strategy from the root according to min expected utility. We prove the intractability of evaluating a strategy in the general case. We then identify different properties of a decision tree that enable to design dedicated resolution procedures. Finally, experimental results are presented that evaluate these procedures.

#index 1826401
#* Pairwise decomposition for combinatorial optimization in graphical models
#@ Aurélie Favier;Simon De Givry;Andrés Legarra;Thomas Schiex
#t 2011
#c 11
#% 534657
#% 1058686
#% 1261231
#% 1292078
#% 1383595
#% 1417383
#% 1477072
#% 1784146
#! We propose a new additive decomposition of probability tables that preserves equivalence of the joint distribution while reducing the size of potentials, without extra variables. We formulate the Most Probable Explanation (MPE) problem in belief networks as a Weighted Constraint Satisfaction Problem (WCSP). Our pairwise decomposition allows to replace a cost function with smaller-arity functions. The resulting pairwise decomposed WCSP is then easier to solve using state-of-the-art WCSP techniques. Although testing pairwise decomposition is equivalent to testing pairwise independence in the original belief network, we show how to efficiently test and enforce it, even in the presence of hard constraints. Furthermore, we infer additional information from the resulting nonbinary cost functions by projecting&subtracting them on binary functions. We observed huge improvements by preprocessing with pairwise decomposition and project&subtract compared to the current state-of-the-art solvers on two difficult sets of benchmark.

#index 1826402
#* Randomized sensing in adversarial environments
#@ Andreas Krause;Alex Roper;Daniel Golovin
#t 2011
#c 11
#% 256685
#% 850011
#% 1061585
#% 1061588
#% 1215597
#% 1269936
#% 1272274
#% 1300139
#% 1305316
#! How should we manage a sensor network to optimally guard security-critical infrastructure? How should we coordinate search and rescue helicopters to best locate survivors after a major disaster? In both applications, we would like to control sensing resources in uncertain, adversarial environments. In this paper, we introduce RSENSE, an efficient algorithm which guarantees near-optimal randomized sensing strategies whenever the detection performance satisfies submodularity, a natural diminishing returns property, for any fixed adversarial scenario. Our approach combines techniques from game theory with submodular optimization. The RSENSE algorithm applies to settings where the goal is to manage a deployed sensor network or to coordinate mobile sensing resources (such as unmanned aerial vehicles). We evaluate our algorithms on two real-world sensing problems.

#index 1826403
#* Scalable multiagent planning using probabilistic inference
#@ Akshat Kumar;Shlomo Zilberstein;Marc Toussaint
#t 2011
#c 11
#% 416636
#% 450852
#% 719917
#% 876063
#% 1084070
#% 1269380
#% 1272052
#% 1272071
#% 1272221
#% 1273798
#% 1273919
#% 1279314
#% 1305322
#% 1456804
#! Multiagent planning has seen much progress with the development of formal models such as Dec-POMDPs. However, the complexity of these models--NEXP-Complete even for two agents-- has limited scalability. We identify certain mild conditions that are sufficient to make multiagent planning amenable to a scalable approximation w.r.t. the number of agents. This is achieved by constructing a graphical model in which likelihood maximization is equivalent to plan optimization. Using the Expectation-Maximization framework for likelihood maximization, we show that the necessary inference can be decomposed into processes that often involve a small subset of agents, thereby facilitating scalability. We derive a global update rule that combines these local inferences to monotonically increase the overall solution quality. Experiments on a large multiagent planning benchmark confirm the benefits of the new approach in terms of runtime and scalability.

#index 1826404
#* A trust prediction approach capturing agents' dynamic behavior
#@ Xin Liu;Anwitaman Datta
#t 2011
#c 11
#% 577367
#% 762655
#% 791020
#% 856790
#% 867150
#% 943777
#% 962947
#% 1092413
#% 1292466
#% 1433661
#% 1453087
#! Predicting trust among the agents is of great importance to various open distributed settings (e.g., emarket, peer-to-peer networks, etc.) in that dishonest agents can easily join the system and achieve their goals by circumventing agreed rules, or gaining unfair advantages, etc. Most existing trust mechanisms derive trust by statistically investigating the target agent's historical information. However, even if rich historical information is available, it is challenging to model an agent's behavior since an intelligent agent may strategically change its behavior to maximize its profits. We therefore propose a trust prediction approach to capture dynamic behavior of the target agent. Specifically, we first identify features which are capable of describing/ representing context of a transaction. Then we use these features to measure similarity between context of the potential transaction and that of previous transactions to estimate trustworthiness of the potential transaction based on previous similar transactions' outcomes. Evaluation using real auction data and synthetic data demonstrates efficacy of our approach in comparison with an existing representative trust mechanism.

#index 1826405
#* Log-linear description logics
#@ Mathias Niepert;Jan Noessner;Heiner Stuckenschmidt
#t 2011
#c 11
#% 335852
#% 850430
#% 935898
#% 977235
#% 1000502
#% 1136065
#% 1249506
#% 1250579
#% 1289408
#% 1416205
#% 1417383
#% 1478789
#% 1495929
#! Log-linear description logics are a family of probabilistic logics integrating various concepts and methods from the areas of knowledge representation and reasoning and statistical relational AI. We define the syntax and semantics of log-linear description logics, describe a convenient representation as sets of first-order formulas, and discuss computational and algorithmic aspects of probabilistic queries in the language. The paper concludes with an experimental evaluation of an implementation of a log-linear DL reasoner.

#index 1826406
#* Eliciting additive reward functions for Markov decision processes
#@ Kevin Regan;Craig Boutilier
#t 2011
#c 11
#% 363744
#% 452359
#% 1289556
#% 1291488
#% 1417103
#! Specifying the reward function of a Markov decision process (MDP) can be demanding, requiring human assessment of the precise quality of, and tradeoffs among, various states and actions. However, reward functions often possess considerable structure which can be leveraged to streamline their specification. We develop new, decision-theoretically sound heuristics for eliciting rewards for factored MDPs whose reward functions exhibit additive independence. Since we can often find good policies without complete reward specification, we also develop new (exact and approximate) algorithms for robust optimization of imprecise-reward MDPs with such additive reward. Our methods are evaluated in two domains: autonomic computing and assistive technology.

#index 1826407
#* Robust online optimization of reward-uncertain MDPs
#@ Kevin Regan;Craig Boutilier
#t 2011
#c 11
#% 363744
#% 466418
#% 695957
#% 810882
#% 959522
#% 983832
#% 1272052
#% 1288650
#% 1291488
#% 1417103
#% 1778828
#% 1826406
#! Imprecise-reward Markov decision processes (IRMDPs) are MDPs in which the reward function is only partially specified (e.g., by some elicitation process). Recent work using minimax regret to solve IRMDPs has shown, despite their theoretical intractability, how the set of policies that are nondominated w.r.t. reward uncertainty can be exploited to accelerate regret computation. However, the number of nondominated policies is generally so large as to undermine this leverage. In this paper, we show how the quality of the approximation can be improved online by pruning/adding nondominated policies during reward elicitation, while maintaining computational tractability. Drawing insights from the POMDP literature, we also develop a new anytime algorithm for constructing the set of nondominated policies with provable (anytime) error bounds. These bounds can be exploited to great effect in our online approximation scheme.

#index 1826408
#* Finding (α, ϑ)-solutions via sampled SCSPs
#@ Roberto Rossi;Brahim Hnich;S. Armagan Tarim;Steven Prestwich
#t 2011
#c 11
#% 102123
#% 862121
#% 1095849
#% 1412965
#% 1412982
#! We discuss a novel approach for dealing with single-stage stochastic constraint satisfaction problems (SCSPs) that include random variables over a continuous or large discrete support. Our approach is based on two novel tools: sampled SCSPs and (α, ϑ)-solutions. Instead of explicitly enumerating a very large or infinite set of future scenarios, we employ statistical estimation to determine if a given assignment is consistent for a SCSP. As in statistical estimation, the quality of our estimate is determined via confidence interval analysis. In contrast to existing approaches based on sampling, we provide likelihood guarantees for the quality of the solutions found. Our approach can be used in concert with existing strategies for solving SCSPs.

#index 1826409
#* Lifted probabilistic inference by first-order knowledge compilation
#@ Guy Van Den Broeck;Nima Taghipour;Wannes Meert;Jesse Davis;Luc De Raedt
#t 2011
#c 11
#% 944140
#% 1000502
#% 1036395
#% 1270256
#% 1270261
#% 1272349
#% 1279353
#% 1289560
#% 1349569
#% 1416197
#% 1417086
#% 1650767
#! Probabilistic logical languages provide powerful formalisms for knowledge representation and learning. Yet performing inference in these languages is extremely costly, especially if it is done at the propositional level. Lifted inference algorithms, which avoid repeated computation by treating indistinguishable groups of objects as one, help mitigate this cost. Seeking inspiration from logical inference, where lifted inference (e.g., resolution) is commonly performed, we develop a model theoretic approach to probabilistic lifted inference. Our algorithm compiles a first-order probabilistic theory into a first-order deterministic decomposable negation normal form (d-DNNF) circuit. Compilation offers the advantage that inference is polynomial in the size of the circuit. Furthermore, by borrowing techniques from the knowledge compilation literature our algorithm effectively exploits the logical structure (e.g., context-specific independencies) within the first-order model, which allows more computation to be done at the lifted level. An empirical comparison demonstrates the utility of the proposed approach.

#index 1826410
#* Learning optimal Bayesian networks using A* search
#@ Changhe Yuan;Brandon Malone;Xiaojian Wu
#t 2011
#c 11
#% 129987
#% 722804
#% 763715
#% 1211704
#% 1272326
#% 1650289
#% 1650483
#! This paper formulates learning optimal Bayesian network as a shortest path finding problem. An A* search algorithm is introduced to solve the problem. With the guidance of a consistent heuristic, the algorithm learns an optimal Bayesian network by only searching the most promising parts of the solution space. Empirical results show that the A* search algorithm significantly improves the time and space efficiency of existing methods on a set of benchmark datasets.

#index 1826411
#* Bayesian chain classifiers for multidimensional classification
#@ Julio H. Zaragoza;L. Enrique Sucar;Eduardo F. Morales;Concha Bielza;Pedro Larrañaga
#t 2011
#c 11
#% 129987
#% 172544
#% 889101
#% 950571
#% 1015814
#% 1095862
#% 1117464
#% 1134224
#% 1264044
#% 1267771
#% 1274835
#% 1570399
#! In multidimensional classification the goal is to assign an instance to a set of different classes. This task is normally addressed either by defining a compound class variable with all the possible combinations of classes (label power-set methods, LPMs) or by building independent classifiers for each class (binary-relevance methods, BRMs). However, LPMs do not scale well and BRMs ignore the dependency relations between classes. We introduce a method for chaining binary Bayesian classifiers that combines the strengths of classifier chains and Bayesian networks for multidimensional classification. The method consists of two phases. In the first phase, a Bayesian network (BN) that represents the dependency relations between the class variables is learned from data. In the second phase, several chain classifiers are built, such that the order of the class variables in the chain is consistent with the class BN. At the end we combine the results of the different generated orders. Our method considers the dependencies between class variables and takes advantage of the conditional independence relations to build simplified models. We perform experiments with a chain of naïve Bayes classifiers on different benchmark multidimensional datasets and show that our approach outperforms other state-of-the-art methods.

#index 1826412
#* CCR: a content-collaborative reciprocal recommender for online dating
#@ Joshua Akehurst;Irena Koprinska;Kalina Yacef;Luiz Pizzato;Judy Kay;Tomasz Rej
#t 2011
#c 11
#% 414514
#% 835906
#% 976808
#% 1396093
#% 1396094
#% 1450837
#% 1476471
#! We present a new recommender system for online dating. Using a large dataset from a major online dating website, we first show that similar people, as defined by a set of personal attributes, like and dislike similar people and are liked and disliked by similar people. This analysis provides the foundation for our Content-Collaborative Reciprocal (CCR) recommender approach. The content-based part uses selected user profile features and similarity measure to generate a set of similar users. The collaborative filtering part uses the interactions of the similar users, including the people they like/dislike and are liked/disliked by, to produce reciprocal recommendations. CCR addresses the cold start problem of new users joining the site by being able to provide recommendations immediately, based on their profiles. Evaluation results show that the success rate of the recommendations is 69.26% compared with a baseline of 35.19% for the top 10 ranked recommendations.

#index 1826413
#* Relation adaptation: learning to extract novel relations with minimum supervision
#@ Danushka Bollegala;Yutaka Matsuo;Mitsuru Ishizuka
#t 2011
#c 11
#% 756964
#% 770830
#% 939384
#% 1190120
#% 1250378
#% 1275182
#% 1330551
#% 1399948
#% 1470649
#! Extracting the relations that exist between two entities is an important step in numerous Web-related tasks such as information extraction. A supervised relation extraction system that is trained to extract a particular relation type might not accurately extract a new type of a relation for which it has not been trained. However, it is costly to create training data manually for every new relation type that one might want to extract. We propose a method to adapt an existing relation extraction system to extract new relation types with minimum supervision. Our proposed method comprises two stages: learning a lower-dimensional projection between different relations, and learning a relational classifier for the target relation type with instance sampling. We evaluate the proposed method using a dataset that contains 2000 instances for 20 different relation types. Our experimental results show that the proposed method achieves a statistically significant macro-average F-score of 62.77. Moreover, the proposed method outperforms numerous baselines and a previously proposed weakly-supervised relation extraction method.

#index 1826414
#* Leveraging unlabeled data to scale blocking for record linkage
#@ Yunbo Cao;Zhiyuan Chen;Jiamin Zhu;Pei Yue;Chin-Yew Lin;Yong Yu
#t 2011
#c 11
#% 310516
#% 328186
#% 376266
#% 480907
#% 659991
#% 898309
#% 915242
#% 967272
#% 1206695
#% 1217163
#% 1250576
#% 1372726
#! Record linkage is the process of matching records between two (or multiple) data sets that represent the same real-world entity. An exhaustive record linkage process involves computing the similarities between all pairs of records, which can be very expensive for large data sets. Blocking techniques alleviate this problem by dividing the records into blocks and only comparing records within the same block. To be adaptive from domain to domain, one category of blocking technique formalizes 'construction of blocking scheme' as a machine learning problem. In the process of learning the best blocking scheme, previous learning-based techniques utilize only a set of labeled data. However, since the set of labeled data is usually not large enough to well characterize the unseen (unlabeled) data, the resultant blocking scheme may poorly perform on the unseen data by generating too many candidate matches. To address that, in this paper, we propose to utilize unlabeled data (in addition to labeled data) for learning blocking schemes. Our experimental results show that using unlabeled data in learning can remarkably reduce the number of candidate matches while keeping the same level of coverage for true matches.

#index 1826415
#* A convex formulation of modularity maximization for community detection
#@ Emprise Y. K. Chan;Dit-Yan Yeung
#t 2011
#c 11
#% 592143
#% 871315
#% 1034723
#% 1224058
#! Complex networks pervade in diverse areas ranging from the natural world to the engineered world and from traditional application domains to new and emerging domains, including web-based social networks. Of crucial importance to the understanding of many network phenomena, dynamics and functions is the study of network structural properties. One important type of network structure is known as community structure which refers to the existence of communities that are tightly knit local groups with relatively dense connections among their members. Community detection is the problem of detecting these communities automatically. In this paper, based on the modularity measure proposed previously for community detection, we first propose a reformulation of an optimization problem for the 2-partition problem. Based on this new formulation, we can extend it naturally for tackling the general k-partition problem directly without having to tackle multiple 2-partition subproblems like what other methods do. We then propose a convex relaxation scheme to give an iterative algorithm which solves a simple quadratic program in each iteration. We empirically compare our method with some related methods and find that our method is both scalable and competitive in performance via maintaining a good tradeoff between efficiency and quality.

#index 1826416
#* What to ask to an incomplete semantic web reasoner?
#@ Bernardo Cuenca Grau;Giorgos Stoilos
#t 2011
#c 11
#% 577305
#% 665856
#% 826032
#% 992962
#% 1016216
#% 1274815
#% 1289408
#% 1305620
#% 1374374
#% 1471545
#% 1540338
#! Largely motivated by Semantic Web applications, many highly scalable, but incomplete, query answering systems have been recently developed. Evaluating the scalability-completeness trade-off exhibited by such systems is an important requirement for many applications. In this paper, we address the problem of formally comparing complete and incomplete systems given an ontology schema (or TBox) T. We formulate precise conditions on TBoxes T expressed in the EL, QL or RL profile of OWL 2 under which an incomplete system is indistinguishable from a complete one w.r.t. T, regardless of the input query and data. Our results also allow us to quantify the "degree of incompleteness" of a given system w.r.t. T as well as to automatically identify concrete queries and data patterns for which the incomplete system will miss answers.

#index 1826417
#* The modular structure of an ontology: atomic decomposition
#@ Chiara Del Vescovo;Bijan Parsia;Uli Sattler;Thomas Schneider
#t 2011
#c 11
#% 665856
#% 763751
#% 1217753
#% 1217766
#% 1272206
#% 1305422
#% 1375725
#% 1413139
#% 1413142
#! Extracting a subset of a given ontology that captures all the ontology's knowledge about a specified set of terms is a well-understood task. This task can be based, for instance, on locality-based modules. However, a single module does not allow us to understand neither topicality, connectedness, structure, or superfluous parts of an ontology, nor agreement between actual and intended modeling. The strong logical properties of locality-based modules suggest that the family of all such modules of an ontology can support comprehension of the ontology as a whole. However, extracting that family is not feasible, since the number of locality-based modules of an ontology can be exponential w.r.t. its size. In this paper we report on a new approach that enables us to efficiently extract a polynomial representation of the family of all locality-based modules of an ontology. We also describe the fundamental algorithm to pursue this task, and report on experiments carried out and results obtained.

#index 1826418
#* Fast algorithm for affinity propagation
#@ Yasuhiro Fujiwara;Go Irie;Tomoe Kitahara
#t 2011
#c 11
#% 296738
#% 1047785
#% 1055701
#% 1131899
#% 1190131
#% 1279769
#% 1334894
#% 1338554
#! Affinity Propagation is a state-of-the-art clustering method recently proposed by Frey and Dueck. It has been successfully applied to broad areas of computer science research because it has much better clustering performance than traditional clustering methods such as k-means. In order to obtain high quality sets of clusters, the original Affinity Propagation algorithm iteratively exchanges real-valued messages between all pairs of data points until convergence. However, this algorithm does not scale for large datasets because it requires quadratic CPU time in the number of data points to compute the messages. This paper proposes an efficient Affinity Propagation algorithm that guarantees the same clustering result as the original algorithm after convergence. The heart of our approach is (1) to prune unnecessary message exchanges in the iterations and (2) to compute the convergence values of prunedmessages after the iterations to determine clusters. Experimental evaluations on several different datasets demonstrate the effectiveness of our algorithm.

#index 1826419
#* Mining the web for the "voice of the herd" to track stock market bubbles
#@ Aaron Gerow;Mark T. Keane
#t 2011
#c 11
#% 262059
#% 301590
#% 616104
#% 786511
#% 854200
#% 939633
#! We show that power-law analyses of financial commentaries from newspaper web-sites can be used to identify stock market bubbles, supplementing traditional volatility analyses. Using a four-year corpus of 17,713 online, finance-related articles (10M+ words) from the Financial Times, the New York Times, and the BBC, we show that week-to-week changes in power-law distributions reflect market movements of the Dow Jones Industrial Average (DJI), the FTSE-100, and the NIKKEI-225, Notably, the statistical regularities in language track the 2007 stock market bubble, showing emerging structure in the language of commentators, as progressively greater agreement arose in their positive perceptions of the market. Furthermore, during the bubble period, a marked divergence in positive language occurs as revealed by a Kullback-Leibler analysis.

#index 1826420
#* Relevance feedback between web search and the semantic web
#@ Harry Halpin;Victor Lavrenko
#t 2011
#c 11
#% 1055815
#% 1131703
#% 1150587
#% 1190105
#% 1413124
#% 1426537
#! We investigate the possibility of using structured data to improve search over unstructured documents. In particular, we use relevance feedback to create a 'virtuous cycle' between structured data from the Semantic Web and web-pages from the hypertext Web. Previous approaches have generally considered searching over the Semantic Web and hypertext Web to be entirely disparate, indexing and searching over different domains. Our novel approach is to use relevance feedback from hypertext Web results to improve Semantic Web search, and results from the Semantic Web to improve the retrieval of hypertext Web data. In both cases, our evaluation is based on certain kinds of informational queries (abstract concepts, people, and places) selected from a real-life query log and checked by human judges. We show our relevance model-based system is better than the performance of real-world search engines for both hypertext and Semantic Web search, and we also investigate Semantic Web inference and pseudo-relevance feedback.

#index 1826421
#* Finding the hidden gems: recommending untagged music
#@ Ben Horsburgh;Susan Craw;Stewart Massie;Robin Boswell
#t 2011
#c 11
#% 1017565
#% 1298156
#% 1369537
#% 1382905
#% 1472230
#% 1484439
#! We have developed a novel hybrid representation for Music Information Retrieval. Our representation is built by incorporating audio content into the tag space in a tag-track matrix, and then learning hybrid concepts using latent semantic analysis. We apply this representation to the task of music recommendation, using similarity-based retrieval from a query music track. We also develop a new approach to evaluating music recommender systems, which is based upon the relationship of users liking tracks. We are interested in measuring the recommendation quality, and the rate at which cold-start tracks are recommended. Our hybrid representation is able to outperform a tag-only representation, in terms of both recommendation quality and the rate that cold-start tracks are included as recommendations.

#index 1826422
#* Fashion coordinates recommender system using photographs from fashion magazines
#@ Tomoharu Iwata;Shinji Watanabe;Hiroshi Sawada
#t 2011
#c 11
#% 120270
#% 247889
#% 642990
#% 643007
#% 722904
#% 736300
#% 760805
#% 936962
#% 1253854
#% 1305518
#% 1338620
#% 1650298
#! Fashion magazines contain a number of photographs of fashion models, and their clothing coordinates serve as useful references. In this paper, we propose a recommender system for clothing coordinates using full-body photographs from fashion magazines. The task is that, given a photograph of a fashion item (e.g. tops) as a query, to recommend a photograph of other fashion items (e.g. bottoms) that is appropriate to the query. With the proposed method, we use a probabilistic topic model for learning information about coordinates from visual features in each fashion item region. We demonstrate the effectiveness of the proposed method using real photographs from a fashion magazine and two fashion style sharing services with the task of making top (bottom) recommendations given bottom (top) photographs.

#index 1826423
#* Mining longitudinal network for predicting company value
#@ Yingzi Jin;Ching-Yung Lin;Yutaka Matsuo;Mituru Ishizuka
#t 2011
#c 11
#% 943088
#% 1270272
#! Real-world social networks are dynamic in nature. Companies continue to collaborate, align strategically, acquire, and merge over time, and receive positive/negative impact from other companies. Consequently, their performance changes with time. If one can understand what types of network changes affect a company's value, he/she can predict the future value of the company, grasp industry innovations, and make business more successful. However, it often requires continuous records of relational changes, which are often difficult to track for companies, and the models of mining longitudinal network are quite complicated. In this study, we developed algorithms and a system to infer large-scale evolutionary company networks from public news during 1981-2009. Then, based on how networks change over time, as well as the financial information of the companies, we predicted company profit growth. This is the first study of longitudinal network-mining-based company performance analysis in the literature

#index 1826424
#* Context sensitive topic models for author influence in document networks
#@ Saurabh Kataria;Prasenjit Mitra;Cornelia Caragea;C. Lee Giles
#t 2011
#c 11
#% 722904
#% 788094
#% 881534
#% 983833
#% 1083684
#% 1133171
#% 1186932
#% 1211773
#% 1272187
#% 1392465
#% 1544149
#% 1650298
#! In a document network such as a citation network of scientific documents, web-logs, etc., the content produced by authors exhibits their interest in certain topics. In addition some authors influence other authors' interests. In this work, we propose to model the influence of cited authors along with the interests of citing authors. Moreover, we hypothesize that apart from the citations present in documents, the context surrounding the citation mention provides extra topical information about the cited authors. However, associating terms in the context to the cited authors remains an open problem. We propose novel document generation schemes that incorporate the context while simultaneously modeling the interests of citing authors and influence of the cited authors. Our experiments show significant improvements over baseline models for various evaluation criteria such as link prediction between document and cited author, and quantitatively explaining unseen text.

#index 1826425
#* Multi-perspective linking of news articles within a repository
#@ Arpit Khurdiya;Lipika Dey;Nidhi Raj;Sk. Mirajul Haque
#t 2011
#c 11
#% 722904
#% 741418
#% 747824
#% 766493
#% 839839
#% 974035
#% 1065814
#% 1136605
#! Given the number of online sources for news, the volumes of news generated are so daunting that gaining insight from these collections become impossible without some aid to link them. Semantic linking of news articles facilitates grouping of similar or relevant news stories together for ease of human consumption. For example, a political analyst may like to have a single view of all news articles that report visits of State heads of different countries to a single country to make an in-depth analytical report on the possible impacts of all associated events. It is likely that no news source links all the relevant news together. In this paper, we discuss a multi-resolution, multi-perspective news analysis system that can link news articles collected from diverse sources over a period of time. The distinctive feature of the proposed news linking system is its capability to simultaneously link news articles and stories at multiple levels of granularity. At the lowest level several articles reporting the same event are linked together. Higher level groupings are more contextual and semantic. We have deployed a range of algorithms that use statistical text processing and Natural Language Processing techniques. The system is incremental in nature and depicts how stories have evolved over time along with main actors and activities. It also illustrates how a single story diverges into multiple themes or multiple stories converge due to conceptual similarity. Accuracy of linking thematically and conceptually linked news articles are also presented.

#index 1826426
#* Social abstract argumentation
#@ João Leite;João Martins
#t 2011
#c 11
#% 198464
#% 825547
#% 992260
#% 1111200
#% 1272060
#% 1526846
#! In this paper we take a step towards using Argumentation in Social Networks and introduce Social Abstract Argumentation Frameworks, an extension of Dung's Abstract Argumentation Frameworks that incorporates social voting. We propose a class of semantics for these new Social Abstract Argumentation Frameworks and prove some important non-trivial properties which are crucial for their applicability in Social Networks.

#index 1826427
#* Cross-domain collaborative filtering over time
#@ Bin Li;Xingquan Zhu;Ruijiang Li;Chengqi Zhang;Xiangyang Xue;Xindong Wu
#t 2011
#c 11
#% 173879
#% 1211767
#% 1214666
#% 1270314
#% 1270334
#% 1275221
#% 1407018
#% 1464068
#% 1476455
#% 1476500
#% 1650298
#! Collaborative filtering (CF) techniques recommend items to users based on their historical ratings. In real-world scenarios, user interests may drift over time since they are affected by moods, contexts, and pop culture trends. This leads to the fact that a user's historical ratings comprise many aspects of user interests spanning a long time period. However, at a certain time slice, one user's interest may only focus on one or a couple of aspects. Thus, CF techniques based on the entire historical ratings may recommend inappropriate items. In this paper, we consider modeling user-interest drift over time based on the assumption that each user has multiple counterparts over temporal domains and successive counterparts are closely related. We adopt the cross-domain CF framework to share the static group-level rating matrix across temporal domains, and let user-interest distribution over item groups drift slightly between successive temporal domains. The derived method is based on a Bayesian latent factor model which can be inferred using Gibbs sampling. Our experimental results show that our method can achieve state-of-the-art recommendation performance as well as explicitly track and visualize user-interest drift over time.

#index 1826428
#* Minimally complete recommendations
#@ David McSherry
#t 2011
#c 11
#% 428440
#% 490786
#% 566642
#% 764483
#% 866951
#% 1272133
#% 1396095
#% 1727819
#! Recent research has highlighted the benefits of completeness as a retrieval criterion in recommender systems. In complete retrieval, any subset of the constraints in a given query that can be satisfied must be satisfied by at least one of the retrieved products. Minimal completeness (i.e., always retrieving the smallest set of products needed for completeness) is also beginning to attract research interest as a way to minimize cognitive load in the approach. Other important features of a retrieval algorithm's behavior include the diversity of the retrieved products and the order in which they are presented to the user. In this paper, we present a new algorithm for minimally complete retrieval (MCR) in which the ranking of retrieved products is primarily based on the number of constraints that they satisfy, but other measures such as similarity or utility can also be used to inform the retrieval process. We also present theoretical and empirical results that demonstrate our algorithm's ability to minimize cognitive load while ensuring the completeness and diversity of the retrieved products.

#index 1826429
#* User similarity from linked taxonomies: subjective assessments of items
#@ Makoto Nakatsuji;Yasuhiro Fujiwara;Toshio Uchiyama;Ko Fujimura
#t 2011
#c 11
#% 173879
#% 576214
#% 805841
#% 1052902
#% 1077150
#% 1201363
#% 1215363
#% 1227601
#% 1250380
#% 1274840
#% 1287228
#% 1482273
#% 1544421
#! Subjective assessments (SAs) are assigned by users against items, such as 'elegant' and 'gorgeous', and are common in reviews/tags in many online-sites. However, previous studies fail to effectively use SAs for improving recommendations because few users rate the same items with the same SAs, which triggers the sparsity problem in collaborative filtering. We propose a novel algorithm that links a taxonomy of items to a taxonomy of SAs to assess user interests in detail. That is, it merges the SAs assigned by users against an item into subjective classes (SCs) and reflects the SAs/SCs assigned to an item to its classes. Thus, it can measure the similarity of users from not only SAs/SCs assigned to items but also their classes, which overcomes the sparsity problem. Our evaluation, which uses data from a popular restaurant review site, shows that our method generates more accurate recommendations than previous methods. Furthermore, we find that SAs frequently assigned on a few item classes are more useful than those widely assigned against many item classes in terms of recommendation accuracy

#index 1826430
#* LIMES: a time-efficient approach for large-scale link discovery on the web of data
#@ Axel-Cyrille Ngonga Ngomo;Sören Auer
#t 2011
#c 11
#% 853027
#% 1022250
#% 1129527
#% 1250667
#% 1328082
#% 1333469
#% 1409954
#% 1540348
#% 1737596
#% 1815525
#! The Linked Data paradigm has evolved into a powerful enabler for the transition from the document-oriented Web into the Semantic Web. While the amount of data published as Linked Data grows steadily and has surpassed 25 billion triples, less than 5% of these triples are links between knowledge bases. Link discovery frameworks provide the functionality necessary to discover missing links between knowledge bases. Yet, this task requires a significant amount of time, especially when it is carried out on large data sets. This paper presents and evaluates LIMES, a novel time-efficient approach for link discovery in metric spaces. Our approach utilizes the mathematical characteristics of metric spaces during the mapping process to filter out a large number of those instance pairs that do not suffice the mapping conditions. We present the mathematical foundation and the core algorithms employed in LIMES. We evaluate our algorithms with synthetic data to elucidate their behavior on small and large data sets with different configurations and compare the runtime of LIMES with another state-of-the-art link discovery tool.

#index 1826431
#* Transfer learning to predict missing ratings via heterogeneous user feedbacks
#@ Weike Pan;Nathan N. Liu;Evan W. Xiang;Qiang Yang
#t 2011
#c 11
#% 124010
#% 274703
#% 1083696
#% 1116993
#% 1211767
#% 1232035
#% 1291600
#% 1305617
#% 1333074
#% 1464068
#% 1472299
#% 1480681
#% 1482349
#% 1558466
#% 1619120
#! Data sparsity due to missing ratings is a major challenge for collaborative filtering (CF) techniques in recommender systems. This is especially true for CF domains where the ratings are expressed numerically. We observe that, while we may lack the information in numerical ratings, we may have more data in the form of binary ratings. This is especially true when users can easily express themselves with their likes and dislikes for certain items. In this paper, we explore how to use the binary preference data expressed in the form of like/dislike to help reduce the impact of data sparsity of more expressive numerical ratings. We do this by transferring the rating knowledge from some auxiliary data source in binary form (that is, likes or dislikes), to a target numerical rating matrix. Our solution is to model both numerical ratings and like/dislike in a principled way, using a novel framework of Transfer by Collective Factorization (TCF). In particular, we construct the shared latent space collectively and learn the data-dependent effect separately. A major advantage of the TCF approach over previous collective matrix factorization (or bifactorization) methods is that we are able to capture the data-dependent effect when sharing the data-independent knowledge, so as to increase the over-all quality of knowledge transfer. Experimental results demonstrate the effectiveness of TCF at various sparsity levels as compared to several state-of-the-art methods.

#index 1826432
#* Making better informed trust decisions with generalized fact-finding
#@ Jeff Pasternack;Dan Roth
#t 2011
#c 11
#% 290830
#% 1019061
#% 1081580
#% 1328156
#% 1355029
#% 1484339
#% 1560195
#! Information retrieval may suggest a document, and information extraction may tell us what it says, but which information sources do we trust and which assertions do we believe when different authors make conflicting claims? Trust algorithms known as fact-finders attempt to answer these questions, but consider only which source makes which claim, ignoring a wealth of background knowledge and contextual detail such as the uncertainty in the information extraction of claims from documents, attributes of the sources, the degree of similarity among claims, and the degree of certainty expressed by the sources. We introduce a new, generalized fact-finding framework able to incorporate this additional information into the fact-finding process. Experiments using several state-of-theart fact-finding algorithms demonstrate that generalized fact-finders achieve significantly better performance than their original variants on both semi-synthetic and real-world problems.

#index 1826433
#* Short text conceptualization using a probabilistic knowledgebase
#@ Yangqiu Song;Haixun Wang;Zhongyuan Wang;Hongsong Li;Weizhu Chen
#t 2011
#c 11
#% 405391
#% 722902
#% 722904
#% 741058
#% 754068
#% 756964
#% 956564
#% 1055680
#% 1063570
#% 1074073
#% 1214660
#% 1250362
#% 1269899
#% 1270267
#% 1275182
#% 1289518
#% 1470582
#! Most text mining tasks, including clustering and topic detection, are based on statistical methods that treat text as bags of words. Semantics in the text is largely ignored in the mining process, and mining results often have low interpretability. One particular challenge faced by such approaches lies in short text understanding, as short texts lack enough content from which statistical conclusions can be drawn easily. In this paper, we improve text understanding by using a probabilistic knowledgebase that is as rich as our mental world in terms of the concepts (of worldly facts) it contains. We then develop a Bayesian inference mechanism to conceptualize words and short text. We conducted comprehensive experiments on conceptualizing textual terms, and clustering short pieces of text such as Twitter messages. Compared to purely statistical methods such as latent semantic topic modeling or methods that use existing knowledge-bases (e.g., WordNet, Freebase and Wikipedia), our approach brings significant improvements in short text understanding as reflected by the clustering accuracy.

#index 1826434
#* A wikipedia based semantic graph model for topic tracking in blogosphere
#@ Jintao Tang;Ting Wang;Qin Lu;Ji Wang;Wenjie Li
#t 2011
#c 11
#% 245500
#% 342596
#% 575570
#% 722904
#% 727861
#% 794513
#% 832271
#% 939376
#% 989613
#% 1055680
#% 1130858
#% 1190121
#% 1250381
#% 1275012
#% 1280619
#% 1351373
#% 1408776
#! There are two key issues for information diffusion in blogosphere: (1) blog posts are usually short, noisy and contain multiple themes, (2) information diffusion through blogosphere is primarily driven by the "word-of-mouth" effect, thus making topics evolve very fast. This paper presents a novel topic tracking approach to deal with these issues by modeling a topic as a semantic graph, in which the semantic relatedness between terms are learned from Wikipedia. For a given topic/post, the name entities, Wikipedia concepts, and the semantic relatedness are extracted to generate the graph model. Noises are filtered out through the graph clustering algorithm. To handle topic evolution, the topic model is enriched by using Wikipedia as background knowledge. Furthermore, graph edit distance is used to measure the similarity between a topic and its posts. The proposed method is tested by using the real-world blog data. Experimental results show the advantage of the proposed method on tracking the topic in short, noisy texts.

#index 1826435
#* Matching large ontologies based on reduction anchors
#@ Peng Wang;Yuming Zhou;Baowen Xu
#t 2011
#c 11
#% 745476
#% 954887
#% 956566
#% 1090777
#% 1696305
#! Matching large ontologies is a challenge due to the high time complexity. This paper proposes a new matching method for large ontologies based on reduction anchors. This method has a distinct advantage over the divide-and-conquer methods because it dose not need to partition large ontologies. In particular, two kinds of reduction anchors, positive and negative reduction anchors, are proposed to reduce the time complexity in matching. Positive reduction anchors use the concept hierarchy to predict the ignorable similarity calculations. Negative reduction anchors use the locality of matching to predict the ignorable similarity calculations. Our experimental results on the real world data sets show that the proposed method is efficient for matching large ontologies.

#index 1826436
#* Line orthogonality in adjacency eigenspace with application to community partition
#@ Leting Wu;Xiaowei Ying;Xintao Wu;Zhi-Hua Zhou
#t 2011
#c 11
#% 273374
#% 313959
#% 956685
#% 1246431
#% 1633202
#% 1710595
#! Different from Laplacian or normal matrix, the properties of the adjacency eigenspace received much less attention. Recent work showed that nodes projected into the adjacency eigenspace exhibit an orthogonal line pattern and nodes from the same community locate along the same line. In this paper, we conduct theoretical studies based on graph perturbation to demonstrate why this line orthogonality property holds in the adjacency eigenspace and why it generally disappears in the Laplacian and normal eigenspaces. Using the orthogonality property in the adjacency eigenspace, we present a graph partition algorithm, AdjCluster, which first projects node coordinates to the unit sphere and then applies the classic k-means to find clusters. Empirical evaluations on synthetic data and real-world social networks validate our theoretical findings and show the effectiveness of our graph partition algorithm.

#index 1826437
#* Source-selection-free transfer learning
#@ Evan Wei Xiang;Sinno Jialin Pan;Weike Pan;Jian Su;Qiang Yang
#t 2011
#c 11
#% 593047
#% 844287
#% 876034
#% 1055680
#% 1083655
#% 1211714
#% 1211726
#% 1267778
#% 1400008
#% 1464068
#% 1582171
#% 1619129
#! Transfer learning addresses the problems that labeled training data are insufficient to produce a high-performance model. Typically, given a target learning task, most transfer learning approaches require to select one or more auxiliary tasks as sources by the designers. However, how to select the right source data to enable effective knowledge transfer automatically is still an unsolved problem, which limits the applicability of transfer learning. In this paper, we take one step ahead and propose a novel transfer learning framework, known as source-selection-free transfer learning (SSFTL), to free users from the need to select source domains. Instead of asking the users for source and target data pairs, as traditional transfer learning does, SSFTL turns to some online information sources such as World Wide Web or the Wikipedia for help. The source data for transfer learning can be hidden somewhere within this large online information source, but the users do not know where they are. Based on the online information sources, we train a large number of classifiers. Then, given a target task, a bridge is built for labels of the potential source candidates and the target domain data in SSFTL via some large online social media with tag cloud as a label translator. An added advantage of SSFTL is that, unlike many previous transfer learning approaches, which are difficult to scale up to the Web scale, SSFTL is highly scalable and can offset much of the training work to offline stage. We demonstrate the effectiveness and efficiency of SSFTL through extensive experiments on several real-world datasets in text classification.

#index 1826438
#* Predicting epidemic tendency through search behavior analysis
#@ Danqing Xu;Yiqun Liu;Min Zhang;Shaoping Ma;Anqi Cui;Liyun Ru
#t 2011
#c 11
#% 310567
#% 330617
#% 989578
#% 1278069
#! The possibility that influenza activity can be generally detected through search log analysis has been explored in recent years. However, previous studies have mainly focused on influenza, and little attention has been paid to other epidemics. With an analysis of web user behavior data, we consider the problem of predicting the tendency of hand-foot -and-mouth disease (HFMD), whose outbreak in 2010 resulted in a great panic in China. In addition to search queries, we consider users' interactions with search engines. Given the collected search logs, we cluster HFMD-related search queries, medical pages and news reports into the following sets: epidemic-related queries (ERQs), epidemic-related pages (ERPs) and epidemic-related news (ERNs). Furthermore, we count their own frequencies as different features, and we conduct a regression analysis with current HFMD occurrences. The experimental results show that these features exhibit good performances on both accuracy and time-lines.

#index 1826439
#* Mining user dwell time for personalized web search re-ranking
#@ Songhua Xu;Hao Jiang;Francis C. M. Lau
#t 2011
#c 11
#% 413615
#% 754126
#% 766454
#% 818259
#% 832349
#% 869471
#% 956552
#% 1127460
#% 1270287
#% 1275012
#! We propose a personalized re-ranking algorithm through mining user dwell times derived from a user's previously online reading or browsing activities. We acquire document level user dwell times via a customized web browser, from which we then infer conceptword level user dwell times in order to understand a user's personal interest. According to the estimated concept word level user dwell times, our algorithm can estimate a user's potential dwell time over a new document, based on which personalized webpage re-ranking can be carried out. We compare the rankings produced by our algorithm with rankings generated by popular commercial search engines and a recently proposed personalized ranking algorithm. The results clearly show the superiority of our method.

#index 1826440
#* Efficient searching top-k semantic similar words
#@ Zhenglu Yang;Masaru Kitsuregawa
#t 2011
#c 11
#% 121278
#% 198058
#% 333854
#% 438135
#% 458630
#% 641963
#% 748600
#% 896031
#% 956570
#% 1275285
#% 1338626
#% 1473931
#! Measuring the semantic meaning between words is an important issue because it is the basis for many applications, such as word sense disambiguation, document summarization, and so forth. Although it has been explored for several decades, most of the studies focus on improving the effectiveness of the problem, i.e., precision and recall. In this paper, we propose to address the efficiency issue, that given a collection of words, how to efficiently discover the top-k most semantic similar words to the query. This issue is very important for real applications yet the existing state-of-the-art strategies cannot satisfy users with reasonable performance. Efficient strategies on searching top-k semantic similar words are proposed. We provide an extensive comparative experimental evaluation demonstrating the advantages of the introduced strategies over the state-of-the-art approaches.

#index 1826441
#* Recommender systems from "words of few mouths"
#@ Richong Zhang;Thomas Tran;Yongyi Mao
#t 2011
#c 11
#% 211820
#% 420077
#% 813966
#% 1127451
#% 1176947
#% 1261574
#% 1558461
#% 1722659
#! This paper identifies a widely existing phenomenon in web data, which we call the "words of few mouths" phenomenon. This phenomenon, in the context of online reviews, refers to the case that a large fraction of the reviews are each voted only by very few users. We discuss the challenges of "words of few mouths" in the development of recommender systems based on users' opinions and advocate probabilistic methodologies to handle such challenges. We develop a probabilistic model and correspondingly a logistic regression based learning algorithm for review helpfulness prediction. Our experimental results indicate that the proposed model outperforms the current state-of-the-art algorithms not only in the presence of the "words of few mouths" phenomenon, but also in the absence of such phenomena.

#index 1826442
#* Integrating task planning and interactive learning for robots to work in human environments
#@ Alejandro Agostini;Carme Torras;Florentin Wörgötter
#t 2011
#c 11
#% 458178
#% 934104
#% 1023574
#% 1270202
#% 1273373
#% 1499593
#! Human environments are challenging for robots, which need to be trainable by lay people and learn new behaviours rapidly without disrupting much the ongoing activity. A system that integrates AI techniques for planning and learning is here proposed to satisfy these strong demands. The approach rapidly learns planning operators from few action experiences using a competitive strategy where many alternatives of cause-effect explanations are evaluated in parallel, and the most successful ones are used to generate the operators. The success of a cause-effect explanation is evaluated by a probabilistic estimate that compensates the lack of experience, producing more confident estimations and speeding up the learning in relation to other known estimates. The system operates without task interruption by integrating in the planning-learning loop a human teacher that supports the planner in making decisions. All the mechanisms are integrated and synchronized in the robot using a general decision-making framework. The feasibility and scalability of the architecture are evaluated in two different robot platforms: a Stäubli arm, and the humanoid ARMAR III.

#index 1826443
#* Plan recognition in virtual laboratories
#@ Ofra Amir;Ya'akov Gal
#t 2011
#c 11
#% 414515
#% 418889
#% 423981
#% 741112
#% 1103670
#% 1210222
#% 1263014
#% 1275013
#! This paper presents a plan recognition algorithm for inferring student behavior using virtual science laboratories. The algorithm extends existing plan recognition technology and was integrated with an existing educational application for chemistry. Automatic recognition of students' activities in virtual laboratories can provide important information to teachers as well as serve as the basis for intelligent tutoring. Student use of virtual laboratories presents several challenges: Students may repeat activities indefinitely, interleave between activities, and engage in exploratory behavior using trial-and-error. The plan recognition algorithm uses a recursive grammar that heuristically generates plans on the fly, taking into account chemical reactions and effects to determine students' intended high-level actions. The algorithm was evaluated empirically on data obtained from college students using virtual laboratory software for teaching chemistry. Results show that the algorithm was able to (1) infer the plans used by students to construct their models; (2) recognize such key processes as titration and dilution when they occurred in students' work; (3) identify partial solutions; (4) isolate sequences of actions that were part of a single error.

#index 1826444
#* A comprehensive approach to on-board autonomy verification and validation
#@ M. Bozzano;A. Cimatti;M. Roveri;A. Tchaltsev
#t 2011
#c 11
#% 121397
#% 297770
#% 541452
#% 655322
#% 657755
#% 743353
#% 930640
#% 1250197
#% 1269410
#% 1279265
#% 1291462
#% 1476265
#% 1703552
#! Deep space missions are characterized by severely constrained communication links. To meet the needs of future missions and increase their scientific return, future space systems will require an increased level of autonomy on-board. In this work, we propose a comprehensive approach to on-board autonomy relying on model-based reasoning, and encompassing many important reasoning capabilities such as plan generation, validation, execution and monitoring, FDIR, and run-time diagnosis. The controlled platform is represented symbolically, and the reasoning capabilities are seen as symbolic manipulation of such formal model. We have developed a prototype of our framework, implemented within an on-board Autonomous Reasoning Engine. We have evaluated our approach on two case-studies inspired by real-world, ongoing projects, and characterized it in terms of reliability, availability and performance.

#index 1826445
#* Non-linear Monte-Carlo search in civilization II
#@ S. R. K. Branavan;David Silver;Regina Barzilay
#t 2011
#c 11
#% 96650
#% 169359
#% 283236
#% 348585
#% 384911
#% 983838
#% 1073993
#% 1105556
#% 1305297
#% 1404135
#% 1453067
#% 1591956
#! This paper presents a new Monte-Carlo search algorithm for very large sequential decision-making problems. We apply non-linear regression within Monte-Carlo search, online, to estimate a state-action value function from the outcomes of random roll-outs. This value function generalizes between related states and actions, and can therefore provide more accurate evaluations after fewer rollouts. A further significant advantage of this approach is its ability to automatically extract and leverage domain knowledge from external sources such as game manuals. We apply our algorithm to the game of Civilization II, a challenging multiagent strategy game with an enormous state space and around 1021 joint actions. We approximate the value function by a neural network, augmented by linguistic knowledge that is extracted automatically from the official game manual. We show that this non-linear value function is significantly more efficient than a linear value function, which is itself more efficient than Monte-Carlo tree search. Our non-linear Monte-Carlo search wins over 78% of games against the built-in AI of Civilization II.

#index 1826446
#* Buried utility pipeline mapping based on multiple spatial data sources: a bayesian data fusion approach
#@ Huanhuan Chen;Anthony G. Cohn
#t 2011
#c 11
#% 752417
#% 1473398
#! Statutory records of underground utility apparatus (such as pipes and cables) are notoriously inaccurate, so street surveys are usually undertaken before road excavation takes place to minimize the extent and duration of excavation and for health and safety reasons. This involves the use of sensors such as Ground Penetrating Radar (GPR). The GPR scans are then manually interpreted and combined with the expectations from the utility records and other data such as surveyed manholes. The task is complex owing to the difficulty in interpreting the sensor data, and the spatial complexity and extent of under street assets. We explore the application of AI techniques, in particular Bayesian data fusion (BDF), to automatically generate maps of buried apparatus. Hypotheses about the spatial location and direction of buried assets are extracted by identifying hyperbolae in the GPR scans. The spatial location of surveyed manholes provides further input to the algorithm, as well as the prior expectations from the statutory records. These three data sources are used to produce the most probable map of the buried assets. Experimental results on real and simulated data sets are presented.

#index 1826447
#* Enhancing search results with semantic annotation using augmented browsing
#@ Hong-Jie Dai;Wei-Chi Tsai;Richard Tzong-Han Tsai;Wen-Lian Hsu
#t 2011
#c 11
#% 722903
#% 850430
#% 905819
#% 1126304
#% 1306358
#% 1329601
#% 1457318
#% 1484259
#! In this paper, we describe how we integrated an artificial intelligence (AI) system into the PubMed search website using augmented browsing technology. Our system dynamically enriches the PubMed search results displayed in a user's browser with semantic annotation provided by several natural language processing (NLP) subsystems, including a sentence splitter, a part-of-speech tagger, a named entity recognizer, a section categorizer and a gene normalizer (GN). After our system is installed, the PubMed search results page is modified on the fly to categorize sections and provide additional information on gene and gene products indentified by our NLP subsystems. In addition, GN involves three main steps: candidate ID matching, false positive filtering and disambiguation, which are highly dependent on each other. We propose a joint model using a Markov logic network (MLN) to model the dependencies found in GN. The experimental results show that our joint model outperforms a baseline system that executes the three steps separately. The developed system is available at https://sites.google.com/site/pubmedannotationtool 4ijcai/home.

#index 1826448
#* Simulation-based data mining solution to the structure of water surrounding proteins
#@ Hieu Chi Dam;Tu Bao Ho;Ayumu Sugiyama
#t 2011
#c 11
#% 938348
#% 1021019
#! What is structure of water surrounding proteins remains as one of fundamental unsolved problems of science. Methods in biophysics only provide qualitative description of the structure and thus clarifying the collective phenomena of a huge number of water molecules is still beyond intuition in biophysics. We introduce a simulation-based data mining approach that quantitatively model the structure of water surrounding a protein as clusters of water molecules having similar moving behavior. The paper presents and explains how the advances of AI technique can potentially solve this challenging data-intensive problem.

#index 1826449
#* A natural language question answering system as a participant in human Q&A portals
#@ Tiansi Dong;Ulrich Furbach;Ingo Glöckner;Björn Pelzer
#t 2011
#c 11
#% 495665
#% 837715
#% 926881
#% 1099439
#% 1362489
#% 1370262
#% 1370273
#% 1434490
#% 1494776
#! LogAnswer is a question answering (QA) system for the German language, aimed at providing concise and correct answers to arbitrary questions. For this purpose LogAnswer is designed as an embedded artificial intelligence system which integrates methods from several fields of AI, namely natural language processing, machine learning, knowledge representation and automated theorem proving. We intend to employ LogAnswer as a virtual user within Internet-based QA forums, where it must be able to identify the questions that it cannot answer correctly, a task that normally receives little attention in QA research compared to the actual answer derivation. The paper presents a machine learning solution to the wrong answer avoidance (WAA) problem, applying a meta classifier to the output of simple term-based classifiers and a rich set of other WAA features. Experiments with a large set of real-world questions from a QA forum show that the proposed method significantly improves the WAA characteristics of our system.

#index 1826450
#* Sketch recognition algorithms for comparing complex and unpredictable shapes
#@ Martin Field;Stephanie Valentine;Julie Linsey;Tracy Hammond
#t 2011
#c 11
#% 109079
#% 998813
#% 1065149
#% 1091629
#% 1111441
#% 1297969
#% 1297970
#% 1910103
#% 1910113
#! In an introductory Engineering course with an annual enrollment of over 1000 students, a professor has little option but to rely on multiple choice exams for midterms and finals. Furthermore, the teaching assistants are too overloaded to give detailed feedback on submitted homework assignments. We introduce Mechanix, a computer-assisted tutoring system for engineering students. Mechanix uses recognition of freehand sketches to provide instant, detailed, and formative feedback as the student progresses through each homework assignment, quiz, or exam. Free sketch recognition techniques allow students to solve free-body diagram and static truss problems as if they were using a pen and paper. The same recognition algorithms enable professors to add new unique problems simply by sketching out the correct answer. Mechanix is able to ease the burden of grading so that instructors can assign more free response questions, which provide a better measure of student progress than multiple choice questions do.

#index 1826451
#* Exploiting probabilistic knowledge under uncertain sensing for efficient robot behaviour
#@ M. Hanheide;C. Gretton;R. Dearden;N. Hawes;J. Wyatt;A. Pronobis;A. Aydemir;M. Göbelbecker;H. Zender
#t 2011
#c 11
#% 1063862
#% 1272089
#% 1272113
#% 1272231
#% 1291064
#% 1369611
#% 1401760
#% 1472304
#% 1480471
#% 1650463
#% 1768976
#! Robots must perform tasks efficiently and reliably while acting under uncertainty. One way to achieve efficiency is to give the robot common-sense knowledge about the structure of the world. Reliable robot behaviour can be achieved by modelling the uncertainty in the world probabilistically. We present a robot system that combines these two approaches and demonstrate the improvements in efficiency and reliability that result. Our first contribution is a probabilistic relational model integrating common-sense knowledge about the world in general, with observations of a particular environment. Our second contribution is a continual planning system which is able to plan in the large problems posed by that model, by automatically switching between decision-theoretic and classical procedures. We evaluate our system on object search tasks in two different real-world indoor environments. By reasoning about the trade-offs between possible courses of action with different informational effects, and exploiting the cues and general structures of those environments, our robot is able to consistently demonstrate efficient and reliable goal-directed behaviour.

#index 1826452
#* Integrated learning for goal-driven autonomy
#@ Ulit Jaidee;H&#233/ctor Mu&#241/oz-Avila;David W. Aha
#t 2011
#c 11
#% 224475
#% 384911
#% 719138
#% 1099643
#% 1100006
#% 1109929
#% 1250208
#% 1252990
#% 1270152
#% 1705993
#% 1737318
#% 1737328
#! Goal-driven autonomy (GDA) is a reflective model of goal reasoning that controls the focus of an agent's planning activities by dynamically resolving unexpected discrepancies in the world state, which frequently arise when solving tasks in complex environments. GDA agents have performed well on such tasks by integrating methods for discrepancy recognition, explanation, goal formulation, and goal management. However, they require substantial domain knowledge, including what constitutes a discrepancy and how to resolve it. We introduce LGDA, a learning algorithm for acquiring this knowledge, modeled as cases, that and integrates case-based reasoning and reinforcement learning methods. We assess its utility on tasks from a complex video game environment. We claim that, for these tasks, LGDA can significantly outperform its ablations. Our evaluation provides evidence to support this claim. LGDA exemplifies a feasible design methodology for deployable GDA agents.

#index 1826453
#* Learning compact visual descriptor for low bit rate mobile landmark search
#@ Rongrong Ji;Ling-Yu Duan;Jie Chen;Hongxun Yao;Tiejun Huang;Wen Gao
#t 2011
#c 11
#% 46803
#% 313937
#% 724320
#% 760805
#% 836746
#% 883971
#% 990321
#% 1148464
#% 1205327
#% 1209714
#% 1298684
#% 1418535
#% 1446867
#% 1502463
#% 1667643
#! In this paper, we propose to extract a compact yet discriminative visual descriptor directly on the mobile device, which tackles the wireless query transmission latency in mobile landmark search. This descriptor originates from offline learning the location contexts of geo-tagged Web photos from both Flickr and Panoramio with two phrases: First, we segment the landmark photo collections into discrete geographical regions using a Gaussian Mixture Model [Stauffer et al., 2000]. Second, a ranking sensitive vocabulary boosting is introduced to learn a compact codebook within each region. To tackle the locally optimal descriptor learning caused by imprecise geographical segmentation, we further iterate above phrases incorporating the feedback of an "entropy" based descriptor compactness into a prior distribution to constrain the Gaussian mixture modeling. Consequently, when entering a specific geographical region, the codebook in the mobile device is downstream adapted, which ensures efficient extraction of compact descriptors, its low bit rate transmission, as well as promising discrimination ability. We descriptors to both HTC and iPhone mobile phones, testing landmark search over one million images in typical areas like Beijing, New York, and Barcelona, etc. Our descriptor outperforms alternative compact descriptors [Chen et al., 2009][Chen et al., 2010][Chandrasekhar et al., 2009a][Chandrasekhar et al., 2009b] with a large margin.

#index 1826454
#* A new search engine integrating hierarchical browsing and keyword search
#@ Da Kuang;Xiao Li;Charles X. Ling
#t 2011
#c 11
#% 318412
#% 458379
#% 466501
#% 590523
#% 717133
#% 722935
#% 766433
#% 801383
#% 807295
#% 829975
#% 995516
#% 998622
#% 1074128
#% 1095862
#% 1117691
#% 1131829
#% 1173691
#% 1378224
#% 1538188
#! The original Yahoo! search engine consists of manually organized topic hierarchy of webpages for easy browsing. Modern search engines (such as Google and Bing), on the other hand, return a flat list of webpages based on keywords. It would be ideal if hierarchical browsing and keyword search can be seamlessly combined. The main difficulty in doing so is to automatically (i.e., not manually) classify and rank a massive number of webpages into various hierarchies (such as topics, media types, regions of the world). In this paper we report our attempt towards building this integrated search engine, called SEE (Search Engine with hiErarchy). We implement a hierarchical classification system based on SupportVector Machines, and embed it in SEE. We also design a novel user interface that allows users to dynamically adjust their desire for a higher accuracy vs. more results in any (sub)category of the hierarchy. Though our current search engine is still small (indexing about 1.2 million webpages), the results, including a small user study, have shown a great promise for integrating such techniques in the next-generation search engine.

#index 1826455
#* Resource-bounded crowd-sourcing of commonsense knowledge
#@ Yen-Ling Kuo;Jane Yung-Jen Hsu
#t 2011
#c 11
#% 198055
#% 198058
#% 509695
#% 723391
#% 860015
#% 995514
#% 1250181
#% 1252605
#% 1269447
#% 1270106
#% 1272743
#! Knowledge acquisition is the essential process of extracting and encoding knowledge, both domain specific and commonsense, to be used in intelligent systems. While many large knowledge bases have been constructed, none is close to complete. This paper presents an approach to improving a knowledge base efficiently under resource constraints. Using a guiding knowledge base, questions are generated from a weak form of similarity-based inference given the glossary mapping between two knowledge bases. The candidate questions are prioritized in terms of the concept coverage of the target knowledge. Experiments were conducted to find questions to grow the Chinese ConceptNet using the English ConceptNet as a guide. The results were evaluated by online users to verify that 94.17% of the questions and 85.77% of the answers are good. In addition, the answers collected in a six-week period showed consistent improvement to a 36.33% increase in concept coverage of the Chinese commonsense knowledge base against the English ConceptNet.

#index 1826456
#* A real-time opponent modeling system for rush football
#@ Kennard Laviers;Gita Sukthankar
#t 2011
#c 11
#% 283197
#% 504942
#% 1289455
#% 1305297
#% 1305362
#% 1355588
#% 1665148
#! One drawback with using plan recognition in adversarial games is that often players must commit to a plan before it is possible to infer the opponent's intentions. In such cases, it is valuable to couple plan recognition with plan repair, particularly in multi-agent domains where complete replanning is not computationally feasible. This paper presents a method for learning plan repair policies in real-time using Upper Confidence Bounds applied to Trees (UCT). We demonstrate how these policies can be coupled with plan recognition in an American football game (Rush 2008) to create an autonomous offensive team capable of responding to unexpected changes in defensive strategy. Our real-time version of UCT learns play modifications that result in a significantly higher average yardage and fewer interceptions than either the baseline game or domain-specific heuristics. Although it is possible to use the actual game simulator to measure reward offline, to execute UCT in real-time demands a different approach; here we describe two modules for reusing data from offline UCT searches to learn accurate state and reward estimators.

#index 1826457
#* Coordinating logistics operations with privacy guarantees
#@ Thomas Léauté;Boi Faltings
#t 2011
#c 11
#% 319849
#% 344813
#% 774348
#% 1084276
#% 1155834
#% 1198205
#% 1281809
#% 1289393
#! Several logistics service providers serve a certain number of customers, geographically spread over an area of operations. They would like to coordinate their operations so as to minimize overall cost. At the same time, they would like to keep information about their costs, constraints and preferences private, thus precluding conventional negotiation. We show how AI techniques, in particular Distributed Constraint Optimization (DCOP), can be integrated with cryptographic techniques to allow such coordination without revealing agents' private information. The problem of assigning customers to companies is formulated as a DCOP, for which we propose two novel, privacy-preserving algorithms. We compare their performances and privacy properties on a set of Vehicle Routing Problem benchmarks.

#index 1826458
#* Learning to identify review spam
#@ Fangtao Li;Minlie Huang;Yi Yang;Xiaoyan Zhu
#t 2011
#c 11
#% 252011
#% 458369
#% 1035590
#% 1127964
#% 1261574
#% 1275196
#% 1301004
#% 1305481
#% 1328329
#% 1471448
#% 1482272
#! In the past few years, sentiment analysis and opinion mining becomes a popular and important task. These studies all assume that their opinion resources are real and trustful. However, they may encounter the faked opinion or opinion spam problem. In this paper, we study this issue in the context of our product review mining system. On product review site, people may write faked reviews, called review spam, to promote their products, or defame their competitors' products. It is important to identify and filter out the review spam. Previous work only focuses on some heuristic rules, such as helpfulness voting, or rating deviation, which limits the performance of this task. In this paper, we exploit machine learning methods to identify review spam. Toward the end, we manually build a spam collection from our crawled reviews. We first analyze the effect of various features in spam identification. We also observe that the review spammer consistently writes spam. This provides us another view to identify review spam: we can identify if the author of the review is spammer. Based on this observation, we provide a twoview semi-supervised method, co-training, to exploit the large amount of unlabeled data. The experiment results show that our proposed method is effective. Our designed machine learning methods achieve significant improvements in comparison to the heuristic baselines.

#index 1826459
#* A system for providing differentiated QoS in retail banking
#@ Sameep Mehta;Girish Chafle;Gyana Parija;Vikas Kedia
#t 2011
#c 11
#% 341672
#% 408396
#% 989670
#% 1119037
#% 1285874
#% 1490845
#! In today's services driven economic environment, it is imperative for organizations to provide better quality service experience to differentiate and grow their business. Customer satisfaction (C-SAT) is the key driver for retention and growth in Retail Banking. Wait time, the time spent by a customer at the branch before getting serviced, contributes significantly to C-SAT. Due to high footfall, it is improbable to improve the wait time of every customer walking in the branch. Therefore, banks in developing countries are strategically looking to segment its customers and services and offer differentiated QoS based service delivery. In this work, we present a system for customer segmentation, and scheduling based on historic value of the customer and characteristics of current service request. We describe the system and give mathematical formulation of the scheduling problem and the associated heuristics. We present results and experience of deployment of this solution in multiple branches of a leading bank in India.

#index 1826460
#* Learning 3D geological structure from drill-rig sensors for automated mining
#@ Sildomar T. Monteiro;Joop Van De Ven;Fabio Ramos;Peter Hatherly
#t 2011
#c 11
#% 44876
#% 464434
#% 770850
#% 889176
#% 1081627
#% 1166535
#% 1202766
#% 1362516
#% 1417383
#% 1446842
#% 1446848
#% 1665139
#% 1815753
#! This paper addresses one of the key components of the mining process: the geological prediction of natural resources from spatially distributed measurements. We present a novel approach combining undirected graphical models with ensemble classifiers to provide 3D geological models from multiple sensors installed in an autonomous drill rig. Drill sensor measurements used for drilling automation, known as measurement-while-drilling (MWD) data, have the potential to provide an estimate of the geological properties of the rocks being drilled. The proposed method maps MWD parameters to rock types while considering spatial relationships, i.e., associating measurements obtained from neighboring regions. We use a conditional random field with local information provided by boosted decision trees to jointly reason about the rock categories of neighboring measurements. To validate the approach, MWD data was collected from a drill rig operating at an iron ore mine. Graphical models of the 3D structure present in real data sets possess a high number of nodes, edges and cycles, making them intractable for exact inference. We provide a comparison of three approximate inference methods to calculate the most probable distribution of class labels. The empirical results demonstrate the benefits of spatial modeling through graphical models to improve classification performance.

#index 1826461
#* Interest prediction on multinomial, time-evolving social graphs
#@ Nozomi Nori;Danushka Bollegala;Mitsuru Ishizuka
#t 2011
#c 11
#% 173879
#% 202011
#% 722904
#% 770816
#% 823388
#% 833088
#% 910167
#% 915225
#% 989640
#% 1055685
#% 1214661
#% 1214674
#% 1451212
#! We propose a method to predict users' interests in social media, using time-evolving, multinomial relational data. We exploit various actions performed by users, and their preferences to predict user interests. Actions performed by users in social media such as Twitter, Delicious and Facebook have two fundamental properties. (a) User actions can be represented as high-dimensional or multinomial relations - e.g. referring URLs, bookmarking and tagging, clicking a favorite button on a post etc. (b) User actions are time-varying and user-specific - each user has unique preferences that change over time. Consequently, it is appropriate to represent each user's action at some point in time as a multinomial relational data. We propose ActionGraph, a novel graph representation for modeling users' multinomial, time-varying actions. Each user's action at some time point is represented by an action node. ActionGraph is a bipartite graph whose edges connect an action node to its involving entities, referred to as object nodes. Using real-world social media data, we empirically justify the proposed graph structure. Our experimental results show that the proposed ActionGraph improves the accuracy in a user interest prediction task by outperforming several baselines including standard tensor analysis, a previously proposed state-of-the-art LDA-based method and other graph-based variants. Moreover, the proposed method shows robust performances in the presence of sparse data.

#index 1826462
#* An agent architecture for prognostic reasoning assistance
#@ Jean Oh;Felipe Meneguzzi;Katia Sycara;Timothy J. Norman
#t 2011
#c 11
#% 1156101
#% 1215530
#% 1275056
#% 1289556
#% 1447090
#! In this paper we describe a software assistant agent that can proactively assist human users situated in a time-constrained environment to perform normative reasoning-reasoning about prohibitions and obligations-so that the user can focus on her planning objectives. In order to provide proactive assistance, the agent must be able to 1) recognize the user's planned activities, 2) reason about potential needs of assistance associated with those predicted activities, and 3) plan to provide appropriate assistance suitable for newly identified user needs. To address these specific requirements, we develop an agent architecture that integrates user intention recognition, normative reasoning over a user's intention, and planning, execution and replanning for assistive actions. This paper presents the agent architecture and discusses practical applications of this approach.

#index 1826463
#* Extending computer assisted assessment systems with natural language processing, user modeling, and recommendations based on human computer interaction and data mining
#@ Ismael Pascual-Nieto;Olga C. Santos;Diana Perez-Marin;Jesus G. Boticario
#t 2011
#c 11
#% 342102
#% 798002
#% 1369952
#% 1476516
#% 1610866
#% 1674876
#! Willow is a free-text Adaptive Computer Assisted Assessment system, which supports natural language processing and user modeling. In this paper we discuss the benefits coming from extending Willow with recommendations. The approach combines human computer interaction methods to elicit the recommendations with data mining techniques to adjust their definition. Following a scenario-based approach, 12 recommendations were designed and delivered in a large scale evaluation with 377 learners. A statistically significant positive impact was found on indicators dealing with the engagement in the course, the learning effectiveness and efficiency, as well as the knowledge acquisition. We present the overall system functionality, the interaction among the different subsystems involved and some evaluation findings.

#index 1826464
#* Integrating learning into a BDI Agent for environments with changing dynamics
#@ Dhirendra Singh;Sebastian Sardina;Lin Padgham;Geoff James
#t 2011
#c 11
#% 376266
#% 384911
#% 504771
#% 918648
#% 1335273
#% 1453097
#% 1453536
#% 1655819
#% 1790980
#% 1948753
#! We propose a framework that adds learning for improving plan selection in the popular BDI agent programming paradigm. In contrast with previous proposals, the approach given here is able to scale up well with the complexity of the agent's plan library. Technically, we develop a novel confidence measure which allows the agent to adjust its reliance on the learning dynamically, facilitating in principle infinitely many (re)learning phases. We demonstrate the benefits of the approach in an example controller for energy management.

#index 1826465
#* Embedding system dynamics in agent based models for complex adaptive systems
#@ Maarika Teose;Kiyan Ahmadizadeh;Eoin O'Mahony;Rebecca L. Smith;Zhao Lu;Stephen P. Ellner;Carla Gomes;Yrjo Grohn
#t 2011
#c 11
#% 375848
#% 1000399
#% 1190980
#% 1665148
#! Complex adaptive systems (CAS) are composed of interacting agents, exhibit nonlinear properties such as positive and negative feedback, and tend to produce emergent behavior that cannot be wholly explained by deconstructing the system into its constituent parts. Both system dynamics (equation-based) approaches and agent-based approaches have been used to model such systems, and each has its benefits and drawbacks. In this paper, we introduce a class of agent-based models with an embedded system dynamics model, and detail the semantics of a simulation framework for these models. This model definition, along with the simulation framework, combines agent-based and system dynamics approaches in a way that retains the strengths of both paradigms. We show the applicability of our model by instantiating it for two example complex adaptive systems in the field of Computational Sustainability, drawn from ecology and epidemiology. We then present a more detailed application in epidemiology, in which we compare a previously unstudied intervention strategy to established ones. Our experimental results, unattainable using previous methods, yield insight into the effectiveness of these intervention strategies.

#index 1826466
#* Kinship verification through transfer learning
#@ Siyu Xia;Ming Shao;Yun Fu
#t 2011
#c 11
#% 235342
#% 235346
#% 466263
#% 729344
#% 806973
#% 883908
#% 884100
#% 889161
#% 983828
#% 1022958
#% 1030817
#% 1134122
#% 1148495
#% 1269755
#% 1446818
#% 1464068
#% 1502510
#% 1861040
#! Because of the inevitable impact factors such as pose, expression, lighting and aging on faces, identity verification through faces is still an unsolved problem. Research on biometrics raises an even challenging problem--is it possible to determine the kinship merely based on face images? A critical observation that faces of parents captured while they were young are more alike their children's compared with images captured when they are old has been revealed by genetics studies. This enlightens us the following research. First, a new kinship database named UB KinFace composed of child, young parent and old parent face images is collected from Internet. Second, an extended transfer subspace learning method is proposed aiming at mitigating the enormous divergence of distributions between children and old parents. The key idea is to utilize an intermediate distribution close to both the source and target distributions to bridge them and reduce the divergence. Naturally the young parent set is suitable for this task. Through this learning process, the large gap between distributions can be significantly reduced and kinship verification problem becomesmore discriminative. Experimental results show that our hypothesis on the role of young parents is valid and transfer learning is effective to enhance the verification accuracy.

#index 1826467
#* Cross-people mobile-phone based activity recognition
#@ Zhongtang Zhao;Yiqiang Chen;Junfa Liu;Zhiqi Shen;Mingjie Liu
#t 2011
#c 11
#% 413620
#% 860058
#% 1242400
#% 1270128
#% 1270540
#% 1464068
#% 1476166
#% 1496690
#% 1699609
#% 1729089
#! Activity recognition using mobile phones has great potential in many applications including mobile healthcare. In order to let a person easily know whether he is in strict compliance with the doctor's exercise prescription and adjust his exercise amount accordingly, we can use a smart-phone based activity reporting system to accurately recognize a range of daily activities and report the duration of each activity. A triaxial accelerometer embedded in the smart phone is used for the classification of several activities, such as staying still, walking, running, and going upstairs and downstairs. The model learnt from a specific person often cannot yield accurate results when used on a different person. To solve the cross-people activity recognition problem, we propose an algorithm known as TransEMDT (Transfer learning EMbedded Decision Tree) that integrates a decision tree and the k-means clustering algorithm for personalized activity-recognition model adaptation. Tested on a real-world data set, the results show that our algorithm outperforms several traditional baseline algorithms.

#index 1826468
#* CHIME: an efficient error-tolerant Cinese pinyin input method
#@ Yabin Zheng;Chen Li;Maosong Sun
#t 2011
#c 11
#% 251405
#% 324015
#% 389155
#% 421719
#% 762147
#% 815881
#% 817571
#% 817577
#% 854775
#% 1190092
#% 1338621
#% 1471206
#% 1484281
#! Chinese Pinyin input methods are very important for Chinese language processing. In many cases, users may make typing errors. For example, a user wants to type in "shenme" (???, meaning "what" in English) but may type in "shenem" instead. Existing Pinyin input methods fail in converting such a Pinyin sequence with errors to the right Chinese words. To solve this problem, we developed an efficient error-tolerant Pinyin input method called "CHIME" that can handle typing errors. By incorporating state-of-the-art techniques and language-specific features, the method achieves a better performance than state-of-the-art input methods. It can efficiently find relevant words in milliseconds for an input Pinyin sequence.

#index 1826469
#* A geometric view of conjugate priors
#@ Arvind Agarwal;Hal Daumé, III
#t 2011
#c 11
#% 883830
#% 916785
#% 989599
#% 1031854
#% 1166535
#% 1305444
#! In Bayesian machine learning, conjugate priors are popular, mostly due to mathematical convenience. In this paper, we show that there are deeper reasons for choosing a conjugate prior. Specifically, we formulate the conjugate prior in the form of Bregman divergence and show that it is the inherent geometry of conjugate priors that makes them appropriate and intuitive. This geometric interpretation allows one to view the hyperparameters of conjugate priors as the effective sample points, thus providing additional intuition. We use this geometric understanding of conjugate priors to derive the hyperparameters and expression of the prior used to couple the generative and discriminative components of a hybrid model for semi-supervised learning.

#index 1826470
#* Human-guided machine learning for fast and accurate network alarm triage
#@ Saleema Amershi;Bongshin Lee;Ashish Kapoor;Ratul Mahajan;Blaine Christian
#t 2011
#c 11
#% 304706
#% 428235
#% 1047296
#% 1573361
#% 1829875
#! Network alarm triage refers to grouping and prioritizing a stream of low-level device health information to help operators find and fix problems. Today, this process tends to be largely manual because existing rule-based tools cannot easily evolve with the network. We present CueT, a system that uses interactive machine learning to constantly learn from the triaging decisions of operators. It then uses that learning in novel visualizations to help them quickly and accurately triage alarms. Unlike prior interactive machine learning systems, CueT handles a highly dynamic environment where the groups of interest are not known a priori and evolve constantly. Our evaluations with real operators and data from a large network show that CueT significantly improves the speed and accuracy of alarm triage.

#index 1826471
#* Lower bounds for width-restricted clause learning on formulas of small width
#@ Eli Ben-Sasson;Jan Johannsen
#t 2011
#c 11
#% 2119
#% 190340
#% 220203
#% 327779
#% 334082
#% 427631
#% 497745
#% 646269
#% 769859
#% 1027250
#% 1230613
#% 1230614
#% 1270064
#% 1272049
#% 1412980
#% 1478761
#! Clause learning is a technique used by backtracking-based propositional satisfiability solvers, where some clauses obtained by analysis of conflicts are added to the formula during backtracking. It has been observed empirically that clause learning does not significantly improve the performance of a solver when restricted to learning clauses of small width only. This experience is supported by lower bound theorems. It is shown that lower bounds on the runtime of width-restricted clause learning follow from lower bounds on the width of resolution proofs. This yields the first lower bounds on width-restricted clause learning for formulas in 3-CNF.

#index 1826472
#* Community detection in social networks through community formation games
#@ Wei Chen;Zhenming Liu;Xiaorui Sun;Yajun Wang
#t 2011
#c 11
#% 806990
#% 949164
#% 1000451
#% 1108861
#! We introduce a game-theoretic framework to address the community detection problem based on the social networks' structure. The dynamics of community formation is framed as a strategic game called community formation game: Given a social network, each node is selfish and selects communities to join or leave based on her own utility measurement. A community structure can be interpreted as an equilibrium of this game. We formulate the agents' utility by the combination of a gain function and a loss function. Each agent can select multiple communities, which naturally captures the concept of "overlapping communities". We propose a gain function based on Newman's modularity function and a simple loss function that reflects the intrinsic costs incurred when people join the communities. We conduct extensive experiments under this framework; our results show that our algorithm is effective in identifying overlapping communities, and is often better than other algorithms we evaluated especially when many people belong to multiple communities.

#index 1826473
#* An algorithm for adapting cases represented in ALC
#@ Julien Cojan;Jean Lieber
#t 2011
#c 11
#% 168280
#% 216971
#% 405727
#% 490604
#% 492202
#% 935898
#% 1077467
#% 1099636
#% 1252992
#% 1409922
#% 1655393
#% 1667771
#! This paper presents an algorithm of adaptation for a case-based reasoning system with cases and domain knowledge represented in the expressive description logic ALC. The principle is to first pretend that the source case to be adapted solves the current target case. This may raise some contradictions with the specification of the target case and with the domain knowledge. The adaptation consists then in repairing these contradictions. This adaptation algorithm is based on an extension of the classical tableau method used for deductive inferences in ALC.

#index 1826474
#* Exploring protein fragment assembly using CLP
#@ Alessandro Dal Palù;Agostino Dovier;Federico Fogolari;Enrico Pontelli
#t 2011
#c 11
#% 534327
#% 1263133
#% 1344812
#% 1466312
#! The paper investigates a novel approach, based on Constraint Logic Programming (CLP), to predict potential 3D conformations of a protein via fragments assembly. The fragments are extracted and clustered by a preprocessor from a database of known protein structures. Assembling fragments into a complete conformation is modeled as a constraint satisfaction problem solved using CLP. The approach makes use of a simplified Cα-side chain centroid protein model, that offers efficiency and a good approximation for space filling. The approach adapts existing energy models for protein representation and applies a large neighboring search (LNS) strategy. The results show the feasibility and efficiency of the method, and the declarative nature of the approach simplifies the introduction of additional knowledge and variations of the model.

#index 1826475
#* Translation-based constraint answer set solving
#@ Christian Drescher;Toby Walsh
#t 2011
#c 11
#% 400992
#% 411814
#% 417651
#% 534510
#% 534644
#% 928731
#% 938017
#% 1197944
#% 1211661
#% 1257217
#% 1257225
#% 1263090
#% 1273544
#% 1274813
#% 1305355
#% 1305356
#% 1412544
#% 1466297
#% 1655183
#% 1655184
#% 1664998
#! We solve constraint satisfaction problems through translation to answer set programming (ASP). Our reformulations have the property that unit-propagation in the ASP solver achieves well defined local consistency properties like arc, bound and range consistency. Experiments demonstrate the computational value of this approach.

#index 1826476
#* Incentive engineering for Boolean games
#@ Ulle Endriss;Sarit Kraus;Jérôme Lang;Michael Wooldridge
#t 2011
#c 11
#% 271160
#% 781219
#% 1000451
#% 1083988
#% 1223241
#% 1291402
#% 1477274
#! We investigate the problem of influencing the preferences of players within a Boolean game so that, if all players act rationally, certain desirable outcomes will result. The way in which we influence preferences is by overlaying games with taxation schemes. In a Boolean game, each player has unique control of a set of Boolean variables, and the choices available to the player correspond to the possible assignments that may be made to these variables. Each player also has a goal, represented by a Boolean formula, that they desire to see satisfied. Whether or not a player's goal is satisfied will depend both on their own choices and on the choices of others, which gives Boolean games their strategic character. We extend this basic framework by introducing an external principal who is able to levy a taxation scheme on the game, which imposes a cost on every possible action that a player can choose. By designing a taxation scheme appropriately, it is possible to perturb the preferences of the players, so that they are incentivised to choose some equilibrium that would not otherwise be chosen. After motivating and formally presenting our model, we explore some issues surrounding it, including the complexity of finding a taxation scheme that implements some socially desirable outcome, and then discuss desirable properties of taxation schemes.

#index 1826477
#* A flat histogram method for computing the density of states of combinatorial problems
#@ Stefano Ermon;Carla Gomes;Bart Selman
#t 2011
#c 11
#% 8387
#% 217824
#% 850430
#% 1181334
#% 1269700
#% 1275122
#% 1493569
#! Consider a combinatorial state space S, such as the set of all truth assignments to N Boolean variables. Given a partition of S, we consider the problem of estimating the size of all the subsets in which S is divided. This problem, also known as computing the density of states, is quite general and has many applications. For instance, if we consider a Boolean formula in CNF and we partition according to the number of violated constraints, computing the density of states is a generalization of both SAT, MAXSAT and model counting. We propose a novel Markov Chain Monte Carlo algorithm to compute the density of states of Boolean formulas that is based on a flat histogram approach. Our method represents a new approach to a variety of inference, learning, and counting problems. We demonstrate its practical effectiveness by showing that the method converges quickly to an accurate solution on a range of synthetic and real-world instances.

#index 1826478
#* picoTrans: using pictures as input for machine translation on mobile devices
#@ Andrew Finch;Wei Song;Kumiko Tanaka-Ishii;Eiichiro Sumita
#t 2011
#c 11
#% 579944
#% 817439
#% 954976
#% 1000335
#% 1211636
#% 1215368
#% 1269923
#% 1356191
#% 1453921
#! In this paper we present a novel user interface that integrates two popular approaches to language translation for travelers allowing multimodal communication between the parties involved: the picture-book, in which the user simply points to multiple picture icons representing what they want to say, and the statistical machine translation (SMT) system that can translate arbitrary word sequences. Our prototype system tightly couples both processes within a translation framework that inherits many of the the positive features of both approaches, while at the same time mitigating their main weaknesses. Our system differs from traditional approaches in that its mode of input is a sequence of pictures, rather than text or speech. Text in the source language is generated automatically, and is used as a detailed representation of the intended meaning. The picture sequence which not only provides a rapid method to communicate basic concepts but also gives a 'second opinion' on the machine transition output that catches machine translation errors and allows the users to retry the translation, avoiding misunderstandings.

#index 1826479
#* Automatic construction of efficient multiple battery usage policies
#@ Maria Fox;Derek Long;Daniele Magazzeni
#t 2011
#c 11
#% 344604
#% 393786
#% 785511
#% 1272095
#% 1272127
#% 1272199
#% 1272257
#% 1275083
#% 1301004
#% 1584385
#! There is a huge and growing number of systems that depend on batteries for power supply, ranging from small mobile devices to large high-powered systems such as electrical substations. In most of these systems, there are significant user-benefits or engineering reasons to base the supply on multiple batteries, with load being switched between batteries by a control system. The key to efficient use of multiple batteries lies in the design of effective policies for the management of the switching of load between them. This paper describes work in which we show that automated planning can produce much more effective policies than other approaches to multiple battery load management in the literature.

#index 1826480
#* Finite model computation via answer set programming
#@ Martin Gebser;Orkunt Sabuncu;Torsten Schaub
#t 2011
#c 11
#% 400992
#% 411814
#% 579716
#% 1099426
#% 1171772
#% 1495924
#% 1598609
#! We show how Finite Model Computation (FMC) of first-order theories can efficiently and transparently be solved by taking advantage of an extension of Answer Set Programming, called incremental Answer Set Programming (iASP). The idea is to use the incremental parameter in iASP programs to account for the domain size of a model. The FMC problem is then successively addressed for increasing domain sizes until an answer set, representing a finite model of the original first-order theory, is found. We developed a system based on the iASP solver iClingo and demonstrate its competitiveness.

#index 1826481
#* Measuring the good and the bad in inconsistent information
#@ John Grant;Anthony Hunter
#t 2011
#c 11
#% 578666
#% 1279226
#% 1705012
#! There is interest in artificial intelligence for principled techniques to analyze inconsistent information. This stems from the recognition that the dichotomy between consistent and inconsistent sets of formulae that comes from classical logics is not sufficient for describing inconsistent information. We review some existing proposals and make new proposals for measures of inconsistency and measures of information, and then prove that they are all pairwise incompatible. This shows that the notion of inconsistency is a multi-dimensional concept where different measures provide different insights. We then explore relationships between measures of inconsistency and measures of information in terms of the trade-offs they identify when using them to guide resolution of inconsistency.

#index 1826482
#* A correctness result for reasoning about one-dimensional planning problems
#@ Yuxiao Hu;Hector J. Levesque
#t 2011
#c 11
#% 35335
#% 297770
#% 342119
#% 572366
#% 1270245
#% 1289432
#% 1290267
#% 1476290
#! A plan with rich control structures like branches and loops can usually serve as a general solution that solves multiple planning instances in a domain. However, the correctness of such generalized plans is non-trivial to define and verify, especially when it comes to whether or not a plan works for all of the infinitely many instances of the problem. In this paper, we give a precise definition of a generalized plan representation called an FSA plan, with its semantics defined in the situation calculus. Based on this, we identify a class of infinite planning problems, which we call one-dimensional (1d), and prove a correctness result that 1d problems can be verified by finite means. We show that this theoretical result leads to an algorithm that does this verification practically, and a planner based on this verification algorithm efficiently generates provably correct plans for 1d problems.

#index 1826483
#* A transitivity aware matrix factorization model for recommendation in social networks
#@ Mohsen Jamali;Martin Ester
#t 2011
#c 11
#% 124010
#% 577217
#% 842605
#% 1083641
#% 1083671
#% 1214661
#% 1227602
#% 1260273
#% 1287243
#% 1476461
#! Recommender systems are becoming tools of choice to select the online information relevant to a given user. Collaborative filtering is the most popular approach to building recommender systems and has been successfully employed in many applications. With the advent of online social networks, the social network based approach to recommendation has emerged. This approach assumes a social network among users and makes recommendations for a user based on the ratings of the users who have direct or indirect social relations with the given user. As one of their major benefits, social network based approaches have been shown to reduce the problems with cold start users. In this paper, we explore a model-based approach for recommendation in social networks, employing matrix factorization techniques. Advancing previous work, we incorporate the mechanism of trust propagation into the model in a principled way. Trust propagation has been shown to be a crucial phenomenon in the social sciences, in social network analysis and in trust-based recommendation. We have conducted experiments on two real life data sets. Our experiments demonstrate that modeling trust propagation leads to a substantial increase in recommendation accuracy, in particular for cold start users.

#index 1826484
#* Reinforcement learning to adjust robot movements to new situations
#@ Jens Kober;Erhan Oztop;Jan Peters
#t 2011
#c 11
#% 124687
#% 225838
#% 236497
#% 464303
#% 720089
#% 891549
#% 983897
#% 1593320
#% 1673020
#! Many complex robot motor skills can be represented using elementary movements, and there exist efficient techniques for learning parametrized motor plans using demonstrations and self-improvement. However with current techniques, in many cases, the robot currently needs to learn a new elementary movement even if a parametrized motor plan exists that covers a related situation. A method is needed that modulates the elementary movement through the meta-parameters of its representation. In this paper, we describe how to learn such mappings from circumstances to meta-parameters using reinforcement learning. In particular we use a kernelized version of the reward-weighted regression. We show two robot applications of the presented setup in robotic domains; the generalization of throwing movements in darts, and of hitting movements in table tennis. We demonstrate that both tasks can be learned successfully using simulated and real robots.

#index 1826485
#* The combined approach to ontology-based data access
#@ R. Kontchakov;C. Lutz;D. Toman;F. Wolter;M. Zakharyaschev
#t 2011
#c 11
#% 101949
#% 654493
#% 992962
#% 1152458
#% 1269632
#% 1305620
#% 1369574
#% 1416180
#% 1594576
#! The use of ontologies for accessing data is one of the most exciting new applications of description logics in databases and other information systems. A realistic way of realising sufficiently scalable ontology-based data access in practice is by reduction to querying relational databases. In this paper, we describe the combined approach, which incorporates the information given by the ontology into the data and employs query rewriting to eliminate spurious answers. We illustrate this approach for ontologies given in the DL-Lite family of description logics and briefly discuss the results obtained for the EL family.

#index 1826486
#* Reasoning and proofing services for semantic web agents
#@ Kalliopi Kravari;Konstantinos Papatheodorou;Grigoris Antoniou;Nick Bassiliades
#t 2011
#c 11
#% 330234
#% 378901
#% 445444
#% 778288
#% 831274
#% 913800
#% 1021227
#% 1036512
#% 1333314
#% 1616181
#% 1714958
#% 1728724
#! The Semantic Web aims to offer an interoperable environment that will allow users to safely delegate complex actions to intelligent agents. Much work has been done for agents' interoperability; especially in the areas of ontology-based metadata and rule-based reasoning. Nevertheless, the SW proof layer has been neglected so far, although it is vital for agents and humans to understand how a result came about, in order to increase the trust in the interchanged information. This paper focuses on the implementation of third party SW reasoning and proofing services wrapped as agents in a multi-agent framework. This way, agents can exchange and justify their arguments without the need to conform to a common rule paradigm. Via external reasoning and proofing services, the receiving agent can grasp the semantics of the received rule set and check the validity of the inferred results.

#index 1826487
#* Efficient rule-based inferencing for OWL EL
#@ Markus Krötzsch
#t 2011
#c 11
#% 63789
#% 268708
#% 814635
#% 935898
#% 1152460
#% 1152473
#% 1289408
#% 1300579
#% 1495929
#% 1666169
#% 1703713
#! We review recent results on inferencing for SROEL(×), a description logic that subsumes the main features of the W3C recommendation OWL EL. Rule-based deduction systems are developed for various reasoning tasks and logical sublanguages. Certain feature combinations lead to increased space upper bounds for materialisation, suggesting that efficient implementations are easier to obtain for suitable fragments of OWL EL.

#index 1826488
#* Flexible tree matching
#@ Ranjitha Kumar;Jerry O. Talton;Salman Ahmad;Tim Roughgarden;Scott R. Klemmer
#t 2011
#c 11
#% 121462
#% 227859
#% 289193
#% 826007
#% 854636
#% 1290919
#% 1573595
#! Tree-matching problems arise in many computational domains. The literature provides several methods for creating correspondences between labeled trees; however, by definition, tree-matching algorithms rigidly preserve ancestry. That is, once two nodes have been placed in correspondence, their descendants must be matched as well. We introduce flexible tree matching, which relaxes this rigid requirement in favor of a tunable formulation in which the role of hierarchy can be controlled. We show that flexible tree matching is strongly NP-complete, give a stochastic approximation algorithm for the problem, and demonstrate how structured prediction techniques can learn the algorithm's parameters from a set of example matchings. Finally, we present results from applying the method to tasks in Web design.

#index 1826489
#* Enhancing case adaptation with introspective reasoning and web mining
#@ David Leake;Jay Powell
#t 2011
#c 11
#% 103914
#% 286419
#% 320847
#% 492358
#% 494443
#% 866959
#% 1099634
#% 1109935
#% 1109944
#% 1274873
#% 1737325
#! Case-based problem-solving systems reason by retrieving relevant prior cases and adapting their solutions to fit new circumstances. The ability of case-based reasoning (CBR) to reason from ungeneralized episodes can benefit knowledge acquisition, but acquiring the needed case adaptation knowledge has proven challenging. This paper presents a method for alleviating this problem with justin-time gathering of case adaptation knowledge, based on introspective reasoning and mining of Web knowledge sources. The approach combines knowledge planning with introspective reasoning to guide recovery from case adaptation failures and reinforcement learning to guide selection of knowledge sources. The failure recovery and knowledge source selection methods have been tested in three highly different domains with encouraging results. The paper closes with a discussion of limitations and future steps.

#index 1826490
#* Recommender systems: missing data and statistical model estimation
#@ Benjamin M. Marlin;Richard S. Zemel;Sam T. Roweis;Malcolm Slaney
#t 2011
#c 11
#% 17144
#% 124010
#% 268079
#% 330687
#% 1287220
#% 1650569
#! The goal of rating-based recommender systems is to make personalized predictions and recommendations for individual users by leveraging the preferences of a community of users with respect to a collection of items like songs or movies. Recommender systems are often based on intricate statistical models that are estimated from data sets containing a very high proportion of missing ratings. This work describes evidence of a basic incompatibility between the properties of recommender system data sets and the assumptions required for valid estimation and evaluation of statistical models in the presence of missing data. We discuss the implications of this problem and describe extended modelling and evaluation frameworks that attempt to circumvent it. We present prediction and ranking results showing that models developed and tested under these extended frameworks can significantly outperform standard models.

#index 1826491
#* Mind the eigen-gap, or how to accelerate semi-supervised spectral learning algorithms
#@ Dimitrios Mavroeidis
#t 2011
#c 11
#% 268079
#% 313959
#% 961204
#% 995140
#% 1176956
#% 1456836
#% 1485751
#! Semi-supervised learning algorithms commonly incorporate the available background knowledge such that an expression of the derived model's quality is improved. Depending on the specific context quality can take several forms and can be related to the generalization performance or to a simple clustering coherence measure. Recently, a novel perspective of semi-supervised learning has been put forward, that associates semi-supervised clustering with the efficiency of spectral methods. More precisely, it has been demonstrated that the appropriate use of partial supervision can bias the data Laplacian matrix such that the necessary eigenvector computations are provably accelerated. This result allows data mining practitioners to use background knowledge not only for improving the quality of clustering results, but also for accelerating the required computations. In this paper we initially provide a high level overview of the relevant efficiency maximizing semi-supervised methods such that their theoretical intuitions are comprehensively outlined. Consecutively, we demonstrate how these methods can be extended to handle multiple clusters and also discuss possible issues that may arise in the continuous semi-supervised solution. Finally, we illustrate the proposed extensions empirically in the context of text clustering.

#index 1826492
#* Ties matter: complexity of voting manipulation revisited
#@ Svetlana Obraztsova;Edith Elkind;Noam Hazon
#t 2011
#c 11
#% 408396
#% 951820
#% 1071500
#% 1083984
#% 1141527
#% 1272142
#% 1279324
#% 1305341
#% 1305345
#% 1426673
#% 1426682
#% 1521681
#% 1698228
#! In their groundbreaking paper, Bartholdi, Tovey and Trick [1989] argued that many well-known voting rules, such as Plurality, Borda, Copeland and Maximin are easy to manipulate. An important assumption made in that paper is that the manipulator's goal is to ensure that his preferred candidate is among the candidates with the maximum score, or, equivalently, that ties are broken in favor of the manipulator's preferred candidate. In this paper, we examine the role of this assumption in the easiness results of [Bartholdi et al., 1989]. We observe that the algorithm presented in [Bartholdi et al., 1989] extends to all rules that break ties according to a fixed ordering over the candidates. We then show that all scoring rules are easy to manipulate if the winner is selected from all tied candidates uniformly at random. This result extends to Maximin under an additional assumption on the manipulator's utility function that is inspired by the original model of [Bartholdi et al., 1989]. In contrast, we show that manipulation becomes hard when arbitrary polynomial-time tie-breaking rules are allowed, both for the rules considered in [Bartholdi et al., 1989], and for a large class of scoring rules.

#index 1826493
#* An on-line algorithm for semantic forgetting
#@ Heather S. Packer;Nicholas Gibbins;Nicholas R. Jennings
#t 2011
#c 11
#% 743386
#% 773291
#% 869464
#% 890345
#% 961683
#% 1333470
#% 1413143
#% 1517643
#% 1540328
#! Ontologies that evolve through use to support new domain tasks can grow extremely large. Moreover, large ontologies require more resources to use and have slower response times than small ones. To help address this problem, we present an on-line semantic forgetting algorithm that removes ontology fragments containing infrequently used or cheap to relearn concepts. We situate our algorithm in an extension of the widely used RoboCup Rescue platform, which provides simulated tasks to agents. We show that our agents send fewer messages and complete more tasks, and thus achieve a greater degree of success, than other state-of-the-art approaches.

#index 1826494
#* GUARDS: innovative application of game theory for national airport security
#@ James Pita;Milind Tambe;Christopher Kiekintveld;Shane Cullen;Erin Steigerwald
#t 2011
#c 11
#% 868454
#% 1280891
#% 1305580
#% 1453026
#% 1453189
#! We describe an innovative application of a novel game-theoretic approach for a national scale security deployment. Working with the United States Transportation Security Administration (TSA), we have developed a new application called GUARDS to allocate the TSA's limited resources across hundreds of security activities to provide protection at over 400 United States airports. Similar security applications (e.g., ARMOR and IRIS) have focused on one-off tailored applications and one security activity (e.g. checkpoints) per application, GUARDS on the other hand faces three new key issues: (i) reasoning about hundreds of heterogeneous security activities; (ii) reasoning over diverse potential threats; (iii) developing a system designed for hundreds of end-users. Since a national deployment precludes tailoring to specific airports, our key ideas are: (i) creating a new game-theoretic framework that allows for heterogeneous defender activities and compact modeling of a large number of threats; (ii) developing an efficient solution technique based on general purpose Stackelberg game solvers; (iii) taking a partially centralized approach for knowledge acquisition. The scheduling assistant has been delivered to the TSA and is currently undergoing evaluation for scheduling practices at an undisclosed airport. If successful, the TSA intends to incorporate the system into their unpredictable scheduling practices nationwide.

#index 1826495
#* Norm compliance of rule-based cognitive agents
#@ Antonino Rotolo
#t 2011
#c 11
#% 136356
#% 289946
#% 539798
#% 774337
#% 1066628
#% 1066630
#% 1280522
#% 1474460
#% 1531053
#% 1616183
#% 1674540
#! This paper shows how belief revision techniques can be used in Defeasible Logic to change rule-based theories characterizing the deliberation process of cognitive agents. We discuss intention reconsideration as a strategy to make agents compliant with the norms regulating their behavior.

#index 1826496
#* Theoretical justification of popular link prediction heuristics
#@ Purnamrita Sarkar;Deepayan Chakrabarti;Andrew W. Moore
#t 2011
#c 11
#% 300078
#% 730089
#! There are common intuitions about how social graphs are generated (for example, it is common to talk informally about nearby nodes sharing a link). There are also common heuristics for predicting whether two currently unlinked nodes in a graph should be linked (e.g. for suggesting friends in an online social network or movies to customers in a recommendation network). This paper provides what we believe to be the first formal connection between these intuitions and these heuristics. We look at a familiar class of graph generation models in which nodes are associated with locations in a latent metric space and connections are more likely between closer nodes. We also look at popular link-prediction heuristics such as number-of-common-neighbors and its weighted variants [Adamic and Adar, 2003] which have proved successful in predicting missing links, but are not direct derivatives of latent space graph models. We provide theoretical justifications for the success of some measures as compared to others, as reported in previous empirical studies. In particular we present a sequence of formal results that show bounds related to the role that a node's degree plays in its usefulness for link prediction, the relative importance of short paths versus long paths, and the effects of increasing non-determinism in the link generation process on link prediction quality. Our results can be generalized to any model as long as the latent space assumption holds.

#index 1826497
#* Evaluation of group profiling strategies
#@ Christophe Senot;Dimitre Kostadinov;Makram Bouzid;Jérôme Picault;Armen Aghasaryan
#t 2011
#c 11
#% 260780
#% 549154
#% 733578
#% 755034
#% 878355
#% 894905
#% 955930
#% 1086560
#! Most of the existing personalization systems such as content recommenders or targeted ads focus on individual users and ignore the social situation in which the services are consumed. However, many human activities are social and involve several individuals whose tastes and expectations must be taken into account by the system. When a group profile is not available, different profile aggregation strategies can be applied to recommend adequate items to a group of users based on their individual profiles. We consider an approach intended to determine the factors that influence the choice of an aggregation strategy. We present evaluations made on a large-scale dataset of TV viewings, where real group interests are compared to the predictions obtained by combining individual user profiles according to different strategies.

#index 1826498
#* Connecting the dots between news articles
#@ Dafna Shahaf;Carlos Guestrin
#t 2011
#c 11
#% 1722
#% 230532
#% 268079
#% 445316
#% 729923
#% 783535
#% 823344
#% 1451202
#! The process of extracting useful knowledge from large datasets has become one of the most pressing problems in today's society. The problem spans entire sectors, from scientists to intelligence analysts and web users, all of whom are constantly struggling to keep up with the larger and larger amounts of content published every day. With this much data, it is often easy to miss the big picture. In this paper, we investigate methods for automatically connecting the dots - providing a structured, easy way to navigate within a new topic and discover hidden connections. We focus on the news domain: given two news articles, our system automatically finds a coherent chain linking them together. For example, it can recover the chain of events leading from the decline of home prices (2007) to the health-care debate (2009). We formalize the characteristics of a good chain and provide efficient algorithms to connect two fixed endpoints. We incorporate user feedback into our framework, allowing the stories to be refined and personalized. Finally, we evaluate our algorithm over real news data. Our user studies demonstrate the algorithm's effectiveness in helping users understanding the news.

#index 1826499
#* Learning linear and kernel predictors with the 0-1 loss function
#@ Shai Shalev-Shwartz;Ohad Shamir;Karthik Sridharan
#t 2011
#c 11
#% 73372
#% 116172
#% 393059
#% 722909
#% 743284
#% 836495
#% 898317
#% 898318
#! Some of the most successful machine learning algorithms, such as Support Vector Machines, are based on learning linear and kernel predictors with respect to a convex loss function, such as the hinge loss. For classification purposes, a more natural loss function is the 0-1 loss. However, using it leads to a non-convex problem for which there is no known efficient algorithm. In this paper, we describe and analyze a new algorithm for learning linear or kernel predictors with respect to the 0-1 loss function. The algorithm is parameterized by L, which quantifies the effective width around the decision boundary in which the predictor may be uncertain. We show that without any distributional assumptions, and for any fixed L, the algorithm runs in polynomial time, and learns a classifier which is worse than the optimal such classifier by at most ε. We also prove a hardness result, showing that under a certain cryptographic assumption, no algorithm can learn such classifiers in time polynomial in L.

#index 1826500
#* Adaptive data compression for robot perception
#@ Mike Smith;Ingmar Posner;Paul Newman
#t 2011
#c 11
#% 149103
#% 450245
#% 726687
#% 891549
#% 916792
#% 1074346
#% 1182603
#% 1192712
#% 1287876
#% 1342687
#% 1590033
#! This paper concerns the creation of an efficient, continuous, non-parametric representation of surfaces implicit in 3D laser data as typically recorded by mobile robots. Our approach explicitly leverages the probabilistic nature of Gaussian Process regression to provide for a principled, adaptive subsampling which automatically prunes redundant data. The algorithm places no restriction on the complexity of the underlying surfaces and enables predictions at arbitrary locations and densities. We present results using real and synthetic data and show that our approach attains decimation factors in excess of two orders of magnitude without significant degradation in fidelity of the workspace reconstructions.

#index 1826501
#* Active exploration for robust object detection
#@ Javier Velez;Garrett Hemann;Albert S. Huang;Ingmar Posner;Nicholas Roy
#t 2011
#c 11
#% 840868
#% 867753
#% 1022064
#% 1201846
#% 1272231
#% 1287876
#% 1287879
#% 1713177
#! Today, mobile robots are increasingly expected to operate in ever more complex and dynamic environments. In order to carry out many of the higher-level tasks envisioned a semantic understanding of a workspace is pivotal. Here our field has benefited significantly from successes in machine learning and vision: applications in robotics of off-the-shelf object detectors are plentiful. This paper outlines an online, any-time planning framework enabling the active exploration of such detections. Our approach exploits the ability to move to different vantage points and implicitly weighs the benefits of gaining more certainty about the existence of an object against the physical cost of the exploration required. The result is a robot which plans trajectories specifically to decrease the entropy of putative detections. Our system is demonstrated to significantly improve detection performance and trajectory length in simulated and real robot experiments.

#index 1826502
#* A framework for longitudinal influence measurement between communication content and social networks
#@ Shenghui Wang;Paul Groth
#t 2011
#c 11
#% 961567
#% 1039360
#% 1060608
#% 1218646
#% 1282011
#% 1287880
#% 1333440
#% 1374378
#% 1409960
#% 1540342
#% 1667794
#! Artificial intelligence has a long history of learning from domain problems ranging from chess to jeopardy. In this work, we look at a problem stemming from social science, namely, how do social relationships influence communication content and vice versa. The tools used to study communication content (content analysis) have rarely been combined with those used to study social relationships (social network analysis). Furthermore, there is even less work addressing the longitudinal characteristics of such a combination. This paper presents a general framework for measuring the dynamic bi-directional influence between communication content and social networks. The framework leverages the idea that knowledge about both kinds of networks can be represented using the same knowledge representation. In particular, through the use of Semantic Web standards, the extraction of networks is made easier. The framework is applied to two use-cases: online forum discussions and conference publications. The results provide a new perspective over the dynamics involving both social networks and communication content.

#index 1826503
#* WSABIE: scaling up to large vocabulary image annotation
#@ Jason Weston;Samy Bengio;Nicolas Usunier
#t 2011
#c 11
#% 132938
#% 269226
#% 635730
#% 780756
#% 961152
#% 961270
#% 987226
#% 1069003
#% 1074021
#% 1119142
#% 1148273
#% 1211822
#% 1269777
#% 1457039
#! Image annotation datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at the top of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations. Our method, called WSABIE, both outperforms several baseline methods and is faster and consumes less memory.

#index 1826504
#* Analysis of adjective-noun word pair extraction methods for online review summarization
#@ Koji Yatani;Michael Novati;Andrew Trusty;Khai N. Truong
#t 2011
#c 11
#% 406493
#% 577355
#% 769892
#% 805873
#% 815915
#% 848644
#% 854646
#% 939912
#% 955013
#% 1001261
#% 1055855
#% 1169597
#% 1305619
#% 1536516
#% 1536586
#% 1573521
#! Many people read online reviews written by other users to learn more about a product or venue. However, the overwhelming amount of user-generated reviews and variance in length, detail and quality across the reviews make it difficult to glean useful information. In this paper, we present a summarization system called Review Spotlight. It provides a brief overview of reviews by using adjective-noun word pairs extracted from the review text. The system also allows the user to click any word pair to read the original sentences from which the word pair was extracted. We present our system implementation as a Google Chrome browser extension, and an evaluation on how two word pair scoring methods (TF and TF-IDF) affect the identification of useful word pairs.

#index 1826505
#* Large linear classification when data cannot fit in memory
#@ Hsiang-Fu Yu;Cho-Jui Hsieh;Kai-Wei Chang;Chih-Jen Lin
#t 2011
#c 11
#% 209021
#% 269217
#% 825642
#% 881477
#% 983905
#% 1073923
#% 1117691
#% 1318710
#% 1451223
#% 1558464
#! Linear classification is a useful tool for dealing with large-scale data in applications such as document classification and natural language processing. Recent developments of linear classification have shown that the training process can be efficiently conducted. However, when the data size exceeds the memory capacity, most training methods suffer from very slow convergence due to the severe disk swapping. Although some methods have attempted to handle such a situation, they are usually too complicated to support some important functions such as parameter selection. In this paper, we introduce a block minimization framework for data larger than memory. Under the framework, a solver splits data into blocks and stores them into separate files. Then, at each time, the solver trains a data block loaded from disk. Although the framework is simple, the experimental results show that it effectively handles a data set 20 times larger than the memory capacity.

#index 1826506
#* Solving the multiagent selection and scheduling problem
#@ James Boerkoel
#t 2011
#c 11
#% 36814
#% 443227
#% 578726
#% 1024750
#% 1056487
#% 1215595
#% 1270320
#% 1614160

#index 1826507
#* Decision support through argumentation-based practical reasoning
#@ Federico Cerutti
#t 2011
#c 11
#% 198464
#% 1228574
#% 1496577
#! This extended research abstract describes an argumentation-based approach to modelling articulated decision making contexts. The approach encompasses a variety of argument and attack schemes aimed at representing basic knowledge and reasoning patterns for decision support.

#index 1826508
#* Behaviour recognition in smart homes
#@ Sook-Ling Chua;Stephen Marsland;Hans W. Guesgen
#t 2011
#c 11
#% 984391
#% 1018413
#% 1089789
#% 1334698

#index 1826509
#* Statement of thesis research: multi-robot sampling strategies for large-scale oceanographic experiments
#@ Jnaneshwar Das
#t 2011
#c 11
#% 1073898
#% 1074346
#% 1138994
#% 1270298
#% 1342780
#! My thesis research focuses on developing tools and techniques in the robotic sciences to study and understand large-scale dynamic coastal processes that are driven by global climate change. As a first step, my work targets Harmful Algal Blooms (HABs) which have significant societal and economic impact to coastal communities, yet are poorly understood ecologically because of undersampling.

#index 1826510
#* Control of robotic systems for safe interaction with human operators
#@ Hao Ding
#t 2011
#c 11
#% 1287874
#% 1367886
#! Human Robot Interaction (HRI) is an active field of integrating and embedding different techniques in artificial intelligence. This paper describes my research topic on: Control of Robotic Systems for Safe Interaction with Human Operators. It consists of online motion generation for robotic manipulators interactingwith dynamic obstacles and humans using a moving horizon scheme, modeling and long term prediction of human motion using probabilistic models and reachability analysis, and development of an HRI demonstration platform.

#index 1826511
#* Combining machine learning and optimization techniques to determine 3-D structures of polypeptides
#@ Márcio Dorn;Luciana S. Buriol;Luis C. Lamb
#t 2011
#c 11
#% 760958
#% 1106811
#% 1429052
#% 1456609
#! One of the main research problems in Structural Bioinformatics is the analysis and prediction of three-dimensional structures (3-D) of polypeptides or proteins. The 1990's Genome projects resulted in a large increase in the number of protein sequences. However, the number of identified 3-D protein structures has not followed the same trend. The determination of protein structure is experimentally expensive and time consuming. This makes scientists largely dependent on computational methods that can predict correct 3-D protein structures only from extended and full amino acid sequences. Several computational methodologies and algorithms have been proposed as a solution to the Protein Structure Prediction (PSP) problem. We briefly describe the AI techniques we have been used to tackle this problem.

#index 1826512
#* An agent-oriented software engineering methodology to develop adaptive virtual organizations
#@ Sergio Esparcia;Estefanía Argente;Vicente Botti
#t 2011
#c 11
#% 378985
#% 431525
#% 822359
#% 931240
#% 1024826
#% 1192291
#% 1230541
#% 1520685
#% 1562617
#! This paper presents the current state of this research work, aimed to develop a methodology for designing Adaptive Virtual Organizations. This paper includes both completed and remaining work on this topic.

#index 1826513
#* Towards social problem-solving with human subjects
#@ Daniel S. Farenzena;Ricardo M. Araujo;Luis C. Lamb
#t 2011
#c 11
#% 1270020
#% 1287523
#! Recently, the use of social and human computing has witnessed increasing interest in the AI community. However, in order to harness the true potential of social computing, human subjects must play an active role in achieving computation in social networks and related media. Our work proposes an initial desiderata for effective social computing, drawing inspiration from artificial intelligence. Extensive experimentation reveals that several open issues and research questions have to be answered before the true potential of social and human computing is achieved. We, however, take a somewhat novel approach, by implementing a social networks environment where human subjects cooperate towards computational problem solving. In our social environment, human and artificial agents cooperate in their computation tasks, which may lead to a single problem-solving social network that potentially allows seamless cooperation among human and machine agents.

#index 1826514
#* Towards spatial methods for socially assistive robotics: validation with children with autism spectrum disorders
#@ David Feil-Seifer
#t 2011
#c 11
#% 1401570
#% 1555514

#index 1826515
#* Regret minimization in multiplayer extensive games
#@ Richard Gibson;Duane Szafron
#t 2011
#c 11
#% 384911
#% 1279308
#% 1453077
#! The counterfactual regret minimization (CFR) algorithm is state-of-the-art for computing strategies in large games and other sequential decision-making problems. Little is known, however, about CFR in games with more than 2 players. This extended abstract outlines research towards a better understanding of CFR in multiplayer games and new procedures for computing even stronger multiplayer strategies. We summarize work already completed that investigates techniques for creating "expert" strategies for playing smaller sub-games, and work that proves CFR avoids classes of undesirable strategies. In addition, we provide an outline of our future research direction. Our goals are to apply regret minimization to the problem of playing multiple games simultaneously, and augment CFR to achieve effective on-line opponent modelling of multiple opponents. The objective of this research is to build a world-class computer poker player for multiplayer Limit Texas Hold'em.

#index 1826516
#* Combinatorial aggregation
#@ Umberto Grandi
#t 2011
#c 11
#% 1096055
#% 1274973
#% 1453101
#% 1826097

#index 1826517
#* Combining spatial and temporal aspects of prediction problems to improve prediction performance
#@ William Groves
#t 2011
#c 11
#% 729921

#index 1826518
#* A decision-theoretic academic advisor
#@ Joshua T. Guerin
#t 2011
#c 11
#% 1453194
#% 1551429

#index 1826519
#* Belief revision on computation tree logic
#@ Paulo T. Guerra;Renata Wassermann
#t 2011
#c 11
#% 2991
#% 1272201
#% 1273492
#% 1547090
#! Model checking is one of the most effective techniques in automated system verification. Although this technique can handle complex verifications, model checking tools usually do not give any suggestions on how to repair inconsistent system models. In this paper, we show that approaches developed to update models of Computation Tree Logic (CTL) cannot deal with all kinds of changes. We introduce the concept of CTL model revision: an approach based on belief revision to handle system inconsistency in a static context.

#index 1826520
#* Distributed constraint optimization problems related with soft arc consistency
#@ Patricia Gutierrez;Pedro Meseguer
#t 2011
#c 11
#% 773217
#% 1083937
#% 1108503
#% 1270059
#% 1279246
#% 1289364
#% 1291421
#% 1305319
#% 1473213
#% 1498839
#! Distributed Constraint Optimization Problems (DCOPs) can be optimally solved by distributed search algorithms, such as ADOPT and BnB-ADOPT. In centralized solving, maintaining soft arc consistency during search has proved to be beneficial for performance. In this thesis we aim to explore the maintenance of different levels of soft arc consistency in distributed search when solving DCOPs.

#index 1826521
#* A trust and reputation model for supply chain management
#@ Yasaman Haghpanah
#t 2011
#c 11
#% 823966
#% 987483
#% 1156102
#% 1453085
#! My thesis contributes to the field of multi-agent systems by proposing a novel trust-based decision model for supply chain management.

#index 1826522
#* Graph pruning and symmetry breaking on grid maps
#@ Daniel Harabor
#t 2011
#c 11
#% 534450
#% 1273866
#% 1305386

#index 1826523
#* Towards scalable mdp algorithms
#@ Andrey Kolobov
#t 2011
#c 11
#% 1305570

#index 1826524
#* Talking about trust in heterogeneous multi-agent systems
#@ Andrew Koster;Jordi Sabater-Mir;Marco Schorlemmer
#t 2011
#c 11
#% 237519
#% 409387
#% 607998
#% 1250347
#% 1453083
#% 1453310
#% 1473403
#% 1485634
#! In heterogeneous multi-agent systems trust is necessary to improve interactions by enabling agents to choose good partners. Most trust models work by taking, in addition to direct experiences, other agents' communicated evaluations into account. However, in an open MAS other agents may use different trust models and the evaluations they communicate are based on different principles: as such they are meaningless without some form of alignment. My doctoral research gives a formal definition of this problem and proposes two methods of achieving an alignment.

#index 1826525
#* An analysis of multiobjective search algorithms and heuristics
#@ E. Machuca
#t 2011
#c 11
#% 102372
#% 1129838
#% 1289385
#% 1384949
#% 1490370
#! This thesis analyzes the performance of multiobjective heuristic graph search algorithms. The analysis is focused on the influence of heuristic information, correlation between objectives and solution depth.

#index 1826526
#* On temporal regulations and commitment protocols
#@ Elisa Marengo;Matteo Baldoni;Cristina Baroglio
#t 2011
#c 11
#% 1334948
#% 1473226
#% 1587226
#% 1615216
#% 1704221
#! The proposal of Elisa Marengo's thesis is to extend commitment protocols in order to (i) allow for expressing commitments to temporal regulations, and (ii) to supply a tool for expressing laws, conventions and the like, in order to specify legal interactions. These two aspects will be deeply investigated in the proposal of a unified framework. This proposal is part of ongoing work that will be included in the thesis.

#index 1826527
#* Contributions to personalizable knowledge integration
#@ Maria Vanina Martinez
#t 2011
#c 11
#% 273687
#% 289283
#% 420659
#% 442755
#% 810019
#% 1274848
#! Inconsistency and partial information is the norm in knowledge bases used in many real world applications that support, among other things, human decision making processes. In this work we argue that the management of this kind of data needs to be context-sensitive, creating a synergy with the user to build useful, flexible data management systems.

#index 1826528
#* Cecision making under uncertainty: social choice and manipulation
#@ Nicholas Mattei
#t 2011
#c 11
#% 951820
#% 1274974
#% 1288655
#% 1332271
#% 1332276

#index 1826529
#* RDFKB: a semantic web knowledge base
#@ James P. McGlothlin;Latifur Khan;Bhavani Thuraisingham
#t 2011
#c 11
#% 1022236
#% 1270470
#% 1333465
#% 1477933
#! There are many significant research projects focused on providing semantic web repositories that are scalable and efficient. However, the true value of the semantic web architecture is its ability to represent meaningful knowledge and not just data. Therefore, a semantic web knowledge base should do more than retrieve collections of triples. We propose RDFKB (Resource Description Knowledge Base), a complete semantic web knowledge case. RDFKB is a solution for managing, persisting and querying semantic web knowledge. Our experiments with real world and synthetic datasets demonstrate that RDFKB achieves superior query performance to other state-of-the-art solutions. The key features of RDFKB that differentiate it from other solutions are: 1) a simple and efficient process for data additions, deletions and updates that does not involve reprocessing the dataset; 2) materialization of inferred triples at addition time without performance degradation; 3) materialization of uncertain information and support for queries involving probabilities; 4) distributed inference across datasets; 5) ability to apply alignments to the dataset and perform queries against multiple sources using alignment. RDFKB allows more knowledge to be stored and retrieved; it is a repository not just for RDF datasets, but also for inferred triples, probability information, and lineage information. RDFKB provides a complete and efficient RDF data repository and knowledge base.

#index 1826530
#* Research proposal: cooperation among self interested agents
#@ Reshef Meir
#t 2011
#c 11
#% 338409
#% 1305325
#% 1530782
#% 1614181
#% 1826112

#index 1826531
#* Temporal defeasible argumentation in multi-agent planning
#@ Sergio Pajares;Eva Onaindia
#t 2011
#c 11
#% 752766
#% 992249
#% 1222443
#% 1410684
#% 1453144
#% 1617539
#! In this paper, I present my ongoing research on temporal defeasible argumentation-based multi-agent planning. In multi-agent planning a team of agents share a set of goals but have diverse abilities and temporal beliefs, which vary over time. In order to plan for these goals, agents start a stepwise dialogue consisting of exchanges of temporal plan proposals, plus temporal arguments against them, where both, actions with different duration, and temporal defeasible arguments, need to be integrated. This thesis proposes a computational framework for this research on multi-agent planning.

#index 1826532
#* Human behavior analysis from video data using bag-of-gestures
#@ Víctor Ponce;Mario Gorga;Xavier Baró;Sergio Escalera
#t 2011
#c 11
#% 429731
#% 736300
#% 803660
#% 1073395
#% 1246209
#% 1784964
#! Human Behavior Analysis in Uncontrolled Environments can be categorized in two main challenges: 1) Feature extraction and 2) Behavior analysis from a set of corporal language vocabulary. In this work, we present our achievements characterizing some simple behaviors from visual data on different real applications and discuss our plan for future work: low level vocabulary definition from bag-of-gesture units and high level modelling and inference of human behaviors.

#index 1826533
#* Multi-agent coordination: dcops and beyond
#@ Marc Pujol-Gonzalez
#t 2011
#c 11
#% 773217
#% 1083937
#% 1289393
#% 1291417
#% 1291421
#% 1305319
#% 1453074
#% 1453076
#% 1497403
#% 1565437
#% 1614188
#% 1809993
#! Distributed constraint optimization problems (DCOPs) are a model for representing multi-agent systems in which agents cooperate to optimize a global objective. The DCOP model has two main advantages: it can represent a wide range of problem domains, and it supports the development of generic algorithms to solve them. Firstly, this paper presents some advances in both complete and approximate DCOP algorithms. Secondly, it explains that the DCOP model makes a number of unrealistic assumptions that severely limit its range of application. Finally, it points out hints on how to tackle such limitations.

#index 1826534
#* Bayesian abductive logic programs: a probabilistic logic for abductive reasoning
#@ Sindhu V. Raghavan
#t 2011
#c 11
#% 44876
#% 550745
#% 850430
#% 1000502
#% 1273436
#% 1274292
#! In this proposal, we introduce Bayesian Abductive Logic Programs (BALP), a probabilistic logic that adapts Bayesian Logic Programs (BLPs) for abductive reasoning. Like BLPs, BALPs also combine first-order logic and Bayes nets. However, unlike BLPs, which use deduction to construct Bayes nets, BALPs employ logical abduction. As a result, BALPs are more suited for problems like plan/activity recognition that require abductive reasoning. In order to demonstrate the efficacy of BALPs, we apply it to two abductive reasoning tasks - plan recognition and natural language understanding.

#index 1826535
#* From an agent logic to an agent programming language for partially observable stochastic domains
#@ Gavin Rens
#t 2011
#c 11
#% 529345
#% 934828
#! Broadly speaking, my research concerns combining logic of action and POMDP theory in a coherent, theoretically sound language for agent programming. We have already developed a logic for specifying partially observable stochastic domains. A logic for reasoning with the models specified must still be developed. An agent programming language will then be developed and used to design controllers for robots.

#index 1826536
#* Agent-based negotiation teams
#@ Victor Sanchez-Anguix;Vicente Julian;Ana García-Fornes
#t 2011
#c 11
#% 1617534
#! Agent-based negotiation teams are negotiation parties formed by more than a single individual. Individuals unite as a single negotiation party because they share a common goal that is related to a negotiation with one or several opponents. My research goal is providing agent-based computational models for negotiation teams in multi-agent systems.

#index 1826537
#* A method for evaluating and standardizing ontologies
#@ A. Patrice Seyed
#t 2011
#c 11
#% 1092031

#index 1826538
#* Towards a model-centric cognitive architecture for service robots
#@ Andreas Steck
#t 2011
#c 11
#% 1546594
#! The development of service robots has gained more and more attention over the last years. Advanced robots have to cope with many different situations and contingencies while executing concurrent and interruptable complex tasks. To manage the sheer variety of different execution variants the robot has to decide at run-time for the most appropriate behavior to execute. That requires task coordination mechanisms that provide the flexibility to adapt at run-time and allow to balance between alternatives.

#index 1826539
#* Sensorimotor models of space and object geometry
#@ Jeremy Stober
#t 2011
#c 11
#% 229084
#! A baby experiencing the world for the first time faces a considerable challenging sorting through what William James called the "blooming, buzzing confusion" of the senses. With the increasing capacity of modern sensors and the complexity of modern robot bodies, a robot in an unknown or unfamiliar body faces a similar and equally daunting challenge. Addressing this challenge directly by designing robot agents capable of resolving the confusion of sensory experience in an autonomous manner would substantially reduce the engineering required to program robots and the improve the robustness of resulting robot capabilities. Working towards a general solution to this problem, this work uses distinctive state abstractions and sensorimotor embedding to generate basic knowledge of sensor structure, local geometry, and object geometry starting with uninterpreted sensors and effectors.

#index 1826540
#* Multiagent hierarchical learning from demonstration
#@ Keith Sullivan
#t 2011
#c 11

#index 1826541
#* Heuristic search under quality and time bounds
#@ Jordan T. Thayer
#t 2011
#c 11
#% 1270238
#% 1272145
#% 1274276
#% 1632825
#% 1826170
#! Heuristic search is a central component of many important applications in AI including automated planning. While we can find optimal solutions to heuristic search problems, doing so may take hours or days. For practical applications, this is unacceptably slow, and we must rely on algorithms which find solutions of high, but not optimal, quality or ones which bound the time used directly. In my dissertation, I present and analyze algorithms for the following settings: quality bounded heuristic search and time bounded heuristic search. The central theme of my doctoral work will be that taking advantage of additional information can improve the performance of heuristic search algorithms.

#index 1826542
#* On the impact of belief state representation in planning under uncertainty
#@ Son Thanh To
#t 2011
#c 11
#% 121397
#% 342378
#% 873941
#% 1172475
#% 1272109
#% 1305550

#index 1826543
#* Autonomous object manipulation: a semantic-driven approach
#@ Nicola Vitucci
#t 2011
#c 11
#% 778740
#% 1033733
#% 1066300
#% 1092069
#% 1136065
#% 1269845
#! The problem of grasping is widely studied in the robotics community. This project focuses on the identification of object graspable features using images and object structural information. The primary aim is the creation of a framework in which the information gathered by the vision system can be integrated with automatically generated knowledge, modelled by means of fuzzy description logics.

#index 1826544
#* Tractable massively multi-agent pathfinding with solution quality and completeness guarantees
#@ Ko-Hsin Cindy Wang
#t 2011
#c 11
#% 1272212
#% 1305589
#% 1342335
#% 1473393

#index 1826545
#* Input parameter calibration in forest fire spread prediction: taking the intelligentway
#@ Kerstin Wendt;Ana Cortés
#t 2011
#c 11
#% 1104470
#% 1277669

#index 1826546
#* Transfer learning in spatial reasoning puzzles
#@ Baylor Wetzel
#t 2011
#c 11
#% 258186
#% 1385963

#index 1826547
#* Trust mechanisms for online systems
#@ Jens Witkowski
#t 2011
#c 11
#% 580514
#% 959133
#% 1305342

#index 1826548
#* Mechanism design for dynamic environments: online double auctions
#@ Dengji Zhao
#t 2011
#c 11
#% 88364
#% 813771
#% 907719
#% 1270027
#% 1272184
#% 1826138
#! This paper states the challenges of mechanism design for dynamic environments, especially dynamic double auctions. After a brief review of related work, we specify the problem we are tackling, and then briefly outline our research plan, the results we have achieved to date, and the ongoing directions.

#index 2015026
#* Joint Proceedings of the Workshop on AI Problems and Approaches for Intelligent Environments and Workshop on Semantic Cities
#@ Sebastian Bader;Anika Schumann;Stephan Sigg;Freddy Lecue;Biplav Srivastava;Zaiqing Nie;Christian Guttmann
#t 2013
#c 11
#! This one-day workshop consisted of two sub-workshops with both exclusive as well as partially overlapping joint sessions. The sub-workshops were called "AI Problems and Approaches for Intelligent Environments" and "Semantic Cities" respectively. However, the common theme was to drive intelligent ecosystems, whether at the level of individual systems like buildings or at the level of system of systems, like cities.

#index 2032832
#* Proceedings of the Twenty-Third international joint conference on Artificial Intelligence
#@ Francesca Rossi
#t 2013
#c 11

#index 2032833
#* Computational perspectives on social phenomena at global scales
#@ Jon Kleinberg
#t 2013
#c 11
#% 1077150
#% 1127964
#% 1190088
#% 1214671
#% 1227295
#% 1269756
#% 1292698
#% 1399963
#% 1399992
#% 1425621
#% 1428692
#% 1536509
#% 1560424
#% 1560429
#% 1592006
#% 1711579
#% 1711663
#% 1746868
#% 1872259
#% 1906975
#% 1913337
#% 1948124
#! The growth of social media and on-line social networks has opened up a set of fascinating new challenges and directions for researchers in both computing and the social sciences, and an active interface is growing between these areas. We discuss a set of basic questions that arise in the design and analysis of systems supporting on-line social interactions, focusing on two main issues: the role of network structure in the dynamics of social media sites, and the analysis of textual data as a way to study properties of on-line social interaction.

#index 2032834
#* Soft robotics: the next generation of intelligent machines
#@ Rolf Pfeifer;Hugo Gravato Marques;Fumiya Iida
#t 2013
#c 11
#% 431471
#% 929398
#% 1766080
#% 1862498
#% 1894068
#! There has been an increasing interest in applying biological principles to the design and control of robots. Unlike industrial robots that are programmed to execute a rather limited number of tasks, the new generation of bio-inspired robots is expected to display a wide range of behaviours in unpredictable environments, as well as to interact safely and smoothly with human co-workers. In this article, we put forward some of the properties that will characterize these new robots: soft materials, flexible and stretchable sensors, modular and efficient actuators, self-organization and distributed control. We introduce a number of design principles; in particular, we try to comprehend the novel design space that now includes soft materials and requires a completely different way of thinking about control. We also introduce a recent case study of developing a complex humanoid robot, discuss the lessons learned and speculate about future challenges and perspectives.

#index 2032835
#* Computational disaster management
#@ Pascal Van Hentenryck
#t 2013
#c 11
#% 733732
#% 1191399
#% 1590593
#% 1598172
#% 1737864
#% 1776806
#% 1874804

#index 2032836
#* Reasoning about normative update
#@ Natasha Alechina;Mehdi Dastani;Brian Logan
#t 2013
#c 11
#% 2991
#% 413871
#% 1171316
#% 1280814
#% 1453136
#% 1529130
#% 1539312
#% 1707092
#% 1875688
#% 1985108
#! We consider the problem of updating a multi-agent system with a set of conditional norms. A norm comes into effect when its condition becomes true, and imposes either an obligation or a prohibition on an agent which remains in force until a state satisfying a deadline condition is reached. If the norm is violated, a sanction is imposed on the agent. We define a notion of a normative update of a multi-agent system by a set of conditional norms, and study the problem of checking whether the agent(s) can bring about a state satisfying a property without incurring a specified number of sanctions.

#index 2032837
#* Undecidability in epistemic planning
#@ Guillaume Aucher;Thomas Bolander
#t 2013
#c 11
#% 167629
#% 188086
#% 194648
#% 283210
#% 379175
#% 380578
#% 480340
#% 743353
#% 823863
#% 943991
#% 1197380
#% 1272071
#% 1630743
#% 1875883
#% 1925304
#! Dynamic epistemic logic (DEL) provides a very expressive framework for multi-agent planning that can deal with nondeterminism, partial observability, sensing actions, and arbitrary nesting of beliefs about other agents' beliefs. However, as we show in this paper, this expressiveness comes at a price. The planning framework is undecidable, even if we allow only purely epistemic actions (actions that change only beliefs, not ontic facts). Undecidability holds already in the S5 setting with at least 2 agents, and even with 1 agent in S4. It shows that multi-agent planning is robustly undecidable if we assume that agents can reason with an arbitrary nesting of beliefs about beliefs. We also prove a corollary showing undecidability of the DEL model checking problem with the star operator on actions (iteration).

#index 2032838
#* Maximal recursive rule: a new social decision scheme
#@ Haris Aziz
#t 2013
#c 11
#% 951820
#% 1250606
#% 1272227
#% 1875759
#% 1989607
#! In social choice settings with strict preferences, random dictatorship rules were characterized by Gibbard [1977] as the only randomized social choice functions that satisfy strategyproofness and ex post efficiency. In the more general domain with indifferences, RSD (random serial dictatorship) rules are the well-known and perhaps only known generalization of random dictatorship. We present a new generalization of random dictatorship for indifferences called Maximal Recursive (MR) rule as an alternative to RSD. We show that MR is polynomial-time computable, weakly strategyproof with respect to stochastic dominance, and, in some respects, outperforms RSD on efficiency.

#index 2032839
#* Audit games
#@ Jeremiah Blocki;Nicolas Christin;Anupam Datta;Ariel D. Procaccia;Arunesh Sinha
#t 2013
#c 11
#% 604673
#% 868454
#% 876083
#% 1067177
#% 1215597
#% 1270420
#% 1386038
#% 1627660
#% 1693959
#% 1747552
#% 1826108
#% 1826494
#! Effective enforcement of laws and policies requires expending resources to prevent and detect offenders, as well as appropriate punishment schemes to deter violators. In particular, enforcement of privacy laws and policies in modern organizations that hold large volumes of personal information (e.g., hospitals, banks) relies heavily on internal audit mechanisms. We study economic considerations in the design of these mechanisms, focusing in particular on effective resource allocation and appropriate punishment schemes. We present an audit game model that is a natural generalization of a standard security game model for resource allocation with an additional punishment parameter. Computing the Stackelberg equilibrium for this game is challenging because it involves solving an optimization problem with non-convex quadratic constraints. We present an additive FPTAS that efficiently computes the solution.

#index 2032840
#* Using double-oracle method and serialized alpha-beta search for pruning in simultaneous move games
#@ Branislav Bošanský;Viliam Lisý;Jiří Čermák;Roman Vítek;Michal Pěchouček
#t 2013
#c 11
#% 180122
#% 1152376
#% 1313373
#% 1597070
#% 1614182
#% 1693959
#% 1713137
#! We focus on solving two-player zero-sum extensive-form games with perfect information and simultaneous moves. In these games, both players fully observe the current state of the game where they simultaneously make a move determining the next state of the game. We solve these games by a novel algorithm that relies on two components: (1) it iteratively solves the games that correspond to a single simultaneous move using a double-oracle method, and (2) it prunes the states of the game using bounds on the sub-game values obtained by the classical Alpha-Beta search on a serialized variant of the game. We experimentally evaluate our algorithm on the Goofspiel card game, a pursuit-evasion game, and randomly generated games. The results show that our novel algorithm typically provides significant running-time improvements and reduction in the number of evaluated nodes compared to the full search algorithm.

#index 2032841
#* Externalities in cake cutting
#@ Simina Brânzei;Ariel D. Procaccia;Jie Zhang
#t 2013
#c 11
#% 1222619
#% 1305328
#% 1425621
#% 1453261
#% 1584771
#% 1783926
#% 1826085
#% 1989587
#% 1989591
#! The cake cutting problem models the fair division of a heterogeneous good between multiple agents. Previous work assumes that each agent derives value only from its own piece. However, agents may also care about the pieces assigned to other agents; such externalities naturally arise in fair division settings. We extend the classical model to capture externalities, and generalize the classical fairness notions of proportionality and envyfreeness. Our technical results characterize the relationship between these generalized properties, establish the existence or nonexistence of fair allocations, and explore the computational feasibility of fairness in the face of externalities.

#index 2032842
#* Are there any nicely structured preference profiles nearby?
#@ Robert Bredereck;Jiehua Chen;Gerhard J. Woeginger
#t 2013
#c 11
#% 408396
#% 857282
#% 1269671
#% 1526880
#% 1590208
#% 1783957
#% 1972413
#! We investigate the problem of deciding whether a given preference profile is close to a nicely structured preference profile of a certain type, as for instance single-peaked, single-caved, singlecrossing, value-restricted, best-restricted, worst-restricted, medium-restricted, or group-separable profiles. We measure this distance by the number of voters or alternatives that have to be deleted so as to reach a nicely structured profile. Our results classify all considered problem variants with respect to their computational complexity, and draw a clear line between computationally tractable (polynomial time solvable) and computationally intractable (NP-hard) questions.

#index 2032843
#* Conditional restricted Boltzmann machines for negotiations in highly competitive and complex domains
#@ Siqi Chen;Haitham Bou Ammar;Karl Tuyls;Gerhard Weiss
#t 2013
#c 11
#% 890251
#% 1020102
#% 1024869
#% 1036396
#% 1211818
#% 1215788
#% 1263884
#% 1826132
#% 1985823
#% 1989639
#! Learning in automated negotiations, while useful, is hard because of the indirect way the target function can be observed and the limited amount of experience available to learn from. This paper proposes two novel opponent modeling techniques based on deep learning methods. Moreover, to improve the learning efficacy of negotiating agents, the second approach is also capable of transferring knowledge efficiently between negotiation tasks. Transfer is conducted by automatically mapping the source knowledge to the target in a rich feature space. Experiments show that using these techniques the proposed strategies outperform existing state-of-the-art agents in highly competitive and complex negotiation domains. Furthermore, the empirical game theoretic analysis reveals the robustness of the proposed strategies.

#index 2032844
#* Kemeny elections with bounded single-peaked or single-crossing width
#@ Denis Cornaz;Lucie Galand;Olivier Spanjaard
#t 2013
#c 11
#% 330769
#% 529806
#% 963243
#% 1091267
#% 1223508
#% 1250228
#% 1250604
#% 1250605
#% 1277456
#% 1288648
#% 1336016
#% 1373433
#% 1411945
#% 1590208
#% 1783957
#% 1826078
#% 1846274
#% 1876131
#! This paper is devoted to complexity results regarding specific measures of proximity to single-peakedness and single-crossingness, called "single-peaked width" [Cornaz et al., 2012] and "single-crossing width". Thanks to the use of the PQ-tree data structure [Booth and Lueker, 1976], we show that both problems are polynomial time solvable in the general case (while it was only known for single-peaked width and in the case of narcissistic preferences). Furthermore, we establish one of the first results (to our knowledge) concerning the effect of nearly single-peaked electorates on the complexity of an NP-hard voting system, namely we show the fixed-parameter tractability of Kemeny elections with respect to the parameters "single-peaked width" and "single-crossing width".

#index 2032845
#* Intention-aware routing to minimise delays at electric vehicle charging stations
#@ Mathijs M. De Weerdt;Enrico H. Gerding;Sebastian Stein;Valentin Robu;Nicholas R. Jennings
#t 2013
#c 11
#% 363744
#% 881970
#% 1614340
#% 1797898
#% 1875767
#! En-route charging stations allow electric vehicles to greatly extend their range. However, as a full charge takes a considerable amount of time, there may be significant waiting times at peak hours. To address this problem, we propose a novel navigation system, which communicates its intentions (i.e., routing policies) to other drivers. Using these intentions, our system accurately predicts congestion at charging stations and suggests the most efficient route to its user. We achieve this by extending existing time-dependent stochastic routing algorithms to include the battery's state of charge and charging stations. Furthermore, we describe a novel technique for combining historical information with agent intentions to predict the queues at charging stations. Through simulations we show that our system leads to a significant increase in utility compared to existing approaches that do not explicitly model waiting times or use intentions, in some cases reducing waiting times by over 80% and achieving near-optimal overall journey times.

#index 2032846
#* Optimally solving dec-POMDPs as continuous-state MDPs
#@ Jilles Steeve Dibangoye;Christopher Amato;Olivier Buffet;François Charpillet
#t 2013
#c 11
#% 450852
#% 739715
#% 788098
#% 836122
#% 1021595
#% 1215581
#% 1215583
#% 1250230
#% 1269380
#% 1272221
#% 1272259
#% 1473939
#% 1617536
#% 1826386
#% 1953718
#% 1989618
#% 2011345
#! Optimally solving decentralized partially observable Markov decision processes (Dec-POMDPs) is a hard combinatorial problem. Current algorithms search through the space of full histories for each agent. Because of the doubly exponential growth in the number of policies in this space as the planning horizon increases, these methods quickly become intractable. However, in real world problems, computing policies over the full history space is often unnecessary. True histories experienced by the agents often lie near a structured, low-dimensional manifold embedded into the history space. We show that by transforming a Dec-POMDP into a continuous-state MDP, we are able to find and exploit these low-dimensional representations. Using this novel transformation, we can then apply powerful techniques for solving POMDPs and continuous-state MDPs. By combining a general search algorithm and dimension reduction based on feature selection, we introduce a novel approach to optimally solve problems with significantly longer planning horizons than previous methods.

#index 2032847
#* Elicitation and approximately stable matching with partial preferences
#@ Joanna Drummond;Craig Boutilier
#t 2013
#c 11
#% 146740
#% 161300
#% 316787
#% 326337
#% 450535
#% 490060
#% 1291488
#% 1492059
#% 1736831
#% 1826110
#% 1987826
#! Algorithms for stable marriage and related matching problems typically assume that full preference information is available. While the Gale-Shapley algorithm can be viewed as a means of eliciting preferences incrementally, it does not prescribe a general means for matching with incomplete information, nor is it designed to minimize elicitation. We propose the use of maximum regret to measure the (inverse) degree of stability of a matching with partial preferences; minimax regret to find matchings that are maximally stable in the presence of partial preferences; and heuristic elicitation schemes that use max regret to determine relevant preference queries. We show that several of our schemes find stable matchings while eliciting considerably less preference information than Gale-Shapley and are much more appropriate in settings where approximate stability is viable.

#index 2032848
#* C-link: a hierarchical clustering approach to large-scale near-optimal coalition formation
#@ Alessandro Farinelli;Manuele Bicego;Sarvapali Ramchurn;Mauro Zucchelli
#t 2013
#c 11
#% 4382
#% 36672
#% 659853
#% 1084394
#% 1130291
#% 1270044
#% 1272269
#% 1453044
#% 1792788
#% 1875675
#! Coalition formation is a fundamental approach to multi-agent coordination. In this paper we address the specific problem of coalition structure generation, and focus on providing good-enough solutions using a novel heuristic approach that is based on data clustering methods. In particular, we propose a hierarchical agglomerative clustering approach (C-Link), which uses a similarity criterion between coalitions based on the gain that the system achieves if two coalitions merge. We empirically evaluate C-Link on a synthetic benchmark data-set as well as in collective energy purchasing settings. Our results show that the C-link approach performs very well against an optimal benchmark based on Mixed-Integer Programming, achieving solutions which are in the worst case about 80% of the optimal (in the synthetic data-set), and 98% of the optimal (in the energy data-set). Thus we show that C-Link can return solutions for problems involving thousands of agents within minutes.

#index 2032849
#* Control in the presence of manipulators: cooperative and competitive cases
#@ Zack Fitzsimmons;Edith Hemaspaandra;Lane A. Hemaspaandra
#t 2013
#c 11
#% 951820
#% 953322
#% 1113937
#% 1152376
#% 1288651
#% 1288655
#% 1305341
#% 1454257
#% 1474452
#% 1602942
#% 1615259
#% 1615260
#% 1615262
#% 1807763
#% 1938704
#! Control and manipulation are two of the most studied types of attacks on elections. In this paper, we study the complexity of control attacks on elections in which there are manipulators. We study both the case where the "chair" who is seeking to control the election is allied with the manipulators, and the case where the manipulators seek to thwart the chair. In the latter case, we see that the order of play substantially influences the complexity. We prove upper bounds, holding over every election system with a polynomial-time winner problem, for all standard control cases, and some of these bounds are at the second or third level of the polynomial hierarchy, and we provide matching lower bounds to prove these tight. Nonetheless, for important natural systems the complexity can be much lower. We prove that for approval and plurality elections, the complexity of even competitive clashes between a controller and manipulators falls far below those high bounds, even as low as polynomial time. Yet we for a Borda-voting case show that such clashes raise the complexity unless NP = coNP.

#index 2032850
#* Action translation in extensive-form games with large action spaces: axioms, paradoxes, and the pseudo-harmonic mapping
#@ Sam Ganzfried;Tuomas Sandholm
#t 2013
#c 11
#% 1083975
#% 1215535
#% 1215607
#% 1250316
#% 1250406
#% 1279308
#% 1305334
#% 1451414
#% 1875791
#% 1880373
#! When solving extensive-form games with large action spaces, typically significant abstraction is needed to make the problem manageable from a modeling or computational perspective. When this occurs, a procedure is needed to interpret actions of the opponent that fall outside of our abstraction (by mapping them to actions in our abstraction). This is called an action translation mapping. Prior action translation mappings have been based on heuristics without theoretical justification. We show that the prior mappings are highly exploitable and that most of them violate certain natural desiderata. We present a new mapping that satisfies these desiderata and has significantly lower exploitability than the prior mappings. Furthermore, we observe that the cost of this worst-case performance benefit (low exploitability) is not high in practice; our mapping performs competitively with the prior mappings against no-limit Texas Hold'em agents submitted to the 2012 Annual Computer Poker Competition. We also observe several paradoxes that can arise when performing action abstraction and translation; for example, we show that it is possible to improve performance by including suboptimal actions in our abstraction and excluding optimal actions.

#index 2032851
#* Bargaining for revenue shares on tree trading networks
#@ Arpita Ghosh;Satyen Kale;Kevin Lang;Benjamin Moseley
#t 2013
#c 11
#% 963345
#% 1063770
#% 1151182
#% 1171603
#% 1222636
#% 1379573
#% 1426643
#% 1484132
#% 1540212
#% 1540224
#! We study trade networks with a tree structure, where a seller with a single indivisible good is connected to buyers, each with some value for the good, via a unique path of intermediaries. Agents in the tree make multiplicative revenue share offers to their parent nodes, who choose the best offer and offer part of it to their parent, and so on; the winning path is determined by who finally makes the highest offer to the seller. In this paper, we investigate how these revenue shares might be set via a natural bargaining process between agents on the tree, specifically, egalitarian bargaining between endpoints of each edge in the tree. We investigate the fixed point of this system of bargaining equations and prove various desirable for this solution concept, including (i) existence, (ii) uniqueness, (iii) efficiency, (iv) membership in the core, (v) strict monotonicity, (vi) polynomial-time computability to any given accuracy. Finally, we present numerical evidence that asynchronous dynamics with randomly ordered updates always converges to the fixed point, indicating that the fixed point shares might arise from decentralized bargaining amongst agents on the trade network.

#index 2032852
#* A matroid approach to the worst case allocation of indivisible goods
#@ Laurent Gourvès;Jérôme Monnot;Lydia Tlilane
#t 2013
#c 11
#% 754147
#% 1096055
#% 1221417
#% 1272227
#% 1332277
#% 1555742
#% 1747574
#% 1988700
#! We consider the problem of equitably allocating a set of indivisible goods to n agents so as to maximize the utility of the least happy agent. [Demko and Hill, 1988] showed the existence of an allocation where every agent values his share at least Vn(α), which is a family of nonincreasing functions in a parameter α, defined as the maximum value assigned by an agent to a single good. A deterministic algorithm returning such an allocation in polynomial time was proposed [Markakis and Psomas, 2011]. Interestingly, Vn(α) is tight for some values of α, i.e. it is the best lower bound on the valuation of the least happy agent. However, it is not true for all values of α. We propose a family of functions Wn such that Wn(x) ≥ Vn(x) for all x, and Wn(x) Vn(x) for values of x where Vn(x) is not tight. The new functions Wn apply on a problem which generalizes the allocation of indivisible goods. It is to find a solution (base) in a matroid which is common to n agents. Our results are constructive, they are achieved by analyzing an extension of the algorithm of Markakis and Psomas.

#index 2032853
#* Audience-based uncertainty in abstract argument games
#@ Davide Grossi;Wiebe Van Der Hoek
#t 2013
#c 11
#% 198464
#% 495971
#% 942470
#% 992252
#% 1111200
#% 1250162
#% 1305330
#% 1305408
#% 1410667
#% 1538164
#% 1614149
#% 1791081
#% 1921500
#! The paper generalizes abstract argument games to cope with cases where proponent and opponent argue in front of an audience whose type is known only with uncertainty. The generalization, which makes use of basic tools from probability theory, is motivated by several examples and delivers a class of abstract argument games whose adequacy is proven robust against uncertainty.

#index 2032854
#* Optimal airline ticket purchasing using automated user-guided feature selection
#@ William Groves;Maria Gini
#t 2013
#c 11
#% 243728
#% 302906
#% 466410
#% 629619
#% 729921
#! Airline ticket purchase timing is a strategic problem that requires both historical data and domain knowledge to solve consistently. Even with some historical information (often a feature of modern travel reservation web sites), it is difficult for consumers to make true cost-minimizing decisions. To address this problem, we introduce an automated agent which is able to optimize purchase timing on behalf of customers and provide performance estimates of its computed action policy based on past performance. We apply machine learning to recent ticket price quotes from many competing airlines for the target flight route. Our novelty lies in extending this using a systematic feature extraction technique incorporating elementary user-provided domain knowledge that greatly enhances the performance of machine learning algorithms. Using this technique, our agent achieves much closer to the optimal purchase policy than other proposed decision theoretic approaches for this domain.

#index 2032855
#* Revenue maximization via hiding item attributes
#@ Mingyu Guo;Argyrios Deligkas
#t 2013
#c 11
#% 314925
#% 600496
#% 1407360
#% 1407391
#% 1783940
#% 1783958
#! We study probabilistic single-item second-price auctions where the item is characterized by a set of attributes. The auctioneer knows the actual instantiation of all the attributes, but he may choose to reveal only a subset of these attributes to the bidders. Our model is an abstraction of the following Ad auction scenario. The website (auctioneer) knows the demographic information of its impressions, and this information is in terms of a list of attributes (e.g., age, gender, country of location). The website may hide certain attributes from its advertisers (bidders) in order to create thicker market, which may lead to higher revenue. We study how to hide attributes in an optimal way. We show that it is NP-hard to compute the optimal attribute hiding scheme. We then derive a polynomial-time solvable upper bound on the optimal revenue. Finally, we propose two heuristic-based attribute hiding schemes. Experiments show that revenue achieved by these schemes is close to the upper bound.

#index 2032856
#* Opponent modelling in persuasion dialogues
#@ Christos Hadjinikolis;Yiannis Siantos;Sanjay Modgil;Elizabeth Black;Peter McBurney
#t 2013
#c 11
#% 166352
#% 198464
#% 431515
#% 1222000
#% 1222453
#% 1617531
#% 1617532
#% 1729248
#% 1791081
#! A strategy is used by a participant in a persuasion dialogue to select locutions most likely to achieve its objective of persuading its opponent. Such strategies often assume that the participant has a model of its opponents, which may be constructed on the basis of a participant's accumulated dialogue experience. However in most cases the fact that an agent's experience may encode additional information which if appropriately used could increase a strategy's efficiency, is neglected. In this work, we rely on an agent's experience to define a mechanism for augmenting an opponent model with information likely to be dialectally related to information already contained in it. Precise computation of this likelihood is exponential in the volume of related information. We thus describe and evaluate an approximate approach for computing these likelihoods based on Monte-Carlo simulation.

#index 2032857
#* Sequential equilibrium in computational games
#@ Joseph Y. Halpern;Rafael Pass
#t 2013
#c 11
#% 188086
#! We examine sequential equilibrium in the context of computational games [Halpern and Pass, 2011a], where agents are charged for computation. In such games, an agent can rationally choose to forget, so issues of imperfect recall arise. In this setting, we consider two notions of sequential equilibrium. One is an ex ante notion, where a player chooses his strategy before the game starts and is committed to it, but chooses it in such a way that it remains optimal even off the equilibrium path. The second is an interim notion, where a player can reconsider at each information set whether he is doing the "right" thing, and if not, can change his strategy. The two notions agree in games of perfect recall, but not in games of imperfect recall. Although the interim notion seems more appealing, in [Halpern and Pass, 2011b] it is argued that there are some deep conceptual problems with it in standard games of imperfect recall. We show that the conceptual problems largely disappear in the computational setting. Moreover, in this setting, under natural assumptions, the two notions coincide.

#index 2032858
#* Why is it so hard to say sorry? evolution of apology with commitments in the iterated Prisoner's Dilemma
#@ The Anh Han;Luís Moniz Pereira;Francisco C. Santos;Tom Lenaerts
#t 2013
#c 11
#% 787223
#% 1024804
#% 1052238
#% 1212617
#% 1609236
#% 1679526
#% 1853620
#% 1875715
#% 1991937
#! When making a mistake, individuals can apologize to secure further cooperation, even if the apology is costly. Similarly, individuals arrange commitments to guarantee that an action such as a cooperative one is in the others' best interest, and thus will be carried out to avoid eventual penalties for commitment failure. Hence, both apology and commitment should go side by side in behavioral evolution. Here we provide a computational model showing that apologizing acts are rare in non-committed interactions, especially whenever cooperation is very costly, and that arranging prior commitments can considerably increase the frequency of such behavior. In addition, we show that in both cases, with or without commitments, apology works only if it is sincere, i.e. costly enough. Most interestingly, our model predicts that individuals tend to use much costlier apology in committed relationships than otherwise, because it helps better identify free-riders such as fake committers: "commitments bring about sincerity'. Furthermore, we show that this strategy of apology supported by commitments outperforms the famous existent strategies of the iterated Prisoner's Dilemma.

#index 2032859
#* The dynamics of reinforcement social learning in cooperative multiagent systems
#@ Jianye Hao;Ho-Fung Leung
#t 2013
#c 11
#% 124691
#% 266286
#% 466730
#% 578705
#% 789557
#% 830736
#% 890326
#% 1274878
#% 1274996
#% 1826130
#% 1880015
#! Coordination in cooperative multiagent systems is an important problem in multiagent learning literature. In practical complex environments, the interactions between agents can be sparse, and each agent's interacting partners may change frequently and randomly. To this end, we investigate the multiagent coordination problems in cooperative environments under the social learning framework. We consider a large population of agents where each agent interacts with another agent randomly chosen from the population in each round. Each agent learns its policy through repeated interactions with the rest of agents via social learning. It is not clear a priori if all agents can learn a consistent optimal coordination policy in such a situation. We distinguish two types of learners: individual action learner and joint action learner. The learning performance of both learners are evaluated under a number of challenging cooperative games, and the influence of the information sharing degree on the learning performance is investigated as well.

#index 2032860
#* Macau: a basis for evaluating reputation systems
#@ Christopher J. Hazard;Munindar P. Singh
#t 2013
#c 11
#% 507535
#% 823906
#% 823908
#% 856790
#% 1001280
#% 1127468
#% 1156102
#% 1168675
#% 1215634
#% 1275003
#% 1305333
#% 1573137
#! Reputation is a crucial concept in dynamic multiagent environments. Despite the large body of work on reputation systems, no metrics exist to directly and quantitatively evaluate and compare them. We present a common conceptual interface for reputation systems and a set of four measurable desiderata that are broadly applicable across multiple domains. These desiderata employ concepts from dynamical systems theory to measure how a reputation system reacts to a strategic agent attempting to maximize its own utility. We study a diverse set of well-known reputation models from the literature in a moral hazard setting and identify a rich variety of characteristics that they support.

#index 2032861
#* How to change a group's collective decision?
#@ Noam Hazon;Raz Lin;Sarit Kraus
#t 2013
#c 11
#% 578703
#% 951820
#% 1150431
#% 1250608
#% 1288655
#% 1305345
#% 1530771
#% 1783993
#% 1826073
#! Persuasion is a common social and economic activity. It usually arises when conflicting interests among agents exist, and one of the agents wishes to sway the opinions of others. This paper considers the problem of an automated agent that needs to influence the decision of a group of self-interested agents that must reach an agreement on a joint action. For example, consider an automated agent that aims to reduce the energy consumption of a nonresidential building, by convincing a group of people who share an office to agree on an economy mode of the air-conditioning and low light intensity. In this paper we present four problems that address issues of minimality and safety of the persuasion process. We discuss the relationships to similar problems from social choice, and show that if the agents are using Plurality or Veto as their voting rule all of our problems are in P. We also show that with K-Approval, Bucklin and Borda voting rules some problems become intractable. We thus present heuristics for efficient persuasion with Borda, and evaluate them through simulations.

#index 2032862
#* A game- heoretic machine learning approach for revenue maximization in sponsored search
#@ Di He;Wei Chen;Liwei Wang;Tie-Yan Liu
#t 2013
#c 11
#% 882286
#% 942409
#% 956546
#% 963333
#% 987262
#% 1074101
#% 1227651
#% 1246500
#% 1451141
#% 1584778
#% 1747562
#% 1747572
#! Sponsored search is an important monetization channel for search engines, in which an auction mechanism is used to select the ads shown to users and determine the prices charged from advertisers. There have been several pieces of work in the literature that investigate how to design an auction mechanism in order to optimize the revenue of the search engine. However, due to some unrealistic assumptions used, the practical values of these studies are not very clear. In this paper, we propose a novel game-theoretic machine learning approach, which naturally combines machine learning and game theory, and learns the auction mechanism using a bilevel optimization framework. In particular, we first learn a Markov model from historical data to describe how advertisers change their bids in response to an auction mechanism, and then for any given auction mechanism, we use the learnt model to predict its corresponding future bid sequences. Next we learn the auction mechanism through empirical revenue maximization on the predicted bid sequences. We show that the empirical revenue will converge when the prediction period approaches infinity, and a Genetic Programming algorithm can effectively optimize this empirical revenue. Our experiments indicate that the proposed approach is able to produce a much more effective auction mechanism than several baselines.

#index 2032863
#* A framework to choose trust models for different e-marketplace environments
#@ Athirai A. Irissappane;Siwei Jiang;Jie Zhang
#t 2013
#c 11
#% 494260
#% 643088
#% 803395
#% 839722
#% 856790
#% 943777
#% 1024840
#% 1133084
#% 1192404
#% 1215638
#% 1250347
#% 1479001
#% 1615264
#% 1617591
#! Many trust models have been proposed to evaluate seller trustworthiness in multiagent e-marketplaces. Their performance varies highly depending on environments where they are applied. However, it is challenging to choose suitable models for environments where ground truth about seller trustworthiness is unknown (called unknown environments). We propose a novel framework to choose suitable trust models for unknown environments, based on the intuition that if a model performs well in one environment, it will do so in another similar environment. Specifically, for an unknown environment, we identify a similar simulated environment (with known ground truth) where the trust model performing the best will be chosen as the suitable solution. Evaluation results confirm the effectiveness of our framework in choosing suitable trust models for different environments.

#index 2032864
#* Defender (mis)coordination in security games
#@ Albert Xin Jiang;Ariel D. Procaccia;Yundi Qian;Nisarg Shah;Milind Tambe
#t 2013
#c 11
#% 344984
#% 1083973
#% 1215518
#% 1222653
#% 1272254
#% 1305580
#% 1393537
#% 1453038
#% 1453189
#% 1617544
#% 1693959
#% 1826108
#% 1875650
#! We study security games with multiple defenders. To achieve maximum security, defenders must perfectly synchronize their randomized allocations of resources. However, in real-life scenarios (such as protection of the port of Boston) this is not the case. Our goal is to quantify the loss incurred by miscoordination between defenders, both theoretically and empirically. We introduce two notions that capture this loss under different assumptions: the price of miscoordination, and the price of sequential commitment. Generally speaking, our theoretical bounds indicate that the loss may be extremely high in the worst case, while our simulations establish a smaller yet significant loss in practice.

#index 2032865
#* A social welfare optimal sequential allocation procedure
#@ Thomas Kalinowski;Nina Narodytska;Toby Walsh
#t 2013
#c 11
#% 1826076
#! We consider a simple sequential allocation procedure for sharing indivisible items between agents in which agents take turns to pick items. Supposing additive utilities and independence between the agents, we show that the expected utility of each agent is computable in polynomial time. Using this result, we prove that the expected utilitarian social welfare is maximized when agents take alternate turns. We also argue that this mechanism remains optimal when agents behave strategically.

#index 2032866
#* An intelligent broker agent for energy trading: an MDP approach
#@ Rodrigue T. Kuate;Minghua He;Maria Chli;Hai H. Wang
#t 2013
#c 11
#% 173854
#% 384911
#% 703709
#% 891559
#% 1269546
#! This paper details the development and evaluation of AstonTAC, an energy broker that successfully participated in the 2012 Power Trading Agent Competition (Power TAC). AstonTAC buys electrical energy from the wholesale market and sells it in the retail market. The main focus of the paper is on the broker's bidding strategy in the wholesale market. In particular, it employs Markov Decision Processes (MDP) to purchase energy at low prices in a day-ahead power wholesale market, and keeps energy supply and demand balanced. Moreover, we explain how the agent uses Non-Homogeneous Hidden Markov Model (NHHMM) to forecast energy demand and price. An evaluation and analysis of the 2012 Power TAC finals show that AstonTAC is the only agent that can buy energy at low price in the wholesale market and keep energy imbalance low.

#index 2032867
#* Agent failures in all-pay auctions
#@ Yoad Lewenberg;Omer Lev;Yoram Bachrach;Jeffrey S. Rosenschein
#t 2013
#c 11
#% 1222631
#% 1668236
#% 1989635
#! All-pay auctions, a common mechanism for various human and agent interactions, suffers, like many other mechanisms, from the possibility of players' failure to participate in the auction. We model such failures and show how they affect the equilibrium state, revealing various properties, such as the lack of influence of the most-likely-to-participate player on the behavior of the other players. We perform this analysis with two scenarios: the sum-profit model, where the auctioneer obtains the sum of all submitted bids, and the max-profit model of crowd-sourcing contests, where the auctioneer can only use the best submissions and thus obtains only the winning bid. Furthermore, we examine various methods of influencing the probability of participation such as the effects of misreporting one's own probability of participating, and how influencing another player's participation chances (e.g., sabotage) changes the player's strategy.

#index 2032868
#* Efficient learning in linearly solvable MDP models
#@ Ang Li;Paul R. Schrater
#t 2013
#c 11
#% 266287
#% 363744
#% 449561
#% 466731
#% 644560
#% 1211754
#% 1272286
#% 1323331
#! Linearly solvable Markov Decision Process (MDP) models are a powerful subclass of problems with a simple structure that allow the policy to be written directly in terms of the uncontrolled (passive) dynamics of the environment and the goals of the agent. However, there have been no learning algorithms for this class of models. In this research, we develop a robust learning approach to linearly solvable MDPs. To exploit the simple solution for general problems, we show how to construct passive dynamics from any transition matrix, use Bayesian updating to estimate the model parameters and apply approximate and efficient Bayesian exploration to speed learning. In addition, we reduce the computational cost of learning using intermittent Bayesian updating and policy solving. We also gave a polynomial theoretical time complexity bound for the convergence of our learning algorithm, and demonstrate a linear bound for the subclass of the reinforcement learning problems with the property that the transition error depends only on the agent itself. Test results for our algorithm in a grid world are presented, comparing our algorithm with the BEB algorithm. The results showed that our algorithm learned more than the BEB algorithm without losing convergence speed, so that the advantage of our algorithm increased as the environment got more complex. We also showed that our algorithm's performance is more stable after convergence. Finally, we show how to apply our approach to the Cellular Telephones problem by defining the passive dynamics.

#index 2032869
#* Game-theoretic question selection for tests
#@ Yuqian Li;Vincent Conitzer
#t 2013
#c 11
#% 53085
#% 288780
#% 868454
#% 1081712
#% 1083973
#% 1181330
#% 1215597
#% 1299701
#% 1332436
#% 1617542
#% 1631455
#% 1875650
#% 1928024
#! Conventionally, the questions on a test are assumed to be kept secret from test takers until the test. However, for tests that are taken on a large scale, particularly asynchronously, this is very hard to achieve. For example, example TOEFL iBT and driver's license test questions are easily found online. This also appears likely to become an issue for Massive Open Online Courses (MOOCs). In this paper, we take the loss of confidentiality as a fact. Even so, not all hope is lost as the test taker can memorize only a limited set of questions' answers, and the tester can randomize which questions appear on the test. We model this as a Stackelberg game, where the tester commits to a mixed strategy and the follower responds. We provide an exponential-size linear program formulation, prove several NP-hardness results, and give efficient algorithms for special cases.

#index 2032870
#* Multi-winner social choice with incomplete preferences
#@ Tyler Lu;Craig Boutilier
#t 2013
#c 11
#% 741027
#% 808366
#% 844381
#% 1083323
#% 1270050
#% 1272243
#% 1291488
#% 1426666
#% 1538167
#% 1631103
#% 1826109
#% 1826110
#% 1989600
#! Multi-winner social choice considers the problem of selecting a slate of K options to realize some social objective. It has found application in the construction of political legislatures and committees, product recommendation, and related problems, and has recently attracted attention from a computational perspective. We address the multi-winner problem when facing incomplete voter preferences, using the notion of minimax regret to determine a robust slate of options in the presence of preference uncertainty. We analyze the complexity of this problem and develop new exact and greedy robust optimization algorithms for its solution. Using these techniques, we also develop preference elicitation heuristics which, in practice, allow us to find near-optimal slates with considerable savings in the preference information required vis-à-vis complete votes.

#index 2032871
#* An ambiguity aversion framework of security games under ambiguities
#@ Wenjun Ma;Xudong Luo;Weiru Liu
#t 2013
#c 11
#% 83936
#% 1281090
#% 1506384
#% 1528628
#% 1617543
#% 1631455
#% 1693959
#% 1938902
#% 1950076
#% 1950696
#! Security is a critical concern around the world. Since resources for security are always limited, lots of interest have arisen in using game theory to handle security resource allocation problems. However, most of the existing work does not address adequately how a defender chooses his optimal strategy in a game with absent, inaccurate, uncertain, and even ambiguous strategy profiles' payoffs. To address this issue, we propose a general framework of security games under ambiguities based on Dempster-Shafer theory and the ambiguity aversion principle of minimax regret. Then, we reveal some properties of this framework. Also, we present two methods to reduce the influence of complete ignorance. Our investigation shows that this new framework is better in handling security resource allocation problems under ambiguities.

#index 2032872
#* Multi-agent team formation: diversity beats strength?
#@ Leandro Soriano Marcolino;Albert Xin Jiang;Milind Tambe
#t 2013
#c 11
#% 414514
#% 823874
#% 1110158
#% 1150043
#% 1272063
#% 1366565
#% 1548963
#% 1870535
#% 1870870
#% 1875689
#% 1875692
#! Team formation is a critical step in deploying a multi-agent team. In some scenarios, agents coordinate by voting continuously. When forming such teams, should we focus on the diversity of the team or on the strength of each member? Can a team of diverse (and weak) agents outperform a uniform team of strong agents? We propose a new model to address these questions. Our key contributions include: (i) we show that a diverse team can overcome a uniform team and we give the necessary conditions for it to happen; (ii) we present optimal voting rules for a diverse team; (iii) we perform synthetic experiments that demonstrate that both diversity and strength contribute to the performance of a team; (iv) we show experiments that demonstrate the usefulness of our model in one of the most difficult challenges for Artificial Intelligence: Computer Go.

#index 2032873
#* Control complexity of schulze voting
#@ Curtis Menton;Preetjot Singh
#t 2013
#c 11
#% 271176
#% 330769
#% 408396
#% 529806
#% 951820
#% 953322
#% 1288651
#% 1288655
#% 1474452
#% 1477274
#% 1615260
#% 1807763
#% 1989604
#! Schulze voting is a recently introduced voting system enjoying unusual popularity and a high degree of real-world use, with users including the Wikimedia foundation, several branches of the Pirate Party, and MTV. It is a Condorcet voting system that determines the winners of an election using information about paths in a graph representation of the election. We resolve the complexity of many electoral control cases for Schulze voting. We find that it falls short of the best known voting systems in terms of control resistance, demonstrating vulnerabilities of concern to some prospective users of the system.

#index 2032874
#* Computational analysis of connectivity games with applications to the investigation of terrorist networks
#@ Tomasz P. Michalak;Talal Rahwan;Nicholas R. Jennings;Piotr L. Szczepański;Oskar Skibski;Ramasuri Narayanam;Michael J. Wooldridge
#t 2013
#c 11
#% 165011
#% 238996
#% 300311
#% 750039
#% 806990
#% 893165
#% 1024833
#% 1083979
#% 1083986
#% 1133165
#% 1221417
#% 1229367
#% 1540202
#% 1701146
#% 1875675
#% 1875677
#! We study a recently developed centrality metric to identify key players in terrorist organisations due to Lindelauf et al. [2013]. This metric, which involves computation of the Shapley value for connectivity games on graphs proposed by Amer and Gimenez [2004], was shown to produce substantially better results than previously used standard centralities. In this paper, we present the first computational analysis of this class of coalitional games, and propose two algorithms for computing Lindelauf et al.'s centrality metric. Our first algorithm is exact, and runs in time linear by number of connected subgraphs in the network. As shown in the numerical simulations, our algorithm identifies key players in the WTC 9/11 terrorist network, constructed of 36 members and 125 links, in less than 40 minutes. In contrast, a general-purpose Shapley value algorithm would require weeks to solve this problem. Our second algorithm is approximate and can be used to study much larger networks.

#index 2032875
#* Sufficient plan-time statistics for decentralized POMDPs
#@ Frans A. Oliehoek
#t 2013
#c 11
#% 363744
#% 450852
#% 643084
#% 773196
#% 782311
#% 1090422
#% 1215583
#% 1250230
#% 1272221
#% 1279314
#% 1290265
#% 1453203
#% 1453204
#% 2011345
#! Optimal decentralized decision making in a team of cooperative agents as formalized by decentralized POMDPs is a notoriously hard problem. A major obstacle is that the agents do not have access to a sufficient statistic during execution, which means that they need to base their actions on their histories of observations. A consequence is that even during off-line planning the choice of decision rules for different stages is tightly interwoven: decisions of earlier stages affect how to act optimally at later stages, and the optimal value function for a stage is known to have a dependence on the decisions made up to that point. This paper makes a contribution to the theory of decentralized POMDPs by showing how this dependence on the 'past joint policy' can be replaced by a sufficient statistic. These results are extended to the case of k-step delayed communication. The paper investigates the practical implications, as well as the effectiveness of a new pruning technique for MAA* methods, in a number of benchmark problems and discusses future avenues of research opened by these contributions.

#index 2032876
#* Efficient vote elicitation under candidate uncertainty
#@ Joel Oren;Yuval Filmus;Craig Boutilier
#t 2013
#c 11
#% 450535
#% 519659
#% 808366
#% 953322
#% 983818
#% 1270050
#% 1288648
#% 1426672
#% 1538167
#% 1631103
#% 1807763
#% 1826110
#! Top-k voting is an especially natural form of partial vote elicitation in which only length k prefixes of rankings are elicited. We analyze the ability of top-k vote elicitation to correctly determine true winners, with high probability, given probabilistic models of voter preferences and candidate availability. We provide bounds on the minimal value of k required to determine the correct winner under the plurality and Borda voting rules, considering both worst-case preference profiles and profiles drawn from the impartial culture and Mallows probabilistic models. We also derive conditions under which the special case of zero-elicitation (i.e., k = 0) produces the correct winner. We provide empirical results that confirm the value of top-k voting.

#index 2032877
#* A proof-theoretical view of collective rationality
#@ Daniele Porello
#t 2013
#c 11
#% 192000
#% 313554
#% 587576
#% 1453101
#% 1826097
#! The impossibility results in judgement aggregation show a clash between fair aggregation procedures and rational collective outcomes. In this paper, we are interested in analysing the notion of rational outcome by proposing a proof-theoretical understanding of collective rationality. In particular, we use the analysis of proofs and inferences provided by linear logic in order to define a fine-grained notion of group reasoning that allows for studying collective rationality with respect to a number of logics. We analyse the well-known paradoxes in judgement aggregation and we pinpoint the reasoning steps that trigger the inconsistencies. Moreover, we extend the map of possibility and impossibility results in judgement aggregation by discussing the case of substructural logics. In particular, we show that there exist fragments of linear logic for which general possibility results can be obtained.

#index 2032878
#* Coalitional games via network flows
#@ Talal Rahwan;Tri-Dung Nguyen;Tomasz P. Michalak;Maria Polukarov;Madalina Croitoru;Nicholas R. Jennings
#t 2013
#c 11
#% 165011
#% 205591
#% 284645
#% 808378
#% 1083989
#% 1156099
#% 1223230
#% 1250153
#% 1250607
#% 1272269
#% 1279301
#% 1290268
#% 1291437
#% 1305314
#% 1412978
#% 1453173
#% 1545554
#% 1614166
#% 1617577
#% 1768048
#% 1826118
#% 1826126
#! We introduce a new representation scheme for coalitional games, called coalition-flow networks (CF-NETs), where the formation of effective coalitions in a task-based setting is reduced to the problem of directing flow through a network. We show that our representation is intuitive, fully expressive, and captures certain patterns in a significantly more concise manner compared to the conventional approach. Furthermore, our representation has the flexibility to express various classes of games, such as characteristic function games, coalitional games with overlapping coalitions, and coalitional games with agent types. As such, to the best of our knowledge, CF-NETs is the first representation that allows for switching conveniently and efficiently between overlapping/non-overlapping coalitions, with/without agent types. We demonstrate the efficiency of our scheme on the coalition structure generation problem, where near-optimal solutions for large instances can be found in a matter of seconds.

#index 2032879
#* Opponent models with uncertainty for strategic argumentation
#@ Tjitze Rienstra;Matthias Thimm;Nir Oren
#t 2013
#c 11
#% 198464
#% 985998
#% 1083990
#% 1223244
#% 1305330
#% 1453196
#% 1540562
#% 1729248
#% 1738319
#% 1947328
#! This paper deals with the issue of strategic argumentation in the setting of Dung-style abstract argumentation theory. Such reasoning takes place through the use of opponent models--recursive representations of an agent's knowledge and beliefs regarding the opponent's knowledge. Using such models, we present three approaches to reasoning. The first directly utilises the opponent model to identify the best move to advance in a dialogue. The second extends our basic approach through the use of quantitative uncertainty over the opponent's model. The final extension introduces virtual arguments into the opponent's reasoning process. Such arguments are unknown to the agent, but presumed to exist and interact with known arguments. They are therefore used to add a primitive notion of risk to the agent's reasoning. We have implemented our models and we have performed an empirical analysis that shows that this added expressivity improves the performance of an agent in a dialogue.

#index 2032880
#* Efficient interdependent value combinatorial auctions with single minded bidders
#@ Valentin Robu;David C. Parkes;Takayuki Ito;Nicholas R. Jennings
#t 2013
#c 11
#% 773225
#% 890386
#% 1024786
#% 1084523
#% 1615257
#% 1738937
#! We study the problem of designing efficient auctions where bidders have interdependent values; i.e., values that depend on the signals of other agents. We consider a contingent bid model in which agents can explicitly condition the value of their bids on the bids submitted by others. In particular, we adopt a linear contingent bidding model for single minded combinatorial auctions (CAs), in which submitted bids are linear combinations of bids received from others. We extend the existing state of the art, by identifying constraints on the interesting bundles and contingency weights reported by the agents which allow the efficient second priced, fixed point bids auction to be implemented in single minded CAs. Moreover, for domains in which the required single crossing condition fails (which characterizes when efficient, IC auctions are possible), we design a two-stage mechanism in which a subset of agents ("experts") are allocated first, using their reports to allocate the remaining items to the other agents.

#index 2032881
#* Efficiently solving joint activity based security games
#@ Eric Shieh;Manish Jain;Albert Xin Jiang;Milind Tambe
#t 2013
#c 11
#% 384911
#% 572734
#% 868454
#% 1083973
#% 1084017
#% 1215597
#% 1393848
#% 1453189
#% 1693959
#% 1746053
#% 1875650
#! Despite recent successful real-world deployments of Stackelberg Security Games (SSGs), scale-up remains a fundamental challenge in this field. The latest techniques do not scale-up to domains where multiple defenders must coordinate time-dependent joint activities. To address this challenge, this paper presents two branch-and-price algorithms for solving SSGs, SMARTO and SMARTH, with three novel features: (i) a column-generation approach that uses an ordered network of nodes (determined by solving the traveling salesman problem) to generate individual defender strategies; (ii) exploitation of iterative reward shaping of multiple coordinating defender units to generate coordinated strategies; (iii) generation of tighter upper-bounds for pruning by solving security games that only abide by key scheduling constraints. We provide extensive experimental results and formal analyses.

#index 2032882
#* Fully proportional representation as resource allocation: approximability results
#@ Piotr Skowron;Piotr Faliszewski;Arkadii Slinko
#t 2013
#c 11
#% 408396
#% 857282
#% 892736
#% 963243
#% 1091267
#% 1152376
#% 1277456
#% 1419423
#% 1453078
#% 1783876
#% 1826109
#% 1950570
#% 1989600
#% 1989602
#! We study the complexity of (approximate) winner determination under Monroe's and Chamberlin-Courant's multiwinner voting rules, where we focus on the total (dis)satisfaction of the voters (the utilitarian case) or the (dis)satisfaction of the worst-off voter (the egalitarian case). We show good approximation algorithms for the satisfaction-based utilitarian cases, and inapproximability results for the remaining settings.

#index 2032883
#* Bimodal switching for online planning in multiagent settings
#@ Ekhlas Sonu;Prashant Doshi
#t 2013
#c 11
#% 788098
#% 1272071
#% 1272231
#% 1272264
#% 1290265
#% 1526847
#% 1875811
#! We present a bimodal method for online planning in partially observable multiagent settings as formalized by a finitely-nested interactive partially observable Markov decision process (I-POMDP). An agent planning in an environment shared with another updates beliefs both over the physical state and the other agents' models. In problems where we do not observe other's action explicitly but must infer it from sensing its effect on the state, observations are more informative about the other when the belief over the state space has reduced uncertainty. For typical, uncertain initial beliefs, we model the agent as if it were acting alone and utilize fast online planning for POMDPs. Subsequently, the agent switches to online planning in multiagent settings. We maintain tight lower and upper bounds at each step, and switch over when the difference between them reduces to less than ε.

#index 2032884
#* Analysis and optimization of multi-dimensional percentile mechanisms
#@ Xin Sui;Craig Boutilier;Tuomas Sandholm
#t 2013
#c 11
#% 1222638
#% 1250155
#% 1269401
#% 1274995
#% 1393537
#% 1426660
#% 1426678
#% 1540220
#% 1631098
#% 1650358
#% 1783952
#% 1826109
#! We consider the mechanism design problem for agents with single-peaked preferences over multi-dimensional domains when multiple alternatives can be chosen. Facility location and committee selection are classic embodiments of this problem. We propose a class of percentile mechanisms, a form of generalized median mechanisms, that are strategy-proof, and derive worst-case approximation ratios for social cost and maximum load for L1 and L2 cost models. More importantly, we propose a sample-based framework for optimizing the choice of percentiles relative to any prior distribution over preferences, while maintaining strategy-proofness. Our empirical investigations, using social cost and maximum load as objectives, demonstrate the viability of this approach and the value of such optimized mechanisms vis-à-vis mechanisms derived through worst-case analysis.

#index 2032885
#* Multi-dimensional single-peaked consistency and its approximations
#@ Xin Sui;Alex Francois-Nienaber;Craig Boutilier
#t 2013
#c 11
#% 1222638
#% 1223508
#% 1288648
#% 1396214
#% 1426678
#% 1540220
#% 1590208
#% 1631098
#% 1783952
#% 1846274
#! Single-peakedness is one of the most commonly used domain restrictions in social choice. However, the extent to which agent preferences are single-peaked in practice, and the extent to which recent proposals for approximate single-peakedness can further help explain voter preferences, is unclear. In this article, we assess the ability of both single-dimensional and multi-dimensional approximations to explain preference profiles drawn from several real-world elections. We develop a simple branch-and-bound algorithm that finds multi-dimensional, single-peaked axes that best fit a given profile, and which works with several forms of approximation. Empirical results on two election data sets show that preferences in these elections are far from single-peaked in any one-dimensional space, but are nearly single-peaked in two dimensions. Our algorithms are reasonably efficient in practice, and also show excellent anytime performance.

#index 2032886
#* An efficient vector-based representation for coalitional games
#@ Long Tran-Thanh;Tri-Dung Nguyen;Talal Rahwan;Alex Rogers;Nicholas R. Jennings
#t 2013
#c 11
#% 284645
#% 808378
#% 1083989
#% 1223910
#% 1250153
#% 1250617
#% 1279301
#% 1381500
#% 1412978
#% 1453173
#% 1493536
#% 1875850
#! We propose a new representation for coalitional games, called the coalitional skill vector model, where there is a set of skills in the system, and each agent has a skill vector--a vector consisting of values that reflect the agents' level in different skills. Furthermore, there is a set of goals, each with requirements expressed in terms of the minimum skill level necessary to achieve the goal. Agents can form coalitions to aggregate their skills, and achieve goals otherwise unachievable. We show that this representation is fully expressive, that is, it can represent any characteristic function game. We also show that, for some interesting classes of games, our representation is significantly more compact than the classical representation, and facilitates the development of efficient algorithms to solve the coalition structure generation problem, as well as the problem of computing the core and/or the least core. We also demonstrate that by using the coalitional skill vector representation, our solver can handle up to 500 agents.

#index 2032887
#* Endogenous boolean games
#@ Paolo Turrini
#t 2013
#c 11
#% 338753
#% 781219
#% 1156103
#% 1202783
#% 1291402
#% 1950075
#! In boolean games players exercise control over propositional variables and strive to achieve a goal formula whose realization might require the opponents' cooperation. Recently, a theory of incentive engineering for such games has been devised, where an external authority steers the outcome of the game towards certain desirable properties consistent with players' goals, by imposing a taxation mechanism on the players that makes the outcomes that do not comply with those properties less appealing to them. The present contribution stems from a complementary perspective and studies, instead, how boolean games can be transformed from inside, rather than from outside, by endowing players with the possibility of sacrificing a part of their payoff received at a certain outcome in order to convince other players to play a certain strategy. What we call here endogenous boolean games (EBGs) boils down to enriching the framework of boolean games with the machinery of side payments coming from game theory. We analyze equilibria in EBGs, showing the preconditions needed for desirable outcomes to be achieved without external intervention. Finally, making use of taxation mechanism, we show how to transform an EBG in such a way that desirable outcomes can be realized independently of side payments.

#index 2032888
#* Monte-Carlo expectation maximization for decentralized POMDPs
#@ Feng Wu;Shlomo Zilberstein;Nicholas R. Jennings
#t 2013
#c 11
#% 384911
#% 425053
#% 450852
#% 876063
#% 983947
#% 1023420
#% 1211825
#% 1250230
#% 1269380
#% 1272259
#% 1275077
#% 1279314
#% 1617536
#% 1826116
#% 1826386
#% 1826403
#! We address two significant drawbacks of state-of-the-art solvers of decentralized POMDPs (DECPOMDPs): the reliance on complete knowledge of the model and limited scalability as the complexity of the domain grows. We extend a recently proposed approach for solving DEC-POMDPs via a reduction to the maximum likelihood problem, which in turn can be solved using EM. We introduce a model-free version of this approach that employs Monte-Carlo EM (MCEM). While a naïve implementation of MCEM is inadequate in multiagent settings, we introduce several improvements in sampling that produce high-quality results on a variety of DEC-POMDP benchmarks, including large problems with thousands of agents.

#index 2032889
#* Scaling-up security games with boundedly rational adversaries: a cutting-plane approach
#@ Rong Yang;Albert Xin Jiang;Milind Tambe;Fernando Ordóñez
#t 2013
#c 11
#% 572734
#% 868454
#% 1065943
#% 1215597
#% 1453189
#% 1456452
#% 1693959
#% 1826136
#% 1875650
#% 1875788
#! To improve the current real-world deployments of Stackelberg security games (SSGs), it is critical now to efficiently incorporate models of adversary bounded rationality in large-scale SSGs. Unfortunately, previously proposed branch-and-price approaches fail to scale-up given the non-convexity of such models, as we show with a realization called COCOMO. Therefore, we next present a novel cutting-plane algorithm called BLADE to scale-up SSGs with complex adversary models, with three key novelties: (i) an efficient scalable separation oracle to generate deep cuts; (ii) a heuristic that uses gradient to further improve the cuts; (iii) techniques for quality-efficiency tradeoff.

#index 2032890
#* Automated generation of interaction graphs for value-factored dec-POMDPs
#@ William Yeoh;Akshat Kumar;Shlomo Zilberstein
#t 2013
#c 11
#% 450852
#% 643287
#% 1026714
#% 1074346
#% 1084074
#% 1215581
#% 1250351
#% 1269380
#% 1272052
#% 1273919
#% 1453224
#% 1614147
#% 1617537
#% 1826403
#! The Decentralized Partially Observable Markov Decision Process (Dec-POMDP) is a powerful model for multiagent planning under uncertainty, but its applicability is hindered by its high complexity - solving Dec-POMDPs optimally is NEXP-hard. Recently, Kumar et al. introduced the Value Factorization (VF) framework, which exploits decomposable value functions that can be factored into subfunctions. This framework has been shown to be a generalization of several models that leverage sparse agent interactions such as TI-Dec-MDPs, NDPOMDPs and TD-POMDPs. Existing algorithms for these models assume that the interaction graph of the problem is given. In this paper, we introduce three algorithms to automatically generate interaction graphs for models within the VF framework and establish lower and upper bounds on the expected reward of an optimal joint policy. We illustrate experimentally the benefits of these techniques for sensor placement in a decentralized tracking application.

#index 2032891
#* A reputation management approach for resource constrained trustee agents
#@ Han Yu;Chunyan Miao;Bo An;Cyril Leung;Victor R. Lesser
#t 2013
#c 11
#% 803395
#% 823966
#% 943777
#% 1384503
#% 1464055
#% 1480225
#% 1541044
#% 1967325
#! Trust is an important mechanism enabling agents to self-police open and dynamic multi-agent systems (ODMASs). Trusters evaluate the reputation of trustees based on their past observed performance, and use this information to guide their future interaction decisions. Existing trust models tend to concentrate trusters' interactions on a small number of highly reputable trustees to minimize risk exposure. When a trustee's servicing capacity is limited, such an approach may cause long delays for trusters and subsequently damage the reputation of trustees. To mitigate this problem, we propose a reputation management approach for trustee agents based on distributed constraint optimization. It helps a trustee to make situation-aware decisions on which incoming requests to serve and prevent the resulting reputation score from being affected by factors out of the trustee's control. The approach is evaluated through theoretical analysis and within a simulated, highly dynamic multi-agent environment. The results show that it can achieve close to optimally efficient utilization of the trustee agents' collective capacity in an ODMAS, promotes fair treatment of trustee agents based on their behavior, and significantly outperforms related work in enhancing social welfare.

#index 2032892
#* Multiwinner elections under preferences that are single-peaked on a tree
#@ Lan Yu;Hau Chan;Edith Elkind
#t 2013
#c 11
#% 242217
#% 408396
#% 892736
#% 1223508
#% 1826109
#% 1846274
#! We study the complexity of electing a committee under several variants of the Chamberlin-Courant rule when the voters' preferences are single-peaked on a tree. We first show that this problem is easy for the egalitarian, or "minimax" version of this problem, for arbitrary trees and misrepresentation functions. For the standard (utilitarian) version of this problem we provide an algorithm for an arbitrary misrepresentation function whose running time is polynomial in the input size as long as the number of leaves of the underlying tree is bounded by a constant. On the other hand, we prove that our problem remains computationally hard on trees that have bounded degree, diameter, or pathwidth. Finally, we show how to modify Trick's [1989] algorithm to check whether an election is single-peaked on a tree whose number of leaves does not exceed a given parameter λ.

#index 2032893
#* On random quotas and proportional representation in weighted voting games
#@ Yair Zick
#t 2013
#c 11
#% 1076646
#% 1151713
#% 1350761
#% 1545554
#% 1701146
#% 1714120
#% 1826141
#! Weighted voting games (WVGs) model decision making bodies such as parliaments and councils. In such settings, it is often important to provide a measure of the influence a player has on the vote. Two highly popular such measures are the Shapley-Shubik power index, and the Banzhaf power index. Given a power measure, proportional representation is the property of having players' voting power proportional to the number of parliament seats they receive. Approximate proportional representation (w.r.t. the Banzhaf power index) can be ensured by changing the number of parliament seats each party receives; this is known as Penrose's square root method. However, a discrepancy between player weights and parliament seats is often undesirable or unfeasible; a simpler way of achieving approximate proportional representation is by changing the quota, i.e. the number of votes required in order to pass a bill. It is known that a player's Shapley-Shubik power index is proportional to his weight when one chooses a quota at random; that is, when taking a random quota, proportional representation holds in expectation. In our work, we show that not only does proportional representation hold in expectation, it also holds for many quotas. We do so by providing bounds on the variance of the Shapley value when the quota is chosen at random, assuming certain weight distributions. We further explore the case where weights are sampled from i.i.d. binomial distributions; for this case, we show good bounds on an important parameter governing the behavior of the variance, as well as substantiating our claims with empirical analysis.

#index 2032894
#* Robust constraint satisfaction and local hidden variables in quantum mechanics
#@ Samson Abramsky;Georg Gottlob;Phokion G. Kolaitis
#t 2013
#c 11
#% 97097
#% 115329
#% 126392
#% 320265
#% 644201
#% 928731
#% 1770496
#% 1907689
#% 1969455
#! Motivated by considerations in quantum mechanics, we introduce the class of robust constraint satisfaction problems in which the question is whether every partial assignment of a certain length can be extended to a solution, provided the partial assignment does not violate any of the constraints of the given instance. We explore the complexity of specific robust colorability and robust satisfiability problems, and show that they are NP-complete. We then use these results to establish the computational intractability of detecting local hidden-variable models in quantum mechanics.

#index 2032895
#* Just-in-time compilation of knowledge bases
#@ Gilles Audemard;Jean-Marie Lagniez;Laurent Simon
#t 2013
#c 11
#% 204396
#% 220203
#% 288165
#% 327779
#% 336874
#% 427631
#% 655781
#% 729052
#% 761106
#% 1269749
#% 1271987
#% 1272349
#% 1275126
#% 1289171
#% 1305353
#% 1305412
#% 1396061
#% 1588684
#% 1664998
#% 1826194
#% 1881894
#% 1890726
#! Since the first principles of Knowledge Compilation (KC), most of the work has been focused in finding a good compilation target language in terms of compromises between compactness and expressiveness. The central idea remains unchanged in the last fifteen years: an off-line, very hard, stage, allows to "compile" the initial theory in order to guarantee (theoretically) an efficient on-line stage, on a set of predefined queries and operations. We propose a new "Just-in-Time" approach for KC. Here, any Knowledge Base (KB) will be immediately available for queries, and the effort spent on past queries will be partly amortized for future ones. To guarantee efficient answers, we rely on the tremendous progresses made in the practical solving of SAT and incremental SAT applicative problems. Even if each query may be theoretically hard, we show that our approach outperforms previous KC approaches on the set of classical problems used in the field, and allows to handle problems that are out of the scope of current approaches.

#index 2032896
#* Maintaining alternative values in constraint-based configuration
#@ Caroline Becker;Hélène Fargier
#t 2013
#c 11
#% 2028
#% 130204
#% 345434
#% 445247
#% 445249
#% 637480
#% 736401
#% 736407
#% 1273489
#% 1477074
#% 1477282
#% 1499495
#! Constraint programming techniques are widely used to model and solve interactive decision problems, and especially configuration problems. In this type of application, the configurable product is described by means of a set of constraints bearing on the configuration variables. The user interactively solves the CSP by assigning the variables according to her preferences. The system then has to keep the domains of the other variables consistent with these choices. Since maintaining the global inverse consistency of the domains is not tractable, the domains are instead filtered according to some level of local consistency, e.g. arc-consistency. The present paper aims at offering a more convenient interaction by providing the user with possible alternative values for the already assigned variables, i.e. values that could replace the current ones without leading to a constraint violation. We thus present the new concept of alternative domains in a (possibly) partially assigned CSP. We propose a propagation algorithm that computes all the alternative domains in a single step. Its worst case complexity is comparable to the one of the naive algorithm that would run a full propagation for each variable, but its experimental efficiency is better.

#index 2032897
#* Breakout local search for the vertex separator problem
#@ Una Benlic;Jin-Kao Hao
#t 2013
#c 11
#% 121466
#% 143603
#% 416918
#% 605157
#% 814190
#% 814191
#% 1558027
#% 1576710
#% 1868140
#% 1896952
#% 1950835
#% 1954886
#! In this paper, we propose the first heuristic approach for the vertex separator problem (VSP), based on Breakout Local Search (BLS). BLS is a recent meta-heuristic that follows the general framework of the popular Iterated Local Search (ILS) with a particular focus on the perturbation strategy. Based on some relevant information on search history, it tries to introduce the most suitable degree of diversification by determining adaptively the number and type of moves for the next perturbation phase. The proposed heuristic is highly competitive with the exact state-of-art approaches from the literature on the current VSP benchmark. Moreover, we present for the first time computational results for a set of large graphs with up to 3000 vertices, which constitutes a new challenging benchmark for VSP approaches.

#index 2032898
#* Detecting and exploiting subproblem tractability
#@ Christian Bessiere;Clement Carbonnel;Emmanuel Hebrard;George Katsirelos;Toby Walsh
#t 2013
#c 11
#% 237054
#% 259825
#% 289332
#% 866593
#% 1015934
#% 1279379
#% 1538232
#% 1985097
#! Constraint satisfaction problems may be nearly tractable. For instance, most of the relations in a problem might belong to a tractable language. We introduce a method to take advantage of this fact by computing a backdoor to this tractable language. The method can be applied to many tractable classes for which the membership test is itself tractable. We introduce therefore two polynomial membership testing algorithms, to check if a language is closed under a majority or conservative Mal'tsev polymorphism, respectively. Then we show that computing a minimal backdoor for such classes is fixed parameter tractable (FPT) if the tractable subset of relations is given, and W[2]- complete otherwise. Finally, we report experimental results on the XCSP benchmark set. We identified a few promising problem classes where problems were nearly closed under a majority polymorphism and small backdoors could be computed.

#index 2032899
#* Constraint acquisition via partial queries
#@ Christian Bessiere;Remi Coletta;Emmanuel Hebrard;George Katsirelos;Nadjib Lazaar;Nina Narodytska;Claude-Guy Quimper;Toby Walsh
#t 2013
#c 11
#% 450951
#% 451056
#% 534343
#% 1145164
#% 1250145
#% 1274759
#% 1520699
#% 1699577
#% 1925237
#! We learn constraint networks by asking the user partial queries. That is, we ask the user to classify assignments to subsets of the variables as positive or negative. We provide an algorithm that, given a negative example, focuses onto a constraint of the target network in a number of queries logarithmic in the size of the example. We give information theoretic lower bounds for learning some simple classes of constraint networks and show that our generic algorithm is optimal in some cases. Finally we evaluate our algorithm on some benchmarks.

#index 2032900
#* On the complexity of trick-taking card games
#@ Édouard Bonnet;Florian Jamain;Abdallah Saffidine
#t 2013
#c 11
#% 34610
#% 165504
#% 251781
#% 289248
#% 980354
#% 1271963
#% 1289371
#% 1305515
#% 1404139
#% 1404140
#% 1485867
#! Determining the complexity of perfect information trick-taking card games is a long standing open problem. This question is worth addressing not only because of the popularity of these games among human players, e.g., DOUBLE DUMMY BRIDGE, but also because of its practical importance as a building block in state-of-the-art playing engines for CONTRACT BRIDGE, SKAT, HEARTS, and SPADES. We define a general class of perfect information two-player trick-taking card games dealing with arbitrary numbers of hands, suits, and suit lengths. We investigate the complexity of determining the winner in various fragments of this game class. Our main result is a proof of PSPACE-completeness for a fragment with bounded number of hands, through a reduction from Generalized Geography. Combining our results with Wästlund's tractability results gives further insight in the complexity landscape of trick-taking card games.

#index 2032901
#* Comprehensive score: towards efficient local search for SAT with long clauses
#@ Shaowei Cai;Kaile Su
#t 2013
#c 11
#% 160270
#% 750050
#% 819505
#% 1250149
#% 1305372
#% 1478526
#% 1585246
#% 1608498
#% 1608506
#% 1726922
#% 1726942
#% 1726950
#% 1881878
#% 1881918
#! It is widely acknowledged that stochastic local search (SLS) algorithms can efficiently find models of satisfiable formulae for the Boolean Satisfiability (SAT) problem. There has been much interest in studying SLS algorithms on random k-SAT instances. Compared to random 3-SAT instances which have special statistical properties rendering them easy to solve, random k-SAT instances with long clauses are similar to structured ones and remain very difficult. This paper is devoted to efficient SLS algorithms for random k-SAT instances with long clauses. By combining a novel variable property subscore with the commonly used property score, we design a scoring function named comprehensive score, which is utilized to develop a new SLS algorithm called CScoreSAT. The experiments show that CScoreSAT outperforms state-of-the-art SLS solvers, including the winners of recent SAT competitions, by one to two orders of magnitudes on large random 5-SAT and 7-SAT instances. In addition, CScoreSAT significantly outperforms its competitors on random k-SAT instances for each k = 4; 5; 6; 7 from SAT Challenge 2012, which indicates its robustness.

#index 2032902
#* A tree-based tabu search algorithm for the manpower allocation problem with time windows and job-teaming constraints
#@ Yilin Cai;Zizhen Zhang;Songshan Guo;Hu Qin;Andrew Lim
#t 2013
#c 11
#% 35388
#% 122671
#% 356938
#% 960025
#% 1129848
#% 1189857
#% 1679957
#% 1881611
#! This paper investigates the manpower allocation problem with time windows and job-teaming constraints (MAPTWTC), a practical scheduling and routing problem that tries to synchronize workers' schedules to complete all tasks. We first provide an integer programming model for the problem and discuss its properties. Next, we show that tree data structure can be used to represent the MAPTWTC solutions, and its optimal solution can be obtained from one of trees by solving a minimum cost flow model for each worker type. Consequently, we develop for the problem a novel tabu search algorithm employing search operators based on the tree data structure. Finally, we prove the effectiveness of the tabu search algorithm by computational experiments on two sets of instances.

#index 2032903
#* On the complexity of global scheduling constraints under structural restrictions
#@ Geoffrey Chu;Serge Gaspers;Nina Narodytska;Andreas Schutt;Toby Walsh
#t 2013
#c 11
#% 160208
#% 419963
#% 576440
#% 657751
#% 857282
#% 949119
#% 1191531
#% 1250136
#% 1270056
#% 1343734
#% 1493599
#% 1499496
#% 1538229
#% 1598186
#% 1716220
#% 1808022
#% 1826146
#% 1826149
#% 1845271
#% 1972413
#! We investigate the computational complexity of two global constraints, CUMULATIVE and INTERDISTANCE. These are key constraints in modeling and solving scheduling problems. Enforcing domain consistency on both is NP-hard. However, restricted versions of these constraints are often sufficient in practice. Some examples include scheduling problems with a large number of similar tasks, or tasks sparsely distributed over time. Another example is runway sequencing problems in air-traffic control, where landing periods have a regular pattern. Such cases can be characterized in terms of structural restrictions on the constraints. We identify a number of such structural restrictions and investigate how they impact the computational complexity of propagating these global constraints. In particular, we prove that such restrictions often make propagation tractable.

#index 2032904
#* Breaking symmetries in graph representation
#@ Michael Codish;Alice Miller;Patrick Prosser;Peter J. Stuckey
#t 2013
#c 11
#% 149795
#% 535172
#% 731608
#% 979221
#% 1411349
#% 1476546
#% 1623091
#% 1946292
#! There are many complex combinatorial problems which involve searching for an undirected graph satisfying a certain property. These problems are often highly challenging because of the large number of isomorphic representations of a possible solution. In this paper we introduce novel, effective and compact, symmetry breaking constraints for undirected graph search. While incomplete, these prove highly beneficial in pruning the search for a graph. We illustrate the application of symmetry breaking in graph representation to resolve several open instances in extremal graph theory.

#index 2032905
#* Variable elimination in binary CSP via forbidden patterns
#@ David A. Cohen;Martin C. Cooper;Guillaume Escamocher;Stanislav Živný
#t 2013
#c 11
#% 644201
#% 717227
#% 928731
#% 1291374
#% 1401708
#% 1664971
#% 1911360
#% 1956734
#! A variable elimination rule allows the polynomial-time identification of certain variables whose elimination does not affect the satisfiability of an instance. Variable elimination in the constraint satisfaction problem (CSP) can be used in preprocessing or during search to reduce search space size. We show that there are essentially just four variable elimination rules defined by forbidding generic sub-instances, known as irreducible patterns, in arc-consistent CSP instances. One of these rules is the Broken Triangle Property, whereas the other three are novel.

#index 2032906
#* Weight-enhanced diversification in stochastic local search for satisfiability
#@ Thach-Thao Duong;Duc Nghia Pham;Abdul Sattar;M. A. Hakim Newton
#t 2013
#c 11
#% 535147
#% 724949
#% 1250149
#% 1369579
#% 1478526
#% 1478779
#% 1608498
#% 1608506
#% 1698704
#% 1698707
#% 1726922
#% 1726942
#% 1881918
#% 1950642
#! Intensification and diversification are the key factors that control the performance of stochastic local search in satisfiability (SAT). Recently, Novelty Walk has become a popular method for improving diversification of the search and so has been integrated in many well-known SAT solvers such as TNM and gNovelty+. In this paper, we introduce new heuristics to improve the effectiveness of Novelty Walk in terms of reducing search stagnation. In particular, we use weights (based on statistical information collected during the search) to focus the diversification phase onto specific areas of interest. With a given probability, we select the most frequently unsatisfied clause instead of a totally random one as Novelty Walk does. Amongst all the variables appearing in the selected clause, we then select the least flipped variable for the next move. Our experimental results show that the new weight-enhanced diversification method significantly improves the performance of gNovelty+ and thus outperforms other local search SAT solvers on a wide range of structured and random satisfiability benchmarks.

#index 2032907
#* An approach to abductive reasoning in equational logic
#@ M. Echenim;N. Peltier;S. Tourret
#t 2013
#c 11
#% 45241
#% 69150
#% 234823
#% 326878
#% 420605
#% 459571
#% 560564
#% 579716
#% 579728
#% 1273435
#% 1289197
#% 1332575
#% 1469370
#% 1478579
#% 1882401
#! Abduction has been extensively studied in propositional logic because of its many applications in artificial intelligence. However, its intrinsic complexity has been a limitation to the implementation of abductive reasoning tools in more expressive logics. We have devised such a tool in ground flat equational logic, in which literals are equations or disequations between constants. Our tool is based on the computation of prime implicates. It uses a relaxed paramodulation calculus, designed to generate all prime implicates of a formula, together with a carefully defined data structure storing the implicates and able to efficiently detect, and remove, redundancies. In addition to a detailed description of this method, we present an analysis of some experimental results.

#index 2032908
#* Dominance rules for the choquet integral in multiobjective dynamic programming
#@ Lucie Galand;Julien Lesca;Patrice Perny
#t 2013
#c 11
#% 308
#% 40313
#% 102372
#% 193910
#% 593993
#% 857276
#% 866432
#% 1071388
#% 1223534
#% 1265162
#% 1289385
#% 1289568
#% 1565896
#% 1631104
#! Multiobjective Dynamic Programming (MODP) is a general problem solving method used to determine the set of Pareto-optimal solutions in optimization problems involving discrete decision variables and multiple objectives. It applies to combinatorial problems in which Pareto-optimality of a solution extends to all its sub-solutions (Bellman principle). In this paper we focus on the determination of the preferred tradeoffs in the Pareto set where preference is measured by a Choquet integral. This model provides high descriptive possibilities but the associated preferences generally do not meet the Bellman principle, thus preventing any straightforward adaptation of MODP. To overcome this difficulty, we introduce here a general family of dominance rules enabling an early pruning of some Pareto-optimal sub-solutions that cannot lead to a Choquet optimum. Within this family, we identify the most efficient dominance rules and show how they can be incorporated into a MODP algorithm. Then we report numerical tests showing the actual efficiency of this approach to find Choquet-optimal tradeoffs in multiobjective knapsack problems.

#index 2032909
#* Constraint satisfaction and fair multi-objective optimization problems: foundations, complexity, and islands of tractability
#@ Gianluigi Greco;Francesco Scarcello
#t 2013
#c 11
#% 83389
#% 289425
#% 321058
#% 331899
#% 339937
#% 419951
#% 644201
#% 866683
#% 928731
#% 942358
#% 1150429
#% 1172185
#% 1231034
#% 1350692
#% 1623071
#! An extension of the CSP optimization framework tailored to identify fair solutions to instances involving multiple optimization functions is studied. Two settings are considered, based on the maximization of the minimum value over all the given functions (MAX-MIN approach) and on its lexicographical refinement where, over all solutions maximizing the minimum value, those maximizing the second minimum value are preferred, and so on, until all functions are considered (LEXMAX-MIN approach). For both settings, the complexity of computing an optimal solution is analyzed and the tractability frontier is charted for acyclic instances, w.r.t. the number and the domains of the functions to be optimized. Larger islands of tractability are then identified via a novel structural approach, based on a notion of guard that is designed to deal with the interactions among constraint scopes and optimization functions.

#index 2032910
#* Preserving partial solutions while relaxing constraint networks
#@ Éric Grégoire;Jean-Marie Lagniez;Bertrand Mazure
#t 2013
#c 11
#% 131559
#% 345434
#% 419943
#% 928731
#% 1223210
#% 1250145
#% 1273575
#% 1399081
#% 1598600
#% 1608488
#% 1721894
#% 1780850
#% 1874779
#% 1925224
#! This paper is about transforming constraint networks to accommodate additional constraints in specific ways. The focus is on two intertwined issues. First, we investigate how partial solutions to an initial network can be preserved from the potential impact of additional constraints. Second, we study how more permissive constraints, which are intended to enlarge the set of solutions, can be accommodated in a constraint network. These two problems are studied in the general case and the light is shed on their relationship. A case study is then investigated where a more permissive additional constraint is taken into account through a form of network relaxation, while some previous partial solutions are preserved at the same time.

#index 2032911
#* Sufficiency-based selection strategy for MCTS
#@ Stefan Freyr Gudmundsson;Yngvi Björnsson
#t 2013
#c 11
#% 169359
#% 348578
#% 384911
#% 425053
#% 891559
#% 983838
#% 1139143
#% 1270060
#% 1404135
#% 1665148
#! Monte-Carlo Tree Search (MCTS) has proved a remarkably effective decision mechanism in many different game domains, including computer Go and general game playing (GGP). However, in GGP, where many disparate games are played, certain type of games have proved to be particularly problematic for MCTS. One of the problems are game trees with so-called optimistic moves, that is, bad moves that superficially look good but potentially require much simulation effort to prove otherwise. Such scenarios can be difficult to identify in real time and can lead to suboptimal or even harmful decisions. In this paper we investigate a selection strategy for MCTS to alleviate this problem. The strategy, called sufficiency threshold, concentrates simulation effort better for resolving potential optimistic move scenarios. The improved strategy is evaluated empirically in an n-arm-bandit test domain for highlighting its properties as well as in a state-of-the-art GGP agent to demonstrate its effectiveness in practice. The new strategy shows significant improvements in both domains.

#index 2032912
#* DeQED: an efficient divide-and-coordinate algorithm for DCOP
#@ Daisuke Hatano;Katsutoshi Hirayama
#t 2013
#c 11
#% 1083942
#% 1084276
#% 1215639
#% 1289393
#% 1291421
#% 1453074
#% 1453076
#! This paper presents a new DCOP algorithm called DeQED (Decomposition with Quadratic Encoding to Decentralize). DeQED is based on the Divide-and-Coordinate (DaC) framework, where the agents repeatedly solve their updated local sub-problems (the divide stage) and exchange coordination information that causes them to update their local sub-problems (the coordinate stage). Unlike other DaC-based DCOP algorithms, DeQED does not essentially increase the complexity of local subproblems and allows agents to avoid exchanging (primal) variable values in the coordinate stage. Our experimental results show that DeQED significantly outperformed other incomplete DCOP algorithms for both random and structured instances.

#index 2032913
#* Extending simple tabular reduction with short supports
#@ Christopher Jefferson;Peter Nightingale
#t 2013
#c 11
#% 984325
#% 1108481
#% 1141526
#% 1223207
#% 1291374
#% 1375864
#% 1399085
#% 1472766
#% 1493582
#% 1619006
#% 1664971
#% 1826162
#% 2011334
#! Constraint propagation is one of the key techniques in constraint programming, and a large body of work has built up around it. Special-purpose constraint propagation algorithms frequently make implicit use of short supports -- by examining a subset of the variables, they can infer support (a justification that a variable-value pair still forms part of a solution to the constraint) for all other variables and values and save substantial work. Recently short supports have been used in general purpose propagators, and (when the constraint is amenable to short supports) speed ups of more than three orders of magnitude have been demonstrated. In this paper we present SHORTSTR2, a development of the Simple Tabular Reduction algorithm STR2+. We show that SHORTSTR2 is complementary to the existing algorithms SHORTGAC and HAGGISGAC that exploit short supports, while being much simpler. When a constraint is amenable to short supports, the short support set can be exponentially smaller than the full-length support set. Therefore SHORTSTR2 can efficiently propagate many constraints that STR2+ cannot even load into memory. We also show that SHORTSTR2 can be combined with a simple algorithm to identify short supports from full-length supports, to provide a superior drop-in replacement for STR2+.

#index 2032914
#* Monte Carlo *-minimax search
#@ Marc Lanctot;Abdallah Saffidine;Joel Veness;Christopher Archibald;Mark H. M. Winands
#t 2013
#c 11
#% 154164
#% 425053
#% 794719
#% 1273918
#% 1291472
#% 1355611
#% 1404135
#% 1665148
#% 1738039
#% 1740192
#! This paper introduces Monte Carlo *-Minimax Search (MCMS), a Monte Carlo search algorithm for turned-based, stochastic, two-player, zero-sum games of perfect information. The algorithm is designed for the class of densely stochastic games; that is, games where one would rarely expect to sample the same successor state multiple times at any particular chance node. Our approach combines sparse sampling techniques from MDP planning with classic pruning techniques developed for adversarial expectimax planning. We compare and contrast our algorithm to the traditional *-Minimax approaches, as well as MCTS enhanced with the Double Progressive Widening, on four games: Pig, EinStein Würfelt Nicht!, Can't Stop, and Ra. Our results show that MCMS can be competitive with enhanced MCTS variants in some domains, while consistently outperforming the equivalent classic approaches given the same amount of thinking time.

#index 2032915
#* Double-wheel graphs are graceful
#@ Ronan Le Bras;Carla P. Gomes;Bart Selman
#t 2013
#c 11
#% 379093
#% 931128
#% 1250525
#% 1630317
#% 1664995
#% 1698703
#! We present the first polynomial time construction procedure for generating graceful double-wheel graphs. A graph is graceful if its vertices can be labeled with distinct integer values from {0;..., e}, where e is the number of edges, such that each edge has a unique value corresponding to the absolute difference of its endpoints. Graceful graphs have a range of practical application domains, including in radio astronomy, X-ray crystallography, cryptography, and experimental design. Various families of graphs have been proven to be graceful, while others have only been conjectured to be. In particular, it has been conjectured that so-called double-wheel graphs are graceful. A double-wheel graph consists of two cycles of N nodes connected to a common hub. We prove this conjecture by providing the first construction for graceful double-wheel graphs, for any N 3, using a framework that combines streamlined constraint reasoning with insights from human computation. We also use this framework to provide a polynomial time construction for diagonally ordered magic squares.

#index 2032916
#* Predicting the size of depth-first branch and bound search trees
#@ Levi H. S. Lelis;Lars Otten;Rina Dechter
#t 2013
#c 11
#% 2194
#% 25470
#% 44876
#% 115963
#% 337983
#% 337986
#% 1250317
#% 1261230
#% 1275306
#% 1473932
#% 1880483
#% 1943417
#% 1954687
#! This paper provides algorithms for predicting the size of the Expanded Search Tree (EST) of Depth-first Branch and Bound algorithms (DFBnB) for optimization tasks. The prediction algorithm is implemented and evaluated in the context of solving combinatorial optimization problems over graphical models such as Bayesian and Markov networks. Our methods extend to DFBnB the approaches provided by Knuth-Chen schemes that were designed and applied for predicting the EST size of backtracking search algorithms. Our empirical results demonstrate good predictions which are superior to competing schemes.

#index 2032917
#* Target-value search revisited
#@ Carlos Linares López;Roni Stern;Ariel Felner
#t 2013
#c 11
#% 2194
#% 533951
#! This paper addresses the Target-Value Search (TVS) problem, which is the problem of finding a path between two nodes in a graph whose cost is as close as possible to a given target value, T. This problem has been previously addressed only for directed acyclic graphs. In this work we develop the theory required to solve this problem optimally for any type of graphs. We modify traditional heuristic search algorithms for this setting, and propose a novel bidirectional search algorithm that is specifically suited for TVS. The benefits of this bidirectional search algorithm are discussed both theoretically and experimentally on several domains.

#index 2032918
#* Algorithm portfolios based on cost-sensitive hierarchical clustering
#@ Yuri Malitsky;Ashish Sabharwal;Horst Samulowitz;Meinolf Sellmann
#t 2013
#c 11
#% 329487
#% 443509
#% 500827
#% 722929
#% 727925
#% 755451
#% 1272228
#% 1289281
#% 1358746
#% 1473345
#% 1623079
#% 1881893
#! Different solution approaches for combinatorial problems often exhibit incomparable performance that depends on the concrete problem instance to be solved. Algorithm portfolios aim to combine the strengths of multiple algorithmic approaches by training a classifier that selects or schedules solvers dependent on the given instance. We devise a new classifier that selects solvers based on a cost-sensitive hierarchical clustering model. Experimental results on SAT and MaxSAT show that the new method outperforms the most effective portfolio builders to date.

#index 2032919
#* On computing minimal correction subsets
#@ Joao Marques-Silva;Federico Heras;Mikolas Janota;Alessandro Previti;Anton Belov
#t 2013
#c 11
#% 21137
#% 431440
#% 431554
#% 456159
#% 729052
#% 776979
#% 1022059
#% 1209770
#% 1230644
#% 1250145
#% 1269577
#% 1272228
#% 1275123
#% 1457065
#% 1473254
#% 1623079
#% 1675296
#% 1681106
#% 1706630
#% 1722417
#% 2023344
#! A set of constraints that cannot be simultaneously satisfied is over-constrained. Minimal relaxations and minimal explanations for over-constrained problems find many practical uses. For Boolean formulas, minimal relaxations of over-constrained problems are referred to as Minimal Correction Subsets (MCSes). MCSes find many applications, including the enumeration of MUSes. Existing approaches for computing MCSes either use a Maximum Satisfiability (MaxSAT) solver or iterative calls to a Boolean Satisfiability (SAT) solver. This paper shows that existing algorithms for MCS computation can be inefficient, and so inadequate, in certain practical settings. To address this problem, this paper develops a number of novel techniques for improving the performance of existing MCS computation algorithms. More importantly, the paper proposes a novel algorithm for computing MCSes. Both the techniques and the algorithm are evaluated empirically on representative problem instances, and are shown to yield the most efficient and robust solutions for MCS computation.

#index 2032920
#* Search strategies for optimal multi-way number partitioning
#@ Michael D. Moffitt
#t 2013
#c 11
#% 267769
#% 369577
#% 408396
#% 1147758
#% 1275261
#% 1279390
#% 1279395
#% 1289192
#% 1289369
#% 1305375
#% 1765796
#% 1826157
#% 1826170
#% 1925280
#! The number partitioning problem seeks to divide a set of n numbers across k distinct subsets so as to minimize the sum of the largest partition. In this work, we develop a new optimal algorithm for multi-way number partitioning. A critical observation motivating our methodology is that a globally optimal k-way partition may be recursively constructed by obtaining suboptimal solutions to subproblems of size k - 1. We introduce a new principle of optimality that provides necessary and sufficient conditions for this construction, and use it to strengthen the relationship between sequential decompositions by enforcing upper and lower bounds on intermediate solutions. We also demonstrate how to further prune unpromising partial assignments by detecting and eliminating dominated solutions. Our approach outperforms the previous state-of-the-art by up to four orders of magnitude, reducing average runtime on the largest benchmarks from several hours to less than a second.

#index 2032921
#* Three generalizations of the FOCUS constraint
#@ Nina Narodytska;Thierry Petit;Mohamed Siala;Toby Walsh
#t 2013
#c 11
#% 903340
#% 1098187
#% 1217786
#% 1411201
#% 1499496
#% 1623064
#% 1925266
#! The FOCUS constraint expresses the notion that solutions are concentrated. In practice, this constraint suffers from the rigidity of its semantics. To tackle this issue, we propose three generalizations of the FOCUS constraint. We provide for each one a complete filtering algorithm as well as discussing decompositions.

#index 2032922
#* Subset selection of search heuristics
#@ Chris Rayner;Nathan Sturtevant;Michael Bowling
#t 2013
#c 11
#% 289395
#% 813718
#% 939032
#% 1305386
#% 1736830
#! Constructing a strong heuristic function is a central problem in heuristic search. A common approach is to combine a number of heuristics by maximizing over the values from each. If a limit is placed on this number, then a subset selection problem arises. We treat this as an optimization problem, and proceed by translating a natural loss function into a submodular and monotonic utility function under which greedy selection is guaranteed to be near-optimal. We then extend this approach with a sampling scheme that retains provable optimality. Our empirical results show large improvements over existing methods, and give new insight into building heuristics for directed domains.

#index 2032923
#* Semiring-based mini-bucket partitioning schemes
#@ Emma Rollon;Javier Larrosa;Rina Dechter
#t 2013
#c 11
#% 44876
#% 230551
#% 417568
#% 419951
#% 448887
#% 578757
#% 644201
#% 751442
#% 1062021
#% 1196918
#% 1223200
#% 1291412
#% 1473938
#% 1650711
#! Graphical models are one of the most prominent frameworks to model complex systems and efficiently query them. Their underlying algebraic properties are captured by a valuation structure that, most usually, is a semiring. Depending on the semiring of choice, we can capture probabilistic models, constraint networks, cost networks, etc. In this paper we address the partitioning problem which occurs in many approximation techniques such as mini-bucket elimination and joingraph propagation algorithms. Roghly speaking, subject to complexity bounds, the algorithm needs to find a partition of a set of factors such that best approximates the whole set. While this problem has been addressed in the past in a particular case, we present here a general description. Furthermore, we also propose a general partitioning scheme. Our proposal is general in the sense that it is presented in terms of a generic semiring with the only additional requirements of a division operation and a refinement of its order. The proposed algorithm instantiates to the particular task of computing the probability of evidence, but also applies directly to other important reasoning tasks. We demonstrate its good empirical behaviour on the problem of computing the most probable explanation.

#index 2032924
#* Improved bin completion for optimal bin packing and number partitioning
#@ Ethan L. Schreiber;Richard E. Korf
#t 2013
#c 11
#% 78107
#% 86465
#% 161236
#% 217814
#% 408396
#% 578765
#% 1191546
#% 1275306
#% 1279390
#% 1305375
#% 1826157
#! The bin-packing problem is to partition a multiset of n numbers into as few bins of capacity C as possible, such that the sum of the numbers in each bin does not exceed C. We compare two existing algorithms for solving this problem: bin completion (BC) and branch-and-cut-and-price (BCP). We show experimentally that the problem difficulty and dominant algorithm are a function of n, the precision of the input elements and the number of bins in an optimal solution. We describe three improvements to BC which result in a speedup of up to five orders of magnitude as compared to the original BC algorithm. While the current belief is that BCP is the dominant bin-packing algorithm, we show that improved BC is up to five orders of magnitude faster than a state-of-the-art BCP algorithm on problems with relatively few bins. We then explore a closely related problem, the number-partitioning problem, and show that an algorithm based on improved bin packing is up to three orders of magnitude faster than a BCP solver called DIMM which claims to be state of the art. Finally, we show how to use number partitioning to generate difficult bin-packing instances.

#index 2032925
#* Forward perimeter search with controlled use of memory
#@ Thorsten Schütt;Robert Döbbelin;Alexander Reinefeld
#t 2013
#c 11
#% 160388
#% 189701
#% 348576
#% 529516
#% 1023420
#% 1250226
#% 1269579
#% 1272322
#% 1273312
#% 1291463
#% 1398243
#% 1939357
#! There are many hard shortest-path search problems that cannot be solved, because best-first search runs out of memory space and depth-first search runs out of time. We propose Forward Perimeter Search (FPS), a heuristic search with controlled use of memory. It builds a perimeter around the root node and tests each perimeter node for a shortest path to the goal. The perimeter is adaptively extended towards the goal during the search process. We show that FPS expands in random 24-puzzles 50% fewer nodes than BF-IDA* while requiring several orders of magnitude less memory. Additionally, we present a hard problem instance of the 24-puzzle that needs at least 140 moves to solve; i.e. 26 more moves than the previously published hardest instance.

#index 2032926
#* Minimizing writes in parallel external memory search
#@ Nathan R. Sturtevant;Matthew J. Rutherford
#t 2013
#c 11
#% 235559
#% 400543
#% 987571
#% 1128420
#% 1223545
#% 1224038
#% 1250219
#% 1250221
#% 1250226
#% 1270069
#! Recent research on external-memory search has shown that disks can be effectively used as secondary storage when performing large breadth-first searches. We introduce the Write-Minimizing Breadth-First Search (WMBFS) algorithm which is designed to minimize the number of writes performed in an external-memory BFS. WMBFS is also designed to store the results of the BFS for later use. We present the results of a BFS on a single-agent version of Chinese Checkers and the Rubik's Cube edge cubes, state spaces with about 1 trillion states each. In evaluating against a comparable approach, WMBFS reduces the I/O for the Chinese Checkers domain by over an order of magnitude. In Rubik's cube, in addition to reducing I/O, the search is also 3.5 times faster. Analysis of the results suggests the machine and state-space properties necessary for WMBFS to perform well.

#index 2032927
#* Towards rational deployment of multiple heuristics in A*
#@ David Tolpin;Tal Beja;Solomon Eyal Shimony;Ariel Felner;Erez Karpas
#t 2013
#c 11
#% 1722
#% 2194
#% 107169
#% 348576
#% 1215626
#% 1272113
#% 1305567
#% 1585249
#% 1826170
#% 1826171
#% 1911365
#! The obvious way to use several admissible heuristics in A* is to take their maximum. In this paper we aim to reduce the time spent on computing heuristics. We discuss Lazy A*, a variant of A* where heuristics are evaluated lazily: only when they are essential to a decision to be made in the A* search process. We present a new rational meta-reasoning based scheme, rational lazy A*, which decides whether to compute the more expensive heuristics at all, based on a myopic value of information estimate. Both methods are examined theoretically. Empirical evaluation on several domains supports the theoretical results, and shows that lazy A* and rational lazy A* are state-of-the-art heuristic combination methods.

#index 2032928
#* A unified approximate nearest neighbor search scheme by combining data structure and hashing
#@ Debing Zhang;Genmao Yang;Yao Hu;Zhongming Jin;Deng Cai;Xiaofei He
#t 2013
#c 11
#% 261733
#% 317313
#% 479973
#% 760805
#% 883971
#% 1023422
#% 1649056
#% 1739422
#% 1750268
#% 1750338
#% 1826272
#% 1883983
#% 1884017
#% 1884109
#% 1884343
#% 1931623
#! Nowadays, Nearest Neighbor Search becomes more and more important when facing the challenge of big data. Traditionally, to solve this problem, researchers mainly focus on building effective data structures such as hierarchical k-means tree or using hashing methods to accelerate the query process. In this paper, we propose a novel unified approximate nearest neighbor search scheme to combine the advantages of both the effective data structure and the fast Hamming distance computation in hashing methods. In this way, the searching procedure can be further accelerated. Computational complexity analysis and extensive experiments have demonstrated the effectiveness of our proposed scheme.

#index 2032929
#* Verifiable equilibria in boolean games
#@ Thomas Ågotnes;Paul Harrenstein;Wiebe Van Der Hoek;Michael Wooldridge
#t 2013
#c 11
#% 188086
#% 380578
#% 781219
#% 1083988
#% 1223241
#% 1291402
#% 1614153
#% 1615246
#! This work is motivated by the following concern. Suppose we have a game exhibiting multiple Nash equilibria, with little to distinguish them except that one of them can be verified while the others cannot. That is, one of these equilibria carries sufficient information that, if this is the outcome, then the players can tell that an equilibrium has been played. This provides an argument for this equilibrium being played, instead of the alternatives. Verifiability can thus serve to make an equilibrium a focal point in the game. We formalise and investigate this concept using a model of Boolean games with incomplete information. We define and investigate three increasingly strong types of verifiable equilibria, characterise the complexity of checking these, and show how checking their existence can be captured in a variant of modal epistemic logic.

#index 2032930
#* Efficient approach to solve the minimal labeling problem of temporal and spatial qualitative constraints
#@ Nouhad Amaneddine;Jean-François Condotta;Michael Sioutis
#t 2013
#c 11
#% 126395
#% 158920
#% 181229
#% 750574
#% 844096
#% 948066
#% 1272728
#% 1273794
#% 1373205
#% 1659527
#% 1925259
#% 1933606
#% 1965303
#! The Interval Algebra (IA) and a subset of the Region Connection Calculus (RCC), namely RCC-8, are the dominant Artificial Intelligence approaches for representing and reasoning about qualitative temporal and topological relations respectively. Such qualitative information can be formulated as a Qualitative Constraint Network (QCN). In this paper, we focus on the minimal labeling problem (MLP) and we propose an algorithm to efficiently derive all the feasible base relations of a QCN. Our algorithm considers chordal QCNs and a new form of partial consistency which we define as G♦-consistency. Further, the proposed algorithm uses tractable subclasses of relations having a specific patchwork property for which ⋄-consistency implies the consistency of the input QCN. Experimentations with QCNs of IA and RCC-8 show the importance and efficiency of this new approach.

#index 2032931
#* Exchanging OWL 2 QL knowledge bases
#@ Marcelo Arenas;Elena Botoeva;Diego Calvanese;Vladislav Ryzhikov
#t 2013
#c 11
#% 378409
#% 494344
#% 654468
#% 809239
#% 826032
#% 912245
#% 924747
#% 992962
#% 1015302
#% 1063712
#% 1215806
#% 1232194
#% 1272100
#% 1369574
#% 1433975
#% 1581822
#% 1770133
#% 1938496
#% 1961531
#! Knowledge base exchange is an important problem in the area of data exchange and knowledge representation, where one is interested in exchanging information between a source and a target knowledge base connected through a mapping. In this paper, we study this fundamental problem for knowledge bases and mappings expressed in OWL2 QL, the profile of OWL2 based on the description logic DL-LiteR. More specifically, we consider the problem of computing universal solutions, identified as one of the most desirable translations to be materialized, and the problem of computing UCQ-representations, which optimally capture in a target TBox the information that can be extracted from a source TBox and a mapping by means of unions of conjunctive queries. For the former we provide a novel automata-theoretic technique, and complexity results that range from NP to EXPTIME, while for the latter we show NLOGSPACE-completeness.

#index 2032932
#* Temporal description logic for ontology-based data access
#@ Alessandro Artale;Roman Kontchakov;Frank Wolter;Michael Zakharyaschev
#t 2013
#c 11
#% 162224
#% 778122
#% 913798
#% 992962
#% 1055732
#% 1116024
#% 1291493
#% 1369574
#% 1409382
#% 1531206
#% 1594576
#% 1724586
#% 1808579
#% 1826203
#% 1829285
#% 1916569
#% 1933378
#% 1933380
#! Our aim is to investigate ontology-based data access over temporal data with validity time and ontologies capable of temporal conceptual modelling. To this end, we design a temporal description logic, TQL, that extends the standard ontology language OWL2QL, provides basic means for temporal conceptual modelling and ensures first-order rewritability of conjunctive queries for suitably defined data instances with validity time.

#index 2032933
#* Functional stable model semantics and answer set programming modulo theories
#@ Michael Bartholomew;Joohyung Lee
#t 2013
#c 11
#% 1257225
#% 1503511
#% 1568279
#% 1891650
#% 1891684
#! Recently there has been an increasing interest in incorporating "intensional" functions in answer set programming. Intensional functions are those whose values can be described by other functions and predicates, rather than being pre-defined as in the standard answer set programming. We demonstrate that the functional stable model semantics plays an important role in the framework of "Answer Set Programming Modulo Theories (ASPMT)" --a tight integration of answer set programming and satisfiability modulo theories, under which existing integration approaches can be viewed as special cases where the role of functions is limited. We show that "tight" ASPMT programs can be translated into SMT instances, which is similar to the known relationship between ASP and SAT.

#index 2032934
#* Decidability of model checking non-uniform artifact-centric quantified interpreted systems
#@ Francesco Belardinelli;Alessio Lomuscio
#t 2013
#c 11
#% 299338
#% 384978
#% 1095795
#% 1100590
#% 1153042
#% 1180017
#% 1202286
#% 1215530
#% 1591771
#% 1694560
#% 1738489
#% 1887605
#% 1890170
#% 1942467
#! Artifact-Centric Systems are a novel paradigm in service-oriented computing. In the present contribution we show that model checking bounded, non-uniform artifact-centric systems is undecidable. We provide a partial model checking procedure for artifact-centric systems against the universal fragment of a first-order version of the logic CTL. We obtain this result by introducing a counterpart semantics and developing an abstraction methodology operating on these structures. This enables us to generate finite abstractions of infinite artifact-centric systems, hence perform verification on abstract models.

#index 2032935
#* Reasoning about continuous uncertainty in the situation calculus
#@ Vaishak Belle;Hector J. Levesque
#t 2013
#c 11
#% 44876
#% 90371
#% 103309
#% 137786
#% 144840
#% 157172
#% 188086
#% 194652
#% 284644
#% 342119
#% 417762
#% 486934
#% 529345
#% 572366
#% 850430
#% 1113048
#% 1149158
#% 1250507
#% 1269826
#% 1289565
#% 1499560
#% 1650381
#% 1650869
#! Among the many approaches for reasoning about degrees of belief in the presence of noisy sensing and acting, the logical account proposed by Bacchus, Halpern, and Levesque is perhaps the most expressive. While their formalism is quite general, it is restricted to fluents whose values are drawn from discrete countable domains, as opposed to the continuous domains seen in many robotic applications. In this paper, we show how this limitation in their approach can be lifted. By dealing seamlessly with both discrete distributions and continuous densities within a rich theory of action, we provide a very general logical specification of how belief should change after acting and sensing in complex noisy domains.

#index 2032936
#* Syntactic computation of hybrid possibilistic conditioning under uncertain inputs
#@ Salem Benferhat;Célia Da Costa Pereira;Andrea G. B. Tettamanzi
#t 2013
#c 11
#% 167544
#% 1136006
#% 1273609
#% 1273623
#% 1291397
#% 1424218
#% 1661391
#! We extend hybrid possibilistic conditioning to deal with inputs consisting of a set of triplets composed of propositional formulas, the level at which the formulas should be accepted, and the way in which their models should be revised. We characterize such conditioning using elementary operations on possibility distributions. We then solve a difficult issue that concerns the syntactic computation of the revision of possibilistic knowledge bases, made of weighted formulas, using hybrid conditioning. An important result is that there is no extra computational cost in using hybrid possibilistic conditioning and in particular the size of the revised possibilistic base is polynomial with respect to the size of the initial base and the input.

#index 2032937
#* Automating quantified conditional logics in HOL
#@ Christoph Benzmüller
#t 2013
#c 11
#% 23014
#% 262234
#% 320132
#% 344361
#% 780335
#% 986481
#% 1108109
#% 1195102
#% 1309331
#% 1369698
#% 1414319
#% 1473337
#% 1737475
#% 1882395
#% 1941681
#! A notion of quantified conditional logics is provided that includes quantification over individual and propositional variables. The former is supported with respect to constant and variable domain semantics. In addition, a sound and complete embedding of this framework in classical higher-order logic is presented. Using prominent examples from the literature it is demonstrated how this embedding enables effective automation of reasoning within (object-level) and about (meta-level) quantified conditional logics with off-the-shelf higher-order theorem provers and model finders.

#index 2032938
#* First-order rewritability of atomic queries in horn description logics
#@ Meghyn Bienvenu;Carsten Lutz;Frank Wolter
#t 2013
#c 11
#% 54225
#% 494344
#% 992962
#% 992964
#% 1065944
#% 1111191
#% 1231038
#% 1289408
#% 1297721
#% 1305615
#% 1305620
#% 1333459
#% 1393549
#% 1594576
#% 1615741
#% 1669994
#% 1972717
#! One of the most advanced approaches to querying data in the presence of ontologies is to make use of relational database systems, rewriting the original query and the ontology into a new query that is formulated in SQL or, equivalently, in first-order logic (FO). For ontologies written in many standard description logics (DLs), however, such FO-rewritings are not guaranteed to exist. We study FO-rewritings and their existence for a basic class of queries and for ontologies formulated in Horn DLs such as Horn-SHI and EL. Our results include characterizations of the existence of FO-rewritings, tight complexity bounds for deciding whether an FO-rewriting exists (EXPTIME and PSPACE), and tight bounds on the (worst-case) size of FO-rewritings, when presented as a union of conjunctive queries.

#index 2032939
#* Conjunctive regular path queries in lightweight description logics
#@ Meghyn Bienvenu;Magdalena Ortiz;Mantas Šimkus
#t 2013
#c 11
#% 268797
#% 384978
#% 992962
#% 1068354
#% 1269731
#% 1289408
#% 1305403
#% 1369574
#% 1405521
#% 1426443
#% 1497253
#% 1826229
#! Conjunctive regular path queries are an expressive extension of the well-known class of conjunctive queries and have been extensively studied in the database community. Somewhat surprisingly, there has been little work aimed at using such queries in the context of description logic (DL) knowledge bases, and all existing results target expressive DLs, even though lightweight DLs are considered better-suited for data-intensive applications. This paper aims to bridge this gap by providing algorithms and tight complexity bounds for answering two-way conjunctive regular path queries over DL knowledge bases formulated in lightweight DLs of the DL-Lite and EL families.

#index 2032940
#* Tractable queries for lightweight description logics
#@ Meghyn Bienvenu;Magdalena Ortiz;Mantas Šimkus;Guohui Xiao
#t 2013
#c 11
#% 263136
#% 273683
#% 342829
#% 464727
#% 992962
#% 993437
#% 1108111
#% 1111206
#% 1289408
#% 1305620
#% 1374374
#% 1589318
#! It is a classic result in database theory that conjunctive query (CQ) answering, which is NP-complete in general, is feasible in polynomial time when restricted to acyclic queries. Subsequent results identified more general structural properties of CQs (like bounded treewidth) which ensure tractable query evaluation. In this paper, we lift these tractability results to knowledge bases formulated in the lightweight description logics DL-Lite and ELH. The proof exploits known properties of query matches in these logics and involves a query-dependent modification of the data. To obtain a more practical approach, we propose a concrete polynomial-time algorithm for answering acyclic CQs based on rewriting queries into datalog programs. A preliminary evaluation suggests the interest of our approach for handling large acyclic CQs.

#index 2032941
#* Tractable approximations of consistent query answering for robust ontology-based data access
#@ Meghyn Bienvenu;Riccardo Rosati
#t 2013
#c 11
#% 33547
#% 181400
#% 204396
#% 273687
#% 992962
#% 1289408
#% 1369574
#% 1416180
#% 1500885
#% 1619627
#% 1826232
#% 1898008
#% 1919039
#% 1933364
#! A robust system for ontology-based data access should provide meaningful answers to queries even when the data conflicts with the ontology. This can be accomplished by adopting an inconsistency-tolerant semantics, with the consistent query answering (CQA) semantics being the most prominent example. Unfortunately, query answering under the CQA semantics has been shown to be computationally intractable, even when extremely simple ontology languages are considered. In this paper, we address this problem by proposing two new families of inconsistency-tolerant semantics which approximate the CQA semantics from above and from below and converge to it in the limit. We study the data complexity of conjunctive query answering under these new semantics, and show a general tractability result for all known first-order rewritable ontology languages. We also analyze the combined complexity of query answering for ontology languages of the DL-Lite family.

#index 2032942
#* The Markov assumption: formalization and impact
#@ Alexander Bochman
#t 2013
#c 11
#% 39262
#% 117869
#% 235089
#% 342119
#% 390685
#% 763743
#% 1014779
#% 1503505
#% 1872918
#! We provide both a semantic interpretation and logical (inferential) characterization of the Markov principle that underlies the main action theories in AI. This principle will be shown to constitute a nonmonotonic assumption that justifies the actual restrictions on action descriptions in these theories, as well as constraints on allowable queries. It will be shown also that the well-known regression principle is a consequence of the Markov assumption, and it is valid also for non-deterministic domains.

#index 2032943
#* Positive subsumption in fuzzy EL with general t-norms
#@ Stefan Borgwardt;Rafael Peñaloza
#t 2013
#c 11
#% 935898
#% 1271958
#% 1279259
#% 1289408
#% 1346742
#% 1346815
#% 1882393
#% 1910991
#% 1944522
#! The Description Logic EL is used to formulate several large biomedical ontologies. Fuzzy extensions of EL can express the vagueness inherent in many biomedical concepts. We study the reasoning problem of deciding positive subsumption in fuzzy EL with semantics based on general t-norms. We show that the complexity of this problem depends on the specific t-norm chosen. More precisely, if the t-norm has zero divisors, then the problem is co-NP-hard; otherwise, it can be decided in polynomial time. We also show that the best subsumption degree cannot be computed in polynomial time if the t-norm contains the Lukasiewicz t-norm.

#index 2032944
#* The impact of disjunction on query answering under guarded-based existential rules
#@ Pierre Bourhis;Michael Morak;Andreas Pieris
#t 2013
#c 11
#% 235018
#% 465053
#% 490909
#% 717498
#% 826032
#% 992962
#% 1020896
#% 1063724
#% 1106486
#% 1108111
#% 1279258
#% 1289408
#% 1369574
#% 1511857
#% 1585244
#% 1611372
#% 1808579
#% 1826177
#% 1826217
#% 1880450
#% 1888838
#% 1896219
#% 1919039
#% 1946304
#! We study the complexity of conjunctive query answering under (weakly-)(frontier-)guarded disjunctive existential rules, i.e., existential rules extended with disjunction, and their main subclasses, linear rules and inclusion dependencies (IDs). Our main result states that conjunctive query answering under a fixed set of disjunctive IDs is 2EXPTIME-hard. This quite surprising result together with a 2EXPTIME upper bound for weakly-frontier-guarded disjunctive rules, obtained by exploiting recent results on guarded negation first-order logic, gives us a complete picture of the computational complexity of our problem. We also consider a natural subclass of disjunctive IDs, namely frontier-one (only one variable is propagated), for which the combined complexity decreases to EXPTIME. Finally, we show that frontier-guarded rules, combined with negative constraints, are strictly more expressive than DL-LiteboolH, one of the most expressive languages of the DL-Lite family. We also show that query answering under DL-LiteboolH is 2EXPTIME- complete in combined complexity.

#index 2032945
#* Abstract dialectical frameworks revisited
#@ Gerhard Brewka;Stefan Ellmauthaler;Hannes Strass;Johannes Peter Wallner;Stefan Woltran
#t 2013
#c 11
#% 179921
#% 198464
#% 769616
#% 992259
#% 1193569
#% 1274813
#% 1473073
#% 1650564
#% 1664525
#% 1826241
#! We present various new concepts and results related to abstract dialectical frameworks (ADFs), a powerful generalization of Dung's argumentation frameworks (AFs). In particular, we show how the existing definitions of stable and preferred semantics which are restricted to the subcase of so-called bipolar ADFs can be improved and generalized to arbitrary frameworks. Furthermore, we introduce preference handling methods for ADFs, allowing for both reasoning with and about preferences. Finally, we present an implementation based on an encoding in answer set programming.

#index 2032946
#* Verification of inconsistency-aware knowledge and action bases
#@ Diego Calvanese;Evgeny Kharlamov;Marco Montali;Ario Santoso;Dmitriy Zheleznyakov
#t 2013
#c 11
#% 90860
#% 131559
#% 297770
#% 341697
#% 743353
#% 826032
#% 879041
#% 942360
#% 992962
#% 1077467
#% 1179996
#% 1180017
#% 1263032
#% 1274795
#% 1416180
#% 1500885
#% 1540299
#% 1933374
#% 1943547
#% 1972715
#! Description Logic Knowledge and Action Bases (KABs) have been recently introduced as a mechanism that provides a semantically rich representation of the information on the domain of interest in terms of a DL KB and a set of actions to change such information over time, possibly introducing new objects. In this setting, decidability of verification of sophisticated temporal properties over KABs, expressed in a variant of first-order µ-calculus, has been shown. However, the established framework treats inconsistency in a simplistic way, by rejecting inconsistent states produced through action execution. We address this problem by showing how inconsistency handling based on the notion of repairs can be integrated into KABs, resorting to inconsistency-tolerant semantics. In this setting, we establish decidability and complexity of verification.

#index 2032947
#* Automated reasoning to infer all minimal keys
#@ P. Cordero;M. Enciso;A. Mora
#t 2013
#c 11
#% 318904
#% 341247
#% 893145
#% 1320104
#% 1468027
#% 1583971
#! Wastl introduced for first time a tableaux-like method based on an inference system for deriving all minimal keys from a relational schema. He introduced two inference rules and built an automated method over them. In this work we tackle the key finding problem with a tableaux method, but we will use two inference rules inspired by the Simplification Logic for Functional Dependencies. Wastl's method requires the input to be a set of functional dependencies (FDs) with atomic right hand sides. Therefore, it is necessary to apply fragmentation rule with the consequent increasing of the input. The main novelty of our rules is that they deal with generalized formulas, avoiding the fragmentation needed in the former tableaux. Finally we illustrate the advantages of our new tableaux method with an experiment.

#index 2032948
#* Do hard SAT-related reasoning tasks become easier in the Krom fragment?
#@ Nadia Creignou;Reinhard Pichler;Stefan Woltran
#t 2013
#c 11
#% 42986
#% 118359
#% 131559
#% 181220
#% 251197
#% 333326
#% 414936
#% 566559
#% 600496
#% 870223
#% 1053890
#% 1172187
#% 1207910
#% 1348502
#% 1428634
#% 1876052
#! Many AI-related reasoning problems are based on the problem of satisfiability (SAT). While SAT itself becomes easy when restricting the structure of the formulas in a certain way, this is not guaranteed for more involved reasoning problems. In this work, we focus on reasoning tasks in the areas of belief revision and logic-based abduction and show that in some cases the restriction to Krom formulas (i.e., formulas in CNF where clauses have at most two literals) decreases the complexity, while in others it does not. We thus also consider additional restrictions to Krom formulas towards a better identification of the tractability frontier of such problems.

#index 2032949
#* Computing datalog rewritings beyond horn ontologies
#@ Bernardo Cuenca Grau;Boris Motik;Giorgos Stoilos;Ian Horrocks
#t 2013
#c 11
#% 29980
#% 194120
#% 204396
#% 577305
#% 665856
#% 992962
#% 992964
#% 1108111
#% 1206804
#% 1269632
#% 1272202
#% 1289408
#% 1289425
#% 1291345
#% 1369574
#% 1405521
#% 1605087
#% 1615741
#% 1826229
#% 1972717
#! Rewriting-based approaches for answering queries over an OWL 2 DL ontology have so far been developed mainly for Horn fragments of OWL 2 DL. In this paper, we study the possibilities of answering queries over non-Horn ontologies using datalog rewritings. We prove that this is impossible in general even for very simple ontology languages, and even if PTIME = NP. Furthermore, we present a resolution-based procedure for SHI ontologies that, in case it terminates, produces a datalog rewriting of the ontology. We also show that our procedure necessarily terminates on DL-LiteboolH,+ ontologies--an extension of OWL 2 QL with transitive roles and Boolean connectives.

#index 2032950
#* Sequences of mechanisms for causal reasoning in artificial intelligence
#@ Denver Dash;Mark Voortman;Martijn De Jongh
#t 2013
#c 11
#% 297171
#% 1000502
#% 1279089
#% 1495935
#% 1650516
#! We present a new approach to token-level causal reasoning that we call Sequences Of Mechanisms (SoMs), which models causality as a dynamic sequence of active mechanisms that chain together to propagate causal influence through time. We motivate this approach by using examples from AI and robotics and show why existing approaches are inadequate. We present an algorithm for causal reasoning based on SoMs, which takes as input a knowledge base of first-order mechanisms and a set of observations, and it hypothesizes which mechanisms are active at what time. We show empirically that our algorithm produces plausible causal explanations of simulated observations generated from a causal model. We argue that the SoMs approach is qualitatively closer to the human causal reasoning process, for example, it will only include relevant variables in explanations. We present new insights about causal reasoning that become apparent with this view. One such insight is that observation and manipulation do not commute in causal models, a fact which we show to be a generalization of the Equilibration-Manipulation Commutability of [Dash(2005)].

#index 2032951
#* Bounded epistemic situation calculus theories
#@ Giuseppe De Giacomo;Yves Lespérance;Fabio Patrizi
#t 2013
#c 11
#% 284644
#% 326595
#% 341697
#% 342119
#% 384978
#% 572366
#% 1060757
#% 1313373
#% 1476290
#% 1478696
#! We define the class of e-bounded theories in the epistemic situation calculus, where the number of fluent atoms that the agent thinks may be true is bounded by a constant. Such theories can still have an infinite domain and an infinite set of states. We show that for them verification of an expressive class of first-order µ-calculus temporal epistemic properties is decidable. We also show that if the agent's knowledge in the initial situation is e-bounded and the objective part of an action theory maintains boundedness, then the entire epistemic theory is e-bounded.

#index 2032952
#* Linear temporal logic and linear dynamic logic on finite traces
#@ Giuseppe De Giacomo;Moshe Y. Vardi
#t 2013
#c 11
#% 1729
#% 65904
#% 167629
#% 188086
#% 215675
#% 241166
#% 289287
#% 296170
#% 342119
#% 390685
#% 392116
#% 399031
#% 404772
#% 427162
#% 502889
#% 544938
#% 555393
#% 836138
#% 930640
#% 1060757
#% 1068329
#% 1393502
#% 1476301
#% 1529778
#% 1565895
#% 1693699
#% 1826382
#! In this paper we look into the assumption of interpreting LTL over finite traces. In particular we show that LTLf, i.e., LTL under this assumption, is less expressive than what might appear at first sight, and that at essentially no computational cost one can make a significant increase in expressiveness while maintaining the same intuitiveness of LTLf. Indeed, we propose a logic, LDLf for Linear Dynamic Logic over finite traces, which borrows the syntax from Propositional Dynamic Logic (PDL), but is interpreted over finite traces. Satisfiability, validity and logical implication (as well as model checking) for LTLf. are PSPACE-complete as for LTLf. (and LTL).

#index 2032953
#* A formal account of nondeterministic and failed actions
#@ James P. Delgrande;Hector J. Levesque
#t 2013
#c 11
#% 39262
#% 179940
#% 224753
#% 236024
#% 284644
#% 322911
#% 341622
#% 342119
#% 529345
#% 572366
#% 655322
#% 763743
#% 1068305
#% 1272572
#% 1290157
#% 1416205
#% 1503508
#! Nondeterminism is pervasive in all but the simplest action domains: an agent may flip a coin or pick up a different object than intended, or an action may fail and may fail in different ways. In this paper we provide a qualitative theory of nondeterminism. The account is based on an epistemic extension to the situation calculus that accommodates sensing actions. Our position is that nondeterminism is an epistemic phenomenon, and that the world is most usefully regarded as deterministic. Nondeterminism arises from an agent's limited awareness and perception. The account offers several advantages: an agent has a set of categorical (as opposed to probabilistic) beliefs, yet can deal with equally-likely outcomes (such as in flipping a fair coin) or with outcomes of differing plausibility (such as an action that may on rare occasion fail).

#index 2032954
#* Data repair of inconsistent DL-programs
#@ Thomas Eiter;Michael Fink;Daria Stepanova
#t 2013
#c 11
#% 752737
#% 935898
#% 992962
#% 1065897
#% 1197942
#% 1289365
#% 1384952
#% 1466301
#% 1500885
#% 1513035
#% 1737594
#% 1826236
#% 1898008
#% 1925309
#! Nonmonotonic Description Logic (DL) programs support rule-based reasoning on top of Description Logic ontologies, using a well-defined query interface. However, the interaction of the rules and the ontology may cause inconsistency such that no answer set (i.e. model) exists. We thus consider repairing DL-programs, i.e., changing formulas to obtain consistency. Viewing the data part of the ontology as the source of inconsistency, we define program repairs and repair answer sets based on changes to it. We analyze the complexity of the notion, and we extend an algorithm for evaluating DL-programs to compute repair answer sets, under optional selection of preferred repairs. The extension involves a generalized ontology repair problem, in which the entailment and non-entailment of sets of queries with updates to the ontology must be achieved. While this is intractable in general, we identify for the Description Logic DL-LiteA some tractable classes of preferred repairs that are useful in practice.

#index 2032955
#* Towards a knowledge compilation map for heterogeneous representation languages
#@ Hélène Fargier;Pierre Marquis;Alexandre Niveau
#t 2013
#c 11
#% 3873
#% 86950
#% 189738
#% 430722
#% 534644
#% 743359
#% 928731
#% 1215046
#% 1270089
#% 1272349
#% 1274809
#% 1275338
#% 1305412
#% 1313373
#% 1473289
#% 1965192
#! The knowledge compilation map introduced by Darwiche and Marquis takes advantage of a number of concepts (mainly queries, transformations, expressiveness, and succinctness) to compare the relative adequacy of representation languages to some AI problems. However, the framework is limited to the comparison of languages that are interpreted in a homogeneous way (formulæ are interpreted as Boolean functions). This prevents one from comparing, on a formal basis, languages that are close in essence, such as OBDD, MDD, and ADD. To fill the gap, we present a generalized framework into which comparing formally heterogeneous representation languages becomes feasible. In particular, we explain how the key notions of queries and transformations, expressiveness, and succinctness can be lifted to the generalized setting.

#index 2032956
#* Semiring labelled decision diagrams, revisited: canonicity and spatial efficiency issues
#@ Hélène Fargier;Pierre Marquis;Nicolas Schmidt
#t 2013
#c 11
#% 451
#% 134014
#% 233849
#% 345434
#% 430718
#% 442515
#% 751442
#% 1272349
#% 1275309
#% 1275338
#% 1289403
#% 1289570
#% 1826194
#! Existing languages in the valued decision diagrams (VDDs) family, including ADD, AADD, and those of the SLDD family, prove to be valuable target languages for compiling multivariate functions. However, their efficiency is directly related to the size of the compiled formulae. In practice, the existence of canonical forms may have a major impact on the size of the compiled VDDs. While efficient normalization procedures have been pointed out for ADD and AADD the canonicity issue for SLDD formulae has not been addressed so far. In this paper, the SLDD family is revisited. We modify the algebraic requirements imposed on the valuation structure so as to ensure tractable conditioning, optimization and normalization for some languages of the revisited SLDD family. We show that AADD is captured by this family. Finally, we compare the spatial efficiency of some languages of this family, from both the theoretical side and the practical side.

#index 2032957
#* FQHT: the logic of stable models for logic programs with intensional functions
#@ Luis Fariñas Del Cerro;David Pearce;Agustín Valverde
#t 2013
#c 11
#% 763743
#% 1171785
#% 1274811
#% 1388133
#% 1568279
#% 1891650
#% 1891665
#! We study a logical system FQHT that is appropriate for reasoning about nonmonotonic theories with intensional functions as treated in the approach of [Bartholomew and Lee, 2012]. We provide a logical semantics, a Gentzen style proof theory and establish completeness results. The adequacy of the approach is demonstrated by showing that it captures the Bartholemew/Lee semantics and satisfies a strong equivalence property.

#index 2032958
#* On the complexity of probabilistic abstract argumentation
#@ Bettina Fazzinga;Sergio Flesca;Francesco Parisi
#t 2013
#c 11
#% 198464
#% 417812
#% 844093
#% 992249
#% 992250
#% 1045998
#% 1060767
#% 1069661
#% 1193569
#% 1221649
#% 1247945
#% 1291495
#% 1292077
#% 1473086
#% 1473088
#% 1526846
#% 1722984
#% 1791081
#% 1921500
#! Probabilistic abstract argumentation combines Dung's abstract argumentation framework with probability theory in order to model uncertainty in argumentation. In this setting, we address the fundamental problem of computing the probability that a set of arguments is an extension according to a given semantics. We focus on the most popular semantics (i.e., admissible, stable, complete, grounded, preferred, ideal), and show the following dichotomy result: computing the probability that a set of arguments is an extension is either PTIME or FP#P -complete depending on the semantics adopted. Our PTIME results are particularly interesting, as they hold for some semantics for which no polynomial-time technique was known so far.

#index 2032959
#* Representation and reasoning about general solid rectangles
#@ Xiaoyu Ge;Jochen Renz
#t 2013
#c 11
#% 109857
#% 257637
#% 319244
#% 329895
#% 400979
#% 527331
#% 736898
#% 950561
#% 1273793
#% 1274583
#! Entities in two-dimensional space are often approximated using rectangles that are parallel to the two axes that define the space, so-called minimum-bounding rectangles (MBRs). MBRs are popular in Computer Vision and other areas as they are easy to obtain and easy to represent. In the area of Qualitative Spatial Reasoning, many different spatial representations are based on MBRs. Surprisingly, there has been no such representation proposed for general rectangles, i.e., rectangles that can have any angle, nor for general solid rectangles (GSRs) that cannot penetrate each other. GSRs are often used in computer graphics and computer games, such as Angry Birds, where they form the building blocks of more complicated structures. In order to represent and reason about these structures, we need a spatial representation that allows us to use GSRs as the basic spatial entities. In this paper we develop and analyze a qualitative spatial representation for GSRs. We apply our representation and the corresponding reasoning methods to solve a very interesting practical problem: Assuming we want to detect GSRs in computer games, but computer vision can only detect MBRs. How can we infer the GSRs from the given MBRs? We evaluate our solution and test its usefulness in a real gaming scenario.

#index 2032960
#* Advanced conflict-driven disjunctive answer set solving
#@ Martin Gebser;Benjamin Kaufmann;Torsten Schaub
#t 2013
#c 11
#% 231786
#% 274131
#% 411814
#% 427631
#% 736900
#% 855344
#% 880394
#% 1171772
#% 1346090
#% 1495941
#% 1503507
#% 1568283
#% 1623076
#% 1656432
#% 1726939
#% 1765808
#% 1783877
#% 1946295
#! We introduce a new approach to disjunctive ASP solving that aims at an equitable interplay between "generating" and "testing" solver units. To this end, we develop novel characterizations of answer sets and unfounded sets allowing for a bidirectional dynamic information exchange between solver units for orthogonal tasks. This results in the new multithreaded disjunctive ASP solver claspD-2, greatly improving the performance of existing systems.

#index 2032961
#* A strongly-local contextual logic
#@ Michael James Gratton
#t 2013
#c 11
#% 28185
#% 127670
#% 160385
#% 411814
#% 478073
#% 757481
#% 1273614
#% 1388294
#% 1495927
#% 1499554
#! A novel contextual logic is presented that combines features of both multi-context systems and logics of context. Broadly, contextual logics are those with a formal notion of context -- knowledge that is true only under specific assumptions. Multicontext systems use discrete logistic systems as individual contexts, related by meta-level rules, whereas logics of context partition a single knowledge base into contexts, related using object-level rules. The contextual logic presented here is strongly-local, in that knowledge and inference is discrete for individual contexts, but which are nevertheless part of a single logistic system that relates contexts at the object-level, so combining advantages of both. A deductive system of contextual inference and a possible-worlds based semantics is given, with formal results including soundness and completeness, and a number of properties are examined.

#index 2032962
#* Bounded programs: a new decidable class of logic programs with function symbols
#@ Sergio Greco;Cristian Molinaro;Irina Trubitsyna
#t 2013
#c 11
#% 101623
#% 297306
#% 486729
#% 497258
#% 763752
#% 807235
#% 936970
#% 1046414
#% 1105169
#% 1171786
#% 1184224
#% 1256410
#% 1265347
#% 1378920
#% 1388140
#% 1466291
#% 1466299
#% 1655201
#% 1697797
#% 1943971
#! While function symbols are widely acknowledged as an important feature in logic programming, they make common inference tasks undecidable. To cope with this problem, recent research has focused on identifying classes of logic programs imposing restrictions on the use of function symbols, but guaranteeing decidability of common inference tasks. This has led to several criteria, called termination criteria, providing sufficient conditions for a program to have finitely many stable models, each of finite size. This paper introduces the new class of bounded programs which guarantees the aforementioned property and strictly includes the classes of programs determined by current termination criteria. Different results on the correctness, the expressiveness, and the complexity of the class of bounded programs are presented.

#index 2032963
#* Iterated boolean games
#@ Julian Gutierrez;Paul Harrenstein;Michael Wooldridge
#t 2013
#c 11
#% 1729
#% 2659
#% 45530
#% 65904
#% 101943
#% 101955
#% 114677
#% 190683
#% 489953
#% 509839
#% 781219
#% 1083988
#% 1108451
#% 1111213
#% 1195119
#% 1202783
#% 1666376
#% 1680802
#% 1736448
#% 1826098
#! Iterated games are well-known in the game theory literature. We study iterated Boolean games. These are games in which players repeatedly choose truth values for Boolean variables they have control over. Our model of iterated Boolean games assumes that players have goals given by formulae of Linear Temporal Logic (LTL), a formalism for expressing properties of state sequences. In order to model the strategies that players use in such games, we use a finite state machine model. After introducing and formally defining iterated Boolean games, we investigate the computational complexity of their associated game-theoretic decision problems as well as semantic conditions characterising classes of LTL properties that are preserved by pure strategy Nash equilibria whenever they exist.

#index 2032964
#* Implicit learning of common sense for reasoning
#@ Brendan Juba
#t 2013
#c 11
#% 25242
#% 89958
#% 178511
#% 198055
#% 203292
#% 214108
#% 239245
#% 274131
#% 284107
#% 288165
#% 296858
#% 327779
#% 345059
#% 427631
#% 451055
#% 656686
#% 807911
#% 850430
#% 1139045
#% 1250405
#% 1272049
#% 1290050
#% 1305534
#% 1416204
#% 1427868
#% 1478761
#% 1526848
#% 1602943
#% 1663918
#! We consider the problem of how enormous databases of "common sense" knowledge can be both learned and utilized in reasoning in a computationally efficient manner. We propose that this is possible if the learning only occurs implicitly, i.e., without generating an explicit representation. We show that it is feasible to invoke such implicitly learned knowledge in essentially all natural tractable reasoning problems. This implicit learning also turns out to be provably robust to occasional counterexamples, as appropriate for such common sense knowledge.

#index 2032965
#* Knowledge compilation for model counting: affine decision trees
#@ Frédéric Koriche;Jean-Marie Lagniez;Pierre Marquis;Samuel Thomas
#t 2013
#c 11
#% 3873
#% 205391
#% 336874
#% 342378
#% 420743
#% 442363
#% 600496
#% 723877
#% 724946
#% 1196918
#% 1223541
#% 1230624
#% 1269433
#% 1269749
#% 1270089
#% 1270101
#% 1272251
#% 1272349
#% 1499541
#% 1655473
#% 1826194
#% 1826222
#% 1882412
#% 1894768
#! Counting the models of a propositional formula is a key issue for a number of AI problems, but few propositional languages offer the possibility to count models efficiently. In order to fill the gap, we introduce the language EADT of (extended) affine decision trees. An extended affine decision tree simply is a tree with affine decision nodes and some specific decomposable conjunction or disjunction nodes. Unlike standard decision trees, the decision nodes of an EADT formula are not labeled by variables but by affine clauses. We study EADT, and several subsets of it along the lines of the knowledge compilation map. We also describe a CNF-to-EADT compiler and present some experimental results. Those results show that the EADT compilation-based approach is competitive with (and in some cases is able to outperform) the model counter Cachet and the d-DNNF compilation-based approach to model counting.

#index 2032966
#* Parameterized complexity of optimal planning: a detailed map
#@ Martin Kronegger;Andreas Pfandler;Reinhard Pichler
#t 2013
#c 11
#% 110377
#% 167629
#% 735461
#% 857282
#% 1250634
#% 1272207
#% 1272220
#% 1428632
#% 1972413
#! The goal of this paper is a systematic parameterized complexity analysis of different variants of propositional STRIPS planning. We identify several natural problem parameters and study all possible combinations of 9 parameters in 6 different settings. These settings arise, for instance, from the distinction if negative effects of actions are allowed or not. We provide a complete picture by establishing for each case either paraNP-hardness (i.e., the parameter combination does not help) or W[t]-completeness with t ∈ {1, 2} (i.e., fixed-parameter intractability), or FPT (i.e., fixed-parameter tractability).

#index 2032967
#* Syntactic labelled tableaux for Łukasiewicz fuzzy ALC
#@ Agnieszka Kułacka;Dirk Pattinson;Lutz Schröder
#t 2013
#c 11
#% 259392
#% 565833
#% 1136065
#% 1187840
#% 1271958
#% 1272188
#% 1346815
#% 1503331
#% 1560584
#% 1826187
#% 1826235
#% 1944522
#! Fuzzy description logics (DLs) serve as a tool to handle vagueness in real-world knowledge. There is particular interest in logics implementing Łukasiewicz semantics, which has a number of favourable properties. Current decision procedures for Łukasiewicz fuzzy DLs work by reduction to exponentially large mixed integer programming problems. Here, we present a decision method that stays closer to logical syntax, a labelled tableau algorithm for Łukasiewicz Fuzzy ALC that calls only on (pure) linear programming, and this only to decide atomic clashes. The algorithm realizes the best known complexity bound, NEXPTIME. Our language features a novel style of fuzzy ABoxes that work with comparisons of truth degrees rather than explicit numerical bounds.

#index 2032968
#* Decidable reasoning in a logic of limited belief with introspection and unknown individuals
#@ Gerhard Lakemeyer;Hector J. Levesque
#t 2013
#c 11
#% 400
#% 36815
#% 116625
#% 123214
#% 211584
#% 371172
#% 780334
#% 782395
#% 1274706
#% 1826195
#! There are not very many existing logics of belief which have both a perspicuous semantics and are computationally attractive. An exception is the logic SL, proposed by Liu, Lakemeyer, and Levesque, which allows for a decidable and often even tractable form of reasoning. While the language is first-order and hence quite expressive, it still has a number of shortcomings. For one, beliefs about beliefs are not addressed at all. For another, the names of individuals are rigid, that is, their identity is assumed to be known. In this paper, we show how both shortcomings can be overcome by suitably extending the language and its semantics. Among other things, we show that determining the beliefs of a certain kind of fully introspective knowledge bases is decidable and that unknown individuals in the knowledge base can be accommodated in a decidable manner as well.

#index 2032969
#* StarVars: effective reasoning about relative directions
#@ Jae Hee Lee;Jochen Renz;Diedrich Wolter
#t 2013
#c 11
#% 13742
#% 549078
#% 1027260
#% 1110283
#% 1223270
#% 1483054
#% 1714119
#! Relative direction information is very commonly used. Observers typically describe their environment by specifying the relative directions in which they see other objects or other people from their point of view. Or they receive navigation instructions with respect to their point of view, for example, turn left at the next intersection. However, it is surprisingly hard to integrate relative direction information obtained from different observers, and to reconstruct a model of the environment or the locations of the observers based on this information. Despite intensive research, there is currently no algorithm that can effectively integrate this information: this problem is NP-hard, but not known to be in NP, even if we only use left and right relations. In this paper we present a novel qualitative representation, StarVars, that can solve these problems. It is an extension of the STAR calculus [Renz and Mitra, 2004]) by a VARiable interpretation of the orientation of observers. We show that reasoning in StarVars is in NP and present the first algorithm that allows us to effectively integrate relative direction information from different observers.

#index 2032970
#* Action language BC: preliminary report
#@ Joohyung Lee;Vladimir Lifschitz;Fangkai Yang
#t 2013
#c 11
#% 100159
#% 258787
#% 266241
#% 340738
#% 417649
#% 417651
#% 476419
#% 752742
#% 763743
#% 790727
#% 1269834
#% 1270359
#% 1478800
#% 1503511
#% 1880206
#! The action description languages B and C have significant common core. Nevertheless, some expressive possibilities of B are difficult or impossible to simulate in C, and the other way around. The main advantage of B is that it allows the user to give Prolog-style recursive definitions, which is important in applications. On the other hand, B solves the frame problem by incorporating the commonsense law of inertia in its semantics, which makes it difficult to talk about fluents whose behavior is described by defaults other than inertia. In C and in its extension C+, the inertia assumption is expressed by axioms that the user is free to include or not to include, and other defaults can be postulated as well. This paper defines a new action description language, called BC, that combines the attractive features of B and C+. Examples of formalizing commonsense domains discussed in the paper illustrate the expressive capabilities of BC and the use of answer set solvers for the automation of reasoning about actions described in this language.

#index 2032971
#* Answer set programming modulo theories and reasoning about continuous changes
#@ Joohyung Lee;Yunsong Meng
#t 2013
#c 11
#% 763743
#% 1197949
#% 1257225
#% 1270359
#% 1272008
#% 1272127
#% 1279366
#% 1291413
#% 1503511
#% 1568279
#% 1624824
#% 1891650
#% 1891685
#% 1911348
#! Answer Set Programming Modulo Theories is a new framework of tight integration of answer set programming (ASP) and satisfiability modulo theories (SMT). Similar to the relationship between first-order logic and SMT, it is based on a recent proposal of the functional stable model semantics by fixing interpretations of background theories. Analogously to a known relationship between ASP and SAT, "tight" ASPMT programs can be translated into SMT instances. We demonstrate the usefulness of ASPMT by enhancing action language C+ to handle continuous changes as well as discrete changes. We reformulate the semantics of C+ in terms of ASPMT, and show that SMT solvers can be used to compute the language. We also show how the language can represent cumulative effects on continuous resources.

#index 2032972
#* Reasoning about state constraints in the situation calculus
#@ Naiqi Li;Yi Fan;Yongmei Liu
#t 2013
#c 11
#% 131357
#% 266388
#% 342119
#% 529658
#% 1029047
#% 1442142
#% 1545439
#! In dynamic systems, state constraints are formulas that hold in every reachable state. It has been shown that state constraints can be used to greatly reduce the planning search space. They are also useful in program verification. In this paper, we propose a sound but incomplete method for automatic verification and discovery of ∀*∃* state constraints for a class of action theories that include many planning benchmarks. Our method is formulated in the situation calculus, theoretically based on Skolemization and Herbrand Theorem, and implemented with SAT solvers. Basically, we verify a state constraint by strengthening it in a novel and smart way so that it becomes a state invariant. We experimented with the blocks world, logistics and satellite domains, and the results showed that, almost all known state constraints can be verified in a reasonable amount of time, and meanwhile succinct and intuitive related state constraints are discovered.

#index 2032973
#* Analogico-deductive generation of Gödel's first incompleteness theorem from the liar paradox
#@ John Licato;Naveen Sundar Govindarajulu,;Selmer Bringsjord;Michael Pomeranz;Logan Gittelson
#t 2013
#c 11
#! Gödel's proof of his famous first incompleteness theorem (G1) has quite understandably long been a tantalizing target for those wanting to engineer impressively intelligent computational systems. After all, in establishing G1, Gödel did something that by any metric must be classified as stunningly intelligent. We observe that it has long been understood that there is some sort of analogical relationship between the Liar Paradox (LP) and G1, and that Gödel himself appreciated and exploited the relationship. Yet the exact nature of the relationship has hitherto not been uncovered, by which we mean that the following question has not been answered: Given a description of LP, and the suspicion that it may somehow be used by a suitably programmed computing machine to find a proof of the incompleteness of Peano Arithmetic, can such a machine, provided this description as input, produce as output a complete and verifiably correct proof of G1? In this paper, we summarize engineering that entails an affirmative answer to this question. Our approach uses what we call analogico-deductive reasoning (ADR), which combines analogical and deductive reasoning to produce a full deductive proof of G1 from LP. Our engineering uses a form of ADR based on our META-R system, and a connection between the Liar Sentence in LP and Gödel's Fixed Point Lemma, from which G1 follows quickly.

#index 2032974
#* An epistemic Halpern-Shoham logic
#@ Alessio R. Lomuscio;Jakub Michaliszyn
#t 2013
#c 11
#% 102358
#% 116625
#% 188086
#% 196708
#% 205239
#% 297770
#% 319244
#% 690951
#% 1014781
#% 1305404
#% 1638626
#% 1645995
#% 1734845
#% 1826198
#! We define a family of epistemic extensions of Halpern-Shoham logic for reasoning about temporal-epistemic properties of multi-agent systems. We exemplify their use and study the complexity of their model checking problem. We show a range of results ranging from PTIME to PSPACE-hard depending on the logic considered.

#index 2032975
#* Preference-based query answering in datalog+/- ontologies
#@ Thomas Lukasiewicz;Maria Vanina Martinez;Gerardo I. Simari
#t 2013
#c 11
#% 331835
#% 465167
#% 490909
#% 566111
#% 731407
#% 1590539
#% 1594608
#% 1661567
#% 1808579
#! The study of preferences has a long tradition in many disciplines, but it has only relatively recently entered the realm of data management through their application in answering queries to relational databases. The current revolution in data availability through the Web and, perhaps most importantly in the last few years, social media sites and applications, puts ontology languages at the forefront of data and information management technologies. In this paper, we propose the first (to our knowledge) integration of ontology languages with preferences as in relational databases by developing PrefDatalog+/-, an extension of the Datalog+/- family of languages with preference management formalisms closely related to those previously studied for relational databases. We focus on two kinds of answers to queries that are relevant to this setting, skyline and k-rank (a generalization of top-k queries), and develop algorithms for computing these answers to both DAQs (disjunctions of atomic queries) and CQs (conjunctive queries). We show that DAQ answering in PrefDatalog+/- can be done in polynomial time in the data complexity, as in relational databases, as long as query answering can also be done in polynomial time (in the data complexity) in the underlying classical ontology.

#index 2032976
#* Ontology-based data access with closed predicates is inherently intractable (sometimes)
#@ Carsten Lutz;İnanç Seylan;Frank Wolter
#t 2013
#c 11
#% 130784
#% 162224
#% 344506
#% 384978
#% 665856
#% 762611
#% 992962
#% 992964
#% 1111191
#% 1201361
#% 1274795
#% 1289408
#% 1305436
#% 1305620
#% 1369574
#% 1384952
#% 1597283
#% 1597490
#% 1631625
#% 1641516
#% 1808579
#! When answering queries in the presence of ontologies, adopting the closed world assumption for some predicates easily results in intractability. We analyze this situation on the level of individual ontologies formulated in the description logics DL-Lite and EL and show that in all cases where answering conjunctive queries (CQs) with (open and) closed predicates is tractable, it coincides with answering CQs with all predicates assumed open. In this sense, CQ answering with closed predicates is inherently intractable. Our analysis also yields a dichotomy between AC0 and CONP for CQ answering w.r.t. ontologies formulated in DL-Lite and a dichotomy between PTIME and CONP for EL. Interestingly, the situation is less dramatic in the more expressive description logic ELI, where we find ontologies for which CQ answering is in PTIME, but does not coincide with CQ answering where all predicates are open.

#index 2032977
#* Computing stable models for nonmonotonic existential rules
#@ Despoina Magka;Markus Krötzsch;Ian Horrocks
#t 2013
#c 11
#% 58574
#% 86715
#% 94456
#% 176471
#% 332915
#% 497258
#% 826032
#% 880394
#% 1063724
#% 1217122
#% 1231842
#% 1300982
#% 1384952
#% 1585244
#% 1619619
#% 1791176
#% 1826217
#% 1876875
#% 1907922
#% 1919039
#! In this work, we consider function-free existential rules extended with nonmonotonic negation under a stable model semantics. We present new acyclicity and stratification conditions that identify a large class of rule sets having finite, unique stable models, and we show how the addition of constraints on the input facts can further extend this class. Checking these conditions is computationally feasible, and we provide tight complexity bounds. Finally, we demonstrate how these new methods allowed us to solve relevant reasoning problems over a real-world knowledge base from biochemistry using an off-the-shelf answer set programming engine.

#index 2032978
#* The route to success: a performance comparison of diagnosis algorithms
#@ Iulia Nica;Ingo Pill;Thomas Quaritsch;Franz Wotawa
#t 2013
#c 11
#% 3460
#% 21137
#% 21138
#% 49315
#% 65347
#% 132062
#% 334203
#% 338611
#% 979225
#% 1139191
#% 1230618
#% 1250145
#% 1273478
#% 1279269
#% 1290122
#% 1474210
#% 1478737
#% 1545036
#% 1826237
#! Diagnosis, i.e., the identification of root causes for failing or unexpected system behavior, is an important task in practice. Within the last three decades, many different AI-based solutions for solving the diagnosis problem have been presented and have been gaining in attraction. This leaves us with the question of which algorithm to prefer in a certain situation. In this paper we contribute to answering this question. In particular, we compare two classes of diagnosis algorithms. One class exploits conflicts in their search, i.e., sets of system components whose correct behavior contradicts given observations. The other class ignores conflicts and derives diagnoses from observations and the underlying model directly. In our study we use different reasoning engines ranging from an optimized Horn-clause theorem prover to general SAT and constraint solvers. Thus we also address the question whether publicly available general reasoning engines can be used for an efficient diagnosis.

#index 2032979
#* Backdoors to abduction
#@ Andreas Pfandler;Stefan Rümmele;Stefan Szeider
#t 2013
#c 11
#% 181220
#% 234823
#% 529173
#% 724872
#% 735461
#% 857282
#% 1053890
#% 1171090
#% 1263089
#% 1279379
#% 1300360
#% 1399077
#% 1464357
#% 1477123
#% 1608501
#% 1768050
#% 1826201
#% 1876130
#% 1888379
#% 1972413
#% 1985061
#! Abductive reasoning (or Abduction, for short) is among the most fundamental AI reasoning methods, with a broad range of applications, including fault diagnosis, belief revision, and automated planning. Unfortunately, Abduction is of high computational complexity; even propositional Abduction is Σ2P-complete and thus harder than NP and co-NP. This complexity barrier rules out the existence of a polynomial transformation to propositional satisfiability (SAT). In this work we use structural properties of the Abduction instance to break this complexity barrier. We utilize the problem structure in terms of small backdoor sets. We present fixed-parameter tractable transformations from Abduction to SAT, which make the power of today's SAT solvers available to Abduction.

#index 2032980
#* Behavioral diagnosis of LTL specifications at operator level
#@ Ingo Pill;Thomas Quaritsch
#t 2013
#c 11
#% 21137
#% 21138
#% 65347
#% 500082
#% 510375
#% 541772
#% 541931
#% 543494
#% 878846
#% 1068329
#% 1195928
#% 1230260
#% 1273478
#% 1397986
#% 1415274
#% 1718207
#% 1728105
#% 1748301
#% 1785224
#! Product defects and rework efforts due to flawed specifications represent major issues for a project's performance, so that there is a high motivation for providing effective means that assist designers in assessing and ensuring a specification's quality. Recent research in the context of formal specifications, e.g. on coverage and vacuity, offers important means to tackle related issues. In the currently underrepresented research direction of diagnostic reasoning on a specification, we propose a scenario-based diagnosis at a specification's operator level using weak or strong fault models. Drawing on efficient SAT encodings, we show in this paper how to achieve that effectively for specifications in LTL. Our experimental results illustrate our approach's validity and attractiveness.

#index 2032981
#* Cyclic causal models with discrete variables: Markov Chain equilibrium semantics and sample ordering
#@ David Poole;Mark Crowley
#t 2013
#c 11
#% 75936
#% 163717
#% 722754
#% 961268
#% 1152376
#% 1271811
#% 1271819
#% 1289741
#% 1416201
#% 1417108
#% 1650683
#% 1650803
#% 1650807
#! We analyze the foundations of cyclic causal models for discrete variables, and compare structural equation models (SEMs) to an alternative semantics as the equilibrium (stationary) distribution of a Markov chain. We show under general conditions, discrete cyclic SEMs cannot have independent noise; even in the simplest case, cyclic structural equation models imply constraints on the noise. We give a formalization of an alternative Markov chain equilibrium semantics which requires not only the causal graph, but also a sample order. We show how the resulting equilibrium is a function of the sample ordering, both theoretically and empirically.

#index 2032982
#* Learning from polyhedral sets
#@ Salvatore Ruggieri
#t 2013
#c 11
#% 13742
#% 55104
#% 115193
#% 121391
#% 253240
#% 743416
#% 1167498
#% 1707011
#% 1910913
#! Parameterized linear systems allow for modelling and reasoning over classes of polyhedra. Collections of squares, rectangles, polytopes, and so on, can readily be defined by means of linear systems with parameters. In this paper, we investigate the problem of learning a parameterized linear system whose class of polyhedra includes a given set of example polyhedral sets and it is minimal.

#index 2032983
#* Efficient extraction and representation of spatial information from video data
#@ Hajar Sadeghi Sokeh;Stephen Gould;Jochen Renz
#t 2013
#c 11
#% 197394
#% 722904
#% 736300
#% 812535
#% 1066707
#% 1622248
#% 1750454
#% 1884267
#% 1942231
#! Vast amounts of video data are available on the web and are being generated daily using surveillance cameras or other sources. Being able to efficiently analyse and process this data is essential for a number of different applications. We want to be able to efficiently detect activities in these videos or be able to extract and store essential information contained in these videos for future use and easy search and access. Cohn et al. (2012) proposed a comprehensive representation of spatial features that can be efficiently extracted from video and used for these purposes. In this paper, we present a modified version of this approach that is equally efficient and allows us to extract spatial information with much higher accuracy than previously possible. We present efficient algorithms both for extracting and storing spatial information from video, as well as for processing this information in order to obtain useful spatial features. We evaluate our approach and demonstrate that the extracted spatial information is considerably more accurate than that obtained from existing approaches.

#index 2032984
#* Combining RCC5 relations with betweenness information
#@ Steven Schockaert;Sanjiang Li
#t 2013
#c 11
#% 172366
#% 353872
#% 400979
#% 419952
#% 421040
#% 1289200
#% 1305425
#% 1327634
#% 1630624
#! RCC5 is an important and well-known calculus for representing and reasoning about mereological relations. Among many other applications, it is pivotal in the formalization of commonsense reasoning about natural categories. In particular, it allows for a qualitative representation of conceptual spaces in the sense of Gärdenfors. To further the role of RCC5 as a vehicle for conceptual reasoning, in this paper we combine RCC5 relations with information about betweenness of regions. The resulting calculus allows us to express, for instance, that some part (but not all) of region B is between regions A and C. We show how consistency can be decided in polynomial time for atomic networks, even when regions are required to be convex. From an application perspective, the ability to express betweenness information allows us to use RCC5 as a basis for interpolative reasoning, while the restriction to convex regions ensures that all consistent networks can be faithfully represented as a conceptual space.

#index 2032985
#* Interpolative reasoning with default rules
#@ Steven Schockaert;Henri Prade
#t 2013
#c 11
#% 44876
#% 77841
#% 115327
#% 116294
#% 229087
#% 353872
#% 418069
#% 780340
#% 1289200
#% 1630624
#% 1680784
#% 1925297
#! Default reasoning and interpolation are two important forms of commonsense rule-based reasoning. The former allows us to draw conclusions from incompletely specified states, by making assumptions on normality, whereas the latter allows us to draw conclusions from states that are not explicitly covered by any of the available rules. Although both approaches have received considerable attention in the literature, it is at present not well understood how they can be combined to draw reasonable conclusions from incompletely specified states and incomplete rule bases. In this paper, we introduce an inference system for interpolating default rules, based on a geometric semantics in which normality is related to spatial density and interpolation is related to geometric betweenness. We view default rules and information on the betweenness of natural categories as particular types of constraints on qualitative representations of Gärdenfors conceptual spaces. We propose an axiomatization, extending the well-known System P, and show its soundness and completeness w.r.t. the proposed semantics. Subsequently, we explore how our extension of preferential reasoning can be further refined by adapting two classical approaches for handling the irrelevance problem in default reasoning: rational closure and conditional entailment.

#index 2032986
#* On condensing a sequence of updates in answer-set programming
#@ Martin Slota;João Leite
#t 2013
#c 11
#% 473186
#% 752737
#% 752748
#% 752792
#% 880392
#% 999272
#% 1388124
#% 1473386
#% 1664549
#% 1690704
#% 1720142
#% 1925325
#! Update semantics for Answer-Set Programming assign models to sequences of answer-set programs which result from the iterative process of updating programs by programs. Each program in the sequence represents an update of the preceding ones. One of the enduring problems in this context is state condensing, or the problem of determining a single logic program that faithfully represents the sequence of programs. Such logic program should 1) be written in the same alphabet, 2) have the same stable models, and 3) be equivalent to the sequence of programs when subject to further updates. It has been known for more than a decade that update semantics easily lead to non-minimal stable models, so an update sequence cannot be represented by a single non-disjunctive program. On the other hand, more expressive classes of programs were never considered, mainly because it was not clear how they could be updated further. In this paper we solve the state condensing problem for two foundational rule update semantics, using nested logic programs. Furthermore, we also show that disjunctive programs with default negation in the head can be used for the same purpose.

#index 2032987
#* Nominal schema absorption
#@ Andreas Steigmiller;Birte Glimm;Thorsten Liebig
#t 2013
#c 11
#% 417625
#% 935898
#% 977139
#% 1560419
#% 1667768
#% 1933392
#! Nominal schemas have recently been introduced as a new approach for the integration of DL-safe rules into the Description Logic framework. The efficient processing of knowledge bases with nominal schemas remains, however, challenging. We address this by extending the well-known optimisation of absorption as well as the standard tableau calculus to directly handle the (absorbed) nominal schema axioms. We implement the resulting extension of standard tableau calculi in a novel reasoning system and we integrate further optimisations. In our empirical evaluation, we show the effect of these optimisations and we find that the proposed approach performs well even when compared to other DL reasoners with dedicated rule support.

#index 2032988
#* Granular description of qualitative change
#@ John G. Stell
#t 2013
#c 11
#% 588642
#% 837641
#% 1179113
#% 1274701
#% 1274784
#% 1275342
#% 1405084
#! Qualitative representations of spatial knowledge have been widely studied and a variety of frameworks are used to express relationships between static regions. Dynamic regions present a much greater challenge, but are important in practical applications such as describing crowds of people moving over time. Previous work has analysed changes as regions merge and split and as new regions are created and existing ones disappear. We present a novel framework for the qualitative description of spatial regions based on two levels of granularity. Introducing granularity yields significantly more informative qualitative descriptions than are available from a single level of detail. The formal model represents a region, which may have multiple components, as a bipartite graph where the nodes are the components of the region at a fine level of detail and at a coarse level. The edges of the graph model the way that a component in the coarse view can be made up of parts of components at the more detailed level. We show that all graphs of this form (except for some degenerate cases) can be realized as regions in a discrete space of pixels, and we develop a theory of relations between these graphs to model the dynamic behaviour of regions.

#index 2032989
#* A rational extension of stable model semantics to the full propositional language
#@ Shahab Tasharrofi
#t 2013
#c 11
#% 1146
#% 77167
#% 289052
#% 651267
#% 906663
#% 1263099
#% 1472761
#% 1577210
#% 1641517
#% 1656398
#% 1826236
#! Answer set programming is the most appreciated framework for non-monotonic reasoning. Stable model semantics, as the semantics behind this success, has been subject to many extensions. The two main such extensions are equilibrium models and FLP semantics. Despite their very interesting foundations, they both have two problems: they cannot guarantee either minimality, or rationality of their intended models. That is, both these semantics allow models in which some atoms are self-justified (i.e., the only possible reason for including those atoms in the model are those atoms themselves). Present paper extends stable model semantics to the full propositional language while guaranteeing both properties above. Our extension is called supported because it guarantees the existence of noncircular justifications for all atoms in a supported model. These goals are achieved through a form of completion in intuitionistic logic. We also discuss how supported models relate to other semantics for non-monotonic reasoning such as equilibrium models. Finally, we discuss the complexity of reasoning about supported models and show that the complexity of brave/cautious reasoning in supported semantics remains as before, i.e., the rationality property comes for no additional cost.

#index 2032990
#* Compact rewritings for existential rules
#@ Michaël Thomazo
#t 2013
#c 11
#% 465511
#% 935898
#% 992962
#% 1279259
#% 1305397
#% 1333459
#% 1585244
#% 1594576
#% 1615741
#% 1808579
#% 1826485
#% 1933380
#! Querying large databases while taking ontologies into account is currently a very active domain research. In this paper, we consider ontologies described by existential rules (also known as Datalog+/-), a framework that generalizes lightweight description logics. A common approach is to rewrite a conjunctive query w.r.t an ontology into a union of conjunctive queries (UCQ) which can be directly evaluated against a database. However, the practicability of this approach is questionable due to 1) the weak expressivity of classes for which efficient rewriters have been implemented 2) the large size of optimal rewritings using UCQ. We propose to use semi-conjunctive queries (SCQ), which are a restricted form of positive existential formulas, and compute sound and complete rewritings, which are union of SCQ (USCQ). A novel algorithm for query rewriting, COMPACT, is presented. It computes sound and complete rewritings for large classes of ontologies. First experiments show that USCQ are both efficiently computable and more efficiently evaluable than their equivalent UCQ.

#index 2032991
#* A classification of first-order progressable action theories in situation calculus
#@ Stavros Vassos;Fabio Patrizi
#t 2013
#c 11
#% 663
#% 155825
#% 229083
#% 284647
#% 342119
#% 572366
#% 1270247
#% 1289434
#% 1289445
#% 1305426
#% 1476290
#% 1499565
#! Projection in the situation calculus refers to answering queries about the future evolutions of the modeled domain, while progression refers to updating the logical representation of the initial state so that it reflects the changes due to an executed action. In the general case projection is not decidable and progression may require second-order logic. In this paper we focus on a recent result about the decidability of projection and use it to drive results for the problem of progression. In particular we contribute with the following: (i) a major result showing that for a large class of intuitive action theories with bounded unknowns a first-order progression always exists and can be computed; (ii) a comprehensive classification of the known classes that can be progressed in first-order; (iii) a novel account of nondeterministic actions in the situation calculus.

#index 2032992
#* An alternative axiomatization of DEL and its applications
#@ Yanjing Wang;Guillaume Aucher
#t 2013
#c 11
#% 188086
#% 338753
#% 421939
#% 480340
#% 555391
#% 751235
#% 1197380
#% 1590188
#! In this paper, we provide a new axiomatization of the event-model-based Dynamic Epistemic Logic, based on the completeness proof method proposed in [Wang and Cao, 2013]. This axiomatization does not use any of the standard reduction axioms, but naturally captures the essence of the update product. We demonstrate the use of our new axiomatization and the corresponding proof techniques by three sets of results: characterization theorems of the update operations, representation theorems of the DEL-generatable epistemic temporal structures given a fixed event model, and a complete axiomatization of DEL on models with protocols.

#index 2032993
#* Knowing that, knowing what, and public communication: public announcement logic with Kv operators
#@ Yanjing Wang;Jie Fan
#t 2013
#c 11
#% 188086
#% 421939
#% 480340
#% 555391
#% 810262
#% 943991
#% 1082312
#% 1197380
#! In his seminal work [Plaza, 1989], Plaza proposed the public announcement logic (PAL), which is considered as the pilot logic in the field of dynamic epistemic logic. In the same paper, Plaza also introduced an interesting "know-value" operator Kv and listed a few valid formulas of PAL+Kv. However, it is unknown that whether these formulas, on top of the axioms for PAL, completely axiomatize PAL+Kv. In this paper, we first give a negative answer to this open problem. Moreover, we generalize the Kv operator and show that in the setting of PAL, replacing the Kv operator with its generalized version does not increase the expressive power of the resulting logic. This suggests that we can simply use the more flexible generalization instead of the original PAL+Kv. As the main result, we give a complete proof system for PAL plus the generalized operator based on a complete axiomatization of epistemic logic with the same operator in the single-agent setting.

#index 2032994
#* Multi-agent subset space logic
#@ Yì N. Wáng;Thomas Ågotnes
#t 2013
#c 11
#% 123204
#% 188086
#% 338753
#% 552834
#% 1022011
#% 1111061
#% 1630755
#! Subset space logics have been introduced and studied as a framework for reasoning about a notion of effort in epistemic logic. The seminal Subset Space Logic (SSL) by Moss and Parikh modeled a single agent, and most work in this area has focused on different extensions of the language, or different model classes resulting from restrictions on subset spaces, while still keeping the single-agent assumption. In this paper we argue that the few existing attempts at multi-agent versions of SSL are unsatisfactory, and propose a new multi-agent subset space logic which is a natural extension of single-agent SSL. The main results are a sound and complete axiomatization of this logic, as well as an alternative and equivalent relational semantics.

#index 2032995
#* Forgetting for answer set programs revisited
#@ Yisong Wang;Kewen Wang;Mingyi Zhang
#t 2013
#c 11
#% 340738
#% 411814
#% 417649
#% 501041
#% 772065
#% 906658
#% 1016491
#% 1076645
#% 1261232
#% 1271987
#% 1279081
#% 1289366
#% 1291484
#% 1442139
#% 1483839
#% 1624824
#% 1656398
#% 1765819
#% 1826219
#% 1911364
#! A new semantic forgetting for answer set programs (ASP), called SM-forgetting, is proposed in the paper. It distinguishes itself from the others in that it preserves not only skeptical and credulous consequences on unforgotten variables, but also strong equivalence-forgetting same variables in strongly equivalent logic programs has strongly equivalent results. The forgetting presents a positive answer to Gabbay, Pearce and Valverde's open question - if ASP has uniform interpolation property. We also investigate some properties, algorithm and computational complexities for the forgetting. It shows that computing the forgetting result is generally intractable even for Horn logic programs.

#index 2032996
#* Transition constraints: a study on the computational complexity of qualitative change
#@ Matthias Westphal;Julien Hué;Stefan Wölfl;Bernhard Nebel
#t 2013
#c 11
#% 84513
#% 319244
#% 408396
#% 418217
#% 600496
#% 918159
#% 1015868
#% 1309989
#% 1310060
#% 1477178
#% 1656670
#% 1664961
#% 1826216
#% 1898686
#! Many formalisms discussed in the literature on qualitative spatial reasoning are designed for expressing static spatial constraints only. However, dynamic situations arise in virtually all applications of these formalisms, which makes it necessary to study variants and extensions dealing with change. This paper presents a study on the computational complexity of qualitative change. More precisely, we discuss the reasoning task of finding a solution to a temporal sequence of static reasoning problems where this sequence is subject to additional transition constraints. Our focus is primarily on smoothness and continuity constraints: we show how such transitions can be defined as relations and expressed within qualitative constraint formalisms. Our results demonstrate that for point-based constraint formalisms the interesting fragments are NP-complete in the presence of continuity constraints, even if the satisfiability problem of its static descriptions is tractable.

#index 2032997
#* Supremal realizability of behaviors with uncontrollable exogenous events
#@ Nitin Yadav;Paolo Felli;Giuseppe De Giacomo;Sebastian Sardina
#t 2013
#c 11
#% 31432
#% 342119
#% 926913
#% 1114335
#% 1195119
#% 1272455
#% 1275054
#% 1305438
#% 1615229
#% 1925331
#% 1954689
#! The behavior composition problem involves the automatic synthesis of a controller able to "realize" (i.e., implement) a desired target behavior specification by suitably coordinating a set of already available behaviors. While the problem has been thoroughly studied, one open issue has resisted a principled solution: if the target specification is not fully realizable, is there a way to realize it "at best"? In this paper we answer positively, by showing that there exists a unique supremal realizable target behavior satisfying the specification. More importantly we give an effective procedure to compute such a target. Then, we introduce exogenous events, and show that the supremal can again be computed, though this time, into two variants, depending on the ability to observe such events.

#index 2032998
#* Multi-agent epistemic explanatory diagnosis via reasoning about actions
#@ Quan Yu;Ximing Wen;Yongmei Liu
#t 2013
#c 11
#% 21137
#% 338753
#% 1197380
#% 1269717
#% 1274837
#% 1291403
#% 1630743
#! The task of explanatory diagnosis conjectures actions to explain observations. This is a common task in real life and an essential ability of intelligent agents. It becomes more complicated in multi-agent scenarios, since agents' actions may be partially observable to other agents, and observations might involve agents' knowledge about the world or other agents' knowledge or even common knowledge of a group of agents. For example, we might want to explain the observation that p does not hold, but Ann believes p, or the observation that Ann, Bob, and Carl commonly believe p. In this paper, we formalize the multi-agent explanatory diagnosis task in the framework of dynamic epistemic logic, where Kripke models of actions are used to represent agents' partial observability of actions. Since this task is undecidable in general, we identify important decidable fragments via techniques of reducing the potentially infinite search spaces to finite ones of epistemic states or action sequences.

#index 2032999
#* Most specific generalizations w.r.t. general EL-TBoxes
#@ Benjamin Zarrieß;Anni-Yasmin Turhan
#t 2013
#c 11
#% 448093
#% 665856
#% 941445
#% 1273744
#% 1279258
#% 1289408
#% 1297721
#% 1473208
#% 1597491
#% 1722438
#! In the area of Description Logics the least common subsumer (lcs) and the most specific concept (msc) are inferences that generalize a set of concepts or an individual, respectively, into a single concept. If computed w.r.t. a general EL-TBox neither the lcs nor the msc need to exist. So far in this setting no exact conditions for the existence of lcs-or msc-concepts are known. This paper provides necessary and sufficient conditions for the existence of these two kinds of concepts. For the lcs of a fixed number of concepts and the msc we show decidability of the existence in PTime and polynomial bounds on the maximal role-depth of the lcs-and msc-concepts. This bound allows to compute the lcs and the msc, respectively.

#index 2033000
#* First-order expressibility and boundedness of disjunctive logic programs
#@ Heng Zhang;Yan Zhang
#t 2013
#c 11
#% 1144
#% 69282
#% 70168
#% 73129
#% 114723
#% 129971
#% 175735
#% 231786
#% 235018
#% 384978
#% 411814
#% 835733
#% 1263083
#% 1274639
#% 1503511
#% 1503512
#% 1531973
#% 1679925
#% 1765800
#! In this paper, the fixed point semantics developed in [Lobo et al., 1992] is generalized to disjunctive logic programs with default negation and over arbitrary structures, and proved to coincide with the stable model semantics. By using the tool of ultra-products, a preservation theorem, which asserts that a disjunctive logic program without default negation is bounded with respect to the proposed semantics if and only if it has a first-order equivalent, is then obtained. For the disjunctive logic programs with default negation, a sufficient condition assuring the first-order expressibility is also proposed.

#index 2033001
#* Definability of horn revision from horn contraction
#@ Zhiqiang Zhuang;Maurice Pagnucco;Yan Zhang
#t 2013
#c 11
#% 109945
#% 204396
#% 782324
#% 1053888
#% 1275166
#% 1305401
#% 1473437
#% 1495937
#% 1693261
#% 1765797
#% 1826197
#% 1826244
#! In the AGM framework [Alchourrón and Makinson, 1985], a revision function can be defined directly through constructions like systems of spheres, epistemic entrenchment, etc., or indirectly through a contraction operation via the Levi identity. A recent trend is to construct AGM style contraction and revision functions that operate under Horn logic. A direct construction of Horn revision is given in [Delgrande and Peppas, 2011]. However, it is unknown whether Horn revision can be defined indirectly from Horn contraction. In this paper, we address this problem by obtaining a model-based Horn revision through the model-based Horn contraction studied in [Zhuang and Pagnucco, 2012]. Our result shows that, under proper restrictions, Horn revision is definable through Horn contraction via the Levi identity.

#index 2033002
#* Learning community-based preferences via dirichlet process mixtures of Gaussian processes
#@ Ehsan Abbasnejad;Scott Sanner;Edwin V. Bonilla;Pascal Poupart
#t 2013
#c 11
#% 729975
#% 840852
#% 1117695
#% 1383034
#% 1496802
#% 1541778
#% 1650424
#% 1650536
#! Bayesian approaches to preference learning using Gaussian Processes (GPs) are attractive due to their ability to explicitly model uncertainty in users' latent utility functions; unfortunately existing techniques have cubic time complexity in the number of users, which renders this approach intractable for collaborative preference learning over a large user base. Exploiting the observation that user populations often decompose into communities of shared preferences, we model user preferences as an infinite Dirichlet Process (DP) mixture of communities and learn (a) the expected number of preference communities represented in the data, (b) a GP-based preference model over items tailored to each community, and (c) the mixture weights representing each user's fraction of community membership. This results in a learning and inference process that scales linearly in the number of users rather than cubicly and additionally provides the ability to analyze individual community preferences and their associated members. We evaluate our approach on a variety of preference data sources including Amazon Mechanical Turk showing that our method is more scalable and as accurate as previous GP-based preference learning work.

#index 2033003
#* An ensemble of Bayesian networks for multilabel classification
#@ Antonucci Alessandro;Giorgio Corani;Denis Mauá;Sandra Gabaglio
#t 2013
#c 11
#% 272381
#% 799040
#% 838412
#% 889176
#% 1013606
#% 1272025
#% 1417383
#% 1567948
#% 1570399
#% 1606350
#% 1647889
#% 1673062
#! We present a novel approach for multilabel classification based on an ensemble of Bayesian networks. The class variables are connected by a tree; each model of the ensemble uses a different class as root of the tree. We assume the features to be conditionally independent given the classes, thus generalizing the naive Bayes assumption to the multi-class case. This assumption allows us to optimally identify the correlations between classes and features; such correlations are moreover shared across all models of the ensemble. Inferences are drawn from the ensemble via logarithmic opinion pooling. To minimize Hamming loss, we compute the marginal probability of the classes by running standard inference on each Bayesian network in the ensemble, and then pooling the inferences. To instead minimize the subset 0/1 loss, we pool the joint distributions of each model and cast the problem as a MAP inference in the corresponding graphical model. Experiments show that the approach is competitive with state-of-the-art methods for multilabel classification.

#index 2033004
#* Self-organized neural learning of statistical inference from high-dimensional data
#@ Johannes Bauer;Stefan Wermter
#t 2013
#c 11
#% 647560
#% 872766
#% 1106655
#% 1926609
#! With information about the world implicitly embedded in complex, high-dimensional neural population responses, the brain must perform some sort of statistical inference on a large scale to form hypotheses about the state of the environment. This ability is, in part, acquired after birth and often with very little feedback to guide learning. This is a very difficult learning problem considering the little information about the meaning of neural responses available at birth. In this paper, we address the question of how the brain might solve this problem: We present an unsupervised artificial neural network algorithm which takes from the self-organizing map (SOM) algorithm the ability to learn a latent variable model from its input. We extend the SOM algorithm so it learns about the distribution of noise in the input and computes probability density functions over the latent variables. The algorithm represents these probability density functions using population codes. This is done with very few assumptions about the distribution of noise. Our simulations indicate that our algorithm can learn to perform similar to a maximum likelihood estimator with the added benefit of requiring no a-priori knowledge about the input and computing not only best hypotheses, but also probabilities for alternatives.

#index 2033005
#* Basic level in formal concept analysis: interesting concepts and psychological ramifications
#@ Radim Belohlavek;Martin Trnecka
#t 2013
#c 11
#% 384416
#% 451052
#% 835018
#% 878207
#% 992699
#% 1301478
#% 1605918
#% 1697360
#% 1727289
#% 1894406
#! We present a study regarding basic level of concepts in conceptual categorization. The basic level of concepts is an important phenomenon studied in the psychology of concepts. We propose to utilize this phenomenon in formal concept analysis to select important formal concepts. Such selection is critical because, as is well known, the number of all concepts extracted from data is usually large. We review and formalize the main existing psychological approaches to basic level which are presented only informally and are not related to any particular formal model of concepts in the psychological literature. We argue and demonstrate by examples that basic level concepts may be regarded as interesting, informative formal concepts from a user viewpoint. Interestingly, our formalization and experiments reveal previously unknown relationships between the existing approaches to basic level. Thus, we argue that a formalization of basic level in the framework of formal concept analysis is beneficial for the psychological investigations themselves because it helps put them on a solid, formal ground.

#index 2033006
#* Exact top-k feature selection via l2,0-norm constraint
#@ Xiao Cai;Feiping Nie;Heng Huang
#t 2013
#c 11
#% 126894
#% 243728
#% 425048
#% 515676
#% 722929
#% 741335
#% 814023
#% 875980
#% 1041316
#% 1130931
#% 1379069
#% 1535440
#% 1688445
#% 1885652
#! In this paper, we propose a novel robust and pragmatic feature selection approach. Unlike those sparse learning based feature selection methods which tackle the approximate problem by imposing sparsity regularization in the objective function, the proposed method only has one l2,1-norm loss term with an explicit l2,0-Norm equality constraint. An efficient algorithm based on augmented Lagrangian method will be derived to solve the above constrained optimization problem to find out the stable local solution. Extensive experiments on four biological datasets show that although our proposed model is not a convex problem, it outperforms the approximate convex counterparts and state-of-art feature selection methods evaluated in terms of classification accuracy by two popular classifiers. What is more, since the regularization parameter of our method has the explicit meaning, i.e. the number of feature selected, it avoids the burden of tuning the parameter, making it a pragmatic feature selection method.

#index 2033007
#* Regularized latent least square regression for cross pose face recognition
#@ Xinyuan Cai;Chunheng Wang;Baihua Xiao;Xue Chen;Ji Zhou
#t 2013
#c 11
#% 235342
#% 721161
#% 729344
#% 791402
#% 983876
#% 1081620
#% 1164188
#% 1220002
#% 1698379
#% 1742155
#% 1750265
#% 1856451
#% 1867403
#% 1923372
#! Pose variation is one of the challenging factors for face recognition. In this paper, we propose a novel cross-pose face recognition method named as Regularized Latent Least Square Regression (RLLSR). The basic assumption is that the images captured under different poses of one person can be viewed as pose-specific transforms of a single ideal object. We treat the observed images as regressor, the ideal object as response, and then formulate this assumption in the least square regression framework, so as to learn the multiple pose-specific transforms. Specifically, we incorporate some prior knowledge as two regularization terms into the least square approach: 1) the smoothness regularization, as the transforms for nearby poses should not differ too much; 2) the local consistency constraint, as the distribution of the latent ideal objects should preserve the geometric structure of the observed image space. We develop an alternating algorithm to simultaneously solve for the ideal objects of the training individuals and a set of pose-specific transforms. The experimental results on the Multi-PIE dataset demonstrate the effectiveness of the proposed method and superiority over the previous methods.

#index 2033008
#* Robust tensor clustering with non-greedy maximization
#@ Xiaochun Cao;Xingxing Wei;Yahong Han;Yi Yang;Dongdai Lin
#t 2013
#c 11
#% 316143
#% 837604
#% 846431
#% 891559
#% 1083660
#% 1116396
#% 1300087
#% 1431737
#% 1537112
#% 1826292
#% 1858998
#% 1867447
#! Tensors are increasingly common in several areas such as data mining, computer graphics, and computer vision. Tensor clustering is a fundamental tool for data analysis and pattern discovery. However, there usually exist outlying data points in real-world datasets, which will reduce the performance of clustering. This motivates us to develop a tensor clustering algorithm that is robust to the outliers. In this paper, we propose an algorithm of Robust Tensor Clustering (RTC). The RTC firstly finds a lower rank approximation of the original tensor data using a L1 norm optimization function. Because the L1 norm doesn't exaggerate the effect of outliers compared with L2 norm, the minimization of the L1 norm approximation function makes RTC robust to outliers. Then we compute the HOSVD decomposition of this approximate tensor to obtain the final clustering results. Different from the traditional algorithm solving the approximation function with a greedy strategy, we utilize a non-greedy strategy to obtain a better solution. Experiments demonstrate that RTC has better performance than the state-of-the-art algorithms and is more robust to outliers.

#index 2033009
#* Central clustering of categorical data with automated feature weighting
#@ Lifei Chen;Shengrui Wang
#t 2013
#c 11
#% 105622
#% 296738
#% 314054
#% 770826
#% 800188
#% 806943
#% 982763
#% 1013613
#% 1051482
#% 1300437
#% 1378330
#% 1477200
#% 1524392
#% 1589524
#% 1694224
#% 1847980
#! The ability to cluster high-dimensional categorical data is essential for many machine learning applications such as bioinfomatics. Currently, central clustering of categorical data is a difficult problem due to the lack of a geometrically interpretable definition of a cluster center. In this paper, we propose a novel kernel-density-based definition using a Bayes-type probability estimator. Then, a new algorithm called k-centers is proposed for central clustering of categorical data, incorporating a new feature weighting scheme by which each attribute is automatically assigned with a weight measuring its individual contribution for the clusters. Experimental results on real-world data show outstanding performance of the proposed algorithm, especially in recognizing the biological patterns in DNA sequences.

#index 2033010
#* Dimensionality reduction with generalized linear models
#@ Mo Chen;Wei Li;Wei Zhang;Xiaogang Wang
#t 2013
#c 11
#% 258937
#% 272536
#% 350337
#% 425021
#% 1073976
#% 1166535
#% 1300087
#! In this paper, we propose a general dimensionality reduction method for data generated from a very broad family of distributions and nonlinear functions based on the generalized linear model, called Generalized Linear Principal Component Analysis (GLPCA). Data of different domains often have very different structures. These data can be modeled by different distributions and reconstruction functions. For example, real valued data can be modeled by the Gaussian distribution with a linear reconstruction function, whereas binary valued data may be more appropriately modeled by the Bernoulli distribution with a logit or probit function. Based on general linear models, we propose a unified framework for extracting features from data of different domains. A general optimization algorithm based on natural gradient ascent on distribution manifold is proposed for obtaining the maximum likelihood solutions. We also present some specific algorithms derived from this framework to deal with specific data modeling problems such as document modeling. Experimental results of these algorithms on several data sets are shown for the validation of GLPCA.

#index 2033011
#* Generalized relational topic models with data augmentation
#@ Ning Chen;Jun Zhu;Fei Xia;Bo Zhang
#t 2013
#c 11
#% 266215
#% 420495
#% 431293
#% 722904
#% 730089
#% 761284
#% 1211734
#% 1211773
#% 1523858
#% 1536568
#! Relational topic models have shown promise on analyzing document network structures and discovering latent topic representations. This paper presents three extensions: 1) unlike the common link likelihood with a diagonal weight matrix that allows the-same-topic interactions only, we generalize it to use a full weight matrix that captures all pairwise topic interactions and is applicable to asymmetric networks; 2) instead of doing standard Bayesian inference, we perform regularized Bayesian inference with a regularization parameter to deal with the imbalanced link structure issue in common real networks; and 3) instead of doing variational approximation with strict mean-field assumptions, we present a collapsed Gibbs sampling algorithm for the generalized relational topic models without making restricting assumptions. Experimental results demonstrate the significance of these extensions on improving the prediction performance, and the time efficiency can be dramatically improved with a simple fast approximation method.

#index 2033012
#* Domain adaptation with topical correspondence learning
#@ Zheng Chen;Weixiong Zhang
#t 2013
#c 11
#% 46803
#% 757953
#% 881468
#% 983828
#% 989592
#% 1041612
#% 1074129
#% 1261539
#% 1270196
#% 1495393
#% 1550603
#% 1642003
#% 1826309
#% 1862326
#% 1944636
#! A serious and ubiquitous issue in machine learning is the lack of sufficient training data in a domain of interest. Domain adaptation is an effective approach to dealing with this problem by transferring information or models learned from related, albeit distinct, domains to the target domain. We develop a novel domain adaptation method for text document classification under the framework of Non-negative Matrix Factorization. Two key ideas of our method are to construct a latent topic space where a topic is decomposed into common words shared by all domains and words specific to individual domains, and then to establish associations between words in different domains through the common words as a bridge for knowledge transfer. The correspondence between cross-domain topics leads to more coherent distributions of source and target domains in the new representation while preserving the predictive power. Our new method outperformed several state-of-the-art domain adaptation methods on several benchmark datasets.

#index 2033013
#* Bayesian nonparametric feature construction for inverse reinforcement learning
#@ Jaedeug Choi;Kee-Eung Kim
#t 2013
#c 11
#% 252013
#% 363744
#% 466418
#% 770852
#% 876036
#% 1074001
#% 1089823
#% 1187663
#% 1270316
#% 1275169
#% 1298896
#% 1341079
#% 1405050
#% 1504451
#! Most of the algorithms for inverse reinforcement learning (IRL) assume that the reward function is a linear function of the pre-defined state and action features. However, it is often difficult to manually specify the set of features that can make the true reward function representable as a linear function. We propose a Bayesian nonparametric approach to identifying useful composite features for learning the reward function. The composite features are assumed to be the logical conjunctions of the pre-defined atomic features so that we can represent the reward function as a linear function of the composite features. We empirically show that our approach is able to learn composite features that capture important aspects of the reward function on synthetic domains, and predict taxi drivers' behaviour with high accuracy on a real GPS trace dataset.

#index 2033014
#* A lossy counting based approach for learning on streams of graphs on a budget
#@ Giovanni Da San Martino;Nicolò Navarin;Alessandro Sperduti
#t 2013
#c 11
#% 309208
#% 310500
#% 342600
#% 342639
#% 629617
#% 874178
#% 961152
#% 993960
#% 1038781
#% 1074047
#% 1083627
#% 1214635
#% 1411055
#% 1472270
#% 1605979
#% 1771640
#% 1926528
#% 1978725
#! In many problem settings, for example on graph domains, online learning algorithms on streams of data need to respect strict time constraints dictated by the throughput on which the data arrive. When only a limited amount of memory (budget) is available, a learning algorithm will eventually need to discard some of the information used to represent the current solution, thus negatively affecting its classification performance. More importantly, the overhead due to budget management may significantly increase the computational burden of the learning algorithm. In this paper we present a novel approach inspired by the Passive Aggressive and the Lossy Counting algorithms. Our algorithm uses a fast procedure for deleting the less influential features. Moreover, it is able to estimate the weighted frequency of each feature and use it for prediction.

#index 2033015
#* Bootstrap learning via modular concept discovery
#@ Eyal Dechter;Jon Malmaud;Ryan P. Adams;Joshua B. Tenenbaum
#t 2013
#c 11
#% 25470
#% 124073
#% 214028
#% 322564
#% 346654
#% 465217
#% 550564
#% 1272315
#% 1274557
#% 1274744
#% 1809531
#! Suppose a learner is faced with a domain of problems about which it knows nearly nothing. It does not know the distribution of problems, the space of solutions is not smooth, and the reward signal is uninformative, providing perhaps a few bits of information but not enough to steer the learner effectively. How can such a learner ever get off the ground? A common intuition is that if the solutions to these problems share a common structure, and the learner can solve some simple problems by brute force, it should be able to extract useful components from these solutions and, by composing them, explore the solution space more efficiently. Here, we formalize this intuition, where the solution space is that of typed functional programs and the gained information is stored as a stochastic grammar over programs. We propose an iterative procedure for exploring such spaces: in the first step of each iteration, the learner explores a finite subset of the domain, guided by a stochastic grammar; in the second step, the learner compresses the successful solutions from the first step to estimate a new stochastic grammar. We test this procedure on symbolic regression and Boolean circuit learning and show that the learner discovers modular concepts for these domains. Whereas the learner is able to solve almost none of the posed problems in the procedure's first iteration, it rapidly becomes able to solve a large number by gaining abstract knowledge of the structure of the solution space.

#index 2033016
#* Topic extraction from online reviews for classification and recommendation
#@ Ruihai Dong;Markus Schaal;Michael P. O'Mahony;Barry Smyth
#t 2013
#c 11
#% 769892
#% 926881
#% 1085122
#% 1176947
#% 1195867
#% 1261574
#% 1281981
#% 1287270
#% 1305481
#% 1482272
#% 1482445
#% 1537498
#% 1539253
#% 1826458
#! Automatically identifying informative reviews is increasingly important given the rapid growth of user generated reviews on sites like Amazon and TripAdvisor. In this paper, we describe and evaluate techniques for identifying and recommending helpful product reviews using a combination of review features, including topical and sentiment information, mined from a review corpus.

#index 2033017
#* Towards robust co-clustering
#@ Liang Du;Yi-Dong Shen
#t 2013
#c 11
#% 342621
#% 729918
#% 881468
#% 1214657
#% 1550603
#% 1595860
#% 1708938
#% 1745125
#% 1755328
#% 1826268
#% 1826311
#% 1884134
#! Nonnegative Matrix Tri-factorization (NMTF) and its graph regularized extensions have been widely used for co-clustering task to group data points and features simultaneously. However existing methods are sensitive to noises and outliers which is because of the squared loss function is used to measure the quality of data reconstruction and graph regularization. In this paper, we extend GNMTF by introducing a sparse outlier matrix into the data reconstruction function and applying the l1 norm to measure graph dual regularization errors, which leads to a novel Robust Co-Clustering (RCC) method. Accordingly, RCC is expected to obtain a more faithful approximation to the data recovered from sparse outliers, and achieve robust regularization by reducing the regularization errors of unreliable graphs via l1 norm. To solve the optimization problem of RCC, an alternating iterative algorithm is provided and its convergence is also proved. We also show the connection between the sparse outlier matrix in data reconstruction function and the robust Huber M-estimator. Experimental results on real-world data sets show that our RCC consistently outperforms the other algorithms in terms of clustering performance, which validates the effectiveness and robustness of the proposed approach.

#index 2033018
#* Learning finite Beta-Liouville mixture models via variational bayes for proportional data clustering
#@ Wentao Fan;Nizar Bouguila
#t 2013
#c 11
#% 250710
#% 269188
#% 345829
#% 431066
#% 593601
#% 637625
#% 662790
#% 865332
#% 889076
#% 891559
#% 975153
#% 1000813
#% 1013662
#% 1187608
#% 1356629
#% 1454737
#% 1513076
#% 1650268
#% 1931747
#% 1938479
#! During the past decade, finite mixture modeling has become a well-established technique in data analysis and clustering. This paper focus on developing a variational inference framework to learn finite Beta-Liouville mixture models that have been proposed recently as an efficient way for proportional data clustering. In contrast to the conventional expectation maximization (EM) algorithm, commonly used for learning finite mixture models, the proposed algorithm has the advantages that it is more efficient from a computational point of view and by preventing over-and under-fitting problems. Moreover, the complexity of the mixture model (i.e. the number of components) can be determined automatically and simultaneously with the parameters estimation in a closed form as part of the Bayesian inference procedure. The merits of the proposed approach are shown using both artificial data sets and two interesting and challenging real applications namely dynamic textures clustering and facial expression recognition.

#index 2033019
#* Optimizing cepstral features for audio classification
#@ Zhouyu Fu;Guojun Lu;Kai Ming Ting;Dengsheng Zhang
#t 2013
#c 11
#% 137711
#% 197394
#% 263850
#% 961154
#% 983830
#% 1117691
#% 1211766
#% 1232015
#% 1558464
#% 1617286
#% 1767413
#% 1775480
#% 1775936
#% 1858190
#! Cepstral features have been widely used in audio applications. Domain knowledge has played an important role in designing different types of cepstral features proposed in the literature. In this paper, we present a novel approach for learning optimized cepstral features directly from audio data to better discriminate between different categories of signals in classification tasks. We employ multi-layer feed-forward neural networks to model the cepstral feature extraction process. The network weights are initialized to replicate a reference cepstral feature like the mel frequency cepstral coefficient. We then propose a embedded approach that integrates feature learning with the training of a support vector machine (SVM) classifier. A single optimization problem is formulated where the feature and classifier variables are optimized simultaneously so as to refine the initial features and minimize the classification risk. Experimental results have demonstrated the effectiveness of the proposed feature learning approach, outperforming competing methods by a large margin on benchmark data.

#index 2033020
#* Uniform convergence, stability and learnability for ranking problems
#@ Wei Gao;Zhi-Hua Zhou
#t 2013
#c 11
#% 66937
#% 237433
#% 296521
#% 722805
#% 734915
#% 829008
#% 840846
#% 983820
#% 1232022
#% 1272396
#% 1385984
#% 1385985
#% 1499781
#% 1551189
#% 1551226
#% 1705502
#% 1817412
#! Most studies were devoted to the design of efficient algorithms and the evaluation and application on diverse ranking problems, whereas few work has been paid to the theoretical studies on ranking learnability. In this paper, we study the relation between uniform convergence, stability and learnability of ranking. In contrast to supervised learning where the learnability is equivalent to uniform convergence, we show that the ranking uniform convergence is sufficient but not necessary for ranking learnability with AERM, and we further present a sufficient condition for ranking uniform convergence with respect to bipartite ranking loss. Considering the ranking uniform convergence being unnecessary for ranking learnability, we prove that the ranking average stability is a necessary and sufficient condition for ranking learnability.

#index 2033021
#* Active learning for level set estimation
#@ Alkis Gotovos;Nathalie Casati;Gregory Hitz;Andreas Krause
#t 2013
#c 11
#% 862547
#% 878207
#% 1060237
#% 1073882
#! Many information gathering problems require determining the set of points, for which an unknown function takes value above or below some given threshold level. We formalize this task as a classification problem with sequential measurements, where the unknown function is modeled as a sample from a Gaussian process (GP). We propose LSE, an algorithm that guides both sampling and classification based on GP-derived confidence bounds, and provide theoretical guarantees about its sample complexity. Furthermore, we extend LSE and its theory to two more natural settings: (1) where the threshold level is implicitly defined as a percentage of the (unknown) maximum of the target function and (2) where samples are selected in batches. We evaluate the effectiveness of our proposed methods on two problems of practical interest, namely autonomous monitoring of algal populations in a lake environment and geolocating network latency.

#index 2033022
#* Histogram of oriented displacements (HOD): describing trajectories of human joints for action recognition
#@ Mohammad A. Gowayyed;Marwan Torki;Mohamed E. Hussein;Motaz El-Saban
#t 2013
#c 11
#% 1378773
#% 1558464
#% 1750536
#% 1750567
#% 1884262
#! Creating descriptors for trajectories has many applications in robotics/human motion analysis and video copy detection. Here, we propose a novel descriptor for 2D trajectories: Histogram of Oriented Displacements (HOD). Each displacement in the trajectory votes with its length in a histogram of orientation angles. 3D trajectories are described by the HOD of their three projections. We use HOD to describe the 3D trajectories of body joints to recognize human actions, which is a challenging machine vision task, with applications in human-robot/machine interaction, interactive entertainment, multimedia information retrieval, and surveillance. The descriptor is fixed-length, scale-invariant and speed-invariant. Experiments on MSR-Action3D and HDM05 datasets show that the descriptor outperforms the state-of-the-art when using off-the-shelf classification tools.

#index 2033023
#* Multi-prototype label ranking with novel pairwise-to-total-rank aggregation
#@ Mihajlo Grbovic;Nemanja Djuric;Slobodan Vucetic
#t 2013
#c 11
#% 304321
#% 642769
#% 972249
#% 983820
#% 1093383
#% 1102242
#% 1211710
#% 1272396
#% 1287222
#% 1318581
#% 1396696
#% 1747262
#% 1811553
#! We propose a multi-prototype-based algorithm for online learning of soft pairwise-preferences over labels. The algorithm learns soft label preferences via minimization of the proposed soft rank-loss measure, and can learn from total orders as well as from various types of partial orders. The soft pairwise preference algorithm outputs are further aggregated to produce a total label ranking prediction using a novel aggregation algorithm that outperforms existing aggregation solutions. Experiments on synthetic and real-world data demonstrate state-of-the-art performance of the proposed model.

#index 2033024
#* MiningZinc: a modeling language for constraint-based mining
#@ Tias Guns;Anton Dries;Guido Tack;Siegfried Nijssen;Luc De Raedt
#t 2013
#c 11
#% 152934
#% 244336
#% 269391
#% 316709
#% 420062
#% 420101
#% 464873
#% 481954
#% 765529
#% 799042
#% 857142
#% 942743
#% 1077571
#% 1077574
#% 1232020
#% 1272228
#% 1289368
#% 1399095
#% 1598216
#% 1598605
#% 1694225
#% 1796598
#% 1874795
#% 1912715
#% 1984495
#! We introduce MiningZinc, a general framework for constraint-based pattern mining, one of the most popular tasks in data mining. MiningZinc consists of two key components: a language component and a toolchain component. The language allows for high-level and natural modeling of mining problems, such that MiningZinc models closely resemble definitions found in the data mining literature. It is inspired by the Zinc family of languages and systems and supports user-defined constraints and optimization criteria. The toolchain allows for finding solutions to the models. It ensures the solver independence of the language and supports both standard constraint solvers and specialized data mining systems. Automatic model transformations enable the efficient use of different solvers and systems. The combination of both components allows one to rapidly model constraint-based mining problems and execute these with a wide variety of methods. We demonstrate this experimentally for a number of well-known solvers and data mining tasks.

#index 2033025
#* Probabilistic multi-label classification with sparse feature learning
#@ Yuhong Guo;Wei Xue
#t 2013
#c 11
#% 311034
#% 763708
#% 770857
#% 818234
#% 818236
#% 838412
#% 961191
#% 989655
#% 997067
#% 1095861
#% 1117042
#% 1134224
#% 1270338
#% 1302843
#% 1302853
#% 1384971
#% 1417091
#% 1570399
#% 1826270
#% 1826317
#% 1826411
#! Multi-label classification is a critical problem in many areas of data analysis such as image labeling and text categorization. In this paper we propose a probabilistic multi-label classification model based on novel sparse feature learning. By employing an individual sparsity inducing l1-norm and a group sparsity inducing l2,1-norm, the proposed model has the capacity of capturing both label interdependencies and common predictive model structures. We formulate this sparse norm regularized learning problem as a non-smooth convex optimization problem, and develop a fast proximal gradient algorithm to solve it for an optimal solution. Our empirical study demonstrates the efficacy of the proposed method on a set of multi-label tasks given a limited number of labeled training instances.

#index 2033026
#* Co-regularized ensemble for feature selection
#@ Yahong Han;Yi Yang;Xiaofang Zhou
#t 2013
#c 11
#% 283145
#% 336073
#% 443790
#% 722816
#% 729437
#% 786615
#% 875962
#% 1073994
#% 1117691
#% 1128929
#% 1132472
#% 1688445
#% 1826317
#% 1915638
#! Supervised feature selection determines feature relevance by evaluating feature's correlation with the classes. Joint minimization of a classifier's loss function and an l2,1-norm regularization has been shown to be effective for feature selection. However, the appropriate feature subset learned from different classifiers' loss function may be different. Less effort has been made on improving the performance of feature selection by the ensemble of different classifiers' criteria and take advantages of them. Furthermore, for the cases when only a few labeled data per class are available, over-fitting would be a potential problem and the performance of each classifier is restrained. In this paper, we add a joint l2,1-norm on multiple feature selection matrices to ensemble different classifiers' loss function into a joint optimization framework. This added co-regularization term has twofold role in enhancing the effect of regularization for each criterion and uncovering common irrelevant features. The problem of over-fitting can be alleviated and thus the performance of feature selection is improved. Extensive experiment on different data types demonstrates the effectiveness of our algorithm.

#index 2033027
#* Improving traffic prediction with tweet semantics
#@ Jingrui He;Wei Shen;Phani Divakaruni;Laura Wynter;Rick Lawrence
#t 2013
#c 11
#% 1298864
#% 1400018
#% 1450992
#% 1470583
#% 1481659
#% 1806896
#! Road traffic prediction is a critical component in modern smart transportation systems. It provides the basis for traffic management agencies to generate proactive traffic operation strategies for alleviating congestion. Existing work on near-term traffic prediction (forecasting horizons in the range of 5 minutes to 1 hour) relies on the past and current traffic conditions. However, once the forecasting horizon is beyond 1 hour, i.e., in longer-term traffic prediction, these techniques do not work well since additional factors other than the past and current traffic conditions start to play important roles. To address this problem, in this paper, for the first time, we examine whether it is possible to use the rich information in online social media to improve longer-term traffic prediction. To this end, we first analyze the correlation between traffic volume and tweet counts with various granularities. Then we propose an optimization framework to extract traffic indicators based on tweet semantics using a transformation matrix, and incorporate them into traffic prediction via linear regression. Experimental results using traffic and Twitter data originated from the San Francisco Bay area of California demonstrate the effectiveness of our proposed framework.

#index 2033028
#* A general framework for interacting bayes-optimally with self-interested agents using arbitrary parametric model and model prior
#@ Trong Nghia Hoang;Kian Hsiang Low
#t 2013
#c 11
#% 266287
#% 378961
#% 464283
#% 643168
#% 876032
#% 1084013
#% 1215600
#% 1274863
#% 1279358
#% 1289288
#% 1289481
#% 1615250
#% 1875661
#% 1875667
#% 1875884
#% 1989551
#! Recent advances in Bayesian reinforcement learning (BRL) have shown that Bayes-optimality is theoretically achievable by modeling the environment's latent dynamics using Flat-Dirichlet-Multinomial (FDM) prior. In self-interested multiagent environments, the transition dynamics are mainly controlled by the other agent's stochastic behavior for which FDM's independence and modeling assumptions do not hold. As a result, FDM does not allow the other agent's behavior to be generalized across different states nor specified using prior domain knowledge. To overcome these practical limitations of FDM, we propose a generalization of BRL to integrate the general class of parametric models and model priors, thus allowing practitioners' domain knowledge to be exploited to produce a fine-grained and compact representation of the other agent's behavior. Empirical evaluation shows that our approach outperforms existing multi-agent reinforcement learning algorithms.

#index 2033029
#* What users care about: a framework for social content alignment
#@ Lei Hou;Juanzi Li;Xiaoli Li;Jiangfeng Qu;Xiaofei Guo;Ou Hui;Jie Tang
#t 2013
#c 11
#% 169806
#% 464641
#% 642990
#% 727883
#% 788094
#% 1055680
#% 1055683
#% 1275203
#% 1279298
#% 1481557
#% 1560208
#% 1598359
#% 1606021
#% 1642195
#% 1826290
#% 1872384
#! With the rapid proliferation of social media, more and more people freely express their opinions (or comments) on news, products, and movies through online services such as forums, discussion groups, and microblogs. Those comments may be concerned with different aspects (topics) of the target Web document (e.g., a news page). It would be interesting to align the social comments to the corresponding subtopics contained in the Web document. In this paper, we propose a novel framework that is able to automatically detect the subtopics from a given Web document, and also align the associated social comments with the detected subtopics. This provides a new view of the Web standard document and its associated user generated content through topics, which facilitates the readers to quickly focus on those hot topics or grasp topics that they are interested in. Extensive experiments show that our proposed framework significantly outperforms the existing state-of-the-art methods in social content alignment.

#index 2033030
#* Efficient kernel learning from side information using ADMM
#@ En-Liang Hu;James T. Kwok
#t 2013
#c 11
#% 209961
#% 464291
#% 722815
#% 763697
#% 770846
#% 961190
#% 961218
#% 983849
#% 995140
#% 1073944
#% 1232019
#% 1606366
#% 1745124
#% 1872317
#! Side information is highly useful in the learning of a nonparametric kernel matrix. However, this often leads to an expensive semidefinite program (SDP). In recent years, a number of dedicated solvers have been proposed. Though much better than off-the-shelf SDP solvers, they still cannot scale to large data sets. In this paper, we propose a novel solver based on the alternating direction method of multipliers (ADMM). The key idea is to use a low-rank decomposition of the kernel matrix K = VTU, with the constraint that V = U. The resultant optimization problem, though non-convex, has favorable convergence properties and can be efficiently solved without requiring eigen-decomposition in each iteration. Experimental results on a number of real-world data sets demonstrate that the proposed method is as accurate as directly solving the SDP, but can be one to two orders of magnitude faster.

#index 2033031
#* Active learning via neighborhood reconstruction
#@ Yao Hu;Debing Zhang;Zhongming Jin;Deng Cai;Xiaofei He
#t 2013
#c 11
#% 236729
#% 464268
#% 722797
#% 724192
#% 876080
#% 1073978
#% 1074378
#% 1211771
#% 1302843
#% 1302853
#% 1378800
#% 1606397
#% 1632603
#% 1755382
#% 1856668
#% 1875731
#! In many real world scenarios, active learning methods are used to select the most informative points for labeling to reduce the expensive human action. One direction for active learning is selecting the most representative points, ie., selecting the points that other points can be approximated by linear combination of the selected points. However, these methods fails to consider the local geometrical information of the data space. In this paper, we propose a novel framework named Active Learning via Neighborhood Reconstruction (ALNR) by taking into account the locality information directly during the selection. Specifically, for the linear reconstruction of target point, the nearer neighbors should have a greater effect and the selected points distant from the target point should be penalized severely. We further develop an efficient two-stage iterative procedure to solve the final optimization problem. Our empirical study shows encouraging results of the proposed algorithms in comparison to other state-of-the-art active learning algorithms on both synthetic and real visual data sets.

#index 2033032
#* Online hashing
#@ Long-Kai Huang;Qiang Yang;Wei-Shi Zheng
#t 2013
#c 11
#% 347225
#% 762054
#% 874628
#% 879566
#% 961152
#% 983903
#% 1073910
#% 2000600
#! Hash function learning has been recently received more and more attentions in fast search for large scale data. However, existing popular learning based hashing methods are batch-based learning models and thus incur large scale computational problem for learning an optimal model on a large scale of labelled data and cannot handle data which comes sequentially. In this paper, we address the problem by developing an online hashing learning algorithm to get hashing model accommodate to each new pair of data. At the same time the new updated hash model is penalized by the last learned model in order to retain important information learned in previous rounds. We also derive a tight bound for the cumulative loss of our proposed online learning algorithm. The experimental results demonstrate superiority of the proposed online hashing model on searching both metric distance neighbors and semantical similar neighbors in the experiments.

#index 2033033
#* Discovering different types of topics: factored topic models
#@ Yun Jiang;Ashutosh Saxena
#t 2013
#c 11
#% 280819
#% 303620
#% 722904
#% 778215
#% 788094
#% 876067
#% 939346
#% 1050550
#% 1055681
#% 1083684
#% 1156096
#% 1211794
#% 1270334
#% 1273828
#% 1481541
#% 1613459
#% 1642074
#% 1647349
#% 1935799
#% 2014439
#! In traditional topic models such as LDA, a word is generated by choosing a topic from a collection. However, existing topic models do not identify different types of topics in a document, such as topics that represent the content and topics that represent the sentiment. In this paper, our goal is to discover such different types of topics, if they exist. We represent our model as several parallel topic models (called topic factors), where each word is generated from topics from these factors jointly. Since the latent membership of the word is now a vector, the learning algorithms become challenging. We show that using a variational approximation still allows us to keep the algorithm tractable. Our experiments over several datasets show that our approach consistently outperforms many classic topic models while also discovering fewer, more meaningful, topics.

#index 2033034
#* Prior-free exploration bonus for and beyond near bayes-optimal behavior
#@ Kenji Kawaguchi;Hiroshi Sato
#t 2013
#c 11
#% 284108
#% 363744
#% 384911
#% 466731
#% 715337
#% 722895
#% 840955
#% 876032
#% 1133454
#% 1139016
#% 1211754
#% 1661375
#! We study Bayesian reinforcement learning (RL) as a solution of the exploration-exploitation dilemma. As full Bayesian planning is intractable except for special cases, previous work has proposed several approximation methods. However, these were often computationally expensive or limited to Dirichlet priors. In this paper, we propose a new algorithm that is fast and of polynomial time for near Bayesian optimal policy with any prior distributions that are not greatly misspecified. Perhaps even more interestingly, the proposed algorithm can naturally avoid being misled by incorrect beliefs, while effectively utilizing useful parts of prior information. It can work well even when an utterly misspecified prior is assigned. In that case, the algorithm will follow PAC-MDP behavior instead, if an existing PACMDP algorithm does so. The proposed algorithm naturally outperformed other algorithms compared with it on a standard benchmark problem.

#index 2033035
#* Causal inference with rare events in large-scale time-series data
#@ Samantha Kleinberg
#t 2013
#c 11
#% 129987
#% 297171
#% 297770
#% 333929
#% 333934
#% 664713
#% 716892
#% 765520
#% 1031998
#% 1041672
#% 1072322
#% 1202160
#% 1417087
#% 1673418
#% 1826214
#! Large-scale observational datasets are prevalent in many areas of research, including biomedical informatics, computational social science, and finance. However, our ability to use these data for decision-making lags behind our ability to collect and mine them. One reason for this is the lack of methods for inferring the causal impact of rare events. In cases such as the monitoring of continuous data streams from intensive care patients, social media, or finance, though, rare events may in fact be the most important ones-signaling critical changes in a patient's status or trading volume. While prior data mining approaches can identify or predict rare events, they cannot determine their impact, and probabilistic causal inference methods fail to handle inference with infrequent events. Instead, we develop a new approach to finding the causal impact of rare events that leverages the large amount of data available to infer a model of a system's functioning and evaluates how rare events explain deviations from usual behavior. Using simulated data, we evaluate the approach and compare it against others, demonstrating that it can accurately infer the effects of rare events.

#index 2033036
#* Active learning for teaching a robot grounded relational symbols
#@ Johannes Kulick;Marc Toussaint;Tobias Lang;Manuel Lopes
#t 2013
#c 11
#% 85153
#% 333786
#% 401697
#% 891549
#% 1272161
#% 1272282
#% 1369255
#% 1545551
#% 1721923
#% 1766092
#! We investigate an interactive teaching scenario, where a human teaches a robot symbols which abstract the geometric properties of objects. There are multiple motivations for this scenario: First, state-of-the-art methods for relational reinforcement learning demonstrate that we can learn and employ strongly generalizing abstract models with great success for goal-directed object manipulation. However, these methods rely on given grounded action and state symbols and raise the classical question: Where do the symbols come from? Second, existing research on learning from human-robot interaction has focused mostly on the motion level (e.g., imitation learning). However, if the goal of teaching is to enable the robot to autonomously solve sequential manipulation tasks in a goal-directed manner, the human should have the possibility to teach the relevant abstractions to describe the task and let the robot eventually leverage powerful relational RL methods. In this paper we formalize human-robot teaching of grounded symbols as an active learning problem, where the robot actively generates pick-and-place geometric situations that maximize its information gain about the symbol to be learned. We demonstrate that the learned symbols can be used by a robot in a relational RL framework to learn probabilistic relational rules and use them to solve object manipulation tasks in a goal-directed manner.

#index 2033037
#* Adaptive thresholding in structure learning of a Bayesian network
#@ Boaz Lerner;Michal Afek;Rafi Bojmel
#t 2013
#c 11
#% 44876
#% 115608
#% 129987
#% 185971
#% 197387
#% 297171
#% 388439
#% 400980
#% 722900
#% 893460
#% 961134
#% 961210
#% 961266
#% 1385960
#% 1386105
#% 1457139
#% 1477185
#% 1551194
#% 1650277
#% 1650282
#% 1650673
#% 1673062
#! Thresholding a measure in conditional independence (CI) tests using a fixed value enables learning and removing edges as part of learning a Bayesian network structure. However, the learned structure is sensitive to the threshold that is commonly selected: 1) arbitrarily; 2) irrespective of characteristics of the domain; and 3) fixed for all CI tests. We analyze the impact on mutual information - a CI measure - of factors, such as sample size, degree of variable dependence, and variables' cardinalities. Following, we suggest to adaptively threshold individual tests based on the factors. We show that adaptive thresholds better distinguish between pairs of dependent variables and pairs of independent variables and enable learning structures more accurately and quickly than when using fixed thresholds.

#index 2033038
#* A Bayesian factorised covariance model for image analysis
#@ Jun Li;Dacheng Tao
#t 2013
#c 11
#% 443790
#% 457831
#% 996872
#% 1013661
#% 1164188
#% 1164191
#! This paper presents a specialised Bayesian model for analysing the covariance of data that are observed in the form of matrices, which is particularly suitable for images. Compared to existing general-purpose covariance learning techniques, we exploit the fact that the variables are organised as an array with two sets of ordered indexes, which induces innate relationship between the variables. Specifically, we adopt a factorised structure for the covariance matrix. The covariance of two variables is represented by the product of the covariance of the two corresponding rows and that of the two columns. The factors, i.e. the row-wise and column-wise covariance matrices are estimated by Bayesian inference with sparse priors. Empirical study has been conducted on image analysis. The model first learns correlations between the rows and columns in an image plane. Then the correlations between individual pixels can be inferred by their locations. This scheme utilises the structural information of an image, and benefits the analysis when the data are damaged or insufficient.

#index 2033039
#* Low-rank coding with b-matching constraint for semi-supervised classification
#@ Sheng Li;Yun Fu
#t 2013
#c 11
#% 235342
#% 336073
#% 443790
#% 732522
#% 1018766
#% 1022958
#% 1164188
#% 1211745
#% 1275154
#% 1455666
#% 1750545
#% 1884049
#% 1884255
#% 1931663
#! Graph based semi-supervised learning (GSSL) plays an important role in machine learning systems. The most crucial step in GSSL is graph construction. Although several interesting graph construction methods have been proposed in recent years, how to construct an effective graph is still an open problem. In this paper, we develop a novel approach to constructing graph, which is based on low-rank coding and b-matching constraint. By virtue of recent advances in low-rank subspace recovery theory, compact encoding using low-rank representation coefficients allows us to obtain a robust similarity metric between all pairs of samples. Meanwhile, the b-matching constraint helps in obtaining a sparse and balanced graph, which benefits label propagation in GSSL. We build a joint optimization model to learn low-rank codes and balanced graph simultaneously. After using a graph re-weighting strategy, we present a semi-supervised learning algorithm by incorporating our sparse and balanced graph with Gaussian harmonic function (GHF). Experimental results on the Extended YaleB, PIE, ORL and USPS databases demonstrate that our graph outperforms several state-of-the-art graphs, especially when the labeled samples are very scarce.

#index 2033040
#* Active learning with multi-label SVM classification
#@ Xin Li;Yuhong Guo
#t 2013
#c 11
#% 169717
#% 424085
#% 457912
#% 458379
#% 464268
#% 466576
#% 722924
#% 724192
#% 760805
#% 763699
#% 763708
#% 829013
#% 1100053
#% 1132472
#% 1195838
#% 1214713
#% 1260420
#% 1264829
#% 1269476
#% 1274885
#% 1667612
#! Multi-label classification, where each instance is assigned to multiple categories, is a prevalent problem in data analysis. However, annotations of multi-label instances are typically more time-consuming or expensive to obtain than annotations of single-label instances. Though active learning has been widely studied on reducing labeling effort for single-label problems, current research on multi-label active learning remains in a preliminary state. In this paper, we first propose two novel multi-label active learning strategies, a max-margin prediction uncertainty strategy and a label cardinality inconsistency strategy, and then integrate them into an adaptive framework of multi-label active learning. Our empirical results on multiple multilabel data sets demonstrate the efficacy of the proposed active instance selection strategies and the integrated active learning approach.

#index 2033041
#* Large-scale spectral clustering on graphs
#@ Jialu Liu;Chi Wang;Marina Danilevsky;Jiawei Han
#t 2013
#c 11
#% 313959
#% 342621
#% 434557
#% 732552
#% 1074115
#% 1127445
#% 1214712
#% 1254273
#% 1392457
#% 1537112
#% 1665175
#% 1872334
#! Graph clustering has received growing attention in recent years as an important analytical technique, both due to the prevalence of graph data, and the usefulness of graph structures for exploiting intrinsic data characteristics. However, as graph data grows in scale, it becomes increasingly more challenging to identify clusters. In this paper we propose an efficient clustering algorithm for large-scale graph data using spectral methods. The key idea is to repeatedly generate a small number of "supernodes" connected to the regular nodes, in order to compress the original graph into a sparse bipartite graph. By clustering the bipartite graph using spectral methods, we are able to greatly improve efficiency without losing considerable clustering power. Extensive experiments show the effectiveness and efficiency of our approach.

#index 2033042
#* Learning discriminative representations from RGB-D video data
#@ Li Liu;Ling Shao
#t 2013
#c 11
#% 443991
#% 490965
#% 876218
#% 983863
#% 997125
#% 1058303
#% 1126935
#% 1211766
#% 1248877
#% 1418210
#% 1883645
#% 1884262
#% 1937917
#! Recently, the low-cost Microsoft Kinect sensor, which can capture real-time high-resolution RGB and depth visual information, has attracted increasing attentions for a wide range of applications in computer vision. Existing techniques extract hand-tuned features from the RGB and the depth data separately and heuristically fuse them, which would not fully exploit the complementarity of both data sources. In this paper, we introduce an adaptive learning methodology to automatically extract (holistic) spatio-temporal features, simultaneously fusing the RGB and depth information, from RGB-D video data for visual recognition tasks. We address this as an optimization problem using our proposed restricted graph-based genetic programming (RGGP) approach, in which a group of primitive 3D operators are first randomly assembled as graph-based combinations and then evolved generation by generation by evaluating on a set of RGB-D video samples. Finally the best-performed combination is selected as the (near-)optimal representation for a pre-defined task. The proposed method is systematically evaluated on a new hand gesture dataset, SKIG, that we collected ourselves and the public MSR Daily Activity 3D dataset, respectively. Extensive experimental results show that our approach leads to significant advantages compared with state-of-the-art hand-crafted and machine-learned features.

#index 2033043
#* Online expectation maximization for reinforcement learning in POMDPs
#@ Miao Liu;Xuejun Liao;Lawrence Carin
#t 2013
#c 11
#% 169358
#% 384911
#% 464448
#% 702594
#% 770768
#% 1211825
#% 1232046
#% 1290265
#% 1565056
#% 1650314
#! We present online nested expectation maximization for model-free reinforcement learning in a POMDP. The algorithm evaluates the policy only in the current learning episode, discarding the episode after the evaluation and memorizing the sufficient statistic, from which the policy is computed in closed-form. As a result, the online algorithm has a time complexity O(n) and a memory complexity O(1), compared to O(n2) and O(n) for the corresponding batch-mode algorithm, where n is the number of learning episodes. The online algorithm, which has a provable convergence, is demonstrated on five benchmark POMDP problems.

#index 2033044
#* The multi-feature information bottleneck with application to unsupervised image categorization
#@ Zhengzheng Lou;Yangdong Ye;Xiaoqiang Yan
#t 2013
#c 11
#% 115608
#% 309128
#% 397139
#% 760805
#% 836717
#% 836905
#% 884039
#% 889294
#% 1058303
#% 1211703
#% 1378797
#% 1408842
#% 1426538
#% 1484524
#% 1495393
#% 1730622
#% 1884327
#! We present a novel unsupervised data analysis method, Multi-feature Information Bottleneck (MfIB), which is an extension of the Information Bottleneck (IB). In comparison with the original IB, the proposed MfIB method can analyze the data simultaneously from multiple feature variables, which characterize the data from multiple cues. To verify the effectiveness of MfIB, we apply the corresponding MfIB algorithm to unsupervised image categorization. In our experiments, by taking into account multiple types of features, such as local shape, color and texture, the MfIB algorithm is found to be consistently superior to the original IB algorithm which takes only one source of features into consideration. Besides, the performance of MfIB algorithm is also superior to the state-of-the-art unsupervised image categorization methods.

#index 2033045
#* Learning canonical correlations of paired tensor sets via tensor-to-vector projection
#@ Haiping Lu
#t 2013
#c 11
#% 732522
#% 769911
#% 812370
#% 855563
#% 1013661
#% 1074000
#% 1176933
#% 1211706
#% 1246227
#% 1300087
#% 1302072
#% 1356632
#% 1549672
#% 1736955
#% 1862054
#! Canonical correlation analysis (CCA) is a useful technique for measuring relationship between two sets of vector data. For paired tensor data sets, we propose a multilinear CCA (MCCA) method. Unlike existing multilinear variations of CCA, MCCA extracts uncorrelated features under two architectures while maximizing paired correlations. Through a pair of tensor-to-vector projections, one architecture enforces zero-correlation within each set while the other enforces zero-correlation between different pairs of the two sets. We take a successive and iterative approach to solve the problem. Experiments on matching faces of different poses show that MCCA outperforms CCA and 2D- CCA, while using much fewer features. In addition, the fusion of two architectures leads to performance improvement, indicating complementary information.

#index 2033046
#* Learning descriptive visual representation by semantic regularized matrix factorization
#@ Zhiwu Lu;Yuxin Peng
#t 2013
#c 11
#% 424085
#% 760805
#% 883972
#% 1038899
#% 1070800
#% 1108903
#% 1116393
#% 1132472
#% 1164188
#% 1358071
#% 1595860
#% 1648811
#% 1730622
#% 1780377
#% 1856288
#% 1856571
#! This paper presents a novel semantic regularized matrix factorization method for learning descriptive visual bag-of-words (BOW) representation. Although very influential in image classification, the traditional visual BOW representation has one distinct drawback. That is, for efficiency purposes, this visual representation is often generated by directly clustering the low-level visual feature vectors extracted from local keypoints or regions, without considering the high-level semantics of images. In other words, this visual representation still suffers from the semantic gap and may lead to significant performance degradation in more challenging tasks (e.g., classification of community-contributed images with large intra-class variations). To overcome this drawback, we develop a semantic regularized matrix factorization method for learning descriptive visual BOW representation by adding Laplacian regularization defined with the tags (easy to access although noisy) of community-contributed images into matrix factorization. Experimental results on two benchmark datasets show the promising performance of the proposed method.

#index 2033047
#* Thinking of images as what they are: compound matrix regression for image classification
#@ Zhigang Ma;Yi Yang;Feiping Nie;Nicu Sebe
#t 2013
#c 11
#% 80995
#% 727684
#% 784540
#% 812492
#% 812512
#% 812612
#% 861251
#% 961218
#% 1493669
#% 1495489
#% 1649042
#% 1750251
#% 1755445
#% 1885542
#% 2014147
#! In this paper, we propose a new classification framework for image matrices. The approach is realized by learning two groups of classification vectors for each dimension of the image matrices. One novelty is that we utilize compound regression models in the learning process, which endows the algorithm increased degree of freedom. On top of that, we extend the two-dimensional classification method to a semi-supervised classifier which leverages both labeled and unlabeled data. A fast iterative solution is then proposed to solve the objective function. The proposed method is evaluated by several different applications. The experimental results show that our method outperforms several classification approaches. In addition, we observe that our method attains respectable classification performance even when only few labeled training samples are provided. This advantage is especially desirable for real-world problems since precisely annotated images are scarce.

#index 2033048
#* An empirical investigation of ceteris paribus learnability
#@ Loizos Michael;Elena Papageorgiou
#t 2013
#c 11
#% 697
#% 1272026
#% 1305424
#% 1305592
#% 1427870
#% 1947796
#! Eliciting user preferences constitutes a major step towards developing recommender systems and decision support tools. Assuming that preferences are ceteris paribus allows for their concise representation as Conditional Preference Networks (CP-nets). This work presents the first empirical investigation of an algorithm for reliably and efficiently learning CP-nets in a manner that is minimally intrusive. At the same time, it introduces a novel process for efficiently reasoning with (the learned) preferences.

#index 2033049
#* Statistical tests for the detection of the arrow of time in vector autoregressive models
#@ Pablo Morales-Mombiela;Daniel Hernández-Lobato;Alberto Suárez
#t 2013
#c 11
#% 925382
#% 1211790
#% 1267791
#% 1826273
#! The problem of detecting the direction of time in vector Autoregressive (VAR) processes using statistical techniques is considered. By analogy to causal AR(1) processes with non-Gaussian noise, we conjecture that the distribution of the time reversed residuals of a linear VAR model is closer to a Gaussian than the distribution of actual residuals in the forward direction. Experiments with simulated data illustrate the validity of the conjecture. Based on these results, we design a decision rule for detecting the direction of VAR processes. The correct direction in time (forward) is the one in which the residuals of the time series are less Gaussian. A series of experiments illustrate the superior results of the proposed rule when compared with other methods based on independence tests.

#index 2033050
#* Meta-interpretive learning of higher-order dyadic datalog: predicate invention revisited
#@ Stephen Muggleton;Dianhuan Lin
#t 2013
#c 11
#% 697
#% 66937
#% 126861
#% 382569
#% 384911
#% 449508
#% 550402
#% 643852
#% 1222482
#% 1275150
#% 1313373
#% 1499982
#% 1693532
#% 1711773
#% 1718464
#% 1718486
#% 1932317
#! In recent years Predicate Invention has been under-explored within Inductive Logic Programming due to difficulties in formulating efficient search mechanisms. However, a recent paper demonstrated that both predicate invention and the learning of recursion can be efficiently implemented for regular and context-free grammars, by way of abduction with respect to a meta-interpreter. New predicate symbols are introduced as constants representing existentially quantified higher-order variables. In this paper we generalise the approach of Meta-Interpretive Learning (MIL) to that of learning higher-order dyadic datalog programs. We show that with an infinite signature the higher-order dyadic datalog class H22 has universal Turing expressivity though H22 is decidable given a finite signature. Additionally we show that Knuth-Bendix ordering of the hypothesis space together with logarithmic clause bounding allows our Dyadic MIL implementation MetagolD to PAC-learn minimal cardinailty H22 definitions. This result is consistent with our experiments which indicate that MetagolD efficiently learns compact H22 definitions involving predicate invention for robotic strategies and higher-order concepts in the NELL language learning domain.

#index 2033051
#* Multi-modal image annotation with multi-instance multi-label LDA
#@ Cam-Tu Nguyen;De-Chuan Zhan;Zhi-Hua Zhou
#t 2013
#c 11
#% 252011
#% 457912
#% 642990
#% 722904
#% 788094
#% 1309523
#% 1451240
#% 1464094
#% 1480880
#% 1558464
#% 1647350
#% 1872027
#% 1872293
#! This paper studies the problem of image annotation in a multi-modal setting where both visual and textual information are available. We propose Multimodal Multi-instance Multi-label Latent Dirichlet Allocation (M3LDA), where the model consists of a visual-label part, a textual-label part and a label-topic part. The basic idea is that the topic decided by the visual information and the topic decided by the textual information should be consistent, leading to the correct label assignment. Particularly, M3LDA is able to annotate image regions, thus provides a promising way to understand the relation between input patterns and output semantics. Experiments on Corel5K and ImageCLEF validate the effectiveness of the proposed method.

#index 2033052
#* Adaptive loss minimization for semi-supervised elastic embedding
#@ Feiping Nie;Hua Wang;Heng Huang;Chris Ding
#t 2013
#c 11
#% 464615
#% 466263
#% 593047
#% 757953
#% 961218
#% 989597
#% 1246174
#% 1268061
#% 1474964
#% 1688445
#% 1885652
#! The semi-supervised learning usually only predict labels for unlabeled data appearing in training data, and cannot effectively predict labels for testing data never appearing in training set. To handle this out-of-sample problem, many inductive methods make a constraint such that the predicted label matrix should be exactly equal to a linear model. In practice, this constraint is too rigid to capture the manifold structure of data. Motivated by this deficiency, we relax the rigid linear embedding constraint and propose to use an elastic embedding constraint on the predicted label matrix such that the manifold structure can be better explored. To solve our new objective and also a more general optimization problem, we study a novel adaptive loss with efficient optimization algorithm. Our new adaptive loss minimization method takes the advantages of both L1 norm and L2 norm, and is robust to the data outlier under Laplacian distribution and can efficiently learn the normal data under Gaussian distribution. Experiments have been performed on image classification tasks and our approach outperforms other state-of-the-art methods.

#index 2033053
#* Early active learning via robust representation and structured sparsity
#@ Feiping Nie;Hua Wang;Heng Huang;Chris Ding
#t 2013
#c 11
#% 116165
#% 235342
#% 236729
#% 336073
#% 466263
#% 770771
#% 876080
#% 950571
#% 1074130
#% 1373023
#% 1378799
#% 1396658
#% 1495503
#% 1868032
#! Labeling training data is quite time-consuming but essential for supervised learning models. To solve this problem, the active learning has been studied and applied to select the informative and representative data points for labeling. However, during the early stage of experiments, only a small number (or none) of labeled data points exist, thus the most representative samples should be selected first. In this paper, we propose a novel robust active learning method to handle the early stage experimental design problem and select the most representative data points. Selecting the representative samples is an NP-hard problem, thus we employ the structured sparsity-inducing norm to relax the objective to an efficient convex formulation. Meanwhile, the robust sparse representation loss function is utilized to reduce the effect of outliers. A new efficient optimization algorithm is introduced to solve our non-smooth objective with low computational cost and proved global convergence. Empirical results on both single-label and multi-label classification benchmark data sets show the promising results of our method.

#index 2033054
#* Annealed importance sampling for structure learning in Bayesian networks
#@ Teppo Niinimäki;Mikko Koivisto
#t 2013
#c 11
#% 44876
#% 90740
#% 129987
#% 197387
#% 297171
#% 424845
#% 763715
#% 830659
#% 1058706
#% 1126604
#% 1275122
#% 1417114
#% 1673062
#! We present a new sampling approach to Bayesian learning of the Bayesian network structure. Like some earlier sampling methods, we sample linear orders on nodes rather than directed acyclic graphs (DAGs). The key difference is that we replace the usual Markov chain Monte Carlo (MCMC) method by the method of annealed importance sampling (AIS). We show that AIS is not only competitive to MCMC in exploring the posterior, but also superior to MCMC in two ways: it enables easy and efficient parallelization, due to the independence of the samples, and lower-bounding of the marginal likelihood of the model with good probabilistic guarantees. We also provide a principled way to correct the bias due to order-based sampling, by implementing a fast algorithm for counting the linear extensions of a given partial order.

#index 2033055
#* Graph classification with imbalanced class distributions and noise
#@ Shirui Pan;Xingquan Zhu
#t 2013
#c 11
#% 359201
#% 629708
#% 813990
#% 1183448
#% 1227871
#% 1246173
#% 1301405
#% 1356669
#% 1451204
#% 1451219
#% 1918355
#% 2010433
#! Recent years have witnessed an increasing number of applications involving data with structural dependency and graph representations. For these applications, it is very common that their class distribution is imbalanced with minority samples being only a small portion of the population. Such imbalanced class distributions impose significant challenges to the learning algorithms. This problem is further complicated with the presence of noise or outliers in the graph data. In this paper, we propose an imbalanced graph boosting algorithm, igBoost, that progressively selects informative subgraph patterns from imbalanced graph data for learning. To handle class imbalance, we take class distributions into consideration to assign different weight values to graphs. The distance of each graph to its class center is also considered to adjust the weight to reduce the impact of noisy graph data. The weight values are integrated into the iterative subgraph feature selection and margin learning process to achieve maximum benefits. Experiments on real-world graph data with different degrees of class imbalance and noise demonstrate the algorithm performance.

#index 2033056
#* Hierarchical Bayesian matrix factorization with side information
#@ Sunho Park;Yong-Deok Kim;Seungjin Choi
#t 2013
#c 11
#% 840924
#% 1073982
#% 1083696
#% 1100108
#% 1214623
#% 1232028
#% 1260273
#% 1617375
#% 1756613
#! Bayesian treatment of matrix factorization has been successfully applied to the problem of collaborative prediction, where unknown ratings are determined by the predictive distribution, inferring posterior distributions over user and item factor matrices that are used to approximate the user-item matrix as their product. In practice, however, Bayesian matrix factorization suffers from cold-start problems, where inferences are required for users or items about which a sufficient number of ratings are not gathered. In this paper we present a method for Bayesian matrix factorization with side information, to handle cold-start problems. To this end, we place Gaussian-Wishart priors on mean vectors and precision matrices of Gaussian user and item factor matrices, such that mean of each prior distribution is regressed on corresponding side information. We develop variational inference algorithms to approximately compute posterior distributions over user and item factor matrices. In addition, we provide Bayesian Cramér-Rao Bound for our model, showing that the hierarchical Bayesian matrix factorization with side information improves the reconstruction over the standard Bayesian matrix factorization where the side information is not used. Experiments on MovieLens data demonstrate the useful behavior of our model in the case of cold-start problems.

#index 2033057
#* A scalable approach to column-based low-rank matrix approximation
#@ Yifan Pi;Haoruo Peng;Shuchang Zhou;Zhihua Zhang
#t 2013
#c 11
#% 215859
#% 224113
#% 309047
#% 336073
#% 420515
#% 453490
#% 800190
#% 801585
#% 870226
#% 916799
#% 975106
#% 1133926
#% 1164922
#% 1287866
#% 1426210
#% 1654518
#% 1658035
#% 1668262
#% 1702019
#% 1745120
#% 1903552
#! In this paper, we address the column-based low-rank matrix approximation problem using a novel parallel approach. Our approach is based on the divide-and-combine idea. We first perform column selection on submatrices of an original data matrix in parallel, and then combine the selected columns into the final output. Our approach enjoys a theoretical relative-error upper bound. In addition, our column-based low-rank approximation partitions data in a deterministic way and makes no assumptions about matrix coherence. Compared with other traditional methods, our approach is scalable on large-scale matrices. Finally, experiments on both simulated and real world data show that our approach is both efficient and effective.

#index 2033058
#* Multiple task learning using iteratively reweighted least square
#@ Jian Pu;Yu-Gang Jiang;Jun Wang;Xiangyang Xue
#t 2013
#c 11
#% 236497
#% 616105
#% 723239
#% 770804
#% 840962
#% 916788
#% 961246
#% 1073879
#% 1128929
#% 1211707
#% 1417091
#% 1451260
#% 1605917
#% 1606019
#% 1654243
#% 1759787
#% 1761292
#% 1872338
#% 1885652
#! Multiple task learning (MTL) is becoming popular due to its theoretical advances and empirical successes. The key idea of MTL is to explore the hidden relationships among multiple tasks to enhance learning performance. Recently, many MTL algorithms have been developed and applied to various problems such as feature selection and kernel learning. However, most existing methods highly relied on certain assumptions of the task relationships. For instance, several works assumed that there is a major task group and several outlier tasks, and used a decomposition approach to identify the group structure and outlier tasks simultaneously. In this paper, we adopt a more general formulation for MTL without making specific structure assumptions. Instead of performing model decomposition, we directly impose an elastic-net regularization with a mixture of the structure and outlier penalties and formulate the objective as an unconstrained convex problem. To derive the optimal solution efficiently, we propose to use an Iteratively Reweighted Least Square (IRLS) method with a preconditioned conjugate gradient, which is computationally affordable for high dimensional data. Extensive experiments are conducted over both synthetic and real data, and comparisons with several state-of-the-art algorithms clearly show the superior performance of the proposed method.

#index 2033059
#* Active learning from relative queries
#@ Buyue Qian;Xiang Wang;Fei Wang;Hongfei Li;Jieping Ye;Ian Davidson
#t 2013
#c 11
#% 169717
#% 341672
#% 464268
#% 479973
#% 529191
#% 770807
#% 875997
#% 876068
#% 1264829
#% 1269476
#% 1274885
#% 1274894
#% 1415435
#% 1606029
#% 1872312
#% 1872318
#% 1872390
#! Active learning has been extensively studied and shown to be useful in solving real problems. The typical setting of traditional active learning methods is querying labels from an oracle. This is only possible if an expert exists, which may not be the case in many real world applications. In this paper, we focus on designing easier questions that can be answered by a non-expert. These questions poll relative information as opposed to absolute information and can be even generated from sideinformation. We propose an active learning approach that queries the ordering of the importance of an instance's neighbors rather than its label. We explore our approach on real datasets and make several interesting discoveries including that querying neighborhood information can be an effective question to ask and sometimes can even yield better performance than querying labels.

#index 2033060
#* Robust unsupervised feature selection
#@ Mingjie Qian;Chengxiang Zhai
#t 2013
#c 11
#% 73441
#% 80995
#% 143194
#% 190265
#% 190581
#% 243728
#% 313959
#% 722929
#% 722938
#% 735256
#% 983948
#% 1270195
#% 1288794
#% 1298163
#% 1305456
#% 1451172
#% 1474964
#% 1641992
#% 1826269
#% 1826274
#% 1826317
#! A new unsupervised feature selection method, i.e., Robust Unsupervised Feature Selection (RUFS), is proposed. Unlike traditional unsupervised feature selection methods, pseudo cluster labels are learned via local learning regularized robust nonnegative matrix factorization. During the label learning process, feature selection is performed simultaneously by robust joint l2,1 norms minimization. Since RUFS utilizes l2,1 norm minimization on processes of both label learning and feature learning, outliers and noise could be effectively handled and redundant or noisy features could be effectively reduced. Our method adopts the advantages of robust non-negative matrix factorization, local learning, and robust feature learning. In order to make RUFS be scalable, we design a (projected) limited-memory BFGS based iterative algorithm to efficiently solve the optimization problem of RUFS in terms of both memory consumption and computation complexity. Experimental results on different benchmark real world datasets show the promising performance of RUFS over the state-of-the-arts.

#index 2033061
#* Path integral control by reproducing kernel Hilbert space embedding
#@ Konrad Rawlik;Marc Toussaint;Sethu Vijayakumar
#t 2013
#c 11
#% 1100645
#% 1211810
#% 1211821
#% 1378114
#% 1473331
#% 1551203
#! We present an embedding of stochastic optimal control problems, of the so called path integral form, into reproducing kernel Hilbert spaces. Using consistent, sample based estimates of the embedding leads to a model-free, non-parametric approach for calculation of an approximate solution to the control problem. This formulation admits a decomposition of the problem into an invariant and task dependent component. Consequently, we make much more efficient use of the sample data compared to previous sample based approaches in this domain, e.g., by allowing sample re-use across tasks. Numerical examples on test problems, which illustrate the sample efficiency, are provided.

#index 2033062
#* Machine-learning-based circuit synthesis
#@ Lior Rokach;Meir Kalech;Gregory Provan;Alexander Feldman
#t 2013
#c 11
#% 102169
#% 275026
#% 407292
#% 439224
#% 586567
#% 833572
#% 1144617
#% 1248844
#% 1394969
#% 1434354
#% 1768084
#! Multi-level logic synthesis is a problem of immense practical significance, and is a key to developing circuits that optimize a number of parameters, such as depth, energy dissipation, reliability, etc. The problem can be defined as the task of taking a collection of components from which one wants to synthesize a circuit that optimizes a particular objective function. This problem is computationally hard, and there are very few automated approaches for its solution. To solve this problem we propose an algorithm, called Circuit-Decomposition Engine (CDE), that is based on learning decision trees, and uses a greedy approach for function learning. We empirically demonstrate that CDE, when given a library of different component types, can learn the function of Disjunctive Normal Form (DNF) Boolean representations and synthesize circuit structure using the input library. We compare the structure of the synthesized circuits with that of well-known circuits using a range of circuit similarity metrics.

#index 2033063
#* Weighted path as a condensed pattern in a single attributed DAG
#@ Jérémy Sanhes;Frédéric Flouvat;Nazha Selmaoui-Folcher;Claude Pasquier;Jean-François Boulicaut
#t 2013
#c 11
#% 320939
#% 337714
#% 443194
#% 464873
#% 478274
#% 501641
#% 629603
#% 629708
#% 729938
#% 731608
#% 841960
#% 902448
#% 1268739
#% 1318771
#% 1402215
#% 1411112
#% 1616854
#% 1710149
#% 1710568
#! Directed acyclic graphs can be used across many application domains. In this paper, we study a new pattern domain for supporting their analysis. Therefore, we propose the pattern language of weighted paths, primitive constraints that enable to specify their relevancy (e.g., frequency and compactness constraints), and algorithms that can compute the specified collections. It leads to a condensed representation setting whose efficiency and scalability are empirically studied.

#index 2033064
#* Multi-dimensional causal discovery
#@ Ulrich Schaechtle;Kostas Stathis;Stefano Bromuri
#t 2013
#c 11
#% 44876
#% 297171
#% 313975
#% 316150
#% 812373
#% 891559
#% 961205
#% 1073925
#% 1300087
#% 1440394
#% 1472286
#% 1580949
#! We propose a method for learning causal relations within high-dimensional tensor data as they are typically recorded in non-experimental databases. The method allows the simultaneous inclusion of numerous dimensions within the data analysis such as samples, time and domain variables construed as tensors. In such tensor data we exploit and integrate non-Gaussian models and tensor analytic algorithms in a novel way. We prove that we can determine simple causal relations independently of how complex the dimensionality of the data is. We rely on a statistical decomposition that flattens higher-dimensional data tensors into matrices. This decomposition preserves the causal information and is therefore suitable for structure learning of causal graphical models, where a causal relation can be generalised beyond dimension, for example, over all time points. Related methods either focus on a set of samples for instantaneous effects or look at one sample for effects at certain time points. We evaluate the resulting algorithm and discuss its performance both with synthetic and real-world data.

#index 2033065
#* Better generalization with forecasts
#@ Tom Schaul;Mark Ring
#t 2013
#c 11
#% 158924
#% 199975
#% 203596
#% 286423
#% 466235
#% 476401
#% 857087
#% 1289484
#% 1615251
#% 1818269
#! Predictive methods are becoming increasingly popular for representing world knowledge in autonomous agents. A recently introduced predictive method that shows particular promise is the General Value Function (GVF), which is more flexible than previous predictive methods and can more readily capture regularities in the agent's sensorimotor stream. The goal of the current paper is to investigate the ability of these GVFs (also called "forecasts") to capture such regularities. We generate focused sets of forecasts and measure their capacity for generalization. We then compare the results with a closely related predictive method (PSRs) already shown to have good generalization abilities. Our results indicate that forecasts provide a substantial improvement in generalization, producing features that lead to better value-function approximation (when computed with linear function approximators) than PSRs and better generalization to as-yet-unseen parts of the state space.

#index 2033066
#* Supervised hypothesis discovery using syllogistic patterns in the biomedical literature
#@ Kazuhiro Seki;Kuniaki Uehara
#t 2013
#c 11
#% 232136
#% 333333
#% 723403
#% 752367
#% 882877
#% 939912
#% 975019
#% 1083647
#% 1250629
#% 1277475
#% 1447016
#% 1549964
#% 1688508
#% 1826315
#! The ever-growing literature in biomedicine makes it virtually impossible for individuals to grasp all the information relevant to their interests. Since even experts' knowledge is limited, important associations among key biomedical concepts may remain unnoticed in the flood of information. Discovering those hidden associations is called hypothesis discovery. This paper reports our approach to this problem taking advantage of a triangular chain of relations extracted from published knowledge. We consider such chains of relations as implicit rules to generate potential hypotheses. The generated hypotheses are then compared with newer knowledge for assessing their validity and, if validated, they are served as positive examples for learning a regression model to rank hypotheses. This framework, called supervised hypothesis discovery, is tested on real-world knowledge from the biomedical literature to demonstrate its effectiveness.

#index 2033067
#* Guarantees of augmented trace norm models in tensor recovery
#@ Ziqiang Shi;Jiqing Han;Tieran Zheng;Ji Li
#t 2013
#c 11
#% 3084
#% 316143
#% 1300087
#% 1302829
#% 1556166
#% 1810658
#% 1814979
#% 1815826
#! This paper studies the recovery guarantees of the models of minimizing ||χ||* + 1/2α||χ||F2 where χ is a tensor and ||χ||* and ||χ||F are the trace and Frobenius norm of respectively. We show that they can efficiently recover low-rank tensors. In particular, they enjoy exact guarantees similar to those known for minimizing ||χ||* under the conditions on the sensing operator such as its null-space property, restricted isometry property, or spherical section property. To recover a low-rank tensor χ0, minimizing ||χ||* + 1/2α||χ||F2 returns the same solution as minimizing ||χ||* almost whenever α ≥ 10 max i ||X(i)0||2.

#index 2033068
#* Hartigan's K-means versus Lloyd's K-means: is it time for a change?
#@ Noam Slonim;Ehud Aharoni;Koby Crammer
#t 2013
#c 11
#% 375388
#% 382854
#% 397139
#% 466083
#% 790143
#% 800188
#% 878207
#% 916785
#% 1813854
#! Hartigan's method for k-means clustering holds several potential advantages compared to the classical and prevalent optimization heuristic known as Lloyd's algorithm. E.g., it was recently shown that the set of local minima of Hartigan's algorithm is a subset of those of Lloyd's method. We develop a closed-form expression that allows to establish Hartigan's method for k-means clustering with any Bregman divergence, and further strengthen the case of preferring Hartigan's algorithm over Lloyd's algorithm. Specifically, we characterize a range of problems with various noise levels of the inputs, for which any random partition represents a local minimum for Lloyd's algorithm, while Hartigan's algorithm easily converges to the correct solution. Extensive experiments on synthetic and real-world data further support our theoretical analysis.

#index 2033069
#* One-class conditional random fields for sequential anomaly detection
#@ Yale Song;Zhen Wen;Ching-Yung Lin;Randall Davis
#t 2013
#c 11
#% 300136
#% 464434
#% 722904
#% 732387
#% 770759
#% 855602
#% 881506
#% 1013670
#% 1202160
#% 1211836
#% 1382627
#% 1383075
#% 1386108
#% 1558463
#% 1558464
#% 2004158
#! Sequential anomaly detection is a challenging problem due to the one-class nature of the data (i.e., data is collected from only one class) and the temporal dependence in sequential data. We present One-Class Conditional Random Fields (OCCRF) for sequential anomaly detection that learn from a one-class dataset and capture the temporal dependence structure, in an unsupervised fashion. We propose a hinge loss in a regularized risk minimization framework that maximizes the margin between each sequence being classified as "normal" and "abnormal." This allows our model to accept most (but not all) of the training data as normal, yet keeps the solution space tight. Experimental results on a number of real-world datasets show our model outperforming several baselines. We also report an exploratory study on detecting abnormal organizational behavior in enterprise social networks.

#index 2033070
#* Measuring statistical dependence via the mutual information dimension
#@ Mahito Sugiyama;Karsten M. Borgwardt
#t 2013
#c 11
#% 159603
#% 187336
#% 722887
#% 1473979
#% 1673681
#% 1865610
#! We propose to measure statistical dependence between two random variables by the mutual information dimension (MID), and present a scalable parameter-free estimation method for this task. Supported by sound dimension theory, our method gives an effective solution to the problem of detecting interesting relationships of variables in massive data, which is nowadays a heavily studied topic in many scientific disciplines. Different from classical Pearson's correlation coefficient, MID is zero if and only if two random variables are statistically independent and is translation and scaling invariant. We experimentally show superior performance of MID in detecting various types of relationships in the presence of noise data. Moreover, we illustrate that MID can be effectively used for feature selection in regression.

#index 2033071
#* Unlearning from demonstration
#@ Keith Sullivan;Ahmed ElMolla;Bill Squires;Sean Luke
#t 2013
#c 11
#% 273900
#% 378932
#% 451703
#% 520224
#% 725787
#% 939769
#% 951455
#% 1038784
#% 1274956
#% 1375728
#% 1477981
#% 1776405
#! When doing learning from demonstration, it is often the case that the demonstrator provides corrective examples to fix errant behavior by the agent or robot. We present a set of algorithms which use this corrective data to identify and remove noisy examples in datasets which caused errant classifications, and ultimately errant behavior. The objective is to actually modify the source datasets rather than solely rely on the noise-insensitivity of the classification algorithm. This is particularly useful in the sparse datasets often found in learning from demonstration experiments. Our approach tries to distinguish between noisy misclassification and mere undersampling of the learning space. If errors are a result of misclassification, we potentially remove the responsible points and update the classifier. We demonstrate our method on UCI Machine Learning datasets at different levels of sparsity and noise, using decision trees, K-Nearest-Neighbor, and support vector machines.

#index 2033072
#* Multi-view maximum entropy discrimination
#@ Shiliang Sun;Guoqing Chao
#t 2013
#c 11
#% 252011
#% 271060
#% 316509
#% 466583
#% 770848
#% 785334
#% 1073994
#% 1074029
#% 1385995
#% 1551183
#% 1551221
#% 1650450
#% 1653965
#% 1743310
#! Maximum entropy discrimination (MED) is a general framework for discriminative estimation based on the well known maximum entropy principle, which embodies the Bayesian integration of prior information with large margin constraints on observations. It is a successful combination of maximum entropy learning and maximum margin learning, and can subsume support vector machines (SVMs) as a special case. In this paper, we present a multi-view maximum entropy discrimination framework that is an extension of MED to the scenario of learning with multiple feature sets. Different from existing approaches to exploiting multiple views, such as co-training style algorithms and co-regularization style algorithms, we propose a new method to make use of the distinct views where classification margins from these views are required to be identical. We give the general form of the solution to the multi-view maximum entropy discrimination, and provide an instantiation under a specific prior formulation which is analogical to a multi-view version of SVMs. Experimental results on real-world data sets show the effectiveness of the proposed multi-view maximum entropy discrimination approach.

#index 2033073
#* Non-negative multiple matrix factorization
#@ Koh Takeuchi;Katsuhiko Ishiguro;Akisato Kimura;Hiroshi Sawada
#t 2013
#c 11
#% 280819
#% 643008
#% 722904
#% 769906
#% 793248
#% 879661
#% 1055681
#% 1130901
#% 1194460
#% 1246302
#% 1275185
#% 1400001
#% 1403206
#% 1440394
#% 1595860
#% 1605960
#% 1605963
#% 1746884
#% 1884010
#% 1978827
#! Non-negative Matrix Factorization (NMF) is a traditional unsupervised machine learning technique for decomposing a matrix into a set of bases and coefficients under the non-negative constraint. NMF with sparse constraints is also known for extracting reasonable components from noisy data. However, NMF tends to give undesired results in the case of highly sparse data, because the information included in the data is insufficient to decompose. Our key idea is that we can ease this problem if complementary data are available that we could integrate into the estimation of the bases and coefficients. In this paper, we propose a novel matrix factorization method called Non-negative Multiple Matrix Factorization (NMMF), which utilizes complementary data as auxiliary matrices that share the row or column indices of the target matrix. The data sparseness is improved by decomposing the target and auxiliary matrices simultaneously, since auxiliary matrices provide information about the bases and coefficients. We formulate NMMF as a generalization of NMF, and then present a parameter estimation procedure derived from the multiplicative update rule. We examined NMMF in both synthetic and real data experiments. The effect of the auxiliary matrices appeared in the improved NMMF performance. We also confirmed that the bases that NMMF obtained from the real data were intuitive and reasonable thanks to the non-negative constraint.

#index 2033074
#* Linear Bayesian reinforcement learning
#@ Nikolaos Tziortziotis;Christos Dimitrakakis;Konstantinos Blekas
#t 2013
#c 11
#% 203596
#% 466731
#% 715337
#% 734920
#% 829011
#% 840860
#% 840955
#% 876032
#% 1073974
#% 1182603
#% 1211754
#% 1233421
#% 1417054
#% 1472281
#% 1495556
#% 1495581
#% 1874059
#% 1932333
#! This paper proposes a simple linear Bayesian approach to reinforcement learning. We show that with an appropriate basis, a Bayesian linear Gaussian model is sufficient for accurately estimating the system dynamics, and in particular when we allow for correlated noise. Policies are estimated by first sampling a transition model from the current posterior, and then performing approximate dynamic programming on the sampled model. This form of approximate Thompson sampling results in good exploration in unknown environments. The approach can also be seen as a Bayesian generalisation of least-squares policy iteration, where the empirical transition matrix is replaced with a sample from the posterior.

#index 2033075
#* Multi class learning with individual sparsity
#@ Ben Zion Vatashsky;Koby Crammer
#t 2013
#c 11
#% 116149
#% 197394
#% 722816
#% 722909
#% 1042631
#% 1211727
#% 1211758
#% 1338580
#% 1385958
#! Multi class problems are everywhere. Given an input the goal is to predict one of a few possible classes. Most previous work reduced learning to minimizing the empirical loss over some training set and an additional regularization term, prompting simple models or some other prior knowledge. Many learning regularizations promote sparsity, that is, small models or small number of features, as performed in group LASSO. Yet, such models do not always represent the classes well. In some problems, for each class, there is a small set of features that represents it well, yet the union of these sets is not small. We propose to use other regularizations that promote this type of sparsity, analyze the generalization property of such formulations, and show empirically that indeed, these regularizations not only perform well, but also promote such sparsity structure.

#index 2033076
#* Coupled attribute analysis on numerical data
#@ Can Wang;Zhong She;Longbing Cao
#t 2013
#c 11
#% 837604
#% 881465
#% 967544
#% 995140
#% 1000422
#% 1270190
#% 1567779
#% 1633202
#% 1642025
#% 1692273
#% 1776128
#% 1826245
#% 1826277
#% 1826297
#% 1826413
#% 1848056
#% 1872272
#! The usual representation of quantitative data is to formalize it as an information table, which assumes the independence of attributes. In real-world data, attributes are more or less interacted and coupled via explicit or implicit relationships. Limited research has been conducted on analyzing such attribute interactions, which only describe a local picture of attribute couplings in an implicit way. This paper proposes a framework of the coupled attribute analysis to capture the global dependency of continuous attributes. Such global couplings integrate the intra-coupled interaction within an attribute (i.e. the correlations between attributes and their own powers) and inter-coupled interaction among different attributes (i.e. the correlations between attributes and the powers of others) to form a coupled representation for numerical objects by the Taylor-like expansion. This work makes one step forward towards explicitly addressing the global interactions of continuous attributes, verified by the applications in data structure analysis, data clustering, and data classification. Substantial experiments on 13 UCI data sets demonstrate that the coupled representation can effectively capture the global couplings of attributes and outperforms the traditional way, supported by statistical analysis.

#index 2033077
#* Manifold alignment preserving global geometry
#@ Chang Wang;Sridhar Mahadevan
#t 2013
#c 11
#% 593047
#% 722927
#% 735134
#% 740901
#% 902496
#% 1074012
#% 1269753
#% 1275191
#% 1305493
#% 1464068
#! This paper proposes a novel algorithm for manifold alignment preserving global geometry. This approach constructs mapping functions that project data instances from different input domains to a new lower-dimensional space, simultaneously matching the instances in correspondence and preserving global distances between instances within the original domains. In contrast to previous approaches, which are largely based on preserving local geometry, the proposed approach is suited to applications where the global manifold geometry needs to be respected. We evaluate the effectiveness of our algorithm for transfer learning in two real-world cross-lingual information retrieval tasks.

#index 2033078
#* Large scale online kernel classification
#@ Jialei Wang;Steven C. H. Hoi;Peilin Zhao;Jinfeng Zhuang;Zhi-Yong Liu
#t 2013
#c 11
#% 302390
#% 563100
#% 881474
#% 961152
#% 1000326
#% 1073905
#% 1073962
#% 1164243
#% 1385999
#% 1606374
#% 1763770
#% 1875717
#% 1945062
#% 1948169
#% 1978752
#% 1978830
#! In this work, we present a new framework for large scale online kernel classification, making kernel methods efficient and scalable for large-scale online learning tasks. Unlike the regular budget kernel online learning scheme that usually uses different strategies to bound the number of support vectors, our framework explores a functional approximation approach to approximating a kernel function/matrix in order to make the subsequent online learning task efficient and scalable. Specifically, we present two different online kernel machine learning algorithms: (i) the Fourier Online Gradient Descent (FOGD) algorithm that applies the random Fourier features for approximating kernel functions; and (ii) the Nyström Online Gradient Descent (NOGD) algorithm that applies the Nyström method to approximate large kernel matrices. We offer theoretical analysis of the proposed algorithms, and conduct experiments for large-scale online classification tasks with some data set of over 1 million instances. Our encouraging results validate the effectiveness and efficiency of the proposed algorithms, making them potentially more practical than the family of existing budget kernel online learning approaches.

#index 2033079
#* Online group feature selection
#@ Jing Wang;Zhong-Qiu Zhao;Xuegang Hu;Yiu-Ming Cheung;Meng Wang;Xindong Wu
#t 2013
#c 11
#% 466912
#% 722929
#% 823363
#% 1076777
#% 1270195
#% 1881281
#% 1923656
#% 1984353
#! Online feature selection with dynamic features has become an active research area in recent years. However, in some real-world applications such as image analysis and email spam filtering, features may arrive by groups. Existing online feature selection methods evaluate features individually, while existing group feature selection methods cannot handle online processing. Motivated by this, we formulate the online group feature selection problem, and propose a novel selection approach for this problem. Our proposed approach consists of two stages: online intra-group selection and online inter-group selection. In the intra-group selection, we use spectral analysis to select discriminative features in each group when it arrives. In the inter-group selection, we use Lasso to select a globally optimal subset of features. This 2-stage procedure continues until there are no more features to come or some predefined stopping conditions are met. Extensive experiments conducted on benchmark and real-world data sets demonstrate that our proposed approach outperforms other state-of-the-art online feature selection methods.

#index 2033080
#* Nonconvex relaxation approaches to robust matrix recovery
#@ Shusen Wang;Dehua Liu;Zhihua Zhang
#t 2013
#c 11
#% 1386133
#% 1472310
#% 1504249
#% 1750246
#% 1750629
#% 1875748
#! Motivated by the recent developments of nonconvex penalties in sparsity modeling, we propose a nonconvex optimization model for handing the low-rank matrix recovery problem. Different from the famous robust principal component analysis (RPCA), we suggest recovering low-rank and sparse matrices via a nonconvex loss function and a nonconvex penalty. The advantage of the nonconvex approach lies in its stronger robustness. To solve the model, we devise a majorization-minimization augmented Lagrange multiplier (MM-ALM) algorithm which finds the local optimal solutions of the proposed nonconvex model. We also provide an efficient strategy to speedup MM-ALM, which makes the running time comparable with the state-of-the-art algorithm of solving RPCA. Finally, empirical results demonstrate the superiority of our nonconvex approach over RPCA in terms of matrix recovery accuracy.

#index 2033081
#* A KNN based kalman filter Gaussian process regression
#@ Yali Wang;Brahim Chaib-Draa
#t 2013
#c 11
#% 891559
#% 1108893
#% 1275105
#% 1472293
#! The standard Gaussian process (GP) regression is often intractable when a data set is large or spatially nonstationary. In this paper, we address these challenging data properties by designing a novel K nearest neighbor based Kalman filter Gaussian process (KNN-KFGP) regression. Based on a state space model established by the KNN driven data grouping, our KNN-KFGP recursively filters out the latent function values in a computationally efficient and accurate Kalman filtering framework. Moreover, KNN allows each test point to find its strongly correlated local training subset, so our KNN-KFGP provides a suitable way to deal with spatial nonstationary problems. We evaluate the performance of our KNN-KFGP on several synthetic and real data sets to show its validity.

#index 2033082
#* Bayesian optimization in high dimensions via random embeddings
#@ Ziyu Wang;Masrour Zoghi;Frank Hutter;David Matheson;Nando De Freitas
#t 2013
#c 11
#% 156278
#% 422182
#% 422369
#% 846487
#% 891549
#% 1275935
#% 1411190
#% 1652622
#% 1653973
#% 1737852
#% 1738047
#% 1747267
#% 1872190
#% 1943421
#! Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm configuration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identified its scaling to high dimensions as one of the holy grails of the field. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple and applies to domains with both categorical and continuous variables. The experiments demonstrate that REMBO can effectively solve high-dimensional problems, including automatic parameter configuration of a popular mixed integer linear programming solver.

#index 2033083
#* Deep feature learning using target priors with applications in ECoG signal decoding for BCI
#@ Zuoguan Wang;Siwei Lyu;Gerwin Schalk;Qiang Ji
#t 2013
#c 11
#% 450248
#% 450888
#% 464465
#% 983878
#% 1147302
#% 1173645
#% 1211766
#% 1211770
#% 1472297
#% 1495391
#% 1511182
#% 1750597
#% 1869229
#% 1911218
#! Recent years have seen a great interest in using deep architectures for feature learning from data. One drawback of the commonly used unsupervised deep feature learning methods is that for supervised or semi-supervised learning tasks, the information in the target variables are not used until the final stage when the classifier or regressor is trained on the learned features. This could lead to over-generalized features that are not competitive on the specific supervised or semi-supervised learning tasks. In this work, we describe a new learning method that combines deep feature learning on mixed labeled and unlabeled data sets. Specifically, we describe a weakly supervised learning method of a prior supervised convolutional stacked auto-encoders (PCSA), of which information in the target variables is represented probabilistically using a Gaussian Bernoulli restricted Boltzmann machine (RBM). We apply this method to the decoding problem of an ECoG based Brain Computer Interface (BCI) system. Our experimental results show that PCSA achieves significant improvement in decoding performance on benchmark data sets compared to the unsupervised feature learning as well as to the current state-of-the-art algorithms that are based on manually crafted features.

#index 2033084
#* Euler clustering
#@ Jian-Sheng Wu;Wei-Shi Zheng;Jian-Huang Lai
#t 2013
#c 11
#% 266426
#% 313959
#% 635689
#% 769935
#% 812535
#% 852098
#% 883972
#% 891559
#% 1606028
#% 1953671
#! By always mapping data from lower dimensional space into higher or even infinite dimensional space, kernel k-means is able to organize data into groups when data of different clusters are not linearly separable. However, kernel k-means incurs the large scale computation due to the representation theorem, i.e. keeping an extremely large kernel matrix in memory when using popular Gaussian and spatial pyramid matching kernels, which largely limits its use for processing large scale data. Also, existing kernel clustering can be overfitted by outliers as well. In this paper, we introduce an Euler clustering, which can not only maintain the benefit of nonlinear modeling using kernel function but also significantly solve the large scale computational problem in kernel-based clustering. This is realized by incorporating Euler kernel. Euler kernel is relying on a nonlinear and robust cosine metric that is less sensitive to outliers. More important it intrinsically induces an empirical map which maps data onto a complex space of the same dimension. Euler clustering takes these advantages to measure the similarity between data in a robust way without increasing the dimensionality of data, and thus solves the large scale problem in kernel k-means. We evaluate Euler clustering and show its superiority against related methods on five publicly available datasets.

#index 2033085
#* A theoretic framework of K-means-based consensus clustering
#@ Junjie Wu;Hongfu Liu;Hui Xiong;Jie Cao
#t 2013
#c 11
#% 36672
#% 349552
#% 571905
#% 579655
#% 722902
#% 727903
#% 803762
#% 837616
#% 937551
#% 1018764
#% 1117063
#% 1117068
#% 1133031
#% 1165667
#% 1270194
#% 1411473
#% 1473791
#% 1535338
#% 1669863
#! Consensus clustering emerges as a promising solution to find cluster structures from data. As an efficient approach for consensus clustering, the K-means based method has garnered attention in the literature, but the existing research is still preliminary and fragmented. In this paper, we provide a systematic study on the framework of K-means-based Consensus Clustering (KCC). We first formulate the general definition of KCC, and then reveal a necessary and sufficient condition for utility functions that work for KCC, on both complete and incomplete basic partitionings. Experimental results on various real-world data sets demonstrate that KCC is highly efficient and is comparable to the state-of-the-art methods in terms of clustering quality. In addition, KCC shows high robustness to incomplete basic partitionings with substantial missing values.

#index 2033086
#* Multi-modal distance metric learning
#@ Pengtao Xie;Eric P. Xing
#t 2013
#c 11
#% 450888
#% 760805
#% 983830
#% 1055761
#% 1292880
#% 1305468
#% 1389537
#% 1551232
#% 1598356
#% 1693917
#% 1746798
#% 1872343
#% 1879089
#! Multi-modal data is dramatically increasing with the fast growth of social media. Learning a good distance measure for data with multiple modalities is of vital importance for many applications, including retrieval, clustering, classification and recommendation. In this paper, we propose an effective and scalable multi-modal distance metric learning framework. Based on the multi-wing harmonium model, our method provides a principled way to embed data of arbitrary modalities into a single latent space, of which an optimal distance metric can be learned under proper supervision, i.e., by minimizing the distance between similar pairs whereas maximizing the distance between dissimilar pairs. The parameters are learned by jointly optimizing the data likelihood under the latent space model and the loss induced by distance supervision, thereby our method seeks a balance between explaining the data and providing an effective distance metric, which naturally avoids overfitting. We apply our general framework to text/image data and present empirical results on retrieval and classification to demonstrate the effectiveness and scalability.

#index 2033087
#* A probabilistic approach to latent cluster analysis
#@ Zhipeng Xie;Rui Dong;Zhengheng Deng;Zhenying He;Weidong Yang
#t 2013
#c 11
#% 296738
#% 722902
#% 745793
#% 803762
#% 1077150
#% 1137063
#% 1305447
#% 1385837
#! Facing a large number of clustering solutions, cluster ensemble method provides an effective approach to aggregating them into a better one. In this paper, we propose a novel cluster ensemble method from probabilistic perspective. It assumes that each clustering solution is generated from a latent cluster model, under the control of two probabilistic parameters. Thus, the cluster ensemble problem is reformulated into an optimization problem of maximum likelihood. An EM-style algorithm is designed to solve this problem. It can determine the number of clusters automatically. Experimenal results have shown that the proposed algorithm outperforms the state-of-the-art methods including EAC-AL, CSPA, HGPA, and MCLA. Furthermore, it has been shown that our algorithm is stable in the predicted numbers of clusters.

#index 2033088
#* Harmonious hashing
#@ Bin Xu;Jiajun Bu;Yue Lin;Chun Chen;Xiaofei He;Deng Cai
#t 2013
#c 11
#% 249321
#% 347225
#% 724227
#% 1211844
#% 1450831
#% 1520218
#% 1538047
#% 1598386
#% 1750268
#% 1750274
#% 1826272
#% 1826280
#% 1919832
#! Hashing-based fast nearest neighbor search technique has attracted great attention in both research and industry areas recently. Many existing hashing approaches encode data with projection-based hash functions and represent each projected dimension by 1-bit. However, the dimensions with high variance hold large energy or information of data but treated equivalently as dimensions with low variance, which leads to a serious information loss. In this paper, we introduce a novel hashing algorithm called Harmonious Hashing which aims at learning hash functions with low information loss. Specifically, we learn a set of optimized projections to preserve the maximum cumulative energy and meet the constraint of equivalent variance on each dimension as much as possible. In this way, we could minimize the information loss after binarization. Despite the extreme simplicity, our method outperforms superiorly to many state-of-the-art hashing methods in large-scale and high-dimensional nearest neighbor search experiments.

#index 2033089
#* Change-point detection with feature selection in high-dimensional time-series data
#@ Makoto Yamada;Akisato Kimura;Futoshi Naya;Hiroshi Sawada
#t 2013
#c 11
#% 135968
#% 310552
#% 477809
#% 577295
#% 722798
#% 1016144
#% 1385955
#% 1411043
#% 1524547
#% 1558464
#% 1601590
#% 1606373
#% 1673681
#% 1756933
#% 1985716
#! Change-point detection is the problem of finding abrupt changes in time-series, and it is attracting a lot of attention in the artificial intelligence and data mining communities. In this paper, we present a supervised learning based change-point detection approach in which we use the separability of past and future data at time t (they are labeled as +1 and -1) as plausibility of change-points. Based on this framework, we propose a detection measure called the additive Hilbert-Schmidt Independence Criterion (aHSIC), which is defined as the weighted sum of the HSIC scores between features and its corresponding binary labels. Here, the HSIC is a kernel-based independence measure. A novel aspect of the aHSIC score is that it can incorporate feature selection during its detection measure estimation. More specifically, we first select features that are responsible for an abrupt change by using a supervised approach, and then compute the aHSIC score by employing the selected features. Thus, compared with traditional detection measures, our approach tends to be robust as regards noise features, and so the aHSIC is suitable for a use with high-dimensional time-series change-point detection problems. We demonstrate that the proposed change-point detection method is promising through extensive experiments on synthetic data sets and a real-world human activity data set.

#index 2033090
#* On robust estimation of high dimensional generalized linear models
#@ Eunho Yang;Ambuj Tewari;Pradeep Ravikumar
#t 2013
#c 11
#% 34077
#% 770857
#% 961223
#% 1311966
#% 1815826
#% 1815936
#! We study robust high-dimensional estimation of generalized linear models (GLMs); where a small number k of the n observations can be arbitrarily corrupted, and where the true parameter is high dimensional in the "p ≫ n" regime, but only has a small number s of non-zero entries. There has been some recent work connecting robustness and sparsity, in the context of linear regression with corrupted observations, by using an explicitly modeled outlier response vector that is assumed to be sparse. Interestingly, we show, in the GLM setting, such explicit outlier response modeling can be performed in two distinct ways. For each of these two approaches, we give l2 error bounds for parameter estimation for general values of the tuple (n, p, s, k).

#index 2033091
#* Reduced heteroscedasticity linear regression for Nyström approximation
#@ Hao Yang;Jianxin Wu
#t 2013
#c 11
#% 197394
#% 266426
#% 840839
#% 847159
#% 870225
#% 883972
#% 916799
#% 1074026
#% 1164243
#% 1495359
#% 1875717
#! The Nyström method is a well known sampling based low-rank matrix approximation approach. It is usually considered to be originated from the numerical treatment of integral equations and eigendecomposition of matrices. In this paper, we present a novel point of view for the Nyström approximation. We show that theoretically the Nyström method can be regraded as a set of point-wise ordinary least square linear regressions of the kernel matrix, sharing the same design matrix. With the new interpretation, we are able to analyze the approximation quality based on the fulfillment of the homoscedasticity assumption and explain the success and deficiency of various sampling methods. We also empirically show that positively skewed explanatory variable distributions can lead to heteroscedasticity. Based on this discovery, we propose to use non-symmetric explanatory functions to improve the quality of the Nyström approximation with almost no extra computational cost. Experiments show that positively skewed datasets widely exist, and our method exhibits good improvements on these datasets.

#index 2033092
#* Multi-view discriminant transfer learning
#@ Pei Yang;Wei Gao
#t 2013
#c 11
#% 46803
#% 235342
#% 252011
#% 420495
#% 466263
#% 729437
#% 815908
#% 837621
#% 1013605
#% 1292600
#% 1450849
#% 1464068
#% 1606063
#% 1862326
#! We study to incorporate multiple views of data in a perceptive transfer learning framework and propose a Multi-view Discriminant Transfer (MDT) learning approach for domain adaptation. The main idea is to find the optimal discriminant weight vectors for each view such that the correlation between the two-view projected data is maximized, while both the domain discrepancy and the view disagreement are minimized simultaneously. Furthermore, we analyze MDT theoretically from discriminant analysis perspective to explain the condition and reason, under which the proposed method is not applicable. The analytical results allow us to investigate whether there exist within-view and/or between-view conflicts, and thus provides a deep insight into whether the transfer learning algorithm work properly or not in the view-based problems and the combined learning problem. Experiments show that MDT significantly outperforms the state-of-the-art baselines including some typical multi-view learning approaches in single-or cross-domain.

#index 2033093
#* Smart hashing update for fast response
#@ Qiang Yang;Long-Kai Huang;Wei-Shi Zheng;Yingbiao Ling
#t 2013
#c 11
#% 479973
#% 762054
#% 1119142
#% 1286845
#% 1606048
#% 1661181
#% 1661257
#% 1884343
#% 1885617
#% 1931623
#% 1945137
#! Recent years have witnessed the growing popularity of hash function learning for large-scale data search. Although most existing hashing-based methods have been proven to obtain high accuracy, they are regarded as passive hashing and assume that the labelled points are provided in advance. In this paper, we consider updating a hashing model upon gradually increased labelled data in a fast response to users, called smart hashing update (SHU). In order to get a fast response to users, SHU aims to select a small set of hash functions to relearn and only updates the corresponding hash bits of all data points. More specifically, we put forward two selection methods for performing efficient and effective update. In order to reduce the response time for acquiring a stable hashing algorithm, we also propose an accelerated method in order to further reduce interactions between users and the computer. We evaluate our proposals on two benchmark data sets. Our experimental results show it is not necessary to update all hash bits in order to adapt the model to new input data, and meanwhile we obtain better or similar performance without sacrificing much accuracy against the batch mode update.

#index 2033094
#* Multi-instance multi-label learning with weak label
#@ Shu-Jun Yang;Yuan Jiang;Zhi-Hua Zhou
#t 2013
#c 11
#% 1528
#% 272527
#% 344447
#% 345848
#% 397854
#% 727883
#% 1128929
#% 1211769
#% 1260808
#% 1277534
#% 1305521
#% 1318819
#% 1535443
#% 1647350
#% 1750449
#% 1872292
#% 1872293
#% 1917971
#! Multi-Instance Multi-Label learning (MIML) deals with data objects that are represented by a bag of instances and associated with a set of class labels simultaneously. Previous studies typically assume that for every training example, all positive labels are tagged whereas the untagged labels are all negative. In many real applications such as image annotation, however, the learning problem often suffers from weak label; that is, users usually tag only a part of positive labels, and the untagged labels are not necessarily negative. In this paper, we propose the MIMLwel approach which works by assuming that highly relevant labels share some common instances, and the underlying class means of bags for each label are with a large margin. Experiments validate the effectiveness of MIMLwel in handling the weak label problem.

#index 2033095
#* Protein function prediction by integrating multiple kernels
#@ Guoxian Yu;Huzefa Rangwala;Carlotta Domeniconi;Guoji Zhang;Zili Zhang
#t 2013
#c 11
#% 757953
#% 793247
#% 832903
#% 833913
#% 905823
#% 1288794
#% 1305490
#% 1447814
#% 1872028
#% 1872360
#% 1984476
#! Determining protein function constitutes an exercise in integrating information derived from several heterogeneous high-throughput experiments. To utilize the information spread across multiple sources in a combined fashion, these data sources are transformed into kernels. Several protein function prediction methods follow a two-phased approach: they first optimize the weights on individual kernels to produce a composite kernel, and then train a classifier on the composite kernel. As such, these methods result in an optimal composite kernel, but not necessarily in an optimal classifier. On the other hand, some methods optimize the loss of binary classifiers, and learn weights for the different kernels iteratively. A protein has multiple functions, and each function can be viewed as a label. These methods solve the problem of optimizing weights on the input kernels for each of the labels. This is computationally expensive and ignores inter-label correlations. In this paper, we propose a method called Protein Function Prediction by Integrating Multiple Kernels (ProMK). ProMK iteratively optimizes the phases of learning optimal weights and reducing the empirical loss of a multi-label classifier for each of the labels simultaneously, using a combined objective function. ProMK can assign larger weights to smooth kernels and downgrade the weights on noisy kernels. We evaluate the ability of ProMK to predict the function of proteins using several standard benchmarks. We show that our approach performs better than previously proposed protein function prediction approaches that integrate data from multiple networks, and multi-label multiple kernel learning methods.

#index 2033096
#* Learning domain differences automatically for dependency parsing adaptation
#@ Mo Yu;Tiejun Zhao;Yalong Bai
#t 2013
#c 11
#% 816186
#% 939343
#% 939563
#% 1215280
#% 1481604
#% 1566291
#% 1764078
#! In this paper, we address the relation between domain differences and domain adaptation for dependency parsing. Our quantitative analyses showed that it is the inconsistent behavior of same features cross-domain, rather than word or feature coverage, that is the major cause of performances decrease of out-domain model. We further studied those ambiguous features in depth and found that the set of ambiguous features is small and has concentric distributions. Based on the analyses, we proposed a DA method. The DA method can automatically learn which features are ambiguous cross domain according to errors made by out-domain model on in-domain training data. Our method is also extended to utilize multiple out-domain models. The results of dependency parser adaptation from WSJ to Genia and Question bank showed that our method achieved significant improvements on small in-domain datasets where DA is mostly in need. Additionally, we achieved improvement on the published best results of CoNLL07 shared task on domain adaptation, which confirms the significance of our analyses and our method.

#index 2033097
#* Bilevel visual words coding for image classification
#@ Jiemi Zhang;Chenxia Wu;Deng Cai;Jianke Zhu
#t 2013
#c 11
#% 724320
#% 784995
#% 812418
#% 883972
#% 883981
#% 961152
#% 992320
#% 1209714
#% 1305617
#% 1446867
#% 1451172
#% 1826266
#% 1826532
#% 1854234
#% 1883961
#% 1885639
#! Bag-of-Words approach has played an important role in recent works for image classification. In consideration of efficiency, most methods use k- means clustering to generate the codebook. The obtained codebooks often lose the cluster size and shape information with distortion errors and low discriminative power. Though some efforts have been made to optimize codebook in sparse coding, they usually incur higher computational cost. Moreover, they ignore the correlations between codes in the following coding stage, that leads to low discriminative power of the final representation. In this paper, we propose a bilevel visual words coding approach in consideration of representation ability, discriminative power and efficiency. In the bilevel codebook generation stage, k-means and an efficient spectral clustering are respectively run in each level by taking both class information and the shapes of each visual word cluster into account. To obtain discriminative representation in the coding stage, we design a certain localized coding rule with bilevel codebook to select local bases. To further achieve an efficient coding referring to this rule, an online method is proposed to efficiently learn a projection of local descriptor to the visual words in the codebook. After projection, coding can be efficiently completed by a low dimensional localized soft-assignment. Experimental results show that our proposed bilevel visual words coding approach outperforms the state-of-the-art approaches for image classification.

#index 2033098
#* Sparse reconstruction for weakly supervised semantic segmentation
#@ Ke Zhang;Wei Zhang;Yingbin Zheng;Xiangyang Xue
#t 2013
#c 11
#% 349208
#% 457912
#% 760805
#% 1183453
#% 1495453
#% 1495498
#% 1619392
#% 1667612
#% 1885657
#% 1885739
#% 1923406
#% 1923555
#% 1923614
#! We propose a novel approach to semantic segmentation using weakly supervised labels. In traditional fully supervised methods, superpixel labels are available for training; however, it is not easy to obtain enough labeled superpixels to learn a satisfying model for semantic segmentation. By contrast, only image-level labels are necessary in weakly supervised methods, which makes them more practical in real applications. In this paper we develop a new way of evaluating classification models for semantic segmentation given weekly supervised labels. For a certain category, provided the classification model parameter, we firstly learn the basis superpixels by sparse reconstruction, and then evaluate the parameters by measuring the reconstruction errors among negative and positive superpixels. Based on Gaussian Mixture Models, we use Iterative Merging Update (IMU) algorithm to obtain the best parameters for the classification models. Experimental results on two real-world datasets show that the proposed approach outperforms the existing weakly supervised methods, and it also competes with state-of-the-art fully supervised methods.

#index 2033099
#* Semi-supervised learning with manifold fitted graphs
#@ Tongtao Zhang;Rongrong Ji;Wei Liu;Dacheng Tao;Gang Hua
#t 2013
#c 11
#% 593047
#% 627366
#% 790049
#% 961218
#% 1034714
#% 1119135
#% 1211745
#% 1354495
#% 1495378
#% 1598386
#% 1750558
#% 1815826
#% 1865565
#! In this paper, we propose a locality-constrained and sparsity-encouraged manifold fitting approach, aiming at capturing the locally sparse manifold structure into neighborhood graph construction by exploiting a principled optimization model. The proposed model formulates neighborhood graph construction as a sparse coding problem with the locality constraint, therefore achieving simultaneous neighbor selection and edge weight optimization. The core idea underlying our model is to perform a sparse manifold fitting task for each data point so that close-by points lying on the same local manifold are automatically chosen to connect and meanwhile the connection weights are acquired by simple geometric reconstruction. We term the novel neighborhood graph generated by our proposed optimization model M-Fitted Graph since such a graph stems from sparse manifold fitting. To evaluate the robustness and effectiveness of M-fitted graphs, we leverage graph-based semi-supervised learning as the testbed. Extensive experiments carried out on six benchmark datasets validate that the proposed M-fitted graph is superior to state-of-the-art neighborhood graphs in terms of classification accuracy using popular graph-based semi-supervised learning methods.

#index 2033100
#* Online community detection for large complex networks
#@ Wangsheng Zhang;Gang Pan;Zhaohui Wu;Shijian Li
#t 2013
#c 11
#% 823342
#% 937549
#% 1034723
#% 1399996
#% 1826281
#% 1826415
#% 1826436
#% 1826472
#! Complex networks describe a wide range of systems in nature and society. To understand the complex networks, it is crucial to investigate their internal structure. In this paper, we propose an online community detection method for large complex networks, which make it possible to process networks edge-by-edge in a serial fashion. We investigate the generative mechanism of complex networks and propose a split mechanism based on the degree of the nodes to create new community. Our method has linear time complexity. The method has been applied to six real-world network datasets and the experimental results show that it is comparable to existing methods in modularity with much less running time.

#index 2033101
#* Multi-view embedding learning for incompletely labeled data
#@ Wei Zhang;Ke Zhang;Pan Gu;Xiangyang Xue
#t 2013
#c 11
#% 791402
#% 812580
#% 983949
#% 1038781
#% 1174086
#% 1269777
#% 1292880
#% 1454143
#% 1484401
#% 1502531
#% 1520224
#% 1649028
#% 1667612
#% 1826280
#% 1919832
#! In many applications, the data may be high dimensional, represented by multiple features, and associated with more than one labels. Embedding learning is an effective strategy for dimensionality reduction and for nearest neighbor search in massive datasets. We propose a novel method to seek compact embedding that allows efficient retrieval with incompletely-labeled multi-view data. Based on multi-graph Laplacian, we achieve the optimal combination of heterogeneous features to effectively describe data, which exploits the feature correlations between different views. We learn the embedding that preserves the neighborhood context in the original spaces, and obtain the complete labels simultaneously. Inter-label correlations are sufficiently leveraged in the proposed framework. Our goal is to find the maps from multiple input spaces to the compact embedding space and to the semantic concept space at the same time. There is semantic gap between the input multi-view feature spaces and the semantic concept space; and the compact embedding space can be looked on as the bridge between the above spaces. Experimental evaluation on three real-world datasets demonstrates the effectiveness of the proposed method.

#index 2033102
#* Learning high-order task relationships in multi-task learning
#@ Yu Zhang;Dit-Yan Yeung
#t 2013
#c 11
#% 236495
#% 236497
#% 722760
#% 723239
#% 769886
#% 829014
#% 840962
#% 916788
#% 961246
#% 983942
#% 1451258
#% 1451259
#% 1451260
#% 1730805
#! Multi-task learning is a way of bringing inductive transfer studied in human learning to the machine learning community. A central issue in multitask learning is to model the relationships between tasks appropriately and exploit them to aid the simultaneous learning of multiple tasks effectively. While some recent methods model and learn the task relationships from data automatically, only pairwise relationships can be represented by them. In this paper, we propose a new model, called Multi-Task High-Order relationship Learning (MTHOL), which extends in a novel way the use of pairwise task relationships to high-order task relationships. We first propose an alternative formulation of an existing multi-task learning method. Based on the new formulation, we propose a high-order generalization leading to a new prior for the model parameters of different tasks. We then propose a new probabilistic model for multi-task learning and validate it empirically on some benchmark datasets.

#index 2033103
#* Lazy paired hyper-parameter tuning
#@ Alice X. Zheng;Mikhail Bilenko
#t 2013
#c 11
#% 416988
#% 425053
#% 576218
#% 722923
#% 1174126
#% 1211740
#% 1625364
#% 1738047
#% 1747267
#% 1792878
#! In virtually all machine learning applications, hyper-parameter tuning is required to maximize predictive accuracy. Such tuning is computationally expensive, and the cost is further exacerbated by the need for multiple evaluations (via cross-validation or bootstrap) at each configuration setting to guarantee statistically significant results. This paper presents a simple, general technique for improving the efficiency of hyper-parameter tuning by minimizing the number of resampled evaluations at each configuration. We exploit the fact that train-test samples can easily be matched across candidate hyper-parameter configurations. This permits the use of paired hypothesis tests and power analysis that allow for statistically sound early elimination of suboptimal candidates to minimize the number of evaluations. Results on synthetic and real-world datasets demonstrate that our method improves over competitors for discrete parameter settings, and enhances state-of-the-art techniques for continuous parameter settings.

#index 2033104
#* Adaptive error-correcting output codes
#@ Guoqiang Zhong;Mohamed Cheriet
#t 2013
#c 11
#% 400847
#% 564283
#% 722756
#% 844859
#% 865331
#% 900179
#% 961134
#% 961246
#% 1128929
#% 1272365
#% 1273928
#% 1327698
#% 1417091
#% 1551209
#% 1861284
#! Error-correcting output codes (ECOC) are a successful technique to combine a set of binary classifiers for multi-class learning problems. However, in traditional ECOC framework, all the base classifiers are trained independently according to the defined ECOC matrix. In this paper, we reformulate the ECOC models from the perspective of multi-task learning, where the binary classifiers are learned in a common subspace of data. This novel model can be considered as an adaptive generalization of the traditional ECOC framework. It simultaneously optimizes the representation of data as well as the binary classifiers. More importantly, it builds a bridge between the ECOC framework and multitask learning for multi-class learning problems. To deal with complex data, we also present the kernel extension of the proposed model. Extensive empirical study on 14 data sets from UCI machine learning repository and the USPS handwritten digits recognition application demonstrates the effectiveness and efficiency of our model.

#index 2033105
#* Accurate probability calibration for multiple classifiers
#@ Leon Wenliang Zhong;James T. Kwok
#t 2013
#c 11
#% 342611
#% 577298
#% 840913
#% 875965
#% 889273
#% 956546
#% 961218
#% 976824
#% 1073884
#% 1117691
#% 1265149
#% 1745124
#% 1906161
#! In classification problems, isotonic regression has been commonly used to map the prediction scores to posterior class probabilities. However, isotonic regression may suffer from overfitting, and the learned mapping is often discontinuous. Besides, current efforts mainly focus on the calibration of a single classifier. As different classifiers have different strengths, a combination of them can lead to better performance. In this paper, we propose a novel probability calibration approach for such an ensemble of classifiers. We first construct isotonic constraints on the desired probabilities based on soft voting of the classifiers. Manifold information is also incorporated to combat overfitting and ensure function smoothness. Computationally, the extended isotonic regression model can be learned efficiently by a novel optimization algorithm based on the alternating direction method of multipliers (ADMM). Experiments on a number of real-world data sets demonstrate that the proposed approach consistently outperforms independent classifiers and other combinations of the classifiers' probabilities in terms of the Brier score and AUC.

#index 2033106
#* Shifted subspaces tracking on sparse outlier for motion segmentation
#@ Tianyi Zhou;Dacheng Tao
#t 2013
#c 11
#% 578409
#% 1149163
#% 1191082
#% 1211747
#% 1309918
#% 1451258
#% 1688441
#% 1750370
#% 1826292
#% 1865739
#% 1876025
#% 1885537
#% 1923351
#% 1987282
#! In low-rank & sparse matrix decomposition, the entries of the sparse part are often assumed to be i.i.d. sampled from a random distribution. But the structure of sparse part, as the central interest of many problems, has been rarely studied. One motivating problem is tracking multiple sparse object flows (motions) in video. We introduce "shifted subspaces tracking (SST)" to segment the motions and recover their trajectories by exploring the low-rank property of background and the shifted subspace property of each motion. SST is composed of two steps, background modeling and flow tracking. In step 1, we propose "semi-soft GoDec" to separate all the motions from the low-rank background L as a sparse outlier S. Its soft-thresholding in updating S significantly speeds up GoDec and facilitates the parameter tuning. In step 2, we update X as S obtained in step 1 and develop "SST algorithm" further decomposing X as X = Σi=1k L(i)oτ(i)+ S+G, wherein L(i) is a low-rank matrix storing the ith flow after transformation τ(i). SST algorithm solves k sub-problems in sequel by alternating minimization, each of which recovers one L(i) and its τ(i) by randomized method. Sparsity of L(i) and between-frame affinity are leveraged to save computations. We justify the effectiveness of SST on surveillance video sequences.

#index 2033107
#* Persistent homology: an introduction and a new text representation for natural language processing
#@ Xiaojin Zhu
#t 2013
#c 11
#% 466900
#% 840583
#% 1014683
#% 1041166
#% 1265816
#% 1452619
#! Persistent homology is a mathematical tool from topological data analysis. It performs multi-scale analysis on a set of points and identifies clusters, holes, and voids therein. These latter topological structures complement standard feature representations, making persistent homology an attractive feature extractor for artificial intelligence. Research on persistent homology for AI is in its infancy, and is currently hindered by two issues: the lack of an accessible introduction to AI researchers, and the paucity of applications. In response, the first part of this paper presents a tutorial on persistent homology specifically aimed at a broader audience without sacrificing mathematical rigor. The second part contains one of the first applications of persistent homology to natural language processing. Specifically, our Similarity Filtration with Time Skeleton (SIFTS) algorithm identifies holes that can be interpreted as semantic "tie-backs" in a text document, providing a new document structure representation. We illustrate our algorithm on documents ranging from nursery rhymes to novels, and on a corpus with child and adolescent writings.

#index 2033108
#* Concept learning for cross-domain text classification: a general probabilistic framework
#@ Fuzhen Zhuang;Ping Luo;Peifeng Yin;Qing He;Zhongzhi Shi
#t 2013
#c 11
#% 116149
#% 466263
#% 983828
#% 989592
#% 1074129
#% 1083655
#% 1130817
#% 1211714
#% 1227700
#% 1237826
#% 1377374
#% 1464068
#% 1482214
#% 1598427
#% 1650298
#! Cross-domain learning targets at leveraging the knowledge from source domains to train accurate models for the test data from target domains with different but related data distributions. To tackle the challenge of data distribution difference in terms of raw features, previous works proposed to mine high-level concepts (e.g., word clusters) across data domains, which shows to be more appropriate for classification. However, all these works assume that the same set of concepts are shared in the source and target domains in spite that some distinct concepts may exist only in one of the data domains. Thus, we need a general framework, which can incorporate both shared and distinct concepts, for cross-domain classification. To this end, we develop a probabilistic model, by which both the shared and distinct concepts can be learned by the EM process which optimizes the data likelihood. To validate the effectiveness of this model we intentionally construct the classification tasks where the distinct concepts exist in the data domains. The systematic experiments demonstrate the superiority of our model over all compared baselines, especially on those much more challenging tasks.

#index 2033109
#* Automatically generating problems and solutions for natural deduction
#@ Umair Z. Ahmed;Sumit Gulwani;Amey Karkare
#t 2013
#c 11
#% 1415300
#% 1578185
#% 1584718
#% 1970506
#% 1977023
#! Natural deduction, which is a method for establishing validity of propositional type arguments, helps develop important reasoning skills and is thus a key ingredient in a course on introductory logic. We present two core components, namely solution generation and practice problem generation, for enabling computer-aided education for this important subject domain. The key enabling technology is use of an offline-computed data-structure called Universal Proof Graph (UPG) that encodes all possible applications of inference rules over all small propositions abstracted using their bitvector-based truth-table representation. This allows an efficient forward search for solution generation. More interestingly, this allows generating fresh practice problems that have given solution characteristics by performing a backward search in UPG. We obtained around 300 natural deduction problems from various textbooks. Our solution generation procedure can solve many more problems than the traditional forward-chaining based procedure, while our problem generation procedure can efficiently generate several variants with desired characteristics.

#index 2033110
#* Automated grading of DFA constructions
#@ Rajeev Alur;Loris D'Antoni;Sumit Gulwani;Dileep Kini;Mahesh Viswanathan
#t 2013
#c 11
#% 241166
#% 359443
#% 502084
#% 826007
#% 903341
#% 925668
#% 1343987
#% 1351373
#% 1638635
#% 1805919
#! One challenge in making online education more effective is to develop automatic grading software that can provide meaningful feedback. This paper provides a solution to automatic grading of the standard computation-theory problem that asks a student to construct a deterministic finite automaton (DFA) from the given description of its language. We focus on how to assign partial grades for incorrect answers. Each student's answer is compared to the correct DFA using a hybrid of three techniques devised to capture different classes of errors. First, in an attempt to catch syntactic mistakes, we compute the edit distance between the two DFA descriptions. Second, we consider the entropy of the symmetric difference of the languages of the two DFAs, and compute a score that estimates the fraction of the number of strings on which the student answer is wrong. Our third technique is aimed at capturing mistakes in reading of the problem description. For this purpose, we consider a description language MOSEL, which adds syntactic sugar to the classical Monadic Second Order Logic, and allows defining regular languages in a concise and natural way. We provide algorithms, along with optimizations, for transforming MOSEL descriptions into DFAs and vice-versa. These allow us to compute the syntactic edit distance of the incorrect answer from the correct one in terms of their logical representations. We report an experimental study that evaluates hundreds of answers submitted by (real) students by comparing grades/feedback computed by our tool with human graders. Our conclusion is that the tool is able to assign partial grades in a meaningful way, and should be preferred over the human graders for both scalability and consistency.

#index 2033111
#* Misleading opinions provided by advisors: dishonesty or subjectivity
#@ Hui Fang;Yang Bao;Jie Zhang
#t 2013
#c 11
#% 44876
#% 303620
#% 856790
#% 993566
#% 1250347
#% 1451229
#% 1615264
#% 1617591
#% 1875950
#! It is indispensable for users to evaluate the trustworthiness of other users (referred to as advisors), to cope with possible misleading opinions provided by them. Advisors' misleading opinions may be induced by their dishonesty, subjectivity difference with users, or both. Existing approaches do not well distinguish the two different causes. In this paper, we propose a novel probabilistic graphical trust model to separately consider these two factors, involving three types of latent variables: benevolence, integrity and competence of advisors, trust propensity of users, and subjectivity difference between users and advisors. Experimental results on real datasets demonstrate that our method advances state-of-the-art approaches to a large extent.

#index 2033112
#* Personalized diagnosis for over-constrained problems
#@ Alexander Felfernig;Monika Schubert;Stefan Reiterer
#t 2013
#c 11
#% 21137
#% 95580
#% 132173
#% 220203
#% 576214
#% 741461
#% 982674
#% 1250145
#% 1269720
#% 1305415
#% 1655399
#! Constraint-based applications such as configurators, recommenders, and scheduling systems support users in complex decision making scenarios. Typically, these systems try to identify a solution that satisfies all articulated user requirements. If the requirements are inconsistent with the underlying constraint set, users have to be actively supported in finding a way out from the no solution could be found dilemma. In this paper we introduce techniques that support the calculation of personalized diagnoses for inconsistent constraint sets. These techniques significantly improve the diagnosis prediction quality compared to approaches based on the calculation of minimal cardinality diagnoses. In order to show the applicability of our approach we present the results of an empirical study and a corresponding performance analysis.

#index 2033113
#* A brain-computer interface to a plan-based narrative
#@ Stephen W. Gilroy;Julie Porteous;Fred Charles;Marc Cavazza;Eyal Soreq;Gal Raz;Limor Ikar;Ayelet Or-Borichov;Udi Ben-Arie;Ilana Klovatch;Talma Hendler
#t 2013
#c 11
#% 1248401
#% 1250468
#% 1269407
#% 1401685
#% 1480467
#% 1545555
#% 1729384
#% 1926820
#! Interactive Narrative is a form of digital entertainment heavily based on AI techniques to support narrative generation and user interaction, significant progress arriving with the adoption of planning techniques. However, there is a lack of unified models that integrate generation, user responses and interaction. This paper addresses this by revisiting existing Interactive Narrative paradigms, granting explicit status to users' disposition towards story characters as part of narrative generation as well as adding support for new forms of interaction. We demonstrate this with a novel Brain-Computer Interface (BCI) design, incorporating empathy for a main character derived from brain signals within filmic conceptions of narrative which drives generation using planning techniques. Results from an experimental study with a fully-implemented system demonstrate the effectiveness of a EEG neurofeedback-based approach, showing that subjects can successfully modulate empathic support of a character in a medical drama. MRI analysis also shows activations in associated regions of the brain during expression of support.

#index 2033114
#* Robust median reversion strategy for on-line portfolio selection
#@ Dingjiang Huang;Junlong Zhou;Bin Li;Steven C. H. Hoi;Shuigeng Zhou
#t 2013
#c 11
#% 115608
#% 214399
#% 757953
#% 875946
#% 961152
#% 1073906
#% 1272037
#% 1558459
#% 1763770
#% 1949431
#! On-line portfolio selection has been attracting increasing interests from artificial intelligence community in recent decades. Mean reversion, as one most frequent pattern in financial markets, plays an important role in some state-of-the-art strategies. Though successful in certain datasets, existing mean reversion strategies do not fully consider noises and outliers in the data, leading to estimation error and thus non-optimal portfolios, which results in poor performance in practice. To overcome the limitation, we propose to exploit the reversion phenomenon by robust L1-median estimator, and design a novel on-line portfolio selection strategy named "Robust Median Reversion" (RMR), which makes optimal portfolios based on the improved reversion estimation. Empirical results on various real markets show that RMR can overcome the drawbacks of existing mean reversion algorithms and achieve significantly better results. Finally, RMR runs in linear time, and thus is suitable for large-scale trading applications.

#index 2033115
#* A cutoff technique for the verification of parameterised interpreted systems with parameterised environments
#@ Panagiotis Kouvaros;Alessio Lomuscio
#t 2013
#c 11
#% 6034
#% 60997
#% 131319
#% 179888
#% 212402
#% 214197
#% 297770
#% 379175
#% 445366
#% 511444
#% 542120
#% 561418
#% 760296
#% 778664
#% 1014781
#% 1215628
#% 1230304
#% 1249006
#% 1415254
#% 1473305
#% 1491416
#% 1539949
#% 1710851
#% 1989660
#! We put forward a cutoff technique for determining the number of agents that is sufficient to consider when checking temporal-epistemic specifications on a system of any size. We identify a special class of interleaved interpreted systems for which we give a parameterised semantics and an abstraction methodology. This enables us to overcome the significant limitations in expressivity present in the state-of-the-art. We present an implementation and discuss experimental results.

#index 2033116
#* TutorialPlan: automated tutorial generation from CAD drawings
#@ Wei Li;Yuanlin Zhang;George Fitzmaurice
#t 2013
#c 11
#% 5168
#% 5562
#% 23668
#% 49484
#% 86309
#% 135132
#% 172788
#% 194858
#% 212488
#% 292171
#% 305343
#% 319640
#% 407891
#% 743353
#% 790477
#% 1183141
#% 1193865
#% 1271992
#% 1628062
#% 1905554
#% 1905555
#% 1905556
#! Authoring tutorials for complex software applications is a time consuming process. It also highly depends on the tutorial designer's skill level and experience. This paper introduces an approach which automatically generates software tutorials using the digital artifacts produced by the users of a software program. We model this process as an optimal planning problem using software produced artifacts, software specifications and the human-computer interaction Keystroke-Level Model (KLM). We present TutorialPlan, an automated tutorial generator, which creates step-by-step text and image instructions from CAD drawings and helps users learn AutoCAD, a complex design and drafting software. In our tutorial generator, the optimal planning problem is represented and solved using DLV, a general Answer Set Programming (ASP) system. DLV offers a natural representation of both the problem and the heuristics needed to solve it efficiently. A user study shows that the tutorials generated by our system are comparable to those generated by experienced AutoCAD users.

#index 2033117
#* Probabilistic equivalence verification approach for automatic mathematical solution assessment
#@ Minh Luan Nguyen;Siu Cheung Hui;Alvis C. M. Fong
#t 2013
#c 11
#% 66654
#% 211059
#% 244328
#% 289409
#% 294169
#% 445401
#% 451509
#% 602390
#% 723469
#% 1006311
#% 1584718
#% 1592004
#% 1905883
#! Automatic mathematical solution assessment checks the equivalence of mathematical expressions in the user answer and standard solution. It is a challenging problem as the semantics of mathematical expressions are highly symbolic and equivalent mathematical expressions can be expressed in different forms. In this paper, we propose an effective Probabilistic Equivalence Verification (PEV) approach for automatic mathematical solution assessment. The proposed PEV approach is a randomized method based on the probabilistic numerical equivalence testing of two mathematical expressions. It can avoid false negative errors completely while guaranteeing a small probability of false positive errors to occur. The performance results have shown that the proposed PEV approach has outperformed other popular techniques in Computer Algebra Systems such as Maple and Mathematica.

#index 2033118
#* Predicting human strategic decisions using facial expressions
#@ Noam Peled;Moshe Bitan;Joseph Keshet;Sarit Kraus
#t 2013
#c 11
#% 197394
#% 1174017
#% 1271973
#% 1647810
#% 1875655
#! People's facial expressions, whether made consciously or subconsciously, continuously reveal their state of mind. This work proposes a method for predicting people's strategic decisions based on their facial expressions. We designed a new version of the centipede game that intorduces an incentive for the human participant to hide her facial expressions. We recorded on video participants who played several games of our centipede version, and concurrently logged their decisions throughout the games. The video snippet of the participants' faces prior to their decisions is represented as a fixed-size vector by estimating the covariance matrix of key facial points which change over time. This vector serves as input to a classifier that is trained to predict the participant's decision. We compare several training techniques, all of which are designed to work with the imbalanced decisions typically made by the players of the game. Furthermore, we investigate adaptation of the trained model to each player individually, while taking into account the player's facial expressions in the previous games. The results show that our method outperforms standard SVM as well as humans in predicting subjects' strategic decisions. To the best of our knowledge, this is the first study to present a methodology for predicting people's strategic decisions when there is an incentive to hide facial expressions.

#index 2033119
#* Employing batch reinforcement learning to control gene regulation without explicitly constructing gene regulatory networks
#@ Utku Sirin;Faruk Polat;Reda Alhajj
#t 2013
#c 11
#% 124692
#% 384911
#% 425072
#% 579658
#% 829011
#% 830858
#% 1188614
#% 1468026
#% 1480468
#% 1756123
#! The goal of controlling a gene regulatory network (GRN) is to generate an intervention strategy, i.e., a control policy, such that by applying the policy the system will avoid undesirable states. In this work, we propose a method to control GRNs by using Batch Mode Reinforcement Learning (Batch RL). Our idea is based on the fact that time series gene expression data can actually be interpreted as a sequence of experience tuples collected from the environment. Existing studies on this control task try to infer a model using gene expression data and then calculate a control policy over the constructed model. However, we propose a method that can directly use the available gene expression data to obtain an approximated control policy for gene regulation that avoids the time consuming model building phase. Results show that we can obtain policies for gene regulation systems of several thousands of genes just in several seconds while existing solutions get stuck for even tens of genes. Interestingly, the reported results also show that our method produces policies that are almost as good as the ones generated by existing model dependent methods.

#index 2033120
#* Protein function prediction via Laplacian network partitioning incorporating function category correlations
#@ Hua Wang;Heng Huang;Chris Ding
#t 2013
#c 11
#% 74120
#% 313959
#% 833125
#% 906419
#% 989597
#% 1495434
#% 1495503
#% 1750425
#% 1798265
#! Understanding the molecular mechanisms of life requires decoding the functions of the proteins in an organism. Various high-throughput experimental techniques have been developed to characterize biological systems at the genome scale. A fundamental challenge of the post-genomic era is to assign biological functions to all the proteins encoded by the genome using high-throughput biological data. To address this challenge, we propose a novel Laplacian Network Partitioning incorporating function category Correlations (LNPC) method to predict protein function on protein-protein interaction (PPI) networks by optimizing a Laplacian based quotient objective function that seeks the optimal network configuration to maximize consistent function assignments over edges on the whole graph. Unlike the existing approaches that have no unique optimization solutions, our optimization problem has unique global solution by eigen-decomposition methods. The correlations among protein function categories are quantified and incorporated into a correlated protein affinity graph which is integrated into the PPI graph to significantly improve the protein function prediction accuracy. We apply our new method to the BioGRID dataset for the Saccharomyces Cerevisiae species using the MIPS annotation scheme. Our new method outperforms other related state-of-the-art approaches more than 63% by the average precision of function prediction and 53% by the average F1 score.

#index 2033121
#* Identifying useful human correction feedback from an on-line machine translation service
#@ Alberto Barrón-Cedeño;Lluís Màrquez;Q. Carlos A. Henríquez;Lluís Formiga;Enrique Romero;Jonathan May
#t 2013
#c 11
#% 190581
#% 269217
#% 616528
#% 732848
#% 740901
#% 815902
#% 926881
#% 1375952
#% 1457068
#% 1558415
#% 1701311
#% 1915294
#% 1915325
#! Post-editing feedback provided by users of on-line translation services offers an excellent opportunity for automatic improvement of statistical machine translation (SMT) systems. However, feedback provided by casual users is very noisy, and must be automatically filtered in order to identify the potentially useful cases. We present a study on automatic feedback filtering in a real weblog collected from Reverso.net. We extend and re-annotate a training corpus, define an extended set of simple features and approach the problem as a binary classification task, experimenting with linear and kernel-based classifiers and feature selection. Results on the feedback filtering task show a significant improvement over the majority class, but also a precision ceiling around 70-80%. This reflects the inherent difficulty of the problem and indicates that shallow features cannot fully capture the semantic nature of the problem. Despite the modest results on the filtering task, the classifiers are proven effective in an application-based evaluation. The incorporation of a filtered set of feedback instances selected from a larger corpus significantly improves the performance of a phrase-based SMT system, according to a set of standard evaluation metrics.

#index 2033122
#* Mining for analogous tuples from an entity-relation graph
#@ Danushka Bollegala;Mitsuru Kusumoto;Yuichi Yoshida;Ken-Ichi Kawarabayashi
#t 2013
#c 11
#% 65345
#% 198058
#% 342630
#% 743284
#% 756964
#% 902089
#% 956564
#% 983830
#% 1063570
#% 1077150
#% 1190120
#% 1269899
#% 1272255
#% 1289532
#% 1409954
#% 1913673
#! The ability to recognize analogies is an important factor that is closely related to human intelligence. Verbal analogies have been used for evaluating both examinees at university entrance exams as well as algorithms for measuring relational similarity. However, relational similarity measures proposed so far are confined to measuring the similarity between pairs of words. Unfortunately, such pairwise approaches ignore the rich relational structure that exists in real-world knowledge bases containing millions of entities and semantic relations. We propose a method to efficiently identify analogous entity tuples from a given entity-relation graph. First, we present an efficient approach for extracting potential analogous tuples from a given entity-relation graph. Second, to measure the structural similarity between two tuples, we propose two types of kernel functions: vertex-feature kernels, and edge-feature kernels. Moreover, we combine those kernels to construct composite kernels that simultaneously consider both vertex and edge features. Experimental results show that our proposed method accurately identifies analogous tuples and significantly outperforms a state-of-the-art pairwise relational similarity measure, extended to tuples.

#index 2033123
#* Leveraging multi-domain prior knowledge in topic models
#@ Zhiyuan Chen;Arjun Mukherjee;Bing Liu;Meichun Hsu;Malu Castellanos;Riddhiman Ghosh
#t 2013
#c 11
#% 198058
#% 280819
#% 722904
#% 956510
#% 1055682
#% 1074129
#% 1089247
#% 1211693
#% 1268066
#% 1302868
#% 1434145
#% 1451218
#% 1464068
#% 1481541
#% 1536586
#% 1591954
#% 1689718
#% 1711748
#% 1826250
#% 1826251
#% 1826366
#% 1905997
#% 1913279
#! Topic models have been widely used to identify topics in text corpora. It is also known that purely unsupervised models often result in topics that are not comprehensible in applications. In recent years, a number of knowledge-based models have been proposed, which allow the user to input prior knowledge of the domain to produce more coherent and meaningful topics. In this paper, we go one step further to study how the prior knowledge from other domains can be exploited to help topic modeling in the new domain. This problem setting is important from both the application and the learning perspectives because knowledge is inherently accumulative. We human beings gain knowledge gradually and use the old knowledge to help solve new problems. To achieve this objective, existing models have some major difficulties. In this paper, we propose a novel knowledge-based model, called MDK-LDA, which is capable of using prior knowledge from multiple domains. Our evaluation results will demonstrate its effectiveness.

#index 2033124
#* Learning topical translation model for microblog hashtag suggestion
#@ Zhuoye Ding;Xipeng Qiu;Qi Zhang;Xuanjing Huang
#t 2013
#c 11
#% 642990
#% 722904
#% 734590
#% 740915
#% 869608
#% 1026895
#% 1040664
#% 1074117
#% 1156304
#% 1214694
#% 1287227
#% 1330519
#% 1450965
#% 1544032
#% 1587367
#% 1591967
#% 1591994
#% 1642034
#% 1711869
#% 1826347
#% 1913299
#! Hashtags can be viewed as an indication to the context of the tweet or as the core idea expressed in the tweet. They provide valuable information for many applications, such as information retrieval, opinion mining, text classification, and so on. However, only a small number of microblogs are manually tagged. To address this problem, in this work, we propose a topical translation model for microblog hashtag suggestion. We assume that the content and hashtags of the tweet are talking about the same themes but written in different languages. Under the assumption, hashtag suggestion is modeled as a translation process from content to hashtags. Moreover, in order to cover the topic of tweets, the proposed model regards the translation probability to be topic-specific. It uses topic-specific word trigger to bridge the vocabulary gap between the words in tweets and hashtags, and discovers the topics of tweets by a topic model designed for microblogs. Experimental results on the dataset crawled from real world microblogging service demonstrate that the proposed method outperforms state-of-the-art methods.

#index 2033125
#* Smoothing for bracketing induction
#@ Xiangyu Duan;Min Zhang;Wenliang Chen
#t 2013
#c 11
#% 740916
#% 815879
#% 828246
#% 938713
#% 938714
#% 939611
#% 939624
#% 1100092
#% 1270657
#% 1270660
#% 1310469
#% 1470678
#% 1481466
#% 1481652
#% 1551201
#% 1592036
#% 1606398
#% 1913289
#! Bracketing induction is the unsupervised learning of hierarchical constituents without labeling their syntactic categories such as verb phrase (VP) from natural raw sentences. Constituent Context Model (CCM) is an effective generative model for the bracketing induction, but the CCM computes probability of a constituent in a very straightforward way no matter how long this constituent is. Such method causes severe data sparse problem because long constituents are more unlikely to appear in test set. To overcome the data sparse problem, this paper proposes to define a non-parametric Bayesian prior distribution, namely the Pitman-Yor Process (PYP) prior, over constituents for constituent smoothing. The PYP prior functions as a back-off smoothing method through using a hierarchical smoothing scheme (HSS). Various kinds of HSS are proposed in this paper. We find that two kinds of HSS are effective, attaining or significantly improving the state-of-the-art performance of the bracketing induction evaluated on standard treebanks of various languages, while another kind of HSS, which is commonly used for smoothing sequences by n-gram Markovization, is not effective for improving the performance of the CCM.

#index 2033126
#* Crowdsourcing-assisted query structure interpretation
#@ Jun Han;Ju Fan;Lizhu Zhou
#t 2013
#c 11
#% 348155
#% 1190076
#% 1227648
#% 1251646
#% 1330534
#% 1400017
#% 1426566
#% 1432722
#% 1471314
#% 1581860
#% 1592050
#% 1598339
#% 1666684
#% 1693900
#% 1712595
#% 1746839
#% 1880463
#! Structured Web search incorporating data from structured sources into search engine results has attracted much attention from both academic and industrial communities. To understand user's intent, query structure interpretation is proposed to analyze the structure of queries in a query log and map query terms to the semantically relevant attributes of data sources in a target domain. Existing methods assume all queries should be classified to the target domain, and thus they are limited when interpreting queries from different domains in real query logs. To address the problem, we introduce a human-machine hybrid method by utilizing crowdsourcing platforms. Our method selects a small number of query terms and asks the crowdsourcing workers to interpret them, and then infers the interpretations based on the crowdsourcing results. To improve the performance, we propose an iterative probabilistic inference method based on a similarity graph of query terms, and select the most useful query terms for crowdsourcing by considering their domain-relevance and gained benefit. We evaluate our method on a real query log, and the experimental results show that our method outperforms the state-of-the-art method.

#index 2033127
#* PPSGen: learning to generate presentation slides for academic papers
#@ Yue Hu;Xiaojun Wan
#t 2013
#c 11
#% 831308
#% 961618
#% 967255
#% 1019065
#% 1249537
#% 1260450
#% 1262964
#% 1392478
#% 1558464
#% 1591977
#% 1712181
#% 1913591
#! In this paper, we investigate a very challenging task of automatically generating presentation slides for academic papers. The generated presentation slides can be used as drafts to help the presenters prepare their formal slides in a quicker way. A novel system called PPSGen is proposed to address this task. It first employs regression methods to learn the importance of the sentences in an academic paper, and then exploits the integer linear programming (ILP) method to generate well-structured slides by selecting and aligning key phrases and sentences. Evaluation results on a test set of 200 pairs of papers and slides collected on the web demonstrate that our proposed PPSGen system can generate slides with better quality. A user study is also illustrated to show that PPSGen has a few evident advantages over baseline methods.

#index 2033128
#* End-to-end coreference resolution for clinical narratives
#@ Prateek Jindal;Dan Roth
#t 2013
#c 11
#% 464434
#% 815292
#% 815329
#% 815876
#% 939857
#% 1264748
#% 1264785
#% 1473347
#% 1481583
#% 1592010
#% 1701285
#% 1896884
#% 1913682
#% 1913747
#! Coreference resolution is the problem of clustering mentions into entities and is very critical for natural language understanding. This paper studies the problem of coreference resolution in the context of the important domain of clinical text. Clinical text is unique because it requires significant use of domain knowledge to support coreference resolution. It also has specific discourse characteristics which impose several constraints on coreference decisions. We present a principled framework to incorporate knowledge-based constraints in the coreference model. We also show that different pronouns behave quite differently, necessitating the development of distinct ways for resolving different pronouns. Our methods result in significant performance improvements and we report the best results on a clinical corpora that has been used in coreference shared tasks. Moreover, for the first time, we report the results for end-to-end coreference resolution on this corpora.

#index 2033129
#* A clause-level hybrid approach to Chinese empty element recovery
#@ Fang Kong;Guodong Zhou
#t 2013
#c 11
#% 740916
#% 808936
#% 815880
#% 855270
#% 938693
#% 938734
#% 939555
#% 940014
#% 1338662
#% 1481597
#% 1544162
#% 1592181
#% 1592255
#! Empty elements (EEs) play a critical role in Chinese syntactic, semantic and discourse analysis. Previous studies employ a language-independent sentence-level approach to EE recovery, by casting it as a linear tagging or structured parsing problem. In comparison, this paper proposes a clause-level hybrid approach to address specific problems in Chinese EE recovery, which recovers EEs in Chinese language from the clause perspective and integrates the advantages of both linear tagging and structured parsing. In particular, a comma disambiguation method is employed to improve syntactic parsing and help determine clauses in Chinese. In this way, the noise introduced by sentence-level syntactic parsing and multiple EEs in the same position of a linear sentence can be well addressed. Evaluation on Chinese Treebank 6.0 shows the significant performance improvement of our clause-level hybrid approach over the state-of-the-art sentence-level baselines, and its great impact on a state-of-the-art Chinese syntactic parser.

#index 2033130
#* Joint modeling of argument identification and role determination in Chinese event extraction with discourse-level information
#@ Peifeng Li;Qiaoming Zhu;Guodong Zhou
#t 2013
#c 11
#% 927762
#% 940036
#% 1227920
#% 1270777
#% 1271484
#% 1338542
#% 1338543
#% 1470685
#% 1471291
#% 1592026
#% 1592041
#% 1592042
#% 1711725
#% 1711736
#% 1913331
#% 1913614
#% 1913631
#% 1913661
#% 1913683
#! Argument extraction is a challenging task in event extraction. However, most of previous studies focused on intra-sentence information and failed to extract inter-sentence arguments. This paper proposes a discourse-level joint model of argument identification and role determination to infer those inter-sentence arguments in a discourse. Moreover, to better represent the relationship among relevant event mentions and the relationship between an event mention and its arguments in a discourse, this paper introduces various kinds of corpus-based and discourse-based constraints in the joint model, either automatically learned or linguistically motivated. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our joint model over a strong baseline in Chinese argument extraction, in particular argument identification.

#index 2033131
#* Active learning for cross-domain sentiment classification
#@ Shoushan Li;Yunxia Xue;Zhongqing Wang;Guodong Zhou
#t 2013
#c 11
#% 476744
#% 815915
#% 854646
#% 938727
#% 1108902
#% 1127964
#% 1176920
#% 1251728
#% 1464068
#% 1471221
#% 1472892
#% 1591941
#% 1591942
#% 1938500
#! In the literature, various approaches have been proposed to address the domain adaptation problem in sentiment classification (also called cross-domain sentiment classification). However, the adaptation performance normally much suffers when the data distributions in the source and target domains differ significantly. In this paper, we suggest to perform active learning for cross-domain sentiment classification by actively selecting a small amount of labeled data in the target domain. Accordingly, we propose an novel active learning approach for cross-domain sentiment classification. First, we train two individual classifiers, i.e., the source and target classifiers with the labeled data from the source and target respectively. Then, the two classifiers are employed to select informative samples with the selection strategy of Query By Committee (QBC). Third, the two classifier is combined to make the classification decision. Importantly, the two classifiers are trained by fully exploiting the unlabeled data in the target domain with the label propagation (LP) algorithm. Empirical studies demonstrate the effectiveness of our active learning approach for cross-domain sentiment classification over some strong baselines.

#index 2033132
#* Opinion target extraction using partially-supervised word alignment model
#@ Kang Liu;Liheng Xu;Yang Liu;Jun Zhao
#t 2013
#c 11
#% 290830
#% 579944
#% 740915
#% 769892
#% 805873
#% 939864
#% 939896
#% 1035591
#% 1055761
#% 1211748
#% 1250237
#% 1264778
#% 1292706
#% 1338688
#% 1479998
#% 1484314
#% 1544094
#% 1544171
#% 1566286
#% 1913286
#% 1913692
#! Mining opinion targets from online reviews is an important and challenging task in opinion mining. This paper proposes a novel approach to extract opinion targets by using partially-supervised word alignment model (PSWAM). At first, we apply PSWAM in a monolingual scenario to mine opinion relations in sentences and estimate the associations between words. Then, a graph-based algorithm is exploited to estimate the confidence of each candidate, and the candidates with higher confidence will be extracted as the opinion targets. Compared with existing syntax-based methods, PSWAM can effectively avoid parsing errors when dealing with informal sentences in online reviews. Compared with the methods using alignment model, PSWAM can capture opinion relations more precisely through partial supervision from partial alignment links. Moreover, when estimating candidate confidence, we make penalties on higher-degree vertices in our graph-based algorithm in order to decrease the probability of the random walk running into the unrelated regions in the graph. As a result, some errors can be avoided. The experimental results on three data sets with different sizes and languages show that our approach outperforms state-of-the-art methods.

#index 2033133
#* Joint and coupled bilingual topic model based sentence representations for language model adaptation
#@ Shixiang Lu;Xiaoyin Fu;Wei Wei;Xingyuan Peng;Bo Xu
#t 2013
#c 11
#% 815902
#% 817439
#% 939707
#% 979655
#% 1237675
#% 1264807
#% 1275638
#% 1338620
#% 1417055
#% 1472297
#% 1481560
#% 1592222
#% 1598401
#% 1701337
#% 1711757
#% 1913616
#! This paper is concerned with data selection for adapting language model (LM) in statistical machine translation (SMT), and aims to find the LM training sentences that are topic similar to the translation task. Although the traditional approaches have gained significant performance, they ignore the topic information and the distribution information of words when selecting similar training sentences. In this paper, we present two bilingual topic model (BLTM) (joint and coupled BLTM) based sentence representations for cross-lingual data selection. We map the data selection task into cross-lingual semantic representations that are language independent, then rank and select sentences in the target language LM training corpus for a sentence in the translation task by the semanticsbased likelihood. The semantic representations are learned from the parallel corpus, with the assumption that the bilingual pair shares the same or similar distribution over semantic topics. Large-scale experimental results demonstrate that our approaches significantly outperform the state-of-the-art approaches on both LM perplexity and translation performance, respectively.

#index 2033134
#* Integrating syntactic and semantic analysis into the open information extraction paradigm
#@ Andrea Moro;Roberto Navigli
#t 2013
#c 11
#% 818916
#% 939600
#% 939944
#% 1063570
#% 1089602
#% 1250397
#% 1409954
#% 1471191
#% 1471209
#% 1478186
#% 1503903
#% 1585243
#% 1591983
#% 1653173
#% 1711819
#% 1913663
#% 1913673
#% 1913697
#% 1919042
#% 1919718
#% 1919797
#% 1925700
#% 1925702
#% 1925703
#% 1942737
#! In this paper we present an approach aimed at enriching the Open Information Extraction paradigm with semantic relation ontologization by integrating syntactic and semantic features into its workflow. To achieve this goal, we combine deep syntactic analysis and distributional semantics using a shortest path kernel method and soft clustering. The output of our system is a set of automatically discovered and ontologized semantic relations.

#index 2033135
#* Combine constituent and dependency parsing via reranking
#@ Xiaona Ren;Xiao Chen;Chunyu Kit
#t 2013
#c 11
#% 450888
#% 466736
#% 740916
#% 742218
#% 744564
#% 746865
#% 811337
#% 843647
#% 853845
#% 854636
#% 938665
#% 939343
#% 939353
#% 939919
#% 1249483
#% 1264734
#% 1264776
#% 1264809
#% 1270788
#% 1338586
#% 1338690
#% 1470565
#% 1471179
#% 1471180
#% 1481537
#% 1764097
#% 1911886
#% 1913356
#! This paper presents a reranking approach to combining constituent and dependency parsing, aimed at improving parsing performance on both sides. Most previous combination methods rely on complicated joint decoding to integrate graph- and transition-based dependency models. Instead, our approach makes use of a high-performance probabilistic context free grammar (PCFG) model to output k-best candidate constituent trees, and then a dependency parsing model to rerank the trees by their scores from both models, so as to get the most probable parse. Experimental results show that this reranking approach achieves the highest accuracy of constituent and dependency parsing on Chinese treebank (CTB5.1) and a comparable performance to the state of the art on English treebank (WSJ).

#index 2033136
#* Fast linearization of tree kernels over large-scale data
#@ Aliaksei Severyn;Alessandro Moschitti
#t 2013
#c 11
#% 269217
#% 452991
#% 464996
#% 577218
#% 722929
#% 740916
#% 742218
#% 815896
#% 817422
#% 858036
#% 881477
#% 939355
#% 939615
#% 939871
#% 959454
#% 1073912
#% 1117691
#% 1249528
#% 1344869
#% 1385997
#% 1617352
#! Convolution tree kernels have been successfully applied to many language processing tasks for achieving state-of-the-art accuracy. Unfortunately, higher computational complexity of learning with kernels w.r.t. using explicit feature vectors makes them less attractive for large-scale data. In this paper, we study the latest approaches to solve such problems ranging from feature hashing to reverse kernel engineering and approximate cutting plane training with model compression. We derive a novel method that relies on reverse-kernel engineering together with an efficient kernel learning method. The approach gives the advantage of using tree kernels to automatically generate rich structured feature spaces and working in the linear space where learning and testing is fast. We experimented with training sets up to 4 million examples from Semantic Role Labeling. The results show that (i) the choice of correct structural features is essential and (ii) we can speed-up training from weeks to less than 20 minutes.

#index 2033137
#* Answer extraction from passage graph for question answering
#@ Hong Sun;Nan Duan;Yajuan Duan;Ming Zhou
#t 2013
#c 11
#% 309124
#% 340954
#% 815868
#% 816220
#% 818316
#% 939358
#% 939612
#% 1481634
#% 1592244
#% 1650318
#% 1712160
#% 1810385
#! In question answering, answer extraction aims to pin-point the exact answer from passages. However, most previous methods perform such extraction on each passage separately, without considering clues provided in other passages. This paper presents a novel approach to extract answers by fully leveraging connections among different passages. Specially, extraction is performed on a Passage Graph which is built by adding links upon multiple passages. Different passages are connected by linking words with the same stem. We use the factor graph as our model for answer extraction. Experimental results on multiple QA data sets demonstrate that our method significantly improves the performance of answer extraction.

#index 2033138
#* Instance selection and instance weighting for cross-domain sentiment classification via PU learning
#@ Rui Xia;Xuelei Hu;Jianfeng Lu;Jian Yang;Chengqing Zong
#t 2013
#c 11
#% 464641
#% 727883
#% 770847
#% 1275203
#% 1305479
#% 1385982
#% 1400008
#% 1464068
#% 1471405
#% 1711757
#% 1826296
#! Due to the explosive growth of the Internet online reviews, we can easily collect a large amount of labeled reviews from different domains. But only some of them are beneficial for training a desired target-domain sentiment classifier. Therefore, it is important for us to identify those samples that are the most relevant to the target domain and use them as training data. To address this problem, a novel approach, based on instance selection and instance weighting via PU learning, is proposed. PU learning is used at first to learn an in-target-domain selector, which assigns an in-target-domain probability to each sample in the training set. For instance selection, the samples with higher in-target-domain probability are used as training data; For instance weighting, the calibrated in-target-domain probabilities are used as sampling weights for training an instance-weighted naive Bayes model, based on the principle of maximum weighted likelihood estimation. The experimental results prove the necessity and effectiveness of the approach, especially when the size of training data is large. It is also proved that the larger the Kullback-Leibler divergence between the training and test data is, the more effective the proposed approach will be.

#index 2033139
#* Modeling lexical cohesion for document-level machine translation
#@ Deyi Xiong;Guosheng Ben;Min Zhang;Yajuan Lü;Qun Liu
#t 2013
#c 11
#% 78171
#% 755818
#% 815902
#% 817439
#% 979655
#% 1042760
#% 1481425
#% 1592057
#% 1592175
#% 1711807
#% 1906947
#% 1913666
#% 1913677
#! Lexical cohesion arises from a chain of lexical items that establish links between sentences in a text. In this paper we propose three different models to capture lexical cohesion for document-level machine translation: (a) a direct reward model where translation hypotheses are rewarded whenever lexical cohesion devices occur in them, (b) a conditional probability model where the appropriateness of using lexical cohesion devices is measured, and (c) a mutual information trigger model where a lexical cohesion relation is considered as a trigger pair and the strength of the association between the trigger and the triggered item is estimated by mutual information. We integrate the three models into hierarchical phrase-based machine translation and evaluate their effectiveness on the NIST Chinese-English translation tasks with large-scale training data. Experiment results show that all three models can achieve substantial improvements over the baseline and that the mutual information trigger model performs better than the others.

#index 2033140
#* A text scanning mechanism simulating human reading process
#@ Bei Xu;Hai Zhuge
#t 2013
#c 11
#% 46803
#% 75896
#% 411760
#% 449746
#% 1051059
#% 1264797
#% 1306081
#% 1306104
#% 1389359
#% 1549516
#% 1560591
#% 1806134
#% 1826350
#% 1826361
#% 1927670
#! Previous text processing techniques focus on text itself while neglecting human reading process. Therefore they are limited in special applications. This paper proposes a text scanning mechanism for generating the dynamic impressions of words in text by simulating recall, association and forget processes during reading. Experiments show that the mechanism is suitable for multiple text processing applications.

#index 2033141
#* i, poet: automatic Chinese poetry composition through a generative summarization framework under constrained optimization
#@ Rui Yan;Han Jiang;Mirella Lapata;Shou-De Lin;Xueqiang Lv;Xiaoming Li
#t 2013
#c 11
#% 329569
#% 722904
#% 787502
#% 816173
#% 1074088
#% 1152725
#% 1251633
#% 1267925
#% 1289086
#% 1481586
#% 1598408
#% 1711764
#! Part of the long lasting cultural heritage of China is the classical ancient Chinese poems which follow strict formats and complicated linguistic rules. Automatic Chinese poetry composition by programs is considered as a challenging problem in computational linguistics and requires high Artificial Intelligence assistance, and has not been well addressed. In this paper, we formulate the poetry composition task as an optimization problem based on a generative summarization framework under several constraints. Given the user specified writing intents, the system retrieves candidate terms out of a large poem corpus, and then orders these terms to fit into poetry formats, satisfying tonal and rhythm requirements. The optimization process under constraints is conducted via iterative term substitutions till convergence, and outputs the subset with the highest utility as the generated poem. For experiments, we perform generation on large datasets of 61,960 classic poems from Tang and Song Dynasty of China. A comprehensive evaluation, using both human judgments and ROUGE scores, has demonstrated the effectiveness of our proposed approach.

#index 2033142
#* Fusion of word and letter based metrics for automatic MT evaluation
#@ Muyun Yang;Junguo Zhu;Sheng Li;Tiejun Zhao
#t 2013
#c 11
#% 269217
#% 815811
#% 815902
#% 816212
#% 817439
#% 817475
#% 938729
#% 995522
#% 1085084
#% 1153965
#% 1264741
#% 1275657
#% 1275669
#% 1275691
#% 1275692
#% 1275698
#% 1275699
#% 1328338
#% 1375947
#% 1375948
#% 1480000
#! With the progress in machine translation, it becomes more subtle to develop the evaluation metric capturing the systems' differences in comparison to the human translations. In contrast to the current efforts in leveraging more linguistic information to depict translation quality, this paper takes the thread of combining language independent features for a robust solution to MT evaluation metric. To compete with finer granularity of modeling brought by linguistic features, the proposed method augments the word level metrics by a letter based calculation. An empirical study is then conducted over WMT data to train the metrics by ranking SVM. The results reveal that the integration of current language independent metrics can generate well enough performance for a variety of languages. Time-split data validation is promising as a better training setting, though the greedy strategy also works well.

#index 2033143
#* Improving function word alignment with frequency and syntactic information
#@ Jingyi Zhang;Hai Zhao
#t 2013
#c 11
#% 579944
#% 740915
#% 757830
#% 815902
#% 816170
#% 817474
#% 1215368
#% 1271192
#% 1275666
#% 1275667
#% 1338551
#% 1711791
#! In statistical word alignment for machine translation, function words usually cause poor aligning performance because they do not have clear correspondence between different languages. This paper proposes a novel approach to improve word alignment by pruning alignments of function words from an existing alignment model with high precision and recall. Based on monolingual and bilingual frequency characteristics, a language-independent function word recognition algorithm is first proposed. Then a group of carefully defined syntactic structures combined with content word alignments are used for further function word alignment pruning. The experimental results show that the proposed approach improves both the quality of word alignment and the performance of statistical machine translation on Chinese-to-English, German-to-English and French-to-English language pairs.

#index 2033144
#* Cross lingual entity linking with bilingual topic model
#@ Tao Zhang;Kang Liu;Jun Zhao
#t 2013
#c 11
#% 722904
#% 1055680
#% 1055682
#% 1130858
#% 1275012
#% 1292487
#% 1338620
#% 1484272
#% 1484385
#% 1536542
#% 1592023
#% 1746843
#! Cross lingual entity linking means linking an entity mention in a background source document in one language with the corresponding real world entity in a knowledge base written in the other language. The key problem is to measure the similarity score between the context of the entity mention and the document of the candidate entity. This paper presents a general framework for doing cross lingual entity linking by leveraging a large scale and bilingual knowledge base, Wikipedia. We introduce a bilingual topic model that mining bilingual topic from this knowledge base with the assumption that the same Wikipedia concept documents of two different languages share the same semantic topic distribution. The extracted topics have two types of representation, with each type corresponding to one language. Thus both the context of the entity mention and the document of the candidate entity can be represented in a space using the same semantic topics. We use these topics to do cross lingual entity linking. Experimental results show that the proposed approach can obtain the competitive results compared with the state-of-art approach.

#index 2033145
#* Integrating semantic relatedness and words' intrinsic features for keyword extraction
#@ Wei Zhang;Wei Feng;Jianyong Wang
#t 2013
#c 11
#% 348173
#% 420487
#% 722904
#% 855293
#% 881477
#% 983820
#% 1190121
#% 1227720
#% 1270224
#% 1292688
#% 1338554
#% 1400085
#% 1481571
#% 1536568
#% 1591967
#% 1872383
#! Keyword extraction attracts much attention for its significant role in various natural language processing tasks. While some existing methods for keyword extraction have considered using single type of semantic relatedness between words or inherent attributes of words, almost all of them ignore two important issues: 1) how to fuse multiple types of semantic relations between words into a uniform semantic measurement and automatically learn the weights of the edges between the words in the word graph of each document, and 2) how to integrate the relations between words and words' intrinsic features into a unified model. In this work, we tackle the two issues based on the supervised random walk model. We propose a supervised ranking based method for keyword extraction, which is called SEAFARER1. It can not only automatically learn the weights of the edges in the unified graph of each document which includes multiple semantic relations but also combine the merits of semantic relations of edges and intrinsic attributes of nodes together. We conducted extensive experimental study on an established benchmark and the experimental results demonstrate that SEAFARER outperforms the state-of-the-art supervised and unsupervised methods.

#index 2033146
#* Partial-tree linearization: generalized word ordering for text synthesis
#@ Yue Zhang
#t 2013
#c 11
#% 742339
#% 815902
#% 816170
#% 840856
#% 846586
#% 854636
#% 979655
#% 1260760
#% 1330528
#% 1338570
#% 1471179
#% 1592177
#% 1711829
#% 1746716
#% 1906051
#! We present partial-tree linearization, a generalized word ordering (i.e. ordering a set of input words into a grammatical and fluent sentence) task for text-to-text applications. Recent studies of word ordering can be categorized into either abstract word ordering (no input syntax except for POS) or tree linearization (input words are associated with a full unordered syntax tree). Partial-tree linearization covers the whole spectrum of input between these two extremes. By allowing POS and dependency relations to be associated with any subset of input words, partial-tree linearization is more practical for a dependency-based NLG pipeline, such as transfer-based MT and abstractive text summarization. In addition, a partial-tree linearizer can also perform abstract word ordering and full-tree linearization. Our system achieves the best published results on standard PTB evaluations of these tasks.

#index 2033147
#* Improving question retrieval in community question answering using world knowledge
#@ Guangyou Zhou;Yang Liu;Fang Liu;Daojian Zeng;Jun Zhao
#t 2013
#c 11
#% 309126
#% 757306
#% 793419
#% 838398
#% 961685
#% 1074073
#% 1074110
#% 1083703
#% 1117027
#% 1214660
#% 1227600
#% 1250362
#% 1264760
#% 1269899
#% 1292492
#% 1292559
#% 1330519
#% 1399953
#% 1471303
#% 1591994
#% 1642070
#% 1913685
#! Community question answering (cQA), which provides a platform for people with diverse background to share information and knowledge, has become an increasingly popular research topic. In this paper, we focus on the task of question retrieval. The key problem of question retrieval is to measure the similarity between the queried questions and the historical questions which have been solved by other users. The traditional methods measure the similarity based on the bag-of-words (BOWs) representation. This representation neither captures dependencies between related words, nor handles synonyms or polysemous words. In this work, we first propose a way to build a concept thesaurus based on the semantic relations extracted from the world knowledge of Wikipedia. Then, we develop a unified framework to leverage these semantic relations in order to enhance the question similarity in the concept space. Experiments conducted on a real cQA data set show that with the help of Wikipedia thesaurus, the performance of question retrieval is improved as compared to the traditional methods.

#index 2033148
#* Efficient latent structural perceptron with hybrid trees for semantic parsing
#@ Junsheng Zhou;Juhong Xu;Weiguang Qu
#t 2013
#c 11
#% 66654
#% 382854
#% 441307
#% 854636
#% 939615
#% 940046
#% 952651
#% 983554
#% 1045831
#% 1264799
#% 1269528
#% 1305487
#% 1330506
#% 1344851
#% 1481654
#% 1913294
#! Discriminative structured prediction models have been widely used in many natural language processing tasks, but it is challenging to apply the method to semantic parsing. In this paper, by introducing hybrid tree as a latent structure variable to close the gap between the input sentences and output representations, we formulate semantic parsing as a structured prediction problem, based on the latent variable perceptron model incorporated with a tree edit-distance loss as optimization criterion. The proposed approach maintains the advantage of a discriminative model in accommodating flexible combination of features and naturally incorporates an efficient decoding algorithm in learning and inference. Furthermore, in order to enhance the efficiency and accuracy of inference, we design an effective approach based on vector space model to extract a smaller subset of relevant MR productions for test examples. Experimental results on publicly available corpus show that our approach significantly outperforms previous systems.

#index 2033149
#* Revisiting regression in planning
#@ Vidal Alcázar;Daniel Borrajo;Susana Fernández;Raquel Fuentetaja
#t 2013
#c 11
#% 337980
#% 710000
#% 1271820
#% 1271962
#% 1272047
#% 1272113
#% 1273776
#% 1289210
#% 1305568
#% 1493597
#% 1545553
#! Heuristic search with reachability-based heuristics is arguably the most successful paradigm in Automated Planning to date. In its earlier stages of development, heuristic search was proposed as both forward and backward search. Due to the disadvantages of backward search, in the last decade researchers focused mainly on forward search, and backward search was abandoned for the most part as a valid alternative. In the last years, important advancements regarding both the theoretical understanding and the performance of heuristic search have been achieved, applied mainly to forward search planners. In this work we revisit regression in planning with reachability-based heuristics, trying to extrapolate to backward search current lines of research that were not as well understood as they are now.

#index 2033150
#* Bridging the gap between refinement and heuristics in abstraction
#@ Christer Bäckström;Peter Jonsson
#t 2013
#c 11
#% 1722
#% 172505
#% 194646
#% 217077
#% 657755
#% 1269581
#% 1269831
#% 1272113
#% 1272230
#% 1290104
#% 1452572
#% 1499544
#! There are two major uses of abstraction in planning and search: refinement (where abstract solutions are extended into concrete solutions) and heuristics (where abstract solutions are used to compute heuristics for the original search space). These two approaches are usually viewed as unrelated in the literature. It is reasonable to believe, though, that they are related, since they are both intrinsically based on the structure of abstract search spaces. We take the first steps towards formally investigating their relationships, employing our recently introduced framework for analysing and comparing abstraction methods. By adding some mechanisms for expressing metric properties, we can capture concepts like admissibility and consistency of heuristics. We present an extensive study of how such metric properties relate to the properties in the original framework, revealing a number of connections between the refinement and heuristic approaches. This also provides new insights into, for example, Valtorta's theorem and spurious states.

#index 2033151
#* An admissible heuristic for SAS+ planning obtained from the state equation
#@ Blai Bonet
#t 2013
#c 11
#% 337980
#% 1269831
#% 1271962
#% 1272047
#% 1275060
#% 1305567
#% 1399103
#% 1473264
#% 1545553
#% 1870189
#% 1911365
#! Domain-independent optimal planning has seen important breakthroughs in recent years with the development of tractable and informative admissible heuristics, suitable for planners based on forward state-space search. These heuristics allow planners to optimally solve an important number of benchmark problems, including problems that are quite involved and difficult for the layman. In this paper we present a new admissible heuristic that is obtained from the state equation associated to the Petri-net representation of the planning problem. The new heuristic, that does not fall into one of the four standard classes, can be computed in polynomial time and is competitive with the current state of the art for optimal planning, as empirically demonstrated over a large number of problems, mainly because it often shows an improved quality-to-cost ratio. The new heuristic applies to SAS+ planning tasks with arbitrary non-negative action costs.

#index 2033152
#* Causal belief decomposition for planning with sensing: completeness results and practical approximation
#@ Blai Bonet;Hector Geffner
#t 2013
#c 11
#% 44876
#% 224751
#% 1272349
#% 1279222
#% 1288659
#% 1305550
#% 1313373
#% 1650437
#% 1665148
#% 1826372
#% 1826387
#! Belief tracking is a basic problem in planning with sensing. While the problem is intractable, it has been recently shown that for both deterministic and non-deterministic systems expressed in compact form, it can be done in time and space that are exponential in the problem width. The width measures the maximum number of state variables that are all relevant to a given precondition or goal. In this work, we extend this result both theoretically and practically. First, we introduce an alternative decomposition scheme and algorithm with the same time complexity but different completeness guarantees, whose space complexity is much smaller: exponential in the causal width of the problem that measures the number of state variables that are causally relevant to a given precondition, goal, or observable. Second, we introduce a fast, meaningful, and powerful approximation that trades completeness by speed, and is both time and space exponential in the problem causal width. It is then shown empirically that the algorithm combined with simple heuristics yields state-of-the-art real-time performance in domains with high widths but low causal widths such as Minesweeper, Battleship, and Wumpus.

#index 2033153
#* Isomorph-free branch and bound search for finite state controllers
#@ Marek Grześ;Pascal Poupart;Jesse Hoey
#t 2013
#c 11
#% 272652
#% 671908
#% 1250227
#% 1271823
#% 1289562
#% 1456804
#% 1617336
#% 1650313
#% 1907270
#! The recent proliferation of smart-phones and other wearable devices has lead to a surge of new mobile applications. Partially observable Markov decision processes provide a natural framework to design applications that continuously make decisions based on noisy sensor measurements. However, given the limited battery life, there is a need to minimize the amount of online computation. This can be achieved by compiling a policy into a finite state controller since there is no need for belief monitoring or online search. In this paper, we propose a new branch and bound technique to search for a good controller. In contrast to many existing algorithms for controllers, our search technique is not subject to local optima. We also show how to reduce the amount of search by avoiding the enumeration of isomorphic controllers and by taking advantage of suitable upper and lower bounds. The approach is demonstrated on several benchmark problems as well as a smart-phone application to assist persons with Alzheimer's to wayfind.

#index 2033154
#* Optimal delete-relaxed (and semi-relaxed) planning with conditional effects
#@ Patrik Haslum
#t 2013
#c 11
#% 100159
#% 117773
#% 1250631
#% 1271818
#% 1271962
#% 1272008
#% 1279705
#% 1288659
#% 1492073
#! Recently, several methods have been proposed for optimal delete-free planning. We present an incremental compilation approach that enables these methods to be applied to problems with conditional effects, which none of them support natively. With an h+ solver for problems with conditional effects in hand, we also consider adapting the h++ anytime lower bound function to use the more space-efficient PceC compilation. This avoids the memory limitation of the original h++ caused by its reliance on an exponential-space compilation. It also leads to improvements on some problems where memory is not an issue.

#index 2033155
#* Interactive POMDP lite: towards practical planning to predict and exploit intentions for interacting with self-interested agents
#@ Trong Nghia Hoang;Kian Hsiang Low
#t 2013
#c 11
#% 465913
#% 643168
#% 890362
#% 1250230
#% 1270029
#% 1272071
#% 1272264
#% 1275077
#% 1279314
#% 1279358
#% 1826386
#% 1875884
#! A key challenge in non-cooperative multi-agent systems is that of developing efficient planning algorithms for intelligent agents to interact and perform effectively among boundedly rational, self-interested agents (e.g., humans). The practicality of existing works addressing this challenge is being undermined due to either the restrictive assumptions of the other agents' behavior, the failure in accounting for their rationality, or the prohibitively expensive cost of modeling and predicting their intentions. To boost the practicality of research in this field, we investigate how intention prediction can be efficiently exploited and made practical in planning, thereby leading to efficient intention-aware planning frameworks capable of predicting the intentions of other agents and acting optimally with respect to their predicted intentions. We show that the performance losses incurred by the resulting planning policies are linearly bounded by the error of intention prediction. Empirical evaluations through a series of stochastic games demonstrate that our policies can achieve better and more robust performance than the state-of-the-art algorithms.

#index 2033156
#* Controlling the hypothesis space in probabilistic plan recognition
#@ Froduald Kabanza;Julien Filion;Abder Rezak Benaskeur;Hengameh Irandoust
#t 2013
#c 11
#% 284787
#% 743353
#% 928207
#% 1034844
#% 1210222
#% 1250303
#% 1270246
#% 1272356
#% 1279469
#% 1289455
#% 1477318
#% 1650474
#! The ability to understand the goals and plans of other agents is an important characteristic of intelligent behaviours in many contexts. One of the approaches used to endow agents with this capability is the weighted model counting approach. Given a plan library and a sequence of observations, this approach exhaustively enumerates plan execution models that are consistent with the observed behaviour. The probability that the agent might be pursuing a particular goal is then computed as a proportion of plan execution models satisfying the goal. The approach allows to recognize multiple interleaved plans, but suffers from a combinatorial explosion of plan execution models, which impedes its application to real-world domains. This paper presents a heuristic weighted model counting algorithm that limits the number of generated plan execution models in order to recognize goals quickly by computing their lower and upper bound likelihoods.

#index 2033157
#* Lifelong learning for acquiring the wisdom of the crowd
#@ Ece Kamar;Ashish Kapoor;Eric Horvitz
#t 2013
#c 11
#% 384911
#% 425053
#% 550562
#% 1060263
#% 1065099
#% 1073993
#% 1083692
#% 1480225
#% 1650283
#% 1650536
#% 1665148
#% 1699628
#% 1875704
#% 1989622
#! Predictive models play a key role for inference and decision making in crowdsourcing. We present methods that can be used to guide the collection of data for enhancing the competency of such predictive models while using the models to provide a base crowdsourcing service. We focus on the challenge of ideally balancing the goals of collecting data over time for learning and for improving task performance with the cost of workers' contributions over the lifetime of the operation of a system. We introduce the use of distributions over a set of predictive models to represent uncertainty about the dynamics of the world. We employ a novel Monte Carlo algorithm to reason simultaneously about uncertainty about the world dynamics and the progression of task solution as workers are hired over time to optimize hiring decisions. We evaluate the methodology with experiments on a challenging citizen-science problem, demonstrating how it balances exploration and exploitation over the lifetime of a crowdsourcing system.

#index 2033158
#* Pareto-based multiobjective AI planning
#@ Mostepha Khouadjia;Marc Schoenauer;Vincent Vidal;Johann Dréo;Pierre Savéant
#t 2013
#c 11
#% 392343
#% 590623
#% 729456
#% 1046055
#% 1250209
#% 1272008
#% 1272014
#% 1369579
#% 1389512
#% 1391537
#% 1736634
#% 1740844
#! Real-world problems generally involve several antagonistic objectives, like quality and cost for design problems, or makespan and cost for planning problems. The only approaches to multiobjective AI Planning rely on metrics, that can incorporate several objectives in some linear combinations, and metric sensitive planners, that are able to give different plans for different metrics, and hence to eventually approximate the Pareto front of the multiobjective problem, i.e. the set of optimal trade-offs between the antagonistic objectives. Divide-and-Evolve (DAE) is an evolutionary planner that embeds a classical planner and feeds it with a sequence of subproblems of the problem at hand. Like all Evolutionary Algorithms, DAE can be turned into a Pareto-based multiobjective solver, even though using an embedded planner that is not metric sensitive. The Pareto-based multiobjective planner MO-DAE thus avoids the drawbacks of the aggregation method. Furthermore, using YAHSP as the embedded planner, it outperforms in many cases the metric-based approach using LPG metric sensitive planner, as witnessed by experimental results on original multiobjective benchmarks built upon IPC-2011 domains.

#index 2033159
#* Flexible execution of partial order plans with temporal constraints
#@ Christian Muise;J. Christopher Beck;Sheila A. McIlraith
#t 2013
#c 11
#% 86199
#% 107137
#% 162493
#% 743353
#% 743461
#% 1068329
#% 1178631
#% 1270230
#% 1271957
#% 1272008
#% 1272020
#% 1275052
#% 1289214
#% 1291060
#% 1590514
#% 1765811
#% 1826378
#! We propose a unified approach to plan execution and schedule dispatching that converts a plan, which has been augmented with temporal constraints, into a policy for dispatching. Our approach generalizes the original plan and temporal constraints so that the executor need only consider the subset of state that is relevant to successful execution of valid plan fragments. We can accommodate a variety of calamitous and serendipitous changes to the state of the world by supporting the seamless re-execution or omission of plan fragments, without the need for costly replanning. Our methodology for plan generalization and online dispatching is a novel combination of plan execution and schedule dispatching techniques. We demonstrate the effectiveness of our method through a prototype implementation and a series of experiments.

#index 2033160
#* Towards a second generation random walk planner: an experimental exploration
#@ Hootan Nakhost;Martin Müller
#t 2013
#c 11
#% 337980
#% 384911
#% 750050
#% 1271962
#% 1272113
#% 1305573
#! Random walks have become a popular component of recent planning systems. The increased exploration is a valuable addition to more exploitative search methods such as Greedy Best First Search (GBFS). A number of successful planners which incorporate random walks have been built. The work presented here aims to exploit the experience gained from building those systems. It begins a systematic study of the design space and alternative choices for building such a system, and develops a new random walk planner from scratch, with careful experiments along the way. Four major insights are: 1. a high state evaluation frequency is usually superior to the endpoint-only evaluation used in earlier systems, 2. adjusting the restarting parameter according to the progress speed in the search space performs better than any fixed setting, 3. biasing the action selection towards preferred operators of only the current state is better than Monte Carlo Helpful Actions, which depend on the number of times an action has been a preferred operator in previous walks, and 4. even simple forms of random walk planning can compete with GBFS.

#index 2033161
#* Fair LTL synthesis for non-deterministic systems using strong cyclic planners
#@ Fabio Patrizi;Nir Lipovetzky;Hector Geffner
#t 2013
#c 11
#% 65904
#% 101943
#% 145228
#% 167629
#% 172932
#% 215675
#% 417597
#% 543813
#% 544938
#% 544943
#% 655322
#% 734712
#% 1068329
#% 1178630
#% 1250631
#% 1395211
#% 1411821
#% 1545553
#% 1723908
#% 1826374
#% 1826382
#! We consider the problem of planning in environments where the state is fully observable, actions have non-deterministic effects, and plans must generate infinite state trajectories for achieving a large class of LTL goals. More formally, we focus on the control synthesis problem under the assumption that the LTL formula to be realized can be mapped into a deterministic Büchi automaton. We show that by assuming that action nondeterminism is fair, namely that infinite executions of a nondeterministic action in the same state yield each possible successor state an infinite number of times, the (fair) synthesis problem can be reduced to a standard strong cyclic planning task over reachability goals. Since strong cyclic planners are built on top of efficient classical planners, the transformation reduces the non-deterministic, fully observable, temporally extended planning task into the solution of classical planning problems. A number of experiments are reported showing the potential benefits of this approach to synthesis in comparison with state-of-the-art symbolic methods.

#index 2033162
#* Fault-tolerant planning under uncertainty
#@ Luis Pineda;Yi Lu;Shlomo Zilberstein;Claudia V. Goldman
#t 2013
#c 11
#% 62653
#% 266196
#% 329491
#% 337981
#% 363744
#% 384911
#% 1275454
#% 1291064
#% 1673028
#! A fault represents some erroneous operation of a system that could result from an action selection error or some abnormal condition. We formally define error models that characterize the likelihood of various faults and consider the problem of fault-tolerant planning, which optimizes performance given an error model. We show that factoring the possibility of errors significantly degrades the performance of stochastic planning algorithms such as LAO*, because the number of reachable states grows dramatically. We introduce an approach to plan for a bounded number of faults and analyze its theoretical properties. When combined with a continual planning paradigm, the k-fault-tolerant planning method can produce near-optimal performance, even when the number of faults exceeds the bound. Empirical results in two challenging domains confirm the effectiveness of the approach in handling different types of runtime errors.

#index 2033163
#* Getting the most out of pattern databases for classical planning
#@ Florian Pommerening;Gabriele Röger;Malte Helmert
#t 2013
#c 11
#% 1269831
#% 1272048
#% 1272113
#% 1272230
#% 1442138
#% 1826379
#! The iPDB procedure by Haslum et al. is the state-of-the-art method for computing additive abstraction heuristics for domain-independent planning. It performs a hill-climbing search in the space of pattern collections, combining information from multiple patterns in the so-called canonical heuristic. We show how stronger heuristic estimates can be obtained through linear programming. An experimental evaluation demonstrates the strength of the new technique on the IPC benchmark suite.

#index 2033164
#* Computing upper bounds on lengths of transition sequences
#@ Jussi Rintanen;Charles Orgill Gretton
#t 2013
#c 11
#% 167629
#% 172505
#% 266388
#% 337980
#% 417604
#% 533951
#% 1168797
#% 1223550
#% 1269831
#% 1271885
#% 1271985
#% 1476298
#% 1478838
#% 1538029
#% 1679926
#% 1698709
#% 1919038
#! We describe an approach to computing upper bounds on the lengths of solutions to reachability problems in transition systems. It is based on a decomposition of state-variable dependency graphs (causal graphs). Our approach is able to find practical upper bounds in a number of planning benchmarks. Computing the bounds is computationally cheap in practice, and in a number of benchmarks our algorithm runs in polynomial time in the number of actions and propositional variables that characterize the problem.

#index 2033165
#* Exploring knowledge engineering strategies in designing and modelling a road traffic accident management domain
#@ Mohammad M. Shah;Lukáš Chrpa;Diane Kitchin;Thomas L. McCluskey;Mauro Vallati
#t 2013
#c 11
#% 785511
#% 999221
#% 1272016
#% 1272116
#! Formulating knowledge for use in AI Planning engines is currently something of an ad-hoc process, where the skills of knowledge engineers and the tools they use may significantly influence the quality of the resulting planning application. There is little in the way of guidelines or standard procedures, however, for knowledge engineers to use when formulating knowledge into planning domain languages such as PDDL. This paper seeks to investigate this process using as a case study a road traffic accident management domain. Managing road accidents requires systematic, sound planning and coordination of resources to improve outcomes for accident victims. We have derived a set of requirements in consultation with stakeholders for the resource coordination part of managing accidents. We evaluate two separate knowledge engineering strategies for encoding the resulting planning domain from the set of requirements: (a) the traditional method of PDDL experts and text editor, and (b) a leading planning GUI with built in UML modelling tools. These strategies are evaluated using process and product metrics, where the domain model (the product) was tested extensively with a range of planning engines. The results give insights into the strengths and weaknesses of the approaches, highlight lessons learned regarding knowledge encoding, and point to important lines of research for knowledge engineering for planning.

#index 2033166
#* The GoDeL planning system: a more perfect union of domain-independent and hierarchical planning
#@ Vikas Shivashankar;Ron Alford;Ugur Kuter;Dana Nau
#t 2013
#c 11
#% 154075
#% 266385
#% 1223551
#% 1271962
#% 1272016
#% 1272047
#% 1305551
#% 1545553
#% 1875804
#! One drawback of Hierarchical Task Network (HTN) planning is the difficulty of providing complete domain knowledge, i.e., a complete and correct set of HTN methods for every task. To provide a principled way to overcome this difficulty, we define a simple formalism that extends classical planning to include problem decomposition using methods, and a planning algorithm based on this formalism. In our formalism, the methods specify ways to achieve goals (rather than tasks as in conventional HTN planning), and goals may be achieved even when no methods are available. Our planning algorithm, GoDeL (Goal Decomposition with Landmarks), is sound and complete irrespective of whether the domain knowledge (i.e., the set of methods given to the planner) is complete. By comparing GoDeL's performance with varying amounts of domain knowledge across three benchmark planning domains, we show experimentally that (1) GoDeL works correctly with partial planning knowledge, (2) GoDeL's performance improves as more planning knowledge is given, and (3) when given full domain knowledge, GoDeL matches the performance of a state-of-the-art hierarchical planner.

#index 2033167
#* Plan quality optimisation via block decomposition
#@ Fazlul Hasan Siddiqui;Patrik Haslum
#t 2013
#c 11
#% 21145
#% 534327
#% 743353
#% 951175
#% 1272333
#% 1272382
#% 1545553
#% 1950691
#! AI planners have to compromise between the speed of the planning process and the quality of the generated plan. Anytime planners try to balance these objectives by finding plans of better quality over time, but current anytime planners often do not make effective use of increasing runtime beyond a certain limit. We present a new method of continuing plan improvement, that works by repeatedly decomposing a given plan into subplans and optimising each subplan locally. The decomposition exploits block-structured plan deordering to identify coherent subplans, which make sense to treat as units. This approach extends the "anytime capability" of current planners - to provide continuing plan quality improvement at any time scale.

#index 2033168
#* Symbolic merge-and-shrink for cost-optimal planning
#@ Álvaro Torralba;Carlos Linares López;Daniel Borrajo
#t 2013
#c 11
#% 3873
#% 160388
#% 189701
#% 430722
#% 1096215
#% 1223544
#% 1269831
#% 1272113
#% 1398234
#% 1398243
#% 1741981
#% 1826379
#! Symbolic PDBs and Merge-and-Shrink (M&S) are two approaches to derive admissible heuristics for optimal planning. We present a combination of these techniques, Symbolic Merge-and-Shrink (SM&S), which uses M&S abstractions as a relaxation criterion for a symbolic backward search. Empirical evaluation shows that SM&S has the strengths of both techniques deriving heuristics at least as good as the best of them for most domains.

#index 2033169
#* Problem splitting using heuristic search in landmark orderings
#@ Simon Vernhes;Guillaume Infantes;Vincent Vidal
#t 2013
#c 11
#% 337980
#% 743353
#% 875422
#% 1270243
#% 1271962
#% 1272047
#% 1473265
#! In this paper, we revisit the idea of splitting a planning problem into subproblems hopefully easier to solve with the help of landmark analysis. While this technique initially proposed in the first approaches related to landmarks has been outperformed by landmark-based heuristics, we believe that it is still a promising research direction. To this end, we propose a new method for problem splitting based on landmarks which has two advantages over the original technique: it is complete (if a solution exists, the algorithm finds it), and it uses the precedence relation over the landmarks in a more flexible way. We lay in this paper the foundations of a meta best-first search algorithm, which explores the landmark orderings to create subproblems and can use any embedded planner to solve subproblems. It opens up avenues for future research: among them are new heuristics for guiding the meta search towards the most promising orderings, different policies for generating subproblems, and influence of the embedded subplanner.

#index 2033170
#* Run-time improvement of point-based POMDP policies
#@ Minlue Wang;Richard Dearden
#t 2013
#c 11
#% 179940
#% 788098
#% 1272075
#% 1272129
#% 1272231
#% 1275170
#! The most successful recent approaches to partially observable Markov decision problem (POMDP) solving have largely been point-based approximation algorithms. These work by selecting a finite number of belief points, computing alpha-vectors for those points, and using the resulting policy everywhere. However, if during execution the belief state is far from the points, there is no guarantee that the policy will be good. This case occurs either when the points are chosen poorly or there are too few points to capture the whole optimal policy, for example in domains where there are many low probability transitions, such as faults or exogenous events. In this paper we explore the use of an on-line plan repair approach to overcome this difficulty. The idea is to split computation between off-line plan creation and, if necessary, on-line plan repair. We evaluate a variety of heuristics used to determine when plan repair might be useful, and then repair the plan by sampling a small number of additional belief points and recomputing the policy. We show in several domains that the approach is more effective than either off-line planning alone even with much more computation time, or a purely on-line planning based on forward search. We also show that the overhead of checking the heuristics is very small when replanning is unnecessary.

#index 2033171
#* Interactive value iteration for Markov decision processes with unknown rewards
#@ Paul Weng;Bruno Zanuttini
#t 2013
#c 11
#% 363744
#% 466418
#% 757953
#% 1211699
#% 1417103
#% 1650672
#% 1672988
#% 1778828
#% 1826406
#% 1826407
#! To tackle the potentially hard task of defining the reward function in a Markov Decision Process, we propose a new approach, based on Value Iteration, which interweaves the elicitation and optimization phases. We assume that rewards whose numeric values are unknown can only be ordered, and that a tutor is present to help comparing sequences of rewards. We first show how the set of possible reward functions for a given preference relation can be represented as a polytope. Then our algorithm, called Interactive Value Iteration, searches for an optimal policy while refining its knowledge about the possible reward functions, by querying a tutor when necessary. We prove that the number of queries needed before finding an optimal policy is upperbounded by a polynomial in the size of the problem, and we present experimental results which demonstrate that our approach is efficient in practice.

#index 2033172
#* Flexibility and decoupling in the simple temporal problem
#@ Michel Wilson;Tomas Klos;Cees Witteveen;Bob Huisman
#t 2013
#c 11
#% 107137
#% 327432
#% 578726
#% 644201
#% 1053972
#% 1289215
#% 1453147
#% 1485499
#% 1614160
#% 2017291
#! In this paper we concentrate on finding a suitable metric to determine the flexibility of a Simple Temporal Problem (STP). After reviewing some flexibility metrics that have been proposed, we conclude that these metrics fail to capture the correlation between events specified in the STP, resulting in an overestimation of the available flexibility in the system. We propose to use an intuitively more acceptable flexibility metric based upon uncorrelated time-intervals for the allowed starting times of events in an STP. This metric is shown to be computable in low-polynomial time. As a byproduct of the flexibility computation, we get a decomposition of the STN almost for free: for every possible k-partitioning of the event space, a decomposition can be computed in O(k)-time. Even more importantly, we show that contrary to popular belief, such a decomposition does not affect the flexibility of the original STP.

#index 2033173
#* Continuously relaxing over-constrained conditional temporal problems through generalized conflict learning and resolution
#@ Peng Yu;Brian Williams
#t 2013
#c 11
#% 107137
#% 126386
#% 486940
#% 535154
#% 722504
#% 979225
#% 1289192
#% 1289383
#! Over-constrained temporal problems are commonly encountered while operating autonomous and decision support systems. An intelligent system must learn a human's preference over a problem in order to generate preferred resolutions that minimize perturbation. We present the Best-first Conflict-Directed Relaxation (BCDR) algorithm for enumerating the best continuous relaxation for an over-constrained conditional temporal problem with controllable choices. BCDR reformulates such a problem by making its temporal constraints relaxable and solves the problem using a conflict-directed approach. It extends the Conflict-Directed A* (CD-A*) algorithm to conditional temporal problems, by first generalizing the conflict learning process to include all discrete variable assignments and continuous temporal constraints, and then by guiding the forward search away from known infeasible regions using conflict resolution. When evaluated empirically on a range of coordinated car sharing network problems, BCDR demonstrates a substantial improvement in performance and solution quality compared to previous conflict-directed approaches.

#index 2033174
#* Robust optimization for hybrid MDPs with state-dependent noise
#@ Zahra Zamani;Scott Sanner;Karina Valdivia Delgado;Leliane Nunes De Barros
#t 2013
#c 11
#% 233849
#% 363744
#% 518593
#% 788054
#% 1269546
#% 1270307
#% 1272125
#% 1272257
#% 1275161
#% 1289241
#% 1478361
#% 1789993
#% 1790104
#% 1868860
#! Recent advances in solutions to Hybrid MDPs with discrete and continuous state and action spaces have significantly extended the class of MDPs for which exact solutions can be derived, albeit at the expense of a restricted transition noise model. In this paper, we work around limitations of previous solutions by adopting a robust optimization approach in which Nature is allowed to adversarially determine transition noise within pre-specified confidence intervals. This allows one to derive an optimal policy with an arbitrary (user-specified) level of success probability and significantly extends the class of transition noise models for which Hybrid MDPs can be solved. This work also significantly extends results for the related "chance-constrained" approach in stochastic hybrid control to accommodate state-dependent noise. We demonstrate our approach working on a variety of hybrid MDPs taken from AI planning, operations research, and control theory, noting that this is the first time robust solutions with strong guarantees over all states have been automatically derived for such problems.

#index 2033175
#* Action-model acquisition from noisy plan traces
#@ Hankz Hankui Zhuo;Subbarao Kambhampati
#t 2013
#c 11
#% 226495
#% 464434
#% 778643
#% 944137
#% 1269503
#% 1269832
#% 1272161
#% 1272189
#% 1279398
#% 1289577
#% 1347859
#% 1483050
#% 1913257
#! There is increasing awareness in the planning community that the burden of specifying complete domain models is too high, which impedes the applicability of planning technology in many real-world domains. Although there have been many learning approaches that help automatically creating domain models, they all assume plan traces (training data) are correct. In this paper, we aim to remove this assumption, allowing plan traces to be with noise. Compared to collecting large amount of correct plan traces, it is much easier to collect noisy plan traces, e.g., we can directly exploit sensors to help collect noisy plan traces. We consider a novel solution for this challenge that can learn action models from noisy plan traces. We create a set of random variables to capture the possible correct plan traces behind the observed noisy ones, and build a graphical model to describe the physics of the domain. We then learn the parameters of the graphical model and acquire the domain model based on the learnt parameters. In the experiment, we empirically show that our approach is effective in several planning domains.

#index 2033176
#* Refining incomplete planning domain models through plan traces
#@ Hankz Hankui Zhuo;Tuan Nguyen;Subbarao Kambhampati
#t 2013
#c 11
#% 1474
#% 55921
#% 329537
#% 449567
#% 578725
#% 778643
#% 778732
#% 944137
#% 1269503
#% 1269832
#% 1269925
#% 1272084
#% 1272141
#% 1272189
#% 1347859
#% 1483050
#! Most existing work on learning planning models assumes that the entire model needs to be learned from scratch. A more realistic situation is that the planning agent has an incomplete model which it needs to refine through learning. In this paper we propose and evaluate a method for doing this. Our method takes as input an incomplete model (with missing preconditions and effects in the actions), as well as a set of plan traces that are known to be correct. It outputs a "refined" model that not only captures additional precondition/effect knowledge about the given actions, but also "macro actions". We use a MAX-SAT framework for learning, where the constraints are derived from the executability of the given plan traces, as well as the preconditions/ effects of the given incomplete model. Unlike traditional macro-action learners which use macros to increase the efficiency of planning (in the context of a complete model), our motivation for learning macros is to increase the accuracy (robustness) of the plans generated with the refined model. We demonstrate the effectiveness of our approach through a systematic empirical evaluation.

#index 2033177
#* Handling open knowledge for service robots
#@ Xiaoping Chen;Jianmin Ji;Zhiqiang Sui;Jiongkun Xie
#t 2013
#c 11
#% 179879
#% 224478
#% 290714
#% 342119
#% 763743
#% 854636
#% 1215046
#% 1250214
#% 1260489
#% 1453162
#% 1453171
#% 1478800
#% 1480471
#% 1490384
#% 1722059
#% 1826350
#% 1920986
#% 1967359
#! Users may ask a service robot to accomplish various tasks so that the designer of the robot cannot program each of the tasks beforehand. As more and more open-source knowledge resources become available, it is worthwhile trying to make use of open-source knowledge resources for service robots. The challenge lies in the autonomous identification, acquisition and utilization of missing knowledge about a user task at hand. In this paper, the core problem is formalized and the complexity results of the main reasoning issues are provided. A mechanism for task planning with open-knowledge rules which are provided by non-experts in semi-structured natural language and thus generally underspecified are introduced. Techniques for translating the semi-structured knowledge from a large open-source knowledge base are also presented. Experiments showed a remarkable improvement of the system performance on a test set consisting of hundreds of user desires from the open-source knowledge base.

#index 2033178
#* Human action recognition using a temporal hierarchy of covariance descriptors on 3D joint locations
#@ Mohamed E. Hussein;Marwan Torki;Mohammad A. Gowayyed;Motaz El-Saban
#t 2013
#c 11
#% 329443
#% 724174
#% 883972
#% 1117719
#% 1378773
#% 1558464
#% 1730641
#% 1750536
#% 1765688
#% 1884262
#% 1923439
#% 1953669
#% 1984205
#! Human action recognition from videos is a challenging machine vision task with multiple important application domains, such as human-robot/machine interaction, interactive entertainment, multimedia information retrieval, and surveillance. In this paper, we present a novel approach to human action recognition from 3D skeleton sequences extracted from depth data. We use the covariance matrix for skeleton joint locations over time as a discriminative descriptor for a sequence. To encode the relationship between joint movement and time, we deploy multiple covariance matrices over sub-sequences in a hierarchical fashion. The descriptor has a fixed length that is independent from the length of the described sequence. Our experiments show that using the covariance descriptor with an off-the-shelf classification algorithm outperforms the state of the art in action recognition on multiple datasets, captured either via a Kinect-type sensor or a sophisticated motion capture system. We also include an evaluation on a novel large dataset using our own annotation.

#index 2033179
#* Rolling dispersion for robot teams
#@ Elizabeth A. Jensen;Maria Gini
#t 2013
#c 11
#% 334657
#% 417745
#% 418713
#% 807269
#% 956105
#% 982722
#% 1271908
#% 1279373
#% 1768677
#% 1768953
#% 1769090
#% 1910572
#! Dispersing a team of robots into an unknown and dangerous environment, such as a collapsed building, can provide information about structural damage and locations of survivors and help rescuers plan their actions. We propose a rolling dispersion algorithm, which makes use of a small number of robots and achieves full exploration. The robots disperse as much as possible while maintaining communication, and then advance as a group, leaving behind beacons to mark explored areas and provide a path back to the entrance. The novelty of this algorithm comes from the manner in which the robots continue their exploration as a group after reaching the maximum dispersion possible while staying in contact with each other. We use simulation to show that the algorithm works in multiple environments and for varying numbers of robots.

#index 2033180
#* Accelerated robust point cloud registration in natural environments through positive and unlabeled learning
#@ Maxime Latulippe;Alexandre Drouin;Philippe Giguère;François Laviolette
#t 2013
#c 11
#% 117665
#% 209021
#% 319464
#% 400847
#% 635748
#% 760805
#% 855602
#% 997125
#% 1038377
#% 1077613
#% 1083647
#% 1202160
#% 1342482
#% 1383201
#% 1520213
#% 1528830
#% 1653970
#% 1938986
#! Localization of a mobile robot is crucial for autonomous navigation. Using laser scanners, this can be facilitated by the pairwise alignment of consecutive scans. In this paper, we are interested in improving this scan alignment in challenging natural environments. For this purpose, local descriptors are generally effective as they facilitate point matching. However, we show that in some natural environments, many of them are likely to be unreliable, which affects the accuracy and robustness of the results. Therefore, we propose to filter the unreliable descriptors as a prior step to alignment. Our approach uses a fast machine learning algorithm, trained on-the-fly under the positive and unlabeled learning paradigm without the need for human intervention. Our results show that the number of descriptors can be significantly reduced, while increasing the proportion of reliable ones, thus speeding up and improving the robustness of the scan alignment process.

#index 2033181
#* Upper confidence weighted learning for efficient exploration in multiclass prediction with binary feedback
#@ Hung Ngo;Matthew Luciw;Ngo Anh Vien;Jurgen Schmidhuber
#t 2013
#c 11
#% 425021
#% 722906
#% 801566
#% 871302
#% 961152
#% 1073927
#% 1338580
#% 1467774
#% 1766043
#! We introduce a novel algorithm called Upper Confidence Weighted Learning (UCWL) for online multiclass learning from binary feedback. UCWL combines the Upper Confidence Bound (UCB) framework with the Soft Confidence Weighted (SCW) online learning scheme. UCWL achieves state of the art performance (especially on noisy and nonseparable data) with low computational costs. Estimated confidence intervals are used for informed exploration, which enables faster learning than the uninformed exploration case or the case where exploration is not used. The targeted application setting is human-robot interaction (HRI), in which a robot is learning to classify its observations while a human teaches it by providing only binary feedback (e.g., right/wrong). Results in an HRI experiment, and with two benchmark datasets, show UCWL outperforms other algorithms in the online binary feedback setting, and surprisingly even sometimes beats state-of-the-art algorithms that get full feedback, while UCWL gets only binary feedback on the same data.

#index 2033182
#* Towards active event recognition
#@ Dimitri Ognibene;Yiannis Demiris
#t 2013
#c 11
#% 101437
#% 205385
#% 344587
#% 390497
#% 838789
#% 884120
#% 977319
#% 1042870
#% 1062441
#% 1275094
#% 1291502
#% 1295107
#% 1427872
#% 1826383
#% 1826399
#% 1950114
#! Directing robot attention to recognise activities and to anticipate events like goal-directed actions is a crucial skill for human-robot interaction. Unfortunately, issues like intrinsic time constraints, the spatially distributed nature of the entailed information sources, and the existence of a multitude of unobservable states affecting the system, like latent intentions, have long rendered achievement of such skills a rather elusive goal. The problem tests the limits of current attention control systems. It requires an integrated solution for tracking, exploration and recognition, which traditionally have been seen as separate problems in active vision. We propose a probabilistic generative framework based on information gain maximisation and a mixture of Kalman Filters that uses predictions in both recognition and attention-control. This framework can efficiently use the observations of one element in a dynamic environment to provide information on other elements, and consequently enables guided exploration. Interestingly, the sensors control policy, directly derived from first principles, represents the intuitive trade-off between finding the most discriminative clues and maintaining overall awareness. Experiments on a simulated humanoid robot observing a human executing goal-oriented actions demonstrated improvement on recognition time and precision over baseline systems.

#index 2033183
#* Hierarchical object discovery and dense modelling from motion cues in RGB-D video
#@ Jörg Stückler;Sven Behnke
#t 2013
#c 11
#% 344568
#% 792704
#% 799050
#% 836673
#% 865328
#% 866415
#% 931245
#% 975110
#% 992989
#% 1342402
#% 1368386
#% 1378798
#% 1378799
#% 1631461
#% 1650347
#% 1694054
#% 1780378
#% 1884208
#% 1885496
#% 1923557
#% 1953661
#% 1980300
#! In this paper, we propose a novel method for object discovery and dense modelling in RGB-D image sequences using motion cues. We develop our method as a building block for active object perception, such that robots can learn about the environment through perceiving the effects of actions. Our approach simultaneously segments rigid-body motion within key views, and discovers objects and hierarchical relations between object parts. The poses of the key views are optimized in a graph of spatial relations to recover the rigid-body motion trajectories of the camera with respect to the objects. In experiments, we demonstrate that our approach finds moving objects, aligns partial views on the objects, and retrieves hierarchical relations between the objects.

#index 2033184
#* Learning visual symbols for parsing human poses in images
#@ Fang Wang;Yi Li
#t 2013
#c 11
#% 778277
#% 812418
#% 835105
#% 1495394
#% 1495506
#% 1750560
#% 1750678
#% 1884041
#% 1885656
#% 1923383
#% 1923522
#! Parsing human poses in images is fundamental in extracting critical visual information for artificial intelligent agents. Our goal is to learn self-contained body part representations from images, which we call visual symbols, and their symbolwise geometric contexts in this parsing process. Each symbol is individually learned by categorizing visual features leveraged by geometric information. In the categorization, we use Latent Support Vector Machine followed by an efficient cross validation procedure. Then, these symbols naturally define geometric contexts of body parts in a fine granularity. When the structure of the compositional parts is a tree, we derive an efficient approach to estimating human poses in images. Experiments on two large datasets suggest our approach outperforms state of the art methods.

#index 2033185
#* A consensual linear opinion pool
#@ Arthur Carvalho;Kate Larson
#t 2013
#c 11
#% 431455
#% 444686
#% 836122
#% 1071502
#% 1096055
#% 1453253
#% 1615236
#% 1875770
#% 1875775
#% 1895241
#! An important question when eliciting opinions from experts is how to aggregate the reported opinions. In this paper, we propose a pooling method to aggregate expert opinions. Intuitively, it works as if the experts were continuously updating their opinions in order to accommodate the expertise of others. Each updated opinion takes the form of a linear opinion pool, where the weight that an expert assigns to a peer's opinion is inversely related to the distance between their opinions. In other words, experts are assumed to prefer opinions that are close to their own opinions. We prove that such an updating process leads to consensus, i.e., the experts all converge towards the same opinion. Further, we show that if rational experts are rewarded using the quadratic scoring rule, then the assumption that they prefer opinions that are close to their own opinions follows naturally. We empirically demonstrate the efficacy of the proposed method using real-world data.

#index 2033186
#* An exact algorithm for computing the same-decision probability
#@ Suming Chen;Arthur Choi;Adnan Darwiche
#t 2013
#c 11
#% 183497
#% 246832
#% 443640
#% 558867
#% 1093466
#% 1196918
#% 1272025
#% 1288657
#% 1610406
#% 1631449
#% 1650712
#% 1672990
#% 1918960
#! When using graphical models for decision making, the presence of unobserved variables may hinder our ability to reach the correct decision. A fundamental question here is whether or not one is ready to make a decision (stopping criteria), and if not, what additional observations should be made in order to better prepare for a decision (selection criteria). A recently introduced notion, the Same-Decision Probability (SDP), has been shown to be useful as both a stopping and a selection criteria. This query has been shown to be highly intractable, being PPPP-complete, and is exemplary of a class of queries which correspond to the computation of certain expectations. We propose the first exact algorithm for computing the SDP in this paper, and demonstrate its effectiveness on several real and synthetic networks. We also present a new complexity result for computing the SDP on models with a Naive Bayes structure.

#index 2033187
#* Probabilistic reasoning with undefined properties in ontologically-based belief networks
#@ Chia-Li Kuo;David Buchman;Arzoo Katiyar;David Poole
#t 2013
#c 11
#% 44876
#% 329486
#% 1000502
#% 1136066
#% 1154612
#% 1177701
#% 1196918
#% 1271984
#% 1273913
#% 1416197
#% 1417383
#% 1650767
#% 1650778
#! This paper concerns building probabilistic models with an underlying ontology that defines the classes and properties used in the model. In particular, it considers the problem of reasoning with properties that may not always be defined. Furthermore, we may even be uncertain about whether a property is defined for a given individual. One approach is to explicitly add a value "undefined" to the range of random variables, forming extended belief networks; however, adding an extra value to a random variable's range has a large computational overhead. In this paper, we propose an alternative, ontologically-based belief networks, where all properties are only used when they are defined, and we show how probabilistic reasoning can be carried out without explicitly using the value "undefined" during inference. We prove this is equivalent to reasoning with the corresponding extended belief network and empirically demonstrate that inference becomes more efficient.

#index 2033188
#* Inference for a new probabilistic constraint logic
#@ Steffen Michels;Arjen Hommersom;Peter J. F. Lucas;Marina Velikova;Pieter Koopman
#t 2013
#c 11
#% 35562
#% 44876
#% 56471
#% 90371
#% 115193
#% 246835
#% 529186
#% 992781
#% 1000502
#% 1271907
#% 1275150
#% 1279089
#% 1416205
#% 1607843
#% 1673040
#! Probabilistic logics combine the expressive power of logic with the ability to reason with uncertainty. Several probabilistic logic languages have been proposed in the past, each of them with their own features. In this paper, we propose a new probabilistic constraint logic programming language, which combines constraint logic programming with probabilistic reasoning. The language supports modeling of discrete as well as continuous probability distributions by expressing constraints on random variables. We introduce the declarative semantics of this language, present an exact inference algorithm to derive bounds on the joint probability distributions consistent with the specified constraints, and give experimental results. The results obtained are encouraging, indicating that inference in our language is feasible for solving challenging problems.

#index 2033189
#* Map matching with inverse reinforcement learning
#@ Takayuki Osogami;Rudy Raymond
#t 2013
#c 11
#% 824722
#% 1270316
#% 1273895
#% 1298894
#% 1480783
#% 1605948
#% 1667223
#% 1826307
#% 1826508
#% 1940991
#% 1940994
#% 1941023
#% 1941052
#% 1941061
#% 1941077
#% 1941078
#! We study map-matching, the problem of estimating the route that is traveled by a vehicle, where the points observed with the Global Positioning System are available. A state-of-the-art approach for this problem is a Hidden Markov Model (HMM). We propose a particular transition probability between latent road segments by the use of the number of turns in addition to the travel distance between the latent road segments. We use inverse reinforcement learning to estimate the importance of the number of turns relative to the travel distance. This estimated importance is incorporated in the transition probability of the HMM. We show, through numerical experiments, that the error of map-matching can be reduced substantially with the proposed transition probability.

#index 2033190
#* Accurate integration of crowdsourced labels using workers' self-reported confidence scores
#@ Satoshi Oyama;Yukino Baba;Yuko Sakurai;Hisashi Kashima
#t 2013
#c 11
#% 1047347
#% 1083692
#% 1214647
#% 1264744
#% 1472273
#% 1495409
#% 1587350
#! We have developed a method for using confidence scores to integrate labels provided by crowdsourcing workers. Although confidence scores can be useful information for estimating the quality of the provided labels, a way to effectively incorporate them into the integration process has not been established. Moreover, some workers are overconfident about the quality of their labels while others are underconfident, and some workers are quite accurate in judging the quality of their labels. This differing reliability of the confidence scores among workers means that the probability distributions for the reported confidence scores differ among workers. To address this problem, we extended the Dawid-Skene model and created two probabilistic models in which the values of unobserved true labels are inferred from the observed provided labels and reported confidence scores by using the expectation-maximization algorithm. Results of experiments using actual crowdsourced data for image labeling and binary question answering tasks showed that incorporating workers' confidence scores can improve the accuracy of integrated crowdsourced labels.

#index 2033191
#* Look versus leap: computing value of information with high-dimensional streaming evidence
#@ Stephanie Rosenthal;Dan Bohus;Ece Kamar;Eric Horvitz
#t 2013
#c 11
#% 329491
#% 443640
#% 731042
#% 783871
#% 1010743
#% 1093466
#% 1269936
#% 1290265
#% 1291411
#% 1305595
#% 1346395
#% 1476322
#% 1631449
#% 1650372
#% 1875704
#! A key decision facing autonomous systems with access to streams of sensory data is whether to act based on current evidence or to wait for additional information that might enhance the utility of taking an action. Computing the value of information is particularly difficult with streaming high-dimensional sensory evidence. We describe a belief projection approach to reasoning about information value in these settings, using models for inferring future beliefs over states given streaming evidence. These belief projection models can be learned from data or constructed via direct assessment of parameters and they fit naturally in modular, hierarchical state inference architectures. We describe principles of using belief projection and present results drawn from an implementation of the methodology within a conversational system.

#index 2033192
#* The inclusion-exclusion rule and its application to the junction tree algorithm
#@ David Smith;Vibhav Gogate
#t 2013
#c 11
#% 55926
#% 289947
#% 329486
#% 527844
#% 571102
#% 771607
#% 1099383
#% 1272251
#% 1272349
#% 1291412
#% 1377453
#% 1650318
#% 1815596
#% 1911311
#! In this paper, we consider the inclusion-exclusion rule - a known yet seldom used rule of probabilistic inference. Unlike the widely used sum rule which requires easy access to all joint probability values, the inclusion-exclusion rule requires easy access to several marginal probability values. We therefore develop a new representation of the joint distribution that is amenable to the inclusion-exclusion rule. We compare the relative strengths and weaknesses of the inclusion-exclusion rule with the sum rule and develop a hybrid rule called the inclusion-exclusion-sum (IES) rule, which combines their power. We apply the IES rule to junction trees, treating the latter as a target for knowledge compilation and show that in many cases it greatly reduces the time required to answer queries. Our experiments demonstrate the power of our approach. In particular, at query time, on several networks, our new scheme was an order of magnitude faster than the junction tree algorithm.

#index 2033193
#* Sample complexity of risk-averse bandit-arm selection
#@ Jia Yuan Yu;Evdokia Nikolova
#t 2013
#c 11
#% 453329
#% 563266
#% 763718
#% 938018
#% 997711
#% 1183868
#% 1191038
#% 1557616
#% 1826926
#! We consider stochastic multiarmed bandit problems where each arm generates i.i.d. rewards according to an unknown distribution. Whereas classical bandit solutions only maximize the expected reward, we consider the problem of minimizing risk using notions such as the value-at-risk, the average value-at-risk, and the mean-variance risk. We present algorithms to minimize the risk over a single and multiple time periods, along with PAC accuracy guarantees given a finite number of reward samples. In the single-period case, we show that finding the arm with least risk requires not many more samples than the arm with highest expected reward. Although minimizing the multiperiod value-at-risk is known to be hard, we present an algorithm with comparable sample complexity under additional assumptions.

#index 2033194
#* A generalization of SAT and #SAT for robust policy evaluation
#@ Erik Zawadzki;André Platzer;Geoffrey J. Gordon
#t 2013
#c 11
#% 112014
#% 121397
#% 205391
#% 266200
#% 274131
#% 327779
#% 336874
#% 342378
#% 420743
#% 655324
#% 938017
#% 1269424
#% 1269577
#% 1273776
#% 1275122
#% 1650647
#% 1698709
#% 1698716
#% 1728050
#% 1881885
#% 1883608
#! Both SAT and #SAT can represent difficult problems in seemingly dissimilar areas such as planning, verification, and probabilistic inference. Here, we examine an expressive new language, #∃SAT, that generalizes both of these languages. #∃SAT problems require counting the number of satisfiable formulas in a concisely-describable set of existentially-quantified, propositional formulas. We characterize the expressiveness and worst-case difficulty of #∃SAT by proving it is complete for the complexity class #PNP[1], and relating this class to more familiar complexity classes. We also experiment with three new general-purpose #∃SAT solvers on a battery of problem distributions including a simple logistics domain. Our experiments show that, despite the formidable worst-case complexity of #PNP[1], many of the instances can be solved efficiently by noticing and exploiting a particular type of frequent structure.

#index 2033195
#* Link label prediction in signed social networks
#@ Priyanka Agrawal;Vikas K. Garg;Ramasuri Narayanam
#t 2013
#c 11
#% 722805
#% 730089
#% 1073906
#% 1190129
#% 1269889
#% 1384246
#% 1399997
#% 1441070
#% 1536533
#% 1565432
#% 1598352
#% 1617325
#% 1642048
#% 1705537
#% 1879048
#! Online social networks continue to witness a tremendous growth both in terms of the number of registered users and their mutual interactions. In this paper, we focus on online signed social networks where positive interactions among the users signify friendship or approval, whereas negative interactions indicate antagonism or disapproval. We introduce a novel problem which we call the link label prediction problem: Given the information about signs of certain links in a social network, we want to learn the nature of relationships that exist among the users by predicting the sign, positive or negative, of the remaining links. We propose a matrix factorization based technique MF-LiSP that exhibits strong generalization guarantees. We also investigate the applicability of logistic regression [8] in this setting. Our experiments on Wiki-Vote, Epinions and Slashdot data sets strongly corroborate the efficacy of these approaches.

#index 2033196
#* Multi-view K-means clustering on big data
#@ Xiao Cai;Feiping Nie;Heng Huang
#t 2013
#c 11
#% 424085
#% 443991
#% 760805
#% 786615
#% 812418
#% 836767
#% 951455
#% 990309
#% 1058303
#% 1214712
#% 1254273
#% 1264031
#% 1558464
#% 1699620
#% 1750500
#% 1884409
#! In past decade, more and more data are collected from multiple sources or represented by multiple views, where different views describe distinct perspectives of the data. Although each view could be individually used for finding patterns by clustering, the clustering performance could be more accurate by exploring the rich information among multiple views. Several multi-view clustering methods have been proposed to unsupervised integrate different views of data. However, they are graph based approaches, e.g. based on spectral clustering, such that they cannot handle the large-scale data. How to combine these heterogeneous features for unsupervised large-scale data clustering has become a challenging problem. In this paper, we propose a new robust large-scale multi-view clustering method to integrate heterogeneous representations of largescale data. We evaluate the proposed new methods by six benchmark data sets and compared the performance with several commonly used clustering approaches as well as the baseline multi-view clustering methods. In all experimental results, our proposed methods consistently achieve superiors clustering performances.

#index 2033197
#* Where you like to go next: successive point-of-interest recommendation
#@ Chen Cheng;Haiqin Yang;Michael R. Lyu;Irwin King
#t 2013
#c 11
#% 1190134
#% 1214666
#% 1400014
#% 1400036
#% 1417104
#% 1480830
#% 1496686
#% 1523885
#% 1524237
#% 1598364
#% 1598366
#% 1606049
#% 1642006
#% 1693933
#% 1693962
#% 1872249
#% 1919779
#% 1941025
#! Personalized point-of-interest (POI) recommendation is a significant task in location-based social networks (LBSNs) as it can help provide better user experience as well as enable third-party services, e.g., launching advertisements. To provide a good recommendation, various research has been conducted in the literature. However, pervious efforts mainly consider the "check-ins" in a whole and omit their temporal relation. They can only recommend POI globally and cannot know where a user would like to go tomorrow or in the next few days. In this paper, we consider the task of successive personalized POI recommendation in LBSNs, which is a much harder task than standard personalized POI recommendation or prediction. To solve this task, we observe two prominent properties in the check-in sequence: personalized Markov chain and region localization. Hence, we propose a novel matrix factorization method, namely FPMC-LR, to embed the personalized Markov chains and the localized regions. Our proposed FPMC-LR not only exploits the personalized Markov chain in the check-in sequence, but also takes into account users' movement constraint, i.e., moving around a localized region. More importantly, utilizing the information of localized regions, we not only reduce the computation cost largely, but also discard the noisy information to boost recommendation. Results on two real-world LBSNs datasets demonstrate the merits of our proposed FPMC-LR.

#index 2033198
#* Celebrity recommendation with collaborative social topic regression
#@ Xuetao Ding;Xiaoming Jin;Yujia Li;Lianghao Li
#t 2013
#c 11
#% 280819
#% 722904
#% 1073982
#% 1077150
#% 1130901
#% 1176909
#% 1214623
#% 1260273
#% 1355025
#% 1358747
#% 1399992
#% 1535439
#% 1535449
#% 1536533
#% 1560408
#% 1605963
#% 1872386
#! Recently how to recommend celebrities to the public becomes an interesting problem on the social network websites, such as Twitter and Tencent Weibo. In this paper, we proposed a unified hierarchical Bayesian model to recommend celebrities to the general users. Specifically, we proposed to leverage both social network and descriptions of celebrities to improve the prediction ability and recommendation interpretability. In our model, we combine topic model with matrix factorization for both social network of celebrities and user following action matrix. It works by regularizing celebrity factors through celebrity's social network and descriptive words associated with each celebrity. We also proposed to incorporate different confidences for different dyadic contexts to handle the situation that only positive observations exist. We conducted experiments on two real-world datasets from Twitter and Tencent Weibo, which are the largest and second largest microblog websites in USA and China, respectively. The experiment results show that our model achieves a higher performance and provide more effective results than the state-of-art methods especially when recommending new celebrities. We also show that our model captures user intertests more precisely and gives better recommendation interpretability.

#index 2033199
#* A novel Bayesian similarity measure for recommender systems
#@ Guibing Guo;Jie Zhang;Neil Yorke-Smith
#t 2013
#c 11
#% 202011
#% 987197
#% 1000869
#% 1001277
#% 1052903
#% 1287235
#% 1313373
#% 1536533
#% 1650569
#% 1714297
#% 1716394
#% 1826427
#% 1888033
#! Collaborative filtering, a widely-used user-centric recommendation technique, predicts an item's rating by aggregating its ratings from similar users. User similarity is usually calculated by cosine similarity or Pearson correlation coefficient. However, both of them consider only the direction of rating vectors, and suffer from a range of drawbacks. To solve these issues, we propose a novel Bayesian similarity measure based on the Dirichlet distribution, taking into consideration both the direction and length of rating vectors. Further, our principled method reduces correlation due to chance. Experimental results on six real-world data sets show that our method achieves superior accuracy.

#index 2033200
#* Cross-domain collaborative filtering via bilinear multilevel analysis
#@ Liang Hu;Jian Cao;Guandong Xu;Jie Wang;Zhiping Gu;Longbing Cao
#t 2013
#c 11
#% 949164
#% 1073982
#% 1083671
#% 1083696
#% 1098241
#% 1130901
#% 1211767
#% 1260273
#% 1277910
#% 1305617
#% 1358747
#% 1659471
#! Cross-domain collaborative filtering (CDCF), which aims to leverage data from multiple domains to relieve the data sparsity issue, is becoming an emerging research topic in recent years. However, current CDCF methods that mainly consider user and item factors but largely neglect the heterogeneity of domains may lead to improper knowledge transfer issues. To address this problem, we propose a novel CDCF model, the Bilinear Multilevel Analysis (BLMA), which seamlessly introduces multilevel analysis theory to the most successful collaborative filtering method, matrix factorization (MF). Specifically, we employ BLMA to more efficiently address the determinants of ratings from a hierarchical view by jointly considering domain, community, and user effects so as to overcome the issues caused by traditional MF approaches. Moreover, a parallel Gibbs sampler is provided to learn these effects. Finally, experiments conducted on a realworld dataset demonstrate the superiority of the BLMA over other state-of-the-art methods.

#index 2033201
#* Social spammer detection in microblogging
#@ Xia Hu;Jiliang Tang;Yanchao Zhang;Huan Liu
#t 2013
#c 11
#% 757953
#% 803668
#% 818234
#% 840965
#% 1132890
#% 1190110
#% 1211747
#% 1292559
#% 1355042
#% 1417091
#% 1450883
#% 1477791
#% 1560252
#% 1642051
#% 1646501
#% 1646502
#% 1746804
#! The availability of microblogging, like Twitter and Sina Weibo, makes it a popular platform for spammers to unfairly overpower normal users with unwanted content via social networks, known as social spamming. The rise of social spamming can significantly hinder the use of microblogging systems for effective information dissemination and sharing. Distinct features of microblogging systems present new challenges for social spammer detection. First, unlike traditional social networks, microblogging allows to establish some connections between two parties without mutual consent, which makes it easier for spammers to imitate normal users by quickly accumulating a large number of "human" friends. Second, microblogging messages are short, noisy, and unstructured. Traditional social spammer detection methods are not directly applicable to microblogging. In this paper, we investigate how to collectively use network and content information to perform effective social spammer detection in microblogging. In particular, we present an optimization formulation that models the social network and content information in a unified framework. Experiments on a real-world Twitter dataset demonstrate that our proposed method can effectively utilize both kinds of information for social spammer detection.

#index 2033202
#* Listening to the crowd: automated analysis of events via aggregated twitter sentiment
#@ Yuheng Hu;Fei Wang;Subbarao Kambhampati
#t 2013
#c 11
#% 280819
#% 722904
#% 769892
#% 854646
#% 881468
#% 938687
#% 956510
#% 1268503
#% 1279645
#% 1328330
#% 1384210
#% 1384224
#% 1591966
#% 1606084
#% 1948178
#! Individuals often express their opinions on social media platforms like Twitter and Facebook during public events such as the U.S. Presidential debate and the Oscar awards ceremony. Gleaning insights from these posts is of importance to analyzing the impact of the event. In this work, we consider the problem of identifying the segments and topics of an event that garnered praise or criticism, according to aggregated Twitter responses. We propose a flexible factorization framework, SOCSENT, to learn factors about segments, topics, and sentiments. To regulate the learning process, several constraints based on prior knowledge on sentiment lexicon, sentiment orientations (on a few tweets) as well as tweets alignments to the event are enforced. We implement our approach using simple update rules to get the optimal solution. We evaluate the proposed method both quantitatively and qualitatively on two large-scale tweet datasets associated with two events from different domains to show that it improves significantly over baseline models.

#index 2033203
#* Social trust prediction using rank-k matrix recovery
#@ Jin Huang;Feiping Nie;Heng Huang;Yu Lei;Chris Ding
#t 2013
#c 11
#% 406493
#% 465928
#% 577273
#% 730089
#% 1001279
#% 1211747
#% 1211772
#% 1275183
#% 1309918
#% 1399997
#% 1441070
#% 1451176
#% 1504249
#% 1561589
#% 1688445
#% 1885752
#% 1919815
#! Trust prediction, which explores the unobserved relationships between online community users, is an emerging and important research topic in social network analysis and many web applications. Similar to other social-based recommender systems, trust relationships between users can be also modeled in the form of matrices. Recent study shows users generally establish friendship due to a few latent factors, it is therefore reasonable to assume the trust matrices are of low-rank. As a result, many recommendation system strategies can be applied here. In particular, trace norm minimization, which uses matrix's trace norm to approximate its rank, is especially appealing. However, recent articles cast doubts on the validity of trace norm approximation. In this paper, instead of using trace norm minimization, we propose a new robust rank-k matrix completion method, which explicitly seeks a matrix with exact rank. Moreover, our method is robust to noise or corrupted observations. We optimize the new objective function in an alternative manner, based on a combination of ancillary variables and Augmented Lagrangian Multiplier (ALM) Method. We perform the experiments on three real-world data sets and all empirical results demonstrate the effectiveness of our method.

#index 2033204
#* Context-dependent conceptualization
#@ Dongwoo Kim;Haixun Wang;Alice Oh
#t 2013
#c 11
#% 330705
#% 452991
#% 577224
#% 722904
#% 747891
#% 1077150
#% 1152447
#% 1214715
#% 1260689
#% 1770359
#% 1826433
#% 1913335
#% 1943531
#! Conceptualization seeks to map a short text (i.e., a word or a phrase) to a set of concepts as a mechanism of understanding text. Most of prior research in conceptualization uses human-crafted knowledge bases that map instances to concepts. Such approaches to conceptualization have the limitation that the mappings are not context sensitive. To overcome this limitation, we propose a framework in which we harness the power of a probabilistic topic model which inherently captures the semantic relations between words. By combining latent Dirichlet allocation, a widely used topic model with Probase, a large-scale probabilistic knowledge base, we develop a corpus-based framework for context-dependent conceptualization. Through this simple but powerful framework, we improve conceptualization and enable a wide range of applications that rely on semantic understanding of short texts, including frame element prediction, word similarity in context, ad-query similarity, and query similarity.

#index 2033205
#* Predicting knowledge in an ontology stream
#@ Freddy Lécué;Jeff Z. Pan
#t 2013
#c 11
#% 152934
#% 329537
#% 333926
#% 481290
#% 578767
#% 665856
#% 729932
#% 748640
#% 818916
#% 824709
#% 867057
#% 1289174
#% 1289408
#% 1320449
#% 1362068
#% 1379023
#% 1409907
#% 1426598
#% 1540298
#% 1642009
#% 1655410
#% 1696308
#% 1696336
#% 1703713
#% 1719991
#% 1938496
#! Recently, ontology stream reasoning has been introduced as a multidisciplinary approach, merging synergies from Artificial Intelligence, Database, World-Wide-Web to reason on semantic augmented data streams. Although knowledge evolution and real-time reasoning have been largely addressed in ontology streams, the challenge of predicting its future (or missing) knowledge remains open and yet unexplored. We tackle predictive reasoning as a correlation and interpretation of past semantics-augmented data over exogenous ontology streams. Consistent predictions are constructed as Description Logics entailments by selecting and applying relevant cross-streams association rules. The experiments have shown accurate prediction with real and live stream data from Dublin City in Ireland.

#index 2033206
#* A unified framework for reputation estimation in online rating systems
#@ Guang Ling;Irwin King;Michael R. Lyu
#t 2013
#c 11
#% 329569
#% 330687
#% 754098
#% 781774
#% 783438
#% 881512
#% 936910
#% 1001283
#% 1073982
#% 1166755
#% 1214666
#% 1227602
#% 1378224
#% 1536533
#% 1555969
#% 1625358
#% 1650569
#% 1879008
#! Online rating systems are now ubiquitous due to the success of recommender systems. In such systems, users are allowed to rate the items (movies, songs, commodities) in a predefined range of values. The ratings collected can be used to infer users' preferences as well as items' intrinsic features, which are then matched to perform personalized recommendation. Most previous work focuses on improving the prediction accuracy or ranking capability. Little attention has been paid to the problem of spammers or low-reputed users in such systems. Spammers contaminate the rating system by assigning unreasonable scores to items, which may affect the accuracy of a recommender system. There are evidences supporting the existence of spammers in online rating systems. Reputation estimation methods can be employed to keep track of users' reputation and detect spammers in such systems. In this paper, we propose a unified framework for computing the reputation score of a user, given only users' ratings on items. We show that previously proposed reputation estimation methods can be captured as special cases of our framework. We propose a new low-rank matrix factorization based reputation estimation method and demonstrate its superior discrimination ability.

#index 2033207
#* Synthesizing union tables from the web
#@ Xiao Ling;Alon Halevy;Fei Wu;Cong Yu
#t 2013
#c 11
#% 235941
#% 617211
#% 772300
#% 816156
#% 854657
#% 1127393
#% 1130858
#% 1250364
#% 1328199
#% 1328200
#% 1523913
#% 1536526
#% 1592066
#% 1592311
#% 1770418
#% 1943531
#! Several recent works have focused on harvesting HTML tables from the Web and recovering their semantics [Cafarella et al., 2008a; Elmeleegy et al., 2009; Limaye et al., 2010; Venetis et al., 2011]. As a result, hundreds of millions of high quality structured data tables can now be explored by the users. In this paper, we argue that those efforts only scratch the surface of the true value of structured data on the Web, and study the challenging problem of synthesizing tables from the Web, i.e., producing never-before-seen tables from raw tables on the Web. Table synthesis offers an important semantic advantage: when a set of related tables are combined into a single union table, powerful mechanisms, such as temporal or geographical comparison and visualization, can be employed to understand and mine the underlying data holistically. We focus on one fundamental task of table synthesis, namely, table stitching. Within a given site, many tables with identical schemas can be scattered across many pages. The task of table stitching involves combining such tables into a single meaningful union table and identifying extra attributes and values for its rows so that rows from different original tables can be distinguished. Specifically, we first define the notion of stitchable tables and identify collections of tables that can be stitched. Second, we design an effective algorithm for extracting hidden attributes that are essential for the stitching process and for aligning values of those attributes across tables to synthesize new columns. We also assign meaningful names to these synthesized columns. Experiments on real world tables demonstrate the effectiveness of our approach.

#index 2033208
#* Recommendation using textual opinions
#@ Claudiu-Cristian Musat;Yizhong Liang;Boi Faltings
#t 2013
#c 11
#% 198058
#% 220709
#% 234992
#% 330687
#% 397155
#% 722904
#% 734591
#% 754126
#% 943811
#% 1297086
#% 1395501
#% 1537492
#% 1625401
#% 1643619
#% 1893823
#! Many web sites collect reviews of products and services and use them provide rankings of their quality. However, such rankings are not personalized. We investigate how the information in the reviews written by a particular user can be used to personalize the ranking she is shown. We propose a new technique, topic profile collaborative filtering, where we build user profiles from users' review texts and use these profiles to filter other review texts with the eyes of this user. We verify on data from an actual review site that review texts and topic profiles indeed correlate with ratings, and show that topic profile collaborative filtering provides both a better mean average error when predicting ratings and a better approximation of user preference orders.

#index 2033209
#* GBPR: group preference based Bayesian personalized ranking for one-class collaborative filtering
#@ Weike Pan;Li Chen
#t 2013
#c 11
#% 879618
#% 1083671
#% 1176909
#% 1176959
#% 1328172
#% 1355024
#% 1400014
#% 1417104
#% 1543062
#% 1598363
#% 1693878
#% 1730808
#% 1743322
#% 1869831
#% 1932861
#! One-class collaborative filtering or collaborative ranking with implicit feedback has been steadily receiving more attention, mostly due to the "one-class" characteristics of data in various services, e.g., "like" in Facebook and "bought" in Amazon. Previous works for solving this problem include pointwise regression methods based on absolute rating assumptions and pairwise ranking methods with relative score assumptions, where the latter was empirically found performing much better because it models users' ranking-related preferences more directly. However, the two fundamental assumptions made in the pairwise ranking methods, (1) individual pairwise preference over two items and (2) independence between two users, may not always hold. As a response, we propose a new and improved assumption, group Bayesian personalized ranking (GBPR), via introducing richer interactions among users. In particular, we introduce group preference, to relax the aforementioned individual and independence assumptions. We then design a novel algorithm correspondingly, which can recommend items more accurately as shown by various ranking-oriented evaluation metrics on four real-world datasets in our experiments.

#index 2033210
#* Promoting diversity in recommendation by entropy regularizer
#@ Lijing Qin;Xiaoyan Zhu
#t 2013
#c 11
#% 262112
#% 414514
#% 452563
#% 729923
#% 734592
#% 734594
#% 805841
#% 813966
#% 879627
#% 1127465
#% 1181244
#% 1274911
#% 1275183
#% 1476483
#% 1591980
#% 1641999
#! We study the problem of diverse promoting recommendation task: selecting a subset of diverse items that can better predict a given user's preference. Recommendation techniques primarily based on user or item similarity can suffer from the risk that users cannot get expected information from the over-specified recommendation lists. In this paper, we propose an entropy regularizer to capture the notion of diversity. The entropy regularizer has good properties in that it satisfies monotonicity and submodularity, such that when we combine it with a modular rating set function, we get submodular objective function, which can be maximized approximately by efficient greedy algorithm, with provable constant factor guarantee of optimality. We apply our approach on the top-K prediction problem and evaluate its performance on Movie-Lens data set, which is a standard database containing movie rating data collected from a popular online movie recommender system. We compare our model with the state-of-the-art recommendation algorithms. Our experiments show that entropy regularizer effectively captures diversity and hence improves the performance of recommendation task.

#index 2033211
#* SCMF: sparse covariance matrix factorization for collaborative filtering
#@ Jianping Shi;Naiyan Wang;Yang Xia;Dit-Yan Yeung;Irwin King;Jiaya Jia
#t 2013
#c 11
#% 397153
#% 452563
#% 734592
#% 757953
#% 818216
#% 983903
#% 1073982
#% 1083671
#% 1127481
#% 1130901
#% 1176909
#% 1287243
#% 1302843
#% 1302853
#% 1536533
#% 1625387
#% 1650569
#! Matrix factorization (MF) is a popular collaborative filtering approach for recommender systems due to its simplicity and effectiveness. Existing MF methods either assume that all latent features are uncorrelated or assume that all are correlated. To address the important issue of what structure should be imposed on the features, we investigate the covariance matrix of the latent features learned from real data. Based on the findings, we propose an MF model with a sparse covariance prior which favors a sparse yet non-diagonal covariance matrix. Not only can this reflect the semantics more faithfully, but imposing sparsity can also have a side effect of preventing overfitting. Starting from a probabilistic generative model with a sparse covariance prior, we formulate the model inference problem as a maximum a posteriori (MAP) estimation problem. The optimization procedure makes use of stochastic gradient descent and majorization-minimization. For empirical validation, we conduct experiments using the MovieLens and Netflix datasets to compare the proposed method with two strong baselines which use different priors. Experimental results show that our sparse covariance prior can lead to performance improvement.

#index 2033212
#* Exploiting local and global social context for recommendation
#@ Jiliang Tang;Xia Hu;Huiji Gao;Huan Liu
#t 2013
#c 11
#% 290830
#% 330687
#% 1001279
#% 1035589
#% 1083671
#% 1130901
#% 1214661
#% 1214666
#% 1355042
#% 1400002
#% 1400031
#% 1476461
#% 1536533
#% 1560408
#% 1598359
#% 1668087
#% 1693870
#% 1872260
#% 1872408
#% 1879048
#% 1918339
#! With the fast development of social media, the information overload problem becomes increasingly severe and recommender systems play an important role in helping online users find relevant information by suggesting information of potential interests. Social activities for online users produce abundant social relations. Social relations provide an independent source for recommendation, presenting both opportunities and challenges for traditional recommender systems. Users are likely to seek suggestions from both their local friends and users with high global reputations, motivating us to exploit social relations from local and global perspectives for online recommender systems in this paper. We develop approaches to capture local and global social relations, and propose a novel framework LOCABAL taking advantage of both local and global social context for recommendation. Empirical results on real-world datasets demonstrate the effectiveness of our proposed framework and further experiments are conducted to understand how local and global social context work for the proposed framework.

#index 2033213
#* Collaborative topic regression with social regularization for tag recommendation
#@ Hao Wang;Binyi Chen;Wu-Jun Li
#t 2013
#c 11
#% 647057
#% 722904
#% 813966
#% 1055704
#% 1127458
#% 1131843
#% 1131923
#% 1190091
#% 1260273
#% 1287228
#% 1294855
#% 1305469
#% 1355024
#% 1401798
#% 1442298
#% 1484399
#% 1490608
#% 1605963
#% 1667787
#% 1826335
#% 1866577
#% 1945117
#! Recently, tag recommendation (TR) has become a very hot research topic in data mining and related areas. However, neither co-occurrence based methods which only use the item-tag matrix nor content based methods which only use the item content information can achieve satisfactory performance in real TR applications. Hence, how to effectively combine the item-tag matrix, item content information, and other auxiliary information into the same recommendation framework is the key challenge for TR. In this paper, we first adapt the collaborative topic regression (CTR) model, which has been successfully applied for article recommendation, to combine both item-tag matrix and item content information for TR. Furthermore, by extending CTR we propose a novel hierarchical Bayesian model, called CTR with social regularization (CTR-SR), to seamlessly integrate the item-tag matrix, item content information, and social networks between items into the same principled model. Experiments on real data demonstrate the effectiveness of our proposed models.

#index 2033214
#* Online egocentric models for citation networks
#@ Hao Wang;Wu-Jun Li
#t 2013
#c 11
#% 722904
#% 823342
#% 853535
#% 1211731
#% 1246431
#% 1305469
#% 1369424
#% 1451159
#% 1826335
#% 1826423
#% 1826424
#% 1826461
#% 1826502
#% 1872232
#! With the emergence of large-scale evolving (time-varying) networks, dynamic network analysis (DNA) has become a very hot research topic in recent years. Although a lot of DNA methods have been proposed by researchers from different communities, most of them can only model snapshot data recorded at a very rough temporal granularity. Recently, some models have been proposed for DNA which can be used to model large-scale citation networks at a fine temporal granularity. However, they suffer from a significant decrease of accuracy over time because the learned parameters or node features are static (fixed) during the prediction process for evolving citation networks. In this paper, we propose a novel model, called online egocentric model (OEM), to learn time-varying parameters and node features for evolving citation networks. Experimental results on real-world citation networks show that our OEM can not only prevent the prediction accuracy from decreasing over time but also uncover the evolution of topics in citation networks.

#index 2033215
#* Boosting cross-lingual knowledge linking via concept annotation
#@ Zhichun Wang;Juanzi Li;Jie Tang
#t 2013
#c 11
#% 941135
#% 1019082
#% 1130858
#% 1155717
#% 1214667
#% 1246170
#% 1288161
#% 1415756
#% 1482288
#% 1597486
#% 1598410
#% 1641519
#% 1746843
#% 1746844
#! Automatically discovering cross-lingual links (CLs) between wikis can largely enrich the cross-lingual knowledge and facilitate knowledge sharing across different languages. In most existing approaches for cross-lingual knowledge linking, the seed CLs and the inner link structures are two important factors for finding new CLs. When there are insufficient seed CLs and inner links, discovering new CLs becomes a challenging problem. In this paper, we propose an approach that boosts cross-lingual knowledge linking by concept annotation. Given a small number of seed CLs and inner links, our approach first enriches the inner links in wikis by using concept annotation method, and then predicts new CLs with a regression-based learning model. These two steps mutually reinforce each other, and are executed iteratively to find as many CLs as possible. Experimental results on the English and Chinese Wikipedia data show that the concept annotation can effectively improve the quantity and quality of predicted CLs. With 50,000 seed CLs and 30% of the original inner links in Wikipedia, our approach discovered 171,393 more CLs in four runs when using concept annotation.

#index 2033216
#* Pagerank with priors: an influence propagation perspective
#@ Biao Xiang;Qi Liu;Enhong Chen;Hui Xiong;Yi Zheng;Yu Yang
#t 2013
#c 11
#% 290830
#% 641979
#% 729923
#% 799632
#% 850029
#% 955712
#% 989613
#% 1214641
#% 1214702
#% 1301029
#% 1355040
#% 1451243
#% 1550712
#% 1567510
#% 1628176
#% 1642219
#% 1663638
#% 1893846
#% 1925633
#! Recent years have witnessed increased interests in measuring authority and modelling influence in social networks. For a long time, PageRank has been widely used for authority computation and has also been adopted as a solid baseline for evaluating social influence related applications. However, the connection between authority measurement and influence modelling is not clearly established. To this end, in this paper, we provide a focused study on understanding of PageRank as well as the relationship between PageRank and social influence analysis. Along this line, we first propose a linear social influence model and reveal that this model is essentially PageRank with prior. Also, we show that the authority computation by PageRank can be enhanced with more generalized priors. Moreover, to deal with the computational challenge of PageRank with general priors, we provide an upper bound for top authoritative nodes identification. Finally, the experimental results on the scientific collaboration network validate the effectiveness of the proposed social influence model.

#index 2033217
#* Social collaborative filtering by trust
#@ Bo Yang;Yu Lei;Dayou Liu;Jiming Liu
#t 2013
#c 11
#% 220706
#% 220708
#% 1102242
#% 1130901
#% 1227602
#% 1476461
#% 1536533
#% 1975825
#! To accurately and actively provide users with their potentially interested information or services is the main task of a recommender system. Collaborative filtering is one of the most widely adopted recommender algorithms, whereas it is suffering the issues of data sparsity and cold start that will severely degrade quality of recommendations. To address such issues, this article proposes a novel method, trying to improve the performance of collaborative filtering recommendation by means of elaborately integrating twofold sparse information, the conventional rating data given by users and the social trust network among the same users. It is a model-based method adopting matrix factorization technique to map users into low-dimensional latent feature spaces in terms of their trust relationship, aiming to reflect users' reciprocal influence on their own opinions more reasonably. The validations against a real-world dataset show that the proposed method performs much better than state-of-the-art recommendation algorithms for social collaborative filtering by trust.

#index 2033218
#* Parametric local multimodal hashing for cross-view similarity search
#@ Deming Zhai;Hong Chang;Yi Zhen;Xianming Liu;Xilin Chen;Wen Gao
#t 2013
#c 11
#% 143194
#% 190581
#% 393059
#% 593047
#% 722904
#% 760805
#% 898309
#% 1022281
#% 1148301
#% 1292880
#% 1484424
#% 1826280
#% 1872343
#% 1884109
#% 1884343
#% 1931623
#! Recent years have witnessed the growing popularity of hashing for efficient large-scale similarity search. It has been shown that the hashing quality could be boosted by hash function learning (HFL). In this paper, we study HFL in the context of multimodal data for cross-view similarity search. We present a novel multimodal HFL method, called Parametric Local Multimodal Hashing (PLMH), which learns a set of hash functions to locally adapt to the data structure of each modality. To balance locality and computational efficiency, the hashing projection matrix of each instance is parameterized, with guaranteed approximation error bound, as a linear combination of basis hashing projections of a small set of anchor points. A local optimal conjugate gradient algorithm is designed to learn the hash functions for each bit, and the overall hash codes are learned in a sequential manner to progressively minimize the bias. Experimental evaluations on cross-media retrieval tasks demonstrate that PLMH performs competitively against the state-of-the-art methods.

#index 2033219
#* Social influence locality for modeling retweeting behaviors
#@ Jing Zhang;Biao Liu;Jie Tang;Ting Chen;Juanzi Li
#t 2013
#c 11
#% 729923
#% 844334
#% 1107420
#% 1214702
#% 1289741
#% 1355040
#% 1379671
#% 1482397
#% 1484274
#% 1512437
#% 1872232
#% 1879058
#! We study an interesting phenomenon of social influence locality in a large microblogging network, which suggests that users' behaviors are mainly influenced by close friends in their ego networks. We provide a formal definition for the notion of social influence locality and develop two instantiation functions based on pairwise influence and structural diversity. The defined influence locality functions have strong predictive power. Without any additional features, we can obtain a F1-score of 71.65% for predicting users' retweet behaviors by training a logistic regression classifier based on the defined functions. Our analysis also reveals several intriguing discoveries. For example, though the probability of a user retweeting a microblog is positively correlated with the number of friends who have retweeted the microblog, it is surprisingly negatively correlated with the number of connected circles that are formed by those friends.

#index 2033220
#* Automatic name-face alignment to enable cross-media news retrieval
#@ Yuejie Zhang;Wei Wu;Yang Li;Cheng Jin;Xiangyang Xue;Jianping Fan
#t 2013
#c 11
#% 434882
#% 592110
#% 884043
#% 1040539
#% 1131918
#% 1149120
#% 1176935
#% 1183843
#% 1207154
#% 1279785
#% 1502510
#% 1632176
#% 1694055
#% 1775842
#% 1800161
#! A new algorithm is developed in this paper to support automatic name-face alignment for achieving more accurate cross-media news retrieval. We focus on extracting valuable information from large amounts of news images and their captions, where multi-level image-caption pairs are constructed for characterizing both significant names with higher salience and their cohesion with human faces extracted from news images. To remedy the issue of lacking enough related information for rare name, Web mining is introduced to acquire the extra multimodal information. We also emphasize on an optimization mechanism by our Improved Self-Adaptive Simulated Annealing Genetic Algorithm to verify the feasibility of alignment combinations. Our experiments have obtained very positive results.

#index 2033221
#* Assessing the resilience of socio-ecosystems: coupling viability theory and active learning with kd-trees. application to bilingual societies
#@ Isabelle Alvarez;Ricardo De Aldama;Sophie Martin;Romain Reuillon
#t 2013
#c 11
#% 415540
#! This paper proposes a new algorithm to compute the resilience of a social system or an ecosystem when it is defined in the framework of the mathematical viability theory. It is applied to the problem of language coexistence: Although bilingual societies do exist, many languages have disappeared and some seem endangered presently. Mathematical models of language competition generally conclude that one language will disappear, except when the relative prestige of the languages can be modified. The viability theory provides concepts and tools that are suitable to study the resilience, but with severe computational limits since it uses extensive search on regular grids. The method we propose considers the computation of the viability output sets as an active learning problem with the objective of restraining the number of calls to the model and information storage. We adapt a kd-tree algorithm to approximate the level sets of the resilience value. We prove that this algorithm converges to the output sets defined by the viability theory (viability kernel and capture basin). The resilience value we compute can then be used to propose a policy of action in risky situations such as migration flows.

#index 2033222
#* Towards understanding global spread of disease from everyday interpersonal interactions
#@ Sean Brennan;Adam Sadilek;Henry Kautz
#t 2013
#c 11
#% 197394
#% 840882
#% 983905
#% 1496812
#% 1561563
#! Monitoring and forecast of global spread of infectious diseases is difficult, mainly due to lack of fine-grained and timely data. Previous work in computational epidemiology has shown that mining data from the web can improve the predictability of high-level aggregate patterns of epidemics. By contrast, this paper explores how individuals contribute to the global spread of disease. We consider the important task of predicting the prevalence of flu-like illness in a given city based on interpersonal interactions of the city's residents with the outside world. We use the geo-tagged status updates of traveling Twitter users to infer properties of the flow of individuals between cities. While previous research considered only the raw volume of passengers, we estimate a number of latent variables, including the number of sick (symptomatic) travelers and the number of sick individuals to whom each traveler was exposed. We show that AI techniques provide insights into the mechanisms of disease spread and significantly improve predictability of future flu outbreaks. Our experiments involve over 51,000 individuals traveling between 75 cities prior and during a severe ongoing flu epidemic (October 2012 - January 2013). Our model leverages the text and interpersonal interactions recorded in over 6.5 million online status updates without any active user participation, enabling scalable public health applications.

#index 2033223
#* Short-term wind power forecasting using Gaussian processes
#@ Niya Chen;Zheng Qian;Xiaofeng Meng;Ian T. Nabney
#t 2013
#c 11
#% 891549
#% 1473328
#% 1525283
#! Since wind has an intrinsically complex and stochastic nature, accurate wind power forecasts are necessary for the safety and economics of wind energy utilization. In this paper, we investigate a combination of numeric and probabilistic models: one-day-ahead wind power forecasts were made with Gaussian Processes (GPs) applied to the outputs of a Numerical Weather Prediction (NWP) model. Firstly the wind speed data from NWP was corrected by a GP. Then, as there is always a defined limit on power generated in a wind turbine due the turbine controlling strategy, a Censored GP was used to model the relationship between the corrected wind speed and power output. To validate the proposed approach, two real world datasets were used for model construction and testing. The simulation results were compared with the persistence method and Artificial Neural Networks (ANNs); the proposed model achieves about 11% improvement in forecasting accuracy (Mean Absolute Error) compared to the ANN model on one dataset, and nearly 5% improvement on another.

#index 2033224
#* Semi-supervised learning for integration of aerosol predictions from multiple satellite instruments
#@ Nemanja Djuric;Lakesh Kansakar;Slobodan Vucetic
#t 2013
#c 11
#% 1211801
#% 1473286
#! Aerosol Optical Depth (AOD), recognized as one of the most important quantities in understanding and predicting the Earth's climate, is estimated daily on a global scale by several Earth-observing satellite instruments. Each instrument has different coverage and sensitivity to atmospheric and surface conditions, and, as a result, the quality of AOD estimated by different instruments varies across the globe. We present a method for learning how to aggregate AOD estimations from multiple satellite instruments into a more accurate estimation. The proposed method is semi-supervised, as it is able to learn from a small number of labeled data, where labels come from a few accurate and expensive ground-based instruments, and a large number of unlabeled data. The method uses a latent variable to partition the data, so that in each partition the expert AOD estimations are aggregated in a different, optimal way. We applied the method to combine AOD estimations from 5 instruments aboard 4 satellites, and the results indicate that it can successfully exploit labeled and unlabeled data to produce accurate aggregated AOD estimations.

#index 2033225
#* Deep sparse coding based recursive disaggregation model for water conservation
#@ Haili Dong;Bingsheng Wang;Chang-Tien Lu
#t 2013
#c 11
#% 408396
#% 1270561
#% 1384319
#% 1607167
#% 1680830
#% 1948615
#% 1978751
#! The increasing demands on drinkable water, along with population growth, water-intensive agriculture and economic development, pose critical challenges to water sustainability. New techniques to long-term water conservation that incorporate principles of sustainability are expected. Recent studies have shown that providing customers with usage information of fixtures could help them save a considerable amount of water. Existing disaggregation techniques focus on learning consumption patterns for individual devices. Little attention has been given to the hierarchical decomposition structure of the aggregated consumption. In this paper, a Deep Sparse Coding based Recursive Disaggregation Model (DSCRDM) is proposed for water conservation. We design a recursive decomposition structure to perform the disaggregation task, and introduce sequential set to capture its characteristics. An efficient and effective algorithm deep sparse coding is developed to automatically learn the disaggregation architecture, along with discriminative and reconstruction dictionaries for each layer. We demonstrated that our proposed approach significantly improved the performance of the benchmark methods on a large scale disaggregation task and illustrated how our model could provide practical feedbacks to customers for water conservation.

#index 2033226
#* Optimal pricing for improving efficiency of taxi systems
#@ Jiarui Gan;Bo An;Haizhong Wang;Xiaoming Sun;Zhongzhi Shi
#t 2013
#c 11
#% 817641
#% 1171116
#% 1272214
#! In Beijing, most taxi drivers intentionally avoid working during peak hours despite of the huge customer demand within these peak periods. This dilemma is mainly due to the fact that taxi drivers' congestion costs are not reflected in the current taxi fare structure. To resolve this problem, we propose a new pricing scheme to provide taxi drivers with extra incentives to work during peak hours. This differs from previous studies of taxi market by considering market variance over multiple periods, taxi drivers' profit-driven decisions, and their scheduling constraints regarding the interdependence among different periods. The major challenge of this research is the computational intensiveness to identify optimal strategy due to the exponentially large size of a taxi driver's strategy space and the scheduling constraints. We develop an atom schedule method to overcome these issues. It reduces the magnitude of the problem while satisfying the constraints to filter out infeasible pure strategies. Simulation results based on real data show the effectiveness of the proposed methods, which opens up a new door to improving the efficiency of taxi market in megacities (e.g., Beijing).

#index 2033227
#* Estimating reference evapotranspiration for irrigation management in the texas high plains
#@ Daniel Holman;Mohan Sridharan;Prasanna Gowda;Dana Porter;Thomas Marek;Terry Howell;Jerry Moorhead
#t 2013
#c 11
#% 132970
#% 268069
#% 1301004
#! Accurate estimates of daily crop evapotranspiration (ET) are needed for efficient irrigation management in regions where crop water demand exceeds rainfall. Daily grass or alfalfa reference ET values and crop coefficients are widely used to estimate crop water demand. Inaccurate reference ET estimates can hence have a tremendous impact on irrigation costs and the demands on freshwater resources. ET networks calculate reference ET using precise measurements of meteorological data. These networks are typically characterized by gaps in spatial coverage and lack of sufficient funding, creating an immediate need for alternative sources that can fill data gaps without high costs. Although non-agricultural weather stations provide publicly accessible meteorological data, there are concerns that the data may be unsuitable for estimating reference ET due to factors such as weather station siting, data formats and quality control issues. The objective of our research is to enable the use of alternative data sources, adapting sophisticated machine learning algorithms such as Gaussian process models and neural networks to discover and model the nonlinear relationships between non-ET weather station data and the reference ET computed by ET networks. Using data from the Texas High Plains region in the U.S., we demonstrate significant improvement in estimation accuracy in comparison with baseline regression models typically used for irrigation management applications.

#index 2033228
#* Information fusion based learning for frugal traffic state sensing
#@ Vikas Joshi;Nithya Rajamani;K. Takayuki;Naveen Prathapaneni;L. V. Subramaniam
#t 2013
#c 11
#% 747151
#% 1132736
#% 1143519
#% 1432726
#% 1723946
#% 1890491
#% 1942819
#! Traffic sensing is a key baseline input for sustainable cities to plan and administer demand-supply management through better road networks, public transportation, urban policies etc., Humans sense the environment frugally using a combination of complementary information signals from different sensors. For example, by viewing and/or hearing traffic one could identify the state of traffic on the road. In this paper, we demonstrate a fusion based learning approach to classify the traffic states using low cost audio and image data analysis using real world dataset. Road side collected traffic acoustic signals and traffic image snapshots obtained from fixed camera are used to classify the traffic condition into three broad classes viz., Jam, Medium and Free. The classification is done on {10sec audio, image snapshot in that 10sec} data tuple. We extract traffic relevant features from audio and image data to form a composite feature vector. In particular, we extract the audio features comprising MFCC (Mel-Frequency Cepstral Coefficients) classifier based features, honk events and energy peaks. A simple heuristic based image classifier is used, where vehicular density and number of corner points within the road segment are estimated and are used as features for traffic sensing. Finally the composite vector is tested for its ability to discriminate the traffic classes using Decision tree classifier, SVM classifier, Discriminant classifier and Logistic regression based classifier. Information fusion at multiple levels (audio, image, overall) shows consistently better performance than individual level decision making. Low cost sensor fusion based on complementary weak classifiers and noisy features still generates high quality results with an overall accuracy of 93-96%.

#index 2033229
#* A multi-objective memetic algorithm for vehicle resource allocation in sustainable transportation planning
#@ Hoong Chuin Lau;Lucas Agussurja;Shih-Fen Cheng;Pang Jin Tan
#t 2013
#c 11
#% 1432898
#% 1564564
#% 1826254
#! Sustainable supply chain management has been an increasingly important topic of research in recent years. At the strategic level, there are computational models which study supply and distribution networks with environmental considerations. At the operational level, there are, for example, routing and scheduling models which are constrained by carbon emissions. Our paper explores work in tactical planning with regards to vehicle resource allocation from distribution centers to customer locations in a multi-echelon logistics network. We formulate the bi-objective optimization problem exactly and design a memetic algorithm to efficiently derive an approximate Pareto front. We illustrate the applicability of our approach with a large real-world dataset.

#index 2033230
#* Crowdsourcing backdoor identification for combinatorial optimization
#@ Ronan Le Bras;Richard Bernstein;Carla P. Gomes;Bart Selman;R. Bruce Van Dover
#t 2013
#c 11
#% 266200
#% 895018
#% 1217773
#% 1269577
#% 1279379
#% 1415274
#% 1603990
#% 1630317
#% 1835483
#% 1876130
#% 1881889
#! We will show how human computation insights can be key to identifying so-called backdoor variables in combinatorial optimization problems. Backdoor variables can be used to obtain dramatic speedups in combinatorial search. Our approach leverages the complementary strength of human input, based on a visual identification of problem structure, crowdsourcing, and the power of combinatorial solvers to exploit complex constraints. We describe our work in the context of the domain of materials discovery. The motivation for considering the materials discovery domain comes from the fact that new materials can provide solutions for key challenges in sustainability, e.g., in energy, new catalysts for more efficient fuel cell technology.

#index 2033231
#* Evolution of common-pool resources and social welfare in structured populations
#@ Jean-Sébastien Lerat;The Anh Han;Tom Lenaerts
#t 2013
#c 11
#% 1166817
#% 1983638
#! The Common-pool resource (CPR) game is a social dilemma where agents have to decide how to consume a shared CPR. Either they each take their cut, completely destroying the CPR, or they restrain themselves, gaining less immediate profit but sustaining the resource and future profit. When no consumption takes place the CPR simply grows to its carrying capacity. As such, this dilemma provides a framework to study the evolution of social consumption strategies and the sustainability of resources, whose size adjusts dynamically through consumption and their own implicit population dynamics. The present study provides for the first time a detailed analysis of the evolutionary dynamics of consumption strategies in finite populations, focusing on the interplay between the resource levels and preferred consumption strategies. We show analytically which restrained consumers survive in relation to the growth rate of the resources and how this affects the resources' carrying capacity. Second, we show that population structures affect the sustainability of the resources and social welfare in the population. Current results provide an initial insight into the complexity of the CPR game, showing potential for a variety of different studies in the context of social welfare and resource sustainability.

#index 2033232
#* Tag-weighted topic model for mining semi-structured documents
#@ Shuangyin Li;Jiefei Li;Rong Pan
#t 2013
#c 11
#% 280819
#% 722904
#% 788094
#% 879587
#% 1130899
#% 1211848
#% 1338553
#% 1417055
#% 1558464
#% 1605964
#% 1606070
#% 1872239
#! In the last decade, latent Dirichlet allocation (LDA) successfully discovers the statistical distribution of the topics over a unstructured text corpus. Meanwhile, more and more document data come up with rich human-provided tag information during the evolution of the Internet, which called semistructured data. The semi-structured data contain both unstructured data (e.g., plain text) and metadata, such as papers with authors and web pages with tags. In general, different tags in a document play different roles with their own weights. To model such semi-structured documents is nontrivial. In this paper, we propose a novel method to model tagged documents by a topic model, called Tag-Weighted Topic Model (TWTM). TWTM is a framework that leverages the tags in each document to infer the topic components for the documents. This allows not only to learn document-topic distributions, but also to infer the tag-topic distributions for text mining (e.g., classification, clustering, and recommendations). Moreover, TWTM automatically infers the probabilistic weights of tags for each document. We present an efficient variational inference method with an EM algorithm for estimating the model parameters. The experimental results show that our TWTM approach outperforms the baseline algorithms over three corpora in document modeling and text classification.

#index 2033233
#* Manifold alignment based on sparse local structures of more corresponding pairs
#@ Xiaojie Li;Jian Cheng Lv;Zhang Yi
#t 2013
#c 11
#% 593047
#% 902496
#% 1074012
#% 1305493
#% 1305545
#% 1399334
#% 1541113
#% 1848053
#! Manifold alignment is to extract the shared latent semantic structure from multiple manifolds. The joint adjacency matrix plays a key role in manifold alignment. To construct the matrix, it is crucial to get more corresponding pairs. This paper proposes an approach to obtain more and reliable corresponding pairs in terms of local structure correspondence. The sparse reconstruction weight matrix of each manifold is established to preserve the local geometry of the original data set. The sparse correspondence matrices are constructed using the sparse local structures of corresponding pairs across manifolds. Further more, a new energy function for manifold alignment is proposed to simultaneously match the corresponding instances and preserve the local geometry of each manifold. The shared low dimensional embedding, which provides better descriptions for the intrinsic geometry and relations between different manifolds, can be obtained by solving the optimization problem with closed-form solution. Experiments demonstrate the effectiveness of the proposed algorithm.

#index 2033234
#* A global constrained optimization method for designing road networks with small diameters
#@ Teng Ma;Yuexian Hou;Xiaozhao Zhao;Dawei Song
#t 2013
#c 11
#% 1143079
#! The road network design problem is to optimize the road network by selecting paths to improve or adding paths in the existing road network, under certain constraints, e.g., the weighted sum of modifying costs. Since its multi-objective nature, the road network design problem is often challenging for designers. Empirically, the smaller diameter a road network has, the more connected and efficient the road network is. Based on this observation, we propose a set of constrained convex models for designing road networks with small diameters. To be specific, we theoretically prove that the diameter of the road network, which is evaluated w.r.t the travel times in the network, can be bounded by the algebraic connectivity in spectral graph theory since that the upper and lower bounds of diameter are inversely proportional to algebraic connectivity. Then we can focus on increasing the algebraic connectivity instead of reducing the network diameter, under the budget constraints. The above formulation leads to a semi-definite program, in which we can get its global solution easily. Then, we present some simulation experiments to show the correctness of our method. At last, we compare our method with an existing method based on the genetic algorithm.

#index 2033235
#* Bayesian joint inversions for the exploration of earth resources
#@ Alistair Reid;Simon O'Callaghan;Edwin V. Bonilla;Lachlan McCalman;Tim Rawling;Fabio Ramos
#t 2013
#c 11
#% 806994
#% 916792
#! We propose a machine learning approach to geophysical inversion problems for the exploration of earth resources. Our approach is based on nonparametric Bayesian methods, specifically, Gaussian processes, and provides a full distribution over the predicted geophysical properties whilst enabling the incorporation of data from different modalities. We assess our method both qualitatively and quantitatively using a real dataset from South Australia containing gravity and drill-hole data and through simulated experiments involving gravity, drill-holes and magnetics, with the goal of characterizing rock densities. The significance of our probabilistic inversion extends to general exploration problems with potential to dramatically benefit the industry.

#index 2033236
#* Dynamic taxi and ridesharing: a framework and heuristics for the optimization problem
#@ Douglas O. Santos;Eduardo C. Xavier
#t 2013
#c 11
#% 1316154
#% 1863956
#! In this paper we study a dynamic problem of ridesharing and taxi sharing with time windows. We consider a scenario where people needing a taxi or interested in getting a ride use a phone app to designate their source and destination points in a city, as well others restrictions (such as maximum allowable time to be at the destination). On the other hand, we have taxis and people interested in giving a ride, with their current positions and also some constraints (vehicle capacity, destination, maximum time to destination). We want to maximize the number of shared trips: in the case of taxis, people going to close locations can share the costs of the trip, and in case of rides, the driver and passengers can share costs as well. This problem is dynamic since new calls for taxis or calls for rides arrive on demand. This gives rise to an optimization problem which we prove to be NP-Hard. We then propose heuristics to deal with it. We focus on the taxi sharing problem, but we show that our model is easily extendable to model the ridesharing situation or even a situation where there are both taxis and car owners. In addition, we present a framework that consists basically of a client application and a server. The last one processes all incoming information in order to match vehicles to passengers requests. The entire system can be used by taxi companies and riders in a way to reduce the traffic in the cities and to reduce the emission of greenhouse gases.

#index 2033237
#* An active learning approach to home heating in the smart grid
#@ Mike Shann;Sven Seuken
#t 2013
#c 11
#% 132583
#% 132697
#% 240794
#% 529348
#% 578692
#% 871302
#% 891559
#% 961177
#% 1211696
#% 1272282
#% 1453063
#% 1701755
#% 1815581
#% 1932340
#! A key issue for the realization of the smart grid vision is the implementation of effective demand-side management. One possible approach involves exposing dynamic energy prices to end-users. In this paper, we consider a resulting problem on the user's side: how to adaptively heat a home given dynamic prices. The user faces the challenge of having to react to dynamic prices in real time, trading off his comfort with the costs of heating his home to a certain temperature. We propose an active learning approach to adjust the home temperature in a semi-automatic way. Our algorithm learns the user's preferences over time and automatically adjusts the temperature in real-time as prices change. In addition, the algorithm asks the user for feedback once a day. To find the best query time, the algorithm solves an optimal stopping problem. Via simulations, we show that our algorithm learns users' preferences quickly, and that using the expected utility loss as the query criterion outperforms standard approaches from the active learning literature.

#index 2033238
#* Planning with MIP for supply restoration in power distribution systems
#@ Sylvie Thiébaux;Carleton Coffrin;Hassan Hijazi;John Slaney
#t 2013
#c 11
#% 1272119
#% 1274767
#% 1650816
#! The next generation of power systems faces significant challenges, both in coping with increased loading of an aging infrastructure and incorporating renewable energy sources. Meeting these challenges requires a fundamental change in the operation of power systems by replacing human-in-the-loop operations with autonomous systems. This is especially acute in distribution systems, where renewable integration often occurs. This paper investigates the automation of power supply restoration (PSR), that is, the process of optimally reconfiguring a faulty distribution grid to resupply customers. The key contributions of the paper are (1) a flexible mixed-integer programming framework for solving PSR, (2) a model decomposition to obtain high-quality solutions within the required time constraints, and (3) an experimental validation of the potential benefits of the proposed PSR operations.

#index 2033239
#* Forecasting multi-appliance usage for smart home energy management
#@ Ngoc Cuong Truong;James McInerney;Long Tran-Thanh;Enrico Costanza;Sarvapali D. Ramchurn
#t 2013
#c 11
#% 722754
#% 891559
#% 1517673
#% 1607173
#% 1614144
#% 1649667
#% 1894911
#% 1897296
#% 1897443
#! We address the problem of forecasting the usage of multiple electrical appliances by domestic users, with the aim of providing suggestions about the best time to run appliances in order to reduce carbon emissions and save money (assuming time-of-use pricing), while minimising the impact on the users' daily habits. An important challenge related to this problem is the modelling the everyday routine of the consumers and of the interdependencies between the use of different appliances. Given this, we develop an important building block of future home energy management systems: a prediction algorithm, based on a graphical model, that captures the everyday habits and the inter-dependency between appliances by exploiting their periodic features. We demonstrate through extensive empirical evaluations on real-world data from a prominent database that our approach outperforms existing methods by up to 47%.

#index 2033240
#* Randomized load control: a simple distributed approach for scheduling smart appliances
#@ Menkes Van Den Briel;Paul Scott;Sylvie Thiébaux
#t 2013
#c 11
#% 1614144
#! A significant portion of the electricity network capacity is built to run only a few days a year when demand peaks. As a result, expensive power generation plants and equipment costing millions of dollars are sitting idle most of the time, which increases costs for everyone. We present randomized load control, a simple distributed approach for scheduling smart appliances. Randomized load control schedules the start time of appliances that are programmed to run within a specified time window, so that the aggregate load achieves a given ideal load. Our results show that we do achieve the given ideal load to a great extent. This is remarkable as the approach is completely distributed and preserves customer privacy as the scheduling happens within each house or building separately.

#index 2033241
#* Parameter learning for latent network diffusion
#@ Xiaojian Wu;Akshat Kumar;Daniel Sheldon;Shlomo Zilberstein
#t 2013
#c 11
#% 269195
#% 342596
#% 729923
#% 949164
#% 1493604
#% 1661308
#% 1800689
#% 1925630
#! Diffusion processes in networks are increasingly used to model dynamic phenomena such as the spread of information, wildlife, or social influence. Our work addresses the problem of learning the underlying parameters that govern such a diffusion process by observing the time at which nodes become active. A key advantage of our approach is that, unlike previous work, it can tolerate missing observations for some nodes in the diffusion process. Having incomplete observations is characteristic of offline networks used to model the spread of wildlife. We develop an EM algorithm to address parameter learning in such settings. Since both the E and M steps are computationally challenging, we employ a number of optimization methods such as nonlinear and difference-of-convex programming to address these challenges. Evaluation of the approach on the Red-cockaded Woodpecker conservation problem shows that it is highly robust and accurately learns parameters in various settings, even with more than 80% missing data.

#index 2033242
#* Towards effective prioritizing water pipe replacement and rehabilitation
#@ Junchi Yan;Yu Wang;Ke Zhou;Jin Huang;Chunhua Tian;Hongyuan Zha;Weishan Dong
#t 2013
#c 11
#% 466086
#% 734915
#% 889273
#% 992948
#% 1812294
#% 1923499
#% 2010330
#! Water pipe failures can not only have a great impact on people's daily life but also cause significant waste of water which is an essential and precious resource to human beings. As a result, preventative maintenance for water pipes, particularly in urban-scale networks, is of great importance for a sustainable society. To achieve effective replacement and rehabilitation, failure prediction aims to proactively find those 'most-likely-to-fail' pipes becomes vital and has been attracting more attention from both academia and industry, especially from the civil engineering field. This paper presents an already-deployed industrial computational system for pipe failure prediction. As an alternative to risk matrix methods often depending on ad-hoc domain heuristics, learning based methods are adopted using the attributes with respect to physical, environmental, operational conditions and etc. Further challenge arises in practice when lacking of profile attributes. A dive into the failure records shows that the failure event sequences typically exhibit temporal clustering patterns, which motivates us to use the stochastic process to tackle the failure prediction task. Specifically, the failure sequence is formulated as a self-exciting stochastic process which is, to our best knowledge, a novel formulation for pipe failure prediction. And we show that it outperforms a baseline assuming the failure risk grows linearly with aging. Broad new problems and research points for the machine learning community are also introduced for future work.

#index 2033243
#* Improved integer programming approaches for chance-constrained stochastic programming
#@ Hiroki Yanagisawa;Takayuki Osogami
#t 2013
#c 11
#% 574222
#% 1133781
#% 1191192
#% 1262870
#% 1399464
#% 1743986
#% 1748804
#% 1826372
#! The Chance-Constrained Stochastic Programming (CCSP) is one of the models for decision making under uncertainty. In this paper, we consider the special case of the CCSP in which only the right-hand side vector is random with a discrete distribution having a finite support. The unit commitment problem is one of the applications of the special case of the CCSP. Existing methods for exactly solving the CCSP problems require an enumeration of scenarios when they model a CCSP problem using a Mixed Integer Programming (MIP). We show how to reduce the number of scenarios enumerated in the MIP model. In addition, we give another compact MIP formulation to approximately solve the CCSP problems.

#index 2033244
#* A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring
#@ Davide Zilli;Oliver Parson;Geoff V Merrett;Alex Rogers
#t 2013
#c 11
#% 1461216
#% 1826253
#! Automated acoustic recognition of species aims to provide a cost-effective method for biodiversity monitoring. This is particularly appealing for detecting endangered animals with a distinctive call, such as the New Forest cicada. To this end, we pursue a crowdsourcing approach, whereby the millions of visitors to the New Forest will help to monitor the presence of this cicada by means of a smartphone app that can detect its mating call. However, current systems for acoustic insect classification are aimed at batch processing and not suited to a realtime approach as required by this system, because they are too computationally expensive and not robust to environmental noise. To address this shortcoming we propose a novel insect detection algorithm based on a hidden Markov model to which we feed as a single feature vector the ratio of two key frequencies extracted through the Goertzel algorithm. Our results show that this novel approach, compared to the state of the art for batch insect classification, is much more robust to noise while also reducing the computational cost.

#index 2033245
#* Forecast oriented classification of spatio-temporal extreme events
#@ Zhengzhang Chen;Yusheng Xie;Yu Cheng;Kunpeng Zhang;Ankit Agrawal;Wei-Keng Liao;Nagiza F. Samatova;Alok Choudhary
#t 2013
#c 11
#% 2007701
#! In complex dynamic systems, accurate forecasting of extreme events, such as hurricanes, is a highly underdetermined, yet very important sustainability problem. While physics-based models deserve their own merits, they often provide unreliable predictions for variables highly related to extreme events. In this paper, we propose a new supervised machine learning problem, which we call a forecast oriented classification of spatio-temporal extreme events. We formulate three important real-world extreme event classification tasks, including seasonal forecasting of (a) tropical cyclones in Northern Hemisphere, (b) hurricanes and landfalling hurricanes in North Atlantic, and (c) North African rainfall. Corresponding predictor and predictand data sets are constructed. These data present unique characteristics and challenges that could potentially motivate future Artificial Intelligent and Data Mining research.

#index 2033246
#* Adaptive management of migratory birds under sea level rise
#@ Samuel Nicol;Olivier Buffet;Takuya Iwamura;Iadine Chadès
#t 2013
#c 11
#% 706380
#% 842579
#! The best practice method for managing ecological systems under uncertainty is adaptive management (AM), an iterative process of reducing uncertainty while simultaneously optimizing a management objective. Existing solution methods used for AM problems assume that the system dynamics are stationary, i.e., described by one of a set of pre-defined models. In reality ecological systems are rarely stationary and evolve over time. Importantly, the effects of climate change on populations are unlikely to be captured by stationary models. Practitioners need efficient algorithms to implement AM on real-world problems. AM can be formulated as a hidden model Markov Decision Process (hmMDP), which allows the state space to be factored and shows promise for the rapid resolution of large problems. We provide an ecological dataset and performance metrics for the AM of a network of shorebird species utilizing the East Asian-Australasian flyway given uncertainty about the rate of sea level rise. The non-stationary system is modelled as a stationary POMDP containing hidden alternative models with known probabilities of transition between them. We challenge the POMDP community to exploit the simplifications allowed by structuring the AM problem as an hmMDP and improve our benchmark solutions.

#index 2033247
#* Detecting and tracking disease outbreaks by mining social media data
#@ Yusheng Xie;Zhengzhang Chen;Yu Cheng;Kunpeng Zhang;Ankit Agrawal;Wei-Keng Liao;Alok Choudhary
#t 2013
#c 11
#% 1689729
#% 1948178
#! The emergence and ubiquity of online social networks have enriched web data with evolving interactions and communities both at mega-scale and in real-time. This data offers an unprecedented opportunity for studying the interaction between society and disease outbreaks. The challenge we describe in this data paper is how to extract and leverage epidemic outbreak insights from massive amounts of social media data and how this exercise can benefit medical professionals, patients, and policymakers alike. We attempt to prepare the research community for this challenge with four datasets. Publishing the four datasets will commoditize the data infrastructure to allow a higher and more efficient focal point for the research community.

#index 2033248
#* Twitter-based user modeling for news recommendations
#@ Fabian Abel;Qi Gao;Geert-Jan Houben;Ke Tao
#t 2013
#c 11
#% 1356185
#% 1384223
#% 1399966
#% 1400018
#% 1476470
#% 1482254
#% 1573472
#% 1603813
#% 1632440
#! In this paper, we study user modeling on Twitter. We investigate different strategies for mining user interest profiles from microblogging activities ranging from strategies that analyze the semantic meaning of Twitter messages to strategies that adapt to temporal patterns that can be observed in the microblogging behavior. We evaluate the quality of the user modeling methods in the context of a personalized news recommendation system. Our results reveals that an understanding of the semantic meaning of microposts is key for generating high-quality user profiles.

#index 2033249
#* Language-based games (extended abstract)
#@ Adam Bjorndahl;Joseph Y. Halpern;Rafael Pass
#t 2013
#c 11
#% 188086
#! We introduce language-based games, a generalization of psychological games [Geanakoplos et al., 1989] that can also capture reference-dependent preferences [Koszegi and Rabin, 2006], which extend the domain of the utility function to situations, maximal consistent sets in some language. The role of the underlying language in this framework is thus particularly critical. Of special interest are languages that can express only coarse beliefs [Mullainathan, 2002]. Despite the expressive power of the approach, we show that it can describe games in a simple, natural way. Nash equilibrium and rationalizability are generalized to this setting; Nash equilibrium is shown not to exist in general, while the existence of rationalizable strategies is proved under mild conditions.

#index 2033250
#* An improved separation of regular resolution from pool resolution and clause learning (extended abstract)
#@ Maria Luisa Bonet;Sam Buss
#t 2013
#c 11
#% 2119
#% 274131
#% 288165
#% 288705
#% 327779
#% 420713
#% 646269
#% 1270064
#% 1272049
#% 1526848
#% 1602943
#% 1654326
#% 1674537
#% 1728024
#% 1881880
#! We establish the unexpected power of conflict driven clause learning (CDCL) proof search by proving that the sets of unsatisfiable clauses obtained from the guarded graph tautology principles of Alekhnovich, Johannsen, Pitassi and Urquhart have polynomial size pool resolution refutations that use only input lemmas as learned clauses. We further show that, under the correct heuristic choices, these refutations can be carried out in polynomial time by CDCL proof search without restarts, even when restricted to greedy, unit-propagating search. The guarded graph tautologies had been conjectured to separate CDCL without restarts from resolution; our results refute this conjecture.

#index 2033251
#* The complexity of one-agent refinement modal logic (extended abstract)
#@ Laura Bozzelli;Hans Van Ditmarsch;Sophie Pinchinat
#t 2013
#c 11
#% 101922
#% 289287
#% 338753
#% 390685
#% 413871
#% 1332460
#% 1388781
#% 1405227
#% 1925306
#! We investigate the complexity of satisfiability for one-agent refinement modal logic (RML), an extension of basic modal logic (ML) obtained by adding refinement quantifiers on structures. RML is known to have the same expressiveness as ML, but the translation of RML into ML is of nonelementary complexity, and RML is at least doubly exponentially more succinct than ML. In this paper we show that RML-satisfiability is 'only' singly exponentially harder than ML-satisfiability, the latter being a well-known PSPACE-complete problem.

#index 2033252
#* An introduction to string re-writing kernel
#@ Fan Bu;Hang Li;Xiaoyan Zhu
#t 2013
#c 11
#% 342630
#% 722803
#% 770816
#% 793247
#% 816156
#% 833088
#% 983885
#% 1196054
#% 1251651
#% 1261527
#% 1299570
#% 1299581
#% 1328356
#% 1470706
#% 1558464
#% 1913290
#! Learning for sentence re-writing is a fundamental task in natural language processing and information retrieval. In this paper, we propose a new class of kernel functions, referred to as string rewriting kernel, to address the problem. A string re-writing kernel measures the similarity between two pairs of strings. It can capture the lexical and structural similarity between sentence pairs without the need of constructing syntactic trees. We further propose an instance of string re-writing kernel which can be computed efficiently. Experimental results on benchmark datasets show that our method can achieve comparable results with state-of-the-art methods on two sentence rewriting learning tasks: paraphrase identification and recognizing textual entailment.

#index 2033253
#* Optimal valve placement in water distribution networks with CLP(FD)
#@ Massimiliano Cattafi;Marco Gavanelli;Maddalena Nonato;Stefano Alvisi;Marco Franchini
#t 2013
#c 11
#% 534496
#% 574007
#% 576214
#% 579443
#% 579444
#% 644201
#% 1466312
#% 1707013
#! This paper presents a new application of logic programming to a real-life problem in hydraulic engineering. The work is developed as a collaboration of computer scientists and hydraulic engineers, and applies Constraint Logic Programming to solve a hard combinatorial problem. This application deals with one aspect of the design of a water distribution network, i.e., the valve isolation system design. We take the formulation of the problem by Giustolisi and Savic [2008] and show how, thanks to constraint propagation, we can get better solutions than the best solution known in the literature for the Apulian distribution network.

#index 2033254
#* Bayesian probabilities for constraint-based causal discovery
#@ Tom Claassen;Tom Heskes
#t 2013
#c 11
#% 129987
#% 197387
#% 297171
#% 650939
#% 722900
#% 1062439
#% 1093382
#% 1232047
#% 1472284
#! We target the problem of accuracy and robustness in causal inference from finite data sets. Our aim is to combine the inherent robustness of the Bayesian approach with the theoretical strength and clarity of constraint-based methods. We use a Bayesian score to obtain probability estimates on the input statements used in a constraint-based procedure. These are subsequently processed in decreasing order of reliability, letting more reliable decisions take precedence in case of conflicts, until a single output model is obtained. Tests show that a basic implementation of the resulting Bayesian Constraint-based Causal Discovery (BCCD) algorithm already outperforms established procedures such as FCI and Conservative PC. It indicates which causal decisions in the output have high reliability and which do not. The approach is easily adapted to other application areas such as complex independence tests.

#index 2033255
#* Satisfiability modulo constraint handling rules (extended abstract)
#@ Gregory J. Duck
#t 2013
#c 11
#% 327779
#% 1211661
#% 1415274
#% 1586164
#% 1707011
#% 1738637
#% 1946299
#! Satisfiability Modulo Constraint Handling Rules (SMCHR) is the integration of the Constraint Handling Rules (CHRs) solver programming language into a Satisfiability Modulo Theories (SMT) solver framework. Constraint solvers are implemented in CHR as a set of high-level rules that specify the simplification (rewriting) and constraint propagation behavior. The traditional CHR execution algorithm manipulates a global store representing a flat conjunction of constraints. This paper introduces SMCHR: a tight integration of CHR with a modern Boolean Satisfiability (SAT) solver. Unlike CHR, SMCHR can handle (quantifier-free) formulae with an arbitrary propositional structure. SMCHR is essentially a Satisfiability Modulo Theories (SMT) solver where the theory T is implemented in CHR.

#index 2033256
#* Case adaptation with qualitative algebras
#@ Valmi Dufour-Lussier;Florence Le Ber;Jean Lieber;Laura Martin
#t 2013
#c 11
#% 109945
#% 319244
#% 405727
#% 486486
#% 490598
#% 490923
#% 1099636
#% 1253016
#% 1389759
#% 1655685
#% 1706028
#% 1737341
#! This paper proposes an approach for the adaptation of spatial or temporal cases in a case-based reasoning system. Qualitative algebras are used as spatial and temporal knowledge representation languages. The intuition behind this adaptation approach is to apply a substitution and then repair potential inconsistencies, thanks to belief revision on qualitative algebras. A temporal example from the cooking domain is given.

#index 2033257
#* Improving the effectiveness of time-based display advertising (extended abstract)
#@ Daniel G. Goldstein;R, Preston McAfee;Siddharth Suri
#t 2013
#c 11
#% 1584776
#% 1783966
#! CPM or cost per thousand impressions is the prevalent metric used for selling online display ads. In previous work, we have shown that the exposure duration of an ad has strong effects on the likelihood of an ad being remembered [Goldstein et al., 2011], with the first seconds of exposure having the greatest impact on memory. Because an ad pricing metric that is based on both time and impressions should be more exact than one based on impressions alone, the industry has good reasons to move towards time-based advertising. We address the following unanswered question: how should time-based ads be scheduled? We test and present one schedule that leads to greater total recollection, which advertisers want, and increased revenue, which publishers want. First, we find that presenting two short, successive ads results in more total recollection than presenting one longer ad of twice the duration. Second, we show that this effect disappears as the duration of these ads increases. Together, these findings suggest a form of time-based ad pricing that should appeal to advertisers and publishers alike.

#index 2033258
#* Preference-based CBR: general ideas and basic principles
#@ Eyke Hüllermeier;Weiwei Cheng
#t 2013
#c 11
#% 168280
#% 176887
#% 920488
#% 1417383
#% 1565896
#% 1745348
#! Building on recent research on preference handling in artificial intelligence and related fields, our goal is to develop a coherent and generic methodological framework for case-based reasoning (CBR) on the basis of formal concepts and methods for knowledge representation and reasoning with preferences. A preference-based approach to CBR appears to be appealing for several reasons, notably because case-based experiences naturally lend themselves to representations in terms of preference or order relations. Moreover, the flexibility and expressiveness of a preference-based formalism well accommodate the uncertain and approximate nature of case-based problem solving. In this paper, we outline the basic ideas of preference-based CBR and sketch a formal framework for realizing these ideas.

#index 2033259
#* Sound, complete, and minimal query rewriting for existential rules
#@ Mélanie König;Michel Leclère;Marie-Laure Mugnier;Michaël Thomazo
#t 2013
#c 11
#% 465511
#% 992962
#% 1217122
#% 1279259
#% 1305397
#% 1333459
#% 1500877
#% 1585244
#% 1594576
#% 1615741
#% 1619617
#% 1826177
#% 1826217
#% 1933380
#! We address the issue of Ontology-Based Data Access which consists of exploiting the semantics expressed in ontologies while querying data. Ontologies are represented in the framework of existential rules, also known as Datalog+/-. We focus on the backward chaining paradigm, which involves rewriting the query (assumed to be a conjunctive query, CQ) into a set of CQs (seen as a union of CQs). The proposed algorithm accepts any set of existential rules as input and stops for so-called finite unification sets of rules (fus). The rewriting step relies on a graph notion, called a piece, which allows to identify subsets of atoms from the query that must be processed together. We first show that our rewriting method computes a minimal set of CQs when this set is finite, i.e., the set of rules is a fus. We then focus on optimizing the rewriting step. First experiments are reported in the associated technical report.

#index 2033260
#* Collaborative filtering on ordinal user feedback
#@ Yehuda Koren;Joseph Sill
#t 2013
#c 11
#% 983903
#% 1083671
#% 1260273
#% 1541728
#% 1625358
#! We propose a collaborative filtering (CF) recommendation framework which is based on viewing user feedback on products as ordinal, rather than the more common numerical view. Such an ordinal view frequently provides a more natural reflection of the user intention when providing qualitative ratings, allowing users to have different internal scoring scales. Moreover, we can address scenarios where assigning numerical scores to different types of user feedback would not be easy. The framework can wrap most collaborative filtering algorithms, enabling algorithms previously designed for numerical values to handle ordinal values. We demonstrate our framework by wrapping a leading matrix factorization CF method. A cornerstone of our method is its ability to predict a full probability distribution of the expected item ratings, rather than only a single score for an item. One of the advantages this brings is a novel approach to estimating the confidence level in each individual prediction. Compared to previous approaches to confidence estimation, ours is more principled and empirically superior in its accuracy. We demonstrate the efficacy of the approach on two of the largest publicly available datasets: the Netflix data and the Yahoo! Music data.

#index 2033261
#* Three semantics for the core of the distributed ontology language (extended abstract)
#@ Till Mossakowski;Christoph Lange;Oliver Kutz
#t 2013
#c 11
#% 189739
#% 481998
#% 763751
#% 1274824
#% 1297721
#% 1882345
#! The Distributed Ontology Language DOL, currently being standardized as ISO WD 17347 within the OntoIOp (Ontology Integration and Interoperability) activity of ISO/TC 37, provides a unified framework for (1) ontologies formalized in heterogeneous logics, (2) modular ontologies, (3) links between ontologies, and (4) ontology annotation. A DOL ontology consists of modules formalized in languages such as OWL or Common Logic, serialized in the existing syntaxes of these languages. On top, DOL's meta level allows for expressing heterogeneous ontologies and links between ontologies, including (heterogeneous) imports and alignments, conservative extensions, and theory interpretations. We present the abstract syntax of these meta-level constructs, with three alternative semantics: direct, translational, and collapsed semantics.

#index 2033262
#* Discovering alignments in ontologies of linked data
#@ Rahul Parundekar;Craig A. Knoblock;José Luis Ambite
#t 2013
#c 11
#% 924747
#% 1409921
#% 1413155
#% 1540317
#% 1540329
#% 1567959
#% 1597469
#% 1597472
#% 1942722
#% 1942747
#! Recently, large amounts of data are being published using Semantic Web standards. Simultaneously, there has been a steady rise in links between objects from multiple sources. However, the ontologies behind these sources have remained largely disconnected, thereby challenging the interoperability goal of the Semantic Web. We address this problem by automatically finding alignments between concepts from multiple linked data sources. Instead of only considering the existing concepts in each ontology, we hypothesize new composite concepts, defined using conjunctions and disjunctions of (RDF) types and value restrictions, and generate alignments between them. In addition, our techniques provide a novel method for curating the linked data web by pointing to likely incorrect or missing assertions. Our approach provides a deeper understanding of the relationships between linked data sources and increases the interoperability among previously disconnected ontologies.

#index 2033263
#* A new trajectory deformation algorithm based on affine transformations
#@ Quang-Cuong Pham;Yoshihiko Nakamura
#t 2013
#c 11
#% 139225
#% 213538
#% 214513
#% 252784
#% 279824
#% 771054
#% 1428097
#% 1524769
#% 1768635
#% 1786332
#% 1868832
#! We propose a method to deform robot trajectories based on affine transformations. At the heart of our approach is the concept of affine invariance: trajectories are deformed in order to avoid unexpected obstacles or to attain new goals but, at the same time, certain precise features of the original motions are preserved. Such features include for instance trajectory smoothness, periodicity, affine velocity, or more generally, all affine-invariant features, which are of particular importance in human-centered applications. Furthermore, the proposed method is very efficient and easy to implement: there is no need to re-integrate even a part of the trajectory and, in most cases, closed-form solutions can be worked out. The method is also versatile: optimization of geometric and dynamics parameters or satisfaction of inequality constraints can be taken into account in a very natural way. As illustration, we present a method for transferring human motions to humanoid robots while preserving equiaffine velocity. Building on the presented affine deformation framework, we finally revisit the concept of trajectory redundancy from the viewpoint of group theory.

#index 2033264
#* A case-based solution to the cold-start problem in group recommenders
#@ Lara Quijano-Sánchez;Derek Bridge;Belén Díaz-Agudo;Juan A. Recio-García
#t 2013
#c 11
#% 220709
#% 342767
#% 490917
#% 490937
#% 578684
#% 712016
#% 733578
#% 1396093
#% 1396104
#% 1536564
#% 1932854
#! In this paper we offer a potential solution to the cold-start problem in group recommender systems. To do so, we use information about previous group recommendation events and copy ratings from a user who played a similar role in some previous group event. We show that copying in this way, i.e. conditioned on groups, is superior to copying nothing and also superior to copying ratings from the most similar user known to the system.

#index 2033265
#* Data mining a trillion time series subsequences under dynamic time warping
#@ Thanawin Rakthanmanon;Bilson Campana;Abdullah Mueen;Gustavo Batista;Brandon Westover;Qiang Zhu;Jesin Zakaria;Eamonn Keogh
#t 2013
#c 11
#% 91091
#% 462231
#% 564263
#% 643518
#% 729931
#% 740761
#% 809264
#% 998813
#% 1066734
#% 1127609
#% 1132575
#% 1173744
#% 1206865
#% 1211645
#% 1214716
#% 1246209
#% 1451249
#% 1538191
#% 1590537
#% 1754971
#% 1872261
#! Most time series data mining algorithms use similarity search as a core subroutine, and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms. The difficulty of scaling search to large datasets largely explains why most academic work on time series data mining has plateaued at considering a few millions of time series objects, while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine truly massive time series for the first time. We demonstrate the following extremely unintuitive fact; in large datasets we can exactly search under DTW much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. We show that our ideas allow us to solve higher-level time series data mining problems at scales that would otherwise be untenable.

#index 2033266
#* On stochastic optimal control and reinforcement learning by approximate inference (extended abstract)
#@ Konrad Rawlik;Marc Toussaint;Sethu Vijayakumar
#t 2013
#c 11
#% 384911
#% 891559
#% 1044118
#% 1211821
#! We present a reformulation of the stochastic optimal control problem in terms of KL divergence minimisation, not only providing a unifying perspective of previous approaches in this area, but also demonstrating that the formalism leads to novel practical approaches to the control problem. Specifically, a natural relaxation of the dual formulation gives rise to exact iterative solutions to the finite and infinite horizon stochastic optimal control problem, while direct application of Bayesian inference methods yields instances of risk sensitive control.

#index 2033267
#* At home with agents: exploring attitudes towards future smart energy infrastructures
#@ Tom A. Rodden;Joel E. Fischer;Nadia Pantidi;Khaled Bachour;Stuart Moran
#t 2013
#c 11
#% 906715
#% 1384316
#% 1399001
#% 1582167
#% 1613905
#% 1701755
#% 1765189
#% 1973301
#! This paper considers how consumers might relate to future smart energy grids. We used animated sketches to convey the nature of a future energy infrastructure based on software agents. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome software agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to design agents to enhance trust in these socio-economic settings.

#index 2033268
#* Decision generalisation from game logs in no limit texas Hold'em
#@ Jonathan Rubin;Ian Watson
#t 2013
#c 11
#% 1083975
#% 1215785
#% 1279308
#% 1305334
#% 1333072
#% 1560594
#% 1737344
#% 1745374
#! Given a set of data, recorded by observing the decisions of an expert player, we present a case-based framework that allows the successful generalisation of those decisions in the game of no limit Texas Hold'em. We address the problems of determining a suitable action abstraction and the resulting state translation that is required to map real-value bet amounts into a discrete set of abstract actions. We also detail the similarity metrics used in order to identify similar scenarios, without which no generalisation of playing decisions would be possible. We show that we were able to successfully generalise no limit betting decisions from recorded data via our agent, SartreNL, which achieved a 5th place finish out of 11 opponents at the 2012 Annual Computer Poker Competition.

#index 2033269
#* Modeling the interplay of people's location, interactions, and social ties
#@ Adam Sadilek;Henry Kautz;Jeffrey P. Bigham
#t 2013
#c 11
#% 716892
#% 955712
#% 989580
#% 1124987
#% 1289474
#% 1399939
#% 1606049
#% 1693933
#! Location plays an essential role in our lives, bridging our online and offline worlds. This paper explores the interplay of people's location, interactions, and social ties within a large real-world dataset. We present and evaluate Flap, a system that solves two intimately related tasks: link and location prediction in online social networks. For link prediction, Flap infers social ties by considering patterns in friendship formation, the content of people's messages, and user location. We show that while each component is a weak predictor of friendship alone, combining them results in a strong model--accurately identifying the majority of friendships. For location prediction, Flap implements a scalable probabilistic model of human mobility, where we treat users with known GPS positions as noisy sensors of the location of their friends. We explore supervised and unsupervised learning scenarios, and focus on the efficiency of both learning and inference. We evaluate Flap on a large sample of highly active users from two distinct geographical areas and show that it (1) reconstructs the entire friendship graph with high accuracy even when no edges are given; and (2) infers people's fine-grained location, even when they keep their data private and we can only access the location of their friends. Our models significantly outperform current approaches to either task.

#index 2033270
#* Active evaluation of ranking functions based on graded relevance (extended abstract)
#@ Christoph Sawade;Steffen Bickel;Timo Von Oertzen;Tobias Scheffer;Niels Landwehr
#t 2013
#c 11
#% 400847
#% 411762
#% 879598
#% 879632
#% 989628
#% 1019126
#% 1292528
#% 1450862
#% 1925641
#! Evaluating the quality of ranking functions is a core task in web search and other information retrieval domains. Because query distributions and item relevance change over time, ranking models often cannot be evaluated accurately on held-out training data. Instead, considerable effort is spent on manually labeling the relevance of query results for test queries in order to track ranking performance. We address the problem of estimating ranking performance as accurately as possible on a fixed labeling budget. Estimates are based on a set of most informative test queries selected by an active sampling distribution. Query labeling costs depend on the number of result items and item-specific attributes such as document length. We derive cost-optimal sampling distributions for commonly used ranking performance measures. Experiments on web search engine data illustrate significant reductions in labeling costs.

#index 2033271
#* CLiMF: collaborative less-is-more filtering
#@ Yue Shi;Alexandros Karatzoglou;Linas Baltrunas;Martha Larson;Nuria Oliver;Alan Hanjalic
#t 2013
#c 11
#% 173879
#% 813966
#% 879618
#% 987226
#% 1176909
#% 1417104
#% 1442575
#% 1450857
#% 1476448
#% 1476471
#% 1625359
#% 1625387
#! In this paper we tackle the problem of recommendation in the scenarios with binary relevance data, when only a few (k) items are recommended to individual users. Past work on Collaborative Filtering (CF) has either not addressed the ranking problem for binary relevance datasets, or not specifically focused on improving top-k recommendations. To solve the problem we propose a new CF approach, Collaborative Less-is-More Filtering (CLiMF). In CLiMF the model parameters are learned by directly maximizing the Mean Reciprocal Rank (MRR), which is a well-known information retrieval metric for capturing the performance of top-k recommendations. We achieve linear computational complexity by introducing a lower bound of the smoothed reciprocal rank metric. Experiments on two social network datasets show that CLiMF significantly outperforms a naive baseline and two state-of-the-art CF methods.

#index 2033272
#* Statistical parsing with probabilistic symbol-refined tree substitution grammars
#@ Hiroyuki Shindo;Yusuke Miyao;Akinori Fujino;Masaaki Nagata
#t 2013
#c 11
#% 740916
#% 741115
#% 817472
#% 939353
#% 939555
#% 1270684
#% 1270788
#% 1272272
#% 1310396
#% 1338690
#% 1470565
#% 1471290
#% 1551201
#% 1913289
#! We present probabilistic Symbol-Refined Tree Substitution Grammars (SR-TSG) for statistical parsing of natural language sentences. An SR-TSG is an extension of the conventional TSG model where each nonterminal symbol can be refined (subcategorized) to fit the training data. Our probabilistic model is consistent based on the hierarchical Pitman-Yor Process to encode backoff smoothing from a fine-grained SR-TSG to simpler CFG rules, thus all grammar rules can be learned from training data in a fully automatic fashion. Our SR-TSG parser achieves the state-of-the-art performance on the Wall Street Journal (WSJ) English Penn Tree-bank data.

#index 2033273
#* Exact recovery of sparsely-used dictionaries
#@ Daniel A. Spielman;Huan Wang;John Wright
#t 2013
#c 11
#% 856216
#% 969915
#% 1211776
#% 1403235
#% 1494031
#% 1759275
#% 1861541
#! We consider the problem of learning sparsely used dictionaries with an arbitrary square dictionary and a random, sparse coefficient matrix. We prove that O(n log n) samples are sufficient to uniquely determine the coefficient matrix. Based on this proof, we design a polynomial-time algorithm, called Exact Recovery of Sparsely-Used Dictionaries (ERSpUD), and prove that it probably recovers the dictionary and coefficient matrix when the coefficient matrix is sufficiently sparse. Simulation results show that ER-SpUD reveals the true dictionary as well as the coefficients with probability higher than many state-of-the-art algorithms.

#index 2033274
#* The roboearth language: representing and exchanging knowledge about actions, objects, and environments (extended abstract)
#@ Moritz Tenorth;Alexander Perzylo;Reinhard Lafrenz;Michael Beetz
#t 2013
#c 11
#% 179879
#% 198055
#% 1996236
#! The community-based generation of content has been tremendously successful in the World Wide Web - people help each other by providing information that could be useful to others. We are trying to transfer this approach to robotics in order to help robots acquire the vast amounts of knowledge needed to competently perform everyday tasks. RoboEarth is intended to be a web community by robots for robots to autonomously share descriptions of tasks they have learned, object models they have created, and environments they have explored. In this paper, we report on the formal language we developed for encoding this information and present our approaches to solve the inference problems related to finding information, to determining if information is usable by a robot, and to grounding it on the robot platform.

#index 2033275
#* Socioscope: spatio-temporal signal recovery from social media (extended abstract)
#@ Jun-Ming Xu;Aniruddha Bhargava;Robert Nowak;Xiaojin Zhu
#t 2013
#c 11
#% 262042
#% 350859
#% 869516
#% 1400018
#% 1432574
#% 1481659
#% 1560379
#% 1560410
#% 1711859
#% 1816821
#% 1925639
#! Counting the number of social media posts on a target phenomenon has become a popular method to monitor a spatiotemporal signal. However, such counting is plagued by biased, missing, or scarce data. We address these issues by formulating signal recovery as a Poisson point process estimation problem. We explicitly incorporate human population bias, time delays and spatial distortions, and spatiotemporal regularization into the model to address the data quality issues. Our model produces qualitatively convincing results in a case study on wildlife roadkill monitoring.

#index 2033276
#* Using strategic logics to reason about agent programs
#@ Nitin Yadav;Sebastian Sardina
#t 2013
#c 11
#% 413871
#% 797745
#% 890363
#% 890409
#% 1021270
#% 1024764
#% 1269796
#% 1275454
#% 1453172
#% 1925330
#! We propose a variant of Alternating-time Temporal Logic (ATL) grounded in the agents' operational know-how, as defined by their libraries of abstract plans. In our logic, it is possible to refer to "rational" strategies for agents developed under the Belief-Desire-Intention agent paradigm. This allows us to express and verify properties of BDI systems using ATL-type logical frameworks.

#index 2033277
#* User-centered programming by demonstration: stylistic elements of behavior
#@ James E. Young;Kentaro Ishii;Takeo Igarashi;Ehud Sharlin
#t 2013
#c 11
#% 65000
#% 297548
#% 751859
#% 781492
#% 948098
#% 1041880
#% 1274956
#% 1280918
#% 1729372
#% 1986668
#! User-Centered Programming by Demonstration is an approach that places the needs of people above algorithmic constraints and requirements. In this paper we present a user-centered programming by demonstration project for authoring interactive robotic locomotion style. The style in which a robot moves about a space, expressed through its motions, can be used for communication. For example, a robot could move aggressively in reaction to a person's actions, or alternatively react using careful, submissive movements. We present a new demonstration interface, algorithm, and evaluation results.

#index 2033278
#* Scalable dynamic nonparametric Bayesian models of content and users
#@ Amr Ahmed;Eric Xing
#t 2013
#c 11
#% 722904
#% 875959
#% 1214625
#% 1481646
#% 1523858
#% 1536572
#% 1560381
#% 1605925
#% 1693873
#% 2018575
#! Online content have become an important medium to disseminate information and express opinions. With their proliferation, users are faced with the problem of missing the big picture in a sea of irrelevant and/or diverse content. In this paper, we addresses the problem of information organization of online document collections, and provide algorithms that create a structured representation of the otherwise unstructured content. We leverage the expressiveness of latent probabilistic models (e.g., topic models) and non-parametric Bayes techniques (e.g., Dirichlet processes), and give online and distributed inference algorithms that scale to terabyte datasets and adapt the inferred representation with the arrival of new documents. This paper is an extended abstract of the 2012 ACM SIGKDD best doctoral dissertation award of Ahmed [2011].

#index 2033279
#* Improving combinatorial optimization: extended abstract
#@ Geoffrey Chu
#t 2013
#c 11
#% 48667
#% 157466
#% 274131
#% 298743
#% 428195
#% 497307
#% 534837
#% 717227
#% 741333
#% 1191486
#% 1272064
#% 1289394
#% 1399096
#% 1412949
#% 1412950
#% 1412951
#% 1412958
#% 1549956
#% 1694449
#% 1737839
#% 1748407
#% 1826145
#! Combinatorial Optimization is an important area of computer science that has many theoretical and practical applications. In the thesis [Chu, 2011], we present important contributions to several different areas of combinatorial optimization, including nogood learning, symmetry breaking, dominance, relaxations and parallelization. We develop a new nogood learning technique based on constraint projection that allows us to exploit subproblem dominances that arise when two different search paths lead to subproblems which are identical on the remaining unfixed variables. We present a new symmetry breaking technique called SBDS-1UIP, which extends Symmetry Breaking During Search (SBDS) by using the more powerful 1UIP nogoods generated by Lazy Clause Generation (LCG) solvers. We present two new general methods for exploiting almost symmetries by modifying SBDS-1UIP and by using conditional symmetry breaking constraints. We solve the Minimization of Open Stacks Problem, the Talent Scheduling Problem (CSPLib prob039), and the Maximum Density Still Life Problem (CSPLib prob032) many orders of magnitude faster than the previous state of the art by applying various powerful techniques such as nogood learning, dynamic programming, dominance and relaxations. We present cache aware data structures for SAT solvers which allows sequential and parallel versions of SAT solvers to run more quickly. And we present a new load balancing scheme for parallel search called confidence based work stealing, which allows the parallel search to make use of the information contained in the branching heuristic.

#index 2033280
#* Cultural diversity for virtual characters (extended abstract)
#@ Birgit Endrass
#t 2013
#c 11
#% 332677
#% 445555
#% 838152
#% 1100227
#% 1108712
#% 1215552
#% 1263762
#% 1273868
#% 1453070
#% 1498602
#% 1669451
#% 1738392
#! In human conversation, meaning is transported through several channels such as verbal and nonverbal behavior. Certain of these behavioral aspects are culturally dependent. Mutual understanding or acceptance is thus, amongst others, depended on the cultural background of the interlocutors. When designing virtual character behavior, culture should be considered as it may improve the character's acceptance by users of certain cultural backgrounds. This paper proposes a hybrid approach for the generation of culture-specific behaviors in a multiagent system. A computational model has been established by refining theoretical knowledge of culture-specific behavior with statistical data extracted from a video corpus of German and Japanese first-time meetings. Evaluation studies of such culturally enhanced virtual characters were conducted in both targeted cultures. Results indicate that human observers tend to prefer character behavior that was designed to resemble their own cultural background.

#index 2033281
#* Landmark-based heuristics and search control for automated planning (extended abstract)
#@ Silvia Richter
#t 2013
#c 11
#% 251783
#% 1076644
#% 1223554
#% 1270243
#% 1271962
#% 1272047
#% 1272113
#% 1272145
#% 1473265
#% 1545553
#! Automated planning is the process of automatically selecting actions that achieve a desired outcome. This paper summarises several contributions that improve the efficiency of automated planning via heuristic search. We discuss novel heuristics based on landmarks and a search algorithm for anytime planning. Furthermore, we analyse various search-enhancement techniques and show how the combination of these techniques lead to a planning system that proved highly successful in the 2008 and 2011 International Planning Competitions.

#index 2033282
#* Learning probabilistic models for mobile manipulation robots
#@ Jürgen Sturm;Wolfram Burgard
#t 2013
#c 11
#% 1305586
#% 1342475
#% 1368277
#% 1631461
#% 1868814
#% 2002344
#! Mobile manipulation robots are envisioned to provide many useful services both in domestic environments as well as in the industrial context. In this paper, we present novel approaches to allow mobile maniplation systems to autonomously adapt to new or changing situations. The approaches developed in this paper cover the following four topics: (1) learning the robot's kinematic structure and properties using actuation and visual feedback, (2) learning about articulated objects in the environment in which the robot is operating, (3) using tactile feedback to augment visual perception, and (4) learning novel manipulation tasks from human demonstrations.

#index 2033283
#* Social norms for self-policing multi-agent systems and virtual societies (extended abstract)
#@ Daniel Villatoro
#t 2013
#c 11
#% 160038
#% 1215798
#% 1274996
#% 1503913
#% 1617596
#% 1826129
#% 1826130
#% 1875862
#! Social norms are one of the mechanisms for decentralized societies to achieve coordination amongst individuals. Such norms are conflict resolution strategies that develop from the population interactions instead of a centralized entity dictating agent protocol. One of the most important characteristics of social norms is that they are imposed by the members of the society, and they are responsible for the fulfillment and defense of these norms. By allowing agents to manage (impose, abide by and defend) social norms, societies achieve a higher degree of freedom by lacking the necessity of authorities supervising all the interactions amongst agents. In this article we summarize the contributions of my dissertation, where we provide an unifying framework for the analysis of social norms in virtual societies, providing an strong emphasis on virtual agents and humans.

#index 2033284
#* Evaluating indirect strategies for Chinese-Spanish statistical machine translation: extended abstract
#@ Marta R. Costa-Jussà;Carlos A. Henríquez;Rafael E. Banchs
#t 2013
#c 11
#% 816170
#% 1915294
#% 1956751
#! Although, Chinese and Spanish are two of the most spoken languages in the world, not much research has been done in machine translation for this language pair. This paper focuses on investigating the state-of-the-art of Chinese-to-Spanish statistical machine translation (SMT), which nowadays is one of the most popular approaches to machine translation. We conduct experimental work with the largest of these three corpora to explore alternative SMT strategies by means of using a pivot language. Three alternatives are considered for pivoting: cascading, pseudo-corpus and triangulation. As pivot language, we use either English, Arabic or French. Results show that, for a phrase-based SMT system, English is the best pivot language between Chinese and Spanish. We propose a system output combination using the pivot strategies which is capable of outperforming the direct translation strategy. The main objective of this work is motivating and involving the research community to work in this important pair of languages given their demographic impact.

#index 2033285
#* Communicating open systems (extended abstract)
#@ Mark D'Inverno;Michael Luck;Pablo Noriega;Juan A. Rodriguez-Aguilar;Carles Sierra
#t 2013
#c 11
#% 193423
#% 251966
#% 431490
#% 636363
#% 741966
#% 1084271
#% 1388842
#% 1768047
#! Just as conventional institutions are organisational structures for coordinating the activities of multiple interacting individuals, electronic institutions provide a computational analogue for coordinating the activities of multiple interacting software agents. In this paper, we argue that open multi-agent systems can be effectively designed and implemented as electronic institutions, for which we provide a comprehensive computational model. More specifically, the paper provides an operational semantics for electronic institutions, specifying the essential data structures, the state representation and the key operations necessary to implement them.

#index 2033286
#* The CQC algorithm: cycling in graphs to semantically enrich and enhance a bilingual dictionary (extended abstract)
#@ Tiziano Flati;Roberto Navigli
#t 2013
#c 11
#% 131434
#% 268079
#% 286069
#% 420471
#% 689546
#% 744285
#% 748241
#% 756595
#% 756952
#% 814007
#% 938759
#% 939905
#% 1131827
#% 1251606
#% 1260668
#% 1260731
#% 1272241
#% 1328332
#% 1366325
#% 1471332
#% 1747943
#% 1911337
#% 1919042
#! Bilingual machine-readable dictionaries are knowledge resources useful in many automatic tasks. However, compared to monolingual computational lexicons like WordNet, bilingual dictionaries typically provide a lower amount of structured information such as lexical and semantic relations, and often do not cover the entire range of possible translations for a word of interest. In this paper we present Cycles and Quasi-Cycles (CQC), a novel algorithm for the automated disambiguation of ambiguous translations in the lexical entries of a bilingual machine-readable dictionary.

#index 2033287
#* Algorithms for generating ordered solutions for explicit AND/OR structures: extended abstract
#@ Priyankar Ghosh;Amit Sharma;P. P. Chakrabarti;Pallab Dasgupta
#t 2013
#c 11
#% 241
#% 25470
#% 60874
#% 269922
#% 424793
#% 480382
#% 944140
#% 1108514
#% 1122372
#% 1231843
#% 1274275
#% 1894299
#% 1911356
#! We present algorithms for generating alternative solutions for explicit acyclic AND/OR structures in non-decreasing order of cost. Our algorithms use a best first search technique and report the solutions using an implicit representation ordered by cost. Experiments on randomly constructed AND/OR DAGs and problem domains including matrix chain multiplication, finding the secondary structure of RNA, etc, show that the proposed algorithms perform favorably to the existing approach in terms of time and space.

#index 2033288
#* YAGO2: a spatially and temporally enhanced knowledge base from wikipedia (extended abstract)
#@ Johannes Hoffart;Fabian M. Suchanek;Klaus Berberich;Gerhard Weikum
#t 2013
#c 11
#% 198055
#% 956564
#% 1269899
#% 1275182
#% 1288161
#% 1292517
#% 1409954
#% 1711796
#% 1925700
#% 1925702
#% 1992101
#! We present YAGO2, an extension of the YAGO knowledge base, in which entities, facts, and events are anchored in both time and space. YAGO2 is built automatically from Wikipedia, GeoNames, and WordNet. It contains 447 million facts about 9.8 million entities. Human evaluation confirmed an accuracy of 95% of the facts in YAGO2. In this paper, we present the extraction methodology and the integration of the spatio-temporal dimension.

#index 2033289
#* Modeling social causality and responsibility judgment in multi-agent interactions: extended abstract
#@ Wenji Mao;Jonathan Gratch
#t 2013
#c 11
#% 145393
#% 199215
#% 484333
#% 895698
#% 1272043
#% 1586145
#% 1650516
#% 1911355
#! Based on psychological attribution theory, this paper presents a domain-independent computational model to automate social causality and responsibility judgment according to an agent's causal knowledge and observations of interaction. The proposed model is also empirically validated via experimental study.

#index 2033290
#* The extended global cardinality constraint: an empirical survey (extended abstract)
#@ Peter Nightingale
#t 2013
#c 11
#% 70370
#% 160208
#% 816230
#% 1136353
#% 1398245
#% 1412936
#% 1412940
#% 1499496
#% 1526851
#% 1732428
#! The Extended Global Cardinality Constraint (EGCC) is an important component of constraint solving systems, since it is very widely used to model diverse problems. The literature contains many different versions of this constraint, which trade strength of inference against computational cost. In this paper, I focus on the highest strength of inference usually considered, enforcing generalized arc consistency (GAC) on the target variables. This work is an extensive empirical survey of algorithms and optimizations, considering both GAC on the target variables, and tightening the bounds of the cardinality variables. I evaluate a number of key techniques from the literature, and report important implementation details of those techniques, which have often not been described in published papers. Two new optimizations are proposed for EGCC. One of the novel optimizations (dynamic partitioning, generalized from AllDifferent) was found to speed up search by 5.6 times in the best case and 1.56 times on average, while exploring the same search tree. The empirical work represents by far the most extensive set of experiments on variants of algorithms for EGCC. Overall, the best combination of optimizations gives a mean speedup of 4.11 times compared to the same implementation without the optimizations.

#index 2033291
#* Revisiting centrality-as-relevance: support sets and similarity as geometric proximity: extended abstract
#@ Ricardo Ribeiro;David Martins De Matos
#t 2013
#c 11
#% 129655
#% 262112
#% 268079
#% 290830
#% 340884
#% 352869
#% 465031
#% 742225
#% 818227
#% 818241
#% 992313
#% 1150045
#% 1223706
#% 1264286
#% 1272053
#% 1395709
#% 1411731
#% 1465383
#% 1765803
#! In automatic summarization, centrality-as-relevance means that the most important content of an information source, or of a collection of information sources, corresponds to the most central passages, considering a representation where such notion makes sense (graph, spatial, etc.). We assess the main paradigms and introduce a new centrality-based relevance model for automatic summarization that relies on the use of support sets to better estimate the relevant content. Geometric proximity is used to compute semantic relatedness. Centrality (relevance) is determined by considering the whole input source (and not only local information), and by taking into account the existence of minor topics or lateral subjects in the information sources to be summarized. The method consists in creating, for each passage of the input source, a support set consisting only of the most semantically related passages. Then, the determination of the most relevant content is achieved by selecting the passages that occur in the largest number of support sets. This model produces extractive summaries that are generic, and language- and domain-independent. Thorough automatic evaluation shows that the method achieves state-of-the-art performance, both in written text, and automatically transcribed speech summarization, even when compared to considerably more complex approaches.

#index 2033292
#* Generalized biwords for bitext compression and translation spotting: extended abstract
#@ Felipe Sánchez-Martínez;Rafael C. Carrasco;Miguel A. Martínez-Prieto;Joaquín Adiego
#t 2013
#c 11
#% 57849
#% 115608
#% 143009
#% 143306
#% 401434
#% 438325
#% 579944
#% 843741
#% 854858
#% 931332
#% 936965
#% 939363
#% 958443
#% 1205299
#% 1264756
#% 1267025
#% 1267026
#% 1346124
#% 1368917
#% 1418527
#% 1587328
#% 1701328
#% 1911344

#index 2033293
#* Computing text semantic relatedness using the contents and links of a hypertext encyclopedia: extended abstract
#@ Majid Yazdani;Andrei Popescu-Belis
#t 2013
#c 11
#% 325502
#% 342963
#% 641979
#% 730089
#% 1069003
#% 1366325
#% 1442580
#% 1516579
#% 1826503
#% 1925707
#! We propose methods for computing semantic relatedness between words or texts by using knowledge from hypertext encyclopedias such as Wikipedia. A network of concepts is built by filtering the encyclopedia's articles, each concept corresponding to an article. A random walk model based on the notion of Visiting Probability (VP) is employed to compute the distance between nodes, and then between sets of nodes. To transfer learning from the network of concepts to text analysis tasks, we develop two common representation approaches. In the first approach, the shared representation space is the set of concepts in the network and every text is represented in this space. In the second approach, a latent space is used as the shared representation, and a transformation from words to the latent space is trained over VP scores. We applied our methods to four important tasks in natural language processing: word similarity, document similarity, document clustering and classification, and ranking in information retrieval. The performance is state-of-the-art or close to it for each task, thus demonstrating the generality of the proposed knowledge resource and the associated methods.

#index 2033294
#* On the approximation ability of evolutionary optimization with application to minimum set cover: extended abstract
#@ Yang Yu;Xin Yao;Zhi-Hua Zhou
#t 2013
#c 11
#% 207195
#% 256685
#% 334205
#% 477874
#% 478054
#% 502378
#% 578305
#% 811613
#% 833346
#% 985928
#% 1073124
#% 1090851
#% 1108330
#% 1173448
#% 1225805
#% 1330033
#% 1356559
#% 1541763
#% 1542707
#% 1586855
#% 1707149
#! Evolutionary algorithms (EAs) are a large family of heuristic optimization algorithms inspired by natural phenomena, and are often used in practice to obtain satisficing instead of optimal solutions. In this work, we investigate a largely underexplored issue: the approximation performance of EAs in terms of how close the obtained solution is to an optimal solution. We study an EA framework named simple EA with isolated population (SEIP) that can be implemented as a single- or multi-objective EA. We present general approximation results of SEIP, and specifically on the minimum set cover problem, we find that SEIP achieves the currently best-achievable approximation ratio. Moreover, on an instance class of the k-set cover problem, we disclose how SEIP can overcome the difficulty that limits the greedy algorithm.

#index 2033295
#* Learning qualitative models from numerical data: extended abstract
#@ Jure Žabkar;Martin Možina;Ivan Bratko;Janez Demšar
#t 2013
#c 11
#% 1115
#% 1116
#% 6200
#% 212219
#% 226441
#% 229931
#% 444743
#% 458625
#% 741451
#% 1272235
#% 1478570
#% 1585250
#! Qualitative models are predictive models that describe how changes in values of input variables affect the output variable in qualitative terms, e.g. increasing or decreasing. We describe Padé, a new method for qualitative learning which estimates partial derivatives of the target function from training data and uses them to induce qualitative models of the target function. We formulated three methods for computation of derivatives, all based on using linear regression on local neighbourhoods. The methods were empirically tested on artificial and real-world data. We also provide a case study which shows how the developed methods can be used in practice.

#index 2033296
#* Decision-theoretic approximations for machine learning
#@ M. Ehsan Abbasnejad
#t 2013
#c 11
#% 1279253
#! Decision theory focuses on the problem of making decisions under uncertainty. This uncertainty arises from the unknown aspects of the state of the world the decision maker is in or the unknown utility function of performing actions. The uncertainty can be modeled as a probability distribution capturing our belief about the world the decision maker is in. Upon making new observations, the decision maker becomes more confident about this model. In addition, if there is a prior belief on this uncertainty that may have obtained from similar experiments, the Bayesian methods may be employed. The loss incurred by the decision maker can also be utilized for the optimal action selection. Most machine learning algorithms developed though focus on one of these aspects for learning and prediction; either learning the probabilistic model or minimizing the loss. In probabilistic models, approximate inference, the process of obtaining the desired model from the observations when its is not tractable, does not consider the task loss. On the other end of the spectrum, the common practice in learning is to minimize the task loss without considering the uncertainty of prediction model. Therefore, we investigate the intersection of decision theory and machine learning considering both uncertainty in prediction model and the task loss.

#index 2033297
#* Managing qualitative preferences and constraints in a dynamic environment
#@ Eisa Alanazi;Malek Mouhoub
#t 2013
#c 11
#% 125386
#% 1272026
#! The problem of finding the set of pareto optimals for constraints and qualitative preferences together is of great interest to many application areas. It can be viewed as a preference constrained optimization problem where the goal is to find one or more feasible solutions that are not dominated by other feasible outcomes. Our work aims to enhance the current literature of the problem by providing solving methods targeting the problem in a dynamic environments. We target the problem with an eye on adopting and benefiting from the current constraint satisfaction techniques.

#index 2033298
#* Towards a deeper understanding of nonmonotonic reasoning with degrees
#@ Marjon Blondeel;Steven Schockaert;Dirk Vermeir;Martine De Cock
#t 2013
#c 11
#% 68240
#% 411814

#index 2033299
#* Capabilities in heterogeneous multi robot systems
#@ Jennifer Buehler
#t 2013
#c 11
#% 405755
#% 1768758

#index 2033300
#* Negotiation algorithms for large agreement spacess
#@ Dave De Jonge
#t 2013
#c 11
#% 870913
#% 1065068

#index 2033301
#* Trust modeling for opinion evaluation by coping with subjectivity and dishonesty
#@ Hui Fang
#t 2013
#c 11
#% 993566
#% 1875950
#% 1989653

#index 2033302
#* High-level program execution in multi-agent settings
#@ Liangda Fang
#t 2013
#c 11
#% 314845
#% 342119
#% 484915
#! In this paper, we state the challenges of high-level program execution in multi-agent settings. We first introduce high-level program execution and the related work. Then we describe the completed work, the future work and its approaches. We conclude with the expected contributions of our research.

#index 2033303
#* Using domain knowledge to systematically guide feature selection
#@ William Groves
#t 2013
#c 11
#% 243728
#% 466410
#% 729921
#! The effectiveness of machine learning models can often be improved by feature selection as a preprocessing step. Often this is a data driven process only and can result in models that may not correspond to true relationships present in the data set due to overfitting. In this work, we propose leveraging known relationships between variables to constrain and guide feature selection. Using commonalities across domains, we provide a framework for the user to express model constraints while still making the feature selection process data driven and sensitive to actual relationships in the data.

#index 2033304
#* Improving the performance of recommender systems by alleviating the data sparsity and cold start problems
#@ Guibing Guo
#t 2013
#c 11
#% 1888033
#% 1893838

#index 2033305
#* Strategic interactions among agents with bounded rationality
#@ Pablo Hernandez-Leal;Enrique Munoz De Cote;L. Enrique Sucar
#t 2013
#c 11
#% 348821
#% 960813
#% 1274755
#% 1989704
#! Interactions among agents are complicated since in order to make the best decisions, each agent has to take into account not only the strategy used by other agents but also how those strategies might change in the future (and what causes these changes). The objective of my work will be to develop a framework for learning agent models (opponent or teammate) more accurately and with less interactions, with a special focus on fast learning non-stationary strategies. As preliminary work we have proposed an initial approach for learning nonstationary strategies in repeated games. We use decision trees to learn a model of the agent, and we transform the learned trees into a MDP and solve it to obtain the optimal policy.

#index 2033306
#* Problem transformations and algorithm selection for CSPs
#@ Barry Hurley;Barry O'Sullivan
#t 2013
#c 11
#% 329487
#% 1272228
#% 1473345
#% 1737851
#% 1881912

#index 2033307
#* Rolling dispersion and exploration for robot teams
#@ Elizabeth A. Jensen
#t 2013
#c 11
#% 1910572
#! After a disaster, human rescuers may have to wait for better conditions before beginning to search for survivors. A team of robots could enter long before the humans and scope out the environment to gather information that could help to prioritize tasks for the rescue operation. We have developed an algorithm to allow a small group of robots to progressively explore an unknown environment, moving as a group until full exploration is achieved. The novel concept behind this algorithm comes from the way in which the team stays together as a group, maintaining communication, in order to ensure full exploration as well as a path to the exit. We demonstrate in simulation that the algorithm works in multiple environments under varying conditions.

#index 2033308
#* Towards the design of robust trust and reputation systems
#@ Siwei Jiang
#t 2013
#c 11
#% 1092413
#% 1875684
#% 1989654

#index 2033309
#* Maintaining soft arc consistencies in BnB-ADOPT+ during search
#@ Ka Man Lei
#t 2013
#c 11
#% 1289393
#% 1291421
#% 1473213
#% 1498839
#% 1875681

#index 2033310
#* Concept generation in language evolution
#@ Martha Lewis;Jonathan Lawry
#t 2013
#c 11
#% 757480
#% 1292076
#! This thesis investigates the generation of new concepts from combinations of existing concepts as a language evolves. We give a method for combining concepts, and will be investigating the utility of composite concepts in language evolution and thence the utility of concept generation.

#index 2033311
#* Normative conflict detection and resolution in cooperating institutions
#@ Tingting Li
#t 2013
#c 11
#% 1388288
#! Institutions (also called normative frameworks) provide an effective mechanism to govern agents in open distributed systems. An institution specifies a set of norms, with respect to the achievement of a goal or goals, that regulate agents' behaviours in terms of permissions, empowerments and obligations. However, in most real circumstances, several institutions probably have to cooperate to govern the same entities simultaneously, which is very likely to give rise to norm conflicts simply if institutions will be designed independently and typically with different goals. In this thesis, we aim: (i) to identify the different ways to combine institutions, (ii) to model those ways formally and computationally by extending an existing model for single institutions, (iii) to detect conflicts in different types of combined institutions automatically, and (iv) to resolve those conflicts via automatic norm revision using an approach based on inductive learning.

#index 2033312
#* Dynamic of argumentation frameworks
#@ Jean-Guy Mailly
#t 2013
#c 11
#% 109945
#% 198464
#% 1215696
#% 1228576
#% 1498838
#% 1630622
#% 1664525
#! My thesis work aims to study change operations for argumentation systems, especially for abstract argumentation systems à la Dung. This paper presents a first study of the AGM revision adapted to the case of argumentation. We also sketch future research works planned to complete the one already achieved.

#index 2033313
#* Approximation algorithms for max-sum-product problems
#@ Denis D. Mauá
#t 2013
#c 11
#% 448887
#% 1673033
#% 1826397
#% 1896853
#% 1911352
#! Many tasks in probabilistic reasoning can be cast as max-sum-product problems, a hard class of combinatorial problems. We describe our results in obtaining a new approximation scheme for the problem, that can be turned into an anytime procedure. For many tasks, this scheme can be shown to be asymptotically the best possible heuristic.

#index 2033314
#* On teaching collaboration to a team of autonomous agents via imitation
#@ Saleha Raza
#t 2013
#c 11
#% 126926
#% 856879
#% 1136485
#% 1187663
#! This research proposes the use of imitation based learning to build collaborative strategies for a team of agents. Imitation based learning involves learning from an expert by observing her demonstrating a task and then replicating it. This mechanism makes it extremely easy for a knowledge engineer to transfer knowledge to a software agent via human demonstrations. This research aims to apply imitation to learn not only the strategy of an individual agent but also the collaborative strategy of a team of agents to achieve a common goal. The effectiveness of the proposed methodology is being assessed in the domain of RoboCup Soccer Simulation 3D which is a promising platform to address many of the complex real-world problems and offers a truly dynamic, stochastic, and partially-observable environment.

#index 2033315
#* Semi-supervised structuring of complex data
#@ Marian-Andrei Rizoiu
#t 2013
#c 11
#% 722904
#% 1186995
#% 1826361
#% 1965172
#% 2005539
#! The objective of the thesis is to explore how complex data can be treated using unsupervised machine learning techniques, in which additional information is injected to guide the exploratory process. Starting from specific problems, our contributions take into account the different dimensions of the complex data: their nature (image, text), the additional information attached to the data (labels, structure, concept ontologies) and the temporal dimension. A special attention is given to data representation and how additional information can be leveraged to improve this representation.

#index 2033316
#* Object recognition based on visual grammars and Bayesian networks
#@ Elías Ruiz;L. Enrique Sucar
#t 2013
#c 11
#% 230296
#% 1015157
#% 1547124
#% 1565503
#% 1616279
#! A novel proposal for object recognition based on relational grammars and Bayesian Networks is presented. Based on a Symbol-Relation grammar an object is represented as a hierarchy of features and spatial relations. This representation is transformed to a Bayesian network structure which parameters are learned from examples. Thus, recognition is based on probabilistic inference in the Bayesian network representation. Preliminary results in modeling natural objects are presented.

#index 2033317
#* Adapting surface sketch recognition techniques for surfaceless sketches
#@ Paul Taele;Tracy Hammond
#t 2013
#c 11
#% 989765
#% 1065149
#% 1543077
#% 1779181
#% 1826532
#% 1910097
#! Researchers have made significant strides in developing recognition techniques for surface sketches, with realized and potential applications to motivate extending these techniques towards analogous surfaceless sketches. Yet surface sketch recognition techniques remain largely untested in surfaceless environments and are still highly constrained for related surfaceless gesture recognition techniques. The focus of the research is to investigate the performance of surface sketch recognition techniques in more challenging surfaceless environments, with the aim of addressing existing limitations through improved surfaceless sketch recognition techniques.

#index 2033318
#* Ontology based query answering with existential rules
#@ Michaël Thomazo
#t 2013
#c 11
#% 826032
#% 935898
#% 992962
#% 1217115
#% 1217122
#% 1279259
#% 1333459
#% 1585244
#% 1594576
#% 1615741
#% 1619617
#% 1619625
#% 1826177
#% 1826217
#% 1933380

#index 2033319
#* Behavior composition optimization
#@ Nitin Yadav
#t 2013
#c 11
#% 1272455
#% 1305438
#% 1615229
#% 1925331
#% 1954689
#! The behavior composition problem involves the automatic synthesis of a controller that is able to "realize" (i.e., implement) a desired target behavior specification by suitably coordinating a set of already available behaviors. While the problem has been thoroughly studied, one open issue has resisted a principled solution: if the target specification is not fully realizable, is there a way to realize it "at best"? In this doctoral work, we look at quantitative and qualitative ways to address this question.

#index 2033320
#* Incorporating expert judgement into Bayesian network machine learning
#@ Yun Zhou;Norman Fenton;Martin Neil;Cheng Zhu
#t 2013
#c 11
#% 443356
#% 961183
#% 961210
#% 992781
#% 1220052
#% 1349571
#% 1986486
#! We review the challenges of Bayesian network learning, especially parameter learning, and specify the problem of learning with sparse data. We explain how it is possible to incorporate both qualitative knowledge and data with a multinomial parameter learning method to achieve more accurate predictions with sparse data.

#index 2033321
#* Arbitration and stability in cooperative games in overlapping coalitions
#@ Yair Zick
#t 2013
#c 11
#% 1545554
#% 1614150
#% 1701146
#% 1875781

